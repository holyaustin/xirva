[{"id": "1810.00188", "submitter": "Simone Silvestri", "authors": "Simone Silvestri and Rene Pecnik", "title": "A fast GPU Monte Carlo Radiative Heat Transfer Implementation for\n  Coupling with Direct Numerical Simulation", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcpx.2019.100032", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implemented a fast Reciprocal Monte Carlo algorithm, to accurately solve\nradiative heat transfer in turbulent flows of non-grey participating media that\ncan be coupled to fully resolved turbulent flows, namely to Direct Numerical\nSimulation (DNS). The spectrally varying absorption coefficient is treated in a\nnarrow-band fashion with a correlated-k distribution. The implementation is\nverified with analytical solutions and validated with results from literature\nand line-by-line Monte Carlo computations. The method is implemented on GPU\nwith a thorough attention to memory transfer and computational efficiency. The\nbottlenecks that dominate the computational expenses are addressed and several\ntechniques are proposed to optimize the GPU execution. By implementing the\nproposed algorithmic accelerations, a speed-up of up to 3 orders of magnitude\ncan be achieved, while maintaining the same accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 10:47:13 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Silvestri", "Simone", ""], ["Pecnik", "Rene", ""]]}, {"id": "1810.00852", "submitter": "Albert Fannjiang", "authors": "Albert Fannjiang", "title": "Raster Grid Pathology and the Cure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind ptychography is a phase retrieval method using multiple coded\ndiffraction patterns from different, overlapping parts of the unknown extended\nobject illuminated with an unknown window function. The window function is also\nknown as the probe in the optics literature. As such blind ptychography is an\ninverse problem of simultaneous recovery of the object and the window function\ngiven the intensities of the windowed Fourier transform and has a multi-scale\nset-up in which the probe has an intermediate scale between the pixel scale and\nthe macro-scale of the extended object. Uniqueness problem for blind\nptychography is analyzed rigorously for the raster scan (of a constant step\nsize {\\tau}) and its variants, in which another scale comes into play: the\noverlap between adjacent blocks (the shifted windows). The block phases are\nshown to form an arithmetic progression and the complete characterization of\nthe raster scan ambiguities is given, including: First, the periodic raster\ngrid pathology of degrees of freedom proportional to {\\tau}^2 and, second, a\nnon-periodic, arithmetically progressing phase shift from block to block.\nFinally irregularly perturbed raster scans are shown to remove all ambiguities\nother than the inherent ambiguities of the scaling factor and the affine phase\nambiguity under the minimum requirement of roughly 50% overlap ratio.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 17:47:54 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 16:42:18 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 19:55:56 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fannjiang", "Albert", ""]]}, {"id": "1810.01361", "submitter": "Luisa Carracciuolo", "authors": "Luisa Carracciuolo and Emil M. Constantinescu and Luisa D'Amore", "title": "Validation of a PETSc based software implementing a 4DVAR Data\n  Assimilation algorithm: a case study related with an Oceanic Model based on\n  Shallow Water equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work are presented and discussed some results related to the\nvalidation process of a software module based on PETSc which implements a Data\nAssimilation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 16:38:07 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 09:40:53 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Carracciuolo", "Luisa", ""], ["Constantinescu", "Emil M.", ""], ["D'Amore", "Luisa", ""]]}, {"id": "1810.02243", "submitter": "Javier Bonila", "authors": "Ahad Mohammadi, Javier Bonilla, Reza Zarghami, Shahab Golshan", "title": "A Novel Heat Exchanger Design Method Using a Delayed Rejection Adaptive\n  Metropolis Hasting Algorithm", "comments": null, "journal-ref": "Applied Thermal Engineering, Volume 137, 2018, Pages 808-821", "doi": "10.1016/j.applthermaleng.2018.04.028", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a shell-and-tube heat exchanger (STHX) design based on seven\ncontinuous independent design variables is proposed. Delayed Rejection Adaptive\nMetropolis hasting (DRAM) was utilized as a powerful tool in the Markov chain\nMonte Carlo (MCMC) sampling method. This Reverse Sampling (RS) method was used\nto find the probability distribution of design variables of the shell and tube\nheat exchanger. Thanks to this probability distribution, an uncertainty\nanalysis was also performed to find the quality of these variables. In\naddition, a decision-making strategy based on confidence intervals of design\nvariables and on the Total Annual Cost (TAC) provides the final selection of\ndesign variables. Results indicated high accuracies for the estimation of\ndesign variables which leads to marginally improved performance compared to\ncommonly used optimization methods. In order to verify the capability of the\nproposed method, a case of study is also presented, it shows that a significant\ncost reduction is feasible with respect to multi-objective and single-objective\noptimization methods. Furthermore, the selected variables have good quality (in\nterms of probability distribution) and a lower TAC was also achieved. Results\nshow that the costs of the proposed design are lower than those obtained from\noptimization method reported in previous studies. The algorithm was also used\nto determine the impact of using probability values for the design variables\nrather than single values to obtain the best heat transfer area and pumping\npower. In particular, a reduction of the TAC up to 3.5% was achieved in the\ncase considered.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 08:05:37 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Mohammadi", "Ahad", ""], ["Bonilla", "Javier", ""], ["Zarghami", "Reza", ""], ["Golshan", "Shahab", ""]]}, {"id": "1810.02286", "submitter": "Janic F\\\"ocke", "authors": "Janic F\\\"ocke", "title": "SiMRX -- A Simulation toolbox for MRX", "comments": "13 pages, 3 figures, 3 listings, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SiMRX is a MRX simulation toolbox written in MATLAB for simulation of\nrealistic 2D and 3D Magnetorelaxometry (MRX) setups, including coils, sensors\nand activation patterns. MRX is a new modality that uses magnetic nanoparticles\n(MNP) as contrast agent and shows promising results in medical applications,\ne.g. cancer treatment. Its basic principles were outlined in [Baumgarten et\nal., 2008], further elaborated in [Liebl et al., 2014], transferred into a\nrigorous mathematical model and analyzed in [F\\\"ocke et al., 2018].\n  SiMRX is available at https://gitlab.com/simrx/simrx/.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:02:15 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 16:22:25 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 14:54:14 GMT"}, {"version": "v4", "created": "Fri, 26 Jul 2019 13:32:57 GMT"}, {"version": "v5", "created": "Tue, 29 Oct 2019 14:31:46 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["F\u00f6cke", "Janic", ""]]}, {"id": "1810.02315", "submitter": "Derek Chang", "authors": "Derek Chang, Devendra Shelar, and Saurabh Amin", "title": "DER Allocation and Line Repair Scheduling for Storm-induced Failures in\n  Distribution Networks", "comments": "7 pages, 4 figures, accepted to 2018 IEEE SmartGridComm Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity distribution networks (DNs) in many regions are increasingly\nsubjected to disruptions caused by tropical storms. Distributed Energy\nResources (DERs) can act as temporary supply sources to sustain \"microgrids\"\nresulting from disruptions. In this paper, we investigate the problem of\nsuitable DER allocation to facilitate more efficient repair operations and\nfaster recovery. First, we estimate the failure probabilities of DN components\n(lines) using a stochastic model of line failures which parametrically depends\non the location-specific storm wind field. Next, we formulate a two-stage\nstochastic mixed integer program, which models the distribution utility's\ndecision to allocate DERs in the DN (pre-storm stage); and accounts for\nmulti-period decisions on optimal dispatch and line repair scheduling\n(post-storm stage). A key feature of this formulation is that it jointly\noptimizes electricity dispatch within the individual microgrids and the line\nrepair schedules to minimize the sum of the cost of DER allocation and cost due\nto lost load. To illustrate our approach, we use the sample average\napproximation method to solve our problem for a small-size DN under different\nstorm intensities and DER/crew constraints.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 16:55:35 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Chang", "Derek", ""], ["Shelar", "Devendra", ""], ["Amin", "Saurabh", ""]]}, {"id": "1810.02620", "submitter": "Benjamin Wassermann", "authors": "Benjamin Wassermann, Stefan Kollmannsberger, Shuohui Yin, L\\'aszl\\'o\n  Kudela, Ernst Rank", "title": "Integrating CAD and Numerical Analysis: 'Dirty Geometry' handling using\n  the Finite Cell Method", "comments": "Accepted Manuscript", "journal-ref": "Computer Methods in Applied Mechanics and Engineering 351 (2019)\n  808-835", "doi": "10.1016/j.cma.2019.04.017", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a computational methodology for the integration of\nComputer Aided Design (CAD) and the Finite Cell Method (FCM) for models with\n\"dirty geometries\". FCM, being a fictitious domain approach based on higher\norder finite elements, embeds the physical model into a fictitious domain,\nwhich can be discretized without having to take into account the boundary of\nthe physical domain. The true geometry is captured by a precise numerical\nintegration of elements cut by the boundary. Thus, an effective Point\nMembership Classification algorithm that determines the inside-outside state of\nan integration point with respect to the physical domain is a core operation in\nFCM. To treat also \"dirty geometries\", i.e. imprecise or flawed geometric\nmodels, a combination of a segment-triangle intersection algorithm and a flood\nfill algorithm being insensitive to most CAD model flaws is proposed to\nidentify the affiliation of the integration points. The present method thus\nallows direct computations on geometrically and topologically flawed models.\nThe potential and merit for practical applications of the proposed method is\ndemonstrated by several numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 11:31:29 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 11:39:04 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Wassermann", "Benjamin", ""], ["Kollmannsberger", "Stefan", ""], ["Yin", "Shuohui", ""], ["Kudela", "L\u00e1szl\u00f3", ""], ["Rank", "Ernst", ""]]}, {"id": "1810.02815", "submitter": "Ding Xiang", "authors": "Ding Xiang, Ermin Wei", "title": "A General Sensitivity Analysis Approach for Demand Response\n  Optimizations", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE econ.GN math.OC q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that demand response can improve the system efficiency as\nwell as lower consumers' (prosumers') electricity bills. However, it is not\nclear how we can either qualitatively identify the prosumer with the most\nimpact potential or quantitatively estimate each prosumer's contribution to the\ntotal social welfare improvement when additional resource capacity/flexibility\nis introduced to the system with demand response, such as allowing net-selling\nbehavior. In this work, we build upon existing literature on the electricity\nmarket, which consists of price-taking prosumers each with various appliances,\nan electric utility company and a social welfare optimizing distribution system\noperator, to design a general sensitivity analysis approach (GSAA) that can\nestimate the potential of each consumer's contribution to the social welfare\nwhen given more resource capacity. GSAA is based on existence of an efficient\ncompetitive equilibrium, which we establish in the paper. When prosumers'\nutility functions are quadratic, GSAA can give closed forms characterization on\nsocial welfare improvement based on duality analysis. Furthermore, we extend\nGSAA to a general convex settings, i.e., utility functions with strong\nconvexity and Lipschitz continuous gradient. Even without knowing the specific\nforms the utility functions, we can derive upper and lower bounds of the social\nwelfare improvement potential of each prosumer, when extra resource is\nintroduced. For both settings, several applications and numerical examples are\nprovided: including extending AC comfort zone, ability of EV to discharge and\nnet selling. The estimation results show that GSAA can be used to decide how to\nallocate potentially limited market resources in the most impactful way.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 07:03:46 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Xiang", "Ding", ""], ["Wei", "Ermin", ""]]}, {"id": "1810.03506", "submitter": "Eric Neiva", "authors": "Eric Neiva and Santiago Badia and Alberto F. Mart\\'in and Michele\n  Chiumenti", "title": "A scalable parallel finite element framework for growing geometries.\n  Application to metal additive manufacturing", "comments": null, "journal-ref": null, "doi": "10.1002/nme.6085", "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces an innovative parallel, fully-distributed finite element\nframework for growing geometries and its application to metal additive\nmanufacturing. It is well-known that virtual part design and qualification in\nadditive manufacturing requires highly-accurate multiscale and multiphysics\nanalyses. Only high performance computing tools are able to handle such\ncomplexity in time frames compatible with time-to-market. However, efficiency,\nwithout loss of accuracy, has rarely held the centre stage in the numerical\ncommunity. Here, in contrast, the framework is designed to adequately exploit\nthe resources of high-end distributed-memory machines. It is grounded on three\nbuilding blocks: (1) Hierarchical adaptive mesh refinement with octree-based\nmeshes; (2) a parallel strategy to model the growth of the geometry; (3)\nstate-of-the-art parallel iterative linear solvers. Computational experiments\nconsider the heat transfer analysis at the part scale of the printing process\nby powder-bed technologies. After verification against a 3D benchmark, a\nstrong-scaling analysis assesses performance and identifies major sources of\nparallel overhead. A third numerical example examines the efficiency and\nrobustness of (2) in a curved 3D shape. Unprecedented parallelism and\nscalability were achieved in this work. Hence, this framework contributes to\ntake on higher complexity and/or accuracy, not only of part-scale simulations\nof metal or polymer additive manufacturing, but also in welding, sedimentation,\natherosclerosis, or any other physical problem where the physical domain of\ninterest grows in time.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 14:51:31 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 09:21:34 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 10:20:37 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Neiva", "Eric", ""], ["Badia", "Santiago", ""], ["Mart\u00edn", "Alberto F.", ""], ["Chiumenti", "Michele", ""]]}, {"id": "1810.04289", "submitter": "Fande Kong", "authors": "Fande Kong, Vitaly Kheyfets, Ender Finol, and Xiao-Chuan Cai", "title": "Simulation of unsteady blood flows in a patient-specific compliant\n  pulmonary artery with a highly parallel monolithically coupled\n  fluid-structure interaction algorithm", "comments": "24 pages, 15 figures. Submitted to International Journal of Numerical\n  Methods in Biomedical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational fluid dynamics (CFD) is increasingly used to study blood flows\nin patient-specific arteries for understanding certain cardiovascular diseases.\nThe techniques work quite well for relatively simple problems, but need\nimprovements when the problems become harder in the case when (1) the geometry\nbecomes complex (from a few branches to a full pulmonary artery), (2) the model\nbecomes more complex (from fluid-only calculation to coupled fluid-structure\ninteraction calculation), (3) both the fluid and wall models become highly\nnonlinear, and (4) the computer on which we run the simulation is a\nsupercomputer with tens of thousands of processor cores. To push the limit of\nCFD in all four fronts, in this paper, we develop and study a highly parallel\nalgorithm for solving a monolithically coupled fluid-structure system for the\nmodeling of the interaction of the blood flow and the arterial wall. As a case\nstudy, we consider a patient-specific, full size pulmonary artery obtained from\nCT (Computed Tomography) images, with an artificially added layer of wall with\na fixed thickness. The fluid is modeled with a system of incompressible\nNavier-Stokes equations and the wall is modeled by a geometrically nonlinear\nelasticity equation. As far as we know this is the first time the unsteady\nblood flow in a full pulmonary artery is simulated without assuming a rigid\nwall. The proposed numerical algorithm and software scale well beyond 10,000\nprocessor cores on a supercomputer for solving the fluid-structure interaction\nproblem discretized with a stabilized finite element method in space and an\nimplicit scheme in time involving hundreds of millions of unknowns.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 22:47:42 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kong", "Fande", ""], ["Kheyfets", "Vitaly", ""], ["Finol", "Ender", ""], ["Cai", "Xiao-Chuan", ""]]}, {"id": "1810.04410", "submitter": "Kostiantyn Maksymenko", "authors": "Kostiantyn Maksymenko (UCA), Maureen Clerc (ATHENA), Th\\'eodore\n  Papadopoulo (ATHENA)", "title": "Fast Approximation of EEG Forward Problem and Application to Tissue\n  Conductivity Estimation", "comments": "Copyright (c) 2019 IEEE. Personal use of this material is permitted.\n  However, permission to use this material for any other purposes must be\n  obtained from the IEEE by sending a request to pubs-permissions@ieee.org", "journal-ref": "IEEE Transactions on Medical Imaging, Institute of Electrical and\n  Electronics Engineers, In press, \\&\\#x27E8;10.1109/TMI.2019.2936921\\&\\#x27E9", "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bioelectric source analysis in the human brain from scalp\nelectroencephalography (EEG) signals is sensitive to the conductivity of the\ndifferent head tissues. Conductivity values are subject dependent, so\nnon-invasive methods for conductivity estimation are necessary to fine tune the\nEEG models. To do so, the EEG forward problem solution (so-called lead field\nmatrix) must be computed for a large number of conductivity configurations.\nComputing one lead field requires a matrix inversion which is computationally\nintensive for realistic head models. Thus, the required time for computing a\nlarge number of lead fields can become impractical. In this work, we propose to\napproximate the lead field matrix for a set of conductivity configurations,\nusing the exact solution only for a small set of basis points in the\nconductivity space. Our approach accelerates the computing time, while\ncontrolling the approximation error. Our method is tested for brain and skull\nconductivity estimation , with simulated and measured EEG data, corresponding\nto evoked somato-sensory potentials. This test demonstrates that the used\napproximation does not introduce any bias and runs significantly faster than if\nexact lead field were to be computed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 08:17:17 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:49:16 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Maksymenko", "Kostiantyn", "", "UCA"], ["Clerc", "Maureen", "", "ATHENA"], ["Papadopoulo", "Th\u00e9odore", "", "ATHENA"]]}, {"id": "1810.04412", "submitter": "Ankit Kumar Shukla", "authors": "Ashutosh Gupta, Somya Mani, and Ankit Shukla", "title": "Synthesis for Vesicle Traffic Systems", "comments": "18 pages, 2 figures, 1 table", "journal-ref": null, "doi": "10.1007/978-3-319-99429-1_6", "report-no": null, "categories": "q-bio.SC cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vesicle Traffic Systems (VTSs) are the material transport mechanisms among\nthe compartments inside the biological cells. The compartments are viewed as\nnodes that are labeled with the containing chemicals and the transport channels\nare similarly viewed as labeled edges between the nodes. Understanding VTSs is\nan ongoing area of research and for many cells they are partially known. For\nexample, there may be undiscovered edges, nodes, or their labels in a VTS of a\ncell. It has been speculated that there are properties that the VTSs must\nsatisfy. For example, stability, i.e., every chemical that is leaving a\ncompartment comes back. Many synthesis questions may arise in this scenario,\nwhere we want to complete a partially known VTS under a given property. In the\npaper, we present novel encodings of the above questions into the QBF\n(quantified Boolean formula) satisfiability problems. We have implemented the\nencodings in a highly configurable tool and applied to a couple of\nfound-in-nature VTSs and several synthetic graphs. Our results demonstrate that\nour method can scale up to the graphs of interest.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 08:34:50 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Gupta", "Ashutosh", ""], ["Mani", "Somya", ""], ["Shukla", "Ankit", ""]]}, {"id": "1810.04776", "submitter": "Carlos Lima Azevedo", "authors": "Carlos Lima Azevedo and Jo\\~ao L. Cardoso and Moshe E. Ben-Akiva", "title": "Probabilistic Safety Analysis using Traffic Microscopic Simulation", "comments": "18 pages, 6 figures, revised and extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic microscopic simulation applications are a common tool in road\ntransportation analysis and several attempts to perform road safety assessments\nhave recently been carried out. However, these approaches often ignore causal\nrelationships between different levels of vehicle interactions and/or accident\ntypes and they lack a physical representation of the accident phenomena itself.\nIn this paper, a new generic probabilistic safety assessment framework for\ntraffic microscopic simulation tools is proposed. The probability of a specific\naccident occurring is estimated by an accident propensity function that\nconsists of a deterministic safety score component and a random component. The\nformulation of the safety score depends on the type of occurrence, on detailed\nvehicle interactions and maneuvers and on its representation in a simulation\nenvironment. This generic model is applied to the case of an urban motorway and\nspecified to four types of outcomes: non-accident events and three types of\naccidents in a nested structure: rear-end, lane-changing, and run-off-road\naccidents. The model was estimated and validated using simulated microscopic\ndata. To obtained the consistent simulated data, a two-step simulation\ncalibration procedure was adopted: (1) using real trajectories collected on\nsite for detailed behavior representation; and (2) using aggregate data from\neach event used in safety model estimation. The final estimated safety model is\nable to identify and interpret several simulated vehicle interactions. The fact\nthat these outcomes were extracted from simulated analysis shows the real\npotential of calibrated traffic microscopic simulation for detailed safety\nassessments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 23:15:08 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Azevedo", "Carlos Lima", ""], ["Cardoso", "Jo\u00e3o L.", ""], ["Ben-Akiva", "Moshe E.", ""]]}, {"id": "1810.05268", "submitter": "Navjot Kukreja", "authors": "Navjot Kukreja, Jan Huckelheim, Mathias Louboutin, Kaiyuan Hou, Fabio\n  Luporini, Paul Hovland, Gerard Gorman", "title": "Combining checkpointing and data compression for large scale seismic\n  inversion", "comments": "Submitted to the 4th International Workshop on Data Reduction for Big\n  Scientific Data (DRBSD-4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Seismic inversion and imaging are adjoint-based optimization problems that\nprocesses up to terabytes of data, regularly exceeding the memory capacity of\navailable computers. Data compression is an effective strategy to reduce this\nmemory requirement by a certain factor, particularly if some loss in accuracy\nis acceptable. A popular alternative is checkpointing, where data is stored at\nselected points in time, and values at other times are recomputed as needed\nfrom the last stored state. This allows arbitrarily large adjoint computations\nwith limited memory, at the cost of additional recomputations. In this paper we\ncombine compression and checkpointing for the first time to compute a realistic\nseismic inversion. The combination of checkpointing and compression allows\nlarger adjoint computations compared to using only compression, and reduces the\nrecomputation overhead significantly compared to using only checkpointing.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 21:58:47 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Kukreja", "Navjot", ""], ["Huckelheim", "Jan", ""], ["Louboutin", "Mathias", ""], ["Hou", "Kaiyuan", ""], ["Luporini", "Fabio", ""], ["Hovland", "Paul", ""], ["Gorman", "Gerard", ""]]}, {"id": "1810.05451", "submitter": "Martin Pfaller", "authors": "Martin R. Pfaller, Julia M. H\\\"ormann, Martina Weigl, Andreas Nagler,\n  Radomir Chabiniok, Crist\\'obal Bertoglio, Wolfgang A. Wall", "title": "The importance of the pericardium for cardiac biomechanics: From\n  physiology to computational modeling", "comments": null, "journal-ref": null, "doi": "10.1007/s10237-018-1098-4", "report-no": null, "categories": "cs.CE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human heart is enclosed in the pericardial cavity. The pericardium\nconsists of a layered thin sac and is separated from the myocardium by a thin\nfilm of fluid. It provides a fixture in space and frictionless sliding of the\nmyocardium. The influence of the pericardium is essential for predictive\nmechanical simulations of the heart. However, there is no consensus on\nphysiologically correct and computationally tractable pericardial boundary\nconditions. Here we propose to model the pericardial influence as a parallel\nspring and dashpot acting in normal direction to the epicardium. Using a\nfour-chamber geometry, we compare a model with pericardial boundary conditions\nto a model with fixated apex. The influence of pericardial stiffness is\ndemonstrated in a parametric study. Comparing simulation results to\nmeasurements from cine magnetic resonance imaging reveals that adding\npericardial boundary conditions yields a better approximation with respect to\natrioventricular plane displacement, atrial filling, and overall spatial\napproximation error. We demonstrate that this simple model of\npericardial-myocardial interaction can correctly predict the pumping mechanisms\nof the heart as previously assessed in clinical studies. Utilizing a\npericardial model can not only provide much more realistic cardiac mechanics\nsimulations but also allows new insights into pericardial-myocardial\ninteraction which cannot be assessed in clinical measurements yet.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 11:26:15 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Pfaller", "Martin R.", ""], ["H\u00f6rmann", "Julia M.", ""], ["Weigl", "Martina", ""], ["Nagler", "Andreas", ""], ["Chabiniok", "Radomir", ""], ["Bertoglio", "Crist\u00f3bal", ""], ["Wall", "Wolfgang A.", ""]]}, {"id": "1810.05547", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "Physics-Driven Regularization of Deep Neural Networks for Enhanced\n  Engineering Design and Analysis", "comments": null, "journal-ref": "Journal of Computing and Information Science in Engineering, 20(1)\n  (2020)", "doi": "10.1115/1.4044507", "report-no": null, "categories": "cs.LG cs.CE cs.NA math.AP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a physics-driven regularization method for\ntraining of deep neural networks (DNNs) for use in engineering design and\nanalysis problems. In particular, we focus on prediction of a physical system,\nfor which in addition to training data, partial or complete information on a\nset of governing laws is also available. These laws often appear in the form of\ndifferential equations, derived from first principles, empirically-validated\nlaws, or domain expertise, and are usually neglected in data-driven prediction\nof engineering systems. We propose a training approach that utilizes the known\ngoverning laws and regularizes data-driven DNN models by penalizing divergence\nfrom those laws. The first two numerical examples are synthetic examples, where\nwe show that in constructing a DNN model that best fits the measurements from a\nphysical system, the use of our proposed regularization results in DNNs that\nare more interpretable with smaller generalization errors, compared to other\ncommon regularization methods. The last two examples concern metamodeling for a\nrandom Burgers' system and for aerodynamic analysis of passenger vehicles,\nwhere we demonstrate that the proposed regularization provides superior\ngeneralization accuracy compared to other common alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 17:12:34 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 22:27:24 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "1810.06077", "submitter": "Wei Dai", "authors": "Jingyuan Xia, Wei Dai, John Polak, and Michel Bierlaire", "title": "Dimension Reduction for Origin-Destination Flow Estimation: Blind\n  Estimation Made Possible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of estimating origin-destination (OD) flows\nfrom link flows. As the number of link flows is typically much less than that\nof OD flows, the inverse problem is severely ill-posed and hence prior\ninformation is required to recover the ground truth. The basic approach in the\nliterature relies on a forward model where the so called traffic assignment\nmatrix maps OD flows to link flows. Due to the ill-posedness of the problem,\nprior information on the assignment matrix and OD flows are typically needed.\n  The main contributions of this paper include a dimension reduction of the\ninquired flows from $O(n^2)$ to $O(n)$, and a demonstration that for the first\ntime the ground truth OD flows can be uniquely identified with no or little\nprior information. To cope with the ill-posedness due to the large number of\nunknowns, a new forward model is developed which does not involve OD flows\ndirectly but is built upon the flows characterized only by their origins,\nhenceforth referred as O-flows. The new model preserves all the OD information\nand more importantly reduces the dimension of the inverse problem\nsubstantially. A Gauss-Seidel method is deployed to solve the inverse problem,\nand a necessary condition for the uniqueness of the solution is proved.\nSimulations demonstrate that blind estimation where no prior information is\navailable is possible for some network settings. Some challenging network\nsettings are identified and discussed, where a remedy based on temporal\npatterns of the O-flows is developed and numerically shown effective.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 18:49:25 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Xia", "Jingyuan", ""], ["Dai", "Wei", ""], ["Polak", "John", ""], ["Bierlaire", "Michel", ""]]}, {"id": "1810.07026", "submitter": "Markus H\\\"ohnerbach", "authors": "Markus H\\\"ohnerbach, Paolo Bientinesi", "title": "Optimizing AIREBO: Navigating the Journey from Complex Legacy Code to\n  High Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite initiatives to improve the quality of scientific codes, there still\nis a large presence of legacy code. Such code often needs to implement a lot of\nfunctionality under time constrains, sacrificing quality. Additionally, quality\nis rarely improved by optimizations for new architectures. This development\nmodel leads to code that is increasingly difficult to work with. Our suggested\nsolution includes complexity-reducing refactoring and hardware abstraction. We\nfocus on the AIREBO potential from LAMMPS, where the challenge is that any\npotential kernel is rather large and complex, hindering systematic\noptimization. This issue is common to codes that model multiple physical\nphenomena. We present our journey from the C++ port of a previous Fortran code\nto performance-portable, KNC-hybrid, vectorized, scalable, optimized code\nsupporting full and reduced precision. The journey includes extensive testing\nthat fixed bugs in the original code. Large-scale, full-precision runs sustain\nspeedups of more than 4x (KNL) and 3x (Skylake).\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 14:21:18 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["H\u00f6hnerbach", "Markus", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1810.07277", "submitter": "Zhenxing Cheng", "authors": "Zhenxing Cheng, Hu Wang, Gui-rong Liu", "title": "Closed loop image aided optimization for cold spray process based on\n  molecular dynamics", "comments": "15 pages, 4 tables, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposed a closed loop image aided optimization (CLIAO) method to\nimprove the quality of deposition during the cold spray process. Some recent\nresearch shows that the quality of deposition measured by flattening ratio of\nthe bonded particle is associated with impact velocity, angle and particle\nsize. Therefore, the original idea of CLIAO is to improve the quality of\ndeposition by obtaining the maximum flattening ratio which is extracted from\nthe molecular dynamics (MD) simulation snapshots directly. To complete this\nstrategy, a Python script is suggested to generate the required snapshots from\nresult files automatically and the image processing technique is used to\nevaluate the flattening ratio from the snapshots. Moreover, three optimization\nmethods including surrogate optimization (Efficient Global Optimization) and\nheuristic algorithms (Particle Swarm Optimization, Different Evolution\nalgorithm) are engaged. Then a back propagation neural network (BPNN) is used\nto accelerate the process of optimization, where the BPNN is used to build the\nmeta-model instead of the forward calculation. The optimization result\ndemonstrates that all the above methods can obtain the acceptable solution. The\ncomparison between those methods is also given and the selection of them should\nbe determined by the trade-off between efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:09:26 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Cheng", "Zhenxing", ""], ["Wang", "Hu", ""], ["Liu", "Gui-rong", ""]]}, {"id": "1810.07310", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Wibe A. de Jong", "title": "Prediction of Atomization Energy Using Graph Kernel and Active Learning", "comments": null, "journal-ref": "J. Chem. Phys. 150(4): 044107, 2019", "doi": "10.1063/1.5078640", "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci cs.CE physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven prediction of molecular properties presents unique challenges to\nthe design of machine learning methods concerning data\nstructure/dimensionality, symmetry adaption, and confidence management. In this\npaper, we present a kernel-based pipeline that can learn and predict the\natomization energy of molecules with high accuracy. The framework employs\nGaussian process regression to perform predictions based on the similarity\nbetween molecules, which is computed using the marginalized graph kernel. To\napply the marginalized graph kernel, a spatial adjacency rule is first employed\nto convert molecules into graphs whose vertices and edges are labeled by\nelements and interatomic distances, respectively. We then derive formulas for\nthe efficient evaluation of the kernel. Specific functional components for the\nmarginalized graph kernel are proposed, while the effect of the associated\nhyperparameters on accuracy and predictive confidence are examined. We show\nthat the graph kernel is particularly suitable for predicting extensive\nproperties because its convolutional structure coincides with that of the\ncovariance formula between sums of random variables. Using an active learning\nprocedure, we demonstrate that the proposed method can achieve a mean absolute\nerror of 0.62 +- 0.01 kcal/mol using as few as 2000 training samples on the QM7\ndata set.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:21:03 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 06:39:50 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 06:00:28 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Tang", "Yu-Hang", ""], ["de Jong", "Wibe A.", ""]]}, {"id": "1810.07619", "submitter": "Christian Krogh", "authors": "Christian Krogh, Johnny Jakobsen and James A. Sherwood", "title": "Development of a Computationally Efficient Fabric Model for Optimization\n  of Gripper Trajectories in Automated Composite Draping", "comments": null, "journal-ref": "EngOpt 2018: EngOpt 2018 Proceedings of the 6th International\n  Conference on Engineering Optimization pp 1107-1118", "doi": "10.1007/978-3-319-97773-7_96", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An automated prepreg fabric draping system is being developed which consists\nof an array of actuated grippers. It has the ability to pick up a fabric ply\nand place it onto a double-curved mold surface. A previous research effort\nbased on a nonlinear Finite Element model showed that the movements of the\ngrippers should be chosen carefully to avoid misplacement and induce of\nwrinkles in the draped configuration. Thus, the present study seeks to develop\na computationally efficient model of the mechanical behavior of a fabric based\non 2D catenaries which can be used for optimization of the gripper\ntrajectories. The model includes bending stiffness, large deflections, large\nply shear and a simple contact formulation. The model is found to be quick to\nevaluate and gives very reasonable predictions of the displacement field.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 15:36:02 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Krogh", "Christian", ""], ["Jakobsen", "Johnny", ""], ["Sherwood", "James A.", ""]]}, {"id": "1810.08649", "submitter": "Marta Bagi\\'nska", "authors": "Marta Bagi\\'nska and Piotr E. Srokosz", "title": "The Optimal ANN Model for Predicting Bearing Capacity of Shallow\n  Foundations Trained on Scarce Data", "comments": "KSCE Journal of Civil Engineering 2018", "journal-ref": null, "doi": "10.1007/s12205-018-2636-4", "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study is focused on determining the potential of using deep neural\nnetworks (DNNs) to predict the ultimate bearing capacity of shallow foundation\nin situations when the experimental data which may be used to train networks is\nscarce. Two experiments involving testing over 17000 networks were conducted.\nThe first experiment was aimed at comparing the accuracy of shallow neural\nnetworks and DNNs predictions. It shows that when the experimental dataset used\nfor preparing models is small then DNNs have a significant advantage over\nshallow networks. The second experiment was conducted to compare the\nperformance of DNNs consisting of different number of neurons and layers.\nObtained results indicate that the optimal number of layers varies between 5 to\n7. Networks with less and - surprisingly - more layers obtain lower accuracy.\nMoreover, the number of neurons in DNN has a lower impact on the prediction\naccuracy than the number of DNN's layers. DNNs perform very well, even when\ntrained with only 6 samples. Basing on the results it seems that when\npredicting the ultimate bearing capacity with ANN models obtaining small but\nhigh-quality experimental training datasets instead of large training datasets\naffected by a higher error is an advisable approach.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 11:17:43 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bagi\u0144ska", "Marta", ""], ["Srokosz", "Piotr E.", ""]]}, {"id": "1810.08923", "submitter": "Ehsan Hoseinzade", "authors": "Ehsan Hoseinzade, Saman Haratizadeh", "title": "CNNPred: CNN-based stock market prediction using several data sources", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.NE q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction from financial data is one of the most important problems\nin market prediction domain for which many approaches have been suggested.\nAmong other modern tools, convolutional neural networks (CNN) have recently\nbeen applied for automatic feature selection and market prediction. However, in\nexperiments reported so far, less attention has been paid to the correlation\namong different markets as a possible source of information for extracting\nfeatures. In this paper, we suggest a CNN-based framework with specially\ndesigned CNNs, that can be applied on a collection of data from a variety of\nsources, including different markets, in order to extract features for\npredicting the future of those markets. The suggested framework has been\napplied for predicting the next day's direction of movement for the indices of\nS&P 500, NASDAQ, DJI, NYSE, and RUSSELL markets based on various sets of\ninitial features. The evaluations show a significant improvement in\nprediction's performance compared to the state of the art baseline algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 10:34:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hoseinzade", "Ehsan", ""], ["Haratizadeh", "Saman", ""]]}, {"id": "1810.09435", "submitter": "Pablo Fernandez", "authors": "Pablo Fernandez, Ngoc-Cuong Nguyen, Jaime Peraire", "title": "On the ability of discontinuous Galerkin methods to simulate\n  under-resolved turbulent flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the ability of discontinuous Galerkin (DG) methods to simulate\nunder-resolved turbulent flows in large-eddy simulation. The role of the\nRiemann solver and the subgrid-scale model in the prediction of a variety of\nflow regimes, including transition to turbulence, wall-free turbulence and\nwall-bounded turbulence, are examined. Numerical and theoretical results show\nthe Riemann solver in the DG scheme plays the role of an implicit subgrid-scale\nmodel and introduces numerical dissipation in under-resolved turbulent regions\nof the flow. This implicit model behaves like a dynamic model and vanishes for\nflows that do not contain subgrid scales, such as laminar flows, which is a\ncritical feature to accurately predict transition to turbulence. In addition,\nfor the moderate-Reynolds-number turbulence problems considered, the implicit\nmodel provides a more accurate representation of the actual subgrid scales in\nthe flow than state-of-the-art explicit eddy viscosity models, including\ndynamic Smagorinsky, WALE and Vreman. The results in this paper indicate new\nbest practices for subgrid-scale modeling are needed with high-order DG\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 19:46:24 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Fernandez", "Pablo", ""], ["Nguyen", "Ngoc-Cuong", ""], ["Peraire", "Jaime", ""]]}, {"id": "1810.09936", "submitter": "Fuli Feng", "authors": "Fuli Feng, Huimin Chen, Xiangnan He, Ji Ding, Maosong Sun, Tat-Seng\n  Chua", "title": "Enhancing Stock Movement Prediction with Adversarial Training", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes a new machine learning solution for stock movement\nprediction, which aims to predict whether the price of a stock will be up or\ndown in the near future. The key novelty is that we propose to employ\nadversarial training to improve the generalization of a neural network\nprediction model. The rationality of adversarial training here is that the\ninput features to stock prediction are typically based on stock price, which is\nessentially a stochastic variable and continuously changed with time by nature.\nAs such, normal training with static price-based features (e.g. the close\nprice) can easily overfit the data, being insufficient to obtain reliable\nmodels. To address this problem, we propose to add perturbations to simulate\nthe stochasticity of price variable, and train the model to work well under\nsmall yet intentional perturbations. Extensive experiments on two real-world\nstock data show that our method outperforms the state-of-the-art solution with\n3.11% relative improvements on average w.r.t. accuracy, validating the\nusefulness of adversarial training for stock prediction task.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 07:27:19 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 11:43:26 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Feng", "Fuli", ""], ["Chen", "Huimin", ""], ["He", "Xiangnan", ""], ["Ding", "Ji", ""], ["Sun", "Maosong", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1810.10103", "submitter": "Shobhit Jain", "authors": "Shobhit Jain, Thomas Breunung, George Haller", "title": "Fast Computation of Steady-State Response for Nonlinear Vibrations of\n  High-Degree-of-Freedom Systems", "comments": null, "journal-ref": null, "doi": "10.1007/s11071-019-04971-1", "report-no": null, "categories": "math.DS cs.CE cs.NA nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss an integral equation approach that enables fast computation of the\nresponse of nonlinear multi-degree-of-freedom mechanical systems under periodic\nand quasi-periodic external excitation. The kernel of this integral equation is\na Green's function that we compute explicitly for general mechanical systems.\nWe derive conditions under which the integral equation can be solved by a\nsimple and fast Picard iteration even for non-smooth mechanical systems. The\nconvergence of this iteration cannot be guaranteed for near-resonant forcing,\nfor which we employ a Newton--Raphson iteration instead, obtaining robust\nconvergence. We further show that this integral-equation approach can be\nappended with standard continuation schemes to achieve an additional,\nsignificant performance increase over common approaches to computing\nsteady-state response.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 21:42:19 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Jain", "Shobhit", ""], ["Breunung", "Thomas", ""], ["Haller", "George", ""]]}, {"id": "1810.10384", "submitter": "Roger Sauer", "authors": "Roger A. Sauer, Reza Ghaffari and Anurag Gupta", "title": "The multiplicative deformation split for shells with application to\n  growth, chemical swelling, thermoelasticity, viscoelasticity and\n  elastoplasticity", "comments": null, "journal-ref": "International Journal of Solids and Structures, Volumes 174-175,\n  Pages 53-68, 2019", "doi": "10.1016/j.ijsolstr.2019.06.002", "report-no": null, "categories": "physics.class-ph cs.CE math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a general unified theory for coupled nonlinear elastic and\ninelastic deformations of curved thin shells. The coupling is based on a\nmultiplicative decomposition of the surface deformation gradient. The\nkinematics of this decomposition is examined in detail. In particular, the\ndependency of various kinematical quantities, such as area change and\ncurvature, on the elastic and inelastic strains is discussed. This is essential\nfor the development of general constitutive models. In order to fully explore\nthe coupling between elastic and different inelastic deformations, the surface\nbalance laws for mass, momentum, energy and entropy are examined in the context\nof the multiplicative decomposition. Based on the second law of thermodynamics,\nthe general constitutive relations are then derived. Two cases are considered:\nIndependent inelastic strains, and inelastic strains that are functions of\ntemperature and concentration. The constitutive relations are illustrated by\nseveral nonlinear examples on growth, chemical swelling, thermoelasticity,\nviscoelasticity and elastoplasticity of shells. The formulation is fully\nexpressed in curvilinear coordinates leading to compact and elegant expressions\nfor the kinematics, balance laws and constitutive relations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 14:23:21 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 10:19:40 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Sauer", "Roger A.", ""], ["Ghaffari", "Reza", ""], ["Gupta", "Anurag", ""]]}, {"id": "1810.10422", "submitter": "Jabarullah Khan Nagoor Kani", "authors": "J.Nagoor Kani and Ahmed H. Elsheikh", "title": "Reduced order modeling of subsurface multiphase flow models using deep\n  residual recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a reduced order modeling (ROM) technique for subsurface\nmulti-phase flow problems building on the recently introduced deep residual\nrecurrent neural network (DR-RNN) [1]. DR-RNN is a physics aware recurrent\nneural network for modeling the evolution of dynamical systems. The DR-RNN\narchitecture is inspired by iterative update techniques of line search methods\nwhere a fixed number of layers are stacked together to minimize the residual\n(or reduced residual) of the physical model under consideration. In this\nmanuscript, we combine DR-RNN with proper orthogonal decomposition (POD) and\ndiscrete empirical interpolation method (DEIM) to reduce the computational\ncomplexity associated with high-fidelity numerical simulations. In the\npresented formulation, POD is used to construct an optimal set of reduced basis\nfunctions and DEIM is employed to evaluate the nonlinear terms independent of\nthe full-order model size.\n  We demonstrate the proposed reduced model on two uncertainty quantification\ntest cases using Monte-Carlo simulation of subsurface flow with random\npermeability field. The obtained results demonstrate that DR-RNN combined with\nPOD-DEIM provides an accurate and stable reduced model with a fixed\ncomputational budget that is much less than the computational cost of standard\nPOD-Galerkin reduced model combined with DEIM for nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 14:33:29 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Kani", "J. Nagoor", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "1810.10858", "submitter": "Christoph Meier", "authors": "Christoph Meier and Alexander Popp and Wolfgang A. Wall", "title": "Extended Comment on the Article \"Consistent Development of a\n  Beam-To-Beam Contact Algorithm via the Curve to Solid Beam Contact - Analysis\n  for the Non-Frictional Case\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the authors' previous works, novel finite element formulations for the\ncontact interaction of slender beams have been proposed. In their recent\narticle \"Consistent Development of a Beam-To-Beam Contact Algorithm via the\nCurve to Solid Beam Contact - Analysis for the Non-Frictional Case\", Konyukhov\net al. refer extensively to the aforementioned works by the authors. However,\nmany of these statements turn out to be scientifically incorrect and not only\nquestion the quality and correctness of the authors' previous works in a way\nthat is neither objective nor justified but also might cause quite some\nconfusion to researchers in this field. Hence, the authors find it necessary to\ncomment on these statements, disprove them if incorrect, and demonstrate the\ncorrectness of the derivations made in their previous works.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 14:40:23 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Meier", "Christoph", ""], ["Popp", "Alexander", ""], ["Wall", "Wolfgang A.", ""]]}, {"id": "1810.12033", "submitter": "Martin Pfaller", "authors": "Martin R. Pfaller, Maria Cruz Varona, Johannes Lang, Crist\\'obal\n  Bertoglio, Wolfgang A. Wall", "title": "Parametric model order reduction and its application to inverse analysis\n  of large nonlinear coupled cardiac problems", "comments": null, "journal-ref": null, "doi": "10.1002/cnm.3320", "report-no": null, "categories": "cs.CE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive high-fidelity finite element simulations of human cardiac\nmechanics co\\-mmon\\-ly require a large number of structural degrees of freedom.\nAdditionally, these models are often coupled with lumped-parameter models of\nhemodynamics. High computational demands, however, slow down model calibration\nand therefore limit the use of cardiac simulations in clinical practice. As\ncardiac models rely on several patient-specific parameters, just one solution\ncorresponding to one specific parameter set does not at all meet clinical\ndemands. Moreover, while solving the nonlinear problem, 90\\% of the computation\ntime is spent solving linear systems of equations. We propose a novel approach\nto reduce only the structural dimension of the monolithically coupled\nstructure-windkessel system by projection onto a lower-dimensional subspace. We\nobtain a good approximation of the displacement field as well as of key scalar\ncardiac outputs even with very few reduced degrees of freedom while achieving\nconsiderable speedups. For subspace generation, we use proper orthogonal\ndecomposition of displacement snapshots. To incorporate changes in the\nparameter set into our reduced order model, we provide a comparison of subspace\ninterpolation methods. We further show how projection-based model order\nreduction can be easily integrated into a gradient-based optimization and\ndemonstrate its performance in a real-world multivariate inverse analysis\nscenario. Using the presented projection-based model order reduction approach\ncan significantly speed up model personalization and could be used for\nmany-query tasks in a clinical setting.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:03:22 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Pfaller", "Martin R.", ""], ["Varona", "Maria Cruz", ""], ["Lang", "Johannes", ""], ["Bertoglio", "Crist\u00f3bal", ""], ["Wall", "Wolfgang A.", ""]]}, {"id": "1810.12228", "submitter": "Pei Cao", "authors": "Pei Cao, Qi Shuai and Jiong Tang", "title": "Leveraging Gaussian Process and Voting-Empowered Many-Objective\n  Evaluation for Fault Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using piezoelectric impedance/admittance sensing for structural health\nmonitoring is promising, owing to the simplicity in circuitry design as well as\nthe high-frequency interrogation capability. The actual identification of fault\nlocation and severity using impedance/admittance measurements, nevertheless,\nremains to be an extremely challenging task. A first-principle based structural\nmodel using finite element discretization requires high dimensionality to\ncharacterize the high-frequency response. As such, direct inversion using the\nsensitivity matrix usually yields an under-determined problem. Alternatively,\nthe identification problem may be cast into an optimization framework in which\nfault parameters are identified through repeated forward finite element\nanalysis which however is oftentimes computationally prohibitive. This paper\npresents an efficient data-assisted optimization approach for fault\nidentification without using finite element model iteratively. We formulate a\nmany-objective optimization problem to identify fault parameters, where\nresponse surfaces of impedance measurements are constructed through Gaussian\nprocess-based calibration. To balance between solution diversity and\nconvergence, an -dominance enabled many-objective simulated annealing algorithm\nis established. As multiple solutions are expected, a voting score calculation\nprocedure is developed to further identify those solutions that yield better\nimplications regarding structural health condition. The effectiveness of the\nproposed approach is demonstrated by systematic numerical and experimental case\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 16:15:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Cao", "Pei", ""], ["Shuai", "Qi", ""], ["Tang", "Jiong", ""]]}, {"id": "1810.12401", "submitter": "Vitalii Makogin", "authors": "Denis Dresvyanskiy and Tatiana Karaseva and Sergei Mitrofanov and\n  Claudia Redenbach and Stefanie Schwaar and Vitalii Makogin and Evgeny\n  Spodarev", "title": "Application of Clustering Methods to Anomaly Detection in Fibrous Media", "comments": null, "journal-ref": null, "doi": "10.1088/1757-899X/537/2/022001", "report-no": null, "categories": "stat.AP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers the problem of anomaly detection in 3D images of fibre\nmaterials. The spatial Stochastic Expectation Maximisation algorithm and\nAdaptive Weights Clustering are applied to solve this problem. The initial 3D\ngrey scale image was divided into small cubes subject to clustering. For each\ncube clustering attributes values were calculated: mean local direction and\ndirectional entropy. Clustering is conducted according to the given attributes.\nThe proposed methods are tested on the simulated images and on real fibre\nmaterials.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:43:31 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Dresvyanskiy", "Denis", ""], ["Karaseva", "Tatiana", ""], ["Mitrofanov", "Sergei", ""], ["Redenbach", "Claudia", ""], ["Schwaar", "Stefanie", ""], ["Makogin", "Vitalii", ""], ["Spodarev", "Evgeny", ""]]}, {"id": "1810.12441", "submitter": "Gustav Markkula", "authors": "Gustav Markkula, Richard Romano, Rachel Waldram, Oscar Giles, Callum\n  Mole, Richard Wilkie", "title": "Modelling visual-vestibular integration and behavioural adaptation in\n  the driving simulator", "comments": "Changes in v2: Minor language improvements to Abstract and\n  Conclusion; Changes in v3: Added acknowledgments and data statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well established that not only vision but also other sensory modalities\naffect drivers' control of their vehicles, and that drivers adapt over time to\npersistent changes in sensory cues (for example in driving simulators), but the\nmechanisms underlying these behavioural phenomena are poorly understood. Here,\nwe consider the existing literature on how driver steering in slalom tasks is\naffected by the down-scaling of vestibular cues, and propose a driver model\nthat can explain the empirically observed effects, namely: decreased task\nperformance and increased steering effort during initial exposure, followed by\na partial reversal of these effects as task exposure is prolonged.\nUnexpectedly, the model also reproduced another empirical finding: a local\noptimum for motion down-scaling, where path-tracking is better than when\none-to-one motion cues are available. Overall, the results imply that: (1)\ndrivers make direct use of vestibular information as part of determining\nappropriate steering, and (2) motion down-scaling causes a yaw rate\nunderestimation phenomenon, where drivers behave as if the simulated vehicle is\nrotating more slowly than it is. However, (3) in the slalom task, a certain\ndegree of such yaw rate underestimation is beneficial to path tracking\nperformance. Furthermore, (4) behavioural adaptation, as empirically observed\nin slalom tasks, may occur due to (a) down-weighting of vestibular cues, and/or\n(b) increased sensitivity to control errors, in determining when to adjust\nsteering and by how much, but (c) seemingly not in the form of a full\ncompensatory rescaling of the received vestibular input. The analyses presented\nhere provide new insights and hypotheses about simulator driving, and the\ndeveloped models can be used to support research on multisensory integration\nand behavioural adaptation in both driving and other task domains.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:30:06 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 16:58:36 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 09:14:46 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Markkula", "Gustav", ""], ["Romano", "Richard", ""], ["Waldram", "Rachel", ""], ["Giles", "Oscar", ""], ["Mole", "Callum", ""], ["Wilkie", "Richard", ""]]}, {"id": "1810.13263", "submitter": "Sebastian Sch\\\"ops", "authors": "Stephanie Friedhoff, Jens Hahne, Iryna Kulchytska-Ruchka, and\n  Sebastian Sch\\\"ops", "title": "Exploring Parallel-in-Time Approaches for Eddy Current Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the usage of parallel-in-time algorithms of the Parareal and\nmultigrid-reduction-in-time (MGRIT) methodologies for the parallel-in-time\nsolution of the eddy current problem. Via application of these methods to a\ntwo-dimensional model problem for a coaxial cable model, we show that a\nsignificant speedup can be achieved in comparison to sequential time stepping.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 13:03:30 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Friedhoff", "Stephanie", ""], ["Hahne", "Jens", ""], ["Kulchytska-Ruchka", "Iryna", ""], ["Sch\u00f6ps", "Sebastian", ""]]}]