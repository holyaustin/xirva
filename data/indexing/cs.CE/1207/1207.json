[{"id": "1207.0313", "submitter": "Yuriy Ostapov", "authors": "Yuriy Ostapov", "title": "Intellectual Management of Enterprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new technology (in addition to ERP) is proposed to provide an increase of\nprofit and normal cash flow. This technology involves the next functions:\nforming of intellectual interface on a natural language to communicate with a\ncontrol system; joint planning of production and sales to get the maximal\nprofit; an adaptation of control system to internal and external events. The\nuse of the natural language permits to overcome a barrier between the control\nsystem and upper managers. To solve posed actual problems of management the\nselection of information from a database and call to mathematical methods are\nexecuted automatically. Optimal planning provides the maximal use of available\nresources and opportunities of market. Adaptive control implements the\nefficient reaction to critical events that lead up to a decrease of profit and\nincrease of accounts receivable.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 09:18:53 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Ostapov", "Yuriy", ""]]}, {"id": "1207.0689", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho, N\\'uria Forns, Antoni Hern\\'andez-Fern\\'andez,\n  Gemma Bel-Enguix and Jaume Baixeries", "title": "The challenges of statistical patterns of language: the case of\n  Menzerath's law in genomes", "comments": "Title changed, abstract and introduction improved and little\n  corrections on the statistical arguments", "journal-ref": null, "doi": "10.1002/cplx.21429", "report-no": null, "categories": "q-bio.GN cs.CE physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of statistical patterns of language has been debated over\ndecades. Although Zipf's law is perhaps the most popular case, recently,\nMenzerath's law has begun to be involved. Menzerath's law manifests in\nlanguage, music and genomes as a tendency of the mean size of the parts to\ndecrease as the number of parts increases in many situations. This statistical\nregularity emerges also in the context of genomes, for instance, as a tendency\nof species with more chromosomes to have a smaller mean chromosome size. It has\nbeen argued that the instantiation of this law in genomes is not indicative of\nany parallel between language and genomes because (a) the law is inevitable and\n(b) non-coding DNA dominates genomes. Here mathematical, statistical and\nconceptual challenges of these criticisms are discussed. Two major conclusions\nare drawn: the law is not inevitable and languages also have a correlate of\nnon-coding DNA. However, the wide range of manifestations of the law in and\noutside genomes suggests that the striking similarities between non-coding DNA\nand certain linguistics units could be anecdotal for understanding the\nrecurrence of that statistical law.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 14:10:38 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2012 07:07:19 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["Forns", "N\u00faria", ""], ["Hern\u00e1ndez-Fern\u00e1ndez", "Antoni", ""], ["Bel-Enguix", "Gemma", ""], ["Baixeries", "Jaume", ""]]}, {"id": "1207.1547", "submitter": "Gol Kim", "authors": "Kim Gol, Ri Suk Yun", "title": "Hybrid Forecasting of Exchange Rate by Using Chaos Wavelet SVM-Markov\n  Model and Grey Relation Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an exchange rate forecasting method by using the grey\nrelative combination approach of chaos wavelet SVM-Markov model. The problem of\nshort-term forecast of exchange rate by using the comprehensive method of the\nphase space reconstitution and SVM method has been researched. We have\nsuggested a wavelet-SVR-Markov forecasting model to predict the finance time\nseries and demonstrated that can more improve the forecasting performance by\nthe rational combination of the forecast results through various combinational\ntests. Our test result has been showed that the two-stage combination model is\nmore excellent than the normal combination model. Also we have comprehensively\nestimated the combination forecast methods according to the forecasting\nperformance indicators.The estimated result have been shown that the\ncombination forecast methods on the basic of the degree of grey relation and\nthe optimal grey relation combination have fine forecast performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 07:54:16 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Gol", "Kim", ""], ["Yun", "Ri Suk", ""]]}, {"id": "1207.1631", "submitter": "Philipp Thomas", "authors": "Philipp Thomas, Hannes Matuschek and Ramon Grima", "title": "Computation of biochemical pathway fluctuations beyond the linear noise\n  approximation using iNA", "comments": "5 pages, 2 figures, conference proceeding IEEE International\n  Conference on Bioinformatics and Biomedicine (BIBM) 2012", "journal-ref": null, "doi": "10.1109/BIBM.2012.6392668", "report-no": null, "categories": "q-bio.QM cs.CE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear noise approximation is commonly used to obtain intrinsic noise\nstatistics for biochemical networks. These estimates are accurate for networks\nwith large numbers of molecules. However it is well known that many biochemical\nnetworks are characterized by at least one species with a small number of\nmolecules. We here describe version 0.3 of the software intrinsic Noise\nAnalyzer (iNA) which allows for accurate computation of noise statistics over\nwide ranges of molecule numbers. This is achieved by calculating the next order\ncorrections to the linear noise approximation's estimates of variance and\ncovariance of concentration fluctuations. The efficiency of the methods is\nsignificantly improved by automated just-in-time compilation using the LLVM\nframework leading to a fluctuation analysis which typically outperforms that\nobtained by means of exact stochastic simulations. iNA is hence particularly\nwell suited for the needs of the computational biology community.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 14:04:12 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 00:56:45 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Thomas", "Philipp", ""], ["Matuschek", "Hannes", ""], ["Grima", "Ramon", ""]]}, {"id": "1207.1933", "submitter": "Gol Kim", "authors": "Gol Kim (Center of Natural Science, University of Sciences, Pyongyang,\n  DPR Korea), Ri Suk Yun (Foreign Economic General Bureau, Pyongyang, DPR\n  Korea)", "title": "A Hybrid Forecast of Exchange Rate based on ARFIMA,Discrete Grey-Markov,\n  and Fractal Kalman Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid forecast based on extended discrete grey Markov and\nvariable dimension Kalman model and show that our hybrid model can improve much\nmore the performance of forecast than traditional grey Markov and Kalman\nmodels. Our simulation results are given to demonstrate that our hybrid\nforecast method combined with degree of grey incidence are better than grey\nMarkov and ARFIMA model or Kalman methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2012 02:08:26 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Kim", "Gol", "", "Center of Natural Science, University of Sciences, Pyongyang,\n  DPR Korea"], ["Yun", "Ri Suk", "", "Foreign Economic General Bureau, Pyongyang, DPR\n  Korea"]]}, {"id": "1207.2169", "submitter": "Paolo Bientinesi", "authors": "Diego Fabregat-Traver (1), Yurii S. Aulchenko (2), Paolo Bientinesi\n  (1), ((1) AICES, RWTH Aachen, (2) Institute of Cytology and Genetics SD RAS)", "title": "High-throughput Genome-wide Association Analysis for Single and Multiple\n  Phenotypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variance component tests used in genomewide association studies of\nthousands of individuals become computationally exhaustive when multiple traits\nare analysed in the context of omics studies. We introduce two high-throughput\nalgorithms -- CLAK-CHOL and CLAK-EIG -- for single and multiple phenotype\ngenome-wide association studies (GWAS). The algorithms, generated with the help\nof an expert system, reduce the computational complexity to the point that\nthousands of traits can be analyzed for association with millions of\npolymorphisms in a course of days on a standard workstation. By taking\nadvantage of problem specific knowledge, CLAK-CHOL and CLAK-EIG significantly\noutperform the current state-of-the-art tools in both single and multiple trait\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2012 20:25:26 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2012 05:19:32 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Fabregat-Traver", "Diego", "", "AICES, RWTH Aachen"], ["Aulchenko", "Yurii S.", "", "Institute of Cytology and Genetics SD RAS"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}, {"id": "1207.2254", "submitter": "Gol Kim", "authors": "Gol Kim (Center of Natural Science, University of Sciences, Pyongyang,\n  DPR Korea), Ri Suk Yun (Foreign Economic General Bureau, Pyongyang, DPR\n  Korea)", "title": "A Hybrid Forecast of Exchange Rate based on Discrete Grey-Markov and\n  Grey Neural Network Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid forecast model based on discrete grey-fuzzy Markov and\ngrey neural network model and show that our hybrid model can improve much more\nthe performance of forecast than traditional grey-Markov model and neural\nnetwork models. Our simulation results are shown that our hybrid forecast\nmethod with the combinational weight based on optimal grey relation degree\nmethod is better than the hybrid model with combinational weight based\nminimization of error-squared criterion.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 07:46:04 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Kim", "Gol", "", "Center of Natural Science, University of Sciences, Pyongyang,\n  DPR Korea"], ["Yun", "Ri Suk", "", "Foreign Economic General Bureau, Pyongyang, DPR\n  Korea"]]}, {"id": "1207.3289", "submitter": "Eric  Werner", "authors": "Eric Werner", "title": "The Origin, Evolution and Development of Bilateral Symmetry in\n  Multicellular Organisms", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational theory and model of the ontogeny and development of bilateral\nsymmetry in multicellular organisms is presented. Understanding the origin and\nevolution of bilateral organisms requires an understanding of how bilateral\nsymmetry develops, starting from a single cell. Bilateral symmetric growth of a\nmulticellular organism from a single starter cell is explained as resulting\nfrom the opposite handedness and orientation along one axis in two daughter\nfounder cells that are in equivalent developmental control network states.\nSeveral methods of establishing the initial orientation of the daughter cells\n(including oriented cell division and cell signaling) are discussed. The\norientation states of the daughter cells are epigenetically inherited by their\nprogeny. This results in mirror development with the two founding daughter\ncells generating complementary mirror image multicellular morphologies. The end\nproduct is a bilateral symmetric organism. The theory gives a unified\nexplanation of diverse phenomena including symmetry breaking, situs inversus,\ngynandromorphs, inside-out growth, bilaterally symmetric cancers, and the\nrapid, punctuated evolution of bilaterally symmetric organisms in the Cambrian\nExplosion. The theory is supported by experimental results on early embryonic\ndevelopment. The theory makes precise testable predications.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 16:06:35 GMT"}], "update_date": "2012-07-16", "authors_parsed": [["Werner", "Eric", ""]]}, {"id": "1207.3437", "submitter": "Massimiliano Vasile", "authors": "Massimiliano Vasile", "title": "Robust Mission Design Through Evidence Theory and Multi-Agent\n  Collaborative Search", "comments": null, "journal-ref": "Annals of the New York Academy of Science, Volume 1065, New Trends\n  in Astrodynamics and Applications pages 152-173, December 2005", "doi": "10.1196/annals.1370.024", "report-no": null, "categories": "cs.CE cs.NE cs.SY math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the preliminary design of a space mission is approached\nintroducing uncertainties on the design parameters and formulating the\nresulting reliable design problem as a multiobjective optimization problem.\nUncertainties are modelled through evidence theory and the belief, or\ncredibility, in the successful achievement of mission goals is maximised along\nwith the reliability of constraint satisfaction. The multiobjective\noptimisation problem is solved through a novel algorithm based on the\ncollaboration of a population of agents in search for the set of highly\nreliable solutions. Two typical problems in mission analysis are used to\nillustrate the proposed methodology.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2012 16:17:52 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Vasile", "Massimiliano", ""]]}, {"id": "1207.3442", "submitter": "Massimiliano Vasile", "authors": "Massimiliano Vasile, Edmondo Minisci and Quirien Wijnands", "title": "Approximated Computation of Belief Functions for Robust Design\n  Optimization", "comments": "AIAA-2012-1932 14th AIAA Non-Deterministic Approaches Conference.\n  23-26 April 2012 Sheraton Waikiki, Honolulu, Hawaii", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE cs.SY math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents some ideas to reduce the computational cost of\nevidence-based robust design optimization. Evidence Theory crystallizes both\nthe aleatory and epistemic uncertainties in the design parameters, providing\ntwo quantitative measures, Belief and Plausibility, of the credibility of the\ncomputed value of the design budgets. The paper proposes some techniques to\ncompute an approximation of Belief and Plausibility at a cost that is a\nfraction of the one required for an accurate calculation of the two values.\nSome simple test cases will show how the proposed techniques scale with the\ndimension of the problem. Finally a simple example of spacecraft system design\nis presented.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2012 16:53:16 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Vasile", "Massimiliano", ""], ["Minisci", "Edmondo", ""], ["Wijnands", "Quirien", ""]]}, {"id": "1207.3472", "submitter": "Gol Kim", "authors": "Gol Kim, Ri Suk Yun", "title": "Optimal Selection of Assets Investing Composition Plan based on Grey\n  Multi Objective Programming method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem for selection of appropriate assets investing composition\nprojects such as assets rationalization plays an important role in promotion of\nbusiness systems. We consider the assets investing composition plan problems\nsubject to grey multiobjective programming with the grey inequality\nconstraints. In this paper, we show in detail the entire process of the\napplication from modeling the case problem to generating its solution. To solve\nthe grey multi objective programming problem, we then develop and apply an\nalgorithm of grey multiple objective programming by weighting method and an\nalgorithm of grey multiple objective programming based on q -positioned\nprogramming method. These algorithms all regard as of great importance\nuncertainty (greyness) at grey multiobjective programming and simple and easy\nthe calculating process. The calculating examples of paper also show ability\nand effectiveness of algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2012 01:30:56 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Kim", "Gol", ""], ["Yun", "Ri Suk", ""]]}, {"id": "1207.3646", "submitter": "Eduardo Pereira", "authors": "Eduardo dos Santos Pereira and Oswaldo D. Miranda", "title": "OGCOSMO: An auxiliary tool for the study of the Universe within\n  hierarchical scenario of structure formation", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE astro-ph.CO astro-ph.IM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this work is presented the software OGCOSMO. This program was written\nusing high level design methodology (HLDM), that is based on the use of very\nhigh level (VHL) programing language as main, and the use of the intermediate\nlevel (IL) language only for the critical processing time. The languages used\nare PYTHON (VHL) and FORTRAN (IL). The core of OGCOSMO is a package called\nOGC{\\_}lib. This package contains a group of modules for the study of\ncosmological and astrophysical processes, such as: comoving distance, relation\nbetween redshift and time, cosmic star formation rate, number density of dark\nmatter haloes and mass function of supermassive black holes (SMBHs). The\nsoftware is under development and some new features will be implemented for the\nresearch of stochastic background of gravitational waves (GWs) generated by:\nstellar collapse to form black holes, binary systems of SMBHs. Even more, we\nshow that the use of HLDM with PYTHON and FORTRAN is a powerful tool for\nproducing astrophysical softwares.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 12:20:16 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Pereira", "Eduardo dos Santos", ""], ["Miranda", "Oswaldo D.", ""]]}, {"id": "1207.3658", "submitter": "Eduardo Pereira", "authors": "Eduardo dos Santos Pereira and Oswaldo D. Miranda", "title": "Programing Using High Level Design With Python and FORTRAN: A Study Case\n  in Astrophysics", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE astro-ph.IM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this work, we present a short review about the high level design\nmethodology (HLDM), that is based on the use of very high level (VHL)\nprograming language as main, and the use of the intermediate level (IL)\nlanguage only for the critical processing time. The languages used are Python\n(VHL) and FORTRAN (IL). Moreover, this methodology, making use of the oriented\nobject programing (OOP), permits to produce a readable, portable and reusable\ncode. Also is presented the concept of computational framework, that naturally\nappears from the OOP paradigm. As an example, we present the framework called\nPYGRAWC (Python framework for Gravitational Waves from Cosmological origin).\nEven more, we show that the use of HLDM with Python and FORTRAN produces a\npowerful tool for solving astrophysical problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 12:50:30 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Pereira", "Eduardo dos Santos", ""], ["Miranda", "Oswaldo D.", ""]]}, {"id": "1207.4074", "submitter": "Sebastian Roch", "authors": "Sebastien Roch", "title": "An analytical comparison of coalescent-based multilocus methods: The\n  three-taxon case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incomplete lineage sorting (ILS) is a common source of gene tree incongruence\nin multilocus analyses. A large number of methods have been developed to infer\nspecies trees in the presence of ILS. Here we provide a mathematical analysis\nof several coalescent-based methods. Our analysis is performed on a three-taxon\nspecies tree and assumes that the gene trees are correctly reconstructed along\nwith their branch lengths.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 18:07:34 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Roch", "Sebastien", ""]]}, {"id": "1207.4122", "submitter": "Gregory F. Cooper", "authors": "Gregory F. Cooper, Denver Dash, John Levander, Weng-Keen Wong, William\n  Hogan, Michael Wagner", "title": "Bayesian Biosurveillance of Disease Outbreaks", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-94-103", "categories": "stat.AP cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early, reliable detection of disease outbreaks is a critical problem today.\nThis paper reports an investigation of the use of causal Bayesian networks to\nmodel spatio-temporal patterns of a non-contagious disease (respiratory anthrax\ninfection) in a population of people. The number of parameters in such a\nnetwork can become enormous, if not carefully managed. Also, inference needs to\nbe performed in real time as population data stream in. We describe techniques\nwe have applied to address both the modeling and inference challenges. A key\ncontribution of this paper is the explication of assumptions and techniques\nthat are sufficient to allow the scaling of Bayesian network modeling and\ninference to millions of nodes for real-time surveillance applications. The\nresults reported here provide a proof-of-concept that Bayesian networks can\nserve as the foundation of a system that effectively performs Bayesian\nbiosurveillance of disease outbreaks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:45:54 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Cooper", "Gregory F.", ""], ["Dash", "Denver", ""], ["Levander", "John", ""], ["Wong", "Weng-Keen", ""], ["Hogan", "William", ""], ["Wagner", "Michael", ""]]}, {"id": "1207.4141", "submitter": "Ludmila Kuncheva", "authors": "Ludmila Kuncheva, C. Whitaker, P. Cockcroft, Z. S. Hoare", "title": "Pre-Selection of Independent Binary Features: An Application to\n  Diagnosing Scrapie in Sheep", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-325-332", "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that the only available information in a multi-class problem are\nexpert estimates of the conditional probabilities of occurrence for a set of\nbinary features. The aim is to select a subset of features to be measured in\nsubsequent data collection experiments. In the lack of any information about\nthe dependencies between the features, we assume that all features are\nconditionally independent and hence choose the Naive Bayes classifier as the\noptimal classifier for the problem. Even in this (seemingly trivial) case of\ncomplete knowledge of the distributions, choosing an optimal feature subset is\nnot straightforward. We discuss the properties and implementation details of\nSequential Forward Selection (SFS) as a feature selection procedure for the\ncurrent problem. A sensitivity analysis was carried out to investigate whether\nthe same features are selected when the probabilities vary around the estimated\nvalues. The procedure is illustrated with a set of probability estimates for\nScrapie in sheep.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:54:09 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Kuncheva", "Ludmila", ""], ["Whitaker", "C.", ""], ["Cockcroft", "P.", ""], ["Hoare", "Z. S.", ""]]}, {"id": "1207.4143", "submitter": "Seyoung Kim", "authors": "Seyoung Kim, Padhraic Smyth, Stefan Luther", "title": "Modeling Waveform Shapes with Random Eects Segmental Hidden Markov\n  Models", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-309-316", "categories": "stat.AP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a general probabilistic framework for modeling\nwaveforms such as heartbeats from ECG data. The model is based on segmental\nhidden Markov models (as used in speech recognition) with the addition of\nrandom effects to the generative model. The random effects component of the\nmodel handles shape variability across different waveforms within a general\nclass of waveforms of similar shape. We show that this probabilistic model\nprovides a unified framework for learning these models from sets of waveform\ndata as well as parsing, classification, and prediction of new waveforms. We\nderive a computationally efficient EM algorithm to fit the model on multiple\nwaveforms, and introduce a scoring method that evaluates a test waveform based\non its shape. Results on two real-world data sets demonstrate that the random\neffects methodology leads to improved accuracy (compared to alternative\napproaches) on classification and segmentation of real-world waveforms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:54:41 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Kim", "Seyoung", ""], ["Smyth", "Padhraic", ""], ["Luther", "Stefan", ""]]}, {"id": "1207.4145", "submitter": "Nebojsa Jojic", "authors": "Nebojsa Jojic, Vladimir Jojic, David Heckerman", "title": "Joint discovery of haplotype blocks and complex trait associations from\n  SNP sequences", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-286-292", "categories": "q-bio.GN cs.CE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haplotypes, the global patterns of DNA sequence variation, have important\nimplications for identifying complex traits. Recently, blocks of limited\nhaplotype diversity have been discovered in human chromosomes, intensifying the\nresearch on modelling the block structure as well as the transitions or\nco-occurrence of the alleles in these blocks as a way to compress the\nvariability and infer the associations more robustly. The haplotype block\nstructure analysis is typically complicated by the fact that the phase\ninformation for each SNP is missing, i.e., the observed allele pairs are not\ngiven in a consistent order across the sequence. The techniques for\ncircumventing this require additional information, such as family data, or a\nmore complex sequencing procedure. In this paper we present a hierarchical\nstatistical model and the associated learning and inference algorithms that\nsimultaneously deal with the allele ambiguity per locus, missing data, block\nestimation, and the complex trait association. While the blo structure may\ndiffer from the structures inferred by other methods, which use the pedigree\ninformation or previously known alleles, the parameters we estimate, including\nthe learned block structure and the estimated block transitions per locus,\ndefine a good model of variability in the set. The method is completely\ndatadriven and can detect Chron's disease from the SNP data taken from the\nhuman chromosome 5q31 with the detection rate of 80% and a small error\nvariance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:55:26 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Jojic", "Nebojsa", ""], ["Jojic", "Vladimir", ""], ["Heckerman", "David", ""]]}, {"id": "1207.4860", "submitter": "Aki-Hiro Sato", "authors": "Aki-Hiro Sato", "title": "Inference of Extreme Synchrony with an Entropy Measure on a Bipartite\n  Network", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CE physics.soc-ph q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a method to quantify the structure of a bipartite graph\nusing a network entropy per link. The network entropy of a bipartite graph with\nrandom links is calculated both numerically and theoretically. As an\napplication of the proposed method to analyze collective behavior, the affairs\nin which participants quote and trade in the foreign exchange market are\nquantified. The network entropy per link is found to correspond to the\nmacroeconomic situation. A finite mixture of Gumbel distributions is used to\nfit the empirical distribution for the minimum values of network entropy per\nlink in each week. The mixture of Gumbel distributions with parameter estimates\nby segmentation procedure is verified by the Kolmogorov--Smirnov test. The\nfinite mixture of Gumbel distributions that extrapolate the empirical\nprobability of extreme events has explanatory power at a statistically\nsignificant level.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 07:08:53 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2012 10:31:11 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2012 11:07:40 GMT"}, {"version": "v4", "created": "Sat, 26 Oct 2013 07:17:23 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Sato", "Aki-Hiro", ""]]}, {"id": "1207.6445", "submitter": "Shang-Pin Sheng", "authors": "Shang-Pin Sheng, Mingyan Liu", "title": "Profit Incentive In A Secondary Spectrum Market: A Contract Design\n  Approach", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we formulate a contract design problem where a primary license\nholder wishes to profit from its excess spectrum capacity by selling it to\npotential secondary users/buyers. It needs to determine how to optimally price\nthe excess spectrum so as to maximize its profit, knowing that this excess\ncapacity is stochastic in nature, does not come with exclusive access, and\ncannot provide deterministic service guarantees to a buyer. At the same time,\nbuyers are of different {\\em types}, characterized by different communication\nneeds, tolerance for the channel uncertainty, and so on, all of which a buyer's\nprivate information. The license holder must then try to design different\ncontracts catered to different types of buyers in order to maximize its profit.\nWe address this problem by adopting as a reference a traditional spectrum\nmarket where the buyer can purchase exclusive access with fixed/deterministic\nguarantees. We fully characterize the optimal solution in the cases where there\nis a single buyer type, and when multiple types of buyers share the same, known\nchannel condition as a result of the primary user activity. In the most general\ncase we construct an algorithm that generates a set of contracts in a\ncomputationally efficient manner, and show that this set is optimal when the\nbuyer types satisfy a monotonicity condition.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 04:25:02 GMT"}], "update_date": "2012-07-30", "authors_parsed": [["Sheng", "Shang-Pin", ""], ["Liu", "Mingyan", ""]]}, {"id": "1207.6821", "submitter": "EPTCS", "authors": "Elham Kashefi (University of Edinburgh, UK), Jean Krivine (University\n  Paris Diderot, France), Femke van Raamsdonk (VU University Amsterdam, The\n  Netherlands)", "title": "Proceedings 7th International Workshop on Developments of Computational\n  Methods", "comments": "EPTCS 88, 2012", "journal-ref": null, "doi": "10.4204/EPTCS.88", "report-no": null, "categories": "cs.CE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the 7th International Workshop on\nDevelopments in Computational Models (DCM 2011) which was held on Sunday July\n3, 2011, in Zurich, Switzerland, as a satelite workshop of ICALP 2011.\n  Recently several new models of computation have emerged, for instance for\nbio-computing and quantum-computing, and in addition traditional models of\ncomputation have been adapted to accommodate new demands or capabilities of\ncomputer systems. The aim of DCM is to bring together researchers who are\ncurrently developing new computational models or new features for traditional\ncomputational models, in order to foster their interaction, to provide a forum\nfor presenting new ideas and work in progress, and to enable newcomers to learn\nabout current activities in this area.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 02:01:37 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Kashefi", "Elham", "", "University of Edinburgh, UK"], ["Krivine", "Jean", "", "University\n  Paris Diderot, France"], ["van Raamsdonk", "Femke", "", "VU University Amsterdam, The\n  Netherlands"]]}, {"id": "1207.7147", "submitter": "EPTCS", "authors": "Livio Bioglio (Dipartimento di Informatica, Universit\\`a di Torino),\n  Mariangiola Dezani-Ciancaglini (Dipartimento di Informatica, Universit\\`a di\n  Torino), Paola Giannini (Dipartimento di Informatica, Universit\\`a di\n  Torino), Angelo Troina (Dipartimento di Informatica, Universit\\`a di Torino)", "title": "A Calculus of Looping Sequences with Local Rules", "comments": "In Proceedings DCM 2011, arXiv:1207.6821", "journal-ref": "EPTCS 88, 2012, pp. 43-58", "doi": "10.4204/EPTCS.88.4", "report-no": null, "categories": "cs.CE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a variant of the Calculus of Looping Sequences (CLS\nfor short) with global and local rewrite rules. While global rules, as in CLS,\nare applied anywhere in a given term, local rules can only be applied in the\ncompartment on which they are defined. Local rules are dynamic: they can be\nadded, moved and erased. We enrich the new calculus with a parallel semantics\nwhere a reduction step is lead by any number of global and local rules that\ncould be performed in parallel. A type system is developed to enforce the\nproperty that a compartment must contain only local rules with specific\nfeatures. As a running example we model some interactions happening in a cell\nstarting from its nucleus and moving towards its mitochondria.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 02:06:26 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Bioglio", "Livio", "", "Dipartimento di Informatica, Universit\u00e0 di Torino"], ["Dezani-Ciancaglini", "Mariangiola", "", "Dipartimento di Informatica, Universit\u00e0 di\n  Torino"], ["Giannini", "Paola", "", "Dipartimento di Informatica, Universit\u00e0 di\n  Torino"], ["Troina", "Angelo", "", "Dipartimento di Informatica, Universit\u00e0 di Torino"]]}]