[{"id": "1210.0234", "submitter": "Marion Scheepers", "authors": "Jacob Herlin, Anna Nelson and Marion Scheepers", "title": "Using Ciliate Operations to construct Chromosome Phylogenies", "comments": "31 pages, 14 figures. Preliminary report", "journal-ref": null, "doi": null, "report-no": "REUG01", "categories": "q-bio.GN cs.CE cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm based on three basic DNA editing operations suggested\nby a model for ciliate micronuclear decryption, to transform a given\npermutation into another. The number of ciliate operations performed by our\nalgorithm during such a transformation is taken to be the distance between two\nsuch permutations. Applying well-known clustering methods to such distance\nfunctions enables one to determine phylogenies among the items to which the\ndistance functions apply. As an application of these ideas we explore the\nrelationships among the chromosomes of eight fruitfly (drosophila) species,\nusing the well-known UPGMA algorithm on the distance function provided by our\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2012 19:57:35 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2012 21:41:56 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2013 14:39:04 GMT"}, {"version": "v4", "created": "Tue, 7 Jan 2014 08:56:24 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Herlin", "Jacob", ""], ["Nelson", "Anna", ""], ["Scheepers", "Marion", ""]]}, {"id": "1210.0690", "submitter": "Santiago Videla", "authors": "Santiago Videla (INRIA - IRISA), Carito Guziolowski (IRCCyN), Federica\n  Eduati (DEI, EBI), Sven Thiele (INRIA - IRISA), Niels Grabe, Julio\n  Saez-Rodriguez (EBI), Anne Siegel (INRIA - IRISA)", "title": "Revisiting the Training of Logic Models of Protein Signaling Networks\n  with a Formal Approach based on Answer Set Programming", "comments": null, "journal-ref": "CMSB - 10th Computational Methods in Systems Biology 2012 7605\n  (2012) 342-361", "doi": "10.1007/978-3-642-33636-2_20", "report-no": null, "categories": "q-bio.QM cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in systems biology is the construction and training to\ndata of mathematical models. Logic formalisms have become very popular to model\nsignaling networks because their simplicity allows us to model large systems\nencompassing hundreds of proteins. An approach to train (Boolean) logic models\nto high-throughput phospho-proteomics data was recently introduced and solved\nusing optimization heuristics based on stochastic methods. Here we demonstrate\nhow this problem can be solved using Answer Set Programming (ASP), a\ndeclarative problem solving paradigm, in which a problem is encoded as a\nlogical program such that its answer sets represent solutions to the problem.\nASP has significant improvements over heuristic methods in terms of efficiency\nand scalability, it guarantees global optimality of solutions as well as\nprovides a complete set of solutions. We illustrate the application of ASP with\nin silico cases based on realistic networks and data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 07:52:52 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2012 07:39:43 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Videla", "Santiago", "", "INRIA - IRISA"], ["Guziolowski", "Carito", "", "IRCCyN"], ["Eduati", "Federica", "", "DEI, EBI"], ["Thiele", "Sven", "", "INRIA - IRISA"], ["Grabe", "Niels", "", "EBI"], ["Saez-Rodriguez", "Julio", "", "EBI"], ["Siegel", "Anne", "", "INRIA - IRISA"]]}, {"id": "1210.1472", "submitter": "Manish Gupta", "authors": "Naman Turakhia, Nilay Chheda, Manish K. Gupta, Ruchin Shah and Jigar\n  Raisinghani", "title": "Biospectrogram: a tool for spectral analysis of biological sequences", "comments": "2 pages, 1 figure, submitted to Bioinformatics Journal,\n  Biospectrogram is available at http://www.guptalab.org/biospectrogram", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summary: Biospectrogam is an open-source software for the spectral analysis\nof DNA and protein sequences. The software can fetch (from NCBI server), import\nand manage biological data. One can analyze the data using Digital Signal\nProcessing (DSP) techniques since the software allows the user to convert the\nsymbolic data into numerical data using 23 popular encodings and then apply\npopular transformations such as Fast Fourier Transform (FFT) etc. and export\nit. The ability of exporting (both encoding files and transform files) as a\nMATLAB .m file gives the user an option to apply variety of techniques of DSP.\nUser can also do window analysis (both sliding in forward and backward\ndirections and stagnant) with different size windows and search for meaningful\nspectral pattern with the help of exported MATLAB file in a dynamic manner by\nchoosing time delay in the plot using Biospectrogram. Random encodings and user\nchoice encoding allows software to search for many possibilities in spectral\nspace.\n  Availability: Biospectrogam is written in Java and is available to download\nfreely from http://www.guptalab.org/biospectrogram. Software has been optimized\nto run on Windows, Mac OSX and Linux. User manual and you-tube (product demo)\ntutorial is also available on the website. We are in the process of acquiring\nopen source license for it.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 14:42:50 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Turakhia", "Naman", ""], ["Chheda", "Nilay", ""], ["Gupta", "Manish K.", ""], ["Shah", "Ruchin", ""], ["Raisinghani", "Jigar", ""]]}, {"id": "1210.2515", "submitter": "Peijun Zhu", "authors": "Ting Huang, Peijun Zhu, Zengyou He", "title": "Protein Inference and Protein Quantification: Two Sides of the Same Coin", "comments": "14 Pages, This paper has submitted to RECOMB2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: In mass spectrometry-based shotgun proteomics, protein\nquantification and protein identification are two major computational problems.\nTo quantify the protein abundance, a list of proteins must be firstly inferred\nfrom the sample. Then the relative or absolute protein abundance is estimated\nwith quantification methods, such as spectral counting. Until now, researchers\nhave been dealing with these two processes separately. In fact, they are two\nsides of same coin in the sense that truly present proteins are those proteins\nwith non-zero abundances. Then, one interesting question is if we regard the\nprotein inference problem as a special protein quantification problem, is it\npossible to achieve better protein inference performance?\n  Contribution: In this paper, we investigate the feasibility of using protein\nquantification methods to solve the protein inference problem. Protein\ninference is to determine whether each candidate protein is present in the\nsample or not. Protein quantification is to calculate the abundance of each\nprotein. Naturally, the absent proteins should have zero abundances. Thus, we\nargue that the protein inference problem can be viewed as a special case of\nprotein quantification problem: present proteins are those proteins with\nnon-zero abundances. Based on this idea, our paper tries to use three very\nsimple protein quantification methods to solve the protein inference problem\neffectively.\n  Results: The experimental results on six datasets show that these three\nmethods are competitive with previous protein inference algorithms. This\ndemonstrates that it is plausible to take the protein inference problem as a\nspecial case of protein quantification, which opens the door of devising more\neffective protein inference algorithms from a quantification perspective.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 07:36:26 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Huang", "Ting", ""], ["Zhu", "Peijun", ""], ["He", "Zengyou", ""]]}, {"id": "1210.4251", "submitter": "Arry Yanuar", "authors": "Heru Suhartanto, Arry Yanuar and Ari Wibisono", "title": "Performance Analysis Cluster and GPU Computing Environment on Molecular\n  Dynamic Simulation of BRV-1 and REM2 with GROMACS", "comments": "5 pages, 1 figure, 5 tables", "journal-ref": "Int. J. Comp. Sci. Issue (2011), Vol. 8, Issue 4, No 2, p131-135", "doi": null, "report-no": null, "categories": "cs.DC cs.CE q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of application that needs high performance computing resources is\nmolecular d ynamic. There is some software available that perform molecular\ndynamic, one of these is a well known GROMACS. Our previous experiment\nsimulating molecular dynamics of Indonesian grown herbal compounds show\nsufficient speed up on 32 n odes Cluster computing environment. In order to\nobtain a reliable simulation, one usually needs to run the experiment on the\nscale of hundred nodes. But this is expensive to develop and maintain. Since\nthe invention of Graphical Processing Units that is also useful for general\nprogramming, many applications have been developed to run on this. This paper\nreports our experiments that evaluate the performance of GROMACS that runs on\ntwo different environment, Cluster computing resources and GPU based PCs. We\nrun the experiment on BRV-1 and REM2 compounds. Four different GPUs are\ninstalled on the same type of PCs of quad cores; they are Gefore GTS 250, GTX\n465, GTX 470 and Quadro 4000. We build a cluster of 16 nodes based on these\nfour quad cores PCs. The preliminary experiment shows that those run on GTX 470\nis the best among the other type of GPUs and as well as the cluster computing\nresource. A speed up around 11 and 12 is gained, while the cost of computer\nwith GPU is only about 25 percent that of Cluster we built.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 05:15:17 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Suhartanto", "Heru", ""], ["Yanuar", "Arry", ""], ["Wibisono", "Ari", ""]]}, {"id": "1210.4791", "submitter": "Callum James Corbett", "authors": "Roger A. Sauer and Thang X. Duong and Callum J. Corbett", "title": "A computational formulation for constrained solid and liquid membranes\n  considering isogeometric finite elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A geometrically exact membrane formulation is presented that is based on\ncurvilinear coordinates and isogeometric finite elements, and is suitable for\nboth solid and liquid membranes. The curvilinear coordinate system is used to\ndescribe both the theory and the finite element equations of the membrane. In\nthe latter case this avoids the use of local cartesian coordinates at the\nelement level. Consequently, no transformation of derivatives is required. The\nformulation considers a split of the in-plane and out-of-plane membrane\ncontributions, which allows the construction of a stable formulation for liquid\nmembranes with constant surface tension. The proposed membrane formulation is\ngeneral, and accounts for dead and live loading, as well as enclosed volume,\narea, and contact constraints. The new formulation is illustrated by several\nchallenging examples, considering linear and quadratic Lagrange elements, as\nwell as isogeometric elements based on quadratic NURBS and cubic T-splines. It\nis seen that the isogeometric elements are much more accurate than standard\nLagrange elements. The gain is especially large for the liquid membrane\nformulation since it depends explicitly on the surface curvature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 16:45:52 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Sauer", "Roger A.", ""], ["Duong", "Thang X.", ""], ["Corbett", "Callum J.", ""]]}, {"id": "1210.4868", "submitter": "Jie Liu", "authors": "Jie Liu, Chunming Zhang, Catherine McCarty, Peggy Peissig, Elizabeth\n  Burnside, David Page", "title": "Graphical-model Based Multiple Testing under Dependence, with\n  Applications to Genome-wide Association Studies", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-511-522", "categories": "stat.ME cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale multiple testing tasks often exhibit dependence, and leveraging\nthe dependence between individual tests is still one challenging and important\nproblem in statistics. With recent advances in graphical models, it is feasible\nto use them to perform multiple testing under dependence. We propose a multiple\ntesting procedure which is based on a Markov-random-field-coupled mixture\nmodel. The ground truth of hypotheses is represented by a latent binary Markov\nrandom field, and the observed test statistics appear as the coupled mixture\nvariables. The parameters in our model can be automatically learned by a novel\nEM algorithm. We use an MCMC algorithm to infer the posterior probability that\neach hypothesis is null (termed local index of significance), and the false\ndiscovery rate can be controlled accordingly. Simulations show that the\nnumerical performance of multiple testing can be improved substantially by\nusing our procedure. We apply the procedure to a real-world genome-wide\nassociation study on breast cancer, and we identify several SNPs with strong\nassociation evidence.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:40:38 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Liu", "Jie", ""], ["Zhang", "Chunming", ""], ["McCarty", "Catherine", ""], ["Peissig", "Peggy", ""], ["Burnside", "Elizabeth", ""], ["Page", "David", ""]]}, {"id": "1210.4903", "submitter": "Mathieu Sinn", "authors": "Mathieu Sinn, Ali Ghodsi, Karsten Keller", "title": "Detecting Change-Points in Time Series by Maximum Mean Discrepancy of\n  Ordinal Pattern Distributions", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-786-794", "categories": "stat.ME cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a new method for detecting change-points in high-resolution time series,\nwe apply Maximum Mean Discrepancy to the distributions of ordinal patterns in\ndifferent parts of a time series. The main advantage of this approach is its\ncomputational simplicity and robustness with respect to (non-linear) monotonic\ntransformations, which makes it particularly well-suited for the analysis of\nlong biophysical time series where the exact calibration of measurement devices\nis unknown or varies with time. We establish consistency of the method and\nevaluate its performance in simulation studies. Furthermore, we demonstrate the\napplication to the analysis of electroencephalography (EEG) and\nelectrocardiography (ECG) recordings.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:51:29 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Sinn", "Mathieu", ""], ["Ghodsi", "Ali", ""], ["Keller", "Karsten", ""]]}, {"id": "1210.4904", "submitter": "Ajit P. Singh", "authors": "Ajit P. Singh, John Halloran, Jeff A. Bilmes, Katrin Kirchoff, William\n  S. Noble", "title": "Spectrum Identification using a Dynamic Bayesian Network Model of Tandem\n  Mass Spectra", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-775-785", "categories": "cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shotgun proteomics is a high-throughput technology used to identify unknown\nproteins in a complex mixture. At the heart of this process is a prediction\ntask, the spectrum identification problem, in which each fragmentation spectrum\nproduced by a shotgun proteomics experiment must be mapped to the peptide\n(protein subsequence) which generated the spectrum. We propose a new algorithm\nfor spectrum identification, based on dynamic Bayesian networks, which\nsignificantly outperforms the de-facto standard tools for this task: SEQUEST\nand Mascot.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:51:39 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Singh", "Ajit P.", ""], ["Halloran", "John", ""], ["Bilmes", "Jeff A.", ""], ["Kirchoff", "Katrin", ""], ["Noble", "William S.", ""]]}, {"id": "1210.4919", "submitter": "Mirwaes Wahabzada", "authors": "Mirwaes Wahabzada, Kristian Kersting, Christian Bauckhage, Christoph\n  Roemer, Agim Ballvora, Francisco Pinto, Uwe Rascher, Jens Leon, Lutz Ploemer", "title": "Latent Dirichlet Allocation Uncovers Spectral Characteristics of Drought\n  Stressed Plants", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-852-862", "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the adaptation process of plants to drought stress is essential\nin improving management practices, breeding strategies as well as engineering\nviable crops for a sustainable agriculture in the coming decades.\nHyper-spectral imaging provides a particularly promising approach to gain such\nunderstanding since it allows to discover non-destructively spectral\ncharacteristics of plants governed primarily by scattering and absorption\ncharacteristics of the leaf internal structure and biochemical constituents.\nSeveral drought stress indices have been derived using hyper-spectral imaging.\nHowever, they are typically based on few hyper-spectral images only, rely on\ninterpretations of experts, and consider few wavelengths only. In this study,\nwe present the first data-driven approach to discovering spectral drought\nstress indices, treating it as an unsupervised labeling problem at massive\nscale. To make use of short range dependencies of spectral wavelengths, we\ndevelop an online variational Bayes algorithm for latent Dirichlet allocation\nwith convolved Dirichlet regularizer. This approach scales to massive datasets\nand, hence, provides a more objective complement to plant physiological\npractices. The spectral topics found conform to plant physiological knowledge\nand can be computed in a fraction of the time compared to existing LDA\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:57:06 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Wahabzada", "Mirwaes", ""], ["Kersting", "Kristian", ""], ["Bauckhage", "Christian", ""], ["Roemer", "Christoph", ""], ["Ballvora", "Agim", ""], ["Pinto", "Francisco", ""], ["Rascher", "Uwe", ""], ["Leon", "Jens", ""], ["Ploemer", "Lutz", ""]]}, {"id": "1210.5290", "submitter": "Kalyana Babu Nakshatrala", "authors": "K. B. Nakshatrala, M. K. Mudunuru, A. J. Valocchi", "title": "A numerical framework for diffusion-controlled bimolecular-reactive\n  systems to enforce maximum principles and non-negative constraint", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2013.07.010", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel computational framework for diffusive-reactive systems\nthat satisfies the non-negative constraint and maximum principles on general\ncomputational grids. The governing equations for the concentration of reactants\nand product are written in terms of tensorial diffusion-reaction equations. %\nWe restrict our studies to fast irreversible bimolecular reactions. If one\nassumes that the reaction is diffusion-limited and all chemical species have\nthe same diffusion coefficient, one can employ a linear transformation to\nrewrite the governing equations in terms of invariants, which are unaffected by\nthe reaction. This results in two uncoupled tensorial diffusion equations in\nterms of these invariants, which are solved using a novel non-negative solver\nfor tensorial diffusion-type equations. The concentrations of the reactants and\nthe product are then calculated from invariants using algebraic manipulations.\nThe novel aspect of the proposed computational framework is that it will always\nproduce physically meaningful non-negative values for the concentrations of all\nchemical species. Several representative numerical examples are presented to\nillustrate the robustness, convergence, and the numerical performance of the\nproposed computational framework. We will also compare the proposed framework\nwith other popular formulations. In particular, we will show that the Galerkin\nformulation (which is the standard single-field formulation) does not produce\nreliable solutions, and the reason can be attributed to the fact that the\nsingle-field formulation does not guarantee non-negative solutions. We will\nalso show that the clipping procedure (which produces non-negative solutions\nbut is considered as a variational crime) does not give accurate results when\ncompared with the proposed computational framework.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 01:06:02 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2012 19:02:39 GMT"}, {"version": "v3", "created": "Sun, 14 Apr 2013 21:20:21 GMT"}, {"version": "v4", "created": "Sat, 27 Jul 2013 22:21:28 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Nakshatrala", "K. B.", ""], ["Mudunuru", "M. K.", ""], ["Valocchi", "A. J.", ""]]}, {"id": "1210.5859", "submitter": "Ertugrul Bayraktar", "authors": "Ertugrul Bayraktar, Ayse Humeyra Bilge", "title": "Determination the Parameters of Markowitz Portfolio Optimization Model", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this study is the determination of the optimal length of\nthe historical data for the estimation of statistical parameters in Markowitz\nPortfolio Optimization. We present a trading simulation using Markowitz method,\nfor a portfolio consisting of foreign currency exchange rates and selected\nassets from the Istanbul Stock Exchange ISE 30, over the period 2001-2009. In\nthe simulation, the expected returns and the covariance matrix are computed\nfrom historical data observed for past n days and the target returns are chosen\nas multiples of the return of the market index. The trading strategy is to buy\na stock if the simulation resulted in a feasible solution and sell the stock\nafter exactly m days, independently from the market conditions. The actual\nreturns are computed for n and m being equal to 21, 42, 63, 84 and 105 days and\nwe have seen that the best return is obtained when the observation period is 2\nor 3 times the investment period.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 10:28:48 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Bayraktar", "Ertugrul", ""], ["Bilge", "Ayse Humeyra", ""]]}, {"id": "1210.6128", "submitter": "Tarun Sharma  Kumar", "authors": "Tarun Kumar Sharma, Millie Pant, V.P.Singh", "title": "Improved Local Search in Artificial Bee Colony using Golden Section\n  Search", "comments": "6 Pages, Journal of Engineering (JOE), World Science Publisher 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Artificial bee colony (ABC), an optimization algorithm is a recent addition\nto the family of population based search algorithm. ABC has taken its\ninspiration from the collective intelligent foraging behavior of honey bees. In\nthis study we have incorporated golden section search mechanism in the\nstructure of basic ABC to improve the global convergence and prevent to stick\non a local solution. The proposed variant is termed as ILS-ABC. Comparative\nnumerical results with the state-of-art algorithms show the performance of the\nproposal when applied to the set of unconstrained engineering design problems.\nThe simulated results show that the proposed variant can be successfully\napplied to solve real life problems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 04:57:04 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Sharma", "Tarun Kumar", ""], ["Pant", "Millie", ""], ["Singh", "V. P.", ""]]}, {"id": "1210.6234", "submitter": "Christian Focke", "authors": "C. Focke and D.Bothe and M. Kuschel and M. Sommerfeld", "title": "Experiments and Direct Numerical Simulations of binary collisions of\n  miscible liquid droplets with different viscosities", "comments": "12th Triennial International Conference on Liquid Atomization and\n  Spray Systems, Heidelberg, Germany, September 2-6, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary droplet collisions are of importance in a variety of practical\napplications comprising dispersed two-phase flows. The background of our\nresearch is the prediction of properties of particulate products formed in\nspray processes. To gain a more thorough understanding of the elementary\nsub-processes inside a spray, experiments and direct numerical simulations of\nbinary droplet collisions are used. The aim of these investigations is to\ndevelop semi-analytical descriptions for the outcome of droplet collisions.\nSuch collision models can then be employed as closure terms for scale-reduced\nsimulations. In the present work we focus on the collision of droplets of\ndifferent liquids. These kinds of collisions take place in every spray drying\nprocess when droplets with different solids contents collide in recirculation\nzones. A new experimental method has been developed allowing for high spatial\nand time resolved recordings via Laser-induced fluorescence. The results\nobtained with the proposed method will be compared with DNS simulations. The\nviscosities of the droplets are different whereas the interfacial tension and\ndensity are equal. The liquids are miscible and no surface tension is acting\nbetween the two liquids. Our intention is to discover elementary phenomena\ncaused by the viscosity ratio of the droplets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 13:53:56 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Focke", "C.", ""], ["Bothe", "D.", ""], ["Kuschel", "M.", ""], ["Sommerfeld", "M.", ""]]}, {"id": "1210.6891", "submitter": "Clifton Phua", "authors": "Clifton Phua, Hong Cao, Jo\\~ao B\\'artolo Gomes, Minh Nhut Nguyen", "title": "Predicting Near-Future Churners and Win-Backs in the Telecommunications\n  Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this work, we presented the strategies and techniques that we have\ndeveloped for predicting the near-future churners and win-backs for a telecom\ncompany. On a large-scale and real-world database containing customer profiles\nand some transaction data from a telecom company, we first analyzed the data\nschema, developed feature computation strategies and then extracted a large set\nof relevant features that can be associated with the customer churning and\nreturning behaviors. Our features include both the original driver factors as\nwell as some derived features. We evaluated our features on the imbalance\ncorrected dataset, i.e. under-sampled dataset and compare a large number of\nexisting machine learning tools, especially decision tree-based classifiers,\nfor predicting the churners and win-backs. In general, we find RandomForest and\nSimpleCart learning algorithms generally perform well and tend to provide us\nwith highly competitive prediction performance. Among the top-15 driver factors\nthat signal the churn behavior, we find that the service utilization, e.g. last\ntwo months' download and upload volume, last three months' average upload and\ndownload, and the payment related factors are the most indicative features for\npredicting if churn will happen soon. Such features can collectively tell\ndiscrepancies between the service plans, payments and the dynamically changing\nutilization needs of the customers. Our proposed features and their\ncomputational strategy exhibit reasonable precision performance to predict\nchurn behavior in near future.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 05:56:45 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Phua", "Clifton", ""], ["Cao", "Hong", ""], ["Gomes", "Jo\u00e3o B\u00e1rtolo", ""], ["Nguyen", "Minh Nhut", ""]]}, {"id": "1210.6912", "submitter": "Gaurav Pandey", "authors": "Gaurav Pandey and Sahil Manocha and Gowtham Atluri and Vipin Kumar", "title": "Enhancing the functional content of protein interaction networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein interaction networks are a promising type of data for studying\ncomplex biological systems. However, despite the rich information embedded in\nthese networks, they face important data quality challenges of noise and\nincompleteness that adversely affect the results obtained from their analysis.\nHere, we explore the use of the concept of common neighborhood similarity\n(CNS), which is a form of local structure in networks, to address these issues.\nAlthough several CNS measures have been proposed in the literature, an\nunderstanding of their relative efficacies for the analysis of interaction\nnetworks has been lacking. We follow the framework of graph transformation to\nconvert the given interaction network into a transformed network corresponding\nto a variety of CNS measures evaluated. The effectiveness of each measure is\nthen estimated by comparing the quality of protein function predictions\nobtained from its corresponding transformed network with those from the\noriginal network. Using a large set of S. cerevisiae interactions, and a set of\n136 GO terms, we find that several of the transformed networks produce more\naccurate predictions than those obtained from the original network. In\nparticular, the $HC.cont$ measure proposed here performs particularly well for\nthis task. Further investigation reveals that the two major factors\ncontributing to this improvement are the abilities of CNS measures, especially\n$HC.cont$, to prune out noisy edges and introduce new links between\nfunctionally related proteins.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 17:13:57 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Pandey", "Gaurav", ""], ["Manocha", "Sahil", ""], ["Atluri", "Gowtham", ""], ["Kumar", "Vipin", ""]]}, {"id": "1210.6956", "submitter": "Jorn Baayen", "authors": "Jorn H. Baayen", "title": "Vortexje - An Open-Source Panel Method for Co-Simulation", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the use of the 3-dimensional panel method for dynamical\nsystem simulation. Specifically, the advantages and disadvantages of model\nexchange versus co-simulation of the aerodynamics and the dynamical system\nmodel are discussed. Based on a trade-off analysis, a set of recommendations\nfor a panel method implementation and for a co-simulation environment is\nproposed. These recommendations are implemented in a C++ library, offered\non-line under an open source license. This code is validated against XFLR5, and\nits suitability for co-simulation is demonstrated with an example of a tethered\nwing, i.e, a kite. The panel method implementation and the co-simulation\nenvironment are shown to be able to solve this stiff problem in a stable\nfashion.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 19:22:46 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 17:14:38 GMT"}, {"version": "v3", "created": "Sat, 9 Mar 2013 17:38:39 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Baayen", "Jorn H.", ""]]}, {"id": "1210.7292", "submitter": "Matthias Messner", "authors": "Matthias Messner (INRIA Bordeaux - Sud-Ouest), B\\'erenger Bramas\n  (INRIA Bordeaux - Sud-Ouest), Olivier Coulaud (INRIA Bordeaux - Sud-Ouest),\n  Eric Darve", "title": "Optimized M2L Kernels for the Chebyshev Interpolation based Fast\n  Multipole Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fast multipole method (FMM) for asymptotically smooth kernel functions\n(1/r, 1/r^4, Gauss and Stokes kernels, radial basis functions, etc.) based on a\nChebyshev interpolation scheme has been introduced in [Fong et al., 2009]. The\nmethod has been extended to oscillatory kernels (e.g., Helmholtz kernel) in\n[Messner et al., 2012]. Beside its generality this FMM turns out to be\nfavorable due to its easy implementation and its high performance based on\nintensive use of highly optimized BLAS libraries. However, one of its\nbottlenecks is the precomputation of the multiple-to-local (M2L) operator, and\nits higher number of floating point operations (flops) compared to other FMM\nformulations. Here, we present several optimizations for that operator, which\nis known to be the costliest FMM operator. The most efficient ones do not only\nreduce the precomputation time by a factor up to 340 but they also speed up the\nmatrix-vector product. We conclude with comparisons and numerical validations\nof all presented optimizations.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2012 05:46:13 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2012 17:46:07 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Messner", "Matthias", "", "INRIA Bordeaux - Sud-Ouest"], ["Bramas", "B\u00e9renger", "", "INRIA Bordeaux - Sud-Ouest"], ["Coulaud", "Olivier", "", "INRIA Bordeaux - Sud-Ouest"], ["Darve", "Eric", ""]]}, {"id": "1210.7325", "submitter": "Paolo Bientinesi", "authors": "Diego Fabregat-Traver (1), Yurii Aulchenko (2), Paolo Bientinesi (1),\n  ((1) AICES, RWTH Aachen, (2) Institute of Cytology and Genetics SD RAS)", "title": "Solving Sequences of Generalized Least-Squares Problems on\n  Multi-threaded Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized linear mixed-effects models in the context of genome-wide\nassociation studies (GWAS) represent a formidable computational challenge: the\nsolution of millions of correlated generalized least-squares problems, and the\nprocessing of terabytes of data. We present high performance in-core and\nout-of-core shared-memory algorithms for GWAS: By taking advantage of\ndomain-specific knowledge, exploiting multi-core parallelism, and handling data\nefficiently, our algorithms attain unequalled performance. When compared to\nGenABEL, one of the most widely used libraries for GWAS, on a 12-core processor\nwe obtain 50-fold speedups. As a consequence, our routines enable genome\nstudies of unprecedented size.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2012 14:26:32 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Fabregat-Traver", "Diego", "", "AICES, RWTH Aachen"], ["Aulchenko", "Yurii", "", "Institute of Cytology and Genetics SD RAS"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}, {"id": "1210.7683", "submitter": "Paolo Bientinesi", "authors": "Diego Fabregat-Traver (1), Paolo Bientinesi (1), ((1) AICES, RWTH\n  Aachen)", "title": "Computing Petaflops over Terabytes of Data: The Case of Genome-Wide\n  Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE cs.PF q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scientific and engineering applications, one has to solve not one but\na sequence of instances of the same problem. Often times, the problems in the\nsequence are linked in a way that allows intermediate results to be reused. A\ncharacteristic example for this class of applications is given by the\nGenome-Wide Association Studies (GWAS), a widely spread tool in computational\nbiology. GWAS entails the solution of up to trillions ($10^{12}$) of correlated\ngeneralized least-squares problems, posing a daunting challenge: the\nperformance of petaflops ($10^{15}$ floating-point operations) over terabytes\nof data.\n  In this paper, we design an algorithm for performing GWAS on multi-core\narchitectures. This is accomplished in three steps. First, we show how to\nexploit the relation among successive problems, thus reducing the overall\ncomputational complexity. Then, through an analysis of the required data\ntransfers, we identify how to eliminate any overhead due to input/output\noperations. Finally, we study how to decompose computation into tasks to be\ndistributed among the available cores, to attain high performance and\nscalability. With our algorithm, a GWAS that currently requires the use of a\nsupercomputer may now be performed in matter of hours on a single multi-core\nnode.\n  The discussion centers around the methodology to develop the algorithm rather\nthan the specific application. We believe the paper contributes valuable\nguidelines of general applicability for computational scientists on how to\ndevelop and optimize numerical algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 14:58:03 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Fabregat-Traver", "Diego", ""], ["Bientinesi", "Paolo", ""]]}]