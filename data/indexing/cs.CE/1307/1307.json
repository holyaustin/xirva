[{"id": "1307.0029", "submitter": "Pabitra Pal Choudhury", "authors": "Ranjeet Kumar Rout, Pabitra Pal Choudhury, B. S. Daya Sagar, Sk. Sarif\n  Hassan", "title": "Fractal and Mathematical Morphology in Intricate Comparison between\n  Tertiary Protein Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Intricate comparison between two given tertiary structures of proteins is as\nimportant as the comparison of their functions. Several algorithms have been\ndevised to compute the similarity and dissimilarity among protein structures.\nBut, these algorithms compare protein structures by structural alignment of the\nprotein backbones which are usually unable to determine precise differences. In\nthis paper, an attempt has been made to compute the similarities and\ndissimilarities among 3D protein structures using the fundamental mathematical\nmorphology operations and fractal geometry which can resolve the problem of\nreal differences. In doing so, two techniques are being used here in\ndetermining the superficial structural (global similarity) and local similarity\nin atomic level of the protein molecules. This intricate structural difference\nwould provide insight to Biologists to understand the protein structures and\ntheir functions more precisely.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 15:20:03 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2013 11:54:04 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Rout", "Ranjeet Kumar", ""], ["Choudhury", "Pabitra Pal", ""], ["Sagar", "B. S. Daya", ""], ["Hassan", "Sk. Sarif", ""]]}, {"id": "1307.0194", "submitter": "Liang Wang", "authors": "Wang Liang and Zhao KaiYong", "title": "A new DNA alignment method based on inverted index", "comments": "7 pages;5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel DNA sequences alignment method based on inverted\nindex. Now most large scale information retrieval system are all use inverted\nindex as the basic data structure. But its application in DNA sequence\nalignment is still not found. This paper just discuss such applications. Three\nmain problems, DNA segmenting, long DNA query search, DNA search ranking\nalgorithm and evaluation method are detailed respectively. This research\npresents a new avenue to build more effective DNA alignment methods.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2013 10:08:04 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Liang", "Wang", ""], ["KaiYong", "Zhao", ""]]}, {"id": "1307.0571", "submitter": "Marius Nicolae", "authors": "Marius Nicolae and Sanguthevar Rajasekaran", "title": "Efficient Sequential and Parallel Algorithms for Planted Motif Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif searching is an important step in the detection of rare events\noccurring in a set of DNA or protein sequences. One formulation of the problem\nis known as (l,d)-motif search or Planted Motif Search (PMS). In PMS we are\ngiven two integers l and d and n biological sequences. We want to find all\nsequences of length l that appear in each of the input sequences with at most d\nmismatches. The PMS problem is NP-complete. PMS algorithms are typically\nevaluated on certain instances considered challenging. This paper presents an\nexact parallel PMS algorithm called PMS8. PMS8 is the first algorithm to solve\nthe challenging (l,d) instances (25,10) and (26,11). PMS8 is also efficient on\ninstances with larger l and d such as (50,21). This paper also introduces\nnecessary and sufficient conditions for 3 l-mers to have a common d-neighbor.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 01:51:06 GMT"}], "update_date": "2013-07-03", "authors_parsed": [["Nicolae", "Marius", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "1307.0747", "submitter": "Uwe Aickelin", "authors": "Stephanie Foan, Andrew Jackson, Ian Spendlove, Uwe Aickelin", "title": "Simulating the Dynamics of T Cell Subsets Throughout the Lifetime", "comments": "Proceedings of the 10th International Conference on Artificial Immune\n  Systems (ICARIS 2011), LNCS Volume 6825, Cambridge, UK, pp 71-76", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely accepted that the immune system undergoes age-related changes\ncorrelating with increased disease in the elderly. T cell subsets have been\nimplicated. The aim of this work is firstly to implement and validate a\nsimulation of T regulatory cell (Treg) dynamics throughout the lifetime, based\non a model by Baltcheva. We show that our initial simulation produces an\ninversion between precursor and mature Treys at around 20 years of age, though\nthe output differs significantly from the original laboratory dataset.\nSecondly, this report discusses development of the model to incorporate new\ndata from a cross-sectional study of healthy blood donors addressing balance\nbetween Treys and Th17 cells with novel markers for Treg. The potential for\nsimulation to add insight into immune aging is discussed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 16:19:54 GMT"}], "update_date": "2013-07-03", "authors_parsed": [["Foan", "Stephanie", ""], ["Jackson", "Andrew", ""], ["Spendlove", "Ian", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.0749", "submitter": "Uwe Aickelin", "authors": "Peer-Olaf Siebers, Galina Sherman, Uwe Aickelin, David Menachof", "title": "Comparing Decison Support Tools for Cargo Screening Processes", "comments": "The 10th International Conference on Modeling and Applied Simulation\n  (MAS), 12-14 September, Rome, Italy, 31-39", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When planning to change operations at ports there are two key stake holders\nwith very different interests involved in the decision making processes. Port\noperators are attentive to their standards, a smooth service flow and economic\nviability while border agencies are concerned about national security. The time\ntaken for security checks often interferes with the compliance to service\nstandards that port operators would like to achieve. Decision support tools as\nfor example Cost-Benefit Analysis or Multi Criteria Analysis are useful helpers\nto better understand the impact of changes to a system. They allow\ninvestigating future scenarios and helping to find solutions that are\nacceptable for all parties involved in port operations. In this paper we\nevaluate two different modelling methods, namely scenario analysis and discrete\nevent simulation. These are useful for driving the decision support tools (i.e.\nthey provide the inputs the decision support tools require). Our aims are, on\nthe one hand, to guide the reader through the modelling processes and, on the\nother hand, to demonstrate what kind of decision support information one can\nobtain from the different modelling methods presented.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2013 16:31:44 GMT"}], "update_date": "2013-07-03", "authors_parsed": [["Siebers", "Peer-Olaf", ""], ["Sherman", "Galina", ""], ["Aickelin", "Uwe", ""], ["Menachof", "David", ""]]}, {"id": "1307.1073", "submitter": "Uwe Aickelin", "authors": "Mazlina Abdul Majid, Peer-Olaf Siebers, Uwe Aickelin", "title": "Modelling Reactive and Proactive Behaviour in Simulation: A Case Study\n  in a University Organisation", "comments": "Gameon-Arabia, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is a well established what-if scenario analysis tool in\nOperational Research (OR). While traditionally Discrete Event Simulation (DES)\nand System Dynamics Simulation (SDS) are the predominant simulation techniques\nin OR, a new simulation technique, namely Agent-Based Simulation (ABS), has\nemerged and is gaining more attention. In our research we focus on discrete\nsimulation methods (i.e. DES and ABS). The contribution made by this paper is\nthe comparison of DES and combined DES/ABS for modelling human reactive and\ndifferent level of detail of human proactive behaviour in service systems. The\nresults of our experiments show that the level of proactiveness considered in\nthe model has a big impact on the simulation output. However, there is not a\nbig difference between the results from the DES and the combined DES/ABS\nsimulation models. Therefore, for service systems of the type we investigated\nwe would suggest to use DES as the preferred analysis tool.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 16:43:23 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Majid", "Mazlina Abdul", ""], ["Siebers", "Peer-Olaf", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.1078", "submitter": "Uwe Aickelin", "authors": "Jenna Reps, Jan Feyereisl, Jonathan M. Garibaldi, Uwe Aickelin, Jack\n  E. Gibson, Richard B. Hubbard", "title": "Investigating the Detection of Adverse Drug Events in a UK General\n  Practice Electronic Health-Care Database", "comments": "UKCI 2011, the 11th Annual Workshop on Computational Intelligence,\n  Manchester, pp 167-173", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-mining techniques have frequently been developed for Spontaneous\nreporting databases. These techniques aim to find adverse drug events\naccurately and efficiently. Spontaneous reporting databases are prone to\nmissing information, under reporting and incorrect entries. This often results\nin a detection lag or prevents the detection of some adverse drug events. These\nlimitations do not occur in electronic health-care databases. In this paper,\nexisting methods developed for spontaneous reporting databases are implemented\non both a spontaneous reporting database and a general practice electronic\nhealth-care database and compared. The results suggests that the application of\nexisting methods to the general practice database may help find signals that\nhave gone undetected when using the spontaneous reporting system database. In\naddition the general practice database provides far more supplementary\ninformation, that if incorporated in analysis could provide a wealth of\ninformation for identifying adverse events more accurately.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 16:55:32 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Reps", "Jenna", ""], ["Feyereisl", "Jan", ""], ["Garibaldi", "Jonathan M.", ""], ["Aickelin", "Uwe", ""], ["Gibson", "Jack E.", ""], ["Hubbard", "Richard B.", ""]]}, {"id": "1307.1079", "submitter": "Uwe Aickelin", "authors": "Ian Dent, Uwe Aickelin, Tom Rodden", "title": "Application of a clustering framework to UK domestic electricity data", "comments": "UKCI 2011, the 11th Annual Workshop on Computational Intelligence,\n  Manchester, pp 161-166", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes an approach to clustering domestic electricity load profiles\nthat has been successfully used with data from Portugal and applies it to UK\ndata. Clustering techniques are applied and it is found that the preferred\ntechnique in the Portuguese work (a two stage process combining Self Organised\nMaps and Kmeans) is not appropriate for the UK data. The work shows that up to\nnine clusters of households can be identified with the differences in usage\nprofiles being visually striking. This demonstrates the appropriateness of\nbreaking the electricity usage patterns down to more detail than the two load\nprofiles currently published by the electricity industry. The paper details\ninitial results using data collected in Milton Keynes around 1990. Further work\nis described and will concentrate on building accurate and meaningful clusters\nof similar electricity users in order to better direct demand side management\ninitiatives to the most relevant target customers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2013 17:03:31 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Dent", "Ian", ""], ["Aickelin", "Uwe", ""], ["Rodden", "Tom", ""]]}, {"id": "1307.1380", "submitter": "Uwe Aickelin", "authors": "Ian Dent, Uwe Aickelin, Tom Rodden", "title": "The Application of a Data Mining Framework to Energy Usage Profiling in\n  Domestic Residences using UK data", "comments": "Buildings Do Not Use Energy, People Do Research Student Conference,\n  Bath, UK, 2011. arXiv admin note: text overlap with arXiv:1307.1079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method for defining representative load profiles for\ndomestic electricity users in the UK. It considers bottom up and clustering\nmethods and then details the research plans for implementing and improving\nexisting framework approaches based on the overall usage profile. The work\nfocuses on adapting and applying analysis framework approaches to UK energy\ndata in order to determine the effectiveness of creating a few (single figures)\narchetypical users with the intention of improving on the current methods of\ndetermining usage profiles. The work is currently in progress and the paper\ndetails initial results using data collected in Milton Keynes around 1990.\nVarious possible enhancements to the work are considered including a split\nbased on temperature to reflect the varying UK weather conditions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 15:45:09 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Dent", "Ian", ""], ["Aickelin", "Uwe", ""], ["Rodden", "Tom", ""]]}, {"id": "1307.1385", "submitter": "Uwe Aickelin", "authors": "Ian Dent, Christian Wagner, Uwe Aickelin, Tom Rodden", "title": "Creating Personalised Energy Plans. From Groups to Individuals using\n  Fuzzy C Means Clustering", "comments": "Digital Engagement 11, Newcastle, November 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changes in the UK electricity market mean that domestic users will be\nrequired to modify their usage behaviour in order that supplies can be\nmaintained. Clustering allows usage profiles collected at the household level\nto be clustered into groups and assigned a stereotypical profile which can be\nused to target marketing campaigns. Fuzzy C Means clustering extends this by\nallowing each household to be a member of many groups and hence provides the\nopportunity to make personalised offers to the household dependent on their\ndegree of membership of each group. In addition, feedback can be provided on\nhow user's changing behaviour is moving them towards more \"green\" or cost\neffective stereotypical usage.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 15:55:33 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Dent", "Ian", ""], ["Wagner", "Christian", ""], ["Aickelin", "Uwe", ""], ["Rodden", "Tom", ""]]}, {"id": "1307.1387", "submitter": "Uwe Aickelin", "authors": "Hala Helmi, Jon M. Garibaldi and Uwe Aickelin", "title": "Examining the Classification Accuracy of TSVMs with ?Feature Selection\n  in Comparison with the GLAD Algorithm", "comments": "UKCI 2011, the 11th Annual Workshop on Computational Intelligence,\n  Manchester, pp 7-12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene expression data sets are used to classify and predict patient diagnostic\ncategories. As we know, it is extremely difficult and expensive to obtain gene\nexpression labelled examples. Moreover, conventional supervised approaches\ncannot function properly when labelled data (training examples) are\ninsufficient using Support Vector Machines (SVM) algorithms. Therefore, in this\npaper, we suggest Transductive Support Vector Machines (TSVMs) as\nsemi-supervised learning algorithms, learning with both labelled samples data\nand unlabelled samples to perform the classification of microarray data. To\nprune the superfluous genes and samples we used a feature selection method\ncalled Recursive Feature Elimination (RFE), which is supposed to enhance the\noutput of classification and avoid the local optimization problem. We examined\nthe classification prediction accuracy of the TSVM-RFE algorithm in comparison\nwith the Genetic Learning Across Datasets (GLAD) algorithm, as both are\nsemi-supervised learning methods. Comparing these two methods, we found that\nthe TSVM-RFE surpassed both a SVM using RFE and GLAD.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 16:06:25 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Helmi", "Hala", ""], ["Garibaldi", "Jon M.", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.1390", "submitter": "Uwe Aickelin", "authors": "Grazziela P Figueredo, Uwe Aickelin, Peer-Olaf Siebers", "title": "Systems Dynamics or Agent-Based Modelling for Immune Simulation?", "comments": "Proceedings of the 10th International Conference on Artificial Immune\n  Systems (ICARIS 2011), LNCS Volume 6825, Cambridge, UK, pp 81-94, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In immune system simulation there are two competing simulation approaches:\nSystem Dynamics Simulation (SDS) and Agent-Based Simulation (ABS). In the\nliterature there is little guidance on how to choose the best approach for a\nspecific immune problem. Our overall research aim is to develop a framework\nthat helps researchers with this choice. In this paper we investigate if it is\npossible to easily convert simulation models between approaches. With no\nexplicit guidelines available from the literature we develop and test our own\nset of guidelines for converting SDS models into ABS models in a non-spacial\nscenario. We also define guidelines to convert ABS into SDS considering a\nnon-spatial and a spatial scenario. After running some experiments with the\ndeveloped models we found that in all cases there are significant differences\nbetween the results produced by the different simulation methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 16:15:11 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Figueredo", "Grazziela P", ""], ["Aickelin", "Uwe", ""], ["Siebers", "Peer-Olaf", ""]]}, {"id": "1307.1394", "submitter": "Uwe Aickelin", "authors": "Yihui Liu, Uwe Aickelin", "title": "Detect adverse drug reactions for drug Alendronate", "comments": "Second International Conference on Business Computing and Global\n  Informatization (BCGIN), pp 820-823, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug reaction (ADR) is widely concerned for public health issue. In\nthis study we propose an original approach to detect the ADRs using feature\nmatrix and feature selection. The experiments are carried out on the drug\nSimvastatin. Major side effects for the drug are detected and better\nperformance is achieved compared to other computerized methods. The detected\nADRs are based on the computerized method, further investigation is needed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 16:24:17 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Liu", "Yihui", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.1411", "submitter": "Uwe Aickelin", "authors": "Jenna Reps, Jonathan M. Garibaldi, Uwe Aickelin, Daniele Soria, Jack\n  E. Gibson, Richard B. Hubbard", "title": "Discovering Sequential Patterns in a UK General Practice Database", "comments": "2012 IEEE-EMBS International Conference on Biomedical and Health\n  Informatics, pp 960-963, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wealth of computerised medical information becoming readily available\npresents the opportunity to examine patterns of illnesses, therapies and\nresponses. These patterns may be able to predict illnesses that a patient is\nlikely to develop, allowing the implementation of preventative actions. In this\npaper sequential rule mining is applied to a General Practice database to find\nrules involving a patients age, gender and medical history. By incorporating\nthese rules into current health-care a patient can be highlighted as\nsusceptible to a future illness based on past or current illnesses, gender and\nyear of birth. This knowledge has the ability to greatly improve health-care\nand reduce health-care costs.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 17:01:44 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Reps", "Jenna", ""], ["Garibaldi", "Jonathan M.", ""], ["Aickelin", "Uwe", ""], ["Soria", "Daniele", ""], ["Gibson", "Jack E.", ""], ["Hubbard", "Richard B.", ""]]}, {"id": "1307.1466", "submitter": "Uwe Aickelin", "authors": "Yihui Liu, Uwe Aickelin", "title": "Detect adverse drug reactions for the drug Pravastatin", "comments": "5th International Conference on Biomedical Engineering and\n  Informatics (BMEI), pp 1188-1192, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug reaction (ADR) is widely concerned for public health issue. ADRs\nare one of most common causes to withdraw some drugs from market. Prescription\nevent monitoring (PEM) is an important approach to detect the adverse drug\nreactions. The main problem to deal with this method is how to automatically\nextract the medical events or side effects from high-throughput medical data,\nwhich are collected from day to day clinical practice. In this study we propose\nan original approach to detect the ADRs using feature matrix and feature\nselection. The experiments are carried out on the drug Pravastatin. Major side\neffects for the drug are detected. The detected ADRs are based on computerized\nmethod, further investigation is needed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2013 16:42:02 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Liu", "Yihui", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.1584", "submitter": "Uwe Aickelin", "authors": "Jenna Reps, Jonathan M. Garibaldi, Uwe Aickelin, Daniele Soria, Jack\n  E. Gibson, Richard B. Hubbard", "title": "Comparing Data-mining Algorithms Developed for Longitudinal\n  Observational Databases", "comments": "UKCI 2012, the 12th Annual Workshop on Computational Intelligence,\n  Heriot-Watt University, pp 1-8, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal observational databases have become a recent interest in the\npost marketing drug surveillance community due to their ability of presenting a\nnew perspective for detecting negative side effects. Algorithms mining\nlongitudinal observation databases are not restricted by many of the\nlimitations associated with the more conventional methods that have been\ndeveloped for spontaneous reporting system databases. In this paper we\ninvestigate the robustness of four recently developed algorithms that mine\nlongitudinal observational databases by applying them to The Health Improvement\nNetwork (THIN) for six drugs with well document known negative side effects.\nOur results show that none of the existing algorithms was able to consistently\nidentify known adverse drug reactions above events related to the cause of the\ndrug and no algorithm was superior.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 11:24:55 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Reps", "Jenna", ""], ["Garibaldi", "Jonathan M.", ""], ["Aickelin", "Uwe", ""], ["Soria", "Daniele", ""], ["Gibson", "Jack E.", ""], ["Hubbard", "Richard B.", ""]]}, {"id": "1307.1597", "submitter": "Uwe Aickelin", "authors": "Grazziela P. Figueredo, Peer-Olaf Siebers, Uwe Aickelin and Stephanie\n  Foan", "title": "A Beginners Guide to Systems Simulation in Immunology", "comments": "Proceedings of the 11th Int. Conf. on Artificial Immune Systems, pp\n  57-71, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some common systems modelling and simulation approaches for immune problems\nare Monte Carlo simulations, system dynamics, discrete-event simulation and\nagent-based simulation. These methods, however, are still not widely adopted in\nimmunology research. In addition, to our knowledge, there is few research on\nthe processes for the development of simulation models for the immune system.\nHence, for this work, we have two contributions to knowledge. The first one is\nto show the importance of systems simulation to help immunological research and\nto draw the attention of simulation developers to this research field. The\nsecond contribution is the introduction of a quick guide containing the main\nsteps for modelling and simulation in immunology, together with challenges that\noccur during the model development. Further, this paper introduces an example\nof a simulation problem, where we test our guidelines.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 12:43:04 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2013 13:37:04 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Figueredo", "Grazziela P.", ""], ["Siebers", "Peer-Olaf", ""], ["Aickelin", "Uwe", ""], ["Foan", "Stephanie", ""]]}, {"id": "1307.1598", "submitter": "Uwe Aickelin", "authors": "Christopher M. Roadknight and Uwe Aickelin", "title": "Extending a Microsimulation of the Port of Dover", "comments": "ORS SW12 Simulation Conference, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling and simulating the traffic of heavily used but secure environments\nsuch as seaports and airports is of increasing importance. This paper discusses\nissues and problems that may arise when extending an existing microsimulation\nstrategy. We also discuss how extensions of these simulations can aid planners\nwith optimal physical and operational feedback. Conclusions are drawn about how\nmicrosimulations can be moved forward as a robust planning tool for the 21st\ncentury.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 12:46:33 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Roadknight", "Christopher M.", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.1599", "submitter": "Uwe Aickelin", "authors": "Chris Roadknight, Uwe Aickelin, Guoping Qiu, John Scholefield, Lindy\n  Durrant", "title": "Supervised Learning and Anti-learning of Colorectal Cancer Classes and\n  Survival Rates from Cellular Biology Parameters", "comments": "IEEE International Conference on Systems, Man, and Cybernetics, pp\n  797-802, 2012", "journal-ref": null, "doi": "10.1109/ICSMC.2012.6377825", "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a dataset relating to cellular and physical\nconditions of patients who are operated upon to remove colorectal tumours. This\ndata provides a unique insight into immunological status at the point of tumour\nremoval, tumour classification and post-operative survival. Attempts are made\nto learn relationships between attributes (physical and immunological) and the\nresulting tumour stage and survival. Results for conventional machine learning\napproaches can be considered poor, especially for predicting tumour stages for\nthe most important types of cancer. This poor performance is further\ninvestigated and compared with a synthetic, dataset based on the logical\nexclusive-OR function and it is shown that there is a significant level of\n'anti-learning' present in all supervised methods used and this can be\nexplained by the highly dimensional, complex and sparsely representative\ndataset. For predicting the stage of cancer from the immunological attributes,\nanti-learning approaches outperform a range of popular algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 12:53:28 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Roadknight", "Chris", ""], ["Aickelin", "Uwe", ""], ["Qiu", "Guoping", ""], ["Scholefield", "John", ""], ["Durrant", "Lindy", ""]]}, {"id": "1307.1601", "submitter": "Uwe Aickelin", "authors": "Chris Roadknight, Uwe Aickelin, Alex Ladas, Daniele Soria, John\n  Scholefield and Lindy Durrant", "title": "Biomarker Clustering of Colorectal Cancer Data to Complement Clinical\n  Classification", "comments": "Federated Conference on Computer Science and Information Systems\n  (FedCSIS), pp 187-191, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a dataset relating to cellular and physical\nconditions of patients who are operated upon to remove colorectal tumours. This\ndata provides a unique insight into immunological status at the point of tumour\nremoval, tumour classification and post-operative survival. Attempts are made\nto cluster this dataset and important subsets of it in an effort to\ncharacterize the data and validate existing standards for tumour\nclassification. It is apparent from optimal clustering that existing tumour\nclassification is largely unrelated to immunological factors within a patient\nand that there may be scope for re-evaluating treatment options and survival\nestimates based on a combination of tumour physiology and patient\nhistochemistry.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 12:56:24 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Roadknight", "Chris", ""], ["Aickelin", "Uwe", ""], ["Ladas", "Alex", ""], ["Soria", "Daniele", ""], ["Scholefield", "John", ""], ["Durrant", "Lindy", ""]]}, {"id": "1307.1625", "submitter": "Piero Triverio", "authors": "Piero Triverio", "title": "Robust Causality Check for Sampled Scattering Parameters via a Filtered\n  Fourier Transform", "comments": null, "journal-ref": "IEEE Microwave and Wireless Components Letters, vol.24, no.2,\n  pp.72,74, Feb. 2014", "doi": "10.1109/LMWC.2013.2290218", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a robust numerical technique to verify the causality of sampled\nscattering parameters given on a finite bandwidth. The method is based on a\nfiltered Fourier transform and includes a rigorous estimation of the errors\ncaused by missing out-of-band samples. Compared to existing techniques, the\nmethod is simpler to implement and provides a useful insight on the time-domain\ncharacteristics of the detected violation. Through an applicative example, we\nshows its usefulness to improve the accuracy and reliability of macromodeling\ntechniques used to convert sampled scattering parameters into models for\ntransient analysis.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2013 14:45:00 GMT"}, {"version": "v2", "created": "Wed, 13 Aug 2014 15:39:04 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Triverio", "Piero", ""]]}, {"id": "1307.1998", "submitter": "Uwe Aickelin", "authors": "Alexandros Ladas, Uwe Aickelin, Jon Garibaldi, Eamonn Ferguson", "title": "Using Clustering to extract Personality Information from socio economic\n  data", "comments": "UKCI 2012, the 12th Annual Workshop on Computational Intelligence,\n  Heriot-Watt University, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become apparent that models that have been applied widely in\neconomics, including Machine Learning techniques and Data Mining methods,\nshould take into consideration principles that derive from the theories of\nPersonality Psychology in order to discover more comprehensive knowledge\nregarding complicated economic behaviours. In this work, we present a method to\nextract Behavioural Groups by using simple clustering techniques that can\npotentially reveal aspects of the Personalities for their members. We believe\nthat this is very important because the psychological information regarding the\nPersonalities of individuals is limited in real world applications and because\nit can become a useful tool in improving the traditional models of Knowledge\nEconomy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 09:25:07 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Ladas", "Alexandros", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jon", ""], ["Ferguson", "Eamonn", ""]]}, {"id": "1307.2001", "submitter": "Uwe Aickelin", "authors": "Aslam Ahmed, Julie Greensmith, Uwe Aickelin", "title": "Variance in System Dynamics and Agent Based Modelling Using the SIR\n  Model of Infectious Disease", "comments": "Proceedings of the 26th European Conference on Modelling and\n  Simulation (ECMS), Koblenz, Germany, May 2012, pp 9-15, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical deterministic simulations of epidemiological processes, such as\nthose based on System Dynamics, produce a single result based on a fixed set of\ninput parameters with no variance between simulations. Input parameters are\nsubsequently modified on these simulations using Monte-Carlo methods, to\nunderstand how changes in the input parameters affect the spread of results for\nthe simulation. Agent Based simulations are able to produce different output\nresults on each run based on knowledge of the local interactions of the\nunderlying agents and without making any changes to the input parameters. In\nthis paper we compare the influence and effect of variation within these two\ndistinct simulation paradigms and show that the Agent Based simulation of the\nepidemiological SIR (Susceptible, Infectious, and Recovered) model is more\neffective at capturing the natural variation within SIR compared to an\nequivalent model using System Dynamics with Monte-Carlo simulation. To\ndemonstrate this effect, the SIR model is implemented using both System\nDynamics (with Monte-Carlo simulation) and Agent Based Modelling based on\npreviously published empirical data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 09:28:27 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Ahmed", "Aslam", ""], ["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1307.2111", "submitter": "Uwe Aickelin", "authors": "Ian Dent, Tony Craig, Uwe Aickelin, Tom Rodden", "title": "Finding the creatures of habit; Clustering households based on their\n  flexibility in using electricity", "comments": "Digital Futures 2012, Aberdeen, UK, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Changes in the UK electricity market, particularly with the roll out of smart\nmeters, will provide greatly increased opportunities for initiatives intended\nto change households' electricity usage patterns for the benefit of the overall\nsystem. Users show differences in their regular behaviours and clustering\nhouseholds into similar groupings based on this variability provides for\nefficient targeting of initiatives. Those people who are stuck into a regular\npattern of activity may be the least receptive to an initiative to change\nbehaviour. A sample of 180 households from the UK are clustered into four\ngroups as an initial test of the concept and useful, actionable groupings are\nfound.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2013 14:47:42 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Dent", "Ian", ""], ["Craig", "Tony", ""], ["Aickelin", "Uwe", ""], ["Rodden", "Tom", ""]]}, {"id": "1307.2789", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Fereydoun Farrahi Moghaddam and Mohamed\n  Cheriet", "title": "Computer Simulation of 3-D Finite-Volume Liquid Transport in Fibrous\n  Materials: a Physical Model for Ink Seepage into Paper", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cond-mat.mes-hall", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A physical model for the simulation ink/paper interaction at the mesoscopic\nscale is developed. It is based on the modified Ising model, and is generalized\nto consider the restriction of the finite-volume of ink and also its dynamic\nseepage. This allows the model to obtain the ink distribution within the paper\nvolume. At the mesoscopic scale, the paper is modeled using a discretized fiber\nstructure. The ink distribution is obtained by solving its equivalent\noptimization problem, which is solved using a modified genetic algorithm, along\nwith a new boundary condition and the quasi-linear technique. The model is able\nto simulate the finite-volume distribution of ink.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2013 13:33:57 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Moghaddam", "Fereydoun Farrahi", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1307.3014", "submitter": "Karthik Keyan vkk", "authors": "V.Karthikeyan, S.Senthilkumar, and V.J.Vijayalakshmi", "title": "A New Approach to the Solution of Economic Dispatch Using Particle Swarm\n  Optimization with Simulated Annealing", "comments": "12 pages,3 figures. arXiv admin note: text overlap with\n  arXiv:1206.0915, arXiv:0910.4116, arXiv:1306.1454 by other authors", "journal-ref": "International Journal on Computational Sciences & Applications\n  (IJCSA)Vol.3, No.3, June 2013", "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to the solution of Economic Dispatch using Particle Swarm\nOptimization is presented. It is the progression of allocating production\namongst the dedicated units such that the restriction forced are fulfilled and\nthe power needs are reduced. More just, the soft computing method has received\nsupplementary concentration and was used in a quantity of successful and\nsensible applications. Here, an attempt has been made to find out the minimum\ncost by using Particle Swarm Optimization Algorithm using the data of three\ngenerating units. In this work, data has been taken such as the loss\ncoefficients with the max-min power limit and cost function. PSO and Simulated\nAnnealing are functional to put out the least amount for dissimilar energy\nrequirements. When the outputs are compared with the conventional method, PSO\nseems to give an improved result with enhanced convergence feature. All the\nmethods are executed in MATLAB environment. The effectiveness and feasibility\nof the proposed method were demonstrated by three generating units case study.\nOutput gives hopeful results, signifying that the projected method of\ncalculation is competent of economically formative advanced eminence solutions\naddressing economic dispatch problems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2013 08:42:30 GMT"}], "update_date": "2013-07-12", "authors_parsed": [["Karthikeyan", "V.", ""], ["Senthilkumar", "S.", ""], ["Vijayalakshmi", "V. J.", ""]]}, {"id": "1307.3337", "submitter": "E.N.Sathishkumar", "authors": "T.Chandrasekhar, K.Thangavel, E.Elayaraja, E.N.Sathishkumar", "title": "Unsupervised Gene Expression Data using Enhanced Clustering Method", "comments": "5 pages, 1 figures, conference", "journal-ref": "International Conference on Emerging Trends in Computing,\n  Communication and Nanotechnology (ICE-CCN), 25-26 March 2013, Page(s): 518 -\n  522", "doi": "10.1109/ICE-CCN.2013.6528554", "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarrays are made it possible to simultaneously monitor the expression\nprofiles of thousands of genes under various experimental conditions.\nIdentification of co-expressed genes and coherent patterns is the central goal\nin microarray or gene expression data analysis and is an important task in\nbioinformatics research. Feature selection is a process to select features\nwhich are more informative. It is one of the important steps in knowledge\ndiscovery. The problem is that not all features are important. Some of the\nfeatures may be redundant, and others may be irrelevant and noisy. In this work\nthe unsupervised Gene selection method and Enhanced Center Initialization\nAlgorithm (ECIA) with K-Means algorithms have been applied for clustering of\nGene Expression Data. This proposed clustering algorithm overcomes the\ndrawbacks in terms of specifying the optimal number of clusters and\ninitialization of good cluster centroids. Gene Expression Data show that could\nidentify compact clusters with performs well in terms of the Silhouette\nCoefficients cluster measure.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 06:20:59 GMT"}], "update_date": "2013-07-15", "authors_parsed": [["Chandrasekhar", "T.", ""], ["Thangavel", "K.", ""], ["Elayaraja", "E.", ""], ["Sathishkumar", "E. N.", ""]]}, {"id": "1307.3388", "submitter": "Fazle Faisal", "authors": "Fazle Elahi Faisal and Tijana Milenkovic", "title": "Dynamic networks reveal key players in aging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Since susceptibility to diseases increases with age, studying\naging gains importance. Analyses of gene expression or sequence data, which\nhave been indispensable for investigating aging, have been limited to studying\ngenes and their protein products in isolation, ignoring their connectivities.\nHowever, proteins function by interacting with other proteins, and this is\nexactly what biological networks (BNs) model. Thus, analyzing the proteins' BN\ntopologies could contribute to understanding of aging. Current methods for\nanalyzing systems-level BNs deal with their static representations, even though\ncells are dynamic. For this reason, and because different data types can give\ncomplementary biological insights, we integrate current static BNs with\naging-related gene expression data to construct dynamic, age-specific BNs.\nThen, we apply sensitive measures of topology to the dynamic BNs to study\ncellular changes with age.\n  Results: While global BN topologies do not significantly change with age,\nlocal topologies of a number of genes do. We predict such genes as\naging-related. We demonstrate credibility of our predictions by: 1) observing\nsignificant overlap between our predicted aging-related genes and \"ground\ntruth\" aging-related genes; 2) showing that our aging-related predictions group\nby functions and diseases that are different than functions and diseases of\ngenes that are not predicted as aging-related; 3) observing significant overlap\nbetween functions and diseases that are enriched in our aging-related\npredictions and those that are enriched in \"ground truth\" aging-related data;\n4) providing evidence that diseases which are enriched in our aging-related\npredictions are linked to human aging; and 5) validating all of our\nhigh-scoring novel predictions via manual literature search.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 09:28:02 GMT"}], "update_date": "2013-07-15", "authors_parsed": [["Faisal", "Fazle Elahi", ""], ["Milenkovic", "Tijana", ""]]}, {"id": "1307.3549", "submitter": "Chandrasekhar.T", "authors": "T.Chandrasekhar, K.Thangavel, E.Elayaraja", "title": "Performance Analysis of Clustering Algorithms for Gene Expression Data", "comments": "4 pages,4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1112.4261, arXiv:1201.4914, arXiv:1307.3337", "journal-ref": "International Journal of Scientific & Engineering Research Volume\n  3, Issue 12, December-2012, page 1-4", "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microarray technology is a process that allows thousands of genes\nsimultaneously monitor to various experimental conditions. It is used to\nidentify the co-expressed genes in specific cells or tissues that are actively\nused to make proteins, This method is used to analysis the gene expression, an\nimportant task in bioinformatics research. Cluster analysis of gene expression\ndata has proved to be a useful tool for identifying co-expressed genes,\nbiologically relevant groupings of genes and samples. In this paper we analysed\nK-Means with Automatic Generations of Merge Factor for ISODATA- AGMFI, to group\nthe microarray data sets on the basic of ISODATA. AGMFI is to generate initial\nvalues for merge and Spilt factor, maximum merge times instead of selecting\nefficient values as in ISODATA. The initial seeds for each cluster were\nnormally chosen either sequentially or randomly. The quality of the final\nclusters was found to be influenced by these initial seeds. For the real life\nproblems, the suitable number of clusters cannot be predicted. To overcome the\nabove drawback the current research focused on developing the clustering\nalgorithms without giving the initial number of clusters.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2013 06:43:27 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["Chandrasekhar", "T.", ""], ["Thangavel", "K.", ""], ["Elayaraja", "E.", ""]]}, {"id": "1307.3712", "submitter": "Khalid Raza", "authors": "Khalid Raza and Rafat Parveen", "title": "Reconstruction of gene regulatory network of colon cancer using\n  information theoretic approach", "comments": "5 pages, 4 figures, 1 table", "journal-ref": "Confluence 2013: The Next Generation Information Technology Summit\n  (4th International Conference), pp. 461 - 466", "doi": "10.1049/cp.2013.2357", "report-no": null, "categories": "cs.CE cs.ET cs.SY q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of gene regulatory networks or 'reverse-engineering' is a\nprocess of identifying gene interaction networks from experimental microarray\ngene expression profile through computation techniques. In this paper, we tried\nto reconstruct cancer-specific gene regulatory network using information\ntheoretic approach - mutual information. The considered microarray data\nconsists of large number of genes with 20 samples - 12 samples from colon\ncancer patient and 8 from normal cell. The data has been preprocessed and\nnormalized. A t-test statistics has been applied to filter differentially\nexpressed genes. The interaction between filtered genes has been computed using\nmutual information and ten different networks has been constructed with varying\nnumber of interactions ranging from 30 to 500. We performed the topological\nanalysis of the reconstructed network, revealing a large number of interactions\nin colon cancer. Finally, validation of the inferred results has been done with\navailable biological databases and literature.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2013 08:51:19 GMT"}], "update_date": "2014-08-25", "authors_parsed": [["Raza", "Khalid", ""], ["Parveen", "Rafat", ""]]}, {"id": "1307.4214", "submitter": "Peter Apian-Bennewitz", "authors": "Peter Apian-Bennewitz", "title": "Review of simulating four classes of window materials for daylighting\n  with non-standard BSDF using the simulation program Radiance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This review describes the currently available simulation models for window\nmaterial to calculate daylighting with the program \"Radiance\". The review is\nbased on four abstract and general classes of window materials, depending on\ntheir scattering and redirecting properties (bidirectional scatter distribution\nfunction, BSDF). It lists potential and limits of the older models and includes\nthe most recent additions to the software. All models are demonstrated using an\nexemplary indoor scene and two typical sky conditions. It is intended as\nclarification for applying window material models in project work or teaching.\nThe underlying algorithmic problems apply to all lighting simulation programs,\nso the scenarios of materials and skies are applicable to other lighting\nprograms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2013 09:25:53 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Apian-Bennewitz", "Peter", ""]]}, {"id": "1307.4296", "submitter": "Shriprakash Sinha", "authors": "Shriprakash Sinha, Marcel J. T. Reinders, Wim Verhaegh", "title": "Prior Biological Knowledge And Epigenetic Information Enhances\n  Prediction Accuracy Of Bayesian Wnt Pathway", "comments": "This paper has been withdrawn by the owner because it was submitted\n  without consent of the co-authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational modeling of Wnt signaling pathway has gained prominence for its\nuse as computer aided diagnostic tool to develop therapeutic cancer target\ndrugs and predict of test samples as cancerous and non cancerous. This\nmanuscript focuses on development of simple static bayesian network models of\nvarying complexity that encompasses prior partially available biological\nknowledge about intra and extra cellular factors affecting the Wnt pathway and\nincorporates epigenetic information like methylation and histone modification\nof a few genes known to have inhibitory affect on Wnt pathway. It might be\nexpected that such models not only increase cancer prediction accuracies and\nalso form basis for understanding Wnt signaling activity in different states of\ntumorigenesis. Initial results in human colorectal cancer cases indicate that\nincorporation of epigenetic information increases prediction accuracy of test\nsamples as being tumorous or normal. Receiver Operator Curves (ROC) and their\nrespective area under the curve (AUC) measurements, obtained from predictions\nof state of test sample and corresponding predictions of the state of\nactivation of transcription complex of the Wnt pathway for the test sample,\nindicate that there is significant difference between the Wnt pathway being on\n(off) and its association with the sample being tumorous (normal). Two sample\nKolmogorov-Smirnov test confirm the statistical deviation between the\ndistributions of these predictions. At a preliminary stage, use of these models\nmay help in understanding the yet unknown effect of certain factors like DKK2,\nDKK3-1 and SFRP-2/3/5 on {\\beta}-catenin transcription complex.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2013 09:27:35 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2013 14:46:54 GMT"}, {"version": "v3", "created": "Wed, 8 Jun 2016 08:50:47 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Sinha", "Shriprakash", ""], ["Reinders", "Marcel J. T.", ""], ["Verhaegh", "Wim", ""]]}, {"id": "1307.5076", "submitter": "Alexandru Cioaca Mr", "authors": "Alexandru Cioaca, Adrian Sandu", "title": "Low-rank Approximations for Computing Observation Impact in 4D-Var Data\n  Assimilation", "comments": null, "journal-ref": null, "doi": null, "report-no": "CSL-TR-3-2013", "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient computational framework to quantify the impact of\nindividual observations in four dimensional variational data assimilation. The\nproposed methodology uses first and second order adjoint sensitivity analysis,\ntogether with matrix-free algorithms to obtain low-rank approximations of ob-\nservation impact matrix. We illustrate the application of this methodology to\nimportant applications such as data pruning and the identification of faulty\nsensors for a two dimensional shallow water test system.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2013 20:34:20 GMT"}], "update_date": "2013-07-22", "authors_parsed": [["Cioaca", "Alexandru", ""], ["Sandu", "Adrian", ""]]}, {"id": "1307.6462", "submitter": "Travis Gagie", "authors": "Hector Ferrada, Travis Gagie, Tommi Hirvola, Simon J. Puglisi", "title": "AliBI: An Alignment-Based Index for Genomic Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With current hardware and software, a standard computer can now hold in RAM\nan index for approximate pattern matching on about half a dozen human genomes.\nSequencing technologies have improved so quickly, however, that scientists will\nsoon demand indexes for thousands of genomes. Whereas most researchers who have\naddressed this problem have proposed completely new kinds of indexes, we\nrecently described a simple technique that scales standard indexes to work on\nmore genomes. Our main idea was to filter the dataset with LZ77, build a\nstandard index for the filtered file, and then create a hybrid of that standard\nindex and an LZ77-based index. In this paper we describe how to our technique\nto use alignments instead of LZ77, in order to simplify and speed up both\npreprocessing and random access.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2013 15:42:23 GMT"}], "update_date": "2013-07-25", "authors_parsed": [["Ferrada", "Hector", ""], ["Gagie", "Travis", ""], ["Hirvola", "Tommi", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1307.6883", "submitter": "Eug\\'enio Rodrigues", "authors": "Eug\\'enio Rodrigues (1), Ad\\'elio Rodrigues Gaspar (1) and \\'Alvaro\n  Gomes (2) ((1) ADAI-LAETA Department of Mechanical Engineering University of\n  Coimbra (2) INESCC Department of Electrical and Computer Engineering,\n  University of Coimbra)", "title": "A gradient descent technique coupled with a dynamic simulation to\n  determine the near optimum orientation of floor plan designs", "comments": "10 pages, 6 figures, conference paper; Proceedings of CLIMA 2013\n  16-19 June 2013 Prague Czech Republic (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prototype tool to assist architects during the early design stage of floor\nplans has been developed, consisting of an Evolutionary Program for the Space\nAllocation Problem (EPSAP), which generates sets of floor plan alternatives\naccording to the architect's preferences; and a Floor Plan Performance\nOptimization Program (FPOP), which optimizes the selected solutions according\nto thermal performance criteria. The design variables subject to optimization\nare window position and size, overhangs, fins, wall positioning, and building\norientation. A procedure using a transformation operator with gradient descent,\nsuch as behavior, coupled with a dynamic simulation engine was developed for\nthe thermal evaluation and optimization process. However, the need to evaluate\nall possible alternatives regarding designing variables being used during the\noptimization process leads to an intensive use of thermal simulation, which\ndramatically increases the simulation time, rendering it unpractical. An\nalternative approach is a smart optimization approach, which utilizes an\noriented and adaptive search technique to efficiently find the near optimum\nsolution. This paper presents the search methodology for the building\norientation of floor plan designs, and the corresponding efficiency and\neffectiveness indicators. The calculations are based on 100 floor plan designs\ngenerated by EPSAP. All floor plans have the same design program, location, and\nweather data, changing only their geometry. Dynamic simulation of buildings was\neffectively used together with the optimization procedure in this approach to\nsignificantly improve the designs. The use of the orientation variable has been\nincluded in the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2013 21:24:53 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2013 16:37:33 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Rodrigues", "Eug\u00e9nio", ""], ["Gaspar", "Ad\u00e9lio Rodrigues", ""], ["Gomes", "\u00c1lvaro", ""]]}, {"id": "1307.7050", "submitter": "Khalid Raza", "authors": "Khalid Raza, Atif N Hasan", "title": "A Comprehensive Evaluation of Machine Learning Techniques for Cancer\n  Class Prediction Based on Microarray Data", "comments": "8 pages, 3 figures and 7 tables", "journal-ref": "International Journal of Bioinformatics Research and Applications,\n  Inderscience, 11(5): 397-416 (2015)", "doi": "10.1504/IJBRA.2015.071940", "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prostate cancer is among the most common cancer in males and its\nheterogeneity is well known. Its early detection helps making therapeutic\ndecision. There is no standard technique or procedure yet which is full-proof\nin predicting cancer class. The genomic level changes can be detected in gene\nexpression data and those changes may serve as standard model for any random\ncancer data for class prediction. Various techniques were implied on prostate\ncancer data set in order to accurately predict cancer class including machine\nlearning techniques. Huge number of attributes and few number of sample in\nmicroarray data leads to poor machine learning, therefore the most challenging\npart is attribute reduction or non significant gene reduction. In this work we\nhave compared several machine learning techniques for their accuracy in\npredicting the cancer class. Machine learning is effective when number of\nattributes (genes) are larger than the number of samples which is rarely\npossible with gene expression data. Attribute reduction or gene filtering is\nabsolutely required in order to make the data more meaningful as most of the\ngenes do not participate in tumor development and are irrelevant for cancer\nprediction. Here we have applied combination of statistical techniques such as\ninter-quartile range and t-test, which has been effective in filtering\nsignificant genes and minimizing noise from data. Further we have done a\ncomprehensive evaluation of ten state-of-the-art machine learning techniques\nfor their accuracy in class prediction of prostate cancer. Out of these\ntechniques, Bayes Network out performed with an accuracy of 94.11% followed by\nNavie Bayes with an accuracy of 91.17%. To cross validate our results, we\nmodified our training dataset in six different way and found that average\nsensitivity, specificity, precision and accuracy of Bayes Network is highest\namong all other techniques used.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2013 14:44:16 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Raza", "Khalid", ""], ["Hasan", "Atif N", ""]]}, {"id": "1307.7385", "submitter": "Bhaskar DasGupta", "authors": "Reka Albert, Bhaskar DasGupta, Nasim Mobasheri", "title": "Some Perspectives on Network Modeling in Therapeutic Target Prediction", "comments": null, "journal-ref": "Biomedical Engineering and Computational Biology, 5, 17-24, 2013", "doi": "10.4137/BECB.S10793", "report-no": null, "categories": "q-bio.MN cs.CE cs.DM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug target identification is of significant commercial interest to\npharmaceutical companies, and there is a vast amount of research done related\nto the topic of therapeutic target identification. Interdisciplinary research\nin this area involves both the biological network community and the graph\nalgorithms community. Key steps of a typical therapeutic target identification\nproblem include synthesizing or inferring the complex network of interactions\nrelevant to the disease, connecting this network to the disease-specific\nbehavior, and predicting which components are key mediators of the behavior.\nAll of these steps involve graph theoretical or graph algorithmic aspects. In\nthis perspective, we provide modelling and algorithmic perspectives for\ntherapeutic target identification and highlight a number of algorithmic\nadvances, which have gotten relatively little attention so far, with the hope\nof strengthening the ties between these two research communities.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2013 17:42:01 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Albert", "Reka", ""], ["DasGupta", "Bhaskar", ""], ["Mobasheri", "Nasim", ""]]}, {"id": "1307.7757", "submitter": "Guoming Tang", "authors": "Guoming Tang, Kui Wu, Jian Pei, Jiuyang Tang and Jingsheng Lei", "title": "Household Electricity Consumption Data Cleansing", "comments": "12 pages, 12 figures; update: modified title and introduction, and\n  corrected some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load curve data in power systems refers to users' electrical energy\nconsumption data periodically collected with meters. It has become one of the\nmost important assets for modern power systems. Many operational decisions are\nmade based on the information discovered in the data. Load curve data, however,\nusually suffers from corruptions caused by various factors, such as data\ntransmission errors or malfunctioning meters. To solve the problem, tremendous\nresearch efforts have been made on load curve data cleansing. Most existing\napproaches apply outlier detection methods from the supply side (i.e.,\nelectricity service providers), which may only have aggregated load data. In\nthis paper, we propose to seek aid from the demand side (i.e., electricity\nservice users). With the help of readily available knowledge on consumers'\nappliances, we present a new appliance-driven approach to load curve data\ncleansing. This approach utilizes data generation rules and a Sequential Local\nOptimization Algorithm (SLOA) to solve the Corrupted Data Identification\nProblem (CDIP). We evaluate the performance of SLOA with real-world trace data\nand synthetic data. The results indicate that, comparing to existing load data\ncleansing methods, such as B-spline smoothing, our approach has an overall\nbetter performance and can effectively identify consecutive corrupted data.\nExperimental results also demonstrate that our method is robust in various\ntests. Our method provides a highly feasible and reliable solution to an\nemerging industry application.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2013 22:22:56 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2013 17:20:58 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2014 10:03:38 GMT"}, {"version": "v4", "created": "Mon, 19 May 2014 19:11:20 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Tang", "Guoming", ""], ["Wu", "Kui", ""], ["Pei", "Jian", ""], ["Tang", "Jiuyang", ""], ["Lei", "Jingsheng", ""]]}, {"id": "1307.7795", "submitter": "Aaron Darling", "authors": "Ramanuja Simha and Hagit Shatkay", "title": "Protein (Multi-)Location Prediction: Using Location Inter-Dependencies\n  in a Probabilistic Framework", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing the location of a protein within the cell is important for\nunderstanding its function, role in biological processes, and potential use as\na drug target. Much progress has been made in developing computational methods\nthat predict single locations for proteins, assuming that proteins localize to\na single location. However, it has been shown that proteins localize to\nmultiple locations. While a few recent systems have attempted to predict\nmultiple locations of proteins, they typically treat locations as independent\nor capture inter-dependencies by treating each locations-combination present in\nthe training set as an individual location-class. We present a new method and a\npreliminary system we have developed that directly incorporates\ninter-dependencies among locations into the multiple-location-prediction\nprocess, using a collection of Bayesian network classifiers. We evaluate our\nsystem on a dataset of single- and multi-localized proteins. Our results,\nobtained by incorporating inter-dependencies are significantly higher than\nthose obtained by classifiers that do not use inter-dependencies. The\nperformance of our system on multi-localized proteins is comparable to a top\nperforming system (YLoc+), without restricting predictions to be based only on\nlocation-combinations present in the training set.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 03:19:05 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Simha", "Ramanuja", ""], ["Shatkay", "Hagit", ""]]}, {"id": "1307.7810", "submitter": "Aaron Darling", "authors": "Denisa Duma, Mary Wootters, Anna C. Gilbert, Hung Q. Ngo, Atri Rudra,\n  Matthew Alpert, Timothy J. Close, Gianfranco Ciardo, and Stefano Lonardi", "title": "Accurate Decoding of Pooled Sequenced Data Using Compressed Sensing", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.IT math.IT q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to overcome the limitations imposed by DNA barcoding when\nmultiplexing a large number of samples in the current generation of\nhigh-throughput sequencing instruments, we have recently proposed a new\nprotocol that leverages advances in combinatorial pooling design (group\ntesting) doi:10.1371/journal.pcbi.1003010. We have also demonstrated how this\nnew protocol would enable de novo selective sequencing and assembly of large,\nhighly-repetitive genomes. Here we address the problem of decoding pooled\nsequenced data obtained from such a protocol. Our algorithm employs a\nsynergistic combination of ideas from compressed sensing and the decoding of\nerror-correcting codes. Experimental results on synthetic data for the rice\ngenome and real data for the barley genome show that our novel decoding\nalgorithm enables significantly higher quality assemblies than the previous\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 04:34:34 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Duma", "Denisa", ""], ["Wootters", "Mary", ""], ["Gilbert", "Anna C.", ""], ["Ngo", "Hung Q.", ""], ["Rudra", "Atri", ""], ["Alpert", "Matthew", ""], ["Close", "Timothy J.", ""], ["Ciardo", "Gianfranco", ""], ["Lonardi", "Stefano", ""]]}, {"id": "1307.7811", "submitter": "Aaron Darling", "authors": "Alexandru I. Tomescu, Anna Kuosmanen, Romeo Rizzi, and Veli M\\\"akinen", "title": "A Novel Combinatorial Method for Estimating Transcript Expression with\n  RNA-Seq: Bounding the Number of Paths", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNA-Seq technology offers new high-throughput ways for transcript\nidentification and quantification based on short reads, and has recently\nattracted great interest. The problem is usually modeled by a weighted splicing\ngraph whose nodes stand for exons and whose edges stand for split alignments to\nthe exons. The task consists of finding a number of paths, together with their\nexpression levels, which optimally explain the coverages of the graph under\nvarious fitness functions, such least sum of squares. In (Tomescu et al.\nRECOMB-seq 2013) we showed that under general fitness functions, if we allow a\npolynomially bounded number of paths in an optimal solution, this problem can\nbe solved in polynomial time by a reduction to a min-cost flow program. In this\npaper we further refine this problem by asking for a bounded number k of paths\nthat optimally explain the splicing graph. This problem becomes NP-hard in the\nstrong sense, but we give a fast combinatorial algorithm based on dynamic\nprogramming for it. In order to obtain a practical tool, we implement three\noptimizations and heuristics, which achieve better performance on real data,\nand similar or better performance on simulated data, than state-of-the-art\ntools Cufflinks, IsoLasso and SLIDE. Our tool, called Traph, is available at\nhttp://www.cs.helsinki.fi/gsa/traph/\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 04:42:47 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Tomescu", "Alexandru I.", ""], ["Kuosmanen", "Anna", ""], ["Rizzi", "Romeo", ""], ["M\u00e4kinen", "Veli", ""]]}, {"id": "1307.7813", "submitter": "Aaron Darling", "authors": "Gustavo Sacomoto, Vincent Lacroix, and Marie-France Sagot", "title": "A polynomial delay algorithm for the enumeration of bubbles with length\n  constraints in directed graphs and its application to the detection of\n  alternative splicing in RNA-seq data", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for enumerating bubbles with length constraints in\ndirected graphs. This problem arises in transcriptomics, where the question is\nto identify all alternative splicing events present in a sample of mRNAs\nsequenced by RNA-seq. This is the first polynomial-delay algorithm for this\nproblem and we show that in practice, it is faster than previous approaches.\nThis enables us to deal with larger instances and therefore to discover novel\nalternative splicing events, especially long ones, that were previously\noverseen using existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 04:48:08 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Sacomoto", "Gustavo", ""], ["Lacroix", "Vincent", ""], ["Sagot", "Marie-France", ""]]}, {"id": "1307.7820", "submitter": "Aaron Darling", "authors": "Balaji Venkatachalam, Dan Gusfield, and Yelena Frid", "title": "Faster Algorithms for RNA-folding using the Four-Russians method", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013). Editor's note: abstract was\n  shortened to comply with arxiv requirements. Full abstract in PDF", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The secondary structure that maximizes the number of non-crossing matchings\nbetween complimentary bases of an RNA sequence of length n can be computed in\nO(n^3) time using Nussinov's dynamic programming algorithm. The Four-Russians\nmethod is a technique that will reduce the running time for certain dynamic\nprogramming algorithms by a multiplicative factor after a preprocessing step\nwhere solutions to all smaller subproblems of a fixed size are exhaustively\nenumerated and solved. Frid and Gusfield designed an O(\\frac{n^3}{\\log n})\nalgorithm for RNA folding using the Four-Russians technique. In their algorithm\nthe preprocessing is interleaved with the algorithm computation. (Algo. Mol.\nBiol., 2010).\n  We simplify the algorithm and the analysis by doing the preprocessing once\nprior to the algorithm computation. We call this the two-vector method. We also\nshow variants where instead of exhaustive preprocessing, we only solve the\nsubproblems encountered in the main algorithm once and memoize the results. We\ngive a simple proof of correctness and explore the practical advantages over\nthe earlier method. The Nussinov algorithm admits an O(n^2) time parallel\nalgorithm. We show a parallel algorithm using the two-vector idea that improves\nthe time bound to O(\\frac{n^2}{log n}).\n  We discuss the organization of the data structures to exploit coalesced\nmemory access for fast running times. The ideas to organize the data structures\nalso help in improving the running time of the serial algorithms. For sequences\nof length up to 6000 bases the parallel algorithm takes only about 2.5 seconds\nand the two-vector serial method takes about 57 seconds on a desktop and 15\nseconds on a server. Among the serial algorithms, the two-vector and memoized\nversions are faster than the Frid-Gusfield algorithm by a factor of 3, and are\nfaster than Nussinov by up to a factor of 20.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 05:13:11 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Venkatachalam", "Balaji", ""], ["Gusfield", "Dan", ""], ["Frid", "Yelena", ""]]}, {"id": "1307.7821", "submitter": "Aaron Darling", "authors": "Jesper Jansson, Chuanqi Shen, and Wing-Kin Sung", "title": "Algorithms for the Majority Rule (+) Consensus Tree and the Frequency\n  Difference Consensus Tree", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two new deterministic algorithms for constructing\nconsensus trees. Given an input of k phylogenetic trees with identical leaf\nlabel sets and n leaves each, the first algorithm constructs the majority rule\n(+) consensus tree in O(kn) time, which is optimal since the input size is\nOmega(kn), and the second one constructs the frequency difference consensus\ntree in min(O(kn^2), O(kn (k+log^2 n))) time.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 05:24:12 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 05:40:35 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Jansson", "Jesper", ""], ["Shen", "Chuanqi", ""], ["Sung", "Wing-Kin", ""]]}, {"id": "1307.7824", "submitter": "Aaron Darling", "authors": "Sebastian B\\\"ocker, Stefan Canzar, and Gunnar W. Klau", "title": "The generalized Robinson-Foulds metric", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Robinson-Foulds (RF) metric is arguably the most widely used measure of\nphylogenetic tree similarity, despite its well-known shortcomings: For example,\nmoving a single taxon in a tree can result in a tree that has maximum distance\nto the original one; but the two trees are identical if we remove the single\ntaxon. To this end, we propose a natural extension of the RF metric that does\nnot simply count identical clades but instead, also takes similar clades into\nconsideration. In contrast to previous approaches, our model requires the\nmatching between clades to respect the structure of the two trees, a property\nthat the classical RF metric exhibits, too. We show that computing this\ngeneralized RF metric is, unfortunately, NP-hard. We then present a simple\nInteger Linear Program for its computation, and evaluate it by an\nall-against-all comparison of 100 trees from a benchmark data set. We find that\nmatchings that respect the tree structure differ significantly from those that\ndo not, underlining the importance of this natural condition.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 05:29:55 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["B\u00f6cker", "Sebastian", ""], ["Canzar", "Stefan", ""], ["Klau", "Gunnar W.", ""]]}, {"id": "1307.7825", "submitter": "Aaron Darling", "authors": "Constantinos Tsirogiannis and Brody Sandel", "title": "Computing the Skewness of the Phylogenetic Mean Pairwise Distance in\n  Linear Time", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phylogenetic Mean Pairwise Distance (MPD) is one of the most popular\nmeasures for computing the phylogenetic distance between a given group of\nspecies. More specifically, for a phylogenetic tree T and for a set of species\nR represented by a subset of the leaf nodes of T, the MPD of R is equal to the\naverage cost of all possible simple paths in T that connect pairs of nodes in\nR.\n  Among other phylogenetic measures, the MPD is used as a tool for deciding if\nthe species of a given group R are closely related. To do this, it is important\nto compute not only the value of the MPD for this group but also the\nexpectation, the variance, and the skewness of this metric. Although efficient\nalgorithms have been developed for computing the expectation and the variance\nthe MPD, there has been no approach so far for computing the skewness of this\nmeasure.\n  In the present work we describe how to compute the skewness of the MPD on a\ntree T optimally, in Theta(n) time; here n is the size of the tree T. So far\nthis is the first result that leads to an exact, let alone efficient,\ncomputation of the skewness for any popular phylogenetic distance measure.\nMoreover, we show how we can compute in Theta(n) time several interesting\nquantities in T that can be possibly used as building blocks for computing\nefficiently the skewness of other phylogenetic measures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 05:37:17 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Tsirogiannis", "Constantinos", ""], ["Sandel", "Brody", ""]]}, {"id": "1307.7828", "submitter": "Aaron Darling", "authors": "Sudheer Vakati and David Fern\\'andez-Baca", "title": "Characterizing Compatibility and Agreement of Unrooted Trees via Cuts in\n  Graphs", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding whether there is a single tree -a supertree- that summarizes the\nevolutionary information in a collection of unrooted trees is a fundamental\nproblem in phylogenetics. We consider two versions of this question: agreement\nand compatibility. In the first, the supertree is required to reflect precisely\nthe relationships among the species exhibited by the input trees. In the\nsecond, the supertree can be more refined than the input trees.\n  Tree compatibility can be characterized in terms of the existence of a\nspecific kind of triangulation in a structure known as the display graph.\nAlternatively, it can be characterized as a chordal graph sandwich problem in a\nstructure known as the edge label intersection graph. Here, we show that the\nlatter characterization yields a natural characterization of compatibility in\nterms of minimal cuts in the display graph, which is closely related to\ncompatibility of splits. We then derive a characterization for agreement.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 05:42:36 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Vakati", "Sudheer", ""], ["Fern\u00e1ndez-Baca", "David", ""]]}, {"id": "1307.7831", "submitter": "Aaron Darling", "authors": "Nicolas Wieseke, Matthias Bernt, and Martin Middendorf", "title": "Unifying Parsimonious Tree Reconciliation", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DS q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution is a process that is influenced by various environmental factors,\ne.g. the interactions between different species, genes, and biogeographical\nproperties. Hence, it is interesting to study the combined evolutionary history\nof multiple species, their genes, and the environment they live in. A common\napproach to address this research problem is to describe each individual\nevolution as a phylogenetic tree and construct a tree reconciliation which is\nparsimonious with respect to a given event model. Unfortunately, most of the\nprevious approaches are designed only either for host-parasite systems, for\ngene tree/species tree reconciliation, or biogeography. Hence, a method is\ndesirable, which addresses the general problem of mapping phylogenetic trees\nand covering all varieties of coevolving systems, including e.g., predator-prey\nand symbiotic relationships. To overcome this gap, we introduce a generalized\ncophylogenetic event model considering the combinatorial complete set of local\ncoevolutionary events. We give a dynamic programming based heuristic for\nsolving the maximum parsimony reconciliation problem in time O(n^2), for two\nphylogenies each with at most n leaves. Furthermore, we present an exact\nbranch-and-bound algorithm which uses the results from the dynamic programming\nheuristic for discarding partial reconciliations. The approach has been\nimplemented as a Java application which is freely available from\nhttp://pacosy.informatik.uni-leipzig.de/coresym.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 05:47:27 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Wieseke", "Nicolas", ""], ["Bernt", "Matthias", ""], ["Middendorf", "Martin", ""]]}, {"id": "1307.7840", "submitter": "Aaron Darling", "authors": "Jo\\~ao Paulo Pereira Zanetti, Priscila Biller, and Jo\\~ao Meidanis", "title": "On the Matrix Median Problem", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Genome Median Problem is an important problem in phylogenetic\nreconstruction under rearrangement models. It can be stated as follows: given\nthree genomes, find a fourth that minimizes the sum of the pairwise\nrearrangement distances between it and the three input genomes. Recently,\nFeijao and Meidanis extended the algebraic theory for genome rearrangement to\nallow for linear chromosomes, thus yielding a new rearrangement model (the\nalgebraic model), very close to the celebrated DCJ model. In this paper, we\nstudy the genome median problem under the algebraic model, whose complexity is\ncurrently open, proposing a more general form of the problem, the matrix median\nproblem. It is known that, for any metric distance, at least one of the corners\nis a 4/3-approximation of the median. Our results allow us to compute up to\nthree additional matrix median candidates, all of them with approximation\nratios at least as good as the best corner, when the input matrices come from\ngenomes. From the application point of view, it is usually more interesting to\nlocate medians farther from the corners. We also show a fourth median candidate\nthat gives better results in cases we tried. However, we do not have proven\nbounds for this fourth candidate yet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 06:52:13 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Zanetti", "Jo\u00e3o Paulo Pereira", ""], ["Biller", "Priscila", ""], ["Meidanis", "Jo\u00e3o", ""]]}, {"id": "1307.7842", "submitter": "Aaron Darling", "authors": "Laurent Bulteau, Guillaume Fertin, Christian Komusiewicz, and Irena\n  Rusu", "title": "A Fixed-Parameter Algorithm for Minimum Common String Partition with Few\n  Duplications", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the study of genome rearrangements, the NP-hard Minimum Common\nString Partition problems asks, given two strings, to split both strings into\nan identical set of blocks. We consider an extension of this problem to\nunbalanced strings, so that some elements may not be covered by any block. We\npresent an efficient fixed-parameter algorithm for the parameters number k of\nblocks and maximum occurrence d of a letter in either string. We then evaluate\nthis algorithm on bacteria genomes and synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 06:59:15 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Bulteau", "Laurent", ""], ["Fertin", "Guillaume", ""], ["Komusiewicz", "Christian", ""], ["Rusu", "Irena", ""]]}, {"id": "1307.7925", "submitter": "Aaron Darling", "authors": "Taku Onodera, Kunihiko Sadakane, and Tetsuo Shibuya", "title": "Detecting Superbubbles in Assembly Graphs", "comments": "Peer-reviewed and presented as part of the 13th Workshop on\n  Algorithms in Bioinformatics (WABI2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.DM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new concept of a subgraph class called a superbubble for\nanalyzing assembly graphs, and propose an efficient algorithm for detecting it.\nMost assembly algorithms utilize assembly graphs like the de Bruijn graph or\nthe overlap graph constructed from reads. From these graphs, many assembly\nalgorithms first detect simple local graph structures (motifs), such as tips\nand bubbles, mainly to find sequencing errors. These motifs are easy to detect,\nbut they are sometimes too simple to deal with more complex errors. The\nsuperbubble is an extension of the bubble, which is also important for\nanalyzing assembly graphs. Though superbubbles are much more complex than\nordinary bubbles, we show that they can be efficiently enumerated. We propose\nan average-case linear time algorithm (i.e., O(n+m) for a graph with n vertices\nand m edges) for graphs with a reasonable model, though the worst-case time\ncomplexity of our algorithm is quadratic (i.e., O(n(n+m))). Moreover, the\nalgorithm is practically very fast: Our experiments show that our algorithm\nruns in reasonable time with a single CPU core even against a very large graph\nof a whole human genome.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2013 11:44:34 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Onodera", "Taku", ""], ["Sadakane", "Kunihiko", ""], ["Shibuya", "Tetsuo", ""]]}]