[{"id": "1508.00749", "submitter": "Indre Zliobaite", "authors": "Tomas Krilavicius, Indre Zliobaite, Henrikas Simonavicius and Laimonas\n  Jarusevicius", "title": "Predicting respiratory motion for real-time tumour tracking in\n  radiotherapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose. Radiation therapy is a local treatment aimed at cells in and around\na tumor. The goal of this study is to develop an algorithmic solution for\npredicting the position of a target in 3D in real time, aiming for the short\nfixed calibration time for each patient at the beginning of the procedure.\nAccurate predictions of lung tumor motion are expected to improve the precision\nof radiation treatment by controlling the position of a couch or a beam in\norder to compensate for respiratory motion during radiation treatment.\n  Methods. For developing the algorithmic solution, data mining techniques are\nused. A model form from the family of exponential smoothing is assumed, and the\nmodel parameters are fitted by minimizing the absolute disposition error, and\nthe fluctuations of the prediction signal (jitter). The predictive performance\nis evaluated retrospectively on clinical datasets capturing different behavior\n(being quiet, talking, laughing), and validated in real-time on a prototype\nsystem with respiratory motion imitation.\n  Results. An algorithmic solution for respiratory motion prediction (called\nExSmi) is designed. ExSmi achieves good accuracy of prediction (error $4-9$\nmm/s) with acceptable jitter values (5-7 mm/s), as tested on out-of-sample\ndata. The datasets, the code for algorithms and the experiments are openly\navailable for research purposes on a dedicated website.\n  Conclusions. The developed algorithmic solution performs well to be\nprototyped and deployed in applications of radiotherapy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2015 12:26:00 GMT"}], "update_date": "2015-08-05", "authors_parsed": [["Krilavicius", "Tomas", ""], ["Zliobaite", "Indre", ""], ["Simonavicius", "Henrikas", ""], ["Jarusevicius", "Laimonas", ""]]}, {"id": "1508.01023", "submitter": "Bokai Cao", "authors": "Bokai Cao, Xiangnan Kong, Philip S. Yu", "title": "A review of heterogeneous data mining for brain disorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.DB q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid advances in neuroimaging techniques, the research on brain\ndisorder identification has become an emerging area in the data mining\ncommunity. Brain disorder data poses many unique challenges for data mining\nresearch. For example, the raw data generated by neuroimaging experiments is in\ntensor representations, with typical characteristics of high dimensionality,\nstructural complexity and nonlinear separability. Furthermore, brain\nconnectivity networks can be constructed from the tensor data, embedding subtle\ninteractions between brain regions. Other clinical measures are usually\navailable reflecting the disease status from different perspectives. It is\nexpected that integrating complementary information in the tensor data and the\nbrain network data, and incorporating other clinical parameters will be\npotentially transformative for investigating disease mechanisms and for\ninforming therapeutic interventions. Many research efforts have been devoted to\nthis area. They have achieved great success in various applications, such as\ntensor-based modeling, subgraph pattern mining, multi-view feature analysis. In\nthis paper, we review some recent data mining methods that are used for\nanalyzing brain disorders.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 09:57:32 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Cao", "Bokai", ""], ["Kong", "Xiangnan", ""], ["Yu", "Philip S.", ""]]}, {"id": "1508.01041", "submitter": "Kristian Jensen", "authors": "K. E. Jensen, P. Szabo, F. Okkels", "title": "Implementation of the Log-Conformation Formulation for Two-Dimensional\n  Viscoelastic Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have implemented the log-conformation method for two-dimensional\nviscoelastic flow in COMSOL, a commercial high-level finite element package.\nThe code is verified for an Oldroyd-B fluid flowing past a confined cylinder.\nWe are also able to describe the well-known bistability of the viscoelastic\nflow in a cross-slot geometry for a FENE-CR fluid, and we describe the changes\nrequired for performing simulations with the Phan-Thien-Tanner (PTT), Giesekus\nand FENE-P models. Finally, we calculate the flow of a FENE-CR fluid in a\ngeometry with three in- and outlets. The implementation is included in the\nsupplementary material, and we hope that it can inspire new as well as\nexperienced researchers in the field of differential constitutive equations for\nviscoelastic flow.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 11:57:14 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 15:15:31 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Jensen", "K. E.", ""], ["Szabo", "P.", ""], ["Okkels", "F.", ""]]}, {"id": "1508.01962", "submitter": "Sebastian Roch", "authors": "Constantinos Daskalakis and Sebastien Roch", "title": "Species Trees are Recoverable from Unrooted Gene Tree Topologies Under a\n  Constant Rate of Horizontal Gene Transfer", "comments": "Submitted. Conference version published as: Daskalakis, Constantinos,\n  and Sebastien Roch. \"Species trees from gene trees despite a high rate of\n  lateral genetic transfer: A tight bound.\" Proceedings of the Twenty-Seventh\n  Annual ACM-SIAM Symposium on Discrete Algorithms. Society for Industrial and\n  Applied Mathematics, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing the tree of life from molecular sequences is a fundamental\nproblem in computational biology. Modern data sets often contain a large number\nof genes, which can complicate the reconstruction problem due to the fact that\ndifferent genes may undergo different evolutionary histories. This is the case\nin particular in the presence of horizontal genetic transfer (HGT), where a\ngene is inherited from a distant species rather than an immediate ancestor.\nSuch an event produces a gene tree which is distinct from, but related to, the\nspecies phylogeny.\n  In previous work, a natural stochastic models of HGT was introduced and\nstudied. It was shown, both in simulation and theoretical studies, that a\nspecies phylogeny can be reconstructed from gene trees despite surprisingly\nhigh rates of HGT under this model. Rigorous lower and upper bounds on this\nachievable rate were also obtained, but a large gap remained. Here we close\nthis gap, up to a constant. Specifically we show that a species phylogeny can\nbe reconstructed correctly from gene trees even when, on each gene, each edge\nof the species tree has a constant probability of being the location of an HGT\nevent. Our new reconstruction algorithm, which relies only on unrooted gene\ntree topologies, builds the tree recursively from the leaves and runs in\npolynomial time.\n  We also provide a matching bound in the negative direction (up to a constant)\nand extend our results to some cases where gene trees are not perfectly known.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2015 22:20:47 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 06:41:57 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Roch", "Sebastien", ""]]}, {"id": "1508.02136", "submitter": "Maria Vasilyeva", "authors": "Donald L. Brown, Maria Vasilyeva", "title": "A Generalized Multiscale Finite Element Method for Poroelasticity\n  Problems I: Linear Problems", "comments": "arXiv admin note: text overlap with arXiv:1309.6030 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the numerical solution of poroelasticity problems\nthat are of Biot type and develop a general algorithm for solving coupled\nsystems. We discuss the challenges associated with mechanics and flow problems\nin heterogeneous media. The two primary issues being the multiscale nature of\nthe media and the solutions of the fluid and mechanics variables traditionally\ndeveloped with separate grids and methods. For the numerical solution we\ndevelop and implement a Generalized Multiscale Finite Element Method (GMsFEM)\nthat solves problem on a coarse grid by constructing local multiscale basis\nfunctions. The procedure begins with construction of multiscale bases for both\ndisplacement and pressure in each coarse block. Using a snapshot space and\nlocal spectral problems, we construct a basis of reduced dimension. Finally,\nafter multiplying by a multiscale partitions of unity, the multiscale basis is\nconstructed in the offline phase and the coarse grid problem then can be solved\nfor arbitrary forcing and boundary conditions. We implement this algorithm on\ntwo heterogenous media and compute error between the multiscale solution with\nthe fine-scale solutions. Randomized oversampling and forcing strategies are\nalso tested.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 06:20:54 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Brown", "Donald L.", ""], ["Vasilyeva", "Maria", ""]]}, {"id": "1508.02138", "submitter": "Maria Vasilyeva", "authors": "Donald L. Brown, Maria Vasilyeva", "title": "A Generalized Multiscale Finite Element Method for Poroelasticity\n  Problems II: Nonlinear Coupling", "comments": "arXiv admin note: text overlap with arXiv:1304.5188 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the numerical solution of some nonlinear\nporoelasticity problems that are of Biot type and develop a general algorithm\nfor solving nonlinear coupled systems. We discuss the difficulties associated\nwith flow and mechanics in heterogenous media with nonlinear coupling. The\ncentral issue being how to handle the nonlinearities and the multiscale scale\nnature of the media. To compute an efficient numerical solution we develop and\nimplement a Generalized Multiscale Finite Element Method (GMsFEM) that solves\nnonlinear problems on a coarse grid by constructing local multiscale basis\nfunctions and treating part of the nonlinearity locally as a parametric value.\nAfter linearization with a Picard Iteration, the procedure begins with\nconstruction of multiscale bases for both displacement and pressure in each\ncoarse block by treating the staggered nonlinearity as a parametric value.\nUsing a snapshot space and local spectral problems, we construct an offline\nbasis of reduced dimension. From here an online, parametric dependent, space is\nconstructed. Finally, after multiplying by a multiscale partitions of unity,\nthe multiscale basis is constructed and the coarse grid problem then can be\nsolved for arbitrary forcing and boundary conditions. We implement this\nalgorithm on a geometry with a linear and nonlinear pressure dependent\npermeability field and compute error between the multiscale solution with the\nfine-scale solutions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 06:29:12 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Brown", "Donald L.", ""], ["Vasilyeva", "Maria", ""]]}, {"id": "1508.02489", "submitter": "Zheng Zhang", "authors": "Zheng Zhang and Hung Dinh Nguyen and Konstantin Turitsyn and Luca\n  Daniel", "title": "Probabilistic Power Flow Computation via Low-Rank and Sparse Tensor\n  Recovery", "comments": "8 pages, 10 figures, submitted to IEEE Trans. Power Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a tensor-recovery method to solve probabilistic power\nflow problems. Our approach generates a high-dimensional and sparse generalized\npolynomial-chaos expansion that provides useful statistical information. The\nresult can also speed up other essential routines in power systems (e.g.,\nstochastic planning, operations and controls).\n  Instead of simulating a power flow equation at all quadrature points, our\napproach only simulates an extremely small subset of samples. We suggest a\nmodel to exploit the underlying low-rank and sparse structure of\nhigh-dimensional simulation data arrays, making our technique applicable to\npower systems with many random parameters. We also present a numerical method\nto solve the resulting nonlinear optimization problem.\n  Our algorithm is implemented in MATLAB and is verified by several benchmarks\nin MATPOWER $5.1$. Accurate results are obtained for power systems with up to\n$50$ independent random parameters, with a speedup factor up to $9\\times\n10^{20}$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 05:08:25 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Zhang", "Zheng", ""], ["Nguyen", "Hung Dinh", ""], ["Turitsyn", "Konstantin", ""], ["Daniel", "Luca", ""]]}, {"id": "1508.02506", "submitter": "Rui Martins", "authors": "R.C. Martins and N. Fachada", "title": "Finite Element Procedures for Enzyme, Chemical Reaction and 'In-Silico'\n  Genome Scale Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capacity to predict and control bioprocesses is perhaps one of the most\nimportant objectives of biotechnology. Computational simulation is an\nestablished methodology for the design and optimization of bioprocesses, where\nthe finite elements method (FEM) is at the state-of-art engineering\nmulti-physics simulation system, with tools such as Finite Element Analysis\n(FEA) and Computational Fluid Dynamics (CFD). Although FEA and CFD are\ncurrently applied to bioreactor design, most simulations are restricted to the\nmulti-physics capabilities of the existing sofware packages. This manuscript is\na contribution for the consolidation of FEM in computational biotechnology, by\npresenting a comprehensive review of finite element procedures of the most\ncommon enzymatic mechanisms found in biotechnological processes, such as,\nenzyme activation, Michaelis Menten, competitive inhibition, non-competitive\ninhibition, anti-competitive inhibition, competition by substrate, sequential\nrandom mechanism, ping-pong bi-bi and Theorel-Chance. Most importantly, the\nmanuscript opens the possibility for the use of FEM in conjunction with\n{\\guillemotleft}in-silico{\\guillemotright} models of metabolic networks, as\nwell as, chemical networks in order to simulate complex bioprocesses in\nbiotechnology, putting emphasis into flux balance analysis, pheno-metabolomics\nspace exploration in time and space, overcoming the limitations of assuming\nchemostat conditions in systems biology computations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 07:44:27 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Martins", "R. C.", ""], ["Fachada", "N.", ""]]}, {"id": "1508.02558", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Javier Prades and Carlos Reano and Federico Silla", "title": "Acceleration-as-a-Service: Exploiting Virtualised GPUs for a Financial\n  Application", "comments": "11th IEEE International Conference on eScience (IEEE eScience) -\n  Munich, Germany, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'How can GPU acceleration be obtained as a service in a cluster?' This\nquestion has become increasingly significant due to the inefficiency of\ninstalling GPUs on all nodes of a cluster. The research reported in this paper\nis motivated to address the above question by employing rCUDA (remote CUDA), a\nframework that facilitates Acceleration-as-a-Service (AaaS), such that the\nnodes of a cluster can request the acceleration of a set of remote GPUs on\ndemand. The rCUDA framework exploits virtualisation and ensures that multiple\nnodes can share the same GPU. In this paper we test the feasibility of the\nrCUDA framework on a real-world application employed in the financial risk\nindustry that can benefit from AaaS in the production setting. The results\nconfirm the feasibility of rCUDA and highlight that rCUDA achieves similar\nperformance compared to CUDA, provides consistent results, and more\nimportantly, allows for a single application to benefit from all the GPUs\navailable in the cluster without loosing efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 11:18:14 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Varghese", "Blesson", ""], ["Prades", "Javier", ""], ["Reano", "Carlos", ""], ["Silla", "Federico", ""]]}, {"id": "1508.02960", "submitter": "Ehsan Fattahi", "authors": "Ehsan Fattahia, Christian Waluga, Barbara Wohlmuth, Ulrich R\\\"ude,\n  Michael Manhart, Rainer Helmig", "title": "Pore-scale lattice Boltzmann simulation of laminar and turbulent flow\n  through a sphere pack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lattice Boltzmann method can be used to simulate flow through porous\nmedia with full geometrical resolution. With such a direct numerical\nsimulation, it becomes possible to study fundamental effects which are\ndifficult to assess either by developing macroscopic mathematical models or\nexperiments. We first evaluate the lattice Boltzmann method with various\nboundary handling of the solid-wall and various collision operators to assess\ntheir suitability for large scale direct numerical simulation of porous media\nflow. A periodic pressure drop boundary condition is used to mimic the pressure\ndriven flow through the simple sphere pack in a periodic domain. The evaluation\nof the method is done in the Darcy regime and the results are compared to a\nsemi-analytic solution. Taking into account computational cost and accuracy, we\nchoose the most efficient combination of the solid boundary condition and\ncollision operator. We apply this method to perform simulations for a wide\nrange of Reynolds numbers from Stokes flow over seven orders of magnitude to\nturbulent flow. Contours and streamlines of the flow field are presented to\nshow the flow behavior in different flow regimes. Moreover, unknown parameters\nof the Forchheimer, the Barree--Conway and friction factor models are evaluated\nnumerically for the considered flow regimes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 15:44:15 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Fattahia", "Ehsan", ""], ["Waluga", "Christian", ""], ["Wohlmuth", "Barbara", ""], ["R\u00fcde", "Ulrich", ""], ["Manhart", "Michael", ""], ["Helmig", "Rainer", ""]]}, {"id": "1508.03428", "submitter": "Dimitris Papamichail", "authors": "Dimitris Papamichail, Hongmei Liu, Vitor Machado, Nathan Gould, J.\n  Robert Coleman, Georgios Papamichail", "title": "Codon Context Optimization in Synthetic Gene Design", "comments": "9 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in de novo synthesis of DNA and computational gene design methods\nmake possible the customization of genes by direct manipulation of features\nsuch as codon bias and mRNA secondary structure. Codon context is another\nfeature significantly affecting mRNA translational efficiency, but existing\nmethods and tools for evaluating and designing novel optimized protein coding\nsequences utilize untested heuristics and do not provide quantifiable\nguarantees on design quality. In this study we examine statistical properties\nof codon context measures in an effort to better understand the phenomenon. We\nanalyze the computational complexity of codon context optimization and design\nexact and efficient heuristic gene recoding algorithms under reasonable\nconstraint models. We also present a web-based tool for evaluating codon\ncontext bias in the appropriate context.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 07:00:07 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Papamichail", "Dimitris", ""], ["Liu", "Hongmei", ""], ["Machado", "Vitor", ""], ["Gould", "Nathan", ""], ["Coleman", "J. Robert", ""], ["Papamichail", "Georgios", ""]]}, {"id": "1508.03604", "submitter": "Brian Drawert", "authors": "Brian Drawert and Michael Trogdon and Salman Toor and Linda Petzold\n  and Andreas Hellander", "title": "MOLNs: A cloud platform for interactive, reproducible and scalable\n  spatial stochastic computational experiments in systems biology using PyURDME", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational experiments using spatial stochastic simulations have led to\nimportant new biological insights, but they require specialized tools, a\ncomplex software stack, as well as large and scalable compute and data analysis\nresources due to the large computational cost associated with Monte Carlo\ncomputational workflows. The complexity of setting up and managing a\nlarge-scale distributed computation environment to support productive and\nreproducible modeling can be prohibitive for practitioners in systems biology.\nThis results in a barrier to the adoption of spatial stochastic simulation\ntools, effectively limiting the type of biological questions addressed by\nquantitative modeling. In this paper, we present PyURDME, a new, user-friendly\nspatial modeling and simulation package, and MOLNs, a cloud computing appliance\nfor distributed simulation of stochastic reaction-diffusion models. MOLNs is\nbased on IPython and provides an interactive programming platform for\ndevelopment of sharable and reproducible distributed parallel computational\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 18:49:36 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Drawert", "Brian", ""], ["Trogdon", "Michael", ""], ["Toor", "Salman", ""], ["Petzold", "Linda", ""], ["Hellander", "Andreas", ""]]}, {"id": "1508.03882", "submitter": "Chandrajit Bajaj", "authors": "Muhibur Rasheed, Nathan Clement, Abhishek Bhowmick, Chandrajit Bajaj", "title": "Quantifying and Visualizing Uncertainties in Molecular Models", "comments": "19 figures, 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational molecular modeling and visualization has seen significant\nprogress in recent years with sev- eral molecular modeling and visualization\nsoftware systems in use today. Nevertheless the molecular biology community\nlacks techniques and tools for the rigorous analysis, quantification and\nvisualization of the associated errors in molecular structure and its\nassociated properties. This paper attempts at filling this vacuum with the\nintroduction of a systematic statistical framework where each source of\nstructural uncertainty is modeled as a ran- dom variable (RV) with a known\ndistribution, and properties of the molecules are defined as dependent RVs. The\nframework consists of a theoretical basis, and an empirical implementation\nwhere the uncertainty quantification (UQ) analysis is achieved by using\nChernoff-like bounds. The framework enables additionally the propagation of\ninput structural data uncertainties, which in the molecular protein world are\ndescribed as B-factors, saved with almost all X-ray models deposited in the\nProtein Data Bank (PDB). Our statistical framework is also able and has been\napplied to quantify and visualize the uncertainties in molecular properties,\nnamely solvation interfaces and solvation free energy estimates. For each of\nthese quantities of interest (QOI) of the molecular models we provide several\nnovel and intuitive visualizations of the input, intermediate, and final\npropagated uncertainties. These methods should enable the end user achieve a\nmore quantitative and visual evaluation of various molecular PDB models for\nstructural and property correctness, or the lack thereof.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 00:18:08 GMT"}, {"version": "v2", "created": "Thu, 19 May 2016 01:36:26 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Rasheed", "Muhibur", ""], ["Clement", "Nathan", ""], ["Bhowmick", "Abhishek", ""], ["Bajaj", "Chandrajit", ""]]}, {"id": "1508.03993", "submitter": "Kristian Jensen", "authors": "Kristian E. Jensen", "title": "Simulating Viscous Fingering with a Timespace Method and Anisotropic\n  Mesh Adaptation", "comments": "Rejected by Journal of Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report findings related to a two dimensional viscous fingering problem\nsolved with a timespace method and anisotropic elements. Timespace methods have\nattracted interest for solution of time dependent partial differential\nequations due to the implications of parallelism in the temporal dimension, but\nthere are also attractive features in the context of anisotropic mesh\nadaptation; not only are heuristics and interpolation errors avoided, but\nslanted elements in timespace also correspond to long and accurate timesteps,\ni.e. the anisotropy in timespace can be exploited. We show that our timespace\nmethod is restricted by a minimum timestep size, which is due to the growth of\nnumerical perturbations. The lower bound on the timestep is, however, quite\nhigh, which is indicative that the number of timesteps can be reduced with\nseveral orders of magnitude for practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 12:19:45 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Jensen", "Kristian E.", ""]]}, {"id": "1508.04105", "submitter": "Emmanuel Osegi", "authors": "Nelson O. Ogbogu, Theophilus C. Madueme, and Emmanuel N. Osegi", "title": "PTILE: A framework for the Evaluation of Power Transformer Insulation\n  Life in Electric Power System", "comments": "5 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a framework is developed for power transformer (Generator Step\nup Unit) insulation life evaluation (PTILE) study on power system Network.\nParameters used for studies include real time sample data obtained from power\ntransformer field studies in the South-South Niger Delta region of Nigeria. It\nis used for performing simulations over varying number of years. Simulation\nreports shows a polynomial running time complexity and validates the stochastic\nHot Spot theory indicating that the transformers in such region should be\nreplaced sooner due to higher hot spots and transformer loading in such regions\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 18:37:58 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Ogbogu", "Nelson O.", ""], ["Madueme", "Theophilus C.", ""], ["Osegi", "Emmanuel N.", ""]]}, {"id": "1508.04245", "submitter": "Christoph Lehrenfeld", "authors": "Christoph Lehrenfeld and Joachim Sch\\\"oberl", "title": "High order exactly divergence-free Hybrid Discontinuous Galerkin Methods\n  for unsteady incompressible flows", "comments": "21 pages, 3 figures, 4 table", "journal-ref": null, "doi": "10.1016/j.cma.2016.04.025", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an efficient discretization method for the solution\nof the unsteady incompressible Navier-Stokes equations based on a high order\n(Hybrid) Discontinuous Galerkin formulation. The crucial component for the\nefficiency of the discretization method is the disctinction between stiff\nlinear parts and less stiff non-linear parts with respect to their temporal and\nspatial treatment. Exploiting the flexibility of operator-splitting time\nintegration schemes we combine two spatial discretizations which are tailored\nfor two simpler sub-problems: a corresponding hyperbolic transport problem and\nan unsteady Stokes problem. For the hyperbolic transport problem a spatial\ndiscretization with an Upwind Discontinuous Galerkin method and an explicit\ntreatment in the time integration scheme is rather natural and allows for an\nefficient implementation. The treatment of the Stokes part involves the\nsolution of linear systems. In this case a discretization with Hybrid\nDiscontinuous Galerkin methods is better suited. We consider such a\ndiscretization for the Stokes part with two important features:\nH(div)-conforming finite elements to garantuee exactly divergence-free velocity\nsolutions and a projection operator which reduces the number of globally\ncoupled unknowns. We present the method, discuss implementational aspects and\ndemonstrate the performance on two and three dimensional benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 08:43:34 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 10:12:35 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Lehrenfeld", "Christoph", ""], ["Sch\u00f6berl", "Joachim", ""]]}, {"id": "1508.04596", "submitter": "Joe Alexandersen", "authors": "Joe Alexandersen and Ole Sigmund and Niels Aage", "title": "Large scale three-dimensional topology optimisation of heat sinks cooled\n  by natural convection", "comments": "Submitted (18th of August 2015)", "journal-ref": "International Journal of Heat and Mass Transfer, Volume 100,\n  September 2016, Pages 876-891", "doi": "10.1016/j.ijheatmasstransfer.2016.05.013", "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the application of density-based topology optimisation to\nthe design of three-dimensional heat sinks cooled by natural convection. The\ngoverning equations are the steady-state incompressible Navier-Stokes equations\ncoupled to the thermal convection-diffusion equation through the Bousinessq\napproximation. The fully coupled non-linear multiphysics system is solved using\nstabilised trilinear equal-order finite elements in a parallel framework\nallowing for the optimisation of large scale problems with order of 40-330\nmillion state degrees of freedom. The flow is assumed to be laminar and several\noptimised designs are presented for Grashof numbers between $10^3$ and $10^6$.\nInterestingly, it is observed that the number of branches in the optimised\ndesign increases with increasing Grashof numbers, which is opposite to\ntwo-dimensional optimised designs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 11:03:06 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Alexandersen", "Joe", ""], ["Sigmund", "Ole", ""], ["Aage", "Niels", ""]]}, {"id": "1508.04731", "submitter": "Ali Pinar", "authors": "Maher Salloum, Janine C. Bennett, Ali Pinar, Ankit Bhagatwala,\n  Jacqueline H. Chen", "title": "Enabling adaptive scientific workflows via trigger detection", "comments": "arXiv admin note: substantial text overlap with arXiv:1506.08258", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation architectures necessitate a shift away from traditional\nworkflows in which the simulation state is saved at prescribed frequencies for\npost-processing analysis. While the need to shift to in~situ workflows has been\nacknowledged for some time, much of the current research is focused on static\nworkflows, where the analysis that would have been done as a post-process is\nperformed concurrently with the simulation at user-prescribed frequencies.\nRecently, research efforts are striving to enable adaptive workflows, in which\nthe frequency, composition, and execution of computational and data\nmanipulation steps dynamically depend on the state of the simulation. Adapting\nthe workflow to the state of simulation in such a data-driven fashion puts\nextremely strict efficiency requirements on the analysis capabilities that are\nused to identify the transitions in the workflow. In this paper we build upon\nearlier work on trigger detection using sublinear techniques to drive adaptive\nworkflows. Here we propose a methodology to detect the time when sudden heat\nrelease occurs in simulations of turbulent combustion. Our proposed method\nprovides an alternative metric that can be used along with our former metric to\nincrease the robustness of trigger detection. We show the effectiveness of our\nmetric empirically for predicting heat release for two use cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 18:29:21 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Salloum", "Maher", ""], ["Bennett", "Janine C.", ""], ["Pinar", "Ali", ""], ["Bhagatwala", "Ankit", ""], ["Chen", "Jacqueline H.", ""]]}, {"id": "1508.04783", "submitter": "Aida Ouangraoua", "authors": "Fran\\c{c}ois B\\'elanger and A\\\"ida Ouangraoua", "title": "Alignment of protein-coding sequences with frameshift extension\n  penalties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm for the alignment of protein- coding sequences\naccounting for frameshifts. The main specificity of this algorithm as compared\nto previously published protein-coding sequence alignment methods is the\nintroduction of a penalty cost for frameshift ex- tensions. Previous algorithms\nhave only used constant frameshift penal- ties. This is similar to the use of\nscoring schemes with affine gap penalties in classical sequence alignment\nalgorithms. However, the overall penalty of a frameshift portion in an\nalignment cannot be formulated as an affine function, because it should also\nincorporate varying codon substitution scores. The second specificity of the\nalgorithm is its search space being the set of all possible alignments between\ntwo coding sequences, under the classical definition of an alignment between\ntwo DNA sequences. Previous algorithms have introduced constraints on the\nlength of the alignments, and additional symbols for the representation of\nframeshift openings in an alignment. The algorithm has the same asymptotic\nspace and time complexity as the classical Needleman-Wunsch algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 20:26:38 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["B\u00e9langer", "Fran\u00e7ois", ""], ["Ouangraoua", "A\u00efda", ""]]}, {"id": "1508.05176", "submitter": "Ali Pinar", "authors": "Cosmin Safta, Richard L.-Y. Chen, Habib N. Najm, Ali Pinar, Jean-Paul\n  Watson", "title": "Efficient Representation of Uncertainty for Stochastic Economic Dispatch", "comments": "arXiv admin note: text overlap with arXiv:1407.2232", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic economic dispatch models address uncertainties in forecasts of\nrenewable generation output by considering a finite number of realizations\ndrawn from a stochastic process model, typically via Monte Carlo sampling.\nAccurate evaluations of expectations or higher-order moments for quantities of\ninterest, e.g., generating cost, can require a prohibitively large number of\nsamples. We propose an alternative to Monte Carlo sampling based on Polynomial\nChaos expansions. These representations are based on sparse quadrature methods,\nand enable accurate propagation of uncertainties in model parameters. We also\ninvestigate a method based on Karhunen-Loeve expansions that enables us to\nefficiently represent uncertainties in renewable energy generation. Considering\nexpected production cost, we demonstrate that the proposed approach can yield\nseveral orders of magnitude reduction in computational cost for solving\nstochastic economic dispatch relative to Monte Carlo sampling, for a given\ntarget error threshold.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 04:49:34 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Safta", "Cosmin", ""], ["Chen", "Richard L. -Y.", ""], ["Najm", "Habib N.", ""], ["Pinar", "Ali", ""], ["Watson", "Jean-Paul", ""]]}, {"id": "1508.05367", "submitter": "Sebasti\\'an Basterrech", "authors": "Andrea Mesa, Sebasti\\'an Basterrech, Gustavo Guerberoff, Fernando\n  Alvarez-Valin", "title": "Hidden Markov Models for Gene Sequence Classification: Classifying the\n  VSG genes in the Trypanosoma brucei Genome", "comments": "Accepted article in July, 2015 in Pattern Analysis and Applications,\n  Springer. The article contains 23 pages, 4 figures, 8 tables and 51\n  references", "journal-ref": null, "doi": "10.1007/s10044-015-0508-9", "report-no": null, "categories": "q-bio.GN cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents an application of Hidden Markov Models (HMMs) for\npattern recognition on genome sequences. We apply HMM for identifying genes\nencoding the Variant Surface Glycoprotein (VSG) in the genomes of Trypanosoma\nbrucei (T. brucei) and other African trypanosomes. These are parasitic protozoa\ncausative agents of sleeping sickness and several diseases in domestic and wild\nanimals. These parasites have a peculiar strategy to evade the host's immune\nsystem that consists in periodically changing their predominant cellular\nsurface protein (VSG). The motivation for using patterns recognition methods to\nidentify these genes, instead of traditional homology based ones, is that the\nlevels of sequence identity (amino acid and DNA sequence) amongst these genes\nis often below of what is considered reliable in these methods. Among pattern\nrecognition approaches, HMM are particularly suitable to tackle this problem\nbecause they can handle more naturally the determination of gene edges. We\nevaluate the performance of the model using different number of states in the\nMarkov model, as well as several performance metrics. The model is applied\nusing public genomic data. Our empirical results show that the VSG genes on T.\nbrucei can be safely identified (high sensitivity and low rate of false\npositives) using HMM.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 14:57:09 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2015 19:39:43 GMT"}], "update_date": "2015-10-22", "authors_parsed": [["Mesa", "Andrea", ""], ["Basterrech", "Sebasti\u00e1n", ""], ["Guerberoff", "Gustavo", ""], ["Alvarez-Valin", "Fernando", ""]]}, {"id": "1508.06561", "submitter": "Akash Nag", "authors": "Akash Nag, Sunil Karforma", "title": "A Space-Efficient Approach towards Distantly Homologous Protein\n  Similarity Searches", "comments": null, "journal-ref": "International Journal of Advanced Research in Computer Science\n  (IJARCS). Vol.6(2). pp:19-22. 2015", "doi": null, "report-no": null, "categories": "cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein similarity searches are a routine job for molecular biologists where\na query sequence of amino acids needs to be compared and ranked against an\never-growing database of proteins. All available algorithms in this field can\nbe grouped into two categories, either solving the problem using sequence\nalignment through dynamic programming, or, employing certain heuristic measures\nto perform an initial screening followed by applying an optimal sequence\nalignment algorithm to the closest matching candidates. While the first\napproach suffers from huge time and space demands, the latter approach might\nmiss some protein sequences which are distantly related to the query sequence.\nIn this paper, we propose a heuristic pair-wise sequence alignment algorithm\nthat can be efficiently employed for protein database searches for moderately\nsized databases. The proposed algorithm is sufficiently fast to be applicable\nto database searches for short query sequences, has constant auxiliary space\nrequirements, produces good alignments, and is sensitive enough to return even\ndistantly related protein chains that might be of interest.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 16:58:35 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Nag", "Akash", ""], ["Karforma", "Sunil", ""]]}, {"id": "1508.06889", "submitter": "Attila Bern\\'ath", "authors": "Erika R. B\\'erczi-Kov\\'acs, Attila Bern\\'ath", "title": "The complexity of the Clar number problem and an FPT algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Clar number of a (hydro)carbon molecule, introduced by Clar [E. Clar,\n\\emph{The aromatic sextet}, (1972).], is the maximum number of mutually\ndisjoint resonant hexagons in the molecule. Calculating the Clar number can be\nformulated as an optimization problem on 2-connected planar graphs. Namely, it\nis the maximum number of mutually disjoint even faces a perfect matching can\nsimultaneously alternate on. It was proved by Abeledo and Atkinson [H. G.\nAbeledo and G. W. Atkinson, \\emph{Unimodularity of the clar number problem},\nLinear algebra and its applications \\textbf{420} (2007), no. 2, 441--448] that\nthe Clar number can be computed in polynomial time if the plane graph has even\nfaces only. We prove that calculating the Clar number in general 2-connected\nplane graphs is NP-hard. We also prove NP-hardness of the maximum independent\nset problem for 2-connected plane graphs with odd faces only, which may be of\nindependent interest. Finally, we give an FPT algorithm that determines the\nClar number of a given 2-connected plane graph. The parameter of the algorithm\nis the length of the shortest odd join in the planar dual graph. For fullerenes\nthis is not yet a polynomial algorithm, but for certain carbon nanotubes it\ngives an efficient algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 15:00:19 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["B\u00e9rczi-Kov\u00e1cs", "Erika R.", ""], ["Bern\u00e1th", "Attila", ""]]}, {"id": "1508.07416", "submitter": "Guoxu Zhou", "authors": "Guoxu Zhou, Qibin Zhao, Yu Zhang, T\\\"ulay Adal{\\i}, Shengli Xie,\n  Andrzej Cichocki", "title": "Linked Component Analysis from Matrices to High Order Tensors:\n  Applications to Biomedical Data", "comments": "20 pages, 11 figures, Proceedings of the IEEE, 2015", "journal-ref": null, "doi": "10.1109/JPROC.2015.2474704", "report-no": null, "categories": "cs.CE cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing availability of various sensor technologies, we now have\naccess to large amounts of multi-block (also called multi-set,\nmulti-relational, or multi-view) data that need to be jointly analyzed to\nexplore their latent connections. Various component analysis methods have\nplayed an increasingly important role for the analysis of such coupled data. In\nthis paper, we first provide a brief review of existing matrix-based (two-way)\ncomponent analysis methods for the joint analysis of such data with a focus on\nbiomedical applications. Then, we discuss their important extensions and\ngeneralization to multi-block multiway (tensor) data. We show how constrained\nmulti-block tensor decomposition methods are able to extract similar or\nstatistically dependent common features that are shared by all blocks, by\nincorporating the multiway nature of data. Special emphasis is given to the\nflexible common and individual feature analysis of multi-block data with the\naim to simultaneously extract common and individual latent components with\ndesired properties and types of diversity. Illustrative examples are given to\ndemonstrate their effectiveness for biomedical data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2015 08:18:14 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Zhou", "Guoxu", ""], ["Zhao", "Qibin", ""], ["Zhang", "Yu", ""], ["Adal\u0131", "T\u00fclay", ""], ["Xie", "Shengli", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1508.07435", "submitter": "Stanislav Sysala", "authors": "Stanislav Sysala and Martin Cermak", "title": "Subdifferential-based implicit return-mapping operators in Mohr-Coulomb\n  plasticity", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": "10.1002/zamm.201600215", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to a constitutive solution, limit load analysis and\nNewton-like methods in elastoplastic problems containing the Mohr-Coulomb yield\ncriterion. Within the constitutive problem, we introduce a self-contained\nderivation of the implicit return-mapping solution scheme using a recent\nsubdifferential-based treatment. Unlike conventional techniques based on\nKoiter's rules, the presented scheme a priori detects a position of the unknown\nstress tensor on the yield surface even if the constitutive solution cannot be\nfound in closed form. This fact eliminates blind guesswork from the scheme,\nenables to analyze properties of the constitutive operator, and simplifies\nconstruction of the consistent tangent operator which is important for the\nsemismooth Newton method applied on the incremental boundary value\nelastoplastic problem. The incremental problem in Mohr-Coulomb plasticity is\ncombined with the limit load analysis. Beside a conventional direct method of\nthe incremental limit analysis, a recent indirect one is introduced and its\nadvantages are described. The paper contains 2D and 3D numerical experiments on\nslope stability with publicly available Matlab implementations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2015 11:11:40 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 07:45:56 GMT"}, {"version": "v3", "created": "Tue, 27 Sep 2016 06:18:36 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Sysala", "Stanislav", ""], ["Cermak", "Martin", ""]]}, {"id": "1508.07527", "submitter": "Aziz Mezlini", "authors": "Aziz M. Mezlini, Fabio Fuligni, Adam Shlien and Anna Goldenberg", "title": "Combining exome and gene expression datasets in one graphical model of\n  disease to empower the discovery of disease mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying genes associated with complex human diseases is one of the main\nchallenges of human genetics and computational medicine. To answer this\nquestion, millions of genetic variants get screened to identify a few of\nimportance. To increase the power of identifying genes associated with diseases\nand to account for other potential sources of protein function aberrations, we\npropose a novel factor-graph based model, where much of the biological\nknowledge is incorporated through factors and priors. Our extensive simulations\nshow that our method has superior sensitivity and precision compared to\nvariant-aggregating and differential expression methods. Our integrative\napproach was able to identify important genes in breast cancer, identifying\ngenes that had coding aberrations in some patients and regulatory abnormalities\nin others, emphasizing the importance of data integration to explain the\ndisease in a larger number of patients.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2015 03:08:39 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Mezlini", "Aziz M.", ""], ["Fuligni", "Fabio", ""], ["Shlien", "Adam", ""], ["Goldenberg", "Anna", ""]]}, {"id": "1508.07982", "submitter": "Florian Schornbaum", "authors": "Florian Schornbaum and Ulrich R\\\"ude", "title": "Massively Parallel Algorithms for the Lattice Boltzmann Method on\n  Non-uniform Grids", "comments": "32 pages, 20 figures, 4 tables", "journal-ref": "SIAM J. Sci. Comput. 38-2 (2016), pp. C96-C126", "doi": "10.1137/15M1035240", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lattice Boltzmann method exhibits excellent scalability on current\nsupercomputing systems and has thus increasingly become an alternative method\nfor large-scale non-stationary flow simulations, reaching up to a trillion grid\nnodes. Additionally, grid refinement can lead to substantial savings in memory\nand compute time. These saving, however, come at the cost of much more complex\ndata structures and algorithms. In particular, the interface between subdomains\nwith different grid sizes must receive special treatment. In this article, we\npresent parallel algorithms, distributed data structures, and communication\nroutines that are implemented in the software framework waLBerla in order to\nsupport large-scale, massively parallel lattice Boltzmann-based simulations on\nnon-uniform grids. Additionally, we evaluate the performance of our approach on\ntwo current petascale supercomputers. On an IBM Blue Gene/Q system, the largest\nweak scaling benchmarks with refined grids are executed with almost two million\nthreads, demonstrating not only near-perfect scalability but also an absolute\nperformance of close to a trillion lattice Boltzmann cell updates per second.\nOn an Intel-based system, the strong scaling of a simulation with refined grids\nand a total of more than 8.5 million cells is demonstrated to reach a\nperformance of less than one millisecond per time step. This enables\nsimulations with complex, non-uniform grids and four million time steps per\nhour compute time.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 19:57:37 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2016 19:51:58 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Schornbaum", "Florian", ""], ["R\u00fcde", "Ulrich", ""]]}]