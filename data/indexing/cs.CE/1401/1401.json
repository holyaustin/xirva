[{"id": "1401.0742", "submitter": "Ishanu Chattopadhyay", "authors": "Ishanu Chattopadhyay and Hod Lipson", "title": "Data Smashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigation of the underlying physics or biology from empirical data\nrequires a quantifiable notion of similarity - when do two observed data sets\nindicate nearly identical generating processes, and when they do not. The\ndiscriminating characteristics to look for in data is often determined by\nheuristics designed by experts, $e.g.$, distinct shapes of \"folded\" lightcurves\nmay be used as \"features\" to classify variable stars, while determination of\npathological brain states might require a Fourier analysis of brainwave\nactivity. Finding good features is non-trivial. Here, we propose a universal\nsolution to this problem: we delineate a principle for quantifying similarity\nbetween sources of arbitrary data streams, without a priori knowledge, features\nor training. We uncover an algebraic structure on a space of symbolic models\nfor quantized data, and show that such stochastic generators may be added and\nuniquely inverted; and that a model and its inverse always sum to the generator\nof flat white noise. Therefore, every data stream has an anti-stream: data\ngenerated by the inverse model. Similarity between two streams, then, is the\ndegree to which one, when summed to the other's anti-stream, mutually\nannihilates all statistical structure to noise. We call this data smashing. We\npresent diverse applications, including disambiguation of brainwaves pertaining\nto epileptic seizures, detection of anomalous cardiac rhythms, and\nclassification of astronomical objects from raw photometry. In our examples,\nthe data smashing principle, without access to any domain knowledge, meets or\nexceeds the performance of specialized algorithms tuned by domain experts.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 22:15:17 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Chattopadhyay", "Ishanu", ""], ["Lipson", "Hod", ""]]}, {"id": "1401.0799", "submitter": "Tobias Kretz", "authors": "Tobias Kretz, Karsten Lehmann, Ingmar Hofs\\\"a{\\ss}", "title": "User Equilibrium Route Assignment for Microscopic Pedestrian Simulation", "comments": null, "journal-ref": "Advances in Complex Systems 17(2) pp. 1450010 (2014)", "doi": "10.1142/S0219525914500106", "report-no": null, "categories": "physics.soc-ph cs.CE cs.MA cs.RO physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the simulation of pedestrians a method is introduced to find routing\nalternatives from any origin position to a given destination area in a given\ngeometry composed of walking areas and obstacles. The method includes a\nparameter which sets a threshold for the approximate minimum size of obstacles\nto generate routing alternatives. The resulting data structure for navigation\nis constructed such that it does not introduce artifacts to the movement of\nsimulated pedestrians and that locally pedestrians prefer to walk on the\nshortest path. The generated set of routes can be used with iterating static or\ndynamic assignment methods.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 11:25:29 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Kretz", "Tobias", ""], ["Lehmann", "Karsten", ""], ["Hofs\u00e4\u00df", "Ingmar", ""]]}, {"id": "1401.0870", "submitter": "Laurence Aroquiaraj", "authors": "I. Laurence Aroquiaraj and K. Thangavel", "title": "Pectoral Muscles Suppression in Digital Mammograms using Hybridization\n  of Soft Computing Methods", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast region segmentation is an essential prerequisite in computerized\nanalysis of mammograms. It aims at separating the breast tissue from the\nbackground of the mammogram and it includes two independent segmentations. The\nfirst segments the background region which usually contains annotations, labels\nand frames from the whole breast region, while the second removes the pectoral\nmuscle portion (present in Medio Lateral Oblique (MLO) views) from the rest of\nthe breast tissue. In this paper we propose hybridization of Connected\nComponent Labeling (CCL), Fuzzy, and Straight line methods. Our proposed\nmethods worked good for separating pectoral region. After removal pectoral\nmuscle from the mammogram, further processing is confined to the breast region\nalone. To demonstrate the validity of our segmentation algorithm, it is\nextensively tested using over 322 mammographic images from the Mammographic\nImage Analysis Society (MIAS) database. The segmentation results were evaluated\nusing a Mean Absolute Error (MAE), Hausdroff Distance (HD), Probabilistic Rand\nIndex (PRI), Local Consistency Error (LCE) and Tanimoto Coefficient (TC). The\nhybridization of fuzzy with straight line method is given more than 96% of the\ncurve segmentations to be adequate or better. In addition a comparison with\nsimilar approaches from the state of the art has been given, obtaining slightly\nimproved results. Experimental results demonstrate the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 08:14:43 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Aroquiaraj", "I. Laurence", ""], ["Thangavel", "K.", ""]]}, {"id": "1401.1152", "submitter": "Radek Stefan", "authors": "Michal Bene\\v{s}, Radek \\v{S}tefan", "title": "Hygro-thermo-mechanical analysis of spalling in concrete walls at high\n  temperatures as a moving boundary problem", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijheatmasstransfer.2015.01.050", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mathematical model allowing coupled hygro-thermo-mechanical analysis of\nspalling in concrete walls at high temperatures by means of the moving boundary\nproblem is presented. A simplified mechanical approach to account for effects\nof thermal stresses and pore pressure build-up on spalling is incorporated into\nthe model. The numerical algorithm based on finite element discretization in\nspace and the semi-implicit method for discretization in time is presented. The\nvalidity of the developed model is carefully examined by a comparison between\nexperimental tests performed by Kalifa et al. (2000) and Mindeguia (2009) on\nconcrete prismatic specimens under unidirectional heating of temperature of 600\n${\\deg}$C and ISO 834 fire curve and the results obtained from the numerical\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 17:42:41 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2014 08:46:25 GMT"}, {"version": "v3", "created": "Fri, 9 Jan 2015 14:24:19 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Bene\u0161", "Michal", ""], ["\u0160tefan", "Radek", ""]]}, {"id": "1401.1308", "submitter": "Tobias Kretz", "authors": "Tobias Kretz, Karsten Lehmann, Ingmar Hofs\\\"a{\\ss}, Axel Leonhardt", "title": "Dynamic Assignment in Microsimulations of Pedestrians", "comments": "Contribution to 93rd Annual Meeting of the Transportation Research\n  Board (TRB) 2014. Contribution no. 14-0941", "journal-ref": "in Annual Meeting of the Transportation Research Board, 14-0941\n  (2014)", "doi": null, "report-no": null, "categories": "cs.CE cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generic method for dynamic assignment used with microsimulation of\npedestrian dynamics is introduced. As pedestrians - unlike vehicles - do not\nmove on a network, but on areas they in principle can choose among an infinite\nnumber of routes. To apply assignment algorithms one has to select for each OD\npair a finite (realistically a small) number of relevant representatives from\nthese routes. This geometric task is the main focus of this contribution. The\nmain task is to find for an OD pair the relevant routes to be used with common\nassignment methods. The method is demonstrated for one single OD pair and\nexemplified with an example.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 08:32:54 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Kretz", "Tobias", ""], ["Lehmann", "Karsten", ""], ["Hofs\u00e4\u00df", "Ingmar", ""], ["Leonhardt", "Axel", ""]]}, {"id": "1401.1686", "submitter": "Tobias Kretz", "authors": "Tobias Kretz, Karsten Lehmann, Ingmar Hofs\\\"a{\\ss}", "title": "Pedestrian Route Choice by Iterated Equilibrium Search", "comments": "contribution to proceedings of Traffic and Granular Flow 2013 (TGF13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vehicular traffic planning it is a long standing problem how to assign\ndemand such on the available model of a road network that an equilibrium with\nregard to travel time or generalized costs is realized. For pedestrian traffic\nthis question can be asked as well. However, as the infrastructure of\npedestrian dynamics is not a network (a graph), but two-dimensional, there is\nin principle an infinitely large set of routes. As a consequence none of the\niterating assignment methods developed for road traffic can be applied for\npedestrians. In this contribution a method to overcome this problem is briefly\nsummarized and applied with an example geometry which as a result is enhanced\nwith routes with intermediate destination areas of certain shape. The enhanced\ngeometry is used in some exemplary assignment calculations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 13:01:55 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Kretz", "Tobias", ""], ["Lehmann", "Karsten", ""], ["Hofs\u00e4\u00df", "Ingmar", ""]]}, {"id": "1401.1757", "submitter": "Mark Bull", "authors": "Mark Tucker and J. Mark Bull", "title": "An efficient algorithm for the calculation of reserves for non-unit\n  linked life policies", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underlying stochastic nature of the requirements for the Solvency II\nregulations has introduced significant challenges if the required calculations\nare to be performed correctly, without resorting to excessive approximations,\nwithin practical timescales. It is generally acknowledged by practising\nactuaries within UK life offices that it is currently impossible to correctly\nfulfil the requirements imposed by Solvency II using existing computational\ntechniques based on commercially available valuation packages. Our work has\nalready shown that it is possible to perform profitability calculations at a\nfar higher rate than is achievable using commercial packages. One of the key\nfactors in achieving these gains is to calculate reserves using recurrence\nrelations that scale linearly with the number of time steps. Here, we present a\ngeneral vector recurrence relation which can be used for a wide range of\nnon-unit linked policies that are covered by Solvency II; such contracts\ninclude annuities, term assurances, and endowments. Our results suggest that by\nusing an optimised parallel implementation of this algorithm, on an affordable\nhardware platform, it is possible to perform the `brute force' approach to\ndemonstrating solvency in a realistic timescale (of the order of a few hours).\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 17:16:29 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 15:23:30 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["Tucker", "Mark", ""], ["Bull", "J. Mark", ""]]}, {"id": "1401.1888", "submitter": "Li-Xin Wang", "authors": "Li-Xin Wang", "title": "Dynamical Models of Stock Prices Based on Technical Trading Rules Part\n  I: The Models", "comments": null, "journal-ref": "IEEE Trans. on Fuzzy Systems, Vol. 23, No. 4, pp. 787-801, 2015", "doi": "10.1109/TFUZZ.2014.2327994", "report-no": null, "categories": "q-fin.TR cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use fuzzy systems theory to convert the technical trading\nrules commonly used by stock practitioners into excess demand functions which\nare then used to drive the price dynamics. The technical trading rules are\nrecorded in natural languages where fuzzy words and vague expressions abound.\nIn Part I of this paper, we will show the details of how to transform the\ntechnical trading heuristics into nonlinear dynamic equations. First, we define\nfuzzy sets to represent the fuzzy terms in the technical trading rules; second,\nwe translate each technical trading heuristic into a group of fuzzy IF-THEN\nrules; third, we combine the fuzzy IF-THEN rules in a group into a fuzzy\nsystem; and finally, the linear combination of these fuzzy systems is used as\nthe excess demand function in the price dynamic equation. We transform a wide\nvariety of technical trading rules into fuzzy systems, including moving average\nrules, support and resistance rules, trend line rules, big buyer, big seller\nand manipulator rules, band and stop rules, and volume and relative strength\nrules. Simulation results show that the price dynamics driven by these\ntechnical trading rules are complex and chaotic, and some common phenomena in\nreal stock prices such as jumps, trending and self-fulfilling appear naturally.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 04:41:39 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2016 07:40:30 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Wang", "Li-Xin", ""]]}, {"id": "1401.1891", "submitter": "Li-Xin Wang", "authors": "Li-Xin Wang", "title": "Dynamical Models of Stock Prices Based on Technical Trading Rules Part\n  II: Analysis of the Models", "comments": null, "journal-ref": "IEEE Trans. on Fuzzy Systems, Vol. 23, No. 4, pp. 1127-1141, 2015", "doi": "10.1109/TFUZZ.2014.2346244", "report-no": null, "categories": "q-fin.TR cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Part II of this paper, we concentrate our analysis on the price dynamical\nmodel with the moving average rules developed in Part I of this paper. By\ndecomposing the excessive demand function, we reveal that it is the interplay\nbetween trend-following and contrarian actions that generates the price chaos,\nand give parameter ranges for the price series to change from divergence to\nchaos and to oscillation. We prove that the price dynamical model has an\ninfinite number of equilibrium points but all these equilibrium points are\nunstable. We demonstrate the short-term predictability of the return volatility\nand derive the detailed formula of the Lyapunov exponent as function of the\nmodel parameters. We show that although the price is chaotic, the volatility\nconverges to some constant very quickly at the rate of the Lyapunov exponent.\nWe extract the formula relating the converged volatility to the model\nparameters based on Monte-Carlo simulations. We explore the circumstances under\nwhich the returns show independency and illustrate in details how the\nindependency index changes with the model parameters. Finally, we plot the\nstrange attractor and return distribution of the chaotic price model to\nillustrate the complex structure and fat-tailed distribution of the returns.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 04:49:30 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2016 07:43:06 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Wang", "Li-Xin", ""]]}, {"id": "1401.1892", "submitter": "Li-Xin Wang", "authors": "Li-Xin Wang", "title": "Dynamical Models of Stock Prices Based on Technical Trading Rules Part\n  III: Application to Hong Kong Stocks", "comments": null, "journal-ref": "IEEE Trans. on Fuzzy Systems, Vol. 23, No. 5, pp. 1680-1697, 2015", "doi": "10.1109/TFUZZ.2014.2374193", "report-no": null, "categories": "q-fin.TR cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Part III of this study, we apply the price dynamical model with big buyers\nand big sellers developed in Part I of this paper to the daily closing prices\nof the top 20 banking and real estate stocks listed in the Hong Kong Stock\nExchange. The basic idea is to estimate the strength parameters of the big\nbuyers and the big sellers in the model and make buy/sell decisions based on\nthese parameter estimates. We propose two trading strategies: (i)\nFollow-the-Big-Buyer which buys when big buyer begins to appear and there is no\nsign of big sellers, holds the stock as long as the big buyer is still there,\nand sells the stock once the big buyer disappears; and (ii) Ride-the-Mood which\nbuys as soon as the big buyer strength begins to surpass the big seller\nstrength, and sells the stock once the opposite happens. Based on the testing\nover 245 two-year intervals uniformly distributed across the seven years from\n03-July-2007 to 02-July-2014 which includes a variety of scenarios, the net\nprofits would increase 67% or 120% on average if an investor switched from the\nbenchmark Buy-and-Hold strategy to the Follow-the-Big-Buyer or Ride-the-Mood\nstrategies during this period, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 04:57:06 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2016 07:46:41 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Wang", "Li-Xin", ""]]}, {"id": "1401.1916", "submitter": "Tao Xiong", "authors": "Tao Xiong, Yukun Bao, Zhongyi Hu", "title": "Multiple-output support vector regression with a firefly algorithm for\n  interval-valued stock price index forecasting", "comments": "33 pages", "journal-ref": "Knowledge-based Systems. 55, 2013:87-100", "doi": "10.1016/j.knosys.2013.10.012", "report-no": null, "categories": "cs.CE cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly accurate interval forecasting of a stock price index is fundamental to\nsuccessfully making a profit when making investment decisions, by providing a\nrange of values rather than a point estimate. In this study, we investigate the\npossibility of forecasting an interval-valued stock price index series over\nshort and long horizons using multi-output support vector regression (MSVR).\nFurthermore, this study proposes a firefly algorithm (FA)-based approach, built\non the established MSVR, for determining the parameters of MSVR (abbreviated as\nFA-MSVR). Three globally traded broad market indices are used to compare the\nperformance of the proposed FA-MSVR method with selected counterparts. The\nquantitative and comprehensive assessments are performed on the basis of\nstatistical criteria, economic criteria, and computational cost. In terms of\nstatistical criteria, we compare the out-of-sample forecasting using\ngoodness-of-forecast measures and testing approaches. In terms of economic\ncriteria, we assess the relative forecast performance with a simple trading\nstrategy. The results obtained in this study indicate that the proposed FA-MSVR\nmethod is a promising alternative for forecasting interval-valued financial\ntime series.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 07:58:06 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Xiong", "Tao", ""], ["Bao", "Yukun", ""], ["Hu", "Zhongyi", ""]]}, {"id": "1401.2000", "submitter": "Andreas Hehn", "authors": "M. Dolfi, J. Gukelberger, A. Hehn, J. Imri\\v{s}ka, K. Pakrouski, T. F.\n  R{\\o}nnow, M. Troyer, I. Zintchenko, F. Chirigati, J. Freire, D. Shasha", "title": "A model project for reproducible papers: critical temperature for the\n  Ising model on a square lattice", "comments": "Authors are listed in alphabetical order by institution and name. 5\n  pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cond-mat.stat-mech physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a simple, yet typical simulation in statistical\nphysics, consisting of large scale Monte Carlo simulations followed by an\ninvolved statistical analysis of the results. The purpose is to provide an\nexample publication to explore tools for writing reproducible papers. The\nsimulation estimates the critical temperature where the Ising model on the\nsquare lattice becomes magnetic to be Tc /J = 2.26934(6) using a finite size\nscaling analysis of the crossing points of Binder cumulants. We provide a\nvirtual machine which can be used to reproduce all figures and results.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 13:44:28 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Dolfi", "M.", ""], ["Gukelberger", "J.", ""], ["Hehn", "A.", ""], ["Imri\u0161ka", "J.", ""], ["Pakrouski", "K.", ""], ["R\u00f8nnow", "T. F.", ""], ["Troyer", "M.", ""], ["Zintchenko", "I.", ""], ["Chirigati", "F.", ""], ["Freire", "J.", ""], ["Shasha", "D.", ""]]}, {"id": "1401.2571", "submitter": "Mahmood A. Rashid", "authors": "Mahmood A. Rashid, Md Tamjidul Hoque and Abdul Sattar", "title": "Association Rules Mining Based Clinical Observations", "comments": "5 pages, MEDINFO 2010, C. Safran et al. (Eds.), IOS Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Healthcare institutes enrich the repository of patients' disease related\ninformation in an increasing manner which could have been more useful by\ncarrying out relational analysis. Data mining algorithms are proven to be quite\nuseful in exploring useful correlations from larger data repositories. In this\npaper we have implemented Association Rules mining based a novel idea for\nfinding co-occurrences of diseases carried by a patient using the healthcare\nrepository. We have developed a system-prototype for Clinical State Correlation\nPrediction (CSCP) which extracts data from patients' healthcare database,\ntransforms the OLTP data into a Data Warehouse by generating association rules.\nThe CSCP system helps reveal relations among the diseases. The CSCP system\npredicts the correlation(s) among primary disease (the disease for which the\npatient visits the doctor) and secondary disease/s (which is/are other\nassociated disease/s carried by the same patient having the primary disease).\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 21:56:45 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Rashid", "Mahmood A.", ""], ["Hoque", "Md Tamjidul", ""], ["Sattar", "Abdul", ""]]}, {"id": "1401.2668", "submitter": "Jinbo Xu", "authors": "Jianzhu Ma, Sheng Wang, Zhiyong Wang and Jinbo Xu", "title": "MRFalign: Protein Homology Detection through Alignment of Markov Random\n  Fields", "comments": "Accepted by both RECOMB 2014 and PLOS Computational Biology", "journal-ref": null, "doi": "10.1371/journal.pcbi.1003500", "report-no": null, "categories": "q-bio.QM cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-based protein homology detection has been extensively studied and so\nfar the most sensitive method is based upon comparison of protein sequence\nprofiles, which are derived from multiple sequence alignment (MSA) of sequence\nhomologs in a protein family. A sequence profile is usually represented as a\nposition-specific scoring matrix (PSSM) or an HMM (Hidden Markov Model) and\naccordingly PSSM-PSSM or HMM-HMM comparison is used for homolog detection. This\npaper presents a new homology detection method MRFalign, consisting of three\nkey components: 1) a Markov Random Fields (MRF) representation of a protein\nfamily; 2) a scoring function measuring similarity of two MRFs; and 3) an\nefficient ADMM (Alternating Direction Method of Multipliers) algorithm aligning\ntwo MRFs. Compared to HMM that can only model very short-range residue\ncorrelation, MRFs can model long-range residue interaction pattern and thus,\nencode information for the global 3D structure of a protein family.\nConsequently, MRF-MRF comparison for remote homology detection shall be much\nmore sensitive than HMM-HMM or PSSM-PSSM comparison. Experiments confirm that\nMRFalign outperforms several popular HMM or PSSM-based methods in terms of both\nalignment accuracy and remote homology detection and that MRFalign works\nparticularly well for mainly beta proteins. For example, tested on the\nbenchmark SCOP40 (8353 proteins) for homology detection, PSSM-PSSM and HMM-HMM\nsucceed on 48% and 52% of proteins, respectively, at superfamily level, and on\n15% and 27% of proteins, respectively, at fold level. In contrast, MRFalign\nsucceeds on 57.3% and 42.5% of proteins at superfamily and fold level,\nrespectively. This study implies that long-range residue interaction patterns\nare very helpful for sequence-based homology detection. The software is\navailable for download at http://raptorx.uchicago.edu/download/.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2014 20:41:08 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2014 01:55:17 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Ma", "Jianzhu", ""], ["Wang", "Sheng", ""], ["Wang", "Zhiyong", ""], ["Xu", "Jinbo", ""]]}, {"id": "1401.2688", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "Pokkuluri Kiran Sree, Inamupudi Ramesh Babu, SSSN Usha Devi N", "title": "PSMACA: An Automated Protein Structure Prediction Using MACA (Multiple\n  Attractor Cellular Automata)", "comments": "6 pages. arXiv admin note: substantial text overlap with\n  arXiv:1310.4342, arXiv:1310.4495", "journal-ref": "Journal of Bioinformatics and Intelligent Control Vol 2, pp\n  211--215, 2013", "doi": "10.1166/jbic.2013.1052", "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein Structure Predication from sequences of amino acid has gained a\nremarkable attention in recent years. Even though there are some prediction\ntechniques addressing this problem, the approximate accuracy in predicting the\nprotein structure is closely 75%. An automated procedure was evolved with MACA\n(Multiple Attractor Cellular Automata) for predicting the structure of the\nprotein. Most of the existing approaches are sequential which will classify the\ninput into four major classes and these are designed for similar sequences.\nPSMACA is designed to identify ten classes from the sequences that share\ntwilight zone similarity and identity with the training sequences. This method\nalso predicts three states (helix, strand, and coil) for the structure. Our\ncomprehensive design considers 10 feature selection methods and 4 classifiers\nto develop MACA (Multiple Attractor Cellular Automata) based classifiers that\nare build for each of the ten classes. We have tested the proposed classifier\nwith twilight-zone and 1-high-similarity benchmark datasets with over three\ndozens of modern competing predictors shows that PSMACA provides the best\noverall accuracy that ranges between 77% and 88.7% depending on the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 00:38:52 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Sree", "Pokkuluri Kiran", ""], ["Babu", "Inamupudi Ramesh", ""], ["N", "SSSN Usha Devi", ""]]}, {"id": "1401.3446", "submitter": "Shiplu Hawlader", "authors": "Md. Shiplu Hawlader and Saifuddin Md. Tareeq", "title": "Amino Acid Interaction Network Prediction using Multi-objective\n  Optimization", "comments": null, "journal-ref": null, "doi": "10.5121/csit.2014.4113", "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein can be represented by amino acid interaction network. This network is\na graph whose vertices are the proteins amino acids and whose edges are the\ninteractions between them. This interaction network is the first step of\nproteins three-dimensional structure prediction. In this paper we present a\nmulti-objective evolutionary algorithm for interaction prediction and ant\ncolony probabilistic optimization algorithm is used to confirm the interaction.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 04:59:08 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Hawlader", "Md. Shiplu", ""], ["Tareeq", "Saifuddin Md.", ""]]}, {"id": "1401.4589", "submitter": "Rania Ibrahim", "authors": "Rania Ibrahim, Noha A. Yousri, Mohamed A. Ismail, Nagwa M. El-Makky", "title": "miRNA and Gene Expression based Cancer Classification using Self-\n  Learning and Co-Training Approaches", "comments": "8 pages, 4 figures, 10 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  miRNA and gene expression profiles have been proved useful for classifying\ncancer samples. Efficient classifiers have been recently sought and developed.\nA number of attempts to classify cancer samples using miRNA/gene expression\nprofiles are known in literature. However, the use of semi-supervised learning\nmodels have been used recently in bioinformatics, to exploit the huge corpuses\nof publicly available sets. Using both labeled and unlabeled sets to train\nsample classifiers, have not been previously considered when gene and miRNA\nexpression sets are used. Moreover, there is a motivation to integrate both\nmiRNA and gene expression for a semi-supervised cancer classification as that\nprovides more information on the characteristics of cancer samples. In this\npaper, two semi-supervised machine learning approaches, namely self-learning\nand co-training, are adapted to enhance the quality of cancer sample\nclassification. These approaches exploit the huge public corpuses to enrich the\ntraining data. In self-learning, miRNA and gene based classifiers are enhanced\nindependently. While in co-training, both miRNA and gene expression profiles\nare used simultaneously to provide different views of cancer samples. To our\nknowledge, it is the first attempt to apply these learning approaches to cancer\nclassification. The approaches were evaluated using breast cancer,\nhepatocellular carcinoma (HCC) and lung cancer expression sets. Results show up\nto 20% improvement in F1-measure over Random Forests and SVM classifiers.\nCo-Training also outperforms Low Density Separation (LDS) approach by around\n25% improvement in F1-measure in breast cancer.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2014 21:02:32 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Ibrahim", "Rania", ""], ["Yousri", "Noha A.", ""], ["Ismail", "Mohamed A.", ""], ["El-Makky", "Nagwa M.", ""]]}, {"id": "1401.4644", "submitter": "Cyril Voyant", "authors": "Cyril Voyant (SPE), Pierrick Haurant (CETHIL), Marc Muselli (SPE),\n  Christophe Paoli (SPE), Marie Laure Nivet (SPE)", "title": "Time series modeling and large scale global solar radiation forecasting\n  from geostationary satellites data", "comments": "Solar Energy (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a territory is poorly instrumented, geostationary satellites data can be\nuseful to predict global solar radiation. In this paper, we use geostationary\nsatellites data to generate 2-D time series of solar radiation for the next\nhour. The results presented in this paper relate to a particular territory, the\nCorsica Island, but as data used are available for the entire surface of the\nglobe, our method can be easily exploited to another place. Indeed 2-D hourly\ntime series are extracted from the HelioClim-3 surface solar irradiation\ndatabase treated by the Heliosat-2 model. Each point of the map have been used\nas training data and inputs of artificial neural networks (ANN) and as inputs\nfor two persistence models (scaled or not). Comparisons between these models\nand clear sky estimations were proceeded to evaluate the performances. We found\na normalized root mean square error (nRMSE) close to 16.5% for the two best\npredictors (scaled persistence and ANN) equivalent to 35-45% related to ground\nmeasurements. Finally in order to validate our 2-D predictions maps, we\nintroduce a new error metric called the gamma index which is a criterion for\ncomparing data from two matrixes in medical physics. As first results, we found\nthat in winter and spring, scaled persistence gives the best results (gamma\nindex test passing rate is respectively 67.7% and 86%), in autumn simple\npersistence is the best predictor (95.3%) and ANN is the best in summer\n(99.8%).\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2014 08:02:29 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Voyant", "Cyril", "", "SPE"], ["Haurant", "Pierrick", "", "CETHIL"], ["Muselli", "Marc", "", "SPE"], ["Paoli", "Christophe", "", "SPE"], ["Nivet", "Marie Laure", "", "SPE"]]}, {"id": "1401.4952", "submitter": "Washington Alves de Oliveira", "authors": "Washington Alves de Oliveira, Luiz Leduino de Salles Neto, Antonio\n  Carlos Moretti and Ednei Felix Reis", "title": "Packing circles within circular containers: a new heuristic algorithm\n  for the balance constraints case", "comments": "18 pages, 5 figures, 4 tables", "journal-ref": "Pesquisa Operacional (2016) 36(2): 279-300", "doi": "10.1590/0101-7438.2016.036.02.0279", "report-no": null, "categories": "cs.CG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a heuristic algorithm for the layout optimization for\ndisks installed in a rotating circular container. This is a unequal circle\npacking problem with additional balance constraints. It proved to be an NP-hard\nproblem, which justifies heuristics methods for its resolution in larger\ninstances. The main feature of our heuristic is based on the selection of the\nnext circle to be placed inside the container according to the position of the\nsystem's center of mass. Our approach has been tested on a series of instances\nup to 55 circles and compared with the literature. Computational results show\ngood performance in terms of solution quality and computational time for the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 19:32:35 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 20:10:04 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["de Oliveira", "Washington Alves", ""], ["Neto", "Luiz Leduino de Salles", ""], ["Moretti", "Antonio Carlos", ""], ["Reis", "Ednei Felix", ""]]}, {"id": "1401.5162", "submitter": "Nalika Ulapane", "authors": "Nalika Ulapane, Sunil Abeyratne, Prabath Binduhewa, Chamari Dhanapala,\n  Shyama Wickramasinghe, Nimal Rathnayake", "title": "A Simple Software Application for Simulating Commercially Available\n  Solar Panels", "comments": "21 pages, 8 figures, 2 tables", "journal-ref": "International Journal of Soft Computing And Software Engineering\n  (JSCSE) e-ISSN: 2251-7545 Vol.2, No.5, 2012", "doi": "10.7321/jscse.v2.n5.5", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses the formulation and validation of a simple PC based\nsoftware application developed for simulating commercially available solar\npanels. The important feature of this application is its capability to produce\nspeedy results in the form of solar panel output characteristics at given\nenvironmental conditions by using minimal input data. Besides, it is able to\ndeliver critical information about the maximum power point of the panel at a\ngiven environmental condition in quick succession. The application is based on\na standard equation which governs solar panels and works by means of estimating\nunknown parameters in the equation to fit a given solar panel. The process of\nparameter estimation is described in detail with the aid of equations and data\nof a commercial solar panel. A validation of obtained results for commercial\nsolar panels is also presented by comparing the panel manufacturers' results\nwith the results generated by the application. In addition, implications of the\nobtained results are discussed along with possible improvements to the\ndeveloped software application.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 03:20:10 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Ulapane", "Nalika", ""], ["Abeyratne", "Sunil", ""], ["Binduhewa", "Prabath", ""], ["Dhanapala", "Chamari", ""], ["Wickramasinghe", "Shyama", ""], ["Rathnayake", "Nimal", ""]]}, {"id": "1401.5197", "submitter": "Shenghao Wang", "authors": "Shenghao Wang, Kai Zhang, Zhili Wang, Kun Gao, Zhao Wu, Peiping Zhu\n  and Ziyu Wu", "title": "A user-friendly nano-CT image alignment and 3D reconstruction platform\n  based on LabVIEW", "comments": "9 pages, 5 figures, 1 chart", "journal-ref": "2015 Chinese Physics C, 39 (1): 018001", "doi": "10.1088/1674-1137/39/1/018001", "report-no": null, "categories": "cs.CE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-ray computed tomography at the nanometer scale (nano-CT) offers a wide\nrange of applications in scientific and industrial areas. Here we describe a\nreliable, user-friendly and fast software package based on LabVIEW that may\nallow to perform all procedures after the acquisition of raw projection images\nin order to obtain the inner structure of the investigated sample. A suitable\nimage alignment process to address misalignment problems among image series due\nto mechanical manufacturing errors, thermal expansion and other external\nfactors has been considered together with a novel fast parallel beam 3D\nreconstruction procedure, developed ad hoc to perform the tomographic\nreconstruction. Remarkably improved reconstruction results obtained at the\nBeijing Synchrotron Radiation Facility after the image calibration confirmed\nthe fundamental role of this image alignment procedure that minimizes unwanted\nblurs and additional streaking artifacts always present in reconstructed\nslices. Moreover, this nano-CT image alignment and its associated 3D\nreconstruction procedure fully based on LabVIEW routines, significantly reduce\nthe data post-processing cycle, thus making faster and easier the activity of\nthe users during experimental runs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 07:01:37 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 06:53:38 GMT"}, {"version": "v3", "created": "Tue, 15 Apr 2014 08:31:25 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Wang", "Shenghao", ""], ["Zhang", "Kai", ""], ["Wang", "Zhili", ""], ["Gao", "Kun", ""], ["Wu", "Zhao", ""], ["Zhu", "Peiping", ""], ["Wu", "Ziyu", ""]]}, {"id": "1401.5364", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "Pokkuluri Kiran Sree, Inampudi Ramesh Babu, SSSN Usha Devi N", "title": "HMACA: Towards Proposing a Cellular Automata Based Tool for Protein\n  Coding, Promoter Region Identification and Protein Structure Prediction", "comments": null, "journal-ref": "International Journal of Research in Computer Applications &\n  Information Technology, Volume 1, Issue 1, July-September, 2013, pp. 26-31", "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human body consists of lot of cells, each cell consist of DeOxaRibo Nucleic\nAcid (DNA). Identifying the genes from the DNA sequences is a very difficult\ntask. But identifying the coding regions is more complex task compared to the\nformer. Identifying the protein which occupy little place in genes is a really\nchallenging issue. For understating the genes coding region analysis plays an\nimportant role. Proteins are molecules with macro structure that are\nresponsible for a wide range of vital biochemical functions, which includes\nacting as oxygen, cell signaling, antibody production, nutrient transport and\nbuilding up muscle fibers. Promoter region identification and protein structure\nprediction has gained a remarkable attention in recent years. Even though there\nare some identification techniques addressing this problem, the approximate\naccuracy in identifying the promoter region is closely 68% to 72%. We have\ndeveloped a Cellular Automata based tool build with hybrid multiple attractor\ncellular automata (HMACA) classifier for protein coding region, promoter region\nidentification and protein structure prediction which predicts the protein and\npromoter regions with an accuracy of 76%. This tool also predicts the structure\nof protein with an accuracy of 80%.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 16:15:29 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Sree", "Pokkuluri Kiran", ""], ["Babu", "Inampudi Ramesh", ""], ["N", "SSSN Usha Devi", ""]]}, {"id": "1401.5580", "submitter": "Pradip Sircar", "authors": "Jugalkishore K. Banoth, Pradip Sircar", "title": "Polynomial Transformation Method for Non-Gaussian Noise Environment", "comments": "4 pages", "journal-ref": "WORLDCOMP 2011, Proc. CSC, pp. 329, Jul 18-21, 2011, Las Vegas,\n  Nevada, USA", "doi": null, "report-no": null, "categories": "math.ST cs.CE stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal processing in non-Gaussian noise environment is addressed in this\npaper. For many real-life situations, the additive noise process present in the\nsystem is found to be dominantly non-Gaussian. The problem of detection and\nestimation of signals corrupted with non-Gaussian noise is difficult to track\nmathematically. In this paper, we present a novel approach for optimal\ndetection and estimation of signals in non-Gaussian noise. It is demonstrated\nthat preprocessing of data by the orthogonal polynomial approximation together\nwith the minimum error-variance criterion converts an additive non-Gaussian\nnoise process into an approximation-error process which is close to Gaussian.\nThe Monte Carlo simulations are presented to test the Gaussian hypothesis based\non the bicoherence of a sequence. The histogram test and the kurtosis test are\ncarried out to verify the Gaussian hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 07:45:29 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Banoth", "Jugalkishore K.", ""], ["Sircar", "Pradip", ""]]}, {"id": "1401.5791", "submitter": "Debadatta Dash", "authors": "Debadatta Dash", "title": "Advanced Signal Processing Techniqes to Study Normal and Epileptic EEG", "comments": null, "journal-ref": "41 st annual conference of OMS and International Conference on\n  Industrial Mathematics and Scientific Computing, 2014", "doi": null, "report-no": "ICIMSC14/OMS41", "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EEG monitoring has an important milestone provide valuable information of\nthose candidates who suffer from epilepsy.In this paper human normal and\nepileptic Electroencephalogram signals are analyzed with popular and efficient\nsignal processing techniques like Fourier and Wavelet transform. The delta,\ntheta, alpha, beta and gamma sub bands of EEG are obtained and studied for\ndetection of seizure and epilepsy. The extracted feature is then applied to ANN\nfor classification of the EEG signals.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 11:22:19 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Dash", "Debadatta", ""]]}, {"id": "1401.6098", "submitter": "Guohua Wu", "authors": "Guohua Wu, Huilin Wang, Haifeng Li, Witold Pedrycz, Dishan Qiu, Manhao\n  Ma, Jin Liu", "title": "An adaptive Simulated Annealing-based satellite observation scheduling\n  method combined with a dynamic task clustering strategy", "comments": "23 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient scheduling is of great significance to rationally make use of\nscarce satellite resources. Task clustering has been demonstrated to realize an\neffective strategy to improve the efficiency of satellite scheduling. However,\nthe previous task clustering strategy is static. That is, it is integrated into\nthe scheduling in a two-phase manner rather than in a dynamic fashion, without\nexpressing its full potential in improving the satellite scheduling\nperformance. In this study, we present an adaptive Simulated Annealing based\nscheduling algorithm aggregated with a dynamic task clustering strategy (or\nASA-DTC for short) for satellite observation scheduling problems (SOSPs).\nFirst, we develop a formal model for the scheduling of Earth observing\nsatellites. Second, we analyze the related constraints involved in the\nobservation task clustering process. Thirdly, we detail an implementation of\nthe dynamic task clustering strategy and the adaptive Simulated Annealing\nalgorithm. The adaptive Simulated Annealing algorithm is efficient, with the\nendowment of some sophisticated mechanisms, i.e. adaptive temperature control,\ntabu-list based revisiting avoidance mechanism, and intelligent combination of\nneighborhood structures. Finally, we report on experimental simulation studies\nto demonstrate the competitive performance of ASA-DTC. Moreover, we show that\nASA-DTC is especially effective when SOSPs contain a large number of targets or\nthese targets are densely distributed in a certain area.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 22:46:27 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Wu", "Guohua", ""], ["Wang", "Huilin", ""], ["Li", "Haifeng", ""], ["Pedrycz", "Witold", ""], ["Qiu", "Dishan", ""], ["Ma", "Manhao", ""], ["Liu", "Jin", ""]]}, {"id": "1401.6484", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "Pokkuluri Kiran Sree, Inampudi Ramesh Babu", "title": "Identification of Protein Coding Regions in Genomic DNA Using\n  Unsupervised FMACA Based Pattern Classifier", "comments": "arXiv admin note: text overlap with arXiv:1312.2642", "journal-ref": "IJCSNS International Journal of Computer Science and Network\n  Security, VOL.8 No.1, January 2008,305-310", "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genes carry the instructions for making proteins that are found in a cell as\na specific sequence of nucleotides that are found in DNA molecules. But, the\nregions of these genes that code for proteins may occupy only a small region of\nthe sequence. Identifying the coding regions play a vital role in understanding\nthese genes. In this paper we propose a unsupervised Fuzzy Multiple Attractor\nCellular Automata (FMCA) based pattern classifier to identify the coding region\nof a DNA sequence. We propose a distinct K-Means algorithm for designing FMACA\nclassifier which is simple, efficient and produces more accurate classifier\nthan that has previously been obtained for a range of different sequence\nlengths. Experimental results confirm the scalability of the proposed\nUnsupervised FCA based classifier to handle large volume of datasets\nirrespective of the number of classes, tuples and attributes. Good\nclassification accuracy has been established.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 01:48:14 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Sree", "Pokkuluri Kiran", ""], ["Babu", "Inampudi Ramesh", ""]]}, {"id": "1401.6597", "submitter": "Sadi Seker E", "authors": "Sadi Evren Seker, Y. Unal, Z. Erdem, and H. Erdinc Kocer", "title": "Ensembled Correlation Between Liver Analysis Outputs", "comments": null, "journal-ref": "International Journal of Biology and Biomedical Engineering, ISSN:\n  1998-4510, Volume 8, pp. 1-5, 2014", "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining techniques on the biological analysis are spreading for most of\nthe areas including the health care and medical information. We have applied\nthe data mining techniques, such as KNN, SVM, MLP or decision trees over a\nunique dataset, which is collected from 16,380 analysis results for a year.\nFurthermore we have also used meta-classifiers to question the increased\ncorrelation rate between the liver disorder and the liver analysis outputs. The\nresults show that there is a correlation among ALT, AST, Billirubin Direct and\nBillirubin Total down to 15% of error rate. Also the correlation coefficient is\nup to 94%. This makes possible to predict the analysis results from each other\nor disease patterns can be applied over the linear correlation of the\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 23:52:37 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Seker", "Sadi Evren", ""], ["Unal", "Y.", ""], ["Erdem", "Z.", ""], ["Kocer", "H. Erdinc", ""]]}, {"id": "1401.6759", "submitter": "Nadia Otmani-Benmehidi", "authors": "Nadia Otmani Benmehidi and Meriem Arar and Imene Chine", "title": "Modeling the behavior of reinforced concrete walls under fire,\n  considering the impact of the span on firewalls", "comments": "8 pages,12 figures, 4 tables", "journal-ref": "International Journal of Soft Computing And Software Engineering\n  (JSCSE), Vol.3,No.3, pp. 600-607, 2013", "doi": "10.7321/jscse.v3.n3.91", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical modeling using computers is known to present several advantages\ncompared to experimental testing. The high cost and the amount of time required\nto prepare and to perform a test were among the main problems on the table when\nthe first tools for modeling structures in fire were developed. The discipline\nstructures-in-fire modeling is still currently the subject of important\nresearch efforts around the word, those research efforts led to develop many\nsoftware. In this paper, our task is oriented to the study of fire behavior and\nthe impact of the span reinforced concrete walls with different sections\nbelonging to a residential building braced by a system composed of porticoes\nand sails. Regarding the design and mechanical loading (compression forces and\nmoments) exerted on the walls in question, we are based on the results of a\nstudy conducted at cold. We use on this subject the software Safir witch obeys\nto the Eurocode laws, to realize this study. It was found that loading,\nheating, and sizing play a capital role in the state of failed walls. Our\nresults justify well the use of reinforced concrete walls, acting as a\nfirewall. Their role is to limit the spread of fire from one structure to\nanother structure nearby, since we get fire resistance reaching more than 10\nhours depending on the loading considered.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 07:50:29 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Benmehidi", "Nadia Otmani", ""], ["Arar", "Meriem", ""], ["Chine", "Imene", ""]]}, {"id": "1401.7344", "submitter": "Brian Hanley", "authors": "Brian P. Hanley", "title": "Release of the Kraken: A Novel Money Multiplier Equation's Debut in 21st\n  Century Banking", "comments": "22 pages, 3 figures, 5 significant equations (of 7). Published in\n  Economics E-Journal", "journal-ref": "Economics: The Open-Access, Open-Assessment E-Journal, Vol. 6,\n  2012-3", "doi": "10.5018/economics-ejournal.ja.2012-3", "report-no": null, "categories": "q-fin.GN cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Historically, the banking multiplier has been in a range of 4 to 100, with\n25% to 1% reserve ratios at most layers of the banking system encompassing the\nmajority of its range in recent centuries. Here it is shown that multipliers\nover 1 000 can occur from a new mechanism in banking. This new multiplier uses\na default insurance note to insure an outstanding loan in order to return the\nvalue of the insured amount into capital. The economic impact of this invention\nis calculably greater than the original invention of reserve banking. The\nconsequence of this lending invention is to render the existing money\nmultiplier equations of reserve banking obsolete where it occurs. The equations\ndescribing this new multiplier do not converge. Each set of parameters for\nreserve percentage, nesting depth, etc. creates a unique logarithmic curve\nrather than approaching a limit. Thus it is necessary to show the behavior of\nthis new equation by numerical methods. Understanding this new multiplier and\nassociated issues is necessary for economic analyses of the Global Financial\nCrisis.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 19:39:14 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Hanley", "Brian P.", ""]]}, {"id": "1401.7416", "submitter": "Pandiselvam Pps", "authors": "Pandiselvam.P, Marimuthu.T and Lawrance.R", "title": "A Comparative Study on String Matching Algorithm of Biological Sequences", "comments": "Selected For International Conference on Intelligent Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  String matching algorithm plays the vital role in the Computational Biology.\nThe functional and structural relationship of the biological sequence is\ndetermined by similarities on that sequence. For that, the researcher is\nsupposed to aware of similarities on the biological sequences. Pursuing of\nsimilarity among biological sequences is an important research area of that can\nbring insight into the evolutionary and genetic relationships among the genes.\nIn this paper, we have studied different kinds of string matching algorithms\nand observed their time and space complexities. For this study, we have\nassessed the performance of algorithms tested with biological sequences.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 05:39:11 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["P", "Pandiselvam.", ""], ["T", "Marimuthu.", ""], ["R", "Lawrance.", ""]]}, {"id": "1401.7631", "submitter": "Natalia Melnikova", "authors": "N.B. Melnikova, D. Jordan, V.V. Krzhizhanovskaya, P.M.A. Sloot", "title": "Slope Instability of the Earthen Levee in Boston, UK: Numerical\n  Simulation and Sensor Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a slope stability analysis for a heterogeneous earthen\nlevee in Boston, UK, which is prone to occasional slope failures under tidal\nloads. Dynamic behavior of the levee under tidal fluctuations was simulated\nusing a finite element model of variably saturated linear elastic perfectly\nplastic soil. Hydraulic conductivities of the soil strata have been calibrated\naccording to piezometers readings, in order to obtain correct range of\nhydraulic loads in tidal mode. Finite element simulation was complemented with\nseries of limit equilibrium analyses. Stability analyses have shown that slope\nfailure occurs with the development of a circular slip surface located in the\nsoft clay layer. Both models (FEM and LEM) confirm that the least stable\nhydraulic condition is the combination of the minimum river levels at low tide\nwith the maximal saturation of soil layers. FEM results indicate that in winter\ntime the levee is almost at its limit state, at the margin of safety (strength\nreduction factor values are 1.03 and 1.04 for the low-tide and high-tide\nphases, respectively); these results agree with real-life observations. The\nstability analyses have been implemented as real-time components integrated\ninto the UrbanFlood early warning system for flood protection.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 19:27:24 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Melnikova", "N. B.", ""], ["Jordan", "D.", ""], ["Krzhizhanovskaya", "V. V.", ""], ["Sloot", "P. M. A.", ""]]}, {"id": "1401.7842", "submitter": "J\\'er\\^ome Bonelle", "authors": "Jerome Bonelle and Alexandre Ern", "title": "Analysis of Compatible Discrete Operator Schemes for the Stokes\n  Equations on Polyhedral Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compatible Discrete Operator schemes preserve basic properties of the\ncontinuous model at the discrete level. They combine discrete differential\noperators that discretize exactly topological laws and discrete Hodge operators\nthat approximate constitutive relations. We devise and analyze two families of\nsuch schemes for the Stokes equations in curl formulation, with the pressure\ndegrees of freedom located at either mesh vertices or cells. The schemes ensure\nlocal mass and momentum conservation. We prove discrete stability by\nestablishing novel discrete Poincar\\'e inequalities. Using commutators related\nto the consistency error, we derive error estimates with first-order\nconvergence rates for smooth solutions. We analyze two strategies for\ndiscretizing the external load, so as to deliver tight error estimates when the\nexternal load has a large irrotational or divergence-free part. Finally,\nnumerical results are presented on three-dimensional polyhedral meshes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 13:43:11 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Bonelle", "Jerome", ""], ["Ern", "Alexandre", ""]]}, {"id": "1401.8044", "submitter": "Kevin Carlberg", "authors": "Kevin Carlberg, Ray Tuminaro, and Paul Boggs", "title": "Preserving Lagrangian structure in nonlinear model reduction with\n  application to structural dynamics", "comments": "Submitted to SIAM Journal on Scientific Computing (SISC)", "journal-ref": "SIAM Journal on Scientific Computing, Vol. 37, No. 2, p. B153-B184\n  (2015)", "doi": "10.1137/140959602", "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a model-reduction methodology that preserves Lagrangian\nstructure (equivalently Hamiltonian structure) and achieves computational\nefficiency in the presence of high-order nonlinearities and arbitrary parameter\ndependence. As such, the resulting reduced-order model retains key properties\nsuch as energy conservation and symplectic time-evolution maps. We focus on\nparameterized simple mechanical systems subjected to Rayleigh damping and\nexternal forces, and consider an application to nonlinear structural dynamics.\nTo preserve structure, the method first approximates the system's `Lagrangian\ningredients'---the Riemannian metric, the potential-energy function, the\ndissipation function, and the external force---and subsequently derives\nreduced-order equations of motion by applying the (forced) Euler--Lagrange\nequation with these quantities. From the algebraic perspective, key\ncontributions include two efficient techniques for approximating parameterized\nreduced matrices while preserving symmetry and positive definiteness: matrix\ngappy POD and reduced-basis sparsification (RBS). Results for a parameterized\ntruss-structure problem demonstrate the importance of preserving Lagrangian\nstructure and illustrate the proposed method's merits: it reduces computation\ntime while maintaining high accuracy and stability, in contrast to existing\nnonlinear model-reduction techniques that do not preserve structure.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 02:43:14 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Carlberg", "Kevin", ""], ["Tuminaro", "Ray", ""], ["Boggs", "Paul", ""]]}, {"id": "1401.8192", "submitter": "Anna Kad{\\l}ubowska MSc", "authors": "Michal Klos, Karol Wawrzyniak, Marcin Jakubek, Grzegorz Orynczak", "title": "The Scheme of a Novel Methodology for Zonal Division Based on Power\n  Transfer Distribution Factors", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the methodologies that carry out the division of the electrical grid\ninto zones is based on the aggregation of nodes characterized by similar Power\nTransfer Distribution Factors (PTDFs). Here, we point out that satisfactory\nclustering algorithm should take into account two aspects. First, nodes of\nsimilar impact on cross-border lines should be grouped together. Second,\ncross-border power flows should be relatively insensitive to differences\nbetween real and assumed Generation Shift Key matrices. We introduce a\ntheoretical basis of a novel clustering algorithm (BubbleClust) that fulfills\nthese requirements and we perform a case study to illustrate social welfare\nconsequences of the division.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 15:28:12 GMT"}, {"version": "v2", "created": "Fri, 18 Jul 2014 09:59:22 GMT"}, {"version": "v3", "created": "Wed, 6 Aug 2014 09:45:46 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Klos", "Michal", ""], ["Wawrzyniak", "Karol", ""], ["Jakubek", "Marcin", ""], ["Orynczak", "Grzegorz", ""]]}]