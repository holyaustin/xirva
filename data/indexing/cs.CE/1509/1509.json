[{"id": "1509.00040", "submitter": "Kentaro Sano", "authors": "Kentaro Sano", "title": "DSL-based Design Space Exploration for Temporal and Spatial Parallelism\n  of Custom Stream Computing", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/06", "categories": "cs.AR cs.CE cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream computation is one of the approaches suitable for FPGA-based custom\ncomputing due to its high throughput capability brought by pipelining with\nregular memory access. To increase performance of iterative stream computation,\nwe can exploit both temporal and spatial parallelism by deepening and\nduplicating pipelines, respectively. However, the performance is constrained by\nseveral factors including available hardware resources on FPGA, an external\nmemory bandwidth, and utilization of pipeline stages, and therefore we need to\nfind the best mix of the different parallelism to achieve the highest\nperformance per power. In this paper, we present a domain-specific language\n(DSL) based design space exploration for temporally and/or spatially parallel\nstream computation with FPGA. We define a DSL where we can easily design a\nhierarchical structure of parallel stream computation with abstract description\nof computation. For iterative stream computation of fluid dynamics simulation,\nwe design hardware structures with a different mix of the temporal and spatial\nparallelism. By measuring the performance and the power consumption, we find\nthe best among them.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:23:57 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Sano", "Kentaro", ""]]}, {"id": "1509.01481", "submitter": "Jurgis Pods", "authors": "Jurgis Pods", "title": "A Comparison of Computational Models for the Extracellular Potential of\n  Neurons", "comments": "12 pages (incl. references), 4 figures (color)", "journal-ref": "Journal of Integrative Neuroscience, vol. 16, no. 1, pp. 19-32,\n  2017", "doi": "10.3233/JIN-170009", "report-no": null, "categories": "q-bio.NC cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extracellular space has an ambiguous role in neuroscience. It is present\nin every physiologically relevant system and often used as a measurement site\nin experimental recordings, but it has received subordinate attention compared\nto the intracellular domain. In computational modeling, it is often regarded as\na passive, homogeneous resistive medium with a constant conductivity, which\ngreatly simplifies the computation of extracellular potentials. However, recent\nstudies have shown that local ionic diffusion and capacitive effects of\nelectrically active membranes can have a substantial impact on the\nextracellular potential. These effects can not be described by traditional\nmodels, and they have been subject to theoretical and experimental analyses. We\nstrive to give an overview over recent progress in modeling the extracellular\nspace with special regard towards the concentration and potential dynamics on\ndifferent temporal and spatial scales. Three models with distinct assumptions\nand levels of detail are compared both theoretically and by means of numerical\nsimulations: the classical volume conductor (VC) model, which is most\nfrequently used in form of the line source approximation (LSA); the very\ndetailed, but computationally intensive Poisson-Nernst-Planck model of\nelectrodiffusion (PNP); and an intermediate one called the electroneutral model\n(EN). The results clearly show that there is no one model for all applications,\nas they show significantly different responses especially close to neuronal\nmembranes. Finally, we list some common use cases for model simulations and\ngive recommendations on which model to use in each situation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 15:01:44 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Pods", "Jurgis", ""]]}, {"id": "1509.01572", "submitter": "Andreas Kreienbuehl", "authors": "Andreas Kreienbuehl and Pietro Benedusi and Daniel Ruprecht and Rolf\n  Krause", "title": "Time parallel gravitational collapse simulation", "comments": "16 pages, 8 figures, 1 listing, and 1 table", "journal-ref": "Communications in Applied Mathematics and Computational Science\n  12-1 (2017), 109--128", "doi": "10.2140/camcos.2017.12.109", "report-no": null, "categories": "gr-qc cs.CE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article demonstrates the applicability of the parallel-in-time method\nParareal to the numerical solution of the Einstein gravity equations for the\nspherical collapse of a massless scalar field. To account for the shrinking of\nthe spatial domain in time, a tailored load balancing scheme is proposed and\ncompared to load balancing based on number of time steps alone. The performance\nof Parareal is studied for both the sub-critical and black hole case; our\nexperiments show that Parareal generates substantial speedup and, in the\nsuper-critical regime, can reproduce Choptuik's black hole mass scaling law.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 19:32:45 GMT"}, {"version": "v2", "created": "Sun, 24 Apr 2016 19:18:58 GMT"}, {"version": "v3", "created": "Wed, 28 Dec 2016 22:06:40 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Kreienbuehl", "Andreas", ""], ["Benedusi", "Pietro", ""], ["Ruprecht", "Daniel", ""], ["Krause", "Rolf", ""]]}, {"id": "1509.01693", "submitter": "Mohamed Abuella", "authors": "Mohamed Abuella and Constantine J. Hatziadoniu (Southern Illinois\n  University)", "title": "The Economic Dispatch for Integrated Wind Power Systems Using Particle\n  Swarm Optimization", "comments": "This paper is a partial work of M.S.Thesis in Electrical and Computer\n  Engineering at Southern Illinois University Carbondale", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The economic dispatch of wind power units is quite different from that in\nconventional thermal units, since the adopted model should take into\nconsideration the intermittency nature of wind speed as well. Therefore, this\npaper uses a model that takes into account the aforementioned consideration in\naddition to whether the utility owns wind turbines or not. The economic\ndispatch is solved by using one of the modern optimization algorithms: the\nparticle swarm optimization algorithm. A 6-bus system is used and it includes\nwind-powered generators besides to thermal generators. The thorough analysis of\nthe results is also provided.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 11:24:36 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Abuella", "Mohamed", "", "Southern Illinois\n  University"], ["Hatziadoniu", "Constantine J.", "", "Southern Illinois\n  University"]]}, {"id": "1509.01709", "submitter": "Peetak Mitra", "authors": "Peetak Mitra, Niranjan Gudibande, Kannan Iyer, TI Eldho", "title": "Algorithm for estimating swirl angles in multi-intake hydraulic sumps", "comments": "The paper has been withdrawn by the author (Peetak Mitra) since it\n  was felt the paper was sketchy in its concepts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper has been withdrawn effective November 18, 2015.\n  Hydraulic Pump sumps are designed to provide a swirl free flow to the pump.\nThe degree of swirl is measured in physical model tests using a swirl meter and\na quantity known as swirl angle is generally measured. The present paper\npresents a novel method to compute the bulk swirl angle using the local\nvelocity field obtained from computational fluid dynamics data. The basis for\nthe present method is the conservation of angular momentum conservation. By\ncarrying out both numerical and experimental studies the novel swirl angle\ncalculation method is validated. Further the effect of vortex suppression\ndevices in reducing the swirl angle is also demonstrated.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 15:37:11 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 14:40:56 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Mitra", "Peetak", ""], ["Gudibande", "Niranjan", ""], ["Iyer", "Kannan", ""], ["Eldho", "TI", ""]]}, {"id": "1509.02762", "submitter": "Christoph Lehrenfeld", "authors": "Christoph Lehrenfeld", "title": "High order unfitted finite element methods on level set domains using\n  isoparametric mappings", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": "10.1016/j.cma.2015.12.005", "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new class of unfitted finite element methods with high order\naccurate numerical integration over curved surfaces and volumes which are only\nimplicitly defined by level set functions. An unfitted finite element method\nwhich is suitable for the case of piecewise planar interfaces is combined with\na parametric mapping of the underlying mesh resulting in an isoparametric\nunfitted finite element method. The parametric mapping is constructed in a way\nsuch that the quality of the piecewise planar interface reconstruction is\nsignificantly improved allowing for high order accurate computations of\n(unfitted) domain and surface integrals. This approach is new. We present the\nmethod, discuss implementational aspects and present numerical examples which\ndemonstrate the quality and potential of this method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 12:59:51 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Lehrenfeld", "Christoph", ""]]}, {"id": "1509.03198", "submitter": "Gurpreet Singh Bhamra", "authors": "G. S. Bhamra, A. K. Verma and R. B. Patel", "title": "Agent enabled Mining of Distributed Protein Data Banks", "comments": null, "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol.5, No.3, May 2015", "doi": "10.5121/ijfcst.2015.5303", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining biological data is an emergent area at the intersection between\nbioinformatics and data mining (DM). The intelligent agent based model is a\npopular approach in constructing Distributed Data Mining (DDM) systems to\naddress scalable mining over large scale distributed data. The nature of\nassociations between different amino acids in proteins has also been a subject\nof great anxiety. There is a strong need to develop new models and exploit and\nanalyze the available distributed biological data sources. In this study, we\nhave designed and implemented a multi-agent system (MAS) called Agent enriched\nQuantitative Association Rules Mining for Amino Acids in distributed Protein\nData Banks (AeQARM-AAPDB). Such globally strong association rules enhance\nunderstanding of protein composition and are desirable for synthesis of\nartificial proteins. A real protein data bank is used to validate the system.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 07:44:29 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Bhamra", "G. S.", ""], ["Verma", "A. K.", ""], ["Patel", "R. B.", ""]]}, {"id": "1509.03530", "submitter": "Ravi Kumar Yadav Dega", "authors": "Ravi Kumar Yadav Dega and Gunes Ercal", "title": "A comparative analysis of progressive multiple sequence alignment\n  approaches using UPGMA and neighbor joining based guide trees", "comments": "9 Pages", "journal-ref": "International Journal of Computer Science, Engineering and\n  Information Technology (IJCSEIT), Vol. 5,No.3/4, August 2015", "doi": null, "report-no": null, "categories": "cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sequence alignment is increasingly important to bioinformatics, with\nseveral applications ranging from phylogenetic analyses to domain\nidentification. There are several ways to perform multiple sequence alignment,\nan important way of which is the progressive alignment approach studied in this\nwork. Progressive alignment involves three steps: find the distance between\neach pair of sequences; construct a guide tree based on the distance matrix;\nfinally based on the guide tree align sequences using the concept of aligned\nprofiles. Our contribution is in comparing two main methods of guide tree\nconstruction in terms of both efficiency and accuracy of the overall alignment:\nUPGMA and Neighbor Join methods. Our experimental results indicate that the\nNeighbor Join method is both more efficient in terms of performance and more\naccurate in terms of overall cost minimization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 14:23:16 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Dega", "Ravi Kumar Yadav", ""], ["Ercal", "Gunes", ""]]}, {"id": "1509.03557", "submitter": "Martin Uecker", "authors": "Martin Uecker and Michael Lustig", "title": "Estimating Absolute-Phase Maps Using ESPIRiT and Virtual Conjugate Coils", "comments": "15 pages, 5 figures", "journal-ref": "Magnetic Resonance in Medicine 77 (2017) 1201-1207", "doi": "10.1002/mrm.26191", "report-no": null, "categories": "cs.CV cs.CE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To develop an ESPIRiT-based method to estimate coil sensitivities\nwith image phase as a building block for efficient and robust image\nreconstruction with phase constraints. Theory and Methods: ESPIRiT is a new\nframework for calibration of the coil sensitivities and reconstruction in\nparallel Magnetic Resonance Imaging (MRI). Applying ESPIRiT to a combined set\nof physical and virtual conjugate coils (VCC-ESPIRiT) implicitly exploits\nconjugate symmetry in k-space similar to VCC-GRAPPA. Based on this method, a\nnew post-processing step is proposed for the explicit computation of coil\nsensitivities that include the absolute phase of the image. The accuracy of the\ncomputed maps is directly validated using a test based on projection onto fully\nsampled coil images and also indirectly in phase-constrained parallel-imaging\nreconstructions. Results: The proposed method can estimate accurate\nsensitivities which include low-resolution image phase. In case of\nhigh-frequency phase variations VCC-ESPIRiT yields an additional set of maps\nthat indicates the existence of a high-frequency phase component. Taking this\nadditional set of maps into account can improve the robustness of\nphase-constrained parallel imaging. Conclusion: The extended VCC-ESPIRiT is a\nuseful tool for phase-constrained imaging.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 22:35:14 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 09:02:37 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Uecker", "Martin", ""], ["Lustig", "Michael", ""]]}, {"id": "1509.03604", "submitter": "Kathryn Huff", "authors": "Kathryn D. Huff, Matthew J. Gidden, Robert W. Carlsen, Robert R.\n  Flanagan, Meghan B. McGarry, Arrielle C. Opotowsky, Erich A. Schneider,\n  Anthony M. Scopatz, Paul P.H. Wilson", "title": "Fundamental concepts in the Cyclus nuclear fuel cycle simulation\n  framework", "comments": null, "journal-ref": "Advances in Engineering Software, Volume 94, April 2016, Pages\n  46-59", "doi": "10.1016/j.advengsoft.2016.01.014", "report-no": null, "categories": "cs.SE cs.CE cs.MA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As nuclear power expands, technical, economic, political, and environmental\nanalyses of nuclear fuel cycles by simulators increase in importance. To date,\nhowever, current tools are often fleet-based rather than discrete and\nrestrictively licensed rather than open source. Each of these choices presents\na challenge to modeling fidelity, generality, efficiency, robustness, and\nscientific transparency. The Cyclus nuclear fuel cycle simulator framework and\nits modeling ecosystem incorporate modern insights from simulation science and\nsoftware architecture to solve these problems so that challenges in nuclear\nfuel cycle analysis can be better addressed. A summary of the Cyclus fuel cycle\nsimulator framework and its modeling ecosystem are presented. Additionally, the\nimplementation of each is discussed in the context of motivating challenges in\nnuclear fuel cycle simulation. Finally, the current capabilities of Cyclus are\ndemonstrated for both open and closed fuel cycles.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 18:39:59 GMT"}, {"version": "v2", "created": "Fri, 11 Mar 2016 16:05:10 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Huff", "Kathryn D.", ""], ["Gidden", "Matthew J.", ""], ["Carlsen", "Robert W.", ""], ["Flanagan", "Robert R.", ""], ["McGarry", "Meghan B.", ""], ["Opotowsky", "Arrielle C.", ""], ["Schneider", "Erich A.", ""], ["Scopatz", "Anthony M.", ""], ["Wilson", "Paul P. H.", ""]]}, {"id": "1509.04250", "submitter": "Ond\\v{r}ej Roko\\v{s}", "authors": "O. Roko\\v{s}, J. M\\'aca", "title": "The response of grandstands driven by filtered Gaussian white noise\n  processes", "comments": "20 pages, 12 figures, 4 tables", "journal-ref": "Advances in Engineering Software, Volume 72, June 2014, Pages\n  85--94, Special Issue dedicated to Professor Zden\\v{e}k Bittnar on the\n  occasion of his Seventieth Birthday: Part 2", "doi": "10.1016/j.advengsoft.2013.05.008", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a semi-analytical estimate of the response of a\ngrandstand occupied by an active crowd and by a passive crowd. Filtered\nGaussian white noise processes are used to approximate the loading terms\nrepresenting an active crowd. Lumped biodynamic models with a single degree of\nfreedom are included to reflect passive spectators occupying the structure. The\nresponse is described in terms of the first two moments, employing the It\\^o\nformula and the state augmentation method for the stationary time domain\nsolution. The quality of the approximation is compared on the basis of three\nexamples of varying complexity using Monte Carlo simulation based on a\nsynthetic generator available in the literature. For comparative purposes,\nthere is also a brief review of frequency domain estimates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 19:23:06 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Roko\u0161", "O.", ""], ["M\u00e1ca", "J.", ""]]}, {"id": "1509.04252", "submitter": "Andreas Kreienbuehl", "authors": "Andreas Kreienbuehl and Arne Naegel and Daniel Ruprecht and Andreas\n  Vogel and Gabriel Wittum and Rolf Krause", "title": "Parareal convergence for 2D unsteady flow around a cylinder", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report we study the convergence of Parareal for 2D\nincompressible flow around a cylinder for different viscosities. Two methods\nare used as fine integrator: backward Euler and a fractional step method. It is\nfound that Parareal converges better for the implicit Euler, likely because it\nunder-resolves the fine-scale dynamics as a result of numerical diffusion.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 19:29:41 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Kreienbuehl", "Andreas", ""], ["Naegel", "Arne", ""], ["Ruprecht", "Daniel", ""], ["Vogel", "Andreas", ""], ["Wittum", "Gabriel", ""], ["Krause", "Rolf", ""]]}, {"id": "1509.04693", "submitter": "Xiang Wang", "authors": "Xiang Wang and Ronald D. Haynes and Qihong Feng", "title": "Well Control Optimization using Derivative-Free Algorithms and a\n  Multiscale Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use numerical optimization algorithms and a multiscale\napproach in order to find an optimal well management strategy over the life of\nthe reservoir. The large number of well rates for each control step make the\noptimization problem more difficult and at a high risk of achieving a\nsuboptimal solution. Moreover, the optimal number of adjustments is not known a\npriori. Adjusting well controls too frequently will increase unnecessary well\nmanagement and operation cost, and an excessively low number of control\nadjustments may not be enough to obtain a good yield. We investigate three\nderivative-free optimization algorithms, chosen for their robust and parallel\nnature, to determine optimal well control strategies. The algorithms chosen\ninclude generalized pattern search (GPS), particle swarm optimization (PSO) and\ncovariance matrix adaptation evolution strategy (CMA-ES). These three\nalgorithms encompass the breadth of available black-box optimization\nstrategies: deterministic local search, stochastic global search and stochastic\nlocal search. In addition, we hybridize the three derivative-free algorithms\nwith a multiscale regularization approach. Starting with a reasonably small\nnumber of control steps, the control intervals are subsequently refined during\nthe optimization. Results for experiments studied indicate that CMA-ES performs\nbest among the three algorithms in solving both small and large scale problems.\nWhen hybridized with a multiscale regularization approach, the ability to find\nthe optimal solution is further enhanced, with the performance of GPS improving\nthe most. Topics affecting the performance of the multiscale approach are\ndiscussed in this paper, including the effect of control frequency on the well\ncontrol problem. The parameter settings for GPS, PSO, and CMA-ES, within the\nmultiscale approach are considered.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 19:26:49 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Wang", "Xiang", ""], ["Haynes", "Ronald D.", ""], ["Feng", "Qihong", ""]]}, {"id": "1509.04729", "submitter": "Christian Jacobs", "authors": "Christian T. Jacobs, Alexandros Avdis, Simon L. Mouradian, Matthew D.\n  Piggott", "title": "Integrating Research Data Management into Geographical Information\n  Systems", "comments": "Accepted, camera-ready version. To appear in the Proceedings of the\n  5th International Workshop on Semantic Digital Archives\n  (http://sda2015.dke-research.de/), held in Pozna\\'n, Poland on 18 September\n  2015 as part of the 19th International Conference on Theory and Practice of\n  Digital Libraries (http://tpdl2015.info/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ocean modelling requires the production of high-fidelity computational meshes\nupon which to solve the equations of motion. The production of such meshes by\nhand is often infeasible, considering the complexity of the bathymetry and\ncoastlines. The use of Geographical Information Systems (GIS) is therefore a\nkey component to discretising the region of interest and producing a mesh\nappropriate to resolve the dynamics. However, all data associated with the\nproduction of a mesh must be provided in order to contribute to the overall\nrecomputability of the subsequent simulation. This work presents the\nintegration of research data management in QMesh, a tool for generating meshes\nusing GIS. The tool uses the PyRDM library to provide a quick and easy way for\nscientists to publish meshes, and all data required to regenerate them, to\npersistent online repositories. These repositories are assigned unique\nidentifiers to enable proper citation of the meshes in journal articles.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 20:20:17 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Jacobs", "Christian T.", ""], ["Avdis", "Alexandros", ""], ["Mouradian", "Simon L.", ""], ["Piggott", "Matthew D.", ""]]}, {"id": "1509.05208", "submitter": "Petr Vabishchevich N.", "authors": "Sergey V. Lemeshevsky, Semion A. Naumovich, Sergey S. Naumovich, Petr\n  N. Vabishchevich, Petr E. Zakharov", "title": "Numerical simulation of the stress-strain state of the dental system", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": "10.1063/1.4964958", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present mathematical models, computational algorithms and software, which\ncan be used for prediction of results of prosthetic treatment. More interest\nissue is biomechanics of the periodontal complex because any prosthesis is\naccompanied by a risk of overloading the supporting elements. Such risk can be\navoided by the proper load distribution and prediction of stresses that occur\nduring the use of dentures. We developed the mathematical model of the\nperiodontal complex and its software implementation. This model is based on\nlinear elasticity theory and allows to calculate the stress and strain fields\nin periodontal ligament and jawbone. The input parameters for the developed\nmodel can be divided into two groups. The first group of parameters describes\nthe mechanical properties of periodontal ligament, teeth and jawbone (for\nexample, elasticity of periodontal ligament etc.). The second group\ncharacterized the geometric properties of objects: the size of the teeth, their\nspatial coordinates, the size of periodontal ligament etc. The mechanical\nproperties are the same for almost all, but the input of geometrical data is\ncomplicated because of their individual characteristics. In this connection, we\ndevelop algorithms and software for processing of images obtained by computed\ntomography (CT) scanner and for constructing individual digital model of the\ntooth-periodontal ligament-jawbone system of the patient. Integration of models\nand algorithms described allows to carry out biomechanical analysis on\nthree-dimensional digital model and to select prosthesis design.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 11:19:42 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Lemeshevsky", "Sergey V.", ""], ["Naumovich", "Semion A.", ""], ["Naumovich", "Sergey S.", ""], ["Vabishchevich", "Petr N.", ""], ["Zakharov", "Petr E.", ""]]}, {"id": "1509.05475", "submitter": "Gautier Marti", "authors": "Gautier Marti, Philippe Very, Philippe Donnat, Frank Nielsen", "title": "A proposal of a methodological framework with experimental guidelines to\n  investigate clustering stability on financial time series", "comments": "Accepted at ICMLA 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper an empirical framework motivated by the practitioner\npoint of view on stability. The goal is to both assess clustering validity and\nyield market insights by providing through the data perturbations we propose a\nmulti-view of the assets' clustering behaviour. The perturbation framework is\nillustrated on an extensive credit default swap time series database available\nonline at www.datagrapple.com.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 23:40:34 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Marti", "Gautier", ""], ["Very", "Philippe", ""], ["Donnat", "Philippe", ""], ["Nielsen", "Frank", ""]]}, {"id": "1509.06457", "submitter": "Suneel Sarswat", "authors": "Suneel Sarswat, Kandathil Mathew Abraham, Subir Kumar Ghosh", "title": "Identifying collusion groups using spectral clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an illiquid stock, traders can collude and place orders on a predetermined\nprice and quantity at a fixed schedule. This is usually done to manipulate the\nprice of the stock or to create artificial liquidity in the stock, which may\nmislead genuine investors. Here, the problem is to identify such group of\ncolluding traders. We modeled the problem instance as a graph, where each\ntrader corresponds to a vertex of the graph and trade corresponds to edges of\nthe graph. Further, we assign weights on edges depending on total volume, total\nnumber of trades, maximum change in the price and commonality between two\nvertices. Spectral clustering algorithms are used on the constructed graph to\nidentify colluding group(s). We have compared our results with simulated data\nto show the effectiveness of spectral clustering to detecting colluding groups.\nMoreover, we also have used parameters of real data to test the effectiveness\nof our algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 04:03:18 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 12:40:52 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Sarswat", "Suneel", ""], ["Abraham", "Kandathil Mathew", ""], ["Ghosh", "Subir Kumar", ""]]}, {"id": "1509.07065", "submitter": "Soumi Chaki", "authors": "Soumi Chaki, Aurobinda Routray and William K. Mohanty", "title": "A Novel Pre-processing Scheme to Improve the Prediction of Sand Fraction\n  from Seismic Attributes using Neural Networks", "comments": "13 pages, volume 8, no 4, pp. 1808-1820, April 2015 in IEE Journal of\n  Selected Topics in Applied Earth Observations and Remote Sensing, 2015", "journal-ref": null, "doi": "10.1109/JSTARS.2015.2404808", "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel pre-processing scheme to improve the prediction\nof sand fraction from multiple seismic attributes such as seismic impedance,\namplitude and frequency using machine learning and information filtering. The\navailable well logs along with the 3-D seismic data have been used to benchmark\nthe proposed pre-processing stage using a methodology which primarily consists\nof three steps: pre-processing, training and post-processing. An Artificial\nNeural Network (ANN) with conjugate-gradient learning algorithm has been used\nto model the sand fraction. The available sand fraction data from the high\nresolution well logs has far more information content than the low resolution\nseismic attributes. Therefore, regularization schemes based on Fourier\nTransform (FT), Wavelet Decomposition (WD) and Empirical Mode Decomposition\n(EMD) have been proposed to shape the high resolution sand fraction data for\neffective machine learning. The input data sets have been segregated into\ntraining, testing and validation sets. The test results are primarily used to\ncheck different network structures and activation function performances. Once\nthe network passes the testing phase with an acceptable performance in terms of\nthe selected evaluators, the validation phase follows. In the validation stage,\nthe prediction model is tested against unseen data. The network yielding\nsatisfactory performance in the validation stage is used to predict\nlithological properties from seismic attributes throughout a given volume.\nFinally, a post-processing scheme using 3-D spatial filtering is implemented\nfor smoothing the sand fraction in the volume. Prediction of lithological\nproperties using this framework is helpful for Reservoir Characterization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 17:15:21 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Chaki", "Soumi", ""], ["Routray", "Aurobinda", ""], ["Mohanty", "William K.", ""]]}, {"id": "1509.07074", "submitter": "Soumi Chaki", "authors": "Akhilesh K Verma, Soumi Chaki, Aurobinda Routray, William K Mohanty,\n  Mamata Jenamani", "title": "Quantification of sand fraction from seismic attributes using\n  Neuro-Fuzzy approach", "comments": "Journal of Applied Geophysics, volume 111, page 141-155", "journal-ref": null, "doi": "10.1016/j.jappgeo.2014.10.005", "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we illustrate the modeling of a reservoir property (sand\nfraction) from seismic attributes namely seismic impedance, seismic amplitude,\nand instantaneous frequency using Neuro-Fuzzy (NF) approach. Input dataset\nincludes 3D post-stacked seismic attributes and six well logs acquired from a\nhydrocarbon field located in the western coast of India. Presence of thin sand\nand shale layers in the basin area makes the modeling of reservoir\ncharacteristic a challenging task. Though seismic data is helpful in\nextrapolation of reservoir properties away from boreholes; yet, it could be\nchallenging to delineate thin sand and shale reservoirs using seismic data due\nto its limited resolvability. Therefore, it is important to develop\nstate-of-art intelligent methods for calibrating a nonlinear mapping between\nseismic data and target reservoir variables. Neural networks have shown its\npotential to model such nonlinear mappings; however, uncertainties associated\nwith the model and datasets are still a concern. Hence, introduction of Fuzzy\nLogic (FL) is beneficial for handling these uncertainties. More specifically,\nhybrid variants of Artificial Neural Network (ANN) and fuzzy logic, i.e., NF\nmethods, are capable for the modeling reservoir characteristics by integrating\nthe explicit knowledge representation power of FL with the learning ability of\nneural networks. The documented results in this study demonstrate acceptable\nresemblance between target and predicted variables, and hence, encourage the\napplication of integrated machine learning approaches such as Neuro-Fuzzy in\nreservoir characterization domain. Furthermore, visualization of the variation\nof sand probability in the study area would assist in identifying placement of\npotential wells for future drilling operations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 17:48:24 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Verma", "Akhilesh K", ""], ["Chaki", "Soumi", ""], ["Routray", "Aurobinda", ""], ["Mohanty", "William K", ""], ["Jenamani", "Mamata", ""]]}, {"id": "1509.07079", "submitter": "Soumi Chaki", "authors": "Soumi Chaki, Akhilesh K Verma, Aurobinda Routray, William K Mohanty,\n  Mamata Jenamani", "title": "Well Tops Guided Prediction of Reservoir Properties using Modular Neural\n  Network Concept A Case Study from Western Onshore, India", "comments": "in Journal of Petroleum Science and Engineering, 2014", "journal-ref": null, "doi": "10.1016/j.petrol.2014.06.019", "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a complete framework consisting pre-processing, modeling,\nand post-processing stages to carry out well tops guided prediction of a\nreservoir property (sand fraction) from three seismic attributes (seismic\nimpedance, instantaneous amplitude, and instantaneous frequency) using the\nconcept of modular artificial neural network (MANN). The data set used in this\nstudy comprising three seismic attributes and well log data from eight wells,\nis acquired from a western onshore hydrocarbon field of India. Firstly, the\nacquired data set is integrated and normalized. Then, well log analysis and\nsegmentation of the total depth range into three different units (zones)\nseparated by well tops are carried out. Secondly, three different networks are\ntrained corresponding to three different zones using combined data set of seven\nwells and then trained networks are validated using the remaining test well.\nThe target property of the test well is predicted using three different tuned\nnetworks corresponding to three zones; and then the estimated values obtained\nfrom three different networks are concatenated to represent the predicted log\nalong the complete depth range of the testing well. The application of multiple\nsimpler networks instead of a single one improves the prediction accuracy in\nterms of performance metrics such as correlation coefficient, root mean square\nerror, absolute error mean and program execution time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 18:09:36 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Chaki", "Soumi", ""], ["Verma", "Akhilesh K", ""], ["Routray", "Aurobinda", ""], ["Mohanty", "William K", ""], ["Jenamani", "Mamata", ""]]}, {"id": "1509.08357", "submitter": "Utkarsh R. Patel", "authors": "Utkarsh R. Patel and Piero Triverio", "title": "Skin Effect Modeling in Conductors of Arbitrary Shape Through a Surface\n  Admittance Operator and the Contour Integral Method", "comments": "This paper has been submitted for publication to the IEEE\n  Transactions on Microwave Theory and Techniques on September 27, 2015", "journal-ref": null, "doi": "10.1109/TMTT.2016.2593721", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate modeling of skin effect inside conductors is of capital\nimportance to solve transmission line and scattering problems. This paper\npresents a surface-based formulation to model skin effect in conductors of\narbitrary cross section, and compute the per-unit-length impedance of a\nmulticonductor transmission line. The proposed formulation is based on the\nDirichlet-Neumann operator that relates the longitudinal electric field to the\ntangential magnetic field on the boundary of a conductor. We demonstrate how\nthe surface operator can be obtained through the contour integral method for\nconductors of arbitrary shape. The proposed algorithm is simple to implement,\nefficient, and can handle arbitrary cross-sections, which is a main advantage\nover the existing approach based on eigenfunctions, which is available only for\ncanonical conductor's shapes. The versatility of the method is illustrated\nthrough a diverse set of examples, which includes transmission lines with\ntrapezoidal, curved, and V-shaped conductors. Numerical results demonstrate the\naccuracy, versatility, and efficiency of the proposed technique.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 15:23:48 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Patel", "Utkarsh R.", ""], ["Triverio", "Piero", ""]]}, {"id": "1509.09211", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Normalized rotation shape descriptors and lossy compression of molecular\n  shape", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a common need to search of molecular databases for compounds\nresembling some shape, what suggests having similar biological activity while\nsearching for new drugs. The large size of the databases requires fast methods\nfor such initial screening, for example based on feature vectors constructed to\nfulfill the requirement that similar molecules should correspond to close\nvectors. Ultrafast Shape Recognition (USR) is a popular approach of this type.\nIt uses vectors of 12 real number as 3 first moments of distances from 4\nemphasized points. These coordinates might contain unnecessary correlations and\ndoes not allow to reconstruct the approximated shape. In contrast, spherical\nharmonic (SH) decomposition uses orthogonal coordinates, suggesting their\nindependence and so lager informational content of the feature vector. There is\nusually considered rotationally invariant SH descriptors, what means discarding\nof some essential information.\n  This article discusses framework for descriptors with normalized rotation,\nfor example by using principal component analysis (PCA-SH). As one of the most\ninteresting are ligands which have to slide into a protein, we will introduce\ndescriptors optimized for such flat elongated shapes. Bent deformed cylinder\n(BDC) describes the molecule as a cylinder which was first bent, then deformed\nsuch that its cross-sections became ellipses of evolving shape. Legendre\npolynomials are used to describe the central axis of such bent cylinder.\nAdditional polynomials are used to define evolution of such elliptic\ncross-section along the main axis. There will be also discussed bent\ncylindrical harmonics (BCH), which uses cross-sections described by cylindrical\nharmonics instead of ellipses. All these normalized rotation descriptors allow\nto reconstruct (decode) the approximated representation of the shape, hence can\nbe also used for lossy compression purposes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 15:11:33 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1509.09227", "submitter": "Dhagash Mehta", "authors": "Daniel K Molzahn, Dhagash Mehta, Matthew Niemerg", "title": "Toward Topologically Based Upper Bounds on the Number of Power Flow\n  Solutions", "comments": "6 pages, 5 figures. Submitted to special session at the IEEE American\n  Control Conference", "journal-ref": null, "doi": "10.1109/ACC.2016.7526599", "report-no": "ADP-15-34/T936", "categories": "math.OC cs.CE math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power flow equations, which relate power injections and voltage phasors,\nare at the heart of many electric power system computations. While Newton-based\nmethods typically find the \"high-voltage\" solution to the power flow equations,\nwhich is of primary interest, there are potentially many \"low-voltage\"\nsolutions that are useful for certain analyses. This paper addresses the number\nof solutions to the power flow equations. There exist upper bounds on the\nnumber of power flow solutions; however, there is only limited work regarding\nbounds that are functions of network topology. This paper empirically explores\nthe relationship between the network topology, as characterized by the maximal\ncliques, and the number of power flow solutions. To facilitate this analysis,\nwe use a numerical polynomial homotopy continuation approach that is guaranteed\nto find all complex solutions to the power flow equations. The number of\nsolutions obtained from this approach upper bounds the number of real\nsolutions. Testing with many small networks informs the development of upper\nbounds that are functions of the network topology. Initial results include\nempirically derived expressions for the maximum number of solutions for certain\nclasses of network topologies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 15:41:53 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Molzahn", "Daniel K", ""], ["Mehta", "Dhagash", ""], ["Niemerg", "Matthew", ""]]}]