[{"id": "1712.00009", "submitter": "Paulo Laerte Natti", "authors": "T.M. Saita, P.L. Natti, E.R. Cirilo, N.M.L. Romeiro, M.A.C. Candezano,\n  R.B Acu\\~na and L.C.G. Moreno", "title": "Numerical Simulation of Fecal Coliform Dynamics in Luruaco Lake,\n  Colombia", "comments": "13 pages, in Portuguese, 4 figures", "journal-ref": "TEMA, v.18, n.3, p.435-447, 2017", "doi": "10.5540/tema.2017.018.03.0435", "report-no": null, "categories": "q-bio.QM cs.CE math.NA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Luruaco Lake located in the Department of Atl\\'antico, Colombia, is\ndamaged by the discharge of untreated sewage, bringing risks to the health of\nall who use its waters. The present study aims to perform the numerical\nsimulation of the concentration dynamics of fecal coliforms in the lake. The\nsimulation of the hydrodynamic flow is carried out by means of a\ntwo-dimensional horizontal (2DH) model, given by a Navier-Stokes system. The\nsimulation of fecal coliform transport is described by a\nconvective-dispersive-reactive equation. These equations are solved numerically\nby the Finite Difference Method (FDM) and the Mark and Cell (MAC) method, in\ngeneralized coordinates. Regarding the construction of the computational mesh\nof the Luruaco Lake, the cubic spline and multiblock methods were used. The\nresults obtained in the simulations allow a better understanding of the\ndynamics of fecal coliforms in the Luruaco Lake, showing the more polluted\nregions. They can also advise public agencies on identifying the emitters of\npollutants in the lake and on developing an optimal treatment for the recovery\nof the polluted environment.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 13:19:47 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Saita", "T. M.", ""], ["Natti", "P. L.", ""], ["Cirilo", "E. R.", ""], ["Romeiro", "N. M. L.", ""], ["Candezano", "M. A. C.", ""], ["Acu\u00f1a", "R. B", ""], ["Moreno", "L. C. G.", ""]]}, {"id": "1712.00203", "submitter": "Mehrdad Gharib Shirangi", "authors": "Mehrdad G Shirangi", "title": "Closed-loop field development with multipoint geostatistics and\n  statistical performance assessment", "comments": "accepted for publication in Journal of Computational Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE physics.data-an stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Closed-loop field development (CLFD) optimization is a comprehensive\nframework for optimal development of subsurface resources. CLFD involves three\nmajor steps: 1) optimization of full development plan based on current set of\nmodels, 2) drilling new wells and collecting new spatial and temporal\n(production) data, 3) model calibration based on all data. This process is\nrepeated until the optimal number of wells is drilled. This work introduces an\nefficient CLFD implementation for complex systems described by multipoint\ngeostatistics (MPS). Model calibration is accomplished in two steps:\nconditioning to spatial data by a geostatistical simulation method, and\nconditioning to production data by optimization-based PCA. A statistical\nprocedure is presented to assess the performance of CLFD. Methodology is\napplied to an oil reservoir example for 25 different true-model cases.\nApplication of a single-step of CLFD, improved the true NPV in 64%--80% of\ncases. The full CLFD procedure (with three steps) improved the true NPV in 96%\nof cases, with an average improvement of 37%.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 06:08:59 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 04:42:56 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Shirangi", "Mehrdad G", ""]]}, {"id": "1712.00335", "submitter": "Ashkan Sadeghi-Mobarakeh", "authors": "Ashkan Sadeghi Mobarakeh, Abbas Rajabi-Ghahnavieh, Hossein Haghighat", "title": "A bilevel approach for optimal contract pricing of independent\n  dispatchable DG units in distribution networks", "comments": null, "journal-ref": "International Transactions on Electrical Energy Systems, 2016", "doi": "10.1002/etep.2172", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Generation (DG) units are increasingly installed in the power\nsystems. Distribution Companies (DisCo) can opt to purchase the electricity\nfrom DG in an energy purchase contract to supply the customer demand and reduce\nenergy loss. This paper proposes a framework for optimal contract pricing of\nindependent dispatchable DG units considering competition among them. While DG\nunits tend to increase their profit from the energy purchase contract, DisCo\nminimizes the demand supply cost. Multi-leader follower game theory concept is\nused to analyze the situation in which competing DG units offer the energy\nprice to DisCo and DisCo determines the DG generation. A bi-level approach is\nused to formulate the competition in which each DG problem is the upper-level\nproblem and the DisCo problem is considered as the lower-level one. Combining\nthe optimality conditions ofall upper-level problems with the lower level\nproblem results in a multi-DG equilibrium problem formulated as an equilibrium\nproblem with equilibrium constraints (EPEC). Using a nonlinear approach, the\nEPEC problem is reformulated as a single nonlinear optimization model which is\nsimultaneously solved for all independent DG units. The proposed framework was\napplied to the Modified IEEE 34-Bus Distribution Test System. Performance and\nrobustness of the proposed framework in determining econo-technically fare DG\ncontract price has been demonstrated through a series of analyses.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 00:29:33 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Mobarakeh", "Ashkan Sadeghi", ""], ["Rajabi-Ghahnavieh", "Abbas", ""], ["Haghighat", "Hossein", ""]]}, {"id": "1712.00408", "submitter": "Inanc Senocak", "authors": "Jaber J. Hasbestan, Inanc Senocak", "title": "Binarized octree generation for Cartesian adaptive mesh refinement\n  around immersed geometries", "comments": "submitted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2018.04.039", "report-no": null, "categories": "cs.CE physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the generation of balanced octrees for adaptive mesh refinement\n(AMR) of Cartesian domains with immersed complex geometries. In a recent short\nnote [Hasbestan and Senocak, J. Comput. Phys. vol. 351:473-477 (2017)], we\nshowed that the data-locality of the Z-order curve in hashed linear octree\ngeneration methods may not be perfect because of potential collisions in the\nhash table. Building on that observation, we propose a binarized octree\ngeneration method that complies with the Z-order curve exactly. Similar to a\nhashed linear octree generation method, we use Morton encoding to index the\nnodes of an octree, but use a red-black tree in place of the hash table.\nRed-black tree is a special kind of a binary tree, which we use for insertion\nand deletion of elements during mesh adaptation. By strictly working with the\nbitwise representation of the octree, we remove computer hardware limitations\non the depth of adaptation on a single processor. Additionally, we introduce a\ngeometry encoding technique for rapidly tagging the solid geometry for\nrefinement. Our results for several geometries with different levels of\nadaptations show that the binarized octree generation outperforms the linear\noctree generation in terms of runtime performance at the expense of only a\nslight increase in memory usage. We provide the current AMR capability as\nopen-source software.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 17:09:41 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Hasbestan", "Jaber J.", ""], ["Senocak", "Inanc", ""]]}, {"id": "1712.00460", "submitter": "Eirik Keilegavlen", "authors": "Eirik Keilegavlen, Alessio Fumagalli, Runar Berge, Ivar Stefansson,\n  Inga Berre", "title": "PorePy: An Open-Source Simulation Tool for Flow and Transport in\n  Deformable Fractured Rocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractures are ubiquitous in the subsurface and strongly affect flow and\ndeformation. The physical shape of the fractures, they are long and thin\nobjects, puts strong limitations on how the effect of this dynamics can be\nincorporated into standard reservoir simulation tools. This paper reports the\ndevelopment of an open-source software framework, termed PorePy, which is aimed\nat simulation of flow and transport in three-dimensional fractured reservoirs,\nas well as deformation of the reservoir due to shearing along fracture and\nfault planes. Starting from a description of fractures as polygons embedded in\na 3D domain, PorePy provides semi-automatic gridding to construct a\ndiscrete-fracture-matrix model, which forms the basis for subsequent\nsimulations. PorePy allows for flow and transport in all lower-dimensional\nobjects, including planes (2D) representing fractures, and lines (1D) and\npoints (0D), representing fracture intersections. Interaction between processes\nin neighboring domains of different dimension is implemented as a sequence of\ncouplings of objects one dimension apart. This readily allows for handling of\ncomplex fracture geometries compared to capabilities of existing software. In\naddition to flow and transport, PorePy provides models for rock mechanics,\nporo-elasticity and coupling with fracture deformation models. The software is\nfully open, and can serve as a framework for transparency and reproducibility\nof simulations. We describe the design principles of PorePy from a user\nperspective, with focus on possibilities within gridding, covered physical\nprocesses and available discretizations. The power of the framework is\nillustrated with two sets of simulations; involving respectively coupled flow\nand transport in a fractured porous medium, and low-pressure stimulation of a\ngeothermal reservoir.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 19:02:15 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 08:23:58 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Keilegavlen", "Eirik", ""], ["Fumagalli", "Alessio", ""], ["Berge", "Runar", ""], ["Stefansson", "Ivar", ""], ["Berre", "Inga", ""]]}, {"id": "1712.00504", "submitter": "Rui Luo", "authors": "Rui Luo, Weinan Zhang, Xiaojun Xu, and Jun Wang", "title": "A Neural Stochastic Volatility Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that the recent integration of statistical models with\ndeep recurrent neural networks provides a new way of formulating volatility\n(the degree of variation of time series) models that have been widely used in\ntime series analysis and prediction in finance. The model comprises a pair of\ncomplementary stochastic recurrent neural networks: the generative network\nmodels the joint distribution of the stochastic volatility process; the\ninference network approximates the conditional distribution of the latent\nvariables given the observables. Our focus here is on the formulation of\ntemporal dynamics of volatility over time under a stochastic recurrent neural\nnetwork framework. Experiments on real-world stock price datasets demonstrate\nthat the proposed model generates a better volatility estimation and prediction\nthat outperforms mainstream methods, e.g., deterministic models such as GARCH\nand its variants, and stochastic models namely the MCMC-based model\n\\emph{stochvol} as well as the Gaussian process volatility model \\emph{GPVol},\non average negative log-likelihood.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:31:36 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 00:28:03 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Luo", "Rui", ""], ["Zhang", "Weinan", ""], ["Xu", "Xiaojun", ""], ["Wang", "Jun", ""]]}, {"id": "1712.00693", "submitter": "Steven Kast", "authors": "Steven M. Kast", "title": "An Introduction to Adjoints and Output Error Estimation in Computational\n  Fluid Dynamics", "comments": "87 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use of adjoint vectors in Computational Fluid Dynamics\n(CFD) has seen a dramatic rise. Their utility in numerous applications,\nincluding design optimization, data assimilation, and mesh adaptation has\nsparked the interest of both researchers and practitioners alike. In many of\nthese fields, the concept of an adjoint is explained differently, with various\nnotations and motivations employed. Further complicating matters is the\nexistence of two seemingly different types of adjoints -- \"continuous\" and\n\"discrete\" -- as well as the more formal definition of adjoint operators\nemployed in linear algebra and functional analysis. These issues can make the\nfundamental concept of an adjoint difficult to pin down. In these notes, we\nhope to clarify some of the ideas surrounding adjoint vectors and to provide a\nuseful reference for both continuous and discrete adjoints alike. In\nparticular, we focus on the use of adjoints within the context of output-based\nmesh adaptation, where the goal is to achieve accuracy in a particular quantity\n(or \"output\") of interest by performing targeted adaptation of the\ncomputational mesh. While this is our application of interest, the ideas\ndiscussed here apply directly to design optimization, data assimilation, and\nmany other fields where adjoints are employed.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 01:53:40 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kast", "Steven M.", ""]]}, {"id": "1712.00975", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Alexandros Iosifidis, Juho Kanniainen, Moncef Gabbouj", "title": "Temporal Attention augmented Bilinear Network for Financial Time-Series\n  Data Analysis", "comments": "12 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2869225", "report-no": null, "categories": "cs.CE cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time-series forecasting has long been a challenging problem because\nof the inherently noisy and stochastic nature of the market. In the\nHigh-Frequency Trading (HFT), forecasting for trading purposes is even a more\nchallenging task since an automated inference system is required to be both\naccurate and fast. In this paper, we propose a neural network layer\narchitecture that incorporates the idea of bilinear projection as well as an\nattention mechanism that enables the layer to detect and focus on crucial\ntemporal information. The resulting network is highly interpretable, given its\nability to highlight the importance and contribution of each temporal instance,\nthus allowing further analysis on the time instances of interest. Our\nexperiments in a large-scale Limit Order Book (LOB) dataset show that a\ntwo-hidden-layer network utilizing our proposed layer outperforms by a large\nmargin all existing state-of-the-art results coming from much deeper\narchitectures while requiring far fewer computations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 09:41:24 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Iosifidis", "Alexandros", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1712.01179", "submitter": "Thang Duong", "authors": "Thang Xuan Duong, Laura De Lorenzis, and Roger A. Sauer", "title": "A segmentation-free isogeometric extended mortar contact method", "comments": "In this version, we have removed the patch test comparison with the\n  classical mortar method and removed corresponding statements. They will be\n  studied in further detail in future work, so that the focus is now entirely\n  on the new IGA mortar formulation", "journal-ref": null, "doi": "10.1007/s00466-018-1599-0", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new isogeometric mortar contact formulation based on an\nextended finite element interpolation to capture physical pressure\ndiscontinuities at the contact boundary. The so called two-half-pass algorithm\nis employed, which leads to an unbiased formulation and, when applied to the\nmortar setting, has the additional advantage that the mortar coupling term is\nno longer present in the contact forces. As a result, the computationally\nexpensive segmentation at overlapping master-slave element boundaries, usually\nrequired in mortar methods (although often simplified with loss of accuracy),\nis not needed from the outset. For the numerical integration of general contact\nproblems, the so-called refined boundary quadrature is employed, which is based\non adaptive partitioning of contact elements along the contact boundary. The\ncontact patch test shows that the proposed formulation passes the test without\nusing either segmentation or refined boundary quadrature. Several numerical\nexamples are presented to demonstrate the robustness and accuracy of the\nproposed formulation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 16:26:52 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 15:42:18 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Duong", "Thang Xuan", ""], ["De Lorenzis", "Laura", ""], ["Sauer", "Roger A.", ""]]}, {"id": "1712.01454", "submitter": "Shuaifang Zhang", "authors": "Shuaifang Zhang, Dongdong He, Dongsheng Li, Zhifeng Zhang, Yu Liu, Wei\n  Shen", "title": "Wave analysis in one dimensional structures with a wavelet finite\n  element model and precise integration method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical simulation of ultrasonic wave propagation provides an efficient\ntool for crack identification in structures, while it requires a high\nresolution and expensive time calculation cost in both time integration and\nspatial discretization. Wavelet finite element model provides a highorder\nfinite element model and gives a higher accuracy on spatial discretization,\nB-Spline wavelet interval (BSWI) has been proved to be one of the most commonly\nused wavelet finite element model with the advantage of getting the same\naccuracy but with fewer element so that the calculation cost is much lower than\ntraditional finite element method and other high-order element methods. Precise\nIntegration Method provides a higher resolution in time integration and has\nbeen proved to be a stable time integration method with a much lower cut-off\nerror for same and even smaller time step. In this paper, a wavelet finite\nelement model combined with precise integration method is presented for the\nnumerical simulation of ultrasonic wave propagation and crack identification in\n1D structures. Firstly, the wavelet finite element based on BSWI is constructed\nfor rod and beam structures. Then Precise Integrated Method is introduced with\napplication for the wave propagation in 1D structures. Finally, numerical\nexamples of ultrasonic wave propagation in rod and beam structures are\nconducted for verification. Moreover, crack identification in both rod and beam\nstructures are studied based on the new model.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:50:09 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Zhang", "Shuaifang", ""], ["He", "Dongdong", ""], ["Li", "Dongsheng", ""], ["Zhang", "Zhifeng", ""], ["Liu", "Yu", ""], ["Shen", "Wei", ""]]}, {"id": "1712.01978", "submitter": "Debojyoti Ghosh", "authors": "Milo R. Dorr and Phillip Colella and Mikhail A. Dorf and Debojyoti\n  Ghosh and Jeffrey A. F. Hittinger and Peter O. Schwartz", "title": "High-order Discretization of a Gyrokinetic Vlasov Model in Edge Plasma\n  Geometry", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2018.07.008", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a high-order spatial discretization of a continuum gyrokinetic\nVlasov model in axisymmetric tokamak edge plasma geometries. Such models\ndescribe the phase space advection of plasma species distribution functions in\nthe absence of collisions. The gyrokinetic model is posed in a four-dimensional\nphase space, upon which a grid is imposed when discretized. To mitigate the\ncomputational cost associated with high-dimensional grids, we employ a\nhigh-order discretization to reduce the grid size needed to achieve a given\nlevel of accuracy relative to lower-order methods. Strong anisotropy induced by\nthe magnetic field motivates the use of mapped coordinate grids aligned with\nmagnetic flux surfaces. The natural partitioning of the edge geometry by the\nseparatrix between the closed and open field line regions leads to the\nconsideration of multiple mapped blocks, in what is known as a mapped\nmultiblock (MMB) approach. We describe the specialization of a more general\nformalism that we have developed for the construction of high-order,\nfinite-volume discretizations on MMB grids, yielding the accurate evaluation of\nthe gyrokinetic Vlasov operator, the metric factors resulting from the MMB\ncoordinate mappings, and the interaction of blocks at adjacent boundaries. Our\nconservative formulation of the gyrokinetic Vlasov model incorporates the fact\nthat the phase space velocity has zero divergence, which must be preserved\ndiscretely to avoid truncation error accumulation. We describe an approach for\nthe discrete evaluation of the gyrokinetic phase space velocity that preserves\nthe divergence-free property to machine precision.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 00:29:03 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Dorr", "Milo R.", ""], ["Colella", "Phillip", ""], ["Dorf", "Mikhail A.", ""], ["Ghosh", "Debojyoti", ""], ["Hittinger", "Jeffrey A. F.", ""], ["Schwartz", "Peter O.", ""]]}, {"id": "1712.02030", "submitter": "Ryan Hermle", "authors": "Ryan Hermle", "title": "Projection Method for Solving Stokes Flow", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods for numerically solving Stokes Flow, where a small Reynolds\nnumber is assumed to be zero, are investigated. If pressure, horizontal\nvelocity, and vertical velocity can be decoupled into three different\nequations, the numerical solution can be obtained with significantly less\ncomputation cost than when compared to solving a fully coupled system. Two\nexisting methods for numerically solving Stokes Flow are explored: One where\nthe variables can be decoupled and one where they cannot. The existing\ndecoupling method the limitation that the viscosity must be spatially constant.\nA new method is introduced where the variables are decoupled without the\nviscosity limitation. This has potential applications in the modeling of red\nblood cells as vesicles to assist in storage techniques that do not require\nextreme temperatures, such as those needed for cyropreservation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 04:24:09 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 11:11:19 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Hermle", "Ryan", ""]]}, {"id": "1712.02443", "submitter": "Utkarsh R. Patel", "authors": "Utkarsh R. Patel, Piero Triverio, and Sean V. Hum", "title": "A Macromodeling Approach to Efficiently Compute Scattering from Large\n  Arrays of Complex Scatterers", "comments": "Submitted for publication to the IEEE Transactions on Antennas and\n  Propagation on December 6, 2017", "journal-ref": null, "doi": "10.1109/TAP.2018.2866509", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full-wave electromagnetic simulations of electrically large arrays of complex\nantennas and scatterers are challenging, as they consume large amount of memory\nand require long CPU times. This paper presents a new reduced-order modeling\ntechnique to compute scattering and radiation from large arrays of complex\nscatterers and antennas. In the proposed technique, each element of the array\nis replaced by an equivalent electric current distribution on a fictitious\nclosed surface enclosing the element. This equivalent electric current density\nis derived using the equivalence theorem and it is related to the surface\ncurrents on the scatterer by the Stratton-Chu formulation. With the proposed\napproach, instead of directly solving for the unknown surface current density\non the scatterers, we only need to solve for the unknowns on the equivalent\nsurface. This approach leads to a reduction in the number of unknowns and\nbetter conditioning when it is applied to problems involving complex scatterers\nwith multiscale features. Furthermore, the proposed approach is accelerated\nwith the adaptive integral equation method to solve large problems. As\nillustrated in several practical examples, the proposed method yields speed up\nof up to 20 times and consumes up to 12 times less memory than the standard\nmethod of moments accelerated with the adaptive integral method.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 23:38:34 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Patel", "Utkarsh R.", ""], ["Triverio", "Piero", ""], ["Hum", "Sean V.", ""]]}, {"id": "1712.02520", "submitter": "Thomas-Peter Fries", "authors": "Thomas-Peter Fries", "title": "Higher-order surface FEM for incompressible Navier-Stokes flows on\n  manifolds", "comments": "Submitted to International Journal for Numerical Methods in Fluids\n  V1: Initial submission V2: Corrected errors in strong forms, revised\n  discussion of the results", "journal-ref": null, "doi": "10.1002/fld.4510", "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stationary and instationary Stokes and Navier-Stokes flows are considered on\ntwo-dimensional manifolds, i.e., on curved surfaces in three dimensions. The\nhigher-order surface FEM is used for the approximation of the geometry,\nvelocities, pressure, and Lagrange multiplier to enforce tangential velocities.\nIndividual element orders are employed for these various fields. Stream-line\nupwind stabilization is employed for flows at high Reynolds numbers.\nApplications are presented which extend classical benchmark test cases from\nflat domains to general manifolds. Highly accurate solutions are obtained and\nhigher-order convergence rates are confirmed.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 07:31:03 GMT"}, {"version": "v2", "created": "Sun, 25 Mar 2018 16:22:16 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Fries", "Thomas-Peter", ""]]}, {"id": "1712.02860", "submitter": "Amir Ahmadi Javid", "authors": "Amir Ahmadi-Javid and Mohsen Ebadi", "title": "Remarks on Bayesian Control Charts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CE math.OC math.PR q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a considerable amount of ongoing research on the use of Bayesian\ncontrol charts for detecting a shift from a good quality distribution to a bad\nquality distribution in univariate and multivariate processes. It is widely\nclaimed that Bayesian control charts are economically optimal; see, for\nexample, Calabrese (1995) [Bayesian process control for attributes. Management\nScience, DOI: 10.1287/mnsc.41.4.637] and Makis (2008) [Multivariate Bayesian\ncontrol chart. Operations Research, DOI: 10.1287/opre.1070.0495]. Some\nresearchers also generalize the optimality of controls defined based on\nposterior probabilities to the class of partially observable Markov decision\nprocesses. This note points out that the existing Bayesian control charts\ncannot generally be optimal because many years ago an analytical counterexample\nwas provided by Taylor (1965) [Markovian sequential replacement processes. The\nAnnals of Mathematical Statistics, DOI: 10.1214/aoms/1177699796].\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 21:10:27 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 13:22:34 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Ahmadi-Javid", "Amir", ""], ["Ebadi", "Mohsen", ""]]}, {"id": "1712.03052", "submitter": "Huu Phuoc Bui", "authors": "Huu Phuoc Bui, Satyendra Tomar and St\\'ephane P.A. Bordas", "title": "Corotational Cut Finite Element Method for real-time surgical\n  simulation: application to needle insertion simulation", "comments": "25 pages, 25 figures", "journal-ref": null, "doi": "10.1016/j.cma.2018.10.023", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the use of the corotational cut Finite Element Method\n(FEM) for real-time surgical simulation. Users only need to provide a\nbackground mesh which is not necessarily conforming to the\nboundaries/interfaces of the simulated object. The details of the surface,\nwhich can be directly obtained from binary images, are taken into account by a\nmultilevel embedding algorithm applied to elements of the background mesh that\ncut by the surface. Boundary conditions can be implicitly imposed on the\nsurface using Lagrange multipliers. The implementation is verified by\nconvergence studies with optimal rates. The algorithm is applied to various\nneedle insertion simulations (e.g. for biopsy or brachytherapy) into brain and\nliver to verify the reliability of method, and numerical results show that the\npresent method can make the discretisation independent from geometric\ndescription, and can avoid the complexity of mesh generation of complex\ngeometries while retaining the accuracy of the standard FEM. Using the proposed\napproach is very suitable for real-time and patient specific simulations as it\nimproves the simulation accuracy by taking into account automatically and\nproperly the simulated geometry.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 13:22:30 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Bui", "Huu Phuoc", ""], ["Tomar", "Satyendra", ""], ["Bordas", "St\u00e9phane P. A.", ""]]}, {"id": "1712.03599", "submitter": "Stephan Eismann", "authors": "Stephan Eismann, Stefan Bartzsch, Stefano Ermon", "title": "Shape optimization in laminar flow with a label-guided variational\n  autoencoder", "comments": "Contribution to workshop \"Bayesian optimization for science and\n  engineering\" at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational design optimization in fluid dynamics usually requires to solve\nnon-linear partial differential equations numerically. In this work, we explore\na Bayesian optimization approach to minimize an object's drag coefficient in\nlaminar flow based on predicting drag directly from the object shape. Jointly\ntraining an architecture combining a variational autoencoder mapping shapes to\nlatent representations and Gaussian process regression allows us to generate\nimproved shapes in the two dimensional case we consider.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 22:24:02 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Eismann", "Stephan", ""], ["Bartzsch", "Stefan", ""], ["Ermon", "Stefano", ""]]}, {"id": "1712.04386", "submitter": "Amrita Gupta", "authors": "Amrita Gupta, Mehrdad Farajtabar, Bistra Dilkina and Hongyuan Zha", "title": "Hawkes Processes for Invasive Species Modeling and Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.AI cs.CE cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of invasive species to new areas threatens the stability of\necosystems and causes major economic losses in agriculture and forestry. We\npropose a novel approach to minimizing the spread of an invasive species given\na limited intervention budget. We first model invasive species propagation\nusing Hawkes processes, and then derive closed-form expressions for\ncharacterizing the effect of an intervention action on the invasion process. We\nuse this to obtain an optimal intervention plan based on an integer programming\nformulation, and compare the optimal plan against several\necologically-motivated heuristic strategies used in practice. We present an\nempirical study of two variants of the invasive control problem: minimizing the\nfinal rate of invasions, and minimizing the number of invasions at the end of a\ngiven time horizon. Our results show that the optimized intervention achieves\nnearly the same level of control that would be attained by completely\neradicating the species, with a 20% cost saving. Additionally, we design a\nheuristic intervention strategy based on a combination of the density and life\nstage of the invasive individuals, and find that it comes surprisingly close to\nthe optimized strategy, suggesting that this could serve as a good rule of\nthumb in invasive species management.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 16:54:27 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Gupta", "Amrita", ""], ["Farajtabar", "Mehrdad", ""], ["Dilkina", "Bistra", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1712.04523", "submitter": "Jun Wu", "authors": "Jun Wu", "title": "Continuous Optimization of Adaptive Quadtree Structures", "comments": "Solid and Physical Modeling - SPM 2018", "journal-ref": "Computer-Aided Design 102 (2018) 72-82", "doi": "10.1016/j.cad.2018.04.008", "report-no": null, "categories": "math.NA cs.CE cs.GR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel continuous optimization method to the discrete problem of\nquadtree optimization. The optimization aims at achieving a quadtree structure\nwith the highest mechanical stiffness, where the edges in the quadtree are\ninterpreted as structural elements carrying mechanical loads. We formulate\nquadtree optimization as a continuous material distribution problem. The\ndiscrete design variables (i.e., to refine or not to refine) are replaced by\ncontinuous variables on multiple levels in the quadtree hierarchy. In discrete\nquadtree optimization, a cell is only eligible for refinement if its parent\ncell has been refined. We propose a continuous analogue to this dependency for\ncontinuous multi-level design variables, and integrate it in the iterative\noptimization process. Our results show that the continuously optimized quadtree\nstructures perform much stiffer than uniform patterns and the heuristically\noptimized counterparts. We demonstrate the use of adaptive structures as\nlightweight infill for 3D printed parts, where uniform geometric patterns have\nbeen typically used in practice.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 21:13:36 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 08:56:03 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Wu", "Jun", ""]]}, {"id": "1712.04546", "submitter": "Changchuan Yin Dr.", "authors": "Changchuan Yin", "title": "Encoding DNA sequences by integer chaos game representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA sequences are fundamental for encoding genetic information. The genetic\ninformation may not only be understood by symbolic sequences but also from the\nhidden signals inside the sequences. The symbolic sequences need to be\ntransformed into numerical sequences so the hidden signals can be revealed by\nsignal processing techniques. All current transformation methods encode DNA\nsequences into numerical values of the same length. These representations have\nlimitations in the applications of genomic signal compression, encryption, and\nsteganography. We propose an integer chaos game representation (iCGR) of DNA\nsequences and a lossless encoding method DNA sequences by the iCGR. In the iCGR\nmethod, a DNA sequence is represented by the iterated function of the\nnucleotides and their positions in the sequence. Then the DNA sequence can be\nuniquely encoded and recovered using three integers from iCGR. One integer is\nthe sequence length and the other two integers represent the accumulated\ndistributions of nucleotides in the sequence. The integer encoding scheme can\ncompress a DNA sequence by 2 bits per nucleotide. The integer representation of\nDNA sequences provides a prospective tool for sequence compression, encryption,\nand steganography. The Python programs in this study are freely available to\nthe public at https://github.com/cyinbox/iCGR\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 21:50:05 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 15:45:57 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Yin", "Changchuan", ""]]}, {"id": "1712.04612", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "Inverse Reinforcement Learning for Marketing", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning customer preferences from an observed behaviour is an important\ntopic in the marketing literature. Structural models typically model\nforward-looking customers or firms as utility-maximizing agents whose utility\nis estimated using methods of Stochastic Optimal Control. We suggest an\nalternative approach to study dynamic consumer demand, based on Inverse\nReinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL\nthat leads to a highly tractable model formulation that amounts to\nlow-dimensional convex optimization in the search for optimal model parameters.\nUsing simulations of consumer demand, we show that observational noise for\nidentical customers can be easily confused with an apparent consumer\nheterogeneity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 05:46:22 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "1712.05012", "submitter": "Morad Behandish", "authors": "Pouya Tavousi, Morad Behandish, Horea T. Ilies, and Kazem Kazerounian", "title": "Protofold II: Enhanced Model and Implementation for Kinetostatic Protein\n  Folding", "comments": "Shorter versions were presented in two conference papers in ASME\n  International Design Engineering Technical Conferences (IDETC'2013)", "journal-ref": "ASME Transactions, Journal of Nanotechnology in Engineering and\n  Medicine, 6(3), p.034601, 2016", "doi": "10.1115/1.4032759", "report-no": "CDL-TR-16-03", "categories": "cs.CE cs.DC cs.DS cs.RO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reliable prediction of 3D protein structures from sequence data remains a\nbig challenge due to both theoretical and computational difficulties. We have\npreviously shown that our kinetostatic compliance method (KCM) implemented into\nthe Protofold package can overcome some of the key difficulties faced by other\nde novo structure prediction methods, such as the very small time steps\nrequired by the molecular dynamics (MD) approaches or the very large number of\nsamples needed by the Monte Carlo (MC) sampling techniques. In this article, we\nimprove the free energy formulation used in Protofold by including the\ntypically underrated entropic effects, imparted due to differences in\nhydrophobicity of the chemical groups, which dominate the folding of most\nwater-soluble proteins. In addition to the model enhancement, we revisit the\nnumerical implementation by redesigning the algorithms and introducing\nefficient data structures that reduce the expected complexity from quadratic to\nlinear. Moreover, we develop and optimize parallel implementations of the\nalgorithms on both central and graphics processing units (CPU/GPU) achieving\nspeed-ups up to two orders of magnitude on the GPU. Our simulations are\nconsistent with the general behavior observed in the folding process in aqueous\nsolvent, confirming the effectiveness of model improvements. We report on the\nfolding process at multiple levels; namely, the formation of secondary\nstructural elements and tertiary interactions between secondary elements or\nacross larger domains. We also observe significant enhancements in running\ntimes that make the folding simulation tractable for large molecules.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 11:36:29 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Tavousi", "Pouya", ""], ["Behandish", "Morad", ""], ["Ilies", "Horea T.", ""], ["Kazerounian", "Kazem", ""]]}, {"id": "1712.05594", "submitter": "Uwe K\\\"ocher", "authors": "Uwe K\\\"ocher", "title": "Influence of the SIPG penalisation on the numerical properties of linear\n  systems for elastic wave propagation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-96415-7_18", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interior penalty discontinuous Galerkin discretisations (IPDG) and especially\nthe symmetric variant (SIPG) for time-domain wave propagation problems are\nbroadly accepted and widely used due to their advantageous properties. Linear\nsystems with block structure arise by applying space-time discretisations and\nreducing the global system to time-slab problems. The design of efficient and\nrobust iterative solvers for linear systems from interior penalty\ndiscretisations for hyperbolic wave equations is still a challenging task and\nrelies on understanding the properties of the systems. In this work the\nnumerical properties such as the condition number and the distribution of\neigenvalues of different representations of the linear systems coming from\nspace-time discretisations for elastic wave propagation are numerically\nstudied. These properties for interior penalty discretisations depend on the\npenalisation and on the time interval length.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 09:44:34 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["K\u00f6cher", "Uwe", ""]]}, {"id": "1712.05936", "submitter": "Yasemin Ozkan Aydin", "authors": "Yasemin Ozkan Aydin, Kemal Leblebicioglu", "title": "A fast and practical grid based algorithm for point-feature label\n  placement problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-feature label placement (PFLP) is a major area of interest within the\nfiled of automated cartography, geographic information systems (GIS), and\ncomputer graphics. The objective of a label placement problem is to assign a\nlabel to each point feature so as to avoid conflicts, considering the\ncartographic conventions. According to computational complexity analysis, the\nlabeling problem has been shown to be NP-Hard. It is also very challenging to\nfind a computationally efficient algorithm that is intended to be used for both\nstatic and dynamic map labeling. In this paper, we propose a heuristic method\nthat first fills the free space of the map with rectangular shape labels like a\ngrid and then matches the corresponding point feature with the nearest label.\nThe performance of the proposed algorithm was evaluated through empirical tests\nwith different data set sizes. The results show that our algorithm based on\ngrid placement of labels is a useful, fast and practical solution for automated\nmap labeling.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 10:48:47 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Aydin", "Yasemin Ozkan", ""], ["Leblebicioglu", "Kemal", ""]]}, {"id": "1712.06091", "submitter": "Eran Treister", "authors": "Eran Treister and Eldad Haber", "title": "A multigrid solver to the Helmholtz equation with a point source based\n  on travel time and amplitude", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Helmholtz equation arises when modeling wave propagation in the frequency\ndomain. The equation is discretized as an indefinite linear system, which is\ndifficult to solve at high wave numbers. In many applications, the solution of\nthe Helmholtz equation is required for a point source. In this case, it is\npossible to reformulate the equation as two separate equations: one for the\ntravel time of the wave and one for its amplitude. The travel time is obtained\nby a solution of the factored eikonal equation, and the amplitude is obtained\nby solving a complex-valued advection-diffusion-reaction (ADR) equation. The\nreformulated equation is equivalent to the original Helmholtz equation, and the\ndifferences between the numerical solutions of these equations arise only from\ndiscretization errors. We develop an efficient multigrid solver for obtaining\nthe amplitude given the travel time, which can be efficiently computed. This\napproach is advantageous because the amplitude is typically smooth in this\ncase, and hence, more suitable for multigrid solvers than the standard\nHelmholtz discretization. We demonstrate that our second order ADR\ndiscretization is more accurate than the standard second order discretization\nat high wave numbers, as long as there are no reflections or caustics.\nMoreover, we show that using our approach, the problem can be solved more\nefficiently than using the common shifted Laplacian multigrid approach.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 11:44:36 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Treister", "Eran", ""], ["Haber", "Eldad", ""]]}, {"id": "1712.06173", "submitter": "Antonio Huerta Prof.", "authors": "Ruben Sevilla, Matteo Giacomini and Antonio Huerta", "title": "A face-centred finite volume method for second-order elliptic problems", "comments": "43 pages, 33 figures, 3 tables", "journal-ref": "Int. J. Numer. Methods Eng., Vol. 115, Issue 8, pp. 986-1014\n  (2018)", "doi": "10.1002/nme.5833", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel finite volume paradigm, the face-centred finite\nvolume (FCFV) method. Contrary to the popular vertex (VCFV) and cell (CCFV)\ncentred finite volume methods, the novel FCFV defines the solution on the mesh\nfaces (edges in 2D) to construct locally-conservative numerical schemes.\n  The idea of the FCFV method stems from a hybridisable discontinuous Galerkin\n(HDG) formulation with constant degree of approximation, thus inheriting the\nconvergence properties of the classical HDG. The resulting FCFV features a\nglobal problem in terms of a piecewise constant function defined on the faces\nof the mesh. The solution and its gradient in each element are then recovered\nby solving a set of independent element-by-element problems.\n  The mathematical formulation of FCFV for Poisson and Stokes equation is\nderived and numerical evidence of optimal convergence in 2D and 3D is provided.\nNumerical examples are presented to illustrate the accuracy, efficiency and\nrobustness of the proposed methodology. The results show that, contrary to\nother FV methods, the accuracy of the FCFV method is not sensitive to mesh\ndistortion and stretching. In addition, the FCFV method shows its better\nperformance, accuracy and robustness using simplicial elements, facilitating\nits application to problems involving complex geometries in 3D.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 20:08:52 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Sevilla", "Ruben", ""], ["Giacomini", "Matteo", ""], ["Huerta", "Antonio", ""]]}, {"id": "1712.06251", "submitter": "Shuaifang Zhang", "authors": "Shuaifang Zhang, Dongsheng Li, Wei Shen, Xiwen Zhang, Yu Liu", "title": "Crack detection in beam structures with a novel Laplace based Wavelet\n  Finite Element method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam structure is one of the most widely used structures in mechanical\nengineering and civil engineering. Ultrasonic guided wave based crack\nidentification is one of the most important and accepted approaches applied to\ndetect unseen small flaws in structures. Numerical simulations of ultrasonic\nguided wave propagation have caught more and more attention due to the fast\ndevelopment of hardware and software in the last few years. From all the\nnumerical simulation methods, wavelet based finite element method has been\nproved to be one of the most efficient methods due to its better spatial\nresolution, which means it needs fewer elements to get the same accuracy and it\ncan improve the calculation cost significantly. However, it needs a very small\ntime interval. Laplace transform can easily convert the time domain into a\nfrequency domain and then revert it back to a time domain. Laplace transform\nhas thus the advantage of finding better results with a very large time\ninterval. which can save a lot of time cost. This paper will present an\ninnovative method combining Laplace transform and the B-spline wavelet on\ninterval (BSWI) finite element method. This novel method allows to get results\nwith the same accuracy and with a significantly lower time cost, which would\nnot only decrease the total number of elements in the structure but also\nincrease the time integration interval. The numerical Laplace transform and\nBSWI finite element will be introduced. Moreover, this innovative method is\napplied to simulate the ultrasonic wave propagation in a beam structure in\ndifferent materials. Numerical examples for crack identification in beam\nstructures have been studied for verification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 05:16:37 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Zhang", "Shuaifang", ""], ["Li", "Dongsheng", ""], ["Shen", "Wei", ""], ["Zhang", "Xiwen", ""], ["Liu", "Yu", ""]]}, {"id": "1712.07206", "submitter": "Edoardo Di Napoli", "authors": "Davor Davidovi\\'c, Diego Fabregat-Traver, Markus H\\\"ohnerbach, and\n  Edoardo di Napoli", "title": "Accelerating the computation of FLAPW methods on heterogeneous\n  architectures", "comments": "22 pages, submitted to special issue of CCPE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legacy codes in computational science and engineering have been very\nsuccessful in providing essential functionality to researchers. However, they\nare not capable of exploiting the massive parallelism provided by emerging\nheterogeneous architectures. The lack of portable performance and scalability\nputs them at high risk: either they evolve or they are doomed to disappear. One\nexample of legacy code which would heavily benefit from a modern design is\nFLEUR, a software for electronic structure calculations. In previous work, the\ncomputational bottleneck of FLEUR was partially re-engineered to have a modular\ndesign that relies on standard building blocks, namely BLAS and LAPACK. In this\npaper, we demonstrate how the initial redesign enables the portability to\nheterogeneous architectures. More specifically, we study different approaches\nto port the code to architectures consisting of multi-core CPUs equipped with\none or more coprocessors such as Nvidia GPUs and Intel Xeon Phis. Our final\ncode attains over 70\\% of the architectures' peak performance, and outperforms\nNvidia's and Intel's libraries. Finally, on JURECA, the supercomputer where\nFLEUR is often executed, the code takes advantage of the full power of the\ncomputing nodes, attaining $5\\times$ speedup over the sole use of the CPUs.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:58:08 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Davidovi\u0107", "Davor", ""], ["Fabregat-Traver", "Diego", ""], ["H\u00f6hnerbach", "Markus", ""], ["di Napoli", "Edoardo", ""]]}, {"id": "1712.07223", "submitter": "Dimitrios Loukrezis", "authors": "Dimitrios Loukrezis, Ulrich R\\\"omer, and Herbert De Gersem", "title": "Assessing the Performance of Leja and Clenshaw-Curtis Collocation for\n  Computational Electromagnetics with Random Input Data", "comments": "27 pages, 11 figures, 2 tables", "journal-ref": null, "doi": "10.1615/Int.J.UncertaintyQuantification.2018025234", "report-no": null, "categories": "cs.CE cs.NA math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quantifying uncertainty regarding the output of an\nelectromagnetic field problem in the presence of a large number of uncertain\ninput parameters. In order to reduce the growth in complexity with the number\nof dimensions, we employ a dimension-adaptive stochastic collocation method\nbased on nested univariate nodes. We examine the accuracy and performance of\ncollocation schemes based on Clenshaw-Curtis and Leja rules, for the cases of\nuniform and bounded, non-uniform random inputs, respectively. Based on\nnumerical experiments with an academic electromagnetic field model, we compare\nthe two rules in both the univariate and multivariate case and for both\nquadrature and interpolation purposes. Results for a real-world electromagnetic\nfield application featuring high-dimensional input uncertainty are also\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 21:28:26 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:07:20 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Loukrezis", "Dimitrios", ""], ["R\u00f6mer", "Ulrich", ""], ["De Gersem", "Herbert", ""]]}, {"id": "1712.07392", "submitter": "Eirik Keilegavlen", "authors": "Eirik Keilegavlen, Alessio Fumagalli, Runar Berge, Ivar Stefansson", "title": "Implementation of mixed-dimensional models for flow in fractured porous\n  media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that involve coupled dynamics in a mixed-dimensional geometry are of\nincreasing interest in several applications. Here, we describe the development\nof a simulation model for flow in fractured porous media, where the fractures\nand their intersections form a hierarchy of interacting subdomains. We discuss\nthe implementation of a simulation framework, with an emphasis on reuse of\nexisting discretization tools for mono-dimensional problems. The key\ningredients are the representation of the mixed-dimensional geometry as a\ngraph, which allows for convenient discretization and data storage, and a\nnon-intrusive coupling of dimensions via boundary conditions and source terms.\nThis approach is applicable for a wide class of mixed-dimensional problems. We\nshow simulation results for a flow problem in a three-dimensional fracture\ngeometry, applying both finite volume and virtual finite element\ndiscretizations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 10:14:31 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Keilegavlen", "Eirik", ""], ["Fumagalli", "Alessio", ""], ["Berge", "Runar", ""], ["Stefansson", "Ivar", ""]]}, {"id": "1712.08037", "submitter": "Hamid Foroughi", "authors": "Hamid Foroughi and Benjamin W. Schafer", "title": "Simulation of conventional cold-formed steel sections formed from\n  Advanced High Strength Steel (AHSS)", "comments": null, "journal-ref": "Annual Stability Conference Structural Stability Research Council,\n  At San Antonio, 2017", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to explore the potential impact of the use of\nadvanced high strength steel (AHSS) to form traditional cold-formed steel\nstructural members. In this study, shell finite element models are constructed,\nand geometric and material nonlinear collapse analysis performed, on simulated\nlipped channel cross-section cold-formed steel members roll-formed from AHSS.\nAHSS sheet is currently being used in automotive applications with thickness\nranging from 0.35 to 0.8 mm (0.0138 to 0.0315 in.) and yield strengths from 350\nto 1250 MPa (51 to 181 ksi). However, AHSS has not yet been employed in\ncold-formed steel construction. To assess the impact of the adoption of AHSS on\ncold-formed steel member strength a group of forty standard structural lipped\nchannel cross-sections are chosen from the Steel Framing Industry Association\nproduct list and simulated with AHSS material properties. The stress-strain\nmodels used in this study are based on AHSS in production, including dual-phase\nand martensitic steels. The simulations consider compression with work on\nbending about the major axis in progress. Three different bracing conditions\nare employed so that the impact of local, distortional, and global buckling,\nincluding interactions can be explored. Due to the higher yield stresses of\nAHSS the potential for interaction and mode switching is anticipated to be\ngreater in these members compared with conventional mild steels. The\nsimulations provide a direct means to assess the increase in strength created\nby the application of AHSS, while also allowing for future exploration of the\nincrease in buckling mode interaction, imperfection sensitivity, and strain\ndemands inherent in the larger capacities. The work is intended to be an\ninitial step in a longer-term effort to foster innovation in the application of\nnew steels in cold-formed steel construction.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 16:02:50 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Foroughi", "Hamid", ""], ["Schafer", "Benjamin W.", ""]]}, {"id": "1712.09592", "submitter": "Murat Ozbayoglu", "authors": "O.B. Sezer, M. Ozbayoglu, E. Dogdu", "title": "An Artificial Neural Network-based Stock Trading System Using Technical\n  Analysis and Big Data Framework", "comments": "ACM Southeast Conference, ACMSE 2017, Kennesaw State University, GA,\n  U.S.A., 13-15 April, 2017", "journal-ref": "ACM Southeast Conference, ACMSE 2017, Kennesaw State University,\n  GA, U.S.A., 13-15 April, 2017", "doi": "10.1145/3077286.3077294", "report-no": null, "categories": "cs.CE q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a neural network-based stock price prediction and trading\nsystem using technical analysis indicators is presented. The model developed\nfirst converts the financial time series data into a series of buy-sell-hold\ntrigger signals using the most commonly preferred technical analysis\nindicators. Then, a Multilayer Perceptron (MLP) artificial neural network (ANN)\nmodel is trained in the learning stage on the daily stock prices between 1997\nand 2007 for all of the Dow30 stocks. Apache Spark big data framework is used\nin the training stage. The trained model is then tested with data from 2007 to\n2017. The results indicate that by choosing the most appropriate technical\nindicators, the neural network model can achieve comparable results against the\nBuy and Hold strategy in most of the cases. Furthermore, fine tuning the\ntechnical indicators and/or optimization strategy can enhance the overall\ntrading performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 14:45:40 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Sezer", "O. B.", ""], ["Ozbayoglu", "M.", ""], ["Dogdu", "E.", ""]]}, {"id": "1712.10191", "submitter": "Sebastian Sch\\\"ops", "authors": "Micha{\\l} Maciejewski and Pascal Bayrasy and Klaus Wolf and Micha{\\l}\n  Wilczek and Bernhard Auchmann and Tina Griesemer and Lorenzo Bortot and Marco\n  Prioli and Alejandro Manuel Fernandez Navarro and Sebastian Sch\\\"ops and\n  Idoia Cortes Garcia and Arjan Verweij", "title": "Coupling of Magneto-Thermal and Mechanical Superconducting Magnet Models\n  by Means of Mesh-Based Interpolation", "comments": "5 pages, 6 figures", "journal-ref": "IEEE Transactions on Applied Superconductivity 28.3 (Apr. 2018).\n  issn: 1051-8223", "doi": "10.1109/TASC.2017.2786721", "report-no": null, "categories": "physics.acc-ph cs.CE math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an algorithm for the coupling of magneto-thermal and\nmechanical finite element models representing superconducting accelerator\nmagnets. The mechanical models are used during the design of the mechanical\nstructure as well as the optimization of the magnetic field quality under\nnominal conditions. The magneto-thermal models allow for the analysis of\ntransient phenomena occurring during quench initiation, propagation, and\nprotection. Mechanical analysis of quenching magnets is of high importance\nconsidering the design of new protection systems and the study of new\nsuperconductor types. We use field/circuit coupling to determine temperature\nand electromagnetic force evolution during the magnet discharge. These\nquantities are provided as a load to existing mechanical models. The models are\ndiscretized with different meshes and, therefore, we employ a mesh-based\ninterpolation method to exchange coupled quantities. The coupling algorithm is\nillustrated with a simulation of a mechanical response of a standalone\nhigh-field dipole magnet protected with CLIQ (Coupling-Loss Induced Quench)\ntechnology.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 11:47:41 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Maciejewski", "Micha\u0142", ""], ["Bayrasy", "Pascal", ""], ["Wolf", "Klaus", ""], ["Wilczek", "Micha\u0142", ""], ["Auchmann", "Bernhard", ""], ["Griesemer", "Tina", ""], ["Bortot", "Lorenzo", ""], ["Prioli", "Marco", ""], ["Navarro", "Alejandro Manuel Fernandez", ""], ["Sch\u00f6ps", "Sebastian", ""], ["Garcia", "Idoia Cortes", ""], ["Verweij", "Arjan", ""]]}]