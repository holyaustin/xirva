[{"id": "1901.00202", "submitter": "Vladim\\'ir Luke\\v{s}", "authors": "Eduard Rohan and Vladim\\'ir Luke\\v{s}", "title": "Homogenization of the vibro-acoustic transmission on perforated plates", "comments": "This manuscript version is made available under the CC-BY-NC-ND 4.0\n  license", "journal-ref": "Applied Mathematics and Computation, 361: 821-845 (2019)", "doi": "10.1016/j.amc.2019.06.005", "report-no": null, "categories": "physics.comp-ph cs.CE math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with modelling of acoustic waves which propagate in inviscid\nfluids interacting with perforated elastic plates. The plate can be replaced by\nan interface on which transmission conditions are derived by homogenization of\na problem describing vibroacoustic fluid-structure interactions in a\ntransmission layer in which the plate is embedded. The Reissner-Mindlin theory\nof plates is adopted for periodic perforations designed by arbitrary\ncylindrical holes with axes orthogonal to the plate midplane. The homogenized\nmodel of the vibroacoustic transmission is obtained using the two-scale\nasymptotic analysis with respect to the layer thickness which is proportional\nto the plate thickness and to the perforation period. The nonlocal, implicit\ntransmission conditions involve a jump in the acoustic potential and its normal\none-side derivatives across the interface which represents the plate with a\ngiven thickness. The homogenized model was implemented using the finite element\nmethod and validated using direct numerical simulations of the non-homogenized\nproblem. Numerical illustrations of the vibroacoustic transmission are\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2019 19:23:03 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Rohan", "Eduard", ""], ["Luke\u0161", "Vladim\u00edr", ""]]}, {"id": "1901.00229", "submitter": "Graciela Del Socorro Herrera Zamarr\\'on", "authors": "Ismael Herrera-Revilla, Iv\\'an Contreras and Graciela S. Herrera\n  (Instituto de Geof\\'isica, Universidad Nacional Aut\\'onoma de M\\'exico\n  (UNAM), Mexico City, Mexico)", "title": "The Divide-and-Conquer Framework: A Suitable Setting for the DDM of the\n  Future", "comments": "14 pages without figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper was prompted by numerical experiments we performed, in which\nalgorithms already available in the literature (DVS-BDDM) yielded accelerations\n(or speedups) many times larger (more than seventy in some examples already\ntreated, but probably often much larger) than the number of processors used.\nBased on these outstanding results, here it is shown that believing in the\nstandard ideal speedup, which is taken to be equal to the number of processors,\nhas limited much the performance goal sought by research on domain\ndecomposition methods (DDM) and has hindered much its development, thus far.\nHence, an improved theory in which the speedup goal is based on the Divide and\nConquer algorithmic paradigm, frequently considered as the leitmotiv of domain\ndecomposition methods, is proposed as a suitable setting for the DDM of the\nfuture.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 01:32:39 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Herrera-Revilla", "Ismael", "", "Instituto de Geof\u00edsica, Universidad Nacional Aut\u00f3noma de M\u00e9xico"], ["Contreras", "Iv\u00e1n", "", "Instituto de Geof\u00edsica, Universidad Nacional Aut\u00f3noma de M\u00e9xico"], ["Herrera", "Graciela S.", "", "Instituto de Geof\u00edsica, Universidad Nacional Aut\u00f3noma de M\u00e9xico"]]}, {"id": "1901.00592", "submitter": "EPTCS", "authors": "Ioana Cristescu (Department of Systems Biology, Harvard Medical\n  School, Boston, USA), Walter Fontana (Department of Systems Biology, Harvard\n  Medical School, Boston, USA), Jean Krivine (IRIF, CNRS and Paris Diderot\n  University)", "title": "Interactions between Causal Structures in Graph Rewriting Systems", "comments": "In Proceedings CREST 2018, arXiv:1901.00073", "journal-ref": "EPTCS 286, 2019, pp. 65-78", "doi": "10.4204/EPTCS.286.6", "report-no": null, "categories": "cs.LO cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph rewrite formalisms are a powerful approach to modeling complex\nmolecular systems. They capture the intrinsic concurrency of molecular\ninteractions, thereby enabling a formal notion of mechanism (a partially\nordered set of events) that explains how a system achieves a particular outcome\ngiven a set of rewrite rules. It is then useful to verify whether the\nmechanisms that emerge from a given model comply with empirical observations\nabout their mutual interference. In this work, our objective is to determine\nwhether a specific event in the mechanism for achieving X prevents or promotes\nthe occurrence of a specific event in the mechanism for achieving Y. Such\nchecks might also be used to hypothesize rules that would bring model\nmechanisms in compliance with observations. We define a rigorous framework for\ndefining the concept of interference (positive or negative) between mechanisms\ninduced by a system of graph-rewrite rules and for establishing whether an\nasserted influence can be realized given two mechanisms as an input.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:53:21 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Cristescu", "Ioana", "", "Department of Systems Biology, Harvard Medical\n  School, Boston, USA"], ["Fontana", "Walter", "", "Department of Systems Biology, Harvard\n  Medical School, Boston, USA"], ["Krivine", "Jean", "", "IRIF, CNRS and Paris Diderot\n  University"]]}, {"id": "1901.00725", "submitter": "Jan Helmig", "authors": "Jan Helmig, Marek Behr, Stefanie Elgeti", "title": "Boundary-Conforming Finite Element Methods for Twin-Screw Extruders:\n  Unsteady - Temperature-Dependent - Non-Newtonian Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a boundary-conforming space-time finite element method to compute\nthe flow inside co-rotating, self-wiping twin-screw extruders. The mesh update\nis carried out using the newly developed Snapping Reference Mesh Update Method\n(SRMUM). It allows to compute time-dependent flow solutions inside twin-screw\nextruders equipped with conveying screw elements without any need for\nre-meshing and projections of solutions - making it a very efficient method. We\nprovide cases for Newtonian and non-Newtonian fluids in 2D and 3D, that show\nmesh convergence of the solution as well as agreement to experimental results.\nFurthermore, a complex, unsteady and temperature-dependent 3D test case with\nmultiple screw elements illustrates the potential of the method also for\nindustrial applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 18:06:24 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Helmig", "Jan", ""], ["Behr", "Marek", ""], ["Elgeti", "Stefanie", ""]]}, {"id": "1901.00759", "submitter": "Sebastian Sch\\\"ops", "authors": "Annalisa Buffa, Jacopo Corno, Carlo de Falco, Sebastian Sch\\\"ops,\n  Rafael V\\'azquez", "title": "Isogeometric Mortar Coupling for Electromagnetic Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses and analyses two domain decomposition approaches for\nelectromagnetic problems that allow the combination of domains discretised by\neither N\\'ed\\'elec-type polynomial finite elements or spline-based isogeometric\nanalysis. The first approach is a new isogeometric mortar method and the second\none is based on a modal basis for the Lagrange multiplier space, called\nstate-space concatenation in the engineering literature. Spectral correctness\nand in particular inf-sup stability of both approaches are analytically and\nnumerically investigated. The new mortar method is shown to be unconditionally\nstable. Its construction of the discrete Lagrange multiplier space takes\nadvantage of the high continuity of splines, and does not have an analogue for\nN\\'ed\\'elec finite elements. On the other hand, the approach with modal basis\nis easier to implement but relies on application knowledge to ensure stability\nand correctness.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 20:10:54 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Buffa", "Annalisa", ""], ["Corno", "Jacopo", ""], ["de Falco", "Carlo", ""], ["Sch\u00f6ps", "Sebastian", ""], ["V\u00e1zquez", "Rafael", ""]]}, {"id": "1901.01144", "submitter": "Yun Feng", "authors": "Yun Feng, Bing-Chuan Wang", "title": "A unified framework of epidemic spreading prediction by empirical mode\n  decomposition based ensemble learning techniques", "comments": "Some issues need to be addressed in this manuscript", "journal-ref": null, "doi": "10.1109/TCSS.2019.2915615", "report-no": null, "categories": "cs.CE cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a unified susceptible-exposed-infected-susceptible-aware\n(SEIS-A) framework is proposed to combine epidemic spreading with individuals'\non-line self-consultation behaviors. An epidemic spreading prediction model is\nestablished based on the SEIS-A framework. The prediction process contains two\nphases. In phase I, the time series data of disease density are decomposed\nthrough the empirical mode decomposition (EMD) method to obtain the intrinsic\nmode functions (IMFs). In phase II, the ensemble learning techniques which use\nthe on-line query data as an additional input are applied to these IMFs.\nFinally, experiments for prediction of weekly consultation rates of\nHand-foot-and-mouth disease (HFMD) in Hong Kong are conducted to validate the\neffectiveness of the proposed method. The main advantage of this method is that\nit outperforms other methods on fluctuating complex data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 02:49:57 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 12:08:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Feng", "Yun", ""], ["Wang", "Bing-Chuan", ""]]}, {"id": "1901.02145", "submitter": "Yu Song", "authors": "Yu Song, Shengping Gong", "title": "Solar-Sail Deep Space Trajectory Optimization Using Successive Convex\n  Programming", "comments": "25 pages, 10 figures (This is a pre-print of an article accepted in\n  Astrophysics and Space Science. The final authenticated version will be\n  available online at: https://doi.org/10.1007/s10509-019-3597-x)", "journal-ref": "Astrophysics and Space Science 364 (2019) 106", "doi": "10.1007/s10509-019-3597-x", "report-no": null, "categories": "cs.CE cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel methodology for solving the time-optimal\ntrajectory optimization problem for interplanetary solar-sail missions using\nsuccessive convex programming. Based on the non-convex problem, different\nconvexification technologies, such as change of variables, successive\nlinearization, trust regions and virtual control, are discussed to convert the\noriginal problem into the formulation of successive convex programming. Because\nof the free final-time, successive linearization is performed iteratively for\nthe nonconvex terminal state constraints. After the convexification process,\neach of problems becomes a convex problem, which can be solved effectively. An\naugmented objective function is introduced to ensure the convergence\nperformance and effectiveness of our algorithm. After that, algorithms are\ndesigned to solve the discrete sub-problems in a successive solution procedure.\nFinally, numerical results demonstrate the effectiveness and accuracy of our\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 03:48:47 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 15:49:10 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Song", "Yu", ""], ["Gong", "Shengping", ""]]}, {"id": "1901.02172", "submitter": "Yu Song", "authors": "Yu Song, Shengping Gong", "title": "Solar-Sail Trajectory Design for Multiple Near Earth Asteroid\n  Exploration Based on Deep Neural Networks", "comments": "34 pages, 19 figures", "journal-ref": "Aerospace Scienceand Technology 91 (2019) 28-40", "doi": "10.1016/j.ast.2019.04.056", "report-no": null, "categories": "cs.CE astro-ph.IM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the preliminary trajectory design of the multi-target rendezvous problem,\na model that can quickly estimate the cost of the orbital transfer is\nessential. The estimation of the transfer time using solar sail between two\narbitrary orbits is difficult and usually requires to solve an optimal control\nproblem. Inspired by the successful applications of the deep neural network in\nnonlinear regression, this work explores the possibility and effectiveness of\nmapping the transfer time for solar sail from the orbital characteristics using\nthe deep neural network. Furthermore, the Monte Carlo Tree Search method is\ninvestigated and used to search the optimal sequence considering a\nmulti-asteroid exploration problem. The obtained sequences from preliminary\ndesign will be solved and verified by sequentially solving the optimal control\nproblem. Two examples of different application backgrounds validate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 06:40:13 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 14:51:26 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 07:24:16 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Song", "Yu", ""], ["Gong", "Shengping", ""]]}, {"id": "1901.02315", "submitter": "Kae-An Liu", "authors": "Kae-An Liu, Hans-Dieter Lang and Costas D. Sarris", "title": "Computation of High-Order Electromagnetic Field Derivatives with FDTD\n  and the Complex-Step Derivative Approximation", "comments": "Submitted to IEEE Transactions on Antennas and Propagation\n  (Aug-31-2018)", "journal-ref": null, "doi": "10.1109/TAP.2019.2905693", "report-no": null, "categories": "cs.NA cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach for the computation of electromagnetic\nfield derivatives, up to any order, with respect to the material and geometric\nparameters of a given geometry, in a single Finite-Difference Time-Domain\n(FDTD) simulation. The proposed method is based on embedding the complex-step\nderivative (CSD) approximation into the standard FDTD update equations. Being\nfinite-difference free, CSD provides accurate derivative approximations even\nfor very small perturbations of the design parameters, unlike finite-difference\napproximations that are prone to subtractive cancellation errors. The\navailability of accurate approximations of field derivatives with respect to\ndesign parameters enables studies such as sensitivity analysis of multiple\nobjective functions (as derivatives of those can be derived from field\nderivatives via the chain rule), uncertainty quantification, as well as\nmulti-parametric modeling and optimization of electromagnetic structures. The\ntheory, FDTD implementation and applications of this technique are presented.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 14:12:30 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Liu", "Kae-An", ""], ["Lang", "Hans-Dieter", ""], ["Sarris", "Costas D.", ""]]}, {"id": "1901.02364", "submitter": "Shantanu Shahane", "authors": "Shantanu Shahane, Narayana Aluru, Placid Ferreira, Shiv G Kapoor,\n  Surya Pratap Vanka", "title": "Optimization of Solidification in Die Casting using Numerical\n  Simulations and Machine Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmapro.2020.01.016", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the combination of machine learning and three\ndimensional numerical simulations for multi-objective optimization of low\npressure die casting. The cooling of molten metal inside the mold is achieved\ntypically by passing water through the cooling lines in the die. Depending on\nthe cooling line location, coolant flow rate and die geometry, nonuniform\ntemperatures are imposed on the molten metal at the mold wall. This boundary\ncondition along with the initial molten metal temperature affect the product\nquality quantified in terms of micro-structure parameters and yield strength. A\nfinite volume based numerical solver is used to determine the temperature-time\nhistory and correlate the inputs to outputs. The objective of this research is\nto develop and demonstrate a procedure to obtain the initial and wall\ntemperatures so as to optimize the product quality. The non-dominated sorting\ngenetic algorithm (NSGA-II) is used for multi-objective optimization in this\nwork. The number of function evaluations required for NSGA-II can be of the\norder of millions and hence, the finite volume solver cannot be used directly\nfor optimization. Therefore, a multilayer perceptron feed-forward neural\nnetwork is first trained using the results from the numerical solution of the\nfluid flow and energy equations and is subsequently used as a surrogate model.\nAs an assessment, simplified versions of the actual problem are designed to\nfirst verify results of the genetic algorithm. An innovative local sensitivity\nbased approach is then used to rank the final Pareto optimal solutions and\nselect a single best design.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 15:28:33 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 17:57:04 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shahane", "Shantanu", ""], ["Aluru", "Narayana", ""], ["Ferreira", "Placid", ""], ["Kapoor", "Shiv G", ""], ["Vanka", "Surya Pratap", ""]]}, {"id": "1901.02716", "submitter": "Jian Zhou Dr", "authors": "Jian Guo Zhou", "title": "Macroscopic Lattice Boltzmann Method (MacLAB)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The birth of the lattice Boltzmann method (LBM) fulfils a dream that simple\narithmetic calculations can simulate complex fluid flows without solving\ncomplicated partial differential flow equations. Its power and potential of\nresolving more and more challenging physical problems have been and are being\ndemonstrated in science and engineering covering a wide range of disciplines\nsuch as physics, chemistry, biology, material science and image analysis. The\nmethod is a highly simplified model for fluid flows using a few limited\nfictitious particles that move one grid at a constant time interval and collide\neach other at a grid point on uniform lattices, which are the two routine steps\nfor implementation of the method to simulate fluid flows. As such, a real\ncomplex particle dynamics is approximated as a regular particle model using\nthree parameters of lattice size, particle speed and collision operator. A\nfundamental question is \"Are the two steps integral to the method or can the\nthree parameters be reduced to one for a minimal lattice Boltzmann method?\".\nHere, I show that the collision step can be removed and the standard LBM can be\nreformulated into a simple macroscopic lattice Boltzmann method (MacLAB). This\nmodel relies on macroscopic physical variables only and is completely defined\nby one basic parameter of lattice size dx, bringing the LBM into a precise\n\"Lattice\" Boltzmann method. The viscous effect on flows is naturally embedded\nthrough the particle speed, making it an ideal automatic simulator for fluid\nflows. The findings have been demonstrated and confirmed with numerical tests\nincluding flows that are independent of and dependent on fluid viscosity, 2D\nand 3D cavity flows, and an unsteady Taylor-Green vortex flow. This provides an\nefficient and powerful model for resolving physical problems in various\ndisciplines of science and engineering.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 17:31:39 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Zhou", "Jian Guo", ""]]}, {"id": "1901.03304", "submitter": "Paul Hines", "authors": "Laurence A. Clarfeld, Paul D.H. Hines, Eric M. Hernandez, and Margaret\n  J. Eppstein", "title": "Risk of Cascading Blackouts Given Correlated Component Outages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascading blackouts typically occur when nearly simultaneous outages occur in\nk out of N components in a power system, triggering subsequent failures that\npropagate through the network and cause significant load shedding. While large\ncascades are rare, their impact can be catastrophic, so quantifying their risk\nis important for grid planning and operation. A common assumption in previous\napproaches to quantifying such risk is that the $k$ initiating component\noutages are statistically independent events. However, when triggered by a\ncommon exogenous cause, initiating outages may actually be correlated. Here,\ncopula analysis is used to quantify the impact of correlation of initiating\noutages on the risk of cascading failure. The method is demonstrated on two\ntest cases; a 2383-bus model of the Polish grid under varying load conditions\nand a synthetic 10,000-bus model based on the geography of the Western US. The\nlarge size of the Western US test case required development of new approaches\nfor bounding an estimate of the total number of N-3 blackout-causing\ncontingencies. The results suggest that both risk of cascading failure, and the\nrelative contribution of higher order contingencies, increase as a function of\nspatial correlation in component failures.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2019 18:17:00 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 02:45:27 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 18:52:10 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Clarfeld", "Laurence A.", ""], ["Hines", "Paul D. H.", ""], ["Hernandez", "Eric M.", ""], ["Eppstein", "Margaret J.", ""]]}, {"id": "1901.04480", "submitter": "Nicolas Pignet", "authors": "Micka\\\"el Abbas and Alexandre Ern and Nicolas Pignet", "title": "A Hybrid High-Order method for finite elastoplastic deformations within\n  a logarithmic strain framework", "comments": "32 pages; 16 figures; 1 table. arXiv admin note: substantial text\n  overlap with arXiv:1804.06129", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise and evaluate numerically a Hybrid High-Order (HHO) method for\nfinite plasticity within a logarithmic strain framework. The HHO method uses as\ndiscrete unknowns piecewise polynomials of order $k\\ge1$ on the mesh skeleton,\ntogether with cell-based polynomials that can be eliminated locally by static\ncondensation. The HHO method leads to a primal formulation, supports polyhedral\nmeshes with non-matching interfaces, is free of volumetric locking, the\nintegration of the behavior law is performed only at cell-based quadrature\nnodes, and the tangent matrix in Newton's method is symmetric. Moreover, the\nprinciple of virtual work is satisfied locally with equilibrated tractions.\nVarious two- and three-dimensional benchmarks are presented, as well as\ncomparison against known solutions with an industrial software using conforming\nand mixed finite elements.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 09:05:07 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 18:02:09 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Abbas", "Micka\u00ebl", ""], ["Ern", "Alexandre", ""], ["Pignet", "Nicolas", ""]]}, {"id": "1901.04832", "submitter": "Zeliang Liu", "authors": "Zeliang Liu, C.T. Wu", "title": "Exploring the 3D architectures of deep material network in data-driven\n  multiscale mechanics", "comments": "35 pages, 25 figures", "journal-ref": null, "doi": "10.1016/j.jmps.2019.03.004", "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the deep material network (DMN) proposed by Liu et al.\n(2019) to tackle general 3-dimensional (3D) problems with arbitrary material\nand geometric nonlinearities. It discovers a new way of describing multiscale\nheterogeneous materials by a multi-layer network structure and mechanistic\nbuilding blocks. The data-driven framework of DMN is discussed in detail about\nthe offline training and online extrapolation stages. Analytical solutions of\nthe 3D building block with a two-layer structure in both small- and\nfinite-strain formulations are derived based on interfacial equilibrium\nconditions and kinematic constraints. With linear elastic data generated by\ndirect numerical simulations on a representative volume element (RVE), the\nnetwork can be effectively trained in the offline stage using stochastic\ngradient descent and advanced model compression algorithms. Efficiency and\naccuracy of DMN on addressing the long-standing 3D RVE challenges with complex\nmorphologies and material laws are validated through numerical experiments,\nincluding 1) hyperelastic particle-reinforced rubber composite with Mullins\neffect; 2) polycrystalline materials with rate-dependent crystal plasticity; 3)\ncarbon fiber reinforced polymer (CFRP) composites with fiber anisotropic\nelasticity and matrix plasticity. In particular, we demonstrate a three-scale\nhomogenization procedure of CFRP system by concatenating the microscale and\nmesoscale material networks. The complete learning and extrapolation procedures\nof DMN establish a reliable data-driven framework for multiscale material\nmodeling and design.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 18:21:38 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 22:43:12 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 22:30:16 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Zeliang", ""], ["Wu", "C. T.", ""]]}, {"id": "1901.04847", "submitter": "Hisham Al-Mubaid", "authors": "Hisham Al-Mubaid, Sasikanth Potu, and M. Shenify", "title": "Determining Multifunctional Genes and Diseases in Human Using Gene\n  Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of human genes and diseases is very rewarding and can lead to\nimprovements in healthcare, disease diagnostics and drug discovery. In this\npaper, we further our previous study on gene disease relationship specifically\nwith the multifunctional genes. We investigate the multifunctional gene disease\nrelationship based on the published molecular function annotations of genes\nfrom the Gene Ontology which is the most comprehensive source on gene\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 23:53:33 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Al-Mubaid", "Hisham", ""], ["Potu", "Sasikanth", ""], ["Shenify", "M.", ""]]}, {"id": "1901.04863", "submitter": "Ece Calikus", "authors": "Ece Calikus, Slawomir Nowaczyk, Anita Sant'Anna, Henrik Gadd, Sven\n  Werner", "title": "A data-driven approach for discovering heat load patterns in district\n  heating", "comments": null, "journal-ref": "Applied Energy, 252, p.113409 (2019)", "doi": "10.1016/j.apenergy.2019.113409", "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the heat usage of customers is crucial for effective district\nheating operations and management. Unfortunately, existing knowledge about\ncustomers and their heat load behaviors is quite scarce. Most previous studies\nare limited to small-scale analyses that are not representative enough to\nunderstand the behavior of the overall network. In this work, we propose a\ndata-driven approach that enables large-scale automatic analysis of heat load\npatterns in district heating networks without requiring prior knowledge. Our\nmethod clusters the customer profiles into different groups, extracts their\nrepresentative patterns, and detects unusual customers whose profiles deviate\nsignificantly from the rest of their group. Using our approach, we present the\nfirst large-scale, comprehensive analysis of the heat load patterns by\nconducting a case study on many buildings in six different customer categories\nconnected to two district heating networks in the south of Sweden. The 1222\nbuildings had a total floor space of 3.4 million square meters and used 1540 TJ\nheat during 2016. The results show that the proposed method has a high\npotential to be deployed and used in practice to analyze and understand\ncustomers' heat-use habits.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 10:54:43 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:14:51 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 11:09:03 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Calikus", "Ece", ""], ["Nowaczyk", "Slawomir", ""], ["Sant'Anna", "Anita", ""], ["Gadd", "Henrik", ""], ["Werner", "Sven", ""]]}, {"id": "1901.04944", "submitter": "Jean-Emmanuel Deschaud", "authors": "Hassan Bouchiba, Simon Santoso, Jean-Emmanuel Deschaud, Luisa\n  Rocha-Da-Silva, Fran\\c{c}ois Goulette, Thierry Coupez", "title": "Computational Fluid Dynamics on 3D Point Set Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CE cs.CG physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational fluid dynamics (CFD) in many cases requires designing 3D models\nmanually, which is a tedious task that requires specific skills. In this paper,\nwe present a novel method for performing CFD directly on scanned 3D point\nclouds. The proposed method builds an anisotropic volumetric tetrahedral mesh\nadapted around a point-sampled surface, without an explicit surface\nreconstruction step. The surface is represented by a new extended implicit\nmoving least squares (EIMLS) scalar representation that extends the definition\nof the function to the entire computational domain, which makes it possible for\nuse in immersed boundary flow simulations. The workflow we present allows us to\ncompute flows around point-sampled geometries automatically. It also gives a\nbetter control of the precision around the surface with a limited number of\ncomputational nodes, which is a critical issue in CFD.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 13:14:19 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Bouchiba", "Hassan", ""], ["Santoso", "Simon", ""], ["Deschaud", "Jean-Emmanuel", ""], ["Rocha-Da-Silva", "Luisa", ""], ["Goulette", "Fran\u00e7ois", ""], ["Coupez", "Thierry", ""]]}, {"id": "1901.05237", "submitter": "Yun-Cheng Tsai", "authors": "Jun-Hao Chen and Yun-Cheng Tsai", "title": "Encoding Candlesticks as Images for Patterns Classification Using\n  Convolutional Neural Networks", "comments": "18 pages, 20 figures. Accepted by Financial Innovation, June 2020.\n  (Social Sciences Citation Index)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Candlestick charts display the high, low, opening, and closing prices in a\nspecific period. Candlestick patterns emerge because human actions and\nreactions are patterned and continuously replicate. These patterns capture\ninformation on the candles. According to Thomas Bulkowski's Encyclopedia of\nCandlestick Charts, there are 103 candlestick patterns. Traders use these\npatterns to determine when to enter and exit. Candlestick pattern\nclassification approaches take the hard work out of visually identifying these\npatterns. To highlight its capabilities, we propose a two-steps approach to\nrecognize candlestick patterns automatically. The first step uses the Gramian\nAngular Field (GAF) to encode the time series as different types of images. The\nsecond step uses the Convolutional Neural Network (CNN) with the GAF images to\nlearn eight critical kinds of candlestick patterns. In this paper, we call the\napproach GAF-CNN. In the experiments, our method can identify the eight types\nof candlestick patterns with 90.7% average accuracy automatically in real-world\ndata, outperforming the LSTM model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 11:29:11 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 14:12:16 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Chen", "Jun-Hao", ""], ["Tsai", "Yun-Cheng", ""]]}, {"id": "1901.05344", "submitter": "Georg Hager", "authors": "Francesco Cremonesi, Georg Hager, Gerhard Wellein, Felix Sch\\\"urmann", "title": "Analytic Performance Modeling and Analysis of Detailed Neuron\n  Simulations", "comments": "18 pages, 6 figures, 15 tables", "journal-ref": null, "doi": "10.1177/1094342020912528", "report-no": null, "categories": "cs.PF cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big science initiatives are trying to reconstruct and model the brain by\nattempting to simulate brain tissue at larger scales and with increasingly more\nbiological detail than previously thought possible. The exponential growth of\nparallel computer performance has been supporting these developments, and at\nthe same time maintainers of neuroscientific simulation code have strived to\noptimally and efficiently exploit new hardware features. Current state of the\nart software for the simulation of biological networks has so far been\ndeveloped using performance engineering practices, but a thorough analysis and\nmodeling of the computational and performance characteristics, especially in\nthe case of morphologically detailed neuron simulations, is lacking. Other\ncomputational sciences have successfully used analytic performance engineering\nand modeling methods to gain insight on the computational properties of\nsimulation kernels, aid developers in performance optimizations and eventually\ndrive co-design efforts, but to our knowledge a model-based performance\nanalysis of neuron simulations has not yet been conducted.\n  We present a detailed study of the shared-memory performance of\nmorphologically detailed neuron simulations based on the Execution-Cache-Memory\n(ECM) performance model. We demonstrate that this model can deliver accurate\npredictions of the runtime of almost all the kernels that constitute the neuron\nmodels under investigation. The gained insight is used to identify the main\ngoverning mechanisms underlying performance bottlenecks in the simulation. The\nimplications of this analysis on the optimization of neural simulation software\nand eventually co-design of future hardware architectures are discussed. In\nthis sense, our work represents a valuable conceptual and quantitative\ncontribution to understanding the performance properties of biological networks\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 15:28:06 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cremonesi", "Francesco", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""], ["Sch\u00fcrmann", "Felix", ""]]}, {"id": "1901.05422", "submitter": "Sayyed Mohsen Vazirizade", "authors": "Achintya Haldara, J. Ramon Gaxiola Camachob, Hamoon Azizsoltanic,\n  Francisco J. Villegas-Mercadoa, and S. Mohsen Vazirizadea", "title": "A Novel Geomechanics Concept for Earthquake Excitations Applied in Time\n  Domain", "comments": "First of all there are some errors in some of the equations. For\n  example some of the notation in Eqn (5) and after that paragraph. There are\n  some discrepancies. In Eqn (11), it is not explained well how the parameters\n  of the vector in the RHS are obtained. Also, the manuscript does not explain\n  the large variation in beta for different records of earthquake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel geomechanics concept is presented for studying the behavior of\ngeomaterials and structures by capturing the underlying dynamics as\nrealistically as possible for earthquake excitation applied in time domain.\nEnormous amount of damages caused to infrastructures during recent earthquakes\nin all over the world indicate that there is a considerable room for\nimprovement. Causes for extensive damages are generally attributed to poor soil\nconditions at the region. It is interesting to note that all structures in a\nregion with poor soil condition do not suffer similar damages; in fact, some of\nthem remain damage-free. There are many reasons for this including inability to\nmodel the soil-structural systems properly, predict the future design\nearthquake time history at the site, model the dynamic amplification of\nresponses caused by the excitation, incorporate major sources of nonlinearity\nand energy dissipation, and most importantly consider the presence of a\nconsiderable amount of uncertainty at every phase of the evaluation process.\nThe most recent research trend is to capture complicated behavior by conducting\nmultiple deterministic analyses by taking advantage of current significantly\nimproved computational capability. By conducting few dozens of deterministic\nanalyses at very intelligently selected points, structures can be designed more\nseismic load-tolerant. The performance based seismic design concept recently\nintroduced in the U.S. is showcased in this paper. The requirements in the\nguidelines appear to be reasonable. The concept is expected to change the\ncurrent engineering design paradigm. The authors believe that the proposed\nalternatives to the simulation and the basic random vibration concept.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 18:19:59 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 05:48:02 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Haldara", "Achintya", ""], ["Camachob", "J. Ramon Gaxiola", ""], ["Azizsoltanic", "Hamoon", ""], ["Villegas-Mercadoa", "Francisco J.", ""], ["Vazirizadea", "S. Mohsen", ""]]}, {"id": "1901.05512", "submitter": "Felipe Viana", "authors": "Renato Giorgiani Nascimento and Felipe A. C. Viana", "title": "Fleet Prognosis with Physics-informed Recurrent Neural Networks", "comments": "Data and codes (including our implementation for both the multi-layer\n  perceptron, the stress intensity and Paris law layers, the cumulative damage\n  cell, as well as python driver scripts) used in this manuscript are publicly\n  available on GitHub at https://github.com/PML-UCF/pinn. The data and code are\n  released under the MIT License", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Services and warranties of large fleets of engineering assets is a very\nprofitable business. The success of companies in that area is often related to\npredictive maintenance driven by advanced analytics. Therefore, accurate\nmodeling, as a way to understand how the complex interactions between operating\nconditions and component capability define useful life, is key for services\nprofitability. Unfortunately, building prognosis models for large fleets is a\ndaunting task as factors such as duty cycle variation, harsh environments,\ninadequate maintenance, and problems with mass production can lead to large\ndiscrepancies between designed and observed useful lives. This paper introduces\na novel physics-informed neural network approach to prognosis by extending\nrecurrent neural networks to cumulative damage models. We propose a new\nrecurrent neural network cell designed to merge physics-informed and\ndata-driven layers. With that, engineers and scientists have the chance to use\nphysics-informed layers to model parts that are well understood (e.g., fatigue\ncrack growth) and use data-driven layers to model parts that are poorly\ncharacterized (e.g., internal loads). A simple numerical experiment is used to\npresent the main features of the proposed physics-informed recurrent neural\nnetwork for damage accumulation. The test problem consist of predicting fatigue\ncrack length for a synthetic fleet of airplanes subject to different mission\nmixes. The model is trained using full observation inputs (far-field loads) and\nvery limited observation of outputs (crack length at inspection for only a\nportion of the fleet). The results demonstrate that our proposed hybrid\nphysics-informed recurrent neural network is able to accurately model fatigue\ncrack growth even when the observed distribution of crack length does not match\nwith the (unobservable) fleet distribution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2019 19:58:35 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Nascimento", "Renato Giorgiani", ""], ["Viana", "Felipe A. C.", ""]]}, {"id": "1901.06794", "submitter": "Chunmei Feng", "authors": "Jin-Xing Liu, Chun-Mei Feng, Xiang-Zhen Kong, Yong Xu", "title": "Dual Graph-Laplacian PCA: A Closed-Form Solution for Bi-clustering to\n  Find \"Checkerboard\" Structures on Gene Expression Data", "comments": "This manuscript was submitted in IEEE Transaction on Knowledge and\n  Data Engineering on 12/01/2017. 9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of cancer, internal \"checkerboard\" structures are normally\nfound in the matrices of gene expression data, which correspond to genes that\nare significantly up- or down-regulated in patients with specific types of\ntumors. In this paper, we propose a novel method, called dual\ngraph-regularization principal component analysis (DGPCA). The main innovation\nof this method is that it simultaneously considers the internal geometric\nstructures of the condition manifold and the gene manifold. Specifically, we\nobtain principal components (PCs) to represent the data and approximate the\ncluster membership indicators through Laplacian embedding. This new method is\nendowed with internal geometric structures, such as the condition manifold and\ngene manifold, which are both suitable for bi-clustering. A closed-form\nsolution is provided for DGPCA. We apply this new method to simultaneously\ncluster genes and conditions (e.g., different samples) with the aim of finding\ninternal \"checkerboard\" structures on gene expression data, if they exist.\nThen, we use this new method to identify regulatory genes under the particular\nconditions and to compare the results with those of other state-of-the-art\nPCA-based methods. Promising results on gene expression data have been verified\nby extensive experiments\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 05:43:31 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Liu", "Jin-Xing", ""], ["Feng", "Chun-Mei", ""], ["Kong", "Xiang-Zhen", ""], ["Xu", "Yong", ""]]}, {"id": "1901.06798", "submitter": "Xinsheng Qin", "authors": "Xinsheng Qin, Randall LeVeque, Michael Motley", "title": "Efficient Tsunami Modeling on Adaptive Grids with Graphics Processing\n  Units (GPUs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE physics.ao-ph physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving the shallow water equations efficiently is critical to the study of\nnatural hazards induced by tsunami and storm surge, since it provides more\nresponse time in an early warning system and allows more runs to be done for\nprobabilistic assessment where thousands of runs may be required. Using\nAdaptive Mesh Refinement (AMR) speeds up the process by greatly reducing\ncomputational demands, while accelerating the code using the Graphics\nProcessing Unit (GPU) does so through using faster hardware. Combining both, we\npresent an efficient CUDA implementation of GeoClaw, an open source\nGodunov-type high-resolution finite volume numerical scheme on adaptive grids\nfor shallow water system with varying topography. The use of AMR and spherical\ncoordinates allows modeling transoceanic tsunami simulation. Numerical\nexperiments on several realistic tsunami modeling problems illustrate the\ncorrectness and efficiency of the code, which implements a simplified\ndimensionally-split version of the algorithms. This implementation is shown to\nbe accurate and faster than the original when using CPUs alone. The GPU\nimplementation, when running on a single GPU, is observed to be 3.6 to 6.4\ntimes faster than the original model running in parallel on a 16-core CPU.\nThree metrics are proposed to evaluate relative performance of the model, which\nshows efficient usage of hardware resources.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 06:01:10 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Qin", "Xinsheng", ""], ["LeVeque", "Randall", ""], ["Motley", "Michael", ""]]}, {"id": "1901.06949", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Terrence W.K. Mak, Pascal Van Hentenryck", "title": "Differential Privacy for Power Grid Obfuscation", "comments": null, "journal-ref": "IEEE Transactions on Smart Grid, vol. 11, no. 2, pp. 1356-1366,\n  March 2020", "doi": "10.1109/TSG.2019.2936712", "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of high-fidelity energy networks brings significant value to\nacademic and commercial research. However, such releases also raise fundamental\nconcerns related to privacy and security as they can reveal sensitive\ncommercial information and expose system vulnerabilities. This paper\ninvestigates how to release power networks where the parameters of transmission\nlines and transformers are obfuscated. It does so by using the framework of\nDifferential Privacy (DP), that provides strong privacy guarantees and has\nattracted significant attention in recent years. Unfortunately, simple DP\nmechanisms often result in AC-infeasible networks. To address these concerns,\nthis paper presents a novel differential privacy mechanism that guarantees\nAC-feasibility and largely preserves the fidelity of the obfuscated network.\nExperimental results also show that the obfuscation significantly reduces the\npotential damage of an attacker exploiting the release of the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 15:07:17 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 14:34:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Mak", "Terrence W. K.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1901.07960", "submitter": "Christoph M Augustin", "authors": "Miguel A. Rodriguez, Christoph M. Augustin, Shawn C. Shadden", "title": "FEniCS Mechanics: A Package for Continuum Mechanics Simulations", "comments": "This work was supported in part from the NSF award 1663747 and the\n  NSF GRFP. Additionally, this project has received funding from the European\n  Union's Horizon 2020 research and innovation programme under the Marie\n  Sklodowska-Curie Action H2020-MSCA-IF-2016 InsiliCardio, GA No. 750835", "journal-ref": "SoftwareX 9:107-111, 2019", "doi": "10.1016/j.softx.2018.10.005", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  FEniCS Mechanics is a Python package to facilitate computational mechanics\nsimulations. The Python library dolfin, from the FEniCS Project, is used to\nformulate and numerically solve the problem in variational form. The general\nbalance laws from continuum mechanics are used to enable rapid prototyping of\ndifferent material laws. In addition to its generality, FEniCS Mechanics also\nchecks the input provided by users to ensure that problem definitions are\nphysically consistent. In turn, this code enables simulations of custom\nmechanics problems to be more accessible to those with limited programming or\nmechanics knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 14:47:05 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Rodriguez", "Miguel A.", ""], ["Augustin", "Christoph M.", ""], ["Shadden", "Shawn C.", ""]]}, {"id": "1901.07993", "submitter": "Anton G. Artemov", "authors": "Anton G. Artemov, Elias Rudberg, Emanuel H. Rubensson", "title": "Parallelization and scalability analysis of inverse factorization using\n  the Chunks and Tasks programming model", "comments": "20 pages, 7 figures, corrected the author list", "journal-ref": null, "doi": "10.1016/j.parco.2019.102548", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present three methods for distributed memory parallel inverse\nfactorization of block-sparse Hermitian positive definite matrices. The three\nmethods are a recursive variant of the AINV inverse Cholesky algorithm,\niterative refinement, and localized inverse factorization, respectively. All\nthree methods are implemented using the Chunks and Tasks programming model,\nbuilding on the distributed sparse quad-tree matrix representation and parallel\nmatrix-matrix multiplication in the publicly available Chunks and Tasks Matrix\nLibrary (CHTML). Although the algorithms are generally applicable, this work\nwas mainly motivated by the need for efficient and scalable inverse\nfactorization of the basis set overlap matrix in large scale electronic\nstructure calculations. We perform various computational tests on overlap\nmatrices for quasi-linear Glutamic Acid-Alanine molecules and three-dimensional\nwater clusters discretized using the standard Gaussian basis set STO-3G with up\nto more than 10 million basis functions. We show that for such matrices the\ncomputational cost increases only linearly with system size for all the three\nmethods. We show both theoretically and in numerical experiments that the\nmethods based on iterative refinement and localized inverse factorization\noutperform previous parallel implementations in weak scaling tests where the\nsystem size is increased in direct proportion to the number of processes. We\nshow also that compared to the method based on pure iterative refinement the\nlocalized inverse factorization requires much less communication.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 16:44:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 13:29:55 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Artemov", "Anton G.", ""], ["Rudberg", "Elias", ""], ["Rubensson", "Emanuel H.", ""]]}, {"id": "1901.08342", "submitter": "Md Rushdie Ibne Islam", "authors": "Md Rushdie Ibne Islam, Chong Peng", "title": "A Total Lagrangian SPH Method for Modelling Damage and Failure in Solids", "comments": "28 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm is proposed to model crack initiation and propagation within the\ntotal Lagrangian Smoothed Particle Hydrodynamics (TLSPH) framework. TLSPH\navoids the two main deficiencies of conventional SPH, i.e., tensile instability\nand inconsistency, by making use of the Lagrangian kernel and gradient\ncorrection, respectively. In the present approach, the support domain of a\nparticle is modified, where it only interacts with its immediately neighbouring\nparticles. A virtual link defines the level of interaction between each\nparticle pair. The state of the virtual link is determined by damage law or\ncracking criterion. The virtual link approach allows easy and natural modelling\nof cracking surfaces without explicit cracking treatments such as particle\nsplitting, field enrichment or visibility criterion. The performance of the\nproposed approach is demonstrated via a few numerical examples of both brittle\nand ductile failure under impact loading.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 10:49:28 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Islam", "Md Rushdie Ibne", ""], ["Peng", "Chong", ""]]}, {"id": "1901.08417", "submitter": "Pierre Gosselet", "authors": "Maxime Blanchard (LMT), Olivier Allix (LMT), Pierre Gosselet (LMT),\n  Geoffrey Desmeure", "title": "Space/time global/local noninvasive coupling strategy: Application to\n  viscoplastic structures", "comments": null, "journal-ref": "Finite Elements in Analysis and Design, Elsevier, 2019, 156,\n  pp.1-12", "doi": "10.1016/j.finel.2019.01.003", "report-no": null, "categories": "cs.CE physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to extend the non-invasive global/local\niterative coupling technique [15] to the case of large structures undergoing\nnonlinear time-dependent evolutions at all scales. It appears that, due to the\nuse of legacy codes, the use of different time grids at the global and local\nlevels is mandatory in order to reach a satisfying level of precision. In this\npaper two strategies are proposed and compared for elastoviscoplastic models.\nThe questions of the precision and performance of those schemes with respect to\na monolithic approach is addressed. The methods are first exposed on a 2D\nexample and then applied on a 3D part of industrial complexity.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 09:25:09 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Blanchard", "Maxime", "", "LMT"], ["Allix", "Olivier", "", "LMT"], ["Gosselet", "Pierre", "", "LMT"], ["Desmeure", "Geoffrey", ""]]}, {"id": "1901.08783", "submitter": "Alberto F. Mart\\'in", "authors": "Santiago Badia, Alberto F. Mart\\'in, Marc Olm", "title": "Scalable solvers for complex electromagnetics problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.finel.2019.04.003", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present scalable balancing domain decomposition by\nconstraints methods for linear systems arising from arbitrary order edge finite\nelement discretizations of multi-material and heterogeneous 3D problems. In\norder to enforce the continuity across subdomains of the method, we use a\npartition of the interface objects (edges and faces) into sub-objects\ndetermined by the variation of the physical coefficients of the problem. For\nmulti-material problems, a constant coefficient condition is enough to define\nthis sub-partition of the objects. For arbitrarily heterogeneous problems, a\nrelaxed version of the method is defined, where we only require that the\nmaximal contrast of the physical coefficient in each object is smaller than a\npredefined threshold. Besides, the addition of perturbation terms to the\npreconditioner is empirically shown to be effective in order to deal with the\ncase where the two coefficients of the model problem jump simultaneously across\nthe interface. The new method, in contrast to existing approaches for problems\nin curl-conforming spaces does not require spectral information whilst\nproviding robustness with regard to coefficient jumps and heterogeneous\nmaterials. A detailed set of numerical experiments, which includes the\napplication of the preconditioner to 3D realistic cases, shows excellent weak\nscalability properties of the implementation of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 08:51:38 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 07:43:18 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 16:16:53 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Badia", "Santiago", ""], ["Mart\u00edn", "Alberto F.", ""], ["Olm", "Marc", ""]]}, {"id": "1901.08986", "submitter": "Irina Georgescu", "authors": "Irina Georgescu, Jani Kinnunen", "title": "How the investor's risk preferences influence the optimal allocation in\n  a credibilistic portfolio problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical portfolio theory deals with finding the optimal proportion in\nwhich an agent invests a wealth in a risk-free asset and a probabilistic risky\nasset. Formulating and solving the problem depend on how the risk is\nrepresented and how, combined with the utility function defines a notion of\nexpected utility. In this paper the risk is a fuzzy variable and the notion of\nexpected utility is defined in the setting of Liu's credibility theory. Thus\nthe portfolio choice problem is formulated as an optimization problem in which\nthe objective function is a credibilistic expected utility. Different\napproximation calculation formulas for the optimal allocation of the\ncredibilistic risky asset are proved. These formulas contain two types of\nparameters: various credibilistic moments associated with fuzzy variables\n(expected value, variance, skewness and kurtosis) and the risk aversion,\nprudence and temperance indicators of the utility function.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 17:05:44 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Georgescu", "Irina", ""], ["Kinnunen", "Jani", ""]]}, {"id": "1901.09469", "submitter": "Yukio Ohsawa", "authors": "Yukio Ohsawa, Teruaki Hayashi, Takaaki Yoshino", "title": "Tangled String for Multi-Scale Explanation of Contextual Shifts in Stock\n  Market", "comments": "16 pages and 7 figures. The author started to write this paper as an\n  extension of the paper [20] in the reference list, but the content came to be\n  changed substantially, not by only minor extension but to a new paper", "journal-ref": "Information (https://www.mdpi.com/2078-2489/10/3/118)", "doi": "10.3390/info10030118", "report-no": null, "categories": "cs.CE q-fin.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The original research question here is given by marketers in general, i.e.,\nhow to explain the changes in the desired timescale of the market. Tangled\nString, a sequence visualization tool based on the metaphor where contexts in a\nsequence are compared to tangled pills in a string, is here extended and\ndiverted to detecting stocks that trigger changes in the market and to\nexplaining the scenario of contextual shifts in the market. Here, the\nsequential data on the stocks of top 10 weekly increase rates in the First\nSection of the Tokyo Stock Exchange for 12 years are visualized by Tangled\nString. The changing in the prices of stocks is a mixture of various timescales\nand can be explained in the time-scale set as desired by using TS. Also, it is\nfound that the change points found by TS coincided by high precision with the\nreal changes in each stock price. As TS has been created from the data-driven\ninnovation platform called Innovators Marketplace on Data Jackets and is\nextended to satisfy data users, this paper is as evidence of the contribution\nof the market of data to data-driven innovations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 00:18:34 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Ohsawa", "Yukio", ""], ["Hayashi", "Teruaki", ""], ["Yoshino", "Takaaki", ""]]}, {"id": "1901.10352", "submitter": "Hanno Gottschalk", "authors": "Alexander Liefke, Vincent Marciniak, Uwe Janoske and Hanno Gottschalk", "title": "Using adjoint CFD to quantify the impact of manufacturing variations on\n  a heavy duty turbine vane", "comments": "15 p., 10 figures, 2 tables", "journal-ref": "6th European Conference on Computational Mechanics (ECCM 6) 7th\n  European Conference on Computational Fluid Dynamics (ECFD 7) June 2018,\n  Glasgow, UK", "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the evaluation of manufacturing variations to the aerodynamic\nperformace of turbine vanes using the adjoint method. The empirical data is\nbased on 102 white light scans from casted parts. We compare expensive\ncalculations by the finite disfference method with cheap adjoint calculations\nand we find high correlations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 22:47:52 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Liefke", "Alexander", ""], ["Marciniak", "Vincent", ""], ["Janoske", "Uwe", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1901.10556", "submitter": "Irina Georgescu", "authors": "Irina Georgescu", "title": "Possibilistic investment models with background risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of investment problem, aside from the investment risk the\nbackground risk appears. Both the investment risk and the background risk are\nprobabilistically described by random variables. This paper starts from the\nhypothesis that the two types of risk can be represented both probabilistically\n(by random variables) and possibilistically (by fuzzy numbers). We will study\nthree models in which the investment risk and the background risk can be: fuzzy\nnumbers, a random variabl-a fuzzy number and a fuzzy number-a random variable.\nA portfolio problem is formulated for each model and an approximate calculation\nformula of the optimal solution is proved.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 11:07:43 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Georgescu", "Irina", ""]]}, {"id": "1901.11013", "submitter": "Kartikay Gupta Mr", "authors": "Kartikay Gupta and Niladri Chatterjee", "title": "Top performing stocks recommendation strategy for portfolio", "comments": "20 pages, 9 Tables, 3 figures. Comments are invited. In the last\n  version, Methodological details corrected at one point, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock return forecasting is of utmost importance in the business world. This\nhas been the favourite topic of research for many academicians since decades.\nRecently, regularization techniques have reported to tremendously increase the\nforecast accuracy of the simple regression model. Still, this model cannot\nincorporate the effect of things like a major natural disaster, large foreign\ninfluence, etc. in its prediction. Such things affect the whole stock market\nand are very unpredictable. Thus, it is more important to recommend top stocks\nrather than predicting exact stock returns. The present paper modifies the\nregression task to output value for each stock which is more suitable for\nranking the stocks by expected returns. Two large datasets consisting of\naltogether 1205 companies listed at Indian exchanges were used for\nexperimentation. Five different metrics were used for evaluating the different\nmodels. Results were also analysed subjectively through plots. The results\nshowed the superiority of the proposed techniques.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 09:19:53 GMT"}, {"version": "v2", "created": "Sun, 21 Apr 2019 03:41:35 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 05:02:13 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gupta", "Kartikay", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "1901.11295", "submitter": "Ling-Ze Bu", "authors": "Ling-Ze Bu, Wei Zhao, Wei Wang", "title": "Second order hierarchical partial least squares regression-polynomial\n  chaos expansion for global sensitivity and reliability analyses of\n  high-dimensional models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To tackle the curse of dimensionality and multicollinearity problems of\npolynomial chaos expansion for analyzing global sensitivity and reliability of\nmodels with high stochastic dimensions, this paper proposes a novel\nnon-intrusive algorithm called second order hierarchical partial least squares\nregression-polynomial chaos expansion. The first step of the innovative\nalgorithm is to divide the polynomials into several groups according to their\ninteraction degrees and nonlinearity degrees, which avoids large data sets and\nreflects the relationship between polynomial chaos expansion and high\ndimensional model representation. Then a hierarchical regression algorithm\nbased on partial least squares regression is devised for extracting latent\nvariables from each group at different variable levels. The optimal interaction\ndegree and the corresponding nonlinearity degrees are automatically estimated\nwith an improved cross validation scheme. Based on the relationship between\nvariables at two adjacent levels, Sobol' sensitivity indices can be obtained by\na simple post-processing of expansion coefficients. Thus, the expansion is\ngreatly simplified through retaining the important inputs, leading to accurate\nreliability analysis without requirements of additional model evaluations.\nFinally, finite element models with three different types of structures\nverified that the proposed method can greatly improve the computational\nefficiency compared with the ordinary least squares regression-based method.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 10:07:19 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 12:25:02 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 06:46:14 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Bu", "Ling-Ze", ""], ["Zhao", "Wei", ""], ["Wang", "Wei", ""]]}, {"id": "1901.11505", "submitter": "Saipraneeth Gouravaraju", "authors": "Saipraneeth Gouravaraju, Roger A. Sauer and Sachin Singh Gautam", "title": "Investigating the normal and tangential peeling behaviour of gecko\n  spatulae using a coupled adhesion-friction model", "comments": "30 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cs.CE physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work investigates the normal and tangential peeling behaviour of\na gecko spatula using a coupled adhesion-friction model. The objective is to\nexplain the strong attachment and easy detachment behaviour of the spatulae as\nwell as to understand the principles behind their optimum design. Using\nnonlinear finite element computations, it is shown that during\ntangentially-constrained peeling the partial sliding of the spatula pad near\nthe peeling front stretches the spatula, thus increasing the strain energy and\nleading to high pull-off forces. The model is used to investigate the influence\nof various parameters on the pull-off forces -- such as the peeling angle,\nspatula shaft angle, strip thickness, and material stiffness. The model shows\nthat increasing the spatula pad thickness beyond a certain level does not lead\nto a significant increase in the attachment forces. Further, the easy\ndetachment behaviour of geckos is studied under tangentially-free peeling\nconditions. It is found that the spatulae readily detach from the substrate by\nchanging their shaft angle and eventually peel vertically like a tape. Since\nthe present computational model is not limited by the geometrical, kinematical,\nand material restrictions of theoretical models, it can be employed to analyse\nsimilar biological adhesive systems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 18:08:40 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 14:43:27 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 16:54:50 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 07:54:46 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gouravaraju", "Saipraneeth", ""], ["Sauer", "Roger A.", ""], ["Gautam", "Sachin Singh", ""]]}]