[{"id": "0705.0150", "submitter": "Myung-Sin Song", "authors": "Palle E. T. Jorgensen, Myung-Sin Song", "title": "Comparison of Discrete and Continuous Wavelet Transforms", "comments": "22 pages, Springer Encyclopedia of Complexity and Systems Science,\n  the full version with figures is available at\n  http://www.siue.edu/~msong/Research/ency.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  In this paper we outline several points of view on the interplay between\ndiscrete and continuous wavelet transforms; stressing both pure and applied\naspects of both. We outline some new links between the two transform\ntechnologies based on the theory of representations of generators and\nrelations. By this we mean a finite system of generators which are represented\nby operators in Hilbert space. We further outline how these representations\nyield sub-band filter banks for signal and image processing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2007 18:24:52 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2007 17:53:30 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Jorgensen", "Palle E. T.", ""], ["Song", "Myung-Sin", ""]]}, {"id": "0705.1033", "submitter": "Kebin Wang", "authors": "Michael A. Bender, Bradley C. Kuszmaul, Shang-Hua Teng, Kebin Wang", "title": "Optimal Cache-Oblivious Mesh Layouts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mesh is a graph that divides physical space into regularly-shaped regions.\nMeshes computations form the basis of many applications, e.g. finite-element\nmethods, image rendering, and collision detection. In one important mesh\nprimitive, called a mesh update, each mesh vertex stores a value and repeatedly\nupdates this value based on the values stored in all neighboring vertices. The\nperformance of a mesh update depends on the layout of the mesh in memory.\n  This paper shows how to find a memory layout that guarantees that the mesh\nupdate has asymptotically optimal memory performance for any set of memory\nparameters. Such a memory layout is called cache-oblivious. Formally, for a\n$d$-dimensional mesh $G$, block size $B$, and cache size $M$ (where\n$M=\\Omega(B^d)$), the mesh update of $G$ uses $O(1+|G|/B)$ memory transfers.\nThe paper also shows how the mesh-update performance degrades for smaller\ncaches, where $M=o(B^d)$.\n  The paper then gives two algorithms for finding cache-oblivious mesh layouts.\nThe first layout algorithm runs in time $O(|G|\\log^2|G|)$ both in expectation\nand with high probability on a RAM. It uses $O(1+|G|\\log^2(|G|/M)/B)$ memory\ntransfers in expectation and $O(1+(|G|/B)(\\log^2(|G|/M) + \\log|G|))$ memory\ntransfers with high probability in the cache-oblivious and disk-access machine\n(DAM) models. The layout is obtained by finding a fully balanced decomposition\ntree of $G$ and then performing an in-order traversal of the leaves of the\ntree. The second algorithm runs faster by almost a $\\log|G|/\\log\\log|G|$ factor\nin all three memory models, both in expectation and with high probability. The\nlayout obtained by finding a relax-balanced decomposition tree of $G$ and then\nperforming an in-order traversal of the leaves of the tree.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2007 05:59:55 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2009 18:45:25 GMT"}], "update_date": "2009-10-05", "authors_parsed": [["Bender", "Michael A.", ""], ["Kuszmaul", "Bradley C.", ""], ["Teng", "Shang-Hua", ""], ["Wang", "Kebin", ""]]}, {"id": "0705.1214", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Control of Complex Systems Using Bayesian Networks and Genetic Algorithm", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  A method based on Bayesian neural networks and genetic algorithm is proposed\nto control the fermentation process. The relationship between input and output\nvariables is modelled using Bayesian neural network that is trained using\nhybrid Monte Carlo method. A feedback loop based on genetic algorithm is used\nto change input variables so that the output variables are as close to the\ndesired target as possible without the loss of confidence level on the\nprediction that the neural network gives. The proposed procedure is found to\nreduce the distance between the desired target and measured outputs\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2007 07:08:58 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "0705.1390", "submitter": "Tshilidzi Marwala", "authors": "M.A. Herzog, T. Marwala and P.S. Heyns", "title": "Machine and Component Residual Life Estimation through the Application\n  of Neural Networks", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  This paper concerns the use of neural networks for predicting the residual\nlife of machines and components. In addition, the advantage of using\ncondition-monitoring data to enhance the predictive capability of these neural\nnetworks was also investigated. A number of neural network variations were\ntrained and tested with the data of two different reliability-related datasets.\nThe first dataset represents the renewal case where the failed unit is repaired\nand restored to a good-as-new condition. Data was collected in the laboratory\nby subjecting a series of similar test pieces to fatigue loading with a\nhydraulic actuator. The average prediction error of the various neural networks\nbeing compared varied from 431 to 841 seconds on this dataset, where test\npieces had a characteristic life of 8,971 seconds. The second dataset was\ncollected from a group of pumps used to circulate a water and magnetite\nsolution within a plant. The data therefore originated from a repaired system\naffected by reliability degradation. When optimized, the multi-layer perceptron\nneural networks trained with the Levenberg-Marquardt algorithm and the general\nregression neural network produced a sum-of-squares error within 11.1% of each\nother. The potential for using neural networks for residual life prediction and\nthe advantage of incorporating condition-based data into the model were proven\nfor both examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2007 05:52:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Herzog", "M. A.", ""], ["Marwala", "T.", ""], ["Heyns", "P. S.", ""]]}, {"id": "0705.1672", "submitter": "Tshilidzi Marwala", "authors": "L. Mdlazi, T. Marwala, C.J. Stander, C. Scheffer and P.S. Heyns", "title": "Principal Component Analysis and Automatic Relevance Determination in\n  Damage Identification", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  This paper compares two neural network input selection schemes, the Principal\nComponent Analysis (PCA) and the Automatic Relevance Determination (ARD) based\non Mac-Kay's evidence framework. The PCA takes all the input data and projects\nit onto a lower dimension space, thereby reduc-ing the dimension of the input\nspace. This input reduction method often results with parameters that have\nsignificant influence on the dynamics of the data being diluted by those that\ndo not influence the dynamics of the data. The ARD selects the most relevant\ninput parameters and discards those that do not contribute significantly to the\ndynamics of the data being modelled. The ARD sometimes results with important\ninput parameters being discarded thereby compromising the dynamics of the data.\nThe PCA and ARD methods are implemented together with a Multi-Layer-Perceptron\n(MLP) network for fault identification in structures and the performance of the\ntwo methods is as-sessed. It is observed that ARD and PCA give similar\naccu-racy levels when used as input-selection schemes. There-fore, the choice\nof input-selection scheme is dependent on the nature of the data being\nprocessed.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:35:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Mdlazi", "L.", ""], ["Marwala", "T.", ""], ["Stander", "C. J.", ""], ["Scheffer", "C.", ""], ["Heyns", "P. S.", ""]]}, {"id": "0705.1673", "submitter": "Tshilidzi Marwala", "authors": "L. Mdlazi, C.J. Stander, P.S. Heyns and T. Marwala", "title": "Using artificial intelligence for data reduction in mechanical\n  engineering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.NE", "license": null, "abstract": "  In this paper artificial neural networks and support vector machines are used\nto reduce the amount of vibration data that is required to estimate the Time\nDomain Average of a gear vibration signal. Two models for estimating the time\ndomain average of a gear vibration signal are proposed. The models are tested\non data from an accelerated gear life test rig. Experimental results indicate\nthat the required data for calculating the Time Domain Average of a gear\nvibration signal can be reduced by up to 75% when the proposed models are\nimplemented.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:49:40 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Mdlazi", "L.", ""], ["Stander", "C. J.", ""], ["Heyns", "P. S.", ""], ["Marwala", "T.", ""]]}, {"id": "0705.1674", "submitter": "Tshilidzi Marwala", "authors": "Lukasz A Machowski, Tshilidzi Marwala", "title": "Evolutionary Optimisation Methods for Template Based Image Registration", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CV", "license": null, "abstract": "  This paper investigates the use of evolutionary optimisation techniques to\nregister a template with a scene image. An error function is created to measure\nthe correspondence of the template to the image. The problem presented here is\nto optimise the horizontal, vertical and scaling parameters that register the\ntemplate with the scene. The Genetic Algorithm, Simulated Annealing and\nParticle Swarm Optimisations are compared to a Nelder-Mead Simplex optimisation\nwith starting points chosen in a pre-processing stage. The paper investigates\nthe precision and accuracy of each method and shows that all four methods\nperform favourably for image registration. SA is the most precise, GA is the\nmost accurate. PSO is a good mix of both and the Simplex method returns local\nminima the most. A pre-processing stage should be investigated for the\nevolutionary methods in order to improve performance. Discrete versions of the\noptimisation methods should be investigated to further improve computational\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:51:36 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Machowski", "Lukasz A", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "0705.1680", "submitter": "Tshilidzi Marwala", "authors": "Michael Maio Pires, Tshilidzi Marwala", "title": "Option Pricing Using Bayesian Neural Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  Options have provided a field of much study because of the complexity\ninvolved in pricing them. The Black-Scholes equations were developed to price\noptions but they are only valid for European styled options. There is added\ncomplexity when trying to price American styled options and this is why the use\nof neural networks has been proposed. Neural Networks are able to predict\noutcomes based on past data. The inputs to the networks here are stock\nvolatility, strike price and time to maturity with the output of the network\nbeing the call option price. There are two techniques for Bayesian neural\nnetworks used. One is Automatic Relevance Determination (for Gaussian\nApproximation) and one is a Hybrid Monte Carlo method, both used with\nMulti-Layer Perceptrons.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2007 15:55:31 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Pires", "Michael Maio", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "0705.1759", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Finite Element Model Updating Using Response Surface Method", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  This paper proposes the response surface method for finite element model\nupdating. The response surface method is implemented by approximating the\nfinite element model surface response equation by a multi-layer perceptron. The\nupdated parameters of the finite element model were calculated using genetic\nalgorithm by optimizing the surface response equation. The proposed method was\ncompared to the existing methods that use simulated annealing or genetic\nalgorithm together with a full finite element model for finite element model\nupdating. The proposed method was tested on an unsymmetri-cal H-shaped\nstructure. It was observed that the proposed method gave the updated natural\nfrequen-cies and mode shapes that were of the same order of accuracy as those\ngiven by simulated annealing and genetic algorithm. Furthermore, it was\nobserved that the response surface method achieved these results at a\ncomputational speed that was more than 2.5 times as fast as the genetic\nalgorithm and a full finite element model and 24 times faster than the\nsimulated annealing.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 10:25:22 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "0705.1760", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Dynamic Model Updating Using Particle Swarm Optimization Method", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": null, "abstract": "  This paper proposes the use of particle swarm optimization method (PSO) for\nfinite element (FE) model updating. The PSO method is compared to the existing\nmethods that use simulated annealing (SA) or genetic algorithms (GA) for FE\nmodel for model updating. The proposed method is tested on an unsymmetrical\nH-shaped structure. It is observed that the proposed method gives updated\nnatural frequencies the most accurate and followed by those given by an updated\nmodel that was obtained using the GA and a full FE model. It is also observed\nthat the proposed method gives updated mode shapes that are best correlated to\nthe measured ones, followed by those given by an updated model that was\nobtained using the SA and a full FE model. Furthermore, it is observed that the\nPSO achieves this accuracy at a computational speed that is faster than that by\nthe GA and a full FE model which is faster than the SA and a full FE model.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2007 10:27:07 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "0705.2604", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Christina Busisiwe Vilakazi", "title": "Computational Intelligence for Condition Monitoring", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": null, "abstract": "  Condition monitoring techniques are described in this chapter. Two aspects of\ncondition monitoring process are considered: (1) feature extraction; and (2)\ncondition classification. Feature extraction methods described and implemented\nare fractals, Kurtosis and Mel-frequency Cepstral Coefficients. Classification\nmethods described and implemented are support vector machines (SVM), hidden\nMarkov models (HMM), Gaussian mixture models (GMM) and extension neural\nnetworks (ENN). The effectiveness of these features were tested using SVM, HMM,\nGMM and ENN on condition monitoring of bearings and are found to give good\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2007 21:20:58 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Vilakazi", "Christina Busisiwe", ""]]}]