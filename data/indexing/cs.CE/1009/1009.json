[{"id": "1009.1446", "submitter": "Sanmay Das", "authors": "Aseem Brahma, Sanmay Das and Malik Magdon-Ismail", "title": "Comparing Prediction Market Structures, With an Application to Market\n  Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring sufficient liquidity is one of the key challenges for designers of\nprediction markets. Various market making algorithms have been proposed in the\nliterature and deployed in practice, but there has been little effort to\nevaluate their benefits and disadvantages in a systematic manner. We introduce\na novel experimental design for comparing market structures in live trading\nthat ensures fair comparison between two different microstructures with the\nsame trading population. Participants trade on outcomes related to a\ntwo-dimensional random walk that they observe on their computer screens. They\ncan simultaneously trade in two markets, corresponding to the independent\nhorizontal and vertical random walks. We use this experimental design to\ncompare the popular inventory-based logarithmic market scoring rule (LMSR)\nmarket maker and a new information based Bayesian market maker (BMM). Our\nexperiments reveal that BMM can offer significant benefits in terms of price\nstability and expected loss when controlling for liquidity; the caveat is that,\nunlike LMSR, BMM does not guarantee bounded loss. Our investigation also\nelucidates some general properties of market makers in prediction markets. In\nparticular, there is an inherent tradeoff between adaptability to market shocks\nand convergence during market equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 8 Sep 2010 03:26:27 GMT"}], "update_date": "2010-09-09", "authors_parsed": [["Brahma", "Aseem", ""], ["Das", "Sanmay", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1009.3771", "submitter": "Germ\\'an Vidal", "authors": "Nicos Angelopoulos and Paul Taylor", "title": "An extensible web interface for databases and its application to storing\n  biochemical data", "comments": "Online proceedings of the Joint Workshop on Implementation of\n  Constraint Logic Programming Systems and Logic-based Methods in Programming\n  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a generic web-based database interface implemented in\nProlog. We discuss the advantages of the implementation platform and\ndemonstrate the system's applicability in providing access to integrated\nbiochemical data. Our system exploits two libraries of SWI-Prolog to create a\nschema-transparent interface within a relational setting. As is expected in\ndeclarative programming, the interface was written with minimal programming\neffort due to the high level of the language and its suitability to the task.\nWe highlight two of Prolog's features that are well suited to the task at hand:\nterm representation of structured documents and relational nature of Prolog\nwhich facilitates transparent integration of relational databases. Although we\ndeveloped the system for accessing in-house biochemical and genomic data the\ninterface is generic and provides a number of extensible features. We describe\nsome of these features with references to our research databases. Finally we\noutline an in-house library that facilitates interaction between Prolog and the\nR statistical package. We describe how it has been employed in the present\ncontext to store output from statistical analysis on to the database.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 11:06:25 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Angelopoulos", "Nicos", ""], ["Taylor", "Paul", ""]]}, {"id": "1009.3984", "submitter": "Hieu Dinh", "authors": "Hieu Dinh and Sanguthevar Rajasekaran", "title": "A memory-efficient data structure representing exact-match overlap\n  graphs with application for next generation DNA assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exact-match overlap graph of $n$ given strings of length $\\ell$ is an\nedge-weighted graph in which each vertex is associated with a string and there\nis an edge $(x,y)$ of weight $\\omega = \\ell - |ov_{max}(x,y)|$ if and only if\n$\\omega \\leq \\lambda$, where $|ov_{max}(x,y)|$ is the length of $ov_{max}(x,y)$\nand $\\lambda$ is a given threshold. In this paper, we show that the exact-match\noverlap graphs can be represented by a compact data structure that can be\nstored using at most $(2\\lambda -1 )(2\\lceil\\log n\\rceil +\n\\lceil\\log\\lambda\\rceil)n$ bits with a guarantee that the basic operation of\naccessing an edge takes $O(\\log \\lambda)$ time.\n  Exact-match overlap graphs have been broadly used in the context of DNA\nassembly and the \\emph{shortest super string problem} where the number of\nstrings $n$ ranges from a couple of thousands to a couple of billions, the\nlength $\\ell$ of the strings is from 25 to 1000, depending on DNA sequencing\ntechnologies. However, many DNA assemblers using overlap graphs are facing a\nmajor problem of constructing and storing them. Especially, it is impossible\nfor these DNA assemblers to handle the huge amount of data produced by the next\ngeneration sequencing technologies where the number of strings $n$ is usually\nvery large ranging from hundred million to a couple of billions. In fact, to\nour best knowledge there is no DNA assemblers that can handle such a large\nnumber of strings. Fortunately, with our compact data structure, the major\nproblem of constructing and storing overlap graphs is practically solved since\nit only requires linear time and and linear memory. As a result, it opens the\ndoor of possibilities to build a DNA assembler that can handle large-scale\ndatasets efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 02:39:34 GMT"}], "update_date": "2010-09-22", "authors_parsed": [["Dinh", "Hieu", ""], ["Rajasekaran", "Sanguthevar", ""]]}, {"id": "1009.4683", "submitter": "Malik Magdon-Ismail", "authors": "Victor Boyarshinov and Malik Magdon-Ismail", "title": "Efficient Computation of Optimal Trading Strategies", "comments": "45 pages; working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the return series for a set of instruments, a \\emph{trading strategy}\nis a switching function that transfers wealth from one instrument to another at\nspecified times. We present efficient algorithms for constructing (ex-post)\ntrading strategies that are optimal with respect to the total return, the\nSterling ratio and the Sharpe ratio. Such ex-post optimal strategies are useful\nanalysis tools. They can be used to analyze the \"profitability of a market\" in\nterms of optimal trading; to develop benchmarks against which real trading can\nbe compared; and, within an inductive framework, the optimal trades can be used\nto to teach learning systems (predictors) which are then used to identify\nfuture trading opportunities.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 19:18:23 GMT"}], "update_date": "2010-09-24", "authors_parsed": [["Boyarshinov", "Victor", ""], ["Magdon-Ismail", "Malik", ""]]}, {"id": "1009.4975", "submitter": "Eric de Sturler", "authors": "Shun Wang, Eric de Sturler, and Glaucio H. Paulino", "title": "Dynamic Adaptive Mesh Refinement for Topology Optimization", "comments": "adaptive mesh refinement, topology optimization, iterative solvers", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved method for topology optimization with both adaptive\nmesh refinement and derefinement. Since the total volume fraction in topology\noptimization is usually modest, after a few initial iterations the domain of\ncomputation is largely void. Hence, it is inefficient to have many small\nelements, in such regions, that contribute significantly to the overall\ncomputational cost but contribute little to the accuracy of computation and\ndesign. At the same time, we want high spatial resolution for accurate\nthree-dimensional designs to avoid postprocessing or interpretation as much as\npossible. Dynamic adaptive mesh refinement (AMR) offers the possibility to\nbalance these two requirements. We discuss requirements on AMR for topology\noptimization and the algorithmic features to implement them. The numerical\ndesign problems demonstrate (1) that our AMR strategy for topology optimization\nleads to designs that are equivalent to optimal designs on uniform meshes, (2)\nhow AMR strategies that do not satisfy the postulated requirements may lead to\nsuboptimal designs, and (3) that our AMR strategy significantly reduces the\ntime to compute optimal designs.\n", "versions": [{"version": "v1", "created": "Sat, 25 Sep 2010 05:49:04 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Wang", "Shun", ""], ["de Sturler", "Eric", ""], ["Paulino", "Glaucio H.", ""]]}, {"id": "1009.6079", "submitter": "Jian Wang", "authors": "Jian Wang, Jianshu Chen, Jian Yuan, Ning Ge and Shuangqing Wei", "title": "A Multi-Interference-Channel Matrix Pair Beamformer for CDMA Systems", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Matrix pair beamformer (MPB) is a promising blind beamformer which exploits\nthe temporal signature of the signal of interest (SOI) to acquire its spatial\nstatistical information. It does not need any knowledge of directional\ninformation or training sequences. However, the major problem of the existing\nMPBs is that they have serious threshold effects and the thresholds will grow\nas the interference power increases or even approach infinity. In particular,\nthis issue prevails in scenarios with structured interference, such as,\nperiodically repeated white noise, tones, or MAIs in multipath channels. In\nthis paper, we will first present the principles for designing the projection\nspace of the MPB which are closely correlated with the ability of suppressing\nstructured interference and system finite sample performance. Then a\nmultiple-interference-channel based matrix pair beamformer (MIC-MPB) for CDMA\nsystems is developed according to the principles. In order to adapt to dynamic\nchannels, an adaptive algorithm for the beamformer is also proposed.\nTheoretical analysis and simulation results show that the proposed beamformer\nhas a small and bounded threshold when the interference power increases.\nPerformance comparisons of the MIC-MPB and the existing MPBs in various\nscenarios via a number of numerical examples are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 09:23:05 GMT"}, {"version": "v2", "created": "Fri, 1 Oct 2010 08:31:47 GMT"}], "update_date": "2010-10-04", "authors_parsed": [["Wang", "Jian", ""], ["Chen", "Jianshu", ""], ["Yuan", "Jian", ""], ["Ge", "Ning", ""], ["Wei", "Shuangqing", ""]]}, {"id": "1009.6119", "submitter": "Clifton Phua", "authors": "Clifton Phua, Vincent Lee, Kate Smith and Ross Gayler", "title": "A Comprehensive Survey of Data Mining-based Fraud Detection Research", "comments": "14 pages", "journal-ref": null, "doi": "10.1016/j.chb.2012.01.002", "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey paper categorises, compares, and summarises from almost all\npublished technical and review articles in automated fraud detection within the\nlast 10 years. It defines the professional fraudster, formalises the main types\nand subtypes of known fraud, and presents the nature of data evidence collected\nwithin affected industries. Within the business context of mining the data to\nachieve higher cost savings, this research presents methods and techniques\ntogether with their problems. Compared to all related reviews on fraud\ndetection, this survey covers much more technical articles and is the only one,\nto the best of our knowledge, which proposes alternative data and solutions\nfrom related domains.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 13:06:12 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Phua", "Clifton", ""], ["Lee", "Vincent", ""], ["Smith", "Kate", ""], ["Gayler", "Ross", ""]]}]