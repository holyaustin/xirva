[{"id": "2106.00192", "submitter": "Sundong Kim", "authors": "Assem Zhunis and Tung-Duong Mai and Sundong Kim", "title": "Responses to COVID-19 with Probabilistic Programming", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The COVID-19 pandemic left its unique mark on the 21st century as one of the\nmost significant disasters in history, triggering governments all over the\nworld to respond with a wide range of interventions. However, these\nrestrictions come with a substantial price tag. It is crucial for governments\nto form anti-virus strategies that balance the trade-off between protecting\npublic health and minimizing the economic cost. This work proposes a\nprobabilistic programming method to quantify the efficiency of major\nnon-pharmaceutical interventions. We present a generative simulation model that\naccounts for the economic and human capital cost of adopting such strategies,\nand provide an end-to-end pipeline to simulate the virus spread and the\nincurred loss of various policy combinations. By investigating the national\nresponse in 10 countries covering four continents, we found that social\ndistancing coupled with contact tracing is the most successful policy, reducing\nthe virus transmission rate by 96\\% along with a 98\\% reduction in economic and\nhuman capital loss. Together with experimental results, we open-sourced a\nframework to test the efficacy of each policy combination.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 02:40:49 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhunis", "Assem", ""], ["Mai", "Tung-Duong", ""], ["Kim", "Sundong", ""]]}, {"id": "2106.00196", "submitter": "Misun Min Dr", "authors": "Yu-Hsiang Lan, Paul Fischer, Elia Merzari, Misun Min", "title": "All-Hex Meshing Strategies For Densely Packed Spheres", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an all-hex meshing strategy for the interstitial space in beds of\ndensely packed spheres that is tailored to turbulent flow simulations based on\nthe spectral element method (SEM). The SEM achieves resolution through elevated\npolynomial order N and requires two to three orders of magnitude fewer elements\nthan standard finite element approaches do. These reduced element counts place\nstringent requirements on mesh quality and conformity. Our meshing algorithm is\nbased on a Voronoi decomposition of the sphere centers. Facets of the Voronoi\ncells are tessellated into quads that are swept to the sphere surface to\ngenerate a high-quality base mesh. Refinements to the algorithm include edge\ncollapse to remove slivers, node insertion to balance resolution, localized\nrefinement in the radial direction about each sphere, and mesh optimization. We\ndemonstrate geometries with 10^2-10^5 spheres using approximately 300 elements\nper sphere (for three radial layers), along with mesh quality metrics, timings,\nflow simulations, and solver performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 02:49:50 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 14:55:57 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lan", "Yu-Hsiang", ""], ["Fischer", "Paul", ""], ["Merzari", "Elia", ""], ["Min", "Misun", ""]]}, {"id": "2106.00313", "submitter": "Julien Dular", "authors": "Julien Dular, Mane Harutyunyan, Lorenzo Bortot, Sebastian Schoeps,\n  Benoit Vanderheyden and Christophe Geuzaine", "title": "On the Stability of Mixed Finite-Element Formulations for\n  High-Temperature Superconductors", "comments": null, "journal-ref": null, "doi": "10.1109/TASC.2021.3098724", "report-no": null, "categories": "math.NA cs.CE cs.NA physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present and analyze the numerical stability of two coupled\nfinite element formulations. The first one is the h-a-formulation and is well\nsuited for modeling systems with superconductors and ferromagnetic materials.\nThe second one, the so-called t-a-formulation with thin-shell approximation,\napplies for systems with thin superconducting domains. Both formulations\ninvolve two coupled unknown fields and are mixed on the coupling interfaces.\nFunction spaces in mixed formulations must satisfy compatibility conditions to\nensure stability of the problem and reliability of the numerical solution. We\npropose stable choices of function spaces using hierarchical basis functions\nand demonstrate the effectiveness of the approach on simple 2D examples.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 08:43:25 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dular", "Julien", ""], ["Harutyunyan", "Mane", ""], ["Bortot", "Lorenzo", ""], ["Schoeps", "Sebastian", ""], ["Vanderheyden", "Benoit", ""], ["Geuzaine", "Christophe", ""]]}, {"id": "2106.00570", "submitter": "Yongxing Wang", "authors": "Yongxing Wang, Hazim A. Hamad, Jochen Voss and Harvey M. Thompson", "title": "Robust design optimisation of continuous flow polymerase chain reaction\n  thermal flow systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents an efficient methodology for the robust optimisation of\nContinuous Flow Polymerase Chain Reaction (CFPCR) devices. It enables the\neffects of uncertainties in device geometry, due to manufacturing tolerances,\non the competing objectives of minimising the temperature deviations within the\nCFPCR thermal zones, together with minimising the pressure drop across the\ndevice, to be explored. We first validate that our training data from conjugate\nheat transfer simulations of the CFPCR thermal flow problems is noise free and\nthen combine a deterministic surrogate model, based on the mean of a Gaussian\nProcess Regression (GPR) simulator, with Polynomial Chaos Expansions (PCE) to\npropagate the manufacturing uncertainties in the geometry design variables into\nthe optimisation outputs. The resultant probabilistic model is used to solve a\nseries of robust optimisation problems. The influence of the robust problem\nformulation and constraints on the design conservatism of the robust optima in\ncomparison with the corresponding deterministic cases is explored briefly.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:33:45 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Yongxing", ""], ["Hamad", "Hazim A.", ""], ["Voss", "Jochen", ""], ["Thompson", "Harvey M.", ""]]}, {"id": "2106.00571", "submitter": "Ivan Fumagalli", "authors": "Ivan Fumagalli", "title": "A reduced 3D-0D FSI model of the aortic valve including leaflets\n  curvature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, we propose a novel lumped-parameter model for the\ndescription of the aortic valve dynamics, including elastic effects associated\nto the leaflets' curvature. The introduction of a lumped-parameter model based\non momentum balance entails an easier calibration of the parameter models, that\nare instead typically numerous in phenomenological-based models. This model is\ncoupled with 3D Navier-Stokes equations describing the blood flow, where the\nvalve surface is represented by a resistive method, and valve leaflets velocity\nis taken into consideration. The resulting reduced fluid-structure interaction\nproblem has a computational cost that is comparable with the solution of a\nprescribed-motion fluid dynamics problem. A SUPG-PSPG stabilized finite element\nscheme is adopted for the discretization of the coupled problem, and the\ncomputational results show the suitability of the system in representing the\nleaflets motion, the blood flow in the ascending aorta, and the pressure jump\nacross the leaflets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 15:34:09 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Fumagalli", "Ivan", ""]]}, {"id": "2106.00755", "submitter": "Americo Cunha Jr", "authors": "Americo Cunha Jr, Luis Fernando Figueira da Silva", "title": "Assessment of a transient homogeneous reactor through in situ adaptive\n  tabulation", "comments": null, "journal-ref": "Journal of the Brazilian Society of Mechanical Sciences and\n  Engineering, vol. 36, pp. 377, 2014", "doi": "10.1007/s40430-013-0080-4", "report-no": null, "categories": "physics.flu-dyn cs.CE math.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of computational models for the numerical simulation of\nchemically reacting flows operating in the turbulent regime requires the\nsolution of partial differential equations that represent the balance of mass,\nlinear momentum, chemical species, and energy. The chemical reactions of the\nmodel may involve detailed reaction mechanisms for the description of the\nphysicochemical phenomena. One of the biggest challenges is the stiffness of\nthe numerical simulation of these models and the nonlinear nature of species\nrate of reaction. This work presents a study of in situ adaptive tabulation\n(ISAT) technique, focusing on the accuracy, efficiency, and memory usage in the\nsimulation of homogeneous stirred reactor models using simple and complex\nreaction mechanisms. The combustion of carbon monoxide with oxygen and methane\nwith air mixtures are considered, using detailed reaction mechanisms with 4 and\n53 species, 3 and 325 reactions, respectively. The results of these simulations\nindicate that the developed implementation of ISAT technique has a absolute\nglobal error smaller than 1 %. Moreover, ISAT technique provides gains, in\nterms of computational time, of up to 80% when compared with the direct\nintegration of the full chemical kinetics. However, in terms of memory usage\nthe present implementation of ISAT technique is found to be excessively\ndemanding.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:09:41 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Cunha", "Americo", "Jr"], ["da Silva", "Luis Fernando Figueira", ""]]}, {"id": "2106.00927", "submitter": "Yuanda Xu", "authors": "Xufei Wang, Yuanda Xu, Han Zheng, Kuang Yu", "title": "An Extendible, Graph-Neural-Network-Based Approach for Accurate Force\n  Field Development of Large Flexible Organic Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cond-mat.soft cs.CE cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An accurate force field is the key to the success of all molecular mechanics\nsimulations on organic polymers and biomolecules. Accuracy beyond density\nfunctional theory is often needed to describe the intermolecular interactions,\nwhile most correlated wavefunction (CW) methods are prohibitively expensive for\nlarge molecules. Therefore, it posts a great challenge to develop an extendible\nab initio force field for large flexible organic molecules at CW level of\naccuracy. In this work, we face this challenge by combining the physics-driven\nnonbonding potential with a data-driven subgraph neural network bonding model\n(named sGNN). Tests on polyethylene glycol polymer chains show that our\nstrategy is highly accurate and robust for molecules of different sizes.\nTherefore, we can develop the force field from small molecular fragments (with\nsizes easily accessible to CW methods) and safely transfer it to large\npolymers, thus opening a new path to the next-generation organic force fields.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 04:12:54 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xufei", ""], ["Xu", "Yuanda", ""], ["Zheng", "Han", ""], ["Yu", "Kuang", ""]]}, {"id": "2106.00982", "submitter": "Yongxing Wang", "authors": "Yongxing Wang", "title": "A monolithic one-velocity-field optimal control formulation for\n  fluid-structure interaction problems with large solid deformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this article, we formulate a monolithic optimal control method for general\ntime-dependent Fluid-Structure Interaction (FSI) systems with large solid\ndeformation. We consider a displacement-tracking type of objective with a\nconstraint of the solid velocity, tackle the time-dependent control problems by\na piecewise-in-time control, cope with large solid displacement using a\none-velocity fictitious domain method, and solve the fully-coupled FSI and the\ncorresponding adjoint equations in a monolithic manner. We implement the\nproposed method in the open-source software package FreeFEM++ and assess it by\nthree numerical experiments, in the aspects of stability of the numerical\nscheme for different regularisation parameters, and efficiency of reducing the\nobjective function with control of the solid velocity.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:56:08 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Yongxing", ""]]}, {"id": "2106.01028", "submitter": "Fangying Chen", "authors": "Fangying Chen, Junyoung Park, Jinkyoo Park", "title": "A Hypergraph Convolutional Neural Network for Molecular Properties\n  Prediction using Functional Group", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Molecular Hypergraph Convolutional Network (MolHGCN) that\npredicts the molecular properties of a molecule using the atom and functional\ngroup information as inputs. Molecules can contain many types of functional\ngroups, which will affect the properties the molecules. For example, the\ntoxicity of a molecule is associated with toxicophores, such as nitroaromatic\ngroups and thiourea. Conventional graph-based methods that consider the\npair-wise interactions between nodes are inefficient in expressing the complex\nrelationship between multiple nodes in a graph flexibly, and applying\nmulti-hops may result in oversmoothing and overfitting problems. Hence, we\npropose MolHGCN to capture the substructural difference between molecules using\nthe atom and functional group information. MolHGCN constructs a hypergraph\nrepresentation of a molecule using functional group information from the input\nSMILES strings, extracts hidden representation using a two-stage message\npassing process (atom and functional group message passing), and predicts the\nproperties of the molecules using the extracted hidden representation. We\nevaluate the performance of our model using Tox21, ClinTox, SIDER, BBBP, BACE,\nESOL, FreeSolv and Lipophilicity datasets. We show that our model is able to\noutperform other baseline methods for most of the datasets. We particularly\nshow that incorporating functional group information along with atom\ninformation results in better separability in the latent space, thus increasing\nthe prediction accuracy of the molecule property prediction.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 08:49:24 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 04:30:36 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Chen", "Fangying", ""], ["Park", "Junyoung", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2106.01200", "submitter": "Karel J.  in 't Hout", "authors": "Karel in 't Hout and Jacob Snoeijer", "title": "Numerical valuation of American basket options via partial differential\n  complementarity problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the principal component analysis based approach introduced by\nReisinger & Wittum (2007) and the comonotonic approach considered by Hanbali &\nLinders (2019) for the approximation of American basket option values via\nmultidimensional partial differential complementarity problems (PDCPs). Both\napproximation approaches require the solution of just a limited number of\nlow-dimensional PDCPs. It is demonstrated by ample numerical experiments that\nthey define approximations that lie close to each other. Next, an efficient\ndiscretisation of the pertinent PDCPs is presented that leads to a favourable\nconvergence behaviour.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:44:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Hout", "Karel in 't", ""], ["Snoeijer", "Jacob", ""]]}, {"id": "2106.01329", "submitter": "Giacomo Indiveri", "authors": "Giacomo Indiveri", "title": "Introducing \"Neuromorphic Computing and Engineering\"", "comments": "NCE Editorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CE cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard nature of computing is currently being challenged by a range of\nproblems that start to hinder technological progress. One of the strategies\nbeing proposed to address some of these problems is to develop novel\nbrain-inspired processing methods and technologies, and apply them to a wide\nrange of application scenarios. This is an extremely challenging endeavor that\nrequires researchers in multiple disciplines to combine their efforts and\nco-design at the same time the processing methods, the supporting computing\narchitectures, and their underlying technologies. The journal ``Neuromorphic\nComputing and Engineering'' (NCE) has been launched to support this new\ncommunity in this effort and provide a forum and repository for presenting and\ndiscussing its latest advances. Through close collaboration with our colleagues\non the editorial team, the scope and characteristics of NCE have been designed\nto ensure it serves a growing transdisciplinary and dynamic community across\nacademia and industry.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 20:12:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Indiveri", "Giacomo", ""]]}, {"id": "2106.01592", "submitter": "Shuo Jiang", "authors": "Shuo Jiang, Jie Hu, Kristin L. Wood, Jianxi Luo", "title": "Data-Driven Design-by-Analogy: State of the Art and Future Directions", "comments": "A Preprint Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design-by-Analogy (DbA) is a design methodology wherein new solutions,\nopportunities or designs are generated in a target domain based on inspiration\ndrawn from a source domain; it can benefit designers in mitigating design\nfixation and improving design ideation outcomes. Recently, the increasingly\navailable design databases and rapidly advancing data science and artificial\nintelligence technologies have presented new opportunities for developing\ndata-driven methods and tools for DbA support. In this study, we survey\nexisting data-driven DbA studies and categorize individual studies according to\nthe data, methods, and applications in four categories, namely, analogy\nencoding, retrieval, mapping, and evaluation. Based on both nuanced organic\nreview and structured analysis, this paper elucidates the state of the art of\ndata-driven DbA research to date and benchmarks it with the frontier of data\nscience and AI research to identify promising research opportunities and\ndirections for the field. Finally, we propose a future conceptual data-driven\nDbA system that integrates all propositions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 04:35:34 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Jiang", "Shuo", ""], ["Hu", "Jie", ""], ["Wood", "Kristin L.", ""], ["Luo", "Jianxi", ""]]}, {"id": "2106.01870", "submitter": "James Hsin-Yu Chiang", "authors": "Massimo Bartoletti, James Hsin-yu Chiang, Alberto Lluch-Lafuente", "title": "Maximizing Extractable Value from Automated Market Makers", "comments": "12 pages. Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CE cs.FL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Market Makers (AMMs) are decentralized applications that allow\nusers to exchange crypto-tokens without the need to find a matching exchange\norder. AMMs are one of the most successful DeFi use case so far, as the main\nAMM platforms UniSwap and Balancer process a daily volume of transactions worth\nbillions of dollars. Despite this success story, AMMs are well-known to suffer\nfrom transaction-ordering issues: indeed, adversaries can frontrun user\ntransactions to increase their gain to the detriment of honest users. Being\nspecifically designated to arrange user transactions into blocks, miners can\neasily play the role of adversary, by suitably selecting and ordering\ntransactions - and possibly inserting their own - to increase their gain. In\nthis paper we formally characterize rational miners as players which follow an\noptimal strategy in the mining game. We identify relevant variants of the game,\ncorresponding to specific real-world constraints that a miner might have. We\ndevise effective procedures to construct solutions to mining game, both in its\nmost general form and in some relevant variants. Most notably, miners can\nexploit these solutions to maximize the value extracted from user transactions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 10:32:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bartoletti", "Massimo", ""], ["Chiang", "James Hsin-yu", ""], ["Lluch-Lafuente", "Alberto", ""]]}, {"id": "2106.02176", "submitter": "Muhao Chen", "authors": "Shuo Ma, Muhao Chen and Robert E. Skelton", "title": "Tensegrity system dynamics based on finite element method", "comments": "13 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a finite element analysis approach to non-linear and\nlinearized tensegrity dynamics based on the Lagrangian method with nodal\ncoordinate vectors as the generalized coordinates. In this paper, nonlinear\ntensegrity dynamics with and without constraints are first derived. The\nequilibrium equations in three standard forms (in terms of nodal coordinate,\nforce density, and force vectors) and the compatibility equation are also\ngiven. Then, we present the linearized dynamics and modal analysis equations\nwith and without constraints. The developed approach is capable of conducting\nthe following comprehensive dynamics studies for any tensegrity structures\naccurately: 1. Performing rigid body dynamics with acceptable errors, which is\nachieved by setting relatively high stiffness for bars in the simulation. 2.\nSimulating FEM dynamics accurately, where bars and strings can have elastic or\nplastic deformations. 3. Dealing with various kinds of boundary conditions, for\nexample, fixing or applying static/dynamic loads at any nodes in any direction\n(i.e., gravitational force, some specified forces, or arbitrary seismic\nvibrations). 4. Conducting accurate modal analysis, including natural frequency\nand corresponding modes. Three examples, a double pendulum, a cantilever truss\nwith external force, and a double prism tensegrity tower, are carefully\nselected and studied. The results are compared with rigid body dynamics and FEM\nsoftware ANSYS. This study provides a deep insight into structures, materials,\nperformances, as well as an interface towards integrating control theories.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 23:47:22 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Ma", "Shuo", ""], ["Chen", "Muhao", ""], ["Skelton", "Robert E.", ""]]}, {"id": "2106.02338", "submitter": "My Ha Dao", "authors": "My Ha Dao", "title": "Projection-Based Reduced Order Model for Simulations of Nonlinear Flows\n  with Multiple Moving Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a reduced order approach for transient modeling of\nmultiple moving objects in nonlinear crossflows. The Proper Orthogonal\nDecomposition method and the Galerkin projection are used to construct a\nreduced version of the nonlinear Navier-Stokes equations. The Galerkin\nprojection implemented in OpenFOAM platform allows accurate impositions of\narbitrary time-dependent boundary conditions at the moving boundaries. A\nmodelling technique based on moving domain and immersed boundary techniques is\nproposed to overcome the challenge of handling moving boundaries due to\nmovements of the multiple objects. The model is demonstrated capable to capture\nthe complex flow fields past one and two oscillating cylinders and the forces\nacting on the cylinders. Simulation time could be reduced by more than three\norders for a small case on a fine mesh as compared to an existing method and\ncould be more for large cases. In general, the simulation time of the reduced\nmodel is of order of seconds as compared to hours of the full order\nComputational Fluid Dynamics models.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:38:23 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Dao", "My Ha", ""]]}, {"id": "2106.02608", "submitter": "Xiaojing Ye", "authors": "Shushan He, Hongyuan Zha and Xiaojing Ye", "title": "Influence Estimation and Maximization via Neural Mean-Field Dynamics", "comments": "26 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2006.09449", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.NA cs.SI math.NA math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel learning framework using neural mean-field (NMF) dynamics\nfor inference and estimation problems on heterogeneous diffusion networks. Our\nnew framework leverages the Mori-Zwanzig formalism to obtain an exact evolution\nequation of the individual node infection probabilities, which renders a delay\ndifferential equation with memory integral approximated by learnable time\nconvolution operators. Directly using information diffusion cascade data, our\nframework can simultaneously learn the structure of the diffusion network and\nthe evolution of node infection probabilities. Connections between parameter\nlearning and optimal control are also established, leading to a rigorous and\nimplementable algorithm for training NMF. Moreover, we show that the projected\ngradient descent method can be employed to solve the challenging influence\nmaximization problem, where the gradient is computed extremely fast by\nintegrating NMF forward in time just once in each iteration. Extensive\nempirical studies show that our approach is versatile and robust to variations\nof the underlying diffusion network models, and significantly outperform\nexisting approaches in accuracy and efficiency on both synthetic and real-world\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 00:02:05 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["He", "Shushan", ""], ["Zha", "Hongyuan", ""], ["Ye", "Xiaojing", ""]]}, {"id": "2106.02609", "submitter": "Toni Mancini", "authors": "Filippo Maggioli and Toni Mancini and Enrico Tronci", "title": "SBML2Modelica: integrating biochemical models within open-standard\n  simulation ecosystems", "comments": "8 pages, 4 figures", "journal-ref": "Bioinformatics, Volume 36, Issue 7, 1 April 2020, pp 2165-2172,\n  Oxford University Press", "doi": "10.1093/bioinformatics/btz860", "report-no": null, "categories": "q-bio.MN cs.CE q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Motivation: SBML is the most widespread language for the definition of\nbiochemical models. Although dozens of SBML simulators are available, there is\na general lack of support to the integration of SBML models within\nopen-standard general-purpose simulation ecosystems. This hinders co-simulation\nand integration of SBML models within larger model networks, in order to, e.g.\nenable in silico clinical trials of drugs, pharmacological protocols, or\nengineering artefacts such as biomedical devices against Virtual Physiological\nHuman models. Modelica is one of the most popular existing open-standard\ngeneral-purpose simulation languages, supported by many simulators. Modelica\nmodels are especially suited for the definition of complex networks of\nheterogeneous models from virtually all application domains. Models written in\nModelica (and in 100+ other languages) can be readily exported into black-box\nFunctional Mock-Up Units (FMUs), and seamlessly co-simulated and integrated\ninto larger model networks within open-standard language-independent simulation\necosystems.\n  Results: In order to enable SBML model integration within heterogeneous model\nnetworks, we present SBML2Modelica, a software system translating SBML models\ninto well-structured, user-intelligible, easily modifiable Modelica models.\nSBML2Modelica is SBML Level 3 Version 2-compliant and succeeds on 96.47% of the\nSBML Test Suite Core (with a few rare, intricate and easily avoidable\ncombinations of constructs unsupported and cleanly signalled to the user). Our\nexperimental campaign on 613 models from the BioModels database (with up to\n5438 variables) shows that the major open-source (general-purpose) Modelica and\nFMU simulators achieve performance comparable to state-of-the-art specialized\nSBML simulators.\n  Availability and implementation: https://bitbucket.org/mclab/sbml2modelica\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 00:21:54 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Maggioli", "Filippo", ""], ["Mancini", "Toni", ""], ["Tronci", "Enrico", ""]]}, {"id": "2106.02687", "submitter": "Christina Nasika", "authors": "Christina Nasikaa, Pedro Diez, Pierre Gerard, Thierry J. Massart and\n  Sergio Zlotnik", "title": "Towards real time assessment of earthfill dams via Model Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of Internet of Things (IoT) technologies is becoming a preferred\nsolution for the assessment of tailings dams' safety. Real-time sensor\nmonitoring proves to be a key tool for reducing the risk related to these\never-evolving earth-fill structures, that exhibit a high rate of sudden and\nhazardous failures. In order to optimally exploit real-time embankment\nmonitoring, one major hindrance has to be overcome: the creation of a\nsupporting numerical model for stability analysis, with rapid-enough response\nto perform data assimilation in real time. A model should be built, such that\nits response can be obtained faster than the physical evolution of the analyzed\nphenomenon. In this work, Reduced Order Modelling (ROM) is used to boost\ncomputational efficiency in solving the coupled hydro-mechanical system of\nequations governing the problem. The Reduced Basis method is applied to the\ncoupled hydro-mechanical equations that govern the groundwater flow, that are\nmade non-linear as a result of considering an unsaturated soil. The resulting\nmodel's performance is assessed by solving a 2D and a 3D problem relevant to\ntailings dams' safety. The ROM technique achieves a speedup of 3 to 15 times\nwith respect to the full-order model (FOM) while maintaining high levels of\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:38:30 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nasikaa", "Christina", ""], ["Diez", "Pedro", ""], ["Gerard", "Pierre", ""], ["Massart", "Thierry J.", ""], ["Zlotnik", "Sergio", ""]]}, {"id": "2106.03114", "submitter": "Thi-Hoa Nguyen", "authors": "Thi-Hoa Nguyen, Ren\\'e R. Hiemstra, Dominik Schillinger", "title": "Leveraging spectral analysis to elucidate membrane locking and unlocking\n  in isogeometric finite element formulations of the curved Euler-Bernoulli\n  beam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we initiate the use of spectral analysis for assessing locking\nphenomena in finite element formulations. We propose to ``measure'' locking by\ncomparing the difference between eigenvalue and mode error curves computed on\ncoarse meshes with ``asymptotic'' error curves computed on ``overkill'' meshes,\nboth plotted with respect to the normalized mode number. To demonstrate the\nintimate relation between membrane locking and spectral accuracy, we focus on\nthe example of a circular ring discretized with isogeometric curved\nEuler-Bernoulli beam elements. We show that the\ntransverse-displacement-dominating modes are locking-prone, while the\ncircumferential-displacement-dominating modes are naturally locking-free. We\nuse eigenvalue and mode errors to assess five isogeometric finite element\nformulations in terms of their locking-related efficiency: the\ndisplacement-based formulation with full and reduced integration and three\nlocking-free formulations based on the B-bar, discrete strain gap and\nHellinger-Reissner methods. Our study shows that spectral analysis uncovers\nlocking-related effects across the spectrum of eigenvalues and eigenmodes,\nrigorously characterizing membrane locking in the displacement-based\nformulation and unlocking in the locking-free formulations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 13:09:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nguyen", "Thi-Hoa", ""], ["Hiemstra", "Ren\u00e9 R.", ""], ["Schillinger", "Dominik", ""]]}, {"id": "2106.03160", "submitter": "Amir Esmalian", "authors": "Amir Esmalian, Wanqiu Wang, and Ali Mostafavi", "title": "Multi-agent Modeling of Hazard-Household-Infrastructure Nexus for\n  Equitable Resilience Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable integrating social equity considerations in infrastructure\nresilience assessments, this study created a new computational multi-agent\nsimulation model which enables integrated assessment of hazard, infrastructure\nsystem, and household elements and their interactions. With a focus on\nhurricane-induced power outages, the model consists of three elements: 1) the\nhazard component simulates exposure of the community to a hurricane with\nvarying intensity levels; 2) the physical infrastructure component simulates\nthe power network and its probabilistic failures and restoration under\ndifferent hazard scenarios; and 3) the households component captures the\ndynamic processes related to preparation, information seeking, and response\nactions of households facing hurricane-induced power outages. We used empirical\ndata from household surveys in conjunction with theoretical decision-making\nmodels to abstract and simulate the underlying mechanisms affecting experienced\nhardship of households. The multi-agent simulation model was then tested in the\ncontext of Harris County, Texas, and verified and validated using empirical\nresults from Hurricane Harvey in 2017. Then, the model was used to examine\neffects of different factors such as forewarning durations, social network\ntypes, and restoration and resource allocation strategies on reducing the\nsocietal impacts of service disruptions in an equitable manner. The results\nshow that improving the restoration prioritization strategy to focus on\nvulnerable populations is an effective approach, especially during\nhigh-intensity events. The results show the capability of the proposed\ncomputational model for capturing the dynamic and complex interactions in the\nnexus of humans, hazards, and infrastructure systems to better integrate\nhuman-centric aspects in resilience planning and into assessment of\ninfrastructure systems in disasters.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 15:51:32 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 03:41:13 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Esmalian", "Amir", ""], ["Wang", "Wanqiu", ""], ["Mostafavi", "Ali", ""]]}, {"id": "2106.03565", "submitter": "Marc Bernacki", "authors": "Brayan Murgas, Sebastian Florez, Nathalie Bozzolo, Julien Fausty, Marc\n  Bernacki", "title": "Comparative study and limits of different level-set formulations for the\n  modeling of anisotropic grain growth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Four different finite element level-set (FE-LS) formulations are compared for\nthe modeling of grain growth in the context of polycrystalline structures and,\nmoreover, two of them are presented for the first time using anisotropic grain\nboundary (GB) energy and mobility. Mean values and distributions are compared\nusing the four formulations. First, we present the strong and weak formulations\nfor the different models and the crystallographic parameters used at the\nmesoscopic scale. Second, some Grim Reaper analytical cases are presented and\ncompared with the simulation results, here the evolutions of individual\nmultiple junctions are followed. Additionally, large scale simulations are\npresented. Anisotropic GB energy and mobility are respectively defined as\nfunctions of the misorientation/inclination and disorientation. The evolution\nof the disorientation distribution function (DDF) is computed and its evolution\nis in accordance with prior works. We found that the formulation called\n\"Anisotropic\" is the more physical one but it could be replaced at the\nmesoscopic scale by an Isotropic formulation for simple microstructures\npresenting an initial Mackenzie-type DDF.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 13:45:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Murgas", "Brayan", ""], ["Florez", "Sebastian", ""], ["Bozzolo", "Nathalie", ""], ["Fausty", "Julien", ""], ["Bernacki", "Marc", ""]]}, {"id": "2106.03771", "submitter": "Daniel Wilke", "authors": "Daniel N. Wilke", "title": "Traction chain networks: Insights beyond force chain networks for\n  non-spherical particle systems", "comments": "19 pages; 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Force chain networks are generally applied in granular materials to gain\ninsight into inter-particle granular contact. For conservative spherical\nparticle systems, i.e. frictionless and undamped, force chains are information\ncomplete due to symmetries resulting from isotropy and constant curvature of a\nsphere. In fact, for conservative spherical particle systems, given the\ngeometry and material, the force chain network uniquely defines the contact\nstate that includes elastic forces, penetration distance, overlap volume,\ncontact areas and contact pressures in a particle system. This is, however, not\nthe case for conservative non-spherical particle systems. The reason is that a\nforce chain network is not sufficient to uniquely define the contact state in a\nconservative non-spherical particle system. Additional information is required\nto define the contact state of non-spherical granular systems. Traction chain\nnetworks are proposed to complement force chain networks for the improved\nquantification of the state of contact of a granular system.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:33:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wilke", "Daniel N.", ""]]}, {"id": "2106.03936", "submitter": "Bruno L\\'evy Ph.D.", "authors": "Bruno L\\'evy (1) ((1) Universit\\'e de Lorraine, CNRS, Inria, LORIA)", "title": "Partial Optimal Transport for a Constant-Volume Lagrangian Mesh with\n  Free Boundaries", "comments": "37 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a representation of dynamic meshes, adapted to some\nnumerical simulations that require controlling the volume of objects with free\nboundaries, such as incompressible fluid simulation, some astrophysical\nsimulations at cosmological scale, and shape/topology optimization. The\nalgorithm decomposes the simulated object into a set of convex cells called a\nLaguerre diagram, parameterized by the position of $N$ points in 3D and $N$\nadditional parameters that control the volumes of the cells. These parameters\nare found as the (unique) solution of a convex optimization problem --\nsemi-discrete Monge-Amp\\`ere equation -- stemming from optimal transport\ntheory. In this article, this setting is extended to objects with free\nboundaries and arbitrary topology, evolving in a domain of arbitrary shape, by\nsolving a partial optimal transport problem. The resulting Lagrangian scheme\nmakes it possible to accurately control the volume of the object, while\nprecisely tracking interfaces, interactions, collisions, and topology changes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 09:39:06 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["L\u00e9vy", "Bruno", "", "Universit\u00e9 de Lorraine, CNRS, Inria, LORIA"]]}, {"id": "2106.04310", "submitter": "Ioan Alexandru Puiu", "authors": "Ioan Alexandru Puiu and Raphael Andreas Hauser", "title": "Principled Data Completion of Network Constraints for Day Ahead Auctions\n  in Power Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network constraints play a key role in the price finding mechanism for\nEuropean Power Markets, but historical data is very sparse and usually\ninsufficient for many quantitative applications. We reconstruct the constraints\ndata, known as the Power Transmission Distribution Factors (PTDFs) and\nRemaining Available Margins (RAMs), by first recovering the underlying time\ndependent signals known as the Generation Shift Keys (GSKs) and Phase Angles\n(PAs), and the electricity grid characteristics, via a mathematical\noptimisation problem. This is solved by exploiting marginal convexity in\ncertain subspaces via alternating minimisation. The GSKs and PAs are then\nmapped to the PTDFs and RAMs, using the grid structure. Our reconstruction\nachieves good in-sample and out-of-sample relative errors for the PTDFs and\nRAMs. We further show that our model outperforms the naive approach, and that\nthe reconstructed GSKs and PAs recover specific structure.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 21:41:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Puiu", "Ioan Alexandru", ""], ["Hauser", "Raphael Andreas", ""]]}, {"id": "2106.04676", "submitter": "Ha Bui Prof", "authors": "Khoa M. Tran, Ha H. Bui, Giang D. Nguyen", "title": "A hybrid discrete-continuum approach to model hydro-mechanical behaviour\n  of soil during desiccation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CE cs.NA math.NA physics.flu-dyn", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Desiccation cracking in clayey soils occurs when they lose moisture, leading\nto an increase in their compressibility and hydraulic conductivity and hence\nsignificant reduction of soil strength. The prediction of desiccation cracking\nin soils is challenging due to the lack of insights into the complex coupled\nhydro-mechanical process at the grain scale. In this paper, a new hybrid\ndiscrete-continuum numerical framework, capable of capturing hydro-mechanical\nbehaviour of soil at both grain and macro scales, is proposed for predicting\ndesiccation cracking in clayey soil. In this framework, a soil layer is\nrepresented by an assembly of DEM particles, each occupies an equivalent\ncontinuum space and carries physical properties governing unsaturated flow.\nThese particles move freely in the computational space following the discrete\nelement method (DEM), while their contact network and the continuum mixture\ntheory are used to model the unsaturated flow. The dependence of\nparticle-to-particle contact behaviour on water content is represented by a\ncohesive-frictional contact model, whose material properties are governed by\nthe water content. In parallel with the theoretical development is a series of\nexperiments on 3D soil desiccation cracking to determine essential properties\nand provide data for the validation of mechanical and physical behaviour. Very\ngood agreement in both physical behaviour (e.g. evolution of water content) and\nmechanical behaviour (e.g. occurrence and development of cracks, and\ndistribution of compressive and tensile strains) demonstrates that the proposed\nframework is capable of capturing the hydro-mechanical behaviour of soil during\ndesiccation. The capability of the proposed framework facilitates numerical\nexperiments for insights into the hydro-mechanical behaviour of unsaturated\nsoils that have not been possible before.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 23:29:45 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tran", "Khoa M.", ""], ["Bui", "Ha H.", ""], ["Nguyen", "Giang D.", ""]]}, {"id": "2106.04892", "submitter": "Sebastian Florez", "authors": "Sebastian Florez, Julien Fausty, Karen Alvarado, Brayan Murgas, Marc\n  Bernacki", "title": "A 2D front-tracking Lagrangian model for the modeling of anisotropic\n  grain growth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Grain growth is a well-known and complex phenomenon occurring during\nannealing of all polycrystalline materials. Its numerical modeling is a complex\ntask when anisotropy sources such as grain orientation and grain boundary\ninclination have to be taken into account. This article presents the\napplication of the front-tracking methodology ToRealMotion introduced in\nprevious works, to the context of anisotropic grain boundary motion at the\nmesoscopic scale. The new formulation of boundary migration can take into\naccount any source of anisotropy both at grain boundaries as well as at\nmultiple junctions (MJs) (intersection point of three or more grain\nboundaries). Special attention is given to the decomposition of high-order MJs\nfor which an algorithm is proposed based on local grain boundary energy\nminimisation. Numerical tests are provided using highly heterogeneous\nconfigurations, and comparisons with a recently developed Finite-Element\nLevel-Set (FE-LS) approach are given. Finally, the computational performance of\nthe model will be studied comparing the CPU-times obtained with the same model\nbut in an isotropic context.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 08:26:16 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 12:19:07 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Florez", "Sebastian", ""], ["Fausty", "Julien", ""], ["Alvarado", "Karen", ""], ["Murgas", "Brayan", ""], ["Bernacki", "Marc", ""]]}, {"id": "2106.05158", "submitter": "Bilen Emek Abali", "authors": "Hua Yang, Bilen Emek Abali, Wolfgang H. M\\\"uller, Salma Barboura, Jia\n  Li", "title": "Verification of asymptotic homogenization method developed for periodic\n  architected materials in strain gradient continuum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strain gradient theory is an accurate model for capturing size effects and\nlocalization phenomena. However, the challenge in identification of\ncorresponding constitutive parameters limits the practical application of such\ntheory. We present and utilize asymptotic homogenization herein. All parameters\nin rank four, five, and six tensors are determined with the demonstrated\ncomputational approach. Examples for epoxy carbon fiber composite, metal matrix\ncomposite, and aluminum foam illustrate the effectiveness and versatility of\nthe proposed method. The influences of volume fraction of matrix, the stack of\nRVEs, and the varying unit cell lengths on the identified parameters are\ninvestigated. The homogenization computational tool is applicable to a wide\nclass materials and makes use of open-source codes in FEniCS.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 16:02:59 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Yang", "Hua", ""], ["Abali", "Bilen Emek", ""], ["M\u00fcller", "Wolfgang H.", ""], ["Barboura", "Salma", ""], ["Li", "Jia", ""]]}, {"id": "2106.05190", "submitter": "Thanh Binh Nguyen", "authors": "Thu Nguyen, Khoi Minh Nguyen-Duy, Duy Ho Minh Nguyen, Binh T. Nguyen,\n  and Bruce Alan Wade", "title": "DPER: Efficient Parameter Estimation for Randomly Missing Data", "comments": "28 pages, 3 tables, 40 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The missing data problem has been broadly studied in the last few decades and\nhas various applications in different areas such as statistics or\nbioinformatics. Even though many methods have been developed to tackle this\nchallenge, most of those are imputation techniques that require multiple\niterations through the data before yielding convergence. In addition, such\napproaches may introduce extra biases and noises to the estimated parameters.\nIn this work, we propose novel algorithms to find the maximum likelihood\nestimates (MLEs) for a one-class/multiple-class randomly missing data set under\nsome mild assumptions. As the computation is direct without any imputation, our\nalgorithms do not require multiple iterations through the data, thus promising\nto be less time-consuming than other methods while maintaining superior\nestimation performance. We validate these claims by empirical results on\nvarious data sets of different sizes and release all codes in a GitHub\nrepository to contribute to the research community related to this problem.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 16:37:48 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Nguyen", "Thu", ""], ["Nguyen-Duy", "Khoi Minh", ""], ["Nguyen", "Duy Ho Minh", ""], ["Nguyen", "Binh T.", ""], ["Wade", "Bruce Alan", ""]]}, {"id": "2106.05452", "submitter": "Timo Koch", "authors": "Timo Koch and Hanchuan Wu and Martin Schneider", "title": "Nonlinear mixed-dimension model for embedded tubular networks with\n  application to root water uptake", "comments": "34 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a numerical scheme for the solution of nonlinear mixed-dimensional\nPDEs describing coupled processes in embedded tubular network system in\nexchange with a bulk domain. Such problems arise in various biological and\ntechnical applications such as in the modeling of root-water uptake, heat\nexchangers, or geothermal wells. The nonlinearity appears in form of\nsolution-dependent parameters such as pressure-dependent permeability or\ntemperature-dependent thermal conductivity. We derive and analyse a numerical\nscheme based on distributing the bulk-network coupling source term by a\nsmoothing kernel with local support. By the use of local analytical solutions,\ninterface unknowns and fluxes at the bulk-network interface can be accurately\nreconstructed from coarsely resolved numerical solutions in the bulk domain.\nNumerical examples give confidence in the robustness of the method and show the\nresults in comparison to previously published methods. The new method\noutperforms these existing methods in accuracy and efficiency. In a root water\nuptake scenario, we accurately estimate the transpiration rate using only a few\nthousand 3D mesh cells and a structured cube grid whereas other\nstate-of-the-art numerical schemes require millions of cells and local grid\nrefinement to reach comparable accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 01:45:13 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:14:41 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Koch", "Timo", ""], ["Wu", "Hanchuan", ""], ["Schneider", "Martin", ""]]}, {"id": "2106.05494", "submitter": "Zhenli Xu", "authors": "Jiuyang Liang, Pan Tan, Yue Zhao, Lei Li, Shi Jin, Liang Hong and\n  Zhenli Xu", "title": "Super-Scalable Molecular Dynamics Algorithm", "comments": "20 pages, including 4 figures, 4 extended data figures and supporting\n  information", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coulomb interaction, following an inverse-square force-law, quantifies the\namount of force between two stationary, electrically charged particles. The\nlong-range nature of Coulomb interactions poses a major challenge to molecular\ndynamics simulations which are major tools for problems at the nano-/micro-\nscale. Various algorithms aim to speed up the pairwise Coulomb interactions to\na linear scaling but the poor scalability limits the size of simulated systems.\nHere, we conduct an efficient molecular dynamics algorithm with the random\nbatch Ewald method on all-atom systems where the complete Fourier components in\nthe Coulomb interaction are replaced by randomly selected mini batches. By\nsimulating the N-body systems up to 100 million particles using 10 thousand CPU\ncores, we show that this algorithm furnishes O(N) complexity, almost perfect\nscalability and an order of magnitude faster computational speed when compared\nto the existing state-of-the-art algorithms. Further examinations of our\nalgorithm on distinct systems, including pure water, micro-phase-separated\nelectrolyte and protein solution demonstrate that the spatiotemporal\ninformation on all time and length scales investigated and thermodynamic\nquantities derived from our algorithm are in perfect agreement with those\nobtained from the existing algorithms. Therefore, our algorithm provides a\nbreakthrough solution on scalability of computing the Coulomb interaction. It\nis particularly useful and cost-effective to simulate ultra-large systems,\nwhich was either impossible or very costing to conduct using existing\nalgorithms, thus would benefit the broad community of sciences.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 04:50:23 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liang", "Jiuyang", ""], ["Tan", "Pan", ""], ["Zhao", "Yue", ""], ["Li", "Lei", ""], ["Jin", "Shi", ""], ["Hong", "Liang", ""], ["Xu", "Zhenli", ""]]}, {"id": "2106.05605", "submitter": "Sebastian Florez", "authors": "Sebastian Florez, Karen Alvarado, Marc Bernacki", "title": "Statistical behaviour of interfaces subjected to curvature flow and\n  torque effects applied to microstructural evolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The movement of grain boundaries in pure metals and alloys with a low\nconcentration of dislocations has been historically proved to follow curvature\nflow behavior. This mechanism is typically known as grain growth (GG). However,\nrecent 3D in-situ experimental results tend to question this global picture\nconcerning the influence of the curvature on the kinetics of interface\nmigration. This article explains, thanks to 2D anisotropic full-field\nsimulations, how the torque effects can complexify these discussions. It is\nthen illustrated that neglecting torque effects in full-field formulations\nremains potentially a strong hypothesis. The apparent mobility can be much more\ncomplex than expected without necessarily questioning the influence of the\ncurvature on the local kinetic equation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 09:19:11 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 10:45:47 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Florez", "Sebastian", ""], ["Alvarado", "Karen", ""], ["Bernacki", "Marc", ""]]}, {"id": "2106.05722", "submitter": "Andrea Manzoni", "authors": "Stefania Fresca, Andrea Manzoni", "title": "Real-time simulation of parameter-dependent fluid flows through deep\n  learning-based reduced order models", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating fluid flows in different virtual scenarios is of key importance in\nengineering applications. However, high-fidelity, full-order models relying,\ne.g., on the finite element method, are unaffordable whenever fluid flows must\nbe simulated in almost real-time. Reduced order models (ROMs) relying, e.g., on\nproper orthogonal decomposition (POD) provide reliable approximations to\nparameter-dependent fluid dynamics problems in rapid times. However, they might\nrequire expensive hyper-reduction strategies for handling parameterized\nnonlinear terms, and enriched reduced spaces (or Petrov-Galerkin projections)\nif a mixed velocity-pressure formulation is considered, possibly hampering the\nevaluation of reliable solutions in real-time. Dealing with fluid-structure\ninteractions entails even higher difficulties. The proposed deep learning\n(DL)-based ROMs overcome all these limitations by learning in a non-intrusive\nway both the nonlinear trial manifold and the reduced dynamics. To do so, they\nrely on deep neural networks, after performing a former dimensionality\nreduction through POD enhancing their training times substantially. The\nresulting POD-DL-ROMs are shown to provide accurate results in almost real-time\nfor the flow around a cylinder benchmark, the fluid-structure interaction\nbetween an elastic beam attached to a fixed, rigid block and a laminar\nincompressible flow, and the blood flow in a cerebral aneurysm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 13:07:33 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Fresca", "Stefania", ""], ["Manzoni", "Andrea", ""]]}, {"id": "2106.06016", "submitter": "Shashank Subramanian", "authors": "Shashank Subramanian, Klaudius Scheufele, Naveen Himthani, Christos\n  Davatzikos, and George Biros", "title": "Ensemble inversion for brain tumor growth models with mass effect", "comments": "10 pages, 3 supplementary pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CE q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for extracting physics-based biomarkers from a single\nmultiparametric Magnetic Resonance Imaging (mpMRI) scan bearing a glioma tumor.\nWe account for mass effect, the deformation of brain parenchyma due to the\ngrowing tumor, which on its own is an important radiographic feature but its\nautomatic quantification remains an open problem. In particular, we calibrate a\npartial differential equation (PDE) tumor growth model that captures mass\neffect, parameterized by a single scalar parameter, tumor proliferation,\nmigration, while localizing the tumor initiation site. The single-scan\ncalibration problem is severely ill-posed because the precancerous, healthy,\nbrain anatomy is unknown. To address the ill-posedness, we introduce an\nensemble inversion scheme that uses a number of normal subject brain templates\nas proxies for the healthy precancer subject anatomy. We verify our solver on a\nsynthetic dataset and perform a retrospective analysis on a clinical dataset of\n216 glioblastoma (GBM) patients. We analyze the reconstructions using our\ncalibrated biophysical model and demonstrate that our solver provides both\nglobal and local quantitative measures of tumor biophysics and mass effect. We\nfurther highlight the improved performance in model calibration through the\ninclusion of mass effect in tumor growth models -- including mass effect in the\nmodel leads to 10% increase in average dice coefficients for patients with\nsignificant mass effect. We further evaluate our model by introducing novel\nbiophysics-based features and using them for survival analysis. Our preliminary\nanalysis suggests that including such features can improve patient\nstratification and survival prediction.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 19:40:03 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Subramanian", "Shashank", ""], ["Scheufele", "Klaudius", ""], ["Himthani", "Naveen", ""], ["Davatzikos", "Christos", ""], ["Biros", "George", ""]]}, {"id": "2106.06184", "submitter": "Shashwat Sharma", "authors": "Shashwat Sharma, Piero Triverio", "title": "A Single-Layer Dual-Mesh Boundary Element Method for Multiscale\n  Electromagnetic Modeling of Penetrable Objects in Layered Media", "comments": "10 pages, 11 figures, submitted to the IEEE Journal on Multiscale and\n  Multiphysics Computational Techniques", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A surface integral representation of Maxwell's equations allows the efficient\nelectromagnetic (EM) modeling of three-dimensional structures with a\ntwo-dimensional discretization, via the boundary element method (BEM). However,\nexisting BEM formulations either lead to a poorly conditioned system matrix for\nmultiscale problems, or are computationally expensive for objects embedded in\nlayered substrates. This article presents a new BEM formulation which leverages\nthe surface equivalence principle and Buffa-Christiansen basis functions\ndefined on a dual mesh, to obtain a well-conditioned system matrix suitable for\nmultiscale EM modeling. Unlike existing methods involving dual meshes, the\nproposed formulation avoids the double-layer potential operator for the\nsurrounding medium, which may be a stratified substrate requiring the use of an\nadvanced Green's function. This feature greatly alleviates the computational\nexpense associated with the use of Buffa-Christiansen functions. Numerical\nexamples drawn from several applications, including remote sensing, chip-level\nEM analysis, and metasurface modeling, demonstrate speed-ups ranging from 3x to\n7x compared to state-of-the-art formulations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 06:14:58 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Sharma", "Shashwat", ""], ["Triverio", "Piero", ""]]}, {"id": "2106.06343", "submitter": "Mischa Blaszczyk", "authors": "Mischa Blaszczyk and Klaus Hackl", "title": "Multiscale modeling of cancellous bone considering full coupling of\n  mechanical, electrical and magnetic effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling of cancellous bone has important applications in the detection and\ntreatment of fatigue fractures and diseases like osteoporosis. In this paper,\nwe present a fully coupled multiscale approach considering mechanical,\nelectrical and magnetic effects by using the multiscale finite element method\nand a two-phase material model on the microscale. We show numerical results for\nboth scales, including calculations for a femur bone, comparing a healthy bone\nto ones affected by different stages of osteoporosis. Here, the magnetic field\nstrength resulting from a small mechanical impact decreases drastically for\nlater stages of the disease, confirming experimental research.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 12:30:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Blaszczyk", "Mischa", ""], ["Hackl", "Klaus", ""]]}, {"id": "2106.06358", "submitter": "Timo Koch", "authors": "Timo Koch", "title": "Projection-based resolved interface mixed-dimension method for embedded\n  tubular network systems", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a flexible discretization technique for computational models of\nthin tubular networks embedded in a bulk domain, for example a porous medium.\nThese systems occur in the simulation of fluid flow in vascularized biological\ntissue, root water and nutrient uptake in soil, hydrological or petroleum wells\nin rock formations, or heat transport in micro-cooling devices. The key\nprocesses, such as heat and mass transfer, are usually dominated by the\nexchange between the network system and the embedding domain. By explicitly\nresolving the interface between these domains with the computational mesh, we\ncan accurately describe these processes. The network is efficiently described\nby a network of line segments. Coupling terms are evaluated by projection of\nthe interface variables. The new method is naturally applicable for nonlinear\nand time-dependent problems and can therefore be used as a reference method in\nthe development of novel implicit interface 1D-3D methods and in the design of\nverification benchmarks for embedded tubular network methods. Implicit\ninterface, not resolving the bulk-network interface explicitly have proven to\nbe very efficient but have only been mathematically analyzed for linear\nelliptic problems so far. Using two application scenarios, fluid perfusion of\nvascularized tissue and root water uptake from soil, we investigate the effect\nof some common modeling assumptions of implicit interface methods numerically.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 12:57:37 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Koch", "Timo", ""]]}, {"id": "2106.06409", "submitter": "Luca Magri", "authors": "Andrea N\\'ovoa and Luca Magri", "title": "Real-time thermoacoustic data assimilation", "comments": "42 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-order thermoacoustic models are qualitatively correct, but they are\ntypically quantitatively inaccurate. We propose a time-domain method to make\nqualitatively low-order models quantitatively (more) accurate. First, we\ndevelop a Bayesian data assimilation method for a low-order model to self-adapt\nand self-correct any time that reference data, for example from experiments,\nbecomes available. Second, we apply the methodology to infer the thermoacoustic\nstates, heat release parameters, and model errors on the fly without storing\ndata (real-time). Third, we analyse the performance of the data assimilation\nwith synthetic data and interpret the results physically. We apply the data\nassimilation algorithm to all nonlinear thermoacoustic regimes, from limit\ncycles to chaos, in which acoustic pressure measurements from microphones are\nassimilated. Fourth, we propose practical rules for thermoacoustic data\nassimilation based on physical observations on the dynamics. An increase,\nreject, inflate strategy is proposed to deal with the rich nonlinear behaviour,\nthe bifurcations of which are sensitive to small perturbations to the\nparameters. We show that (i) the correct acoustic pressure and parameters can\nbe accurately inferred; (ii) the learning is robust because it can tackle large\nuncertainties in the observations (up to 50% the mean values); (iii) the\nuncertainty of the prediction and parameters is naturally part of the output;\nand (iv) both the time-accurate solution and statistics can be successfully\ninferred. Physical time scales for assimilation are proposed in non-chaotic\nregimes (with the Nyquist-Shannon criterion) and in chaotic regimes (with the\nLyapunov time). Data assimilation opens up new possibility for real--time\nprediction of thermoacoustics by synergistically combining physical knowledge\nand data.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 14:06:59 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["N\u00f3voa", "Andrea", ""], ["Magri", "Luca", ""]]}, {"id": "2106.06478", "submitter": "Liwei Wang", "authors": "Liwei Wang, Anton van Beek, Daicong Da, Yu-Chin Chan, Ping Zhu, Wei\n  Chen", "title": "Data-Driven Multiscale Design of Cellular Composites with Multiclass\n  Microstructures for Natural Frequency Maximization", "comments": "Preprint submitted to Composite Structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For natural frequency optimization of engineering structures, cellular\ncomposites have been shown to possess an edge over solid. However, existing\nmultiscale design methods for cellular composites are either computationally\nexhaustive or confined to a single class of microstructures. In this paper, we\npropose a data-driven topology optimization (TO) approach to enable the\nmultiscale design of cellular structures with various choices of microstructure\nclasses. The key component is a newly proposed latent-variable Gaussian process\n(LVGP) model through which different classes of microstructures are mapped into\na low-dimensional continuous latent space. It provides an interpretable\ndistance metric between classes and captures their effects on the homogenized\nstiffness tensors. By introducing latent vectors as design variables, a\ndifferentiable transition of stiffness matrix between classes can be easily\nachieved with an analytical gradient. After integrating LVGP with the\ndensity-based TO, an efficient data-driven cellular composite optimization\nprocess is developed to enable concurrent exploration of microstructure\nconcepts and the associated volume fractions for natural frequency\noptimization. Examples reveal that the proposed cellular designs with\nmulticlass microstructures achieve higher natural frequencies than both\nsingle-scale and single-class designs. This framework can be easily extended to\nother multi-scale TO problems, such as thermal compliance and dynamic response\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:59:33 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Wang", "Liwei", ""], ["van Beek", "Anton", ""], ["Da", "Daicong", ""], ["Chan", "Yu-Chin", ""], ["Zhu", "Ping", ""], ["Chen", "Wei", ""]]}, {"id": "2106.06839", "submitter": "Tobias Schlagenhauf", "authors": "Tobias Schlagenhauf, Niklas Burghardt, and J\\\"urgen Fleischer", "title": "Intelligent Vision Based Wear Forecasting on Surfaces of Machine Tool\n  Elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses the ability to enable machines to automatically detect\nfailures on machine tool components as well as estimating the severity of the\nfailures, which is a critical step towards autonomous production machines.\nExtracting information about the severity of failures has been a substantial\npart of classical, as well as Machine Learning based machine vision systems.\nEfforts have been undertaken to automatically predict the severity of failures\non machine tool components for predictive maintenance purposes. Though, most\napproaches only partly cover a completely automatic system from detecting\nfailures to the prognosis of their future severity. To the best of the authors\nknowledge, this is the first time a vision-based system for defect detection\nand prognosis of failures on metallic surfaces in general and on Ball Screw\nDrives in specific has been proposed. The authors show that they can do both,\ndetect and prognose the evolution of a failure on the surface of a Ball Screw\nDrive.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 19:34:54 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Schlagenhauf", "Tobias", ""], ["Burghardt", "Niklas", ""], ["Fleischer", "J\u00fcrgen", ""]]}, {"id": "2106.07801", "submitter": "Hangrui Bi", "authors": "Hangrui Bi, Hengyi Wang, Chence Shi, Connor Coley, Jian Tang, Hongyu\n  Guo", "title": "Non-Autoregressive Electron Redistribution Modeling for Reaction\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reliably predicting the products of chemical reactions presents a fundamental\nchallenge in synthetic chemistry. Existing machine learning approaches\ntypically produce a reaction product by sequentially forming its subparts or\nintermediate molecules. Such autoregressive methods, however, not only require\na pre-defined order for the incremental construction but preclude the use of\nparallel decoding for efficient computation. To address these issues, we devise\na non-autoregressive learning paradigm that predicts reaction in one shot.\nLeveraging the fact that chemical reactions can be described as a\nredistribution of electrons in molecules, we formulate a reaction as an\narbitrary electron flow and predict it with a novel multi-pointer decoding\nnetwork. Experiments on the USPTO-MIT dataset show that our approach has\nestablished a new state-of-the-art top-1 accuracy and achieves at least 27\ntimes inference speedup over the state-of-the-art methods. Also, our\npredictions are easier for chemists to interpret owing to predicting the\nelectron flows.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 16:39:08 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bi", "Hangrui", ""], ["Wang", "Hengyi", ""], ["Shi", "Chence", ""], ["Coley", "Connor", ""], ["Tang", "Jian", ""], ["Guo", "Hongyu", ""]]}, {"id": "2106.07954", "submitter": "Liexin Cheng", "authors": "Haoxue Wang, Liexin Cheng", "title": "CatBoost model with synthetic features in application to loan risk\n  assessment of small businesses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loan risk for small businesses has long been a complex problem worthy of\nexploring. Predicting the loan risk can benefit entrepreneurship by developing\nmore jobs for the society. CatBoost (Categorical Boosting) is a powerful\nmachine learning algorithm suitable for dataset with many categorical variables\nlike the dataset for forecasting loan risk. In this paper, we identify the\nimportant risk factors that contribute to loan status classification problem.\nThen we compare the performance between boosting-type algorithms(especially\nCatBoost) with other traditional yet popular ones. The dataset we adopt in the\nresearch comes from the U.S. Small Business Administration (SBA) and holds a\nvery large sample size (899,164 observations and 27 features). In order to make\nthe best use of the important features in the dataset, we propose a technique\nnamed \"synthetic generation\" to develop more combined features based on\narithmetic operation, which ends up improving the accuracy and AUC of the\noriginal CatBoost model. We obtain a high accuracy of 95.84% and well-performed\nAUC of 98.80% compared with the existent literature of related research.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 08:17:00 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 01:24:23 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 07:29:27 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Wang", "Haoxue", ""], ["Cheng", "Liexin", ""]]}, {"id": "2106.08123", "submitter": "Michael Robinson", "authors": "Michael Robinson and Christopher Capraro", "title": "Super-resolving star clusters with sheaves", "comments": "arXiv admin note: text overlap with arXiv:2106.04445", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.CE math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article explains an optimization-based approach for counting and\nlocalizing stars within a small cluster, based on photon counts in a focal\nplane array. The array need not be arranged in any particular way, and\nrelatively small numbers of photons are required in order to ensure\nconvergence. The stars can be located close to one another, as the location and\nbrightness errors were found to be low when the separation was larger than\n$0.2$ Rayleigh radii. To ensure generality of our approach, it was constructed\nas a special case of a general theory built upon topological signal processing\nusing the mathematics of sheaves.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 15:24:20 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Robinson", "Michael", ""], ["Capraro", "Christopher", ""]]}, {"id": "2106.08146", "submitter": "Xiu Yang", "authors": "Peiyuan Gao, Xiu Yang, Yu-Hang Tang, Muqing Zheng, Amity Anderson,\n  Vijayakumar Murugesan, Aaron Hollas, Wei Wang", "title": "Graphical Gaussian Process Regression Model for Aqueous Solvation Free\n  Energy Prediction of Organic Molecules in Redox Flow Battery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solvation free energy of organic molecules is a critical parameter in\ndetermining emergent properties such as solubility, liquid-phase equilibrium\nconstants, and pKa and redox potentials in an organic redox flow battery. In\nthis work, we present a machine learning (ML) model that can learn and predict\nthe aqueous solvation free energy of an organic molecule using Gaussian process\nregression method based on a new molecular graph kernel. To investigate the\nperformance of the ML model on electrostatic interaction, the nonpolar\ninteraction contribution of solvent and the conformational entropy of solute in\nsolvation free energy, three data sets with implicit or explicit water solvent\nmodels, and contribution of conformational entropy of solute are tested. We\ndemonstrate that our ML model can predict the solvation free energy of\nmolecules at chemical accuracy with a mean absolute error of less than 1\nkcal/mol for subsets of the QM9 dataset and the Freesolv database. To solve the\ngeneral data scarcity problem for a graph-based ML model, we propose a\ndimension reduction algorithm based on the distance between molecular graphs,\nwhich can be used to examine the diversity of the molecular data set. It\nprovides a promising way to build a minimum training set to improve prediction\nfor certain test sets where the space of molecular structures is predetermined.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 13:48:26 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Gao", "Peiyuan", ""], ["Yang", "Xiu", ""], ["Tang", "Yu-Hang", ""], ["Zheng", "Muqing", ""], ["Anderson", "Amity", ""], ["Murugesan", "Vijayakumar", ""], ["Hollas", "Aaron", ""], ["Wang", "Wei", ""]]}, {"id": "2106.08274", "submitter": "Chengcheng Liu", "authors": "Chengcheng Liu, M\\'aty\\'as A. Sustik", "title": "Elasticity Based Demand Forecasting and Price Optimization for Online\n  Retail", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CE cs.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a problem of an online retailer who observes the unit sales of a\nproduct, and dynamically changes the retail price, in order to maximize the\nexpected revenue. Assuming the demand of the product is price sensitive, we are\ninterested in the optimal pricing policy when future demand is uncertain. We\nbuild a system to investigate the relationship between retail price and demand\nand estimate the demand function. The system predicts demand and revenue at a\ngiven retail price. We formulate a revenue maximization problem over a discrete\nfinite time horizon with discrete retail price. The optimal pricing policy is\nsolved based on the predicted demand and revenue values. With computational\nexperiments, we investigate the effect of optimal pricing policy to inventory\nmanagement.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 22:23:32 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 02:40:03 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Liu", "Chengcheng", ""], ["Sustik", "M\u00e1ty\u00e1s A.", ""]]}, {"id": "2106.09132", "submitter": "Tianyang Xie", "authors": "Chenyanzi Yu, Tianyang Xie", "title": "Multivariate Pair Trading by Volatility & Model Adaption Trade-off", "comments": "Submitting to Journal of Financial Economics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pair trading is one of the most discussed topics among financial researches.\nDespite a growing base of work, portfolio management for multivariate time\nseries is rarely discussed. On the other hand, most researches focus on\nrefining strategy rules instead of finding the optimal portfolio weight. In\nthis paper, we brought up a simple yet profitable strategy called Volatility &\nModel Adaption Trade-off (VMAT) to leverage the issues. Experiment studies show\nits superior profit performance over baselines.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 15:57:33 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yu", "Chenyanzi", ""], ["Xie", "Tianyang", ""]]}, {"id": "2106.09245", "submitter": "Prabhat Kumar", "authors": "Prabhat Kumar, Anupam Saxena", "title": "A Material Mask Overlay Strategy for Close to Binary Design-dependent\n  Pressure-loaded Optimized Topologies", "comments": "22 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a Material Mask Overlay Strategy topology optimization\napproach with improved material assignment at the element level for achieving\nclose to black-and-white designs for pressure-loaded problems. Hexagonal\nelements are employed to parametrize the design domain as this tessellation\nprovides nonsingular local connectivity. Elliptical negative masks are used to\nfind the optimized material layout. The material dilation and material erosion\nvariables of each mask are systematically varied in association with a\ngray-scale measure constraint to achieve designs close to 0-1. Darcy's law in\nassociation with a drainage term is used to formulate the pressure field. The\nobtained pressure field is converted into the consistent nodal forces using\nWachspress shape functions. Sensitivities of the objective and pressure load\nare evaluated using the adjoint-variable method. The approach is demonstrated\nby solving various pressure-loaded structures and pressure-actuated compliant\nmechanisms. Compliance is minimized for loadbearing structures, whereas a\nmulticriteria objective is minimized for mechanism designs.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 04:49:39 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Kumar", "Prabhat", ""], ["Saxena", "Anupam", ""]]}, {"id": "2106.09575", "submitter": "C. Lawrence Zitnick", "authors": "Muhammed Shuaibi, Adeesh Kolluru, Abhishek Das, Aditya Grover, Anuroop\n  Sriram, Zachary Ulissi, C. Lawrence Zitnick", "title": "Rotation Invariant Graph Neural Networks using Spin Convolutions", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress towards the energy breakthroughs needed to combat climate change can\nbe significantly accelerated through the efficient simulation of atomic\nsystems. Simulation techniques based on first principles, such as Density\nFunctional Theory (DFT), are limited in their practical use due to their high\ncomputational expense. Machine learning approaches have the potential to\napproximate DFT in a computationally efficient manner, which could dramatically\nincrease the impact of computational simulations on real-world problems.\nApproximating DFT poses several challenges. These include accurately modeling\nthe subtle changes in the relative positions and angles between atoms, and\nenforcing constraints such as rotation invariance or energy conservation. We\nintroduce a novel approach to modeling angular information between sets of\nneighboring atoms in a graph neural network. Rotation invariance is achieved\nfor the network's edge messages through the use of a per-edge local coordinate\nframe and a novel spin convolution over the remaining degree of freedom. Two\nmodel variants are proposed for the applications of structure relaxation and\nmolecular dynamics. State-of-the-art results are demonstrated on the\nlarge-scale Open Catalyst 2020 dataset. Comparisons are also performed on the\nMD17 and QM9 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 14:59:34 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Shuaibi", "Muhammed", ""], ["Kolluru", "Adeesh", ""], ["Das", "Abhishek", ""], ["Grover", "Aditya", ""], ["Sriram", "Anuroop", ""], ["Ulissi", "Zachary", ""], ["Zitnick", "C. Lawrence", ""]]}, {"id": "2106.09901", "submitter": "Kazuo Yonekura", "authors": "Kazuo Yonekura, Kazunari Wada, and Katsuyuki Suzuki", "title": "Generating various airfoil shapes with required lift coefficient using\n  conditional variational autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple shapes must be obtained in the mechanical design process to satisfy\nthe required design specifications. The inverse design problem has been\nanalyzed in previous studies to obtain such shapes. However, finding multiple\nshapes in a short computation period is difficult while using the conventional\nmethods. This paper proposes the use of the conditional variational\nautoencoders (CVAE) with normal distribution, denoted by N-CVAE, along with the\nvon Mises-Fischer distribution, denoted by S-CVAE, to find multiple solutions\nfor the inverse design problems. Both the CVAE models embed shapes into a\nlatent space. The S-CVAE enables the separation of data in the latent space,\nwhereas the N-CVAE embeds the data in a narrow space. These different features\nare used for various tasks in this study. In one of the tasks, the dataset\nconsists of only one type of data and generates similar airfoils. Here, S-CVAE\noutperforms N-CVAE because it can separate the data. Another task involves\ncombining different types of airfoils and generating new types of data. N-CVAE\nis useful in this instance since it embeds different shapes in the same latent\narea, due to which, the model outputs intermediate shapes of different types.\nThe shape-generation capability of S-CVAE and N-CVAE are experimentally\ncompared in this study.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 03:50:40 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Yonekura", "Kazuo", ""], ["Wada", "Kazunari", ""], ["Suzuki", "Katsuyuki", ""]]}, {"id": "2106.10104", "submitter": "Fareed Sheriff", "authors": "Fareed Sheriff", "title": "ELMOPP: An Application of Graph Theory and Machine Learning to Traffic\n  Light Coordination", "comments": "13 pages, 3 figures, published in Applied Computing and Informatics\n  (2021)", "journal-ref": null, "doi": "10.1108/ACI-07-2020-0035", "report-no": null, "categories": "cs.CE cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traffic light management is a broad subject with various papers published\nthat put forth algorithms to efficiently manage traffic using traffic lights.\nTwo such algorithms are the OAF (oldest arrival first) and ITLC (intelligent\ntraffic light controller) algorithms. However, many traffic light algorithms do\nnot consider future traffic flow and therefore cannot mitigate traffic in such\na way as to reduce future traffic in the present. This paper presents the Edge\nLoad Management and Optimization through Pseudoflow Prediction (ELMOPP)\nalgorithm, which aims to solve problems detailed in previous algorithms;\nthrough machine learning with nested long short-term memory (NLSTM) modules and\ngraph theory, the algorithm attempts to predict the near future using past data\nand traffic patterns to inform its real-time decisions and better mitigate\ntraffic by predicting future traffic flow based on past flow and using those\npredictions to both maximize present traffic flow and decrease future traffic\ncongestion. Furthermore, while ITLC and OAF require the use of GPS\ntransponders; and GPS, speed sensors, and radio, respectively, ELMOPP only uses\ntraffic light camera footage, something that is almost always readily available\nin contrast to GPS and speed sensors. ELMOPP was tested against the ITLC and\nOAF traffic management algorithms using a simulation modeled after the one\npresented in the ITLC paper, a single-intersection simulation, and the\ncollected data supports the conclusion that ELMOPP statistically significantly\noutperforms both algorithms in throughput rate, a measure of how many vehicles\nare able to exit inroads every second.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 20:57:29 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Sheriff", "Fareed", ""]]}, {"id": "2106.10159", "submitter": "Cheng-Te Li", "authors": "Yi-Ling Hsu, Yu-Che Tsai, Cheng-Te Li", "title": "FinGAT: Financial Graph Attention Networks for Recommending Top-K\n  Profitable Stocks", "comments": "Accepted to IEEE TKDE 2021. The first two authors equally contribute\n  to this work. Code is available at\n  https://github.com/Roytsai27/Financial-GraphAttention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial technology (FinTech) has drawn much attention among investors and\ncompanies. While conventional stock analysis in FinTech targets at predicting\nstock prices, less effort is made for profitable stock recommendation. Besides,\nin existing approaches on modeling time series of stock prices, the\nrelationships among stocks and sectors (i.e., categories of stocks) are either\nneglected or pre-defined. Ignoring stock relationships will miss the\ninformation shared between stocks while using pre-defined relationships cannot\ndepict the latent interactions or influence of stock prices between stocks. In\nthis work, we aim at recommending the top-K profitable stocks in terms of\nreturn ratio using time series of stock prices and sector information. We\npropose a novel deep learning-based model, Financial Graph Attention Networks\n(FinGAT), to tackle the task under the setting that no pre-defined\nrelationships between stocks are given. The idea of FinGAT is three-fold.\nFirst, we devise a hierarchical learning component to learn short-term and\nlong-term sequential patterns from stock time series. Second, a fully-connected\ngraph between stocks and a fully-connected graph between sectors are\nconstructed, along with graph attention networks, to learn the latent\ninteractions among stocks and sectors. Third, a multi-task objective is devised\nto jointly recommend the profitable stocks and predict the stock movement.\nExperiments conducted on Taiwan Stock, S&P 500, and NASDAQ datasets exhibit\nremarkable recommendation performance of our FinGAT, comparing to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:51:14 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Hsu", "Yi-Ling", ""], ["Tsai", "Yu-Che", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2106.10568", "submitter": "Jiaojiao Fan", "authors": "Jiaojiao Fan, Amirhossein Taghvaei, and Yongxin Chen", "title": "Stein particle filtering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new particle filtering algorithm for nonlinear systems in the\ndiscrete-time setting. Our algorithm is based on the Stein variational gradient\ndescent (SVGD) framework, which is a general approach to sample from a target\ndistribution. We merge the standard two-step paradigm in particle filtering\ninto one step so that SVGD can be used. A distinguishing feature of the\nproposed algorithm is that, unlike most particle filtering methods, all the\nparticles at any time step are equally weighted and thus no update on the\nweights is needed. We further extended our algorithm to allow for updating\nprevious particles within a sliding window. This strategy may improve the\nreliability of the algorithm with respect to unexpected disturbance in the\ndynamics or outlier-measurements. The efficacy of the proposed algorithms is\nillustrated through several numerical examples in comparison with a standard\nparticle filtering method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 20:41:19 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fan", "Jiaojiao", ""], ["Taghvaei", "Amirhossein", ""], ["Chen", "Yongxin", ""]]}, {"id": "2106.11381", "submitter": "Benjamin Unger", "authors": "Felix Black, Philipp Schulze, Benjamin Unger", "title": "Efficient Wildland Fire Simulation via Nonlinear Model Order Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new hyper-reduction method for a recently introduced nonlinear\nmodel reduction framework based on dynamically transformed basis functions and\nespecially well-suited for advection-dominated systems. Furthermore, we discuss\napplying this new method to a wildland fire model whose dynamics feature\ntraveling combustion waves and local ignition and is thus challenging for\nclassical model reduction schemes based on linear subspaces. The new\nhyper-reduction framework allows us to construct parameter-dependent\nreduced-order models (ROMs) with efficient offline/online decomposition. The\nnumerical experiments demonstrate that the ROMs obtained by the novel method\noutperform those obtained by a classical approach using the proper orthogonal\ndecomposition and the discrete empirical interpolation method in terms of run\ntime and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 19:32:24 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Black", "Felix", ""], ["Schulze", "Philipp", ""], ["Unger", "Benjamin", ""]]}, {"id": "2106.12668", "submitter": "Leonardo Moraes", "authors": "Leonardo, R. C. Moraes and Hermes Alves Filho and Ricardo C. Barros", "title": "On the calculation of neutron sources generating steady prescribed power\n  distributions in subcritical systems using multigroup X,Y-geometry discrete\n  ordinates models", "comments": "24 pages, 7 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "nucl-th cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a methodology is described to estimate multigroup neutron\nsource distributions which must be added into a subcritical system to drive it\nto a steady state prescribed power distribution. This work has been motivated\nby the principle of operation of the ADS (Accelerator Driven System) reactors,\nwhich have subcritical cores stabilized by the action of external sources. We\nuse the energy multigroup two-dimensional neutron transport equation in the\ndiscrete ordinates formulation (SN) and the equation which is adjoint to it,\nwhose solution is interpreted here as a distribution measuring the importance\nof the angular flux of neutrons to a linear functional. These equations are\ncorrelated through a reciprocity relation, leading to a relationship between\nthe interior sources of neutrons and the power produced by unit length of\nheight of the domain. A coarse-mesh numerical method of the spectral nodal\nclass, referred to as adjoint response matrix constant-nodal method, is applied\nto numerically solve the adjoint SN equations. Numerical experiments are\nperformed to analyze the accuracy of the present methodology so as to\nillustrate its potential practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 21:56:52 GMT"}], "update_date": "2021-06-26", "authors_parsed": [["Leonardo", "", ""], ["Moraes", "R. C.", ""], ["Filho", "Hermes Alves", ""], ["Barros", "Ricardo C.", ""]]}, {"id": "2106.12856", "submitter": "Tobias Weinzierl", "authors": "Maximilien Gadouleau, Tobias Weinzierl", "title": "The maximum discrete surface-to-volume ratio of space-filling curve\n  partitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-filling curves (SFCs) are used in high performance computing to\ndistribute a computational domain or its mesh, respectively, amongst different\ncompute units, i.e.~cores or nodes or accelerators. The part of the domain\nallocated to each compute unit is called a partition. Besides the balancing of\nthe work, the communication cost to exchange data between units determines the\nquality of a chosen partition. This cost can be approximated by the\nsurface-to-volume ratio of partitions: the volume represents the amount of\nlocal work, while the surface represents the amount of data to be transmitted.\nEmpirical evidence suggests that space-filling curves yield advantageous\nsurface-to-volume ratios. Formal proofs are available only for regular grids.\nWe investigate the surface-to-volume ratio of space-filling curve partitions\nfor adaptive grids and derive the maximum surface-to-volume ratio as a function\nof the number of cells in the partition. In order to prove our main theorem, we\nconstruct a new framework for the study of adaptive grids, notably introducing\nthe concepts of a shape and of classified partitions. The new methodological\nframework yields insight about the SFC-induced partition character even if the\ngrids refine rather aggressively in localised areas: it quantifies the obtained\nsurface-to-volume ratio. This framework thus has the potential to guide the\ndesign of better load balancing algorithms on the long term.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 09:34:01 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Gadouleau", "Maximilien", ""], ["Weinzierl", "Tobias", ""]]}, {"id": "2106.12950", "submitter": "Dong Zhou", "authors": "Hengxu Lin, Dong Zhou, Weiqing Liu, Jiang Bian", "title": "Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor\n  and Optimal Transport", "comments": "Accepted by KDD 2021 (research track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful quantitative investment usually relies on precise predictions of\nthe future movement of the stock price. Recently, machine learning based\nsolutions have shown their capacity to give more accurate stock prediction and\nbecome indispensable components in modern quantitative investment systems.\nHowever, the i.i.d. assumption behind existing methods is inconsistent with the\nexistence of diverse trading patterns in the stock market, which inevitably\nlimits their ability to achieve better stock prediction performance. In this\npaper, we propose a novel architecture, Temporal Routing Adaptor (TRA), to\nempower existing stock prediction models with the ability to model multiple\nstock trading patterns. Essentially, TRA is a lightweight module that consists\nof a set of independent predictors for learning multiple patterns as well as a\nrouter to dispatch samples to different predictors. Nevertheless, the lack of\nexplicit pattern identifiers makes it quite challenging to train an effective\nTRA-based model. To tackle this challenge, we further design a learning\nalgorithm based on Optimal Transport (OT) to obtain the optimal sample to\npredictor assignment and effectively optimize the router with such assignment\nthrough an auxiliary loss term. Experiments on the real-world stock ranking\ntask show that compared to the state-of-the-art baselines, e.g., Attention LSTM\nand Transformer, the proposed method can improve information coefficient (IC)\nfrom 0.053 to 0.059 and 0.051 to 0.056 respectively. Our dataset and code used\nin this work are publicly available:\nhttps://github.com/microsoft/qlib/tree/main/examples/benchmarks/TRA.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:19:45 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 09:13:25 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Lin", "Hengxu", ""], ["Zhou", "Dong", ""], ["Liu", "Weiqing", ""], ["Bian", "Jiang", ""]]}, {"id": "2106.12955", "submitter": "Abdolrahman Khoshrou", "authors": "Abdolrahman Khoshrou, Eric J. Pauwels", "title": "Regularisation for PCA- and SVD-type matrix factorisations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Singular Value Decomposition (SVD) and its close relative, Principal\nComponent Analysis (PCA), are well-known linear matrix decomposition techniques\nthat are widely used in applications such as dimension reduction and\nclustering. However, an important limitation of SVD/PCA is its sensitivity to\nnoise in the input data. In this paper, we take another look at the problem of\nregularisation and show that different formulations of the minimisation problem\nlead to qualitatively different solutions.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 12:25:12 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Khoshrou", "Abdolrahman", ""], ["Pauwels", "Eric J.", ""]]}, {"id": "2106.13267", "submitter": "Wibke D\\\"usterh\\\"oft-Wriggers", "authors": "Wibke D\\\"usterh\\\"oft-Wriggers, Antonia Larese, Thomas Rung, Eugenio\n  O\\~nate", "title": "Free surface flow through rigid porous media -- An overview and\n  comparison of formulations", "comments": "27 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications free surface flow through rigid porous media has to be\nmodeled. Examples refer to coastal engineering applications as well as\ngeotechnical or biomedical applications. Albeit the frequent applications,\nslight inconsistencies in the formulation of the governing equations can be\nfound in the literature. The main goal of this paper is to identify these\ndifferences and provide a quantitative assessment of different approaches.\nFollowing a review of the different formulations, simulation results obtained\nfrom three alternative formulations are compared with experimental and\nnumerical data. Results obtained by 2D and 3D test cases indicate that the\npredictive differences returned by the different formulations remain small for\nmost applications, in particular for small porous Reynolds number ReP < 5000.\nThus it seems justified to select a formulation that supports an efficient\nalgorithm and coding structure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 18:39:17 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["D\u00fcsterh\u00f6ft-Wriggers", "Wibke", ""], ["Larese", "Antonia", ""], ["Rung", "Thomas", ""], ["O\u00f1ate", "Eugenio", ""]]}, {"id": "2106.13649", "submitter": "Jaroslav Budi\\v{s}", "authors": "Jaroslav Budis, Werner Krampl, Marcel Kucharik, Rastislav Hekel,\n  Adrian Goga, Michal Lichvar, David Smolak, Miroslav Bohmer, Andrej Balaz,\n  Frantisek Duris, Juraj Gazdarica, Katarina Soltys, Jan Turna, Jan Radvanszky,\n  Tomas Szemes", "title": "SnakeLines: integrated set of computational pipelines for sequencing\n  reads", "comments": "22 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Background: With the rapid growth of massively parallel sequencing\ntechnologies, still more laboratories are utilizing sequenced DNA fragments for\ngenomic analyses. Interpretation of sequencing data is, however, strongly\ndependent on bioinformatics processing, which is often too demanding for\nclinicians and researchers without a computational background. Another problem\nrepresents the reproducibility of computational analyses across separated\ncomputational centers with inconsistent versions of installed libraries and\nbioinformatics tools.\n  Results: We propose an easily extensible set of computational pipelines,\ncalled SnakeLines, for processing sequencing reads; including mapping,\nassembly, variant calling, viral identification, transcriptomics, metagenomics,\nand methylation analysis. Individual steps of an analysis, along with methods\nand their parameters can be readily modified in a single configuration file.\nProvided pipelines are embedded in virtual environments that ensure isolation\nof required resources from the host operating system, rapid deployment, and\nreproducibility of analysis across different Unix-based platforms.\n  Conclusion: SnakeLines is a powerful framework for the automation of\nbioinformatics analyses, with emphasis on a simple set-up, modifications,\nextensibility, and reproducibility.\n  Keywords: Computational pipeline, framework, massively parallel sequencing,\nreproducibility, virtual environment\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 14:10:19 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Budis", "Jaroslav", ""], ["Krampl", "Werner", ""], ["Kucharik", "Marcel", ""], ["Hekel", "Rastislav", ""], ["Goga", "Adrian", ""], ["Lichvar", "Michal", ""], ["Smolak", "David", ""], ["Bohmer", "Miroslav", ""], ["Balaz", "Andrej", ""], ["Duris", "Frantisek", ""], ["Gazdarica", "Juraj", ""], ["Soltys", "Katarina", ""], ["Turna", "Jan", ""], ["Radvanszky", "Jan", ""], ["Szemes", "Tomas", ""]]}, {"id": "2106.13723", "submitter": "Sharana Kumar Shivanand", "authors": "Sharana Kumar Shivanand and Bojana Rosi\\'c", "title": "Scale-invariant multilevel Monte Carlo method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the scale-invariant version of the mean and variance\nmulti-level Monte Carlo estimate is proposed. The optimization of the\ncomputation cost over the grid levels is done with the help of a novel\nnormalized error based on t-statistic. In this manner, the algorithm\nconvergence is made invariant to the physical scale at which the estimate is\ncomputed. The novel algorithm is tested on the linear elastic example, the\nconstitutive law of which is described by material uncertainty including both\nheterogeneity and anisotropy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 13:23:08 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Shivanand", "Sharana Kumar", ""], ["Rosi\u0107", "Bojana", ""]]}, {"id": "2106.13727", "submitter": "Jan N. Fuhg", "authors": "Jan Niklas Fuhg, Am\\'elie Fau, Nikolaos Bouklas", "title": "Interval and fuzzy physics-informed neural networks for uncertain fields", "comments": "13 pages,12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Temporally and spatially dependent uncertain parameters are regularly\nencountered in engineering applications. Commonly these uncertainties are\naccounted for using random fields and processes which require knowledge about\nthe appearing probability distributions functions which is not readily\navailable. In these cases non-probabilistic approaches such as interval\nanalysis and fuzzy set theory are helpful uncertainty measures. Partial\ndifferential equations involving fuzzy and interval fields are traditionally\nsolved using the finite element method where the input fields are sampled using\nsome basis function expansion methods. This approach however is problematic, as\nit is reliant on knowledge about the spatial correlation fields. In this work\nwe utilize physics-informed neural networks (PINNs) to solve interval and fuzzy\npartial differential equations. The resulting network structures termed\ninterval physics-informed neural networks (iPINNs) and fuzzy physics-informed\nneural networks (fPINNs) show promising results for obtaining bounded solutions\nof equations involving spatially uncertain parameter fields. In contrast to\nfinite element approaches, no correlation length specification of the input\nfields as well as no averaging via Monte-Carlo simulations are necessary. In\nfact, information about the input interval fields is obtained directly as a\nbyproduct of the presented solution scheme. Furthermore, all major advantages\nof PINNs are retained, i.e. meshfree nature of the scheme, and ease of inverse\nproblem set-up.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 21:06:42 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Fuhg", "Jan Niklas", ""], ["Fau", "Am\u00e9lie", ""], ["Bouklas", "Nikolaos", ""]]}, {"id": "2106.13728", "submitter": "Santiago Badia Sb", "authors": "Santiago Badia, Eric Neiva, Francesc Verdugo", "title": "Linking ghost penalty and aggregated unfitted methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we analyse the links between ghost penalty stabilisation and\naggregation-based discrete extension operators for the numerical approximation\nof elliptic partial differential equations on unfitted meshes. We explore the\nbehavior of ghost penalty methods in the limit as the penalty parameter goes to\ninfinity, which returns a strong version of these methods. We observe that\nthese methods suffer locking in that limit. On the contrary, aggregated finite\nelement spaces are locking-free because they can be expressed as an extension\noperator from well-posed to ill-posed degrees of freedom. Next, we propose\nnovel ghost penalty methods that penalise the distance between the solution and\nits aggregation-based discrete extension. These methods are locking-free and\nconverge to aggregated finite element methods in the infinite penalty parameter\nlimit. We include an exhaustive set of numerical experiments in which we\ncompare weak (ghost penalty) and strong (aggregated finite elements) schemes in\nterms of error quantities, condition numbers and sensitivity with respect to\npenalty coefficients on different geometries, intersection locations and mesh\ntopologies.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 10:23:04 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Badia", "Santiago", ""], ["Neiva", "Eric", ""], ["Verdugo", "Francesc", ""]]}, {"id": "2106.13878", "submitter": "Yue Yu", "authors": "Mikil Foss, Petronela Radu, Yue Yu", "title": "Convergence Analysis and Numerical Studies for Linearly Elastic\n  Peridynamics with Dirichlet-Type Boundary Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.CE cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The nonlocal models of peridynamics have successfully predicted fractures and\ndeformations for a variety of materials. In contrast to local mechanics,\nperidynamic boundary conditions must be defined on a finite volume region\noutside the body. Therefore, theoretical and numerical challenges arise in\norder to properly formulate Dirichlet-type nonlocal boundary conditions, while\nconnecting them to the local counterparts. While a careless imposition of local\nboundary conditions leads to a smaller effective material stiffness close to\nthe boundary and an artificial softening of the material, several strategies\nwere proposed to avoid this unphysical surface effect.\n  In this work, we study convergence of solutions to nonlocal state-based\nlinear elastic model to their local counterparts as the interaction horizon\nvanishes, under different formulations and smoothness assumptions for nonlocal\nDirichlet-type boundary conditions. Our results provide explicit rates of\nconvergence that are sensitive to the compatibility of the nonlocal boundary\ndata and the extension of the solution for the local model. In particular,\nunder appropriate assumptions, constant extensions yield $\\frac{1}{2}$ order\nconvergence rates and linear extensions yield $\\frac{3}{2}$ order convergence\nrates. With smooth extensions, these rates are improved to quadratic\nconvergence. We illustrate the theory for any dimension $d\\geq 2$ and\nnumerically verify the convergence rates with a number of two dimensional\nbenchmarks, including linear patch tests, manufactured solutions, and domains\nwith curvilinear surfaces. Numerical results show a first order convergence for\nconstant extensions and second order convergence for linear extensions, which\nsuggests a possible room of improvement in the future convergence analysis.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 20:40:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Foss", "Mikil", ""], ["Radu", "Petronela", ""], ["Yu", "Yue", ""]]}, {"id": "2106.13996", "submitter": "Konstantinos F. Panagiotou Dr.", "authors": "Constantinos F. Panagiotou and Davide Cerizza and Tamer A. Zaki and\n  Yosuke Hasegawa", "title": "Optimization of a Moving Sensor Trajectory for Observing a Point Scalar\n  Source in Turbulent Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a strategy for optimizing a sensor trajectory in order to estimate\nthe time dependence of a localized scalar source in turbulent channel flow. The\napproach leverages the view of the adjoint scalar field as the sensitivity of\nmeasurement to a possible source. A cost functional is constructed so that the\noptimal sensor trajectory maintains a high sensitivity and low temporal\nvariation in the measured signal, for a given source location. This naturally\nleads to the adjoint-of-adjoint equation based on which the sensor trajectory\nis iteratively optimized. It is shown that the estimation performance based on\nthe measurement obtained by a sensor moving along the optimal trajectory is\ndrastically improved from that achieved with a stationary sensor. It is also\nshown that the ratio of the fluctuation and the mean of the sensitivity for a\ngiven sensor trajectory can be used as a diagnostic tool to evaluate the\nresultant performance. Based on this finding, we propose a new cost functional\nwhich only includes the ratio without any adjustable parameters, and\ndemonstrate its effectiveness in predicting the time dependence of scalar\nrelease from the source.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 10:43:32 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Panagiotou", "Constantinos F.", ""], ["Cerizza", "Davide", ""], ["Zaki", "Tamer A.", ""], ["Hasegawa", "Yosuke", ""]]}, {"id": "2106.14108", "submitter": "Dan Rosenbaum", "authors": "Dan Rosenbaum, Marta Garnelo, Michal Zielinski, Charlie Beattie, Ellen\n  Clancy, Andrea Huber, Pushmeet Kohli, Andrew W. Senior, John Jumper, Carl\n  Doersch, S. M. Ali Eslami, Olaf Ronneberger and Jonas Adler", "title": "Inferring a Continuous Distribution of Atom Coordinates from Cryo-EM\n  Images using VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryo-electron microscopy (cryo-EM) has revolutionized experimental protein\nstructure determination. Despite advances in high resolution reconstruction, a\nmajority of cryo-EM experiments provide either a single state of the studied\nmacromolecule, or a relatively small number of its conformations. This reduces\nthe effectiveness of the technique for proteins with flexible regions, which\nare known to play a key role in protein function. Recent methods for capturing\nconformational heterogeneity in cryo-EM data model it in volume space, making\nrecovery of continuous atomic structures challenging. Here we present a fully\ndeep-learning-based approach using variational auto-encoders (VAEs) to recover\na continuous distribution of atomic protein structures and poses directly from\npicked particle images and demonstrate its efficacy on realistic simulated\ndata. We hope that methods built on this work will allow incorporation of\nstronger prior information about protein structure and enable better\nunderstanding of non-rigid protein structures.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 22:55:46 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Rosenbaum", "Dan", ""], ["Garnelo", "Marta", ""], ["Zielinski", "Michal", ""], ["Beattie", "Charlie", ""], ["Clancy", "Ellen", ""], ["Huber", "Andrea", ""], ["Kohli", "Pushmeet", ""], ["Senior", "Andrew W.", ""], ["Jumper", "John", ""], ["Doersch", "Carl", ""], ["Eslami", "S. M. Ali", ""], ["Ronneberger", "Olaf", ""], ["Adler", "Jonas", ""]]}, {"id": "2106.14189", "submitter": "Jinao Zhang", "authors": "Jinao Zhang", "title": "A direct Jacobian total Lagrangian explicit dynamics finite element\n  algorithm for real-time simulation of hyperelastic materials", "comments": "Accepted for publication in International Journal for Numerical\n  Methods in Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel direct Jacobian total Lagrangian explicit\ndynamics (DJ-TLED) finite element algorithm for real-time nonlinear mechanics\nsimulation. The nodal force contributions are expressed using only the Jacobian\noperator, instead of the deformation gradient tensor and finite deformation\ntensor, for fewer computational operations at run-time. Owing to this proposed\nJacobian formulation, novel expressions are developed for strain invariants and\nconstant components, which are also based on the Jacobian operator. Results\nshow that the proposed DJ-TLED consumed between 0.70x and 0.88x CPU solution\ntimes compared to state-of-the-art TLED and achieved up to 121.72x and 94.26x\nspeed improvements in tetrahedral and hexahedral meshes, respectively, using\nGPU acceleration. Compared to TLED, the most notable difference is that the\nnotions of stress and strain are not explicitly visible in the proposed DJ-TLED\nbut embedded implicitly in the formulation of nodal forces. Such a force\nformulation can be beneficial for fast deformation computation and can be\nparticularly useful if the displacement field is of primary interest, which is\ndemonstrated using a neurosurgical simulation of brain deformations for\nimage-guided neurosurgery. The present work contributes towards a comprehensive\nDJ-TLED algorithm concerning isotropic and anisotropic hyperelastic\nconstitutive models and GPU implementation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 10:33:46 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhang", "Jinao", ""]]}, {"id": "2106.14623", "submitter": "Dominik Klein", "authors": "Dominik Klein, Mauricio Fern\\'andez, Robert J. Martin, Patrizio Neff\n  and Oliver Weeger", "title": "Polyconvex anisotropic hyperelasticity with neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present work, two machine learning based constitutive models for\nfinite deformations are proposed. Using input convex neural networks, the\nmodels are hyperelastic, anisotropic and fulfill the polyconvexity condition,\nwhich implies ellipticity and thus ensures material stability. The first\nconstitutive model is based on a set of polyconvex, anisotropic and objective\ninvariants. The second approach is formulated in terms of the deformation\ngradient, its cofactor and determinant, uses group symmetrization to fulfill\nthe material symmetry condition, and data augmentation to fulfill objectivity\napproximately. The extension of the dataset for the data augmentation approach\nis based on mechanical considerations and does not require additional\nexperimental or simulation data. The models are calibrated with highly\nchallenging simulation data of cubic lattice metamaterials, including finite\ndeformations and lattice instabilities. A moderate amount of calibration data\nis used, based on deformations which are commonly applied in experimental\ninvestigations. While the invariant-based model shows drawbacks for several\ndeformation modes, the model based on the deformation gradient alone is able to\nreproduce and predict the effective material behavior very well and exhibits\nexcellent generalization capabilities. Thus, in particular the second model\npresents a highly flexible constitutive modeling approach, that leads to a\nmathematically well-posed problem.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 15:33:31 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Klein", "Dominik", ""], ["Fern\u00e1ndez", "Mauricio", ""], ["Martin", "Robert J.", ""], ["Neff", "Patrizio", ""], ["Weeger", "Oliver", ""]]}, {"id": "2106.14730", "submitter": "Philip Caplan", "authors": "Philip Claude Caplan", "title": "Higher-dimensional power diagrams for semi-discrete optimal transport", "comments": "29th International Meshing Roundtable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient algorithms for solving optimal transport problems are important for\nmeasuring and optimizing distances between functions. In the $L^2$\nsemi-discrete context, this problem consists of finding a map from a continuous\ndensity function to a discrete set of points so as to minimize the transport\ncost, using the squared Euclidean distance as the cost function. This has\nimportant applications in image stippling, clustering, resource allocation and\nin generating blue noise point distributions for rendering. Recent algorithms\nhave been developed for solving the semi-discrete problem in $2d$ and $3d$,\nhowever, algorithms in higher dimensions have yet to be demonstrated, which\nrely on the efficient calculation of the power diagram (Laguerre diagram) in\nhigher dimensions. Here, we introduce an algorithm for computing power\ndiagrams, which extends to any topological dimension. We first evaluate the\nperformance of the algorithm in $2d-6d$. We then restrict our attention to\nfour-dimensional settings, demonstrating that our power diagrams can be used to\nsolve optimal quantization and semi-discrete optimal transport problems,\nwhereby a prescribed mass of each power cell is achieved by computing an\noptimized power diagram.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:00:09 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Caplan", "Philip Claude", ""]]}, {"id": "2106.15222", "submitter": "Jonas Bundschuh", "authors": "Jonas Bundschuh, Laura A.M. D'Angelo, Herbert De Gersem", "title": "Quasi-3-D Spectral Wavelet Method for a Thermal Quench Simulation", "comments": "22 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The finite element method is widely used in simulations of various fields.\nHowever, when considering domains whose extent differs strongly in different\nspatial directions a finite element simulation becomes computationally very\nexpensive due to the large number of degrees of freedom. An example of such a\ndomain are the cables inside of the magnets of particle accelerators. For\ntranslationally invariant domains, this work proposes a quasi-3-D method.\nThereby, a 2-D finite element method with a nodal basis in the cross-section is\ncombined with a spectral method with a wavelet basis in the longitudinal\ndirection. Furthermore, a spectral method with a wavelet basis and an adaptive\nand time-dependent resolution is presented. All methods are verified. As an\nexample the hot-spot propagation due to a quench in Rutherford cables is\nsimulated successfully.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:11:48 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bundschuh", "Jonas", ""], ["D'Angelo", "Laura A. M.", ""], ["De Gersem", "Herbert", ""]]}, {"id": "2106.15296", "submitter": "Deborah Pereg", "authors": "Deborah Pereg, Israel Cohen, and Anthony A. Vassiliou", "title": "Convolutional Sparse Coding Fast Approximation with Application to\n  Seismic Reflectivity Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sparse coding, we attempt to extract features of input vectors, assuming\nthat the data is inherently structured as a sparse superposition of basic\nbuilding blocks. Similarly, neural networks perform a given task by learning\nfeatures of the training data set. Recently both data-driven and model-driven\nfeature extracting methods have become extremely popular and have achieved\nremarkable results. Nevertheless, practical implementations are often too slow\nto be employed in real-life scenarios, especially for real-time applications.\nWe propose a speed-up upgraded version of the classic iterative thresholding\nalgorithm, that produces a good approximation of the convolutional sparse code\nwithin 2-5 iterations. The speed advantage is gained mostly from the\nobservation that most solvers are slowed down by inefficient global\nthresholding. The main idea is to normalize each data point by the local\nreceptive field energy, before applying a threshold. This way, the natural\ninclination towards strong feature expressions is suppressed, so that one can\nrely on a global threshold that can be easily approximated, or learned during\ntraining. The proposed algorithm can be employed with a known predetermined\ndictionary, or with a trained dictionary. The trained version is implemented as\na neural net designed as the unfolding of the proposed solver. The performance\nof the proposed solution is demonstrated via the seismic inversion problem in\nboth synthetic and real data scenarios. We also provide theoretical guarantees\nfor a stable support recovery. Namely, we prove that under certain conditions\nthe true support is perfectly recovered within the first iteration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 12:19:07 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Pereg", "Deborah", ""], ["Cohen", "Israel", ""], ["Vassiliou", "Anthony A.", ""]]}, {"id": "2106.15351", "submitter": "Vincenzo Bonnici Ph.D.", "authors": "Vincenzo Bonnici and Giuditta Franco and Vincenzo Manca", "title": "Spectral concepts in genome informational analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of k-spectrum for genomes is here investigated as a basic tool to\nanalyze genomes. Related spectral notions based on k-mers are introduced with\nsome related mathematical properties which are relevant for informational\nanalysis of genomes. Procedures to generate spectral segmentations of genomes\nare provided and are tested (under several values of length k for k-mers) on\ncases of real genomes, such as some human chromosomes and Saccharomyces\ncerevisiae.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 10:00:55 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bonnici", "Vincenzo", ""], ["Franco", "Giuditta", ""], ["Manca", "Vincenzo", ""]]}, {"id": "2106.15472", "submitter": "Joseph Paul", "authors": "Joseph Suresh Paul, Sreekanth Madhusoodhanan", "title": "Robust Multi-echo GRE Phase processing using a unity rank enforced\n  complex exponential model", "comments": "33 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: Develop a processing scheme for Gradient Echo (GRE) phase to enable\nrestoration of susceptibility-related (SuR) features in regions affected by\nimperfect phase unwrapping, background suppression and low signal-to-noise\nratio (SNR) due to phase dispersion. Theory and Methods: The predictable\ncomponents sampled across the echo dimension in a multi-echo GRE sequence are\nrecovered by rank minimizing a Hankel matrix formed using the complex\nexponential of the background suppressed phase. To estimate the single\nfrequency component that relates to the susceptibility induced field, it is\nrequired to maintain consistency with the measured phase after background\nsuppression, penalized by a unity rank approximation (URA) prior. This is\nformulated as an optimization problem, implemented using the alternating\ndirection method of multiplier (ADMM). Results: With in vivo multi-echo GRE\ndata, the magnitude susceptibility weighted image (SWI) reconstructed using URA\nprior shows additional venous structures that are obscured due to phase\ndispersion and noise in regions subject to remnant non-local field variations.\nThe performance is compared with the susceptibility map weighted imaging (SMWI)\nand the standard SWI. It is also shown using numerical simulation that\nquantitative susceptibility map (QSM) computed from the reconstructed phase\nexhibits reduced artifacts and quantification error. In vivo experiments reveal\niron depositions in insular, motor cortex and superior frontal gyrus that are\nnot identified in standard QSM. Conclusion: URA processed GRE phase is less\nsensitive to imperfections in the phase pre-processing techniques, and thereby\nenable robust estimation of SWI and QSM.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 10:22:37 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Paul", "Joseph Suresh", ""], ["Madhusoodhanan", "Sreekanth", ""]]}, {"id": "2106.15476", "submitter": "Georgios Argyris", "authors": "Georgios Argyris, Alberto Lluch Lafuente, Mirco Tribastone, Max\n  Tschaikowski, and Andrea Vandin", "title": "Reducing Boolean Networks with Backward Boolean Equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean Networks (BNs) are established models to qualitatively describe\nbiological systems. The analysis of BNs might be infeasible for medium to large\nBNs due to the state-space explosion problem. We propose a novel reduction\ntechnique called \\emph{Backward Boolean Equivalence} (BBE), which preserves\nsome properties of interest of BNs. In particular, reduced BNs provide a\ncompact representation by grouping variables that, if initialized equally, are\nalways updated equally. The resulting reduced state space is a subset of the\noriginal one, restricted to identical initialization of grouped variables. The\ncorresponding trajectories of the original BN can be exactly restored. We show\nthe effectiveness of BBE by performing a large-scale validation on the whole\nGINsim BN repository. In selected cases, we show how our method enables\nanalyses that would be otherwise intractable. Our method complements, and can\nbe combined with, other reduction methods found in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 14:54:39 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 09:46:56 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Argyris", "Georgios", ""], ["Lafuente", "Alberto Lluch", ""], ["Tribastone", "Mirco", ""], ["Tschaikowski", "Max", ""], ["Vandin", "Andrea", ""]]}, {"id": "2106.15930", "submitter": "Thomas Spenke", "authors": "Thomas Spenke, Norbert Hosters, Marek Behr", "title": "The Performance Impact of Newton Iterations per Solver Call in\n  Partitioned Fluid-Structure Interaction", "comments": null, "journal-ref": "Proceedings of the IX International Conference on Computational\n  Methods for Coupled Problems in Science and Engineering (COUPLED PROBLEMS\n  2021)", "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost of a partitioned fluid-structure interaction scheme is typically\nassessed by the number of coupling iterations required per time step, while\nignoring the Newton loops within the nonlinear sub-solvers. In this work, we\ndiscuss why these single-field iterations deserve more attention when\nevaluating the coupling's efficiency and how to find the optimal number of\nNewton steps per coupling iteration.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 09:31:10 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Spenke", "Thomas", ""], ["Hosters", "Norbert", ""], ["Behr", "Marek", ""]]}, {"id": "2106.16049", "submitter": "Charilaos Mylonas Mr.", "authors": "Charilaos Mylonas, Imad Abdallah and Eleni Chatzi", "title": "Relational VAE: A Continuous Latent Variable Model for Graph Structured\n  Data", "comments": "Code and simulated datasets will be released after finalization of\n  peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Networks (GNs) enable the fusion of prior knowledge and relational\nreasoning with flexible function approximations. In this work, a general\nGN-based model is proposed which takes full advantage of the relational\nmodeling capabilities of GNs and extends these to probabilistic modeling with\nVariational Bayes (VB). To that end, we combine complementary pre-existing\napproaches on VB for graph data and propose an approach that relies on\ngraph-structured latent and conditioning variables. It is demonstrated that\nNeural Processes can also be viewed through the lens of the proposed model. We\nshow applications on the problem of structured probability density modeling for\nsimulated and real wind farm monitoring data, as well as on the meta-learning\nof simulated Gaussian Process data. We release the source code, along with the\nsimulated datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 13:24:27 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Mylonas", "Charilaos", ""], ["Abdallah", "Imad", ""], ["Chatzi", "Eleni", ""]]}]