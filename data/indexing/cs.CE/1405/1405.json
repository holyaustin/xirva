[{"id": "1405.0354", "submitter": "Umang Vipul", "authors": "Umang Vipul", "title": "Map-Reduce Parallelization of Motif Discovery", "comments": "4 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif discovery is one of the most challenging problems in bioinformatics\ntoday. DNA sequence motifs are becoming increasingly important in analysis of\ngene regulation. Motifs are short, recurring patterns in DNA that have a\nbiological function. For example, they indicate binding sites for Transcription\nFactors (TFs) and nucleases. There are a number of Motif Discovery algorithms\nthat run sequentially. The sequential nature stops these algorithms from being\nparallelized. HOMER is one such Motif discovery tool, that we have decided to\nuse to overcome this limitation. To overcome this limitation, we propose a new\nmethodology for Motif Discovery, using HOMER, that parallelizes the task.\nParallelized version can potentially yield better scalability and performance.\nTo achieve this, we have decided to use sub-sampling and the Map Reduce model.\nAt each Map node, a sub-sampled version of the input DNA sequences is used as\ninput to HOMER. Subsampling at each map node is performed with different\nparameters to ensure that no two HOMER instances receive identical inputs. The\noutput of the map phase and the input of the reduce phase is a list of Motifs\ndiscovered using the sub-sampled sequences. The reduce phase calculates the\nmode, most frequent Motifs, and outputs them as the final discovered Motifs. We\nfound marginal speed gains with this model of execution and substantial amount\nof quality loss in discovered Motifs.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 07:30:45 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Vipul", "Umang", ""]]}, {"id": "1405.0534", "submitter": "Nicolas Courtois", "authors": "Nicolas T. Courtois", "title": "On The Longest Chain Rule and Programmed Self-Destruction of Crypto\n  Currencies", "comments": "89 pages, work in progress, the author's blog is\n  blog.bettercrypto.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we revisit some major orthodoxies which lie at the heart of the\nbitcoin crypto currency and its numerous clones. In particular we look at The\nLongest Chain Rule, the monetary supply policies and the exact mechanisms which\nimplement them. We claim that these built-in properties are not as brilliant as\nthey are sometimes claimed. A closer examination reveals that they are closer\nto being... engineering mistakes which other crypto currencies have copied\nrather blindly. More precisely we show that the capacity of current crypto\ncurrencies to resist double spending attacks is poor and most current crypto\ncurrencies are highly vulnerable. Satoshi did not implement a timestamp for\nbitcoin transactions and the bitcoin software does not attempt to monitor\ndouble spending events. As a result major attacks involving hundreds of\nmillions of dollars can occur and would not even be recorded. Hundreds of\nmillions have been invested to pay for ASIC hashing infrastructure yet\ninsufficient attention was paid to network neutrality and to insure that the\nprotection layer it promises is effective and cannot be abused. In this paper\nwe develop a theory of Programmed Self-Destruction of crypto currencies. We\nobserve that most crypto currencies have mandated abrupt and sudden\ntransitions. These affect their hash rate and therefore their protection\nagainst double spending attacks which we do not limit the to the notion of 51%\nattacks which is highly misleading. In addition we show that smaller bitcoin\ncompetitors are substantially more vulnerable. In addition to small hash rate,\nmany bitcoin competitors mandate incredibly important adjustments in miner\nreward. We exhibit examples of 'alt-coins' which validate our theory and for\nwhich the process of programmed decline and rapid self-destruction has clearly\nalready started.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 22:58:02 GMT"}, {"version": "v10", "created": "Tue, 18 Nov 2014 22:10:18 GMT"}, {"version": "v11", "created": "Wed, 10 Dec 2014 15:22:34 GMT"}, {"version": "v2", "created": "Sat, 10 May 2014 17:09:23 GMT"}, {"version": "v3", "created": "Wed, 14 May 2014 22:55:06 GMT"}, {"version": "v4", "created": "Tue, 20 May 2014 12:33:51 GMT"}, {"version": "v5", "created": "Sun, 25 May 2014 23:53:09 GMT"}, {"version": "v6", "created": "Mon, 2 Jun 2014 23:02:19 GMT"}, {"version": "v7", "created": "Sat, 9 Aug 2014 02:51:39 GMT"}, {"version": "v8", "created": "Tue, 2 Sep 2014 21:21:08 GMT"}, {"version": "v9", "created": "Sun, 28 Sep 2014 21:10:11 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Courtois", "Nicolas T.", ""]]}, {"id": "1405.0549", "submitter": "Omar S. Soliman", "authors": "Omar S. Soliman, Eman AboElhamd", "title": "Classification of Diabetes Mellitus using Modified Particle Swarm\n  Optimization and Least Squares Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Diabetes Mellitus is a major health problem all over the world. Many\nclassification algorithms have been applied for its diagnoses and treatment. In\nthis paper, a hybrid algorithm of Modified-Particle Swarm Optimization and\nLeast Squares- Support Vector Machine is proposed for the classification of\ntype II DM patients. LS-SVM algorithm is used for classification by finding\noptimal hyper-plane which separates various classes. Since LS-SVM is so\nsensitive to the changes of its parameter values, Modified-PSO algorithm is\nused as an optimization technique for LS-SVM parameters. This will Guarantee\nthe robustness of the hybrid algorithm by searching for the optimal values for\nLS-SVM parameters. The pro-posed Algorithm is implemented and evaluated using\nPima Indians Diabetes Data set from UCI repository of machine learning\ndatabases. It is also compared with different classifier algorithms which were\napplied on the same database. The experimental results showed the superiority\nof the proposed algorithm which could achieve an average classification\naccuracy of 97.833%.\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 02:31:07 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Soliman", "Omar S.", ""], ["AboElhamd", "Eman", ""]]}, {"id": "1405.0560", "submitter": "Ashish Garg", "authors": "Vidit Sharma, Ashish Garg", "title": "Numerical Investigation of Effects of Compound Angle and Length to\n  Diameter Ratio on Adiabatic Film Cooling Effectiveness", "comments": "13 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modification has been done in the normal injection hole of 35 degree, by\ninjecting the cold fluid at different angles(compound angle) in lateral\ndirection, providing a significant change in the shape of holes which later we\nfound in our numerical investigation giving good quality of effectiveness in\ncooling. Different L/D ratios are also studied for each compound angle. The\nnumerical simulation is performed based on Reynolds Averaged\nNavier-Stokes(RANS) equations with k-epsilon turbulence model by using\nFluent(Commercial Software). Adiabatic Film Cooling Effectiveness has been\nstudied for compound angles of (0, 30, 45 and 60 degrees) and L/D ratios of (1,\n2, 3 and 4) on a hole of 6mm diameter with blowing ratio 0.5. The findings are\nobtained from the results, concludes that the trend of laterally averaged\nadiabatic effectiveness is the function of L/D ratio and compound angle.\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 08:15:32 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Sharma", "Vidit", ""], ["Garg", "Ashish", ""]]}, {"id": "1405.0877", "submitter": "Simon Kramer", "authors": "Simon Kramer", "title": "A Galois-Connection between Cattell's and Szondi's Personality Profiles", "comments": "closely related to arXiv:1403.2000 as explained in the first\n  paragraph", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We propose a computable Galois-connection between, on the one hand, Cattell's\n16-Personality-Factor (16PF) Profiles, one of the most comprehensive and\nwidely-used personality measures for non-psychiatric populations and their\ncontaining PsychEval Personality Profiles (PPPs) for psychiatric populations,\nand, on the other hand, Szondi's personality profiles (SPPs), a less well-known\nbut, as we show, finer personality measure for psychiatric as well as\nnon-psychiatric populations (conceived as a unification of the depth psychology\nof S. Freud, C.G. Jung, and A. Adler). The practical significance of our result\nis that our Galois-connection provides a pair of computable, interpreting\ntranslations between the two personality spaces of PPPs (containing the 16PFs)\nand SPPs: one concrete from PPP-space to SPP-space (because SPPs are finer than\nPPPs) and one abstract from SPP-space to PPP-space (because PPPs are coarser\nthan SPPs). Thus Cattell's and Szondi's personality-test results are mutually\ninterpretable and inter-translatable, even automatically by computers.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 12:45:11 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Kramer", "Simon", ""]]}, {"id": "1405.0878", "submitter": "Anna Kad{\\l}ubowska MSc", "authors": "Grzegorz Orynczak, Marcin Jakubek, Karol Wawrzyniak, Michal Klos", "title": "Market Coupling as the Universal Algorithm to Assess Zonal Divisions", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CY cs.SY q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adopting a zonal structure of electricity market requires specification of\nzones' borders. In this paper we use social welfare as the measure to assess\nquality of various zonal divisions. The social welfare is calculated by Market\nCoupling algorithm. The analyzed divisions are found by the usage of extended\nLocational Marginal Prices (LMP) methodology presented in paper [1], which\ntakes into account variable weather conditions. The offered method of\nassessment of a proposed division of market into zones is however not limited\nto LMP approach but can evaluate the social welfare of divisions obtained by\nany methodology.\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 12:51:21 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Orynczak", "Grzegorz", ""], ["Jakubek", "Marcin", ""], ["Wawrzyniak", "Karol", ""], ["Klos", "Michal", ""]]}, {"id": "1405.1300", "submitter": "Giorgos Kouropoulos", "authors": "Giorgos Kouropoulos", "title": "Calculation software for efficiency and penetration of a fibrous filter\n  medium based on the mathematical models of air filtration", "comments": "8 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At this article will be created a software written in visual basic for\nefficiency and penetration calculation in a fibrous filter medium for given\nvalues of particles diameter that are retained in the filter. Initially, will\nbecome report of mathematical models of air filtration in fibrous filters media\nand then will develop the code and the graphical interface of application, that\nare the base for software creation in the visual basic platform.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 16:00:45 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Kouropoulos", "Giorgos", ""]]}, {"id": "1405.1304", "submitter": "Sumaira Tasnim", "authors": "Akhlaqur Rahman and Sumaira Tasnim", "title": "Application of Machine Learning Techniques in Aquaculture", "comments": "2 pages", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V10(3):214-215 Apr 2014. ISSN:2231-2803", "doi": "10.14445/22312803/IJCTT-V10P137", "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present applications of different machine learning\nalgorithms in aquaculture. Machine learning algorithms learn models from\nhistorical data. In aquaculture historical data are obtained from farm\npractices, yields, and environmental data sources. Associations between these\ndifferent variables can be obtained by applying machine learning algorithms to\nhistorical data. In this paper we present applications of different machine\nlearning algorithms in aquaculture applications.\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 14:26:42 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Rahman", "Akhlaqur", ""], ["Tasnim", "Sumaira", ""]]}, {"id": "1405.2051", "submitter": "Laurent Fournier", "authors": "Laurent Fournier", "title": "Merchant Sharing Towards a Zero Marginal Cost Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC cs.CE q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the first attempt to formalize a new field of economics;\nstudding the Intangibles Goods available on the Internet. We are taking\nadvantage of the digital world's specific rules, in particular the zero\nmarginal cost, to propose a theory of trading & sharing unified. A function\nbased money is created as a world-wide currency; \"cup\". We argue that our\nsystem discourage speculation activities while it makes easy captured taxes for\ngovernments. The implementation removes the today's paywall on the Internet and\nprovides a simple-to-use, open-source, free-of-charge, highly-secure,\nperson-to-person, privacy-respectful, digital payment tool for citizens, using\nstandard smart-phones with a strong authentication. Next step will be the\npropagation of the network application and we expect many shared benefits for\nthe whole economics development.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 11:58:31 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Fournier", "Laurent", ""]]}, {"id": "1405.2220", "submitter": "Li-Xin Wang", "authors": "Li-Xin Wang", "title": "Gaussian-Chain Filters for Heavy-Tailed Noise with Application to\n  Detecting Big Buyers and Big Sellers in Stock Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.CV cs.SY q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new heavy-tailed distribution --- Gaussian-Chain (GC)\ndistribution, which is inspirited by the hierarchical structures prevailing in\nsocial organizations. We determine the mean, variance and kurtosis of the\nGaussian-Chain distribution to show its heavy-tailed property, and compute the\ntail distribution table to give specific numbers showing how heavy is the\nheavy-tails. To filter out the heavy-tailed noise, we construct two filters ---\n2nd and 3rd-order GC filters --- based on the maximum likelihood principle.\nSimulation results show that the GC filters perform much better than the\nbenchmark least-squares algorithm when the noise is heavy-tail distributed.\nUsing the GC filters, we propose a trading strategy, named Ride-the-Mood, to\nfollow the mood of the market by detecting the actions of the big buyers and\nthe big sellers in the market based on the noisy, heavy-tailed price data.\nApplication of the Ride-the-Mood strategy to five blue-chip Hong Kong stocks\nover the recent two-year period from April 2, 2012 to March 31, 2014 shows that\ntheir returns are higher than the returns of the benchmark Buy-and-Hold\nstrategy and the Hang Seng Index Fund.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 13:06:27 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Wang", "Li-Xin", ""]]}, {"id": "1405.2271", "submitter": "Camellia Ray", "authors": "Camellia Ray, Jayanta Kumar Das, Pabitra Pal Choudhury", "title": "On Analysis and Generation of some Biologically Important Boolean\n  Functions", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean networks are used to model biological networks such as gene\nregulatory networks. Often Boolean networks show very chaotic behaviour which\nis sensitive to any small perturbations. In order to reduce the chaotic\nbehaviour and to attain stability in the gene regulatory network, nested\nCanalizing Functions (NCFs) are best suited. NCFs and its variants have a wide\nrange of applications in systems biology. Previously, many works were done on\nthe application of canalizing functions, but there were fewer methods to check\nif any arbitrary Boolean function is canalizing or not. In this paper, by using\nKarnaugh Map this problem is solved and also it has been shown that when the\ncanalizing functions of variable is given, all the canalizing functions of\nvariable could be generated by the method of concatenation. In this paper we\nhave uniquely identified the number of NCFs having a particular Hamming\nDistance (H.D) generated by each variable as starting canalizing input.\nPartially NCFs of 4 variables has also been studied in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 15:51:32 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2014 12:25:58 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Ray", "Camellia", ""], ["Das", "Jayanta Kumar", ""], ["Choudhury", "Pabitra Pal", ""]]}, {"id": "1405.2806", "submitter": "Quentin Gemine", "authors": "Quentin Gemine, Damien Ernst, Bertrand Corn\\'elusse", "title": "Active network management for electrical distribution systems: problem\n  formulation, benchmark, and approximate solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing share of renewable and distributed generation in\nelectrical distribution systems, Active Network Management (ANM) becomes a\nvaluable option for a distribution system operator to operate his system in a\nsecure and cost-effective way without relying solely on network reinforcement.\nANM strategies are short-term policies that control the power injected by\ngenerators and/or taken off by loads in order to avoid congestion or voltage\nissues. Advanced ANM strategies imply that the system operator has to solve\nlarge-scale optimal sequential decision-making problems under uncertainty. For\nexample, decisions taken at a given moment constrain the future decisions that\ncan be taken and uncertainty must be explicitly accounted for because neither\ndemand nor generation can be accurately forecasted. We first formulate the ANM\nproblem, which in addition to be sequential and uncertain, has a nonlinear\nnature stemming from the power flow equations and a discrete nature arising\nfrom the activation of power modulation signals. This ANM problem is then cast\nas a stochastic mixed-integer nonlinear program, as well as second-order cone\nand linear counterparts, for which we provide quantitative results using state\nof the art solvers and perform a sensitivity analysis over the size of the\nsystem, the amount of available flexibility, and the number of scenarios\nconsidered in the deterministic equivalent of the stochastic program. To foster\nfurther research on this problem, we make available at\nhttp://www.montefiore.ulg.ac.be/~anm/ three test beds based on distribution\nnetworks of 5, 33, and 77 buses. These test beds contain a simulator of the\ndistribution system, with stochastic models for the generation and consumption\ndevices, and callbacks to implement and test various ANM strategies.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 15:31:34 GMT"}, {"version": "v2", "created": "Sat, 17 May 2014 19:06:23 GMT"}, {"version": "v3", "created": "Mon, 23 Jun 2014 14:25:38 GMT"}, {"version": "v4", "created": "Wed, 13 Aug 2014 14:27:43 GMT"}, {"version": "v5", "created": "Wed, 23 Sep 2015 11:09:41 GMT"}, {"version": "v6", "created": "Wed, 1 Jun 2016 19:19:10 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Gemine", "Quentin", ""], ["Ernst", "Damien", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "1405.3166", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "Pokkuluri Kiran Sree, Inampudi Ramesh Babu", "title": "Clonal-Based Cellular Automata in Bioinformatics", "comments": "14 Pages. arXiv admin note: substantial text overlap with\n  arXiv:1404.0453", "journal-ref": "Journal of Advanced Research in Applied Artificial Intelligence &\n  Neural Network Vol.1, Issue1, 2014", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at providing a survey on the problems that can be easily\naddressed by clonalbased cellular automata in bioinformatics. Researchers try\nto address the problems in bioinformatics independent of each problem. None of\nthe researchers has tried to relate the major problems in bioinformatics and\nfind a solution using common frame work. We tried to find various problems in\nbioinformatics which can be addressed easily by clonal based cellular automata.\nExtensive literature survey is conducted. We have considered some papers in\nvarious journals and conferences for conduct of our research. This paper\nprovides intuition towards relating various problems in bioinformatics\nlogically and tries to attain a common frame work with respect to clonal based\ncellular automata classifier for addressing the same.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 14:35:18 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Sree", "Pokkuluri Kiran", ""], ["Babu", "Inampudi Ramesh", ""]]}, {"id": "1405.3240", "submitter": "Juan Jose Lopez-Villarejo", "authors": "David A. Kosower and J.J. Lopez-Villarejo", "title": "Flowgen: Flowchart-Based Documentation for C++ Codes", "comments": "17 pages, 10 figures, supplemental material (two ancillary files)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CE hep-ex hep-lat hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Flowgen tool, which generates flowcharts from annotated C++\nsource code. The tool generates a set of interconnected high-level UML activity\ndiagrams, one for each function or method in the C++ sources. It provides a\nsimple and visual overview of complex implementations of numerical algorithms.\nFlowgen is complementary to the widely-used Doxygen documentation tool. The\nultimate aim is to render complex C++ computer codes accessible, and to enhance\ncollaboration between programmers and algorithm or science specialists. We\ndescribe the tool and a proof-of-concept application to the VINCIA plug-in for\nsimulating collisions at CERN's Large Hadron Collider.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 17:28:17 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Kosower", "David A.", ""], ["Lopez-Villarejo", "J. J.", ""]]}, {"id": "1405.3302", "submitter": "Laura De Lorenzis", "authors": "Claudio Maruccio, Laura De Lorenzis, Luana Persano, Dario Pisignano", "title": "Computational homogenization of fibrous piezoelectric materials", "comments": "22 pages, 13 figures", "journal-ref": "Computational Mechanics, Volume 55, Issue 5, pp. 983-998, 2015", "doi": "10.1007/s00466-015-1147-0", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexible piezoelectric devices made of polymeric materials are widely used\nfor micro- and nano-electro-mechanical systems. In particular, numerous recent\napplications concern energy harvesting. Due to the importance of computational\nmodeling to understand the influence that microscale geometry and constitutive\nvariables exert on the macroscopic behavior, a numerical approach is developed\nhere for multiscale and multiphysics modeling of thin piezoelectric sheets made\nof aligned arrays of polymeric nanofibers, manufactured by electrospinning. At\nthe microscale, the representative volume element consists in piezoelectric\npolymeric nanofibers, assumed to feature a piezoelastic behavior and subjected\nto electromechanical contact constraints. The latter are incorporated into the\nvirtual work equations by formulating suitable electric, mechanical and\ncoupling potentials and the constraints are enforced by using the penalty\nmethod. From the solution of the micro-scale boundary value problem, a suitable\nscale transition procedure leads to identifying the performance of a\nmacroscopic thin piezoelectric shell element.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 20:44:40 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2015 09:13:01 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2015 16:48:19 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Maruccio", "Claudio", ""], ["De Lorenzis", "Laura", ""], ["Persano", "Luana", ""], ["Pisignano", "Dario", ""]]}, {"id": "1405.3574", "submitter": "Tilman Sumpf J", "authors": "Tilman J. Sumpf (1), Andreas Petrovic (2), Martin Uecker (3), Florian\n  Knoll (4), Jens Frahm (1) ((1) Biomedizinische NMR Forschungs GmbH am\n  Max-Planck-Institut f\\\"ur biophysikalische Chemie, G\\\"ottingen. (2) Ludwig\n  Boltzmann Institute for Clinical Forensic Imaging, Graz, Austria, and\n  Institute for Medical Engineering, Graz University of Technology, Graz,\n  Austria. (3) Department of Electrical Engineering and Computer Sciences,\n  University of California, Berkeley, California. (4) Center for Biomedical\n  Imaging, New York University School of Medicine, New York.)", "title": "Fast T2 Mapping with Improved Accuracy Using Undersampled Spin-echo MRI\n  and Model-based Reconstructions with a Generating Function", "comments": "10 pages, 7 figures", "journal-ref": "Medical Imaging, IEEE Transactions on 33 (2014) 2213-2222", "doi": "10.1109/TMI.2014.2333370", "report-no": null, "categories": "physics.med-ph cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model-based reconstruction technique for accelerated T2 mapping with\nimproved accuracy is proposed using undersampled Cartesian spin-echo MRI data.\nThe technique employs an advanced signal model for T2 relaxation that accounts\nfor contributions from indirect echoes in a train of multiple spin echoes. An\niterative solution of the nonlinear inverse reconstruction problem directly\nestimates spin-density and T2 maps from undersampled raw data. The algorithm is\nvalidated for simulated data as well as phantom and human brain MRI at 3 T. The\nperformance of the advanced model is compared to conventional pixel-based\nfitting of echo-time images from fully sampled data. The proposed method yields\nmore accurate T2 values than the mono-exponential model and allows for\nundersampling factors of at least 6. Although limitations are observed for very\nlong T2 relaxation times, respective reconstruction problems may be overcome by\na gradient dampening approach. The analytical gradient of the utilized cost\nfunction is included as Appendix.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 13:08:25 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Sumpf", "Tilman J.", ""], ["Petrovic", "Andreas", ""], ["Uecker", "Martin", ""], ["Knoll", "Florian", ""], ["Frahm", "Jens", ""]]}, {"id": "1405.4044", "submitter": "Nicolas Guarin-Zapata", "authors": "Nicol\\'as Guar\\'in-Zapata, Juan G\\'omez and Juan Jaramillo", "title": "Seismic Wave Scattering Through a Compressed Hybrid BEM/FEM Method", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA physics.comp-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Approximated numerical techniques, for the solution of the elastic wave\nscattering problem over semi-infinite domains are reviewed. The approximations\ninvolve the representation of the half-space by a boundary condition described\nin terms of 2D boundary element discretizations. The classical BEM matrices are\ninitially re-written into the form of a dense dynamic stiffness matrix and\nlater approximated to a banded matrix. The resulting final banded matrix is\nthen used like a standard finite element to solve the wave scattering problem\nat lower memory requirements. The accuracy of the reviewed methods is\nbenchmarked against the classical problems of a semi-circular and a rectangular\ncanyon. Results are presented in the time and frequency domain, as well as in\nterms of relative errors in the considered approximations. The main goal of the\npaper is to give the analyst a method that can be used at the practising level\nwhere an approximate solution is enough in order to support engineering\ndecisions.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 01:26:35 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Guar\u00edn-Zapata", "Nicol\u00e1s", ""], ["G\u00f3mez", "Juan", ""], ["Jaramillo", "Juan", ""]]}, {"id": "1405.4201", "submitter": "Luisa Polania", "authors": "Luisa F. Polania, Rafael E. Carrillo, Manuel Blanco-Velasco, and\n  Kenneth E. Barner", "title": "Exploiting Prior Knowledge in Compressed Sensing Wireless ECG Systems", "comments": "Accepted for publication at IEEE Journal of Biomedical and Health\n  Informatics", "journal-ref": null, "doi": "10.1109/JBHI.2014.2325017", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in telecardiology show that compressed sensing (CS) is a\npromising tool to lower energy consumption in wireless body area networks for\nelectrocardiogram (ECG) monitoring. However, the performance of current\nCS-based algorithms, in terms of compression rate and reconstruction quality of\nthe ECG, still falls short of the performance attained by state-of-the-art\nwavelet based algorithms. In this paper, we propose to exploit the structure of\nthe wavelet representation of the ECG signal to boost the performance of\nCS-based methods for compression and reconstruction of ECG signals. More\nprecisely, we incorporate prior information about the wavelet dependencies\nacross scales into the reconstruction algorithms and exploit the high fraction\nof common support of the wavelet coefficients of consecutive ECG segments.\nExperimental results utilizing the MIT-BIH Arrhythmia Database show that\nsignificant performance gains, in terms of compression rate and reconstruction\nquality, can be obtained by the proposed algorithms compared to current\nCS-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 15:12:34 GMT"}, {"version": "v2", "created": "Thu, 29 May 2014 16:07:41 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Polania", "Luisa F.", ""], ["Carrillo", "Rafael E.", ""], ["Blanco-Velasco", "Manuel", ""], ["Barner", "Kenneth E.", ""]]}, {"id": "1405.4394", "submitter": "Tapio Pahikkala", "authors": "Michiel Stock, Thomas Fober, Eyke H\\\"ullermeier, Serghei Glinca,\n  Gerhard Klebe, Tapio Pahikkala, Antti Airola, Bernard De Baets, Willem\n  Waegeman", "title": "Identification of functionally related enzymes by learning-to-rank\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enzyme sequences and structures are routinely used in the biological sciences\nas queries to search for functionally related enzymes in online databases. To\nthis end, one usually departs from some notion of similarity, comparing two\nenzymes by looking for correspondences in their sequences, structures or\nsurfaces. For a given query, the search operation results in a ranking of the\nenzymes in the database, from very similar to dissimilar enzymes, while\ninformation about the biological function of annotated database enzymes is\nignored.\n  In this work we show that rankings of that kind can be substantially improved\nby applying kernel-based learning algorithms. This approach enables the\ndetection of statistical dependencies between similarities of the active cleft\nand the biological function of annotated enzymes. This is in contrast to\nsearch-based approaches, which do not take annotated training data into\naccount. Similarity measures based on the active cleft are known to outperform\nsequence-based or structure-based measures under certain conditions. We\nconsider the Enzyme Commission (EC) classification hierarchy for obtaining\nannotated enzymes during the training phase. The results of a set of sizeable\nexperiments indicate a consistent and significant improvement for a set of\nsimilarity measures that exploit information about small cavities in the\nsurface of enzymes.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 13:51:42 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Stock", "Michiel", ""], ["Fober", "Thomas", ""], ["H\u00fcllermeier", "Eyke", ""], ["Glinca", "Serghei", ""], ["Klebe", "Gerhard", ""], ["Pahikkala", "Tapio", ""], ["Airola", "Antti", ""], ["De Baets", "Bernard", ""], ["Waegeman", "Willem", ""]]}, {"id": "1405.4607", "submitter": "Bernardo Gon\\c{c}alves", "authors": "Bernardo Gon\\c{c}alves, Fabio Porto", "title": "$\\Upsilon$-DB: Managing scientific hypotheses as uncertain data", "comments": "To appear in PVLDB 2014", "journal-ref": "PVLDB 7(11):959-62, 2014", "doi": null, "report-no": null, "categories": "cs.DB cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In view of the paradigm shift that makes science ever more data-driven, we\nconsider deterministic scientific hypotheses as uncertain data. This vision\ncomprises a probabilistic database (p-DB) design methodology for the systematic\nconstruction and management of U-relational hypothesis DBs, viz.,\n$\\Upsilon$-DBs. It introduces hypothesis management as a promising new class of\napplications for p-DBs. We illustrate the potential of $\\Upsilon$-DB as a tool\nfor deep predictive analytics.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 05:09:50 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Gon\u00e7alves", "Bernardo", ""], ["Porto", "Fabio", ""]]}, {"id": "1405.4890", "submitter": "Xiaoyu Wang Dr.", "authors": "Meng Yue and Xiaoyu Wang", "title": "A Revised Incremental Conductance MPPT Algorithm for Solar PV Generation\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A revised Incremental Conductance (IncCond) maximum power point tracking\n(MPPT) algorithm for PV generation systems is proposed in this paper. The\ncommonly adopted traditional IncCond method uses a constant step size for\nvoltage adjustment and is difficult to achieve both a good tracking performance\nand quick elimination of the oscillations, especially under the dramatic\nchanges of the environment conditions. For the revised algorithm, the\nincremental voltage change step size is adaptively adjusted based on the slope\nof the power-voltage (P-V) curve. An accelerating factor and a decelerating\nfactor are further applied to adjust the voltage step change considering\nwhether the sign of the P-V curve slope remains the same or not in a subsequent\ntracking step. In addition, the upper bound of the maximum voltage step change\nis also updated considering the information of sign changes. The revised MPPT\nalgorithm can quickly track the maximum power points (MPPs) and remove the\noscillation of the actual operation points around the real MPPs. The\neffectiveness of the revised algorithm is demonstrated using a simulation.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 20:51:16 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Yue", "Meng", ""], ["Wang", "Xiaoyu", ""]]}, {"id": "1405.5148", "submitter": "Hao Li", "authors": "Ting Zhu, Yuxuan Zhu, Hong Yang, Hao Li", "title": "Determination of Boiling Range of Xylene Mixed in PX Device Using\n  Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Determination of boiling range of xylene mixed in PX device is currently a\ncrucial topic in the practical applications because of the recent disputes of\nPX project in China. In our study, instead of determining the boiling range of\nxylene mixed by traditional approach in laboratory or industry, we successfully\nestablished two Artificial Neural Networks (ANNs) models to determine the\ninitial boiling point and final boiling point respectively. Results show that\nthe Multilayer Feedforward Neural Networks (MLFN) model with 7 nodes (MLFN-7)\nis the best model to determine the initial boiling point of xylene mixed, with\nthe RMS error 0.18; while the MLFN model with 4 nodes (MLFN-4) is the best\nmodel to determine the final boiling point of xylene mixed, with the RMS error\n0.75. The training and testing processes both indicate that the models we\ndeveloped are robust and precise. Our research can effectively avoid the damage\nof the PX device to human body and environment.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 16:33:25 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Zhu", "Ting", ""], ["Zhu", "Yuxuan", ""], ["Yang", "Hong", ""], ["Li", "Hao", ""]]}, {"id": "1405.5197", "submitter": "Yitao Zhu", "authors": "Yitao Zhu, Corina Sandu, Daniel Dopico, Adrian Sandu", "title": "Optimization of Vehicle Dynamics based on Multibody Models using Adjoint\n  Sensitivity Analysis", "comments": "I tried to replace this paper with a new one which has corrected\n  several errors in this paper. However, I didn't know how to replace it at\n  that time, I submitted a new one \"Dynamic Response Optimization of Complex\n  Multibody Systems in a Penalty Formulation using Adjoint Sensitivity\", the\n  identifier is arXiv:1410.8422. Since I have already submitted that one, I\n  want to withdraw this one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multibody dynamics simulations have become widely used tools for vehicle\nsystems analysis and design. As this approach evolves, it becomes able to\nprovide additional information for various types of analyses. One very\nimportant direction is the optimization of multibody systems. Sensitivity\nanalysis of multibody system dynamics is essential for design optimization.\nDynamic sensitivities, when needed, are often calculated by means of finite\ndifferences. However, depending of the number of parameters involved, this\nprocedure can be computationally expensive. Moreover, in many cases the results\nsuffer from low accuracy when real perturbations are used. This paper develops\nthe adjoint sensitivity analysis of multibody systems in the context of penalty\nformulations. The resulting sensitivities are applied to perform dynamical\noptimization of a full vehicle system.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 19:29:51 GMT"}, {"version": "v2", "created": "Mon, 3 Nov 2014 21:55:51 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Zhu", "Yitao", ""], ["Sandu", "Corina", ""], ["Dopico", "Daniel", ""], ["Sandu", "Adrian", ""]]}, {"id": "1405.5206", "submitter": "Hao Li", "authors": "Xiaohui Huang, Xing Hu, Weichang Jiang, Zhi Yang, Hao Li", "title": "Application of Multilayer Feedforward Neural Networks in Predicting Tree\n  Height and Forest Stock Volume of Chinese Fir", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Wood increment is critical information in forestry management. Previous\nstudies used mathematics models to describe complex growing pattern of forest\nstand, in order to determine the dynamic status of growing forest stand in\nmultiple conditions. In our research, we aimed at studying non-linear\nrelationships to establish precise and robust Artificial Neural Networks (ANN)\nmodels to predict the precise values of tree height and forest stock volume\nbased on data of Chinese fir. Results show that Multilayer Feedforward Neural\nNetworks with 4 nodes (MLFN-4) can predict the tree height with the lowest RMS\nerror (1.77); Multilayer Feedforward Neural Networks with 7 nodes (MLFN-7) can\npredict the forest stock volume with the lowest RMS error (4.95). The training\nand testing process have proved that our models are precise and robust.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 19:52:43 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Huang", "Xiaohui", ""], ["Hu", "Xing", ""], ["Jiang", "Weichang", ""], ["Yang", "Zhi", ""], ["Li", "Hao", ""]]}, {"id": "1405.5245", "submitter": "Luca Bonaventura", "authors": "G. Tumolo and L. Bonaventura", "title": "An accurate and efficient numerical framework for adaptive numerical\n  weather prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.ao-ph physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an accurate and efficient discretization approach for the adaptive\ndiscretization of typical model equations employed in numerical weather\nprediction. A semi-Lagrangian approach is combined with the TR-BDF2\nsemi-implicit time discretization method and with a spatial discretization\nbased on adaptive discontinuous finite elements. The resulting method has full\nsecond order accuracy in time and can employ polynomial bases of arbitrarily\nhigh degree in space, is unconditionally stable and can effectively adapt the\nnumber of degrees of freedom employed in each element, in order to balance\naccuracy and computational cost. The p-adaptivity approach employed does not\nrequire remeshing, therefore it is especially suitable for applications, such\nas numerical weather prediction, in which a large number of physical quantities\nare associated with a given mesh. Furthermore, although the proposed method can\nbe implemented on arbitrary unstructured and nonconforming meshes, even its\napplication on simple Cartesian meshes in spherical coordinates can cure\neffectively the pole problem by reducing the polynomial degree used in the\npolar elements. Numerical simulations of classical benchmarks for the shallow\nwater and for the fully compressible Euler equations validate the method and\ndemonstrate its capability to achieve accurate results also at large Courant\nnumbers, with time steps up to 100 times larger than those of typical explicit\ndiscretizations of the same problems, while reducing the computational cost\nthanks to the adaptivity algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 21:08:44 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Tumolo", "G.", ""], ["Bonaventura", "L.", ""]]}, {"id": "1405.5550", "submitter": "Hao Li", "authors": "Hao Li, Dazuo Yang, Fudi Chen, Yibing Zhou, and Zhilong Xiu", "title": "Application of Artificial Neural Networks in Predicting Abrasion\n  Resistance of Solution Polymerized Styrene-Butadiene Rubber Based Composites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Abrasion resistance of solution polymerized styrene-butadiene rubber (SSBR)\nbased composites is a typical and crucial property in practical applications.\nPrevious studies show that the abrasion resistance can be calculated by the\nmultiple linear regression model. In our study, considering this relationship\ncan also be described into the non-linear conditions, a Multilayer Feed-forward\nNeural Networks model with 3 nodes (MLFN-3) was successfully established to\ndescribe the relationship between the abrasion resistance and other properties,\nusing 23 groups of data, with the RMS error 0.07. Our studies have proved that\nArtificial Neural Networks (ANN) model can be used to predict the SSBR-based\ncomposites, which is an accurate and robust process.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 20:30:22 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Li", "Hao", ""], ["Yang", "Dazuo", ""], ["Chen", "Fudi", ""], ["Zhou", "Yibing", ""], ["Xiu", "Zhilong", ""]]}, {"id": "1405.6173", "submitter": "Ahmed Ibrahim Taloba", "authors": "M. H. Marghny, Rasha M. Abd El-Aziz, Ahmed I. Taloba", "title": "An Effective Evolutionary Clustering Algorithm: Hepatitis C Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Clustering analysis plays an important role in scientific research and\ncommercial application. K-means algorithm is a widely used partition method in\nclustering. However, it is known that the K-means algorithm may get stuck at\nsuboptimal solutions, depending on the choice of the initial cluster centers.\nIn this article, we propose a technique to handle large scale data, which can\nselect initial clustering center purposefully using Genetic algorithms (GAs),\nreduce the sensitivity to isolated point, avoid dissevering big cluster, and\novercome deflexion of data in some degree that caused by the disproportion in\ndata partitioning owing to adoption of multi-sampling. We applied our method to\nsome public datasets these show the advantages of the proposed approach for\nexample Hepatitis C dataset that has been taken from the machine learning\nwarehouse of University of California. Our aim is to evaluate hepatitis\ndataset. In order to evaluate this dataset we did some preprocessing operation,\nthe reason to preprocessing is to summarize the data in the best and suitable\nway for our algorithm. Missing values of the instances are adjusted using local\nmean method.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 11:03:28 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Marghny", "M. H.", ""], ["El-Aziz", "Rasha M. Abd", ""], ["Taloba", "Ahmed I.", ""]]}, {"id": "1405.6181", "submitter": "Benyuan Liu", "authors": "Benyuan Liu", "title": "Py-oopsi: the python implementation of the fast-oopsi algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Fast-oopsi was developed by Joshua Vogelstein in 2009, which is now widely\nused to extract neuron spike activities from calcium fluorescence signals.\nHere, we propose detailed implementation of the fast-oopsi algorithm in python\nprogramming language. Some corrections are also made to the original fast-oopsi\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 06:05:04 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Liu", "Benyuan", ""]]}, {"id": "1405.7290", "submitter": "Christian Jacobs", "authors": "Christian T. Jacobs, Alexandros Avdis, Gerard J. Gorman, Matthew D.\n  Piggott", "title": "PyRDM: A Python-based library for automating the management and online\n  publication of scientific software and data", "comments": "Revised version. The main changes are: Added pdfLaTeX to the\n  dependencies list; Improved Figure 1 to show the 'publish' option selected in\n  Diamond; Added two paragraphs to explain why users would want to use PyRDM;\n  Added some content on the PyRDM roadmap, and also some content regarding\n  engagement with libraries and research software engineers", "journal-ref": "Journal of Open Research Software 2:e28 (2014) 1-6", "doi": "10.5334/jors.bj", "report-no": null, "categories": "cs.CE cs.DL cs.MS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The recomputability and reproducibility of results from scientific software\nrequires access to both the source code and all associated input and output\ndata. However, the full collection of these resources often does not accompany\nthe key findings published in journal articles, thereby making it difficult or\nimpossible for the wider scientific community to verify the correctness of a\nresult or to build further research on it. This paper presents a new\nPython-based library, PyRDM, whose functionality aims to automate the process\nof sharing the software and data via online, citable repositories such as\nFigshare. The library is integrated into the workflow of an open-source\ncomputational fluid dynamics package, Fluidity, to demonstrate an example of\nits usage.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 16:07:12 GMT"}, {"version": "v2", "created": "Thu, 21 Aug 2014 10:48:05 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Jacobs", "Christian T.", ""], ["Avdis", "Alexandros", ""], ["Gorman", "Gerard J.", ""], ["Piggott", "Matthew D.", ""]]}]