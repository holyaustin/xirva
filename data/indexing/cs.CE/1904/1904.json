[{"id": "1904.00141", "submitter": "Suchuan Dong", "authors": "Zhiguo Yang and Suchuan Dong", "title": "A Roadmap for Discretely Energy-Stable Schemes for Dissipative Systems\n  Based on a Generalized Auxiliary Variable with Guaranteed Positivity", "comments": "50 pages, 20 figures, 1 table", "journal-ref": null, "doi": "10.1016/j.jcp.2019.109121", "report-no": null, "categories": "physics.comp-ph cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for devising discretely energy-stable schemes for\ngeneral dissipative systems based on a generalized auxiliary variable. The\nauxiliary variable, a scalar number, can be defined in terms of the energy\nfunctional by a general class of functions, not limited to the square root\nfunction adopted in previous approaches. The current method has another\nremarkable property: the computed values for the generalized auxiliary variable\nare guaranteed to be positive on the discrete level, regardless of the time\nstep sizes or the external forces. This property of guaranteed positivity is\nnot available in previous approaches. A unified procedure for treating the\ndissipative governing equations and the generalized auxiliary variable on the\ndiscrete level has been presented. The discrete energy stability of the\nproposed numerical scheme and the positivity of the computed auxiliary variable\nhave been proved for general dissipative systems. The current method, termed\ngPAV (generalized Positive Auxiliary Variable), requires only the solution of\nlinear algebraic equations within a time step. With appropriate choice of the\noperator in the algorithm, the resultant linear algebraic systems upon\ndiscretization involve only constant and time-independent coefficient matrices,\nwhich only need to be computed once and can be pre-computed. Several specific\ndissipative systems are studied in relative detail using the gPAV framework.\nAmple numerical experiments are presented to demonstrate the performance of the\nmethod, and the robustness of the scheme at large time step sizes.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 03:08:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Yang", "Zhiguo", ""], ["Dong", "Suchuan", ""]]}, {"id": "1904.00182", "submitter": "Joe Alexandersen", "authors": "Nicolo Pollini and Ole Sigmund and Casper Schousboe Andreasen and Joe\n  Alexandersen", "title": "A \"poor man's\" approach for high-resolution three-dimensional topology\n  optimization of natural convection problems", "comments": null, "journal-ref": "Advances in Engineering Software, Volume 140, February 2020,\n  102736", "doi": "10.1016/j.advengsoft.2019.102736", "report-no": null, "categories": "cs.CE cs.DC math.OC physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper treats topology optimization of natural convection problems. A\nsimplified model is suggested to describe the flow of an incompressible fluid\nin steady state conditions, similar to Darcy's law for fluid flow in porous\nmedia. The equations for the fluid flow are coupled to the thermal\nconvection-diffusion equation through the Boussinesq approximation. The coupled\nnon-linear system of equations is discretized with stabilized finite elements\nand solved in a parallel framework that allows for the optimization of high\nresolution three-dimensional problems. A density-based topology optimization\napproach is used, where a two-material interpolation scheme is applied to both\nthe permeability and conductivity of the distributed material. Due to the\nsimplified model, the proposed methodology allows for a significant reduction\nof the computational effort required in the optimization. At the same time, it\nis significantly more accurate than even simpler models that rely on convection\nboundary conditions based on Newton's law of cooling. The methodology discussed\nherein is applied to the optimization-based design of three-dimensional heat\nsinks. The final designs are formally compared with results of previous work\nobtained from solving the full set of Navier-Stokes equations. The results are\ncompared in terms of performance of the optimized designs and computational\ncost. The computational time is shown to be decreased to around 5-20% in terms\nof core-hours, allowing for the possibility of generating an optimized design\nduring the workday on a small computational cluster and overnight on a high-end\ndesktop.\n", "versions": [{"version": "v1", "created": "Sat, 30 Mar 2019 09:41:13 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Pollini", "Nicolo", ""], ["Sigmund", "Ole", ""], ["Andreasen", "Casper Schousboe", ""], ["Alexandersen", "Joe", ""]]}, {"id": "1904.01095", "submitter": "Alberto Hernandez", "authors": "Alberto Hernandez, Adarsh Balasubramanian, Fenglin Yuan, Simon Mason,\n  and Tim Mueller", "title": "Fast, accurate, and transferable many-body interatomic potentials by\n  symbolic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The length and time scales of atomistic simulations are limited by the\ncomputational cost of the methods used to predict material properties. In\nrecent years there has been great progress in the use of machine learning\nalgorithms to develop fast and accurate interatomic potential models, but it\nremains a challenge to develop models that generalize well and are fast enough\nto be used at extreme time and length scales. To address this challenge, we\nhave developed a machine learning algorithm based on symbolic regression in the\nform of genetic programming that is capable of discovering accurate,\ncomputationally efficient manybody potential models. The key to our approach is\nto explore a hypothesis space of models based on fundamental physical\nprinciples and select models within this hypothesis space based on their\naccuracy, speed, and simplicity. The focus on simplicity reduces the risk of\noverfitting the training data and increases the chances of discovering a model\nthat generalizes well. Our algorithm was validated by rediscovering an exact\nLennard-Jones potential and a Sutton Chen embedded atom method potential from\ntraining data generated using these models. By using training data generated\nfrom density functional theory calculations, we found potential models for\nelemental copper that are simple, as fast as embedded atom models, and capable\nof accurately predicting properties outside of their training set. Our approach\nrequires relatively small sets of training data, making it possible to generate\ntraining data using highly accurate methods at a reasonable computational cost.\nWe present our approach, the forms of the discovered models, and assessments of\ntheir transferability, accuracy and speed.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 20:21:36 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 15:20:36 GMT"}, {"version": "v3", "created": "Sat, 17 Aug 2019 14:32:48 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Hernandez", "Alberto", ""], ["Balasubramanian", "Adarsh", ""], ["Yuan", "Fenglin", ""], ["Mason", "Simon", ""], ["Mueller", "Tim", ""]]}, {"id": "1904.01162", "submitter": "Nicolas Guarin-Zapata", "authors": "Camilo Valencia, Juan Gomez, Nicol\\'as Guar\\'in-Zapata", "title": "A general-purpose element-based approach to compute dispersion relations\n  in periodic materials with existing finite element codes", "comments": "24 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most of standard Finite Element (FE) codes it is not easy to calculate\ndispersion relations from periodic materials. Here we propose a new strategy to\ncalculate such dispersion relations with available FE codes using user element\nsubroutines. Typically, the Bloch boundary conditions are applied to the global\nassembled matrices of the structure through a transformation matrix or\nrow-and-column operations. Such a process is difficult to implement in standard\nFE codes since the user does not have access to the global matrices. In this\nwork, we apply those Bloch boundary conditions directly at the elemental level.\nThe proposed strategy can be easily implemented in any FE code. This strategy\ncan be used either in real or complex algebra solvers. It is general enough to\npermit any spatial dimension and physical phenomena involving periodic\nstructures. A detailed process of calculation and assembly of the elemental\nmatrices is shown. We verify our method with available analytical solutions and\nexternal numerical results, using different material models and unit cell\ngeometries\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 01:25:20 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Valencia", "Camilo", ""], ["Gomez", "Juan", ""], ["Guar\u00edn-Zapata", "Nicol\u00e1s", ""]]}, {"id": "1904.01192", "submitter": "Georgios Bourantas", "authors": "K. Miller, G. R. Joldes, G. Bourantas, S. K. Warfield, D. E. Hyde, R.\n  Kikinis, A. Wittek", "title": "Biomechanical modeling and computer simulation of the brain during\n  neurosurgery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational biomechanics of the brain for neurosurgery is an emerging area\nof research recently gaining in importance and practical applications. This\nreview paper presents the contributions of the Intelligent Systems for Medicine\nLaboratory and it's collaborators to this field, discussing the modeling\napproaches adopted and the methods developed for obtaining the numerical\nsolutions. We adopt a physics-based modeling approach, and describe the brain\ndeformation in mechanical terms (such as displacements, strains and stresses),\nwhich can be computed using a biomechanical model, by solving a continuum\nmechanics problem. We present our modeling approaches related to geometry\ncreation, boundary conditions, loading and material properties. From the point\nof view of solution methods, we advocate the use of fully nonlinear modeling\napproaches, capable of capturing very large deformations and nonlinear material\nbehavior. We discuss finite element and meshless domain discretization, the use\nof the Total Lagrangian formulation of continuum mechanics, and explicit time\nintegration for solving both time-accurate and steady state problems. We\npresent the methods developed for handling contacts and for warping 3D medical\nimages using the results of our simulations. We present two examples to\nshowcase these methods: brain shift estimation for image registration and brain\ndeformation computation for neuronavigation in epilepsy treatment.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 03:28:58 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Miller", "K.", ""], ["Joldes", "G. R.", ""], ["Bourantas", "G.", ""], ["Warfield", "S. K.", ""], ["Hyde", "D. E.", ""], ["Kikinis", "R.", ""], ["Wittek", "A.", ""]]}, {"id": "1904.01244", "submitter": "Roberto M\\'inguez", "authors": "Roberto M\\'inguez and V\\'ictor Casero-Alonso", "title": "On the convergence of cutting-plane methods for robust optimization with\n  ellipsoidal uncertainty sets", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in cutting-plane strategies applied to robust optimization\nproblems show that they are competitive with respect to problem reformulations\nand interior-point algorithms. However, although its application with\npolyhedral uncertainty sets guarantees convergence, finite termination when\nusing ellipsoidal uncertainty sets is not theoretically guaranteed. This paper\ndemonstrates that the cutting-plane algorithm set out for ellipsoidal\nuncertainty sets in its more general form also converges in a finite number of\nsteps.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 07:00:35 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["M\u00ednguez", "Roberto", ""], ["Casero-Alonso", "V\u00edctor", ""]]}, {"id": "1904.01521", "submitter": "Oliver Kunc", "authors": "Oliver Kunc and Felix Fritzen", "title": "Finite Strain Homogenization Using a Reduced Basis and Efficient\n  Sampling", "comments": "28 pages", "journal-ref": "Math. Comput. Appl. 2019, 24, 56", "doi": "10.3390/mca24020056", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The computational homogenization of hyperelastic solids in the geometrically\nnonlinear context has yet to be treated with sufficient efficiency in order to\nallow for real-world applications in true multiscale settings. This problem is\naddressed by a problem-specific surrogate model founded on a reduced basis\napproximation of the deformation gradient on the microscale. The setup phase is\nbased upon a snapshot POD on deformation gradient fluctuations, in contrast to\nthe widespread displacement-based approach. In order to reduce the\ncomputational offline costs, the space of relevant macroscopic stretch tensors\nis sampled efficiently by employing the Hencky strain. Numerical results show\nspeed-up factors in the order of 5-100 and significantly improved robustness\nwhile retaining good accuracy. An open-source demonstrator tool with 50 lines\nof code emphasizes the simplicity and efficiency of the method.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 11:19:24 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 06:15:51 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 12:07:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kunc", "Oliver", ""], ["Fritzen", "Felix", ""]]}, {"id": "1904.02499", "submitter": "Chong Peng Dr.", "authors": "Md Rushdie Ibne Islam, Ankur Bansal, Chong Peng", "title": "Numerical Simulation of Metal Machining Process with Eulerian and Total\n  Lagrangian SPH", "comments": "21 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents numerical simulations of metal machining processes with\nEulerian and Total Lagrangian Smoothed Particle Hydrodynamics (SPH). Being a\nmesh-free method, SPH can conveniently handle large deformation and material\nseparation. However, the Eulerian SPH (ESPH) in which the kernel functions are\ncomputed based on the current particle positions suffers from the tensile\ninstability. The Total Lagrangian SPH (TLSPH) is free of this instability as\nthe kernel functions are calculated in the reference configurations. In this\nwork, the metals are modelled using the Johnson-Cook constitutive model, which\ncan capture strain hardening and thermal softening in metals. The\nprocessing/cutting tools are modelled as rigid bodies, while the metal-tool\ncontact forces are considered using the standard SPH interaction and the\nparticle-particle pinball contact in ESPH and TLSPH, respectively. The two\nmethods are employed to model several cases with impact, pressing, and cutting;\nthe results are compared with reference experimental and numerical results. It\nis found that both the two SPH methods can capture the salient phenomena in\nmetal processing, e.g. strain localisation, large deformation, and material\nseparation. However, the TLSPH approach provides a better simulation of strain\nlocalisation and chip morphology. This work shows that the TLSPH method has the\npotential to model the metal machining processes efficiently without any\nnumerical instabilities.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 11:55:02 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Islam", "Md Rushdie Ibne", ""], ["Bansal", "Ankur", ""], ["Peng", "Chong", ""]]}, {"id": "1904.03096", "submitter": "Shunchuan Yang", "authors": "Xiaochao Zhou, Shunchuan Yang, and Donglin Su", "title": "A Surface Integral Formulation for Scattering Modeling by 2D Penetrable\n  Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a single-source surface integral formulation to\naccurately solve the scattering problems by 2D penetrable objects. In this\nmethod, the objects are replaced by their surrounding medium through enforcing\na surface equivalent electric current to ensure fields exactly the same as\nthose in the original scattering problem. The equivalent electric current is\nobtained through emitting the equivalent magnetic current by enforcing that the\nelectric fields in the original and equivalent problems equal to each other.\nThrough solving the Helmholtz equation inside objects by the scalar second\nGreen theorem, we could accurately model arbitrarily shaped objects. Then, we\nsolve the exterior scattering problems through the combined integral equation\n(CFIE) with the equivalent electric current. The proposed formulation only\nrequires a single electric current source to model penetrable objects. At last,\ntwo numerical experiments are carried out to validate its accuracy, stability\nand capability of handling non-smoothing objects.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 14:48:10 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Zhou", "Xiaochao", ""], ["Yang", "Shunchuan", ""], ["Su", "Donglin", ""]]}, {"id": "1904.03328", "submitter": "Ye Wu", "authors": "Ye Wu, Yoonmi Hong, Yuanjing Feng, Dinggang Shen, Pew-Thian Yap", "title": "Mitigating Gyral Bias in Cortical Tractography via Asymmetric Fiber\n  Orientation Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion tractography in brain connectomics often involves tracing axonal\ntrajectories across gray-white matter boundaries in gyral blades of complex\ncortical convolutions. To date, gyral bias is observed in most tractography\nalgorithms with streamlines predominantly terminating at gyral crowns instead\nof sulcal banks. This work demonstrates that asymmetric fiber orientation\ndistribution functions (AFODFs), computed via a multi-tissue global estimation\nframework, can mitigate the effects of gyral bias, enabling fiber streamlines\nat gyral blades to make sharper turns into the cortical gray matter. We use\nex-vivo data of an adult rhesus macaque and in-vivo data from the Human\nConnectome Project (HCP) to show that the fiber streamlines given by AFODFs\nbend more naturally into the cortex than the conventional symmetric FODFs in\ntypical gyral blades. We demonstrate that AFODF tractography improves\ncortico-cortical connectivity and provides highly consistent outcomes between\ntwo different field strengths (3T and 7T).\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 01:05:19 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 19:09:38 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Wu", "Ye", ""], ["Hong", "Yoonmi", ""], ["Feng", "Yuanjing", ""], ["Shen", "Dinggang", ""], ["Yap", "Pew-Thian", ""]]}, {"id": "1904.03678", "submitter": "Xing Lu", "authors": "Xing Lu, Kathryn Hinkelman, Yangyang Fu, Jing Wang, Wangda Zuo,\n  Qianqian Zhang, Walid Saad", "title": "An Open Source Modeling Framework for Interdependent\n  Energy-Transportation- Communication Infrastructure in Smart and Connected\n  Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrastructure in future smart and connected communities is envisioned as an\naggregate of public services, including the energy, transportation and\ncommunication systems, all intertwined with each other. The intrinsic\ninterdependency among these systems may exert underlying influence on both\ndesign and operation of the heterogeneous infrastructures. However, few prior\nstudies have tapped into the interdependency among the three systems in order\nto quantify their potential impacts during standard operation. In response to\nthis, this paper proposes an open source, flexible, integrated modeling\nframework suitable for designing coupled energy, transportation, and\ncommunication systems and for assessing the impact of their interdependencies.\nFirst, a novel multi-level, multi-layer, multi-agent approach is proposed to\nenable flexible modeling of the interconnected energy, transportation, and\ncommunication systems. Then, for the framework's proof-of-concept, preliminary\ncomponent and system-level models for different systems are designed and\nimplemented using Modelica, an equation-based object-oriented modeling\nlanguage. Finally, three case studies of gradually increasing complexity are\npresented (energy, energy + transportation, energy + transportation +\ncommunication) to evaluate the interdependencies among the three systems.\nQuantitative analyses show that the deviation of the average velocity on the\nroad can be 10.5\\% and the deviation of the power draw from the grid can be 7\\%\nwith or without considering the transportation and communication system at the\npeak commute time, indicating the presence of notable interdependencies. The\nproposed modeling framework also has the potential to be further extended for\nvarious modeling purposes and use cases, such as dynamic modeling and\noptimization, resilience analysis, and integrated decision making in future\nconnected communities.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 16:06:44 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Lu", "Xing", ""], ["Hinkelman", "Kathryn", ""], ["Fu", "Yangyang", ""], ["Wang", "Jing", ""], ["Zuo", "Wangda", ""], ["Zhang", "Qianqian", ""], ["Saad", "Walid", ""]]}, {"id": "1904.04327", "submitter": "Daniel Alejandro Sabogal-Su\\'arez M.Sc.", "authors": "J. D. Alzate-Cardona, D. Sabogal-Su\\'arez, J. Torres and E.\n  Restrepo-Parra", "title": "MFV: Application software for the visualization and characterization of\n  the DC magnetic field distribution in circular coil systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterization of the magnetic field distribution is essential in\nexperiments and devices that use magnetic field coil systems. We present an\nopen-source application software, MFV (Magnetic Field Visualizer), for the\nvisualization of the distribution of the magnetic field produced by circular\ncoil systems. MFV models, simulates, and plots the magnetic field of coil\nsystems composed by any number of circular coils of any size placed\nsymmetrically along the same axis. Therefore, any new design or well known coil\nsystem, such as the Helmholtz or the Maxwell coil, can be easily modeled and\nsimulated using MFV. A graph of the homogeneity of the magnetic field can be\nalso produced, showing the work region where the magnetic field is homogeneous\naccording to a percentage of homogeneity given by the user. An standardized\ninput and output file format is employed to facilitate the exchange and\narchiving of data. We include some results obtained using MFV, showing its\napplicability to characterize the magnetic field in different coil systems.\nFurthermore, the magnetic field results provided by MFV were validated by\ncomparing them with results obtained experimentally in a Helmholtz coil system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 15:34:45 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Alzate-Cardona", "J. D.", ""], ["Sabogal-Su\u00e1rez", "D.", ""], ["Torres", "J.", ""], ["Restrepo-Parra", "E.", ""]]}, {"id": "1904.05163", "submitter": "Luca Magri", "authors": "Tullio Traverso, Luca Magri", "title": "Data assimilation in a nonlinear time-delayed dynamical system", "comments": "13 pages, 4 figures", "journal-ref": "Computational Science - ICCS 2019. ICCS 2019. Lecture Notes in\n  Computer Science, vol 11539. Springer, Cham", "doi": "10.1007/978-3-030-22747-0_12", "report-no": null, "categories": "cs.CE cs.LG physics.data-an physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the heat released by a flame is sufficiently in phase with the acoustic\npressure, a self-excited thermoacoustic oscillation can arise. These nonlinear\noscillations are one of the biggest challenges faced in the design of safe and\nreliable gas turbines and rocket motors. In the worst-case scenario,\nuncontrolled thermoacoustic oscillations can shake an engine apart.\nReduced-order thermoacoustic models, which are nonlinear and time-delayed, can\nonly qualitatively predict thermoacoustic oscillations. To make reduced-order\nmodels quantitatively predictive, we develop a data assimilation framework for\nstate estimation. We numerically estimate the most likely nonlinear state of a\nGalerkin-discretized time delayed model of a horizontal Rijke tube, which is a\nprototypical combustor. Data assimilation is an optimal blending of\nobservations with previous state estimates (background) to produce optimal\ninitial conditions. A cost functional is defined to measure the statistical\ndistance between the model output and the measurements from experiments; and\nthe distance between the initial conditions and the background knowledge. Its\nminimum corresponds to the optimal state, which is computed by Lagrangian\noptimization with the aid of adjoint equations. We study the influence of the\nnumber of Galerkin modes, which are the natural acoustic modes of the duct,\nwith which the model is discretized. We show that decomposing the measured\npressure signal in a finite number of modes is an effective way to enhance\nstate estimation, especially when nonlinear modal interactions occur during the\nassimilation window. This work represents the first application of data\nassimilation to nonlinear thermoacoustics, which opens up new possibilities for\nreal-time calibration of reduced-order models with experimental measurements.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:12:55 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Traverso", "Tullio", ""], ["Magri", "Luca", ""]]}, {"id": "1904.06197", "submitter": "Andrea Mendizabal", "authors": "Andrea Mendizabal, Pablo M\\'arquez-Neila, St\\'ephane Cotin", "title": "Simulation of hyperelastic materials in real-time using Deep Learning", "comments": null, "journal-ref": "Medical Image Analysis, Volume 59, January 2020, 101569", "doi": "10.1016/j.media.2019.101569", "report-no": null, "categories": "cs.CE cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite element method (FEM) is among the most commonly used numerical\nmethods for solving engineering problems. Due to its computational cost,\nvarious ideas have been introduced to reduce computation times, such as domain\ndecomposition, parallel computing, adaptive meshing, and model order reduction.\nIn this paper we present U-Mesh: a data-driven method based on a U-Net\narchitecture that approximates the non-linear relation between a contact force\nand the displacement field computed by a FEM algorithm. We show that deep\nlearning, one of the latest machine learning methods based on artificial neural\nnetworks, can enhance computational mechanics through its ability to encode\nhighly non-linear models in a compact form. Our method is applied to two\nbenchmark examples: a cantilever beam and an L-shape subject to moving punctual\nloads. A comparison between our method and proper orthogonal decomposition\n(POD) is done through the paper. The results show that U-Mesh can perform very\nfast simulations on various geometries, mesh resolutions and number of input\nforces with very small errors.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 17:30:28 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 14:04:58 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Mendizabal", "Andrea", ""], ["M\u00e1rquez-Neila", "Pablo", ""], ["Cotin", "St\u00e9phane", ""]]}, {"id": "1904.07021", "submitter": "Laurent van den Bos", "authors": "L.M.M. van den Bos, W.A.A.M. Bierbooms, A. Alexandre, B. Sanderse,\n  G.J.W. van Bussel", "title": "Fatigue design load calculations of the offshore NREL 5MW benchmark\n  turbine using quadrature rule techniques", "comments": null, "journal-ref": "Wind Energy 23(5), May 2020, pages 1181-1195", "doi": "10.1002/we.2470", "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is proposed to reduce, compared to the conventional binning\napproach, the large number of aeroelastic code evaluations that are necessary\nto obtain equivalent loads acting on wind turbines. These loads describe the\neffect of long-term environmental variability on the fatigue loads of a\nhorizontal-axis wind turbine. In particular Design Load Case 1.2, as\nstandardized by IEC, is considered. The approach is based on numerical\nintegration techniques and, more specifically, quadrature rules. The quadrature\nrule used in this work is a recently proposed \"implicit\" quadrature rule, which\nhas the main advantage that it can be constructed directly using measurements\nof the environment. It is demonstrated that the proposed approach yields\naccurate estimations of the equivalent loads using a significantly reduced\nnumber of aeroelastic model evaluations (compared to binning). Moreover the\nerror introduced by the seeds (introduced by averaging over random wind fields\nand sea states) is incorporated in the quadrature framework, yielding an even\nfurther reduction in the number of aeroelastic code evaluations. The reduction\nin computational time is demonstrated by assessing the fatigue loads on the\nNREL 5MW reference offshore wind turbine in conjunction with measurement data\nobtained at the North Sea, both for a simplified and a full load case.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 10:37:39 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bos", "L. M. M. van den", ""], ["Bierbooms", "W. A. A. M.", ""], ["Alexandre", "A.", ""], ["Sanderse", "B.", ""], ["van Bussel", "G. J. W.", ""]]}, {"id": "1904.07441", "submitter": "Esmaeil Seraj", "authors": "Esmaeil Seraj, Mehran Yazdi, Nastaran Shahparian", "title": "fMRI Based Cerebral Instantaneous Parameters for Automatic Alzheimer's,\n  Mild Cognitive Impairment and Healthy Subject Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CE eess.IV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic identification and categorization of Alzheimer's patients and the\nability to distinguish between different levels of this disease can be very\nhelpful to the research community in this field, since other non-automatic\napproaches are very time-consuming and are highly dependent on experts'\nexperience. Herein, we propose the utility of cerebral instantaneous phase and\nenvelope information in order to discriminate between Alzheimer's patients, MCI\nsubjects and healthy normal individuals from functional magnetic resonance\nimaging (fMRI) data. To this end, after performing the region-of-interest (ROI)\nanalysis on fMRI data, different features covering power, entropy and coherency\naspects of data are derived from instantaneous phase and envelope sequences of\nROI signals. Various sets of features are calculated and fed to a sequential\nforward floating feature selection (SFFFS) to choose the most discriminative\nand informative sets of features. A Student's t-test has been used to select\nthe most relevant features from chosen sets. Finally, a K-NN classifier is used\nto distinguish between classes in a three-class categorization problem. The\nreported performance in overall accuracy using fMRI data of 111 combined\nsubjects, is 80.1% with 80.0% Sensitivity to both Alzheimer's and Normal\ncategories distinction and is comparable to the state-of-the-art approaches\nrecently proposed in this regard. The significance of obtained results was\nstatistically confirmed by evaluating through standard classification\nperformance indicators. The obtained results illustrate that introduced\nanalytic phase and envelope feature indexes derived from the ROI signals are\nsignificantly discriminative in distinguishing between Alzheimer's patients and\nNormal healthy subject.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 03:50:48 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Seraj", "Esmaeil", ""], ["Yazdi", "Mehran", ""], ["Shahparian", "Nastaran", ""]]}, {"id": "1904.07445", "submitter": "Antonio E. Porreca", "authors": "Claudio Ferretti, Alberto Leporati, Luca Manzoni, Antonio E. Porreca", "title": "The many roads to the simulation of reaction systems", "comments": "Postprint, to appear in Fundamenta Informaticae", "journal-ref": "Fundamenta Informaticae, vol. 171, no. 1-4, pp. 175-188, 2020", "doi": "10.3233/FI-2020-1878", "report-no": null, "categories": "cs.FL cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reaction systems are a computational model inspired by the bio-chemical\nreactions that happen inside biological cells. They have been and currently are\nstudied for their many nice theoretical properties. They are also a useful\nmodeling tool for biochemical systems, but in order to be able to employ them\neffectively in the field the presence of efficient and widely available\nsimulators is essential. Here we explore three different algorithms and\nimplementations of the simulation, comparing them to the current state of the\nart. We also show that we can obtain performances comparable to GPU-based\nsimulations on real-world systems by using a carefully tuned CPU-based\nsimulator.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 13:08:44 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ferretti", "Claudio", ""], ["Leporati", "Alberto", ""], ["Manzoni", "Luca", ""], ["Porreca", "Antonio E.", ""]]}, {"id": "1904.07981", "submitter": "L. A. Barba", "authors": "Olivier Mesnard, Lorena A. Barba", "title": "Reproducible Workflow on a Public Cloud for Computational Fluid Dynamics", "comments": "11 pages, 8 figures, 5 tables", "journal-ref": "Computing in Science and Engineering, Vol. 22(1):102-116, 2019", "doi": "10.1109/MCSE.2019.2941702", "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a new effort to make our research transparent and reproducible by others,\nwe developed a workflow to run and share computational studies on the public\ncloud Microsoft Azure. It uses Docker containers to create an image of the\napplication software stack. We also adopt several tools that facilitate\ncreating and managing virtual machines on compute nodes and submitting jobs to\nthese nodes. The configuration files for these tools are part of an expanded\n\"reproducibility package\" that includes workflow definitions for cloud\ncomputing, in addition to input files and instructions. This facilitates\nre-creating the cloud environment to re-run the computations under the same\nconditions. Although cloud providers have improved their offerings, many\nresearchers using high-performance computing (HPC) are still skeptical about\ncloud computing. Thus, we ran benchmarks for tightly coupled applications to\nconfirm that the latest HPC nodes of Microsoft Azure are indeed a viable\nalternative to traditional on-site HPC clusters. We also show that cloud\nofferings are now adequate to complete computational fluid dynamics studies\nwith in-house research software that uses parallel computing with GPUs.\nFinally, we share with the community what we have learned from nearly two years\nof using Azure cloud to enhance transparency and reproducibility in our\ncomputational simulations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:50:09 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 17:20:07 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 18:59:13 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mesnard", "Olivier", ""], ["Barba", "Lorena A.", ""]]}, {"id": "1904.07988", "submitter": "Amine Bejaoui", "authors": "Amine Bejaoui, Ki-Hong Park, Mohamed Slim Alouini", "title": "A QoS-Oriented Trajectory Optimization in Swarming\n  Unmanned-Aerial-Vehicles Communications", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This letter aims to present a novel approach for unmanned aerial vehicles\n(UAV)' path planning with respect to certain quality of service requirements.\nMore specifically, we study the max-min fairness problem in an air-to-ground\ncommunication system where multiple UAVs and multiple ground stations exist. We\njointly optimize the UAVs trajectories and power allocation as well as the user\nscheduling. To this end, we propose an effective iterative algorithm that\nrelies on the successive convex approximation and the block coordinate decent\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 21:13:45 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 14:14:19 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 14:51:50 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 21:08:47 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Bejaoui", "Amine", ""], ["Park", "Ki-Hong", ""], ["Alouini", "Mohamed Slim", ""]]}, {"id": "1904.08488", "submitter": "Dejan Brkic", "authors": "Dejan Brki\\'c and Pavel Praks", "title": "Short Overview of Early Developments of the Hardy Cross Type Methods for\n  Computation of Flow Distribution in Pipe Networks", "comments": "16 pages, 5 figures, 2 tables, 60 references", "journal-ref": "Brki\\'c, D.; Praks, P. Short Overview of Early Developments of the\n  Hardy Cross Type Methods for Computation of Flow Distribution in Pipe\n  Networks. Appl. Sci. 2019, 9, 2019. https://doi.org/10.3390/app9102019", "doi": "10.3390/app9102019", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardy Cross originally proposed a method for analysis of flow in networks of\nconduits or conductors in 1936. His method was the first really useful\nengineering method in the field of pipe network calculation. Only electrical\nanalogs of hydraulic networks were used before the Hardy Cross method. A\nproblem with flow resistance versus electrical resistance makes these\nelectrical analog methods obsolete. The method by Hardy Cross is taught\nextensively at faculties, and it remains an important tool for the analysis of\nlooped pipe systems. Engineers today mostly use a modified Hardy Cross method\nwhich considers the whole looped network of pipes simultaneously (use of these\nmethods without computers is practically impossible). A method from a Russian\npractice published during the 1930s, which is similar to the Hardy Cross\nmethod, is described, too. Some notes from the work of Hardy Cross are also\npresented. Finally, an improved version of the Hardy Cross method, which\nsignificantly reduces the number of iterations, is presented and discussed. We\nalso tested multi-point iterative methods, which can be used as a substitution\nfor the Newton-Raphson approach used by Hardy Cross, but in this case this\napproach did not reduce the number of iterations. Although many new models have\nbeen developed since the time of Hardy Cross, the main purpose of this paper is\nto illustrate the very beginning of modelling of gas and water pipe networks\nand ventilation systems. As a novelty, a new multi-point iterative solver is\nintroduced and compared with the standard Newton-Raphson iterative method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 09:51:09 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Brki\u0107", "Dejan", ""], ["Praks", "Pavel", ""]]}, {"id": "1904.08684", "submitter": "Sara Faghih-Naini", "authors": "Sara Faghih-Naini, Sebastian Kuckuk, Vadym Aizinger, Daniel Zint,\n  Roberto Grosso, Harald K\\\"ostler", "title": "Towards whole program generation of quadrature-free discontinuous\n  Galerkin methods for the shallow water equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shallow water equations (SWE) are a commonly used model to study\ntsunamis, tides, and coastal ocean circulation. However, there exist various\napproaches to discretize and solve them efficiently. Which of them is best for\na certain scenario is often not known and, in addition, depends heavily on the\nused HPC platform. From a simulation software perspective, this places a\npremium on the ability to adapt easily to different numerical methods and\nhardware architectures. One solution to this problem is to apply code\ngeneration techniques and to express methods and specific hardware-dependent\nimplementations on different levels of abstraction. This allows for a\nseparation of concerns and makes it possible, e.g., to exchange the\ndiscretization scheme without having to rewrite all low-level optimized\nroutines manually. In this paper, we show how code for an advanced\nquadrature-free discontinuous Galerkin (DG) discretized shallow water equation\nsolver can be generated. Here, we follow the multi-layered approach from the\nExaStencils project that starts from the continuous problem formulation, moves\nto the discrete scheme, spells out the numerical algorithms, and, finally, maps\nto a representation that can be transformed to a distributed memory parallel\nimplementation by our in-house Scala-based source-to-source compiler. Our\ncontributions include: A new quadrature-free discontinuous Galerkin\nformulation, an extension of the class of supported computational grids, and an\nextension of our toolchain allowing to evaluate discrete integrals stemming\nfrom the DG discretization implemented in Python. As first results we present\nthe whole toolchain and also demonstrate the convergence of our method for\nhigher order DG discretizations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 11:02:13 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Faghih-Naini", "Sara", ""], ["Kuckuk", "Sebastian", ""], ["Aizinger", "Vadym", ""], ["Zint", "Daniel", ""], ["Grosso", "Roberto", ""], ["K\u00f6stler", "Harald", ""]]}, {"id": "1904.08749", "submitter": "Emilio Mart\\'inez-Pa\\~neda", "authors": "Hirshikesh, Sundararajan Natarajan, Ratna K. Annabattula, Emilio\n  Mart\\'inez-Pa\\~neda", "title": "Phase field modelling of crack propagation in functionally graded\n  materials", "comments": null, "journal-ref": "Composites Part B: Engineering (2019)", "doi": "10.1016/j.compositesb.2019.04.003", "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a phase field formulation for fracture in functionally graded\nmaterials (FGMs). The model builds upon homogenization theory and accounts for\nthe spatial variation of elastic and fracture properties. Several paradigmatic\ncase studies are addressed to demonstrate the potential of the proposed\nmodelling framework. Specifically, we (i) gain insight into the crack growth\nresistance of FGMs by conducting numerical experiments over a wide range of\nmaterial gradation profiles and orientations, (ii) accurately reproduce the\ncrack trajectories observed in graded photodegradable copolymers and\nglass-filled epoxy FGMs, (iii) benchmark our predictions with results from\nalternative numerical methodologies, and (iv) model complex crack paths and\nfailure in three dimensional functionally graded solids. The suitability of\nphase field fracture methods in capturing the crack deflections intrinsic to\ncrack tip mode-mixity due to material gradients is demonstrated. Material\ngradient profiles that prevent unstable fracture and enhance crack growth\nresistance are identified: this provides the foundation for the design of\nfracture resistant FGMs. The finite element code developed can be downloaded\nfrom www.empaneda.com/codes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 12:48:49 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Hirshikesh", "", ""], ["Natarajan", "Sundararajan", ""], ["Annabattula", "Ratna K.", ""], ["Mart\u00ednez-Pa\u00f1eda", "Emilio", ""]]}, {"id": "1904.10257", "submitter": "Luca Berardocco", "authors": "Luca Berardocco, Martin Kronbichler and Volker Gravemeier", "title": "A hybridizable discontinuous Galerkin method for electromagnetics with a\n  view on subsurface applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113071", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two Hybridizable Discontinuous Galerkin (HDG) schemes for the solution of\nMaxwell's equations in the time domain are presented. The first method is based\non an electromagnetic diffusion equation, while the second is based on\nFaraday's and Maxwell--Amp\\`ere's laws. Both formulations include the diffusive\nterm depending on the conductivity of the medium. The three-dimensional\nformulation of the electromagnetic diffusion equation in the framework of HDG\nmethods, the introduction of the conduction current term and the choice of the\nelectric field as hybrid variable in a mixed formulation are the key points of\nthe current study. Numerical results are provided for validation purposes and\nconvergence studies of spatial and temporal discretizations are carried out.\nThe test cases include both simulation in dielectric and conductive media.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 11:42:10 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Berardocco", "Luca", ""], ["Kronbichler", "Martin", ""], ["Gravemeier", "Volker", ""]]}, {"id": "1904.10434", "submitter": "Rahul-Vigneswaran K", "authors": "Rahul-Vigneswaran K, Neethu Mohan, Soman KP", "title": "Data-driven Computing in Elasticity via Chebyshev Approximation", "comments": "6 pages, Accepted for ICCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a data-driven approach for computing elasticity by means\nof a non-parametric regression approach rather than an optimization approach.\nThe Chebyshev approximation is utilized for tackling the material data-sets\nnon-linearity of the elasticity. Also, additional efforts have been taken to\ncompare the results with several other state-of-the-art methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 17:29:21 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["K", "Rahul-Vigneswaran", ""], ["Mohan", "Neethu", ""], ["KP", "Soman", ""]]}, {"id": "1904.11392", "submitter": "Haoran Wang", "authors": "Haoran Wang, Xun Yu Zhou", "title": "Continuous-Time Mean-Variance Portfolio Selection: A Reinforcement\n  Learning Framework", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the continuous-time mean-variance (MV) portfolio selection with\nreinforcement learning (RL). The problem is to achieve the best tradeoff\nbetween exploration and exploitation, and is formulated as an\nentropy-regularized, relaxed stochastic control problem. We prove that the\noptimal feedback policy for this problem must be Gaussian, with time-decaying\nvariance. We then establish connections between the entropy-regularized MV and\nthe classical MV, including the solvability equivalence and the convergence as\nexploration weighting parameter decays to zero. Finally, we prove a policy\nimprovement theorem, based on which we devise an implementable RL algorithm. We\nfind that our algorithm outperforms both an adaptive control based method and a\ndeep neural networks based algorithm by a large margin in our simulations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 14:47:15 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 00:25:27 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wang", "Haoran", ""], ["Zhou", "Xun Yu", ""]]}, {"id": "1904.11433", "submitter": "Evan Drumwright", "authors": "Ryan Elandt, Evan Drumwright, Michael Sherman, and Andy Ruina", "title": "A pressure field model for fast, robust approximation of net contact\n  force and moment between nominally rigid objects", "comments": "(revised in accordance with the IROS camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approximate model for predicting the net contact wrench\nbetween nominally rigid objects for use in simulation, control, and state\nestimation. The model combines and generalizes two ideas: a bed of springs (an\n\"elastic foundation\") and hydrostatic pressure. In this model, continuous\npressure fields are computed offline for the interior of each nominally rigid\nobject. Unlike hydrostatics or elastic foundations, the pressure fields need\nnot satisfy mechanical equilibrium conditions. When two objects nominally\noverlap, a contact surface is defined where the two pressure fields are equal.\nThis static pressure is supplemented with a dissipative rate-dependent pressure\nand friction to determine tractions on the contact surface. The contact wrench\nbetween pairs of objects is an integral of traction contributions over this\nsurface. The model evaluates much faster than elasticity-theory models, while\nshowing the essential trends of force, moment, and stiffness increase with\ncontact load. It yields continuous wrenches even for non-convex objects and\ncoarse meshes. The method shows promise as sufficiently fast, accurate, and\nrobust for design-in-simulation of robot controllers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 16:14:52 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 20:48:39 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Elandt", "Ryan", ""], ["Drumwright", "Evan", ""], ["Sherman", "Michael", ""], ["Ruina", "Andy", ""]]}, {"id": "1904.12992", "submitter": "Isaac Ross", "authors": "N. Koeppen, I. M. Ross, L. C. Wilcox, R. J. Proulx", "title": "Fast Mesh Refinement in Pseudospectral Optimal Control", "comments": "27 pages, 12 figures, JGCD April 2019", "journal-ref": "J. Guidance, Control and Dynamics, April 2019", "doi": null, "report-no": null, "categories": "math.OC cs.CE cs.NA econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mesh refinement in pseudospectral (PS) optimal control is embarrassingly easy\n--- simply increase the order $N$ of the Lagrange interpolating polynomial and\nthe mathematics of convergence automates the distribution of the grid points.\nUnfortunately, as $N$ increases, the condition number of the resulting linear\nalgebra increases as $N^2$; hence, spectral efficiency and accuracy are lost in\npractice. In this paper, we advance Birkhoff interpolation concepts over an\narbitrary grid to generate well-conditioned PS optimal control discretizations.\nWe show that the condition number increases only as $\\sqrt{N}$ in general, but\nis independent of $N$ for the special case of one of the boundary points being\nfixed. Hence, spectral accuracy and efficiency are maintained as $N$ increases.\nThe effectiveness of the resulting fast mesh refinement strategy is\ndemonstrated by using \\underline{polynomials of over a thousandth order} to\nsolve a low-thrust, long-duration orbit transfer problem.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 23:50:07 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Koeppen", "N.", ""], ["Ross", "I. M.", ""], ["Wilcox", "L. C.", ""], ["Proulx", "R. J.", ""]]}]