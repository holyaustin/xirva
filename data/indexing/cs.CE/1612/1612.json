[{"id": "1612.00402", "submitter": "Maciej Balajewicz", "authors": "Maciej Balajewicz and Jari Toivanen", "title": "Reduced Order Models for Pricing European and American Options under\n  Stochastic Volatility and Jump-Diffusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  European options can be priced by solving parabolic partial(-integro)\ndifferential equations under stochastic volatility and jump-diffusion models\nlike Heston, Merton, and Bates models. American option prices can be obtained\nby solving linear complementary problems (LCPs) with the same operators. A\nfinite difference discretization leads to a so-called full order model (FOM).\nReduced order models (ROMs) are derived employing proper orthogonal\ndecomposition (POD). The early exercise constraint of American options is\nenforced by a penalty on subset of grid points. The presented numerical\nexperiments demonstrate that pricing with ROMs can be orders of magnitude\nfaster within a given model parameter variation range.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 19:58:34 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Balajewicz", "Maciej", ""], ["Toivanen", "Jari", ""]]}, {"id": "1612.00585", "submitter": "Soumi Chaki", "authors": "Soumi Chaki, Aurobinda Routray, William K. Mohanty, Mamata Jenamani", "title": "Development of a hybrid learning system based on SVM, ANFIS and domain\n  knowledge: DKFIS", "comments": "6 pages, 5 figures, 3tables Presented at Indicon 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the development of a hybrid learning system based on\nSupport Vector Machines (SVM), Adaptive Neuro-Fuzzy Inference System (ANFIS)\nand domain knowledge to solve prediction problem. The proposed two-stage Domain\nKnowledge based Fuzzy Information System (DKFIS) improves the prediction\naccuracy attained by ANFIS alone. The proposed framework has been implemented\non a noisy and incomplete dataset acquired from a hydrocarbon field located at\nwestern part of India. Here, oil saturation has been predicted from four\ndifferent well logs i.e. gamma ray, resistivity, density, and clay volume. In\nthe first stage, depending on zero or near zero and non-zero oil saturation\nlevels the input vector is classified into two classes (Class 0 and Class 1)\nusing SVM. The classification results have been further fine-tuned applying\nexpert knowledge based on the relationship among predictor variables i.e. well\nlogs and target variable - oil saturation. Second, an ANFIS is designed to\npredict non-zero (Class 1) oil saturation values from predictor logs. The\npredicted output has been further refined based on expert knowledge. It is\napparent from the experimental results that the expert intervention with\nqualitative judgment at each stage has rendered the prediction into the\nfeasible and realistic ranges. The performance analysis of the prediction in\nterms of four performance metrics such as correlation coefficient (CC), root\nmean square error (RMSE), and absolute error mean (AEM), scatter index (SI) has\nestablished DKFIS as a useful tool for reservoir characterization.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 07:56:23 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Chaki", "Soumi", ""], ["Routray", "Aurobinda", ""], ["Mohanty", "William K.", ""], ["Jenamani", "Mamata", ""]]}, {"id": "1612.01357", "submitter": "Georgios Panou", "authors": "G. Panou, R. Korakitis", "title": "Geodesic equations and their numerical solutions in geodetic and\n  Cartesian coordinates on an oblate spheroid", "comments": "Submitted to an academic Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The direct geodesic problem on an oblate spheroid is described as an initial\nvalue problem and is solved numerically in geodetic and Cartesian coordinates.\nThe geodesic equations are formulated by means of the theory of differential\ngeometry. The initial value problem under consideration is reduced to a system\nof first-order ordinary differential equations, which is solved using a\nnumerical method. The solution provides the coordinates and the azimuths at any\npoint along the geodesic. The Clairaut constant is not assumed known but it is\ncomputed, allowing to check the precision of the method. An extended data set\nof geodesics is used, in order to evaluate the performance of the method in\neach coordinate system. The results for the direct geodesic problem are\nvalidated by comparison to Karney's method. We conclude that a complete,\nstable, precise, accurate and fast solution of the problem in Cartesian\ncoordinates is accomplished.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 13:31:03 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Panou", "G.", ""], ["Korakitis", "R.", ""]]}, {"id": "1612.01586", "submitter": "Yongxing Wang", "authors": "Yongxing Wang, Peter Jimack, Mark Walkley", "title": "A One-Field Monolithic Fictitious Domain Method for Fluid-Structure\n  Interactions", "comments": "arXiv admin note: substantial text overlap with arXiv:1608.04998", "journal-ref": null, "doi": "10.1016/j.cma.2017.01.023", "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a one-field monolithic fictitious domain (FD)\nmethod for simulation of general fluid-structure interactions (FSI). One-field\nmeans only one velocity field is solved in the whole domain, based upon the use\nof an appropriate L2 projection. Monolithic means the fluid and solid equations\nare solved synchronously (rather than sequentially). We argue that the proposed\nmethod has the same generality and robustness as FD methods with distributed\nLagrange multiplier (DLM) but is significantly more computationally efficient\n(because of one-field) whilst being very straightforward to implement. The\nmethod is described in detail, followed by the presentation of multiple\ncomputational examples in order to validate it across a wide range of fluid and\nsolid parameters and interactions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 23:19:53 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Wang", "Yongxing", ""], ["Jimack", "Peter", ""], ["Walkley", "Mark", ""]]}, {"id": "1612.02275", "submitter": "Akihito Kikuchi Dr", "authors": "Akihito Kikuchi", "title": "Computer Algebra and Material Design", "comments": "The 4th version: some parts of the article (statements, equations,\n  figures, references, and the appendix ) are rewritten. It contains 227 pages", "journal-ref": null, "doi": null, "report-no": "Springer Series in Material Science Volume 272, 2018", "categories": "cond-mat.mtrl-sci cs.CE cs.SC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is intended to an introductory lecture in material physics, in\nwhich the modern computational group theory and the electronic structure\ncalculation are in collaboration. The effort of mathematicians in field of the\ngroup theory, have ripened as a new trend, called \"computer algebra\", outcomes\nof which now can be available as handy computational packages, and would also\nbe useful to physicists with practical purposes. This article, in the former\npart, explains how to use the computer algebra for the applications in the\nsolid-state simulation, by means of one of the computer algebra package, the\nGAP system. The computer algebra enables us to obtain various group theoretical\nproperties with ease, such as the representations, the character tables, the\nsubgroups, etc. Furthermore it would grant us a new perspective of material\ndesign, which could be executed in mathematically rigorous and systematic way.\nSome technical details and some computations which require the knowledge of a\nlittle higher mathematics (but computable easily by the computer algebra) are\nalso given. The selected topics will provide the reader with some insights\ntoward the dominating role of the symmetry in crystal, or, the \"mathematical\nfirst principles\" in it. In the latter part of the article, we analyze the\nrelation between the structural symmetry and the electronic structure in\nC$_{60}$ (as an example to the sysmem without periodicity). The principal\nobject of the study is to illustrate the hierarchical change of the\nquantum-physical properties of the molecule, in accordance with the reduction\nof the symmetry (as it descends down in the ladder of subgroups). In order to\nserve the common interest of the researchers, the details of the computations\n(the required initial data and the small programs developed for the purpose)\nare explained as minutely as possible.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 07:16:40 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 04:44:57 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 06:21:36 GMT"}, {"version": "v4", "created": "Sat, 17 Feb 2018 00:05:27 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Kikuchi", "Akihito", ""]]}, {"id": "1612.03247", "submitter": "Salah Hamim", "authors": "Salah U. Hamim", "title": "Parameter Estimation of a Nonlinear Burgers Model using Nanoindentation\n  and Finite Element-based Inverse Analysis", "comments": "PhD Dissertation, Oklahoma State University, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanoindentation involves probing a hard diamond tip into a material, where\nthe load and the displacement experienced by the tip is recorded continuously.\nThis load-displacement data is a direct function of material's innate\nstress-strain behavior. Thus, theoretically it is possible to extract\nmechanical properties of a material through nanoindentation. However, due to\nvarious nonlinearities associated with nanoindentation the process of\ninterpreting load-displacement data into material properties is difficult.\nAlthough, simple elastic behavior can be characterized easily, a method to\ncharacterize complicated material behavior such as nonlinear viscoelasticity is\nstill lacking. In this study, a nanoindentation-based material characterization\ntechnique is developed to characterize soft materials exhibiting nonlinear\nviscoelasticity. Nanoindentation experiment was modeled in finite element\nanalysis software (ABAQUS), where a nonlinear viscoelastic behavior was\nincorporated using user-defined subroutine (UMAT). The model parameters were\ncalibrated using a process called inverse analysis. In this study, a surrogate\nmodel-based approach was used for the inverse analysis. The different factors\naffecting the surrogate model performance are analyzed in order to optimize the\nperformance with respect to the computational cost.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 03:39:20 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Hamim", "Salah U.", ""]]}, {"id": "1612.03350", "submitter": "Zheng Xu", "authors": "Zheng Xu, Furong Huang, Louiqa Raschid, Tom Goldstein", "title": "Non-negative Factorization of the Occurrence Tensor from Financial\n  Contracts", "comments": "NIPS tensor workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for the non-negative factorization of an occurrence\ntensor built from heterogeneous networks. We use l0 norm to model sparse errors\nover discrete values (occurrences), and use decomposed factors to model the\nembedded groups of nodes. An efficient splitting method is developed to\noptimize the nonconvex and nonsmooth objective. We study both synthetic\nproblems and a new dataset built from financial documents, resMBS.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 22:26:30 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Xu", "Zheng", ""], ["Huang", "Furong", ""], ["Raschid", "Louiqa", ""], ["Goldstein", "Tom", ""]]}, {"id": "1612.04431", "submitter": "Ali Burak \\\"Unal", "authors": "Ali Burak \\\"Unal, \\\"Oznur Ta\\c{s}tan", "title": "Identification of Cancer Patient Subgroups via Smoothed Shortest Path\n  Graph Kernel", "comments": "NIPS Workshop on Machine Learning in Computational Biology,\n  Barcelona, Spain, December 10, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing patient somatic mutations through next-generation sequencing\ntechnologies opens up possibilities for refining cancer subtypes. However,\ncatalogues of mutations reveal that only a small fraction of the genes are\naltered frequently in patients. On the other hand different genomic alterations\nmay perturb the same pathways. We propose a novel clustering procedure that\nquantifies the similarities of patients from their mutational profile on\npathways via a novel graph kernel. We represent each KEGG pathway as an\nundirected graph. For each patient the vertex labels are assigned based on her\naltered genes. Smoothed shortest path graph kernel (smSPK) evaluates each pair\nof patients by comparing their vertex labeled pathway graphs. Our clustering\nprocedure involves two steps: the smSPK kernel matrix derived for each pathway\nare input to kernel k-means algorithm and each pathway is evaluated\nindividually. In the next step, only those pathways that are successful are\ncombined in to a single kernel input to kernel k-means to stratify patients.\nEvaluating the procedure on simulated data showed that smSPK clusters patients\nup to 88\\% accuracy. Finally to identify ovarian cancer patient subgroups, we\napply our methodology to the cancer genome atlas ovarian data that involves 481\npatients. The identified subgroups are evaluated through survival analysis.\nGrouping patients into four clusters results with patients groups that are\nsignificantly different in their survival times ($p$-value $\\le 0.005$).\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 23:47:41 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 10:27:58 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["\u00dcnal", "Ali Burak", ""], ["Ta\u015ftan", "\u00d6znur", ""]]}, {"id": "1612.04451", "submitter": "Michael McCourt", "authors": "Michael McCourt and Ian Dewancker and Salvatore Ganci", "title": "Preemptive Termination of Suggestions during Sequential Kriging\n  Optimization of a Brain Activity Reconstruction Simulation", "comments": "4 pages of text, 2 pages of citations, 1 figure, 1 algorithm, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing brain activity through electroencephalography requires a\nboundary value problem (BVP) solver to take a proposed distribution of current\ndipoles within the brain and compute the resulting electrostatic potential on\nthe scalp. This article proposes the use of sequential kriging optimization to\nidentify different optimal BVP solver parameters for dipoles located in\nisolated sections of the brain by considering the cumulative impact of randomly\noriented dipoles within a chosen isolated section. We attempt preemptive\ntermination of parametrizations suggested during the sequential kriging\noptimization which, given the results to that point, seem unlikely to produce\nhigh quality solutions. Numerical experiments on a simplification of the full\ngeometry for which an approximate solution is available show a benefit from\nthis preemptive termination.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 01:32:53 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["McCourt", "Michael", ""], ["Dewancker", "Ian", ""], ["Ganci", "Salvatore", ""]]}, {"id": "1612.05916", "submitter": "Boyce Griffith", "authors": "Boyce E. Griffith, Xiaoyu Luo", "title": "Hybrid finite difference/finite element immersed boundary method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The immersed boundary method is an approach to fluid-structure interaction\nthat uses a Lagrangian description of the structural deformations, stresses,\nand forces along with an Eulerian description of the momentum, viscosity, and\nincompressibility of the fluid-structure system. The original immersed boundary\nmethods described immersed elastic structures using systems of flexible fibers,\nand even now, most immersed boundary methods still require Lagrangian meshes\nthat are finer than the Eulerian grid. This work introduces a coupling scheme\nfor the immersed boundary method to link the Lagrangian and Eulerian variables\nthat facilitates independent spatial discretizations for the structure and\nbackground grid. This approach employs a finite element discretization of the\nstructure while retaining a finite difference scheme for the Eulerian\nvariables. We apply this method to benchmark problems involving elastic, rigid,\nand actively contracting structures, including an idealized model of the left\nventricle of the heart. Our tests include cases in which, for a fixed Eulerian\ngrid spacing, coarser Lagrangian structural meshes yield discretization errors\nthat are as much as several orders of magnitude smaller than errors obtained\nusing finer structural meshes. The Lagrangian-Eulerian coupling approach\ndeveloped in this work enables the effective use of these coarse structural\nmeshes with the immersed boundary method. This work also contrasts two\ndifferent weak forms of the equations, one of which is demonstrated to be more\neffective for the coarse structural discretizations facilitated by our coupling\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 14:26:02 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2017 20:30:03 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Griffith", "Boyce E.", ""], ["Luo", "Xiaoyu", ""]]}, {"id": "1612.07649", "submitter": "Denys Dutykh", "authors": "Julien Berger (LOCIE, PUCPR), Suelen Gasparin (PUCPR), Denys Dutykh\n  (LAMA), Nathan Mendes (PUCPR)", "title": "Accurate numerical simulation of moisture front in porous material", "comments": "34 pages, 15 figures, 48 references. Other author's papers can be\n  downloaded at http://www.denys-dutykh.com/", "journal-ref": "Building and Environment (2017), Vol. 118, pp. 211-224", "doi": "10.1016/j.buildenv.2017.03.016", "report-no": null, "categories": "cs.CE physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing measurements to numerical simulations of moisture transfer\nthrough porous materials a rush of the experimental moisture front is commonly\nobserved in several works shown in the literature, with transient models that\nconsider only the diffusion process. Thus, to overcome the discrepancies\nbetween the experimental and the numerical models, this paper proposes to\ninclude the moisture advection transfer in the governing equation. To solve the\nadvection-diffusion differential equation, it is first proposed two efficient\nnumerical schemes and their efficiencies are investigated for both linear and\nnonlinear cases. The first scheme, Scharfetter-Gummel (SG), presents a\nCourant-Friedrichs-Lewy (CFL) condition but is more accurate and faster than\nthe second scheme, the well-known Crank-Nicolson approach. Furthermore, the SG\nscheme has the advantages of being well-balanced and asymptotically preserved.\nThen, to conclude, results of the convective moisture transfer problem obtained\nwith the SG numerical scheme are compared to experimental data from the\nliterature. The inclusion of an advective term in the model may clearly lead to\nbetter results than purely diffusive models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 15:33:20 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 08:04:44 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 12:32:50 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Berger", "Julien", "", "LOCIE, PUCPR"], ["Gasparin", "Suelen", "", "PUCPR"], ["Dutykh", "Denys", "", "LAMA"], ["Mendes", "Nathan", "", "PUCPR"]]}, {"id": "1612.07840", "submitter": "Ying-Cheng Lai", "authors": "Liang Huang, Xuan Ni, William L. Ditto, Mark Spano, Paul R. Carney,\n  and Ying-Cheng Lai", "title": "Detecting and characterizing high frequency oscillations in epilepsy - A\n  case study of big data analysis", "comments": "22 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework to uncover and analyze dynamical anomalies from\nmassive, nonlinear and non-stationary time series data. The framework consists\nof three steps: preprocessing of massive data sets to eliminate erroneous data\nsegments, application of the empirical mode decomposition and Hilbert transform\nparadigm to obtain the fundamental components embedded in the time series at\ndistinct time scales, and statistical/scaling analysis of the components. As a\ncase study, we apply our framework to detecting and characterizing high\nfrequency oscillations (HFOs) from a big database of rat EEG recordings. We\nfind a striking phenomenon: HFOs exhibit on-off intermittency that can be\nquantified by algebraic scaling laws. Our framework can be generalized to big\ndata-related problems in other fields such as large-scale sensor data and\nseismic data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 00:20:10 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Huang", "Liang", ""], ["Ni", "Xuan", ""], ["Ditto", "William L.", ""], ["Spano", "Mark", ""], ["Carney", "Paul R.", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "1612.08965", "submitter": "Reza Ghaffari", "authors": "Reza Ghaffari, Thang X. Duong, Roger A. Sauer", "title": "A new shell formulation for graphene structures based on existing\n  ab-initio data", "comments": "New examples are added and some typos are removed. The previous\n  results are unchanged, International Journal of Solids and Structures (2017)", "journal-ref": null, "doi": "10.1016/j.ijsolstr.2017.11.008", "report-no": null, "categories": "physics.comp-ph cond-mat.mes-hall cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An existing hyperelastic membrane model for graphene calibrated from\nab-initio data (Kumar and Parks, 2014) is adapted to curvilinear coordinates\nand extended to a rotation-free shell formulation based on isogeometric finite\nelements. Therefore, the membrane model is extended by a hyperelastic bending\nmodel that reflects the ab-inito data of Kudin et al. (2001). The proposed\nformulation can be implemented straight-forwardly into an existing finite\nelement package, since it does not require the description of molecular\ninteractions. It thus circumvents the use of interatomic potentials that tend\nto be less accurate than ab-initio data. The proposed shell formulation is\nverified and analyzed by a set of simple test cases. The results are in\nagreement to analytical solutions and satisfy the FE patch test. The\nperformance of the shell formulation for graphene structures is illustrated by\nseveral numerical examples. The considered examples are indentation and peeling\nof graphene and torsion, bending and axial stretch of carbon nanotubes.\nAdhesive substrates are modeled by the Lennard-Jones potential and a coarse\ngrained contact model. In principle, the proposed formulation can be extended\nto other 2D materials.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 19:49:36 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 22:58:12 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Ghaffari", "Reza", ""], ["Duong", "Thang X.", ""], ["Sauer", "Roger A.", ""]]}, {"id": "1612.09087", "submitter": "Farshad Roohbakhshan", "authors": "Farshad Roohbakhshan and Roger A. Sauer", "title": "Efficient isogeometric thin shell formulations for soft biological\n  materials", "comments": "Typos are removed. Remark 3.4 is added. Eq. (18) in the previous\n  version is removed. Thus, the equations get renumbered. Example 5.5 is\n  updated. Minor typos in Eqs. (17), (80), (145) and (146), are corrected. They\n  do not affect the results", "journal-ref": "Biomech Model Mechanobiol (2017) 16:1569", "doi": "10.1007/s10237-017-0906-6", "report-no": null, "categories": "cs.CE cond-mat.soft", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents three different constitutive approaches to model thin\nrotation-free shells based on the Kirchhoff-Love hypothesis. One approach is\nbased on numerical integration through the shell thickness while the other two\napproaches do not need any numerical integration and so they are\ncomputationally more efficient. The formulation is designed for large\ndeformations and allows for geometrical and material nonlinearities, which\nmakes it very suitable for the modeling of soft tissues. Furthermore, six\ndifferent isotropic and anisotropic material models, which are commonly used to\nmodel soft biological materials, are examined for the three proposed\nconstitutive approaches. Following an isogeometric approach, NURBS-based finite\nelements are used for the discretization of the shell surface. Several\nnumerical examples are investigated to demonstrate the capabilities of the\nformulation. Those include the contact simulation during balloon angioplasty.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 10:02:43 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 14:33:41 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Roohbakhshan", "Farshad", ""], ["Sauer", "Roger A.", ""]]}, {"id": "1612.09262", "submitter": "Vladimir Salnikov", "authors": "Vladimir Salnikov, Daniel Choi, Philippe Karamian-Surville", "title": "Computation of effective electrical conductivity of composite materials:\n  a novel approach based on analysis of graphs", "comments": "16 pages, 10 figures; version accepted to Composite Structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we continue the investigation of different approaches to\nconception and modeling of composite materials. The global method we focus on,\nis called 'stochastic homogenization'. In this approach, the classical\ndeterministic homogenization techniques and procedures are used to compute the\nmacroscopic parameters of a composite starting from its microscopic properties.\nThe stochastic part is due to averaging over some series of samples, and the\nfact that these samples fit into the concept of RVE (Representative Volume\nElement) in order to reduce the variance effect.\n  In this article, we present a novel method for computation of effective\nelectric properties of composites -- it is based on the analysis of the\nconnectivity graph (and the respective adjacency matrix) for each sample of a\ncomposite material. We describe how this matrix is constructed in order to take\ninto account complex microscopic geometry. We also explain what we mean by\nhomogenization procedure for electrical conductivity, and how the constructed\nmatrix is related to the problem. The developed method is applied to a test\nstudy of the influence of micromorphology of composites materials on their\nconductivity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 19:43:41 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 09:53:31 GMT"}, {"version": "v3", "created": "Tue, 6 Feb 2018 10:01:14 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Salnikov", "Vladimir", ""], ["Choi", "Daniel", ""], ["Karamian-Surville", "Philippe", ""]]}, {"id": "1612.09447", "submitter": "Sebastian Sch\\\"ops", "authors": "Christian Richter and Sebastian Sch\\\"ops and Markus Clemens", "title": "GPU Accelerated Explicit Time Integration Methods for\n  Electro-Quasistatic Fields", "comments": "4 pages, 5 figures", "journal-ref": "IEEE Trans. Magn., Volume: 53, Issue: 6, June 2017", "doi": "10.1109/TMAG.2017.2662234", "report-no": null, "categories": "cs.CE math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electro-quasistatic field problems involving nonlinear materials are commonly\ndiscretized in space using finite elements. In this paper, it is proposed to\nsolve the resulting system of ordinary differential equations by an explicit\nRunge-Kutta-Chebyshev time-integration scheme. This mitigates the need for\nNewton-Raphson iterations, as they are necessary within fully implicit time\nintegration schemes. However, the electro-quasistatic system of ordinary\ndifferential equations has a Laplace-type mass matrix such that parts of the\nexplicit time-integration scheme remain implicit. An iterative solver with\nconstant preconditioner is shown to efficiently solve the resulting multiple\nright-hand side problem. This approach allows an efficient parallel\nimplementation on a system featuring multiple graphic processing units.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 10:37:05 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Richter", "Christian", ""], ["Sch\u00f6ps", "Sebastian", ""], ["Clemens", "Markus", ""]]}]