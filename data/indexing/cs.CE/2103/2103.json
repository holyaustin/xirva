[{"id": "2103.00600", "submitter": "John Cartlidge", "authors": "Henry Hanifan, Ben Watson, John Cartlidge, Dave Cliff", "title": "Time Matters: Exploring the Effects of Urgency and Reaction Speed in\n  Automated Traders", "comments": "22 pages. To be published in A. P. Rocha et al. (Eds.), ICAART 2020,\n  LNAI 12613, 2021. arXiv admin note: substantial text overlap with\n  arXiv:1912.02775", "journal-ref": null, "doi": "10.1007/978-3-030-71158-0_7", "report-no": null, "categories": "cs.MA cs.CE q-fin.CP q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider issues of time in automated trading strategies in simulated\nfinancial markets containing a single exchange with public limit order book and\ncontinuous double auction matching. In particular, we explore two effects: (i)\nreaction speed - the time taken for trading strategies to calculate a response\nto market events; and (ii) trading urgency - the sensitivity of trading\nstrategies to approaching deadlines. Much of the literature on trading agents\nfocuses on optimising pricing strategies only and ignores the effects of time,\nwhile real-world markets continue to experience a race to zero latency, as\nautomated trading systems compete to quickly access information and act in the\nmarket ahead of others. We demonstrate that modelling reaction speed can\nsignificantly alter previously published results, with simple strategies such\nas SHVR outperforming more complex adaptive algorithms such as AA. We also show\nthat adding a pace parameter to ZIP traders (ZIP-Pace, or ZIPP) can create a\nsense of urgency that significantly improves profitability.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 19:38:52 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Hanifan", "Henry", ""], ["Watson", "Ben", ""], ["Cartlidge", "John", ""], ["Cliff", "Dave", ""]]}, {"id": "2103.01038", "submitter": "Charlelie Laurent", "authors": "Charlelie Laurent", "title": "Low-Order Modeling and High-Fidelity Simulations for the Prediction of\n  Combustion Instabilities in Liquid Rocket Engines and Gas Turbines", "comments": "PhD Thesis, 246 pages, 99 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combustion instabilities are a major concern in the design of Liquid Rocket\nEngines (LREs) and gas turbines. During this PhD work, several directions were\nexplored to understand and mitigate their effects. First, more efficient and\nrobust numerical methods for their prediction in complex combustors were\ndesigned. In this matter, a novel type of modal expansion, named a frame\nexpansion and comparable to the classical Galerkin expansion, was introduced to\nbuild more accurate acoustic Low-Order Models (LOMs), able to account for the\nfull geometrical complexity of industrial combustors. In particular, the frame\nexpansion is able to accurately represent the acoustic velocity field near\nnon-rigid-wall boundaries, a crucial ability that the Galerkin method lacks. An\nentire class of novel numerical methods, based on the frame expansion, were\nthen designed and combined with the state-space formalism to build acoustic\nnetworks of complex systems. The second ingredient in the prediction of\nthermoacoustic instabilities is the flame dynamics modeling. This work dealt\nwith this problem, in the specific case of a cryogenic coaxial jet-flame\ncharacteristic of a LRE. Flame dynamics driving phenomena were identified\nthanks to three-dimensional Large Eddy Simulations (LES) of the Mascotte\nexperimental test rig where both reactants (CH4 and O2) are injected in\ntranscritical conditions. Several LES with harmonic modulation of the fuel\ninflow at various frequencies and amplitudes were performed in order to\nevaluate the flame response to acoustic oscillations and compute a Flame\nTransfer Function (FTF). The stabilization of this flame in the near-injector\nregion, which is of primary importance on the overall flame dynamics, was also\ninvestigated thanks to multi-physics two-dimensional Direct Numerical\nSimulations (DNS), where a conjugate heat transfer problem is resolved at the\ninjector lip.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:31:14 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Laurent", "Charlelie", ""]]}, {"id": "2103.01048", "submitter": "L. A. Barba", "authors": "Tingyu Wang, Christopher D. Cooper, Timo Betcke, Lorena A. Barba", "title": "High-productivity, high-performance workflow for virus-scale\n  electrostatic simulations with Bempp-Exafmm", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomolecular electrostatics is key in protein function and the chemical\nprocesses affecting it.Implicit-solvent models expressed by the\nPoisson-Boltzmann (PB) equation can provide insights with less computational\npower than full atomistic models, making large-system studies -- at the scale\nof viruses, for example -- accessible to more researchers. This paper presents\na high-productivity and high-performance computational workflow combining\nExafmm, a fast multipole method (FMM) library, and Bempp, a Galerkin boundary\nelement method (BEM) package. It integrates an easy-to-use Python interface\nwith well-optimized computational kernels that are written in compiled\nlanguages. Researchers can run PB simulations interactively via Jupyter\nnotebooks, enabling faster prototyping and analyzing. We provide results that\nshowcase the capability of the software, confirm correctness, and evaluate its\nperformance with problem sizes between 8,000 and 2 million boundary elements. A\nstudy comparing two variants of the boundary integral formulation in regards to\nalgebraic conditioning showcases the power of this interactive computing\nplatform to give useful answers with just a few lines of code. As a form of\nsolution verification, mesh refinement studies with a spherical geometry as\nwell as with a real biological structure (5PTI) confirm convergence at the\nexpected $1/N$ rate, for $N$ boundary elements. Performance results include\ntimings, breakdowns, and computational complexity. Exafmm offers evaluation\nspeeds of just a few seconds for tens of millions of points, and\n$\\mathcal{O}(N)$ scaling. This allowed computing the solvation free energy of a\nZika virus, represented by 1.6 million atoms and 10 million boundary elements,\nat 80-min runtime on a single compute node (dual 20-core Intel Xeon Gold 6148).\nAll results in the paper are presented with utmost care for reproducibility.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:43:27 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 12:35:01 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wang", "Tingyu", ""], ["Cooper", "Christopher D.", ""], ["Betcke", "Timo", ""], ["Barba", "Lorena A.", ""]]}, {"id": "2103.01380", "submitter": "Heather Pacella", "authors": "Heather Pacella, Alec Dunton, Alireza Doostan, Gianluca Iaccarino", "title": "Task-parallel in-situ temporal compression of large-scale computational\n  fluid dynamics data", "comments": "There are 32 pages and 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Present day computational fluid dynamics simulations generate extremely large\namounts of data, sometimes on the order of TB/s. Often, a significant fraction\nof this data is discarded because current storage systems are unable to keep\npace. To address this, data compression algorithms can be applied to data\narrays containing flow quantities of interest to reduce the overall amount of\nstorage. Compression methods either exactly reconstruct the original dataset\n(lossless compression) or provide an approximate representation of the original\ndataset (lossy compression). The matrix column interpolative decomposition (ID)\ncan be implemented as a type of lossy compression for data matrices that\nfactors the original data matrix into a product of two smaller factor matrices.\nOne of these matrices consists of a subset of the columns of the original data\nmatrix, while the other is a coefficient matrix which approximates the columns\nof the original data matrix as linear combinations of the selected columns.\nMotivating this work is the observation that the structure of ID algorithms\nmakes them a natural fit for the asynchronous nature of task-based parallelism;\nthey are able to operate independently on sub-domains of the system of interest\nand, as a result, provide varied levels of compression. Using the task-based\nLegion programming model, a single-pass ID algorithm (SPID) for CFD\napplications is implemented. Performance studies, scalability, and the accuracy\nof the compression algorithms are presented for an analytical Taylor-Green\nvortex problem, followed by a large-scale implementation of a compressible\nTaylor-Green vortex using a high-order Navier-Stokes solver. In both cases,\ncompression factors exceeding 100 are achieved with relative errors at or below\n10e-3. Moreover, strong and weak scaling results demonstrate that introducing\nSPID to solvers leads to negligible increases in runtime.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 00:38:02 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Pacella", "Heather", ""], ["Dunton", "Alec", ""], ["Doostan", "Alireza", ""], ["Iaccarino", "Gianluca", ""]]}, {"id": "2103.01513", "submitter": "Petr Karnakov", "authors": "Petr Karnakov (1), Sergey Litvinov (1), Petros Koumoutsakos (1 and 2)\n  ((1) ETH Zurich, (2) Harvard University)", "title": "Computing foaming flows across scales: from breaking waves to\n  microfluidics", "comments": "11 pages, 7 figures, supplementary information, software\n  https://github.com/cselab/aphros", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA math.NA physics.flu-dyn", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Crashing ocean waves, cappuccino froths and microfluidic bubble crystals are\nexamples of foamy flows. Foamy flows are critical in numerous natural and\nindustrial processes and remain notoriously difficult to compute as they\ninvolve coupled, multiscale physical processes. Computations need to resolve\nthe interactions of the bubbles with the fluid and complex boundaries, while\ncapturing the drainage and rupture of the microscopic liquid films at their\ninterface. We present a novel multilayer simulation framework (Multi-VOF) that\nadvances the state of the art in simulation capabilities of foamy flows. The\nframework introduces a novel scheme for the distinct handling of multiple\nneighboring bubbles and a new regularization method that produces sharp\ninterfaces and removes spurious fragments. Multi-VOF is verified and validated\nwith experimental results and complemented with open source, efficient scalable\nsoftware. We demonstrate capturing of bubble crystalline structures in\nrealistic microfluidics devices and foamy flows involving tens of thousands of\nbubbles in a waterfall. The present multilayer framework extends the classical\nvolume-of-fluid methodology and allows for unprecedented large scale,\npredictive simulations of flows with multiple interfaces.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 06:53:24 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Karnakov", "Petr", "", "ETH Zurich"], ["Litvinov", "Sergey", "", "ETH Zurich"], ["Koumoutsakos", "Petros", "", "1 and 2"]]}, {"id": "2103.01670", "submitter": "John Cartlidge", "authors": "Zijian Shi, Yu Chen, John Cartlidge", "title": "The LOB Recreation Model: Predicting the Limit Order Book from TAQ\n  History Using an Ordinary Differential Equation Recurrent Neural Network", "comments": "12 pages, preprint accepted for publication in the 35th AAAI\n  Conference on Artificial Intelligence (AAAI-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.NE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an order-driven financial market, the price of a financial asset is\ndiscovered through the interaction of orders - requests to buy or sell at a\nparticular price - that are posted to the public limit order book (LOB).\nTherefore, LOB data is extremely valuable for modelling market dynamics.\nHowever, LOB data is not freely accessible, which poses a challenge to market\nparticipants and researchers wishing to exploit this information. Fortunately,\ntrades and quotes (TAQ) data - orders arriving at the top of the LOB, and\ntrades executing in the market - are more readily available. In this paper, we\npresent the LOB recreation model, a first attempt from a deep learning\nperspective to recreate the top five price levels of the LOB for small-tick\nstocks using only TAQ data. Volumes of orders sitting deep in the LOB are\npredicted by combining outputs from: (1) a history compiler that uses a Gated\nRecurrent Unit (GRU) module to selectively compile prediction relevant quote\nhistory; (2) a market events simulator, which uses an Ordinary Differential\nEquation Recurrent Neural Network (ODE-RNN) to simulate the accumulation of net\norder arrivals; and (3) a weighting scheme to adaptively combine the\npredictions generated by (1) and (2). By the paradigm of transfer learning, the\nsource model trained on one stock can be fine-tuned to enable application to\nother financial assets of the same class with much lower demand on additional\ndata. Comprehensive experiments conducted on two real world intraday LOB\ndatasets demonstrate that the proposed model can efficiently recreate the LOB\nwith high accuracy using only TAQ data as input.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 12:07:43 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Shi", "Zijian", ""], ["Chen", "Yu", ""], ["Cartlidge", "John", ""]]}, {"id": "2103.01934", "submitter": "Philipp Trunschke", "authors": "Christian Bayer, Martin Eigel, Leon Sallandt, Philipp Trunschke", "title": "Pricing high-dimensional Bermudan options with hierarchical tensor\n  formats", "comments": "26 pages, 3 figures, 5 tables, added affiliations and update\n  acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient compression technique based on hierarchical tensors for popular\noption pricing methods is presented. It is shown that the \"curse of\ndimensionality\" can be alleviated for the computation of Bermudan option prices\nwith the Monte Carlo least-squares approach as well as the dual martingale\nmethod, both using high-dimensional tensorized polynomial expansions. This\ndiscretization allows for a simple and computationally cheap evaluation of\nconditional expectations. Complexity estimates are provided as well as a\ndescription of the optimization procedures in the tensor train format.\nNumerical experiments illustrate the favourable accuracy of the proposed\nmethods. The dynamical programming method yields results comparable to recent\nNeural Network based methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 18:46:28 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 09:19:51 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Bayer", "Christian", ""], ["Eigel", "Martin", ""], ["Sallandt", "Leon", ""], ["Trunschke", "Philipp", ""]]}, {"id": "2103.01983", "submitter": "Steven Rodriguez", "authors": "Steven N. Rodriguez, Athanasios P. Iliopoulos, Kevin T. Carlberg,\n  Steven L. Brunton, John C. Steuben, John G. Michopoulos", "title": "Projection-tree reduced order modeling for fast N-body computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a data-driven reduced-order modeling framework to\naccelerate the computations of $N$-body dynamical systems and their pair-wise\ninteractions. The proposed framework differs from traditional acceleration\nmethods, like the Barnes-Hut method, which requires online tree building of the\nstate space, or the fast-multipole method, which requires rigorous $a$ $priori$\nanalysis of governing kernels and online tree building. Our approach combines\nBarnes-Hut hierarchical decomposition, dimensional compression via the\nleast-squares Petrov-Galerkin (LSPG) projection, and hyper-reduction by way of\nthe Gauss-Newton with approximated tensor (GNAT) approach. The resulting\n$projection-tree$ reduced order model (PTROM) enables a drastic reduction in\noperational count complexity by constructing sparse hyper-reduced pairwise\ninteractions of the $N$-body dynamical system. As a result, the presented\nframework is capable of achieving an operational count complexity that is\nindependent of $N$, the number of bodies in the numerical domain. Capabilities\nof the PTROM method are demonstrated on the two-dimensional fluid-dynamic\nBiot-Savart kernel within a parametric and reproductive setting. Results show\nthe PTROM is capable of achieving over 2000$\\times$ wall-time speed-up with\nrespect to the full-order model, where the speed-up increases with $N$. The\nresulting solution delivers quantities of interest with errors that are less\nthan 0.1$\\%$ with respect to full-order model.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 19:04:17 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 15:20:56 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Rodriguez", "Steven N.", ""], ["Iliopoulos", "Athanasios P.", ""], ["Carlberg", "Kevin T.", ""], ["Brunton", "Steven L.", ""], ["Steuben", "John C.", ""], ["Michopoulos", "John G.", ""]]}, {"id": "2103.02043", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Nathaniel R. Morgan, Evan J. Lieberman, Donald E. Burton", "title": "A discontinuous Galerkin method based on a hierarchical orthogonal basis\n  for Lagrangian hydrodynamics on curvilinear grids", "comments": "39 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-18-26689", "categories": "physics.comp-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new high-order accurate Lagrangian discontinuous Galerkin (DG)\nhydrodynamic method to simulate material dynamics (for e.g., gasses, fluids,\nand solids) with up to fourth-order accuracy on cubic meshes. The variables,\nsuch as specific volume, velocity, specific total energy, and deformation\ngradient fields within a cell, are represented with a polynomial constructed\nfrom a novel hierarchical orthogonal basis about the center of mass, which\ndecouples the moments of the solution because the mass matrix is diagonal. The\ndiscontinuity in the polynomials at the cell boundary is addressed by solving a\nmulti-directional Riemann problem at the vertices of the cell and a 1D Riemann\nproblem at additional non-vertex quadrature points along the edges so that the\nsurface integral is exact for the polynomial order. The uniqueness lies in that\nthe vertices of the curvilinear grid work as the quadrature points for the\nsurface integral of DG methods. To ensure robust mesh motion, the pressure for\nthe Riemann problem accounts for the difference between the density variation\nover the cell and a density field from subcell mesh stabilization (SMS). The\naccuracy and robustness of the new high-order accurate Lagrangian DG\nhydrodynamic method is demonstrated by simulating a diverse suite of\nchallenging test problems covering gas and solid dynamic problems on curved\ngrids.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 14:40:43 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Liu", "Xiaodong", ""], ["Morgan", "Nathaniel R.", ""], ["Lieberman", "Evan J.", ""], ["Burton", "Donald E.", ""]]}, {"id": "2103.02388", "submitter": "Nils Kohl", "authors": "Nils Kohl, Marcus Mohr, Sebastian Eibl, Ulrich R\\\"ude", "title": "A massively parallel Eulerian-Lagrangian method for advection-dominated\n  transport in viscous fluids", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by challenges in Earth mantle convection, we present a massively\nparallel implementation of an Eulerian-Lagrangian method for the\nadvection-diffusion equation in the advection-dominated regime. The advection\nterm is treated by a particle-based, characteristics method coupled to a\nblock-structured finite-element framework. Its numerical and computational\nperformance is evaluated in multiple, two- and three-dimensional benchmarks,\nincluding curved geometries, discontinuous solutions, pure advection, and it is\napplied to a coupled non-linear system modeling buoyancy-driven convection in\nStokes flow. We demonstrate the parallel performance in a strong and weak\nscaling experiment, with scalability to up to $147,456$ parallel processes,\nsolving for more than $5.2 \\times 10^{10}$ (52 billion) degrees of freedom per\ntime-step.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 13:26:52 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Kohl", "Nils", ""], ["Mohr", "Marcus", ""], ["Eibl", "Sebastian", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "2103.02588", "submitter": "Wei Chen", "authors": "Jun Wang, Wei Chen, Mark Fuge, Rahul Rai", "title": "IH-GAN: A Conditional Generative Model for Implicit Surface-Based\n  Inverse Design of Cellular Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variable-density cellular structures can overcome connectivity and\nmanufacturability issues of topologically-optimized, functionally graded\nstructures, particularly when those structures are represented as discrete\ndensity maps. One na\\\"ive approach to creating variable-density cellular\nstructures is simply replacing the discrete density map with an unselective\ntype of unit cells having corresponding densities. However, doing so breaks the\ndesired mechanical behavior, as equivalent density alone does not guarantee\nequivalent mechanical properties. Another approach uses homogenization methods\nto estimate each pre-defined unit cell's effective properties and remaps the\nunit cells following a scaling law. However, a scaling law merely mitigates the\nproblem by performing an indirect and inaccurate mapping from the material\nproperty space to single-type unit cells. In contrast, we propose a deep\ngenerative model that resolves this problem by automatically learning an\naccurate mapping and generating diverse cellular unit cells conditioned on\ndesired properties (i.e., Young's modulus and Poisson's ratio). We demonstrate\nour method via the use of implicit function-based unit cells and conditional\ngenerative adversarial networks. Results show that our method can 1) generate\nvarious unit cells that satisfy given material properties with high accuracy\n(relative error <5%), 2) create functionally graded cellular structures with\nhigh-quality interface connectivity (98.7% average overlap area at interfaces),\nand 3) improve the structural performance over the conventional\ntopology-optimized variable-density structure (84.4% reduction in concentrated\nstress and extra 7% reduction in displacement).\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 18:39:25 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Wang", "Jun", ""], ["Chen", "Wei", ""], ["Fuge", "Mark", ""], ["Rai", "Rahul", ""]]}, {"id": "2103.02843", "submitter": "Agastya Bhati", "authors": "Agastya P. Bhati, Shunzhou Wan, Dario Alf\\`e, Austin R. Clyde, Mathis\n  Bode, Li Tan, Mikhail Titov, Andre Merzky, Matteo Turilli, Shantenu Jha,\n  Roger R. Highfield, Walter Rocchia, Nicola Scafuri, Sauro Succi, Dieter\n  Kranzlm\\\"uller, Gerald Mathias, David Wifling, Yann Donon, Alberto Di Meglio,\n  Sofia Vallecorsa, Heng Ma, Anda Trifan, Arvind Ramanathan, Tom Brettin,\n  Alexander Partin, Fangfang Xia, Xiaotan Duan, Rick Stevens, Peter V. Coveney", "title": "Pandemic Drugs at Pandemic Speed: Accelerating COVID-19 Drug Discovery\n  with Hybrid Machine Learning- and Physics-based Simulations on High\n  Performance Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.LG physics.bio-ph q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The race to meet the challenges of the global pandemic has served as a\nreminder that the existing drug discovery process is expensive, inefficient and\nslow. There is a major bottleneck screening the vast number of potential small\nmolecules to shortlist lead compounds for antiviral drug development. New\nopportunities to accelerate drug discovery lie at the interface between machine\nlearning methods, in this case developed for linear accelerators, and\nphysics-based methods. The two in silico methods, each have their own\nadvantages and limitations which, interestingly, complement each other. Here,\nwe present an innovative method that combines both approaches to accelerate\ndrug discovery. The scale of the resulting workflow is such that it is\ndependent on high performance computing. We have demonstrated the applicability\nof this workflow on four COVID-19 target proteins and our ability to perform\nthe required large-scale calculations to identify lead compounds on a variety\nof supercomputers.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 05:43:18 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Bhati", "Agastya P.", ""], ["Wan", "Shunzhou", ""], ["Alf\u00e8", "Dario", ""], ["Clyde", "Austin R.", ""], ["Bode", "Mathis", ""], ["Tan", "Li", ""], ["Titov", "Mikhail", ""], ["Merzky", "Andre", ""], ["Turilli", "Matteo", ""], ["Jha", "Shantenu", ""], ["Highfield", "Roger R.", ""], ["Rocchia", "Walter", ""], ["Scafuri", "Nicola", ""], ["Succi", "Sauro", ""], ["Kranzlm\u00fcller", "Dieter", ""], ["Mathias", "Gerald", ""], ["Wifling", "David", ""], ["Donon", "Yann", ""], ["Di Meglio", "Alberto", ""], ["Vallecorsa", "Sofia", ""], ["Ma", "Heng", ""], ["Trifan", "Anda", ""], ["Ramanathan", "Arvind", ""], ["Brettin", "Tom", ""], ["Partin", "Alexander", ""], ["Xia", "Fangfang", ""], ["Duan", "Xiaotan", ""], ["Stevens", "Rick", ""], ["Coveney", "Peter V.", ""]]}, {"id": "2103.03280", "submitter": "Sander van Rijn", "authors": "Sander van Rijn, Sebastian Schmitt, Matthijs van Leeuwen, Thomas\n  B\\\"ack", "title": "Finding Efficient Trade-offs in Multi-Fidelity Response Surface Modeling", "comments": "12 pages, 9 figures, submitted to Numerical Methods in Engineering\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of optimization approaches to engineering applications,\ntime-consuming simulations are often utilized which can be configured to\ndeliver solutions for various levels of accuracy, commonly referred to as\ndifferent fidelity levels. It is common practice to train hierarchical\nsurrogate models on the objective functions in order to speed-up the\noptimization process. These operate under the assumption that there is a\ncorrelation between the high- and low-fidelity versions of the problem that can\nbe exploited to cheaply gain information. In the practical scenario where the\ncomputational budget has to be allocated between multiple fidelities, limited\nguidelines are available to help make that division. In this paper we evaluate\na range of different choices for a two-fidelity setup that provide helpful\nintuitions about the trade-off between evaluating in high- or low-fidelity. We\npresent a heuristic method based on subsampling from an initial Design of\nExperiments (DoE) to find a suitable division of the computational budget\nbetween the fidelity levels. This enables the setup of multi-fidelity\noptimizations which utilize the available computational budget efficiently,\nindependent of the multi-fidelity model used.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 19:29:15 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["van Rijn", "Sander", ""], ["Schmitt", "Sebastian", ""], ["van Leeuwen", "Matthijs", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2103.03567", "submitter": "Philipp Junker", "authors": "Miriam Kick, Philipp Junker", "title": "Thermodynamic topology optimization including plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we present an extension of the thermodynamic topology\noptimization that accounts for a non-linear material behavior due to the\nevolution of plastic strains. Physically, a plastic material behavior is\ncharacterized by a hysteresis in the stress/strain diagram after loading and\nunloading. In contrast, topology optimization is usually employed for a\ntime-invariant load and the optimized component will only be loaded during\nphysical use. Still, a virtual increase and decrease of strains, i.e., an\nunphysical evolution of the strains during the optimization process, is locally\nobserved due to the evolution of the structure and thus modulation of the\nstiffness. If a classical plasticity model is employed for this unphysical\n``loading'' and ``unloading'', incorrect strain and stress states are computed\ndue to the apparent energy dissipation and hysteresis in the stress/strain\ndiagram. Therefore, this problem is usually resolved by recomputing the\nphysical behavior for each optimization step: the initial conditions are\nrefreshed by deleting all plastic strains computed for the previous\noptimization step. This restores the virgin state for the updated topology. The\nplastic strains are subsequently determined by evaluating the classical\nplasticity model which requires a discretization of the loading which results\nin several finite element simulations. After the correct plastic strains have\nbeen found, the next update step for the topology optimization is performed. To\navoid this time-consuming procedure, we develop a novel surrogate material\nmodel that allows to correctly account for the physical state in terms of the\nplastic strains. Hence, finite element simulations purely for the plastic\nmaterial behavior become obsolete such that the optimization of plastic\nmaterials now consumes comparable computation times as the optimization of\nelastic materials.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 09:52:51 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 14:19:19 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kick", "Miriam", ""], ["Junker", "Philipp", ""]]}, {"id": "2103.03655", "submitter": "Georgios Tsialiamanis", "authors": "George Tsialiamanis, Charilaos Mylonas, Eleni Chatzi, Nikolaos\n  Dervilis, David J. Wagg, Keith Worden", "title": "Foundations of Population-Based SHM, Part IV: The Geometry of Spaces of\n  Structures and their Feature Spaces", "comments": null, "journal-ref": "Mechanical Systems and Signal Processing 157 (2021): 107692", "doi": "10.1016/j.ymssp.2021.107692", "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One of the requirements of the population-based approach to Structural Health\nMonitoring (SHM) proposed in the earlier papers in this sequence, is that\nstructures be represented by points in an abstract space. Furthermore, these\nspaces should be metric spaces in a loose sense; i.e. there should be some\nmeasure of distance applicable to pairs of points; similar structures should\nthen be close in the metric. However, this geometrical construction is not\nenough for the framing of problems in data-based SHM, as it leaves undefined\nthe notion of feature spaces. Interpreting the feature values on a\nstructure-by-structure basis as a type of field over the space of structures,\nit seems sensible to borrow an idea from modern theoretical physics, and define\nfeature assignments as sections in a vector bundle over the structure space.\nWith this idea in place, one can interpret the effect of environmental and\noperational variations as gauge degrees of freedom, as in modern gauge field\ntheories. This paper will discuss the various geometrical structures required\nfor an abstract theory of feature spaces in SHM, and will draw analogies with\nhow these structures have shown their power in modern physics. In the second\npart of the paper, the problem of determining the normal condition cross\nsection of a feature bundle is addressed. The solution is provided by the\napplication of Graph Neural Networks (GNN), a versatile non-Euclidean machine\nlearning algorithm which is not restricted to inputs and outputs from vector\nspaces. In particular, the algorithm is well suited to operating directly on\nthe sort of graph structures which are an important part of the proposed\nframework for PBSHM. The solution of the normal section problem is demonstrated\nfor a heterogeneous population of truss structures for which the feature of\ninterest is the first natural frequency.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 13:28:51 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Tsialiamanis", "George", ""], ["Mylonas", "Charilaos", ""], ["Chatzi", "Eleni", ""], ["Dervilis", "Nikolaos", ""], ["Wagg", "David J.", ""], ["Worden", "Keith", ""]]}, {"id": "2103.03923", "submitter": "Raymond Leung", "authors": "Raymond Leung, Mehala Balamurali, Alexander Lowe", "title": "Surface Warping Incorporating Machine Learning Assisted Domain\n  Likelihood Estimation: A New Paradigm in Mine Geology Modelling and\n  Automation", "comments": "Keywords: Bayesian computation, machine learning, ensemble\n  classifiers, neural network, mesh geometry, surface warping, geochemistry,\n  domain likelihood, geological boundaries. 23 pages, 15 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper illustrates an application of machine learning (ML) within a\ncomplex system that performs grade estimation. In surface mining, assay\nmeasurements taken from production drilling often provide useful information\nthat allows initially inaccurate surfaces created using sparse exploration data\nto be revised and subsequently improved. Recently, a Bayesian warping technique\nhas been proposed to reshape modeled surfaces using geochemical and spatial\nconstraints imposed by newly acquired blasthole data. This paper focuses on\nincorporating machine learning into this warping framework to make the\nlikelihood computation generalizable. The technique works by adjusting the\nposition of vertices on the surface to maximize the integrity of modeled\ngeological boundaries with respect to sparse geochemical observations. Its\nfoundation is laid by a Bayesian derivation in which the geological domain\nlikelihood given the chemistry, p(g|c), plays a similar role to p(y(c)|g). This\nobservation allows a manually calibrated process centered around the latter to\nbe automated since ML techniques may be used to estimate the former in a\ndata-driven way. Machine learning performance is evaluated for gradient\nboosting, neural network, random forest and other classifiers in a binary and\nmulti-class context using precision and recall rates. Once ML likelihood\nestimators are integrated in the surface warping framework, surface shaping\nperformance is evaluated using unseen data by examining the categorical\ndistribution of test samples located above and below the warped surface.\nLarge-scale validation experiments are performed to assess the overall efficacy\nof ML assisted surface warping as a fully integrated component within an ore\ngrade estimation system where the posterior mean is obtained via Gaussian\nProcess inference with a Matern 3/2 kernel.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 10:37:52 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 01:28:05 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Leung", "Raymond", ""], ["Balamurali", "Mehala", ""], ["Lowe", "Alexander", ""]]}, {"id": "2103.04085", "submitter": "Anouar Ben Mabrouk", "authors": "Malika Jallouli, Sabrine Arfaoui, Anouar Ben Mabrouk and Carlo Cattani", "title": "Clifford wavelets for fetal ECG extraction", "comments": "21 pages, 8 figures, 1 table", "journal-ref": null, "doi": "10.3390/e23070844", "report-no": null, "categories": "physics.med-ph cs.CE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Analysis of the fetal heart rate during pregnancy is essential for monitoring\nthe proper development of the fetus. Current fetal heart monitoring techniques\nlack the accuracy in fetal heart rate monitoring and features acquisition,\nresulting in diagnostic medical issues. The challenge lies in the extraction of\nthe fetal ECG from the mother's ECG during pregnancy. This approach has the\nadvantage of being a reliable and non-invasive technique. For this aim, we\npropose in this paper a wavelet/multi-wavelet method allowing to extract\nperfectly the feta ECG parameters from the abdominal mother ECG. The method is\nessentially due to the exploitation of Clifford wavelets as recent variants in\nthe field. We prove that these wavelets are more efficient and performing\nagainst classical ones. The experimental results are therefore due to two basic\nclasses of wavelets and multi-wavelets. A first-class is the classical Haar\nSchauder, and a second one is due to Clifford valued wavelets and\nmulti-wavelets. These results showed that wavelets/multiwavelets are already\ngood bases for the FECG processing, provided that Clifford ones are the best.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 10:02:57 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 20:05:36 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jallouli", "Malika", ""], ["Arfaoui", "Sabrine", ""], ["Mabrouk", "Anouar Ben", ""], ["Cattani", "Carlo", ""]]}, {"id": "2103.04431", "submitter": "Carolin Mehlmann", "authors": "C. Mehlmann, S. Danilov, M. Losch, J.F. Lemieux, N. Hutter, T.\n  Richter, P. Blain, E.C. Hunke, P Korn", "title": "Simulating linear kinematic features in viscous-plastic sea ice models\n  on quadrilateral and triangular grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Kinematic Features (LKFs) are found everywhere in the Arctic sea ice\ncover. They are strongly localized deformations often associated with the\nformation of leads and pressure ridges. Viscous-plastic sea ice models start to\ngenerate LKFs at high spatial grid resolution, typically with a grid spacing\nbelow 5 km. Besides grid spacing, other aspects of a numerical implementation,\nsuch as discretization details, may affect the number and definition of\nsimulated LKFs. To explore these effects, the solutions of sea ice models with\ndifferent grid spacings, mesh types, and numerical discretization techniques\nare compared in an idealized configuration, which could also serve as a\nbenchmark problem in the future. The A, B, and C-grid discretizations of sea\nice dynamics on quadrilateral meshes leads to a similar number of LKFs as the\nA-grid approximation on triangular meshes (with the same number of vertices).\nThe discretization on an Arakawa CD-grid on both structured quadrilateral and\ntriangular meshes resolves the same number of LKFs as conventional Arakawa\nA-grid, B-grid, and C-grid approaches, but on two times coarser meshes. This is\ndue to the fact that the CD-grid approach has a higher number of degrees of\nfreedom to discretize the velocity field. Due to its enhanced resolving\nproperties, the CD-grid discretization is an attractive alternative to\nconventional discretizations.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 19:22:27 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Mehlmann", "C.", ""], ["Danilov", "S.", ""], ["Losch", "M.", ""], ["Lemieux", "J. F.", ""], ["Hutter", "N.", ""], ["Richter", "T.", ""], ["Blain", "P.", ""], ["Hunke", "E. C.", ""], ["Korn", "P", ""]]}, {"id": "2103.04594", "submitter": "Mohamed Tarek", "authors": "Mohamed Tarek, Tapabrata Ray", "title": "Robust and stochastic compliance-based topology optimization with\n  finitely many loading scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the problem of load uncertainty in compliance problems is\naddressed where the uncertainty is described in the form of a set of finitely\nmany loading scenarios. Computationally more efficient methods are proposed to\nexactly evaluate and differentiate: 1) the mean compliance, or 2) any\nscalar-valued function of the individual load compliances such as the weighted\nsum of the mean and standard deviation. The computational time complexities of\nall the proposed algorithms are analyzed, compared with the naive approaches\nand then experimentally verified. Finally, a mean compliance minimization\nproblem, a risk-averse compliance minimization problem and a maximum compliance\nconstrained problem are solved to showcase the efficacy of the proposed\nalgorithms. The maximum compliance constrained problem is solved using the\naugmented Lagrangian method and the method proposed for handling scalar-valued\nfunctions of the load compliances, where the scalar-valued function is the\naugmented Lagrangian function.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 08:21:09 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 01:55:59 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tarek", "Mohamed", ""], ["Ray", "Tapabrata", ""]]}, {"id": "2103.04652", "submitter": "Maxence Reberol", "authors": "Maxence Reberol, Christos Georgiadis, Jean-Fran\\c{c}ois Remacle", "title": "Quasi-structured quadrilateral meshing in Gmsh -- a robust pipeline for\n  complex CAD models", "comments": "33 pages, 10 figures, supplemental at\n  https://www.hextreme.eu/data/quadqs2021_supplemental.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end pipeline to robustly generate high-quality\nquadrilateral meshes for complex CAD models. An initial quad-dominant mesh is\ngenerated with frontal point insertion guided by a locally integrable cross\nfield and a scalar size map adapted to the small CAD features. After triangle\ncombination and midpoint-subdivision into an all-quadrilateral mesh, the\ntopology of the mesh is modified to reduce the number of irregular vertices.\nThe idea is to preserve the irregular vertices matching cross-field\nsingularities and to eliminate the others. The topological modifications are\neither local and based on disk quadrangulations, or more global with the\nremeshing of patches of quads according to predefined patterns. Validity of the\nquad mesh is guaranteed by monitoring element quality during all operations and\nreverting the changes when necessary. Advantages of our approach include\nrobustness, strict respect of the CAD features and support for user-prescribed\nsize constraints. The quad mesher, which is available in Gmsh, is validated and\nillustrated on two datasets of CAD models.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 10:23:55 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Reberol", "Maxence", ""], ["Georgiadis", "Christos", ""], ["Remacle", "Jean-Fran\u00e7ois", ""]]}, {"id": "2103.04770", "submitter": "Javier Segurado", "authors": "M. Magri, S. Lucarini, G. Lemoine, L. Adam and J. Segurado", "title": "An FFT framework for simulating non-local ductile failure in\n  heterogeneous materials", "comments": "Accepted for publication, last version", "journal-ref": "computer methods in applied mechanics and engineering, 2021", "doi": "10.1016/j.cma.2021.113759", "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The simulation of fracture using continuum ductile damage models attains a\npathological discretization dependence caused by strain localization, after\nloss of ellipticity of the problem, in regions whose size is connected to the\nspatial discretization. Implicit gradient techniques suppress this problem\nintroducing some inelastic non-local fields and solving an enriched formulation\nwhere the classical balance of linear momentum is fully coupled with a\nHelmholtz-type equation for each of the non-local variable. Such Helmholtz-type\nequations determine the distribution of the non-local fields in bands whose\nwidth is controlled by a characteristic length, independently on the spatial\ndiscretization. The numerical resolution of this coupled problem using the\nFinite Element method is computationally very expensive and its use to simulate\nthe damage process in 3D multi-phase microstructures becomes prohibitive. In\nthis work, we propose a novel FFT-based iterative algorithm for simulating\ngradient ductile damage in computational homogenization problems. In\nparticular, the Helmholtz-type equation of the implicit gradient approach is\nproperly generalized to model the regularization of damage in multi-phase\nmedia, where multiple damage variables and different characteristic lengths may\ncome into play. In the proposed iterative algorithm, two distinct problems are\nsolved in a staggered fashion: (i) a conventional mechanical problem via a\nFFT-Galerkin solver with mixed macroscopic loading control and (ii) the\ngeneralized Helmholtz-type equation using a Krylov-based algorithm combined\nwith an efficient pre-conditioner. The numerical implementation is firstly\nvalidated. Finally, the robustness and efficiency of the algorithm is\ndemonstrated in the simulation of failure of complex 3D particle reinforced\ncomposites characterized by millions of degrees of freedom.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 18:54:54 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Magri", "M.", ""], ["Lucarini", "S.", ""], ["Lemoine", "G.", ""], ["Adam", "L.", ""], ["Segurado", "J.", ""]]}, {"id": "2103.05275", "submitter": "Christian Krogh", "authors": "Christian Krogh, Johnny Jakobsen, Jakob Wilm", "title": "Will it Crease or Cease? A study of Debulking of Air Pockets in\n  Automated Prepreg Composite Layup", "comments": "Accepted manuscript", "journal-ref": "Composites Part A: Applied Science and Manufacturing, Volume 138,\n  November 2020, 106052", "doi": "10.1016/j.compositesa.2020.106052", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automatic draping of carbon-fiber prepreg plies for the aerospace industry is\na promising technique for lowering the manufacturing costs and to this end, a\nthorough in-process quality control is crucial. In this paper, out-of-plane\ndefects in the layup are investigated. After draping, air pockets are\noccasionally encountered. The question is, if such apparent defects can be\nmitigated sufficiently during vacuum debulking. The 3D topology is measured by\nmeans of a structured-light 3D scanner and air pockets are segmented. An\napproximate mass-spring ply model is used to study the behavior of the air\npockets during application of vacuum pressure. The model is computationally\nfast and will indicate online whether the air pocket will be removed or manual\nintervention is required. Upon comparing the model predictions with\nexperimental data, it is shown that the system is capable of correctly\npredicting 13 out of 14 air pockets in a test layup.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 07:48:24 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Krogh", "Christian", ""], ["Jakobsen", "Johnny", ""], ["Wilm", "Jakob", ""]]}, {"id": "2103.05358", "submitter": "Elias Cueto", "authors": "Abel Sancarlos, Victor Champaney, Jean-Louis Duval, Elias Cueto, and\n  Francisco Chinesta", "title": "PGD-based advanced nonlinear multiparametric regressions for\n  constructing metamodels at the scarce-data limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Regressions created from experimental or simulated data enable the\nconstruction of metamodels, widely used in a variety of engineering\napplications. Many engineering problems involve multi-parametric physics whose\ncorresponding multi-parametric solutions can be viewed as a sort of\ncomputational vademecum that, once computed offline, can be then used in a\nvariety of real-time engineering applications including optimization, inverse\nanalysis, uncertainty propagation or simulation based control. Sometimes, these\nmulti-parametric problems can be solved by using advanced model order reduction\n-- MOR -- techniques. However, when the solution of these multi-parametric\nproblems becomes cumbersome, one possibility consists in solving the problem\nfor a sample of the parametric values, and then creating a regression from all\nthe computed solutions, to finally infer the solution for any choice of the\nproblem parameters. However, addressing high-dimensionality at the low data\nlimit, ensuring accuracy and avoiding overfitting constitutes a difficult\nchallenge. The present paper aims at proposing and discussing different\nPGD-based advanced regressions enabling the just referred features.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 11:11:17 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Sancarlos", "Abel", ""], ["Champaney", "Victor", ""], ["Duval", "Jean-Louis", ""], ["Cueto", "Elias", ""], ["Chinesta", "Francisco", ""]]}, {"id": "2103.05443", "submitter": "Emilio Mart\\'inez-Pa\\~neda", "authors": "P.K. Kristensen, C.F. Niordson, E. Mart\\'inez-Pa\\~neda", "title": "An assessment of phase field fracture: crack initiation and growth", "comments": null, "journal-ref": "Philosophical Transactions of the Royal Society A: Mathematical,\n  Physical and Engineering Sciences (2021)", "doi": "10.1098/rsta.2021.0021", "report-no": null, "categories": "cs.CE cs.NA math.NA physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase field paradigm, in combination with a suitable variational\nstructure, has opened a path for using Griffith's energy balance to predict the\nfracture of solids. These so-called phase field fracture methods have gained\nsignificant popularity over the past decade, and are now part of commercial\nfinite element packages and engineering fitness-for-service assessments. Crack\npaths can be predicted, in arbitrary geometries and dimensions, based on a\nglobal energy minimisation - without the need for \\textit{ad hoc} criteria. In\nthis work, we review the fundamentals of phase field fracture methods and\nexamine their capabilities in delivering predictions in agreement with the\nclassical fracture mechanics theory pioneered by Griffith. The two most widely\nused phase field fracture models are implemented in the context of the finite\nelement method, and several paradigmatic boundary value problems are addressed\nto gain insight into their predictive abilities across all cracking stages;\nboth the initiation of growth and stable crack propagation are investigated. In\naddition, we examine the effectiveness of phase field models with an internal\nmaterial length scale in capturing size effects and the transition flaw size\nconcept. Our results show that phase field fracture methods satisfactorily\napproximate classical fracture mechanics predictions and can also reconcile\nstress and toughness criteria for fracture. The accuracy of the approximation\nis however dependent on modelling and constitutive choices; we provide a\nrationale for these differences and identify suitable approaches for delivering\nphase field fracture predictions that are in good agreement with\nwell-established fracture mechanics paradigms.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 07:27:55 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kristensen", "P. K.", ""], ["Niordson", "C. F.", ""], ["Mart\u00ednez-Pa\u00f1eda", "E.", ""]]}, {"id": "2103.05453", "submitter": "Andrew Lesniewski", "authors": "Patrick S. Hagan, Andrew Lesniewski, Georgios E. Skoufis, and Diana E.\n  Woodward", "title": "Portfolio risk allocation through Shapley value", "comments": "15 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.34681.80484", "report-no": null, "categories": "q-fin.CP cs.CE econ.EM math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We argue that using the Shapley value of cooperative game theory as the\nscheme for risk allocation among non-orthogonal risk factors is a natural way\nof interpreting the contribution made by each of such factors to overall\nportfolio risk. We discuss a Shapley value scheme for allocating risk to\nnon-orthogonal greeks in a portfolio of derivatives. Such a situation arises,\nfor example, when using a stochastic volatility model to capture option\nvolatility smile. We also show that Shapley value allows for a natural method\nof interpreting components of enterprise risk measures such as VaR and ES. For\nall applications discussed, we derive explicit formulas and / or numerical\nalgorithms to calculate the allocations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 14:36:16 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Hagan", "Patrick S.", ""], ["Lesniewski", "Andrew", ""], ["Skoufis", "Georgios E.", ""], ["Woodward", "Diana E.", ""]]}, {"id": "2103.05968", "submitter": "Felix Ernesti", "authors": "Felix Ernesti, Matti Schneider", "title": "An FFT-based method for computing the effective crack energy of a\n  heterogeneous material on a combinatorially consistent grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce an FFT-based solver for the combinatorial continuous maximum\nflow discretization applied to computing the minimum cut through heterogeneous\nmicrostructures. Recently, computational methods were introduced for computing\nthe effective crack energy of periodic and random media. These were based on\nthe continuous minimum cut-maximum flow duality of G. Strang, and made use of\ndiscretizations based on trigonometric polynomials and finite elements. For\nmaximum flow problems on graphs, node-based discretization methods avoid\nmetrication artifacts associated to edge-based discretizations. We discretize\nthe minimum cut problem on heterogeneous microstructures by the combinatorial\ncontinuous maximum flow discretization introduced by Couprie et al.\nFurthermore, we introduce an associated FFT-based ADMM solver and provide\nseveral adaptive strategies for choosing numerical parameters. We demonstrate\nthe salient features of the proposed approach on problems of industrial scale.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 09:55:01 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Ernesti", "Felix", ""], ["Schneider", "Matti", ""]]}, {"id": "2103.06373", "submitter": "Dengpeng Huang", "authors": "Dengpeng Huang, Sigrid Leyendecker", "title": "An electromechanically coupled beam model for dielectric elastomer\n  actuators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, the Cosserat formulation of geometrically exact beam dynamics\nis extended by adding the electric potential as an additional degree of freedom\nto account for the electromechanical coupling in the Dielectric Elastomer\nActuators (DEAs). To be able to generate complex beam deformations via\ndielectric actuator, a linear distribution of electric potential on the beam\ncross section is proposed. Based on this electric potential, the electric field\nand the strain-like electrical variable are defined for the beam, where the\nstrain-like electrical variable is work-conjugated to the electric\ndisplacement. The electromechanically coupled strain energy for the beam is\nderived consistently from continuum electromechanics, which leads to the direct\napplication of the material models in the continuum to the beam model. The\nelectromechanically coupled problem in beam dynamics is first spatially\nsemidiscretized by 1D finite elements and then solved via variational time\nintegration. By applying different electrical boundary conditions, different\ndeformations of the beam are obtained in the numerical examples, including\ncontraction, shear, bending and torsion. The damping effect induced by the\nviscosity as well as the total energy of the beam are evaluated. The\ndeformations of the electromechanically coupled beam model are compared with\nthe results of the 3D finite element model, where a good agreement of the\ndeformations in the beam model and that in the 3D finite element model is\nobserved. However, less degrees of freedom are required to resolve the complex\ndeformations in the beam model.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 14:32:29 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Huang", "Dengpeng", ""], ["Leyendecker", "Sigrid", ""]]}, {"id": "2103.06374", "submitter": "Wenjia Xie", "authors": "Wenjia Xie, Zhengyu Tian, Ye Zhang, Hang Yu", "title": "A unified construction of all-speed HLL-type schemes for hypersonic\n  heating computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a unified framework to develop all-speed HLL-type schemes for\nhypersonic heating computations is constructed. Such a unified construction\nmethod combines two effective improving techniques: a shock robustness\nimprovement and a low-Mach number fix. It is implemented by properly modifying\nthe approximate solutions of the local Riemann problem in the HLL framework,\nresulting in two all-speed HLL-type schemes, namely ASHLLC and ASHLLEM solvers.\nResults from both numerical analysis and experiments demonstrate that the newly\nproposed schemes not only preserve desirable properties of their original\nversions, but are also able to provide accurate and robust solutions for\ncomplex flows ranging from low-Mach number incompressible to hypersonic\ncompressible regimes. Thus, both the ASHLLC and ASHLLEM schemes can be used as\nreliable methods for hypersonic heating computations.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 13:37:18 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Xie", "Wenjia", ""], ["Tian", "Zhengyu", ""], ["Zhang", "Ye", ""], ["Yu", "Hang", ""]]}, {"id": "2103.06393", "submitter": "Ilias Giannakopoulos", "authors": "Ilias I. Giannakopoulos, Georgy D. Guryev, Jose E. C. Serralles,\n  Ioannis P. Georgakis, Luca Daniel, Jacob K. White, Riccardo Lattanzi", "title": "Compression of volume-surface integral equation matrices via Tucker\n  decomposition for magnetic resonance applications", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a method for the compression of the coupling matrix\nin volume\\hyp surface integral equation (VSIE) formulations. VSIE methods are\nused for electromagnetic analysis in magnetic resonance imaging (MRI)\napplications, for which the coupling matrix models the interactions between the\ncoil and the body. We showed that these effects can be represented as\nindependent interactions between remote elements in 3D tensor formats, and\nsubsequently decomposed with the Tucker model. Our method can work in tandem\nwith the adaptive cross approximation technique to provide fast solutions of\nVSIE problems. We demonstrated that our compression approaches can enable the\nuse of VSIE matrices of prohibitive memory requirements, by allowing the\neffective use of modern graphical processing units (GPUs) to accelerate the\narising matrix\\hyp vector products. This is critical to enable numerical MRI\nsimulations at clinical voxel resolutions in a feasible computation time. In\nthis paper, we demonstrate that the VSIE matrix\\hyp vector products needed to\ncalculate the electromagnetic field produced by an MRI coil inside a numerical\nbody model with $1$ mm$^3$ voxel resolution, could be performed in $\\sim 33$\nseconds in a GPU, after compressing the associated coupling matrix from $\\sim\n80$ TB to $\\sim 43$ MB.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 00:20:27 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 17:25:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Giannakopoulos", "Ilias I.", ""], ["Guryev", "Georgy D.", ""], ["Serralles", "Jose E. C.", ""], ["Georgakis", "Ioannis P.", ""], ["Daniel", "Luca", ""], ["White", "Jacob K.", ""], ["Lattanzi", "Riccardo", ""]]}, {"id": "2103.06569", "submitter": "Hamidreza Dehghani", "authors": "Hamidreza Dehghani and Andreas Zilian", "title": "ANN-aided incremental multiscale-remodelling-based finite strain\n  poroelasticity", "comments": null, "journal-ref": null, "doi": "10.1007/s00466-021-02023-3", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mechanical modelling of poroelastic media under finite strain is usually\ncarried out via phenomenological models neglecting complex micro-macro scales\ninterdependency. One reason is that the mathematical two-scale analysis is only\nstraightforward assuming infinitesimal strain theory. Exploiting the potential\nof ANNs for fast and reliable upscaling and localisation procedures, we propose\nan incremental numerical approach that considers rearrangement of the cell\nproperties based on its current deformation, which leads to the remodelling of\nthe macroscopic model after each time increment. This computational framework\nis valid for finite strain and large deformation problems while it ensures\ninfinitesimal strain increments within time steps. The full effects of the\ninterdependency between the properties and response of macro and micro scales\nare considered for the first time providing more accurate predictive analysis\nof fluid-saturated porous media which is studied via a numerical consolidation\nexample. Furthermore, the (nonlinear) deviation from Darcy's law is captured in\nfluid filtration numerical analyses. Finally, the brain tissue mechanical\nresponse under uniaxial cyclic test is simulated and studied.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 09:52:12 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Dehghani", "Hamidreza", ""], ["Zilian", "Andreas", ""]]}, {"id": "2103.06813", "submitter": "I. Esra Buyuktahtakin", "authors": "Xuecheng Yin, I. Esra Buyuktahtakin, Bhumi P. Patel", "title": "COVID-19: Optimal Allocation of Ventilator Supply under Uncertainty and\n  Risk", "comments": "35 pages, 6 figures, 10 tables, Under Review for a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CE q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a new risk-averse multi-stage stochastic\nepidemics-ventilator-logistics compartmental model to address the resource\nallocation challenges of mitigating COVID-19. This epidemiological logistics\nmodel involves the uncertainty of untested asymptomatic infections and\nincorporates short-term human migration. Disease transmission is also\nforecasted through a new formulation of transmission rates that evolve over\nspace and time with respect to various non-pharmaceutical interventions, such\nas wearing masks, social distancing, and lockdown. The proposed multi-stage\nstochastic model overviews different scenarios on the number of asymptomatic\nindividuals while optimizing the distribution of resources, such as\nventilators, to minimize the total expected number of newly infected and\ndeceased people. The Conditional Value at Risk (CVaR) is also incorporated into\nthe multi-stage mean-risk model to allow for a trade-off between the weighted\nexpected loss due to the outbreak and the expected risks associated with\nexperiencing disastrous pandemic scenarios. We apply our multi-stage mean-risk\nepidemics-ventilator-logistics model to the case of controlling the COVID-19 in\nhighly-impacted counties of New York and New Jersey. We calibrate, validate,\nand test our model using actual infection, population, and migration data. The\nresults indicate that short-term migration influences the transmission of the\ndisease significantly. The optimal number of ventilators allocated to each\nregion depends on various factors, including the number of initial infections,\ndisease transmission rates, initial ICU capacity, the population of a\ngeographical location, and the availability of ventilator supply. Our\ndata-driven modeling framework can be adapted to study the disease transmission\ndynamics and logistics of other similar epidemics and pandemics.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 01:48:35 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Yin", "Xuecheng", ""], ["Buyuktahtakin", "I. Esra", ""], ["Patel", "Bhumi P.", ""]]}, {"id": "2103.07377", "submitter": "Franciane Rocha PhD", "authors": "Franciane F. Rocha, Fabricio S. Sousa, Roberto F. Ausas, Felipe\n  Pereira, Gustavo C. Buscaglia", "title": "Interface spaces based on physics for multiscale mixed methods applied\n  to flows in fractured-like porous media", "comments": "42 pages, 26 figures. Submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that domain-decomposition-based multiscale mixed methods\nrely on interface spaces, defined on the skeleton of the decomposition, to\nconnect the solution among the non-overlapping subdomains. Usual spaces, such\nas polynomial-based ones, cannot properly represent high-contrast channelized\nfeatures such as fractures (high permeability) and barriers (low permeability)\nfor flows in heterogeneous porous media. We propose here new interface spaces,\nwhich are based on physics, to deal with permeability fields in the\nsimultaneous presence of fractures and barriers, accommodated respectively, by\nthe pressure and flux spaces. Existing multiscale methods based on mixed\nformulations can take advantage of the proposed interface spaces, however, in\norder to present and test our results, we use the newly developed Multiscale\nRobin Coupled Method (MRCM) [Guiraldello, et al., J. Comput. Phys., 355 (2018)\npp. 1-21], which generalizes most well-known multiscale mixed methods, and\nallows for the independent choice of the pressure and flux interface spaces. An\nadaptive version of the MRCM [Rocha, et al., J. Comput. Phys., 409 (2020),\n109316] is considered that automatically selects the physics-based pressure\nspace for fractured structures and the physics-based flux space for regions\nwith barriers, resulting in a procedure with unprecedented accuracy. The\nfeatures of the proposed approach are investigated through several numerical\nsimulations of single-phase and two-phase flows, in different heterogeneous\nporous media. The adaptive MRCM combined with the interface spaces based on\nphysics provides promising results for challenging problems with the\nsimultaneous presence of fractures and barriers.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 16:18:18 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Rocha", "Franciane F.", ""], ["Sousa", "Fabricio S.", ""], ["Ausas", "Roberto F.", ""], ["Pereira", "Felipe", ""], ["Buscaglia", "Gustavo C.", ""]]}, {"id": "2103.07502", "submitter": "Steven Atkinson", "authors": "Steven Atkinson and Yiming Zhang and Liping Wang", "title": "Discovery of Physics and Characterization of Microstructure from Data\n  with Bayesian Hidden Physics Models", "comments": "7, pages, 6 figures. To appear, AAAI 2021 Spring Symposium on\n  Combining Artificial Intelligence with Physical Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge in the interest of using machine learning techniques\nto assist in the scientific process of formulating knowledge to explain\nobservational data. We demonstrate the use of Bayesian Hidden Physics Models to\nfirst uncover the physics governing the propagation of acoustic impulses in\nmetallic specimens using data obtained from a pristine sample. We then use the\nlearned physics to characterize the microstructure of a separate specimen with\na surface-breaking crack flaw. Remarkably, we find that the physics learned\nfrom the first specimen allows us to understand the backscattering observed in\nthe latter sample, a qualitative feature that is wholly absent from the\nspecimen from which the physics were inferred. The backscattering is explained\nthrough inhomogeneities of a latent spatial field that can be recognized as the\nspeed of sound in the media.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 19:47:06 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Atkinson", "Steven", ""], ["Zhang", "Yiming", ""], ["Wang", "Liping", ""]]}, {"id": "2103.07627", "submitter": "Matti Schneider", "authors": "Matti Schneider and Marc Josien and Felix Otto", "title": "Representative volume elements for matrix-inclusion composites -- a\n  computational study on periodizing the ensemble", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.AP math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate volume-element sampling strategies for the stochastic\nhomogenization of particle-reinforced composites and show, via computational\nexperiments, that an improper treatment of particles intersecting the boundary\nof the computational cell may affect the accuracy of the computed effective\nproperties. Motivated by recent results on a superior convergence rate of the\nsystematic error for periodized ensembles compared to taking snapshots of\nensembles, we conduct computational experiments for microstructures with\ncircular, spherical and cylindrical inclusions and monitor the systematic\nerrors in the effective thermal conductivity for snapshots of ensembles\ncompared to working with microstructures sampled from periodized ensembles. We\nobserve that the standard deviation of the apparent properties computed on\nmicrostructures sampled from the periodized ensembles decays at the scaling\nexpected from the central limit theorem. In contrast, the standard deviation\nfor the snapshot ensembles shows an inferior decay rate at high filler content.\nThe latter effect is caused by additional long-range correlations that\nnecessarily appear in particle-reinforced composites at high, industrially\nrelevant, volume fractions. Periodized ensembles, however, appear to be less\naffected by these correlations. Our findings provide guidelines for working\nwith digital volume images of material microstructures and the design of\nrepresentative volume elements for computational homogenization.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 06:04:43 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Schneider", "Matti", ""], ["Josien", "Marc", ""], ["Otto", "Felix", ""]]}, {"id": "2103.07768", "submitter": "Robin Swezey", "authors": "Robin Swezey, Bruno Charron", "title": "Large-scale Recommendation for Portfolio Optimization", "comments": null, "journal-ref": "In Proceedings of the 12th ACM Conference on Recommender Systems\n  (RecSys 2018). Association for Computing Machinery, New York, NY, USA,\n  382-386", "doi": "10.1145/3240323.3240386", "report-no": null, "categories": "cs.AI cs.CE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual investors are now massively using online brokers to trade stocks\nwith convenient interfaces and low fees, albeit losing the advice and\npersonalization traditionally provided by full-service brokers. We frame the\nproblem faced by online brokers of replicating this level of service in a\nlow-cost and automated manner for a very large number of users. Because of the\ncare required in recommending financial products, we focus on a risk-management\napproach tailored to each user's portfolio and risk profile. We show that our\nhybrid approach, based on Modern Portfolio Theory and Collaborative Filtering,\nprovides a sound and effective solution. The method is applicable to stocks as\nwell as other financial assets, and can be easily combined with various\nfinancial forecasting models. We validate our proposal by comparing it with\nseveral baselines in a domain expert-based study.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 18:22:48 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Swezey", "Robin", ""], ["Charron", "Bruno", ""]]}, {"id": "2103.07925", "submitter": "Sebastian Fuchs", "authors": "Sebastian L. Fuchs, Christoph Meier, Wolfgang A. Wall, Christian J.\n  Cyron", "title": "An SPH framework for fluid-solid and contact interaction problems\n  including thermo-mechanical coupling and reversible phase transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work proposes an approach for fluid-solid and contact interaction\nproblems including thermo-mechanical coupling and reversible phase transitions.\nThe solid field is assumed to consist of several arbitrarily-shaped,\nundeformable but mobile rigid bodies, that are evolved in time individually and\nallowed to get into mechanical contact with each other. The fluid field\ngenerally consists of multiple liquid or gas phases. All fields are spatially\ndiscretized using the method of smoothed particle hydrodynamics (SPH). This\napproach is especially suitable in the context of continually changing\ninterface topologies and dynamic phase transitions without the need for\nadditional methodological and computational effort for interface tracking as\ncompared to mesh- or grid-based methods. Proposing a concept for the\nparallelization of the computational framework, in particular concerning a\ncomputationally efficient evaluation of rigid body motion, is an essential part\nof this work. Finally, the accuracy and robustness of the proposed framework is\ndemonstrated by several numerical examples in two and three dimensions,\ninvolving multiple rigid bodies, two-phase flow, and reversible phase\ntransitions, with a focus on two potential application scenarios in the fields\nof engineering and biomechanics: powder bed fusion additive manufacturing\n(PBFAM) and disintegration of food boluses in the human stomach. The efficiency\nof the parallel computational framework is demonstrated by a strong scaling\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 13:39:56 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Fuchs", "Sebastian L.", ""], ["Meier", "Christoph", ""], ["Wall", "Wolfgang A.", ""], ["Cyron", "Christian J.", ""]]}, {"id": "2103.08253", "submitter": "Sebastian Gajek", "authors": "Sebastian Gajek, Matti Schneider and Thomas B\\\"ohlke", "title": "An FE-DMN method for the multiscale analysis of fiber reinforced plastic\n  components", "comments": "Submitted to \"Computer Methods in Applied Mechanics and Engineering\"", "journal-ref": null, "doi": "10.1016/j.cma.2021.113952", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a fully coupled multiscale strategy for components\nmade from short fiber reinforced composites, where each Gauss point of the\nmacroscopic finite element model is equipped with a deep material network (DMN)\nwhich covers the different fiber orientation states varying within the\ncomponent. These DMNs need to be identified by linear elastic precomputations\non representative volume elements, and serve as high-fidelity surrogates for\nfull-field simulations on microstructures with inelastic constituents. We\ndiscuss how to extend direct DMNs to account for varying fiber orientation, and\npropose a simplified sampling strategy which significantly speeds up the\ntraining process. To enable concurrent multiscale simulations, evaluating the\nDMNs efficiently is crucial. We discuss dedicated techniques for exploiting\nsparsity and high-performance linear algebra modules, and demonstrate the power\nof the proposed approach on an industrial-scale three-dimensional component.\nIndeed, the DMN is capable of accelerating two-scale simulations significantly,\nproviding possible speed-ups of several magnitudes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 10:06:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gajek", "Sebastian", ""], ["Schneider", "Matti", ""], ["B\u00f6hlke", "Thomas", ""]]}, {"id": "2103.08347", "submitter": "Joseph Morlier Dr", "authors": "Ghislain Raze, Joseph Morlier", "title": "Explicit topology optimization through moving node approach: beam\n  elements recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structural optimization (topology, shapes, sizing) is an important tool for\nfacilitating the emergence of new concepts in structural design. Normally,\ntopology optimization is carried out at the early stage of design and then\nshape and sizing design are performed sequentially. Unlike traditional topology\noptimization method, explicit methodologies have attracted a great deal of\nattention because of the advantages of shortcuting the costly CAD/CAE processes\nwhile dealing with low order number of design variables compared to implicit\nmethod (such as SIMP). This paper aims at presenting an adaptation of a\nflow-inspired approach so-called Moving Node Approach (MNA) in topology\noptimization. In this approach, the discretization is decoupled from the\nmaterial distribution and the final objective is to recognize the best beam\nassembly while minimizing compliance. The paradigm has here changed and new\ndesign variables are used such as nodes location, elements length/orientation\nand size providing a lower number of design variables than pixels-based. The\nmethodology is validated using 2 classical testcases in the field of Topology\nOptimization: the Cantilever beam and the L-Shape problem.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 17:10:12 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Raze", "Ghislain", ""], ["Morlier", "Joseph", ""]]}, {"id": "2103.08414", "submitter": "Gabriel Borrageiro Mr", "authors": "Gabriel Borrageiro, Nick Firoozye and Paolo Barucca", "title": "Online Learning with Radial Basis Function Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the benefits of feature selection, nonlinear modelling and\nonline learning when forecasting in financial time series. We consider the\nsequential and continual learning sub-genres of online learning. The\nexperiments we conduct show that there is a benefit to online transfer\nlearning, in the form of radial basis function networks, beyond the sequential\nupdating of recursive least-squares models. We show that the radial basis\nfunction networks, which make use of clustering algorithms to construct a\nkernel Gram matrix, are more beneficial than treating each training vector as\nseparate basis functions, as occurs with kernel Ridge regression. We\ndemonstrate quantitative procedures to determine the very structure of the\nradial basis function networks. Finally, we conduct experiments on the log\nreturns of financial time series and show that the online learning models,\nparticularly the radial basis function networks, are able to outperform a\nrandom walk baseline, whereas the offline learning models struggle to do so.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 14:39:40 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 08:26:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Borrageiro", "Gabriel", ""], ["Firoozye", "Nick", ""], ["Barucca", "Paolo", ""]]}, {"id": "2103.08426", "submitter": "Tim Van Der Velden", "authors": "Tim van der Velden, Bob Rommes, Andreas Klink, Stefanie Reese, Johanna\n  Waimann", "title": "A novel approach for the efficient modeling of material dissolution in\n  electrochemical machining", "comments": null, "journal-ref": "Int. J. Solids Struct. 229 (2021) 111106", "doi": "10.1016/j.ijsolstr.2021.111106", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel approach to efficiently model anodic dissolution\nin electrochemical machining. Earlier modeling approaches employ a strict space\ndiscretization of the anodic surface that is associated with a remeshing\nprocedure at every time step. Besides that, the presented model is formulated\nby means of effective material parameters. Thereby, it allows to use a constant\nmesh for the entire simulation and, thus, decreases the computational costs.\nBased on Faraday's law of electrolysis, an effective dissolution level is\nintroduced, which describes the ratio of a dissolved volume and its\ncorresponding reference volume. This inner variable allows the modeling of the\ncomplex dissolution process without the necessity of computationally expensive\nremeshing by controlling the effective material parameters. Additionally, full\ncoupling of the thermoelectric problem is considered and its linearization and\nnumerical implementation are presented. The model shows good agreement with\nanalytical and experimental validation examples by yielding realistic results.\nFurthermore, simulations of a pulsed electrochemical machining process yield a\nprocess signature of the surface roughness related to the specific accumulated\nelectric charge. The numerical examples confirm the simulation's computational\nefficiency and accurate modeling qualities.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 14:56:43 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["van der Velden", "Tim", ""], ["Rommes", "Bob", ""], ["Klink", "Andreas", ""], ["Reese", "Stefanie", ""], ["Waimann", "Johanna", ""]]}, {"id": "2103.08654", "submitter": "Angran Li", "authors": "Angran Li, Amir Barati Farimani and Yongjie Jessica Zhang", "title": "Deep learning of material transport in complex neurite networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neurons exhibit complex geometry in their branched networks of neurites which\nis essential to the function of individual neuron but also brings challenges to\ntransport a wide variety of essential materials throughout their neurite\nnetworks for their survival and function. While numerical methods like\nisogeometric analysis (IGA) have been used for modeling the material transport\nprocess via solving partial differential equations (PDEs), they require long\ncomputation time and huge computation resources to ensure accurate geometry\nrepresentation and solution, thus limit their biomedical application. Here we\npresent a graph neural network (GNN)-based deep learning model to learn the\nIGA-based material transport simulation and provide fast material concentration\nprediction within neurite networks of any topology. Given input boundary\nconditions and geometry configurations, the well-trained model can predict the\ndynamical concentration change during the transport process with an average\nerror less than 10% and 120~330 times faster compared to IGA simulations. The\neffectiveness of the proposed model is demonstrated within several complex\nneurite networks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 19:05:09 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Li", "Angran", ""], ["Farimani", "Amir Barati", ""], ["Zhang", "Yongjie Jessica", ""]]}, {"id": "2103.08932", "submitter": "Xiangyu Y Hu", "authors": "Yujie Zhu and Chi Zhang and Xiangyu Hu", "title": "A splitting random-choice dynamic relaxation method for smoothed\n  particle hydrodynamics", "comments": "35 pages 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For conventional smoothed particle hydrodynamics (SPH), obtaining the static\nsolution of a problem is time-consuming. To address this drawback, we propose\nan efficient dynamic relaxation method by adding large\nartificial-viscosity-based damping into the momentum conservation equation.\nThen, operator splitting methods are introduced to discretize the added viscous\nterm for relaxing the time-step limit. To further improve the convergence rate,\na random-choice strategy is adopted, in which the viscous term is imposed\nrandomly rather than at every time step. In addition, to avoid the\nthread-conflict induced by applying shared-memory parallelization to accelerate\nimplicit method, a splitting cell-linked list scheme is devised. A number of\nbenchmark tests suggest that the present method helps systems achieve\nequilibrium state efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 09:30:16 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhu", "Yujie", ""], ["Zhang", "Chi", ""], ["Hu", "Xiangyu", ""]]}, {"id": "2103.08957", "submitter": "Bernhard Eidel", "authors": "Ajinkya Gote, Andreas Fischer, Chuanzeng Zhang, Bernhard Eidel", "title": "Computational Homogenization of Concrete in the Cyber\n  Size-Resolution-Discretization (SRD) Parameter Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Micro- and mesostructures of multiphase materials obtained from tomography\nand image acquisition are an ever more important database for simulation\nanalyses. Huge data sets for reconstructed 3d volumes typically as voxel grids\ncall for criteria and measures to find an affordable balance of accuracy and\nefficiency. The present work shows for a 3d mesostructure of concrete in the\nelastic deformation range, how the computational complexity in analyses of\nnumerical homogenization can be reduced at controlled errors. Reduction is\nsystematically applied to specimen size S, resolution R, and discretization D,\nwhich span the newly introduced SRD parameter space. Key indicators for\naccuracy are (i) the phase fractions, (ii) the homogenized elasticity tensor,\n(iii) its invariance with respect to the applied boundary conditions and (iv)\nthe total error as well as spatial error distributions, which are computed and\nestimated. Pre-analyses in the 2d SRD parameter sub-space explore the\ntransferability to the 3d case. Beyond the concrete specimen undergoing elastic\ndeformations in the present work, the proposed concept enables\naccuracy-efficiency balances for various classes of heterogeneous materials in\ndifferent deformation regimes and thus contributes to build comprehensive\ndigital twins of materials with validated attributes.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 10:32:19 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gote", "Ajinkya", ""], ["Fischer", "Andreas", ""], ["Zhang", "Chuanzeng", ""], ["Eidel", "Bernhard", ""]]}, {"id": "2103.09100", "submitter": "Junqi Zhang", "authors": "Junqi Zhang, Ankit Ankit, Hauke Gravenkamp, Sascha Eisentr\\\"ager,\n  Chongmin Song", "title": "A massively parallel explicit solver for elasto-dynamic problems\n  exploiting octree meshes", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2021.113811", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Typical areas of application of explicit dynamics are impact, crash test, and\nmost importantly, wave propagation simulations. Due to the numerically highly\ndemanding nature of these problems, efficient automatic mesh generators and\ntransient solvers are required. To this end, a parallel explicit solver\nexploiting the advantages of balanced octree meshes is introduced. To avoid the\nhanging nodes problem encountered in standard finite element analysis (FEA),\nthe scaled boundary finite element method (SBFEM) is deployed as a spatial\ndiscretization scheme. Consequently, arbitrarily shaped star-convex polyhedral\nelements are straightforwardly generated. Considering the scaling and\ntransformation of octree cells, the stiffness and mass matrices of a limited\nnumber of unique cell patterns are pre-computed. A recently proposed mass\nlumping technique is extended to 3D yielding a well-conditioned diagonal mass\nmatrix. This enables us to leverage the advantages of explicit time integrator,\ni.e., it is possible to efficiently compute the nodal displacements without the\nneed for solving a system of linear equations. We implement the proposed scheme\ntogether with a central difference method (CDM) in a distributed computing\nenvironment. The performance of our parallel explicit solver is evaluated by\nmeans of several numerical benchmark examples, including complex geometries and\nvarious practical applications. A significant speedup is observed for these\nexamples with up to one billion of degrees of freedom and running on up to\n16,384 computing cores.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 14:29:22 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zhang", "Junqi", ""], ["Ankit", "Ankit", ""], ["Gravenkamp", "Hauke", ""], ["Eisentr\u00e4ger", "Sascha", ""], ["Song", "Chongmin", ""]]}, {"id": "2103.09550", "submitter": "Nina Korshunova", "authors": "Nina Korshunova, Iason Papaioannou, Stefan Kollmannsberger, Daninel\n  Straub, Ernst Rank", "title": "Uncertainty quantification of microstructure variability and mechanical\n  behaviour of additively manufactured lattice structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Process-induced defects are the leading cause of discrepancies between\nas-designed and as-manufactured additive manufacturing (AM) product behavior.\nEspecially for metal lattices, the variations in the printed geometry cannot be\nneglected. Therefore, the evaluation of the influence of microstructural\nvariability on their mechanical behavior is crucial for the quality assessment\nof the produced structures. Commonly, the as-manufactured geometry can be\nobtained by computed tomography (CT). However, to incorporate all\nprocess-induced defects into the numerical analysis is often computationally\ndemanding. Thus, commonly this task is limited to a predefined set of\nconsidered variations, such as strut size or strut diameter. In this work, a\nCT-based binary random field is proposed to generate statistically equivalent\ngeometries of periodic metal lattices. The proposed random field model in\ncombination with the Finite Cell Method (FCM), an immersed boundary method,\nallows to efficiently evaluate the influence of the underlying microstructure\non the variability of the mechanical behavior of AM products. Numerical\nanalysis of two lattices manufactured at different scales shows an excellent\nagreement with experimental data. Furthermore, it provides a unique insight\ninto the effects of the process on the occurring geometrical variations and\nfinal mechanical behavior.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 10:26:52 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Korshunova", "Nina", ""], ["Papaioannou", "Iason", ""], ["Kollmannsberger", "Stefan", ""], ["Straub", "Daninel", ""], ["Rank", "Ernst", ""]]}, {"id": "2103.09790", "submitter": "Zhan Ma", "authors": "Zhan Ma, Wenxiao Pan", "title": "Data-driven nonintrusive reduced order modeling for dynamical systems\n  with moving boundaries using Gaussian process regression", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering, (2021) 373,\n  113495", "doi": "10.1016/j.cma.2020.113495", "report-no": null, "categories": "cs.CE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven nonintrusive model order reduction method for\ndynamical systems with moving boundaries. The proposed method draws on the\nproper orthogonal decomposition, Gaussian process regression, and moving least\nsquares interpolation. It combines several attributes that are not\nsimultaneously satisfied in the existing model order reduction methods for\ndynamical systems with moving boundaries. Specifically, the method requires\nonly snapshot data of state variables at discrete time instances and the\nparameters that characterize the boundaries, but not further knowledge of the\nfull-order model and the underlying governing equations. The dynamical systems\ncan be generally nonlinear. The movements of boundaries are not limited to\nprescribed or periodic motions but can be free motions. In addition, we\nnumerically investigate the ability of the reduced order model constructed by\nthe proposed method to forecast the full-order solutions for future times\nbeyond the range of snapshot data. The error analysis for the proposed reduced\norder modeling and the criteria to determine the furthest forecast time are\nalso provided. Through numerical experiments, we assess the accuracy and\nefficiency of the proposed method in several benchmark problems. The snapshot\ndata used to construct and validate the reduced order model are from\nanalytical/numerical solutions and experimental measurements.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 17:23:50 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Ma", "Zhan", ""], ["Pan", "Wenxiao", ""]]}, {"id": "2103.10203", "submitter": "Christian Gierden", "authors": "Christian Gierden, Johanna Waimann, Bob Svendsen, Stefanie Reese", "title": "A geometrically adapted reduced set of frequencies for a FFT-based\n  microstructure simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modified model order reduction (MOR) technique for the FFT-based\nsimulation of composite microstructures. It utilizes the earlier introduced MOR\ntechnique (Kochmann et al. [2019]), which is based on solving the\nLippmann-Schwinger equation in Fourier space by a reduced set of frequencies.\nCrucial for the accuracy of this MOR technique is on the one hand the amount of\nused frequencies and on the other hand the choice of frequencies used within\nthe simulation. Kochmann et al. [2019] defined the reduced set of frequencies\nby using a fixed sampling pattern, which is most general but leads to poor\nmicrostructural results when considering only a few frequencies. Consequently,\na reconstruction algorithm based on the TV1-algorithm [Candes et al., 2006] was\nused in a post-processing step to generate highly resolved micromechanical\nfields. The present work deals with a modified sampling pattern generation for\nthis MOR technique. Based on the idea, that the micromechanical material\nresponse strongly depends on the phase-wise material behavior, we propose the\nusage of sampling patterns adapted to the spatial arrangement of the individual\nphases. This leads to significantly improved microscopic and overall results.\nHence, the time-consuming reconstruction in the post-processing step that was\nnecessary in the earlier work is no longer required. To show the adaptability\nand robustness of this new choice of sampling patterns, several two dimensional\nexamples are investigated. In addition, also the 3D extension of the algorithm\nis presented.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 12:12:42 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Gierden", "Christian", ""], ["Waimann", "Johanna", ""], ["Svendsen", "Bob", ""], ["Reese", "Stefanie", ""]]}, {"id": "2103.10264", "submitter": "Shobhit Jain", "authors": "Shobhit Jain, George Haller", "title": "How to Compute Invariant Manifolds and their Reduced Dynamics in\n  High-Dimensional Finite-Element Models?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariant manifolds are important constructs for the quantitative and\nqualitative understanding of nonlinear phenomena in dynamical systems. In\nnonlinear damped mechanical systems, for instance, spectral submanifolds have\nemerged as useful tools for the computation of forced response curves, backbone\ncurves, detached resonance curves (isolas) via exact reduced-order models. For\nconservative nonlinear mechanical systems, Lyapunov subcenter manifolds and\ntheir reduced dynamics provide a way to identify nonlinear amplitude-frequency\nrelationships in the form of conservative backbone curves. Despite these\npowerful predictions offered by invariant manifolds, their use has largely been\nlimited to low-dimensional academic examples. This is because several\nchallenges render their computation unfeasible for realistic engineering\nstructures described by finite-element models. In this work, we address these\ncomputational challenges and develop methods for computing invariant manifolds\nand their reduced dynamics in very high-dimensional nonlinear systems arising\nfrom spatial discretization of the governing partial differential equations. We\nillustrate our computational algorithms on finite-element models of mechanical\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 14:01:11 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Jain", "Shobhit", ""], ["Haller", "George", ""]]}, {"id": "2103.10381", "submitter": "Zhan Ma", "authors": "Shu Wang, Zhan Ma, Wenxiao Pan", "title": "Data-driven Coarse-grained Modeling of Non-equilibrium Systems", "comments": "Large part of this paper needs to be revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling a high-dimensional Hamiltonian system in reduced dimensions with\nrespect to coarse-grained (CG) variables can greatly reduce computational cost\nand enable efficient bottom-up prediction of main features of the system for\nmany applications. However, it usually experiences significantly altered\ndynamics due to loss of degrees of freedom upon coarse-graining. To establish\nCG models that can faithfully preserve dynamics, previous efforts mainly\nfocused on equilibrium systems. In contrast, various soft matter systems are\nknown out of equilibrium. Therefore, the present work concerns non-equilibrium\nsystems and enables accurate and efficient CG modeling that preserves\nnon-equilibrium dynamics and is generally applicable to any non-equilibrium\nprocess and any observable of interest. To this end, the dynamic equation of a\nCG variable is built in the form of the non-stationary generalized Langevin\nequation (nsGLE) to account for the dependence of non-equilibrium processes on\nthe initial conditions, where the two-time memory kernel is determined from the\ndata of the two-time auto-correlation function of the non-equilibrium\ntrajectory-averaged observable of interest. By embedding the non-stationary\nnon-Markovian process in an extended stochastic framework, an explicit form of\nthe non-stationary random noise in the nsGLE is introduced, and the cost is\nsignificantly reduced for solving the nsGLE to predict the non-equilibrium\ndynamics of the CG variable. To prove and exploit the equivalence of the nsGLE\nand extended dynamics, the memory kernel is parameterized in a two-time\nexponential expansion. A data-driven hybrid optimization process is proposed\nfor the parameterization, a non-convex and high-dimensional optimization\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 17:10:13 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 15:06:49 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Wang", "Shu", ""], ["Ma", "Zhan", ""], ["Pan", "Wenxiao", ""]]}, {"id": "2103.10432", "submitter": "Yutong Xie", "authors": "Yutong Xie, Chence Shi, Hao Zhou, Yuwei Yang, Weinan Zhang, Yong Yu,\n  Lei Li", "title": "MARS: Markov Molecular Sampling for Multi-objective Drug Discovery", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching for novel molecules with desired chemical properties is crucial in\ndrug discovery. Existing work focuses on developing neural models to generate\neither molecular sequences or chemical graphs. However, it remains a big\nchallenge to find novel and diverse compounds satisfying several properties. In\nthis paper, we propose MARS, a method for multi-objective drug molecule\ndiscovery. MARS is based on the idea of generating the chemical candidates by\niteratively editing fragments of molecular graphs. To search for high-quality\ncandidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules\nwith an annealing scheme and an adaptive proposal. To further improve sample\nefficiency, MARS uses a graph neural network (GNN) to represent and select\ncandidate edits, where the GNN is trained on-the-fly with samples from MCMC.\nExperiments show that MARS achieves state-of-the-art performance in various\nmulti-objective settings where molecular bio-activity, drug-likeness, and\nsynthesizability are considered. Remarkably, in the most challenging setting\nwhere all four objectives are simultaneously optimized, our approach\noutperforms previous methods significantly in comprehensive evaluations. The\ncode is available at https://github.com/yutxie/mars.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 10:04:15 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Xie", "Yutong", ""], ["Shi", "Chence", ""], ["Zhou", "Hao", ""], ["Yang", "Yuwei", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Li", "Lei", ""]]}, {"id": "2103.10545", "submitter": "Alessandra Vizzaccaro Ms", "authors": "Andrea Opreni, Alessandra Vizzaccaro, Attilio Frangi, Cyril Touz\\'e", "title": "Model Order Reduction based on Direct Normal Form: Application to Large\n  Finite Element MEMS Structures Featuring Internal Resonance", "comments": "34 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA math.DS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dimensionality reduction in mechanical vibratory systems poses challenges for\ndistributed structures including geometric nonlinearities, mainly because of\nthe lack of invariance of the linear subspaces. A reduction method based on\ndirect normal form computation for large finite element (FE) models is here\ndetailed. The main advantage resides in operating directly from the physical\nspace, hence avoiding the computation of the complete eigenfunctions spectrum.\nExplicit solutions are given, thus enabling a fully non-intrusive version of\nthe reduction method. The reduced dynamics is obtained from the normal form of\nthe geometrically nonlinear mechanical problem, free of non-resonant monomials,\nand truncated to the selected master coordinates, thus making a direct link\nwith the parametrisation of invariant manifolds. The method is fully expressed\nwith a complex-valued formalism by detailing the homological equations in a\nsystematic manner, and the link with real-valued expressions is established. A\nspecial emphasis is put on the treatment of second-order internal resonances\nand the specific case of a 1:2 resonance is made explicit. Finally,\napplications to large-scale models of Micro-Electro-Mechanical structures\nfeaturing 1:2 and 1:3 resonances are reported, along with considerations on\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 22:14:22 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Opreni", "Andrea", ""], ["Vizzaccaro", "Alessandra", ""], ["Frangi", "Attilio", ""], ["Touz\u00e9", "Cyril", ""]]}, {"id": "2103.10578", "submitter": "Zhan Ma", "authors": "Zhan Ma, Shu Wang, Minhee Kim, Kaibo Liu, Chun-Long Chen, Wenxiao Pan", "title": "Transfer Learning of Memory Kernels in Coarse-grained Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work concerns the transferability of coarse-grained (CG) modeling\nin reproducing the dynamic properties of the reference atomistic systems across\na range of parameters. In particular, we focus on implicit-solvent CG modeling\nof polymer solutions. The CG model is based on the generalized Langevin\nequation, where the memory kernel plays the critical role in determining the\ndynamics in all time scales. Thus, we propose methods for transfer learning of\nmemory kernels. The key ingredient of our methods is Gaussian process\nregression. By integration with the model order reduction via proper orthogonal\ndecomposition and the active learning technique, the transfer learning can be\npractically efficient and requires minimum training data. Through two example\npolymer solution systems, we demonstrate the accuracy and efficiency of the\nproposed transfer learning methods in the construction of transferable memory\nkernels. The transferability allows for out-of-sample predictions, even in the\nextrapolated domain of parameters. Built on the transferable memory kernels,\nthe CG models can reproduce the dynamic properties of polymers in all time\nscales at different thermodynamic conditions (such as temperature and solvent\nviscosity) and for different systems with varying concentrations and lengths of\npolymers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 01:05:14 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Ma", "Zhan", ""], ["Wang", "Shu", ""], ["Kim", "Minhee", ""], ["Liu", "Kaibo", ""], ["Chen", "Chun-Long", ""], ["Pan", "Wenxiao", ""]]}, {"id": "2103.10872", "submitter": "Anton V. Proskurnikov", "authors": "Giuseppe Calafiore, Giulia Fracastoro, and Anton V. Proskurnikov", "title": "Optimal Clearing Payments in a Financial Contagion Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern financial networks are characterized by complex structures of mutual\nobligations. Such interconnections may propagate and amplificate individual\ndefaults, leading in some cases to financial disaster. For this reason,\nmathematical models for the study and control of systemic risk (the risk of\nsevere instabilities on the system as a whole, due to default of single\nentities) have attracted considerable research attention in recent years. One\nimportant line of research is concerned with mechanisms of clearing, that is,\nthe mechanism by which mutual debts are repaid, in the regular regime, or in a\ndefault regime. One of the first models of a clearing mechanism was proposed by\nEisenberg and Noe and is based on the three rules: limited liability, the\npriority of debt claims over the shareholders' interests, and the equal\npriority of debts (pro-rata rule). These three principles naturally lead to the\nconcept of clearing vector (the vector of the entities' total payments). In\nthis paper, we propose a necessary and sufficient condition for the uniqueness\nof clearing vector applicable to an arbitrary topology of the financial\nnetwork. Further, we show that the overall system loss can be reduced if one\nrelaxes the pro-rata rule and replaces the clearing vector by a matrix of\nclearing payments. This approach shifts the focus from the individual interest\nto the system, or social, interest, in order to control and contain the adverse\neffects of cascaded failures.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 15:50:47 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Calafiore", "Giuseppe", ""], ["Fracastoro", "Giulia", ""], ["Proskurnikov", "Anton V.", ""]]}, {"id": "2103.10958", "submitter": "Kerstin D\\\"achert", "authors": "Kerstin D\\\"achert, Ria Grindel, Elisabeth Leoff, Jonas Mahnkopp,\n  Florian Schirra and J\\\"org Wenzel", "title": "Multicriteria asset allocation in practice", "comments": "24 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.PM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we consider the strategic asset allocation of an insurance\ncompany. This task can be seen as a special case of portfolio optimization. In\nthe 1950s, Markowitz proposed to formulate portfolio optimization as a\nbicriteria optimization problem considering risk and return as objectives.\nHowever, recent developments in the field of insurance require four and more\nobjectives to be considered, among them the so-called solvency ratio that stems\nfrom the Solvency II directive of the European Union issued in 2009. Moreover,\nthe distance to the current portfolio plays an important role. While literature\non portfolio optimization with three objectives is already scarce, applications\nwith four and more objectives have not yet been solved so far by\nmulti-objective approaches based on scalarizations. However, recent algorithmic\nimprovements in the field of exact multi-objective methods allow the\nincorporation of many objectives and the generation of well-spread\nrepresentations within few iterations. We describe the implementation of such\nan algorithm for a strategic asset allocation with four objective functions and\ndemonstrate its usefulness for the practitioner. Our approach is in operative\nuse in a German insurance company. Our partners report a significant\nimprovement in their decision making process since, due to the proper\nintegration of the new objectives, the software proposes portfolios of much\nbetter quality than before within short running time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 15:42:08 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["D\u00e4chert", "Kerstin", ""], ["Grindel", "Ria", ""], ["Leoff", "Elisabeth", ""], ["Mahnkopp", "Jonas", ""], ["Schirra", "Florian", ""], ["Wenzel", "J\u00f6rg", ""]]}, {"id": "2103.11341", "submitter": "Dave Cliff", "authors": "Dave Cliff", "title": "Parameterised-Response Zero-Intelligence Traders", "comments": "39 pages, 18 figures, 67 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.GT cs.MA econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce PRZI (Parameterised-Response Zero Intelligence), a new form of\nzero-intelligence trader intended for use in simulation studies of auction\nmarkets. Like Gode & Sunder's classic Zero-Intelligence Constrained (ZIC)\ntrader, PRZI generates quote-prices from a random distribution over some\nspecified domain of discretely-valued allowable quote-prices. Unlike ZIC, which\nuses a uniform distribution to generate prices, the probability distribution in\na PRZI trader is parameterised in such a way that its probability mass function\n(PMF) is determined by a real-valued control variable s in the range [-1.0,\n+1.0] that determines the strategy for that trader. When s is zero, a PRZI\ntrader behaves identically to the ZIC strategy, with a flat/rectangular PMF;\nbut when s is close to plus or minus one the PRZI trader's PMF becomes\nasymptotically maximally skewed to one extreme or the other of the price-range,\nthereby enabling the PRZI trader to act in the same way as the \"Shaver\"\nstrategy (SHVR) or the \"Giveaway\" strategy (GVWY), both of which have recently\nbeen demonstrated to be surprisingly dominant over more sophisticated, and\nsupposedly more profitable, trader-strategies that incorporate adaptive\nmechanisms and machine learning. Depending on the value of s, a PRZI trader\nwill behave either as a ZIC, or as a SHVR, or as a GVWY, or as some hybrid\nstrategy part-way between two of these three previously-reported strategies.\nThe novel smoothly-varying strategy in PRZI has value in giving trader-agents\nplausibly useful \"market impact\" responses to imbalances in an auction-market's\nlimit-order-book, and also allows for the study of co-adaptive dynamics in\ncontinuous strategy-spaces rather than the discrete spaces that have\ntraditionally been studied in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 08:43:39 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 19:09:48 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 13:53:31 GMT"}, {"version": "v4", "created": "Wed, 14 Jul 2021 21:43:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cliff", "Dave", ""]]}, {"id": "2103.11730", "submitter": "Hermes Sampedro Llopis Mr.", "authors": "Hermes Sampedro Llopis, Allan P. Engsig-Karup, Cheol-Ho Jeong, Finnur\n  Pind and Jan S. Hesthaven", "title": "Efficient numerical room acoustic simulations with parametrized\n  boundaries using the spectral element and reduced basis method", "comments": "14 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Numerical methods can be used to simulate wave propagation in rooms, with\napplications in virtual reality and building design. Such methods can be highly\naccurate but computationally expensive when simulating high frequencies and\nlarge domains for long simulation times. Moreover, it is common that solutions\nare sought for multiple input parameter values, e.g., in design processes in\nroom acoustics, where different boundary absorption properties are evaluated\niteratively. We present a framework that combines a spectral element method\n(SEM) and a reduced basis method (RBM) to achieve a computational cost\nreduction for parameterized room acoustic simulations. The SEM provides low\ndispersion and dissipation properties due to the high-order discretization and\nthe RBM reduces the computational burden further when parametrizing the\nboundary properties for both frequency-independent and dependent conditions.\nThe problem is solved in the Laplace domain, which avoids instability issues on\nthe reduced model. We demonstrate that the use of high-order discretization and\nmodel order reduction has significant advantages for room acoustics in terms of\ncomputational efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 11:13:21 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Llopis", "Hermes Sampedro", ""], ["Engsig-Karup", "Allan P.", ""], ["Jeong", "Cheol-Ho", ""], ["Pind", "Finnur", ""], ["Hesthaven", "Jan S.", ""]]}, {"id": "2103.13110", "submitter": "Jonas F. Eichinger", "authors": "Jonas F. Eichinger, Maximilian J. Grill, Iman Davoodi Kermani, Roland\n  C. Aydin, Wolfgang A. Wall, Jay D. Humphrey, Christian J. Cyron", "title": "A computational framework for modeling cell-matrix interactions in soft\n  biological tissues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living soft tissues appear to promote the development and maintenance of a\npreferred mechanical state within a defined tolerance around a so-called\nset-point. This phenomenon is often referred to as mechanical homeostasis. In\ncontradiction to the prominent role of mechanical homeostasis in various\n(patho)physiological processes, its underlying micromechanical mechanisms\nacting on the level of individual cells and fibers remain poorly understood,\nespecially, how these mechanisms on the microscale lead to what we\nmacroscopically call mechanical homeostasis. Here, we present a novel finite\nelement based computational framework that is constructed bottom up, that is,\nit models key mechanobiological mechanisms such as actin cytoskeleton\ncontraction and molecular clutch behavior of individual cells interacting with\na reconstructed three-dimensional extracellular fiber matrix. The framework\nreproduces many experimental observations regarding mechanical homeostasis on\nshort time scales (hours), in which the deposition and degradation of\nextracellular matrix can largely be neglected. This model can serve as a\nsystematic tool for future in silico studies of the origin of the numerous\nstill unexplained experimental observations about mechanical homeostasis.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 11:31:21 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Eichinger", "Jonas F.", ""], ["Grill", "Maximilian J.", ""], ["Kermani", "Iman Davoodi", ""], ["Aydin", "Roland C.", ""], ["Wall", "Wolfgang A.", ""], ["Humphrey", "Jay D.", ""], ["Cyron", "Christian J.", ""]]}, {"id": "2103.14036", "submitter": "David Smith", "authors": "David Smith, Frederik Geth, Elliott Vercoe, Andrew Feutrill, Ming\n  Ding, Jonathan Chan, James Foster and Thierry Rakotoarivelo", "title": "Realistic Differentially-Private Transmission Power Flow Data Release", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the modeling, design and planning of future energy transmission networks,\nit is vital for stakeholders to access faithful and useful power flow data,\nwhile provably maintaining the privacy of business confidentiality of service\nproviders. This critical challenge has recently been somewhat addressed in [1].\nThis paper significantly extends this existing work. First, we reduce the\npotential leakage information by proposing a fundamentally different\npost-processing method, using public information of grid losses rather than\npower dispatch, which achieve a higher level of privacy protection. Second, we\nprotect more sensitive parameters, i.e., branch shunt susceptance in addition\nto series impedance (complete pi-model). This protects power flow data for the\ntransmission high-voltage networks, using differentially private\ntransformations that maintain the optimal power flow consistent with, and\nfaithful to, expected model behaviour. Third, we tested our approach at a\nlarger scale than previous work, using the PGLib-OPF test cases [10]. This\nresulted in the successful obfuscation of up to a 4700-bus system, which can be\nsuccessfully solved with faithfulness of parameters and good utility to data\nanalysts. Our approach addresses a more feasible and realistic scenario, and\nprovides higher than state-of-the-art privacy guarantees, while maintaining\nsolvability, fidelity and feasibility of the system.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 04:04:12 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Smith", "David", ""], ["Geth", "Frederik", ""], ["Vercoe", "Elliott", ""], ["Feutrill", "Andrew", ""], ["Ding", "Ming", ""], ["Chan", "Jonathan", ""], ["Foster", "James", ""], ["Rakotoarivelo", "Thierry", ""]]}, {"id": "2103.14404", "submitter": "Yang Su Mr.", "authors": "Yang Su and Damith C. Ranasinghe", "title": "ReaDmE: Read-Rate Based Dynamic Execution Scheduling for Intermittent\n  RF-Powered Devices", "comments": "Accepted by IEEE RFID 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for remotely and dynamically determining the\nexecution schedule of long-running tasks on intermittently powered devices such\nas computational RFID. Our objective is to prevent brown-out events caused by\nsudden power-loss due to the intermittent nature of the powering channel. We\nformulate, validate and demonstrate that the read-rate measured from an RFID\nreader (number of successful interrogations per second) can provide an adequate\nmeans of estimating the powering channel condition for passively powered CRFID\ndevices. This method is attractive because it can be implemented without\nimposing an added burden on the device or requiring additional hardware. We\nfurther propose ReaDmE, a dynamic execution scheduling scheme to mitigate\nbrownout events to support long-run execution of complex tasks, such as\ncryptographic algorithms, on CRFID. Experimental results demonstrate that the\nReaDmE method can improve CRFID's long-run execution success rate by 20% at the\ncritical operational range or reduce time overhead by up to 23% compared to\nprevious execution scheduling methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 11:22:56 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 05:33:14 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Su", "Yang", ""], ["Ranasinghe", "Damith C.", ""]]}, {"id": "2103.14735", "submitter": "Peter Marvin Muller", "authors": "Peter Marvin M\\\"uller, Niklas K\\\"uhl, Martin Siebenborn, Klaus\n  Deckelnick, Michael Hinze, Thomas Rung", "title": "A Novel $p$-Harmonic Descent Approach Applied to Fluid Dynamic Shape\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel method for the implementation of shape optimziation in\nfluid dynamics applications, where we propose to use the shape derivative to\ndetermine deformation fields with the help of the $p-$ Laplacian for $p > 2$.\nThis approach is closely related to the computation of steepest descent\ndirections of the shape functional in the $W^{1,\\infty}-$ topology. Our\napproach is demonstrated for shape optimization related to drag-minimal free\nfloating bodies. The method is validated against existing approaches with\nrespect to convergence of the optimization algorithm, the obtained shape, and\nregarding the quality of the computational grid after large deformations. Our\nnumerical results strongly indicate that shape optimization related to the\n$W^{1,\\infty}$-topology -- though numerically more demanding -- seems to be\nsuperior over the classical approaches invoking Hilbert space methods,\nconcerning the convergence, the obtained shapes and the mesh quality after\nlarge deformations, in particular when the optimal shape features sharp\ncorners.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 21:06:35 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["M\u00fcller", "Peter Marvin", ""], ["K\u00fchl", "Niklas", ""], ["Siebenborn", "Martin", ""], ["Deckelnick", "Klaus", ""], ["Hinze", "Michael", ""], ["Rung", "Thomas", ""]]}, {"id": "2103.15481", "submitter": "Di Zuo", "authors": "Di Zuo, Yiqian He, St\\'ephane Avril, Haitian Yang, Klaus Hackl", "title": "A thermodynamic framework for unified continuum models for the healing\n  of damaged soft biological tissue", "comments": "42 pages, 17 figures, 3 tables, submit to Journal of the Mechanics\n  and Physics of Solids", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.med-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When they are damaged or injured, soft biological tissues are able to\nself-repair and heal. Mechanics is critical during the healing process, as the\ndamaged extracellular matrix (ECM) tends to be replaced with a new undamaged\nECM supporting homeostatic stresses. Computational modeling has been commonly\nused to simulate the healing process. However, there is a pressing need to have\na unified thermodynamics theory for healing. From the viewpoint of continuum\ndamage mechanics, some key parameters related to healing processes, for\ninstance, the volume fraction of newly grown soft tissue and the growth\ndeformation, can be regarded as internal variables and have related evolution\nequations. This paper is aiming to establish this unified framework inspired by\nthermodynamics for continuum damage models for the healing of soft biological\ntissues. The significant advantage of the proposed model is that no \\textit{ad\nhoc} equations are required for describing the healing process. Therefore, this\nnew model is more concise and offers a universal approach to simulate the\nhealing process. Three numerical examples are provided to demonstrate the\neffectiveness of the proposed model, which is in good agreement with the\nexisting works, including an application for balloon angioplasty in an\narteriosclerotic artery with a fiber cap.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 10:34:25 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zuo", "Di", ""], ["He", "Yiqian", ""], ["Avril", "St\u00e9phane", ""], ["Yang", "Haitian", ""], ["Hackl", "Klaus", ""]]}, {"id": "2103.15493", "submitter": "Benjamin Marussig", "authors": "A. Borkovi\\'c, B. Marussig, and G. Radenkovi\\'c", "title": "Geometrically exact static isogeometric analysis of arbitrarily curved\n  plane Bernoulli-Euler beam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a geometrically exact nonlinear analysis of elastic in-plane beams\nin the context of finite but small strain theory. The formulation utilizes the\nfull beam metric and obtains the complete analytic elastic constitutive model\nby employing the exact relation between the reference and equidistant strains.\nThus, we account for the nonlinear strain distribution over the thickness of a\nbeam. In addition to the full analytical constitutive model, four simplified\nones are presented. Their comparison provides a thorough examination of the\ninfluence of a beam's metric on the structural response. We show that the\nappropriate formulation depends on the curviness of a beam at all\nconfigurations. Furthermore, the nonlinear distribution of strain along the\nthickness of strongly curved beams must be considered to obtain a complete and\naccurate response.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 10:51:20 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Borkovi\u0107", "A.", ""], ["Marussig", "B.", ""], ["Radenkovi\u0107", "G.", ""]]}, {"id": "2103.16120", "submitter": "Jan Ackmann", "authors": "Jan Ackmann, Peter D. D\\\"uben, Tim N. Palmer, Piotr K. Smolarkiewicz", "title": "Mixed-precision for Linear Solvers in Global Geophysical Flows", "comments": "38 pages, 12 figures; to be submitted to the Journal of Computational\n  Physics (JCP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA math.NA physics.ao-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-implicit time-stepping schemes for atmosphere and ocean models require\nelliptic solvers that work efficiently on modern supercomputers. This paper\nreports our study of the potential computational savings when using mixed\nprecision arithmetic in the elliptic solvers. The essential components of a\nrepresentative elliptic solver are run at precision levels as low as half (16\nbits), and accompanied with a detailed evaluation of the impact of reduced\nprecision on the solver convergence and the solution quality.\n  A detailed inquiry into reduced precision requires a model configuration that\nis meaningful but cheaper to run and easier to evaluate than full\natmosphere/ocean models. This study is therefore conducted in the context of a\nnovel semi-implicit shallow-water model on the sphere, purposely designed to\nmimic numerical intricacies of modern all-scale weather and climate (W&C)\nmodels with the numerical stability independent on celerity of all wave\nmotions. The governing algorithm of the shallow-water model is based on the\nnon-oscillatory MPDATA methods for geophysical flows, whereas the resulting\nelliptic problem employs a strongly preconditioned non-symmetric\nKrylov-subspace solver GCR, proven in advanced atmospheric applications. The\nclassical longitude/latitude grid is deliberately chosen to retain the\nstiffness of global W&C models posed in thin spherical shells as well as to\nbetter understand the performance of reduced-precision arithmetic in the\nvicinity of grid singularities. Precision reduction is done on a software\nlevel, using an emulator. The reduced-precision experiments are conducted for\nestablished dynamical-core test-cases, like the Rossby-Haurwitz wave number 4\nand a zonal orographic flow.\n  The study shows that selected key components of the elliptic solver, most\nprominently the preconditioning, can be performed at the level of half\nprecision.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 07:11:26 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ackmann", "Jan", ""], ["D\u00fcben", "Peter D.", ""], ["Palmer", "Tim N.", ""], ["Smolarkiewicz", "Piotr K.", ""]]}, {"id": "2103.16202", "submitter": "Pedro D\\'iez", "authors": "Marc Rocas, Alberto Garc\\'ia-Gonz\\'alez, Xabier Larrayoz and Pedro\n  D\\'iez", "title": "Adaptive surrogates of crashworthiness models for multi-purpose\n  engineering analyses accounting for uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty Quantification (UQ) is a booming discipline for complex\ncomputational models based on the analysis of robustness, reliability and\ncredibility. UQ analysis for nonlinear crash models with high dimensional\noutputs presents important challenges. In crashworthiness, nonlinear structural\nbehaviours with multiple hidden modes require expensive models (18 hours for a\nsingle run). Surrogate models (metamodels) allow substituting the full order\nmodel, introducing a response surface for a reduced training set of numerical\nexperiments. Moreover, uncertain input and large number of degrees of freedom\nresult in high dimensional problems, which derives to a bottle neck that blocks\nthe computational efficiency of the metamodels. Kernel Principal Component\nAnalysis (kPCA) is a multidimensionality reduction technique for non-linear\nproblems, with the advantage of capturing the most relevant information from\nthe response and improving the efficiency of the metamodel. Aiming to compute\nthe minimum number of samples with the full order model. The proposed\nmethodology is tested with a practical industrial problem that arises from the\nautomotive industry.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 09:36:09 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Rocas", "Marc", ""], ["Garc\u00eda-Gonz\u00e1lez", "Alberto", ""], ["Larrayoz", "Xabier", ""], ["D\u00edez", "Pedro", ""]]}, {"id": "2103.16312", "submitter": "Khodr Jaber", "authors": "Khodr Jaber", "title": "FastCTF: A Robust Solver for Conduction Transfer Function Coefficients\n  and Thermal Response Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Conduction transfer functions (CTF) are commonly used in the building\nservices to quickly estimate hourly conduction heat loads through multilayered\nwalls without resorting to expensive, time-consuming solutions of the heat\nequation. It is essential for any software developed for this purpose to be\nable to simulate walls of varying weight with a high degree of accuracy. A\nrobust algorithm for computing CTF coefficients and thermal response factors\nbased on power series expansions of solutions of the governing equations in the\ncomplex s-domain is presented and validated. These series expansions are used\nto to construct Pad\\'e approximants of the system's transfer functions, which\ngreatly simplifies the inversion of the solution from the complex domain to the\ntime domain, and allows for an easy recovery of a time series representation\nvia the Z-transform. The algorithm is also implemented in an open-source C++\ncode. Its performance is validated with respect to exact theoretical frequency\ncharacteristics and its results are compared with data generated by previously\nestablished methods for computing CTF coefficients / response factors.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:03:36 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Jaber", "Khodr", ""]]}, {"id": "2103.16345", "submitter": "Nicolas Moes", "authors": "Nicolas Moes and Nicolas Chevaugeon", "title": "Lipschitz regularization for softening material models: the Lip-field\n  approach", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Softening material models are known to trigger spurious localizations.This\nmay be shown theoretically by the existence of solutions with zero dissipation\nwhen localization occurs and numerically with spurious mesh dependency and\nlocalization in a single layer of elements. We introduce in this paper a new\nway to avoid spurious localization. The idea is to enforce a Lipschitz\nregularity on the internal variables responsible for the material softening.\nThe regularity constraint introduces the needed length scale in the material\nformulation. Moreover, we prove bounds on the domain affected by this\nconstraint. A first one-dimensional finite element implementation is proposed\nfor softening elasticity and softening plasticity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 13:43:05 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 12:40:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Moes", "Nicolas", ""], ["Chevaugeon", "Nicolas", ""]]}, {"id": "2103.16409", "submitter": "Zissis Poulos", "authors": "Jay Cao, Jacky Chen, John Hull, Zissis Poulos", "title": "Deep Hedging of Derivatives Using Reinforcement Learning", "comments": "21 pages, 3 figures, 4 tables", "journal-ref": "The Journal of Financial Data Science Winter 2021, 3 (1) 10-27", "doi": "10.3905/jfds.2020.1.052", "report-no": null, "categories": "q-fin.CP cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper shows how reinforcement learning can be used to derive optimal\nhedging strategies for derivatives when there are transaction costs. The paper\nillustrates the approach by showing the difference between using delta hedging\nand optimal hedging for a short position in a call option when the objective is\nto minimize a function equal to the mean hedging cost plus a constant times the\nstandard deviation of the hedging cost. Two situations are considered. In the\nfirst, the asset price follows a geometric Brownian motion. In the second, the\nasset price follows a stochastic volatility process. The paper extends the\nbasic reinforcement learning approach in a number of ways. First, it uses two\ndifferent Q-functions so that both the expected value of the cost and the\nexpected value of the square of the cost are tracked for different state/action\ncombinations. This approach increases the range of objective functions that can\nbe used. Second, it uses a learning algorithm that allows for continuous state\nand action space. Third, it compares the accounting P&L approach (where the\nhedged position is valued at each step) and the cash flow approach (where cash\ninflows and outflows are used). We find that a hybrid approach involving the\nuse of an accounting P&L approach that incorporates a relatively simple\nvaluation model works well. The valuation model does not have to correspond to\nthe process assumed for the underlying asset price.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 07:43:30 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Cao", "Jay", ""], ["Chen", "Jacky", ""], ["Hull", "John", ""], ["Poulos", "Zissis", ""]]}, {"id": "2103.16841", "submitter": "Martin Schanz", "authors": "Dominik P\\\"olz and Martin Schanz", "title": "On the space-time discretization of variational retarded potential\n  boundary integral equations", "comments": "submitted to Computers and Mathematics with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the practical development of space-time boundary element\nmethods for the wave equation in three spatial dimensions. The employed trial\nspaces stem from simplex meshes of the lateral boundary of the space-time\ncylinder. This approach conforms genuinely to the distinguished structure of\nthe solution operators of the wave equation, so-called retarded potentials.\nSince the numerical evaluation of the arising integrals is intricate, the bulk\nof this work is constituted by ideas about quadrature techniques for retarded\nlayer potentials and associated energetic bilinear forms. Finally, we glimpse\nat algorithmic aspects regarding the efficient implementation of retarded\npotentials in the space-time setting. The proposed methods are verified by\nmeans of numerical experiments, which illustrate their capacity.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 06:48:52 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["P\u00f6lz", "Dominik", ""], ["Schanz", "Martin", ""]]}, {"id": "2103.16982", "submitter": "Sebastian Fuchs", "authors": "Christoph Meier, Sebastian L. Fuchs, Nils Much, Jonas Nitzler, Ryan W.\n  Penny, Patrick M. Praegla, Sebastian D. Pr\\\"oll, Yushen Sun, Reimar\n  Weissbach, Magdalena Schreter, Neil E. Hodge, A. John Hart, Wolfgang A. Wall", "title": "Physics-Based Modeling and Predictive Simulation of Powder Bed Fusion\n  Additive Manufacturing Across Length Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powder bed fusion additive manufacturing (PBFAM) of metals has the potential\nto enable new paradigms of product design, manufacturing and supply chains\nwhile accelerating the realization of new technologies in the medical,\naerospace, and other industries. Currently, wider adoption of PBFAM is held\nback by difficulty in part qualification, high production costs and low\nproduction rates, as extensive process tuning, post-processing, and inspection\nare required before a final part can be produced and deployed. Physics-based\nmodeling and predictive simulation of PBFAM offers the potential to advance\nfundamental understanding of physical mechanisms that initiate process\ninstabilities and cause defects. In turn, these insights can help link process\nand feedstock parameters with resulting part and material properties, thereby\npredicting optimal processing conditions and inspiring the development of\nimproved processing hardware, strategies and materials. This work presents\nrecent developments of our research team in the modeling of metal PBFAM\nprocesses spanning length scales, namely mesoscale powder modeling, mesoscale\nmelt pool modeling, macroscale thermo-solid-mechanical modeling and\nmicrostructure modeling. Ongoing work in experimental validation of these\nmodels is also summarized. In conclusion, we discuss the interplay of these\nindividual submodels within an integrated overall modeling approach, along with\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 11:00:04 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 16:44:37 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Meier", "Christoph", ""], ["Fuchs", "Sebastian L.", ""], ["Much", "Nils", ""], ["Nitzler", "Jonas", ""], ["Penny", "Ryan W.", ""], ["Praegla", "Patrick M.", ""], ["Pr\u00f6ll", "Sebastian D.", ""], ["Sun", "Yushen", ""], ["Weissbach", "Reimar", ""], ["Schreter", "Magdalena", ""], ["Hodge", "Neil E.", ""], ["Hart", "A. John", ""], ["Wall", "Wolfgang A.", ""]]}]