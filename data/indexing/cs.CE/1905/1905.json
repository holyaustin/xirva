[{"id": "1905.00240", "submitter": "Xin Bian", "authors": "Xin Bian and Sergey Litvinov and Petros Koumoutsakos", "title": "Bending models of lipid bilayer membranes: spontaneous curvature and\n  area-difference elasticity", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.112758", "report-no": null, "categories": "cs.CE cond-mat.soft math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We preset a computational study of bending models for the curvature\nelasticity of lipid bilayer membranes that are relevant for simulations of\nvesicles and red blood cells. We compute bending energy and forces on\ntriangulated meshes and evaluate and extend four well established schemes for\ntheir approximation: Kantor and Nelson 1987, Phys. Rev. A 36, 4020, J\\\"ulicher\n1996, J. Phys. II France 6, 1797, Gompper and Kroll 1996, J. Phys. I France 6,\n1305, and Meyer et. al. 2003 in Visualization and Mathematics III, Springer,\np35, termed A, B, C, D. We present a comparative study of these four schemes on\nthe minimal bending model and propose extensions for schemes B, C and D. These\nextensions incorporate the reference state and non-local energy to account for\nthe spontaneous curvature, bilayer coupling, and area-difference elasticity\nmodels. Our results indicate that the proposed extensions enhance the models to\naccount for shape transformation including budding/vesiculation as well as for\nnon-axisymmetric shapes. We find that the extended scheme B is superior to the\nrest in terms of accuracy, and robustness as well as simplicity of\nimplementation. We demonstrate the capabilities of this scheme on several\nbenchmark problems including the budding-vesiculating process and the\nreproduction of the phase diagram of vesicles.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 09:53:17 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Bian", "Xin", ""], ["Litvinov", "Sergey", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1905.00482", "submitter": "Kapil Khandelwal", "authors": "Guodong Zhang and Kapil Khandelwal", "title": "Computational Design of Finite Strain Auxetic Metamaterials via Topology\n  Optimization and Nonlinear Homogenization", "comments": "54 pages, 29 figures", "journal-ref": null, "doi": "10.1016/j.cma.2019.07.027", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A novel computational framework for designing metamaterials with negative\nPoisson's ratio over a large strain range is presented in this work by\ncombining the density-based topology optimization together with a mixed\nstress/deformation driven nonlinear homogenization method. A measure of\nPoisson's ratio based on the macro deformations is proposed, which is further\nvalidated through direct numerical simulations. With the consistent\noptimization formulations based on nonlinear homogenization, auxetic\nmetamaterial designs with respect to different loading orientations and with\ndifferent unit cell domains are systematically explored. In addition, the\nextension to multimaterial auxetic metamaterial designs is also considered, and\nstable optimization formulations are presented to obtain discrete metamaterial\ntopologies under finite strains. Various new auxetic designs are obtained based\non the proposed framework. To validate the performance of optimized designs, a\nmultiscale stability analysis is carried out using the Bloch wave method and\nrank-one convexity check. As demonstrated, short and/or long wavelength\ninstabilities can occur during the loading process, leading to a change of\nperiodicity of the microstructure, which can affect the performance of an\noptimized design.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 22:04:23 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Zhang", "Guodong", ""], ["Khandelwal", "Kapil", ""]]}, {"id": "1905.01472", "submitter": "Faissal El Bouanani", "authors": "Elmehdi Illi, Faissal El Bouanani, Ki-Hong Park, Fouad Ayoub,\n  Mohamed-Slim Alouini", "title": "An Improved Accurate Solver for the Time-Dependent RTE in Underwater\n  Optical Wireless Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an improved numerical solver to evaluate the time-dependent\nradiative transfer equation (RTE) for underwater optical wireless\ncommunications (UOWC) is investigated. The RTE evaluates the optical path-loss\nof light wave in an underwater channel in terms of the inherent optical\nproperties related to the environments, namely the absorption and scattering\ncoefficients as well as the phase scattering function (PSF). The proposed\nnumerical algorithm was improved based on the ones proposed in [1]-[4], by\nmodifying the finite difference scheme proposed in [1] as well as an\nenhancement of the quadrature method proposed in [2] by involving a more\naccurate 7-points quadrature scheme in order to calculate the quadrature weight\ncoefficients corresponding to the integral term of the RTE. Furthermore, the\nscattering angular discretization algorithm used in [3] and [4] was modified,\nbased on which the receiver's field of view discretization was adapted\ncorrespondingly. Interestingly, the RTE solver has been applied to three volume\nscattering functions, namely: the single-term HG phase function, the two-term\nHG phase function [5], and the Fournier-Forand phase function [6], over\nHarbor-I and Harbor-II water types. Based on the normalized received power\nevaluated through the proposed algorithm, the bit error rate performance of the\nUOWC system is investigated in terms of system and channel parameters. The\nenhanced algorithm gives a tightly close performance to its Monte Carlo\ncounterpart improved based on the simulations provided in [7], by adjusting the\nnumerical cumulative distribution function computation method as well as\noptimizing the number of scattering angles. Matlab codes for the proposed RTE\nsolver are presented in [8].\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 10:29:02 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Illi", "Elmehdi", ""], ["Bouanani", "Faissal El", ""], ["Park", "Ki-Hong", ""], ["Ayoub", "Fouad", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "1905.01982", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Firas A. Khasawneh, Andreas Otto", "title": "On Transfer Learning For Chatter Detection in Turning Using Wavelet\n  Packet Transform and Empirical Mode Decomposition", "comments": "Informative wavelet packet numbers were edited with respect to\n  frequency ordering in section 3. Three more supervised learning algorithms\n  were added to compare performance of both method (see section 5 and 6). For\n  transfer learning, results of the application where classifiers are trained\n  with two different stickout size data and tested on remaining cases were\n  added into section 6.3", "journal-ref": null, "doi": "10.1016/j.cirpj.2019.11.003", "report-no": null, "categories": "eess.SP cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing availability of sensor data at machine tools makes automatic\nchatter detection algorithms a trending topic in metal cutting. Two prominent\nand advanced methods for feature extraction via signal decomposition are\nWavelet Packet Transform (WPT) and Ensemble Empirical Mode Decomposition\n(EEMD). We apply these two methods to time series acquired from an acceleration\nsensor at the tool holder of a lathe. Different turning experiments with\nvarying dynamic behavior of the machine tool structure were performed. We\ncompare the performance of these two methods with Support Vector Machine (SVM),\nLogistic Regression, Random Forest Classification and Gradient Boosting\ncombined with Recursive Feature Elimination (RFE). We also show that the common\nWPT-based approach of choosing wavelet packets with the highest energy ratios\nas representative features for chatter does not always result in packets that\nenclose the chatter frequency, thus reducing the classification accuracy.\nFurther, we test the transfer learning capability of each of these methods by\ntraining the classifier on one of the cutting configurations and then testing\nit on the other cases. It is found that when training and testing on data from\nthe same cutting configuration both methods yield high accuracies reaching in\none of the cases as high as 94% and 95%, respectively, for WPT and EEMD.\nHowever, our experimental results show that EEMD can outperform WPT in transfer\nlearning applications with accuracy of up to 95%.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:11:23 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 20:38:21 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Khasawneh", "Firas A.", ""], ["Otto", "Andreas", ""]]}, {"id": "1905.02080", "submitter": "Emanuele Grifoni", "authors": "Emanuele Grifoni, GiovanniMaria Piccini and Michele Parrinello", "title": "A microscopic description of acid-base equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acid-base reactions are ubiquitous in nature. Understanding their mechanisms\nis crucial in many fields, from biochemistry to industrial catalysis.\nUnfortunately, experiments only give limited information without much insight\ninto the molecular behaviour. Atomistic simulations could complement\nexperiments and shed precious light on microscopic mechanisms. The large free\nenergy barriers connected to proton dissociation however make the use of\nenhanced sampling methods mandatory. Here we perform an ab initio molecular\ndynamics (MD) simulation and enhance sampling with the help of methadynamics.\nThis has been made possible by the introduction of novel descriptors or\ncollective variables (CVs) that are based on a conceptually new outlook on\nacid-base equilibria. We test successfully our approach on three different\naqueous solutions of acetic acid, ammonia, and bicarbonate. These are\nrepresentative of acid, basic, and amphoteric behaviour.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 22:56:25 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Grifoni", "Emanuele", ""], ["Piccini", "GiovanniMaria", ""], ["Parrinello", "Michele", ""]]}, {"id": "1905.02135", "submitter": "Junxi Feng", "authors": "Junxi Feng, Xiaohai He, Qizhi Teng, Chao Ren, Honggang Chen, Yang Li", "title": "Accurate and Fast reconstruction of Porous Media from Extremely Limited\n  Information Using Conditional Generative Adversarial Network", "comments": null, "journal-ref": "Phys. Rev. E 100, 033308 (2019)", "doi": "10.1103/PhysRevE.100.033308", "report-no": null, "categories": "eess.IV cs.CE cs.CV physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Porous media are ubiquitous in both nature and engineering applications, thus\ntheir modelling and understanding is of vital importance. In contrast to direct\nacquisition of three-dimensional (3D) images of such medium, obtaining its\nsub-region (s) like two-dimensional (2D) images or several small areas could be\nmuch feasible. Therefore, reconstructing whole images from the limited\ninformation is a primary technique in such cases. Specially, in practice the\ngiven data cannot generally be determined by users and may be incomplete or\npartially informed, thus making existing reconstruction methods inaccurate or\neven ineffective. To overcome this shortcoming, in this study we proposed a\ndeep learning-based framework for reconstructing full image from its much\nsmaller sub-area(s). Particularly, conditional generative adversarial network\n(CGAN) is utilized to learn the mapping between input (partial image) and\noutput (full image). To preserve the reconstruction accuracy, two simple but\neffective objective functions are proposed and then coupled with the other two\nfunctions to jointly constrain the training procedure. Due to the inherent\nessence of this ill-posed problem, a Gaussian noise is introduced for producing\nreconstruction diversity, thus allowing for providing multiple candidate\noutputs. Extensively tested on a variety of porous materials and demonstrated\nby both visual inspection and quantitative comparison, the method is shown to\nbe accurate, stable yet fast ($\\sim0.08s$ for a $128 \\times 128$ image\nreconstruction). We highlight that the proposed approach can be readily\nextended, such as incorporating any user-define conditional data and an\narbitrary number of object functions into reconstruction, and being coupled\nwith other reconstruction methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:08:28 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Feng", "Junxi", ""], ["He", "Xiaohai", ""], ["Teng", "Qizhi", ""], ["Ren", "Chao", ""], ["Chen", "Honggang", ""], ["Li", "Yang", ""]]}, {"id": "1905.02679", "submitter": "Boris Kramer", "authors": "Boris Kramer, Alexandre Noll Marques, Benjamin Peherstorfer, Umberto\n  Villa, Karen Willcox", "title": "Multifidelity probability estimation via fusion of estimators", "comments": null, "journal-ref": "Journal of Computational Physics 392, 385-402, 2019", "doi": "10.1016/j.jcp.2019.04.071", "report-no": null, "categories": "stat.CO cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper develops a multifidelity method that enables estimation of failure\nprobabilities for expensive-to-evaluate models via information fusion and\nimportance sampling. The presented general fusion method combines multiple\nprobability estimators with the goal of variance reduction. We use low-fidelity\nmodels to derive biasing densities for importance sampling and then fuse the\nimportance sampling estimators such that the fused multifidelity estimator is\nunbiased and has mean-squared error lower than or equal to that of any of the\nimportance sampling estimators alone. By fusing all available estimators, the\nmethod circumvents the challenging problem of selecting the best biasing\ndensity and using only that density for sampling. A rigorous analysis shows\nthat the fused estimator is optimal in the sense that it has minimal variance\namongst all possible combinations of the estimators. The asymptotic behavior of\nthe proposed method is demonstrated on a convection-diffusion-reaction partial\ndifferential equation model for which $10^5$ samples can be afforded. To\nillustrate the proposed method at scale, we consider a model of a free plane\njet and quantify how uncertainties at the flow inlet propagate to a quantity of\ninterest related to turbulent mixing. Compared to an importance sampling\nestimator that uses the high-fidelity model alone, our multifidelity estimator\nreduces the required CPU time by 65\\% while achieving a similar coefficient of\nvariation.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:33:34 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kramer", "Boris", ""], ["Marques", "Alexandre Noll", ""], ["Peherstorfer", "Benjamin", ""], ["Villa", "Umberto", ""], ["Willcox", "Karen", ""]]}, {"id": "1905.02902", "submitter": "Jun Wu", "authors": "Jun Wu, Weiming Wang and Xifeng Gao", "title": "Design and Optimization of Conforming Lattice Structures", "comments": "14 pages", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics 2019", "doi": "10.1109/TVCG.2019.2938946", "report-no": null, "categories": "cs.CE cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by natural cellular materials such as trabecular bone, lattice\nstructures have been developed as a new type of lightweight material. In this\npaper we present a novel method to design lattice structures that conform with\nboth the principal stress directions and the boundary of the optimized shape.\nOur method consists of two major steps: the first optimizes concurrently the\nshape (including its topology) and the distribution of orthotropic lattice\nmaterials inside the shape to maximize stiffness under application-specific\nexternal loads; the second takes the optimized configuration (i.e.\nlocally-defined orientation, porosity, and anisotropy) of lattice materials\nfrom the previous step, and extracts a globally consistent lattice structure by\nfield-aligned parameterization. Our approach is robust and works for both 2D\nplanar and 3D volumetric domains. Numerical results and physical verifications\ndemonstrate remarkable structural properties of conforming lattice structures\ngenerated by our method.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 04:17:38 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wu", "Jun", ""], ["Wang", "Weiming", ""], ["Gao", "Xifeng", ""]]}, {"id": "1905.03058", "submitter": "Md Rushdie Ibne Islam", "authors": "Md Rushdie Ibne Islam, Amit Shaw", "title": "Numerical Modelling of Crack Initiation, Propagation and Branching under\n  Dynamic Loading", "comments": "26 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper crack initiation, propagation and branching phenomena are\nsimulated using the Pseudo-Spring Smooth Particle Hydrodynamics (SPH) in two\nand three-dimensional domains. The pseudo-spring analogy is used to model\nmaterial damage. Here, the interaction of particles is limited to its initial\nimmediate neighbours. The particles are connected via springs. These springs do\nnot provide any extra stiffness in the system but only define the level of\ninteraction between the connecting pairs. It is assumed that a crack has passed\nthrough a spring connecting a particle pair if the damage indicator of that\nspring becomes more than a predefined value. The crack branching of a\npre-notched plate under dynamic loading and the effect of loading amplitude are\nstudied here. The computed crack speeds, crack paths and surfaces are compared\nwith experimental and numerical results available in the literature and are\nfound to be in good agreement. The effect of notch location for a plate with a\ncircular hole is studied here. The ability of the framework to model arbitrary\ncrack paths and surfaces are demonstrated via three-dimensional simulations of\nchalk under torsion, Kalthoff-Winkler experiment and Taylor bullet impact.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 18:02:34 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Islam", "Md Rushdie Ibne", ""], ["Shaw", "Amit", ""]]}, {"id": "1905.03350", "submitter": "Ali Hebbal", "authors": "Ali Hebbal, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi and\n  Nouredine Melab", "title": "Bayesian Optimization using Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization using Gaussian Processes is a popular approach to deal\nwith the optimization of expensive black-box functions. However, because of the\na priori on the stationarity of the covariance matrix of classic Gaussian\nProcesses, this method may not be adapted for non-stationary functions involved\nin the optimization problem. To overcome this issue, a new Bayesian\nOptimization approach is proposed. It is based on Deep Gaussian Processes as\nsurrogate models instead of classic Gaussian Processes. This modeling technique\nincreases the power of representation to capture the non-stationarity by simply\nconsidering a functional composition of stationary Gaussian Processes,\nproviding a multiple layer structure. This paper proposes a new algorithm for\nGlobal Optimization by coupling Deep Gaussian Processes and Bayesian\nOptimization. The specificities of this optimization method are discussed and\nhighlighted with academic test cases. The performance of the proposed algorithm\nis assessed on analytical test cases and an aerospace design optimization\nproblem and compared to the state-of-the-art stationary and non-stationary\nBayesian Optimization approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 11:07:53 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Hebbal", "Ali", ""], ["Brevault", "Loic", ""], ["Balesdent", "Mathieu", ""], ["Talbi", "El-Ghazali", ""], ["Melab", "Nouredine", ""]]}, {"id": "1905.03831", "submitter": "Wenyuan Liao", "authors": "Keran Li, Wenyuan Liao", "title": "An Efficient and high accuracy finite-difference scheme for the acoustic\n  wave equation in 3D heterogeneous media", "comments": "Submitted to Journal of Computational Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and accurate numerical simulation of 3D acoustic wave propagation\nin heterogeneous media plays an important role in the success of seismic full\nwaveform inversion (FWI) problem. In this work, we employed the combined scheme\nand developed a new explicit compact high-order finite difference scheme to\nsolve the 3D acoustic wave equation with spatially variable acoustic velocity.\nThe boundary conditions for the second derivatives of spatial variables have\nbeen derived by using the equation itself and the boundary condition for $u$.\nTheoretical analysis shows that the new scheme has an accuracy order of\n$O(\\tau^2) + O(h^4)$, where $\\tau$ is the time step and $h$ is the grid size.\nCombined with Richardson extrapolation or Runge-Kutta method, the new method\ncan be improved to 4th-order in time. Three numerical experiments are conducted\nto validate the efficiency and accuracy of the new scheme. The stability of the\nnew scheme has been proved by an energy method, which shows that the new scheme\nis conditionally stable with a Courant - Friedrichs - Lewy (CFL) number which\nis slightly lower than that of the Pad\\'{e} approximation based method.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 19:45:03 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Li", "Keran", ""], ["Liao", "Wenyuan", ""]]}, {"id": "1905.03875", "submitter": "Adam Larios", "authors": "Siavash Jafarzadeh, Adam Larios, Florin Bobaru", "title": "Efficient solutions for nonlocal diffusion problems via boundary-adapted\n  spectral methods", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": "10.1007/s42102-019-00026-6", "report-no": null, "categories": "math.NA cs.CE math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient boundary-adapted spectral method for peridynamic\ndiffusion problems with arbitrary boundary conditions. The spectral approach\ntransforms the convolution integral in the peridynamic formulation into a\nmultiplication in the Fourier space, resulting in computations that scale as\nO(NlogN). The limitation of regular spectral methods to periodic problems is\neliminated using the volume penalization method. We show that arbitrary\nboundary conditions or volume constraints can be enforced in this way to\nachieve high levels of accuracy. To test the performance of our approach we\ncompare the computational results with analytical solutions of the nonlocal\nproblem. The performance is tested with convergence studies in terms of nodal\ndiscretization and the size of the penalization parameter in problems with\nDirichlet and Neumann boundary conditions.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 22:16:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Jafarzadeh", "Siavash", ""], ["Larios", "Adam", ""], ["Bobaru", "Florin", ""]]}, {"id": "1905.04624", "submitter": "Panagiotis Chatzigiannis", "authors": "Panagiotis Chatzigiannis, Foteini Baldimtsi, Igor Griva and Jiasun Li", "title": "Diversification Across Mining Pools: Optimal Mining Strategies under PoW", "comments": "13 pages, 16 figures. Presented at WEIS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining is a central operation of all proof-of-work (PoW) based\ncryptocurrencies. The vast majority of miners today participate in \"mining\npools\" instead of \"solo mining\" in order to lower risk and achieve a more\nsteady income. However, this rise of participation in mining pools negatively\naffects the decentralization levels of most cryptocurrencies. In this work, we\nlook into mining pools from the point of view of a miner: We present an\nanalytical model and implement a computational tool that allows miners to\noptimally distribute their computational power over multiple pools and PoW\ncryptocurrencies (i.e. build a mining portfolio), taking into account their\nrisk aversion levels. Our tool allows miners to maximize their risk-adjusted\nearnings by diversifying across multiple mining pools which enhances PoW\ndecentralization. Finally, we run an experiment in Bitcoin historical data and\ndemonstrate that a miner diversifying over multiple pools, as instructed by our\nmodel/tool, receives a higher overall Sharpe ratio (i.e. average excess reward\nover its standard deviation/volatility).\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 01:51:08 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 02:47:50 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Chatzigiannis", "Panagiotis", ""], ["Baldimtsi", "Foteini", ""], ["Griva", "Igor", ""], ["Li", "Jiasun", ""]]}, {"id": "1905.04872", "submitter": "Ryan Wen Liu", "authors": "Yan Li, Ryan Wen Liu, Zhao Liu, Jingxian Liu", "title": "Similarity Grouping-Guided Neural Network Modeling for Maritime Time\n  Series Prediction", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reliable and accurate prediction of time series plays a crucial role in\nmaritime industry, such as economic investment, transportation planning, port\nplanning and design, etc. The dynamic growth of maritime time series has the\npredominantly complex, nonlinear and non-stationary properties. To guarantee\nhigh-quality prediction performance, we propose to first adopt the empirical\nmode decomposition (EMD) and ensemble EMD (EEMD) methods to decompose the\noriginal time series into high- and low-frequency components. The low-frequency\ncomponents can be easily predicted directly through traditional neural network\n(NN) methods. It is more difficult to predict high-frequency components due to\ntheir properties of weak mathematical regularity. To take advantage of the\ninherent self-similarities within high-frequency components, these components\nwill be divided into several continuous small (overlapping) segments. The\ngrouped segments with high similarities are then selected to form more proper\ntraining datasets for traditional NN methods. This regrouping strategy can\nassist in enhancing the prediction accuracy of high-frequency components. The\nfinal prediction result is obtained by integrating the predicted high- and\nlow-frequency components. Our proposed three-step prediction frameworks benefit\nfrom the time series decomposition and similar segments grouping. Experiments\non both port cargo throughput and vessel traffic flow have illustrated its\nsuperior performance in terms of prediction accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 06:13:27 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Li", "Yan", ""], ["Liu", "Ryan Wen", ""], ["Liu", "Zhao", ""], ["Liu", "Jingxian", ""]]}, {"id": "1905.04929", "submitter": "Konstantinos A. Mountris", "authors": "Konstantinos A. Mountris, George C. Bourantas, Daniel Mill\\'an, Grand\n  R. Joldes, Karol Miller, Esther Pueyo, and Adam Wittek", "title": "Cell-based Maximum Entropy Approximants for Three Dimensional Domains:\n  Application in Large Strain Elastodynamics using the Meshless Total\n  Lagrangian Explicit Dynamics Method", "comments": "Added link to the repository where the CME approximants code can be\n  found", "journal-ref": null, "doi": "10.1002/nme.6218", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Cell-based Maximum Entropy (CME) approximants in E3 space by\nconstructing the smooth approximation distance function to polyhedral surfaces.\nCME is a meshfree approximation method combining the properties of the Maximum\nEntropy approximants and the compact support of element-based interpolants. The\nmethod is evaluated in problems of large strain elastodynamics for\nthree-dimensional (3D) continua using the well-established Meshless Total\nLagrangian Explicit Dynamics (MTLED) method. The accuracy and efficiency of the\nmethod is assessed in several numerical examples in terms of computational\ntime, accuracy in boundary conditions imposition, and strain energy density\nerror. Due to the smoothness of CME basis functions, the numerical stability in\nexplicit time integration is preserved for large time step. The challenging\ntask of essential boundary conditions imposition in non-interpolating meshless\nmethods (e.g., Moving Least Squares) is eliminated in CME due to the weak\nKronecker-delta property. The essential boundary conditions are imposed\ndirectly, similar to the Finite Element Method. CME is proven a valuable\nalternative to other meshless and element-based methods for large-scale\nelastodynamics in 3D.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:23:24 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 06:43:27 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 13:07:41 GMT"}, {"version": "v4", "created": "Tue, 29 Oct 2019 11:40:42 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Mountris", "Konstantinos A.", ""], ["Bourantas", "George C.", ""], ["Mill\u00e1n", "Daniel", ""], ["Joldes", "Grand R.", ""], ["Miller", "Karol", ""], ["Pueyo", "Esther", ""], ["Wittek", "Adam", ""]]}, {"id": "1905.05000", "submitter": "Laura Carreras", "authors": "Laura Carreras, Albert Turon, Brian L. V. Bak, Esben Lindgaard, Jordi\n  Renart, Federico M. de la Escalera, Yasser Essa", "title": "A simulation method for fatigue-driven delamination in layered\n  structures involving non-negligible fracture process zones and arbitrarily\n  shaped crack fronts", "comments": "37 pages, 14 figures, 7 tables", "journal-ref": null, "doi": "10.1016/j.compositesa.2019.04.026", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing methods for fatigue-driven delamination are limited to\ntwo-dimensional (2D) applications or their predictive capabilities have not\nbeen validated in three-dimensional (3D) problems. This work presents a new\ncohesive zone-based computational method for simulating fatigue-driven\ndelamination in the analysis of 3D structures without crack migration. The\nmethod accurately predicts fatigue propagation of non-nelgigible fracture\nprocess zones with arbitrarily shaped delamination fronts. The model does not\nrequire any kind of fitting parameter since all the input parameters are\nobtained experimentally from coupon tests. The evaluation of the energy release\nrate is done using two new techniques recently developed by the authors (the\ngrowth driving direction and the mode-decomposed J-integral) leading to an\naccurate prediction of delamination propagation under mixed-mode and\nnon-self-similar growing conditions. The new method has been implemented as a\nUEL for Abaqus and validated against an experimental benchmark case with\nvarying crack growth rate and shape and extension of the fracture process zone.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 05:59:55 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Carreras", "Laura", ""], ["Turon", "Albert", ""], ["Bak", "Brian L. V.", ""], ["Lindgaard", "Esben", ""], ["Renart", "Jordi", ""], ["de la Escalera", "Federico M.", ""], ["Essa", "Yasser", ""]]}, {"id": "1905.05001", "submitter": "Alfredo Jaramillo", "authors": "Alfredo Jaramillo, Gustavo C Buscaglia", "title": "An extended Elrod-Adams model to account for backpressure and blow-by\n  inception", "comments": "10 pages,18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Piston-Ring-Liner system is the main tribological component of internal\ncombustion engines. The Elrod-Adams model is customarily used to numerically\nassess the hydrodynamics of different ring designs and liner surface\ntreatments. However, that model does not incorporate the backpressure boundary\ncondition, which in this case corresponds to the combustion chamber pressure\nand is quite significant. In this contribution a model is proposed that imposes\nthe combustion-chamber pressure in a mass-conserving way, together with an\neffective algorithm for its numerical approximation. The new model incorporates\nthe pressure difference across the ring, which is shown to have a substantial\neffect on the predicted friction force and MFT. The model is further elaborated\nso as to provide a criterion for predicting blow-by inception.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 18:13:37 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Jaramillo", "Alfredo", ""], ["Buscaglia", "Gustavo C", ""]]}, {"id": "1905.05308", "submitter": "Alexei Novikov", "authors": "Miguel Moscoso, Alexei Novikov, George Papanicolaou and Chrysoula\n  Tsogka", "title": "Synthetic aperture imaging with intensity-only data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider imaging the reflectivity of scatterers from intensity-only data\nrecorded by a single moving transducer that both emits and receives signals,\nforming a synthetic aperture. By exploiting frequency illumination diversity,\nwe obtain multiple intensity measurements at each location, from which we\ndetermine field cross-correlations using an appropriate phase controlled\nillumination strategy and the inner product polarization identity. The field\ncross-correlations obtained this way do not, however, provide all the missing\nphase information because they are determined up to a phase that depends on the\nreceiver's location. The main result of this paper is an algorithm with which\nwe recover the field cross-correlations up to a single phase that is common to\nall the data measured over the synthetic aperture, so all the data are\nsynchronized. Thus, we can image coherently with data over all frequencies and\nmeasurement locations as if full phase information was recorded.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 22:44:03 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Moscoso", "Miguel", ""], ["Novikov", "Alexei", ""], ["Papanicolaou", "George", ""], ["Tsogka", "Chrysoula", ""]]}, {"id": "1905.05345", "submitter": "Jan N. Fuhg", "authors": "Jan N. Fuhg", "title": "Adaptive surrogate models for parametric studies", "comments": "225 pages, Master's thesis, Leibniz University of Hannover, Germany\n  (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational effort for the evaluation of numerical simulations based on\ne.g. the finite-element method is high. Metamodels can be utilized to create a\nlow-cost alternative. However the number of required samples for the creation\nof a sufficient metamodel should be kept low, which can be achieved by using\nadaptive sampling techniques. In this Master thesis adaptive sampling\ntechniques are investigated for their use in creating metamodels with the\nKriging technique, which interpolates values by a Gaussian process governed by\nprior covariances. The Kriging framework with extension to multifidelity\nproblems is presented and utilized to compare adaptive sampling techniques\nfound in the literature for benchmark problems as well as applications for\ncontact mechanics. This thesis offers the first comprehensive comparison of a\nlarge spectrum of adaptive techniques for the Kriging framework. Furthermore a\nmultitude of adaptive techniques is introduced to multifidelity Kriging as well\nas well as to a Kriging model with reduced hyperparameter dimension called\npartial least squares Kriging. In addition, an innovative adaptive scheme for\nbinary classification is presented and tested for identifying chaotic motion of\na Duffing's type oscillator.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 11:08:50 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Fuhg", "Jan N.", ""]]}, {"id": "1905.05417", "submitter": "Pablo Antolin", "authors": "Pablo Antolin", "title": "Fast assembly of Galerkin matrices for 3D solid laminated composites\n  using finite element and isogeometric discretizations", "comments": "40 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel methodology for speeding up the assembly of\nstiffness matrices for laminate composite 3D structures in the context of\nisogeometric and finite element discretizations. By splitting the involved\nterms into their in-plane and out-of-plane contributions, this method computes\nthe problems's 3D stiffness matrix as a combination of 2D (in-plane) and 1D\n(out-of-plane) integrals. Therefore, the assembly's computational complexity is\nreduced to the one of a 2D problem. Additionally, the number of 2D integrals to\nbe computed becomes independent of the number of material layers that\nconstitute the laminated composite, it only depends on the number of different\nmaterials used (or different orientations of the same anisotropic material).\nHence, when a high number of layers is present, the proposed technique reduces\nby orders of magnitude the computational time required to create the stiffness\nmatrix with standard methods, being the resulting matrices identical up to\nmachine precision. The predicted performance is illustrated through numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 06:59:47 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Antolin", "Pablo", ""]]}, {"id": "1905.05892", "submitter": "Ahmad Khaled Zarabie", "authors": "Ahmad Khaled Zarabie, Sanjoy Das", "title": "Pareto-Optimal Allocation of Transactive Energy at Market Equilibrium in\n  Distribution Systems: A Constrained Vector Optimization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a grid constrained transactive distribution system market, distribution\nlocational marginal pricing DLMP is influenced by the distance from the\nsubstation to an energy user, thereby causing households that are further away\nfrom the substation to be charged more. The Jain index of fairness, which has\nbeen recently applied to alleviate this undesirable effect of inefficient\nenergy allocations, is used in this research to quantify fairness. It is shown\nthat the Jain index is strictly quasi-concave. A bilevel distributed mechanism\nis proposed, where at the lower level, auction mechanisms are invoked\nsimultaneously at each aggregator to obtain energy costs under market\nequilibrium conditions. A constrained multi gradient ascent algorithm,\nAugmented Lagrangian Multigradient Approach ALMA, is proposed for\nimplementation at the upper level to attain energy allocations that represent\ntradeoffs between efficiency and fairness. Theoretical issues pertaining to\nALMA as a generic algorithm for constrained vector optimization are considered.\nIt is shown that when the objectives are restricted to be strictly quasi\nconcave functions and if the feasible region is convex, ALMA converges towards\nglobal Pareto optimality. The overall effectiveness of the proposed approach is\nconfirmed through a set of MATLAB simulations implemented on a modified IEEE\n37-bus system platform.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 00:01:34 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 16:07:27 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zarabie", "Ahmad Khaled", ""], ["Das", "Sanjoy", ""]]}, {"id": "1905.06089", "submitter": "Jos\\'e Rui Figueira", "authors": "Jos\\'e Rui Figueira, Salvatore Greco, Bernard Roy", "title": "Electre-Score: A first outranking based method for scoring actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present (to the best of our knowledge) the first outranking\nmethod to assign a score to each alternative. It is a method of the Electre\nfamily, and we will call it Electre-Score. Contrarily to the Multi-Attribute\nValue Theory methods, Electre-Score does not construct a value function for\neach criterion, and then proceeds to the aggregation into a single value. It\nrather, makes use of the outranking relations to make a comparison with\nreference sets of actions (to which a score is assigned) and proposes a score\nrange to each alternative, instead of a single value. This is a more robust way\nof proceeding given the fragility of a single score. The sets of limiting\nprofiles are defined with the help of Electre Tri-nB and the reference scores\nare assigned to them through the application of the deck of cards technique.\nThe fact of being able to use outranking relations, makes it also possible to\ntake into account the imperfect knowledge of data and avoids systematic\ncompensatory effects. Some fundamental theoretical results guaranteeing the\nconsistency of the method and an illustrative example are also provided in this\npaper.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 11:03:55 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Figueira", "Jos\u00e9 Rui", ""], ["Greco", "Salvatore", ""], ["Roy", "Bernard", ""]]}, {"id": "1905.06327", "submitter": "Ali Takbiri-Borujeni", "authors": "Ali Takbiri-Borujeni and Hadi Kazemi and Nasser Nasrabadi", "title": "A data-driven proxy to Stoke's flow in porous media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective for this work is to develop a data-driven proxy to\nhigh-fidelity numerical flow simulations using digital images. The proposed\nmodel can capture the flow field and permeability in a large verity of digital\nporous media based on solid grain geometry and pore size distribution by\ndetailed analyses of the local pore geometry and the local flow fields. To\ndevelop the model, the detailed pore space geometry and simulation runs data\nfrom 3500 two-dimensional high-fidelity Lattice Boltzmann simulation runs are\nused to train and to predict the solutions with a high accuracy in much less\ncomputational time. The proposed methodology harness the enormous amount of\ngenerated data from high-fidelity flow simulations to decode the often\nunder-utilized patterns in simulations and to accurately predict solutions to\nnew cases. The developed model can truly capture the physics of the problem and\nenhance prediction capabilities of the simulations at a much lower cost. These\npredictive models, in essence, do not spatio-temporally reduce the order of the\nproblem. They, however, possess the same numerical resolutions as their Lattice\nBoltzmann simulations equivalents do with the great advantage that their\nsolutions can be achieved by significant reduction in computational costs\n(speed and memory).\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 21:49:58 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Takbiri-Borujeni", "Ali", ""], ["Kazemi", "Hadi", ""], ["Nasrabadi", "Nasser", ""]]}, {"id": "1905.06810", "submitter": "Parnian Ghasemi Mrs", "authors": "Parnian Ghasemi, Shibin Lin, Derrick K. Rollins, R. Christopher\n  Williams", "title": "Predicting Dynamic Modulus of Asphalt Mixture Using Data Obtained from\n  Indirect Tension Mode of Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding stress-strain behavior of asphalt pavement under repetitive\ntraffic loading is of critical importance to predict pavement performance and\nservice life. For viscoelastic materials, the stress-strain relationship can be\nrepresented by the dynamic modulus. The dynamic modulus test in indirect\ntension mode can be used to measure the modulus of each specific layer of\nasphalt pavements using representative samples. Dynamic modulus is a function\nof material properties, loading, and environmental conditions. Developing\npredictive models for dynamic modulus is efficient and cost effective. This\narticle focuses on developing an accurate Finite Element (FE) model using\nmixture elastic modulus and asphalt binder properties to predict dynamic\nmodulus of asphalt mix in indirect tension mode. An Artificial Neural Network\n(ANN) is used to back-calculate the elastic modulus of asphalt mixtures. The\ndeveloped FE model was verified against experimental results of field cores\nfrom nine different pavement sections from five districts in the State of\nMinnesota. It is demonstrated that the ANN modeling is a powerful tool to\nback-calculate the elastic modulus and FE model is capable of accurately\npredicting dynamic modulus.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:26:41 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Ghasemi", "Parnian", ""], ["Lin", "Shibin", ""], ["Rollins", "Derrick K.", ""], ["Williams", "R. Christopher", ""]]}, {"id": "1905.06811", "submitter": "Aleksandr Linkov", "authors": "A. M. Linkov", "title": "Modern theory of hydraulic fracture modeling with using explicit and\n  implicit schemes", "comments": "38 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents novel results, obtained on the basis of the modified\ntheory of hydraulic fractures (HF). The theory underlines significance of the\nspeed equation. When applied to numerical simulation of HF, the theory reveals\nthree distinct issues: (i) modeling the central part of a HF; (ii) modeling the\nnear-front zone; and (iii) tracing changes in the shape of a fracture contour.\nModeling the central part leads to a stiff system of ODE in time, what strongly\ncomplicates its integration. For explicit schemes, it requires small time steps\nto meet the CFL condition. For implicit schemes, it requires proper\npreconditioners. The gains and flaws of the two strategies are discussed. It is\nnoted that a rough spatial mesh may be used in the central part. Modeling the\nnear-front zone reveals the vital role of the speed equation for HF modeling by\nany method. Its asymptotic analysis has resulted in the fundamental concept of\nthe universal asymptotic umbrella. For the near-front zone, it is also\nestablished that a notable part of the zone adjacent to the front propagates\nvirtually as a simple wave. This implies that the CFL condition of stability\nfor this zone is much less restrictive than for the central part of the\nfracture. Of essence is also that the wave-like propagation of the near front\nzone makes preferable upwind schemes of time stepping. On whole, the analysis\nimplies that explicit time stepping may be complementing, competitive and even\nsuperior over implicit integration. Tracing changes in the front shape appears\nmerely in 3D problems when the contour changes its form. The problem, being\nessentially geometrical, it may be solved separately by various methods,\nincluding fast marching, level set and the simplest string/marker methods. In\n1D cases, it does not arise at all.\n  Quantitative estimations and numerical examples illustrate the theoretical\nconclusions.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 09:11:26 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Linkov", "A. M.", ""]]}, {"id": "1905.06879", "submitter": "Sebastian Sch\\\"ops", "authors": "Stephanie Friedhoff and Jens Hahne and Sebastian Sch\\\"ops", "title": "Multigrid-reduction-in-time for Eddy Current problems", "comments": "Contribution from GAMM 2019 conference", "journal-ref": "Proc. Appl. Math. Mech., 19: e201900262, 2019", "doi": "10.1002/pamm.201900262", "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel-in-time methods have shown success for reducing the simulation time\nof many time-dependent problems. Here, we consider applying the\nmultigrid-reduction-in-time (MGRIT) algorithm to a voltage-driven eddy current\nmodel problem.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 16:05:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Friedhoff", "Stephanie", ""], ["Hahne", "Jens", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1905.07526", "submitter": "Yury Dvorkin", "authors": "Robert Mieth and Yury Dvorkin", "title": "Distribution Electricity Pricing under Uncertainty", "comments": null, "journal-ref": null, "doi": "10.1109/TPWRS.2019.2954971", "report-no": null, "categories": "cs.SY cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution locational marginal prices (DLMPs) facilitate the efficient\noperation of low-voltage electric power distribution systems. We propose an\napproach to internalize the stochasticity of renewable distributed energy\nresources (DERs) and risk tolerance of the distribution system operator in DLMP\ncomputations. This is achieved by means of applying conic duality to a\nchance-constrained AC optimal power flow. We show that the resulting DLMPs\nconsist of the terms that allow to itemize the prices for the active and\nreactive power production, balancing regulation, and voltage support provided.\nFinally, we prove the proposed DLMPs constitute a competitive equilibrium,\nwhich can be leveraged for designing a distribution electricity market, and\nshow that imposing chance constraints on voltage limits distorts the\nequilibrium.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 03:22:46 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 20:43:11 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 21:41:21 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 19:53:38 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Mieth", "Robert", ""], ["Dvorkin", "Yury", ""]]}, {"id": "1905.08485", "submitter": "Ahmed Ghareeb", "authors": "Ahmed Ghareeb, Ahmed Elbanna", "title": "An Adaptive Quasi-Continuum Approach for Modeling Fracture in Networked\n  Materials: Application to Modeling of Polymer Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmps.2019.103819", "report-no": null, "categories": "cond-mat.soft cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials with network-like microstructure, including polymers, are the\nbackbone for many natural and human-made materials such as gels, biological\ntissues, metamaterials, and rubbers. Fracture processes in these networked\nmaterials are intrinsically multiscale, and it is computationally prohibitive\nto adopt a fully discrete approach for large scale systems. To overcome such a\nchallenge, we introduce an adaptive numerical algorithm for modeling fracture\nin this class of materials, with a primary application to polymer networks,\nusing an extended version of the Quasi-Continuum method that accounts for both\nmaterial and geometric nonlinearities. In regions of high interest, for example\nnear crack tips, explicit representation of the local topology is retained\nwhere each polymer chain is idealized using the worm like chain model. Away\nfrom these imperfections, the degrees of freedom are limited to a fraction of\nthe network nodes and the network structure is computationally homogenized,\nusing the micro-macro energy consistency condition, to yield an anisotropic\nmaterial tensor consistent with the underlying network structure. A nonlinear\nfinite element framework is used to solve the system where dynamic adaptivity\nallows transition between the continuum and discrete scales. The method enables\naccurate modelling of crack propagation without a priori constraint on the\nfracture energy while maintaining the influence of large-scale elastic loading\nin the bulk. We demonstrate the accuracy and efficiency of the method by\napplying it to study the fracture in different examples of network structures.\nWe further use the method to investigate the effects of network topology and\ndisorder on its fracture characteristics. We discuss the implications of our\nmethod for multiscale analysis of fracture in networked material as they arise\nin different applications in biology and engineering.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:23:52 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 23:28:09 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ghareeb", "Ahmed", ""], ["Elbanna", "Ahmed", ""]]}, {"id": "1905.08619", "submitter": "Tian Yang", "authors": "Leiting Dong, Tian Yang, Kailei Wang, Satya N. Atluri", "title": "A new Fragile Points Method (FPM) in computational mechanics, based on\n  the concepts of Point Stiffnesses and Numerical Flux Corrections", "comments": null, "journal-ref": "Engineering Analysis with Boundary Elements,2019", "doi": "10.1016/j.enganabound.2019.07.009", "report-no": null, "categories": "physics.comp-ph cs.CE math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new method, named the Fragile Points Method (FPM), is\ndeveloped for computer modeling in engineering and sciences. In the FPM,\nsimple, local, polynomial, discontinuous and Point-based trial and test\nfunctions are proposed based on randomly scattered points in the problem\ndomain. The local discontinuous polynomial trial and test functions are\npostulated by using the Generalized Finite Difference method. These functions\nare only piece-wise continuous over the global domain. By implementing the\nPoint-based trial and test functions into the Galerkin weak form, we define the\nconcept of Point Stiffnesses as the contribution of each Point in the problem\ndomain to the global stiffness matrix. However, due to the discontinuity of\ntrial and test functions in the domain, directly using the Galerkin weak form\nleads to inconsistency. To resolve this, Numerical Flux Corrections, which are\nfrequently used in Discontinuous Galerkin methods are further employed in the\nFPM. The resulting global stiffness matrix is symmetric and sparse, which is\nadvantageous for large-scale engineering computations. Several numerical\nexamples of 1D and 2D Poisson equations are given in this paper to demonstrate\nthe high accuracy, robustness and convergence of the FPM. Because of the\nlocality and discontinuity of the Point-based trial and test functions, this\nmethod can be easily extended to model extreme problems in mechanics, such as\nfragility, rupture, fracture, damage, and fragmentation. These extreme problems\nwill be discussed in our future studies.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 13:26:23 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 12:04:00 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 09:31:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Dong", "Leiting", ""], ["Yang", "Tian", ""], ["Wang", "Kailei", ""], ["Atluri", "Satya N.", ""]]}, {"id": "1905.08651", "submitter": "Simon Tamayo", "authors": "Simon Tamayo and Thibaud Monteiro", "title": "Mathematical method for calculating batch fragmentations and their\n  impacts on product recall within a FIFO assignment policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores the interactions between order sizes, batch sizes and\npotential product recalls within a FIFO assignment policy. Evidence is provided\nthat the extent of a product recall is related to the fragmentation of the\nbatches of input materials as it amplifies the impact of a crisis. A new\nmanagement indicator is proposed in order to quantify the expected number of\nfragments composing a customer order FrBO. A probabilistic analysis reveals\nthat for a given likelihood of crisis, the presence of different batches in a\ncustomer order will largely increase its risk. Accordingly, a new equation is\nproposed for calculating the expected recall size. Taking into account the\nfragmentation measure allows, for the first time, for the integration of a\nproactive product recall policy in the batch sizing decision process. A Monte\nCarlo simulation is performed to validate the effectiveness of this approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:03:32 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Tamayo", "Simon", ""], ["Monteiro", "Thibaud", ""]]}, {"id": "1905.08740", "submitter": "Konrad Simon Ph.D.", "authors": "Konrad Simon and J\\\"orn Behrens", "title": "Semi-Lagrangian Subgrid Reconstruction for Advection-Dominant Multiscale\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new framework of numerical multiscale methods for\nadvection-dominated problems motivated by climate sciences. Current numerical\nmultiscale methods (MsFEM) work well on stationary elliptic problems but have\ndifficulties when the model involves dominant lower order terms. Our idea to\novercome the assocociated difficulties is a semi-Lagrangian based\nreconstruction of subgrid variablity into a multiscale basis by solving many\nlocal inverse problems. Globally the method looks like a Eulerian method with\nmultiscale stabilized basis. We show example runs in one and two dimensions and\na comparison to standard methods to support our ideas and discuss possible\nextensions to other types of Galerkin methods, higher dimensions and nonlinear\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:36:34 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 18:25:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Simon", "Konrad", ""], ["Behrens", "J\u00f6rn", ""]]}, {"id": "1905.08903", "submitter": "Yongbo Deng Dr.", "authors": "Yongbo Deng, Zhenyu Liu, Jan G. Korvink", "title": "Topology optimization on two-dimensional manifolds", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.112937", "report-no": null, "categories": "physics.comp-ph cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper implements topology optimization on two-dimensional manifolds. In\nthis paper, the material interpolation is implemented on a material parameter\nin the partial differential equation used to describe a physical field, when\nthis physical field is defined on a two-dimensional manifold; the material\ndensity is used to formulate a mixed boundary condition of the physical field\nand implement the penalization between two different types of boundary\nconditions, when this physical field is defined on a three-dimensional domain\nwith its boundary conditions defined on the two-dimensional manifold\ncorresponding a surface or an interface of this three-dimensional domain. Based\non the homeomorphic property of two-dimensional manifolds, typical\ntwo-dimensional manifolds, e.g., sphere, torus, M\\\"{o}bius strip and Klein\nbottle, are included in the numerical tests, which are provided for the\nproblems on fluidic mechanics, heat transfer and electromagnetics.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 17:59:43 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 10:44:50 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 13:41:29 GMT"}, {"version": "v4", "created": "Mon, 29 Jul 2019 14:51:01 GMT"}, {"version": "v5", "created": "Wed, 21 Aug 2019 10:32:42 GMT"}, {"version": "v6", "created": "Sat, 7 Sep 2019 13:34:29 GMT"}, {"version": "v7", "created": "Thu, 12 Sep 2019 11:24:10 GMT"}, {"version": "v8", "created": "Wed, 6 Nov 2019 15:43:57 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Deng", "Yongbo", ""], ["Liu", "Zhenyu", ""], ["Korvink", "Jan G.", ""]]}, {"id": "1905.09744", "submitter": "Christoph Ager", "authors": "Christoph Ager, Alexander Seitz, Wolfgang A. Wall", "title": "A consistent and comprehensive computational approach for general\n  Fluid-Structure-Contact Interaction problems", "comments": "34 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a consistent approach that allows to solve challenging general\nnonlinear fluid-structure-contact interaction (FSCI) problems. The underlying\ncontinuous formulation includes both \"no-slip\" fluid-structure interaction as\nwell as frictionless contact between multiple elastic bodies. The respective\ninterface conditions in normal and tangential orientation and especially the\nrole of the fluid stress within the region of closed contact are discussed for\nthe general problem of FSCI. To ensure continuity of the tangential constraints\nfrom no-slip to frictionless contact, a transition is enabled by using the\ngeneral Navier condition with varying slip length. Moreover, the fluid stress\nin the contact zone is obtained by an extension approach as it plays a crucial\nrole for the lift-off behavior of contacting bodies. With the given continuity\nof the spatially continuous formulation, continuity of the discrete problem\n(which is essential for the convergence of Newton's method) is reached\nnaturally. As topological changes of the fluid domain are an inherent challenge\nin FSCI configurations, a non-interface fitted Cut Finite Element Method\n(CutFEM) is applied to discretize the fluid domain. All interface conditions,\nthat is the `no-slip' FSI, the general Navier condition, and frictionless\ncontact are incorporated using Nitsche based methods, thus retaining the\ncontinuity and consistency of the model. To account for the strong interaction\nbetween the fluid and solid discretization, the overall coupled discrete system\nis solved monolithically. Numerical examples of varying complexity are\npresented to corroborate the developments.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 16:06:38 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ager", "Christoph", ""], ["Seitz", "Alexander", ""], ["Wall", "Wolfgang A.", ""]]}, {"id": "1905.09815", "submitter": "Marco Tezzele", "authors": "Andrea Mola and Marco Tezzele and Mahmoud Gadalla and Federica\n  Valdenazzi and Davide Grassi and Roberta Padovan and Gianluigi Rozza", "title": "Efficient Reduction in Shape Parameter Space Dimension for Ship\n  Propeller Blade Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present the results of a ship propeller design optimization\ncampaign carried out in the framework of the research project PRELICA, funded\nby the Friuli Venezia Giulia regional government. The main idea of this work is\nto operate on a multidisciplinary level to identify propeller shapes that lead\nto reduced tip vortex-induced pressure and increased efficiency without\naltering the thrust. First, a specific tool for the bottom-up construction of\nparameterized propeller blade geometries has been developed. The algorithm\nproposed operates with a user defined number of arbitrary shaped or NACA\nairfoil sections, and employs arbitrary degree NURBS to represent the chord,\npitch, skew and rake distribution as a function of the blade radial coordinate.\nThe control points of such curves have been modified to generate, in a fully\nautomated way, a family of blade geometries depending on as many as 20 shape\nparameters. Such geometries have then been used to carry out potential flow\nsimulations with the Boundary Element Method based software PROCAL. Given the\nhigh number of parameters considered, such a preliminary stage allowed for a\nfast evaluation of the performance of several hundreds of shapes. In addition,\nthe data obtained from the potential flow simulation allowed for the\napplication of a parameter space reduction methodology based on active\nsubspaces (AS) property, which suggested that the main propeller performance\nindices are, at a first but rather accurate approximation, only depending on a\nsingle parameter which is a linear combination of all the original geometric\nones. AS analysis has also been used to carry out a constrained optimization\nexploiting response surface method in the reduced parameter space, and a\nsensitivity analysis based on such surrogate model. The few selected shapes\nwere finally used to set up high fidelity RANS simulations and select an\noptimal shape.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:29:00 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Mola", "Andrea", ""], ["Tezzele", "Marco", ""], ["Gadalla", "Mahmoud", ""], ["Valdenazzi", "Federica", ""], ["Grassi", "Davide", ""], ["Padovan", "Roberta", ""], ["Rozza", "Gianluigi", ""]]}, {"id": "1905.09868", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Radu Statem, Jean Hilger", "title": "Modeling Smart Contracts Activities: A Tensor Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are autonomous software executing predefined conditions. Two\nof the biggest advantages of the smart contracts are secured protocols and\ntransaction costs reduction. On the Ethereum platform, an open-source\nblockchain-based platform, smart contracts implement a distributed virtual\nmachine on the distributed ledger. To avoid denial of service attacks and\nmonetize the services, payment transactions are executed whenever code is being\nexecuted between contracts. It is thus natural to investigate if predictive\nanalysis is capable to forecast these interactions. We have addressed this\nissue and propose an innovative application of the tensor decomposition\nCANDECOMP/PARAFAC to the temporal link prediction of smart contracts. We\nintroduce a new approach leveraging stochastic processes for series predictions\nbased on the tensor decomposition that can be used for smart contracts\npredictive analytics.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:46:30 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Charlier", "Jeremy", ""], ["Statem", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.09869", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Radu State, Jean Hilger", "title": "Non-Negative PARATUCK2 Tensor Decomposition Combined to LSTM Network For\n  Smart Contracts Profiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contracts are programs stored and executed on a blockchain. The\nEthereum platform, an open-source blockchain-based platform, has been designed\nto use these programs offering secured protocols and transaction costs\nreduction. The Ethereum Virtual Machine performs smart contracts runs, where\nthe execution of each contract is limited to the amount of gas required to\nexecute the operations described in the code. Each gas unit must be paid using\nEther, the crypto-currency of the platform. Due to smart contracts interactions\nevolving over time, analyzing the behavior of smart contracts is very\nchallenging. We address this challenge in our paper. We develop for this\npurpose an innovative approach based on the non-negative tensor decomposition\nPARATUCK2 combined with long short-term memory (LSTM) to assess if predictive\nanalysis can forecast smart contracts interactions over time. To validate our\nmethodology, we report results for two use cases. The main use case is related\nto analyzing smart contracts and allows shedding some light into the complex\ninteractions among smart contracts. In order to show the generality of our\nmethod on other use cases, we also report its performance on video on demand\nrecommendation.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 18:54:13 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Charlier", "Jeremy", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.10190", "submitter": "Yinzhong Yan", "authors": "Yinzhong Yan, Qingming Li", "title": "Low-pass-filter-based shock response spectrum and the evaluation method\n  of transmissibility between equipment and sensitive components interfaces", "comments": null, "journal-ref": "Volume 117, 15 February 2019, Pages 97-115", "doi": "10.1016/j.ymssp.2018.07.023", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  According to the features of the sources of pyroshock and ballistic shock,\nthis study considers the pyroshock and ballistic shock generated by their\nrespective impulsive sources as damped harmonic waves with different\nfrequencies. According to the linear superposition assumption of damped\nharmonic waves in a linear elastic structure, a shock analysis method based on\nlow-pass-filtered shock signals and their corresponding shock response spectrum\n(SRS), termed as low-pass-filter-based shock response spectrum (LPSRS), is\nproposed. LPSRS contains rich information of the frequency distribution of the\nshock excitation signal. A method to calculate shock transmissibility is\nproposed based on LPSRS and basic modal information of the equipment structure.\nLPSRS and SRS curves can be predicted at any given position of the equipment\nstructure. The prediction method is validated by finite element method (FEM)\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:09:18 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Yan", "Yinzhong", ""], ["Li", "Qingming", ""]]}, {"id": "1905.10363", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Eric Falk, Radu State, Jean Hilger", "title": "User-Device Authentication in Mobile Banking using APHEN for Paratuck2\n  Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new financial European regulations such as PSD2 are changing the retail\nbanking services. Noticeably, the monitoring of the personal expenses is now\nopened to other institutions than retail banks. Nonetheless, the retail banks\nare looking to leverage the user-device authentication on the mobile banking\napplications to enhance the personal financial advertisement. To address the\nprofiling of the authentication, we rely on tensor decomposition, a higher\ndimensional analogue of matrix decomposition. We use Paratuck2, which expresses\na tensor as a multiplication of matrices and diagonal tensors, because of the\nimbalance between the number of users and devices. We highlight why Paratuck2\nis more appropriate in this case than the popular CP tensor decomposition,\nwhich decomposes a tensor as a sum of rank-one tensors. However, the\ncomputation of Paratuck2 is computational intensive. We propose a new\nAPproximate HEssian-based Newton resolution algorithm, APHEN, capable of\nsolving Paratuck2 more accurately and faster than the other popular approaches\nbased on alternating least square or gradient descent. The results of Paratuck2\nare used for the predictions of users' authentication with neural networks. We\napply our method for the concrete case of targeting clients for financial\nadvertising campaigns based on the authentication events generated by mobile\nbanking applications.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 19:38:32 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Charlier", "Jeremy", ""], ["Falk", "Eric", ""], ["State", "Radu", ""], ["Hilger", "Jean", ""]]}, {"id": "1905.10469", "submitter": "Paul Atzberger", "authors": "B. J. Gross, N. Trask, P. Kuberry, and P. J. Atzberger", "title": "Meshfree Methods on Manifolds for Hydrodynamic Flows on Curved Surfaces:\n  A Generalized Moving Least-Squares (GMLS) Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109340", "report-no": null, "categories": "math.NA cond-mat.soft cs.CE cs.CG cs.NA q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize generalized moving least squares (GMLS) to develop meshfree\ntechniques for discretizing hydrodynamic flow problems on manifolds. We use\nexterior calculus to formulate incompressible hydrodynamic equations in the\nStokesian regime and handle the divergence-free constraints via a generalized\nvector potential. This provides less coordinate-centric descriptions and\nenables the development of efficient numerical methods and splitting schemes\nfor the fourth-order governing equations in terms of a system of second-order\nelliptic operators. Using a Hodge decomposition, we develop methods for\nmanifolds having spherical topology. We show the methods exhibit high-order\nconvergence rates for solving hydrodynamic flows on curved surfaces. The\nmethods also provide general high-order approximations for the metric,\ncurvature, and other geometric quantities of the manifold and associated\nexterior calculus operators. The approaches also can be utilized to develop\nhigh-order solvers for other scalar-valued and vector-valued problems on\nmanifolds.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 22:46:05 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 06:29:12 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Gross", "B. J.", ""], ["Trask", "N.", ""], ["Kuberry", "P.", ""], ["Atzberger", "P. J.", ""]]}, {"id": "1905.10553", "submitter": "Hasan Al-Marzouqi", "authors": "H. Sun, H. Al-Marzouqi and S. Vega", "title": "EPCI: A New Tool for Predicting Absolute Permeability from CT images", "comments": null, "journal-ref": "Geophysics 84.3 (2019): 1-29", "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new and fast Matlab algorithm for predicting absolute permeability is\npresented. The developed tool relies on measuring the connectivity of pores in\na given three-dimensional (3D) micro-CT rock image. An index of pore\nconnectivity is introduced. After a calibration step, the developed index is\nused to estimate permeability in a variety of rocks with challenging pore\nstructures (e.g. complex carbonate formations). The developed algorithm was\ntested on sandstone and carbonate rock samples. It offers large computational\nand memory savings when compared with algorithms based on the Lattice Boltzmann\nMethod (LBM). Permeability estimates were, in general, in good agreement with\nlaboratory measurements and numerical simulation results. Source code for\ncomputing the developed index along with an associated GUI panel are available\nonline at https://github.com/cupbkust/EPCI.git\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 08:08:46 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sun", "H.", ""], ["Al-Marzouqi", "H.", ""], ["Vega", "S.", ""]]}, {"id": "1905.10828", "submitter": "Evan Drumwright", "authors": "Evan Drumwright", "title": "An Unconditionally Stable First-Order Constraint Solver for Multibody\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This article describes an absolutely stable, first-order constraint solverfor\nmulti-rigid body systems that calculates (predicts) constraint forces for\ntypical bilateral and unilateral constraints, contact constraints with\nfriction, and many other constraint types. Redundant constraints do not pose\nnumerical problems or require regularization. Coulomb friction for contact is\nmodeled using a true friction cone, rather than a linearized approximation. The\ncomputational expense of the solver is dependent upon the types of constraints\npresent in the input. The hardest (in a computational complexity sense) inputs\nare reducible to solving convex optimization problems, i.e., polynomial time\nsolvable. The simplest inputs require only solving a linear system. The solver\nis L-stable, which will imply that the forces due to constraints induce no\ncomputational stiffness into the multi-body dynamics differential equations.\nThis approach is targeted to multibodies simulated with coarse accuracy,\nsubject to computational stiffness arising from constraints, and where the\nnumber of constraint equations is not large compared to the number of multibody\nposition and velocity state variables. For such applications, the approach\nshould prove far faster than using other implicit integration approaches. I\nassess the approach on some fundamental multibody dynamics problems.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 16:14:24 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Drumwright", "Evan", ""]]}, {"id": "1905.12725", "submitter": "Javier Segurado", "authors": "Sergio Lucarini and Javier Segurado", "title": "DBFFT: A displacement based FFT approach for non-linear homogenization\n  of the mechanical behavior", "comments": null, "journal-ref": "International Journal of Engineering Science 144, 103131, 2019", "doi": "10.1016/j.ijengsci.2019.103131", "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the FFT methods available for homogenization of the mechanical\nresponse use the strain/deformation gradient as unknown, imposing their\ncompatibility using Green's functions or projection operators. This implies the\nallocation of redundant information and, when the method is based in solving a\nlinear equation, the rank-deficiency of the resulting system. In this work we\npropose a fast, robust and memory-efficient FFT homogenization framework in\nwhich the displacement field on the Fourier space is the unknown: the\ndisplacement based FFT (DBFFT) algorithm. The framework allows any general\nnon-linear constitutive behavior for the phases and direct strain, stress and\nmixed control of the macroscopic load. In the linear case, the method results\nin a linear system defined in terms of linear operators in the Fourier space\nand that does not require a reference medium. The system has an associated full\nrank Hermitian matrix and can be solved using iterative Krylov solvers and\nallows the use of preconditioners. A preconditioner is proposed to improve the\nefficiency of the system resolution. Finally, some numerical examples including\nelastic, hyperelastic and viscoplastic materials are solved to check the\naccuracy and efficiency of the method. The computational cost reduction respect\nthe Galerkin-FFT was around 30%.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 08:35:09 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 10:35:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lucarini", "Sergio", ""], ["Segurado", "Javier", ""]]}, {"id": "1905.13012", "submitter": "Denys Dutykh", "authors": "Julien Berger (LOCIE), Denys Dutykh (LAMA)", "title": "Evaluation of the reliability of building energy performance models for\n  parameter estimation", "comments": "29 pages, 20 figures, 4 tables, 1 appendix, 29 references. Other\n  author's papers can be downloaded at http://www.denys-dutykh.com/", "journal-ref": "Computational Technologies (2019), Vol. 24, Number 3, pp. 4-32", "doi": "10.25743/ICT.2019.24.3.002", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fidelity of a model relies both on its accuracy to predict the physical\nphenomena and its capability to estimate unknown parameters using observations.\nThis article focuses on this second aspect by analyzing the reliability of two\nmathematical models proposed in the literature for the simulation of heat\nlosses through building walls. The first one, named DuFort-Frankel (DF), is the\nclassical heat diffusion equation combined with the DuFort-Frankel numerical\nscheme. The second is the so-called RC lumped approach, based on a simple\nordinary differential equation to compute the temperature within the wall. The\nreliability is evaluated following a two stages method. First, samples of\nobservations are generated using a pseudo-spectral numerical model for the heat\ndiffusion equation with known input parameters. The results are then modified\nby adding a noise to simulate experimental measurements. Then, for each sample\nof observation, the parameter estimation problem is solved using one of the two\nmathematical models. The reliability is assessed based on the accuracy of the\napproach to recover the unknown parameter. Three case studies are considered\nfor the estimation of (i) the heat capacity, (ii) the thermal conductivity or\n(iii) the heat transfer coefficient at the interface between the wall and the\nambient air. For all cases, the DF mathematical model has a very satisfactory\nreliability to estimate the unknown parameters without any bias. However, the\nRC model lacks of fidelity and reliability. The error on the estimated\nparameter can reach 40% for the heat capacity, 80% for the thermal conductivity\nand 450% for the heat transfer coefficient.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:39:38 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Berger", "Julien", "", "LOCIE"], ["Dutykh", "Denys", "", "LAMA"]]}, {"id": "1905.13035", "submitter": "Denys Dutykh", "authors": "Julien Berger (LOCIE), Suelen Gasparin (LAMA, PUCPR), Denys Dutykh\n  (LAMA), Nathan Mendes (PUCPR)", "title": "On the comparison of three numerical methods applied to building\n  simulation: finite-differences, RC circuit approximation and a spectral\n  method", "comments": "35 pages, 19 figures, 2 tables, 42 references. Other author's papers\n  can be downloaded at http://www.denys-dutykh.com/", "journal-ref": "Building Simulation (2020), Vol. 13, pp. 1-18", "doi": "10.1007/s12273-019-0555-z", "report-no": null, "categories": "cs.CE math.AP physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions of physical phenomena in buildings are carried out by using\nphysical models formulated as a mathematical problem and solved by means of\nnumerical methods, aiming at evaluating, for instance, the building thermal or\nhygrothermal performance by calculating distributions and fluxes of heat and\nmoisture transfer. Therefore, the choice of the numerical method is crucial\nsince it is a compromise among (i) the solution accuracy, (ii) the\ncomputational cost to obtain the solution and (iii) the complexity of the\nmethod implementation. An efficient numerical method enables to compute an\naccurate solution with a minimum computational run time (CPU). On that account,\nthis article brings an investigation on the performance of three numerical\nmethods. The first one is the standard and widely used finite-difference\napproach, while the second one is the so-called RC approach, which is a\nparticular method brought to the building physics area by means of an analogy\nof electric circuits. The third numerical method is the spectral one, which has\nbeen recently proposed to solve nonlinear diffusive problems in building\nphysics. The three methods are evaluated in terms of accuracy on the assessment\nof the dependent variable (temperature or vapor pressure) or of density of\nfluxes for three different cases: i) heat diffusion through a concrete slab,\nii) moisture diffusion through an aerated concrete slab and iii) heat diffusion\nusing measured temperatures as boundary conditions. Results highlight the\nspectral approach as the most accurate method. The RC based model with a few\nnumber of resistances does not provide accurate results for temperature and\nvapor pressure distributions neither to flux densities nor conduction loads.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:29:36 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Berger", "Julien", "", "LOCIE"], ["Gasparin", "Suelen", "", "LAMA, PUCPR"], ["Dutykh", "Denys", "", "LAMA"], ["Mendes", "Nathan", "", "PUCPR"]]}, {"id": "1905.13076", "submitter": "Iryna Kulchytska-Ruchka", "authors": "Iryna Kulchytska-Ruchka, Herbert De Gersem, and Sebastian Sch\\\"ops", "title": "An efficient steady-state analysis of the eddy current problem using a\n  parallel-in-time algorithm", "comments": null, "journal-ref": "The Tenth International Conference on Computational\n  Electromagnetics (CEM 2019), Edinburgh, UK", "doi": "10.1049/cp.2019.0113", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a parallel-in-time algorithm for efficient steady-state\nsolution of the eddy current problem. Its main idea is based on the application\nof the well-known multi-harmonic (or harmonic balance) approach as the coarse\nsolver within the periodic parallel-in-time framework. A frequency domain\nrepresentation allows for the separate calculation of each harmonic component\nin parallel and therefore accelerates the solution of the time-periodic system.\nThe presented approach is verified for a nonlinear coaxial cable model.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 14:37:33 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Kulchytska-Ruchka", "Iryna", ""], ["De Gersem", "Herbert", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1905.13166", "submitter": "Yaser Afshar", "authors": "Yaser Afshar, Saakaar Bhatnagar, Shaowu Pan, Karthik Duraisamy,\n  Shailendra Kaushik", "title": "Prediction of Aerodynamic Flow Fields Using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1007/s00466-019-01740-0", "report-no": "CM-19-0035", "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approximation model based on convolutional neural networks (CNNs) is\nproposed for flow field predictions. The CNN is used to predict the velocity\nand pressure field in unseen flow conditions and geometries given the pixelated\nshape of the object. In particular, we consider Reynolds Averaged Navier-Stokes\n(RANS) flow solutions over airfoil shapes. The CNN can automatically detect\nessential features with minimal human supervision and shown to effectively\nestimate the velocity and pressure field orders of magnitude faster than the\nRANS solver, making it possible to study the impact of the airfoil shape and\noperating conditions on the aerodynamic forces and the flow field in near-real\ntime. The use of specific convolution operations, parameter sharing, and\nrobustness to noise are shown to enhance the predictive capabilities of CNN. We\nexplore the network architecture and its effectiveness in predicting the flow\nfield for different airfoil shapes, angles of attack, and Reynolds numbers.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 16:50:38 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Afshar", "Yaser", ""], ["Bhatnagar", "Saakaar", ""], ["Pan", "Shaowu", ""], ["Duraisamy", "Karthik", ""], ["Kaushik", "Shailendra", ""]]}, {"id": "1905.13450", "submitter": "Andrea Beck", "authors": "David G Flad and Andrea D Beck and Philipp Guthke", "title": "A large eddy simulation method for DGSEM using non-linearly optimized\n  relaxation filters", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109303", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply a specifically designed dissipative spatial filter as\nsub-grid scale model within the increasingly popular discontinuous Galerkin\nmethods and the closely related flux reconstruction high order methods for\nlarge eddy simulation. The parameters of the filter kernel are optimized with\ndata obtained from direct numerical simulation, that is filtered and used as a\nground truth to fit the overall kinetic energy and dissipation rate over time.\nThe optimization is carried out for polynomial degree 3 to 10. The optimal\nkernels are rigorously tested in the limit of infinite Reynolds number flows\n(HIT and Taylor Green Vortex flow). Additionally, a brief extension to plane\nturbulent channel flow is given. Besides the overall good performance, the\nmethod is especially attractive in combination with wall modeled LES, because\nit avoids the computation of second order derivatives for very high Reynolds\nnumber flows.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 07:45:20 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 11:14:40 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Flad", "David G", ""], ["Beck", "Andrea D", ""], ["Guthke", "Philipp", ""]]}]