[{"id": "1505.00078", "submitter": "Spyridon Chatzivasileiadis", "authors": "Spyros Chatzivasileiadis, Marco Bonvini, Javier Matanza, Rongxin Yin,\n  Zhenhua Liu, Thierry Nouidui, Emre C. Kara, Rajiv Parmar, David Lorenzetti,\n  Michael Wetter, Sila Kiliccote", "title": "Cyber physical modeling of distributed resources for distribution system\n  operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-simulation platforms are necessary to study the interactions of complex\nsystems integrated in future smart grids. The Virtual Grid Integration\nLaboratory (VirGIL) is a modular co-simulation platform designed to study\ninteractions between demand response strategies, building comfort,\ncommunication networks, and power system operation. This paper presents the\ncoupling of power systems, buildings, communications and control under a master\nalgorithm. There are two objectives. First, to use a modular architecture for\nVirGIL, based on the Functional Mock-up Interface (FMI), where several\ndifferent modules can be added, exchanged, and tested. Second, to use a\ncommercial power system simulation platform, familiar to power system\noperators, such as DIgSILENT Powerfactory. This will help reduce the barriers\nto the industry for adopting such platforms, investigate and subsequently\ndeploy demand response strategies in their daily operation. VirGIL further\nintroduces the integration of the Quantized State System (QSS) methods for\nsimulation in this co-simulation platform. Results on how these systems\ninteract using a real network and consumption data are also presented.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2015 03:01:11 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Chatzivasileiadis", "Spyros", ""], ["Bonvini", "Marco", ""], ["Matanza", "Javier", ""], ["Yin", "Rongxin", ""], ["Liu", "Zhenhua", ""], ["Nouidui", "Thierry", ""], ["Kara", "Emre C.", ""], ["Parmar", "Rajiv", ""], ["Lorenzetti", "David", ""], ["Wetter", "Michael", ""], ["Kiliccote", "Sila", ""]]}, {"id": "1505.00851", "submitter": "Zifu  Wang", "authors": "Zifu Wang, Thomas Henneron and Heath Hofmann", "title": "Space-Time Galerkin Projection of Electro-Magnetic Fields", "comments": "Published at Compumag 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial Galerkin projection transfers fields between different meshes. In the\narea of finite element analysis of electromagnetic fields, it provides great\nconvenience for remeshing, multi-physics, domain decomposition methods, etc. In\nthis paper, a space-time Galerkin projection is developed in order to transfer\nfields between different spatial and temporal discretization bases.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 01:05:12 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Wang", "Zifu", ""], ["Henneron", "Thomas", ""], ["Hofmann", "Heath", ""]]}, {"id": "1505.00925", "submitter": "Sriganesh Srihari Dr", "authors": "Sriganesh Srihari and Hon Wai Leong", "title": "Parameterized Algorithms for Clustering PPI Networks", "comments": "10 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of high-throughput wet lab technologies the amount of protein\ninteraction data available publicly has increased substantially, in turn\nspurring a plethora of computational methods for in silico knowledge discovery\nfrom this data. In this paper, we focus on parameterized methods for modeling\nand solving complex computational problems encountered in such knowledge\ndiscovery from protein data. Specifically, we concentrate on three relevant\nproblems today in proteomics, namely detection of lethal proteins, functional\nmodules and alignments from protein interaction networks. We propose novel\ngraph theoretic models for these problems and devise practical parameterized\nalgorithms. At a broader level, we demonstrate how these methods can be viable\nalternatives for the several heurestic, randomized, approximation and\nsub-optimal methods by arriving at parameterized yet optimal solutions for\nthese problems. We substantiate these theoretical results by experimenting on\nreal protein interaction data of S. cerevisiae (budding yeast) and verifying\nthe results using gene ontology.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 08:59:29 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Srihari", "Sriganesh", ""], ["Leong", "Hon Wai", ""]]}, {"id": "1505.00940", "submitter": "Luca Bonaventura", "authors": "Luca Bonaventura and Roberto Ferretti", "title": "Flux form Semi-Lagrangian methods for parabolic problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-Lagrangian method for parabolic problems is proposed, that extends\nprevious work by the authors to achieve a fully conservative, flux-form\ndiscretization of linear and nonlinear diffusion equations. A basic consistency\nand convergence analysis are proposed. Numerical examples validate the proposed\nmethod and display its potential for consistent semi-Lagrangian discretization\nof advection--diffusion and nonlinear parabolic problems.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 09:54:36 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Bonaventura", "Luca", ""], ["Ferretti", "Roberto", ""]]}, {"id": "1505.00965", "submitter": "Desmond Higham J", "authors": "Desmond J. Higham", "title": "An Introduction to Multilevel Monte Carlo for Option Valuation", "comments": "Submitted to International Journal of Computer Mathematics, special\n  issue on Computational Methods in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE physics.data-an q-fin.CP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo is a simple and flexible tool that is widely used in\ncomputational finance. In this context, it is common for the quantity of\ninterest to be the expected value of a random variable defined via a stochastic\ndifferential equation. In 2008, Giles proposed a remarkable improvement to the\napproach of discretizing with a numerical method and applying standard Monte\nCarlo. His multilevel Monte Carlo method offers an order of speed up given by\nthe inverse of epsilon, where epsilon is the required accuracy. So computations\ncan run 100 times more quickly when two digits of accuracy are required. The\nmultilevel philosophy has since been adopted by a range of researchers and a\nwealth of practically significant results has arisen, most of which have yet to\nmake their way into the expository literature.\n  In this work, we give a brief, accessible, introduction to multilevel Monte\nCarlo and summarize recent results applicable to the task of option evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 11:39:16 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Higham", "Desmond J.", ""]]}, {"id": "1505.01118", "submitter": "Zifu Wang", "authors": "Zifu Wang, Zuqi Tang, Thomas Henneron, Francis Piriou and Jean-Claude\n  Mipo", "title": "Energetic Galerkin Projection of Electromagnetic Fields between\n  Different Meshes", "comments": "published at Compumag 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to project electromagnetic fields between different meshes with\nrespect to the conservation of energetic values, Galerkin projection\nformulations based on the energetic norm are developed in this communication.\nThe proposed formulations are applied to an academic example.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 18:29:28 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Wang", "Zifu", ""], ["Tang", "Zuqi", ""], ["Henneron", "Thomas", ""], ["Piriou", "Francis", ""], ["Mipo", "Jean-Claude", ""]]}, {"id": "1505.01998", "submitter": "Artur Gramacki", "authors": "Witold Andrzejewski, Artur Gramacki, Jaros{\\l}aw Gramacki", "title": "Density Estimations for Approximate Query Processing on SIMD\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate query processing (AQP) is an interesting alternative for exact\nquery processing. It is a tool for dealing with the huge data volumes where\nresponse time is more important than perfect accuracy (this is typically the\ncase during initial phase of data exploration). There are many techniques for\nAQP, one of them is based on probability density functions (PDF). PDFs are\ntypically calculated using nonparametric data-driven methods. One of the most\npopular nonparametric method is the kernel density estimator (KDE). However, a\nvery serious drawback of using KDEs is the large number of calculations\nrequired to compute them. The shape of final density function is very sensitive\nto an entity called bandwidth or smoothing parameter. Calculating it's optimal\nvalue is not a trivial task and in general is very time consuming. In this\npaper we investigate the possibility of utilizing two SIMD architectures: SSE\nCPU extensions and NVIDIA's CUDA architecture to accelerate finding of the\nbandwidth. Our experiments show orders of magnitude improvements over a simple\nsequential implementation of classical algorithms used for that task.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 11:16:49 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Andrzejewski", "Witold", ""], ["Gramacki", "Artur", ""], ["Gramacki", "Jaros\u0142aw", ""]]}, {"id": "1505.02008", "submitter": "Michal Klos", "authors": "Michal Klos, Karol Wawrzyniak and Marcin Jakubek", "title": "Decomposition of Power Flow Used for Optimizing Zonal Configurations of\n  Energy Market", "comments": "5 pages, 2 figures, IEEE European Energy Markets 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zonal configuration of energy market is often a consequence of political\nborders. However there are a few methods developed to help with zonal\ndelimitation in respect to some measures. This paper presents the approach\naiming at reduction of the loop flow effect - an element of unscheduled flows\nwhich introduces a loss of market efficiency. In order to undertake zonal\npartitioning, a detailed decomposition of power flow is performed. Next, we\nidentify the zone which is a source of the problem and enhance delimitation by\ndividing it into two zones. The procedure is illustrated by a study of simple\ncase.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 11:59:43 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Klos", "Michal", ""], ["Wawrzyniak", "Karol", ""], ["Jakubek", "Marcin", ""]]}, {"id": "1505.02710", "submitter": "Lior Pachter", "authors": "Nicolas Bray, Harold Pimentel, P\\'all Melsted and Lior Pachter", "title": "Near-optimal RNA-Seq quantification", "comments": "- Added some results (paralog analysis, allele specific expression\n  analysis, alignment comparison, accuracy analysis with TPMs) - Switched\n  bootstrap analysis to human sample from SEQC-MAQCIII - Provided link to a\n  snakefile that allows for reproducibility of all results and figures in the\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.DS q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to RNA-Seq quantification that is near optimal in\nspeed and accuracy. Software implementing the approach, called kallisto, can be\nused to analyze 30 million unaligned paired-end RNA-Seq reads in less than 5\nminutes on a standard laptop computer while providing results as accurate as\nthose of the best existing tools. This removes a major computational bottleneck\nin RNA-Seq analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 17:42:04 GMT"}, {"version": "v2", "created": "Fri, 15 May 2015 17:12:58 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bray", "Nicolas", ""], ["Pimentel", "Harold", ""], ["Melsted", "P\u00e1ll", ""], ["Pachter", "Lior", ""]]}, {"id": "1505.03532", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Kesheng Wu, Alex Sim, Michael Churchill, Jong Y. Choi,\n  Andreas Stathopoulos, Cs Chang and Scott Klasky", "title": "Towards Real-Time Detection and Tracking of Spatio-Temporal Features:\n  Blob-Filaments in Fusion Plasma", "comments": "14 pages, 40 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.DS physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel algorithm and implementation of real-time identification and tracking\nof blob-filaments in fusion reactor data is presented. Similar spatio-temporal\nfeatures are important in many other applications, for example, ignition\nkernels in combustion and tumor cells in a medical image. This work presents an\napproach for extracting these features by dividing the overall task into three\nsteps: local identification of feature cells, grouping feature cells into\nextended feature, and tracking movement of feature through overlapping in\nspace. Through our extensive work in parallelization, we demonstrate that this\napproach can effectively make use of a large number of compute nodes to detect\nand track blob-filaments in real time in fusion plasma. On a set of 30GB fusion\nsimulation data, we observed linear speedup on 1024 processes and completed\nblob detection in less than three milliseconds using Edison, a Cray XC30 system\nat NERSC.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 20:01:14 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2016 13:22:05 GMT"}, {"version": "v3", "created": "Sat, 2 Jul 2016 17:19:52 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Wu", "Lingfei", ""], ["Wu", "Kesheng", ""], ["Sim", "Alex", ""], ["Churchill", "Michael", ""], ["Choi", "Jong Y.", ""], ["Stathopoulos", "Andreas", ""], ["Chang", "Cs", ""], ["Klasky", "Scott", ""]]}, {"id": "1505.03738", "submitter": "Erik Winfree", "authors": "Casey Grun, Karthik Sarma, Brian Wolfe, Seung Woo Shin, and Erik\n  Winfree", "title": "A domain-level DNA strand displacement reaction enumerator allowing\n  arbitrary non-pseudoknotted secondary structures", "comments": "Accepted for oral presentation at Verification of Engineered\n  Molecular Devices and Programs (VEMDP), July 17, 2014, Vienna, Austria. 29\n  pages, conference version. (Revised and expanded journal version is in\n  preparation.)", "journal-ref": "Journal of the Royal Society Interface, 17: 20190866 (2020)", "doi": "10.1098/rsif.2019.0866", "report-no": null, "categories": "cs.CE cs.ET q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA strand displacement systems have proven themselves to be fertile\nsubstrates for the design of programmable molecular machinery and circuitry.\nDomain-level reaction enumerators provide the foundations for molecular\nprogramming languages by formalizing DNA strand displacement mechanisms and\nmodeling interactions at the \"domain\" level - one level of abstraction above\nmodels that explicitly describe DNA strand sequences. Unfortunately, the\nmost-developed models currently only treat pseudo-linear DNA structures, while\nmany systems being experimentally and theoretically pursued exploit a much\nbroader range of secondary structure configurations. Here, we describe a new\ndomain-level reaction enumerator that can handle arbitrary non-pseudoknotted\nsecondary structures and reaction mechanisms including association and\ndissociation, 3-way and 4-way branch migration, and direct as well as remote\ntoehold activation. To avoid polymerization that is inherent when considering\ngeneral structures, we employ a time-scale separation technique that holds in\nthe limit of low concentrations. This also allows us to \"condense\" the detailed\nreactions by eliminating fast transients, with provable guarantees of\ncorrectness for the set of reactions and their kinetics. We hope that the new\nreaction enumerator will be used in new molecular programming languages,\ncompilers, and tools for analysis and verification that treat a wider variety\nof mechanisms of interest to experimental and theoretical work. We have\nimplemented this enumerator in Python, and it is included in the DyNAMiC\nWorkbench Integrated Development Environment.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 21:26:12 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Grun", "Casey", ""], ["Sarma", "Karthik", ""], ["Wolfe", "Brian", ""], ["Shin", "Seung Woo", ""], ["Winfree", "Erik", ""]]}, {"id": "1505.03932", "submitter": "Giancarlo Crocetti", "authors": "Giancarlo Crocetti, Michael Coakley, Phil Dressner, Wanda Kellum,\n  Tamba Lamin", "title": "Using Ensemble Models in the Histological Examination of Tissue\n  Abnormalities", "comments": "4 pages, 4 tables, 3 figures. Proceedings of 12th Annual Research\n  Day, 2014 - Pace University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification models for the automatic detection of abnormalities on\nhistological samples do exists, with an active debate on the cost associated\nwith false negative diagnosis (underdiagnosis) and false positive diagnosis\n(overdiagnosis). Current models tend to underdiagnose, failing to recognize a\npotentially fatal disease.\n  The objective of this study is to investigate the possibility of\nautomatically identifying abnormalities in tissue samples through the use of an\nensemble model on data generated by histological examination and to minimize\nthe number of false negative cases.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 00:59:48 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Crocetti", "Giancarlo", ""], ["Coakley", "Michael", ""], ["Dressner", "Phil", ""], ["Kellum", "Wanda", ""], ["Lamin", "Tamba", ""]]}, {"id": "1505.04036", "submitter": "Krzysztof Gawryluk", "authors": "Krzysztof Gawryluk, Tomasz Karpiuk, Mariusz Gajda, Kazimierz\n  Rzazewski, Miroslaw Brewczyk", "title": "Unified way for computing dynamics of Bose-Einstein condensates and\n  degenerate Fermi gases", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": "10.1080/00207160.2017.1370545", "report-no": "Int. J. Comput. Math. 95, (2018) 2143-2161", "categories": "cs.CE cond-mat.quant-gas", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a very simple and efficient numerical scheme which\ncan be applied to study the dynamics of bosonic systems like, for instance,\nspinor Bose-Einstein condensates with nonlocal interactions but equally well\nworks for Fermi gases. The method we use is a modification of well known Split\nOperator Method (SOM). We carefully examine this algorithm in the case of $F=1$\nspinor Bose-Einstein condensate without and with dipolar interactions and for\nstrongly interacting two-component Fermi gas. Our extension of the SOM method\nhas many advantages: it is fast, stable, and keeps constant all the physical\nconstraints (constants of motion) at high level.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 11:30:30 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 15:05:43 GMT"}, {"version": "v3", "created": "Tue, 26 Sep 2017 07:26:13 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Gawryluk", "Krzysztof", ""], ["Karpiuk", "Tomasz", ""], ["Gajda", "Mariusz", ""], ["Rzazewski", "Kazimierz", ""], ["Brewczyk", "Miroslaw", ""]]}, {"id": "1505.04112", "submitter": "Jennifer Warrender BSc MSc", "authors": "Jennifer D. Warrender and Phillip Lord", "title": "How, What and Why to test an ontology", "comments": "4 pages, accepted at Bio-Ontologies 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology development relates to software development in that they both\ninvolve the production of formal computational knowledge. It is possible,\ntherefore, that some of the techniques used in software engineering could also\nbe used for ontologies; for example, in software engineering testing is a\nwell-established process, and part of many different methodologies.\n  The application of testing to ontologies, therefore, seems attractive. The\nKaryotype Ontology is developed using the novel Tawny-OWL library. This\nprovides a fully programmatic environment for ontology development, which\nincludes a complete test harness.\n  In this paper, we describe how we have used this harness to build an\nextensive series of tests as well as used a commodity continuous integration\nsystem to link testing deeply into our development process; this environment,\nis applicable to any OWL ontology whether written using Tawny-OWL or not.\nMoreover, we present a novel analysis of our tests, introducing a new\nclassification of what our different tests are. For each class of test, we\ndescribe why we use these tests, also by comparison to software tests. We\nbelieve that this systematic comparison between ontology and software\ndevelopment will help us move to a more agile form of ontology development.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 16:30:17 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Warrender", "Jennifer D.", ""], ["Lord", "Phillip", ""]]}, {"id": "1505.04114", "submitter": "Jennifer Warrender BSc MSc", "authors": "Jennifer D. Warrender and Phillip Lord", "title": "Scaffolding the Mitochondrial Disease Ontology from extant knowledge\n  sources", "comments": "5 pages, 1 figure, accepted at ICBO 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-medical ontologies can contain a large number of concepts. Often many of\nthese concepts are very similar to each other, and similar or identical to\nconcepts found in other bio-medical databases. This presents both a challenge\nand opportunity: maintaining many similar concepts is tedious and fastidious\nwork, which could be substantially reduced if the data could be derived from\npre-existing knowledge sources. In this paper, we describe how we have achieved\nthis for an ontology of the mitochondria using our novel ontology development\nenvironment, the Tawny-OWL library.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2015 16:35:43 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Warrender", "Jennifer D.", ""], ["Lord", "Phillip", ""]]}, {"id": "1505.04417", "submitter": "Gordon Inggs", "authors": "Gordon Inggs, David B. Thomas and Wayne Luk", "title": "A Domain Specific Approach to High Performance Heterogeneous Computing", "comments": "14 pages, preprint draft, minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of heterogeneous computing systems face two problems: firstly, in\nunderstanding the trade-off relationships between the observable\ncharacteristics of their applications, such as latency and quality of the\nresult, and secondly, how to exploit knowledge of these characteristics to\nallocate work to distributed computing platforms efficiently. A domain specific\napproach addresses both of these problems. By considering a subset of\noperations or functions, models of the observable characteristics or domain\nmetrics may be formulated in advance, and populated at run-time for task\ninstances. These metric models can then be used to express the allocation of\nwork as a constrained integer program, which can be solved using heuristics,\nmachine learning or Mixed Integer Linear Programming (MILP) frameworks. These\nclaims are illustrated using the example domain of derivatives pricing in\ncomputational finance, with the domain metrics of workload latency or makespan\nand pricing accuracy. For a large, varied workload of 128 Black-Scholes and\nHeston model-based option pricing tasks, running upon a diverse array of 16\nMulticore CPUs, GPUs and FPGAs platforms, predictions made by models of both\nthe makespan and accuracy are generally within 10% of the run-time performance.\nWhen these models are used as inputs to machine learning and MILP-based\nworkload allocation approaches, a latency improvement of up to 24 and 270 times\nover the heuristic approach is seen.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2015 17:24:10 GMT"}, {"version": "v2", "created": "Sat, 23 May 2015 14:27:48 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2016 21:40:44 GMT"}, {"version": "v4", "created": "Mon, 14 Mar 2016 07:46:31 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Inggs", "Gordon", ""], ["Thomas", "David B.", ""], ["Luk", "Wayne", ""]]}, {"id": "1505.04511", "submitter": "Simon Schilling", "authors": "Simon J. Schilling", "title": "Contribution to Temporal Fault Tree Analysis without Modularization and\n  Transformation into the State Space", "comments": "Translation into English of the german doctoral thesis \"Beitrag zur\n  dynamischen Fehlerbaumanalyse ohne Modulbildung und zustandsbasierte\n  Erweiterungen\" of Dr. Ing. Simon J. Schilling at the Bergische Universit\\\"at\n  Wuppertal\n  (http://nbn-resolving.de/urn/resolver.pl?urn=urn:nbn:de:hbz:468-20100070).\n  This translation is licensed under a Creative Commons Attribution-ShareAlike\n  4.0 License", "journal-ref": null, "doi": null, "report-no": "urn:nbn:de:hbz:468-20100070", "categories": "cs.CE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background:\n  Fault tree analysis (FTA) is a well established method for qualitative as\nwell as probabilistic reliability and safety analysis. As a Boolean model it\ndoes not support modelling of dynamic effects like sequence dependencies\nbetween fault events. This work describes a method that allows consideration of\nsequence dependencies without transformations into state-space.\n  Concept:\n  The new temporal fault tree analysis (TFTA) described in this work extends\nthe Boolean FTA. The TFTA is based on a new temporal logic which adds a concept\nof time to the Boolean logic and algebra. This allows modelling of temporal\nrelationships between events using two new temporal operators (PAND and SAND).\nWith a set of temporal logic rules, a given temporal term may be simplified to\nits temporal disjunctive normal form (TDNF) which is similar to the Boolean DNF\nbut includes event sequencies. In TDNF the top event's temporal system function\nmay be reduced to a list of minimal cutset sequences (MCSS). These allow\nqualitative analyses similar to Boolean cutset analysis in normal FTA.\nFurthermore the TFTA may also be used for probabilistic analyses without using\nstate-space models.\n  Results:\n  One significant aspect of the new TFTA described in this work is the\npossibility to take sequence dependencies into account for qualitative and\nprobabilistic analyses without state-space transformations. Among others, this\nallows for modelling of event sequencies at all levels within a fault tree, a\nreal qualitative analysis similar to the FTA's cutset analysis, and\nquantification of sequence dependencies within the same model.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 04:55:26 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Schilling", "Simon J.", ""]]}, {"id": "1505.04785", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Advances in Bioinformatics and Computational Biology: Don't take them\n  too seriously anyway", "comments": "The paper was submitted to the BIOCOMP'15 conference (Las Vegas,\n  Nevada, USA, July 27-30, 2015) and was accepted as a poster presentation.\n  arXiv admin note: text overlap with arXiv:1505.04578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few decades or so, we witness a paradigm shift in our nature\nstudies - from a data-processing based computational approach to an\ninformation-processing based cognitive approach. The process is restricted and\noften misguided by the lack of a clear understanding about what information is\nand how it should be treated in research applications (in general) and in\nbiological studies (in particular). The paper intend to provide some remedies\nfor this bizarre situation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 10:18:20 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "1505.05193", "submitter": "Steven Woodhouse", "authors": "Jasmin Fisher, Ali Sinan K\\\"oksal, Nir Piterman and Steven Woodhouse", "title": "Synthesising Executable Gene Regulatory Networks from Single-cell Gene\n  Expression Data", "comments": "Final published version to appear in Computer Aided Verification\n  (CAV), Springer, July 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental advances in biology allow researchers to obtain gene\nexpression profiles at single-cell resolution over hundreds, or even thousands\nof cells at once. These single-cell measurements provide snapshots of the\nstates of the cells that make up a tissue, instead of the population-level\naverages provided by conventional high-throughput experiments. This new data\ntherefore provides an exciting opportunity for computational modelling. In this\npaper we introduce the idea of viewing single-cell gene expression profiles as\nstates of an asynchronous Boolean network, and frame model inference as the\nproblem of reconstructing a Boolean network from its state space. We then give\na scalable algorithm to solve this synthesis problem. We apply our technique to\nboth simulated and real data. We first apply our technique to data simulated\nfrom a well established model of common myeloid progenitor differentiation. We\nshow that our technique is able to recover the original Boolean network rules.\nWe then apply our technique to a large dataset taken during embryonic\ndevelopment containing thousands of cell measurements. Our technique\nsynthesises matching Boolean networks, and analysis of these models yields new\npredictions about blood development which our experimental collaborators were\nable to verify.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 21:26:46 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 14:15:47 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Fisher", "Jasmin", ""], ["K\u00f6ksal", "Ali Sinan", ""], ["Piterman", "Nir", ""], ["Woodhouse", "Steven", ""]]}, {"id": "1505.05932", "submitter": "Sumith Yd", "authors": "Sumith YD and Shalabh C. Maroo", "title": "A new algorithm for contact angle estimation in molecular dynamics\n  simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": "InterPACKICNMM2015-48569", "categories": "cond-mat.soft cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  It is important to study contact angle of a liquid on a solid surface to\nunderstand its wetting properties, capillarity and surface interaction energy.\nWhile performing transient molecular dynamics (MD) simulations it requires\ncalculating the time evolution of contact angle. This is a tedious effort to do\nmanually or with image processing algorithms. In this work we propose a new\nalgorithm to estimate contact angle from MD simulations directly and in a\ncomputationally efficient way. This algorithm segregates the droplet molecules\nfrom the vapor molecules using Mahalanobis distance (MND) technique. Then the\ndensity is smeared onto a 2D grid using 4th order B-spline interpolation\nfunction. The vapor liquid interface data is estimated from the grid using\ndensity filtering. With the interface data a circle is fitted using Landau\nmethod. The equation of this circle is solved for obtaining the contact angle.\nThis procedure is repeated by rotating the droplet about the vertical axis. We\nhave applied this algorithm to a number of studies (different potentials and\nthermostat methods) which involves the MD simulation of water.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2015 01:20:21 GMT"}], "update_date": "2015-05-25", "authors_parsed": [["YD", "Sumith", ""], ["Maroo", "Shalabh C.", ""]]}, {"id": "1505.06282", "submitter": "Francesco Gadaleta", "authors": "Francesco Gadaleta", "title": "Are we far from correctly inferring gene interaction networks with\n  Lasso?", "comments": "7 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.GN", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Detecting the interactions of genetic compounds like genes, SNPs, proteins,\nmetabolites, etc. can potentially unravel the mechanisms behind complex traits\nand common genetic disorders. Several methods have been taken into\nconsideration for the analysis of different types of genetic data, regression\nbeing one of the most widely adopted. Without any doubt, a common data type is\nrepresented by gene expression profiles, from which gene regulatory networks\nhave been inferred with different approaches. In this work we review nine\npenalised regression methods applied to microarray data to infer the topology\nof the network of interactions. We evaluate each method with respect to the\ncomplexity of biological data. We analyse the limitations of each of them in\norder to suggest a number of precautions that should be considered to make\ntheir predictions more significant and reliable.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 07:29:22 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Gadaleta", "Francesco", ""]]}, {"id": "1505.06531", "submitter": "Tsu-Wei Chen", "authors": "Tsu-Wei Chen, Meena Abdelmaseeh, Daniel Stashuk", "title": "Affine and Regional Dynamic Time Warpng", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointwise matches between two time series are of great importance in time\nseries analysis, and dynamic time warping (DTW) is known to provide generally\nreasonable matches. There are situations where time series alignment should be\ninvariant to scaling and offset in amplitude or where local regions of the\nconsidered time series should be strongly reflected in pointwise matches. Two\ndifferent variants of DTW, affine DTW (ADTW) and regional DTW (RDTW), are\nproposed to handle scaling and offset in amplitude and provide regional\nemphasis respectively. Furthermore, ADTW and RDTW can be combined in two\ndifferent ways to generate alignments that incorporate advantages from both\nmethods, where the affine model can be applied either globally to the entire\ntime series or locally to each region. The proposed alignment methods\noutperform DTW on specific simulated datasets, and one-nearest-neighbor\nclassifiers using their associated difference measures are competitive with the\ndifference measures associated with state-of-the-art alignment methods on real\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 03:23:31 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Chen", "Tsu-Wei", ""], ["Abdelmaseeh", "Meena", ""], ["Stashuk", "Daniel", ""]]}, {"id": "1505.06550", "submitter": "Yang Li", "authors": "Yang Li and XifengYan", "title": "MSPKmerCounter: A Fast and Memory Efficient Approach for K-mer Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in next-generation genome sequencing (NGS) is to assemble\nmassive overlapping short reads that are randomly sampled from DNA fragments.\nTo complete assembling, one needs to finish a fundamental task in many leading\nassembly algorithms: counting the number of occurrences of k-mers (length-k\nsubstrings in sequences). The counting results are critical for many components\nin assembly (e.g. variants detection and read error correction). For large\ngenomes, the k-mer counting task can easily consume a huge amount of memory,\nmaking it impossible for large-scale parallel assembly on commodity servers.\n  In this paper, we develop MSPKmerCounter, a disk-based approach, to\nefficiently perform k-mer counting for large genomes using a small amount of\nmemory. Our approach is based on a novel technique called Minimum Substring\nPartitioning (MSP). MSP breaks short reads into multiple disjoint partitions\nsuch that each partition can be loaded into memory and processed individually.\nBy leveraging the overlaps among the k-mers derived from the same short read,\nMSP can achieve astonishing compression ratio so that the I/O cost can be\nsignificantly reduced. For the task of k-mer counting, MSPKmerCounter offers a\nvery fast and memory-efficient solution. Experiment results on large real-life\nshort reads data sets demonstrate that MSPKmerCounter can achieve better\noverall performance than state-of-the-art k-mer counting approaches.\n  MSPKmerCounter is available at http://www.cs.ucsb.edu/~yangli/MSPKmerCounter\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 07:21:56 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Li", "Yang", ""], ["XifengYan", "", ""]]}, {"id": "1505.06607", "submitter": "Yijie Wang", "authors": "Yijie Wang and Xiaoning Qian", "title": "Stochastic Block Coordinate Frank-Wolfe Algorithm for Large-Scale\n  Biological Network Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasingly \"big\" data available in biomedical research, deriving\naccurate and reproducible biology knowledge from such big data imposes enormous\ncomputational challenges. In this paper, motivated by recently developed\nstochastic block coordinate algorithms, we propose a highly scalable randomized\nblock coordinate Frank-Wolfe algorithm for convex optimization with general\ncompact convex constraints, which has diverse applications in analyzing\nbiomedical data for better understanding cellular and disease mechanisms. We\nfocus on implementing the derived stochastic block coordinate algorithm to\nalign protein-protein interaction networks for identifying conserved functional\npathways based on the IsoRank framework. Our derived stochastic block\ncoordinate Frank-Wolfe (SBCFW) algorithm has the convergence guarantee and\nnaturally leads to the decreased computational cost (time and space) for each\niteration. Our experiments for querying conserved functional protein complexes\nin yeast networks confirm the effectiveness of this technique for analyzing\nlarge-scale biological networks.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 12:28:03 GMT"}, {"version": "v2", "created": "Tue, 26 May 2015 17:09:21 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Wang", "Yijie", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1505.06699", "submitter": "Hao Zhuang", "authors": "Hao Zhuang, Wenjian Yu, Shih-Hung Weng, Ilgweon Kang, Jeng-Hau Lin,\n  Xiang Zhang, Ryan Coutts, Chung-Kuan Cheng", "title": "Simulation Algorithms with Exponential Integration for Time-Domain\n  Analysis of Large-Scale Power Delivery Networks", "comments": "Accepted by IEEE Transactions on Computer Aided Design of Integrated\n  Circuits and Systems (TCAD)", "journal-ref": null, "doi": "10.1109/TCAD.2016.2523908", "report-no": null, "categories": "cs.CE cs.DC cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an algorithmic framework using matrix exponentials for time-domain\nsimulation of power delivery network (PDN). Our framework can reuse factorized\nmatrices to simulate the large-scale linear PDN system with variable stepsizes.\nIn contrast, current conventional PDN simulation solvers have to use fixed\nstep-size approach in order to reuse factorized matrices generated by the\nexpensive matrix decomposition. Based on the proposed exponential integration\nframework, we design a PDN solver R-MATEX with the flexible time-stepping\ncapability. The key operation of matrix exponential and vector product (MEVP)\nis computed by the rational Krylov subspace method.\n  To further improve the runtime, we also propose a distributed computing\nframework DR-MATEX. DR-MATEX reduces Krylov subspace generations caused by\nfrequent breakpoints from a large number of current sources during simulation.\nBy virtue of the superposition property of linear system and scaling invariance\nproperty of Krylov subspace, DR-MATEX can divide the whole simulation task into\nsubtasks based on the alignments of breakpoints among those sources. The\nsubtasks are processed in parallel at different computing nodes without any\ncommunication during the computation of transient simulation. The final result\nis obtained by summing up the partial results among all the computing nodes\nafter they finish the assigned subtasks. Therefore, our computation model\nbelongs to the category known as Embarrassingly Parallel model.\n  Experimental results show R-MATEX and DR-MATEX can achieve up to around 14.4X\nand 98.0X runtime speedups over traditional trapezoidal integration based\nsolver with fixed timestep approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 17:39:17 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 06:28:51 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2016 04:54:09 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhuang", "Hao", ""], ["Yu", "Wenjian", ""], ["Weng", "Shih-Hung", ""], ["Kang", "Ilgweon", ""], ["Lin", "Jeng-Hau", ""], ["Zhang", "Xiang", ""], ["Coutts", "Ryan", ""], ["Cheng", "Chung-Kuan", ""]]}, {"id": "1505.06751", "submitter": "Ayad Ghany Ismaeel", "authors": "Ayad Ghany Ismaeel, Raghad Zuhair Yousif", "title": "Novel Mining of Cancer via Mutation in Tumor Protein P53 using Quick\n  Propagation Network", "comments": "6 Pages, 9 figures, 2 Table", "journal-ref": "International Journal of Computer Science and Electronics\n  Engineering IJCSEE, Volume 3, Issue 2, 2015", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  There is multiple databases contain datasets of TP53 gene and its tumor\nprotein P53 which believed to be involved in over 50% of human cancers cases,\nthese databases are rich as datasets covered all mutations caused diseases\n(cancers), but they haven't efficient mining method can classify and diagnosis\nmutations patient's then predict the cancer of that patient. This paper\nproposed a novel mining of cancer via mutations because there is no mining\nmethod before offers friendly, effective and flexible predict or diagnosis of\ncancers via using whole common database of TP53 gene (tumor protein P53) as\ndataset and selecting a minimum number of fields in training and testing quick\npropagation algorithm which supporting this miming method. Simulating quick\npropagation network for the train dataset shows results the Correlation\n(0.9999), R-squared (0.9998) and mean of Absolute Relative Error (0.0029),\nwhile the training for the ALL datasets (train, test and validation dataset)\nhave results the Correlation (0.9993), R-squared (0.9987) and mean of Absolute\nRelative Error (0.0057).\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2015 15:46:45 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Ismaeel", "Ayad Ghany", ""], ["Yousif", "Raghad Zuhair", ""]]}, {"id": "1505.06915", "submitter": "Jean-Philippe Vert", "authors": "K\\'evin Vervier (CBIO), Pierre Mah\\'e, Maud Tournoud, Jean-Baptiste\n  Veyrieras, Jean-Philippe Vert (CBIO)", "title": "Large-scale Machine Learning for Metagenomics Sequence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomics characterizes the taxonomic diversity of microbial communities\nby sequencing DNA directly from an environmental sample. One of the main\nchallenges in metagenomics data analysis is the binning step, where each\nsequenced read is assigned to a taxonomic clade. Due to the large volume of\nmetagenomics datasets, binning methods need fast and accurate algorithms that\ncan operate with reasonable computing requirements. While standard\nalignment-based methods provide state-of-the-art performance, compositional\napproaches that assign a taxonomic class to a DNA read based on the k-mers it\ncontains have the potential to provide faster solutions. In this work, we\ninvestigate the potential of modern, large-scale machine learning\nimplementations for taxonomic affectation of next-generation sequencing reads\nbased on their k-mers profile. We show that machine learning-based\ncompositional approaches benefit from increasing the number of fragments\nsampled from reference genome to tune their parameters, up to a coverage of\nabout 10, and from increasing the k-mer size to about 12. Tuning these models\ninvolves training a machine learning model on about 10 8 samples in 10 7\ndimensions, which is out of reach of standard soft-wares but can be done\nefficiently with modern implementations for large-scale machine learning. The\nresulting models are competitive in terms of accuracy with well-established\nalignment tools for problems involving a small to moderate number of candidate\nspecies, and for reasonable amounts of sequencing errors. We show, however,\nthat compositional approaches are still limited in their ability to deal with\nproblems involving a greater number of species, and more sensitive to\nsequencing errors. We finally confirm that compositional approach achieve\nfaster prediction times, with a gain of 3 to 15 times with respect to the\nBWA-MEM short read mapper, depending on the number of candidate species and the\nlevel of sequencing noise.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2015 12:02:04 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Vervier", "K\u00e9vin", "", "CBIO"], ["Mah\u00e9", "Pierre", "", "CBIO"], ["Tournoud", "Maud", "", "CBIO"], ["Veyrieras", "Jean-Baptiste", "", "CBIO"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1505.07335", "submitter": "Guy Karlebach", "authors": "Guy Karlebach", "title": "A Novel Algorithm for the Maximal Fit Problem in Boolean Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene regulatory networks (GRNs) are increasingly used for explaining\nbiological processes with complex transcriptional regulation. A GRN links the\nexpression levels of a set of genes via regulatory controls that gene products\nexert on one another. Boolean networks are a common modeling choice since they\nbalance between detail and ease of analysis. However, even for Boolean networks\nthe problem of fitting a given network model to an expression dataset is\nNP-Complete. Previous methods have addressed this issue heuristically or by\nfocusing on acyclic networks and specific classes of regulation functions. In\nthis paper we introduce a novel algorithm for this problem that makes use of\nsampling in order to handle large datasets. Our algorithm can handle time\nseries data for any network type and steady state data for acyclic networks.\nUsing in-silico time series data we demonstrate good performance on large\ndatasets with a significant level of noise.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2015 08:12:41 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 19:32:39 GMT"}, {"version": "v3", "created": "Mon, 20 Jun 2016 02:29:12 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Karlebach", "Guy", ""]]}]