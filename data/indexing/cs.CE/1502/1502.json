[{"id": "1502.00274", "submitter": "Igor Vladimirov", "authors": "Arash Kh. Sichani, Igor G. Vladimirov, Ian R. Petersen", "title": "A Gradient Descent Approach to Optimal Coherent Quantum LQG Controller\n  Design", "comments": "11 pages, 2 figures. A version of this paper will appear in the\n  Proceedings of the 2015 American Control Conference, July 1-3, Chicago,\n  Illinois, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CE cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the Coherent Quantum Linear Quadratic Gaussian\n(CQLQG) control problem of finding a stabilizing measurement-free quantum\ncontroller for a quantum plant so as to minimize an infinite-horizon mean\nsquare performance index for the fully quantum closed-loop system. In\ncomparison with the observation-actuation structure of classical controllers,\nthe coherent quantum feedback is less invasive to the quantum dynamics and\nquantum information. Both the plant and the controller are open quantum systems\nwhose dynamic variables satisfy the canonical commutation relations (CCRs) of a\nquantum harmonic oscillator and are governed by linear quantum stochastic\ndifferential equations (QSDEs). In order to correspond to such oscillators,\nthese QSDEs must satisfy physical realizability (PR) conditions, which are\norganised as quadratic constraints on the controller matrices and reflect the\npreservation of CCRs in time. The CQLQG problem is a constrained optimization\nproblem for the steady-state quantum covariance matrix of the plant-controller\nsystem satisfying an algebraic Lyapunov equation. We propose a gradient descent\nalgorithm equipped with adaptive stepsize selection for the numerical solution\nof the problem. The algorithm finds a local minimum of the LQG cost over the\nparameters of the Hamiltonian and coupling operators of a stabilizing PR\nquantum controller, thus taking the PR constraints into account. A convergence\nanalysis of the proposed algorithm is presented. A numerical example of a\nlocally optimal CQLQG controller design is provided to demonstrate the\nalgorithm performance.\n", "versions": [{"version": "v1", "created": "Sun, 1 Feb 2015 15:45:37 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Sichani", "Arash Kh.", ""], ["Vladimirov", "Igor G.", ""], ["Petersen", "Ian R.", ""]]}, {"id": "1502.00495", "submitter": "Ha Bui", "authors": "H. Bui, R. Fukagawa, K. Sako", "title": "A Study of the Matter of SPH Application to Saturated Soil Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an application of SPH to saturated soilproblems. Herein, the\nstandard SPH formulation was improved to model saturated soil. It is shown that\nthe proposed formulation could yield several advantages such as: it takes into\naccount the pore-water pressure in an accurate manner, it automatically\nsatisfies the dynamics boundary conditions between submerged soil and water,\nand it reduced the computational cost. Discussions on the use of the standard\nand the new SPH formulations are also given through some numerical tests.\nFurthermore, some techniques to obtained correct SPH solution are also proposed\nand discussed. To the end, this paper suggests that the proposed SPH\nformulation should be considered as the basic formulation for further\ndevelopments of SPH for soil-water couple problems\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2015 20:19:29 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Bui", "H.", ""], ["Fukagawa", "R.", ""], ["Sako", "K.", ""]]}, {"id": "1502.01119", "submitter": "Peter Peter Hansbo", "authors": "Peter Hansbo, Kent Salomonsson", "title": "A discontinuous Galerkin method for cohesive zone modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a discontinuous finite element method for small strain elasticity\nallowing for cohesive zone modeling. The method yields a seamless transition\nbetween the discontinuous Galerkin method and classical cohesive zone modeling.\nSome relevant numerical examples are presented.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 08:24:04 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Hansbo", "Peter", ""], ["Salomonsson", "Kent", ""]]}, {"id": "1502.01227", "submitter": "Xuesong Meng", "authors": "Xuesong Meng, Phillip Sewell, Sendy Phang, Ana Vukovic, Trevor M.\n  Benson", "title": "Modeling Curved Carbon Fiber Composite (CFC) Structures in the\n  Transmission-Line Modeling (TLM) Method", "comments": "8 pages, 12 figures, accepted for publication in IEEE Transactions on\n  EMC", "journal-ref": "Electromagnetic Compatibility, IEEE Transactions on (Volume:PP ,\n  Issue: 99 ), 2015", "doi": "10.1109/TEMC.2015.2400055", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new embedded model for curved thin panels is developed in the Transmission\nLine Modeling (TLM) method. In this model, curved panels are first linearized\nand then embedded between adjacent 2D TLM nodes allowing for arbitrary\npositioning between adjacent node centers. The embedded model eliminates the\nnecessity for fine discretization thus reducing the run time and memory\nrequirements for the calculation. The accuracy and convergence of the model are\nverified by comparing the resonant frequencies of an elliptical cylinder formed\nusing carbon fiber composite (CFC) materials with those of the equivalent metal\ncylinder. Furthermore, the model is used to analyze the shielding performance\nof CFC airfoil NACA2415.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 15:11:57 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Meng", "Xuesong", ""], ["Sewell", "Phillip", ""], ["Phang", "Sendy", ""], ["Vukovic", "Ana", ""], ["Benson", "Trevor M.", ""]]}, {"id": "1502.01380", "submitter": "Anna Kucerova", "authors": "Tom\\'a\\v{s} Mare\\v{s}, Eli\\v{s}ka Janouchov\\'a, and Anna\n  Ku\\v{c}erov\\'a", "title": "Artificial neural networks in calibration of nonlinear mechanical models", "comments": "26 pages, 8 figures, 11 tables, accepted for publication in Advances\n  in Engineering Software", "journal-ref": "Advances in Engineering Software, 95:68-81, 2016", "doi": "10.1016/j.advengsoft.2016.01.017", "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid development in numerical modelling of materials and the complexity of\nnew models increases quickly together with their computational demands. Despite\nthe growing performance of modern computers and clusters, calibration of such\nmodels from noisy experimental data remains a nontrivial and often\ncomputationally exhaustive task. The layered neural networks thus represent a\nrobust and efficient technique to overcome the time-consuming simulations of a\ncalibrated model. The potential of neural networks consists in simple\nimplementation and high versatility in approximating nonlinear relationships.\nTherefore, there were several approaches proposed to accelerate the calibration\nof nonlinear models by neural networks. This contribution reviews and compares\nthree possible strategies based on approximating (i) model response, (ii)\ninverse relationship between the model response and its parameters and (iii)\nerror function quantifying how well the model fits the data. The advantages and\ndrawbacks of particular strategies are demonstrated on the calibration of four\nparameters of the affinity hydration model from simulated data as well as from\nexperimental measurements. This model is highly nonlinear, but computationally\ncheap thus allowing its calibration without any approximation and better\nquantification of results obtained by the examined calibration strategies. The\npaper can be thus viewed as a guide intended for the engineers to help them\nselect an appropriate strategy in their particular calibration problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Feb 2015 22:24:35 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 20:24:04 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Mare\u0161", "Tom\u00e1\u0161", ""], ["Janouchov\u00e1", "Eli\u0161ka", ""], ["Ku\u010derov\u00e1", "Anna", ""]]}, {"id": "1502.01733", "submitter": "Othman Soufan", "authors": "Othman Soufan and Samer Arafat", "title": "Arrhythmia Detection using Mutual Information-Based Integration Method", "comments": "6 pages, 1 figure, 7 tables, WConSC 2011 conference\n  http://www.ece.ualberta.ca/~reform/WConSC/ (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to propose an application of mutual\ninformation-based ensemble methods to the analysis and classification of heart\nbeats associated with different types of Arrhythmia. Models of multilayer\nperceptrons, support vector machines, and radial basis function neural networks\nwere trained and tested using the MIT-BIH arrhythmia database. This research\nbrings a focus to an ensemble method that, to our knowledge, is a novel\napplication in the area of ECG Arrhythmia detection. The proposed classifier\nensemble method showed improved performance, relative to either majority voting\nclassifier integration or to individual classifier performance. The overall\nensemble accuracy was 98.25%.\n", "versions": [{"version": "v1", "created": "Thu, 5 Feb 2015 21:31:25 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Soufan", "Othman", ""], ["Arafat", "Samer", ""]]}, {"id": "1502.01975", "submitter": "Govinda Kamath", "authors": "Govinda M. Kamath and Eren \\c{S}a\\c{s}o\\u{g}lu and David Tse", "title": "Optimal Haplotype Assembly from High-Throughput Mate-Pair Reads", "comments": "10 pages, 4 figures, Submitted to ISIT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CE math.IT q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have $23$ pairs of homologous chromosomes. The homologous pairs are\nalmost identical pairs of chromosomes. For the most part, differences in\nhomologous chromosome occur at certain documented positions called single\nnucleotide polymorphisms (SNPs). A haplotype of an individual is the pair of\nsequences of SNPs on the two homologous chromosomes. In this paper, we study\nthe problem of inferring haplotypes of individuals from mate-pair reads of\ntheir genome. We give a simple formula for the coverage needed for haplotype\nassembly, under a generative model. The analysis here leverages connections of\nthis problem with decoding convolutional codes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2015 18:16:33 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Kamath", "Govinda M.", ""], ["\u015ea\u015fo\u011flu", "Eren", ""], ["Tse", "David", ""]]}, {"id": "1502.02223", "submitter": "Sungroh Yoon", "authors": "Sungmin Lee, Hyeyoung Min, and Sungroh Yoon", "title": "Will solid-state drives accelerate your bioinformatics? In-depth\n  profiling, performance analysis, and beyond", "comments": "Availability: http://best.snu.ac.kr/pub/biossd; to be published in\n  Briefings in Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of large-scale data has been produced in bioinformatics. In\nresponse, the need for efficient handling of biomedical big data has been\npartly met by parallel computing. However, the time demand of many\nbioinformatics programs still remains high for large-scale practical uses due\nto factors that hinder acceleration by parallelization. Recently, new\ngenerations of storage devices have emerged, such as NAND flash-based\nsolid-state drives (SSDs), and with the renewed interest in near-data\nprocessing, they are increasingly becoming acceleration methods that can\naccompany parallel processing. In certain cases, a simple drop-in replacement\nof hard disk drives (HDDs) by SSDs results in dramatic speedup. Despite the\nvarious advantages and continuous cost reduction of SSDs, there has been little\nreview of SSD-based profiling and performance exploration of important but\ntime-consuming bioinformatics programs. For an informative review, we perform\nin-depth profiling and analysis of 23 key bioinformatics programs using\nmultiple types of devices. Based on the insight we obtain from this research,\nwe further discuss issues related to design and optimize bioinformatics\nalgorithms and pipelines to fully exploit SSDs. The programs we profile cover\ntraditional and emerging areas of importance, such as alignment, assembly,\nmapping, expression analysis, variant calling, and metagenomics. We explain how\nacceleration by parallelization can be combined with SSDs for improved\nperformance and also how using SSDs can expedite important bioinformatics\npipelines, such as variant calling by the Genome Analysis Toolkit (GATK) and\ntranscriptome analysis using RNA sequencing (RNA-seq). We hope that this review\ncan provide useful directions and tips to accompany future bioinformatics\nalgorithm design procedures that properly consider new generations of powerful\nstorage devices.\n", "versions": [{"version": "v1", "created": "Sun, 8 Feb 2015 07:32:21 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2015 06:30:54 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Lee", "Sungmin", ""], ["Min", "Hyeyoung", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1502.02511", "submitter": "Behzad Ghanbarian", "authors": "Behzad Ghanbarian, Vahid Taslimitehrani, Guozhu Dong, Yakov A.\n  Pachepsky", "title": "Measurement Scale Effect on Prediction of Soil Water Retention Curve and\n  Saturated Hydraulic Conductivity", "comments": null, "journal-ref": "Journal of Hydrology (2015) Vol. 528 pp. 127-137", "doi": "10.1016/j.jhydrol.2015.06.024", "report-no": null, "categories": "cs.CE cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soil water retention curve (SWRC) and saturated hydraulic conductivity (SHC)\nare key hydraulic properties for unsaturated zone hydrology and groundwater. In\nparticular, SWRC provides useful information on entry pore-size distribution,\nand SHC is required for flow and transport modeling in the hydrologic cycle.\nNot only the SWRC and SHC measurements are time-consuming, but also scale\ndependent. This means as soil column volume increases, variability of the SWRC\nand SHC decreases. Although prediction of the SWRC and SHC from available\nparameters, such as textural data, organic matter, and bulk density have been\nunder investigation for decades, up to now no research has focused on the\neffect of measurement scale on the soil hydraulic properties pedotransfer\nfunctions development. In the literature, several data mining approaches have\nbeen applied, such as multiple linear regression, artificial neural networks,\ngroup method of data handling. However, in this study we develop pedotransfer\nfunctions using a novel approach called contrast pattern aided regression\n(CPXR) and compare it with the multiple linear regression method. For this\npurpose, two databases including 210 and 213 soil samples are collected to\ndevelop and evaluate pedotransfer functions for the SWRC and SHC, respectively,\nfrom the UNSODA database. The 10-fold cross-validation method is applied to\nevaluate the accuracy and reliability of the proposed regression-based models.\nOur results show that including measurement scale parameters, such as sample\ninternal diameter and length could substantially improve the accuracy of the\nSWRC and SHC pedotransfer functions developed using the CPXR method, while this\nis not the case when MLR is used. Moreover, the CPXR method yields remarkably\nmore accurate soil water retention curve and saturated hydraulic conductivity\npredictions than the MLR approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Feb 2015 14:54:48 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Ghanbarian", "Behzad", ""], ["Taslimitehrani", "Vahid", ""], ["Dong", "Guozhu", ""], ["Pachepsky", "Yakov A.", ""]]}, {"id": "1502.02764", "submitter": "Yu-Ting Lin", "authors": "Yu-Ting Lin", "title": "The Modeling and Quantification of Rhythmic to Non-rhythmic Phenomenon\n  in Electrocardiography during Anesthesia", "comments": "Doctoral Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variations of instantaneous heart rate appears regularly oscillatory in\ndeeper levels of anesthesia and less regular in lighter levels of anesthesia.\nIt is impossible to observe this \"rhythmic-to-non-rhythmic\" phenomenon from raw\nelectrocardiography waveform in current standard anesthesia monitors. To\nexplore the possible clinical value, I proposed the adaptive harmonic model,\nwhich fits the descriptive property in physiology, and provides adequate\nmathematical conditions for the quantification. Based on the adaptive harmonic\nmodel, multitaper Synchrosqueezing transform was used to provide time-varying\npower spectrum, which facilitates to compute the quantitative index:\n\"Non-rhythmic-to-Rhythmic Ratio\" index (NRR index). I then used a clinical\ndatabase to analyze the behavior of NRR index and compare it with other\nstandard indices of anesthetic depth. The positive statistical results suggest\nthat NRR index provides addition clinical information regarding motor reaction,\nwhich aligns with current standard tools. Furthermore, the ability to indicates\nthe noxious stimulation is an additional finding. Lastly, I have proposed an\nreal-time interpolation scheme to contribute my study further as a clinical\napplication.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 03:07:56 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Lin", "Yu-Ting", ""]]}, {"id": "1502.02824", "submitter": "Sukanta Nayak", "authors": "Sukanta Nayak and Snehashish Chakraverty", "title": "Fuzzy finite element solution of uncertain neutron diffusion equation\n  for imprecisely defined homogeneous triangular bare reactor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scattering of neutron collision inside a reactor depends upon geometry of the\nreactor, diffusion coefficient and absorption coefficient etc. In general these\nparameters are not crisp and hence we may get uncertain neutron diffusion\nequation. In this paper we have investigated the above problem for a bare\ntriangular homogeneous reactor. Here the uncertain governing differential\nequation is modelled by a modified fuzzy finite element method using newly\nproposed interval arithmetic. Obtained eigenvalues by the proposed method are\nstudied in detail. Further the eigenvalues are compared with the classical\nfinite element method in special cases and various uncertain results have been\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Feb 2015 09:37:17 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Nayak", "Sukanta", ""], ["Chakraverty", "Snehashish", ""]]}, {"id": "1502.03234", "submitter": "Paul Springer", "authors": "Paul Springer", "title": "A Scalable, Linear-Time Dynamic Cutoff Algorithm for Molecular\n  Simulations of Interfacial Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This master thesis introduces the idea of dynamic cutoffs in molecular\ndynamics simulations, based on the distance between particles and the\ninterface, and presents a solution for detecting interfaces in real-time. Our\ndynamic cutoff method (DCM) exhibits a linear-time complexity as well as nearly\nideal weak and strong scaling. The DCM is tailored for massively parallel\narchitectures and for large interfacial systems with millions of particles. We\nimplemented the DCM as part of the LAMMPS open-source molecular dynamics\npackage and demonstrate the nearly ideal weak- and strong-scaling behavior of\nthis method on an IBM BlueGene/Q supercomputer. Our results for a liquid/vapor\nsystem consisting of Lennard-Jones particles show that the accuracy of DCM is\ncomparable to that of the traditional particle-particle particle- mesh (PPPM)\nalgorithm. The performance comparison indicates that DCM is preferable for\nlarge systems due to the limited scaling of FFTs within the PPPM algorithm.\nMoreover, the DCM requires the interface to be identified every other MD\ntimestep. As a consequence, this thesis also presents an interface detection\nmethod which is (1) applicable in real time; (2) parallelizable; and (3) scales\nlinearly with respect to the number of particles.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 09:44:26 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Springer", "Paul", ""]]}, {"id": "1502.03379", "submitter": "Anthony Labarre", "authors": "Philippe Gambette and Andreas D. M. Gunawan and Anthony Labarre and\n  St\\'ephane Vialette and Louxin Zhang", "title": "Locating a Tree in a Phylogenetic Network in Quadratic Time", "comments": "Accepted to RECOMB 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in the study of phylogenetic networks is to determine\nwhether or not a given phylogenetic network contains a given phylogenetic tree.\nWe develop a quadratic-time algorithm for this problem for binary nearly-stable\nphylogenetic networks. We also show that the number of reticulations in a\nreticulation visible or nearly stable phylogenetic network is bounded from\nabove by a function linear in the number of taxa.\n", "versions": [{"version": "v1", "created": "Wed, 11 Feb 2015 17:07:06 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Gambette", "Philippe", ""], ["Gunawan", "Andreas D. M.", ""], ["Labarre", "Anthony", ""], ["Vialette", "St\u00e9phane", ""], ["Zhang", "Louxin", ""]]}, {"id": "1502.03645", "submitter": "Andreas Kreienbuehl", "authors": "Andreas Kreienbuehl, Arne Naegel, Daniel Ruprecht, Robert Speck,\n  Gabriel Wittum, and Rolf Krause", "title": "Numerical simulation of skin transport using Parareal", "comments": "11 pages, 8 figures", "journal-ref": "Computing and Visualization in Science 17(2), pp. 99-108, 2015", "doi": "10.1007/s00791-015-0246-y", "report-no": null, "categories": "cs.CE cs.DC cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-silico investigation of skin permeation is an important but also\ncomputationally demanding problem. To resolve all scales involved in full\ndetail will not only require exascale computing capacities but also suitable\nparallel algorithms. This article investigates the applicability of the\ntime-parallel Parareal algorithm to a brick and mortar setup, a precursory\nproblem to skin permeation. The C++ library Lib4PrM implementing Parareal is\ncombined with the UG4 simulation framework, which provides the spatial\ndiscretization and parallelization. The combination's performance is studied\nwith respect to convergence and speedup. It is confirmed that anisotropies in\nthe domain and jumps in diffusion coefficients only have a minor impact on\nParareal's convergence. The influence of load imbalances in time due to\ndifferences in number of iterations required by the spatial solver as well as\nspatio-temporal weak scaling is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 13:21:09 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2015 13:23:04 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Kreienbuehl", "Andreas", ""], ["Naegel", "Arne", ""], ["Ruprecht", "Daniel", ""], ["Speck", "Robert", ""], ["Wittum", "Gabriel", ""], ["Krause", "Rolf", ""]]}, {"id": "1502.03774", "submitter": "Aiswarya Iyer", "authors": "Aiswarya Iyer, S. Jeyalatha, Ronak Sumbaly", "title": "Diagnosis of diabetes using classification mining techniques", "comments": null, "journal-ref": "International Journal of Data Mining & Knowledge Management\n  Process (IJDKP), Vol.5, No.1, January 2015, pp. 1-14", "doi": "10.5121/ijdkp.2015.5101", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes has affected over 246 million people worldwide with a majority of\nthem being women. According to the WHO report, by 2025 this number is expected\nto rise to over 380 million. The disease has been named the fifth deadliest\ndisease in the United States with no imminent cure in sight. With the rise of\ninformation technology and its continued advent into the medical and healthcare\nsector, the cases of diabetes as well as their symptoms are well documented.\nThis paper aims at finding solutions to diagnose the disease by analyzing the\npatterns found in the data through classification analysis by employing\nDecision Tree and Na\\\"ive Bayes algorithms. The research hopes to propose a\nquicker and more efficient technique of diagnosing the disease, leading to\ntimely treatment of the patients.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 19:07:19 GMT"}], "update_date": "2015-02-13", "authors_parsed": [["Iyer", "Aiswarya", ""], ["Jeyalatha", "S.", ""], ["Sumbaly", "Ronak", ""]]}, {"id": "1502.05041", "submitter": "Ngoc Hieu Tran", "authors": "Ngoc Hieu Tran and Xin Chen", "title": "AMAS: optimizing the partition and filtration of adaptive seeds to speed\n  up read mapping", "comments": "IEEE/ACM Transactions on Computational Biology and Bioinformatics,\n  2016", "journal-ref": null, "doi": "10.1109/TCBB.2015.2465900", "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Identifying all possible mapping locations of next-generation\nsequencing (NGS) reads is highly essential in several applications such as\nprediction of genomic variants or protein binding motifs located in repeat\nregions, isoform expression quantification, metagenomics analysis, etc.\nHowever, this task is very time-consuming and majority of mapping tools only\nfocus on one or a few best mapping locations. Results: We propose AMAS, an\nalignment tool specialized in identifying all possible mapping locations of NGS\nreads in a reference sequence. AMAS features an effective use of adaptive seeds\nto speed up read mapping while preserving sensitivity. Specifically, an index\nis designed to pre-store the locations of adaptive seeds in the reference\nsequence, efficiently reducing the time for seed matching and partitioning. An\naccurate filtration of adaptive seeds is further applied to substantially\ntighten the candidate alignment space. As a result, AMAS runs several times\nfaster than other state-of-the-art read mappers while achieving similar\naccuracy. Conclusions: AMAS provides a valuable resource to speed up the\nimportant yet time-consuming task of identifying all mapping locations of NGS\nreads. AMAS is implemented in C++ based on the SeqAn library and is freely\navailable at https://sourceforge.net/projects/ngsamas/. Keywords:\nnext-generation sequencing, read mapping, sequence alignment, adaptive seeds,\nseed partition, filtration\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2015 02:59:08 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Tran", "Ngoc Hieu", ""], ["Chen", "Xin", ""]]}, {"id": "1502.05911", "submitter": "Uwe Aickelin", "authors": "Alexandros Ladas, Eamonn Ferguson, Uwe Aickelin and Jon Garibaldi", "title": "A Data Mining framework to model Consumer Indebtedness with\n  Psychological Factors", "comments": "IEEE International Conference of Data Mining: The Seventh\n  International Workshop on Domain Driven Data Mining 2014 (DDDM 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling Consumer Indebtedness has proven to be a problem of complex nature.\nIn this work we utilise Data Mining techniques and methods to explore the\nmultifaceted aspect of Consumer Indebtedness by examining the contribution of\nPsychological Factors, like Impulsivity to the analysis of Consumer Debt. Our\nresults confirm the beneficial impact of Psychological Factors in modelling\nConsumer Indebtedness and suggest a new approach in analysing Consumer Debt,\nthat would take into consideration more Psychological characteristics of\nconsumers and adopt techniques and practices from Data Mining.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 15:47:49 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Ladas", "Alexandros", ""], ["Ferguson", "Eamonn", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jon", ""]]}, {"id": "1502.05938", "submitter": "Uwe Aickelin", "authors": "Jenna Reps, Uwe Aickelin", "title": "Incorporating Spontaneous Reporting System Data to Aid Causal Inference\n  in Longitudinal Healthcare Data", "comments": "IEEE International Conference of Data Mining: The Fifth Workshop on\n  Biological Data Mining and its Applications in Healthcare, 2014", "journal-ref": null, "doi": "10.1109/ICDMW.2014.54", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring causality using longitudinal observational databases is challenging\ndue to the passive way the data are collected. The majority of associations\nfound within longitudinal observational data are often non-causal and occur due\nto confounding.\n  The focus of this paper is to investigate incorporating information from\nadditional databases to complement the longitudinal observational database\nanalysis. We investigate the detection of prescription drug side effects as\nthis is an example of a causal relationship. In previous work a framework was\nproposed for detecting side effects only using longitudinal data. In this paper\nwe combine a measure of association derived from mining a spontaneous reporting\nsystem database to previously proposed analysis that extracts domain expertise\nfeatures for causal analysis of a UK general practice longitudinal database.\n  The results show that there is a significant improvement to the performance\nof detecting prescription drug side effects when the longitudinal observation\ndata analysis is complemented by incorporating additional drug safety sources\ninto the framework. The area under the receiver operating characteristic curve\n(AUC) for correctly classifying a side effect when other data were considered\nwas 0.967, whereas without it the AUC was 0.923 However, the results of this\npaper may be biased by the evaluation and future work should overcome this by\ndeveloping an unbiased reference set.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 17:03:36 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Reps", "Jenna", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1502.05943", "submitter": "Uwe Aickelin", "authors": "Jenna M. Reps, Uwe Aickelin, Jiangang Ma, Yanchun Zhang", "title": "Refining Adverse Drug Reactions using Association Rule Mining for\n  Electronic Healthcare Data", "comments": "IEEE International Conference of Data Mining: Data Mining in\n  Biomedical Informatics and Healthcare (DMBIH) Workshop 2014, 2014", "journal-ref": null, "doi": "10.1109/ICDMW.2014.53", "report-no": null, "categories": "cs.DB cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side effects of prescribed medications are a common occurrence. Electronic\nhealthcare databases present the opportunity to identify new side effects\nefficiently but currently the methods are limited due to confounding (i.e. when\nan association between two variables is identified due to them both being\nassociated to a third variable).\n  In this paper we propose a proof of concept method that learns common\nassociations and uses this knowledge to automatically refine side effect\nsignals (i.e. exposure-outcome associations) by removing instances of the\nexposure-outcome associations that are caused by confounding. This leaves the\nsignal instances that are most likely to correspond to true side effect\noccurrences. We then calculate a novel measure termed the confounding-adjusted\nrisk value, a more accurate absolute risk value of a patient experiencing the\noutcome within 60 days of the exposure.\n  Tentative results suggest that the method works. For the four signals (i.e.\nexposure-outcome associations) investigated we are able to correctly filter the\nmajority of exposure-outcome instances that were unlikely to correspond to true\nside effects. The method is likely to improve when tuning the association rule\nmining parameters for specific health outcomes.\n  This paper shows that it may be possible to filter signals at a patient level\nbased on association rules learned from considering patients' medical\nhistories. However, additional work is required to develop a way to automate\nthe tuning of the method's parameters.\n", "versions": [{"version": "v1", "created": "Fri, 20 Feb 2015 17:14:17 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Reps", "Jenna M.", ""], ["Aickelin", "Uwe", ""], ["Ma", "Jiangang", ""], ["Zhang", "Yanchun", ""]]}, {"id": "1502.06256", "submitter": "Gregory Kucherov", "authors": "Karel Brinda and Maciej Sykulski and Gregory Kucherov", "title": "Spaced seeds improve k-mer-based metagenomic classification", "comments": "23 pages", "journal-ref": "Bioinformatics (2015) 31 (22): 3584-3592", "doi": "10.1093/bioinformatics/btv419", "report-no": null, "categories": "q-bio.GN cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomics is a powerful approach to study genetic content of environmental\nsamples that has been strongly promoted by NGS technologies. To cope with\nmassive data involved in modern metagenomic projects, recent tools [4, 39] rely\non the analysis of k-mers shared between the read to be classified and sampled\nreference genomes. Within this general framework, we show in this work that\nspaced seeds provide a significant improvement of classification accuracy as\nopposed to traditional contiguous k-mers. We support this thesis through a\nseries a different computational experiments, including simulations of\nlarge-scale metagenomic projects. Scripts and programs used in this study, as\nwell as supplementary material, are available from\nhttp://github.com/gregorykucherov/spaced-seeds-for-metagenomics.\n", "versions": [{"version": "v1", "created": "Sun, 22 Feb 2015 18:30:58 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 18:25:54 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 09:47:00 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Brinda", "Karel", ""], ["Sykulski", "Maciej", ""], ["Kucherov", "Gregory", ""]]}, {"id": "1502.06434", "submitter": "Barack Wanjawa Mr.", "authors": "B. W. Wanjawa and L. Muchemi", "title": "ANN Model to Predict Stock Prices at Stock Exchange Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock exchanges are considered major players in financial sectors of many\ncountries. Most Stockbrokers, who execute stock trade, use technical,\nfundamental or time series analysis in trying to predict stock prices, so as to\nadvise clients. However, these strategies do not usually guarantee good returns\nbecause they guide on trends and not the most likely price. It is therefore\nnecessary to explore improved methods of prediction.\n  The research proposes the use of Artificial Neural Network that is\nfeedforward multi-layer perceptron with error backpropagation and develops a\nmodel of configuration 5:21:21:1 with 80% training data in 130,000 cycles. The\nresearch develops a prototype and tests it on 2008-2012 data from stock markets\ne.g. Nairobi Securities Exchange and New York Stock Exchange, where prediction\nresults show MAPE of between 0.71% and 2.77%. Validation done with Encog and\nNeuroph realized comparable results. The model is thus capable of prediction on\ntypical stock markets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 06:59:18 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Wanjawa", "B. W.", ""], ["Muchemi", "L.", ""]]}, {"id": "1502.06564", "submitter": "Raul Isea", "authors": "Raul Isea, Esther Montes, Antonio J. Rubio-Montero and Rafael Mayo", "title": "Challenges and characterization of a Biological system on Grid by means\n  of the PhyloGrid application", "comments": "8 pages, 3 figures, appears in Proceedings of the First EELA-2\n  Conference, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC q-bio.QM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this work we present a new application that is being developed. PhyloGrid\nis able to perform large-scale phylogenetic calculations as those that have\nbeen made for estimating the phylogeny of all the sequences already stored in\nthe public NCBI database. The further analysis has been focused on checking the\norigin of the HIV-1 disease by means of a huge number of sequences that sum up\nto 2900 taxa. Such a study has been able to be done by the implementation of a\nworkflow in Taverna.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 13:19:29 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Isea", "Raul", ""], ["Montes", "Esther", ""], ["Rubio-Montero", "Antonio J.", ""], ["Mayo", "Rafael", ""]]}, {"id": "1502.07758", "submitter": "Jonathan Blackman", "authors": "Jonathan Blackman, Scott E. Field, Chad R. Galley, Bela Szilagyi, Mark\n  A. Scheel, Manuel Tiglio, Daniel A. Hemberger", "title": "Fast and accurate prediction of numerical relativity waveforms from\n  binary black hole coalescences using surrogate models", "comments": "Updated to published version, which includes a section comparing the\n  surrogate and effective-one-body models. The surrogate is publicly available\n  for download at http://www.black-holes.org/surrogates/ . 6 pages, 6 figures", "journal-ref": "Phys. Rev. Lett. 115, 121102 (2015)", "doi": "10.1103/PhysRevLett.115.121102", "report-no": null, "categories": "gr-qc astro-ph.HE cs.CE physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating a binary black hole (BBH) coalescence by solving Einstein's\nequations is computationally expensive, requiring days to months of\nsupercomputing time. Using reduced order modeling techniques, we construct an\naccurate surrogate model, which is evaluated in a millisecond to a second, for\nnumerical relativity (NR) waveforms from non-spinning BBH coalescences with\nmass ratios in $[1, 10]$ and durations corresponding to about $15$ orbits\nbefore merger. We assess the model's uncertainty and show that our modeling\nstrategy predicts NR waveforms {\\em not} used for the surrogate's training with\nerrors nearly as small as the numerical error of the NR code. Our model\nincludes all spherical-harmonic ${}_{-2}Y_{\\ell m}$ waveform modes resolved by\nthe NR code up to $\\ell=8.$ We compare our surrogate model to Effective One\nBody waveforms from $50$-$300 M_\\odot$ for advanced LIGO detectors and find\nthat the surrogate is always more faithful (by at least an order of magnitude\nin most cases).\n", "versions": [{"version": "v1", "created": "Thu, 26 Feb 2015 21:01:55 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2015 21:42:57 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Blackman", "Jonathan", ""], ["Field", "Scott E.", ""], ["Galley", "Chad R.", ""], ["Szilagyi", "Bela", ""], ["Scheel", "Mark A.", ""], ["Tiglio", "Manuel", ""], ["Hemberger", "Daniel A.", ""]]}, {"id": "1502.07816", "submitter": "Joshua Glaser", "authors": "Joshua I. Glaser, Bradley M. Zamft, George M. Church, Konrad P.\n  Kording", "title": "Puzzle Imaging: Using Large-scale Dimensionality Reduction Algorithms\n  for Localization", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0131593", "report-no": null, "categories": "q-bio.NC cs.CE cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current high-resolution imaging techniques require an intact sample that\npreserves spatial relationships. We here present a novel approach, \"puzzle\nimaging,\" that allows imaging a spatially scrambled sample. This technique\ntakes many spatially disordered samples, and then pieces them back together\nusing local properties embedded within the sample. We show that puzzle imaging\ncan efficiently produce high-resolution images using dimensionality reduction\nalgorithms. We demonstrate the theoretical capabilities of puzzle imaging in\nthree biological scenarios, showing that (1) relatively precise 3-dimensional\nbrain imaging is possible; (2) the physical structure of a neural network can\noften be recovered based only on the neural connectivity matrix; and (3) a\nchemical map could be reproduced using bacteria with chemosensitive DNA and\nconjugative transfer. The ability to reconstruct scrambled images promises to\nenable imaging based on DNA sequencing of homogenized tissue samples.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 04:55:54 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2015 07:16:17 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2015 19:17:03 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Glaser", "Joshua I.", ""], ["Zamft", "Bradley M.", ""], ["Church", "George M.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1502.07847", "submitter": "Carleton Coffrin", "authors": "Carleton Coffrin, Hassan L. Hijazi, Pascal Van Hentenryck", "title": "The QC Relaxation: Theoretical and Computational Results on Optimal\n  Power Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex relaxations of the power flow equations and, in particular, the\nSemi-Definite Programming (SDP) and Second-Order Cone (SOC) relaxations, have\nattracted significant interest in recent years. The Quadratic Convex (QC)\nrelaxation is a departure from these relaxations in the sense that it imposes\nconstraints to preserve stronger links between the voltage variables through\nconvex envelopes of the polar representation. This paper is a systematic study\nof the QC relaxation for AC Optimal Power Flow with realistic side constraints.\nThe main theoretical result shows that the QC relaxation is stronger than the\nSOC relaxation and neither dominates nor is dominated by the SDP relaxation. In\naddition, comprehensive computational results show that the QC relaxation may\nproduce significant improvements in accuracy over the SOC relaxation at a\nreasonable computational cost, especially for networks with tight bounds on\nphase angle differences. The QC and SOC relaxations are also shown to be\nsignificantly faster and reliable compared to the SDP relaxation given the\ncurrent state of the respective solvers.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 09:59:10 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2015 05:30:52 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Coffrin", "Carleton", ""], ["Hijazi", "Hassan L.", ""], ["Van Hentenryck", "Pascal", ""]]}]