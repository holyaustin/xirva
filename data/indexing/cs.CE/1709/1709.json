[{"id": "1709.00086", "submitter": "Deborah Bard", "authors": "Brian Friesen, Md. Mostofa Ali Patwary, Brian Austin, Nadathur Satish,\n  Zachary Slepian, Narayanan Sundaram, Deborah Bard, Daniel J Eisenstein, Jack\n  Deslippe, Pradeep Dubey, Prabhat", "title": "Galactos: Computing the Anisotropic 3-Point Correlation Function for 2\n  Billion Galaxies", "comments": "11 pages, 7 figures, accepted to SuperComputing 2017", "journal-ref": null, "doi": "10.1145/3126908.3126927", "report-no": null, "categories": "astro-ph.CO cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nature of dark energy and the complete theory of gravity are two central\nquestions currently facing cosmology. A vital tool for addressing them is the\n3-point correlation function (3PCF), which probes deviations from a spatially\nrandom distribution of galaxies. However, the 3PCF's formidable computational\nexpense has prevented its application to astronomical surveys comprising\nmillions to billions of galaxies. We present Galactos, a high-performance\nimplementation of a novel, O(N^2) algorithm that uses a load-balanced k-d tree\nand spherical harmonic expansions to compute the anisotropic 3PCF. Our\nimplementation is optimized for the Intel Xeon Phi architecture, exploiting\nSIMD parallelism, instruction and thread concurrency, and significant L1 and L2\ncache reuse, reaching 39% of peak performance on a single node. Galactos scales\nto the full Cori system, achieving 9.8PF (peak) and 5.06PF (sustained) across\n9636 nodes, making the 3PCF easily computable for all galaxies in the\nobservable universe.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 21:14:32 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Friesen", "Brian", ""], ["Patwary", "Md. Mostofa Ali", ""], ["Austin", "Brian", ""], ["Satish", "Nadathur", ""], ["Slepian", "Zachary", ""], ["Sundaram", "Narayanan", ""], ["Bard", "Deborah", ""], ["Eisenstein", "Daniel J", ""], ["Deslippe", "Jack", ""], ["Dubey", "Pradeep", ""], ["Prabhat", "", ""]]}, {"id": "1709.00402", "submitter": "Qingyuan Hu", "authors": "Qingyuan Hu, Yang Xia, Sundararajan Natarajan, Andreas Zilian, Ping\n  Hu, St\\'ephane P.A. Bordas", "title": "Isogeometric analysis of thin Reissner-Mindlin plates and shells:\n  locking phenomena and B-bar method", "comments": "32 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a local type of B-bar formulation, addressing locking in\ndegenerated Reissner-Mindlin plate and shell formulations in the context of\nisogeometric analysis. Parasitic strain components are projected onto the\nphysical space locally, i.e. at the element level, using a least-squares\napproach. The formulation allows the flexible utilization of basis functions of\ndifferent order as the projection bases. The present formulation is much\ncheaper computationally than the classical $\\bar{B}$ method. We show the\nnumerical consistency of the scheme through numerical examples, moreover they\nshow that the proposed formulation alleviates locking and yields good accuracy\neven for slenderness ratios of $1 \\times 10^5$, and has the ability to capture\ndeformations of thin shells using relatively coarse meshes. In addition it can\nbe opined that the proposed method is less sensitive to locking and mesh\ndistortion.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 17:51:52 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 12:48:12 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Hu", "Qingyuan", ""], ["Xia", "Yang", ""], ["Natarajan", "Sundararajan", ""], ["Zilian", "Andreas", ""], ["Hu", "Ping", ""], ["Bordas", "St\u00e9phane P. A.", ""]]}, {"id": "1709.00821", "submitter": "Ximin Wang", "authors": "Lang-lang Xiong, Xi-min Wang, Song Liu, Zhi-yun Peng, and Shuang-ying\n  Zhong", "title": "The electromagnetic waves propagation in unmagnetized plasma media using\n  parallelized finite-difference time-domain method", "comments": "12 pages,3 figures", "journal-ref": "Lang-lang Xiong, Xi-min Wang, Song Liu, Zhi-yun Peng, Shuang-ying\n  Zhong, The electromagnetic waves propagation in unmagnetized plasma media\n  using parallelized finite-difference time-domain method, Optik, Volume 166,\n  August 2018, Pages 8-14", "doi": "10.1016/j.ijleo.2018.03.136", "report-no": null, "categories": "physics.comp-ph cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The finite-difference time-domain (FDTD) method has been commonly utilized to\nsimulate the electromagnetic (EM) waves propagation in the plasma media.\nHowever, the FDTD method may bring about extra run-time on concerning\ncomputationally large and complicated EM problems. Fortunately, the FDTD method\nis easy to parallelize. Besides, GPU has been widely used for parallel\ncomputing due to its unique SPMD (Single Program Multiple Data) architecture.\nIn this paper, we represent the parallel Runge-Kutta exponential time\ndifferencing scheme FDTD (RKETD) method for the unmagnetized plasma implemented\non GPU. The detailed flowchart of parallel RKETD-FDTD method is described. The\naccuracy and acceleration performance of the proposed parallel RKETD-FDTD\nmethod implemented on GPU are substantiated by calculating the reflection and\ntransmission coefficients for one-dimensional unmagnetized plasma slab. The\nresults indicate that the numerical precision of the parallel RKETD-FDTD scheme\nis consistent with that of the code implemented on CPU. The computation\nefficiency is greatly improved compared with merely CPU-based serial RKETD-FDTD\nmethod. Moreover, the comparisons of the performance of CUDA-based GPU parallel\nprogram, OpenMP (Open Multi-Processing)-based CPU parallel program, and\nsingle-CPU serial program on the same host computer are done. Compared with the\nserial program, both parallel programs get good results, while GPU-based\nparallel program gains better result.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 06:01:46 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 08:53:31 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 04:28:15 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Xiong", "Lang-lang", ""], ["Wang", "Xi-min", ""], ["Liu", "Song", ""], ["Peng", "Zhi-yun", ""], ["Zhong", "Shuang-ying", ""]]}, {"id": "1709.00913", "submitter": "Bilen Emek Abali", "authors": "Bilen Emek Abali", "title": "An accurate finite element method for the numerical solution of\n  isothermal and incompressible flow of viscous fluid", "comments": null, "journal-ref": null, "doi": "10.3390/fluids4010005", "report-no": null, "categories": "cs.CE math.NA physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its numerical challenges, finite element method is used to compute\nviscous fluid flow. A consensus on the cause of numerical problems has been\nreached; however, general algorithms---allowing a robust and accurate\nsimulation for any process---are still missing. Either a very high\ncomputational cost is necessary for a direct numerical solution (DNS) or some\nlimiting procedure is used by adding artificial dissipation to the system.\nThese stabilization methods are useful; however, they are often applied\nrelative to the element size such that a local monotonous convergence is\nchallenging to acquire. We need a computational strategy for solving viscous\nfluid flow using solely the balance equations. In this work, we present a\ngeneral procedure solving fluid mechanics problems without use of any\nstabilization or splitting schemes. Hence, its generalization to multiphysics\napplications is straightforward. We discuss emerging numerical problems and\npresent the methodology rigorously. Implementation is achieved by using\nopen-source packages and the accuracy as well as the robustness is demonstrated\nby comparing results to the closed-form solutions and also by solving\nwell-known benchmarking problems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 12:21:10 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 20:15:42 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 19:40:19 GMT"}, {"version": "v4", "created": "Sat, 8 Dec 2018 13:37:46 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Abali", "Bilen Emek", ""]]}, {"id": "1709.00939", "submitter": "Nagoor Kani Jabarullah Khan", "authors": "J.Nagoor Kani, Ahmed H. Elsheikh", "title": "DR-RNN: A deep residual recurrent neural network for model reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep residual recurrent neural network (DR-RNN) as an\nefficient model reduction technique for nonlinear dynamical systems. The\ndeveloped DR-RNN is inspired by the iterative steps of line search methods in\nfinding the residual minimiser of numerically discretized differential\nequations. We formulate this iterative scheme as stacked recurrent neural\nnetwork (RNN) embedded with the dynamical structure of the emulated\ndifferential equations. Numerical examples demonstrate that DR-RNN can\neffectively emulate the full order models of nonlinear physical systems with a\nsignificantly lower number of parameters in comparison to standard RNN\narchitectures. Further, we combined DR-RNN with Proper Orthogonal Decomposition\n(POD) for model reduction of time dependent partial differential equations. The\npresented numerical results show the stability of proposed DR-RNN as an\nexplicit reduced order technique. We also show significant gains in accuracy by\nincreasing the depth of proposed DR-RNN similar to other applications of deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 13:17:20 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Kani", "J. Nagoor", ""], ["Elsheikh", "Ahmed H.", ""]]}, {"id": "1709.01268", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Martin Magris, Juho Kanniainen, Moncef Gabbouj,\n  Alexandros Iosifidis", "title": "Tensor Representation in High-Frequency Financial Data for Price Change\n  Prediction", "comments": "accepted in SSCI 2017, typos fixed", "journal-ref": "IEEE Symposium Series on Computational Intelligence (SSCI), 2017", "doi": "10.1109/SSCI.2017.8280812", "report-no": null, "categories": "cs.CE cs.LG cs.NA q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the availability of massive amount of trade data collected,\nthe dynamics of the financial markets pose both a challenge and an opportunity\nfor high frequency traders. In order to take advantage of the rapid, subtle\nmovement of assets in High Frequency Trading (HFT), an automatic algorithm to\nanalyze and detect patterns of price change based on transaction records must\nbe available. The multichannel, time-series representation of financial data\nnaturally suggests tensor-based learning algorithms. In this work, we\ninvestigate the effectiveness of two multilinear methods for the mid-price\nprediction problem against other existing methods. The experiments in a large\nscale dataset which contains more than 4 millions limit orders show that by\nutilizing tensor representation, multilinear models outperform vector-based\napproaches and other competing ones.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 07:48:33 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 05:14:34 GMT"}, {"version": "v3", "created": "Mon, 2 Oct 2017 17:33:50 GMT"}, {"version": "v4", "created": "Tue, 28 Nov 2017 11:03:45 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Magris", "Martin", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1709.02513", "submitter": "Biswarup Bhattacharya", "authors": "Biswarup Bhattacharya and Abhishek Sinha", "title": "Intelligent Subset Selection of Power Generators for Economic Dispatch", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainable and economical generation of electrical power is an essential and\nmandatory component of infrastructure in today's world. Optimal generation\n(generator subset selection) of power requires a careful evaluation of various\nfactors like type of source, generation, transmission & storage capacities,\ncongestion among others which makes this a difficult task. We created a grid to\nsimulate various conditions including stimuli like generator supply, weather\nand load demand using Siemens PSS/E software and this data is trained using\ndeep learning methods and subsequently tested. The results are highly\nencouraging. As per our knowledge, this is the first paper to propose a working\nand scalable deep learning model for this problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 02:54:59 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Bhattacharya", "Biswarup", ""], ["Sinha", "Abhishek", ""]]}, {"id": "1709.03611", "submitter": "Zheqing Zhu", "authors": "Zheqing Zhu and Jian-guo Liu and Lei Li", "title": "A Modified Levy Jump-Diffusion Model Based on Market Sentiment Memory\n  for Online Jump Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a modified Levy jump diffusion model with market\nsentiment memory for stock prices, where the market sentiment comes from data\nmining implementation using Tweets on Twitter. We take the market sentiment\nprocess, which has memory, as the signal of Levy jumps in the stock price. An\nonline learning and optimization algorithm with the Unscented Kalman filter\n(UKF) is then proposed to learn the memory and to predict possible price jumps.\nExperiments show that the algorithm provides a relatively good performance in\nidentifying asset return trends.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 22:06:00 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Zhu", "Zheqing", ""], ["Liu", "Jian-guo", ""], ["Li", "Lei", ""]]}, {"id": "1709.03747", "submitter": "Nicolas Pignet", "authors": "Micka\\\"el Abbas, Alexandre Ern, Nicolas Pignet", "title": "Hybrid High-Order methods for finite deformations of hyperelastic\n  materials", "comments": "29 pages", "journal-ref": null, "doi": "10.1007/s00466-018-1538-0", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise and evaluate numerically Hybrid High-Order (HHO) methods for\nhyperelastic materials undergoing finite deformations. The HHO methods use as\ndiscrete unknowns piecewise polynomials of order $k\\ge1$ on the mesh skeleton,\ntogether with cell-based polynomials that can be eliminated locally by static\ncondensation. The discrete problem is written as the minimization of the broken\nnonlinear elastic energy where a local reconstruction of the displacement\ngradient is used. Two HHO methods are considered: a stabilized method where the\ngradient is reconstructed as a tensor-valued polynomial of order $k$ and a\nstabilization is added to the discrete energy functional, and an unstabilized\nmethod which reconstructs a stable higher-order gradient and circumvents the\nneed for stabilization. Both methods satisfy the principle of virtual work\nlocally with equilibrated tractions. We present a numerical study of both HHO\nmethods on test cases with known solution and on more challenging\nthree-dimensional test cases including finite deformations with strong shear\nlayers and cavitating voids. We assess the computational efficiency of both\nmethods, and we compare our results to those obtained with an industrial\nsoftware using conforming finite elements and to results from the literature.\nBoth methods exhibit robust behavior in the quasi-incompressible regime.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 09:03:07 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 10:12:37 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 12:46:19 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Abbas", "Micka\u00ebl", ""], ["Ern", "Alexandre", ""], ["Pignet", "Nicolas", ""]]}, {"id": "1709.04070", "submitter": "Christopher Rook", "authors": "Christopher J. Rook", "title": "Multivariate Density Modeling for Retirement Finance", "comments": "Full C/C++ implementation is included in the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior to the financial crisis mortgage securitization models increased in\nsophistication as did products built to insure against losses. Layers of\ncomplexity formed upon a foundation that could not support it and as the\nfoundation crumbled the housing market followed. That foundation was the\nGaussian copula which failed to correctly model failure-time correlations of\nderivative securities in duress. In retirement, surveys suggest the greatest\nfear is running out of money and as retirement decumulation models become\nincreasingly sophisticated, large financial firms and robo-advisors may\nguarantee their success. Similar to an investment bank failure the event of\nretirement ruin is driven by outliers and correlations in times of stress. It\nwould be desirable to have a foundation able to support the increased\ncomplexity before it forms however the industry currently relies upon similar\nGaussian (or lognormal) dependence structures. We propose a multivariate\ndensity model having fixed marginals that is tractable and fits data which are\nskewed, heavy-tailed, multimodal, i.e., of arbitrary complexity allowing for a\nrich correlation structure. It is also ideal for stress-testing a retirement\nplan by fitting historical data seeded with black swan events. A preliminary\nsection reviews all concepts before they are used and fully documented C/C++\nsource code is attached making the research self-contained. Lastly, we take the\nopportunity to challenge existing retirement finance dogma and also review some\nrecent criticisms of retirement ruin probabilities and their suggested\nreplacement metrics.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 22:12:04 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Rook", "Christopher J.", ""]]}, {"id": "1709.04620", "submitter": "Takashi Shinzato", "authors": "Daichi Tada, Hisashi Yamamoto and Takashi Shinzato", "title": "Random matrix approach for primal-dual portfolio optimization problems", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": "10.7566/JPSJ.86.124804", "report-no": null, "categories": "q-fin.PM cond-mat.dis-nn cs.CE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the portfolio optimization problems of the\nminimization/maximization of investment risk under constraints of budget and\ninvestment concentration (primal problem) and the maximization/minimization of\ninvestment concentration under constraints of budget and investment risk (dual\nproblem) for the case that the variances of the return rates of the assets are\nidentical. We analyze both optimization problems by using the Lagrange\nmultiplier method and the random matrix approach. Thereafter, we compare the\nresults obtained from our proposed approach with the results obtained in\nprevious work. Moreover, we use numerical experiments to validate the results\nobtained from the replica approach and the random matrix approach as methods\nfor analyzing both the primal and dual portfolio optimization problems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 05:45:45 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 12:25:38 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Tada", "Daichi", ""], ["Yamamoto", "Hisashi", ""], ["Shinzato", "Takashi", ""]]}, {"id": "1709.05254", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Damian Borth, Andreas Dengel and Bernd\n  Reimer", "title": "Detection of Anomalies in Large Scale Accounting Data using Deep\n  Autoencoder Networks", "comments": "19 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to detect fraud in large-scale accounting data is one of the\nlong-standing challenges in financial statement audits or fraud investigations.\nNowadays, the majority of applied techniques refer to handcrafted rules derived\nfrom known fraud scenarios. While fairly successful, these rules exhibit the\ndrawback that they often fail to generalize beyond known fraud scenarios and\nfraudsters gradually find ways to circumvent them. To overcome this\ndisadvantage and inspired by the recent success of deep learning we propose the\napplication of deep autoencoder neural networks to detect anomalous journal\nentries. We demonstrate that the trained network's reconstruction error\nobtainable for a journal entry and regularized by the entry's individual\nattribute probabilities can be interpreted as a highly adaptive anomaly\nassessment. Experiments on two real-world datasets of journal entries, show the\neffectiveness of the approach resulting in high f1-scores of 32.93 (dataset A)\nand 16.95 (dataset B) and less false positive alerts compared to state of the\nart baseline methods. Initial feedback received by chartered accountants and\nfraud examiners underpinned the quality of the approach in capturing highly\nrelevant accounting anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 15:07:29 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 15:47:52 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Borth", "Damian", ""], ["Dengel", "Andreas", ""], ["Reimer", "Bernd", ""]]}, {"id": "1709.05261", "submitter": "Wenbin Wu", "authors": "Wenbin Wu and Mugen Peng", "title": "A Data Mining Approach Combining K-Means Clustering with Bagging Neural\n  Network for Short-term Wind Power Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wind power forecasting (WPF) is significant to guide the dispatching of grid\nand the production planning of wind farm effectively. The intermittency and\nvolatility of wind leading to the diversity of the training samples have a\nmajor impact on the forecasting accuracy. In this paper, to deal with the\ntraining samples dynamics and improve the forecasting accuracy, a data mining\napproach consisting of K-means clustering and bagging neural network is\nproposed for short-term WPF. Based on the similarity among historical days,\nK-means clustering is used to classify the samples into several categories,\nwhich contain the information of meteorological conditions and historical power\ndata. In order to overcome the over fitting and instability problems of\nconventional networks, a bagging-based ensemble approach is integrated into the\nback propagation neural network. To confirm the effectiveness, the proposed\ndata mining approach is examined on real wind generation data traces. The\nsimulation results show that it can obtain better forecasting accuracy than\nother baseline and existed short-term WPF approaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 13:59:28 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Wu", "Wenbin", ""], ["Peng", "Mugen", ""]]}, {"id": "1709.05832", "submitter": "Frits de Prenter", "authors": "Frits de Prenter, Christoph Lehrenfeld and Andr\\'e Massing", "title": "A note on the penalty parameter in Nitsche's method for unfitted\n  boundary value problems", "comments": null, "journal-ref": "Computers & Mathematics with applications 2018", "doi": "10.1016/j.camwa.2018.03.032", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nitsche's method is a popular approach to implement Dirichlet-type boundary\nconditions in situations where a strong imposition is either inconvenient or\nsimply not feasible. The method is widely applied in the context of unfitted\nfinite element methods. From the classical (symmetric) Nitsche's method it is\nwell-known that the stabilization parameter in the method has to be chosen\nsufficiently large to obtain unique solvability of discrete systems. In this\nshort note we discuss an often used strategy to set the stabilization parameter\nand describe a possible problem that can arise from this. We show that in\nspecific situations error bounds can deteriorate and give examples of\ncomputations where Nitsche's method yields large and even diverging\ndiscretization errors.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 09:33:54 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["de Prenter", "Frits", ""], ["Lehrenfeld", "Christoph", ""], ["Massing", "Andr\u00e9", ""]]}, {"id": "1709.06004", "submitter": "Sebastian Sch\\\"ops", "authors": "Zeger Bontinck, Jacopo Corno, Herbert De Gersem, Stefan Kurz, Andreas\n  Pels, Sebastian Sch\\\"ops, Felix Wolf, Carlo de Falco, J\\\"urgen D\\\"olz, Rafael\n  V\\'azquez and Ulrich R\\\"omer", "title": "Recent Advances of Isogeometric Analysis in Computational\n  Electromagnetics", "comments": "submitted to the ICS Newsletter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this communication the advantages and drawbacks of the isogeometric\nanalysis (IGA) are reviewed in the context of electromagnetic simulations. IGA\nextends the set of polynomial basis functions, commonly employed by the\nclassical Finite Element Method (FEM). While identical to FEM with\nN\\'ed\\'elec's basis functions in the lowest order case, it is based on B-spline\nand Non-Uniform Rational B-spline basis functions. The main benefit of this is\nthe exact representation of the geometry in the language of computer aided\ndesign (CAD) tools. This simplifies the meshing as the computational mesh is\nimplicitly created by the engineer using the CAD tool. The curl- and\ndiv-conforming spline function spaces are recapitulated and the available\nsoftware is discussed. Finally, several non-academic benchmark examples in two\nand three dimensions are shown which are used in optimization and uncertainty\nquantification workflows.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 15:21:23 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Bontinck", "Zeger", ""], ["Corno", "Jacopo", ""], ["De Gersem", "Herbert", ""], ["Kurz", "Stefan", ""], ["Pels", "Andreas", ""], ["Sch\u00f6ps", "Sebastian", ""], ["Wolf", "Felix", ""], ["de Falco", "Carlo", ""], ["D\u00f6lz", "J\u00fcrgen", ""], ["V\u00e1zquez", "Rafael", ""], ["R\u00f6mer", "Ulrich", ""]]}, {"id": "1709.06483", "submitter": "Lukas Einkemmer", "authors": "N. Auer and L. Einkemmer and P. Kandolf and A. Ostermann", "title": "Magnus integrators on multicore CPUs and GPUs", "comments": null, "journal-ref": "Computer Physics Communications, Volume 228, Pages 115-122, 2018", "doi": "10.1016/j.cpc.2018.02.019", "report-no": null, "categories": "physics.comp-ph cs.CE cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we consider numerical methods to solve the discrete\nSchr\\\"odinger equation with a time dependent Hamiltonian (motivated by problems\nencountered in the study of spin systems). We will consider both short-range\ninteractions, which lead to evolution equations involving sparse matrices, and\nlong-range interactions, which lead to dense matrices. Both of these settings\nshow very different computational characteristics. We use Magnus integrators\nfor time integration and employ a framework based on Leja interpolation to\ncompute the resulting action of the matrix exponential. We consider both\ntraditional Magnus integrators (which are extensively used for these types of\nproblems in the literature) as well as the recently developed commutator-free\nMagnus integrators and implement them on modern CPU and GPU (graphics\nprocessing unit) based systems.\n  We find that GPUs can yield a significant speed-up (up to a factor of $10$ in\nthe dense case) for these types of problems. In the sparse case GPUs are only\nadvantageous for large problem sizes and the achieved speed-ups are more\nmodest. In most cases the commutator-free variant is superior but especially on\nthe GPU this advantage is rather small. In fact, none of the advantage of\ncommutator-free methods on GPUs (and on multi-core CPUs) is due to the\nelimination of commutators. This has important consequences for the design of\nmore efficient numerical methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 15:13:04 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 13:19:03 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Auer", "N.", ""], ["Einkemmer", "L.", ""], ["Kandolf", "P.", ""], ["Ostermann", "A.", ""]]}, {"id": "1709.06743", "submitter": "Leon Thurner", "authors": "Leon Thurner, Alexander Scheidler, Florian Sch\\\"afer, Jan-Hendrik\n  Menke, Julian Dollichon, Friederike Meier, Steffen Meinecke and Martin Braun", "title": "pandapower - an Open Source Python Tool for Convenient Modeling,\n  Analysis and Optimization of Electric Power Systems", "comments": null, "journal-ref": null, "doi": "10.1109/TPWRS.2018.2829021", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  pandapower is a Python based, BSD-licensed power system analysis tool aimed\nat automation of static and quasi-static analysis and optimization of balanced\npower systems. It provides power flow, optimal power flow, state estimation,\ntopological graph searches and short circuit calculations according to IEC\n60909. pandapower includes a Newton-Raphson power flow solver formerly based on\nPYPOWER, which has been accelerated with just-in-time compilation. Additional\nenhancements to the solver include the capability to model constant current\nloads, grids with multiple reference nodes and a connectivity check. The\npandapower network model is based on electric elements, such as lines, two and\nthree-winding transformers or ideal switches. All elements can be defined with\nnameplate parameters and are internally processed with equivalent circuit\nmodels, which have been validated against industry standard software tools. The\ntabular data structure used to define networks is based on the Python library\npandas, which allows comfortable handling of input and output parameters. The\nimplementation in Python makes pandapower easy to use and allows comfortable\nextension with third-party libraries. pandapower has been successfully applied\nin several grid studies as well as for educational purposes. A comprehensive,\npublicly available case-study demonstrates a possible application of pandapower\nin an automated time series calculation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 07:14:52 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 13:51:30 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2018 15:11:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Thurner", "Leon", ""], ["Scheidler", "Alexander", ""], ["Sch\u00e4fer", "Florian", ""], ["Menke", "Jan-Hendrik", ""], ["Dollichon", "Julian", ""], ["Meier", "Friederike", ""], ["Meinecke", "Steffen", ""], ["Braun", "Martin", ""]]}, {"id": "1709.06793", "submitter": "Daniel Drzisga", "authors": "Simon Bauer, Daniel Drzisga, Marcus Mohr, Ulrich Ruede, Christian\n  Waluga, Barbara Wohlmuth", "title": "A stencil scaling approach for accelerating matrix-free finite element\n  implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to fast on-the-fly low order finite element\nassembly for scalar elliptic partial differential equations of Darcy type with\nvariable coefficients optimized for matrix-free implementations. Our approach\nintroduces a new operator that is obtained by appropriately scaling the\nreference stiffness matrix from the constant coefficient case. Assuming\nsufficient regularity, an a priori analysis shows that solutions obtained by\nthis approach are unique and have asymptotically optimal order convergence in\nthe $H^1$- and the $L^2$-norm on hierarchical hybrid grids. For the\npre-asymptotic regime, we present a local modification that guarantees uniform\nellipticity of the operator. Cost considerations show that our novel approach\nrequires roughly one third of the floating-point operations compared to a\nclassical finite element assembly scheme employing nodal integration. Our\ntheoretical considerations are illustrated by numerical tests that confirm the\nexpectations with respect to accuracy and run-time. A large scale application\nwith more than a hundred billion ($1.6\\cdot10^{11}$) degrees of freedom\nexecuted on 14,310 compute cores demonstrates the efficiency of the new scaling\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 09:58:20 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 09:02:23 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bauer", "Simon", ""], ["Drzisga", "Daniel", ""], ["Mohr", "Marcus", ""], ["Ruede", "Ulrich", ""], ["Waluga", "Christian", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "1709.07068", "submitter": "Sebastian Sch\\\"ops", "authors": "Jennifer Dutin\\'e and Markus Clemens and Sebastian Sch\\\"ops", "title": "Survey on Semi-Explicit Time Integration of Eddy Current Problems", "comments": "accepted by the SCEE 2016 proceedings to be published in the Springer\n  Series \"Mathematics in Industry\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial discretization of the magnetic vector potential formulation of\nmagnetoquasistatic field problems results in an infinitely stiff\ndifferential-algebraic equation system. It is transformed into a finitely stiff\nordinary differential equation system by applying a generalized Schur\ncomplement. Applying the explicit Euler time integration scheme to this system\nresults in a small maximum stable time step size. Fast computations are\nrequired in every time step to yield an acceptable overall simulation time.\nSeveral acceleration methods are presented.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 20:12:41 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Dutin\u00e9", "Jennifer", ""], ["Clemens", "Markus", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1709.07527", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen, Alberto Bemporad", "title": "A posteriori multi-stage optimal trading under transaction costs and a\n  diversification constraint", "comments": "25 pages, 4 figures, 6 tables", "journal-ref": "The Journal of Trading Summer 2018, 13 (3) 67-83", "doi": "10.3905/jot.2018.1.064", "report-no": null, "categories": "q-fin.PM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple method for a posteriori (historical)\nmulti-variate multi-stage optimal trading under transaction costs and a\ndiversification constraint. Starting from a given amount of money in some\ncurrency, we analyze the stage-wise optimal allocation over a time horizon with\npotential investments in multiple currencies and various assets. Three variants\nare discussed, including unconstrained trading frequency, a fixed number of\ntotal admissable trades, and the waiting of a specific time-period after every\nexecuted trade until the next trade. The developed methods are based on\nefficient graph generation and consequent graph search, and are evaluated\nquantitatively on real-world data. The fundamental motivation of this work is\npreparatory labeling of financial time-series data for supervised machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 22:04:39 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 14:31:16 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Plessen", "Mogens Graf", ""], ["Bemporad", "Alberto", ""]]}, {"id": "1709.07841", "submitter": "Simon Mak", "authors": "Shiang-Ting Yeh, Xingjian Wang, Chih-Li Sung, Simon Mak, Yu-Hung\n  Chang, Liwei Zhang, C. F. Jeff Wu, Vigor Yang", "title": "Data-Driven Analysis and Common Proper Orthogonal Decomposition\n  (CPOD)-Based Spatio-Temporal Emulator for Design Exploration", "comments": "52 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes a data-driven framework trained with high-fidelity\nsimulation results to facilitate decision making for combustor designs. At its\ncore is a surrogate model employing a machine-learning technique called\nkriging, which is combined with data-driven basis functions to extract and\nmodel the underlying coherent structures. This emulation framework encompasses\nkey design parameter sensitivity analysis, physics-guided classification of\ndesign parameter sets, and flow evolution modeling for efficient design survey.\nTo better inform the model of quantifiable physical knowledge, a sensitivity\nanalysis using Sobol' indices and a decision tree are incorporated into the\nframework. This information improves the surrogate model training process,\nwhich employs basis functions as regression functions over the design space for\nthe kriging model. The novelty of the proposed approach is the construction of\nthe model through Common Proper Orthogonal Decomposition, which allows for\ndata-reduction and extraction of common coherent structures. The accuracy of\nprediction of mean flow features for new swirl injector designs is assessed and\nthe dynamic flowfield is captured in the form of power spectrum densities. This\ndata-driven framework also demonstrates the uncertainty quantification of\npredictions, providing a metric for model fit. The significantly reduced\ncomputation time required for evaluating new design points enables efficient\nsurvey of the design space.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 21:11:57 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Yeh", "Shiang-Ting", ""], ["Wang", "Xingjian", ""], ["Sung", "Chih-Li", ""], ["Mak", "Simon", ""], ["Chang", "Yu-Hung", ""], ["Zhang", "Liwei", ""], ["Wu", "C. F. Jeff", ""], ["Yang", "Vigor", ""]]}, {"id": "1709.08225", "submitter": "Stefanos Papanikolaou", "authors": "Stefanos Papanikolaou, Michail Tzimas, Andrew C.E. Reid and Stephen A.\n  Langer", "title": "Learning crystal plasticity using digital image correlation: Examples\n  from discrete dislocation dynamics", "comments": "35 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.stat-mech cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital image correlation (DIC) is a well-established, non-invasive technique\nfor tracking and quantifying the deformation of mechanical samples under\nstrain. While it provides an obvious way to observe incremental and aggregate\ndisplacement information, it seems likely that DIC data sets, which after all\nreflect the spatially-resolved response of a microstructure to loads, contain\nmuch richer information than has generally been extracted from them. In this\npaper, we demonstrate a machine-learning approach to quantifying the prior\ndeformation history of a crystalline sample based on its response to a\nsubsequent DIC test. This prior deformation history is encoded in the\nmicrostructure through the inhomogeneity of the dislocation microstructure, and\nin the spatial correlations of the dislocation patterns, which mediate the\nsystem's response to the DIC test load. Our domain consists of deformed\ncrystalline thin films generated by a discrete dislocation plasticity\nsimulation. We explore the range of applicability of machine learning (ML) for\ntypical experimental protocols, and as a function of possible size effects and\nstochasticity. Plasticity size effects may directly influence the data,\nrendering unsupervised techniques unable to distinguish different plasticity\nregimes.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 17:30:51 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 15:55:15 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Papanikolaou", "Stefanos", ""], ["Tzimas", "Michail", ""], ["Reid", "Andrew C. E.", ""], ["Langer", "Stephen A.", ""]]}, {"id": "1709.09122", "submitter": "Santiago Badia Sb", "authors": "Santiago Badia, Francesc Verdugo, Alberto F. Mart\\'in", "title": "The aggregated unfitted finite element method for elliptic problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2018.03.022", "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfitted finite element techniques are valuable tools in different\napplications where the generation of body-fitted meshes is difficult. However,\nthese techniques are prone to severe ill conditioning problems that obstruct\nthe efficient use of iterative Krylov methods and, in consequence, hinders the\npractical usage of unfitted methods for realistic large scale applications. In\nthis work, we present a technique that addresses such conditioning problems by\nconstructing enhanced finite element spaces based on a cell aggregation\ntechnique. The presented method, called aggregated unfitted finite element\nmethod, is easy to implement, and can be used, in contrast to previous works,\nin Galerkin approximations of coercive problems with conforming Lagrangian\nfinite element spaces. The mathematical analysis of the new method states that\nthe condition number of the resulting linear system matrix scales as in\nstandard finite elements for body-fitted meshes, without being affected by\nsmall cut cells, and that the method leads to the optimal finite element\nconvergence order. These theoretical results are confirmed with 2D and 3D\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 16:39:26 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Badia", "Santiago", ""], ["Verdugo", "Francesc", ""], ["Mart\u00edn", "Alberto F.", ""]]}, {"id": "1709.09235", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Dongkun Zhang and George Em Karniadakis", "title": "An Atomistic Fingerprint Algorithm for Learning Ab Initio Molecular\n  Force Fields", "comments": null, "journal-ref": null, "doi": "10.1063/1.5008630", "report-no": null, "categories": "cs.CE physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular fingerprints, i.e. feature vectors describing atomistic\nneighborhood configurations, is an important abstraction and a key ingredient\nfor data-driven modeling of potential energy surface and interatomic force. In\nthis paper, we present the Density-Encoded Canonically Aligned Fingerprint\n(DECAF) fingerprint algorithm, which is robust and efficient, for fitting\nper-atom scalar and vector quantities. The fingerprint is essentially a\ncontinuous density field formed through the superimposition of smoothing\nkernels centered on the atoms. Rotational invariance of the fingerprint is\nachieved by aligning, for each fingerprint instance, the neighboring atoms onto\na local canonical coordinate frame computed from a kernel minisum optimization\nprocedure. We show that this approach is superior over PCA-based methods\nespecially when the atomistic neighborhood is sparse and/or contains symmetry.\nWe propose that the `distance' between the density fields be measured using a\nvolume integral of their pointwise difference. This can be efficiently computed\nusing optimal quadrature rules, which only require discrete sampling at a small\nnumber of grid points. We also experiment on the choice of weight functions for\nconstructing the density fields, and characterize their performance for fitting\ninteratomic potentials. The applicability of the fingerprint is demonstrated\nthrough a set of benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 19:49:32 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 03:44:30 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 05:48:08 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Tang", "Yu-Hang", ""], ["Zhang", "Dongkun", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1709.09510", "submitter": "Christoph Meier", "authors": "Christoph Meier and Ryan W. Penny and Yu Zou and Jonathan S. Gibbs and\n  A. John Hart", "title": "Thermophysical Phenomena in Metal Additive Manufacturing by Selective\n  Laser Melting: Fundamentals, Modeling, Simulation and Experimentation", "comments": null, "journal-ref": null, "doi": "10.1615/AnnualRevHeatTransfer.2018019042", "report-no": null, "categories": "physics.app-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many additive manufacturing (AM) processes for metallic materials,\nselective laser melting (SLM) is arguably the most versatile in terms of its\npotential to realize complex geometries along with tailored microstructure.\nHowever, the complexity of the SLM process, and the need for predictive\nrelation of powder and process parameters to the part properties, demands\nfurther development of computational and experimental methods. This review\naddresses the fundamental physical phenomena of SLM, with a special emphasis on\nthe associated thermal behavior. Simulation and experimental methods are\ndiscussed according to three primary categories. First, macroscopic approaches\naim to answer questions at the component level and consider for example the\ndetermination of residual stresses or dimensional distortion effects prevalent\nin SLM. Second, mesoscopic approaches focus on the detection of defects such as\nexcessive surface roughness, residual porosity or inclusions that occur at the\nmesoscopic length scale of individual powder particles. Third, microscopic\napproaches investigate the metallurgical microstructure evolution resulting\nfrom the high temperature gradients and extreme heating and cooling rates\ninduced by the SLM process. Consideration of physical phenomena on all of these\nthree length scales is mandatory to establish the understanding needed to\nrealize high part quality in many applications, and to fully exploit the\npotential of SLM and related metal AM processes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 13:18:18 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Meier", "Christoph", ""], ["Penny", "Ryan W.", ""], ["Zou", "Yu", ""], ["Gibbs", "Jonathan S.", ""], ["Hart", "A. John", ""]]}, {"id": "1709.09723", "submitter": "Yingzhuo Zhang", "authors": "Yingzhuo Zhang, Noa Malem-Shinitski, Stephen A Allsop, Kay Tye and\n  Demba Ba", "title": "Estimating a Separably-Markov Random Field (SMuRF) from Binary\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in neuroscience is to characterize the dynamics of\nspiking from the neurons in a circuit that is involved in learning about a\nstimulus or a contingency. A key limitation of current methods to analyze\nneural spiking data is the need to collapse neural activity over time or\ntrials, which may cause the loss of information pertinent to understanding the\nfunction of a neuron or circuit. We introduce a new method that can determine\nnot only the trial-to-trial dynamics that accompany the learning of a\ncontingency by a neuron, but also the latency of this learning with respect to\nthe onset of a conditioned stimulus. The backbone of the method is a separable\ntwo-dimensional (2D) random field (RF) model of neural spike rasters, in which\nthe joint conditional intensity function of a neuron over time and trials\ndepends on two latent Markovian state sequences that evolve separately but in\nparallel. Classical tools to estimate state-space models cannot be applied\nreadily to our 2D separable RF model. We develop efficient statistical and\ncomputational tools to estimate the parameters of the separable 2D RF model. We\napply these to data collected from neurons in the pre-frontal cortex (PFC) in\nan experiment designed to characterize the neural underpinnings of the\nassociative learning of fear in mice. Overall, the separable 2D RF model\nprovides a detailed, interpretable, characterization of the dynamics of neural\nspiking that accompany the learning of a contingency.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 20:18:48 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Zhang", "Yingzhuo", ""], ["Malem-Shinitski", "Noa", ""], ["Allsop", "Stephen A", ""], ["Tye", "Kay", ""], ["Ba", "Demba", ""]]}, {"id": "1709.10048", "submitter": "Daniel Aubram", "authors": "Daniel Aubram", "title": "Notes on rate equations in nonlinear continuum mechanics", "comments": "47 pages, 4 figures, 105 references, some minor typos removed [v2]", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.class-ph cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper gives an introduction to rate equations in nonlinear continuum\nmechanics which should obey specific transformation rules. Emphasis is placed\non the geometrical nature of the operations involved in order to clarify the\ndifferent concepts. The paper is particularly concerned with common classes of\nconstitutive equations based on corotational stress rates and their proper\nimplementation in time for solving initial boundary value problems. Hypoelastic\nsimple shear is considered as an example application for the derived theory and\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 16:31:29 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 09:38:37 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Aubram", "Daniel", ""]]}, {"id": "1709.10069", "submitter": "Sebastian Sch\\\"ops", "authors": "David Duque and Tomas Gotthans and Renaud Gillon and Sebastian\n  Sch\\\"ops", "title": "An Extended Analytic Model for the Heating of Bondwires", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extended analytic formula for the calculation of the\ntemperature profile along a bondwire embedded in a package. The resulting\nclosed formula is built by coupling the heat transfer equations of the bondwire\nand the surrounding moulding compound by means of auxiliary variables that stem\nfrom an \\emph{ad-hoc} linearisation and mediate the wire-mould thermal\ninteraction. The model, which corrects typical simplifications in previously\nintroduced analytic models, is also optimised against carefully taken\nexperimental samples representing fusing events of bondwires within real\npackages.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:19:50 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Duque", "David", ""], ["Gotthans", "Tomas", ""], ["Gillon", "Renaud", ""], ["Sch\u00f6ps", "Sebastian", ""]]}]