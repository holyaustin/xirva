[{"id": "1111.0379", "submitter": "Jakub Truszkowski", "authors": "Daniel G. Brown and Jakub Truszkowski", "title": "Fast reconstruction of phylogenetic trees using locality-sensitive\n  hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first sub-quadratic time algorithm that with high probability\ncorrectly reconstructs phylogenetic trees for short sequences generated by a\nMarkov model of evolution. Due to rapid expansion in sequence databases, such\nvery fast algorithms are becoming necessary. Other fast heuristics have been\ndeveloped for building trees from very large alignments (Price et al, and Brown\net al), but they lack theoretical performance guarantees. Our new algorithm\nruns in $O(n^{1+\\gamma(g)}\\log^2n)$ time, where $\\gamma$ is an increasing\nfunction of an upper bound on the branch lengths in the phylogeny, the upper\nbound $g$ must be below$1/2-\\sqrt{1/8} \\approx 0.15$, and $\\gamma(g)<1$ for all\n$g$. For phylogenies with very short branches, the running time of our\nalgorithm is close to linear. For example, if all branch lengths correspond to\na mutation probability of less than 0.02, the running time of our algorithm is\nroughly $O(n^{1.2}\\log^2n)$. Via a prototype and a sequence of large-scale\nexperiments, we show that many large phylogenies can be reconstructed fast,\nwithout compromising reconstruction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 04:21:19 GMT"}, {"version": "v2", "created": "Thu, 31 May 2012 07:28:25 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Brown", "Daniel G.", ""], ["Truszkowski", "Jakub", ""]]}, {"id": "1111.1414", "submitter": "Christoph Raeth", "authors": "C. Raeth, M. Gliozzi, I. E. Papadakis, W. Brinkmann", "title": "Revisiting algorithms for generating surrogate time series", "comments": "5 pages, 4 figures, accepted for publication in PRL", "journal-ref": null, "doi": "10.1103/PhysRevLett.109.144101", "report-no": null, "categories": "physics.data-an astro-ph.HE cs.CE nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of surrogates is one of the key concepts of nonlinear data\nanalysis. Here, we demonstrate that commonly used algorithms for generating\nsurrogates often fail to generate truly linear time series. Rather, they create\nsurrogate realizations with Fourier phase correlations leading to\nnon-detections of nonlinearities. We argue that reliable surrogates can only be\ngenerated, if one tests separately for static and dynamic nonlinearities.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 12:59:28 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2012 18:11:57 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Raeth", "C.", ""], ["Gliozzi", "M.", ""], ["Papadakis", "I. E.", ""], ["Brinkmann", "W.", ""]]}, {"id": "1111.1426", "submitter": "Rajat Roy", "authors": "Rajat S. Roy, Kevin C. Chen, Anirvan M. Sengupta, Alexander Schliep", "title": "SLIQ: Simple Linear Inequalities for Efficient Contig Scaffolding", "comments": "16 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaffolding is an important subproblem in \"de novo\" genome assembly in which\nmate pair data are used to construct a linear sequence of contigs separated by\ngaps. Here we present SLIQ, a set of simple linear inequalities derived from\nthe geometry of contigs on the line that can be used to predict the relative\npositions and orientations of contigs from individual mate pair reads and thus\nproduce a contig digraph. The SLIQ inequalities can also filter out unreliable\nmate pairs and can be used as a preprocessing step for any scaffolding\nalgorithm. We tested the SLIQ inequalities on five real data sets ranging in\ncomplexity from simple bacterial genomes to complex mammalian genomes and\ncompared the results to the majority voting procedure used by many other\nscaffolding algorithms. SLIQ predicted the relative positions and orientations\nof the contigs with high accuracy in all cases and gave more accurate position\npredictions than majority voting for complex genomes, in particular the human\ngenome. Finally, we present a simple scaffolding algorithm that produces linear\nscaffolds given a contig digraph. We show that our algorithm is very efficient\ncompared to other scaffolding algorithms while maintaining high accuracy in\npredicting both contig positions and orientations for real data sets.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 15:46:57 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2011 15:16:32 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Roy", "Rajat S.", ""], ["Chen", "Kevin C.", ""], ["Sengupta", "Anirvan M.", ""], ["Schliep", "Alexander", ""]]}, {"id": "1111.2514", "submitter": "Muhammad Rahman M.Sc", "authors": "Muhammad Mahbubur Rahman, Arif Ul Alam, Abdullah-Al-Mamun, Tamnun E\n  Mursalin", "title": "A more appropriate Protein Classification using Data Mining", "comments": "11 pages, 15 figures, 7 tables. arXiv admin note: some text overlap\n  with articles written by other authors,\n  http://bioinformatics.oxfordjournals.org/content/21/15/3234.full ,\n  http://www.oxfordjournals.org/nar/database/summary/616 ,\n  http://www.jsbi.org/pdfs/journal1/GIW01/GIW01F14.pdf", "journal-ref": "Journal of Theoretical and Applied Information Technology(JATIT),\n  pp. 33-43, 2010", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in bioinformatics is a complex phenomenon as it overlaps two\nknowledge domains, namely, biological and computer sciences. This paper has\ntried to introduce an efficient data mining approach for classifying proteins\ninto some useful groups by representing them in hierarchy tree structure. There\nare several techniques used to classify proteins but most of them had few\ndrawbacks on their grouping. Among them the most efficient grouping technique\nis used by PSIMAP. Even though PSIMAP (Protein Structural Interactome Map)\ntechnique was successful to incorporate most of the protein but it fails to\nclassify the scale free property proteins. Our technique overcomes this\ndrawback and successfully maps all the protein in different groups, including\nthe scale free property proteins failed to group by PSIMAP. Our approach\nselects the six major attributes of protein: a) Structure comparison b)\nSequence Comparison c) Connectivity d) Cluster Index e) Interactivity f)\nTaxonomic to group the protein from the databank by generating a hierarchal\ntree structure. The proposed approach calculates the degree (probability) of\nsimilarity of each protein newly entered in the system against of existing\nproteins in the system by using probability theorem on each six properties of\nproteins.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2011 12:18:39 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Alam", "Arif Ul", ""], ["Abdullah-Al-Mamun", "", ""], ["Mursalin", "Tamnun E", ""]]}, {"id": "1111.2616", "submitter": "Jakob Heide J{\\o}rgensen", "authors": "Jakob H. J{\\o}rgensen, Emil Y. Sidky, and Xiaochuan Pan", "title": "Ensuring convergence in total-variation-based reconstruction for\n  accurate microcalcification imaging in breast X-ray CT", "comments": "5 pages, 4 figures, extended version of conference paper for 2011\n  IEEE Nuclear Science Symposium and Medical Imaging Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast X-ray CT imaging is being considered in screening as an extension to\nmammography. As a large fraction of the population will be exposed to\nradiation, low-dose imaging is essential. Iterative image reconstruction based\non solving an optimization problem, such as Total-Variation minimization, shows\npotential for reconstruction from sparse-view data. For iterative methods it is\nimportant to ensure convergence to an accurate solution, since important image\nfeatures, such as presence of microcalcifications indicating breast cancer, may\nnot be visible in a non-converged reconstruction, and this can have clinical\nsignificance. To prevent excessively long computational times, which is a\npractical concern for the large image arrays in CT, it is desirable to keep the\nnumber of iterations low, while still ensuring a sufficiently accurate\nreconstruction for the specific imaging task. This motivates the study of\naccurate convergence criteria for iterative image reconstruction. In simulation\nstudies with a realistic breast phantom with microcalcifications we compare\ndifferent convergence criteria for reliable reconstruction. Our results show\nthat it can be challenging to ensure a sufficiently accurate microcalcification\nreconstruction, when using standard convergence criteria. In particular, the\ngray level of the small microcalcifications may not have converged long after\nthe background tissue is reconstructed uniformly. We propose the use of the\nindividual objective function gradient components to better monitor possible\nregions of non-converged variables. For microcalcifications we find empirically\na large correlation between nonzero gradient components and non-converged\nvariables, which occur precisely within the microcalcifications. This supports\nour claim that gradient components can be used to ensure convergence to a\nsufficiently accurate reconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2011 21:17:55 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["J\u00f8rgensen", "Jakob H.", ""], ["Sidky", "Emil Y.", ""], ["Pan", "Xiaochuan", ""]]}, {"id": "1111.3127", "submitter": "Argimiro Arratia", "authors": "Argimiro Arratia and Alejandra Caba\\~na", "title": "Tracing the temporal evolution of clusters in a financial stock market", "comments": "22 pages, 3 figures (submitted for publication)", "journal-ref": null, "doi": "10.1007/s10614-012-9327-x", "report-no": null, "categories": "cs.CE math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology for clustering financial time series of stocks'\nreturns, and a graphical set-up to quantify and visualise the evolution of\nthese clusters through time. The proposed graphical representation allows for\nthe application of well known algorithms for solving classical combinatorial\ngraph problems, which can be interpreted as problems relevant to portfolio\ndesign and investment strategies. We illustrate this graph representation of\nthe evolution of clusters in time and its use on real data from the Madrid\nStock Exchange market.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 08:04:16 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Arratia", "Argimiro", ""], ["Caba\u00f1a", "Alejandra", ""]]}, {"id": "1111.3304", "submitter": "Mihai Cucuringu", "authors": "Mihai Cucuringu, Amit Singer, David Cowburn", "title": "Eigenvector Synchronization, Graph Rigidity and the Molecule Problem", "comments": "49 pages, 8 figures", "journal-ref": "Information and inference : a journal of the IMA 2012, 1, 21", "doi": "10.1093/imaiai/ias002", "report-no": null, "categories": "cs.CE cs.DS math.CO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph realization problem has received a great deal of attention in\nrecent years, due to its importance in applications such as wireless sensor\nnetworks and structural biology. In this paper, we extend on previous work and\npropose the 3D-ASAP algorithm, for the graph realization problem in\n$\\mathbb{R}^3$, given a sparse and noisy set of distance measurements. 3D-ASAP\nis a divide and conquer, non-incremental and non-iterative algorithm, which\nintegrates local distance information into a global structure determination.\nOur approach starts with identifying, for every node, a subgraph of its 1-hop\nneighborhood graph, which can be accurately embedded in its own coordinate\nsystem. In the noise-free case, the computed coordinates of the sensors in each\npatch must agree with their global positioning up to some unknown rigid motion,\nthat is, up to translation, rotation and possibly reflection. In other words,\nto every patch there corresponds an element of the Euclidean group Euc(3) of\nrigid transformations in $\\mathbb{R}^3$, and the goal is to estimate the group\nelements that will properly align all the patches in a globally consistent way.\nFurthermore, 3D-ASAP successfully incorporates information specific to the\nmolecule problem in structural biology, in particular information on known\nsubstructures and their orientation. In addition, we also propose 3D-SP-ASAP, a\nfaster version of 3D-ASAP, which uses a spectral partitioning algorithm as a\npreprocessing step for dividing the initial graph into smaller subgraphs. Our\nextensive numerical simulations show that 3D-ASAP and 3D-SP-ASAP are very\nrobust to high levels of noise in the measured distances and to sparse\nconnectivity in the measurement graph, and compare favorably to similar\nstate-of-the art localization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2011 17:38:16 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2012 01:13:29 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2012 02:24:58 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Singer", "Amit", ""], ["Cowburn", "David", ""]]}, {"id": "1111.4267", "submitter": "Victor A. Rodriguez-Toro", "authors": "Victor A. Rodriguez-Toro, Jaime E. Garzon, Jesus A. Lopez", "title": "Control Neuronal por Modelo Inverso de un Servosistema Usando Algoritmos\n  de Aprendizaje Levenberg-Marquardt y Bayesiano", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the experimental results of the neural network\ncontrol of a servo-system in order to control its speed. The control strategy\nis implemented by using an inverse-model control based on Artificial Neural\nNetworks (ANNs). The network training was performed using two learning\nalgorithms: Levenberg-Marquardt and Bayesian regularization. We evaluate the\ngeneralization capability for each method according to both the correct\noperation of the controller to follow the reference signal, and the control\nefforts developed by the ANN-based controller.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 03:26:47 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Rodriguez-Toro", "Victor A.", ""], ["Garzon", "Jaime E.", ""], ["Lopez", "Jesus A.", ""]]}, {"id": "1111.4289", "submitter": "Axman Fisher", "authors": "Axman Fisher", "title": "Interfacial Numerical Dispersion and New Conformal FDTD Method", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This article shows the interfacial relation in electrodynamics shall be\ncorrected in discrete grid form which can be seen as certain numerical\ndispersion beyond the usual bulk type. Furthermore we construct a lossy\nconductor model to illustrate how to simulate more general materials other than\ntraditional PEC or simple dielectrics, by a new conformal FDTD method which\nmain considers the effects of penetrative depth and the distribution of free\nbulk electric charge and current.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 05:54:45 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2011 05:16:16 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Fisher", "Axman", ""]]}, {"id": "1111.4610", "submitter": "Jan Mandel", "authors": "Jan Mandel, Jonathan D. Beezley, Adam K. Kochanski, Volodymyr Y.\n  Kondratenko, Lin Zhang, Erik Anderson, Joel Daniels II, Claudio T. Silva, and\n  Christopher R. Johnson", "title": "A wildland fire modeling and visualization environment", "comments": "12 pages; Ninth Symposium on Fire and Forest Meteorology, Palm\n  Springs, CA, October 2011", "journal-ref": null, "doi": null, "report-no": "UCD CCM Report 305", "categories": "physics.ao-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of a modeling environment, consisting of a coupled\natmosphere-wildfire model, utilities for visualization, data processing, and\ndiagnostics, open source software repositories, and a community wiki. The fire\nmodel, called SFIRE, is based on a fire-spread model, implemented by the\nlevel-set method, and it is coupled with the Weather Research Forecasting (WRF)\nmodel. A version with a subset of the features is distributed with WRF 3.3 as\nWRF-Fire. In each time step, the fire module takes the wind as input and\nreturns the latent and sensible heat fluxes. The software architecture uses WRF\nparallel infrastructure for massively parallel computing. Recent features of\nthe code include interpolation from an ideal logarithmic wind profile for\nnonhomogeneous fuels and ignition from a fire perimeter with an atmosphere and\nfire spin-up. Real runs use online sources for fuel maps, fine-scale\ntopography, and meteorological data, and can run faster than real time.\nVisualization pathways allow generating images and animations in many packages,\nincluding VisTrails, VAPOR, MayaVi, and Paraview, as well as output to Google\nEarth. The environment is available from openwfm.org. New diagnostic variables\nwere added to the code recently, including a new kind of fireline intensity,\nwhich takes into account also the speed of burning, unlike Byram's fireline\nintensity.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 05:50:00 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Mandel", "Jan", ""], ["Beezley", "Jonathan D.", ""], ["Kochanski", "Adam K.", ""], ["Kondratenko", "Volodymyr Y.", ""], ["Zhang", "Lin", ""], ["Anderson", "Erik", ""], ["Daniels", "Joel", "II"], ["Silva", "Claudio T.", ""], ["Johnson", "Christopher R.", ""]]}, {"id": "1111.4639", "submitter": "Leo Lahti", "authors": "Leo Lahti, Martin Sch\\\"afer, Hans-Ulrich Klein, Silvio Bicciato, and\n  Martin Dugas", "title": "Cancer gene prioritization by integrative analysis of mRNA expression\n  and DNA copy number data: a comparative review", "comments": "PDF file including supplementary material. 9 pages. Preprint", "journal-ref": null, "doi": "10.1093/bib/bbs005", "report-no": null, "categories": "cs.CE q-bio.GN stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A variety of genome-wide profiling techniques are available to probe\ncomplementary aspects of genome structure and function. Integrative analysis of\nheterogeneous data sources can reveal higher-level interactions that cannot be\ndetected based on individual observations. A standard integration task in\ncancer studies is to identify altered genomic regions that induce changes in\nthe expression of the associated genes based on joint analysis of genome-wide\ngene expression and copy number profiling measurements. In this review, we\nprovide a comparison among various modeling procedures for integrating\ngenome-wide profiling data of gene copy number and transcriptional alterations\nand highlight common approaches to genomic data integration. A transparent\nbenchmarking procedure is introduced to quantitatively compare the cancer gene\nprioritization performance of the alternative methods. The benchmarking\nalgorithms and data sets are available at http://intcomp.r-forge.r-project.org\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 15:23:09 GMT"}], "update_date": "2012-03-23", "authors_parsed": [["Lahti", "Leo", ""], ["Sch\u00e4fer", "Martin", ""], ["Klein", "Hans-Ulrich", ""], ["Bicciato", "Silvio", ""], ["Dugas", "Martin", ""]]}, {"id": "1111.4785", "submitter": "Ivo Sbalzarini", "authors": "Christian L. Muller, Rajesh Ramaswamy, Ivo F. Sbalzarini", "title": "Global parameter identification of stochastic reaction networks from\n  single trajectories", "comments": "Article in print as a book chapter in Springer's \"Advances in Systems\n  Biology\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the unknown parameters of a stochastic\nbiochemical network model from a single measured time-course of the\nconcentration of some of the involved species. Such measurements are available,\ne.g., from live-cell fluorescence microscopy in image-based systems biology. In\naddition, fluctuation time-courses from, e.g., fluorescence correlation\nspectroscopy provide additional information about the system dynamics that can\nbe used to more robustly infer parameters than when considering only mean\nconcentrations. Estimating model parameters from a single experimental\ntrajectory enables single-cell measurements and quantification of cell--cell\nvariability. We propose a novel combination of an adaptive Monte Carlo sampler,\ncalled Gaussian Adaptation, and efficient exact stochastic simulation\nalgorithms that allows parameter identification from single stochastic\ntrajectories. We benchmark the proposed method on a linear and a non-linear\nreaction network at steady state and during transient phases. In addition, we\ndemonstrate that the present method also provides an ellipsoidal volume\nestimate of the viable part of parameter space and is able to estimate the\nphysical volume of the compartment in which the observed reactions take place.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 08:30:29 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Muller", "Christian L.", ""], ["Ramaswamy", "Rajesh", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "1111.5228", "submitter": "Andrew Lo", "authors": "Emmanuel A. Abbe, Amir E. Khandani, Andrew W. Lo", "title": "Privacy-Preserving Methods for Sharing Financial Risk Exposures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.CE cs.CR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike other industries in which intellectual property is patentable, the\nfinancial industry relies on trade secrecy to protect its business processes\nand methods, which can obscure critical financial risk exposures from\nregulators and the public. We develop methods for sharing and aggregating such\nrisk exposures that protect the privacy of all parties involved and without the\nneed for a trusted third party. Our approach employs secure multi-party\ncomputation techniques from cryptography in which multiple parties are able to\ncompute joint functions without revealing their individual inputs. In our\nframework, individual financial institutions evaluate a protocol on their\nproprietary data which cannot be inverted, leading to secure computations of\nreal-valued statistics such a concentration indexes, pairwise correlations, and\nother single- and multi-point statistics. The proposed protocols are\ncomputationally tractable on realistic sample sizes. Potential financial\napplications include: the construction of privacy-preserving real-time indexes\nof bank capital and leverage ratios; the monitoring of delegated portfolio\ninvestments; financial audits; and the publication of new indexes of\nproprietary trading strategies.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2011 21:21:10 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2011 01:43:55 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Abbe", "Emmanuel A.", ""], ["Khandani", "Amir E.", ""], ["Lo", "Andrew W.", ""]]}, {"id": "1111.5892", "submitter": "Gene Sher", "authors": "Gene I. Sher", "title": "Evolving Chart Pattern Sensitive Neural Network Based Forex Trading\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though machine learning has been applied to the foreign exchange market for\nalgorithmic trading for quiet some time now, and neural networks(NN) have been\nshown to yield positive results, in most modern approaches the NN systems are\noptimized through traditional methods like the backpropagation algorithm for\nexample, and their input signals are price lists, and lists composed of other\ntechnical indicator elements. The aim of this paper is twofold: the\npresentation and testing of the application of topology and weight evolving\nartificial neural network (TWEANN) systems to automated currency trading, and\nto demonstrate the performance when using Forex chart images as input to\ngeometrical regularity aware indirectly encoded neural network systems,\nenabling them to use the patterns & trends within, when trading. This paper\npresents the benchmark results of NN based automated currency trading systems\nevolved using TWEANNs, and compares the performance and generalization\ncapabilities of these direct encoded NNs which use the standard sliding-window\nbased price vector inputs, and the indirect (substrate) encoded NNs which use\ncharts as input. The TWEANN algorithm I will use in this paper to evolve these\ncurrency trading agents is the memetic algorithm based TWEANN system called\nDeus Ex Neural Network (DXNN) platform.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 05:11:14 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2012 19:48:31 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Sher", "Gene I.", ""]]}, {"id": "1111.6214", "submitter": "Adel Javanmard", "authors": "Morteza Ibrahimi, Adel Javanmard, Yashodhan Kanoria and Andrea\n  Montanari", "title": "Robust Max-Product Belief Propagation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimizing a graph-structured objective function\nunder \\emph{adversarial} uncertainty. This problem can be modeled as a\ntwo-persons zero-sum game between an Engineer and Nature. The Engineer controls\na subset of the variables (nodes in the graph), and tries to assign their\nvalues to maximize an objective function. Nature controls the complementary\nsubset of variables and tries to minimize the same objective. This setting\nencompasses estimation and optimization problems under model uncertainty, and\nstrategic problems with a graph structure. Von Neumann's minimax theorem\nguarantees the existence of a (minimax) pair of randomized strategies that\nprovide optimal robustness for each player against its adversary.\n  We prove several structural properties of this strategy pair in the case of\ngraph-structured payoff function. In particular, the randomized minimax\nstrategies (distributions over variable assignments) can be chosen in such a\nway to satisfy the Markov property with respect to the graph. This\nsignificantly reduces the problem dimensionality. Finally we introduce a\nmessage passing algorithm to solve this minimax problem. The algorithm\ngeneralizes max-product belief propagation to this new domain.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 02:02:53 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Ibrahimi", "Morteza", ""], ["Javanmard", "Adel", ""], ["Kanoria", "Yashodhan", ""], ["Montanari", "Andrea", ""]]}]