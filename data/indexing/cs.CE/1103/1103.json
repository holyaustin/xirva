[{"id": "1103.1124", "submitter": "Hamed Owladeghaffari O.Ghaffari", "authors": "H. Ghaffari, A. Nabovati, M. Sharifzadeh, R. P. Young", "title": "Fluid flow analysis in a rough fracture (type II) using complex networks\n  and lattice Boltzmann method", "comments": "2011 PanAm-CGS Geotechnical Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity of fluid flow in a rough fracture is induced by the complex\nconfigurations of opening areas between the fracture planes. In this study, we\nmodel fluid flow in an evolvable real rock joint structure, which under certain\nnormal load is sheared. In an experimental study, information regarding about\napertures of the rock joint during consecutive 20 mm displacements and fluid\nflow (permeability) in different pressure heads have been recorded by a scanner\nlaser. Our aim in this study is to simulate the fluid flow in the mentioned\ncomplex geometries using the lattice Boltzmann method (LBM), while the\ncharacteristics of the aperture field will be compared with the modeled fluid\nflow permeability To characterize the aperture, we use a new concept in the\ngraph theory, namely: complex networks and motif analysis of the corresponding\nnetworks. In this approach, the similar aperture profile along the fluid flow\ndirection is mapped in to a network space. The modeled permeability using the\nLBM shows good correlation with the experimental measured values. Furthermore,\nthe two main characters of the obtained networks, i.e., characteristic length\nand number of edges show the same evolutionary trend with the modeled\npermeability values. Analysis of motifs through the obtained networks showed\nthe most transient sub-graphs are much more frequent in residual stages. This\ncoincides with nearly stable fluid flow and high permeability values.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2011 13:28:03 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Ghaffari", "H.", ""], ["Nabovati", "A.", ""], ["Sharifzadeh", "M.", ""], ["Young", "R. P.", ""]]}, {"id": "1103.1264", "submitter": "Leo Liberti", "authors": "Leo Liberti, Carlile Lavor, Benoit Masson, Antonio Mucherino", "title": "Polynomial cases of the Discretizable Molecular Distance Geometry\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important application of distance geometry to biochemistry studies the\nembeddings of the vertices of a weighted graph in the three-dimensional\nEuclidean space such that the edge weights are equal to the Euclidean distances\nbetween corresponding point pairs. When the graph represents the backbone of a\nprotein, one can exploit the natural vertex order to show that the search space\nfor feasible embeddings is discrete. The corresponding decision problem can be\nsolved using a binary tree based search procedure which is exponential in the\nworst case. We discuss assumptions that bound the search tree width to a\npolynomial size.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2011 12:41:44 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Liberti", "Leo", ""], ["Lavor", "Carlile", ""], ["Masson", "Benoit", ""], ["Mucherino", "Antonio", ""]]}, {"id": "1103.1777", "submitter": "Jan Egger", "authors": "Jan Egger, Miriam H. A. Bauer, Daniela Kuhnt, Christoph Kappus,\n  Barbara Carl, Bernd Freisleben, Christopher Nimsky", "title": "A Flexible Semi-Automatic Approach for Glioblastoma multiforme\n  Segmentation", "comments": "4 pages, 4 figures, BIOSIGNAL, Berlin, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.med-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gliomas are the most common primary brain tumors, evolving from the cerebral\nsupportive cells. For clinical follow-up, the evaluation of the preoperative\ntumor volume is essential. Volumetric assessment of tumor volume with manual\nsegmentation of its outlines is a time-consuming process that can be overcome\nwith the help of segmentation methods. In this paper, a flexible semi-automatic\napproach for grade IV glioma segmentation is presented. The approach uses a\nnovel segmentation scheme for spherical objects that creates a directed 3D\ngraph. Thereafter, the minimal cost closed set on the graph is computed via a\npolynomial time s-t cut, creating an optimal segmentation of the tumor. The\nuser can improve the results by specifying an arbitrary number of additional\nseed points to support the algorithm with grey value information and\ngeometrical constraints. The presented method is tested on 12 magnetic\nresonance imaging datasets. The ground truth of the tumor boundaries are\nmanually extracted by neurosurgeons. The segmented gliomas are compared with a\none click method, and the semi-automatic approach yields an average Dice\nSimilarity Coefficient (DSC) of 77.72% and 83.91%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2011 13:27:22 GMT"}], "update_date": "2011-03-10", "authors_parsed": [["Egger", "Jan", ""], ["Bauer", "Miriam H. A.", ""], ["Kuhnt", "Daniela", ""], ["Kappus", "Christoph", ""], ["Carl", "Barbara", ""], ["Freisleben", "Bernd", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1103.1778", "submitter": "Jan Egger", "authors": "Jan Egger, Miriam H. A. Bauer, Daniela Kuhnt, Bernd Freisleben,\n  Christopher Nimsky", "title": "Pituitary Adenoma Segmentation", "comments": "4 pages, 5 figures, BIOSIGNAL, Berlin, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.med-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sellar tumors are approximately 10-15% among all intracranial neoplasms. The\nmost common sellar lesion is the pituitary adenoma. Manual segmentation is a\ntime-consuming process that can be shortened by using adequate algorithms. In\nthis contribution, we present a segmentation method for pituitary adenoma. The\nmethod is based on an algorithm we developed recently in previous work where\nthe novel segmentation scheme was successfully used for segmentation of\nglioblastoma multiforme and provided an average Dice Similarity Coefficient\n(DSC) of 77%. This scheme is used for automatic adenoma segmentation. In our\nexperimental evaluation, neurosurgeons with strong experiences in the treatment\nof pituitary adenoma performed manual slice-by-slice segmentation of 10\nmagnetic resonance imaging (MRI) cases. Afterwards, the segmentations were\ncompared with the segmentation results of the proposed method via the DSC. The\naverage DSC for all data sets was 77.49% +/- 4.52%. Compared with a manual\nsegmentation that took, on the average, 3.91 +/- 0.54 minutes, the overall\nsegmentation in our implementation required less than 4 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2011 13:33:23 GMT"}], "update_date": "2011-03-10", "authors_parsed": [["Egger", "Jan", ""], ["Bauer", "Miriam H. A.", ""], ["Kuhnt", "Daniela", ""], ["Freisleben", "Bernd", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1103.2351", "submitter": "Szymon Grabowski", "authors": "Szymon Grabowski, Sebastian Deorowicz", "title": "Engineering Relative Compression of Genomes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.IT math.IT q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology progress in DNA sequencing boosts the genomic database growth at\nfaster and faster rate. Compression, accompanied with random access\ncapabilities, is the key to maintain those huge amounts of data. In this paper\nwe present an LZ77-style compression scheme for relative compression of\nmultiple genomes of the same species. While the solution bears similarity to\nknown algorithms, it offers significantly higher compression ratios at\ncompression speed over a order of magnitude greater. One of the new successful\nideas is augmenting the reference sequence with phrases from the other\nsequences, making more LZ-matches available.\n", "versions": [{"version": "v1", "created": "Fri, 11 Mar 2011 19:27:20 GMT"}], "update_date": "2011-03-14", "authors_parsed": [["Grabowski", "Szymon", ""], ["Deorowicz", "Sebastian", ""]]}, {"id": "1103.2447", "submitter": "Fei Wei", "authors": "Fei Wei, Huazhong Yang", "title": "Mini-step Strategy for Transient Analysis", "comments": "a preprint version, full version is submitted to an international\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain decomposition methods are widely used to solve sparse linear systems\nfrom scientific problems, but they are not suited to solve sparse linear\nsystems extracted from integrated circuits. The reason is that the sparse\nlinear system of integrated circuits may be non-diagonal-dominant, and domain\ndecomposition method might be unconvergent for these non-diagonal-dominant\nmatrices. In this paper, we propose a mini-step strategy to do the circuit\ntransient analysis. Different from the traditional large-step approach, this\nstrategy is able to generate diagonal-dominant sparse linear systems. As a\nresult, preconditioned domain decomposition methods can be used to simulate the\nlarge integrated circuits on the supercomputers and clouds.\n", "versions": [{"version": "v1", "created": "Sat, 12 Mar 2011 14:30:48 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Wei", "Fei", ""], ["Yang", "Huazhong", ""]]}, {"id": "1103.3391", "submitter": "Pedro Leite-Rocha", "authors": "Edmund K. Burke, Pedro Leite-Rocha and Sanja Petrovic", "title": "An Integer Linear Programming Model for the Radiotherapy Treatment\n  Scheduling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiotherapy represents an important phase of treatment for a large number of\ncancer patients. It is essential that resources used to deliver this treatment\nare employed effectively. This paper presents a new integer linear programming\nmodel for real-world radiotherapy treatment scheduling and analyses the\neffectiveness of using this model on a daily basis in a hospital. Experiments\nare conducted varying the days on which schedules can be created. Results\nobtained using real-world data from the Nottingham University Hospitals NHS\nTrust, UK, are presented and show how the proposed model can be used with\ndifferent policies in order to achieve good quality schedules.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2011 12:27:10 GMT"}], "update_date": "2011-03-18", "authors_parsed": [["Burke", "Edmund K.", ""], ["Leite-Rocha", "Pedro", ""], ["Petrovic", "Sanja", ""]]}, {"id": "1103.3624", "submitter": "Frank G. Borg", "authors": "Frank Borg", "title": "Analyzing biosignals using the R freeware (open source) tool", "comments": "18 pages and supplementary material. Added two new subsections. An\n  error corrected in supplementary file EMGfuns.R", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For researchers in electromyography (EMG), and similar biosginals, signal\nprocessing is naturally an essential topic. There are a number of excellent\ntools available. To these one may add the freely available open source\nstatistical software package R, which is in fact also a programming language.\nIt is becoming one the standard tools for scientists to visualize and process\ndata. A large number of additional packages are continually contributed by an\nactive community. The purpose of this paper is to alert biomechanics\nresearchers to the usefulness of this versatile tool. We discuss a set of basic\nsignal processing methods and their realizations with R which are provided in\nthe supplementary material. The data used in the examples are EMG and force\nplate data acquired during a quiet standing test.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2011 14:59:40 GMT"}, {"version": "v2", "created": "Fri, 19 Aug 2011 14:49:56 GMT"}, {"version": "v3", "created": "Tue, 8 Jul 2014 11:10:05 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Borg", "Frank", ""]]}, {"id": "1103.3698", "submitter": "Francois Orieux", "authors": "F. Orieux, J.-F. Giovannelli, T. Rodet, A. Abergel, H. Ayasso, M.\n  Husson", "title": "Super-resolution in map-making based on a physical instrument model and\n  regularized inversion. Application to SPIRE/Herschel", "comments": "Astronomy & Astrophysics", "journal-ref": null, "doi": "10.1051/0004-6361/201116817", "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate super-resolution methods for image reconstruction from data\nprovided by a family of scanning instruments like the Herschel observatory. To\ndo this, we constructed a model of the instrument that faithfully reflects the\nphysical reality, accurately taking the acquisition process into account to\nexplain the data in a reliable manner. The inversion, ie the image\nreconstruction process, is based on a linear approach resulting from a\nquadratic regularized criterion and numerical optimization tools. The\napplication concerns the reconstruction of maps for the SPIRE instrument of the\nHerschel observatory. The numerical evaluation uses simulated and real data to\ncompare the standard tool (coaddition) and the proposed method. The inversion\napproach is capable to restore spatial frequencies over a bandwidth four times\nthat possible with coaddition and thus to correctly show details invisible on\nstandard maps. The approach is also applied to real data with significant\nimprovement in spatial resolution.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2011 10:47:14 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2011 13:32:13 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Orieux", "F.", ""], ["Giovannelli", "J. -F.", ""], ["Rodet", "T.", ""], ["Abergel", "A.", ""], ["Ayasso", "H.", ""], ["Husson", "M.", ""]]}, {"id": "1103.3801", "submitter": "Yaroslav Sergeyev", "authors": "Yaroslav D. Sergeyev, Pasquale Daponte, Domenico Grimaldi, Anna\n  Molinaro", "title": "Two methods for solving optimization problems arising in electronic\n  measurements and electrical engineering", "comments": null, "journal-ref": "SIAM Journal on Optimization, 10(1) (1999) 1-21", "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA math.OC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a common problem in electronic measurements and\nelectrical engineering: finding the first root from the left of an equation in\nthe presence of some initial conditions. We present examples of\nelectrotechnical devices (analog signal filtering), where it is necessary to\nsolve it. Two new methods for solving this problem, based on global\noptimization ideas, are introduced. The first uses the exact a priori given\nglobal Lipschitz constant for the first derivative. The second method\nadaptively estimates local Lipschitz constants during the search. Both\nalgorithms either find the first root from the left or determine the global\nminimizers (in the case when the objective function has no roots). Sufficient\nconditions for convergence of the new methods to the desired solution are\nestablished in both cases. The results of numerical experiments for real\nproblems and a set of test functions are also presented.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 18:38:52 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Sergeyev", "Yaroslav D.", ""], ["Daponte", "Pasquale", ""], ["Grimaldi", "Domenico", ""], ["Molinaro", "Anna", ""]]}, {"id": "1103.4720", "submitter": "Kodge B. G.", "authors": "B. G. Kodge, P. S. Hiremath", "title": "Computer Modelling of 3D Geological Surface", "comments": "05 Pages, and 05 Figures", "journal-ref": "International Journal of Computer Science and Information\n  Security, Vol. 9, No. 2, February 2011, pp: 175-179", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geological surveying presently uses methods and tools for the computer\nmodeling of 3D-structures of the geographical subsurface and geotechnical\ncharacterization as well as the application of geoinformation systems for\nmanagement and analysis of spatial data, and their cartographic presentation.\nThe objectives of this paper are to present a 3D geological surface model of\nLatur district in Maharashtra state of India. This study is undertaken through\nthe several processes which are discussed in this paper to generate and\nvisualize the automated 3D geological surface model of a projected area.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2011 10:31:44 GMT"}, {"version": "v2", "created": "Fri, 25 Mar 2011 07:00:16 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Kodge", "B. G.", ""], ["Hiremath", "P. S.", ""]]}, {"id": "1103.5633", "submitter": "Jan Zeman", "authors": "J.Nov\\'ak, \\L. Kaczmarczyk, P. Grassl, J. Zeman and C.J. Pearce", "title": "A micromechanics-enhanced finite element formulation for modelling\n  heterogeneous materials", "comments": "28 pages, 12 figures, 2 tables", "journal-ref": "Computer Methods in Applied Mechanics and Engineering (201--204),\n  53-64, 2012", "doi": "10.1016/j.cma.2011.09.003", "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the analysis of composite materials with heterogeneous microstructures,\nfull resolution of the heterogeneities using classical numerical approaches can\nbe computationally prohibitive. This paper presents a micromechanics-enhanced\nfinite element formulation that accurately captures the mechanical behaviour of\nheterogeneous materials in a computationally efficient manner. The strategy\nexploits analytical solutions derived by Eshelby for ellipsoidal inclusions in\norder to determine the mechanical perturbation fields as a result of the\nunderlying heterogeneities. Approximation functions for these perturbation\nfields are then incorporated into a finite element formulation to augment those\nof the macroscopic fields. A significant feature of this approach is that the\nfinite element mesh does not explicitly resolve the heterogeneities and that no\nadditional degrees of freedom are introduced. In this paper, hybrid-Trefftz\nstress finite elements are utilised and performance of the proposed formulation\nis demonstrated with numerical examples. The method is restricted here to\nelastic particulate composites with ellipsoidal inclusions but it has been\ndesigned to be extensible to a wider class of materials comprising arbitrary\nshaped inclusions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2011 13:30:29 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2011 09:55:37 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Nov\u00e1k", "J.", ""], ["Kaczmarczyk", "\u0141.", ""], ["Grassl", "P.", ""], ["Zeman", "J.", ""], ["Pearce", "C. J.", ""]]}, {"id": "1103.5855", "submitter": "Ilona Kosinska", "authors": "Ilona D. Kosinska (Wroclaw University of Technology, Institute of\n  Biomedical Engineering and Instrumentation, Poland)", "title": "The FEM approach to the 3D electrodiffusion on 'meshes' optimized with\n  the Metropolis algorithm", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presented article contains a 3D mesh generation routine optimized with\nthe Metropolis algorithm. The procedure enables to produce meshes of a\nprescribed volume V_0 of elements. The finite volume meshes are used with the\nFinite Element approach. The FEM analysis enables to deal with a set of coupled\nnonlinear differential equations that describes the electrodiffusional problem.\nMesh quality and accuracy of FEM solutions are also examined. High quality of\nFEM type space-dependent approximation and correctness of discrete\napproximation in time are ensured by finding solutions to the 3D Laplace\nproblem and to the 3D diffusion equation, respectively. Their comparison with\nanalytical solutions confirms accuracy of obtained approximations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Mar 2011 09:24:00 GMT"}], "update_date": "2011-03-31", "authors_parsed": [["Kosinska", "Ilona D.", "", "Wroclaw University of Technology, Institute of\n  Biomedical Engineering and Instrumentation, Poland"]]}]