[{"id": "1310.0068", "submitter": "Rosemary  Renaut", "authors": "Saeed Vatankhah, Vahid E Ardestani and Rosemary A Renaut", "title": "Automatic estimation of the regularization parameter in 2-D focusing\n  gravity inversion: an application to the Safo manganese mine in northwest of\n  Iran", "comments": null, "journal-ref": "J. Geophys. Eng. 11 (2014) 045001", "doi": "10.1088/1742-2132/11/4/045001", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of Tikhonov regularization with the minimum support\nstabilizer for underdetermined 2-D inversion of gravity data. This stabilizer\nproduces models with non-smooth properties which is useful for identifying\ngeologic structures with sharp boundaries. A very important aspect of using\nTikhonov regularization is the choice of the regularization parameter that\ncontrols the trade off between the data fidelity and the stabilizing\nfunctional. The L-curve and generalized cross validation techniques, which only\nrequire the relative sizes of the uncertainties in the observations are\nconsidered. Both criteria are applied in an iterative process for which at each\niteration a value for regularization parameter is estimated. Suitable values\nfor the regularization parameter are successfully determined in both cases for\nsynthetic but practically relevant examples. Whenever the geologic situation\npermits, it is easier and more efficient to model the subsurface with a 2-D\nalgorithm, rather than to apply a full 3-D approach. Then, because the problem\nis not large it is appropriate to use the generalized singular value\ndecomposition for solving the problem efficiently. The method is applied on a\nprofile of gravity data acquired over the Safo mining camp in Maku-Iran, which\nis well known for manganese ores. The presented results demonstrate success in\nreconstructing the geometry and density distribution of the subsurface source.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 21:43:25 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2014 00:49:06 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Vatankhah", "Saeed", ""], ["Ardestani", "Vahid E", ""], ["Renaut", "Rosemary A", ""]]}, {"id": "1310.0395", "submitter": "Wajeb Gharibi", "authors": "Wajeb Gharibi, Marwah Mohammed Bakri", "title": "Protein Threading Based on Nonlinear Integer Programming", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1204.4562", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein threading is a method of computational protein structure prediction\nused for protein sequences which have the same fold as proteins of known\nstructures but do not have homologous proteins with known structure. The most\npopular algorithm is based on linear integer programming. In this paper, we\nconsider methods based on nonlinear integer programming. Actually, the existing\nlinear integer programming is directly linearized from the original quadratic\ninteger programming. We then develop corresponding efficient algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 17:03:06 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Gharibi", "Wajeb", ""], ["Bakri", "Marwah Mohammed", ""]]}, {"id": "1310.0883", "submitter": "Srikumar Venugopal", "authors": "Freddie Sunarso, Srikumar Venugopal and Federico Lauro", "title": "Scalable Protein Sequence Similarity Search using Locality-Sensitive\n  Hashing and MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": "UNSW CSE TR 201325", "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomics is the study of environments through genetic sampling of their\nmicrobiota. Metagenomic studies produce large datasets that are estimated to\ngrow at a faster rate than the available computational capacity. A key step in\nthe study of metagenome data is sequence similarity searching which is\ncomputationally intensive over large datasets. Tools such as BLAST require\nlarge dedicated computing infrastructure to perform such analysis and may not\nbe available to every researcher.\n  In this paper, we propose a novel approach called ScalLoPS that performs\nsearching on protein sequence datasets using LSH (Locality-Sensitive Hashing)\nthat is implemented using the MapReduce distributed framework. ScalLoPS is\ndesigned to scale across computing resources sourced from cloud computing\nproviders. We present the design and implementation of ScalLoPS followed by\nevaluation with datasets derived from both traditional as well as metagenomic\nstudies. Our experiments show that with this method approximates the quality of\nBLAST results while improving the scalability of protein sequence search.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 03:11:06 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Sunarso", "Freddie", ""], ["Venugopal", "Srikumar", ""], ["Lauro", "Federico", ""]]}, {"id": "1310.0890", "submitter": "Chunhua Shen", "authors": "Fayao Liu, Luping Zhou, Chunhua Shen, Jianping Yin", "title": "Multiple Kernel Learning in the Primal for Multi-modal Alzheimer's\n  Disease Classification", "comments": "7 pages. Appearing in IEEE Journal of Biomedical and Health\n  Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve effective and efficient detection of Alzheimer's disease (AD),\nmany machine learning methods have been introduced into this realm. However,\nthe general case of limited training samples, as well as different feature\nrepresentations typically makes this problem challenging. In this work, we\npropose a novel multiple kernel learning framework to combine multi-modal\nfeatures for AD classification, which is scalable and easy to implement.\nContrary to the usual way of solving the problem in the dual space, we look at\nthe optimization from a new perspective. By conducting Fourier transform on the\nGaussian kernel, we explicitly compute the mapping function, which leads to a\nmore straightforward solution of the problem in the primal space. Furthermore,\nwe impose the mixed $L_{21}$ norm constraint on the kernel weights, known as\nthe group lasso regularization, to enforce group sparsity among different\nfeature modalities. This actually acts as a role of feature modality selection,\nwhile at the same time exploiting complementary information among different\nkernels. Therefore it is able to extract the most discriminative features for\nclassification. Experiments on the ADNI data set demonstrate the effectiveness\nof the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 03:53:22 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Liu", "Fayao", ""], ["Zhou", "Luping", ""], ["Shen", "Chunhua", ""], ["Yin", "Jianping", ""]]}, {"id": "1310.1659", "submitter": "Dan He", "authors": "Dan He, Irina Rish, David Haws, Simon Teyssedre, Zivan Karaman, Laxmi\n  Parida", "title": "MINT: Mutual Information based Transductive Feature Selection for\n  Genetic Trait Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whole genome prediction of complex phenotypic traits using high-density\ngenotyping arrays has attracted a great deal of attention, as it is relevant to\nthe fields of plant and animal breeding and genetic epidemiology. As the number\nof genotypes is generally much bigger than the number of samples, predictive\nmodels suffer from the curse-of-dimensionality. The curse-of-dimensionality\nproblem not only affects the computational efficiency of a particular genomic\nselection method, but can also lead to poor performance, mainly due to\ncorrelation among markers. In this work we proposed the first transductive\nfeature selection method based on the MRMR (Max-Relevance and Min-Redundancy)\ncriterion which we call MINT. We applied MINT on genetic trait prediction\nproblems and showed that in general MINT is a better feature selection method\nthan the state-of-the-art inductive method mRMR.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 02:26:45 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["He", "Dan", ""], ["Rish", "Irina", ""], ["Haws", "David", ""], ["Teyssedre", "Simon", ""], ["Karaman", "Zivan", ""], ["Parida", "Laxmi", ""]]}, {"id": "1310.1869", "submitter": "Vasil Kolev", "authors": "Vasil Kolev, Katya Tsvetkova, and Milcho Tsvetkov", "title": "Singular Value Decomposition of Images from Scanned Photographic Plates", "comments": "pages 15, Proceedings of the VII Bulgarian-Serbian Astronomical\n  Conference,Bulgaria,2010", "journal-ref": "Proceedings of the VII Bulgarian-Serbian Astronomical Conference\n  (VII BSAC) Chepelare, Bulgaria, June 1-4,pp.187-200, 2010,", "doi": null, "report-no": null, "categories": "cs.CV astro-ph.IM cs.CE", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We want to approximate the mxn image A from scanned astronomical photographic\nplates (from the Sofia Sky Archive Data Center) by using far fewer entries than\nin the original matrix. By using rank of a matrix, k we remove the redundant\ninformation or noise and use as Wiener filter, when rank k<m or k<n. With this\napproximation more than 98% compression ration of image of astronomical plate\nwithout that image details, is obtained. The SVD of images from scanned\nphotographic plates (SPP) is considered and its possible image compression.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 17:36:48 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Kolev", "Vasil", ""], ["Tsvetkova", "Katya", ""], ["Tsvetkov", "Milcho", ""]]}, {"id": "1310.2182", "submitter": "Ayad Ghany Ismaeel", "authors": "Ayad Ghany Ismaeel", "title": "New Approach for Prediction Pre-cancer via Detecting Mutated in Tumor\n  Protein P53", "comments": "6 pages, 9 figures and 1 table,\n  http://www.ijser.org/researchpaper/New-Approach-for-Prediction-Pre-cancer-via-Detecting-Mutated-in-Tumor-Protein-P53.pdf", "journal-ref": "International Journal of Scientific & Engineering Research, Volume\n  4,Issue 10, October 2013 ISSN 2229-5518", "doi": null, "report-no": null, "categories": "cs.CE q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tumor protein P53 is believed to be involved in over half of human cancers\ncases, the prediction of malignancies plays essential roles not only in advance\ndetection for cancer, but also in discovering effective prevention and\ntreatment of cancer, till now there isn't approach be able in prediction the\nmutated in tumor protein P53 which is caused high ratio of human cancers like\nbreast, Blood, skin, liver, lung, bladder etc. This research proposed a new\napproach for prediction pre-cancer via detection malignant mutations in tumor\nprotein P53 using bioinformatics tools like FASTA, BLAST, CLUSTALW and TP53\ndatabases worldwide. Implement and apply this new approach of prediction\npre-cancer through mutations at tumor protein P53 shows an effective result\nwhen used more specific parameters/features to extract the prediction result\nthat means when the user increase the number of filters of the results which\nobtained from the database gives more specific diagnosis and classify, addition\nthat the detecting pre-cancer via prediction mutated tumor protein P53 will\nreduces a person's cancers in the future by avoiding exposure to toxins,\nradiation or monitoring themselves at older ages by change their food,\nenvironment, even the pace of living. Also that new approach of prediction\npre-cancer will help if there is any treatment can give for that person to\ntherapy the mutated tumor protein P53. Index Terms (Normal Homology TP53 gene,\nTumor Protein P53, Oncogene Labs, GC and AT content, FASTA, BLAST, ClustalW)\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 15:43:25 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Ismaeel", "Ayad Ghany", ""]]}, {"id": "1310.2274", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Andrew Rau-Chaplin", "title": "Accounting for Secondary Uncertainty: Efficient Computation of Portfolio\n  Risk Measures on Multi and Many Core Architectures", "comments": "10 pages, Workshop on High Performance Computational Finance at SC\n  2013, Denver, Colorado, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregate Risk Analysis is a computationally intensive and a data intensive\nproblem, thereby making the application of high-performance computing\ntechniques interesting. In this paper, the design and implementation of a\nparallel Aggregate Risk Analysis algorithm on multi-core CPU and many-core GPU\nplatforms are explored. The efficient computation of key risk measures,\nincluding Probable Maximum Loss (PML) and the Tail Value-at-Risk (TVaR) in the\npresence of both primary and secondary uncertainty for a portfolio of property\ncatastrophe insurance treaties is considered. Primary Uncertainty is the the\nuncertainty associated with whether a catastrophe event occurs or not in a\nsimulated year, while Secondary Uncertainty is the uncertainty in the amount of\nloss when the event occurs.\n  A number of statistical algorithms are investigated for computing secondary\nuncertainty. Numerous challenges such as loading large data onto hardware with\nlimited memory and organising it are addressed. The results obtained from\nexperimental studies are encouraging. Consider for example, an aggregate risk\nanalysis involving 800,000 trials, with 1,000 catastrophic events per trial, a\nmillion locations, and a complex contract structure taking into account\nsecondary uncertainty. The analysis can be performed in just 41 seconds on a\nGPU, that is 24x faster than the sequential counterpart on a fast multi-core\nCPU. The results indicate that GPUs can be used to efficiently accelerate\naggregate risk analysis even in the presence of secondary uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 20:36:49 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Varghese", "Blesson", ""], ["Rau-Chaplin", "Andrew", ""]]}, {"id": "1310.2361", "submitter": "Chanda Panse ms", "authors": "Chanda Panse, Dr. Manali Kshirsagar", "title": "Survey on Modelling Methods Applicable to Gene Regulatory Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene Regulatory Network (GRN) plays an important role in knowing insight of\ncellular life cycle. It gives information about at which different\nenvironmental conditions genes of particular interest get over expressed or\nunder expressed. Modelling of GRN is nothing but finding interactive\nrelationships between genes. Interaction can be positive or negative. For\ninference of GRN, time series data provided by Microarray technology is used.\nKey factors to be considered while constructing GRN are scalability,\nrobustness, reliability and maximum detection of true positive interactions\nbetween genes. This paper gives detailed technical review of existing methods\napplied for building of GRN along with scope for future work.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 05:58:26 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Panse", "Chanda", ""], ["Kshirsagar", "Dr. Manali", ""]]}, {"id": "1310.3119", "submitter": "Petr Novotn\\'y", "authors": "Tom\\'a\\v{s} Br\\'azdil, Taolue Chen, Vojt\\v{e}ch Forejt, Petr\n  Novotn\\'y, and Aistis Simaitis", "title": "Solvency Markov Decision Processes with Interest", "comments": "25 pages. This is a full version of a paper accepted at FST&TCS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solvency games, introduced by Berger et al., provide an abstract framework\nfor modelling decisions of a risk-averse investor, whose goal is to avoid ever\ngoing broke. We study a new variant of this model, where, in addition to\nstochastic environment and fixed increments and decrements to the investor's\nwealth, we introduce interest, which is earned or paid on the current level of\nsavings or debt, respectively.\n  We study problems related to the minimum initial wealth sufficient to avoid\nbankruptcy (i.e. steady decrease of the wealth) with probability at least p. We\npresent an exponential time algorithm which approximates this minimum initial\nwealth, and show that a polynomial time approximation is not possible unless P\n= NP. For the qualitative case, i.e. p=1, we show that the problem whether a\ngiven number is larger than or equal to the minimum initial wealth belongs to\nboth NP and coNP, and show that a polynomial time algorithm would yield a\npolynomial time algorithm for mean-payoff games, existence of which is a\nlongstanding open problem. We also identify some classes of solvency MDPs for\nwhich this problem is in P. In all above cases the algorithms also give\ncorresponding bankruptcy avoiding strategies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 13:38:22 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Chen", "Taolue", ""], ["Forejt", "Vojt\u011bch", ""], ["Novotn\u00fd", "Petr", ""], ["Simaitis", "Aistis", ""]]}, {"id": "1310.3360", "submitter": "Vena Pearl Bongolan Dr.", "authors": "Vena Pearl Bongolan, Rocco Rongo, Valeria Lupiano, Donato D'Ambrosio,\n  William Spataro and Giulio Iovine", "title": "A Probabilistic Approach to Risk Mapping for Mt. Etna", "comments": "Most recent presentation of related material was at the IMACS 2013\n  World Congress, August 26-30, 2013, San Lorenzo de El Escorial, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate susceptibility to lava flows on Mt. Etna based on specially\ndesigned die-toss experiments using probabilities for type, time and place of\nactivation from the volcano's 400-year recorded history and current studies on\nits known fractures and fissures. The types of activations were forcast using a\ntable of probabilities for events, typed by duration and volume of ejecta.\nLengths of time were represented by the number of activations to expect within\na given time-frame, calculated assuming Poisson-distributed inter-arrival times\nfor activations. Locations of future activations were forecast with a\nprobability distribution function for activation probabilities. Most likely\nscenarios for risk and resulting topography were generated for Etna's next\nactivation (average 7.76 years), the next 25, 50 and 100 years. Forecasts for\nareas most likely affected are in good agreement with previous risk studies\nmade. Forecasts for risks of lava invasions, as well as future topographies\nmight be a first. Threats to lifelines are also discussed.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 11:08:54 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Bongolan", "Vena Pearl", ""], ["Rongo", "Rocco", ""], ["Lupiano", "Valeria", ""], ["D'Ambrosio", "Donato", ""], ["Spataro", "William", ""], ["Iovine", "Giulio", ""]]}, {"id": "1310.3567", "submitter": "Adam Vaughan", "authors": "Adam Vaughan and Stanislav V. Bohac", "title": "An Extreme Learning Machine Approach to Predicting Near Chaotic HCCI\n  Combustion Phasing in Real-Time", "comments": "11 pages, 7 figures, minor revision (added implementation details and\n  video link), submitted to Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuel efficient Homogeneous Charge Compression Ignition (HCCI) engine\ncombustion timing predictions must contend with non-linear chemistry,\nnon-linear physics, period doubling bifurcation(s), turbulent mixing, model\nparameters that can drift day-to-day, and air-fuel mixture state information\nthat cannot typically be resolved on a cycle-to-cycle basis, especially during\ntransients. In previous work, an abstract cycle-to-cycle mapping function\ncoupled with $\\epsilon$-Support Vector Regression was shown to predict\nexperimentally observed cycle-to-cycle combustion timing over a wide range of\nengine conditions, despite some of the aforementioned difficulties. The main\nlimitation of the previous approach was that a partially acausual randomly\nsampled training dataset was used to train proof of concept offline\npredictions. The objective of this paper is to address this limitation by\nproposing a new online adaptive Extreme Learning Machine (ELM) extension named\nWeighted Ring-ELM. This extension enables fully causal combustion timing\npredictions at randomly chosen engine set points, and is shown to achieve\nresults that are as good as or better than the previous offline method. The\nbroader objective of this approach is to enable a new class of real-time model\npredictive control strategies for high variability HCCI and, ultimately, to\nbring HCCI's low engine-out NOx and reduced CO2 emissions to production\nengines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 06:00:31 GMT"}, {"version": "v2", "created": "Wed, 24 Sep 2014 16:52:27 GMT"}, {"version": "v3", "created": "Tue, 5 May 2015 20:23:49 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Vaughan", "Adam", ""], ["Bohac", "Stanislav V.", ""]]}, {"id": "1310.4201", "submitter": "Hantian Zhang", "authors": "Hantian Zhang, Dong Eui Chang, and Qingjie Cao", "title": "Lyapunov-based Low-thrust Optimal Orbit Transfer: An approach in\n  Cartesian coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple approach to low-thrust optimal-fuel and\noptimal-time transfer problems between two elliptic orbits using the Cartesian\ncoordinates system. In this case, an orbit is described by its specific angular\nmomentum and Laplace vectors with a free injection point. Trajectory\noptimization with the pseudospectral method and nonlinear programming are\nsupported by the initial guess generated from the Chang-Chichka-Marsden\nLyapunov-based transfer controller. This approach successfully solves several\nlow-thrust optimal problems. Numerical results show that the Lyapunov-based\ninitial guess overcomes the difficulty in optimization caused by the strong\noscillation of variables in the Cartesian coordinates system. Furthermore, a\ncomparison of the results shows that obtaining the optimal transfer solution\nthrough the polynomial approximation by utilizing Cartesian coordinates is\neasier than using orbital elements, which normally produce strongly nonlinear\nequations of motion. In this paper, the Earth's oblateness and shadow effect\nare not taken into account.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 20:56:57 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Zhang", "Hantian", ""], ["Chang", "Dong Eui", ""], ["Cao", "Qingjie", ""]]}, {"id": "1310.4342", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "Pokkuluri Kiran Sree, Inampudi Ramesh Babuhor, SSSN Usha Devi N3", "title": "An Extensive Report on Cellular Automata Based Artificial Immune System\n  for Strengthening Automated Protein Prediction", "comments": "arXiv admin note: text overlap with arXiv:0801.4312 by other authors", "journal-ref": "Advances in Biomedical Engineering Research (ABER) Volume 1 Issue\n  3, September 2013", "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Immune System (AIS-MACA) a novel computational intelligence\ntechnique is can be used for strengthening the automated protein prediction\nsystem with more adaptability and incorporating more parallelism to the system.\nMost of the existing approaches are sequential which will classify the input\ninto four major classes and these are designed for similar sequences. AIS-MACA\nis designed to identify ten classes from the sequences that share twilight zone\nsimilarity and identity with the training sequences with mixed and hybrid\nvariations. This method also predicts three states (helix, strand, and coil)\nfor the secondary structure. Our comprehensive design considers 10 feature\nselection methods and 4 classifiers to develop MACA (Multiple Attractor\nCellular Automata) based classifiers that are build for each of the ten\nclasses. We have tested the proposed classifier with twilight-zone and\n1-high-similarity benchmark datasets with over three dozens of modern competing\npredictors shows that AIS-MACA provides the best overall accuracy that ranges\nbetween 80% and 89.8% depending on the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 12:14:48 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Sree", "Pokkuluri Kiran", ""], ["Babuhor", "Inampudi Ramesh", ""], ["N3", "SSSN Usha Devi", ""]]}, {"id": "1310.4495", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "Pokkuluri Kiran Sree, Inampudi Ramesh Babu and SSSN Usha Devi Nedunuri", "title": "Multiple Attractor Cellular Automata (MACA) for Addressing Major\n  Problems in Bioinformatics", "comments": "arXiv admin note: text overlap with arXiv:1310.4342", "journal-ref": "Review of Bioinformatics and Biometrics (RBB) Volume 2 Issue 3,\n  September 2013", "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CA has grown as potential classifier for addressing major problems in\nbioinformatics. Lot of bioinformatics problems like predicting the protein\ncoding region, finding the promoter region, predicting the structure of protein\nand many other problems in bioinformatics can be addressed through Cellular\nAutomata. Even though there are some prediction techniques addressing these\nproblems, the approximate accuracy level is very less. An automated procedure\nwas proposed with MACA (Multiple Attractor Cellular Automata) which can address\nall these problems. The genetic algorithm is also used to find rules with good\nfitness values. Extensive experiments are conducted for reporting the accuracy\nof the proposed tool. The average accuracy of MACA when tested with ENCODE,\nBG570, HMR195, Fickett and Tongue, ASP67 datasets is 78%.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 15:01:19 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Sree", "Pokkuluri Kiran", ""], ["Babu", "Inampudi Ramesh", ""], ["Nedunuri", "SSSN Usha Devi", ""]]}, {"id": "1310.4734", "submitter": "David \\v{S}afr\\'anek", "authors": "Lubos Brim and Milan Ceska and Sven Drazan and David Safranek", "title": "On Robustness Analysis of Stochastic Biochemical Systems by\n  Probabilistic Model Checking", "comments": "43 pages, 15 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report proposes a novel framework for a rigorous robustness analysis of\nstochastic biochemical systems. The technique is based on probabilistic model\nchecking. We adapt the general definition of robustness introduced by Kitano to\nthe class of stochastic systems modelled as continuous time Markov Chains in\norder to extensively analyse and compare robustness of biological models with\nuncertain parameters. The framework utilises novel computational methods that\nenable to effectively evaluate the robustness of models with respect to\nquantitative temporal properties and parameters such as reaction rate constants\nand initial conditions.\n  The framework is applied to gene regulation as an example of a central\nbiological mechanism where intrinsic and extrinsic stochasticity plays crucial\nrole due to low numbers of DNA and RNA molecules. Using our methods we have\nobtained a comprehensive and precise analysis of stochastic dynamics under\nparameter uncertainty. Furthermore, we apply our framework to compare several\nvariants of two-component signalling networks from the perspective of\nrobustness with respect to intrinsic noise caused by low populations of\nsignalling components. We succeeded to extend previous studies performed on\ndeterministic models (ODE) and show that stochasticity may significantly affect\nobtained predictions. Our case studies demonstrate that the framework can\nprovide deeper insight into the role of key parameters in maintaining the\nsystem functionality and thus it significantly contributes to formal methods in\ncomputational systems biology.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 15:00:14 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Brim", "Lubos", ""], ["Ceska", "Milan", ""], ["Drazan", "Sven", ""], ["Safranek", "David", ""]]}, {"id": "1310.5022", "submitter": "Anna Kad{\\l}ubowska MSc", "authors": "Karol Wawrzyniak, Grzegorz Orynczak, Michal Klos, Aneta Goska, Marcin\n  Jakubek", "title": "Division of the Energy Market into Zones in Variable Weather Conditions\n  using Locational Marginal Prices", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adopting a zonal structure of electricity market requires specification of\nzones' borders. One of the approaches to identify zones is based on clustering\nof Locational Marginal Prices (LMP). The purpose of the paper is twofold: (i)\nwe extend the LMP methodology by taking into account variable weather\nconditions and (ii) we point out some weaknesses of the method and suggest\ntheir potential solutions. The offered extension comprises simulations based on\nthe Optimal Power Flow (OPF) algorithm and twofold clustering method. First,\nLMP are calculated by OPF for each of scenario representing different weather\nconditions. Second, hierarchical clustering based on Ward's criterion is used\non each realization of the prices separately. Then, another clustering method,\ni.e. consensus clustering, is used to aggregate the results from all\nsimulations and to find the global division into zones. The offered method of\naggregation is not limited only to LMP methodology and is universal.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 13:55:59 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Wawrzyniak", "Karol", ""], ["Orynczak", "Grzegorz", ""], ["Klos", "Michal", ""], ["Goska", "Aneta", ""], ["Jakubek", "Marcin", ""]]}, {"id": "1310.5025", "submitter": "Anna Kad{\\l}ubowska MSc", "authors": "Karol Wawrzyniak, Michal Klos, Grzegorz Orynczak, Marcin Jakubek", "title": "The Optimal Division of the Energy Market into Zones: Comparison of Two\n  Methodologies under Variable Wind Conditions", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare two competing methodologies of market zones identification under\nthe criterion of social welfare maximization: (i) consensus clustering of\nLocational Marginal Prices over different wind scenarios and (ii) congestion\ncontribution identification with congested lines identified across variable\nwind generation outputs. We test the division of market into zones based on\neach of the two methodologies using a welfare criterion, i.e., comparing the\ncost of supplying energy on uniform market (including readjustments made on a\nbalancing market to overcome the congestion) with cost on k-zone market. A\ndivision which maximizes the welfare is considered as the optimum.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 14:10:50 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Wawrzyniak", "Karol", ""], ["Klos", "Michal", ""], ["Orynczak", "Grzegorz", ""], ["Jakubek", "Marcin", ""]]}, {"id": "1310.5202", "submitter": "Omur  Arslan", "authors": "Omur Arslan, Dan P. Guralnik and Daniel E. Koditschek", "title": "Discriminative Measures for Comparison of Phylogenetic Trees", "comments": "24 pages, 7 figures, 1 table, a new graph-theoretic formulation of\n  the NNI navigation dissimilarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and study three new measures for efficient\ndiscriminative comparison of phylogenetic trees. The NNI navigation\ndissimilarity $d_{nav}$ counts the steps along a \"combing\" of the Nearest\nNeighbor Interchange (NNI) graph of binary hierarchies, providing an efficient\napproximation to the (NP-hard) NNI distance in terms of \"edit length\". At the\nsame time, a closed form formula for $d_{nav}$ presents it as a weighted count\nof pairwise incompatibilities between clusters, lending it the character of an\nedge dissimilarity measure as well. A relaxation of this formula to a simple\ncount yields another measure on all trees --- the crossing dissimilarity\n$d_{CM}$. Both dissimilarities are symmetric and positive definite (vanish only\nbetween identical trees) on binary hierarchies but they fail to satisfy the\ntriangle inequality. Nevertheless, both are bounded below by the widely used\nRobinson-Foulds metric and bounded above by a closely related true metric, the\ncluster-cardinality metric $d_{CC}$. We show that each of the three proposed\nnew dissimilarities is computable in time $O(n^2)$ in the number of leaves $n$,\nand conclude the paper with a brief numerical exploration of the distribution\nover tree space of these dissimilarities in comparison with the Robinson-Foulds\nmetric and the more recently introduced matching-split distance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2013 05:03:23 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2015 14:10:43 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Arslan", "Omur", ""], ["Guralnik", "Dan P.", ""], ["Koditschek", "Daniel E.", ""]]}, {"id": "1310.5207", "submitter": "Varun Shankar", "authors": "Varun Shankar, Grady B. Wright, Aaron L. Fogelson and Robert M. Kirby", "title": "A Radial Basis Function (RBF)-Finite Difference Method for the\n  Simulation of Reaction-Diffusion Equations on Stationary Platelets within the\n  Augmented Forcing Method", "comments": "27 pages, 7 figures, 9 tables", "journal-ref": "International Journal for Numerical Methods in Fluids, Volume 75,\n  1,1-22, 2014", "doi": "10.1002/fld.3880", "report-no": null, "categories": "math.NA cs.CE cs.NA q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational method for solving the coupled problem of chemical\ntransport in a fluid (blood) with binding/unbinding of the chemical to/from\ncellular (platelet) surfaces in contact with the fluid, and with transport of\nthe chemical on the cellular surfaces. The overall framework is the Augmented\nForcing Point Method (AFM) (\\emph{L. Yao and A.L. Fogelson, Simulations of\nchemical transport and reaction in a suspension of cells I: An augmented\nforcing point method for the stationary case, IJNMF (2012) 69, 1736-52.}) for\nsolving fluid-phase transport in a region outside of a collection of cells\nsuspended in the fluid. We introduce a novel Radial Basis Function-Finite\nDifference (RBF-FD) method to solve reaction-diffusion equations on the surface\nof each of a collection of 2D stationary platelets suspended in blood.\nParametric RBFs are used to represent the geometry of the platelets and give\naccurate geometric information needed for the RBF-FD method. Symmetric\nHermite-RBF interpolants are used for enforcing the boundary conditions on the\nfluid-phase chemical concentration, and their use removes a significant\nlimitation of the original AFM. The efficacy of the new methods are shown\nthrough a series of numerical experiments; in particular, second order\nconvergence for the coupled problem is demonstrated.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2013 07:50:24 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 20:04:56 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Shankar", "Varun", ""], ["Wright", "Grady B.", ""], ["Fogelson", "Aaron L.", ""], ["Kirby", "Robert M.", ""]]}, {"id": "1310.5306", "submitter": "Constantinos Siettos", "authors": "Panagiotis Papaioannnou, Lucia Russo, George Papaioannou, Constantinos\n  Siettos", "title": "Can social microblogging be used to forecast intraday exchange rates?", "comments": "This is a prior version of the paper published at NETNOMICS. The\n  final publication is available at\n  http://www.springer.com/economics/economic+theory/journal/11066", "journal-ref": "Netnomics, 14, 47-68 (2013)", "doi": "10.1007/s11066-013-9079-3", "report-no": null, "categories": "cs.SI cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Efficient Market Hypothesis (EMH) is widely accepted to hold true under\ncertain assumptions. One of its implications is that the prediction of stock\nprices at least in the short run cannot outperform the random walk model. Yet,\nrecently many studies stressing the psychological and social dimension of\nfinancial behavior have challenged the validity of the EMH. Towards this aim,\nover the last few years, internet-based communication platforms and search\nengines have been used to extract early indicators of social and economic\ntrends. Here, we used Twitter's social networking platform to model and\nforecast the EUR/USD exchange rate in a high-frequency intradaily trading\nscale. Using time series and trading simulations analysis, we provide some\nevidence that the information provided in social microblogging platforms such\nas Twitter can in certain cases enhance the forecasting efficiency regarding\nthe very short (intradaily) forex.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2013 08:08:06 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Papaioannnou", "Panagiotis", ""], ["Russo", "Lucia", ""], ["Papaioannou", "George", ""], ["Siettos", "Constantinos", ""]]}, {"id": "1310.5568", "submitter": "Larry Bull", "authors": "Larry Bull", "title": "Towards Application of the RBNK Model", "comments": "arXiv admin note: substantial text overlap with arXiv:1306.4793,\n  arXiv:1303.7220", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational modeling of genetic regulatory networks is now common\nplace, either by fitting a system to experimental data or by exploring the\nbehaviour of abstract systems with the aim of identifying underlying\nprinciples. This paper presents an approach to the latter, considering the\nresponse to environmental changes of a well-known model placed upon tunable\nfitness landscapes. The effects on genome size and gene connectivity are\nexplored.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 14:31:20 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Bull", "Larry", ""]]}, {"id": "1310.6486", "submitter": "Antoaneta Serguieva", "authors": "Antoaneta Sergueiva", "title": "Systemic Risk Identification, Modelling, Analysis, and Monitoring: An\n  Integrated Approach", "comments": "The author is grateful to J Doyne Farmer and Yaneer Bar-Yam for their\n  constructive comments and time, and to Kevin James for the opportunity to\n  attend and present at the Bank of England seminars on systemic risk and\n  financial stability. Would like to thank Jeffrey Johnson for kindly providing\n  a copy of his forthcoming book in advance, and to Marzena Rostek for sending\n  a recent unpublished", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research capacity is critical in understanding systemic risk and informing\nnew regulation. Banking regulation has not kept pace with all the complexities\nof financial innovation. The academic literature on systemic risk is rapidly\nexpanding. The majority of papers analyse a single source or a consolidated\nsource of risk and its effect. A fraction of publications quantify systemic\nrisk measures or formulate penalties for systemically important financial\ninstitutions that are of practical regulatory relevance. The challenges facing\nsystemic risk evaluation and regulation still persist, as the definition of\nsystemic risk is somewhat unsettled and that affects attempts to provide\nsolutions. Our understanding of systemic risk is evolving and the awareness of\ndata relevance is rising gradually; this challenge is reflected in the focus of\nmajor international research initiatives. There is a consensus that the direct\nand indirect costs of a systemic crisis are enormous as opposed to preventing\nit, and that without regulation the externalities will not be prevented; but\nthere is no consensus yet on the extent and detail of regulation, and research\nexpectations are to facilitate the regulatory process. This report outlines an\nintegrated approach for systemic risk evaluation based on multiple types of\ninterbank exposures through innovative modelling approaches as tensorial\nmultilayer networks, suggests how to relate underlying economic data and how to\nextend the network to cover financial market information. We reason about data\nrequirements and time scale effects, and outline a multi-model hypernetwork of\nsystemic risk knowledge as a scenario analysis and policy support tool. The\nargument is that logical steps forward would incorporate the range of risk\nsources and their interrelated effects as contributions towards an overall\nsystemic risk indicator, would perform an integral analysis of ...\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 05:03:25 GMT"}], "update_date": "2013-10-25", "authors_parsed": [["Sergueiva", "Antoaneta", ""]]}, {"id": "1310.6876", "submitter": "Sabyasachi  Mukhopadhyay", "authors": "Sabyasachi Mukhopadhyay, Debadatta Dash, Asish Mitra, Prasanta\n  K.Panigrahi", "title": "Application of Fourier and Wavelet Transform for analysing 300 years\n  Sunspot numbers to Explain the Solar Cycles", "comments": "This paper has been withdrawn by the author due to some modifications\n  are required for current paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper Fourier Transform and Wavelet Transform are applied in case of\nrecent 300 years of sunspot numbers to explain the solar cycles. Here basically\nparallel study of Fourier and Wavelet analysis are done and we have observed\nthat the better result can be obtained from Wavelet analysis during sunspot\nnumber analysis. We are able to show various minima and maxima in the recent\nages of solar cycles with this tool. The exact periodicity and other possible\nperiodicities in the cyclic phenomenon of sunspot activity are determined.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2013 11:00:02 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2013 16:39:16 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Mukhopadhyay", "Sabyasachi", ""], ["Dash", "Debadatta", ""], ["Mitra", "Asish", ""], ["Panigrahi", "Prasanta K.", ""]]}, {"id": "1310.7276", "submitter": "Dmytro Iatsenko", "authors": "Dmytro Iatsenko, Peter V. E. McClintock, Aneta Stefanovska", "title": "On the extraction of instantaneous frequencies from ridges in\n  time-frequency representations of signals", "comments": "13 pages, 7 figures, plus 4 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of oscillatory components and their properties from different\ntime-frequency representations, such as windowed Fourier transform and wavelet\ntransform, is an important topic in signal processing. The first step in this\nprocedure is to find an appropriate ridge curve: a sequence of amplitude peak\npositions (ridge points), corresponding to the component of interest. This is\nnot a trivial issue, and the optimal method for extraction is still not settled\nor agreed. We discuss and develop procedures that can be used for this task and\ncompare their performance on both simulated and real data. In particular, we\npropose a method which, in contrast to many other approaches, is highly\nadaptive so that it does not need any parameter adjustment for the signal to be\nanalysed. Being based on dynamic path optimization and fixed point iteration,\nthe method is very fast, and its superior accuracy is also demonstrated. In\naddition, we investigate the advantages and drawbacks that synchrosqueezing\noffers in relation to curve extraction. The codes used in this work are freely\navailable for download.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 23:41:43 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2014 23:08:02 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2015 14:43:52 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Iatsenko", "Dmytro", ""], ["McClintock", "Peter V. E.", ""], ["Stefanovska", "Aneta", ""]]}, {"id": "1310.7346", "submitter": "Joachim Mathiesen", "authors": "Joachim Mathiesen, Luiza Angheluta, Peter T.H. Ahlgren, Mogens H.\n  Jensen", "title": "Excitable human dynamics driven by extrinsic events in massive\n  communities", "comments": "9 pages, 3 figures", "journal-ref": "Proceedings of the National Academy of Sciences 110, no. 43\n  (2013): 17259-17262", "doi": "10.1073/pnas.1304179110", "report-no": null, "categories": "physics.soc-ph cs.CE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using empirical data from a social media site (Twitter) and on trading\nvolumes of financial securities, we analyze the correlated human activity in\nmassive social organizations. The activity, typically excited by real-world\nevents and measured by the occurrence rate of international brand names and\ntrading volumes, is characterized by intermittent fluctuations with bursts of\nhigh activity separated by quiescent periods. These fluctuations are broadly\ndistributed with an inverse cubic tail and have long-range temporal\ncorrelations with a $1/f$ power spectrum. We describe the activity by a\nstochastic point process and derive the distribution of activity levels from\nthe corresponding stochastic differential equation. The distribution and the\ncorresponding power spectrum are fully consistent with the empirical\nobservations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 08:58:52 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Mathiesen", "Joachim", ""], ["Angheluta", "Luiza", ""], ["Ahlgren", "Peter T. H.", ""], ["Jensen", "Mogens H.", ""]]}, {"id": "1310.7532", "submitter": "Sang Hoon Lee", "authors": "Sang Hoon Lee, Robyn Ffrancon, Daniel M. Abrams, Beom Jun Kim, Mason\n  A. Porter", "title": "Matchmaker, Matchmaker, Make Me a Match: Migration of Populations via\n  Marriages in the Past", "comments": "24 pages, 23 figures, 5 tables", "journal-ref": "Phys. Rev. X 4, 041009 (2014)", "doi": "10.1103/PhysRevX.4.041009", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn cs.CE nlin.AO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of human mobility is both of fundamental importance and of great\npotential value. For example, it can be leveraged to facilitate efficient city\nplanning and improve prevention strategies when faced with epidemics. The\nnewfound wealth of rich sources of data---including banknote flows, mobile\nphone records, and transportation data---has led to an explosion of attempts to\ncharacterize modern human mobility. Unfortunately, the dearth of comparable\nhistorical data makes it much more difficult to study human mobility patterns\nfrom the past. In this paper, we present an analysis of long-term human\nmigration, which is important for processes such as urbanization and the spread\nof ideas. We demonstrate that the data record from Korean family books (called\n\"jokbo\") can be used to estimate migration patterns via marriages from the past\n750 years. We apply two generative models of long-term human mobility to\nquantify the relevance of geographical information to human marriage records in\nthe data, and we find that the wide variety in the geographical distributions\nof the clans poses interesting challenges for the direct application of these\nmodels. Using the different geographical distributions of clans, we quantify\nthe \"ergodicity\" of clans in terms of how widely and uniformly they have spread\nacross Korea, and we compare these results to those obtained using surname data\nfrom the Czech Republic. To examine population flow in more detail, we also\nconstruct and examine a population-flow network between regions. Based on the\ncorrelation between ergodicity and migration in Korea, we identify two\ndifferent types of migration patterns: diffusive and convective. We expect the\nanalysis of diffusive versus convective effects in population flows to be\nwidely applicable to the study of mobility and migration patterns across\ndifferent cultures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 18:56:27 GMT"}, {"version": "v2", "created": "Tue, 27 May 2014 10:19:13 GMT"}, {"version": "v3", "created": "Thu, 14 Aug 2014 02:16:08 GMT"}, {"version": "v4", "created": "Thu, 16 Oct 2014 16:55:01 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Lee", "Sang Hoon", ""], ["Ffrancon", "Robyn", ""], ["Abrams", "Daniel M.", ""], ["Kim", "Beom Jun", ""], ["Porter", "Mason A.", ""]]}, {"id": "1310.7935", "submitter": "Nicolas Courtois", "authors": "Nicolas T. Courtois, Marek Grajek and Rahul Naik", "title": "The Unreasonable Fundamental Incertitudes Behind Bitcoin Mining", "comments": "45 pages, colour figures in jpg, not published elsewhere than arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is a \"crypto currency\", a decentralized electronic payment scheme\nbased on cryptography which has recently gained excessive popularity.\nScientific research on bitcoin is less abundant. A paper at Financial\nCryptography 2012 conference explains that it is a system which \"uses no fancy\ncryptography\", and is \"by no means perfect\". It depends on a well-known\ncryptographic standard SHA-256. In this paper we revisit the cryptographic\nprocess which allows one to make money by producing bitcoins. We reformulate\nthis problem as a Constrained Input Small Output (CISO) hashing problem and\nreduce the problem to a pure block cipher problem. We estimate the speed of\nthis process and we show that the cost of this process is less than it seems\nand it depends on a certain cryptographic constant which we estimated to be at\nmost 1.86. These optimizations enable bitcoin miners to save tens of millions\nof dollars per year in electricity bills. Miners who set up mining operations\nface many economic incertitudes such as high volatility. In this paper we point\nout that there are fundamental incertitudes which depend very strongly on the\nbitcoin specification. The energy efficiency of bitcoin miners have already\nbeen improved by a factor of about 10,000, and we claim that further\nimprovements are inevitable. Better technology is bound to be invented, would\nit be quantum miners. More importantly, the specification is likely to change.\nA major change have been proposed in May 2013 at Bitcoin conference in San\nDiego by Dan Kaminsky. However, any sort of change could be flatly rejected by\nthe community which have heavily invested in mining with the current\ntechnology. Another question is the reward halving scheme in bitcoin. The\ncurrent bitcoin specification mandates a strong 4-year cyclic property. We find\nthis property totally unreasonable and harmful and explain why and how it needs\nto be changed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 19:06:33 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2013 17:23:06 GMT"}, {"version": "v3", "created": "Thu, 10 Apr 2014 14:06:32 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Courtois", "Nicolas T.", ""], ["Grajek", "Marek", ""], ["Naik", "Rahul", ""]]}, {"id": "1310.8583", "submitter": "Swakkhar Shatabda", "authors": "Swakkhar Shatabda, M.A. Hakim Newton, Duc Nghia Pham and Abdul Sattar", "title": "A Hybrid Local Search for Simplified Protein Structure Prediction", "comments": null, "journal-ref": "Proceedings of the International Conference on Bioinformatics\n  Models, Methods and Algorithms, Barcelona, Spain, 11 - 14 February, 2013.\n  SciTePress 2013 ISBN 978-989-8565-35-8 pages:158-163", "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein structure prediction based on Hydrophobic-Polar energy model\nessentially becomes searching for a conformation having a compact hydrophobic\ncore at the center. The hydrophobic core minimizes the interaction energy\nbetween the amino acids of the given protein. Local search algorithms can\nquickly find very good conformations by moving repeatedly from the current\nsolution to its \"best\" neighbor. However, once such a compact hydrophobic core\nis found, the search stagnates and spends enormous effort in quest of an\nalternative core. In this paper, we attempt to restructure segments of a\nconformation with such compact core. We select one large segment or a number of\nsmall segments and apply exhaustive local search. We also apply a mix of\nheuristics so that one heuristic can help escape local minima of another. We\nevaluated our algorithm by using Face Centered Cubic (FCC) Lattice on a set of\nstandard benchmark proteins and obtain significantly better results than that\nof the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 16:41:44 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Shatabda", "Swakkhar", ""], ["Newton", "M. A. Hakim", ""], ["Pham", "Duc Nghia", ""], ["Sattar", "Abdul", ""]]}]