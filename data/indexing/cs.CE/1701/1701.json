[{"id": "1701.00169", "submitter": "Hamid Hamraz", "authors": "Hamid Hamraz, Marco A. Contreras, and Jun Zhang", "title": "Vertical stratification of forest canopy for segmentation of under-story\n  trees within small-footprint airborne LiDAR point clouds", "comments": null, "journal-ref": "ISPRS Journal of Photogrammetry and Remote Sensing 130C (2017) pp.\n  385-392", "doi": "10.1016/j.isprsjprs.2017.07.001", "report-no": null, "categories": "cs.CV cs.CE cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airborne LiDAR point cloud representing a forest contains 3D data, from which\nvertical stand structure even of understory layers can be derived. This paper\npresents a tree segmentation approach for multi-story stands that stratifies\nthe point cloud to canopy layers and segments individual tree crowns within\neach layer using a digital surface model based tree segmentation method. The\nnovelty of the approach is the stratification procedure that separates the\npoint cloud to an overstory and multiple understory tree canopy layers by\nanalyzing vertical distributions of LiDAR points within overlapping locales.\nThe procedure does not make a priori assumptions about the shape and size of\nthe tree crowns and can, independent of the tree segmentation method, be\nutilized to vertically stratify tree crowns of forest canopies. We applied the\nproposed approach to the University of Kentucky Robinson Forest - a natural\ndeciduous forest with complex and highly variable terrain and vegetation\nstructure. The segmentation results showed that using the stratification\nprocedure strongly improved detecting understory trees (from 46% to 68%) at the\ncost of introducing a fair number of over-segmented understory trees (increased\nfrom 1% to 16%), while barely affecting the overall segmentation quality of\noverstory trees. Results of vertical stratification of the canopy showed that\nthe point density of understory canopy layers were suboptimal for performing a\nreasonable tree segmentation, suggesting that acquiring denser LiDAR point\nclouds would allow more improvements in segmenting understory trees. As shown\nby inspecting correlations of the results with forest structure, the\nsegmentation approach is applicable to a variety of forest types.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 21:53:09 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 19:28:07 GMT"}, {"version": "v3", "created": "Fri, 5 May 2017 15:01:30 GMT"}, {"version": "v4", "created": "Sat, 15 Jul 2017 19:55:09 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Hamraz", "Hamid", ""], ["Contreras", "Marco A.", ""], ["Zhang", "Jun", ""]]}, {"id": "1701.00180", "submitter": "Hamid Hamraz", "authors": "Hamid Hamraz, Marco A. Contreras, and Jun Zhang", "title": "A scalable approach for tree segmentation within small-footprint\n  airborne LiDAR data", "comments": "The replacement version is exactly the same and only the journal\n  biblio information and the DOI of the published version was added", "journal-ref": "Computers and Geosciences 102 (pp. 139-147): Elsevier (2017)", "doi": "10.1016/j.cageo.2017.02.017", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a distributed approach that scales up to segment tree\ncrowns within a LiDAR point cloud representing an arbitrarily large forested\narea. The approach uses a single-processor tree segmentation algorithm as a\nbuilding block in order to process the data delivered in the shape of tiles in\nparallel. The distributed processing is performed in a master-slave manner, in\nwhich the master maintains the global map of the tiles and coordinates the\nslaves that segment tree crowns within and across the boundaries of the tiles.\nA minimal bias was introduced to the number of detected trees because of trees\nlying across the tile boundaries, which was quantified and adjusted for.\nTheoretical and experimental analyses of the runtime of the approach revealed a\nnear linear speedup. The estimated number of trees categorized by crown class\nand the associated error margins as well as the height distribution of the\ndetected trees aligned well with field estimations, verifying that the\ndistributed approach works correctly. The approach enables providing\ninformation of individual tree locations and point cloud segments for a\nforest-level area in a timely manner, which can be used to create detailed\nremotely sensed forest inventories. Although the approach was presented for\ntree segmentation within LiDAR point clouds, the idea can also be generalized\nto scale up processing other big spatial datasets.\n  Highlights: - A scalable distributed approach for tree segmentation was\ndeveloped and theoretically analyzed. - ~2 million trees in a 7440 ha forest\nwas segmented in 2.5 hours using 192 cores. - 2% false positive trees were\nidentified as a result of the distributed run. - The approach can be used to\nscale up processing other big spatial data\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2017 00:10:42 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 21:13:31 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Hamraz", "Hamid", ""], ["Contreras", "Marco A.", ""], ["Zhang", "Jun", ""]]}, {"id": "1701.00198", "submitter": "Hamid Hamraz", "authors": "Hamid Hamraz, Marco A. Contreras, and Jun Zhang", "title": "A robust approach for tree segmentation in deciduous forests using\n  small-footprint airborne LiDAR data", "comments": null, "journal-ref": "International Journal of Applied Earth Observation and\n  Geoinformation 52 (pp. 532-541): Elsevier (2016)", "doi": "10.1016/j.jag.2016.07.006", "report-no": null, "categories": "cs.CV cs.CE cs.CG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a non-parametric approach for segmenting trees from\nairborne LiDAR data in deciduous forests. Based on the LiDAR point cloud, the\napproach collects crown information such as steepness and height on-the-fly to\ndelineate crown boundaries, and most importantly, does not require a priori\nassumptions of crown shape and size. The approach segments trees iteratively\nstarting from the tallest within a given area to the smallest until all trees\nhave been segmented. To evaluate its performance, the approach was applied to\nthe University of Kentucky Robinson Forest, a deciduous closed-canopy forest\nwith complex terrain and vegetation conditions. The approach identified 94% of\ndominant and co-dominant trees with a false detection rate of 13%. About 62% of\nintermediate, overtopped, and dead trees were also detected with a false\ndetection rate of 15%. The overall segmentation accuracy was 77%. Correlations\nof the segmentation scores of the proposed approach with local terrain and\nstand metrics was not significant, which is likely an indication of the\nrobustness of the approach as results are not sensitive to the differences in\nterrain and stand structures.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2017 04:49:47 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Hamraz", "Hamid", ""], ["Contreras", "Marco A.", ""], ["Zhang", "Jun", ""]]}, {"id": "1701.00317", "submitter": "Endre Somogyi", "authors": "Endre Somogyi and James A. Glazier", "title": "A modeling and simulation language for biological cells with coupled\n  mechanical and chemical processes", "comments": "Symp. Theory of Modeling & Simulation (TMS/DEVS) Spring Sim 2017,\n  Virginia Beach VA, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological cells are the prototypical example of active matter. Cells sense\nand respond to mechanical, chemical and electrical environmental stimuli with a\nrange of behaviors, including dynamic changes in morphology and mechanical\nproperties, chemical uptake and secretion, cell differentiation, proliferation,\ndeath, or migration.\n  Modeling and simulation of such dynamic phenomena poses a number of\ncomputational challenges. A modeling language to describe cellular dynamics\nmust be able to naturally represent complex intra and extra-cellular spatial\nstructures, and coupled mechanical, chemical and electrical processes. In order\nto be useful to domain experts, a modeling language should be based on\nconcepts, terms and principles native to the problem domain. A compiler must\nthen be able to generate an executable model from this physically motivated\ndescription. Finally, an executable model must efficiently calculate the time\nevolution of such dynamic and inhomogeneous phenomena.\n  We present a spatial hybrid systems modeling language, compiler and mesh-free\nLagrangian based simulation engine which will enable domain experts to define\nmodels using natural, biologically motivated constructs and to simulate time\nevolution of coupled cellular, mechanical and chemical processes acting on a\ntime varying number of cells and their environment.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 05:32:15 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 19:23:08 GMT"}, {"version": "v3", "created": "Wed, 11 Jan 2017 02:12:17 GMT"}, {"version": "v4", "created": "Thu, 12 Jan 2017 01:19:24 GMT"}, {"version": "v5", "created": "Fri, 24 Feb 2017 19:46:51 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Somogyi", "Endre", ""], ["Glazier", "James A.", ""]]}, {"id": "1701.00392", "submitter": "Christoph Boeddeker", "authors": "Christoph Boeddeker and Patrick Hanebrink and Lukas Drude and Jahn\n  Heymann and Reinhold Haeb-Umbach", "title": "On the Computation of Complex-valued Gradients with Application to\n  Statistically Optimum Beamforming", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes the computation of gradients by algorithmic\ndifferentiation for statistically optimum beamforming operations. Especially\nthe derivation of complex-valued functions is a key component of this approach.\nTherefore the real-valued algorithmic differentiation is extended via the\ncomplex-valued chain rule. In addition to the basic mathematic operations the\nderivative of the eigenvalue problem with complex-valued eigenvectors is one of\nthe key results of this report. The potential of this approach is shown with\nexperimental results on the CHiME-3 challenge database. There, the beamforming\ntask is used as a front-end for an ASR system. With the developed derivatives a\njoint optimization of a speech enhancement and speech recognition system w.r.t.\nthe recognition optimization criterion is possible.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 14:03:38 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 10:08:28 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Boeddeker", "Christoph", ""], ["Hanebrink", "Patrick", ""], ["Drude", "Lukas", ""], ["Heymann", "Jahn", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1701.00435", "submitter": "Jason T. L. Wang", "authors": "Kevin Byron and Jason T. L. Wang", "title": "A Computational Approach to Finding RNA Tertiary Motifs in Genomic\n  Sequences", "comments": "23 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif finding in DNA, RNA and proteins plays an important role in life\nscience research. Recent patents concerning motif finding in the biomolecular\ndata are recorded in the DNA Patent Database which serves as a resource for\npolicy makers and members of the general public interested in fields like\ngenomics, genetics and biotechnology. In this paper we present a computational\napproach to mining for RNA tertiary motifs in genomic sequences. Specifically\nwe describe a method, named CSminer, for finding RNA coaxial helical stackings\nin genomes. A coaxial helical stacking occurs in an RNA tertiary structure\nwhere two separate helical elements form a pseudocontiguous helix and provides\nthermodynamic stability to the molecule as a whole. Experimental results\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 16:18:05 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Byron", "Kevin", ""], ["Wang", "Jason T. L.", ""]]}, {"id": "1701.00557", "submitter": "Carlos Barron-Romero Prof.", "authors": "Carlos Barr\\'on-Romero", "title": "Discrete Optimal Global Convergence of an Evolutionary Algorithm for\n  Clusters under the Potential of Lennard Jones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A review of the properties that bond the particles under Lennard Jones\nPotential allow to states properties and conditions for building evolutive\nalgorithms using the CB lattice with other different lattices. The new lattice\nis called CB lattice and it is based on small cubes. A set of propositions\nstates convergence and optimal conditions over the CB lattice for an\nevolutionary algorithm. The evolutionary algorithm is a reload version of\nprevious genetic algorithms based in phenotypes. The novelty using CB lattice,\ntogether with the other lattices, and ad-hoc cluster segmentation and\nenumeration, is to allow the combination of genotype (DNA coding for cluster\nusing their particle's number) and phenotype (geometrical shapes using\nparticle's coordinates in 3D). A parallel version of an evolutionary algorithm\nfor determining the global optimality is depicted. The results presented are\nfrom a standalone program for a personal computer of the evolutionary\nalgorithm, which can estimate all putative optimal Lennard Jones Clusters from\n13 to 1612 particles. The novelty are the theoretical results for the\nevolutionary algorithm's efficiency, the strategies with phenotype or genotype,\nand the classification of the clusters based in an ad-hoc geometric algorithm\nfor segmenting a cluster into its nucleus and layers. Also, the standalone\nprogram is not only capable to replicate the optimal Lennard Jones clusters in\nThe Cambridge Cluster Database (CCD), but to find new ones.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 00:37:08 GMT"}, {"version": "v2", "created": "Wed, 4 Jan 2017 01:54:11 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Barr\u00f3n-Romero", "Carlos", ""]]}, {"id": "1701.00997", "submitter": "Severin Sadjina", "authors": "Severin Sadjina, Lars T. Kyllingstad, Martin Rindar{\\o}y, Stian\n  Skjong, Vilmar {\\AE}s{\\o}y, Dariusz Eirik Fathi, Vahid Hassani, Trond\n  Johnsen, J{\\o}rgen Bremnes Nielsen, Eilif Pedersen", "title": "Distributed Co-Simulation of Maritime Systems and Operations", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we present the concept of an open virtual prototyping framework for\nmaritime systems and operations that enables its users to develop re-usable\ncomponent or subsystem models, and combine them in full-system simulations for\nprototyping, verification, training, and performance studies. This framework\nconsists of a set of guidelines for model coupling, high-level and low-level\ncoupling interfaces to guarantee interoperability, a full-system simulation\nsoftware, and example models and demonstrators. We discuss the requirements for\nsuch a framework, address the challenges and the possibilities in fulfilling\nthem, and aim to give a list of best practices for modular and efficient\nvirtual prototyping and full-system simulation. The context of our work is\nwithin maritime systems and operations, but the issues and solutions we present\nhere are general enough to be of interest to a much broader audience, both\nindustrial and scientific.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 13:23:04 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Sadjina", "Severin", ""], ["Kyllingstad", "Lars T.", ""], ["Rindar\u00f8y", "Martin", ""], ["Skjong", "Stian", ""], ["\u00c6s\u00f8y", "Vilmar", ""], ["Fathi", "Dariusz Eirik", ""], ["Hassani", "Vahid", ""], ["Johnsen", "Trond", ""], ["Nielsen", "J\u00f8rgen Bremnes", ""], ["Pedersen", "Eilif", ""]]}, {"id": "1701.01359", "submitter": "Daniel Ruprecht", "authors": "Daniel Ruprecht", "title": "Wave propagation characteristics of Parareal", "comments": null, "journal-ref": "Computing and Visualization in Science 19(1), pp. 1- 17, 2018", "doi": "10.1007/s00791-018-0296-z", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper derives and analyses the (semi-)discrete dispersion relation of the\nParareal parallel-in-time integration method. It investigates Parareal's wave\npropagation characteristics with the aim to better understand what causes the\nwell documented stability problems for hyperbolic equations. The analysis shows\nthat the instability is caused by convergence of the amplification factor to\nthe exact value from above for medium to high wave numbers. Phase errors in the\ncoarse propagator are identified as the culprit, which suggests that\nspecifically tailored coarse level methods could provide a remedy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 15:49:54 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 12:33:08 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Ruprecht", "Daniel", ""]]}, {"id": "1701.01430", "submitter": "Christopher Vogl", "authors": "Christopher J. Vogl and Randall J. LeVeque", "title": "A High-Resolution Finite Volume Seismic Model to Generate Seafloor\n  Deformation for Tsunami Modeling", "comments": null, "journal-ref": null, "doi": "10.1007/s10915-017-0459-y", "report-no": null, "categories": "cs.CE physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high-resolution finite volume method approach to incorporating\ntime-dependent slip across rectangular subfaults when modeling general fault\ngeometry is presented. The fault slip is induced by a modification of the\nRiemann problem to the linear elasticity equations across cell interfaces\naligned with the subfaults. This is illustrated in the context of the\nhigh-resolution wave-propagation algorithms that are implemented in the open\nsource Clawpack software (www.clawpack.org), but this approach could be easily\nincorporated into other Riemann solver based numerical methods. Surface\ndeformation results are obtained in both two and three dimensions and compared\nto those given by the steady-state, homogeneous half-space Okada solution.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 03:14:07 GMT"}, {"version": "v2", "created": "Sun, 14 May 2017 03:59:01 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Vogl", "Christopher J.", ""], ["LeVeque", "Randall J.", ""]]}, {"id": "1701.01496", "submitter": "Bernd Flemisch", "authors": "Bernd Flemisch, Inga Berre, Wietse Boon, Alessio Fumagalli, Nicolas\n  Schwenck, Anna Scotti, Ivar Stefansson, and Alexandru Tatomir", "title": "Benchmarks for single-phase flow in fractured porous media", "comments": null, "journal-ref": null, "doi": "10.1016/j.advwatres.2017.10.036", "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents several test cases intended to be benchmarks for\nnumerical schemes for single-phase fluid flow in fractured porous media. A\nnumber of solution strategies are compared, including a vertex and a\ncell-centered finite volume method, a non-conforming embedded discrete fracture\nmodel, a primal and a dual extended finite element formulation, and a mortar\ndiscrete fracture model. The proposed benchmarks test the schemes by increasing\nthe difficulties in terms of network geometry, e.g. intersecting fractures, and\nphysical parameters, e.g. low and high fracture-matrix permeability ratio as\nwell as heterogeneous fracture permeabilities. For each problem, the results\npresented by the participants are the number of unknowns, the approximation\nerrors in the porous matrix and in the fractures with respect to a reference\nsolution, and the sparsity and condition number of the discretized linear\nsystem. All data and meshes used in this study are publicly available for\nfurther comparisons.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 23:00:21 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Flemisch", "Bernd", ""], ["Berre", "Inga", ""], ["Boon", "Wietse", ""], ["Fumagalli", "Alessio", ""], ["Schwenck", "Nicolas", ""], ["Scotti", "Anna", ""], ["Stefansson", "Ivar", ""], ["Tatomir", "Alexandru", ""]]}, {"id": "1701.02059", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Lu Lu, He Li, Constantinos Evangelinos, Leopold\n  Grinberg, Vipin Sachdeva, George Em Karniadakis", "title": "OpenRBC: A Fast Simulator of Red Blood Cells at Protein Resolution", "comments": null, "journal-ref": null, "doi": "10.1016/j.bpj.2017.04.020", "report-no": null, "categories": "physics.bio-ph cond-mat.mes-hall cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present OpenRBC, a coarse-grained molecular dynamics code, which is\ncapable of performing an unprecedented in silico experiment --- simulating an\nentire mammal red blood cell lipid bilayer and cytoskeleton as modeled by 4\nmillion mesoscopic particles --- using a single shared memory commodity\nworkstation. To achieve this, we invented an adaptive spatial-searching\nalgorithm to accelerate the computation of short-range pairwise interactions in\nan extremely sparse 3D space. The algorithm is based on a Voronoi partitioning\nof the point cloud of coarse-grained particles, and is continuously updated\nover the course of the simulation. The algorithm enables the construction of\nthe key spatial searching data structure in our code, i.e. a lattice-free cell\nlist, with a time and space cost linearly proportional to the number of\nparticles in the system. The position and shape of the cells also adapt\nautomatically to the local density and curvature. The code implements OpenMP\nparallelization and scales to hundreds of hardware threads. It outperforms a\nlegacy simulator by almost an order of magnitude in time-to-solution and more\nthan 40 times in problem size, thus providing a new platform for probing the\nbiomechanics of red blood cells.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 03:50:29 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Tang", "Yu-Hang", ""], ["Lu", "Lu", ""], ["Li", "He", ""], ["Evangelinos", "Constantinos", ""], ["Grinberg", "Leopold", ""], ["Sachdeva", "Vipin", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1701.03009", "submitter": "Sebastian Sch\\\"ops", "authors": "Jennifer Dutin\\'e and Markus Clemens and Sebastian Sch\\\"ops and Georg\n  Wimmer", "title": "Explicit Time Integration of Transient Eddy Current Problems", "comments": "9 pages, 6 figures", "journal-ref": "Int. J. Numer. Model., 2017, e2227", "doi": "10.1002/jnm.2227", "report-no": null, "categories": "cs.CE math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For time integration of transient eddy current problems commonly implicit\ntime integration methods are used, where in every time step one or several\nnonlinear systems of equations have to be linearized with the Newton-Raphson\nmethod due to ferromagnetic materials involved. In this paper, a generalized\nSchur-complement is applied to the magnetic vector potential formulation, which\nconverts a differential-algebraic equation system of index 1 into a system of\nordinary differential equations (ODE) with reduced stiffness. For the time\nintegration of this ODE system of equations, the explicit Euler method is\napplied. The Courant-Friedrich-Levy (CFL) stability criterion of explicit time\nintegration methods may result in small time steps. Applying a pseudo-inverse\nof the discrete curl-curl operator in nonconducting regions of the problem is\nrequired in every time step. For the computation of the pseudo-inverse, the\npreconditioned conjugate gradient (PCG) method is used. The cascaded Subspace\nExtrapolation method (CSPE) is presented to produce suitable start vectors for\nthese PCG iterations. The resulting scheme is validated using the TEAM 10\nbenchmark problem.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 15:23:21 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Dutin\u00e9", "Jennifer", ""], ["Clemens", "Markus", ""], ["Sch\u00f6ps", "Sebastian", ""], ["Wimmer", "Georg", ""]]}, {"id": "1701.03147", "submitter": "Corneliu Arsene Dr", "authors": "Corneliu T.C. Arsene", "title": "Uncertainty Quantification of Water Distribution System Measurement Data\n  based on a Least Squares Loop Flows State Estimator", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel algorithm for uncertainty quantification of water\ndistribution system measurement data including nodal demands/consumptions as\nwell as real pressure and flow measurements. This procedure, referred to as\nConfidence Limit Analysis (CLA), is concerned with a deployment of a Least\nSquares (LS) state estimator based on the loop corrective flows and the\nvariation of nodal demands as independent variables. The confidence limits\nobtained for the nodal pressures and the inflows/outflows of a water network\nare determined with the novel algorithm called Error Maximization (EM) method\nand are evaluated with respect to two other more established CLA algorithms\nbased on an Experimental Sensitivity Matrix (ESM) and on the sensitivity matrix\nmethod obtained with the LS nodal heads equations state estimator. The\nestimated confidence limits obtained for two real water networks show that the\nproposed EM algorithm is comparable to the other two CLA benchmark algorithms\nbut due to its computational efficiency it is more suitable for online decision\nsupport applications in water distribution systems. Both ESM and EM methods\nwork for any operating point, whether arbitrarily or randomly chosen, for any\nwater network although EM method has the advantage of being computationally\nsuperior and working with any sets of measurements.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 20:14:45 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2017 13:43:31 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Arsene", "Corneliu T. C.", ""]]}, {"id": "1701.03205", "submitter": "M.Nazif Faqiry", "authors": "M. Nazif Faqiry, Ahmad Khaled Zarabie, Fatehullah Nassery, Hongyu Wu,\n  Sanjoy Das", "title": "A Day Ahead Market Energy Auction for Distribution System Operation", "comments": "Electro Information Technology (EIT), 2017 IEEE International\n  Conference on", "journal-ref": null, "doi": "10.1109/EIT.2017.8053352", "report-no": null, "categories": "cs.SY cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a day ahead double energy auction in a distribution\nsystem involving dispatchable generation units, renewable generation units\nsupported by battery storage systems(BSSs), fixed loads, price responsive\nloads, and supply from the Whole Sale Market(WSM) at Locational Marginal\nPrice(LMP). The auction is implemented within a Distribution System Operator\n(DSO) premises using Mixed Integer Linear Programming (MIP). The proposed\nauction is cleared at the Distribution LMP (DLMP) and is observed to be weakly\nbudget balanced if no penalty is applied for DSO's deviation from originally\ncommitted supply from the WSM. Furthermore, the dynamics of LMP and DLMP, and\ntheir effect on distribution market participants scheduled quantities as well\nas the WSM supply to the distribution system is investigated.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 01:23:39 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 18:37:42 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2017 17:20:16 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Faqiry", "M. Nazif", ""], ["Zarabie", "Ahmad Khaled", ""], ["Nassery", "Fatehullah", ""], ["Wu", "Hongyu", ""], ["Das", "Sanjoy", ""]]}, {"id": "1701.03636", "submitter": "Jan Zeman", "authors": "Alena Zemanov\\'a, Jan Zeman, and Michal \\v{S}ejnoha", "title": "Comparison of viscoelastic finite element models for laminated glass\n  beams", "comments": "30 pages, 11 figures, 8 tables, 1 algorithm", "journal-ref": "International Journal of Mechanical Sciences 131--132, 380--395,\n  (2017)", "doi": "10.1016/j.ijmecsci.2017.05.035", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laminated glass elements, which consist of stiff elastic glass layers\nconnected with a compliant viscoelastic polymer foil, exhibit geometrically\nnon-linear and time/temperature-sensitive behavior. In computational modeling,\nthe viscoelastic effects are often neglected or a detailed continuum\nformulation typically based on the volumetric-deviatoric elastic-viscoelastic\nsplit is used for the interlayer. Four layerwise beam theories are introduced\nin this paper, which differ in the non-linear beam formulation at the layer\nlevel (von K\\'{a}rm\\'{a}n/Reissner) and in constitutive assumptions for the\ninterlayer (a viscoelastic solid with the time-independent bulk modulus/Poisson\nratio). We perform detailed verification and validation studies at different\ntemperatures and compare the accuracy of the selected formulation with\nsimplified elastic solutions used in practice. We show that all the four\nformulations predict very similar responses. Therefore, our suggestion is to\nuse the most straightforward formulation that combines the von K\\'{a}rm\\'{a}n\nmodel with the assumption of time-independent Poisson ratio. The simplified\nelastic model mostly provides a response in satisfactory agreement with full\nviscoelastic solutions. However, it can lead to unsafe or inaccurate\npredictions for rapid changes of loading. These findings provide a suitable\nbasis for extensions towards laminated plates and glass layer fracture, owing\nto the modular format of layerwise theories.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 11:53:56 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 12:09:07 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Zemanov\u00e1", "Alena", ""], ["Zeman", "Jan", ""], ["\u0160ejnoha", "Michal", ""]]}, {"id": "1701.03978", "submitter": "Nikolaos Sahinidis", "authors": "Nick D. Austin, Nikolaos V. Sahinidis, and Daniel W. Trahan", "title": "Computer-aided molecular design: An introduction and review of tools,\n  applications, and solution techniques", "comments": "38 pages, 13 figures, 3 tables, 173 references", "journal-ref": "Chemical Engineering Research and Design, 116, 2-26, 2016", "doi": "10.1016/j.cherd.2016.10.014", "report-no": null, "categories": "cs.CE physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an introduction to and review of the field of\ncomputer-aided molecular design (CAMD). It is intended to be approachable for\nthe absolute beginner as well as useful to the seasoned CAMD practitioner. We\nbegin by discussing various quantitative structure-property relationships\n(QSPRs) which have been demonstrated to work well with CAMD problems. The\nmethods discussed in this article are (1) group contribution methods, (2)\ntopological indices, and (3) signature descriptors. Next, we present general\noptimization formulations for various forms of the CAMD problem. Common design\nconstraints are discussed and structural feasibility constraints are provided\nfor the three types of QSPRs addressed. We then detail useful techniques for\napproaching CAMD optimization problems, including decomposition methods,\nheuristic approaches, and mathematical programming strategies. Finally, we\ndiscuss many applications that have been addressed using CAMD.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 01:12:11 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Austin", "Nick D.", ""], ["Sahinidis", "Nikolaos V.", ""], ["Trahan", "Daniel W.", ""]]}, {"id": "1701.04503", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Nathan O. Hodas, Abhinav Vishnu", "title": "Deep Learning for Computational Chemistry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CE cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise and fall of artificial neural networks is well documented in the\nscientific literature of both computer science and computational chemistry. Yet\nalmost two decades later, we are now seeing a resurgence of interest in deep\nlearning, a machine learning algorithm based on multilayer neural networks.\nWithin the last few years, we have seen the transformative impact of deep\nlearning in many domains, particularly in speech recognition and computer\nvision, to the extent that the majority of expert practitioners in those field\nare now regularly eschewing prior established models in favor of deep learning\nmodels. In this review, we provide an introductory overview into the theory of\ndeep neural networks and their unique properties that distinguish them from\ntraditional machine learning algorithms used in cheminformatics. By providing\nan overview of the variety of emerging applications of deep neural networks, we\nhighlight its ubiquity and broad applicability to a wide range of challenges in\nthe field, including QSAR, virtual screening, protein structure prediction,\nquantum chemistry, materials design and property prediction. In reviewing the\nperformance of deep neural networks, we observed a consistent outperformance\nagainst non-neural networks state-of-the-art models across disparate research\ntopics, and deep neural network based models often exceeded the \"glass ceiling\"\nexpectations of their respective tasks. Coupled with the maturity of\nGPU-accelerated computing for training deep neural networks and the exponential\ngrowth of chemical data on which to train these networks on, we anticipate that\ndeep learning algorithms will be a valuable tool for computational chemistry.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 01:15:14 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Goh", "Garrett B.", ""], ["Hodas", "Nathan O.", ""], ["Vishnu", "Abhinav", ""]]}, {"id": "1701.04681", "submitter": "Corneliu Arsene Dr", "authors": "Corneliu T.C. Arsene", "title": "Operational Decision Support in the Presence of Uncertainties", "comments": "PhD thesis - corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book addresses the scientific domains of operations research,\ninformation science and statistics with a focus on engineering applications.\nThe purpose of this book is to report on the implications of the loop equations\nformulation of the state estimation procedure of the network systems, for the\npurpose of the implementation of Decision Support (DS) systems for the\noperational control of the network systems. In general an operational DS\ncomprises a series of standalone applications from which the mathematical\nmodeling and simulation of the distribution systems and the managing of the\nuncertainty in the decision-making process are essential in order to obtain\nefficient control and monitoring of the distribution systems. The mathematical\nmodeling and simulation forms the basis for detailed optimization of the\nnetwork operations and the second one uses uncertainty based reasoning in order\nto reduce the complexity of the network system and to increase the credibility\nof its model. This book reports on the integration of the two aspects of\noperational DS into a single computational framework of loop network equations.\nThe proposed DS system will be validated using case studies taken from the\nwater industry. The optimal control of water distribution systems is an\nimportant problem because the models are non-linear and large-scale and\nmeasurements are prone to errors and very often they are incomplete.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 15:45:53 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2017 13:22:39 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 23:35:53 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Arsene", "Corneliu T. C.", ""]]}, {"id": "1701.04695", "submitter": "Arun Hegde", "authors": "Arun Hegde, Wenyu Li, James Oreluk, Andrew Packard, Michael Frenklach", "title": "Consistency Analysis for Massively Inconsistent Datasets in\n  Bound-to-Bound Data Collaboration", "comments": "31 pages, published in SIAM/ASA Journal on Uncertainty Quantification", "journal-ref": "SIAM/ASA J. Uncertainty Quantification, 6(2), 2018, pp. 429-456", "doi": "10.1137/16M1110005", "report-no": null, "categories": "math.OC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bound-to-Bound Data Collaboration (B2BDC) provides a natural framework for\naddressing both forward and inverse uncertainty quantification problems. In\nthis approach, QOI (quantity of interest) models are constrained by related\nexperimental observations with interval uncertainty. A collection of such\nmodels and observations is termed a dataset and carves out a feasible region in\nthe parameter space. If a dataset has a nonempty feasible set, it is said to be\nconsistent. In real-world applications, it is often the case that collections\nof experiments and observations are inconsistent. Revealing the source of this\ninconsistency, i.e., identifying which models and/or observations are\nproblematic, is essential before a dataset can be used for prediction. To\naddress this issue, we introduce a constraint relaxation-based approach,\nentitled the vector consistency measure, for investigating datasets with\nnumerous sources of inconsistency. The benefits of this vector consistency\nmeasure over a previous method of consistency analysis are demonstrated in two\nrealistic gas combustion examples.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 21:41:54 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 05:49:46 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 05:04:01 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Hegde", "Arun", ""], ["Li", "Wenyu", ""], ["Oreluk", "James", ""], ["Packard", "Andrew", ""], ["Frenklach", "Michael", ""]]}, {"id": "1701.05242", "submitter": "Paul Springer", "authors": "Paul Springer, Ahmed E. Ismail, Paolo Bientinesi", "title": "A Scalable, Linear-Time Dynamic Cutoff Algorithm for Molecular Dynamics", "comments": "in ISC High Performance 2015", "journal-ref": null, "doi": "10.1007/978-3-319-20119-1_12", "report-no": null, "categories": "physics.comp-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results on supercomputers show that beyond 65K cores, the efficiency\nof molecular dynamics simulations of interfacial systems decreases\nsignificantly. In this paper, we introduce a dynamic cutoff method (DCM) for\ninterfacial systems of arbitrarily large size. The idea consists in adopting a\ncutoff-based method in which the cutoff is cho- sen on a particle-by-particle\nbasis, according to the distance from the interface. Computationally, the\nchallenge is shifted from the long-range solvers to the detection of the\ninterfaces and to the computation of the particle-interface distances. For\nthese tasks, we present linear-time algorithms that do not rely on global\ncommunication patterns. As a result, the DCM algorithm is suited for large\nsystems of particles and mas- sively parallel computers. To demonstrate its\npotential, we integrated DCM into the LAMMPS open-source molecular dynamics\npackage, and simulated large liquid/vapor systems on two supercomputers:\nSuperMuc and JUQUEEN. In all cases, the accuracy of DCM is comparable to the\ntraditional particle-particle particle-mesh (PPPM) algorithm, while the\nperformance is considerably superior for large numbers of particles. For\nJUQUEEN, we provide timings for simulations running on the full system (458,\n752 cores), and show nearly perfect strong and weak scaling.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 21:53:25 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Springer", "Paul", ""], ["Ismail", "Ahmed E.", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1701.06182", "submitter": "Andreas Nold", "authors": "Andreas Nold, Benjamin D. Goddard, Peter Yatsyshin, Nikos Savva,\n  Serafim Kalliadasis", "title": "Pseudospectral methods for density functional theory in bounded and\n  unbounded domains", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2016.12.023", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical Density Functional Theory (DFT) is a statistical-mechanical\nframework to analyze fluids, which accounts for nanoscale fluid inhomogeneities\nand non-local intermolecular interactions. DFT can be applied to a wide range\nof interfacial phenomena, as well as problems in adsorption, colloidal science\nand phase transitions in fluids. Typical DFT equations are highly non-linear,\nstiff and contain several convolution terms. We propose a novel, efficient\npseudo-spectral collocation scheme for computing the non-local terms in real\nspace with the help of a specialized Gauss quadrature. Due to the exponential\naccuracy of the quadrature and a convenient choice of collocation points near\ninterfaces, we can use grids with a significantly lower number of nodes than\nmost other reported methods. We demonstrate the capabilities of our numerical\nmethodology by studying equilibrium and dynamic two-dimensional test cases with\nsingle- and multispecies hard-sphere and hard-disc particles modelled with\nfundamental measure theory, with and without van der Waals attractive forces,\nin bounded and unbounded physical domains. We show that our results satisfy\nstatistical mechanical sum rules.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2017 16:23:38 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Nold", "Andreas", ""], ["Goddard", "Benjamin D.", ""], ["Yatsyshin", "Peter", ""], ["Savva", "Nikos", ""], ["Kalliadasis", "Serafim", ""]]}, {"id": "1701.06254", "submitter": "Hui Liu Mr", "authors": "Hui Liu, Lihua Shen, Yan Chen, Kun Wang, Bo Yang, Zhangxin Chen", "title": "A Parallel Simulator for Massive Reservoir Models Utilizing\n  Distributed-Memory Parallel Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1606.00556", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our work on developing parallel computational methods for\ntwo-phase flow on modern parallel computers, where techniques for linear\nsolvers and nonlinear methods are studied and the standard and inexact Newton\nmethods are investigated. A multi-stage preconditioner for two-phase flow is\napplied and advanced matrix processing strategies are studied. A local\nreordering method is developed to speed the solution of linear systems.\nNumerical experiments show that these computational methods are effective and\nscalable, and are capable of computing large-scale reservoir simulation\nproblems using thousands of CPU cores on parallel computers. The nonlinear\ntechniques, preconditioner and matrix processing strategies can also be applied\nto three-phase black oil, compositional and thermal models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 02:35:21 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Liu", "Hui", ""], ["Shen", "Lihua", ""], ["Chen", "Yan", ""], ["Wang", "Kun", ""], ["Yang", "Bo", ""], ["Chen", "Zhangxin", ""]]}, {"id": "1701.06432", "submitter": "Alessandro Pluchino", "authors": "A. Greco, A. Pluchino, S. Caddemi, I. Cali\\`o, F. Cannizzaro", "title": "On profile reconstruction of Euler-Bernoulli beams by means of an energy\n  based genetic algorithm", "comments": "27 pages, 7 figures, 6 tables", "journal-ref": "Engineering with Computers 2019", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the inverse problem related to the identification of the\nflexural stiffness of an Euler Bernoulli beam in order to reconstruct its\nprofile starting from available response data. The proposed identification\nprocedure makes use of energy measurements and is based on the application of a\nclosed form solution for the static displacements of multi-stepped beams. This\nsolution allows to easily calculate the energy related to beams modeled with\narbitrary multi-step shapes subjected to a transversal roving force, and to\ncompare it with the correspondent data obtained through direct measurements on\nreal beams. The optimal solution which minimizes the difference between\nmeasured and calculated data is then sought by means of genetic algorithms. In\nthe paper several different stepped beams are investigated showing that the\nproposed procedure allows in many cases to identify the exact beam profile.\nHowever it is shown that in some other cases different multi-step profiles may\ncorrespond to very similar static responses, and therefore to comparable minima\nin the optimization problem, thus complicating the profile identification\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 08:39:00 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 11:00:56 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Greco", "A.", ""], ["Pluchino", "A.", ""], ["Caddemi", "S.", ""], ["Cali\u00f2", "I.", ""], ["Cannizzaro", "F.", ""]]}, {"id": "1701.07059", "submitter": "Denys Dutykh", "authors": "Suelen Gasparin (PUCPR, LAMA), Julien Berger (LOCIE, PUCPR), Denys\n  Dutykh (LAMA), Nathan Mendes (PUCPR)", "title": "Stable explicit schemes for simulation of nonlinear moisture transfer in\n  porous materials", "comments": "35 pages, 16 figures, 1 table, 32 references. Other author's papers\n  can be downloaded at http://www.denys-dutykh.com/. arXiv admin note: text\n  overlap with arXiv:1612.07649", "journal-ref": "Journal of Building Performance Simulation (2018), Vol. 11, Issue\n  2, pp. 129-144", "doi": "10.1080/19401493.2017.1298669", "report-no": null, "categories": "cs.CE cs.NA physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit schemes have been extensively used in building physics to compute\nthe solution of moisture diffusion problems in porous materials for improving\nstability conditions. Nevertheless, these schemes require important\nsub-iterations when treating non-linear problems. To overcome this\ndisadvantage, this paper explores the use of improved explicit schemes, such as\nDufort-Frankel, Crank-Nicolson and hyperbolisation approaches. A first case\nstudy has been considered with the hypothesis of linear transfer. The\nDufort-Frankel, Crank-Nicolson and hyperbolisation schemes were compared to the\nclassical Euler explicit scheme and to a reference solution. Results have shown\nthat the hyperbolisation scheme has a stability condition higher than the\nstandard Courant-Friedrichs-Lewy (CFL) condition. The error of this schemes\ndepends on the parameter \\tau representing the hyperbolicity magnitude added\ninto the equation. The Dufort-Frankel scheme has the advantages of being\nunconditionally stable and is preferable for non-linear transfer, which is the\nsecond case study. Results have shown the error is proportional to O(\\Delta t).\nA modified Crank-Nicolson scheme has been proposed in order to avoid\nsub-iterations to treat the non-linearities at each time step. The main\nadvantages of the Dufort-Frankel scheme are (i) to be twice faster than the\nCrank-Nicolson approach; (ii) to compute explicitly the solution at each time\nstep; (iii) to be unconditionally stable and (iv) easier to parallelise on\nhigh-performance computer systems. Although the approach is unconditionally\nstable, the choice of the time discretisation $\\Delta t$ remains an important\nissue to accurately represent the physical phenomena.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 15:06:51 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2017 14:17:38 GMT"}, {"version": "v3", "created": "Tue, 28 Mar 2017 08:25:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Gasparin", "Suelen", "", "PUCPR, LAMA"], ["Berger", "Julien", "", "LOCIE, PUCPR"], ["Dutykh", "Denys", "", "LAMA"], ["Mendes", "Nathan", "", "PUCPR"]]}, {"id": "1701.08742", "submitter": "Christopher Zimmermann", "authors": "Christopher Zimmermann and Roger A. Sauer", "title": "Adaptive local surface refinement based on LR NURBS and its application\n  to contact", "comments": "Computational Mechanics (2017)", "journal-ref": null, "doi": "10.1007/s00466-017-1455-7", "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel adaptive local surface refinement technique based on Locally Refined\nNon-Uniform Rational B-Splines (LR NURBS) is presented. LR NURBS can model\ncomplex geometries exactly and are the rational extension of LR B-splines. The\nlocal representation of the parameter space overcomes the drawback of\nnon-existent local refinement in standard NURBS-based isogeometric analysis.\nFor a convenient embedding into general finite element code, the B\\'ezier\nextraction operator for LR NURBS is formulated. An automatic remeshing\ntechnique is presented that allows adaptive local refinement and coarsening of\nLR NURBS. In this work, LR NURBS are applied to contact computations of 3D\nsolids and membranes. For solids, LR NURBS-enriched finite elements are used to\ndiscretize the contact surfaces with LR NURBS finite elements, while the rest\nof the body is discretized by linear Lagrange finite elements. For membranes,\nthe entire surface is discretized by LR NURBS. Various numerical examples are\nshown, and they demonstrate the benefit of using LR NURBS: Compared to uniform\nrefinement, LR NURBS can achieve high accuracy at lower computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 18:29:18 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 10:06:56 GMT"}, {"version": "v3", "created": "Mon, 18 Sep 2017 15:58:09 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Zimmermann", "Christopher", ""], ["Sauer", "Roger A.", ""]]}, {"id": "1701.09079", "submitter": "Eric Guyes", "authors": "Eric N. Guyes, Amit N. Shocron, Anastasia Simanovski, P.M. Biesheuvel,\n  Matthew E. Suss", "title": "A one-dimensional model for water desalination by flow-through electrode\n  capacitive deionization", "comments": "13 pages, 4 figures. Engineering model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capacitive deionization (CDI) is a fast-emerging water desalination\ntechnology in which a small cell voltage of ~1 V across porous carbon\nelectrodes removes salt from feedwaters via electrosorption. In flow-through\nelectrode (FTE) CDI cell architecture, feedwater is pumped through macropores\nor laser perforated channels in porous electrodes, enabling highly compact\ncells with parallel flow and electric field, as well as rapid salt removal. We\nhere present a one-dimensional model describing water desalination by FTE CDI,\nand a comparison to data from a custom-built experimental cell. The model\nemploys simple cell boundary conditions derived via scaling arguments. We show\ngood model-to-data fits with reasonable values for fitting parameters such as\nthe Stern layer capacitance, micropore volume, and attraction energy. Thus, we\ndemonstrate that from an engineering modeling perspective, an FTE CDI cell may\nbe described with simpler one-dimensional models, unlike more typical\nflow-between electrodes architecture where 2D models are required.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 19:51:35 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Guyes", "Eric N.", ""], ["Shocron", "Amit N.", ""], ["Simanovski", "Anastasia", ""], ["Biesheuvel", "P. M.", ""], ["Suss", "Matthew E.", ""]]}, {"id": "1701.09131", "submitter": "Philippe Karamian - Surville", "authors": "Viwanou Hounkpati, Vladimir Salnikov, Alexandre Vivet, Philippe\n  Karamian-Surville", "title": "On the choice of homogenization method to achieve effective mechanical\n  properties of composites reinforced by ellipsoidal and spherical particles", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, several rigorous numerical simulations were conducted to\nexamine the relevance of mean-field micromechanical models compared to the Fast\nFourier Transform full-field computation by considering spherical or\nellipsoidal inclusions. To be more general, the numerical study was extended to\na mixture of different kind of microstructures consisting of spheroidal shapes\nwithin the same RVE. Although the Fast Fourier Transform full field calculation\nis sensitive to high contrasts, calculation time, for a combination of complex\nmicrostructures, remains reasonable compared with those obtained with\nmean-field micromechanical models. Moreover, for low volume fractions of\ninclusions, the results of the mean-field approximations and those of the Fast\nFourier Transform-based (FFTb) full-field computation are very close, whatever\nthe inclusions morphology is. For RVEs consisting of ellipsoidal or a mixture\nof ellipsoidal and spherical inclusions, when the inclusions volume fraction\nbecomes higher, one observes that Lielens' model and the FFTb full-field\ncomputation give similar estimates. The accuracy of the computational methods\ndepends on the shape of the inclusions' and their volume fraction.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 17:06:29 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Hounkpati", "Viwanou", ""], ["Salnikov", "Vladimir", ""], ["Vivet", "Alexandre", ""], ["Karamian-Surville", "Philippe", ""]]}]