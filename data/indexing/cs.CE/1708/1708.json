[{"id": "1708.00420", "submitter": "Leander Kotzur", "authors": "Leander Kotzur, Peter Markewitz, Martin Robinius, Detlef Stolten", "title": "Impact of different time series aggregation methods on optimal energy\n  system design", "comments": null, "journal-ref": null, "doi": "10.1016/j.renene.2017.10.017", "report-no": null, "categories": "math.OC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling renewable energy systems is a computationally-demanding task due to\nthe high fluctuation of supply and demand time series. To reduce the scale of\nthese, this paper discusses different methods for their aggregation into\ntypical periods. Each aggregation method is applied to a different type of\nenergy system model, making the methods fairly incomparable. To overcome this,\nthe different aggregation methods are first extended so that they can be\napplied to all types of multidimensional time series and then compared by\napplying them to different energy system configurations and analyzing their\nimpact on the cost optimal design. It was found that regardless of the method,\ntime series aggregation allows for significantly reduced computational\nresources. Nevertheless, averaged values lead to underestimation of the real\nsystem cost in comparison to the use of representative periods from the\noriginal time series. The aggregation method itself, e.g. k means clustering,\nplays a minor role. More significant is the system considered: Energy systems\nutilizing centralized resources require fewer typical periods for a feasible\nsystem design in comparison to systems with a higher share of renewable\nfeed-in. Furthermore, for energy systems based on seasonal storage, currently\nexisting models integration of typical periods is not suitable.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 17:15:29 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Kotzur", "Leander", ""], ["Markewitz", "Peter", ""], ["Robinius", "Martin", ""], ["Stolten", "Detlef", ""]]}, {"id": "1708.00465", "submitter": "Peyman Tavallali", "authors": "Peyman Tavallali, Hana Koorehdavoudi, Joanna Krupa", "title": "Intrinsic Frequency Analysis and Fast Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic Frequency (IF) has recently been introduced as an ample signal\nprocessing method for analyzing carotid and aortic pulse pressure tracings. The\nIF method has also been introduced as an effective approach for the analysis of\ncardiovascular system dynamics. The physiological significance, convergence and\naccuracy of the IF algorithm has been established in prior works. In this\npaper, we show that the IF method could be derived by appropriate mathematical\napproximations from the Navier-Stokes and elasticity equations. We further\nintroduce a fast algorithm for the IF method based on the mathematical analysis\nof this method. In particular, we demonstrate that the IF algorithm can be made\nfaster, by a factor or more than 100 times, using a proper set of initial\nguesses based on the topology of the problem, fast analytical solution at each\npoint iteration, and substituting the brute force algorithm with a pattern\nsearch method. Statistically, we observe that the algorithm presented in this\narticle complies well with its brute-force counterpart. Furthermore, we will\nshow that on a real dataset, the fast IF method can draw correlations between\nthe extracted intrinsic frequency features and the infusion of certain drugs.\nIn general, this paper aims at a mathematical analysis of the IF method to show\nits possible origins and also to present faster algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 18:23:40 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Tavallali", "Peyman", ""], ["Koorehdavoudi", "Hana", ""], ["Krupa", "Joanna", ""]]}, {"id": "1708.00745", "submitter": "Emmanuel Soubies", "authors": "Emmanuel Soubies, Thanh-An Pham and Michael Unser", "title": "Efficient Inversion of Multiple-Scattering Model for Optical Diffraction\n  Tomography", "comments": null, "journal-ref": "Opt. Express 25, 21786-21800 (2017)", "doi": "10.1364/OE.25.021786", "report-no": null, "categories": "cs.CE cs.NA physics.data-an physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical diffraction tomography relies on solving an inverse scattering\nproblem governed by the wave equation. Classical reconstruction algorithms are\nbased on linear approximations of the forward model (Born or Rytov), which\nlimits their applicability to thin samples with low refractive-index contrasts.\nMore recent works have shown the benefit of adopting nonlinear models. They\naccount for multiple scattering and reflections, improving the quality of\nreconstruction. To reduce the complexity and memory requirements of these\nmethods, we derive an explicit formula for the Jacobian matrix of the nonlinear\nLippmann-Schwinger model which lends itself to an efficient evaluation of the\ngradient of the data- fidelity term. This allows us to deploy efficient methods\nto solve the corresponding inverse problem subject to sparsity constraints.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 09:46:32 GMT"}, {"version": "v2", "created": "Thu, 31 Aug 2017 09:40:55 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Soubies", "Emmanuel", ""], ["Pham", "Thanh-An", ""], ["Unser", "Michael", ""]]}, {"id": "1708.01391", "submitter": "Zheng Li", "authors": "Zheng Li and Maria Kihl and Anders Robertsson", "title": "On a Feedback Control-based Mechanism of Bidding for Cloud Spot Service", "comments": "Proceedings of the 7th International Conference on Cloud Computing\n  Technology and Science (CloudCom 2015), pp. 290-297, Vancouver, Canada,\n  November 30 - December 03, 2015", "journal-ref": null, "doi": "10.1109/CloudCom.2015.76", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a cost-effective option for Cloud consumers, spot service has been\nconsidered to be a significant supplement for building a full-fledged market\neconomy for the Cloud ecosystem. However, unlike the static and straightforward\nway of trading on-demand and reserved Cloud services, the market-driven\nregulations of employing spot service could be too complicated for Cloud\nconsumers to comprehensively understand. In particular, it would be both\ndifficult and tedious for potential consumers to determine suitable bids from\ntime to time. To reduce the complexity in applying spot resources, we propose\nto use a feedback control to help make bidding decisions. Based on an\narccotangent-function-type system model, our novel bidding mechanism imitates\nfuzzy and intuitive human activities to refine and issue new bids according to\nprevious errors. The validation is conducted by using Amazon's historical spot\nprice trace to perform a set of simulations and comparisons. The result shows\nthat the feedback control-based mechanism obtains a better trade-off between\nbidding rationality and success rate than the other five comparable strategies.\nAlthough this mechanism is only for black-box bidding (price prediction) at\nthis current stage, it can be conveniently and gradually upgraded to take into\naccount external constraints in the future.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 06:26:02 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Li", "Zheng", ""], ["Kihl", "Maria", ""], ["Robertsson", "Anders", ""]]}, {"id": "1708.01397", "submitter": "Zheng Li", "authors": "Zheng Li and William Tarneberg and Maria Kihl and Anders Robertsson", "title": "Using a Predator-Prey Model to Explain Variations of Cloud Spot Price", "comments": "Proceedings of the 6th International Conference on Cloud Computing\n  and Services Science (CLOSER 2016), pp. 51-58, Rome, Italy, April 23-25, 2016", "journal-ref": null, "doi": "10.5220/0005808600510058", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spot pricing scheme has been considered to be resource-efficient for\nproviders and cost-effective for consumers in the Cloud market. Nevertheless,\nunlike the static and straightforward strategies of trading on-demand and\nreserved Cloud services, the market-driven mechanism for trading spot service\nwould be complicated for both implementation and understanding. The largely\ninvisible market activities and their complex interactions could especially\nmake Cloud consumers hesitate to enter the spot market. To reduce the\ncomplexity in understanding the Cloud spot market, we decided to reveal the\nbackend information behind spot price variations. Inspired by the methodology\nof reverse engineering, we developed a Predator-Prey model that can simulate\nthe interactions between demand and resource based on the visible spot price\ntraces. The simulation results have shown some basic regular patterns of market\nactivities with respect to Amazon's spot instance type m3.large. Although the\nfindings of this study need further validation by using practical data, our\nwork essentially suggests a promising approach (i.e.~using a Predator-Prey\nmodel) to investigate spot market activities.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 06:48:07 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Li", "Zheng", ""], ["Tarneberg", "William", ""], ["Kihl", "Maria", ""], ["Robertsson", "Anders", ""]]}, {"id": "1708.01502", "submitter": "Liang Yu", "authors": "Liang Yu, Jin Zhao, Lin Gao", "title": "Predicting potential treatments for complex diseases based on miRNA and\n  tissue specificity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug repositioning, that is finding new uses for existing drugs to treat more\npatients. Cumulative studies demonstrate that the mature miRNAs as well as\ntheir precursors can be targeted by small molecular drugs. At the same time,\nhuman diseases result from the disordered interplay of tissue- and cell\nlineage-specific processes. However, few computational researches predict\ndrug-disease potential relationships based on miRNA data and tissue\nspecificity. Therefore, based on miRNA data and the tissue specificity of\ndiseases, we propose a new method named as miTS to predict the potential\ntreatments for diseases. Firstly, based on miRNAs data, target genes and\ninformation of FDA approved drugs, we evaluate the relationships between miRNAs\nand drugs in the tissue-specific PPI network. Then, we construct a tripartite\nnetwork: drug-miRNA-disease Finally, we obtain the potential drug-disease\nassociations based on the tripartite network. In this paper, we take breast\ncancer as case study and focus on the top-30 predicted drugs. 25 of them\n(83.3%) are found having known connections with breast cancer in CTD benchmark\nand the other 5 drugs are potential drugs for breast cancer. We further\nevaluate the 5 newly predicted drugs from clinical records, literature mining,\nKEGG pathways enrichment analysis and overlapping genes between enriched\npathways. For each of the 5 new drugs, strongly supported evidences can be\nfound in three or more aspects. In particular, Regorafenib has 15 overlapping\nKEGG pathways with breast cancer and their p-values are all very small. In\naddition, whether in the literature curation or clinical validation,\nRegorafenib has a strong correlation with breast cancer. All the facts show\nthat Regorafenib is likely to be a truly effective drug, worthy of our further\nstudy. It further follows that our method miTS is effective and practical for\npredicting new drug indications.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 09:57:54 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Yu", "Liang", ""], ["Zhao", "Jin", ""], ["Gao", "Lin", ""]]}, {"id": "1708.01601", "submitter": "Mojtaba Barzegari", "authors": "Mojtaba Barzegari, Bahman Vahidi, Mohammad Reza Safarinejad", "title": "A Clinical and Finite Elements Study of Stress Urinary Incontinence in\n  Women Using Fluid-Structure Interactions", "comments": null, "journal-ref": null, "doi": "10.1007/s11517-020-02148-2", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress Urinary Incontinence (SUI) or urine leakage from urethra occurs due to\nan increase in abdominal pressure resulting from stress like a cough or jumping\nheight. SUI is more frequent among post-menopausal women. In the absence of\nbladder contraction, vesical pressure exceeds from urethral pressure leading to\nurine leakage. Despite a large number of patients diagnosed with this problem,\nfew studies have investigated its function and mechanics. The main goal of this\nstudy is to model bladder and urethra computationally under an external\npressure like sneezing. Finite Element Method and Fluid-Structure Interactions\nare utilized for simulation. Linear mechanical properties assigned to the\nbladder and urethra and pressure boundary conditions are indispensable in this\nmodel. The results show good accordance between the clinical data and predicted\nvalues of the computational models, such as the pressure at the center of the\nbladder. This indicates that numerical methods and simplified physics of\nbiological systems like inferior urinary tract are helpful to achieve the\nresults similar to clinical results, in order to investigate pathological\nconditions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 17:44:48 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Barzegari", "Mojtaba", ""], ["Vahidi", "Bahman", ""], ["Safarinejad", "Mohammad Reza", ""]]}, {"id": "1708.01608", "submitter": "Mojtaba Barzegari", "authors": "Mojtaba Barzegari, Hossein Bayani, S.M.H. Mirbagheri", "title": "A criterion for bubble merging in liquid metal: computational and\n  experimental study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An innovative model is presented for merging of bubbles inside a liquid\nmetal. The proposed model is based on forming a thin film (narrow channel)\nbetween merging bubbles during growth. Rupturing of the film occurs when an\noscillation in velocity and pressure arises inside the channel followed by\nmerging of the bubbles. The proposed model based on lattice Boltzmann Method is\ncapable of simulating merging bubbles in micro, meso, and macro-scales with no\nlimitation on the number of bubbles. Experimental studies reveal a good\nconsistency between modeling results and real conditions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 17:58:39 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Barzegari", "Mojtaba", ""], ["Bayani", "Hossein", ""], ["Mirbagheri", "S. M. H.", ""]]}, {"id": "1708.01610", "submitter": "Zhenxing Cheng", "authors": "Zhenxing Cheng, Hu Wang", "title": "A novel X-FEM based fast computational method for crack propagation", "comments": "22 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study suggests a fast computational method for crack propagation, which\nis based on the extended finite element method (X-FEM). It is well known that\nthe X-FEM might be the most popular numerical method for crack propagation.\nHowever, with the increase of complexity of the given problem, the size of FE\nmodel and the number of iterative steps are increased correspondingly. To\nimprove the efficiency of X-FEM, an efficient computational method termed\ndecomposed updating reanalysis (DUR) method is suggested. For most of X-FEM\nsimulation procedures, the change of each iterative step is small and it will\nonly lead a local change of stiffness matrix. Therefore, the DUR method is\nproposed to predict the modified response by only calculating the changed part\nof equilibrium equations. Compared with other fast computational methods, the\ndistinctive characteristic of the proposed method is to update the modified\nstiffness matrix with a local updating strategy, which only the changed part of\nstiffness matrix needs to be updated. To verify the performance of the DUR\nmethod, several typical numerical examples have been analyzed and the results\ndemonstrate that this method is a highly efficient method with high accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 05:46:27 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 03:03:06 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Cheng", "Zhenxing", ""], ["Wang", "Hu", ""]]}, {"id": "1708.01613", "submitter": "Mojtaba Barzegari", "authors": "Mojtaba Barzegari, Hossein Bayani, S.M.H. Mirbagheri, Hasan\n  Shetabivash", "title": "Multiphase Aluminum A356 Foam Formation Process Simulation Using Lattice\n  Boltzmann Method", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmrt.2018.03.010", "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shan-Chen model is a numerical scheme to simulate multiphase fluid flows\nusing Lattice Boltzmann approach. The original Shan-Chen model suffers from\ninability to accurately predict behavior of air bubbles interacting in a\nnon-aqueous fluid. In the present study, we extended the Shan-Chen model to\ntake the effect of the attraction-repulsion barriers among bubbles in to\naccount. The proposed model corrects the interaction and coalescence criterion\nof the original Shan-Chen scheme in order to have a more accurate simulation of\nbubbles morphology in a metal foam. The model is based on forming a thin film\n(narrow channel) between merging bubbles during growth. Rupturing of the film\noccurs when an oscillation in velocity and pressure arises inside the channel\nfollowed by merging of the bubbles. Comparing numerical results obtained from\nproposed model with mettallorgraphy images for aluminum A356 demonstrated a\ngood consistency in mean bubble size and bubbles distribution\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 17:39:45 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 22:06:36 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Barzegari", "Mojtaba", ""], ["Bayani", "Hossein", ""], ["Mirbagheri", "S. M. H.", ""], ["Shetabivash", "Hasan", ""]]}, {"id": "1708.01773", "submitter": "Santiago Badia Sb", "authors": "Santiago Badia, Alberto F. Mart\\'in and Javier Principe", "title": "FEMPAR: An object-oriented parallel finite element framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FEMPAR is an open source object oriented Fortran200X scientific software\nlibrary for the high-performance scalable simulation of complex multiphysics\nproblems governed by partial differential equations at large scales, by\nexploiting state-of-the-art supercomputing resources. It is a highly\nmodularized, flexible, and extensible library, that provides a set of modules\nthat can be combined to carry out the different steps of the simulation\npipeline. FEMPAR includes a rich set of algorithms for the discretization step,\nnamely (arbitrary-order) grad, div, and curl-conforming finite element methods,\ndiscontinuous Galerkin methods, B-splines, and unfitted finite element\ntechniques on cut cells, combined with $h$-adaptivity. The linear solver module\nrelies on state-of-the-art bulk-asynchronous implementations of multilevel\ndomain decomposition solvers for the different discretization alternatives and\nblock-preconditioning techniques for multiphysics problems. FEMPAR is a\nframework that provides users with out-of-the-box state-of-the-art\ndiscretization techniques and highly scalable solvers for the simulation of\ncomplex applications, hiding the dramatic complexity of the underlying\nalgorithms. But it is also a framework for researchers that want to experience\nwith new algorithms and solvers, by providing a highly extensible framework. In\nthis work, the first one in a series of articles about FEMPAR, we provide a\ndetailed introduction to the software abstractions used in the discretization\nmodule and the related geometrical module. We also provide some ingredients\nabout the assembly of linear systems arising from finite element\ndiscretizations, but the software design of complex scalable multilevel solvers\nis postponed to a subsequent work.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 14:47:00 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 08:57:48 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 13:15:02 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Badia", "Santiago", ""], ["Mart\u00edn", "Alberto F.", ""], ["Principe", "Javier", ""]]}, {"id": "1708.02409", "submitter": "Zeger Bontinck", "authors": "Zeger Bontinck, Jacopo Corno, Prithvi Bhat, Herbert De Gersem,\n  Sebastian Sch\\\"ops", "title": "Modelling of a Permanent Magnet Synchronous Machine Using Isogeometric\n  Analysis", "comments": "4 pages, 7 figures, 18th International Symposium on Electromagnetic\n  Fields in Mechatronics, Electrical and Electronic Engineering, 14-16\n  September 2017, Lodz, Poland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isogeometric analysis (IGA) is used to simulate a permanent magnet\nsynchronous machine. IGA uses non-uniform rational B-splines to parametrise the\ndomain and to approximate the solution space, thus allowing for the exact\ndescription of the geometries even on the coarsest level of mesh refinement.\nGiven the properties of the isogeometric basis functions, this choice\nguarantees a higher accuracy than the classical finite element method.\n  For dealing with the different stator and rotor topologies, the domain is\nsplit into two non-overlapping parts on which Maxwell's equations are solved\nindependently in the context of a classical Dirichlet-to-Neumann domain\ndecomposition scheme. The results show good agreement with the ones obtained by\nthe classical finite element approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 08:56:00 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Bontinck", "Zeger", ""], ["Corno", "Jacopo", ""], ["Bhat", "Prithvi", ""], ["De Gersem", "Herbert", ""], ["Sch\u00f6ps", "Sebastian", ""]]}, {"id": "1708.02524", "submitter": "Sebastian Roch", "authors": "Sebastien Roch, Kun-Chieh Wang", "title": "Sufficient condition for root reconstruction by parsimony on binary\n  trees with general weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring an ancestral state from observations at\nthe leaves of a tree, assuming the state evolves along the tree according to a\ntwo-state symmetric Markov process. We establish a general branching rate\ncondition under which maximum parsimony, a common reconstruction method\nrequiring only the knowledge of the tree, succeeds better than random guessing\nuniformly in the depth of the tree. We thereby generalize previous results of\n(Zhang et al., 2010) and (Gascuel and Steel, 2010). Our results apply to both\ndeterministic and i.i.d. edge weights.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 15:36:54 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 17:27:50 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Roch", "Sebastien", ""], ["Wang", "Kun-Chieh", ""]]}, {"id": "1708.02941", "submitter": "Daniel Johnson", "authors": "Daniel Johnson, E. A. Huerta, and Roland Haas", "title": "Python Open Source Waveform Extractor (POWER): An open source, Python\n  package to monitor and post-process numerical relativity simulations", "comments": "v2: minor corrections. Accepted to Classical and Quantum Gravity", "journal-ref": "Class. Quantum Grav. 35 027002, 2018", "doi": "10.1088/1361-6382/aa9cad", "report-no": null, "categories": "gr-qc cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical simulations of Einstein's field equations provide unique insights\ninto the physics of compact objects moving at relativistic speeds, and which\nare driven by strong gravitational interactions. Numerical relativity has\nplayed a key role to firmly establish gravitational wave astrophysics as a new\nfield of research, and it is now paving the way to establish whether\ngravitational wave radiation emitted from compact binary mergers is accompanied\nby electromagnetic and astro-particle counterparts. As numerical relativity\ncontinues to blend in with routine gravitational wave data analyses to validate\nthe discovery of gravitational wave events, it is essential to develop open\nsource tools to streamline these studies. Motivated by our own experience as\nusers and developers of the open source, community software, the Einstein\nToolkit, we present an open source, Python package that is ideally suited to\nmonitor and post-process the data products of numerical relativity simulations,\nand compute the gravitational wave strain at future null infinity in high\nperformance environments. We showcase the application of this new package to\npost-process a large numerical relativity catalog and extract higher-order\nwaveform modes from numerical relativity simulations of eccentric binary black\nhole mergers and neutron star mergers. This new software fills a critical void\nin the arsenal of tools provided by the Einstein Toolkit Consortium to the\nnumerical relativity community.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 18:00:00 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 17:52:41 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Johnson", "Daniel", ""], ["Huerta", "E. A.", ""], ["Haas", "Roland", ""]]}, {"id": "1708.03183", "submitter": "Fabio Luporini", "authors": "Fabio Luporini, Michael Lange, Christian T. Jacobs, Gerard J. Gorman,\n  J. Ramanujam, Paul H. J. Kelly", "title": "Automated Tiling of Unstructured Mesh Computations with Application to\n  Seismological Modelling", "comments": "29 pages including supplementary materials and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse tiling is a technique to fuse loops that access common data, thus\nincreasing data locality. Unlike traditional loop fusion or blocking, the loops\nmay have different iteration spaces and access shared datasets through indirect\nmemory accesses, such as A[map[i]] -- hence the name \"sparse\". One notable\nexample of such loops arises in discontinuous-Galerkin finite element methods,\nbecause of the computation of numerical integrals over different domains (e.g.,\ncells, facets). The major challenge with sparse tiling is implementation -- not\nonly is it cumbersome to understand and synthesize, but it is also onerous to\nmaintain and generalize, as it requires a complete rewrite of the bulk of the\nnumerical computation. In this article, we propose an approach to extend the\napplicability of sparse tiling based on raising the level of abstraction.\nThrough a sequence of compiler passes, the mathematical specification of a\nproblem is progressively lowered, and eventually sparse-tiled C for-loops are\ngenerated. Besides automation, we advance the state-of-the-art by introducing:\na revisited, more efficient sparse tiling algorithm; support for\ndistributed-memory parallelism; a range of fine-grained optimizations for\nincreased run-time performance; implementation in a publicly-available library,\nSLOPE; and an in-depth study of the performance impact in Seigen, a real-world\nelastic wave equation solver for seismological problems, which shows speed-ups\nup to 1.28x on a platform consisting of 896 Intel Broadwell cores.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 12:38:48 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 11:47:45 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Luporini", "Fabio", ""], ["Lange", "Michael", ""], ["Jacobs", "Christian T.", ""], ["Gorman", "Gerard J.", ""], ["Ramanujam", "J.", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1708.03519", "submitter": "Frits De Prenter", "authors": "Frits de Prenter, Clemens Verhoosel, Harald van Brummelen", "title": "Preconditioning immersed isogeometric finite element methods with\n  application to flow problems", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering 2019", "doi": "10.1016/j.cma.2019.01.030", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Immersed finite element methods generally suffer from conditioning problems\nwhen cut elements intersect the physical domain only on a small fraction of\ntheir volume. De Prenter et al. [Computer Methods in Applied Mechanics and\nEngineering, 316 (2017) pp. 297-327] present an analysis for symmetric positive\ndefinite (SPD) immersed problems, and for this class of problems an algebraic\npreconditioner is developed. In this contribution the conditioning analysis is\nextended to immersed finite element methods for systems that are not SPD and\nthe preconditioning technique is generalized to a connectivity-based\npreconditioner inspired by Additive-Schwarz preconditioning. This\nConnectivity-based Additive-Schwarz (CbAS) preconditioner is applicable to\nproblems that are not SPD and to mixed problems, such as the Stokes and\nNavier-Stokes equations. A detailed numerical investigation of the effectivity\nof the CbAS preconditioner to a range of flow problems is presented.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 12:29:11 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["de Prenter", "Frits", ""], ["Verhoosel", "Clemens", ""], ["van Brummelen", "Harald", ""]]}, {"id": "1708.03877", "submitter": "Michele Piana", "authors": "M. A. Duval-Poo and M. Piana and A. M. Massone", "title": "Solar hard X-ray imaging by means of Compressed Sensing and Finite\n  Isotropic Wavelet Transform", "comments": null, "journal-ref": "A&A 615, A59 (2018)", "doi": "10.1051/0004-6361/201731765", "report-no": null, "categories": "astro-ph.SR cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that compressed sensing realized by means of regularized\ndeconvolution and the Finite Isotropic Wavelet Transform is effective and\nreliable in hard X-ray solar imaging.\n  The method utilizes the Finite Isotropic Wavelet Transform with Meyer\nfunction as the mother wavelet. Further, compressed sensing is realized by\noptimizing a sparsity-promoting regularized objective function by means of the\nFast Iterative Shrinkage-Thresholding Algorithm. Eventually, the regularization\nparameter is selected by means of the Miller criterion.\n  The method is applied against both synthetic data mimicking the\nSpectrometer/Telescope Imaging X-rays (STIX) measurements and experimental\nobservations provided by the Reuven Ramaty High Energy Solar Spectroscopic\nImager (RHESSI). The performances of the method are compared with the results\nprovided by standard visibility-based reconstruction methods.\n  The results show that the application of the sparsity constraint and the use\nof a continuous, isotropic framework for the wavelet transform provide a\nnotable spatial accuracy and significantly reduce the ringing effects due to\nthe instrument point spread functions.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 08:53:46 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Duval-Poo", "M. A.", ""], ["Piana", "M.", ""], ["Massone", "A. M.", ""]]}, {"id": "1708.04138", "submitter": "Petr Vabishchevich N.", "authors": "Alexander G. Churbanov and Oleg Iliev and Valery F. Strizhov and Petr\n  N. Vabishchevich", "title": "Numerical simulation of oxidation processes in a cross-flow around tube\n  bundles", "comments": "33 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An oxidation process is simulated for a bundle of metal tubes in a\ncross-flow. A fluid flow is governed by the incompressible Navier-Stokes\nequations. To describe the transport of oxygen, the corresponding\nconvection-diffusion equation is applied. The key point of the model is related\nto the description of oxidation processes taking into account the growth of a\nthin oxide film in the quasi-stationary approximation. Mathematical modeling of\noxidant transport in a tube bundle is carried out in the 2D approximation. The\nnumerical algorithm employed in the work is based on the finite-element\ndiscretization in space and the fully implicit discretization in time. The tube\nrows of a bundle can be either in-line or staggered in the direction of the\nfluid flow velocity. The growth of the oxide film on tube walls is predicted\nfor various bundle structures using the developed oxidation model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 15:04:05 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Churbanov", "Alexander G.", ""], ["Iliev", "Oleg", ""], ["Strizhov", "Valery F.", ""], ["Vabishchevich", "Petr N.", ""]]}, {"id": "1708.04157", "submitter": "Marco van Hulten PhD", "authors": "Marco van Hulten and Jean-Claude Dutay and Matthieu Roy-Barman", "title": "A global scavenging and circulation ocean model of thorium-230 and\n  protactinium-231 with realistic particle dynamics (NEMO-ProThorP 0.1)", "comments": "submitted to Geoscientific Model Development", "journal-ref": "Geoscientific Model Development, 11, 3537-3556, 2018", "doi": "10.5194/gmd-11-3537-2018", "report-no": null, "categories": "physics.ao-ph cs.CE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we set forth a 3-D ocean model of the radioactive trace\nisotopes Th-230 and Pa-231. The interest arises from the fact that these\nisotopes are extensively used for investigating particle transport in the ocean\nand reconstructing past ocean circulation. The tracers are reversibly scavenged\nby biogenic and lithogenic particles.\n  Our simulations of Th-230 and Pa-231 are based on the NEMO-PISCES ocean\nbiogeochemistry general circulation model, which includes biogenic particles,\nnamely small and big particulate organic carbon, calcium carbonate and biogenic\nsilica. Small and big lithogenic particles from dust deposition are included in\nour model as well. Their distributions generally compare well with the small\nand big lithogenic particle concentrations from recent observations from the\nGEOTRACES programme, except for boundary nepheloid layers for which, as up to\ntoday, there are no non-trivial, prognostic models available on a global scale.\nOur simulations reproduce Th-230 and Pa-231 dissolved concentrations: they\ncompare well with recent GEOTRACES observations in many parts of the ocean.\nParticulate Th-230 and Pa-231 concentrations are significantly improved\ncompared to previous studies, but they are still too low because of missing\nparticles from nepheloid layers. Our simulation reproduces the main\ncharacteristics of the Pa-231/Th-230 ratio observed in the sediments, and\nsupports a moderate affinity of Pa-231 to biogenic silica as suggested by\nrecent observations, relative to Th-230.\n  Future model development may further improve understanding, especially when\nthis will include a more complete representation of all particles, including\ndifferent size classes, manganese hydroxides and nepheloid layers. This can be\ndone based on our model, as its source code is readily available.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 14:49:38 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 13:15:34 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["van Hulten", "Marco", ""], ["Dutay", "Jean-Claude", ""], ["Roy-Barman", "Matthieu", ""]]}, {"id": "1708.04173", "submitter": "Amir Hossein Delgoshaie", "authors": "Amir H. Delgoshaie, Patrick Jenny, Hamdi A. Tchelepi", "title": "Temporal Markov Processes for Transport in Porous Media: Random Lattice\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1029/2018WR022735", "report-no": null, "categories": "physics.comp-ph cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo (MC) simulations of transport in random porous networks indicate\nthat for high variances of the log-normal permeability distribution, the\ntransport of a passive tracer is non-Fickian. Here we model this non-Fickian\ndispersion in random porous networks using discrete temporal Markov models. We\nshow that such temporal models capture the spreading behavior accurately. This\nis true despite the fact that the slow velocities are strongly correlated in\ntime, and some studies have suggested that the persistence of low velocities\nwould render the temporal Markovian model inapplicable. Compared to previously\nproposed temporal stochastic differential equations with case specific drift\nand diffusion terms, the models presented here require fewer modeling\nassumptions. Moreover, we show that discrete temporal Markov models can be used\nto represent dispersion in unstructured networks, which are widely used to\nmodel porous media. A new method is proposed to extend the state space of\ntemporal Markov models to improve the model predictions in the presence of\nextremely low velocities in particle trajectories and extend the applicability\nof the model to higher temporal resolutions. Finally, it is shown that by\ncombining multiple transitions, temporal models are more efficient for\ncomputing particle evolution compared to correlated CTRW with spatial\nincrements that are equal to the lengths of the links in the network.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 00:02:06 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 01:28:25 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Delgoshaie", "Amir H.", ""], ["Jenny", "Patrick", ""], ["Tchelepi", "Hamdi A.", ""]]}, {"id": "1708.04524", "submitter": "Milan Jain", "authors": "Milan Jain", "title": "ThermalSim: A Thermal Simulator for Error Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have extensively explored predictive control strategies for\ncontrolling heating, ventilation, and air conditioning (HVAC) units in\ncommercial buildings. Predictive control strategies, however, critically rely\non weather and occupancy forecasts. Existing state-of-the-art building\nsimulators are incapable of analysing the influence of prediction errors (in\nweather and occupancy) on HVAC energy consumption and occupant comfort. In this\npaper, we introduce ThermalSim, a building simulator that can quantify the\neffect of prediction errors on the HVAC operations. ThermalSim has been\nimplemented in C/C++ and MATLAB. We describe its design, use, and input format.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 15:29:46 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Jain", "Milan", ""]]}, {"id": "1708.04682", "submitter": "Eric Mason", "authors": "Bariscan Yonel, Eric Mason, Birsen Yaz{\\i}c{\\i}", "title": "Deep Learning for Passive Synthetic Aperture Radar", "comments": "Submitted to IEEE Journal of Selected Topics in Signal Processing", "journal-ref": null, "doi": "10.1109/JSTSP.2017.2784181", "report-no": null, "categories": "cs.CV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep learning (DL) framework for inverse problems in imaging,\nand demonstrate the advantages and applicability of this approach in passive\nsynthetic aperture radar (SAR) image reconstruction. We interpret image recon-\nstruction as a machine learning task and utilize deep networks as forward and\ninverse solvers for imaging. Specifically, we design a recurrent neural network\n(RNN) architecture as an inverse solver based on the iterations of proximal\ngradient descent optimization methods. We further adapt the RNN architecture to\nimage reconstruction problems by transforming the network into a recurrent\nauto-encoder, thereby allowing for unsupervised training. Our DL based inverse\nsolver is particularly suitable for a class of image formation problems in\nwhich the forward model is only partially known. The ability to learn forward\nmodels and hyper parameters combined with unsupervised training approach\nestablish our recurrent auto-encoder suitable for real world applications. We\ndemonstrate the performance of our method in passive SAR image reconstruction.\nIn this regime a source of opportunity, with unknown location and transmitted\nwaveform, is used to illuminate a scene of interest. We investigate recurrent\nauto- encoder architecture based on the 1 and 0 constrained least- squares\nproblem. We present a projected stochastic gradient descent based training\nscheme which incorporates constraints of the unknown model parameters. We\ndemonstrate through extensive numerical simulations that our DL based approach\nout performs conventional sparse coding methods in terms of computation and\nreconstructed image quality, specifically, when no information about the\ntransmitter is available.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 00:25:10 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Yonel", "Bariscan", ""], ["Mason", "Eric", ""], ["Yaz\u0131c\u0131", "Birsen", ""]]}, {"id": "1708.05201", "submitter": "Shahar Tsiper Mr.", "authors": "Deborah Cohen, Shahar Tsiper and Yonina C. Eldar", "title": "Analog to Digital Cognitive Radio: Sampling, Detection and Hardware", "comments": "Submitted to IEEE Signal Processing Magazine", "journal-ref": null, "doi": "10.1109/MSP.2017.2740966", "report-no": null, "categories": "cs.CE cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of wireless communications has recently created a\nbottleneck in terms of spectrum availability. Motivated by the observation that\nthe root of the spectrum scarcity is not a lack of resources but an inefficient\nmanaging that can be solved, dynamic opportunistic exploitation of spectral\nbands has been considered, under the name of Cognitive Radio (CR). This\ntechnology allows secondary users to access currently idle spectral bands by\ndetecting and tracking the spectrum occupancy. The CR application revisits this\ntraditional task with specific and severe requirements in terms of spectrum\nsensing and detection performance, real-time processing, robustness to noise\nand more. Unfortunately, conventional methods do not satisfy these demands for\ntypical signals, that often have very high Nyquist rates.\n  Recently, several sampling methods have been proposed that exploit signals' a\npriori known structure to sample them below the Nyquist rate. Here, we review\nsome of these techniques and tie them to the task of spectrum sensing in the\ncontext of CR. We then show how issues related to spectrum sensing can be\ntackled in the sub-Nyquist regime. First, to cope with low signal to noise\nratios, we propose to recover second-order statistics from the low rate\nsamples, rather than the signal itself. In particular, we consider\ncyclostationary based detection, and investigate CR networks that perform\ncollaborative spectrum sensing to overcome channel effects. To enhance the\nefficiency of the available spectral bands detection, we present joint spectrum\nsensing and direction of arrival estimation methods. Throughout this work, we\nhighlight the relation between theoretical algorithms and their practical\nimplementation. We show hardware simulations performed on a prototype we built,\ndemonstrating the feasibility of sub-Nyquist spectrum sensing in the context of\nCR.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 11:05:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Cohen", "Deborah", ""], ["Tsiper", "Shahar", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1708.05350", "submitter": "Huan Liu", "authors": "Huan Liu, Haobin Dong, Zheng Liu, Jian Ge, Bingjie Bai and Cheng Zhang", "title": "Application of Hilbert-Huang decomposition to reduce noise and\n  characterize for NMR FID signal of proton precession magnetometer", "comments": "14 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parameters in a nuclear magnetic resonance (NMR) free induction decay\n(FID) signal contain information that is useful in magnetic field measurement,\nmagnetic resonance sounding (MRS) and other related applications. A real time\nsampled FID signal is well modeled as a finite mixture of exponential sequences\nplus noise. We propose to use the Hilbert-Huang Transform (HHT) for noise\nreduction and characterization, where the generalized Hilbert-Huang represents\na way to decompose a signal into so-called intrinsic mode function (IMF) along\nwith a trend, and obtain instantaneous frequency data. Moreover, the HHT for an\nFID signal's feature analysis is applied for the first time. First, acquiring\nthe actual untuned FID signal by a developed prototype of proton magnetometer,\nand then the empirical mode decomposition (EMD) is performed to decompose the\nnoise and original FID. Finally, the HHT is applied to the obtained IMFs to\nextract the Hilbert energy spectrum, to indicate the energy distribution of the\nsignal on the frequency axis. By theory analysis and the testing of an actual\nFID signal, the results show that, compared with general noise reduction\nmethods such as auto correlation and singular value decomposition (SVD),\ncombined with the proposed method can further suppress the interfered signals\neffectively, and can obtain different components of FID signal, which can use\nto identify the magnetic anomaly, the existence of groundwater etc. This is a\nvery important property since it can be exploited to separate the FID signal\nfrom noise and to estimate exponential sequence parameters of FID signal.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 22:57:25 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Liu", "Huan", ""], ["Dong", "Haobin", ""], ["Liu", "Zheng", ""], ["Ge", "Jian", ""], ["Bai", "Bingjie", ""], ["Zhang", "Cheng", ""]]}, {"id": "1708.05711", "submitter": "Jan Egger", "authors": "Jan Egger, J\\\"urgen Wallner, Markus Gall, Xiaojun Chen, Katja\n  Schwenzer-Zimmerer, Knut Reinbacher, Dieter Schmalstieg", "title": "Computer-aided position planning of miniplates to treat facial bone\n  defects", "comments": "19 pages, 13 Figures, 2 Tables", "journal-ref": "PLoS ONE 12(8): e0182839 (2017)", "doi": "10.1371/journal.pone.0182839", "report-no": null, "categories": "cs.CV cs.CE cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, a software system for computer-aided position planning\nof miniplates to treat facial bone defects is proposed. The intra-operatively\nused bone plates have to be passively adapted on the underlying bone contours\nfor adequate bone fragment stabilization. However, this procedure can lead to\nfrequent intra-operatively performed material readjustments especially in\ncomplex surgical cases. Our approach is able to fit a selection of common\nimplant models on the surgeon's desired position in a 3D computer model. This\nhappens with respect to the surrounding anatomical structures, always including\nthe possibility of adjusting both the direction and the position of the used\nosteosynthesis material. By using the proposed software, surgeons are able to\npre-plan the out coming implant in its form and morphology with the aid of a\ncomputer-visualized model within a few minutes. Further, the resulting model\ncan be stored in STL file format, the commonly used format for 3D printing.\nUsing this technology, surgeons are able to print the virtual generated\nimplant, or create an individually designed bending tool. This method leads to\nadapted osteosynthesis materials according to the surrounding anatomy and\nrequires further a minimum amount of money and time.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 18:37:02 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Egger", "Jan", ""], ["Wallner", "J\u00fcrgen", ""], ["Gall", "Markus", ""], ["Chen", "Xiaojun", ""], ["Schwenzer-Zimmerer", "Katja", ""], ["Reinbacher", "Knut", ""], ["Schmalstieg", "Dieter", ""]]}, {"id": "1708.06160", "submitter": "Amir Ahmadi Javid", "authors": "Amir Ahmadi-Javid and Mohsen Ebadi", "title": "Economic Design of Memory-Type Control Charts: The Fallacy of the\n  Formula Proposed by Lorenzen and Vance (1986)", "comments": "Computational Statistics, 2020", "journal-ref": "Ahmadi-Javid, A., & Ebadi, M. (2020). Economic design of\n  memory-type control charts: The fallacy of the formula proposed by Lorenzen\n  and Vance (1986). Computational Statistics, DOI: 10.1007/s00180-020-01019-6", "doi": "10.1007/s00180-020-01019-6", "report-no": null, "categories": "stat.AP cs.CE econ.GN math.OC q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The memory-type control charts, such as EWMA and CUSUM, are powerful tools\nfor detecting small quality changes in univariate and multivariate processes.\nMany papers on economic design of these control charts use the formula proposed\nby Lorenzen and Vance (1986) [Lorenzen, T. J., & Vance, L. C. (1986). The\neconomic design of control charts: A unified approach. Technometrics, 28(1),\n3-10, DOI: 10.2307/1269598]. This paper shows that this formula is not correct\nfor memory-type control charts and its values can significantly deviate from\nthe original values even if the ARL values used in this formula are accurately\ncomputed. Consequently, the use of this formula can result in charts that are\nnot economically optimal. The formula is corrected for memory-type control\ncharts, but unfortunately the modified formula is not a helpful tool from a\ncomputational perspective. We show that simulation-based optimization is a\npossible alternative method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 11:38:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ahmadi-Javid", "Amir", ""], ["Ebadi", "Mohsen", ""]]}, {"id": "1708.06216", "submitter": "Edward G. Nikonov", "authors": "Eduard G. Nikonov, Miron Pavlu\\v{s}, and M\\'aria Popovi\\v{c}ov\\'a", "title": "Molecular dynamic simulation of water vapor interaction with blind pore\n  of dead-end and saccate type", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cond-mat.soft cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the varieties of pores, often found in natural or artificial building\nmaterials, are the so-called blind pores of dead-end or saccate type.\nThree-dimensional model of such kind of pore has been developed in this work.\nThis model has been used for simulation of water vapor interaction with\nindividual pore by molecular dynamics in combination with the diffusion\nequation method. Special investigations have been done to find dependencies\nbetween thermostats implementations and conservation of thermodynamic and\nstatistical values of water vapor - pore system. The two types of evolution of\nwater-pore system have been investigated: drying and wetting of the pore. Full\nresearch of diffusion coefficient, diffusion velocity and other diffusion\nparameters has been made.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 08:29:18 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Nikonov", "Eduard G.", ""], ["Pavlu\u0161", "Miron", ""], ["Popovi\u010dov\u00e1", "M\u00e1ria", ""]]}, {"id": "1708.06586", "submitter": "Tomaso Aste", "authors": "Noemi Nava and T. Di Matteo and Tomaso Aste", "title": "Dynamic correlations at different time-scales with Empirical Mode\n  Decomposition", "comments": "19 pages, 11 figures", "journal-ref": null, "doi": "10.1016/j.physa.2018.02.108", "report-no": null, "categories": "cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Empirical Mode Decomposition (EMD) provides a tool to characterize time\nseries in terms of its implicit components oscillating at different\ntime-scales. We apply this decomposition to intraday time series of the\nfollowing three financial indices: the S\\&P 500 (USA), the IPC (Mexico) and the\nVIX (volatility index USA), obtaining time-varying multidimensional\ncross-correlations at different time-scales. The correlations computed over a\nrolling window are compared across the three indices, across the components at\ndifferent time-scales, at different lags and over time. We uncover a rich\nheterogeneity of interactions which depends on the time-scale and has important\nled-lag relations which can have practical use for portfolio management, risk\nestimation and investments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 12:48:12 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Nava", "Noemi", ""], ["Di Matteo", "T.", ""], ["Aste", "Tomaso", ""]]}, {"id": "1708.06912", "submitter": "Rasmus Dalgas Kongskov", "authors": "Rasmus Dalgas Kongskov and Yiqiu Dong", "title": "Tomographic Reconstruction Methods for Decomposing Directional\n  Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposition of tomographic reconstructions has many different practical\napplication. We propose two new reconstruction methods that combines the task\nof tomographic reconstruction with object decomposition. We demonstrate these\nreconstruction methods in the context of decomposing directional objects into\nvarious directional components. Furthermore we propose a method for estimating\nthe main direction in a directional object, directly from the measured computed\ntomography data. We demonstrate all the proposed methods on simulated and real\nsamples to show their practical applicability. The numerical tests show that\ndecomposition and reconstruction can combined to achieve a highly useful\nfibre-crack decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 08:08:47 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Kongskov", "Rasmus Dalgas", ""], ["Dong", "Yiqiu", ""]]}, {"id": "1708.06987", "submitter": "Arion Pons", "authors": "Arion Pons and Stefanie Gutschmidt", "title": "Multiparameter spectral analysis for aeroelastic instability problems", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": "10.1115/1.4039671", "report-no": null, "categories": "cs.SY cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel application of multiparameter spectral theory to\nthe study of structural stability, with particular emphasis on aeroelastic\nflutter. Methods of multiparameter analysis allow the development of new\nsolution algorithms for aeroelastic flutter problems; most significantly, a\ndirect solver for polynomial problems of arbitrary order and size, something\nwhich has not before been achieved. Two major variants of this direct solver\nare presented, and their computational characteristics are compared. Both are\neffective for smaller problems arising in reduced-order modelling and\npreliminary design optimization. Extensions and improvements to this new\nconceptual framework and solution method are then discussed.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 21:38:12 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Pons", "Arion", ""], ["Gutschmidt", "Stefanie", ""]]}, {"id": "1708.07040", "submitter": "Sayan Nag", "authors": "Sayan Nag", "title": "Adaptive Plant Propagation Algorithm for Solving Economic Load Dispatch\n  Problem", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization problems in design engineering are complex by nature, often\nbecause of the involvement of critical objective functions accompanied by a\nnumber of rigid constraints associated with the products involved. One such\nproblem is Economic Load Dispatch (ED) problem which focuses on the\noptimization of the fuel cost while satisfying some system constraints.\nClassical optimization algorithms are not sufficient and also inefficient for\nthe ED problem involving highly nonlinear, and non-convex functions both in the\nobjective and in the constraints. This led to the development of metaheuristic\noptimization approaches which can solve the ED problem almost efficiently. This\npaper presents a novel robust plant intelligence based Adaptive Plant\nPropagation Algorithm (APPA) which is used to solve the classical ED problem.\nThe application of the proposed method to the 3-generator and 6-generator\nsystems shows the efficiency and robustness of the proposed algorithm. A\ncomparative study with another state-of-the-art algorithm (APSO) demonstrates\nthe quality of the solution achieved by the proposed method along with the\nconvergence characteristics of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:09:36 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Nag", "Sayan", ""]]}, {"id": "1708.07061", "submitter": "Jesus Lago", "authors": "Jesus Lago, Fjo De Ridder, Peter Vrancx, Bart De Schutter", "title": "Forecasting day-ahead electricity prices in Europe: the importance of\n  considering market integration", "comments": null, "journal-ref": "Applied Energy, Volume 211, 1 February 2018, Pages 890-903", "doi": "10.1016/j.apenergy.2017.11.098", "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.NE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the increasing integration among electricity markets, in this\npaper we propose two different methods to incorporate market integration in\nelectricity price forecasting and to improve the predictive performance. First,\nwe propose a deep neural network that considers features from connected markets\nto improve the predictive accuracy in a local market. To measure the importance\nof these features, we propose a novel feature selection algorithm that, by\nusing Bayesian optimization and functional analysis of variance, evaluates the\neffect of the features on the algorithm performance. In addition, using market\nintegration, we propose a second model that, by simultaneously predicting\nprices from two markets, improves the forecasting accuracy even further. As a\ncase study, we consider the electricity market in Belgium and the improvements\nin forecasting accuracy when using various French electricity features. We show\nthat the two proposed models lead to improvements that are statistically\nsignificant. Particularly, due to market integration, the predictive accuracy\nis improved from 15.7% to 12.5% sMAPE (symmetric mean absolute percentage\nerror). In addition, we show that the proposed feature selection algorithm is\nable to perform a correct assessment, i.e. to discard the irrelevant features.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 15:34:48 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 17:12:16 GMT"}, {"version": "v3", "created": "Thu, 7 Dec 2017 15:34:43 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Lago", "Jesus", ""], ["De Ridder", "Fjo", ""], ["Vrancx", "Peter", ""], ["De Schutter", "Bart", ""]]}, {"id": "1708.07364", "submitter": "Ming Li Dr.", "authors": "Dengyang Zhao, Ming Li, Yusheng Liu", "title": "Self-supporting Topology Optimization for Additive Manufacturing", "comments": "submitted out", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a topology optimization approach that designs an optimal\nstructure, called a self-supporting structure, which is ready to be fabricated\nvia additive manufacturing without the usage of additional support structures.\nSuch supports in general have to be created during the fabricating process so\nthat the primary object can be manufactured layer by layer without collapse,\nwhich is very time-consuming and waste of material.\n  The proposed approach resolves this problem by formulating the\nself-supporting requirements as a novel explicit quadratic continuous\nconstraint in the topology optimization problem, or specifically, requiring the\nnumber of unsupported elements (in terms of the sum of squares of their\ndensities) to be zero. Benefiting form such novel formulations, computing\nsensitivity of the self-supporting constraint with respect to the design\ndensity is straightforward, which otherwise would require lots of research\nefforts in general topology optimization studies. The derived sensitivity for\neach element is only linearly dependent on its sole density, which, different\nfrom previous layer-based sensitivities, consequently allows for a parallel\nimplementation and possible higher convergence rate. In addition, a discrete\nconvolution operator is also designed to detect the unsupported elements as\ninvolved in each step of optimization iteration, and improves the detection\nprocess 100 times as compared with simply enumerating these elements. The\napproach works for cases of general overhang angle, or general domain, and\nproduces an optimized structures, and their associated optimal compliance, very\nclose to that of the reference structure obtained without considering the\nself-supporting constraint, as demonstrated by extensive 2D and 3D benchmark\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 11:55:15 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Zhao", "Dengyang", ""], ["Li", "Ming", ""], ["Liu", "Yusheng", ""]]}, {"id": "1708.07567", "submitter": "Michael McCourt", "authors": "Kevin Tee, Michael McCourt, Ruben Martinez-Cantin, Ian Dewancker,\n  Frank Liu", "title": "Active Preference Learning for Personalized Portfolio Construction", "comments": "4 pages, 2 figures, 1 algorithm, ICML Human in the Loop workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In financial asset management, choosing a portfolio requires balancing\nreturns, risk, exposure, liquidity, volatility and other factors. These\nconcerns are difficult to compare explicitly, with many asset managers using an\nintuitive or implicit sense of their interaction. We propose a mechanism for\nlearning someone's sense of distinctness between portfolios with the goal of\nbeing able to identify portfolios which are predicted to perform well but are\ndistinct from the perspective of the user. This identification occurs, e.g., in\nthe context of Bayesian optimization of a backtested performance metric.\nNumerical experiments are presented which show the impact of personal beliefs\nin informing the development of a diverse and high-performing portfolio.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 22:21:29 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Tee", "Kevin", ""], ["McCourt", "Michael", ""], ["Martinez-Cantin", "Ruben", ""], ["Dewancker", "Ian", ""], ["Liu", "Frank", ""]]}, {"id": "1708.08098", "submitter": "Zhen Chen", "authors": "Zhen Chen, Ren-qian Zhang", "title": "Capital flow constrained lot sizing problem with loss of goodwill and\n  loan", "comments": null, "journal-ref": "Intl. Trans. in Op. Res. 2019", "doi": "10.1111/itor.12675", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce capital flow constraints, loss of good will and loan to the lot\nsizing problem. Capital flow constraint is different from traditional capacity\nconstraints: when a manufacturer launches production, its present capital\nshould not be less than its present total production cost; otherwise, it must\ndecrease production quantity or suspend production. Unsatisfied demand in one\nperiod may cause customer's demand to shrink in the next period considering\nloss of goodwill. Fixed loan can be adopted in the starting period for\nproduction. A mixed integer model for a deterministic single-item problem is\nconstructed. Based on the analysis about the structure of optimal solutions, we\napproximate it to a traveling salesman problem, and divide it into sub-linear\nprogramming problems without integer variables. A forward recursive algorithm\nwith heuristic adjustments is proposed to solve it. When unit variable\nproduction costs are equal and goodwill loss rate is zero, the algorithm can\nobtain optimal solutions. Under other situations, numerical comparisons with\nCPLEX 12.6.2 show our algorithm can reach optimal in most cases and has\ncomputation time advantage for large-size problems. Numerical tests also\ndemonstrate that initial capital availability as well as loan interest rate can\nsubstantially affect the manufacturer's optimal lot sizing decisions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 16:11:35 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chen", "Zhen", ""], ["Zhang", "Ren-qian", ""]]}, {"id": "1708.08551", "submitter": "Mohammad Amin Nabian", "authors": "Mohammad Amin Nabian, Hadi Meidani", "title": "Deep Learning for Accelerated Reliability Analysis of Infrastructure\n  Networks", "comments": null, "journal-ref": "Nabian, M. A. and Meidani, H. (2018), Deep Learning for\n  Accelerated Seismic Reliability Analysis of Transportation Networks. Computer\n  Aided Civil and Infrastructure Engineering, 33: 443-458", "doi": "10.1111/mice.12359", "report-no": null, "categories": "cs.CE cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural disasters can have catastrophic impacts on the functionality of\ninfrastructure systems and cause severe physical and socio-economic losses.\nGiven budget constraints, it is crucial to optimize decisions regarding\nmitigation, preparedness, response, and recovery practices for these systems.\nThis requires accurate and efficient means to evaluate the infrastructure\nsystem reliability. While numerous research efforts have addressed and\nquantified the impact of natural disasters on infrastructure systems, typically\nusing the Monte Carlo approach, they still suffer from high computational cost\nand, thus, are of limited applicability to large systems. This paper presents a\ndeep learning framework for accelerating infrastructure system reliability\nanalysis. In particular, two distinct deep neural network surrogates are\nconstructed and studied: (1) A classifier surrogate which speeds up the\nconnectivity determination of networks, and (2) An end-to-end surrogate that\nreplaces a number of components such as roadway status realization,\nconnectivity determination, and connectivity averaging. The proposed approach\nis applied to a simulation-based study of the two-terminal connectivity of a\nCalifornia transportation network subject to extreme probabilistic earthquake\nevents. Numerical results highlight the effectiveness of the proposed approach\nin accelerating the transportation system two-terminal reliability analysis\nwith extremely high prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 22:41:11 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Nabian", "Mohammad Amin", ""], ["Meidani", "Hadi", ""]]}, {"id": "1708.08741", "submitter": "Dominik Bartuschat", "authors": "Dominik Bartuschat and Ulrich R\\\"ude", "title": "A Scalable Multiphysics Algorithm for Massively Parallel Direct\n  Numerical Simulations of Electrophoresis", "comments": "Accepted manuscript of publication in Journal of Computational\n  Science (Elsevier)", "journal-ref": null, "doi": "10.1016/j.jocs.2018.05.011", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we introduce a novel coupled algorithm for massively parallel\ndirect numerical simulations of electrophoresis in microfluidic flows. This\nmultiphysics algorithm employs an Eulerian description of fluid and ions,\ncombined with a Lagrangian representation of moving charged particles. The\nfixed grid facilitates efficient solvers and the employed lattice Boltzmann\nmethod can efficiently handle complex geometries. Validation experiments with\nmore than $70\\,000$ time steps are presented, together with scaling experiments\nwith over ${4\\cdot10^{6}}$ particles and ${1.96\\cdot10^{11}}$ grid cells for\nboth hydrodynamics and electric potential. We achieve excellent performance and\nscaling on up to $65\\,536$ cores of a current supercomputer.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 13:41:38 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 18:49:36 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Bartuschat", "Dominik", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "1708.08857", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen, Alberto Bemporad", "title": "Stock Trading via Feedback Control: Stochastic Model Predictive or\n  Genetic?", "comments": "7 pages, 3 figures, 3 tables, presented as a poster at XVIII Workshop\n  on Quantitative Finance (QFW2017) in Milano on January 25-27, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek a discussion about the most suitable feedback control structure for\nstock trading under the consideration of proportional transaction costs.\nSuitability refers to robustness and performance capability. Both are tested by\nconsidering different one-step ahead prediction qualities, including the ideal\ncase, correct prediction of the direction of change in daily stock prices and\nthe worst-case. Feedback control structures are partitioned into two general\nclasses: stochastic model predictive control (SMPC) and genetic. For the former\nclass three controllers are discussed, whereby it is distinguished between two\nMarkowitz- and one dynamic hedging-inspired SMPC formulation. For the latter\nclass five trading algorithms are disucssed, whereby it is distinguished\nbetween two different moving average (MA) based, two trading range (TR) based,\nand one strategy based on historical optimal (HistOpt) trajectories. This paper\nalso gives a preliminary discussion about how modified dynamic hedging-inspired\nSMPC formulations may serve as alternatives to Markowitz portfolio\noptimization. The combinations of all of the eight controllers with five\ndifferent one-step ahead prediction methods are backtested for daily trading of\nthe 30 components of the German stock market index DAX for the time period\nbetween November 27, 2015 and November 25, 2016.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 16:11:09 GMT"}, {"version": "v2", "created": "Wed, 4 Oct 2017 06:22:33 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Plessen", "Mogens Graf", ""], ["Bemporad", "Alberto", ""]]}]