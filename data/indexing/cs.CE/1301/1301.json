[{"id": "1301.0039", "submitter": "EPTCS", "authors": "Adrien Champion (Onera / Rockwell Collins France), R\\'emi Delmas\n  (Onera), Michael Dierkes (Rockwell Collins France)", "title": "Generating Property-Directed Potential Invariants By Backward Analysis", "comments": "In Proceedings FTSCS 2012, arXiv:1212.6574", "journal-ref": "EPTCS 105, 2012, pp. 22-38", "doi": "10.4204/EPTCS.105.3", "report-no": null, "categories": "cs.LO cs.CE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the issue of lemma generation in a k-induction-based\nformal analysis of transition systems, in the linear real/integer arithmetic\nfragment. A backward analysis, powered by quantifier elimination, is used to\noutput preimages of the negation of the proof objective, viewed as unauthorized\nstates, or gray states. Two heuristics are proposed to take advantage of this\nsource of information. First, a thorough exploration of the possible\npartitionings of the gray state space discovers new relations between state\nvariables, representing potential invariants. Second, an inexact exploration\nregroups and over-approximates disjoint areas of the gray state space, also to\ndiscover new relations between state variables. k-induction is used to isolate\nthe invariants and check if they strengthen the proof objective. These\nheuristics can be used on the first preimage of the backward exploration, and\neach time a new one is output, refining the information on the gray states. In\nour context of critical avionics embedded systems, we show that our approach is\nable to outperform other academic or commercial tools on examples of interest\nin our application field. The method is introduced and motivated through two\nmain examples, one of which was provided by Rockwell Collins, in a\ncollaborative formal verification framework.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 01:54:21 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Champion", "Adrien", "", "Onera / Rockwell Collins France"], ["Delmas", "R\u00e9mi", "", "Onera"], ["Dierkes", "Michael", "", "Rockwell Collins France"]]}, {"id": "1301.0173", "submitter": "Doreswamy", "authors": "Doreswamy", "title": "Knowledge Discovery System For Fiber Reinforced Polymer Matrix Composite\n  Laminate", "comments": "International Journal of Computing, Vol. 2, Issue 7, pp. 121-130,\n  July 2010. (ISSN 2151-9617)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper Knowledge Discovery System (KDS) is proposed and implemented\nfor the extraction of knowledge-mean stiffness of a polymer composite material\nin which when fibers are placed at different orientations. Cosine amplitude\nmethod is implemented for retrieving compatible polymer matrix and\nreinforcement fiber which is coming under predicted fiber class, from the\npolymer and reinforcement database respectively, based on the design\nrequirements. Fuzzy classification rules to classify fibers into short, medium\nand long fiber classes are derived based on the fiber length and the computed\nor derive critical length of fiber. Longitudinal and Transverse module of\nPolymer Matrix Composite consisting of seven layers with different fiber volume\nfractions and different fibers orientations at 0,15,30,45,60,75 and 90 degrees\nare analyzed through Rule-of Mixture material design model. The analysis\nresults are represented in different graphical steps and have been measured\nwith statistical parameters. This data mining application implemented here has\nfocused the mechanical problems of material design and analysis. Therefore,\nthis system is an expert decision support system for optimizing the materials\nperformance for designing light-weight and strong, and cost effective polymer\ncomposite materials.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 06:47:45 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Doreswamy", "", ""]]}, {"id": "1301.0176", "submitter": "Doreswamy", "authors": "Doreswamy, M.N.Vanajakshi", "title": "Similarity Measuring Approuch for Engineering Materials Selection", "comments": "International Journal of Computational Intelligence Systems (IJCIS),\n  Vol.3, Issue 1, April 2010, pp.115-122. (ISSN: 1875-6883)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced engineering materials design involves the exploration of massive\nmultidimensional feature spaces, the correlation of materials properties and\nthe processing parameters derived from disparate sources. The search for\nalternative materials or processing property strategies, whether through\nanalytical, experimental or simulation approaches, has been a slow and arduous\ntask, punctuated by infrequent and often expected discoveries. A few systematic\nefforts have been made to analyze the trends in data as a basis for\nclassifications and predictions. This is particularly due to the lack of large\namounts of organized data and more importantly the challenging of shifting\nthrough them in a timely and efficient manner. The application of recent\nadvances in Data Mining on materials informatics is the state of art of\ncomputational and experimental approaches for materials discovery. In this\npaper similarity based engineering materials selection model is proposed and\nimplemented to select engineering materials based on the composite materials\nconstraints. The result reviewed from this model is sustainable for effective\ndecision making in advanced engineering materials design applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 07:07:20 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Doreswamy", "", ""], ["Vanajakshi", "M. N.", ""]]}, {"id": "1301.0363", "submitter": "Sriganesh Srihari Dr", "authors": "Sriganesh Srihari and Hon Wai Leong", "title": "Employing functional interactions for characterization and detection of\n  sparse complexes from yeast PPI networks", "comments": "18 pages, 9 Tables, 1 Figure", "journal-ref": "Int J Bioinform Res Appl. 2012, 8(3-4):286-304", "doi": "10.1504/IJBRA.2012.048962", "report-no": null, "categories": "cs.CE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, several computational techniques have been devised\nto recover protein complexes from the protein interaction (PPI) networks of\norganisms. These techniques model \"dense\" subnetworks within PPI networks as\ncomplexes. However, our comprehensive evaluations revealed that these\ntechniques fail to reconstruct many 'gold standard' complexes that are \"sparse\"\nin the networks (only 71 recovered out of 123 known yeast complexes embedded in\na network of 9704 interactions among 1622 proteins). In this work, we propose a\nnovel index called Component-Edge (CE) score to quantitatively measure the\nnotion of \"complex derivability\" from PPI networks. Using this index, we\ntheoretically categorize complexes as \"sparse\" or \"dense\" with respect to a\ngiven network. We then devise an algorithm SPARC that selectively employs\nfunctional interactions to improve the CE scores of predicted complexes, and\nthereby elevates many of the \"sparse\" complexes to \"dense\". This empowers\nexisting methods to detect these \"sparse\" complexes. We demonstrate that our\napproach is effective in reconstructing significantly many complexes missed\npreviously (104 recovered out of the 123 known complexes or ~47% improvement).\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 02:01:10 GMT"}], "update_date": "2013-01-04", "authors_parsed": [["Srihari", "Sriganesh", ""], ["Leong", "Hon Wai", ""]]}, {"id": "1301.0633", "submitter": "Sarod Yatawatta", "authors": "Sanaz Kazemi, Sarod Yatawatta, Saleem Zaroubi", "title": "Clustered Calibration: An Improvement to Radio Interferometric Direction\n  Dependent Self-Calibration", "comments": "18 pages, 21 figures, Accepted 2013 January 2. Abstract abridged", "journal-ref": "Monthly Notices of the Royal Astronomical Society, Volume 430,\n  Issue 2, p.1457-1472, 2013", "doi": "10.1093/mnras/stt018", "report-no": null, "categories": "astro-ph.IM cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new generation of radio synthesis arrays, such as LOFAR and SKA, have\nbeen designed to surpass existing arrays in terms of sensitivity, angular\nresolution and frequency coverage. This evolution has led to the development of\nadvanced calibration techniques that ensure the delivery of accurate results at\nthe lowest possible computational cost. However, the performance of such\ncalibration techniques is still limited by the compact, bright sources in the\nsky, used as calibrators. It is important to have a bright enough source that\nis well distinguished from the background noise level in order to achieve\nsatisfactory results in calibration. We present \"clustered calibration\" as a\nmodification to traditional radio interferometric calibration, in order to\naccommodate faint sources that are almost below the background noise level into\nthe calibration process. The main idea is to employ the information of the\nbright sources' measured signals as an aid to calibrate fainter sources that\nare nearby the bright sources. In the case where we do not have bright enough\nsources, a source cluster could act as a bright source that can be\ndistinguished from background noise. We construct a number of source clusters\nassuming that the signals of the sources belonging to a single cluster are\ncorrupted by almost the same errors, and each cluster is calibrated as a single\nsource, using the combined coherencies of its sources simultaneously. This\nupgrades the power of an individual faint source by the effective power of its\ncluster. We give performance analysis of clustered calibration to show the\nsuperiority of this approach compared to the traditional unclustered\ncalibration. We also provide analytical criteria to choose the optimum number\nof clusters for a given observation in an efficient manner.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 21:13:39 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Kazemi", "Sanaz", ""], ["Yatawatta", "Sarod", ""], ["Zaroubi", "Saleem", ""]]}, {"id": "1301.1295", "submitter": "Roberto Herrera", "authors": "Roberto H. Herrera, Jean-Baptiste Tary and Mirko van der Baan", "title": "Time-Frequency Representation of Microseismic Signals using the\n  Synchrosqueezing Transform", "comments": "4 pages, 2 figures, GeoConvention 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resonance frequencies can provide useful information on the deformation\noccurring during fracturing experiments or $CO_2$ management, complementary to\nthe microseismic event distribution. An accurate time-frequency representation\nis of crucial importance prior to interpreting the cause of resonance\nfrequencies during microseismic experiments. The popular methods of Short-Time\nFourier Transform (STFT) and wavelet analysis have limitations in representing\nclose frequencies and dealing with fast varying instantaneous frequencies and\nthis is often the nature of microseismic signals. The synchrosqueezing\ntransform (SST) is a promising tool to track these resonant frequencies and\nprovide a detailed time-frequency representation. Here we apply the\nsynchrosqueezing transform to microseismic signals and also show its potential\nto general seismic signal processing applications.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 18:26:25 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Herrera", "Roberto H.", ""], ["Tary", "Jean-Baptiste", ""], ["van der Baan", "Mirko", ""]]}, {"id": "1301.1409", "submitter": "Francisco Pe\\~nu\\~nuri", "authors": "F. Penunuri, R. Peon-Escalante, C. Villanueva, O. Mendoza, Carlos A.\n  Cruz-Villar", "title": "A Dual Number Approach for Numerical Calculation of Velocity and\n  Acceleration in the Spherical 4R Mechanism", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a methodology to calculate both the first and second\nderivatives of a vector function of one variable in a single computation step.\nThe method is based on the nested application of the dual number approach for\nfirst order derivatives.\n  It has been implemented in Fortran language, a module which contains the dual\nversion of elementary functions as well as more complex functions, which are\ncommon in the field of rotational kinematics. Since we have three quantities of\ninterest, namely the function itself and its first and second derivative, our\nbasic numerical entity has three elements. Then, for a given vector function\n$f:\\mathbb{R}\\to \\mathbb{R}^m$, its dual version will have the form\n$\\tilde{f}:\\mathbb{R}^3\\to \\mathbb{R}^{3m}$.\n  As a study case, the proposed methodology is used to calculate the velocity\nand acceleration of a point moving on the coupler-point curve generated by a\nspherical four-bar mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 04:40:27 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2013 21:01:21 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2013 18:32:10 GMT"}], "update_date": "2013-07-24", "authors_parsed": [["Penunuri", "F.", ""], ["Peon-Escalante", "R.", ""], ["Villanueva", "C.", ""], ["Mendoza", "O.", ""], ["Cruz-Villar", "Carlos A.", ""]]}, {"id": "1301.1502", "submitter": "Hannah Inbarani", "authors": "N. Kalaiselvi, H. Hannah Inbarani", "title": "Fuzzy Soft Set Based Classification for Gene Expression Data", "comments": "7 pages, IJSER Vol.3 Issue: 10 Oct 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the major issues in Data Mining Research fields. The\nclassification problems in medical area often classify medical dataset based on\nthe result of medical diagnosis or description of medical treatment by the\nmedical practitioner. This research work discusses the classification process\nof Gene Expression data for three different cancers which are breast cancer,\nlung cancer and leukemia cancer with two classes which are cancerous stage and\nnon cancerous stage. We have applied a fuzzy soft set similarity based\nclassifier to enhance the accuracy to predict the stages among cancer genes and\nthe informative genes are selected by using Entopy filtering.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 11:48:49 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Kalaiselvi", "N.", ""], ["Inbarani", "H. Hannah", ""]]}, {"id": "1301.1608", "submitter": "Hamidreza Chitsaz", "authors": "Elmirasadat Forouzmand and Hamidreza Chitsaz", "title": "The RNA Newton Polytope and Learnability of Energy Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite nearly two scores of research on RNA secondary structure and RNA-RNA\ninteraction prediction, the accuracy of the state-of-the-art algorithms are\nstill far from satisfactory. Researchers have proposed increasingly complex\nenergy models and improved parameter estimation methods in anticipation of\nendowing their methods with enough power to solve the problem. The output has\ndisappointingly been only modest improvements, not matching the expectations.\nEven recent massively featured machine learning approaches were not able to\nbreak the barrier. In this paper, we introduce the notion of learnability of\nthe parameters of an energy model as a measure of its inherent capability. We\nsay that the parameters of an energy model are learnable iff there exists at\nleast one set of such parameters that renders every known RNA structure to date\nthe minimum free energy structure. We derive a necessary condition for the\nlearnability and give a dynamic programming algorithm to assess it. Our\nalgorithm computes the convex hull of the feature vectors of all feasible\nstructures in the ensemble of a given input sequence. Interestingly, that\nconvex hull coincides with the Newton polytope of the partition function as a\npolynomial in energy parameters. We demonstrated the application of our theory\nto a simple energy model consisting of a weighted count of A-U and C-G base\npairs. Our results show that this simple energy model satisfies the necessary\ncondition for less than one third of the input unpseudoknotted\nsequence-structure pairs chosen from the RNA STRAND v2.0 database. For another\none third, the necessary condition is barely violated, which suggests that\naugmenting this simple energy model with more features such as the Turner loops\nmay solve the problem. The necessary condition is severely violated for 8%,\nwhich provides a small set of hard cases that require further investigation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 17:43:08 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Forouzmand", "Elmirasadat", ""], ["Chitsaz", "Hamidreza", ""]]}, {"id": "1301.1714", "submitter": "Teruyoshi Washizawa", "authors": "Teruyoshi Washizawa, Yasuhiro Nakahara", "title": "Parallel Computing of Discrete Element Method on GPU", "comments": "3 tables", "journal-ref": "Applied Mathematics, vol.4, no.1A, pp.242-247, (January 2013)", "doi": "10.4236/am.2013.41A037", "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate applicability of GPU to DEM. NVIDIA's code obtained superior\nperformance than CPU in computational time. A model of contact forces in\nNVIDIA's code is too simple for practical use. We modify this model by\nreplacing it with the practical model. The simulation shows that the practical\nmodel obtains the computing speed 6 times faster than the practical one on CPU\nwhile 7 times slower than the simple one on GPU. The result are analyzed.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 23:09:49 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Washizawa", "Teruyoshi", ""], ["Nakahara", "Yasuhiro", ""]]}, {"id": "1301.2354", "submitter": "Teruyoshi Washizawa", "authors": "Teruyoshi Washizawa, Akira Asai, Nobuhiro Yoshikawa", "title": "A New Approach for Solving Singular Systems in Topology Optimization\n  Using Krylov Subspace Methods", "comments": "21 pages, 4 figures", "journal-ref": "Structural and Multidisciplinary Optimization, vol.28, pp.330-339,\n  2004", "doi": "10.1007/s00158-004-0439-3", "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topology optimization, the design parameter with no contribution to the\nobjective function vanishes. This causes the stiffness matrix to become\nsingular. We show that a local optimal solution is obtained by Conjugate\nResidual Method and Conjugate Gradient Method even if the stiffness matrix\nbecomes singular. We prove that CGMconverges to a local optimal solution in\nthat case. Computer simulation shows that CGM gives the same solutions obtained\nby CRM in case of a cantilever beam problem.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 23:11:16 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Washizawa", "Teruyoshi", ""], ["Asai", "Akira", ""], ["Yoshikawa", "Nobuhiro", ""]]}, {"id": "1301.2634", "submitter": "Andrei Zinovyev Dr.", "authors": "Andrei Zinovyev, Ulykbek Kairov, Tatiana Karpenyuk and Erlan\n  Ramanculov", "title": "Blind source separation methods for deconvolution of complex signals in\n  cancer biology", "comments": "Zinovyev A., Kairov U., Karpenyuk T., Ramanculov E. Blind Source\n  Separation Methods For Deconvolution Of Complex Signals In Cancer Biology.\n  2012. Biochemical and Biophysical Research Communications. In Press. DOI:\n  10.1016/j.bbrc.2012.12.043", "journal-ref": "2013. Biochemical and Biophysical Research Communications 430(3),\n  1182-1187", "doi": "10.1016/j.bbrc.2012.12.043", "report-no": null, "categories": "q-bio.QM cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two blind source separation methods (Independent Component Analysis and\nNon-negative Matrix Factorization), developed initially for signal processing\nin engineering, found recently a number of applications in analysis of\nlarge-scale data in molecular biology. In this short review, we present the\ncommon idea behind these methods, describe ways of implementing and applying\nthem and point out to the advantages compared to more traditional statistical\napproaches. We focus more specifically on the analysis of gene expression in\ncancer. The review is finalized by listing available software implementations\nfor the methods described.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 23:47:16 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Zinovyev", "Andrei", ""], ["Kairov", "Ulykbek", ""], ["Karpenyuk", "Tatiana", ""], ["Ramanculov", "Erlan", ""]]}, {"id": "1301.2866", "submitter": "Juan Galvis", "authors": "Yalchin Efendiev, Juan Galvis, Thomas Y. Hou", "title": "Generalized Multiscale Finite Element Methods (GMsFEM)", "comments": "Revised version", "journal-ref": null, "doi": "10.1016/j.jcp.2013.04.045", "report-no": null, "categories": "math.NA cs.CE cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general approach called Generalized Multiscale\nFinite Element Method (GMsFEM) for performing multiscale simulations for\nproblems without scale separation over a complex input space. As in multiscale\nfinite element methods (MsFEMs), the main idea of the proposed approach is to\nconstruct a small dimensional local solution space that can be used to generate\nan efficient and accurate approximation to the multiscale solution with a\npotentially high dimensional input parameter space. In the proposed approach,\nwe present a general procedure to construct the offline space that is used for\na systematic enrichment of the coarse solution space in the online stage. The\nenrichment in the online stage is performed based on a spectral decomposition\nof the offline space. In the online stage, for any input parameter, a\nmultiscale space is constructed to solve the global problem on a coarse grid.\nThe online space is constructed via a spectral decomposition of the offline\nspace and by choosing the eigenvectors corresponding to the largest\neigenvalues. The computational saving is due to the fact that the construction\nof the online multiscale space for any input parameter is fast and this space\ncan be re-used for solving the forward problem with any forcing and boundary\ncondition. Compared with the other approaches where global snapshots are used,\nthe local approach that we present in this paper allows us to eliminate\nunnecessary degrees of freedom on a coarse-grid level. We present various\nexamples in the paper and some numerical results to demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 06:43:11 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2013 12:31:10 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Efendiev", "Yalchin", ""], ["Galvis", "Juan", ""], ["Hou", "Thomas Y.", ""]]}, {"id": "1301.3118", "submitter": "Qasim  Nasar-Ullah", "authors": "Qasim Nasar-Ullah", "title": "A parallel implementation of a derivative pricing model incorporating\n  SABR calibration and probability lookup tables", "comments": "21 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a high performance parallel implementation of a derivative\npricing model, within which we introduce a new parallel method for the\ncalibration of the industry standard SABR (stochastic-\\alpha \\beta \\rho)\nstochastic volatility model using three strike inputs. SABR calibration\ninvolves a non-linear three dimensional minimisation and parallelisation is\nachieved by incorporating several assumptions unique to the SABR class of\nmodels. Our calibration method is based on principles of surface intersection,\nguarantees convergence to a unique solution and operates by iteratively\nrefining a two dimensional grid with local mesh refinement. As part of our\npricing model we additionally present a fast parallel iterative algorithm for\nthe creation of dynamically sized cumulative probability lookup tables that are\nable to cap maximum estimated linear interpolation error. We optimise\nperformance for probability distributions that exhibit clustering of linear\ninterpolation error. We also make an empirical assessment of error propagation\nthrough our pricing model as a result of changes in accuracy parameters within\nthe pricing model's multiple algorithmic steps. Algorithms are implemented on a\nGPU (graphics processing unit) using Nvidia's Fermi architecture. The pricing\nmodel targets the evaluation of spread options using copula methods, however\nthe presented algorithms can be applied to a wider class of financial\ninstruments.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 20:33:00 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Nasar-Ullah", "Qasim", ""]]}, {"id": "1301.3934", "submitter": "David Basanta", "authors": "Jacob G. Scott, Prakash Chinnaiyan, Alexander R. A. Anderson, Anita\n  Hjelmeland, David Basanta", "title": "Intrinsic cell factors that influence tumourigenicity in cancer stem\n  cells - towards hallmarks of cancer stem cells", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the discovery of a cancer initiating side population in solid tumours,\nstudies focussing on the role of so-called cancer stem cells in cancer\ninitiation and progression have abounded. The biological interrogation of these\ncells has yielded volumes of information about their behaviour, but there has,\nas of yet, not been many actionable generalised theoretical conclusions. To\naddress this point, we have created a hybrid, discrete/continuous computational\ncellular automaton model of a generalised stem-cell driven tissue and explored\nthe phenotypic traits inherent in the inciting cell and the resultant tissue\ngrowth. We identify the regions in phenotype parameter space where these\ninitiating cells are able to cause a disruption in homeostasis, leading to\ntissue overgrowth and tumour formation. As our parameters and model are\nnon-specific, they could apply to any tissue cancer stem-cell and do not assume\nspecific genetic mutations. In this way, our model suggests that targeting\nthese phenotypic traits could represent generalizable strategies across cancer\ntypes and represents a first attempt to identify the hallmarks of cancer stem\ncells.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 22:04:46 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2013 16:34:40 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2013 21:23:10 GMT"}], "update_date": "2013-08-22", "authors_parsed": [["Scott", "Jacob G.", ""], ["Chinnaiyan", "Prakash", ""], ["Anderson", "Alexander R. A.", ""], ["Hjelmeland", "Anita", ""], ["Basanta", "David", ""]]}, {"id": "1301.4194", "submitter": "Ankit Dangi Mr.", "authors": "Ankit Dangi", "title": "Financial Portfolio Optimization: Computationally guided agents to\n  investigate, analyse and invest!?", "comments": "Thesis work under the guidance of Dr. Abhijit Kulkarni, Advanced\n  Analytics Lab. (SSO), SAS Research & Development, India. Submitted at Centre\n  for Modeling and Simulation, University of Pune for completion of Master of\n  Technology (M. Tech.) in Modeling and Simulation (M&S)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.CE cs.NE q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial portfolio optimization is a widely studied problem in mathematics,\nstatistics, financial and computational literature. It adheres to determining\nan optimal combination of weights associated with financial assets held in a\nportfolio. In practice, it faces challenges by virtue of varying math.\nformulations, parameters, business constraints and complex financial\ninstruments. Empirical nature of data is no longer one-sided; thereby\nreflecting upside and downside trends with repeated yet unidentifiable cyclic\nbehaviours potentially caused due to high frequency volatile movements in asset\ntrades. Portfolio optimization under such circumstances is theoretically and\ncomputationally challenging. This work presents a novel mechanism to reach an\noptimal solution by encoding a variety of optimal solutions in a solution bank\nto guide the search process for the global investment objective formulation. It\nconceptualizes the role of individual solver agents that contribute optimal\nsolutions to a bank of solutions, a super-agent solver that learns from the\nsolution bank, and, thus reflects a knowledge-based computationally guided\nagents approach to investigate, analyse and reach to optimal solution for\ninformed investment decisions.\n  Conceptual understanding of classes of solver agents that represent varying\nproblem formulations and, mathematically oriented deterministic solvers along\nwith stochastic-search driven evolutionary and swarm-intelligence based\ntechniques for optimal weights are discussed. Algorithmic implementation is\npresented by an enhanced neighbourhood generation mechanism in Simulated\nAnnealing algorithm. A framework for inclusion of heuristic knowledge and human\nexpertise from financial literature related to investment decision making\nprocess is reflected via introduction of controlled perturbation strategies\nusing a decision matrix for neighbourhood generation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 19:26:02 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Dangi", "Ankit", ""]]}, {"id": "1301.4668", "submitter": "Kirana Kumara P", "authors": "Kirana Kumara P", "title": "A MATLAB Code for Three Dimensional Linear Elastostatics using Constant\n  Boundary Elements", "comments": "12 pages (pdf), 8 supplementary files, accepted author manuscript", "journal-ref": "International Journal of Advances in Engineering Sciences(IJAES)\n  Vol 2 No 3 (2012) pp. 9-20 [e-ISSN: 2231-0347, Print-ISSN: 2231-2013]", "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Present work presents a code written in the very simple programming language\nMATLAB, for three dimensional linear elastostatics, using constant boundary\nelements. The code, in full or in part, is not a translation or a copy of any\nof the existing codes. Present paper explains how the code is written, and\nlists all the formulae used. Code is verified by using the code to solve a\nsimple problem which has the well known approximate analytical solution. Of\ncourse, present work does not make any contribution to research on boundary\nelements, in terms of theory. But the work is justified by the fact that, to\nthe best of author's knowledge, as of now, one cannot find an open access\nMATLAB code for three dimensional linear elastostatics using constant boundary\nelements. Author hopes this paper to be of help to beginners who wish to\nunderstand how a simple but complete boundary element code works, so that they\ncan build upon and modify the present open access code to solve complex\nengineering problems quickly and easily. The code is available online for open\naccess (as supplementary file for the present paper), and may be downloaded\nfrom the website for the present journal.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 16:29:09 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["P", "Kirana Kumara", ""]]}, {"id": "1301.5273", "submitter": "arXiv Admin", "authors": "Rick B. Jenison", "title": "Using Periodicity of Nucleotide Sequences", "comments": "arXiv admin note: entirely plagiarized from\n  http://www.ncbi.nlm.nih.gov/pubmed/19261626", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Withdrawn by arXiv administrators due to content entirely plagiarized from\nother authors (not in arXiv).\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 02:02:30 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2013 18:25:26 GMT"}], "update_date": "2013-02-15", "authors_parsed": [["Jenison", "Rick B.", ""]]}, {"id": "1301.5595", "submitter": "Antoine Mokbel Karam", "authors": "Antoine Karam and Daniel Play", "title": "A discrete analysis of metal-v belt drive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metal-V belt drive includes a large number of parts which interact\nbetween them to transmit power from the input to the output pulleys. A\ncompression belt composed of a great number of struts is maintained by a\ntension flat belt. Power is them shared into the two belts that moves generally\nin opposite directions. Due to the particular geometry of the elements and to\nthe great number of parts, a numerical approach achieves the global equilibrium\nof the mechanism from the elementary part equilibrium. Sliding arc on each\npulley can be thus defined both for the compression and tension belts. Finally,\npower sharing can be calculated as differential motion between the belts, is\ndefined. The first part of the paper will present the different steps of the\nquasi-static mechanical analysis and their numerical implementations. Load\ndistributions, speed profiles and sliding angle values will be discussed. The\nsecond part of the paper will deal to a systematic use of the computer\nsoftware. Speed ratio, transmitted torque, strut geometry and friction\ncoefficients effect will be analysed with the output parameter variations.\nFinally, the effect pulley deformable flanges will be discussed.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 17:52:48 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Karam", "Antoine", ""], ["Play", "Daniel", ""]]}, {"id": "1301.5831", "submitter": "Manuel Marques-Pita PhD", "authors": "Manuel Marques-Pita and Luis M. Rocha", "title": "Canalization and control in automata networks: body segmentation in\n  Drosophila melanogaster", "comments": "77 pages, 21 figures and 4 tables. Supplementary information not\n  included. PLoS ONE (in press)", "journal-ref": null, "doi": "10.1371/journal.pone.0055946", "report-no": null, "categories": "q-bio.MN cs.CE cs.DM cs.FL nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present schema redescription as a methodology to characterize canalization\nin automata networks used to model biochemical regulation and signalling. In\nour formulation, canalization becomes synonymous with redundancy present in the\nlogic of automata. This results in straightforward measures to quantify\ncanalization in an automaton (micro-level), which is in turn integrated into a\nhighly scalable framework to characterize the collective dynamics of\nlarge-scale automata networks (macro-level). This way, our approach provides a\nmethod to link micro- to macro-level dynamics -- a crux of complexity. Several\nnew results ensue from this methodology: uncovering of dynamical modularity\n(modules in the dynamics rather than in the structure of networks),\nidentification of minimal conditions and critical nodes to control the\nconvergence to attractors, simulation of dynamical behaviour from incomplete\ninformation about initial conditions, and measures of macro-level canalization\nand robustness to perturbations. We exemplify our methodology with a well-known\nmodel of the intra- and inter cellular genetic regulation of body segmentation\nin Drosophila melanogaster. We use this model to show that our analysis does\nnot contradict any previous findings. But we also obtain new knowledge about\nits behaviour: a better understanding of the size of its wild-type attractor\nbasin (larger than previously thought), the identification of novel minimal\nconditions and critical nodes that control wild-type behaviour, and the\nresilience of these to stochastic interventions. Our methodology is applicable\nto any complex network that can be modelled using automata, but we focus on\nbiochemical regulation and signalling, towards a better understanding of the\n(decentralized) control that orchestrates cellular activity -- with the\nultimate goal of explaining how do cells and tissues 'compute'.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 16:28:45 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2013 16:18:57 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Marques-Pita", "Manuel", ""], ["Rocha", "Luis M.", ""]]}]