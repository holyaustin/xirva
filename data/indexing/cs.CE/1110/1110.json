[{"id": "1110.0543", "submitter": "Kevin Jorissen", "authors": "Kevin Jorissen, Fernando D. Vila, and John J. Rehr", "title": "A high performance scientific cloud computing environment for materials\n  simulations", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2012.04.010", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the development of a scientific cloud computing (SCC) platform\nthat offers high performance computation capability. The platform consists of a\nscientific virtual machine prototype containing a UNIX operating system and\nseveral materials science codes, together with essential interface tools (an\nSCC toolset) that offers functionality comparable to local compute clusters. In\nparticular, our SCC toolset provides automatic creation of virtual clusters for\nparallel computing, including tools for execution and monitoring performance,\nas well as efficient I/O utilities that enable seamless connections to and from\nthe cloud. Our SCC platform is optimized for the Amazon Elastic Compute Cloud\n(EC2). We present benchmarks for prototypical scientific applications and\ndemonstrate performance comparable to local compute clusters. To facilitate\ncode execution and provide user-friendly access, we have also integrated cloud\ncomputing capability in a JAVA-based GUI. Our SCC platform may be an\nalternative to traditional HPC resources for materials science or quantum\nchemistry applications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 23:35:46 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Jorissen", "Kevin", ""], ["Vila", "Fernando D.", ""], ["Rehr", "John J.", ""]]}, {"id": "1110.0693", "submitter": "Manuel Bodirsky", "authors": "Manuel Bodirsky (CNRS/LIX, Ecole Polytechnique, Palaiseau, France),\n  Jens K Mueller (Friedrich-Schiller-University Jena, Germany)", "title": "The Complexity of Rooted Phylogeny Problems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 7, Issue 4 (November\n  24, 2011) lmcs:906", "doi": "10.2168/LMCS-7(4:6)2011", "report-no": null, "categories": "cs.CC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several computational problems in phylogenetic reconstruction can be\nformulated as restrictions of the following general problem: given a formula in\nconjunctive normal form where the literals are rooted triples, is there a\nrooted binary tree that satisfies the formula? If the formulas do not contain\ndisjunctions, the problem becomes the famous rooted triple consistency problem,\nwhich can be solved in polynomial time by an algorithm of Aho, Sagiv,\nSzymanski, and Ullman. If the clauses in the formulas are restricted to\ndisjunctions of negated triples, Ng, Steel, and Wormald showed that the problem\nremains NP-complete. We systematically study the computational complexity of\nthe problem for all such restrictions of the clauses in the input formula. For\ncertain restricted disjunctions of triples we present an algorithm that has\nsub-quadratic running time and is asymptotically as fast as the fastest known\nalgorithm for the rooted triple consistency problem. We also show that any\nrestriction of the general rooted phylogeny problem that does not fall into our\ntractable class is NP-complete, using known results about the complexity of\nBoolean constraint satisfaction problems. Finally, we present a pebble game\nargument that shows that the rooted triple consistency problem (and also all\ngeneralizations studied in this paper) cannot be solved by Datalog.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 14:09:06 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2011 10:14:46 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bodirsky", "Manuel", "", "CNRS/LIX, Ecole Polytechnique, Palaiseau, France"], ["Mueller", "Jens K", "", "Friedrich-Schiller-University Jena, Germany"]]}, {"id": "1110.0895", "submitter": "Michael Friedlander", "authors": "Aleksandr Aravkin, Michael P. Friedlander, Tristan van Leeuwen", "title": "Robust inversion via semistochastic dimensionality reduction", "comments": "Mathematical Programming, 2012", "journal-ref": "Mathematical Programming 134 (1), 101-125, 2012", "doi": "10.1007/s10107-012-0571-6", "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of inverse problems where it is possible to aggregate the\nresults of multiple experiments. This class includes problems where the forward\nmodel is the solution operator to linear ODEs or PDEs. The tremendous size of\nsuch problems motivates dimensionality reduction techniques based on randomly\nmixing experiments. These techniques break down, however, when robust\ndata-fitting formulations are used, which are essential in cases of missing\ndata, unusually large errors, and systematic features in the data unexplained\nby the forward model. We survey robust methods within a statistical framework,\nand propose a semistochastic optimization approach that allows dimensionality\nreduction. The efficacy of the methods are demonstrated for a large-scale\nseismic inverse problem using the robust Student's t-distribution, where a\nuseful synthetic velocity model is recovered in the extreme scenario of 60%\ndata missing at random. The semistochastic approach achieves this recovery\nusing 20% of the effort required by a direct robust approach.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 04:55:59 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2011 18:30:05 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2012 23:54:40 GMT"}, {"version": "v4", "created": "Mon, 2 Jul 2012 14:07:13 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Aravkin", "Aleksandr", ""], ["Friedlander", "Michael P.", ""], ["van Leeuwen", "Tristan", ""]]}, {"id": "1110.0983", "submitter": "Markus Gusenbauer", "authors": "Markus Gusenbauer, Alexander Kovacs, Franz Reichel, Lukas Exl, Simon\n  Bance, Harald Ozelt, Thomas Schrefl", "title": "Self-organizing magnetic beads for biomedical applications", "comments": null, "journal-ref": "Journal of Magnetism and Magnetic Materials 324.6 (2012): 977-982", "doi": "10.1016/j.jmmm.2011.09.034", "report-no": null, "categories": "physics.bio-ph cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of biomedicine magnetic beads are used for drug delivery and to\ntreat hyperthermia. Here we propose to use self-organized bead structures to\nisolate circulating tumor cells using lab-on-chip technologies. Typically blood\nflows past microposts functionalized with antibodies for circulating tumor\ncells. Creating these microposts with interacting magnetic beads makes it\npossible to tune the geometry in size, position and shape. We developed a\nsimulation tool that combines micromagnetics and discrete particle dynamics, in\norder to design micropost arrays made of interacting beads. The simulation\ntakes into account the viscous drag of the blood flow, magnetostatic\ninteractions between the magnetic beads and gradient forces from external\naligned magnets. We developed a particle-particle particle-mesh method for\neffective computation of the magnetic force and torque acting on the particles.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 13:49:35 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Gusenbauer", "Markus", ""], ["Kovacs", "Alexander", ""], ["Reichel", "Franz", ""], ["Exl", "Lukas", ""], ["Bance", "Simon", ""], ["Ozelt", "Harald", ""], ["Schrefl", "Thomas", ""]]}, {"id": "1110.0995", "submitter": "Markus Gusenbauer", "authors": "Markus Gusenbauer, Ivan Cimrak, Simon Bance, Lukas Exl, Franz Reichel,\n  Harald Oezelt, Thomas Schrefl", "title": "A tunable cancer cell filter using magnetic beads: cellular and fluid\n  dynamic simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of biomedicine magnetic beads are used for drug delivery and to\ntreat hyperthermia. Here we propose to use self-organized bead structures to\nisolate circulating tumor cells using lab-on-chip technologies. Typically blood\nflows past microposts functionalized with antibodies for circulating tumor\ncells. Creating these microposts with interacting magnetic beads makes it\npossible to tune the geometry in size, position and shape. We develop a\nsimulation tool that combines micromagnetics, discrete particle dynamics and\nfluid dynamics, in order to design micropost arrays made of interacting beads.\nFor the simulation of blood flow we use the Lattice-Boltzmann method with\nimmersed elastic blood cell models. Parallelization distributes large fluid and\nparticle dynamic simulations over available resources to reduce overall\ncalculation time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 14:15:30 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Gusenbauer", "Markus", ""], ["Cimrak", "Ivan", ""], ["Bance", "Simon", ""], ["Exl", "Lukas", ""], ["Reichel", "Franz", ""], ["Oezelt", "Harald", ""], ["Schrefl", "Thomas", ""]]}, {"id": "1110.1628", "submitter": "Olivier Montagnier OM", "authors": "Olivier Montagnier and Christian Hochard", "title": "Optimisation of hybrid high-modulus/high-strength carbon fiber\n  reinforced plastic composite drive", "comments": "13 pages, preprint submitted to Materials and Design (Received 22\n  February 2012; received in revised form 18 september 2012; accepted 21\n  september 2012)", "journal-ref": null, "doi": "10.1016/j.matdes.2012.09.035", "report-no": null, "categories": "cs.CE cs.SE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study deals with the optimisation of hybrid composite drive shafts\noperating at subcritical or supercritical speeds, using a genetic algorithm. A\nformulation for the flexural vibrations of a composite drive shaft mounted on\nviscoelastic supports including shear effects is developed. In particular, an\nanalytic stability criterion is developed to ensure the integrity of the system\nin the supercritical regime. Then it is shown that the torsional strength can\nbe computed with the maximum stress criterion. A shell method is developed for\ncomputing drive shaft torsional buckling. The optimisation of a helicopter tail\nrotor driveline is then performed. In particular, original hybrid shafts\nconsisting of high-modulus and high-strength carbon fibre reinforced epoxy\nplies were studied. The solutions obtained using the method presented here made\nit possible to greatly decrease the number of shafts and the weight of the\ndriveline under subcritical conditions, and even more under supercritical\nconditions. This study yielded some general rules for designing an optimum\ncomposite shaft without any need for optimisation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 19:03:24 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2012 13:17:06 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Montagnier", "Olivier", ""], ["Hochard", "Christian", ""]]}, {"id": "1110.1708", "submitter": "Esmond G Ng", "authors": "E Ng, J Sarich, S M Wild, T Munson, H Aktulga, C Yang, P Maris, J P\n  Vary, N Schunck, M G Bertolli, M Kortelainen, W Nazarewicz, T Papenbrock, M V\n  Stoitsov", "title": "Advancing Nuclear Physics Through TOPS Solvers and Tools", "comments": "SciDAC 2011 Conference, July 10-14, 2011, Denver, CO; 5 pages, 2\n  tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of many scientific applications is the solution of algebraic\nsystems, such as linear systems of equations, eigenvalue problems, and\noptimization problems, to name a few. TOPS, which stands for Towards Optimal\nPetascale Simulations, is a SciDAC applied math center focused on the\ndevelopment of solvers for tackling these algebraic systems, as well as the\ndeployment of such technologies in large-scale scientific applications of\ninterest to the U.S. Department of Energy. In this paper, we highlight some of\nthe solver technologies we have developed in optimization and matrix\ncomputations. We also describe some accomplishments achieved using these\ntechnologies in UNEDF, a SciDAC application project on nuclear physics.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2011 08:35:04 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Ng", "E", ""], ["Sarich", "J", ""], ["Wild", "S M", ""], ["Munson", "T", ""], ["Aktulga", "H", ""], ["Yang", "C", ""], ["Maris", "P", ""], ["Vary", "J P", ""], ["Schunck", "N", ""], ["Bertolli", "M G", ""], ["Kortelainen", "M", ""], ["Nazarewicz", "W", ""], ["Papenbrock", "T", ""], ["Stoitsov", "M V", ""]]}, {"id": "1110.2049", "submitter": "Jan Sykora", "authors": "A. Kucerova and J. Sykora and B. Rosic and H. G. Matthies", "title": "Acceleration of Uncertainty Updating in the Description of Transport\n  Processes in Heterogeneous Materials", "comments": null, "journal-ref": "Journal of Computational and Applied Mathematics, 236(18),\n  4862-4872, 2012", "doi": "10.1016/j.cam.2012.02.003", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of thermo-mechanical behaviour of heterogeneous materials such\nas heat and moisture transport is strongly influenced by the uncertainty in\nparameters. Such materials occur e.g. in historic buildings, and the durability\nassessment of these therefore needs a reliable and probabilistic simulation of\ntransport processes, which is related to the suitable identification of\nmaterial parameters. In order to include expert knowledge as well as\nexperimental results, one can employ an updating procedure such as Bayesian\ninference. The classical probabilistic setting of the identification process in\nBayes's form requires the solution of a stochastic forward problem via\ncomputationally expensive sampling techniques, which makes the method almost\nimpractical. In this paper novel stochastic computational techniques such as\nthe stochastic Galerkin method are applied in order to accelerate the updating\nprocedure. The idea is to replace the computationally expensive forward\nsimulation via the conventional finite element (FE) method by the evaluation of\na polynomial chaos expansion (PCE). Such an approximation of the FE model for\nthe forward simulation perfectly suits the Bayesian updating. The presented\nuncertainty updating techniques are applied to the numerical model of coupled\nheat and moisture transport in heterogeneous materials with spatially varying\ncoefficients defined by random fields.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 14:22:16 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Kucerova", "A.", ""], ["Sykora", "J.", ""], ["Rosic", "B.", ""], ["Matthies", "H. G.", ""]]}, {"id": "1110.2055", "submitter": "Jan Sykora", "authors": "J.Sykora and T. Krejci and J. Kruis and M. Sejnoha", "title": "Computational homogenization of non-stationary transport processes in\n  masonry structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fully coupled transient heat and moisture transport in a masonry structure\nis examined in this paper. Supported by several successful applications in\ncivil engineering the nonlinear diffusion model proposed by K\\\"{u}nzel is\nadopted in the present study. A strong material heterogeneity together with a\nsignificant dependence of the model parameters on initial conditions as well as\nthe gradients of heat and moisture fields vindicates the use of a hierarchical\nmodeling strategy to solve the problem of this kind. Attention is limited to\nthe classical first order homogenization in a spatial domain developed here in\nthe framework of a two step (meso-macro) multi-scale computational scheme (FE^2\nproblem). Several illustrative examples are presented to investigate the\ninfluence of transient flow at the level of constituents (meso-scale) on the\nmacroscopic response including the effect of macro-scale boundary conditions. A\ntwo-dimensional section of Charles Bridge subjected to actual climatic\nconditions is analyzed next to confirm the suitability of algorithmic format of\nFE^2 scheme for the parallel computing.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 14:34:59 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Sykora", "J.", ""], ["Krejci", "T.", ""], ["Kruis", "J.", ""], ["Sejnoha", "M.", ""]]}, {"id": "1110.2478", "submitter": "Emiliano De Cristofaro", "authors": "Pierre Baldi, Roberta Baronio, Emiliano De Cristofaro, Paolo Gasti,\n  Gene Tsudik", "title": "Countering Gattaca: Efficient and Secure Testing of Fully-Sequenced\n  Human Genomes (Full Version)", "comments": "18th ACM Conference on Computer and Communications Security (CCS\n  2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in DNA sequencing technologies have put ubiquitous\navailability of fully sequenced human genomes within reach. It is no longer\nhard to imagine the day when everyone will have the means to obtain and store\none's own DNA sequence. Widespread and affordable availability of fully\nsequenced genomes immediately opens up important opportunities in a number of\nhealth-related fields. In particular, common genomic applications and tests\nperformed in vitro today will soon be conducted computationally, using\ndigitized genomes. New applications will be developed as genome-enabled\nmedicine becomes increasingly preventive and personalized. However, this\nprogress also prompts significant privacy challenges associated with potential\nloss, theft, or misuse of genomic data. In this paper, we begin to address\ngenomic privacy by focusing on three important applications: Paternity Tests,\nPersonalized Medicine, and Genetic Compatibility Tests. After carefully\nanalyzing these applications and their privacy requirements, we propose a set\nof efficient techniques based on private set operations. This allows us to\nimplement in in silico some operations that are currently performed via in\nvitro methods, in a secure fashion. Experimental results demonstrate that\nproposed techniques are both feasible and practical today.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2011 19:47:11 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2011 23:34:58 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2011 19:35:13 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Baldi", "Pierre", ""], ["Baronio", "Roberta", ""], ["De Cristofaro", "Emiliano", ""], ["Gasti", "Paolo", ""], ["Tsudik", "Gene", ""]]}, {"id": "1110.3121", "submitter": "Yoshiharu Maeno", "authors": "Yoshiharu Maeno", "title": "Transient fluctuation of the prosperity of firms in a network economy", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2013.03.046", "report-no": null, "categories": "q-bio.MN cs.CE physics.bio-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transient fluctuation of the prosperity of firms in a network economy is\ninvestigated with an abstract stochastic model. The model describes the profit\nwhich firms make when they sell materials to a firm which produces a product\nand the fixed cost expense to the firms to produce those materials and product.\nThe formulae for this model are parallel to those for population dynamics. The\nswinging changes in the fluctuation in the transient state from the initial\ngrowth to the final steady state are the consequence of a topology-dependent\ntime trial competition between the profitable interactions and expense. The\nfirm in a sparse random network economy is more likely to go bankrupt than\nexpected from the value of the limit of the fluctuation in the steady state,\nand there is a risk of failing to reach by far the less fluctuating steady\nstate.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 04:36:15 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2012 05:17:28 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2012 14:01:47 GMT"}, {"version": "v4", "created": "Wed, 1 Aug 2012 07:05:58 GMT"}, {"version": "v5", "created": "Tue, 5 Feb 2013 07:26:17 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Maeno", "Yoshiharu", ""]]}, {"id": "1110.3382", "submitter": "Tshilidzi Marwala", "authors": "I. Boulkaibet, T. Marwala, L. Mthembu, M. I. Friswell, S. Adhikari", "title": "Sampling Techniques in Bayesian Finite Element Model Updating", "comments": "Paper Accepted in the 25th International Modal Analysis Conference,\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers in the field of Finite Element Model (FEM) updating have\nhighlighted the benefits of Bayesian techniques. The Bayesian approaches are\ndesigned to deal with the uncertainties associated with complex systems, which\nis the main problem in the development and updating of FEMs. This paper\nhighlights the complexities and challenges of implementing any Bayesian method\nwhen the analysis involves a complicated structural dynamic model. In such\nsystems an analytical Bayesian formulation might not be available in an\nanalytic form; therefore this leads to the use of numerical methods, i.e.\nsampling methods. The main challenge then is to determine an efficient sampling\nof the model parameter space. In this paper, three sampling techniques, the\nMetropolis-Hastings (MH) algorithm, Slice Sampling and the Hybrid Monte Carlo\n(HMC) technique, are tested by updating a structural beam model. The efficiency\nand limitations of each technique is investigated when the FEM updating problem\nis implemented using the Bayesian Approach. Both MH and HMC techniques are\nfound to perform better than the Slice sampling when Young's modulus is chosen\nas the updating parameter. The HMC method gives better results than MH and\nSlice sampling techniques, when the area moment of inertias and section areas\nare updated.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2011 05:17:18 GMT"}], "update_date": "2011-10-18", "authors_parsed": [["Boulkaibet", "I.", ""], ["Marwala", "T.", ""], ["Mthembu", "L.", ""], ["Friswell", "M. I.", ""], ["Adhikari", "S.", ""]]}, {"id": "1110.3546", "submitter": "Bhaskar DasGupta", "authors": "Piotr Berman, Bhaskar DasGupta, Lakshmi Kaligounder, Marek Karpinski", "title": "On the Computational Complexity of Measuring Global Stability of Banking\n  Networks", "comments": "to appear in Algorithmica", "journal-ref": "Algorithmica, 70(4), 595-647, 2014", "doi": "10.1007/s00453-013-9769-0", "report-no": null, "categories": "q-fin.RM cs.CC cs.CE cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threats on the stability of a financial system may severely affect the\nfunctioning of the entire economy, and thus considerable emphasis is placed on\nthe analyzing the cause and effect of such threats. The financial crisis in the\ncurrent and past decade has shown that one important cause of instability in\nglobal markets is the so-called financial contagion, namely the spreading of\ninstabilities or failures of individual components of the network to other,\nperhaps healthier, components. This leads to a natural question of whether the\nregulatory authorities could have predicted and perhaps mitigated the current\neconomic crisis by effective computations of some stability measure of the\nbanking networks. Motivated by such observations, we consider the problem of\ndefining and evaluating stabilities of both homogeneous and heterogeneous\nbanking networks against propagation of synchronous idiosyncratic shocks given\nto a subset of banks. We formalize the homogeneous banking network model of\nNier et al. and its corresponding heterogeneous version, formalize the\nsynchronous shock propagation procedures, define two appropriate stability\nmeasures and investigate the computational complexities of evaluating these\nmeasures for various network topologies and parameters of interest. Our results\nand proofs also shed some light on the properties of topologies and parameters\nof the network that may lead to higher or lower stabilities.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 00:53:36 GMT"}, {"version": "v2", "created": "Sat, 12 Nov 2011 17:07:56 GMT"}, {"version": "v3", "created": "Wed, 15 Feb 2012 15:13:02 GMT"}, {"version": "v4", "created": "Tue, 27 Mar 2012 09:47:43 GMT"}, {"version": "v5", "created": "Sat, 9 Mar 2013 17:16:26 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Berman", "Piotr", ""], ["DasGupta", "Bhaskar", ""], ["Kaligounder", "Lakshmi", ""], ["Karpinski", "Marek", ""]]}, {"id": "1110.3711", "submitter": "Alejandro J.C. Crespo", "authors": "Jose M. Dom\\'inguez, Alejandro J.C. Crespo and Moncho G\\'omez-Gesteira", "title": "Optimization strategies for parallel CPU and GPU implementations of a\n  meshfree particle method", "comments": "18 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the current focus in high performance computing (HPC) for\ncomputational fluid dynamics (CFD) deals with grid based methods. However,\nparallel implementations for new meshfree particle methods such as Smoothed\nParticle Hydrodynamics (SPH) are less studied. In this work, we present\noptimizations for both central processing unit (CPU) and graphics processing\nunit (GPU) of a SPH method. These optimization strategies can be further\napplied to many other meshfree methods. The obtained performance for each\narchitecture and a comparison between the most efficient implementations for\nCPU and GPU are shown.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 15:54:48 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 09:49:40 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2011 08:32:50 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Dom\u00ednguez", "Jose M.", ""], ["Crespo", "Alejandro J. C.", ""], ["G\u00f3mez-Gesteira", "Moncho", ""]]}, {"id": "1110.5091", "submitter": "Debora Marks", "authors": "Debora S. Marks, Lucy J. Colwell, Robert Sheridan, Thomas A. Hopf,\n  Andrea Pagnani, Riccardo Zecchina, Chris Sander", "title": "3D Protein Structure Predicted from Sequence", "comments": "Debora S Marks and Lucy J Colwell are joint first authors. Supplement\n  and Appendices at: http://cbio.mskcc.org/foldingproteins. Updated version\n  25-Oct-2011 with '3D' added to the title and corrections of details in the\n  methods section to make it compatible with derivation of equations in the\n  main text and in the supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CE physics.bio-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolutionary trajectory of a protein through sequence space is\nconstrained by function and three-dimensional (3D) structure. Residues in\nspatial proximity tend to co-evolve, yet attempts to invert the evolutionary\nrecord to identify these constraints and use them to computationally fold\nproteins have so far been unsuccessful. Here, we show that co-variation of\nresidue pairs, observed in a large protein family, provides sufficient\ninformation to determine 3D protein structure. Using a data-constrained maximum\nentropy model of the multiple sequence alignment, we identify pairs of\nstatistically coupled residue positions which are expected to be close in the\nprotein fold, termed contacts inferred from evolutionary information (EICs). To\nassess the amount of information about the protein fold contained in these\ncoupled pairs, we evaluate the accuracy of predicted 3D structures for proteins\nof 50-260 residues, from 15 diverse protein families, including a G-protein\ncoupled receptor. These structure predictions are de novo, i.e., they do not\nuse homology modeling or sequence-similar fragments from known structures. The\nresulting low C{\\alpha}-RMSD error range of 2.7-5.1{\\AA}, over at least 75% of\nthe protein, indicates the potential for predicting essentially correct 3D\nstructures for the thousands of protein families that have no known structure,\nprovided they include a sufficiently large number of divergent sample\nsequences. With the current enormous growth in sequence information based on\nnew sequencing technology, this opens the door to a comprehensive survey of\nprotein 3D structures, including many not currently accessible to the\nexperimental methods of structural genomics. This advance has potential\napplications in many biological contexts, such as synthetic biology,\nidentification of functional sites in proteins and interpretation of the\nfunctional impact of genetic variants.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2011 22:02:12 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2011 18:59:33 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Marks", "Debora S.", ""], ["Colwell", "Lucy J.", ""], ["Sheridan", "Robert", ""], ["Hopf", "Thomas A.", ""], ["Pagnani", "Andrea", ""], ["Zecchina", "Riccardo", ""], ["Sander", "Chris", ""]]}, {"id": "1110.5265", "submitter": "Eric  Werner", "authors": "Eric Werner", "title": "On Programs and Genomes", "comments": "This a slightly extended version of Part I of a position paper\n  distributed on November 18, 2007 to the participants of our Balliol Seminar\n  on the Conceptual Foundations of Systems Biology. It presented my ideas on\n  the global control architecture of genomes. Denis Noble and myself started\n  the seminar in the Michaelmas term in the autumn of 2006 at Balliol College,\n  University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline the global control architecture of genomes. A theory of genomic\ncontrol information is presented. The concept of a developmental control\nnetwork called a cene (for control gene) is introduced. We distinguish\nparts-genes from control genes or cenes. Cenes are interpreted and executed by\nthe cell and, thereby, direct cell actions including communication, growth,\ndivision, differentiation and multi-cellular development. The cenome is the\nglobal developmental control network in the genome. The cenome is also a cene\nthat consists of interlinked sub-cenes that guide the ontogeny of the organism.\nThe complexity of organisms is linked to the complexity of the cenome. The\nrelevance to ontogeny and evolution is mentioned. We introduce the concept of a\nuniversal cell and a universal genome.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2011 15:49:30 GMT"}], "update_date": "2011-10-25", "authors_parsed": [["Werner", "Eric", ""]]}, {"id": "1110.5765", "submitter": "Yiannis Andreopoulos", "authors": "Davide Anastasia and Yiannis Andreopoulos", "title": "Throughput-Distortion Computation Of Generic Matrix Multiplication:\n  Toward A Computation Channel For Digital Signal Processing Systems", "comments": "IEEE Transactions on Signal Processing (vol. 60, 2012)", "journal-ref": null, "doi": "10.1109/TSP.2011.2176337", "report-no": null, "categories": "cs.MS cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The generic matrix multiply (GEMM) function is the core element of\nhigh-performance linear algebra libraries used in many\ncomputationally-demanding digital signal processing (DSP) systems. We propose\nan acceleration technique for GEMM based on dynamically adjusting the\nimprecision (distortion) of computation. Our technique employs adaptive scalar\ncompanding and rounding to input matrix blocks followed by two forms of packing\nin floating-point that allow for concurrent calculation of multiple results.\nSince the adaptive companding process controls the increase of concurrency (via\npacking), the increase in processing throughput (and the corresponding increase\nin distortion) depends on the input data statistics. To demonstrate this, we\nderive the optimal throughput-distortion control framework for GEMM for the\nbroad class of zero-mean, independent identically distributed, input sources.\nOur approach converts matrix multiplication in programmable processors into a\ncomputation channel: when increasing the processing throughput, the output\nnoise (error) increases due to (i) coarser quantization and (ii) computational\nerrors caused by exceeding the machine-precision limitations. We show that,\nunder certain distortion in the GEMM computation, the proposed framework can\nsignificantly surpass 100% of the peak performance of a given processor. The\npractical benefits of our proposal are shown in a face recognition system and a\nmulti-layer perceptron system trained for metadata learning from a large music\nfeature database.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2011 11:17:21 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Anastasia", "Davide", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1110.5865", "submitter": "Eric  Werner", "authors": "Eric Werner", "title": "Cancer Networks: A general theoretical and computational framework for\n  understanding cancer", "comments": "Key words: Cancer networks, cene, cenome, developmental control\n  networks, stem cells, stem cell networks, cancer stem cells, stochastic stem\n  cell networks, metastases hierarchy, linear networks, exponential networks,\n  geometric cancer networks, cell signaling, cancer cell communication\n  networks, systems biology, computational biology, multiagent systems,\n  muticellular modeling, cancer modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE cs.MA q-bio.CB q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general computational theory of cancer and its developmental\ndynamics. The theory is based on a theory of the architecture and function of\ndevelopmental control networks which guide the formation of multicellular\norganisms. Cancer networks are special cases of developmental control networks.\nCancer results from transformations of normal developmental networks. Our\ntheory generates a natural classification of all possible cancers based on\ntheir network architecture. Each cancer network has a unique topology and\nsemantics and developmental dynamics that result in distinct clinical tumor\nphenotypes. We apply this new theory with a series of proof of concept cases\nfor all the basic cancer types. These cases have been computationally modeled,\ntheir behavior simulated and mathematically described using a multicellular\nsystems biology approach. There are fascinating correspondences between the\ndynamic developmental phenotype of computationally modeled {\\em in silico}\ncancers and natural {\\em in vivo} cancers. The theory lays the foundation for a\nnew research paradigm for understanding and investigating cancer. The theory of\ncancer networks implies that new diagnostic methods and new treatments to cure\ncancer will become possible.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2011 18:07:37 GMT"}], "update_date": "2011-11-16", "authors_parsed": [["Werner", "Eric", ""]]}, {"id": "1110.6317", "submitter": "Yun Shen", "authors": "Yun Shen and Wilhelm Stannat and Klaus Obermayer", "title": "Risk-sensitive Markov control processes", "comments": "21 pages", "journal-ref": "SIAM J. Control Optim., 51(5), 3652-3672, 2013", "doi": "10.1137/120899005", "report-no": null, "categories": "math.OC cs.CE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for measuring risk in the context of Markov\ncontrol processes with risk maps on general Borel spaces that generalize known\nconcepts of risk measures in mathematical finance, operations research and\nbehavioral economics. Within the framework, applying weighted norm spaces to\nincorporate also unbounded costs, we study two types of infinite-horizon\nrisk-sensitive criteria, discounted total risk and average risk, and solve the\nassociated optimization problems by dynamic programming. For the discounted\ncase, we propose a new discount scheme, which is different from the\nconventional form but consistent with the existing literature, while for the\naverage risk criterion, we state Lyapunov-like stability conditions that\ngeneralize known conditions for Markov chains to ensure the existence of\nsolutions to the optimality equation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2011 12:37:44 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2011 00:13:07 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2013 14:34:38 GMT"}, {"version": "v4", "created": "Sun, 17 Nov 2013 10:07:22 GMT"}, {"version": "v5", "created": "Thu, 23 Jan 2014 21:43:23 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Shen", "Yun", ""], ["Stannat", "Wilhelm", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1110.6739", "submitter": "Paola Bonizzoni", "authors": "Paola Bonizzoni and Chiara Braghin and Riccardo Dondi and Gabriella\n  Trucco", "title": "The Binary Perfect Phylogeny with Persistent characters", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary perfect phylogeny model is too restrictive to model biological\nevents such as back mutations. In this paper we consider a natural\ngeneralization of the model that allows a special type of back mutation. We\ninvestigate the problem of reconstructing a near perfect phylogeny over a\nbinary set of characters where characters are persistent: characters can be\ngained and lost at most once. Based on this notion, we define the problem of\nthe Persistent Perfect Phylogeny (referred as P-PP). We restate the P-PP\nproblem as a special case of the Incomplete Directed Perfect Phylogeny, called\nIncomplete Perfect Phylogeny with Persistent Completion, (refereed as IP-PP),\nwhere the instance is an incomplete binary matrix M having some missing\nentries, denoted by symbol ?, that must be determined (or completed) as 0 or 1\nso that M admits a binary perfect phylogeny. We show that the IP-PP problem can\nbe reduced to a problem over an edge colored graph since the completion of each\ncolumn of the input matrix can be represented by a graph operation. Based on\nthis graph formulation, we develop an exact algorithm for solving the P-PP\nproblem that is exponential in the number of characters and polynomial in the\nnumber of species.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2011 10:17:52 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 14:08:44 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Bonizzoni", "Paola", ""], ["Braghin", "Chiara", ""], ["Dondi", "Riccardo", ""], ["Trucco", "Gabriella", ""]]}]