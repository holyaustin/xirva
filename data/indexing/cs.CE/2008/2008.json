[{"id": "2008.00018", "submitter": "Homayoun Valafar", "authors": "Michael Bryson, Xijiang Miao, Homayoun Valafar", "title": "Process of Efficiently Parallelizing a Protein Structure Determination\n  Algorithm", "comments": "7 pages published in PDPA2006", "journal-ref": "PDPTA 2006: 320-326", "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.NA math.NA q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational protein structure determination involves optimization in a\nproblem space much too large to exhaustively search. Existing approaches\ninclude optimization algorithms such as gradient descent and simulated\nannealing, but these typically only find local minima. One novel approach\nimplemented in REDcRAFT is to instead of folding a protein all at the same\ntime, fold it residue by residue. This simulates a protein folding as each\nresidue exits from the generating ribosome. While REDcRAFT exponentially\nreduces the problem space so it can be explored in polynomial time, it is still\nextremely computationally demanding. This algorithm does have the advantage\nthat most of the execution time is spent in inherently parallelizable code.\nHowever, preliminary results from parallel execution indicate that\napproximately two-thirds of execution time is dedicated to system overhead.\nAdditionally, by carefully analyzing and timing the structure of the program\nthe major bottlenecks can be identified. After addressing these issues,\nREDcRAFT becomes a scalable parallel application with nearly two orders of\nmagnitude improvement.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:04:39 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bryson", "Michael", ""], ["Miao", "Xijiang", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2008.00263", "submitter": "Francesco Bardozzo", "authors": "Francesco Bardozzo, Pietro Li\\`o, Roberto Tagliaferri", "title": "Signal metrics analysis of oscillatory patterns in bacterial multi-omic\n  networks", "comments": "8 pages, 5 figure, 3 algorithms, journal paper", "journal-ref": null, "doi": "10.1093/bioinformatics/btaa966", "report-no": null, "categories": "q-bio.MN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: One of the branches of Systems Biology is focused on a deep\nunderstanding of underlying regulatory networks through the analysis of the\nbiomolecules oscillations and their interplay. Synthetic Biology exploits gene\nor/and protein regulatory networks towards the design of oscillatory networks\nfor producing useful compounds. Therefore, at different levels of application\nand for different purposes, the study of biomolecular oscillations can lead to\ndifferent clues about the mechanisms underlying living cells. It is known that\nnetwork-level interactions involve more than one type of biomolecule as well as\nbiological processes operating at multiple omic levels. Combining\nnetwork/pathway-level information with genetic information it is possible to\ndescribe well-understood or unknown bacterial mechanisms and organism-specific\ndynamics. Results: Network multi-omic integration has led to the discovery of\ninteresting oscillatory signals. Following the methodologies used in signal\nprocessing and communication engineering, a new methodology is introduced to\nidentify and quantify the extent of the multi-omic oscillations of the signal.\nNew signal metrics are designed to allow further biotechnological explanations\nand provide important clues about the oscillatory nature of the pathways and\ntheir regulatory circuits. Our algorithms designed for the analysis of\nmulti-omic signals are tested and validated on 11 different bacteria for\nthousands of multi-omic signals perturbed at the network level by different\nexperimental conditions. Information on the order of genes, codon usage, gene\nexpression, and protein molecular weight is integrated at three different\nfunctional levels. Oscillations show interesting evidence that network-level\nmulti-omic signals present a synchronized response to perturbations and\nevolutionary relations along with taxa.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 13:27:53 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bardozzo", "Francesco", ""], ["Li\u00f2", "Pietro", ""], ["Tagliaferri", "Roberto", ""]]}, {"id": "2008.00861", "submitter": "Andrew Weinert", "authors": "Andrew Weinert, Ngaire Underhill, Bilal Gill, Ashley Wicks", "title": "Processing of Crowdsourced Observations of Aircraft in a High\n  Performance Computing Environment", "comments": "6 pages, 4 figures, 4 tables", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286229", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As unmanned aircraft systems (UASs) continue to integrate into the U.S.\nNational Airspace System (NAS), there is a need to quantify the risk of\nairborne collisions between unmanned and manned aircraft to support regulation\nand standards development. Both regulators and standards developing\norganizations have made extensive use of Monte Carlo collision risk analysis\nsimulations using probabilistic models of aircraft flight. We've previously\ndetermined that the observations of manned aircraft by the OpenSky Network, a\ncommunity network of ground-based sensors, are appropriate to develop models of\nthe low altitude environment. This works overviews the high performance\ncomputing workflow designed and deployed on the Lincoln Laboratory\nSupercomputing Center to process 3.9 billion observations of aircraft. We then\ntrained the aircraft models using more than 250,000 flight hours at 5,000 feet\nabove ground level or below. A key feature of the workflow is that all the\naircraft observations and supporting datasets are available as open source\ntechnologies or been released to the public domain.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 13:29:20 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Weinert", "Andrew", ""], ["Underhill", "Ngaire", ""], ["Gill", "Bilal", ""], ["Wicks", "Ashley", ""]]}, {"id": "2008.01066", "submitter": "Xiu Yang", "authors": "Yixiang Deng, Guang Lin and Xiu Yang", "title": "Multifidelity Data Fusion via Gradient-Enhanced Gaussian Process\n  Regression", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0151", "report-no": null, "categories": "cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data fusion method based on multi-fidelity Gaussian process\nregression (GPR) framework. This method combines available data of the quantity\nof interest (QoI) and its gradients with different fidelity levels, namely, it\nis a Gradient-enhanced Cokriging method (GE-Cokriging). It provides the\napproximations of both the QoI and its gradients simultaneously with\nuncertainty estimates. We compare this method with the conventional\nmulti-fidelity Cokriging method that does not use gradients information, and\nthe result suggests that GE-Cokriging has a better performance in predicting\nboth QoI and its gradients. Moreover, GE-Cokriging even shows better\ngeneralization result in some cases where Cokriging performs poorly due to the\nsingularity of the covariance matrix. We demonstrate the application of\nGE-Cokriging in several practical cases including reconstructing the\ntrajectories and velocity of an underdamped oscillator with respect to time\nsimultaneously, and investigating the sensitivity of power factor of a load bus\nwith respect to varying power inputs of a generator bus in a large scale power\nsystem. We also show that though GE-Cokriging method requires a little bit\nhigher computational cost than Cokriging method, the result of accuracy\ncomparison shows that this cost is usually worth it.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:57:12 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Deng", "Yixiang", ""], ["Lin", "Guang", ""], ["Yang", "Xiu", ""]]}, {"id": "2008.01512", "submitter": "Fleurianne Bertrand", "authors": "Fleurianne Bertrand, Lena Lambers, Tim Ricken", "title": "Least Squares Finite Element Method for Hepatic Sinusoidal Blood Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simulation of complex biological systems such as the description of blood\nflow in organs requires a lot of computational power as well as a detailed\ndescription of the organ physiology. We present a novel Least-Squares\ndiscretization method for the simulation of sinusoidal blood flow in liver\nlobules using a porous medium approach for the liver tissue. The scaling of the\ndifferent Least-Squares terms leads to a robust algorithm and the inherent\nerror estimator provides an efficient refinement strategy.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:26:10 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Bertrand", "Fleurianne", ""], ["Lambers", "Lena", ""], ["Ricken", "Tim", ""]]}, {"id": "2008.01516", "submitter": "Christoph B\\\"ohm", "authors": "Christoph B\\\"ohm (1), Bla\\v{z} Hudobivnik (1), Michele Marino (1 and\n  2), Peter Wriggers (1) ((1) Institute of Continuum Mechanics, Leibniz\n  University Hanover, Garbsen, Germany, (2) Dep. of Civil Eng. and Computer\n  Science, University Rome Tor Vergata, Rome, Italy)", "title": "Electro-magneto-mechanically response of polycrystalline materials:\n  Computational Homogenization via the Virtual Element Method", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2021.113775", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a study on the computational homogenization of\nelectro-magneto-mechanically coupled problems through the Virtual Element\nMethod (VEM). VE-approaches have great potential for the homogenization of the\nphysical properties of heterogeneous polycrystalline microstructures with\nanisotropic grains. The flexibility in element shapes can be exploited for\ncreating VE-mesh with a significant lower number of degrees of freedom if\ncompared to finite element (FE) meshes, while maintaining a high accuracy.\nEvidence that VE-approaches outperform FEM are available in the literature, but\nonly addressing purely-mechanic problems (i.e. elastic properties) and\ntransversely anisotropic materials. The aim of this work is twofold. On one\nhand, the study compares VE-and FE-based numerical homogenization schemes for\nelectro-mechanically coupled problems for different crystal lattice structures\nand degrees of elastic anisotropy. Within all considered materials, the\nVE-approach outperforms the FE-approach for the same number of nodes. On the\nother hand a hybrid microstructure made up by both electro-mechanical and\nmagneto-mechanical grains is investigated resulting in a\nelectro-magneto-mechanically coupled microstructure. Again, VEM provides a more\naccurate solution strategy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 13:38:42 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["B\u00f6hm", "Christoph", "", "1 and\n  2"], ["Hudobivnik", "Bla\u017e", "", "1 and\n  2"], ["Marino", "Michele", "", "1 and\n  2"], ["Wriggers", "Peter", ""]]}, {"id": "2008.01539", "submitter": "Jiamin Jiang", "authors": "Jiamin Jiang", "title": "Localized Nonlinear Solution Strategies for Efficient Simulation of\n  Unconventional Reservoirs", "comments": null, "journal-ref": "Applied Mathematical Modelling 2020", "doi": "10.1016/j.apm.2020.10.018", "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient numerical simulation of unconventional reservoirs is\nchallenging. Long periods of transient flow and steep potential gradients occur\ndue to the extreme conductivity contrast between matrix and fracture. Detailed\nnear-well/near-fracture models are necessary to provide sufficient resolution,\nbut they are computationally impractical for field cases with multiple fracture\nstages. Previous works in the literature of unconventional simulations mainly\nfocus on gridding level that adapts to wells and fractures. Limited research\nhas been conducted on nonlinear strategies that exploit locality across\ntimesteps and nonlinear iterations. To perform localized computations, an\na-priori strategy is essential to first determine the active subset of\nsimulation cells for the subsequent iteration. The active set flags the cells\nthat will be updated, and then the corresponding localized linear system is\nsolved. This work develops localization methods that are readily applicable to\ncomplex fracture networks and flow physics in unconventional reservoirs. By\nutilizing the diffusive nature of pressure updates, an adaptive algorithm is\nproposed to make adequate estimates for the active domains. In addition, we\ndevelop a localized solver based on nonlinear domain decomposition (DD).\nComparing to a standard DD method, domain partitions are dynamically\nconstructed. The new solver provides effective partitioning that adapts to flow\ndynamics and Newton updates. We evaluate the developed methods using several\ncomplex problems with discrete fracture networks. The results show that large\ndegrees of solution locality present across timesteps and iterations. Comparing\nto a standard Newton solver, the new solvers enable superior computational\nperformance. Moreover, Newton convergence behavior is preserved, without any\nimpact on solution accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 21:44:04 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 15:03:32 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Jiang", "Jiamin", ""]]}, {"id": "2008.02862", "submitter": "Shane McQuarrie", "authors": "Shane A. McQuarrie, Cheng Huang, Karen E. Willcox", "title": "Data-driven reduced-order models via regularized operator inference for\n  a single-injector combustion process", "comments": "To appear in the Journal of the Royal Society of New Zealand. See\n  https://github.com/Willcox-Research-Group/ROM-OpInf-Combustion-2D for code\n  and additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper derives predictive reduced-order models for rocket engine\ncombustion dynamics via Operator Inference, a scientific machine learning\napproach that blends data-driven learning with physics-based modeling. The\nnon-intrusive nature of the approach enables variable transformations that\nexpose system structure. The specific contribution of this paper is to advance\nthe formulation robustness and algorithmic scalability of the Operator\nInference approach. Regularization is introduced to the formulation to avoid\nover-fitting. The task of determining an optimal regularization is posed as an\noptimization problem that balances training error and stability of long-time\nintegration dynamics. A scalable algorithm and open-source implementation are\npresented, then demonstrated for a single-injector rocket combustion example.\nThis example exhibits rich dynamics that are difficult to capture with\nstate-of-the-art reduced models. With appropriate regularization and an\ninformed selection of learning variables, the reduced-order models exhibit high\naccuracy in re-predicting the training regime and acceptable accuracy in\npredicting future dynamics, while achieving close to a million times speedup in\ncomputational cost. When compared to a state-of-the-art model reduction method,\nthe Operator Inference models provide the same or better accuracy at\napproximately one thousandth of the computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:26:48 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 21:01:34 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["McQuarrie", "Shane A.", ""], ["Huang", "Cheng", ""], ["Willcox", "Karen E.", ""]]}, {"id": "2008.03186", "submitter": "Guotong Ren", "authors": "Guotong Ren and Rami M. Younis", "title": "An integrated numerical model for coupled poro-hydro-mechanics and\n  fracture propagation using embedded meshes", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113606", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated models for fluid-driven fracture propagation and general\nmultiphase flow in porous media are valuable to the study and engineering of\nseveral systems, including hydraulic fracturing, underground disposal of waste,\nand geohazard mitigation across such applications. This work extends the\ncoupled model multiphase flow and poromechanical model of\n\\cite{ren2018embedded} to admit fracture propagation (FP). The coupled\nXFEM-EDFM scheme utilizes a separate fracture mesh that is embedded on a static\nbackground mesh. The onset and dynamics of fracture propagation (FP) are\ngoverned by the equivalent stress intensity factor (SIF) criterion. A\ndomain-integral method (J integral) is applied to compute this information. An\nadaptive time-marching scheme is proposed to rapidly restrict and grow temporal\nresolution to match the underlying time-scales. The proposed model is verified\nwith analytical solutions, and shows the capability to accurately and\nadaptively co-simulate fluid transport and deformation as well as the\npropagation of multiple fractures.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:47:52 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ren", "Guotong", ""], ["Younis", "Rami M.", ""]]}, {"id": "2008.03375", "submitter": "Viktor Nikitin", "authors": "Viktor Nikitin, Vincent De Andrade, Azat Slyamov, Benjamin J. Gould,\n  Yuepeng Zhang, Vandana Sampathkumar, Narayanan Kasthuri, Doga Gursoy,\n  Francesco De Carlo", "title": "Distributed optimization for nonrigid nano-tomography", "comments": null, "journal-ref": null, "doi": "10.1109/TCI.2021.3060915", "report-no": null, "categories": "cs.CE cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resolution level and reconstruction quality in nano-computed tomography\n(nano-CT) are in part limited by the stability of microscopes, because the\nmagnitude of mechanical vibrations during scanning becomes comparable to the\nimaging resolution, and the ability of the samples to resist beam damage during\ndata acquisition. In such cases, there is no incentive in recovering the sample\nstate at different time steps like in time-resolved reconstruction methods, but\ninstead the goal is to retrieve a single reconstruction at the highest possible\nspatial resolution and without any imaging artifacts. Here we propose a joint\nsolver for imaging samples at the nanoscale with projection alignment,\nunwarping and regularization. Projection data consistency is regulated by dense\noptical flow estimated by Farneback's algorithm, leading to sharp sample\nreconstructions with less artifacts. Synthetic data tests show robustness of\nthe method to Poisson and low-frequency background noise. Applicability of the\nmethod is demonstrated on two large-scale nano-imaging experimental data sets.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 19:22:43 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 17:14:31 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Nikitin", "Viktor", ""], ["De Andrade", "Vincent", ""], ["Slyamov", "Azat", ""], ["Gould", "Benjamin J.", ""], ["Zhang", "Yuepeng", ""], ["Sampathkumar", "Vandana", ""], ["Kasthuri", "Narayanan", ""], ["Gursoy", "Doga", ""], ["De Carlo", "Francesco", ""]]}, {"id": "2008.04079", "submitter": "Artem Lunev", "authors": "Artem Lunev, Vadim Zborovskii and Teymur Aliev", "title": "Complexity matters: highly-accurate numerical models of coupled\n  radiative-conductive heat transfer in a laser flash experiment", "comments": "39 pages, 13 figures, 6 tables", "journal-ref": null, "doi": "10.1016/j.ijthermalsci.2020.106695", "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal diffusivity measurements of samples transmitting thermal radiation\nrequire adjustments to the data treatment procedures in laser flash analysis.\nConventionally, an unconstrained diathermic model is used. Current results show\nthat the alternative coupled radiative-conductive models produce substantially\ndifferent results -- for instance, at high temperatures in oxide ceramics.\nHowever, care must be taken to ensure accurate implementations of each\nconstituent computational technique. The latter are presented in this work.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 18:22:23 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Lunev", "Artem", ""], ["Zborovskii", "Vadim", ""], ["Aliev", "Teymur", ""]]}, {"id": "2008.04098", "submitter": "Tomasz Waclawczyk PhD", "authors": "Tomasz Wac{\\l}awczyk", "title": "Modeling of non-equilibrium effects in intermittency region between two\n  phases", "comments": "The paper accepted for publication to International Journal of\n  Multiphase Flow", "journal-ref": null, "doi": "10.1016/j.ijmultiphaseflow.2020.103459", "report-no": null, "categories": "physics.flu-dyn cond-mat.mes-hall cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns modeling of the evolution of intermittency region between\ntwo weakly miscible phases due to temporal and spatial variations of its\ncharacteristic length scale. First, the need of a more general description\nallowing for the evolution of intermittency region is rationalized. Afterwards,\nresults of the previous work (Wac{\\l}awczyk T., 2017, On a relation between the\nvolume of fluid, level-set and phase field interface models, Int. J. Multiphas.\nFlow, Vol. 97) are discussed in context of the sharp interface models known in\nthe literature and insight into droplet coalescence mechanism recently\nrecognized in the molecular dynamics studies (Perumanath S., Borg M.K.,\nChubynsky M.V., Sprittles J.E., Reese J.M., 2019, Droplet coalescence is\ninitiated by thermal motion, Phys. Rev. Lett., Vol. 122). Finally, the physical\nand numerical models extending applicability of the equilibrium solution to the\ncase when intermittency region could also be in the non-equilibrium state is\nintroduced and verified in several test cases.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:12:20 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 14:34:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wac\u0142awczyk", "Tomasz", ""]]}, {"id": "2008.04356", "submitter": "Andrea Beck", "authors": "Jakob D\\\"urrw\\\"achter, Marius Kurz, Patrick Kopper, Daniel Kempf,\n  Claus-Dieter Munz, Andrea Beck", "title": "An Efficient Sliding Mesh Interface Method for High-Order Discontinuous\n  Galerkin Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliding meshes are a powerful method to treat deformed domains in\ncomputational fluid dynamics, where different parts of the domain are in\nrelative motion. In this paper, we present an efficient implementation of a\nsliding mesh method into a discontinuous Galerkin compressible Navier-Stokes\nsolver and its application to a large eddy simulation of a 1-1/2 stage turbine.\nThe method is based on the mortar method and is high-order accurate. It can\nhandle three-dimensional sliding mesh interfaces with various interface shapes.\nFor plane interfaces, which are the most common case, conservativity and\nfree-stream preservation are ensured. We put an emphasis on efficient parallel\nimplementation. Our implementation generates little computational and storage\noverhead. Inter-node communication via MPI in a dynamically changing mesh\ntopology is reduced to a bare minimum by ensuring a priori information about\ncommunication partners and data sorting. We provide performance and scaling\nresults showing the capability of the implementation strategy. Apart from\nanalytical validation computations and convergence results, we present a\nwall-resolved implicit LES of the 1-1/2 stage Aachen turbine test case as a\nlarge scale practical application example.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 18:39:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["D\u00fcrrw\u00e4chter", "Jakob", ""], ["Kurz", "Marius", ""], ["Kopper", "Patrick", ""], ["Kempf", "Daniel", ""], ["Munz", "Claus-Dieter", ""], ["Beck", "Andrea", ""]]}, {"id": "2008.04382", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Mohammad Amin Hariri-Ardebili, Farhad Pourkamali-Anaraki, Siamak\n  Sattar", "title": "Uncertainty Quantification of Structural Systems with Subset of Data", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification of the impact of uncertainty in material properties as well as\nthe input ground motion on structural responses is an important step in\nimplementing a performance-based earthquake engineering (PBEE) framework. Among\nvarious sources of uncertainty, the variability in the input ground motions,\na.k.a. record-to-record, greatly affects the assessment results. The objective\nof this paper is to quantify the uncertainty in structural response with hybrid\nuncertainty sources. In this paper, multiple matrix completion methods are\nproposed and applied on a case study structure. The matrix completion method is\na means to estimate the analyses results for the entire set of input parameters\nby conducting analysis for only a small subset of analyses. The main\nalgorithmic contributions of our proposed method are twofold. First, we develop\na sampling technique for choosing a subset of representative simulations, which\nallows improving the accuracy of the estimated response. An unsupervised\nmachine learning technique is used for this purpose. Next, the proposed matrix\ncompletion method for uncertainty quantification is further refined by\nincorporating a regression model that is trained on the available partial\nsimulations. The regression model improves the initial sampling as it provides\na rough estimation of the structural responses. Finally, the proposed algorithm\nis applied to a multi-degree-of-freedom system, and the structural responses\n(i.e., displacements and base shear) are estimated. Results show that the\nproposed algorithm can effectively estimate the response from a full set of\nnonlinear simulations by conducting analyses only on a small portion of the\nset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 00:20:40 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Hariri-Ardebili", "Mohammad Amin", ""], ["Pourkamali-Anaraki", "Farhad", ""], ["Sattar", "Siamak", ""]]}, {"id": "2008.04703", "submitter": "Amir Mosavi Prof", "authors": "Ali Sahragard, Hamid Falaghi, Mahdi Farhadi, Amir Mosavi, Abouzar\n  Estebsari", "title": "Generation expansion planning in the presence of wind power plants using\n  a genetic algorithm model", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the essential aspects of power system planning is generation expansion\nplanning (GEP). The purpose of GEP is to enhance construction planning and\nreduce the costs of installing different types of power plants. This paper\nproposes a method based on Genetic Algorithm (GA) for GEP in the presence of\nwind power plants. Since it is desired to integrate the maximum possible wind\npower production in GEP, the constraints for incorporating different levels of\nwind energy in power generation are investigated comprehensively. This will\nallow obtaining the maximum reasonable amount of wind penetration in the\nnetwork. Besides, due to the existence of different wind regimes, the\npenetration of strong and weak wind on GEP is assessed. The results show that\nthe maximum utilization of wind power generation capacity could increase the\nexploitation of more robust wind regimes. Considering the growth of the wind\nfarm industry and the cost reduction for building wind power plants, the\nsensitivity of GEP to the variations of this cost is investigated. The results\nfurther indicate that for a 10% reduction in the initial investment cost of\nwind power plants, the proposed model estimates that the overall cost will be\nminimized.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 07:20:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Sahragard", "Ali", ""], ["Falaghi", "Hamid", ""], ["Farhadi", "Mahdi", ""], ["Mosavi", "Amir", ""], ["Estebsari", "Abouzar", ""]]}, {"id": "2008.04707", "submitter": "Florian Wirthm\\\"uller", "authors": "Lucas Eiermann, Florian Wirthm\\\"uller, Kay Massow, Gabi Breuel and\n  Ilja Radusch", "title": "Driver Assistance for Safe and Comfortable On-Ramp Merging Using\n  Environment Models Extended through V2X Communication and Role-Based Behavior\n  Predictions", "comments": "the article has been accepted for publication during the 16th IEEE\n  International Conference on Intelligent Computer Communication and Processing\n  (ICCP 2020), 8 pages, 8 figures, 1 table", "journal-ref": null, "doi": "10.1109/ICCP51029.2020.9266186", "report-no": null, "categories": "eess.SP cs.CE cs.ET cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern driver assistance systems as well as autonomous vehicles take their\ndecisions based on local maps of the environment. These maps include, for\nexample, surrounding moving objects perceived by sensors as well as routes and\nnavigation information. Current research in the field of environment mapping is\nconcerned with two major challenges. The first one is the integration of\ninformation from different sources e.g. on-board sensors like radar, camera,\nultrasound and lidar, offline map data or backend information. The second\nchallenge comprises in finding an abstract representation of this aggregated\ninformation with suitable interfaces for different driving functions and\ntraffic situations. To overcome these challenges, an extended environment model\nis a reasonable choice. In this paper, we show that role-based motion\npredictions in combination with v2x-extended environment models are able to\ncontribute to increased traffic safety and driving comfort. Thus, we combine\nthe mentioned research areas and show possible improvements, using the example\nof a threading process at a motorway access road. Furthermore, it is shown that\nalready an average v2x equipment penetration of 80% can lead to a significant\nimprovement of 0.33m/s^2 of the total acceleration and 12m more safety distance\ncompared to non v2x-equipped vehicles during the threading process.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 14:00:20 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 08:45:04 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 06:32:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Eiermann", "Lucas", ""], ["Wirthm\u00fcller", "Florian", ""], ["Massow", "Kay", ""], ["Breuel", "Gabi", ""], ["Radusch", "Ilja", ""]]}, {"id": "2008.05137", "submitter": "Zhenxing Cheng", "authors": "Zhenxing Cheng, Hu Wang, Gui-Rong Liu, Guangyao Li", "title": "Molecular dynamics simulation of crack growth in mono-crystal nickel\n  with voids and inclusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, the crack propagation of the pre-cracked mono-crystal nickel\nwith the voids and inclusions has been investigated by molecular dynamics\nsimulations. Different sizes of voids, inclusions and materials of inclusions\nare used to fully study the effect of the voids and inclusions during the crack\npropagation process. The dislocations evolution, stress distribution and crack\nlength are analyzed as the associated mechanical properties. The results\nindicate that the voids and inclusions can change the path of crack propagation\nof the pre-cracked mono-crystal nickel. Moreover, the results show that the\nvoids and inclusions can lead a better resistance to plastic deformation of the\nmono-crystal and the inclusions can make the system more difficult to fracture.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 07:11:18 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Cheng", "Zhenxing", ""], ["Wang", "Hu", ""], ["Liu", "Gui-Rong", ""], ["Li", "Guangyao", ""]]}, {"id": "2008.05254", "submitter": "Benjamin Marussig", "authors": "G. Radenkovi\\'c, A. Borkovi\\'c, B. Marussig", "title": "Nonlinear static isogeometric analysis of arbitrarily curved\n  Kirchhoff-Love shells", "comments": null, "journal-ref": "International Journal of Mechanical Sciences, Volume 192, 2021,\n  106143", "doi": "10.1016/j.ijmecsci.2020.106143", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The geometrically rigorous nonlinear analysis of elastic shells is considered\nin the context of finite, but small, strain theory. The research is focused on\nthe introduction of the full shell metric and examination of its influence on\nthe nonlinear structural response. The exact relation between the reference and\nequidistant strains is employed and the complete analytic elastic constitutive\nrelation between energetically conjugated forces and strains is derived via the\nreciprocal shift tensor. Utilizing these strict relations, the geometric\nstiffness matrix is derived explicitly by the variation of the unknown metric.\nMoreover, a compact form of this matrix is presented. Despite the linear\ndisplacement distribution due to the Kirchhoff-Love hypothesis, a nonlinear\nstrain distribution arises along the shell thickness. This fact is sometimes\ndisregarded for the nonlinear analysis of thin shells based on the initial\ngeometry, thereby ignoring the strong curviness of a shell at some subsequent\nconfiguration. We show that the curviness of a shell at each configuration\ndetermines the appropriate shell formulation. For shells that become strongly\ncurved at some configurations during deformation, the nonlinear distribution of\nstrain throughout the thickness must be considered in order to obtain accurate\nresults. We investigate four computational models: one based on the full\nanalytical constitutive relation, and three simplified ones. Robustness,\nefficiency and accuracy of the presented formulation are examined via selected\nnumerical experiments. Our main finding is that the employment of the full\nmetric is often required when the complete response of the shells is sought,\neven for the initially thin shells. Finally, the simplified model that provided\nthe best balance between efficiency and accuracy is suggested for the nonlinear\nanalysis of strongly curved shells.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 12:02:10 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 11:01:17 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Radenkovi\u0107", "G.", ""], ["Borkovi\u0107", "A.", ""], ["Marussig", "B.", ""]]}, {"id": "2008.05599", "submitter": "Udaya Pratap Singh", "authors": "Udaya Pratap Singh", "title": "A new operational matrix technique to solve linear boundary value\n  problems", "comments": "10 pages; 12 figures; 04 heads; 04 examples; 35 equations; 27\n  citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new technique is presented to solve a class of linear boundary value\nproblems (BVP). Technique is primarily based on an operational matrix developed\nfrom a set of modified Bernoulli polynomials. The new set of polynomials is an\northonormal set obtained with Gram-Schmidt orthogonalization applied to\nclassical Bernoulli polynomials. The presented method changes a given linear\nBVP into a system of algebraic equations which is solved to find an approximate\nsolution of BVP in form of a polynomial of required degree. The technique is\napplied to four problems and obtained approximate solutions are graphically\ncompared to available exact and other numerical solutions. The method is\nsimpler than many existing methods and provides a high degree of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 14:26:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Singh", "Udaya Pratap", ""]]}, {"id": "2008.06153", "submitter": "Takao Miki", "authors": "Takao Miki, Takayuki Yamada", "title": "Topology optimization considering the distortion in additive\n  manufacturing", "comments": "35 pages, 20 figures", "journal-ref": null, "doi": "10.1016/j.finel.2021.103558", "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive manufacturing is a free-form manufacturing technique in which parts\nare built in a layer-by-layer manner. Laser powder bed fusion is one of the\npopular techniques used to fabricate metal parts. However, it induces residual\nstress and distortion during fabrication that adversely affects the mechanical\nproperties and dimensional accuracy of the manufactured parts. Therefore,\npredicting and avoiding the residual stress and distortion are critical issues.\nIn this study, we propose a topology optimization method that accounts for the\ndistortion. First, we propose a computationally inexpensive analytical model\nfor additive manufacturing that uses laser powder bed fusion and formulated an\noptimization problem. Next, we approximate the topological derivative of the\nobjective function using an adjoint variable method that is then utilized to\nupdate the level set function via a time evolutionary reaction-diffusion\nequation. Finally, the validity and effectiveness of the proposed optimization\nmethod was established using two-dimensional design examples.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 01:18:46 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 05:12:30 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Miki", "Takao", ""], ["Yamada", "Takayuki", ""]]}, {"id": "2008.06216", "submitter": "Shunchuan Yang", "authors": "Xiaochao Zhou, Zekun Zhu, and Shunchuan Yang", "title": "Formulation of Single-Source Surface Integral Equation for\n  Electromagnetic Analysis of Composite Penetrable Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new single-source surface integral equation (SS-SIE) to\nmodel composite penetrable objects. In the proposed formulation, the surface\nelectric and magnetic fields on all interior boundaries are first eliminated\nthrough combining integral solutions inside each object. Then, by enforcing the\nsurface electric fields in the original and equivalent configurations are equal\nto each other, an equivalent model with only the electric current density on\nthe outermost boundaries is derived. Compared with other SIEs, like the PMCHWT\nformulation, all unknowns are residing on the outermost boundaries in the\nproposed formulation and therefore, less count of unknowns can be obtained.\nFinally, two numerical examples are carried out to validate the effectiveness\nof the proposed SS-SIE.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:25:05 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhou", "Xiaochao", ""], ["Zhu", "Zekun", ""], ["Yang", "Shunchuan", ""]]}, {"id": "2008.06360", "submitter": "Patrick Zulian", "authors": "Patrick Zulian, Philipp Sch\\\"adle, Liudmila Karagyaur, Maria Nestola", "title": "Comparison and Application of non-Conforming Mesh Models for Flow in\n  Fractured Porous Media using dual {L}agrange multipliers", "comments": "24 pages, 14 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geological settings with reservoir characteristics include fractures with\ndifferent material and geometrical properties. Hence, numerical simulations in\napplied geophysics demands for computational frameworks which efficiently allow\nto integrate various fracture geometries in a porous medium matrix. This study\npresents a modeling approach for single-phase flow in fractured porous media\nand its application to different types of non-conforming mesh models. We\npropose a combination of the Lagrange multiplier method with variational\ntransfer to allow for complex non-conforming geometries as well as hybrid- and\nequi-dimensional models and discretizations of flow through fractured porous\nmedia. The variational transfer is based on the $L^2$-projection and enables an\naccurate and highly efficient parallel projection of fields between\nnon-conforming meshes (e.g.,\\ between fracture and porous matrix domain). We\npresent the different techniques as a unified mathematical framework with a\npractical perspective. By means of numerical examples we discuss both,\nperformance and applicability of the particular strategies. Comparisons of\nfinite element simulation results to widely adopted 2D benchmark cases show\ngood agreement and the dual Lagrange multiplier spaces show good performance.\nIn an extension to 3D fracture networks, we first provide complementary results\nto a recently developed benchmark case, before we explore a complex scenario\nwhich leverages the different types of fracture meshes. Complex and highly\nconductive fracture networks are found more suitable in combination with\nembedded hybrid-dimensional fractures. However, thick and blocking fractures\nare better approximated by equi-dimensional embedded fractures and the\nequi-dimensional mortar method, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 13:27:08 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zulian", "Patrick", ""], ["Sch\u00e4dle", "Philipp", ""], ["Karagyaur", "Liudmila", ""], ["Nestola", "Maria", ""]]}, {"id": "2008.06841", "submitter": "Matloob Khushi Dr", "authors": "Zhiwen Zeng and Matloob Khushi", "title": "Wavelet Denoising and Attention-based RNN-ARIMA Model to Predict Forex\n  Price", "comments": null, "journal-ref": "IJCNN 2020", "doi": null, "report-no": null, "categories": "cs.CE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every change of trend in the forex market presents a great opportunity as\nwell as a risk for investors. Accurate forecasting of forex prices is a crucial\nelement in any effective hedging or speculation strategy. However, the complex\nnature of the forex market makes the predicting problem challenging, which has\nprompted extensive research from various academic disciplines. In this paper, a\nnovel approach that integrates the wavelet denoising, Attention-based Recurrent\nNeural Network (ARNN), and Autoregressive Integrated Moving Average (ARIMA) are\nproposed. Wavelet transform removes the noise from the time series to stabilize\nthe data structure. ARNN model captures the robust and non-linear relationships\nin the sequence and ARIMA can well fit the linear correlation of the sequential\ninformation. By hybridization of the three models, the methodology is capable\nof modelling dynamic systems such as the forex market. Our experiments on\nUSD/JPY five-minute data outperforms the baseline methods.\nRoot-Mean-Squared-Error (RMSE) of the hybrid approach was found to be 1.65 with\na directional accuracy of ~76%.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 05:32:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zeng", "Zhiwen", ""], ["Khushi", "Matloob", ""]]}, {"id": "2008.07115", "submitter": "Tao Yin", "authors": "Lu Zhang, Liwei Xu, Tao Yin", "title": "An accurate hyper-singular boundary integral equation method for dynamic\n  poroelasticity in two dimensions", "comments": "22 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the boundary integral equation method for\nsolving the exterior Neumann boundary value problem of dynamic poroelasticity\nin two dimensions. The main contribution of this work consists of two aspescts:\nthe proposal of a novel regularized boundary integral equation, and the\npresentation of new regularized formulations of the strongly-singular and\nhyper-singular boundary integral operators. Firstly, turning to the spectral\nproperties of the double-layer operator and the corresponding Calder\\'{o}n\nrelation of the poroelasticity, we propose the novel low-GMRES-iteration\nintegral equation whose eigenvalues are bounded away from zero and infinity.\nSecondly, with the help of the G\\\"{u}nter derivatives, we reformulate the\nstrongly-singular and hyper-singular integral operators into combinations of\nthe weakly-singular operators and the tangential derivatives. The accuracy and\nefficiency of the proposed methodology are demonstrated through several\nnumerical examples.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 06:43:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zhang", "Lu", ""], ["Xu", "Liwei", ""], ["Yin", "Tao", ""]]}, {"id": "2008.08064", "submitter": "Igor Shovkun", "authors": "I. Shovkun and T. Garipov and H. A. Tchelepi", "title": "Embedded Fracture Model for Coupled Flow and Geomechanics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluid injection and production cause changes in reservoir pressure, which\nresult in deformations in the subsurface. This phenomenon is particularly\nimportant in reservoirs with abundant fractures and faults because the induced\nslip and opening of the fractures may significantly alter their hydraulic\nproperties. Modeling strongly coupled poro-mechanical processes in naturally\nfractured reservoirs is a challenging problem. The Discrete Fracture Model\n(DFM) is a state-of-art method for modeling coupled flow and mechanics in\nfractured reservoirs. This method requires constructing computational grids\nthat comform to fractures, which is very challenging in complex 3D settings.\nThe objective of this study is to develop a numerical method that does not\nrequire gridding near fractures and can efficiently model hydromechanical\ninteractions in fractured reservoirs. We utilize formulations based on the\nStrong Discontinuity Approach (SDA) for mechanics and Embedded Discrete\nFracture Model (EDFM) for flow. We first present a mathematical formulation and\nemphasize the kinematic aspects of fracture slip and opening. We then introduce\na series of mechanical tests that investigate the spatial convergence of the\nmodel and compare its accuracy with the Discrete Fracture Model (DFM). We\nfinally consider a synthetic coupled case of a reservoir with several fractures\nand compare the performance of the SDA and DFM methods. Our results indicate\nsuper-linear spatial convergence of the proposed SDA algorithm. Numerical\nsimulations confirm the applicability of the proposed method to modeling the\ncoupling effects in subsurface applications.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:45:58 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Shovkun", "I.", ""], ["Garipov", "T.", ""], ["Tchelepi", "H. A.", ""]]}, {"id": "2008.08328", "submitter": "Maarten Blommaert", "authors": "Maarten Blommaert, Yannick Wack, Martine Baelmans", "title": "An adjoint optimization approach for the topological design of\n  large-scale district heating networks based on nonlinear models", "comments": null, "journal-ref": "Applied Energy, Vol. 280, 116025, 15 December 2020", "doi": "10.1016/j.apenergy.2020.116025", "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the problem of finding the best topology, pipe\ndiameter choices, and operation parameters for realistic district heating\nnetworks. Present design tools that employ non-linear flow and heat transport\nmodels for topological design are limited to small heating networks with up to\n20 potential consumers. We introduce an alternative adjoint-based numerical\noptimization strategy to enable large-scale nonlinear thermal network\noptimization. In order to avoid a strong computational cost scaling with the\nnetwork size, we aggregate consumer constraints with a constraint aggregation\nstrategy. Moreover, to align this continuous optimization strategy with the\ndiscrete nature of topology optimization and pipe size choices, we present a\nnumerical continuation strategy that gradually forces the design variables\ntowards discrete design choices. As such, optimal network topology and pipe\nsizes are determined simultaneously. Finally, we demonstrate the scalability of\nthe algorithm by designing a fictitious district heating network with 160\nconsumers. As a proof-of-concept, the network is optimized for minimal\ninvestment cost and pumping power, while keeping the heat supplied to the\nconsumers within a thermal comfort range of 5 %. Starting from a uniform\ndistribution of 15 cm wide piping throughout the network, the novel algorithm\nfinds a network lay-out that reduces piping investment by 23 % and pump-related\ncosts by a factor of 14 in less than an hour on a standard laptop. Moreover,\nthe importance of embedding the non-linear transport model is clear from a\ntemperature-induced variation in the consumer flow rates of 72 %.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:37:00 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 17:54:02 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Blommaert", "Maarten", ""], ["Wack", "Yannick", ""], ["Baelmans", "Martine", ""]]}, {"id": "2008.08482", "submitter": "Armin Galetzka", "authors": "Armin Galetzka, Dimitrios Loukrezis, Herbert De Gersem", "title": "Data-Driven Solvers for Strongly Nonlinear Material Response", "comments": "25 pages, 13 figures", "journal-ref": null, "doi": "10.1002/nme.6589", "report-no": null, "categories": "physics.comp-ph cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work presents a data-driven magnetostatic finite-element solver that is\nspecifically well-suited to cope with strongly nonlinear material responses.\nThe data-driven computing framework is essentially a multiobjective\noptimization procedure matching the material operation points as closely as\npossible to given material data while obeying Maxwell's equations. Here, the\nframework is extended with heterogeneous (local) weighting factors - one per\nfinite element - equilibrating the goal function locally according to the\nmaterial behavior. This modification allows the data-driven solver to cope with\nunbalanced measurement data sets, i.e. data sets suffering from unbalanced\nspace filling. This occurs particularly in the case of strongly nonlinear\nmaterials, which constitute problematic cases that hinder the efficiency and\naccuracy of standard data-driven solvers with a homogeneous (global) weighting\nfactor. The local weighting factors are embedded in the distance-minimizing\ndata-driven algorithm used for noiseless data, likewise for the maximum entropy\ndata-driven algorithm used for noisy data. Numerical experiments based on a\nquadrupole magnet model with a soft magnetic material show that the proposed\nmodification results in major improvements in terms of solution accuracy and\nsolver efficiency. For the case of noiseless data, local weighting factors\nimprove the convergence of the data-driven solver by orders of magnitude. When\nnoisy data are considered, the convergence rate of the data-driven solver is\ndoubled.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:42:27 GMT"}, {"version": "v2", "created": "Sun, 23 Aug 2020 11:13:04 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 10:27:08 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Galetzka", "Armin", ""], ["Loukrezis", "Dimitrios", ""], ["De Gersem", "Herbert", ""]]}, {"id": "2008.08902", "submitter": "Prabhat Kumar", "authors": "P. Kumar, C. Schmidleithner, N. B. Larsen and O. Sigmund", "title": "Topology Optimization and 3D printing of Large Deformation Compliant\n  Mechanisms for Straining Biological Tissues", "comments": "23 pages, 14 figures", "journal-ref": "Structural and Multidisciplinary Optimization, volume 63, 2021", "doi": "10.1007/s00158-020-02764-4", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a synthesis approach in a density-based topology\noptimization setting to design large deformation compliant mechanisms for\ninducing desired strains in biological tissues. The modelling is based on\ngeometrical nonlinearity together with a suitably chosen hypereleastic material\nmodel, wherein the mechanical equilibrium equations are solved using the total\nLagrangian finite element formulation. An objective based on least-square error\nwith respect to target strains is formulated and minimized with the given set\nof constraints and the appropriate surroundings of the tissues. To circumvent\nnumerical instabilities arising due to large deformation in low stiffness\ndesign regions during topology optimization, a strain-energy based\ninterpolation scheme is employed. The approach uses an extended robust\nformulation i.e. the eroded, intermediate and dilated projections for the\ndesign description as well as variation in tissue stiffness. Efficacy of the\nsynthesis approach is demonstrated by designing various compliant mechanisms\nfor providing different target strains in biological tissue constructs.\nOptimized compliant mechanisms are 3D-printed and their performances are\nrecorded in a simplified experiment and compared with simulation results\nobtained by a commercial software.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:42:48 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 09:40:04 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Kumar", "P.", ""], ["Schmidleithner", "C.", ""], ["Larsen", "N. B.", ""], ["Sigmund", "O.", ""]]}, {"id": "2008.09015", "submitter": "Ravindra Duddu", "authors": "Gourab Ghosh, Ravindra Duddu, Chandrasekhar Annavarapu", "title": "A stabilized finite element method for delamination analysis of\n  composites using cohesive elements", "comments": "32 pages, 20 figures, submitted to computational mechanics journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the ability of a stabilized finite element method, inspired by\nthe weighted Nitsche approach, to alleviate spurious traction oscillations at\ninterlaminar interfaces in multi-ply multi-directional composite laminates. In\ncontrast with the standard (penalty-like) method, the stabilized method allows\nthe use of arbitrarily large values of cohesive stiffness and obviates the need\nfor engineering approaches to estimate minimum cohesive stiffness necessary for\naccurate delamination analysis. This is achieved by defining a weighted\ninterface traction in the stabilized method, which allows a gradual transition\nfrom penalty-like method for soft elastic contact to Nitsche-like method for\nrigid contact. We conducted several simulation studies involving constant\nstrain patch tests and benchmark delamination tests under mode-I, mode-II and\nmixed-mode loadings. Our results show clear evidence of traction oscillations\nwith the standard method with structured and perturbed finite element meshes,\nand that the stabilized method alleviates these oscillations, thus illustrating\nits robustness.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:11:11 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Ghosh", "Gourab", ""], ["Duddu", "Ravindra", ""], ["Annavarapu", "Chandrasekhar", ""]]}, {"id": "2008.09090", "submitter": "Rilwan Adewoyin", "authors": "Rilwan Adewoyin, Peter Dueben, Peter Watson, Yulan He, Ritabrata Dutta", "title": "TRU-NET: A Deep Learning Approach to High Resolution Prediction of\n  Rainfall", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate models (CM) are used to evaluate the impact of climate change on the\nrisk of floods and strong precipitation events. However, these numerical\nsimulators have difficulties representing precipitation events accurately,\nmainly due to limited spatial resolution when simulating multi-scale dynamics\nin the atmosphere. To improve the prediction of high resolution precipitation\nwe apply a Deep Learning (DL) approach using an input of CM simulations of the\nmodel fields (weather variables) that are more predictable than local\nprecipitation. To this end, we present TRU-NET (Temporal Recurrent U-Net), an\nencoder-decoder model featuring a novel 2D cross attention mechanism between\ncontiguous convolutional-recurrent layers to effectively model multi-scale\nspatio-temporal weather processes. We use a conditional-continuous loss\nfunction to capture the zero-skewed %extreme event patterns of rainfall.\nExperiments show that our model consistently attains lower RMSE and MAE scores\nthan a DL model prevalent in short term precipitation prediction and improves\nupon the rainfall predictions of a state-of-the-art dynamical weather model.\nMoreover, by evaluating the performance of our model under various, training\nand testing, data formulation strategies, we show that there is enough data for\nour deep learning approach to output robust, high-quality results across\nseasons and varying regions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:27:59 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:30:08 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Adewoyin", "Rilwan", ""], ["Dueben", "Peter", ""], ["Watson", "Peter", ""], ["He", "Yulan", ""], ["Dutta", "Ritabrata", ""]]}, {"id": "2008.09169", "submitter": "Roya Sabbagh Novin", "authors": "Roya Sabbagh Novin, Ellen Taylor, Tucker Hermans, Andrew Merryweather", "title": "Development of a Novel Computational Model for Evaluating Fall Risk in\n  Patient Room Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: The aims of this study are to identify factors in physical\nenvironments that contribute to patient falls in hospitals and to propose a\ncomputational model to evaluate patient room designs.\n  Background: The existing fall risk assessment tools have an acceptable level\nof sensitivity and specificity, however, they only consider intrinsic factors\nand medications, making the prediction very limited in terms of how the\nphysical environment contributes to fall risk.\n  Methods: We provide a computational model for risk of fall based on\nphysical-environment and patient-motion factors. We use a trajectory\noptimization approach for patient motion prediction.\n  Results: We run the proposed model on four room designs as examples of\nvarious room design categories. Results show the capabilities of the proposed\nmodel in identifying risky locations within the room.\n  Conclusions: Our study shows the potential capabilities of the proposed\nmodel. Due to lack of enough evidence for the examined factors, it is not\npossible at this point to gain robust confidence in the final evaluations. More\nstudies using quantitative, relational, or causal designs are recommended to\ninform the proposed model for patient falls.\n  Application: Developing a comprehensive fall risk model is a significant step\nin understanding and solving the problem of patient falls in hospitals. It can\nprovide guidance for healthcare decision makers to optimize effective\ninterventions to reduce risk of falls while promoting safe patient mobility in\nthe hospital room environment. We can also use it in healthcare technologies\nsuch as assistive robots to provide informed assistance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 19:13:37 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 23:15:56 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Novin", "Roya Sabbagh", ""], ["Taylor", "Ellen", ""], ["Hermans", "Tucker", ""], ["Merryweather", "Andrew", ""]]}, {"id": "2008.09471", "submitter": "Matloob Khushi Dr", "authors": "Zezheng Zhang and Matloob Khushi", "title": "GA-MSSR: Genetic Algorithm Maximizing Sharpe and Sterling Ratio Method\n  for RoboTrading", "comments": null, "journal-ref": "IJCNN 2020", "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foreign exchange is the largest financial market in the world, and it is also\none of the most volatile markets. Technical analysis plays an important role in\nthe forex market and trading algorithms are designed utilizing machine learning\ntechniques. Most literature used historical price information and technical\nindicators for training. However, the noisy nature of the market affects the\nconsistency and profitability of the algorithms. To address this problem, we\ndesigned trading rule features that are derived from technical indicators and\ntrading rules. The parameters of technical indicators are optimized to maximize\ntrading performance. We also proposed a novel cost function that computes the\nrisk-adjusted return, Sharpe and Sterling Ratio (SSR), in an effort to reduce\nthe variance and the magnitude of drawdowns. An automatic robotic trading\n(RoboTrading) strategy is designed with the proposed Genetic Algorithm\nMaximizing Sharpe and Sterling Ratio model (GA-MSSR) model. The experiment was\nconducted on intraday data of 6 major currency pairs from 2018 to 2019. The\nresults consistently showed significant positive returns and the performance of\nthe trading system is superior using the optimized rule-based features. The\nhighest return obtained was 320% annually using 5-minute AUDUSD currency pair.\nBesides, the proposed model achieves the best performance on risk factors,\nincluding maximum drawdowns and variance in return, comparing to benchmark\nmodels. The code can be accessed at\nhttps://github.com/zzzac/rule-based-forextrading-system\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 05:33:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zhang", "Zezheng", ""], ["Khushi", "Matloob", ""]]}, {"id": "2008.09521", "submitter": "Olivier Rousselle", "authors": "Olivier Rousselle", "title": "Evaluation of the cumulated impacts on the marine resource of a\n  socio-ecological coral system: approach by agent-based modeling", "comments": "in French, Thesis CNRS (French National Centre for Scientific\n  Research) - CRIOBE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of climate change and significant changes in human activities\naround the world, coral reefs are subject to many disruptions. We develop here\na tool to help decision-making in Moorea (French Polynesia), based on\nmulti-agent modeling. We model the trophic interactions with a Lotka-Volterra\nmodel, and also the interactions between fishermen, trophic groups and tourist\noperators. The results are generated through global, temporal (time series),\nand spatial (GIS maps) outputs. The model produced here can be transposed to\nother ecological and economic situations, and other geographical areas, by\nmodifying the parameters and changing the input map data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:51:14 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Rousselle", "Olivier", ""]]}, {"id": "2008.09589", "submitter": "Amir Shahmoradi", "authors": "Amir Shahmoradi, Fatemeh Bagheri", "title": "ParaDRAM: A Cross-Language Toolbox for Parallel High-Performance\n  Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE astro-ph.IM physics.data-an stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ParaDRAM, a high-performance Parallel Delayed-Rejection Adaptive\nMetropolis Markov Chain Monte Carlo software for optimization, sampling, and\nintegration of mathematical objective functions encountered in scientific\ninference. ParaDRAM is currently accessible from several popular programming\nlanguages including C/C++, Fortran, MATLAB, Python and is part of the ParaMonte\nopen-source project with the following principal design goals: 1. full\nautomation of Monte Carlo simulations, 2. interoperability of the core library\nwith as many programming languages as possible, thus, providing a unified\nApplication Programming Interface and Monte Carlo simulation environment across\nall programming languages, 3. high-performance 4. parallelizability and\nscalability of simulations from personal laptops to supercomputers, 5.\nvirtually zero-dependence on external libraries, 6. fully-deterministic\nreproducibility of simulations, 7. automatic comprehensive reporting and\npost-processing of the simulation results. We present and discuss several novel\ntechniques implemented in ParaDRAM to automatically and dynamically ensure the\ngood-mixing and the diminishing-adaptation of the resulting pseudo-Markov\nchains from ParaDRAM. We also discuss the implementation of an efficient data\nstorage method used in ParaDRAM that reduces the average memory and storage\nrequirements of the algorithm by, a factor of 4 for simple simulation problems,\nto an order of magnitude and more for sampling complex high-dimensional\nmathematical objective functions. Finally, we discuss how the design goals of\nParaDRAM can help users readily and efficiently solve a variety of machine\nlearning and scientific inference problems on a wide range of computing\nplatforms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:29:24 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shahmoradi", "Amir", ""], ["Bagheri", "Fatemeh", ""]]}, {"id": "2008.09645", "submitter": "Sheng Liu", "authors": "Sheng Liu, Zuo-Jun Max Shen, Xiang Ji", "title": "Urban Bike Lane Planning with Bike Trajectories: Models, Algorithms, and\n  a Real-World Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an urban bike lane planning problem based on the fine-grained bike\ntrajectory data, which is made available by smart city infrastructure such as\nbike-sharing systems. The key decision is where to build bike lanes in the\nexisting road network. As bike-sharing systems become widespread in the\nmetropolitan areas over the world, bike lanes are being planned and constructed\nby many municipal governments to promote cycling and protect cyclists.\nTraditional bike lane planning approaches often rely on surveys and heuristics.\nWe develop a general and novel optimization framework to guide the bike lane\nplanning from bike trajectories. We formalize the bike lane planning problem in\nview of the cyclists' utility functions and derive an integer optimization\nmodel to maximize the utility. To capture cyclists' route choices, we develop a\nbilevel program based on the Multinomial Logit model. We derive structural\nproperties about the base model and prove that the Lagrangian dual of the bike\nlane planning model is polynomial-time solvable. Furthermore, we reformulate\nthe route choice based planning model as a mixed integer linear program using a\nlinear approximation scheme. We develop tractable formulations and efficient\nalgorithms to solve the large-scale optimization problem. Via a real-world case\nstudy with a city government, we demonstrate the efficiency of the proposed\nalgorithms and quantify the trade-off between the coverage of bike trips and\ncontinuity of bike lanes. We show how the network topology evolves according to\nthe utility functions and highlight the importance of understanding cyclists'\nroute choices. The proposed framework drives the data-driven urban planning\nscheme in smart city operations management.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:46:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Sheng", ""], ["Shen", "Zuo-Jun Max", ""], ["Ji", "Xiang", ""]]}, {"id": "2008.09667", "submitter": "Xiao Li", "authors": "Xiao Li and Weili Wu", "title": "A Blockchain Transaction Graph based Machine Learning Method for Bitcoin\n  Price Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin, as one of the most popular cryptocurrency, is recently attracting\nmuch attention of investors. Bitcoin price prediction task is consequently a\nrising academic topic for providing valuable insights and suggestions. Existing\nbitcoin prediction works mostly base on trivial feature engineering, that\nmanually designs features or factors from multiple areas, including Bticoin\nBlockchain information, finance and social media sentiments. The feature\nengineering not only requires much human effort, but the effectiveness of the\nintuitively designed features can not be guaranteed. In this paper, we aim to\nmining the abundant patterns encoded in bitcoin transactions, and propose\nk-order transaction graph to reveal patterns under different scope. We propose\nthe transaction graph based feature to automatically encode the patterns. A\nnovel prediction method is proposed to accept the features and make price\nprediction, which can take advantage from particular patterns from different\nhistory period. The results of comparison experiments demonstrate that the\nproposed method outperforms the most recent state-of-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:08:17 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Xiao", ""], ["Wu", "Weili", ""]]}, {"id": "2008.09687", "submitter": "Christophe Bonneville", "authors": "Wensi Wu, Christophe Bonneville, Christopher J. Earls", "title": "A Principled Approach to Design Using High Fidelity Fluid-Structure\n  Interaction Simulations", "comments": null, "journal-ref": null, "doi": "10.1016/j.finel.2021.103562", "report-no": null, "categories": "cs.CE cs.NA math.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high fidelity fluid-structure interaction simulation may require many days\nto run, on hundreds of cores. This poses a serious burden, both in terms of\ntime and economic considerations, when repetitions of such simulations may be\nrequired (e.g. for the purpose of design optimization). In this paper we\npresent strategies based on (constrained) Bayesian optimization (BO) to\nalleviate this burden. BO is a numerical optimization technique based on\nGaussian processes (GP) that is able to efficiently (with minimal calls to the\nexpensive FSI models) converge towards some globally optimal design, as gauged\nusing a black box objective function. In this study we present a principled\ndesign evolution that moves from FSI model verification, through a series of\nBridge Simulations (bringing the verification case incrementally closer to the\napplication), in order that we may identify material properties for an\nunderwater, unmanned, autonomous vehicle (UUAV) sail plane. We are able to\nachieve fast convergence towards an optimal design, using a small number of FSI\nsimulations (a dozen at most), even when selecting over several design\nparameters, and while respecting optimization constraints.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 21:37:12 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wu", "Wensi", ""], ["Bonneville", "Christophe", ""], ["Earls", "Christopher J.", ""]]}, {"id": "2008.09725", "submitter": "Patrick Diehl", "authors": "Serge Prudhomme and Patrick Diehl", "title": "On the treatment of boundary conditions for bond-based peridynamic\n  models", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113391", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two approaches to apply boundary conditions for\nbond-based peridynamic models. There has been in recent years a renewed\ninterest in the class of so-called non-local models, which include peridynamic\nmodels, for the simulation of structural mechanics problems as an alternative\napproach to classical local continuum models. However, a major issue, which is\noften disregarded when dealing with this class of models, is concerned with the\nmanner by which boundary conditions should be prescribed. Our point of view\nhere is that classical boundary conditions, since applied on surfaces of solid\nbodies, are naturally associated with local models. The paper describes two\nmethods to incorporate classical Dirichlet and Neumann boundary conditions into\nbond-based peridynamics. The first method consists in artificially extending\nthe domain with a thin boundary layer over which the displacement field is\nrequired to behave as an odd function with respect to the boundary points. The\nsecond method resorts to the idea that peridynamic models and local models\nshould be compatible in the limit that the so-called horizon vanishes. The\napproach consists then in decreasing the horizon from a constant value in the\ninterior of the domain to zero at the boundary so that one can directly apply\nthe classical boundary conditions. We present the continuous and discrete\nformulations of the two methods and assess their performance on several\nnumerical experiments dealing with the simulation of a one-dimensional bar.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 00:48:06 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Prudhomme", "Serge", ""], ["Diehl", "Patrick", ""]]}, {"id": "2008.09763", "submitter": "Jiaqing Xie", "authors": "Hongyuan Dong, Jiaqing Xie, Zhi Jing, Dexin Ren", "title": "Variational Autoencoder for Anti-Cancer Drug Response Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is a primary cause of human death, but discovering drugs and tailoring\ncancer therapies are expensive and time-consuming. We seek to facilitate the\ndiscovery of new drugs and treatment strategies for cancer using variational\nautoencoders (VAEs) and multi-layer perceptrons (MLPs) to predict anti-cancer\ndrug responses. Our model takes as input gene expression data of cancer cell\nlines and anti-cancer drug molecular data and encodes these data with our {\\sc\n{GeneVae}} model, which is an ordinary VAE model, and a rectified junction tree\nvariational autoencoder ({\\sc JTVae}) model, respectively. A multi-layer\nperceptron processes these encoded features to produce a final prediction. Our\ntests show our system attains a high average coefficient of determination\n($R^{2} = 0.83$) in predicting drug responses for breast cancer cell lines and\nan average $R^{2} = 0.845$ for pan-cancer cell lines. Additionally, we show\nthat our model can generates effective drug compounds not previously used for\nspecific cancer cell lines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 06:03:22 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 15:00:42 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 12:32:32 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 13:10:25 GMT"}, {"version": "v5", "created": "Sat, 7 Nov 2020 02:10:01 GMT"}, {"version": "v6", "created": "Wed, 25 Nov 2020 04:36:14 GMT"}, {"version": "v7", "created": "Thu, 15 Apr 2021 09:08:43 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Dong", "Hongyuan", ""], ["Xie", "Jiaqing", ""], ["Jing", "Zhi", ""], ["Ren", "Dexin", ""]]}, {"id": "2008.10996", "submitter": "Sansit Patnaik", "authors": "Sansit Patnaik and Fabio Semperlotti", "title": "Variable-Order Fracture Mechanics and its Application to Dynamic\n  Fracture", "comments": "14 pages, 3 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents the formulation, the numerical solution, and the\nvalidation of a theoretical framework based on the concept of variable-order\nmechanics and capable of modeling dynamic fracture in brittle and quasi-brittle\nsolids. More specifically, the reformulation of the elastodynamic problem via\nvariable and fractional order operators enables a unique and extremely powerful\napproach to model nucleation and propagation of cracks in solids under dynamic\nloading. The resulting dynamic fracture formulation is fully evolutionary hence\nenabling the analysis of complex crack patterns without requiring any a prior\nassumptions on the damage location and the growth path, as well as the use of\nany algorithm to track the evolving crack surface. The evolutionary nature of\nthe variable-order formalism also prevents the need for additional partial\ndifferential equations to predict the damage field, hence suggesting a\nconspicuous reduction in the computational cost. Remarkably, the variable order\nformulation is naturally capable of capturing extremely detailed features\ncharacteristic of dynamic crack propagation such as crack surface roughening,\nsingle and multiple branching. The accuracy and robustness of the proposed\nvariable-order formulation is validated by comparing the results of direct\nnumerical simulations with experimental data of typical benchmark problems\navailable in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 23:48:02 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Patnaik", "Sansit", ""], ["Semperlotti", "Fabio", ""]]}, {"id": "2008.11057", "submitter": "Mojtaba Barzegari", "authors": "Mojtaba Barzegari, Liesbet Geris", "title": "Highly scalable numerical simulation of coupled reaction-diffusion\n  systems with moving interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A combination of reaction-diffusion models with moving-boundary problems\nyields a system in which the diffusion (spreading and penetration) and reaction\n(transformation) evolve the system's state and geometry over time. These\nsystems can be used in a wide range of engineering applications. In this study,\nas an example of such a system, the degradation of metallic materials is\ninvestigated. A mathematical model is constructed of the diffusion-reaction\nprocesses and the movement of corrosion front of a magnesium block floating in\na chemical solution. The corresponding parallelized computational model is\nimplemented using the finite element method, and the weak and strong scaling\nbehaviors of the model are evaluated to analyze the performance and efficiency\nof the employed high-performance computing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:30:19 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Barzegari", "Mojtaba", ""], ["Geris", "Liesbet", ""]]}, {"id": "2008.11528", "submitter": "Sai Sidhardh", "authors": "Sai Sidhardh, Sansit Patnaik, Fabio Semperlotti", "title": "Fractional-Order Structural Stability: Formulation and Application to\n  the Critical Load of Slender Structures", "comments": "5 Figures, 9 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents the framework to perform a stability analysis of nonlocal\nsolids whose response is formulated according to the fractional-order continuum\ntheory. In this formulation, space fractional-order operators are used to\ncapture the nonlocal response of the medium by introducing nonlocal kinematic\nrelations. First, we use the geometrically nonlinear fractional-order kinematic\nrelations within an energy-based approach to establish the Lagrange-Dirichlet\nstability criteria for fractional-order nonlocal structures. This energy-based\napproach to nonlocal structural stability is possible due to a\npositive-definite and thermodynamically consistent definition of deformation\nenergy enabled by the fractional-order kinematic formulation. Then, the\nRayleigh-Ritz coefficient for the critical load is derived for linear buckling\nconditions. The fractional-order formulation is finally used to determine\ncritical buckling loads of slender nonlocal beams and plates using a dedicated\nfractional-order finite element solver. Results establish that, in contrast to\nexisting studies, the effect of nonlocal interactions is observed on both the\nmaterial and the geometric stiffness, when using the fractional-order\nkinematics approach. We support these observations quantitatively with the help\nof case studies focusing on the critical buckling response of fractional-order\nnonlocal slender structures, and qualitatively via direct comparison of the\nfractional-order approach with the classical nonlocal approaches.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 18:27:49 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Sidhardh", "Sai", ""], ["Patnaik", "Sansit", ""], ["Semperlotti", "Fabio", ""]]}, {"id": "2008.11815", "submitter": "Hyoung Suk Suh", "authors": "Hyoung Suk Suh, WaiChing Sun", "title": "An immersed phase field fracture model for fluid-infiltrating porous\n  media with evolving Beavers-Joseph-Saffman condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study presents a phase field model for brittle fracture in\nfluid-infiltrating vuggy porous media. While the state-of-the-art in hydraulic\nphase field fracture considers Darcian fracture flow with enhanced permeability\nalong the crack, in this study, the phase field not only acts as a damage\nvariable that provides diffuse representation of cracks or cavities, but also\nacts as an indicator function that separates the domain into two regions where\nfluid flows are governed by Stokes and Darcy equations, respectively. Since the\nphase field and its gradient can be respectively regarded as smooth\napproximations of the Heaviside function and Dirac delta function, our new\napproach is capable of imposing interfacial transmissibility conditions without\nexplicit interface parametrizations. In addition, the interaction between solid\nand fluid constituents is modeled by adopting the concept of mixture theory,\nwhere the fluid velocities in Stokes and Darcy regions are considered as\nrelative measures compared to the solid motion. This model is particularly\nattractive for coupled flow analysis in geological materials with complex\nmicrostructures undergoing brittle fracture often encountered in energy\ngeotechnics problems, since it completely eliminates the needs to generate\nspecific enrichment function, integration scheme, or meshing algorithm tailored\nfor complex geological features.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 22:20:48 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Suh", "Hyoung Suk", ""], ["Sun", "WaiChing", ""]]}, {"id": "2008.11819", "submitter": "Pouria Akbari Mistani", "authors": "Pouria A. Mistani, Samira Pakravan, Frederic G. Gibou", "title": "A fractional stochastic theory for interfacial polarization of cell\n  aggregates", "comments": "13 figures, 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.bio-ph physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical framework to model the electric response of cell\naggregates. We establish a coarse representation for each cell as a combination\nof membrane and cytoplasm dipole moments. Then we compute the effective\nconductivity of the resulting system, and thereafter derive a Fokker-Planck\npartial differential equation that captures the time-dependent evolution of the\ndistribution of induced cellular polarizations in an ensemble of cells. Our\nmodel predicts that the polarization density parallel to an applied pulse\nfollows a skewed t-distribution, while the transverse polarization density\nfollows a symmetric t-distribution, which are in accordance with our direct\nnumerical simulations. Furthermore, we report a reduced order model described\nby a coupled pair of ordinary differential equations that reproduces the\naverage and the variance of induced dipole moments in the aggregate. We extend\nour proposed formulation by considering fractional order time derivatives that\nwe find necessary to explain anomalous relaxation phenomena observed in\nexperiments as well as our direct numerical simulations. Owing to its\ntime-domain formulation, our framework can be easily used to consider nonlinear\nmembrane effects or intercellular couplings that arise in several scientific,\nmedical and technological applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:58:31 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Mistani", "Pouria A.", ""], ["Pakravan", "Samira", ""], ["Gibou", "Frederic G.", ""]]}, {"id": "2008.12850", "submitter": "Ondrej Rokos", "authors": "S.E.H.M. van Bree, O. Roko\\v{s}, R.H.J. Peerlings, M.\n  Do\\v{s}k\\'a\\v{r}, M.G.D. Geers", "title": "A Newton Solver for Micromorphic Computational Homogenization Enabling\n  Multiscale Buckling Analysis of Pattern-Transforming Metamaterials", "comments": "34 pages, 17 figures, 1 table, 1 algorithm, abstract shortened to\n  fulfill 1920 character limit", "journal-ref": null, "doi": "10.1016/j.cma.2020.113333", "report-no": null, "categories": "cs.CE cond-mat.soft", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanical metamaterials feature engineered microstructures designed to\nexhibit exotic, and often counter-intuitive, effective behaviour. Such a\nbehaviour is often achieved through instability-induced transformations of the\nunderlying periodic microstructure into one or multiple patterning modes. Due\nto a strong kinematic coupling of individual repeating microstructural cells,\nnon-local behaviour and size effects emerge, which cannot easily be captured by\nclassical homogenization schemes. In addition, the individual patterning modes\ncan mutually interact in space as well as in time, while at the engineering\nscale the entire structure can buckle globally. For efficient numerical\nmacroscale predictions, a micromorphic computational homogenization scheme has\nrecently been developed. Although this framework is in principle capable of\naccounting for spatial and temporal interactions between individual patterning\nmodes, its implementation relied on a gradient-based quasi-Newton solution\ntechnique. This solver is suboptimal because (i) it has sub-quadratic\nconvergence, and (ii) the absence of Hessians does not allow for proper\nbifurcation analyses. Given that mechanical metamaterials often rely on\ncontrolled instabilities, these limitations are serious. To address them, a\nfull Newton method is provided in detail in this paper. The construction of the\nmacroscopic tangent operator is not straightforward due to specific model\nassumptions on the decomposition of the underlying displacement field pertinent\nto the micromorphic framework, involving orthogonality constraints. Analytical\nexpressions for the first and second variation of the total potential energy\nare given, and the complete algorithm is listed. The developed methodology is\ndemonstrated with two examples in which a competition between local and global\nbuckling exists and where multiple patterning modes emerge.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 11:06:02 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 14:03:56 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["van Bree", "S. E. H. M.", ""], ["Roko\u0161", "O.", ""], ["Peerlings", "R. H. J.", ""], ["Do\u0161k\u00e1\u0159", "M.", ""], ["Geers", "M. G. D.", ""]]}, {"id": "2008.13284", "submitter": "Weichen Li", "authors": "Weichen Li and Xiaojia Shelly Zhang", "title": "Momentum-based Accelerated Mirror Descent Stochastic Approximation for\n  Robust Topology Optimization under Stochastic Loads", "comments": "38 pages (including reference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust topology optimization (RTO) improves the robustness of designs with\nrespect to random sources in real-world structures, yet an accurate sensitivity\nanalysis requires the solution of many systems of equations at each\noptimization step, leading to a high computational cost. To open up the full\npotential of RTO under a variety of random sources, this paper presents a\nmomentum-based accelerated mirror descent stochastic approximation (AC-MDSA)\napproach to efficiently solve RTO problems involving various types of load\nuncertainties. The proposed framework can perform high-quality design updates\nwith highly noisy stochastic gradients. We reduce the sample size to two\n(minimum for unbiased variance estimation) and show only two samples are\nsufficient for evaluating stochastic gradients to obtain robust designs, thus\ndrastically reducing the computational cost. We derive the AC-MDSA update\nformula based on $\\ell_1$-norm with entropy function, which is tailored to the\ngeometry of the feasible domain. To accelerate and stabilize the algorithm, we\nintegrate a momentum-based acceleration scheme, which also alleviates the step\nsize sensitivity. Several 2D and 3D examples with various sizes are presented\nto demonstrate the effectiveness and efficiency of the proposed AC-MDSA\nframework to handle RTO involving various types of loading uncertainties.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 21:51:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Weichen", ""], ["Zhang", "Xiaojia Shelly", ""]]}, {"id": "2008.13547", "submitter": "Qiming Zhu", "authors": "Qiming Zhu, Zeliang Liu, Jinhui Yan", "title": "Machine learning for metal additive manufacturing: Predicting\n  temperature and melt pool fluid dynamics using physics-informed neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG physics.app-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent explosion of machine learning (ML) and artificial intelligence\n(AI) shows great potential in the breakthrough of metal additive manufacturing\n(AM) process modeling. However, the success of conventional machine learning\ntools in data science is primarily attributed to the unprecedented large amount\nof labeled data-sets (big data), which can be either obtained by experiments or\nfirst-principle simulations. Unfortunately, these labeled data-sets are\nexpensive to obtain in AM due to the high expense of the AM experiments and\nprohibitive computational cost of high-fidelity simulations.\n  We propose a physics-informed neural network (PINN) framework that fuses both\ndata and first physical principles, including conservation laws of momentum,\nmass, and energy, into the neural network to inform the learning processes. To\nthe best knowledge of the authors, this is the first application of PINN to\nthree dimensional AM processes modeling. Besides, we propose a hard-type\napproach for Dirichlet boundary conditions (BCs) based on a Heaviside function,\nwhich can not only enforce the BCs but also accelerate the learning process.\nThe PINN framework is applied to two representative metal manufacturing\nproblems, including the 2018 NIST AM-Benchmark test series. We carefully assess\nthe performance of the PINN model by comparing the predictions with available\nexperimental data and high-fidelity simulation results. The investigations show\nthat the PINN, owed to the additional physical knowledge, can accurately\npredict the temperature and melt pool dynamics during metal AM processes with\nonly a moderate amount of labeled data-sets. The foray of PINN to metal AM\nshows the great potential of physics-informed deep learning for broader\napplications to advanced manufacturing.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 20:34:38 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 17:29:15 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhu", "Qiming", ""], ["Liu", "Zeliang", ""], ["Yan", "Jinhui", ""]]}, {"id": "2008.13584", "submitter": "Adam Yonge", "authors": "Adam Yonge and M. Ross Kunz and Rakesh Batchu and Zongtang Fang and\n  Tobin Issac and Rebecca Fushimi and Andrew J. Medford", "title": "TAPsolver: A Python package for the simulation and analysis of TAP\n  reactor experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open-source, Python-based Temporal Analysis of Products (TAP) reactor\nsimulation and processing program is introduced. TAPsolver utilizes algorithmic\ndifferentiation for the calculation of highly accurate derivatives, which are\nused to perform sensitivity analyses and PDE-constrained optimization. The tool\nsupports constraints to ensure thermodynamic consistency, which can lead to\nmore accurate parameters and assist in mechanism discrimination. The\nmathematical and structural details of TAPsolver are outlined, as well as\nvalidation of the forward and inverse problems against well-studied prototype\nproblems. Benchmarks of the code are presented, and a case study for extracting\nthermodynamically-consistent kinetic parameters from experimental TAP\nmeasurements of CO oxidation on supported platinum particles is presented.\nTAPsolver will act as a foundation for future development and dissemination of\nTAP data processing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:07:10 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Yonge", "Adam", ""], ["Kunz", "M. Ross", ""], ["Batchu", "Rakesh", ""], ["Fang", "Zongtang", ""], ["Issac", "Tobin", ""], ["Fushimi", "Rebecca", ""], ["Medford", "Andrew J.", ""]]}]