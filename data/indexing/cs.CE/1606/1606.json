[{"id": "1606.00093", "submitter": "Vivekanandan Balasubramanian", "authors": "Vivekanandan Balasubramanian, Iain Bethune, Ardita Shkurti, Elena\n  Breitmoser, Eugen Hruska, Cecilia Clementi, Charles Laughton, Shantenu Jha", "title": "ExTASY: Scalable and Flexible Coupling of MD Simulations and Advanced\n  Sampling Techniques", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many macromolecular systems the accurate sampling of the relevant regions\non the potential energy surface cannot be obtained by a single, long Molecular\nDynamics (MD) trajectory. New approaches are required to promote more efficient\nsampling. We present the design and implementation of the Extensible Toolkit\nfor Advanced Sampling and analYsis (ExTASY) for building and executing advanced\nsampling workflows on HPC systems. ExTASY provides Python based \"templated\nscripts\" that interface to an interoperable and high-performance pilot-based\nrun time system, which abstracts the complexity of managing multiple\nsimulations. ExTASY supports the use of existing highly-optimised parallel MD\ncode and their coupling to analysis tools based upon collective coordinates\nwhich do not require a priori knowledge of the system to bias. We describe two\nworkflows which both couple large \"ensembles\" of relatively short MD\nsimulations with analysis tools to automatically analyse the generated\ntrajectories and identify molecular conformational structures that will be used\non-the-fly as new starting points for further \"simulation-analysis\" iterations.\nOne of the workflows leverages the Locally Scaled Diffusion Maps technique; the\nother makes use of Complementary Coordinates techniques to enhance sampling and\ngenerate start-points for the next generation of MD simulations. We show that\nthe ExTASY tools have been deployed on a range of HPC systems including ARCHER\n(Cray CX30), Blue Waters (Cray XE6/XK7), and Stampede (Linux cluster), and that\ngood strong scaling can be obtained up to 1000s of MD simulations, independent\nof the size of each simulation. We discuss how ExTASY can be easily extended or\nmodified by end-users to build their own workflows, and ongoing work to improve\nthe usability and robustness of ExTASY.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 02:01:25 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Balasubramanian", "Vivekanandan", ""], ["Bethune", "Iain", ""], ["Shkurti", "Ardita", ""], ["Breitmoser", "Elena", ""], ["Hruska", "Eugen", ""], ["Clementi", "Cecilia", ""], ["Laughton", "Charles", ""], ["Jha", "Shantenu", ""]]}, {"id": "1606.00414", "submitter": "Nicolas Turenne", "authors": "Nicolas Turenne", "title": "On a Possible Similarity between Gene and Semantic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several domains such as linguistics, molecular biology or social sciences,\nholistic effects are hardly well-defined by modeling with single units, but\nmore and more studies tend to understand macro structures with the help of\nmeaningful and useful associations in fields such as social networks, systems\nbiology or semantic web. A stochastic multi-agent system offers both accurate\ntheoretical framework and operational computing implementations to model\nlarge-scale associations, their dynamics and patterns extraction. We show that\nclustering around a target object in a set of associations of object prove some\nsimilarity in specific data and two case studies about gene-gene and term-term\nrelationships leading to an idea of a common organizing principle of cognition\nwith random and deterministic effects.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 11:24:50 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Turenne", "Nicolas", ""]]}, {"id": "1606.00548", "submitter": "Hui Liu Mr", "authors": "Hui Liu and Kun Wang and Zhangxin Chen", "title": "Large-scale Reservoir Simulations on IBM Blue Gene/Q", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our work on simulation of large-scale reservoir models on\nIBM Blue Gene/Q and studying the scalability of our parallel reservoir\nsimulators. An in-house black oil simulator has been implemented. It uses MPI\nfor communication and is capable of simulating reservoir models with hundreds\nof millions of grid cells. Benchmarks show that our parallel simulator are\nthousands of times faster than sequential simulators that designed for\nworkstations and personal computers, and the simulator has excellent\nscalability.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 06:06:28 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Liu", "Hui", ""], ["Wang", "Kun", ""], ["Chen", "Zhangxin", ""]]}, {"id": "1606.00556", "submitter": "Hui Liu Mr", "authors": "Hui Liu, Lihua Shen, Kun Wang, Bo Yang, Zhangxin Chen", "title": "Numerical Simulation of Multi-phase Flow in Porous Media on Parallel\n  Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parallel reservoir simulator has been developed, which is designed for\nlarge-scale black oil simulations. It handles three phases, including water,\noil and gas, and three components, including water, oil and gas. This simulator\ncan calculate traditional reservoir models and naturally fractured models.\nVarious well operations are supported, such as water flooding, gas flooding and\npolymer flooding. The operation constraints can be fixed bottom-hole pressure,\na fixed fluid rate, and combinations of them. The simulator is based on our\nin-house platform, which provides grids, cell-centred data, linear solvers,\npreconditioners and well modeling. The simulator and the platform use MPI for\ncommunications among computation nodes. Our simulator is capable of simulating\ngiant reservoir models with hundreds of millions of grid cells. Numerical\nsimulations show that our simulator matches with commercial simulators and it\nhas excellent scalability.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 06:51:10 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 18:26:44 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Liu", "Hui", ""], ["Shen", "Lihua", ""], ["Wang", "Kun", ""], ["Yang", "Bo", ""], ["Chen", "Zhangxin", ""]]}, {"id": "1606.01139", "submitter": "Baruch Feldman", "authors": "Baruch Feldman, Yunkai Zhou", "title": "A partitioned shift-without-invert algorithm to improve parallel\n  eigensolution efficiency in real-space electronic transport", "comments": null, "journal-ref": "Comp. Phys. Communic. 207, 105, October 2016", "doi": "10.1016/j.cpc.2016.05.015", "report-no": null, "categories": "physics.comp-ph cond-mat.mes-hall cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an eigenspectrum partitioning scheme without inversion for the\nrecently described real-space electronic transport code, TRANSEC. The primary\nadvantage of TRANSEC is its highly parallel algorithm, which enables studying\nconductance in large systems. The present scheme adds a new source of\nparallelization, significantly enhancing TRANSEC's parallel scalability,\nespecially for systems with many electrons. In principle, partitioning could\nenable super-linear parallel speedup, as we demonstrate in calculations within\nTRANSEC. In practical cases, we report better than five-fold improvement in CPU\ntime and similar improvements in wall time, compared to previously-published\nlarge calculations. Importantly, the suggested scheme is relatively simple to\nimplement. It can be useful for general large Hermitian or weakly non-Hermitian\neigenvalue problems, whenever relatively accurate inversion via direct or\niterative linear solvers is impractical.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 06:32:12 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Feldman", "Baruch", ""], ["Zhou", "Yunkai", ""]]}, {"id": "1606.01243", "submitter": "Jos Schijndel van", "authors": "A.W.M. van Schijndel", "title": "BES with FEM: Building Energy Simulation using Finite Element Methods", "comments": "5 pages, 6 figures, Proceedings of the 2012 COMSOL Conference in\n  Milan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An overall objective of energy efficiency in the built environment is to\nimprove building and systems performances in terms of durability, comfort and\neconomics. In order to predict, improve and meet a certain set of performance\nrequirements related to the indoor climate of buildings and the associated\nenergy demand, building energy simulation (BES) tools are indispensable. Due to\nthe rapid development of FEM software and the Multiphysics approaches, it\nshould possible to build and simulate full 3D models of buildings regarding the\nenergy demand. The paper presents a methodology for performing building energy\nsimulation with Comsol. The method was applied to an international test box\nexperiment. The results showed an almost perfect agreement between the used BES\nmodel and Comsol. These preliminary results confirm the great opportunities to\nuse FEM related software for building energy performance simulation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 08:20:32 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["van Schijndel", "A. W. M.", ""]]}, {"id": "1606.01289", "submitter": "Darren Engwirda", "authors": "Darren Engwirda", "title": "Conforming restricted Delaunay mesh generation for piecewise smooth\n  complexes", "comments": "To appear at the 25th International Meshing Roundtable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Frontal-Delaunay refinement algorithm for mesh generation in piecewise\nsmooth domains is described. Built using a restricted Delaunay framework, this\nnew algorithm combines a number of novel features, including: (i) an\nunweighted, conforming restricted Delaunay representation for domains specified\nas a (non-manifold) collection of piecewise smooth surface patches and curve\nsegments, (ii) a protection strategy for domains containing curve segments that\nsubtend sharply acute angles, and (iii) a new class of off-centre refinement\nrules designed to achieve high-quality point-placement along embedded curve\nfeatures. Experimental comparisons show that the new Frontal-Delaunay algorithm\noutperforms a classical (statically weighted) restricted Delaunay-refinement\ntechnique for a number of three-dimensional benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 22:06:58 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 18:06:16 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Engwirda", "Darren", ""]]}, {"id": "1606.01313", "submitter": "Rodrigo de Lamare", "authors": "H. Ruan and R. C. de Lamare", "title": "Design of Robust Adaptive Beamforming Algorithms Based on Low-Rank and\n  Cross-Correlation Techniques", "comments": "11 figures, 12 pages", "journal-ref": null, "doi": "10.1109/TSP.2016.2550006", "report-no": null, "categories": "cs.CE cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents cost-effective low-rank techniques for designing robust\nadaptive beamforming (RAB) algorithms. The proposed algorithms are based on the\nexploitation of the cross-correlation between the array observation data and\nthe output of the beamformer. Firstly, we construct a general linear equation\nconsidered in large dimensions whose solution yields the steering vector\nmismatch. Then, we employ the idea of the full orthogonalization method (FOM),\nan orthogonal Krylov subspace based method, to iteratively estimate the\nsteering vector mismatch in a reduced-dimensional subspace, resulting in the\nproposed orthogonal Krylov subspace projection mismatch estimation (OKSPME)\nmethod. We also devise adaptive algorithms based on stochastic gradient (SG)\nand conjugate gradient (CG) techniques to update the beamforming weights with\nlow complexity and avoid any costly matrix inversion. The main advantages of\nthe proposed low-rank and mismatch estimation techniques are their\ncost-effectiveness when dealing with high dimension subspaces or large sensor\narrays. Simulations results show excellent performance in terms of the output\nsignal-to-interference-plus-noise ratio (SINR) of the beamformer among all the\ncompared RAB methods.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 00:44:35 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Ruan", "H.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1606.02422", "submitter": "Hussein Rappel", "authors": "Hussein Rappel, Lars A.A. Beex, Jack S. Hale, Stephane P.A. Bordas", "title": "Bayesian inference for the stochastic identification of elastoplastic\n  material parameters: Introduction, misconceptions and insights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss Bayesian inference (BI) for the probabilistic identification of\nmaterial parameters. This contribution aims to shed light on the use of BI for\nthe identification of elastoplastic material parameters. For this purpose a\nsingle spring is considered, for which the stress-strain curves are\nartificially created. Besides offering a didactic introduction to BI, this\npaper proposes an approach to incorporate statistical errors both in the\nmeasured stresses, and in the measured strains. It is assumed that the\nuncertainty is only due to measurement errors and the material is homogeneous.\nFurthermore, a number of possible misconceptions on BI are highlighted based on\nthe purely elastic case.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 07:03:09 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2016 10:26:46 GMT"}, {"version": "v3", "created": "Fri, 7 Oct 2016 15:24:42 GMT"}, {"version": "v4", "created": "Sun, 15 Jan 2017 21:18:24 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Rappel", "Hussein", ""], ["Beex", "Lars A. A.", ""], ["Hale", "Jack S.", ""], ["Bordas", "Stephane P. A.", ""]]}, {"id": "1606.02596", "submitter": "Huan Lei", "authors": "Huan Lei, Nathan Baker, Xiantao Li", "title": "Data-driven parameterization of the generalized Langevin equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven approach to determine the memory kernel and random\nnoise in generalized Langevin equations. To facilitate practical\nimplementations, we parameterize the kernel function in the Laplace domain by a\nrational function, with coefficients directly linked to the equilibrium\nstatistics of the coarse-grain variables. We show that such an approximation\ncan be constructed to arbitrarily high order and the resulting generalized\nLangevin dynamics can be embedded in an extended stochastic model without\nexplicit memory. We demonstrate how to introduce the stochastic noise so that\nthe second fluctuation-dissipation theorem is exactly satisfied. Results from\nseveral numerical tests are presented to demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 15:12:43 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 06:41:28 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Lei", "Huan", ""], ["Baker", "Nathan", ""], ["Li", "Xiantao", ""]]}, {"id": "1606.03855", "submitter": "Iryna Kononenko", "authors": "Iryna Kononenko, Oleksiy Kononenko", "title": "Mathematical Modeling of Dynamics for Partially Filled Shells of\n  Revolution", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the dynamic behaviour of compound shells of revolution\npartially filled with an ideal incompressible fluid based on boundary-value\nproblems. New analytical mathematical model with corresponding discrete scheme\nfor the elastic displacements and the dynamic liquid pressure is developed. The\ndiscrete scheme is based on the method of discrete singularities. A code to\nperform the numerical analysis is developed. Comprehensive benchmarking of the\nobtained results against other methods is done and good agreement is observed.\nThe convergence of the proposed numerical method is demonstrated. One of the\nadvantages of this new model is that the initial 3D problem is analytically\nreduced to a 1D integral equation. Moreover, it can handle the behaviour of the\npressure in the vicinity of the nodes explicitly and the computational\ntechnique used has a quick convergence requiring a negligible amount of CPU\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 08:27:21 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 05:13:40 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Kononenko", "Iryna", ""], ["Kononenko", "Oleksiy", ""]]}, {"id": "1606.04464", "submitter": "Maruti Mudunuru", "authors": "M. K. Mudunuru, S. Karra, N. Makedonska, T. Chen", "title": "Sequential geophysical and flow inversion to characterize fracture\n  networks in subsurface systems", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": "10.1002/sam.11356", "report-no": null, "categories": "cs.CE math.NA physics.comp-ph physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsurface applications including geothermal, geological carbon\nsequestration, oil and gas, etc., typically involve maximizing either the\nextraction of energy or the storage of fluids. Characterizing the subsurface is\nextremely complex due to heterogeneity and anisotropy. Due to this complexity,\nthere are uncertainties in the subsurface parameters, which need to be\nestimated from multiple diverse as well as fragmented data streams. In this\npaper, we present a non-intrusive sequential inversion framework, for\nintegrating data from geophysical and flow sources to constraint subsurface\nDiscrete Fracture Networks (DFN). In this approach, we first estimate bounds on\nthe statistics for the DFN fracture orientations using microseismic data. These\nbounds are estimated through a combination of a focal mechanism (physics-based\napproach) and clustering analysis (statistical approach) of seismic data. Then,\nthe fracture lengths are constrained based on the flow data. The efficacy of\nthis multi-physics based sequential inversion is demonstrated through a\nrepresentative synthetic example.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 17:18:06 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 16:05:06 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 01:04:40 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Mudunuru", "M. K.", ""], ["Karra", "S.", ""], ["Makedonska", "N.", ""], ["Chen", "T.", ""]]}, {"id": "1606.04561", "submitter": "Amir Ahooye Atashin", "authors": "Amir Ahooye Atashin, Parsa Bagherzadeh, Kamaledin Ghiasi-Shirazi", "title": "A two-stage learning method for protein-protein interaction prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new method for PPI (proteinprotein interaction) prediction\nis proposed. In PPI prediction, a reliable and sufficient number of training\nsamples is not available, but a large number of unlabeled samples is in hand.\nIn the proposed method, the denoising auto encoders are employed for learning\nrobust features. The obtained robust features are used in order to train a\nclassifier with a better performance. The experimental results demonstrate the\ncapabilities of the proposed method.\n  Protein-protein interaction; Denoising auto encoder;Robust features;\nUnlabelled data;\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 20:49:22 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 16:04:09 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Atashin", "Amir Ahooye", ""], ["Bagherzadeh", "Parsa", ""], ["Ghiasi-Shirazi", "Kamaledin", ""]]}, {"id": "1606.04567", "submitter": "Maruti Mudunuru", "authors": "M. K. Mudunuru, S. Karra, D. R. Harp, G. D. Guthrie, H. S. Viswanathan", "title": "Regression-based reduced-order models to predict transient thermal\n  output for enhanced geothermal systems", "comments": "25 pages, 8 figures", "journal-ref": "M.K. Mudunuru, S. Karra, D.R. Harp, G.D. Guthrie, H.S.\n  Viswanathan, Regression-based reduced-order models to predict transient\n  thermal output for enhanced geothermal systems, Geothermics, Volume 70, 2017,\n  Pages 192-205", "doi": "10.1016/j.geothermics.2017.06.013", "report-no": null, "categories": "cs.CE math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to assess the utility of Reduced-Order Models\n(ROMs) developed from 3D physics-based models for predicting transient thermal\npower output for an enhanced geothermal reservoir while explicitly accounting\nfor uncertainties in the subsurface system and site-specific details. Numerical\nsimulations are performed based on Latin Hypercube Sampling (LHS) of model\ninputs drawn from uniform probability distributions. Key sensitive parameters\nare identified from these simulations, which are fracture zone permeability,\nwell/skin factor, bottom hole pressure, and injection flow rate. The inputs for\nROMs are based on these key sensitive parameters. The ROMs are then used to\nevaluate the influence of subsurface attributes on thermal power production\ncurves. The resulting ROMs are compared with field-data and the detailed\nphysics-based numerical simulations. We propose three different ROMs with\ndifferent levels of model parsimony, each describing key and essential features\nof the power production curves. ROM-1 is able to accurately reproduce the power\noutput of numerical simulations for low values of permeabilities and certain\nfeatures of the field-scale data, and is relatively parsimonious. ROM-2 is a\nmore complex model than ROM-1 but it accurately describes the field-data. At\nhigher permeabilities, ROM-2 reproduces numerical results better than ROM-1,\nhowever, there is a considerable deviation at low fracture zone permeabilities.\nROM-3 is developed by taking the best aspects of ROM-1 and ROM-2 and provides a\nmiddle ground for model parsimony. It is able to describe various features of\nnumerical simulations and field-data. From the proposed workflow, we\ndemonstrate that the proposed simple ROMs are able to capture various complex\nfeatures of the power production curves of Fenton Hill HDR system. For typical\nEGS applications, ROM-2 and ROM-3 outperform ROM-1.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 21:05:16 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 05:22:16 GMT"}, {"version": "v3", "created": "Wed, 12 Jul 2017 19:05:32 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Mudunuru", "M. K.", ""], ["Karra", "S.", ""], ["Harp", "D. R.", ""], ["Guthrie", "G. D.", ""], ["Viswanathan", "H. S.", ""]]}, {"id": "1606.04872", "submitter": "Vincenzo Nicosia", "authors": "Nicol\\'o Musmeci, Vincenzo Nicosia, Tomaso Aste, Tiziana Di Matteo,\n  Vito Latora", "title": "The multiplex dependency structure of financial markets", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose here a multiplex network approach to investigate simultaneously\ndifferent types of dependency in complex data sets. In particular, we consider\nmultiplex networks made of four layers corresponding respectively to linear,\nnon-linear, tail, and partial correlations among a set of financial time\nseries. We construct the sparse graph on each layer using a standard network\nfiltering procedure, and we then analyse the structural properties of the\nobtained multiplex networks. The study of the time evolution of the multiplex\nconstructed from financial data uncovers important changes in intrinsically\nmultiplex properties of the network, and such changes are associated with\nperiods of financial stress. We observe that some features are unique to the\nmultiplex structure and would not be visible otherwise by the separate analysis\nof the single-layer networks corresponding to each dependency measure.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 17:28:59 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Musmeci", "Nicol\u00f3", ""], ["Nicosia", "Vincenzo", ""], ["Aste", "Tomaso", ""], ["Di Matteo", "Tiziana", ""], ["Latora", "Vito", ""]]}, {"id": "1606.04987", "submitter": "Yuxiang Wang", "authors": "Yuxiang Wang and Gregory J. Gerling", "title": "Automatic finite element implementation of hyperelastic material with a\n  double numerical differentiation algorithm", "comments": "19 pages, 3 figures, and 2 tables. Was presented as a podium\n  presentation at the Computer Methods in Biomechanics and Biomedical\n  Engineering 2015, September 3rd, Montreal, Quebec, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to accelerate implementation of hyperelastic materials for finite\nelement analysis, we developed an automatic numerical algorithm that only\nrequires the strain energy function. This saves the effort on analytical\nderivation and coding of stress and tangent modulus, which is time-consuming\nand prone to human errors. Using the one-sided Newton difference quotients, the\nproposed algorithm first perturbs deformation gradients and calculate the\ndifference on strain energy to approximate stress. Then, we perturb again to\nget difference in stress to approximate tangent modulus. Accuracy of the\napproximations were evaluated across the perturbation parameter space, where we\nfind the optimal amount of perturbation being $10^{-6}$ to obtain stress and\n$10^{-4}$ to obtain tangent modulus. Single element verification in ABAQUS with\nNeo-Hookean material resulted in a small stress error of only $7\\times10^{-5}$\non average across uniaxial compression and tension, biaxial tension and simple\nshear situations. A full 3D model with Holzapfel anisotropic material for\nartery inflation generated a small relative error of $4\\times10^{-6}$ for\ninflated radius at $25 kPa$ pressure. Results of the verification tests suggest\nthat the proposed numerical method has good accuracy and convergence\nperformance, therefore a good material implementation algorithm in small scale\nmodels and a useful debugging tool for large scale models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 17:54:41 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Wang", "Yuxiang", ""], ["Gerling", "Gregory J.", ""]]}, {"id": "1606.05168", "submitter": "Severin Sadjina", "authors": "Severin Sadjina, Eilif Pedersen", "title": "Energy Conservation and Coupling Error Reduction in Non-Iterative\n  Co-Simulations", "comments": "8 pages, 6 figures, 9 tables", "journal-ref": "Engineering with Computers (2019)", "doi": "10.1007/s00366-019-00783-4", "report-no": null, "categories": "cs.SY cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When simulators are energetically coupled in a co-simulation, residual\nenergies alter the total energy of the full coupled system. This distorts the\nsystem dynamics, lowers the quality of the results, and can lead to\ninstability. By using power bonds to realize simulator coupling, the\nEnergy-Conservation-based Co-Simulation method (ECCO) [Sadjina et al. 2016]\nexploits these concepts to define non-iterative global error estimation and\nadaptive step size control relying on coupling variable data alone. Following\nsimilar argumentation, the Nearly Energy Preserving Coupling Element (NEPCE)\n[Benedikt et al. 2013] uses corrections to the simulator inputs to\napproximately ensure energy conservation. Here, we discuss a modification to\nNEPCE for when direct feed-through is present in one of the coupled simulators.\nWe further demonstrate how accuracy and efficiency in non-iterative\nco-simulations are substantially enhanced when combining NEPCE with ECCO's\nadaptive step size controller. A quarter car model with linear and nonlinear\ndamping characteristics serves as a co-simulation benchmark, and we observe\nreductions of the coupling errors of up to 98% utilizing the concepts discussed\nhere.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 12:55:42 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Sadjina", "Severin", ""], ["Pedersen", "Eilif", ""]]}, {"id": "1606.05556", "submitter": "Alexandros Syrakos", "authors": "Alexandros Syrakos, Stylianos Varchanis, Yannis Dimakopoulos,\n  Apostolos Goulas, John Tsamopoulos", "title": "A critical analysis of some popular methods for the discretisation of\n  the gradient operator in finite volume methods", "comments": "Minor corrections compared to the previous version", "journal-ref": "Physics of Fluids 29, 127103 (2017)", "doi": "10.1063/1.4997682", "report-no": null, "categories": "cs.NA cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite volume methods (FVMs) constitute a popular class of methods for the\nnumerical simulation of fluid flows. Among the various components of these\nmethods, the discretisation of the gradient operator has received less\nattention despite its fundamental importance with regards to the accuracy of\nthe FVM. The most popular gradient schemes are the divergence theorem (DT) (or\nGreen-Gauss) scheme, and the least-squares (LS) scheme. Both are widely\nbelieved to be second-order accurate, but the present study shows that in fact\nthe common variant of the DT gradient is second-order accurate only on\nstructured meshes whereas it is zeroth-order accurate on general unstructured\nmeshes, and the LS gradient is second-order and first-order accurate,\nrespectively. This is explained through a theoretical analysis and is confirmed\nby numerical tests. The schemes are then used within a FVM to solve a simple\ndiffusion equation on unstructured grids generated by several methods; the\nresults reveal that the zeroth-order accuracy of the DT gradient is inherited\nby the FVM as a whole, and the discretisation error does not decrease with grid\nrefinement. On the other hand, use of the LS gradient leads to second-order\naccurate results, as does the use of alternative, consistent, DT gradient\nschemes, including a new iterative scheme that makes the common DT gradient\nconsistent at almost no extra cost. The numerical tests are performed using\nboth an in-house code and the popular public domain PDE solver OpenFOAM.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 15:18:08 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 15:29:54 GMT"}, {"version": "v3", "created": "Sat, 3 Jun 2017 21:53:08 GMT"}, {"version": "v4", "created": "Mon, 19 Jun 2017 19:59:48 GMT"}, {"version": "v5", "created": "Tue, 25 Jul 2017 10:44:42 GMT"}, {"version": "v6", "created": "Fri, 29 Dec 2017 19:59:15 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Syrakos", "Alexandros", ""], ["Varchanis", "Stylianos", ""], ["Dimakopoulos", "Yannis", ""], ["Goulas", "Apostolos", ""], ["Tsamopoulos", "John", ""]]}, {"id": "1606.05656", "submitter": "Leopoldo Catania", "authors": "Leopoldo Catania and Nima Nonejad", "title": "Dynamic Model Averaging for Practitioners in Economics and Finance: The\n  eDMA Package", "comments": "21 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raftery, Karny, and Ettler (2010) introduce an estimation technique, which\nthey refer to as Dynamic Model Averaging (DMA). In their application, DMA is\nused to predict the output strip thickness for a cold rolling mill, where the\noutput is measured with a time delay. Recently, DMA has also shown to be useful\nin macroeconomic and financial applications. In this paper, we present the eDMA\npackage for DMA estimation implemented in R. The eDMA package is especially\nsuited for practitioners in economics and finance, where typically a large\nnumber of predictors are available. Our implementation is up to 133 times\nfaster then a standard implementation using a single-core CPU. Thus, with the\nhelp of this package, practitioners are able to perform DMA on a standard PC\nwithout resorting to large clusters, which are not easily available to all\nresearchers. We demonstrate the usefulness of this package through simulation\nexperiments and an empirical application using quarterly U.S. inflation data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 20:00:56 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 14:30:52 GMT"}, {"version": "v3", "created": "Mon, 16 Oct 2017 19:34:04 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Catania", "Leopoldo", ""], ["Nonejad", "Nima", ""]]}, {"id": "1606.06143", "submitter": "Olivier Pironneau", "authors": "Gilles Pag\\`es (UPMC), Olivier Pironneau (LJLL), Guillaume Sall (LJLL)", "title": "Vibrato and automatic differentiation for high order derivatives and\n  sensitivities of financial options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the computation of second or higher order greeks of\nfinancial securities. It combines two methods, Vibrato and automatic\ndifferentiation and compares with other methods. We show that this combined\ntechnique is faster than standard finite difference, more stable than automatic\ndifferentiation of second order derivatives and more general than Malliavin\nCalculus. We present a generic framework to compute any greeks and present\nseveral applications on different types of financial contracts: European and\nAmerican options, multidimensional Basket Call and stochastic volatility models\nsuch as Heston's model. We give also an algorithm to compute derivatives for\nthe Longstaff-Schwartz Monte Carlo method for American options. We also extend\nautomatic differentiation for second order derivatives of options with\nnon-twice differentiable payoff. 1. Introduction. Due to BASEL III regulations,\nbanks are requested to evaluate the sensitivities of their portfolios every day\n(risk assessment). Some of these portfolios are huge and sensitivities are time\nconsuming to compute accurately. Faced with the problem of building a software\nfor this task and distrusting automatic differentiation for non-differentiable\nfunctions, we turned to an idea developed by Mike Giles called Vibrato. Vibrato\nat core is a differentiation of a combination of likelihood ratio method and\npathwise evaluation. In Giles [12], [13], it is shown that the computing time,\nstability and precision are enhanced compared with numerical differentiation of\nthe full Monte Carlo path. In many cases, double sensitivities, i.e. second\nderivatives with respect to parameters, are needed (e.g. gamma hedging). Finite\ndifference approximation of sensitivities is a very simple method but its\nprecision is hard to control because it relies on the appropriate choice of the\nincrement. Automatic differentiation of computer programs bypass the difficulty\nand its computing cost is similar to finite difference, if not cheaper. But in\nfinance the payoff is never twice differentiable and so generalized derivatives\nhave to be used requiring approximations of Dirac functions of which the\nprecision is also doubtful. The purpose of this paper is to investigate the\nfeasibility of Vibrato for second and higher derivatives. We will first compare\nVibrato applied twice with the analytic differentiation of Vibrato and show\nthat it is equivalent, as the second is easier we propose the best compromise\nfor second derivatives: Automatic Differentiation of Vibrato. In [8], Capriotti\nhas recently investigated the coupling of different mathematical methods --\nnamely pathwise and likelihood ratio methods -- with an Automatic differ\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 14:36:39 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Pag\u00e8s", "Gilles", "", "UPMC"], ["Pironneau", "Olivier", "", "LJLL"], ["Sall", "Guillaume", "", "LJLL"]]}, {"id": "1606.06154", "submitter": "Julius Smith III", "authors": "Julius Orion Smith and Harrison Freeman Smith", "title": "Closed Form Fractional Integration and Differentiation via Real\n  Exponentially Spaced Pole-Zero Pairs", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.SD cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive closed-form expressions for the poles and zeros of approximate\nfractional integrator/differentiator filters, which correspond to spectral\nroll-off filters having any desired log-log slope to a controllable degree of\naccuracy over any bandwidth. The filters can be described as a uniform\nexponential distribution of poles along the negative-real axis of the s plane,\nwith zeros interleaving them. Arbitrary spectral slopes are obtained by sliding\nthe array of zeros relative to the array of poles, where each array maintains\nperiodic spacing on a log scale. The nature of the slope approximation is close\nto Chebyshev optimal in the interior of the pole-zero array, approaching\nconjectured Chebyshev optimality over all frequencies in the limit as the order\napproaches infinity. Practical designs can arbitrarily approach the\nequal-ripple approximation by enlarging the pole-zero array band beyond the\ndesired frequency band. The spectral roll-off slope can be robustly modulated\nin real time by varying only the zeros controlled by one slope parameter.\nSoftware implementations are provided in matlab and Faust.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 07:01:50 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Smith", "Julius Orion", ""], ["Smith", "Harrison Freeman", ""]]}, {"id": "1606.06512", "submitter": "Krishnamurthy Dvijotham", "authors": "Krishnamurthy Dvijotham, Pascal Van Hentenryck, Michael Chertkov,\n  Sidhant Misra, Marc Vuffray", "title": "Graphical Models for Optimal Power Flow", "comments": "To appear in Proceedings of the 22nd International Conference on\n  Principles and Practice of Constraint Programming (CP 2016(", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.CE math.OC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal power flow (OPF) is the central optimization problem in electric\npower grids. Although solved routinely in the course of power grid operations,\nit is known to be strongly NP-hard in general, and weakly NP-hard over tree\nnetworks. In this paper, we formulate the optimal power flow problem over tree\nnetworks as an inference problem over a tree-structured graphical model where\nthe nodal variables are low-dimensional vectors. We adapt the standard dynamic\nprogramming algorithm for inference over a tree-structured graphical model to\nthe OPF problem. Combining this with an interval discretization of the nodal\nvariables, we develop an approximation algorithm for the OPF problem. Further,\nwe use techniques from constraint programming (CP) to perform interval\ncomputations and adaptive bound propagation to obtain practically efficient\nalgorithms. Compared to previous algorithms that solve OPF with optimality\nguarantees using convex relaxations, our approach is able to work for arbitrary\ndistribution networks and handle mixed-integer optimization problems. Further,\nit can be implemented in a distributed message-passing fashion that is scalable\nand is suitable for \"smart grid\" applications like control of distributed\nenergy resources. We evaluate our technique numerically on several benchmark\nnetworks and show that practical OPF problems can be solved effectively using\nthis approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 11:04:10 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Dvijotham", "Krishnamurthy", ""], ["Van Hentenryck", "Pascal", ""], ["Chertkov", "Michael", ""], ["Misra", "Sidhant", ""], ["Vuffray", "Marc", ""]]}, {"id": "1606.06975", "submitter": "Yuehaw Khoo", "authors": "Yuehaw Khoo, Amit Singer, David Cowburn", "title": "Bias Correction in Saupe Tensor Estimation", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of the Saupe tensor is central to the determination of molecular\nstructures from residual dipolar couplings (RDC) or chemical shift\nanisotropies. Assuming a given template structure, the singular value\ndecomposition (SVD) method proposed in Losonczi et al. 1999 has been used\ntraditionally to estimate the Saupe tensor. Despite its simplicity, whenever\nthe template structure has large structural noise, the eigenvalues of the\nestimated tensor have a magnitude systematically smaller than their actual\nvalues. This leads to systematic error when calculating the eigenvalue\ndependent parameters, magnitude and rhombicity. We propose here a Monte Carlo\nsimulation method to remove such bias. We further demonstrate the effectiveness\nof our method in the setting when the eigenvalue estimates from multiple\ntemplate protein fragments are available and their average is used as an\nimproved eigenvalue estimator. For both synthetic and experimental RDC datasets\nof ubiquitin, when using template fragments corrupted by large noise, the\nmagnitude of our proposed bias-reduced estimator generally reaches at least 90%\nof the actual value, whereas the magnitude of SVD estimator can be shrunk below\n80% of the true value.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 15:05:23 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Khoo", "Yuehaw", ""], ["Singer", "Amit", ""], ["Cowburn", "David", ""]]}, {"id": "1606.07149", "submitter": "Ivo Bukovsky Ph.D.", "authors": "Ivo Bukovsky and Noriyasu Homma", "title": "An Approach to Stable Gradient Descent Adaptation of Higher-Order Neural\n  Units", "comments": "2016, 13 pages", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems,ISSN:\n  2162-237X,2016", "doi": "10.1109/TNNLS.2016.2572310", "report-no": null, "categories": "cs.NE cs.AI cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability evaluation of a weight-update system of higher-order neural units\n(HONUs) with polynomial aggregation of neural inputs (also known as classes of\npolynomial neural networks) for adaptation of both feedforward and recurrent\nHONUs by a gradient descent method is introduced. An essential core of the\napproach is based on spectral radius of a weight-update system, and it allows\nstability monitoring and its maintenance at every adaptation step individually.\nAssuring stability of the weight-update system (at every single adaptation\nstep) naturally results in adaptation stability of the whole neural\narchitecture that adapts to target data. As an aside, the used approach\nhighlights the fact that the weight optimization of HONU is a linear problem,\nso the proposed approach can be generally extended to any neural architecture\nthat is linear in its adaptable parameters.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 01:07:27 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Bukovsky", "Ivo", ""], ["Homma", "Noriyasu", ""]]}, {"id": "1606.07981", "submitter": "Amir Hosein Zamanian", "authors": "Amir Hosein Zamanian, Abdolreza Ohadi", "title": "Gear fault diagnosis based on Gaussian correlation of vibrations signals\n  and wavelet coefficients", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2011.06.020", "report-no": null, "categories": "cs.IT cs.CE cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The features of non-stationary multi-component signals are often difficult to\nbe extracted for expert systems. In this paper, a new method for feature\nextraction that is based on maximization of local Gaussian correlation function\nof wavelet coefficients and signal is presented. The effect of empirical mode\ndecomposition (EMD) to decompose multi-component signals to intrinsic mode\nfunctions (IMFs), before using of local Gaussian correlation is discussed. The\nexperimental vibration signals from two gearbox systems are used to show the\nefficiency of the presented method. Linear support vector machine (SVM) is\nutilized to classify feature sets extracted with the presented method. The\nobtained results show that the features extracted in this method have excellent\nability to classify faults without any additional feature selection; it is also\nshown that EMD can improve or degrade features according to the utilized\nfeature reduction method.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 00:16:44 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Zamanian", "Amir Hosein", ""], ["Ohadi", "Abdolreza", ""]]}, {"id": "1606.08040", "submitter": "Birte Schmidtmann", "authors": "Birte Schmidtmann, Mariia Astrakhantceva, Manuel Torrilhon", "title": "Hybrid Riemann Solvers for Large Systems of Conservation Laws", "comments": "9 pages", "journal-ref": "Eccomas Proceedia ID: 2395 / Conference Proceeding ID: 11923", "doi": "10.7712/100016.2395.11923", "report-no": null, "categories": "math.NA astro-ph.IM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new family of approximate Riemann solvers for the\nnumerical approximation of solutions of hyperbolic conservation laws. They are\napproximate, also referred to as incomplete, in the sense that the solvers\navoid computing the characteristic decomposition of the flux Jacobian. Instead,\nthey require only an estimate of the globally fastest wave speeds in both\ndirections. Thus, this family of solvers is particularly efficient for large\nsystems of conservation laws, i.e. with many different propagation speeds, and\nwhen no explicit expression for the eigensystem is available. Even though only\nfastest wave speeds are needed as input values, the new family of Riemann\nsolvers reproduces all waves with less dissipation than HLL, which has the same\nprerequisites, requiring only one additional flux evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 13:55:25 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Schmidtmann", "Birte", ""], ["Astrakhantceva", "Mariia", ""], ["Torrilhon", "Manuel", ""]]}, {"id": "1606.08761", "submitter": "Piero Triverio", "authors": "Fadime Bekmambetova, Xinyue Zhang and Piero Triverio", "title": "A Dissipative Systems Theory for FDTD with Application to Stability\n  Analysis and Subgridding", "comments": null, "journal-ref": null, "doi": "10.1109/TAP.2016.2637867", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a far-reaching connection between the\nFinite-Difference Time-Domain method (FDTD) and the theory of dissipative\nsystems. The FDTD equations for a rectangular region are written as a dynamical\nsystem having the magnetic and electric fields on the boundary as inputs and\noutputs. Suitable expressions for the energy stored in the region and the\nenergy absorbed from the boundaries are introduced, and used to show that the\nFDTD system is dissipative under a generalized Courant-Friedrichs-Lewy\ncondition. Based on the concept of dissipation, a powerful theoretical\nframework to investigate the stability of FDTD methods is devised. The new\nmethod makes FDTD stability proofs simpler, more intuitive, and modular.\nStability conditions can indeed be given on the individual components (e.g.\nboundary conditions, meshes, embedded models) instead of the whole coupled\nsetup. As an example of application, we derive a new subgridding method with\nmaterial traverse, arbitrary grid refinement, and guaranteed stability. The\nmethod is easy to implement and has a straightforward stability proof.\nNumerical results confirm its stability, low reflections, and ability to handle\nmaterial traverse.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 15:45:32 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Bekmambetova", "Fadime", ""], ["Zhang", "Xinyue", ""], ["Triverio", "Piero", ""]]}]