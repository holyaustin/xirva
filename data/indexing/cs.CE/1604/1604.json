[{"id": "1604.00547", "submitter": "Hoang X. Nguyen", "authors": "Hoang X. Nguyen, Tuan N. Nguyen, M. Abdel-Wahab, S.P.A. Bordas, H.\n  Nguyen-Xuan, Thuc P. Vo", "title": "Isogeometric analysis for functionally graded microplates based on\n  modified couple stress theory", "comments": "57 pages, 14 figures, 18 tables", "journal-ref": null, "doi": "10.1016/j.cma.2016.10.002", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of static bending, free vibration and buckling behaviours of\nfunctionally graded microplates is investigated in this study. The main idea is\nto use the isogeometric analysis in associated with novel four-variable refined\nplate theory and quasi-3D theory. More importantly, the modified couple stress\ntheory with only one material length scale parameter is employed to effectively\ncapture the size-dependent effects within the microplates. Meanwhile, the\nquasi-3D theory which is constructed from a novel seventh-order shear\ndeformation refined plate theory with four unknowns is able to consider both\nshear deformations and thickness stretching effect without requiring shear\ncorrection factors. The NURBS-based isogeometric analysis is integrated to\nexactly describe the geometry and approximately calculate the unknown fields\nwith higher-order derivative and continuity requirements. The convergence and\nverification show the validity and efficiency of this proposed computational\napproach in comparison with those existing in the literature. It is further\napplied to study the static bending, free vibration and buckling responses of\nrectangular and circular functionally graded microplates with various types of\nboundary conditions. A number of investigations are also conducted to\nillustrate the effects of the material length scale, material index, and\nlength-to-thickness ratios on the responses of the microplates.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 19:33:15 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Nguyen", "Hoang X.", ""], ["Nguyen", "Tuan N.", ""], ["Abdel-Wahab", "M.", ""], ["Bordas", "S. P. A.", ""], ["Nguyen-Xuan", "H.", ""], ["Vo", "Thuc P.", ""]]}, {"id": "1604.00594", "submitter": "Pradip Sircar", "authors": "Santhosh Kumar, Pradip Sircar", "title": "Two Dimensional Angle of Arrival Estimation", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for the estimation of two dimensional (2D) angles of\narrival (AOAs), namely, azimuth and incidence angles of multiple narrowband\nsignals of same frequency in the far field of antenna array.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 05:21:19 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Kumar", "Santhosh", ""], ["Sircar", "Pradip", ""]]}, {"id": "1604.00812", "submitter": "Farshad Rassaei", "authors": "Farshad Rassaei, Wee-Seng Soh, Kee-Chaing Chua", "title": "Decarbonized Demand Response for Residential Plug-in Electric Vehicles\n  in Smart Grids", "comments": "arXiv admin note: text overlap with arXiv:1505.06505,\n  arXiv:1512.06600", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, in Paris, the world has reached an agreement whereby many countries\ncommit to bolster their efforts about reducing adverse climate changes. Hence,\nwe can expect that decarbonization will even attract more attention in\ndifferent energy sectors in near future. In particular, both generation side\nand consumption side are required to be run more congruently and\nenvironmentally friendly. Thus, employing the renewables at the generation side\nalong with our proposed decarbonized demand response (DDR) at the consumption\nside could significantly reduce deleterious impacts on the climate. Such\nambition, at the consumption side, necessitates symbiosis and synergy between\nthe customers and the retailer, and among customers, respectively. In other\nwords, there should be some incentive-based collaboration between customers and\nthe retailer as well as coordination among customers to make the objective be\nachieved successfully. In this paper, we present such matching demand response\n(DR) algorithm for residential users owning vehicle-to-grid (V2G) enabled\nplug-in electric vehicles (PEVs) who obtain electricity from a common retailer.\nThe retailer itself is connected to the wholesale electricity market to\npurchase and sell electricity. Furthermore, we explain the details of the\nexisting symbiosis and synergy in our system. Our simulation results illustrate\nthat substantial cost savings can be achieved along with pollution reduction by\nour proposed technique.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 11:04:40 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Rassaei", "Farshad", ""], ["Soh", "Wee-Seng", ""], ["Chua", "Kee-Chaing", ""]]}, {"id": "1604.01367", "submitter": "Hung Nguyen-Xuan", "authors": "T. Le-Manh, Q. Huynh-Van, Thu D. Phan, Huan D. Phan, H. Nguyen-Xuan", "title": "Isogeometric nonlinear bending and buckling analysis of\n  variable-thickness composite plate structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates nonlinear bending and buckling behaviours of\ncomposite plates characterized by a thickness variation. Layer interfaces are\ndescribed as functions of inplane coordinates. Top and bottom surfaces of the\nplate are symmetric about the midplane and the plate could be considered as a\nflat surface in analysis along with thickness parameters which vary over the\nplate. The variable thickness at a certain position in the midplane is modeled\nby a set of control points (or thickness-parameters) through NURBS (Non-Uniform\nRational B-Spline) basic functions. The knot parameter space which is referred\nin modelling geometry and approximating displacement variables is employed for\napproximating thickness, simultaneously. The use of quadratic NURBS functions\nresults in C^1 continuity of modeling variable thickness and analyzing\nsolutions. Thin to moderately thick laminates in bound of first-order shear\ndeformation theory (FSDT) are taken into account. Strain-displacement relations\nin sense of von-Karman theory are employed for large deformation. Riks method\nis used for geometrically nonlinear analysis. The weak form is approximated\nnumerically by the isogeometric analysis (IGA), which has been found to be a\nrobust, stable and realistic numerical tool. Numerical results confirm the\nreliability and capacity of the propose method.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 19:45:23 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Le-Manh", "T.", ""], ["Huynh-Van", "Q.", ""], ["Phan", "Thu D.", ""], ["Phan", "Huan D.", ""], ["Nguyen-Xuan", "H.", ""]]}, {"id": "1604.01504", "submitter": "Yuehaw Khoo", "authors": "Yuehaw Khoo, Amit Singer, David Cowburn", "title": "Integrating NOE and RDC using sum-of-squares relaxation for protein\n  structure determination", "comments": "41 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of protein structure determination from geometrical\nrestraints from NMR, using convex optimization. It is well-known that the\nNP-hard distance geometry problem of determining atomic positions from pairwise\ndistance restraints can be relaxed into a convex semidefinite program. Often\nthe NOE distance restraints are too imprecise and sparse for accurate structure\ndetermination. Residual dipolar coupling (RDC) measurements provide additional\ngeometric information on the angles between atom-pair directions and axes of\nthe principal-axis-frame. The optimization problem involving RDC is highly\nnon-convex and requires a good initialization even within the simulated\nannealing framework. In this paper, we model the protein backbone as an\narticulated structure composed of rigid units. Determining the rotation of each\nrigid unit gives the full protein structure. We propose solving the non-convex\noptimization problems using the sum-of-squares (SOS) hierarchy. The two\nalgorithms - RDC-SOS and RDC-NOE-SOS, have polynomial time complexity in the\nnumber of amino-acid residues and run efficiently on a standard desktop. In\nmany instances, the proposed methods exactly recover the solution to the\noriginal non-convex optimization problem. We introduce a statistical tool, the\nCramer-Rao bound (CRB), to provide an information theoretic bound on the\nhighest resolution one can hope to achieve when determining protein structure\nfrom noisy measurements using any methodology. Our simulation results show that\nwhen the RDC measurements are corrupted by Gaussian noise of realistic\nvariance, both SOS based algorithms attain the CRB. We successfully apply our\nmethod in a divide-and-conquer fashion to determine the structure of ubiquitin\nfrom experimental NOE and RDC measurements, achieving more accurate and faster\nreconstructions compared to the current state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 06:22:35 GMT"}, {"version": "v2", "created": "Sun, 10 Apr 2016 19:24:48 GMT"}, {"version": "v3", "created": "Thu, 12 May 2016 18:45:56 GMT"}, {"version": "v4", "created": "Sun, 15 May 2016 17:23:21 GMT"}, {"version": "v5", "created": "Sun, 26 Feb 2017 20:00:00 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Khoo", "Yuehaw", ""], ["Singer", "Amit", ""], ["Cowburn", "David", ""]]}, {"id": "1604.01651", "submitter": "Rebecca E. Morrison", "authors": "Rebecca E Morrison, Todd A Oliver, Robert D Moser", "title": "Representing model inadequacy: A stochastic operator approach", "comments": null, "journal-ref": "SIAM/ASA Journal on Uncertainty Quantification 6 (2), 457-496\n  (2018)", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical models of physical systems are subject to many uncertainties\nsuch as measurement errors and uncertain initial and boundary conditions. After\naccounting for these uncertainties, it is often revealed that discrepancies\nbetween the model output and the observations remain; if so, the model is said\nto be inadequate. In practice, the inadequate model may be the best that is\navailable or tractable, and so despite its inadequacy the model may be used to\nmake predictions of unobserved quantities. In this case, a representation of\nthe inadequacy is necessary, so the impact of the observed discrepancy can be\ndetermined. We investigate this problem in the context of chemical kinetics and\npropose a new technique to account for model inadequacy that is both\nprobabilistic and physically meaningful. A stochastic inadequacy operator\n$\\mathcal{S}$ is introduced which is embedded in the ODEs describing the\nevolution of chemical species concentrations and which respects certain\nphysical constraints such as conservation laws. The parameters of $\\mathcal{S}$\nare governed by probability distributions, which in turn are characterized by a\nset of hyperparameters. The model parameters and hyperparameters are calibrated\nusing high-dimensional hierarchical Bayesian inference. We apply the method to\na typical problem in chemical kinetics---the reaction mechanism of hydrogen\ncombustion.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 14:57:56 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 19:50:34 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 17:53:58 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Morrison", "Rebecca E", ""], ["Oliver", "Todd A", ""], ["Moser", "Robert D", ""]]}, {"id": "1604.02099", "submitter": "Yoo Ah Kim", "authors": "Yoo-Ah Kim, Sanna Madan, and Teresa M. Przytycka", "title": "WeSME: Uncovering Mutual Exclusivity of Cancer Drivers and Beyond", "comments": "Paper accepted at RECOMB-CCB 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual exclusivity is a widely recognized property of many cancer drivers.\nKnowledge about these relationships can provide important insights into cancer\ndrivers, cancer-driving pathways, and cancer subtypes. It can also be used to\npredict new functional interactions between cancer driving genes and uncover\nnovel cancer drivers. Currently, most of mutual exclusivity analyses are\npreformed focusing on a limited set of genes in part due to the computational\ncost required to rigorously compute p-values. To reduce the computing cost and\nperform less restricted mutual exclusivity analysis, we developed an efficient\nmethod to estimate p-values while controlling the mutation rates of individual\npatients and genes similar to the permutation test. A comprehensive mutual\nexclusivity analysis allowed us to uncover mutually exclusive pairs, some of\nwhich may have relatively low mutation rates. These pairs often included likely\ncancer drivers that have been missed in previous analyses. More importantly,\nour results demonstrated that mutual exclusivity can also provide information\nthat goes beyond the interactions between cancer drivers and can, for example,\nelucidate different mutagenic processes in different cancer groups. In\nparticular, including frequently mutated, long genes such as TTN in our\nanalysis allowed us to observe interesting patterns of APOBEC activity in\nbreast cancer and identify a set of related driver genes that are highly\npredictive of patient survival. In addition, we utilized our mutual exclusivity\nanalysis in support of a previously proposed model where APOBEC activity is the\nunderlying process that causes TP53 mutations in a subset of breast cancer\ncases.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 18:18:21 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Kim", "Yoo-Ah", ""], ["Madan", "Sanna", ""], ["Przytycka", "Teresa M.", ""]]}, {"id": "1604.03081", "submitter": "Jan Hoinka", "authors": "Phuong Dao, Jan Hoinka, Yijie Wang, Mayumi Takahashi, Jiehua Zhou,\n  Fabrizio Costa, John Rossi, John Burnett, Rolf Backofen, Teresa M. Przytycka", "title": "AptaTRACE: Elucidating Sequence-Structure Binding Motifs by Uncovering\n  Selection Trends in HT-SELEX Experiments", "comments": "This paper was selected for oral presentation at RECOMB 2016 and an\n  abstract is published in the conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aptamers, short synthetic RNA/DNA molecules binding specific targets with\nhigh affinity and specificity, are utilized in an increasing spectrum of\nbio-medical applications. Aptamers are identified in vitro via the Systematic\nEvolution of Ligands by Exponential Enrichment (SELEX) protocol. SELEX selects\nbinders through an iterative process that, starting from a pool of random\nssDNA/RNA sequences, amplifies target-affine species through a series of\nselection cycles. HT-SELEX, which combines SELEX with high throughput\nsequencing, has recently transformed aptamer development and has opened the\nfield to even more applications. HT-SELEX is capable of generating over half a\nbillion data points, challenging computational scientists with the task of\nidentifying aptamer properties such as sequence structure motifs that determine\nbinding. While currently available motif finding approaches suggest partial\nsolutions to this question, none possess the generality or scalability required\nfor HT-SELEX data, and they do not take advantage of important properties of\nthe experimental procedure.\n  We present AptaTRACE, a novel approach for the identification of\nsequence-structure binding motifs in HT-SELEX derived aptamers. Our approach\nleverages the experimental design of the SELEX protocol and identifies\nsequence-structure motifs that show a signature of selection. Because of its\nunique approach, AptaTRACE can uncover motifs even when these are present in\nonly a minuscule fraction of the pool. Due to these features, our method can\nhelp to reduce the number of selection cycles required to produce aptamers with\nthe desired properties, thus reducing cost and time of this rather expensive\nprocedure. The performance of the method on simulated and real data indicates\nthat AptaTRACE can detect sequence-structure motifs even in highly challenging\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 18:47:52 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Dao", "Phuong", ""], ["Hoinka", "Jan", ""], ["Wang", "Yijie", ""], ["Takahashi", "Mayumi", ""], ["Zhou", "Jiehua", ""], ["Costa", "Fabrizio", ""], ["Rossi", "John", ""], ["Burnett", "John", ""], ["Backofen", "Rolf", ""], ["Przytycka", "Teresa M.", ""]]}, {"id": "1604.03195", "submitter": "Carlos Leandro", "authors": "Carlos Leandro and Jorge Ambr\\'osio", "title": "Multibody minimum-energy trajectory with applications to protein folding", "comments": "41 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the optimal control of multibody systems being actuated\nwith control forces in order to find a dynamically feasible minimum-energy\ntrajectory of the system. The optimal control problem and its constraints are\nintegrated in a discrete version of the equation of motion allowing the\nminimization of system energy with respect to a discrete state and control\ntrajectory. The work is centred on a specific type of open-chain multibody\nsystem, with strong local propensity, where the overall system kinematics is\ndescribed essentially by the torsion around the links that connect rigid\nbodies. The coupling between the rigid body motion, and the optimal\nconformation is described as an elastic band of replicas of the original system\nwith different conformations. The band forces are used to control system's\nmotion directly, reflecting the influence of the system energy field on its\nconformation, using for that the Nudged-Elastic Band method. Here the equation\nof motion of the multibody grid are solved by using the augmented Lagrangean\nmethod. In this context, if a feasible minimum-energy trajectory of the\noriginal system exists it is a stationary state of the extended system. This\napproach is applied to the folding of a single chain protein.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 01:26:44 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 11:17:28 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Leandro", "Carlos", ""], ["Ambr\u00f3sio", "Jorge", ""]]}, {"id": "1604.05015", "submitter": "Indranil Ghosh", "authors": "Tamal Datta Chaudhuri and Indranil Ghosh", "title": "Using Clustering Method to Understand Indian Stock Market Volatility", "comments": null, "journal-ref": null, "doi": "10.5120/cae2015651793", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use Clustering Method to understand whether stock market\nvolatility can be predicted at all, and if so, when it can be predicted. The\nexercise has been performed for the Indian stock market on daily data for two\nyears. For our analysis we map number of clusters against number of variables.\nWe then test for efficiency of clustering. Our contention is that, given a\nfixed number of variables, one of them being historic volatility of NIFTY\nreturns, if increase in the number of clusters improves clustering efficiency,\nthen volatility cannot be predicted. Volatility then becomes random as, for a\ngiven time period, it gets classified in various clusters. On the other hand,\nif efficiency falls with increase in the number of clusters, then volatility\ncan be predicted as there is some homogeneity in the data. If we fix the number\nof clusters and then increase the number of variables, this should have some\nimpact on clustering efficiency. Indeed if we can hit upon, in a sense, an\noptimum number of variables, then if the number of clusters is reasonably\nsmall, we can use these variables to predict volatility. The variables that we\nconsider for our study are volatility of NIFTY returns, volatility of gold\nreturns, India VIX, CBOE VIX, volatility of crude oil returns, volatility of\nDJIA returns, volatility of DAX returns, volatility of Hang Seng returns and\nvolatility of Nikkei returns. We use three clustering algorithms namely Kernel\nK-Means, Self Organizing Maps and Mixture of Gaussian models and two internal\nclustering validity measures, Silhouette Index and Dunn Index, to assess the\nquality of generated clusters.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 06:58:30 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Chaudhuri", "Tamal Datta", ""], ["Ghosh", "Indranil", ""]]}, {"id": "1604.05122", "submitter": "Lubin  Vulkov", "authors": "Tatiana P. Chernogorova, Lubin G. Vulkov", "title": "Numerical solution of a parabolic system in air pollution", "comments": "10 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An air pollution model is generally described by a system of PDEs on\nunbounded domain. Transformation of the independent variable is used to convert\nthe problem for nonlinear air pollution on finite computational domain. We\ninvestigate the new, degenerated parabolic problem in Sobolev spaces with\nweights for well-posedness and positivity of the solution. Then we construct a\nfitted finite volume difference scheme. Some results from computations are\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 12:44:39 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Chernogorova", "Tatiana P.", ""], ["Vulkov", "Lubin G.", ""]]}, {"id": "1604.05178", "submitter": "Lubin  Vulkov", "authors": "Yuri M. Dimitrov, Lubin G. Vulkov", "title": "High order finite difference schemes on non-uniform meshes for the\n  time-fractional Black-Scholes equation", "comments": "9 pages, 2 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a three-point compact finite difference scheme on a non-uniform\nmesh for the time-fractional Black-Scholes equation. We show that for special\ngraded meshes used in finance, the Tavella-Randall and the quadratic meshes the\nnumerical solution has a fourth-order accuracy in space. Numerical experiments\nare discussed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 14:25:55 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Dimitrov", "Yuri M.", ""], ["Vulkov", "Lubin G.", ""]]}, {"id": "1604.05201", "submitter": "Lubin  Vulkov", "authors": "Ivanka Tr. Angelova, Lubin G. Vulkov", "title": "Two-grid algorithms for singularly perturbed reaction-diffusion problems\n  on layer adapted meshes", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new two-grid approach based on Bellman-Kalaba quasilinearization\nand Axelsson-Xu finite element two-grid method for the solution of singularly\nperturbed reaction-diffusion equations. The algorithms involve solving one\ninexpensive problem on coarse grid and solving on fine grid one linear problem\nobtained by quasilinearization of the differential equation about an\ninterpolant of the computed solution on the coarse grid. Different meshes (of\nBakhvalov, Shishkin and Vulanovi\\'c types) are examined. All the schemes are\nuniformly convergent with respect to the small parameter. We show theoretically\nand numerically that the global error of the two-grid method is the same as of\nthe nonlinear problem solved directly on the fine layer-adapted mesh.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 15:15:01 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Angelova", "Ivanka Tr.", ""], ["Vulkov", "Lubin G.", ""]]}, {"id": "1604.06416", "submitter": "Roee Diamant", "authors": "Roee Diamant", "title": "Computationally Efficient Calculations of Target Performance of the\n  Normalized Matched Filter Detector for Hydrocoustic Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CE cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of hydroacoustic transmissions is a key enabling technology in\napplications such as depth measurements, detection of objects, and undersea\nmapping. To cope with the long channel delay spread and the low signal-to-noise\nratio, hydroacoustic signals are constructed with a large time-bandwidth\nproduct, $N$. A promising detector for hydroacoustic signals is the normalized\nmatched filter (NMF). For the NMF, the detection threshold depends only on $N$,\nthereby obviating the need to estimate the characteristics of the sea ambient\nnoise which are time-varying and hard to estimate. While previous works\nanalyzed the characteristics of the normalized matched filter (NMF), for\nhydroacoustic signals with large $N$ values the expressions available are\ncomputationally complicated to evaluate. Specifically for hydroacoustic signals\nof large $N$ values, this paper presents approximations for the probability\ndistribution of the NMF. These approximations are found extremely accurate in\nnumerical simulations. We also outline a computationally efficient method to\ncalculate the receiver operating characteristic (ROC) which is required to\ndetermine the detection threshold. Results from an experiment conducted in the\nMediterranean sea at depth of 900~m agree with the analysis.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 17:42:19 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Diamant", "Roee", ""]]}, {"id": "1604.06777", "submitter": "Olivier Delestre", "authors": "M Abily (I-CiTy), O Delestre (JAD), P Gourbesville (I-CiTy), N\n  Bertrand (IRSN), C.-M Duluc (IRSN), Y Richet (IRSN)", "title": "Global Sensitivity Analysis with 2D Hydraulic Codes: Application on\n  Uncertainties Related to High-Resolution Topographic Data", "comments": null, "journal-ref": "2014, Jun 2014, Sophia Antipolis - Nice, France. Springer\n  Singapore, Advances in Hydroinformatics - Simhydro 2014, pp.301-315, 2015,\n  Advances in Hydroinformatics - Simhydro 2014", "doi": "10.1007/978-981-287-615-7_21", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technologies such as aerial photogrammetry allow production of 3D topographic\ndata including complex environments such as urban areas. Therefore, it is\npossible to create High Resolution (HR) Digital Elevation Models (DEM)\nincorporating thin above ground elements influencing overland flow paths. Even\nthough this category of big data has a high level of accuracy, there are still\nerrors in measurements and hypothesis under DEM elaboration. Moreover,\noperators look for optimizing spatial discretization resolution in order to\nimprove flood models computation time. Errors in measurement, errors in DEM\ngeneration, and operator choices for inclusion of this data within 2D hydraulic\nmodel, might influence results of flood models simulations. These errors and\nhypothesis may influence significantly flood modelling results variability. The\npurpose of this study is to investigate uncertainties related to (i) the own\nerror of high resolution topographic data, and (ii) the modeller choices when\nincluding topographic data in hydraulic codes. The aim is to perform a Global\nSensitivity Analysis (GSA) which goes through a Monte-Carlo uncertainty\npropagation, to quantify impact of uncertainties, followed by a Sobol' indices\ncomputation, to rank influence of identified parameters on result variability.\nA process using a coupling of an environment for parametric computation\n(Prom{\\'e}th{\\'e}e) and a code relying on 2D shallow water equations (FullSWOF\n2D) has been developed (P-FS tool). The study has been performed over the lower\npart of the Var river valley using the estimated hydrograph of 1994 flood\nevent. HR topographic data has been made available for the study area, which is\n17.5 km 2 , by Nice municipality. Three uncertain parameters were studied: the\nmeasurement error (var. E), the level of details of above-ground element\nrepresentation in DEM (buildings, sidewalks, etc.) (var. S), and the spatial\ndiscretization resolution (grid cell size for regular mesh) (var. R). Parameter\nvar. E follows a probability density function, whereas parameters var. S and\nvar. R. are discrete operator choices. Combining these parameters, a database\nof 2, 000 simulations has been produced using P-FS tool implemented on a high\nperformance computing structure. In our study case, the output of interest is\nthe maximal\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 07:56:43 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Abily", "M", "", "I-CiTy"], ["Delestre", "O", "", "JAD"], ["Gourbesville", "P", "", "I-CiTy"], ["Bertrand", "N", "", "IRSN"], ["Duluc", "C. -M", "", "IRSN"], ["Richet", "Y", "", "IRSN"]]}, {"id": "1604.07138", "submitter": "Kenya Murase", "authors": "Kenya Murase", "title": "An integral-transform approach to the bioheat transfer problems in\n  magnetic hyperthermia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our purpose in this study was to present an integral-transform approach to\nthe analytical solutions of the Pennes's bioheat transfer equation and to apply\nit to the calculation of temperature distribution in tissues in hyperthermia\nwith magnetic nanoparticles (magnetic hyperthermia). The validity of our method\nwas investigated by comparison with the analytical solutions obtained by the\nGreen's function method for point and shell heat sources and the numerical\nsolutions obtained by the finite-difference method for Gaussin-distributed and\nstep-function sources. There was good agreement between the radial profiles of\ntemperature calculated by our method and those obtained by the Green's function\nmethod. There was also good agreement between our method and the\nfinite-difference method except for the central temperature for a step-function\nsource that had approximately a 0.3% difference. We also found that the\nequations describing the steady-state solutions for point and shell sources\nobtained by our method agreed with those obtained by the Green's function\nmethod. These results appear to indicate the validity of our method. In\nconclusion, we presented an integral-transform approach to the bioheat transfer\nproblems in magnetic hyperthermia, and this study demonstrated the validity of\nour method. The analytical solutions presented in this study will be useful for\ngaining some insight into the heat diffusion process during magnetic\nhyperthermia, for testing numerical codes and/or more complcated approaches,\nand for performing sensitivity analysis and optimization of the parameters that\naffect the thermal diffusion process in magnetic hyperthermia.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 06:22:36 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 09:49:31 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 01:44:29 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 02:26:24 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Murase", "Kenya", ""]]}, {"id": "1604.07426", "submitter": "Razieh Abdollahi", "authors": "Zahra Razaghi-Moghadama, Razieh Abdollahia, Sama Goliaeib and Morteza\n  Ebrahimia", "title": "HybridRanker: Integrating network structure and disease knowledge to\n  prioritize cancer candidate genes", "comments": "16 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the notable fields in studying the genetics of cancer is disease gene\nidentification which affects disease treatment and drug discovery. Many\nresearches have been done in this field. Genome-wide association studies (GWAS)\nare one of them that focus on the identification of diseases-susceptible loci\non chromosomes. Recently, computational approaches, known as gene\nprioritization methods have been used to identify candidate disease genes. Gene\nprioritization methods integrate several data sources to discover and\nprioritize the most probable candidate disease genes. In this paper, we propose\na prioritization method, called HybridRanker which is a network-based technique\nand it also uses experimental data to identify candidate cancer genes. We apply\nour proposed method on colorectal cancer data. It is notable to say that in\nHybridRanker, for considering both local and global network information of a\nprotein-protein interaction network, different algorithms such as\nshortest-path, random walk with restart and network propagation are exploited.\nBy using these algorithms, initial scores are given to genes within the\nnetwork. Furthermore, by looking through diseases with similar symptoms and\nalso comorbid diseases and by extracting their causing genes, the gene scores\nare recalculated. We also use gene-phenotype relations for an additional\nscoring of the candidate genes. Our method is validated and compared with other\nprioritization methods in leave one-out cross-validation and the comparison\nresults show the better performance of the HybridRanker.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 20:08:38 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Razaghi-Moghadama", "Zahra", ""], ["Abdollahia", "Razieh", ""], ["Goliaeib", "Sama", ""], ["Ebrahimia", "Morteza", ""]]}, {"id": "1604.07427", "submitter": "Razieh Abdollahi", "authors": "Zahra Razaghi-Moghadam, Razieh Abdollahi, Sama Goliaei, and Morteza\n  Ebrahimi", "title": "NRSSPrioritize: Associating Protein Complex and Disease Similarity\n  Information to Prioritize Disease Candidate Genes", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of disease-associated genes has recently gathered much\nattention for uncovering disease complex mechanisms that could lead to new\ninsights into the treatment of diseases. For exploring disease-susceptible\ngenes, not only experimental approaches such as genome-wide association studies\n(GWAS) have been used, but also computational methods. Since experimental\napproaches are both time-consuming and expensive, numerous studies have\nutilized computational techniques to explore disease genes. These methods use\nvarious biological data sources and known disease genes to prioritize disease\ncandidate genes. In this paper, we propose a gene prioritization method\n(NRSSPrioritize), which benefits from both local and global measures of a\nprotein-protein interaction (PPI) network and also from disease similarity\nknowledge to suggest candidate genes for colorectal cancer (CRC)\nsusceptibility. Network Propagation, Random Walk with Restart, and Shortest\nPaths are three network analysis tools that are applied to a PPI network for\nthe purpose of scoring candidate genes. Also, by looking through diseases with\nsimilar symptoms to CRC and obtaining their causing genes, candidate genes are\nscored in a different way. Finally, to integrate these four different scoring\nschemes, Technique for Order Preference by Similarity to Ideal Solution\n(TOPSIS) and Analytic Network Process (ANP) methods are applied to obtain\nappropriate weights for the above four quantified measures and the weighted\nsummation of these measures are used to calculate the final score of each\ncandidate gene. NRSSPrioritize was validated by cross-validation analysis and\nits results were compared with other prioritization tools, which gave the best\nperformance when using our proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 20:13:30 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Razaghi-Moghadam", "Zahra", ""], ["Abdollahi", "Razieh", ""], ["Goliaei", "Sama", ""], ["Ebrahimi", "Morteza", ""]]}, {"id": "1604.08461", "submitter": "Alexandros Syrakos", "authors": "Alexandros Syrakos, Georgios C. Georgiou, Andreas N. Alexandrou", "title": "Solution of the square lid-driven cavity flow of a Bingham plastic using\n  the finite volume method", "comments": null, "journal-ref": "Journal of Non-Newtonian Fluid Mechanics 195 (2013) 19-31", "doi": "10.1016/j.jnnfm.2012.12.008", "report-no": null, "categories": "physics.comp-ph cs.CE physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of the finite volume method in solving\nviscoplastic flows. The creeping square lid-driven cavity flow of a Bingham\nplastic is chosen as the test case and the constitutive equation is regularised\nas proposed by Papanastasiou [J. Rheol. 31 (1987) 385-404]. It is shown that\nthe convergence rate of the standard SIMPLE pressure-correction algorithm,\nwhich is used to solve the algebraic equation system that is produced by the\nfinite volume discretisation, severely deteriorates as the Bingham number\nincreases, with a corresponding increase in the non-linearity of the equations.\nIt is shown that using the SIMPLE algorithm in a multigrid context dramatically\nimproves convergence, although the multigrid convergence rates are much worse\nthan for Newtonian flows. The numerical results obtained for Bingham numbers as\nhigh as 1000 compare favourably with reported results of other methods.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 15:21:00 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Syrakos", "Alexandros", ""], ["Georgiou", "Georgios C.", ""], ["Alexandrou", "Andreas N.", ""]]}]