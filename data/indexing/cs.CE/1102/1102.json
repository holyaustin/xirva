[{"id": "1102.0059", "submitter": "Donghui Yan", "authors": "Donghui Yan, Pei Wang, Michael Linden, Beatrice Knudsen, Timothy\n  Randolph", "title": "Statistical methods for tissue array images - algorithmic scoring and\n  co-training", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS543 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1280-1305", "doi": "10.1214/12-AOAS543", "report-no": "IMS-AOAS-AOAS543", "categories": "stat.ME cs.CE cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in tissue microarray technology have allowed\nimmunohistochemistry to become a powerful medium-to-high throughput analysis\ntool, particularly for the validation of diagnostic and prognostic biomarkers.\nHowever, as study size grows, the manual evaluation of these assays becomes a\nprohibitive limitation; it vastly reduces throughput and greatly increases\nvariability and expense. We propose an algorithm - Tissue Array Co-Occurrence\nMatrix Analysis (TACOMA) - for quantifying cellular phenotypes based on\ntextural regularity summarized by local inter-pixel relationships. The\nalgorithm can be easily trained for any staining pattern, is absent of\nsensitive tuning parameters and has the ability to report salient pixels in an\nimage that contribute to its score. Pathologists' input via informative\ntraining patches is an important aspect of the algorithm that allows the\ntraining for any specific marker or cell type. With co-training, the error rate\nof TACOMA can be reduced substantially for a very small training sample (e.g.,\nwith size 30). We give theoretical insights into the success of co-training via\nthinning of the feature set in a high-dimensional setting when there is\n\"sufficient\" redundancy among the features. TACOMA is flexible, transparent and\nprovides a scoring process that can be evaluated with clarity and confidence.\nIn a study based on an estrogen receptor (ER) marker, we show that TACOMA is\ncomparable to, or outperforms, pathologists' performance in terms of accuracy\nand repeatability.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 02:08:00 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2012 09:20:39 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Yan", "Donghui", ""], ["Wang", "Pei", ""], ["Linden", "Michael", ""], ["Knudsen", "Beatrice", ""], ["Randolph", "Timothy", ""]]}, {"id": "1102.0309", "submitter": "Katharina Huber", "authors": "A.W.M. Dress, K.T. Huber, M. Steel", "title": "`Lassoing' a phylogenetic tree I: Basic properties, shellings, and\n  covers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A classical result, fundamental to evolutionary biology, states that an\nedge-weighted tree $T$ with leaf set $X$, positive edge weights, and no\nvertices of degree 2 can be uniquely reconstructed from the set of leaf-to-leaf\ndistances between any two elements of $X$. In biology, $X$ corresponds to a set\nof taxa (e.g. extant species), the tree $T$ describes their phylogenetic\nrelationships, the edges correspond to earlier species evolving for a time\nuntil splitting in two or more species by some speciation/bifurcation event,\nand their length corresponds to the genetic change accumulating over that time\nin such a species. In this paper, we investigate which subsets of\n$\\binom{X}{2}$ suffice to determine (`lasso') a tree from the leaf-to-leaf\ndistances induced by that tree. The question is particularly topical since\nreliable estimates of genetic distance - even (if not in particular) by modern\nmass-sequencing methods - are, in general, available only for certain\ncombinations of taxa.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 21:59:40 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2011 10:45:04 GMT"}, {"version": "v3", "created": "Thu, 14 Jul 2011 16:17:14 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["Dress", "A. W. M.", ""], ["Huber", "K. T.", ""], ["Steel", "M.", ""]]}, {"id": "1102.0683", "submitter": "Michel Fliess", "authors": "Michel Fliess (LIX), C\\'edric Join (INRIA Saclay - Ile de France,\n  CRAN), Fr\\'ed\\'eric Hatt", "title": "Volatility made observable at last", "comments": null, "journal-ref": "3\\`emes Journ\\'ees Identification et Mod\\'elisation\n  Exp\\'erimentale, Douai : France (2011)", "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cartier-Perrin theorem, which was published in 1995 and is expressed in\nthe language of nonstandard analysis, permits, for the first time perhaps, a\nclear-cut mathematical definition of the volatility of a financial asset. It\nyields as a byproduct a new understanding of the means of returns, of the beta\ncoefficient, and of the Sharpe and Treynor ratios. New estimation techniques\nfrom automatic control and signal processing, which were already successfully\napplied in quantitative finance, lead to several computer experiments with some\nquite convincing forecasts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 13:46:49 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Fliess", "Michel", "", "LIX"], ["Join", "C\u00e9dric", "", "INRIA Saclay - Ile de France,\n  CRAN"], ["Hatt", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1102.2017", "submitter": "Francisco Pe\\~nu\\~nuri", "authors": "F. Penunuri, R. Peon-Escalante, C. Villanueva, D. Pech-Oy", "title": "Synthesis of Mechanism for single- and hybrid-tasks using Differential\n  Evolution", "comments": "Final version accepted in Mechanism and Machine Theory", "journal-ref": "Mechanism and Machine Theory 46 (2011) 1335--1349", "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal dimensional synthesis for planar mechanisms using differential\nevolution (DE) is demonstrated. Four examples are included: in the first case,\nthe synthesis of a mechanism for hybrid-tasks, considering path generation,\nfunction generation, and motion generation, is carried out. The second and\nthird cases pertain to path generation, with and without prescribed timing.\nFinally, the synthesis of an Ackerman mechanism is reported. Order defect\nproblem is solved by manipulating individuals instead of penalizing or\ndiscretizing the search space for the parameters. A technique that consists in\napplying a transformation in order to satisfy the Grashof and crank conditions\nto generate an initial elitist population is introduced. As a result, the\nevolutionary algorithm increases its efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 10 Feb 2011 00:50:54 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2011 03:29:35 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Penunuri", "F.", ""], ["Peon-Escalante", "R.", ""], ["Villanueva", "C.", ""], ["Pech-Oy", "D.", ""]]}, {"id": "1102.2654", "submitter": "EPTCS", "authors": "Oana Andrei (School of Computing Science, University of Glasgow),\n  Maribel Fern\\'andez (King's College London), H\\'el\\`ene Kirchner (INRIA\n  Bordeaux Sud-Ouest), Guy Melan\\c{c}on (INRIA Bordeaux Sud-Ouest), Olivier\n  Namet (King's College London), Bruno Pinaud (INRIA Bordeaux Sud-Ouest)", "title": "PORGY: Strategy-Driven Interactive Transformation of Graphs", "comments": "In Proceedings TERMGRAPH 2011, arXiv:1102.2268", "journal-ref": "EPTCS 48, 2011, pp. 54-68", "doi": "10.4204/EPTCS.48.7", "report-no": null, "categories": "cs.CE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of graph rewriting systems as a modelling\ntool, and advocates the embedding of such systems in an interactive\nenvironment. One important application domain is the modelling of biochemical\nsystems, where states are represented by port graphs and the dynamics is driven\nby rules and strategies. A graph rewriting tool's capability to interactively\nexplore the features of the rewriting system provides useful insights into\npossible behaviours of the model and its properties. We describe PORGY, a\nvisual and interactive tool we have developed to model complex systems using\nport graphs and port graph rewrite rules guided by strategies, and to navigate\nin the derivation history. We demonstrate via examples some functionalities\nprovided by PORGY.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 01:09:40 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Andrei", "Oana", "", "School of Computing Science, University of Glasgow"], ["Fern\u00e1ndez", "Maribel", "", "King's College London"], ["Kirchner", "H\u00e9l\u00e8ne", "", "INRIA\n  Bordeaux Sud-Ouest"], ["Melan\u00e7on", "Guy", "", "INRIA Bordeaux Sud-Ouest"], ["Namet", "Olivier", "", "King's College London"], ["Pinaud", "Bruno", "", "INRIA Bordeaux Sud-Ouest"]]}, {"id": "1102.2819", "submitter": "Verena Wolf", "authors": "Aleksandr Andreychenko, Linar Mikeev, David Spieler, Verena Wolf", "title": "Parameter Identification for Markov Models of Biochemical Reactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a numerical technique for parameter inference in Markov models of\nbiological processes. Based on time-series data of a process we estimate the\nkinetic rate constants by maximizing the likelihood of the data. The\ncomputation of the likelihood relies on a dynamic abstraction of the discrete\nstate space of the Markov model which successfully mitigates the problem of\nstate space largeness. We compare two variants of our method to\nstate-of-the-art, recently published methods and demonstrate their usefulness\nand efficiency on several case studies from systems biology.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 16:27:08 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Andreychenko", "Aleksandr", ""], ["Mikeev", "Linar", ""], ["Spieler", "David", ""], ["Wolf", "Verena", ""]]}, {"id": "1102.2933", "submitter": "Garth Wells", "authors": "Mikael Mortensen, Hans Petter Langtangen, Garth N. Wells", "title": "A FEniCS-Based Programming Framework for Modeling Turbulent Flow by the\n  Reynolds-Averaged Navier-Stokes Equations", "comments": "To appear in Advances in Water Resources", "journal-ref": null, "doi": "10.1016/j.advwatres.2011.02.013", "report-no": null, "categories": "cs.CE physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an appropriate turbulence model for a given flow case usually calls\nfor extensive experimentation with both models and numerical solution methods.\nThis work presents the design and implementation of a flexible, programmable\nsoftware framework for assisting with numerical experiments in computational\nturbulence. The framework targets Reynolds-averaged Navier-Stokes models,\ndiscretized by finite element methods. The novel implementation makes use of\nPython and the FEniCS package, the combination of which leads to compact and\nreusable code, where model- and solver-specific code resemble closely the\nmathematical formulation of equations and algorithms. The presented ideas and\nprogramming techniques are also applicable to other fields that involve systems\nof nonlinear partial differential equations. We demonstrate the framework in\ntwo applications and investigate the impact of various linearizations on the\nconvergence properties of nonlinear solvers for a Reynolds-averaged\nNavier-Stokes model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 00:08:11 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2011 17:12:17 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Mortensen", "Mikael", ""], ["Langtangen", "Hans Petter", ""], ["Wells", "Garth N.", ""]]}, {"id": "1102.4086", "submitter": "Martin Ehler", "authors": "Wojciech Czaja and Martin Ehler", "title": "Schroedinger Eigenmaps for the Analysis of Bio-Medical Data", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2012.270", "report-no": null, "categories": "cs.CE physics.data-an physics.med-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Schroedinger Eigenmaps, a new semi-supervised manifold learning\nand recovery technique. This method is based on an implementation of graph\nSchroedinger operators with appropriately constructed barrier potentials as\ncarriers of labeled information. We use our approach for the analysis of\nstandard bio-medical datasets and new multispectral retinal images.\n", "versions": [{"version": "v1", "created": "Sun, 20 Feb 2011 17:08:52 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2012 16:48:26 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Czaja", "Wojciech", ""], ["Ehler", "Martin", ""]]}, {"id": "1102.4293", "submitter": "Pawe{\\l} Widera", "authors": "Pawe{\\l} Widera and Natalio Krasnogor", "title": "Protein Models Comparator: Scalable Bioinformatics Computing on the\n  Google App Engine Platform", "comments": "10 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC q-bio.BM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The comparison of computer generated protein structural models is an\nimportant element of protein structure prediction. It has many uses including\nmodel quality evaluation, selection of the final models from a large set of\ncandidates or optimisation of parameters of energy functions used in\ntemplate-free modelling and refinement. Although many protein comparison\nmethods are available online on numerous web servers, they are not well suited\nfor large scale model comparison: (1) they operate with methods designed to\ncompare actual proteins, not the models of the same protein, (2) majority of\nthem offer only a single pairwise structural comparison and are unable to scale\nup to a required order of thousands of comparisons. To bridge the gap between\nthe protein and model structure comparison we have developed the Protein Models\nComparator (pm-cmp). To be able to deliver the scalability on demand and handle\nlarge comparison experiments the pm-cmp was implemented \"in the cloud\".\n  Protein Models Comparator is a scalable web application for a fast\ndistributed comparison of protein models with RMSD, GDT TS, TM-score and\nQ-score measures. It runs on the Google App Engine (GAE) cloud platform and is\na showcase of how the emerging PaaS (Platform as a Service) technology could be\nused to simplify the development of scalable bioinformatics services. The\nfunctionality of pm-cmp is accessible through API which allows a full\nautomation of the experiment submission and results retrieval. Protein Models\nComparator is free software released on the Affero GNU Public Licence and is\navailable with its source code at: http://www.infobiotics.org/pm-cmp\n  This article presents a new web application addressing the need for a\nlarge-scale model-specific protein structure comparison and provides an insight\ninto the GAE (Google App Engine) platform and its usefulness in scientific\ncomputing.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 17:57:04 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2011 18:30:22 GMT"}], "update_date": "2011-07-27", "authors_parsed": [["Widera", "Pawe\u0142", ""], ["Krasnogor", "Natalio", ""]]}, {"id": "1102.4528", "submitter": "Nilo Serpa Costa", "authors": "Nilo Serpa and Jose Roberto Steiner", "title": "Modelling the Dynamics of the Work-Employment System by Predator-Prey\n  Interactions", "comments": "17 pages, 11 figures and original formalism", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad application range of the predator-prey modelling enabled us to\napply it to represent the dynamics of the work-employment system. For the\nadopted period, we conclude that this dynamics is chaotic in the beginning of\nthe time series and tends to less perturbed states, as time goes by, due to\npublic policies and hidden intrinsic system features. Basic Lotka-Volterra\napproach was revised and adapted to the reality of the study. The final aim is\nto provide managers with generalized theoretical elements that allow to a more\naccurate understanding of the behavior of the work-employment system.\n", "versions": [{"version": "v1", "created": "Tue, 22 Feb 2011 15:01:06 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 11:50:29 GMT"}, {"version": "v3", "created": "Thu, 17 Mar 2011 20:19:37 GMT"}], "update_date": "2011-03-21", "authors_parsed": [["Serpa", "Nilo", ""], ["Steiner", "Jose Roberto", ""]]}, {"id": "1102.4904", "submitter": "Bhaskar DasGupta", "authors": "Bhaskar DasGupta and Paola Vera-Licona and Eduardo Sontag", "title": "Reverse Engineering of Molecular Networks from a Common Combinatorial\n  Approach", "comments": "15 pages; in Algorithms in Computational Molecular Biology:\n  Techniques, Approaches and Applications, M. Elloumi and A. Zomaya (editors),\n  John Wiley & Sons, Inc., January 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of molecular cell biology requires insight into the\nstructure and dynamics of networks that are made up of thousands of interacting\nmolecules of DNA, RNA, proteins, metabolites, and other components. One of the\ncentral goals of systems biology is the unraveling of the as yet poorly\ncharacterized complex web of interactions among these components. This work is\nmade harder by the fact that new species and interactions are continuously\ndiscovered in experimental work, necessitating the development of adaptive and\nfast algorithms for network construction and updating. Thus, the\n\"reverse-engineering\" of networks from data has emerged as one of the central\nconcern of systems biology research.\n  A variety of reverse-engineering methods have been developed, based on tools\nfrom statistics, machine learning, and other mathematical domains. In order to\neffectively use these methods, it is essential to develop an understanding of\nthe fundamental characteristics of these algorithms. With that in mind, this\nchapter is dedicated to the reverse-engineering of biological systems.\n  Specifically, we focus our attention on a particular class of methods for\nreverse-engineering, namely those that rely algorithmically upon the so-called\n\"hitting-set\" problem, which is a classical combinatorial and computer science\nproblem, Each of these methods utilizes a different algorithm in order to\nobtain an exact or an approximate solution of the hitting set problem. We will\nexplore the ultimate impact that the alternative algorithms have on the\ninference of published in silico biological networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 04:56:37 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["DasGupta", "Bhaskar", ""], ["Vera-Licona", "Paola", ""], ["Sontag", "Eduardo", ""]]}, {"id": "1102.5509", "submitter": "Leo Lahti", "authors": "Leo Lahti", "title": "Probabilistic analysis of the human transcriptome with side information", "comments": "Doctoral thesis. 103 pages, 11 figures", "journal-ref": "TKK Dissertations in Information and Computer Science TKK-ICS-D19.\n  Aalto University School of Science and Technology, Department of Information\n  and Computer Science, Espoo, Finland, 2010", "doi": null, "report-no": "TKK-ICS-D19", "categories": "stat.ML cs.CE q-bio.GN q-bio.MN q-bio.QM stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Understanding functional organization of genetic information is a major\nchallenge in modern biology. Following the initial publication of the human\ngenome sequence in 2001, advances in high-throughput measurement technologies\nand efficient sharing of research material through community databases have\nopened up new views to the study of living organisms and the structure of life.\nIn this thesis, novel computational strategies have been developed to\ninvestigate a key functional layer of genetic information, the human\ntranscriptome, which regulates the function of living cells through protein\nsynthesis. The key contributions of the thesis are general exploratory tools\nfor high-throughput data analysis that have provided new insights to\ncell-biological networks, cancer mechanisms and other aspects of genome\nfunction.\n  A central challenge in functional genomics is that high-dimensional genomic\nobservations are associated with high levels of complex and largely unknown\nsources of variation. By combining statistical evidence across multiple\nmeasurement sources and the wealth of background information in genomic data\nrepositories it has been possible to solve some the uncertainties associated\nwith individual observations and to identify functional mechanisms that could\nnot be detected based on individual measurement sources. Statistical learning\nand probabilistic models provide a natural framework for such modeling tasks.\nOpen source implementations of the key methodological contributions have been\nreleased to facilitate further adoption of the developed methods by the\nresearch community.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 14:11:30 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Lahti", "Leo", ""]]}]