[{"id": "1602.00668", "submitter": "Ehsan Kazemi", "authors": "Ehsan Kazemi and Matthias Grossglauser", "title": "On the Structure and Efficient Computation of IsoRank Node Similarities", "comments": "8 pages and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alignment of protein-protein interaction (PPI) networks has many\napplications, such as the detection of conserved biological network motifs, the\nprediction of protein interactions, and the reconstruction of phylogenetic\ntrees [1, 2, 3]. IsoRank is one of the first global network alignment\nalgorithms [4, 5, 6], where the goal is to match all (or most) of the nodes of\ntwo PPI networks. The IsoRank algorithm first computes a pairwise node\nsimilarity metric, and then generates a matching between the two node sets\nbased on this metric. The metric is a convex combination of a structural\nsimilarity score (with weight $ \\alpha $) and an extraneous amino-acid sequence\nsimilarity score for two proteins (with weight $ 1 - \\alpha $). In this short\npaper, we make two contributions. First, we show that when IsoRank similarity\ndepends only on network structure ($\\alpha = 1$), the similarity of two nodes\nis only a function of their degrees. In other words, IsoRank similarity is\ninvariant to any network rewiring that does not affect the node degrees. This\nresult suggests a reason for the poor performance of IsoRank in structure-only\n($ \\alpha = 1 $) alignment. Second, using ideas from [7, 8], we develop an\napproximation algorithm that outperforms IsoRank (including recent versions\nwith better scaling, e.g., [9]) by several orders of magnitude in time and\nmemory complexity, despite only a negligible loss in precision.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 20:28:40 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2016 10:10:23 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Grossglauser", "Matthias", ""]]}, {"id": "1602.02490", "submitter": "Jan Egger", "authors": "Jan Egger, Stefan Gro{\\ss}kopf, Bernd Freisleben", "title": "Simulation of bifurcated stent grafts to treat abdominal aortic\n  aneurysms (AAA)", "comments": "6 pages, 5 figures, 5 equations, 9 references in Proc. SPIE 6509,\n  Medical Imaging 2007: Visualization and Image-Guided Procedures, 65091N (22\n  March 2007)", "journal-ref": null, "doi": "10.1117/12.709260", "report-no": null, "categories": "cs.GR cs.CE cs.CG physics.med-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a method is introduced, to visualize bifurcated stent grafts in\nCT-Data. The aim is to improve therapy planning for minimal invasive treatment\nof abdominal aortic aneurysms (AAA). Due to precise measurement of the\nabdominal aortic aneurysm and exact simulation of the bifurcated stent graft,\nphysicians are supported in choosing a suitable stent prior to an intervention.\nThe presented method can be used to measure the dimensions of the abdominal\naortic aneurysm as well as simulate a bifurcated stent graft. Both of these\nprocedures are based on a preceding segmentation and skeletonization of the\naortic, right and left iliac. Using these centerlines (aortic, right and left\niliac) a bifurcated initial stent is constructed. Through the implementation of\nan ACM method the initial stent is fit iteratively to the vessel walls - due to\nthe influence of external forces (distance- as well as balloonforce). Following\nthe fitting process, the crucial values for choosing a bifurcated stent graft\nare measured, e.g. aortic diameter, right and left common iliac diameter,\nminimum diameter of distal neck. The selected stent is then simulated to the\nCT-Data - starting with the initial stent. It hereby becomes apparent if the\ndimensions of the bifurcated stent graft are exact, i.e. the fitting to the\narteries was done properly and no ostium was covered.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 08:09:06 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Egger", "Jan", ""], ["Gro\u00dfkopf", "Stefan", ""], ["Freisleben", "Bernd", ""]]}, {"id": "1602.02675", "submitter": "Mohammad Shabouei", "authors": "M. Komeili, M. Mirzaei, M. Shabouei", "title": "Performance of 1-D and 2-D Lattice Boltzmann (LB) in Solution of the\n  Shock Tube Problem", "comments": "in International Conference on Fascinating Advancement in Mechanical\n  Engineering (FAME2008), India, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we presented a lattice Boltzmann with square grid for\ncompressible flow problems. Triple level velocity is considered for each cell.\nMigration step use discrete velocity but continuous parameters are utilized to\ncalculate density, velocity, and energy. So, we called this semi-discrete\nmethod. To evaluate the performance of the method the well-known shock tube\nproblem is solved, using 1-D and 2-D version of the lattice Boltzmann method.\nThe results of these versions are compared with each other and with the results\nof the analytical solution.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 18:14:57 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 06:20:21 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Komeili", "M.", ""], ["Mirzaei", "M.", ""], ["Shabouei", "M.", ""]]}, {"id": "1602.02680", "submitter": "Mohammad Shabouei", "authors": "M. Shabouei, R. Ebrahimi, K. Mazaheri Body", "title": "Numerical Solution of Cylindrically Converging Shock Waves", "comments": "International Conference on Fascinating Advancement in Mechanical\n  Engineering (FAME08), India, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cylindrically converging shock wave was numerically simulated by solving\nthe Euler equations in cylindrical coordinates with TVD scheme and MUSCL\napproach, using Roe's approximate Riemann solver and super-bee nonlinear\nlimiter. The present study used the in house code developed for this purpose.\nThe behavior of the solution in the vicinity of axis is investigated and the\nresults of the numerical solution are compared with the computed data given by\nPayne, Lapidus, Abarbanel, and Goldberg, Sod, and Leutioff et al.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 18:26:36 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 06:34:04 GMT"}, {"version": "v3", "created": "Mon, 12 Sep 2016 07:08:25 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Shabouei", "M.", ""], ["Ebrahimi", "R.", ""], ["Body", "K. Mazaheri", ""]]}, {"id": "1602.02847", "submitter": "Hamed Azami", "authors": "Hamed Azami, Alberto Fernandez, Javier Escudero", "title": "Refined Multiscale Fuzzy Entropy based on Standard Deviation for\n  Biomedical Signal Analysis", "comments": null, "journal-ref": null, "doi": "10.1007/s11517-017-1647-5", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiscale entropy (MSE) has been a prevalent algorithm to quantify the\ncomplexity of fluctuations in the local mean value of biomedical time series.\nRecent developments in the field have tried to improve the MSE by reducing its\nvariability in large scale factors. On the other hand, there has been recent\ninterest in using other statistical moments than the mean, i.e. variance, in\nthe coarse-graining step of the MSE. Building on these trends, here we\nintroduce the so-called refined composite multiscale fuzzy entropy based on the\nstandard deviation (RCMFE{\\sigma}) to quantify the dynamical properties of\nspread over multiple time scales. We demonstrate the dependency of the\nRCMFE{\\sigma}, in comparison with other multiscale approaches, on several\nstraightforward signal processing concepts using a set of synthetic signals. We\nalso investigate the complementarity of using the standard deviation instead of\nthe mean in the coarse-graining process using magnetoencephalograms in\nAlzheimer disease and publicly available electroencephalograms recorded from\nfocal and non-focal areas in epilepsy. Our results indicate that RCMFE{\\sigma}\noffers complementary information to that revealed by classical coarse-graining\napproaches and that it has superior performance to distinguish different types\nof physiological activity.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 03:17:07 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 15:48:52 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Azami", "Hamed", ""], ["Fernandez", "Alberto", ""], ["Escudero", "Javier", ""]]}, {"id": "1602.02982", "submitter": "Olve Mo", "authors": "Bjorn Gustavsen and Olve Mo", "title": "Variable Transmission Voltage for Loss Minimization in Long Offshore\n  Wind Farm AC Export Cables", "comments": "To be submitted to IEEE Transactions on Power Delivery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connection of offshore wind farms to shore requires the use of submarine\ncables. In the case of long HVAC connections, the capacitive charging currents\nlimit the transfer capability and lead to high losses. This paper shows that\nthe losses can be substantially reduced by continuously adjusting the cable\noperating voltage according to the instantaneous wind farm power\nproduction.Calculations for a 320 MW windfarm connected to shore via a 200 km\ncable at 220 kV nominal voltage shows that an annual loss reduction of 9\npercent is achievable by simply using a 15 percent tap changer voltage\nregulation on the two transformers. Allowing a larger voltage regulation range\nleads to further loss reduction (13 percent for 0.4-1.0 p.u. voltage range). If\nthe windfarm has a low utilization factor, the loss reduction potential is\ndemonstrated to be as high as 21 percent . The methodology can be applied\nwithout introducing new technology that needs to be developed or qualified.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 13:44:03 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Gustavsen", "Bjorn", ""], ["Mo", "Olve", ""]]}, {"id": "1602.03031", "submitter": "Can Alkan", "authors": "Atalay M. Ileri, Halil I. Ozercan, Alper Gundogdu, Ahmet K. Senol, M.\n  Yusuf Ozkaya, Can Alkan", "title": "Coinami: A Cryptocurrency with DNA Sequence Alignment as Proof-of-work", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CR q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rate of growth of the amount of data generated using the high throughput\nsequencing (HTS) platforms now exceeds the growth stipulated by Moore's Law.\nThe HTS data is expected to surpass those of other \"big data\" domains such as\nastronomy, before the year 2025. In addition to sequencing genomes for research\npurposes, genome and exome sequencing in clinical settings will be a routine\npart of health care. The analysis of such large amounts of data, however, is\nnot without computational challenges. This burden is even more increased due to\nthe periodic updates to reference genomes, which typically require re-analysis\nof existing data. Here we propose Coin-Application Mediator Interface (Coinami)\nto distribute the workload for mapping reads to reference genomes using a\nvolunteer grid computer approach similar to Berkeley Open Infrastructure for\nNetwork Computing (BOINC). However, since HTS read mapping requires substantial\ncomputational resources and fast analysis turnout is desired, Coinami uses the\nHTS read mapping as proof-of-work to generate valid blocks to main its own\ncryptocurrency system, which may help motivate volunteers to dedicate more\nresources. The Coinami protocol includes mechanisms to ensure that jobs\nperformed by volunteers are correct, and provides genomic data privacy. The\nprototype implementation of Coinami is available at http://coinami.github.io/.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 15:23:38 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2016 11:19:35 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Ileri", "Atalay M.", ""], ["Ozercan", "Halil I.", ""], ["Gundogdu", "Alper", ""], ["Senol", "Ahmet K.", ""], ["Ozkaya", "M. Yusuf", ""], ["Alkan", "Can", ""]]}, {"id": "1602.03641", "submitter": "Feng Xing", "authors": "Feng Xing (JAD, COFFEE, BRGM), Roland Masson (JAD, COFFEE), Simon\n  Lopez (BRGM)", "title": "Parallel Vertex Approximate Gradient discretization of hybrid\n  dimensional Darcy flow and transport in discrete fracture networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a parallel numerical algorithm to simulate the flow and\nthe transport in a discrete fracture network taking into account the mass\nexchanges with the surrounding matrix. The discretization of the Darcy fluxes\nis based on the Vertex Approximate Gradient finite volume scheme adapted to\npolyhedral meshes and to heterogeneous anisotropic media, and the transport\nequation is discretized by a first order upwind scheme combined with an Euler\nexplicit integration in time. The parallelization is based on the SPMD (Single\nProgram, Multiple Data) paradigm and relies on a distribution of the mesh on\nthe processes with one layer of ghost cells in order to allow for a local\nassembly of the discrete systems. The linear system for the Darcy flow is\nsolved using different linear solvers and preconditioners implemented in the\nPETSc and Trilinos libraries. The convergence of the scheme is validated on two\noriginal analytical solutions with one and four intersecting fractures. Then,\nthe parallel efficiency of the algorithm is assessed on up to 512 processes\nwith different types of meshes, different matrix fracture permeability ratios,\nand different levels of complexity of the fracture network.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 08:26:07 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 08:03:27 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Xing", "Feng", "", "JAD, COFFEE, BRGM"], ["Masson", "Roland", "", "JAD, COFFEE"], ["Lopez", "Simon", "", "BRGM"]]}, {"id": "1602.03854", "submitter": "Saeid Dindarloo", "authors": "Saeid R. Dindarloo and Elnaz Siami-Irdemoosa", "title": "Estimating the unconfined compressive strength of carbonate rocks using\n  gene expression programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, many researchers have used both regression and black box\ntechniques to estimate the unconfined compressive strength (UCS) of different\nrocks. The advantage of the regression approach is that it can be used to\nrender a functional relationship between the predictive rock indices and its\nUCS. The advantage of the black box techniques is in rendering more accurate\npredictions. Gene expression programming (GEP) is proposed, in this study, as a\nrobust mathematical alternative for predicting the UCS of carbonate rocks. The\ntwo parameters of total porosity and P-wave speed were selected as predictive\nindices. The proposed GEP model had the advantage of the both traditionally\nused approaches by proposing a mathematical model, similar to a regression,\nwhile keeping the prediction errors as low as the black box methods. The GEP\noutperformed both artificial neural networks and support vector machines in\nterms of yielding more accurate estimates of UCS. Both the porosity and the\nP-wave velocity were sufficient predictive indices for estimating the UCS of\nthe carbonate rocks in this study. Nearly, 95% of the observed variation in the\nUCS values was explained by these two parameters (i.e., R2 =95%).\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 01:35:23 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Dindarloo", "Saeid R.", ""], ["Siami-Irdemoosa", "Elnaz", ""]]}, {"id": "1602.03979", "submitter": "Deng Shi-Wen", "authors": "Shi-Wen Deng and Ji-Qing Han", "title": "Signal periodic decomposition with conjugate subspaces", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": "10.1109/TSP.2016.2600509", "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on hidden period identification and the periodic\ndecomposition of signals. Based on recent results on the Ramanujan subspace, we\nreveal the conjugate symmetry of the Ramanujan subspace with a set of complex\nexponential basis functions and represent the subspace as the union of a series\nof conjugate subspaces. With these conjugate subspaces, the signal periodic\nmodel is introduced to characterize the periodic structure of a signal. To\nachieve the decomposition of the proposed model, the conjugate subspace\nmatching pursuit (CSMP) algorithm is proposed based on two different greedy\nstrategies. The CSMP is performed iteratively in two stages. In the first\nstage, the dominant hidden period is chosen with the periodicity strategy.\nThen, the dominant conjugate subspace is chosen with the energy strategy in the\nsecond stage. Compared with the current state-of-the-art methods for hidden\nperiod identification, the main advantages provided by the CSMP are the\nfollowing: (i) the capability of identifying all the hidden periods in the\nrange from $1$ to the maximum hidden period $Q$ of a signal of any length,\nwithout truncating the signal; (ii) the ability to identify the time-varying\nhidden period with its shifted version; and (iii) the low computational cost,\nwithout generating and using a large over-complete dictionary. Moreover, we\nprovide examples and applications to demonstrate the abilities of the proposed\ntwo-stage CSMP algorithm, which include hidden period identification, signal\napproximation, time-varying period detection, and pitch detection of speech.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 08:22:49 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Deng", "Shi-Wen", ""], ["Han", "Ji-Qing", ""]]}, {"id": "1602.05566", "submitter": "Daniel Tameling", "authors": "Daniel Tameling (1), Paolo Bientinesi (1), Ahmed E. Ismail (1,2) ((1)\n  AICES, RWTH Aachen, (2) Aachener Verfahrenstechnik - Molecular Simulations\n  and Transformations, RWTH Aachen)", "title": "A Note on Time Measurements in LAMMPS", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICES-2016/02-1", "categories": "cond-mat.mtrl-sci cs.CE physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the issue of assessing the efficiency of components of a parallel\nprogram at the example of the MD package LAMMPS. In particular, we look at how\nLAMMPS deals with the issue and explain why the approach adopted might lead to\ninaccurate conclusions. The misleading nature of this approach is subsequently\nverified experimentally with a case study. Afterwards, we demonstrate how one\nshould correctly determine the efficiency of the components and show what\nchanges to the code base of LAMMPS are necessary in order to get the correct\nbehavior.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 20:45:49 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Tameling", "Daniel", ""], ["Bientinesi", "Paolo", ""], ["Ismail", "Ahmed E.", ""]]}, {"id": "1602.05754", "submitter": "Balthasar Reuter", "authors": "Balthasar Reuter, Vadym Aizinger, Manuel Wieland, Florian Frank, Peter\n  Knabner", "title": "FESTUNG: A MATLAB / GNU Octave toolbox for the discontinuous Galerkin\n  method. Part II: Advection operator and slope limiting", "comments": "Updated with the accepted manuscript", "journal-ref": "Computers & Mathematics with Applications, Volume 72, Issue 7,\n  October 2016, Pages 1896-1925", "doi": "10.1016/j.camwa.2016.08.006", "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the second in a series of papers on implementing a discontinuous\nGalerkin (DG) method as an open source Matlab / GNU Octave toolbox. The\nintention of this ongoing project is to offer a rapid prototyping package for\napplication development using DG methods. The implementation relies on fully\nvectorized matrix / vector operations and is comprehensively documented.\nParticular attention was paid to maintaining a direct mapping between\ndiscretization terms and code routines as well as to supporting the full code\nfunctionality in GNU Octave. The present work focuses on a two-dimensional\ntime-dependent linear advection equation with space / time-varying\ncoefficients, and provides a general order implementation of several slope\nlimiting schemes for the DG method.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 11:04:06 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 11:41:58 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Reuter", "Balthasar", ""], ["Aizinger", "Vadym", ""], ["Wieland", "Manuel", ""], ["Frank", "Florian", ""], ["Knabner", "Peter", ""]]}, {"id": "1602.05901", "submitter": "Hui Liu Mr", "authors": "Hui Liu, Kun Wang, Bo Yang and Zhangxin Chen", "title": "Development of A Scalable Platform for Large-scale Reservoir Simulations\n  on Parallel computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our work on designing a parallel platform for large-scale\nreservoir simulations. Detailed components, such as grid and linear solver, and\ndata structures are introduced, which can serve as a guide to parallel\nreservoir simulations and other parallel applications. The main objective of\nplatform is to support implementation of various parallel reservoir simulators\non distributed-memory parallel systems, where MPI (Message Passing Interface)\nis employed for communications among computation nodes. It provides structured\ngrid due to its simplicity and cell-centered data is applied for each cell. The\nplatform has a distributed matrix and vector module and a map module. The\nmatrix and vector module is the base of our parallel linear systems. The map\nconnects grid and linear system modules, which defines various mappings between\ngrid and linear systems. Commonly-used Krylov subspace linear solvers are\nimplemented, including the restarted GMRES method and the BiCGSTAB method. It\nalso has an interface to a parallel algebraic multigrid solver, BoomerAMG from\nHYPRE. Parallel general-purpose preconditioners and special preconditioners for\nreservoir simulations are also developed. Various data structures are designed,\nsuch as grid, cell, data, linear solver and preconditioner, and some key\ndefault parameters are presented in this paper. The numerical experiments show\nthat our platform has excellent scalability and it can simulate giant reservoir\nmodels with hundreds of millions of grid cells using thousands of CPU cores.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 18:22:18 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2016 04:57:21 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2016 21:22:47 GMT"}, {"version": "v4", "created": "Fri, 7 Oct 2016 18:01:45 GMT"}, {"version": "v5", "created": "Sun, 30 Oct 2016 03:20:27 GMT"}, {"version": "v6", "created": "Thu, 30 Aug 2018 04:44:47 GMT"}, {"version": "v7", "created": "Sat, 1 Sep 2018 00:46:52 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Liu", "Hui", ""], ["Wang", "Kun", ""], ["Yang", "Bo", ""], ["Chen", "Zhangxin", ""]]}, {"id": "1602.06434", "submitter": "Severin Sadjina", "authors": "Severin Sadjina, Lars T. Kyllingstad, Eilif Pedersen, Stian Skjong", "title": "Energy Conservation and Power Bonds in Co-Simulations: Non-Iterative\n  Adaptive Step Size Control and Error Estimation", "comments": "14 pages, 11 figures, 12 tables", "journal-ref": "Engineering with Computers (2016)", "doi": "10.1007/s00366-016-0492-8", "report-no": null, "categories": "cs.SY cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we study the flow of energy between coupled simulators in a\nco-simulation environment using the concept of power bonds. We introduce energy\nresiduals which are a direct expression of the coupling errors and hence the\naccuracy of co-simulation results. We propose a novel Energy-Conservation-based\nCo-Simulation method (ECCO) for adaptive macro step size control to improve\naccuracy and efficiency. In contrast to most other co-simulation algorithms,\nthis method is non-iterative and only requires knowledge of the current\ncoupling data. Consequently, it allows for significant speed ups and the\nprotection of sensitive information contained within simulator models. A\nquarter car model with linear and nonlinear damping serves as a co-simulation\nbenchmark and verifies the capabilities of the energy residual concept:\nReductions in the errors of up to 93% are achieved at no additional\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 17:25:02 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 19:45:29 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Sadjina", "Severin", ""], ["Kyllingstad", "Lars T.", ""], ["Pedersen", "Eilif", ""], ["Skjong", "Stian", ""]]}, {"id": "1602.06589", "submitter": "Edoardo Di Napoli", "authors": "Edoardo Di Napoli (1 and 4), Elmar Peise (2), Markus Hrywniak (3),\n  Paolo Bientinesi (2) ((1) J\\\"ulich Supercomputing Centre, (2) AICES, RWTH\n  Aachen University, (3) GRS, RWTH Aachen University, (4) J\\\"ulich Aachen\n  Research Alliance -- High-performance Computing)", "title": "High-performance generation of the Hamiltonian and Overlap matrices in\n  FLAPW methods", "comments": "Second revised version. Corrected notation. Added acknowledgment. 30\n  pages, 2 figures and two tables. Submitted to a Special Issue of Computer\n  Physics Communication", "journal-ref": null, "doi": "10.1016/j.cpc.2016.10.003", "report-no": null, "categories": "cs.CE cs.DS cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest efforts of computational scientists is to translate the\nmathematical model describing a class of physical phenomena into large and\ncomplex codes. Many of these codes face the difficulty of implementing the\nmathematical operations in the model in terms of low level optimized kernels\noffering both performance and portability. Legacy codes suffer from the\nadditional curse of rigid design choices based on outdated performance metrics\n(e.g. minimization of memory footprint). Using a representative code from the\nMaterials Science community, we propose a methodology to restructure the most\nexpensive operations in terms of an optimized combination of dense linear\nalgebra kernels. The resulting algorithm guarantees an increased performance\nand an extended life span of this code enabling larger scale simulations.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 22:09:30 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 08:24:02 GMT"}, {"version": "v3", "created": "Mon, 15 Aug 2016 19:40:16 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Di Napoli", "Edoardo", "", "1 and 4"], ["Peise", "Elmar", ""], ["Hrywniak", "Markus", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1602.07851", "submitter": "Sophie Lemaitre", "authors": "Sophie Lemaitre and Vladimir Salnikov and Daniel Choi and Philippe\n  Karamian-Surville", "title": "Influence of morphological parameters in 3D composite materials on their\n  effective thermal properties and comparison with effective mechanical\n  properties", "comments": "27 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the effective thermal behaviour of 3D representative\nvolume elements (RVEs) of two-phased composite materials constituted by a\nmatrix with cylindrical and spherical inclusions distributed randomly, with\nperiodic boundaries. Variations around the shape of inclusions have been taken\ninto account, by corrugating shapes, excavating and/or by removing pieces of\ninclusions. The effective behaviour is computed with the help of homogenization\nprocess based on an accelerated FFT-scheme giving the thermal conductivity\ntensor. Several morphological parameters are also taken into account for\ninstance the number and the volume fraction of each type of inclusions,... in\norder to analyse the behaviour of the composite for a large number of\ngeometries. We compare the results obtained for RVEs with and without\nvariations, and then with the mechanical results of such composite studied in\nour previous paper.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 09:07:19 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Lemaitre", "Sophie", ""], ["Salnikov", "Vladimir", ""], ["Choi", "Daniel", ""], ["Karamian-Surville", "Philippe", ""]]}, {"id": "1602.08463", "submitter": "Holly Ferguson", "authors": "Holly T. Ferguson, Aimee. P. C. Buccellato, Samuel Paolucci, Na Yu,\n  Charles F. Vardeman II", "title": "Green Scale Research Tool for Multi-Criteria and Multi-Metric Energy\n  Analysis Performed During the Architectural Design Process", "comments": "38 pages double spaced, including appendices; single column format;\n  multi-disciplinary work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prevailing computational tools available to and used by architecture and\nengineering professionals purport to gather and present thorough and accurate\nperspectives of the environmental impacts associated with their contributions\nto the built environment. The presented research of building modeling and\nanalysis software used by the Architecture, Engineering, Construction, and\nOperations (AECO) industry reveals that many of the most heavily relied-upon\nindustry tools are isolated in functionality, utilize incomplete models and\ndata, and are disruptive to normative design and building optimization\nworkflows. This paper describes the current models and tools, their primary\nfunctions and limitations, and presents our concurrent research to develop more\nadvanced models to assess lifetime building energy consumption alongside\noperating energy use. A series of case studies describes the current\nstate-of-the-art in tools and building energy analysis followed by the research\nmodels and novel design and analysis Tool that the Green Scale Research Group\nhas developed in response. A fundamental goal of this effort is to increase the\nuse and efficacy of building impact studies conducted by architects, engineers,\nand building owners and operators during the building design process.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 20:08:18 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Ferguson", "Holly T.", ""], ["Buccellato", "Aimee. P. C.", ""], ["Paolucci", "Samuel", ""], ["Yu", "Na", ""], ["Vardeman", "Charles F.", "II"]]}]