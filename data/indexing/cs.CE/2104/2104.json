[{"id": "2104.01210", "submitter": "Hao Deng", "authors": "Hao Deng, Praveen S. Vulimiri, and Albert C. To", "title": "An efficient 146-line 3D sensitivity analysis code of stress-based\n  topology optimization written in MATLAB", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient and compact MATLAB code for\nthree-dimensional stress-based sensitivity analysis. The 146 lines code\nincludes the finite element analysis and p-norm stress sensitivity analysis\nbased on the adjoint method. The 3D sensitivity analysis for p-norm global\nstress measure is derived and explained in detail accompanied by corresponding\nMATLAB code. The correctness of the analytical sensitivity is verified by\ncomparison with finite difference approximation. The nonlinear optimization\nsolver is chosen as the Method of moving asymptotes (MMA). Three typical\nvolume-constrained stress minimization problems are presented to verify the\neffectiveness of sensitivity analysis code. The MATLAB code presented in this\npaper can be extended to resolve different stress related 3D topology\noptimization problems. The complete program for sensitivity analysis is given\nin the Appendix and is intended for educational purposes only.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 19:18:38 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Deng", "Hao", ""], ["Vulimiri", "Praveen S.", ""], ["To", "Albert C.", ""]]}, {"id": "2104.01367", "submitter": "Vladim\\'ir Luke\\v{s}", "authors": "Eduard Rohan and Vladim\\'ir Luke\\v{s}", "title": "Homogenization of the vibro-acoustic transmission on periodically\n  perforated elastic plates with arrays of resonators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.CE cs.NA math.AP math.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Based on our previous work, we propose a homogenized model of acoustic waves\npropagating through periodically perforated elastic plates with metamaterial\nproperties due to embedded arrays of soft elastic inclusions serving for\nresonators. Such structures enable to suppress the acoustic transmission for\nselected frequency bands. Homogenization of the vibro-acoustic fluid-structure\ninteraction problem in a 3D complex geometry of the transmission layer leads to\neffective transmission conditions prescribed on the acoustic meta-surface\nassociated with the mid-plane of the Reissner-Mindlin plate. Asymptotic\nanalysis with respect to the layer thickness, proportional to the plate\nthickness and to the perforation period, yields an implicit\nDirichlet-to-Neumann operator defined on the homogenized metasurface. An\nefficient method is proposed for computing frequency-dependent effective\nparameters involved in the homogenized model of the layer. These can change\ntheir signs, thus modifying the acoustic impedance and the effective mass of\nthe metasurface. The global problem of the acoustic wave propagation in a\nwaveguide fitted with the plate is solved using the finite element method. The\nhomogenized interface allows for a significant reduction of the computational\nmodel. Numerical illustrations are presented.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 10:12:24 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Rohan", "Eduard", ""], ["Luke\u0161", "Vladim\u00edr", ""]]}, {"id": "2104.01439", "submitter": "Daniel Drzisga", "authors": "Daniel Drzisga and Tobias K\\\"oppl and Barbara Wohlmuth", "title": "Semi matrix-free twogrid shifted Laplacian preconditioner for the\n  Helmholtz equation with near optimal shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its significance in terms of wave phenomena a considerable effort has\nbeen put into the design of preconditioners for the Helmholtz equation. One\noption to derive a preconditioner is to apply a multigrid method on a shifted\noperator. In such an approach, the wavenumber is shifted by some imaginary\nvalue. This step is motivated by the observation that the shifted problem can\nbe more efficiently handled by iterative solvers when compared to the standard\nHelmholtz equation. However, up to now, it is not obvious what the best\nstrategy for the choice of the shift parameter is. It is well known that a good\nshift parameter depends sensitively on the wavenumber and the discretization\nparameters such as the order and the mesh size. Therefore, we study the choice\nof a near optimal complex shift such that an FGMRES solver converges with fewer\niterations. Our goal is to provide a map which returns the near optimal shift\nfor the preconditioner depending on the wavenumber and the mesh size. In order\nto compute this map, a data driven approach is considered: We first generate\nmany samples, and in a second step, we perform a nonlinear regression on this\ndata. With this representative map, the near optimal shift can be obtained by a\nsimple evaluation. Our preconditioner is based on a twogrid V-cycle applied to\nthe shifted problem, allowing us to implement a semi matrix-free method. The\nperformance of our preconditioned FGMRES solver is illustrated by several\nbenchmark problems with heterogeneous wavenumbers in two and three space\ndimensions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 16:12:14 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Drzisga", "Daniel", ""], ["K\u00f6ppl", "Tobias", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "2104.01965", "submitter": "Aaditya Chandrasekhar", "authors": "Aaditya Chandrasekhar, Saketh Sridhara, Krishnan Suresh", "title": "AuTO: A Framework for Automatic differentiation in Topology Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A critical step in topology optimization (TO) is finding sensitivities.\nManual derivation and implementation of the sensitivities can be quite\nlaborious and error-prone, especially for non-trivial objectives, constraints\nand material models. An alternate approach is to utilize automatic\ndifferentiation (AD). While AD has been around for decades, and has also been\napplied in TO, wider adoption has largely been absent.\n  In this educational paper, we aim to reintroduce AD for TO, and make it\neasily accessible through illustrative codes. In particular, we employ JAX, a\nhigh-performance Python library for automatically computing sensitivities from\na user defined TO problem. The resulting framework, referred to here as AuTO,\nis illustrated through several examples in compliance minimization, compliant\nmechanism design and microstructural design.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 15:36:17 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chandrasekhar", "Aaditya", ""], ["Sridhara", "Saketh", ""], ["Suresh", "Krishnan", ""]]}, {"id": "2104.02043", "submitter": "Juan Pablo Agnelli", "authors": "J. P. Agnelli, V. Kolehmainen, M. Lassas, P. Ola, S. Siltanen", "title": "Simultaneous reconstruction of conductivity, boundary shape and contact\n  impedances in electrical impedance tomography", "comments": "34 pages, 17 figures; typos corrected, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of electrical impedance tomography (EIT) is to reconstruct the\ninternal conductivity of a physical body based on current and voltage\nmeasurements at the boundary of the body. In many medical applications the\nexact shape of the domain boundary and contact impedances are not available.\nThis is problematic as even small errors in the boundary shape of the\ncomputation domain or in the contact impedance values can produce large\nartifacts in the reconstructed images which results in a loss of relevant\ninformation. A method is proposed that simultaneously reconstructs the\nconductivity, the contact impedances and the boundary shape from EIT data. The\napproach consists of three steps: first, the unknown contact impedances and an\nanisotropic conductivity reproducing the measured EIT data in a model domain\nare computed. Second, using isothermal coordinates, a deformation is\nconstructed that makes the conductivity isotropic. The final step minimizes the\nerror of true and reconstructed known geometric properties (like the electrode\nlengths) using conformal deformations. The feasibility of the method is\nillustrated with experimental EIT data, with robust and accurate\nreconstructions of both conductivity and boundary shape.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:46:15 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 15:48:49 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Agnelli", "J. P.", ""], ["Kolehmainen", "V.", ""], ["Lassas", "M.", ""], ["Ola", "P.", ""], ["Siltanen", "S.", ""]]}, {"id": "2104.02588", "submitter": "Giorgio Gnecco", "authors": "Giorgio Gnecco, Andrea Bacigalupo, Francesca Fantoni, and Daniela\n  Selvi", "title": "Principal Component Analysis Applied to Gradient Fields in Band Gap\n  Optimization Problems for Metamaterials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A promising technique for the spectral design of acoustic metamaterials is\nbased on the formulation of suitable constrained nonlinear optimization\nproblems. Unfortunately, the straightforward application of classical\ngradient-based iterative optimization algorithms to the numerical solution of\nsuch problems is typically highly demanding, due to the complexity of the\nunderlying physical models. Nevertheless, supervised machine learning\ntechniques can reduce such a computational effort, e.g., by replacing the\noriginal objective functions of such optimization problems with more-easily\ncomputable approximations. In this framework, the present article describes the\napplication of a related unsupervised machine learning technique, namely,\nprincipal component analysis, to approximate the gradient of the objective\nfunction of a band gap optimization problem for an acoustic metamaterial, with\nthe aim of making the successive application of a gradient-based iterative\noptimization algorithm faster. Numerical results show the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 11:13:37 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:48:48 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 22:20:30 GMT"}, {"version": "v4", "created": "Sat, 24 Apr 2021 00:32:34 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 15:09:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Gnecco", "Giorgio", ""], ["Bacigalupo", "Andrea", ""], ["Fantoni", "Francesca", ""], ["Selvi", "Daniela", ""]]}, {"id": "2104.02877", "submitter": "Rui Yao", "authors": "Rui Yao, Feng Qiu", "title": "Hybrid QSS and Dynamic Extended-Term Simulation Based on Holomorphic\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Power system simulations that extend over a time period of minutes, hours, or\neven longer are called extended-term simulations. As power systems evolve into\ncomplex systems with increasing interdependencies and richer dynamic behaviors\nacross a wide range of timescales, extended-term simulation is needed for many\npower system analysis tasks (e.g., resilience analysis, renewable energy\nintegration, cascading failures), and there is an urgent need for efficient and\nrobust extended-term simulation approaches. The conventional approaches are\ninsufficient for dealing with the extended-term simulation of multi-timescale\nprocesses. This paper proposes an extended-term simulation approach based on\nthe holomorphic embedding (HE) methodology. Its accuracy and computational\nefficiency are backed by HE's high accuracy in event-driven simulation, larger\nand adaptive time steps, and flexible switching between full-dynamic and\nquasi-steady-state (QSS) models. We used this proposed extended-term simulation\napproach to evaluate bulk power system restoration plans, and it demonstrates\nsatisfactory accuracy and efficiency in this complex simulation task.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 03:01:32 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Yao", "Rui", ""], ["Qiu", "Feng", ""]]}, {"id": "2104.03743", "submitter": "Wei Xing", "authors": "Wei W. Xing, Akeel A. Shah, Peng Wang, Shandian Zhe Qian Fu, and\n  Robert. M. Kirby", "title": "Residual Gaussian Process: A Tractable Nonparametric Bayesian Emulator\n  for Multi-fidelity Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenges in multi-fidelity modeling relate to accuracy, uncertainty\nestimation and high-dimensionality. A novel additive structure is introduced in\nwhich the highest fidelity solution is written as a sum of the lowest fidelity\nsolution and residuals between the solutions at successive fidelity levels,\nwith Gaussian process priors placed over the low fidelity solution and each of\nthe residuals. The resulting model is equipped with a closed-form solution for\nthe predictive posterior, making it applicable to advanced, high-dimensional\ntasks that require uncertainty estimation. Its advantages are demonstrated on\nunivariate benchmarks and on three challenging multivariate problems. It is\nshown how active learning can be used to enhance the model, especially with a\nlimited computational budget. Furthermore, error bounds are derived for the\nmean prediction in the univariate case.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 12:57:46 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Xing", "Wei W.", ""], ["Shah", "Akeel A.", ""], ["Wang", "Peng", ""], ["Fu", "Shandian Zhe Qian", ""], ["Kirby", "Robert. M.", ""]]}, {"id": "2104.03907", "submitter": "Philippe Kirschen", "authors": "Philippe Kirschen, Edward Burnell", "title": "Hyperloop System Optimization", "comments": "13 pages, 15 figures, submitted to AIAA Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperloop system design is a uniquely coupled problem because it involves the\nsimultaneous design of a complex, high-performance vehicle and its accompanying\ninfrastructure. In the clean-sheet design of this new mode of high-speed mass\ntransportation there is an excellent opportunity for the application of\nrigorous system optimization techniques. This work presents a system\noptimization tool, HOPS, that has been adopted as a central component of the\nVirgin Hyperloop design process. We discuss the choice of objective function,\nthe use of a convex optimization technique called geometric programming, and\nthe level of modeling fidelity that has allowed us to capture the system's many\nintertwined, and often recursive, design relationships. We also highlight the\nways in which the tool has been used. Because organizational confidence in a\nmodel is as vital as its technical merit, we close with discussion of the\nmeasures taken to build stakeholder trust in HOPS.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 04:08:57 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 05:09:10 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 20:40:55 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Kirschen", "Philippe", ""], ["Burnell", "Edward", ""]]}, {"id": "2104.04017", "submitter": "Sumit Bhattacharya", "authors": "Sumit Bhattacharya, Devanshu Arya, Debjani Bhowmick, Rajat Mani\n  Thomas, Deepak Kumar Gupta", "title": "Improving Solar Cell Metallization Designs using Convolutional Neural\n  Networks", "comments": "Published as a workshop paper at ICLR 2021 SimDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing the design of solar cell metallizations is one of the ways to\nimprove the performance of solar cells. Recently, it has been shown that\nTopology Optimization (TO) can be used to design complex metallization patterns\nfor solar cells that lead to improved performance. TO generates unconventional\ndesign patterns that cannot be obtained with the traditional shape optimization\nmethods. In this paper, we show that this design process can be improved\nfurther using a deep learning inspired strategy. We present SolarNet, a\nCNN-based reparameterization scheme that can be used to obtain improved\nmetallization designs. SolarNet modifies the optimization domain such that\nrather than optimizing the electrode material distribution directly, the\nweights of a CNN model are optimized. The design generated by CNN is then\nevaluated using the physics equations, which in turn generates gradients for\nbackpropagation. SolarNet is trained end-to-end involving backpropagation\nthrough the solar cell model as well as the CNN pipeline. Through application\non solar cells of different shapes as well as different busbar geometries, we\ndemonstrate that SolarNet improves the performance of solar cells compared to\nthe traditional TO approach.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 19:24:45 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Bhattacharya", "Sumit", ""], ["Arya", "Devanshu", ""], ["Bhowmick", "Debjani", ""], ["Thomas", "Rajat Mani", ""], ["Gupta", "Deepak Kumar", ""]]}, {"id": "2104.04027", "submitter": "Abdel Alsnayyan", "authors": "A. M. A. Alsnayyan and B. Shanker", "title": "Laplace-Beltrami based Multi-Resolution Shape Reconstruction on\n  Subdivision Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The eigenfunctions of the Laplace-Beltrami operator have widespread\napplications in a number of disciplines of engineering, computer\nvision/graphics, machine learning, etc. These eigenfunctions or manifold\nharmonics, provide the means to smoothly interpolate data on a manifold. They\nare highly effective, specifically as it relates to geometry representation and\nediting; manifold harmonics form a natural basis for multi-resolution\nrepresentation (and editing) of complex surfaces and functioned defined\ntherein. In this paper, we seek to develop the framework to exploit the\nbenefits of manifold harmonics for shape reconstruction. To this end, we\ndevelop a highly compressible, multi-resolution shape reconstruction scheme\nusing manifold harmonics. The method relies on subdivision basis sets to\nconstruct both boundary element isogeometric methods for analysis and surface\nfinite elements to construct manifold harmonics. We pair this technique with\nthe volumetric source reconstruction method to determine an initial starting\npoint. Examples presented highlight efficacy of the approach in the presence of\nnoisy data, including significant reduction in the number of degrees of freedom\nfor complex objects, the accuracy of reconstruction, and multi-resolution\ncapabilities.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 19:56:19 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Alsnayyan", "A. M. A.", ""], ["Shanker", "B.", ""]]}, {"id": "2104.04096", "submitter": "Gianmarco Manzini", "authors": "Sebastian Naranjo-Alvarez, Vrushali Bokil, Vitaliy Gyrya, Gianmarco\n  Manzini", "title": "The virtual element method for the coupled system of\n  magneto-hydrodynamics", "comments": "36 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we review the framework of the Virtual Element Method (VEM) for\na model in magneto-hydrodynamics (MHD), that incorporates a coupling between\nelectromagnetics and fluid flow, and allows us to construct novel\ndiscretizations for simulating realistic phenomenon in MHD. First, we study two\nchains of spaces approximating the electromagnetic and fluid flow components of\nthe model. Then, we show that this VEM approximation will yield divergence free\ndiscrete magnetic fields, an important property in any simulation in MHD. We\npresent a linearization strategy to solve the VEM approximation which respects\nthe divergence free condition on the magnetic field. This linearization will\nrequire that, at each non-linear iteration, a linear system be solved. We study\nthese linear systems and show that they represent well-posed saddle point\nproblems. We conclude by presenting numerical experiments exploring the\nperformance of the VEM applied to the subsystem describing the\nelectromagnetics. The first set of experiments provide evidence regarding the\nspeed of convergence of the method as well as the divergence-free condition on\nthe magnetic field. In the second set we present a model for magnetic\nreconnection in a mesh that includes a series of hanging nodes, which we use to\ncalibrate the resolution of the method. The magnetic reconnection phenomenon\nhappens near the center of the domain where the mesh resolution is finer and\nhigh resolution is achieved.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 22:07:36 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Naranjo-Alvarez", "Sebastian", ""], ["Bokil", "Vrushali", ""], ["Gyrya", "Vitaliy", ""], ["Manzini", "Gianmarco", ""]]}, {"id": "2104.04152", "submitter": "Emilio Mart\\'inez-Pa\\~neda", "authors": "Yousef Navidtehrani, Covadonga Beteg\\'on, Emilio Mart\\'inez-Pa\\~neda", "title": "A unified Abaqus implementation of the phase field fracture method using\n  only a user material subroutine", "comments": null, "journal-ref": "Materials (2021)", "doi": "10.3390/ma14081913", "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and robust implementation of the phase field fracture\nmethod in Abaqus. Unlike previous works, only a user material (UMAT) subroutine\nis used. This is achieved by exploiting the analogy between the phase field\nbalance equation and heat transfer, which avoids the need for a user element\nmesh and enables taking advantage of Abaqus' in-built features. A unified\ntheoretical framework and its implementation are presented, suitable for any\narbitrary choice of crack density function and fracture driving force.\nSpecifically, the framework is exemplified with the so-called AT1, AT2 and\nphase field-cohesive zone models (PF-CZM). Both staggered and monolithic\nsolution schemes are handled. We demonstrate the potential and robustness of\nthis new implementation by addressing several paradigmatic 2D and 3D boundary\nvalue problems. The numerical examples show how the current implementation can\nbe used to reproduce numerical and experimental results from the literature,\nand efficiently capture advanced features such as complex crack trajectories,\ncrack nucleation from arbitrary sites and contact problems. The code developed\ncan be downloaded from www.empaneda.com/codes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 10:07:52 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Navidtehrani", "Yousef", ""], ["Beteg\u00f3n", "Covadonga", ""], ["Mart\u00ednez-Pa\u00f1eda", "Emilio", ""]]}, {"id": "2104.04451", "submitter": "Theron Guo", "authors": "Theron Guo, Ond\\v{r}ej Roko\\v{s}, Karen Veroy", "title": "Learning constitutive models from microstructural simulations via a\n  non-intrusive reduced basis method", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2021.113924", "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In order to optimally design materials, it is crucial to understand the\nstructure-property relations in the material by analyzing the effect of\nmicrostructure parameters on the macroscopic properties. In computational\nhomogenization, the microstructure is thus explicitly modeled inside the\nmacrostructure, leading to a coupled two-scale formulation. Unfortunately, the\nhigh computational costs of such multiscale simulations often render the\nsolution of design, optimization, or inverse problems infeasible. To address\nthis issue, we propose in this work a non-intrusive reduced basis method to\nconstruct inexpensive surrogates for parametrized microscale problems; the\nmethod is specifically well-suited for multiscale simulations since the coupled\nsimulation is decoupled into two independent problems: (1) solving the\nmicroscopic problem for different (loading or material) parameters and learning\na surrogate model from the data; and (2) solving the macroscopic problem with\nthe learned material model. The proposed method has three key features. First,\nthe microscopic stress field can be fully recovered. Second, the method is able\nto accurately predict the stress field for a wide range of material parameters;\nfurthermore, the derivatives of the effective stress with respect to the\nmaterial parameters are available and can be readily utilized in solving\noptimization problems. Finally, it is more data efficient, i.e. requiring less\ntraining data, as compared to directly performing a regression on the effective\nstress. For the microstructures in the two test problems considered, the mean\napproximation error of the effective stress is as low as 0.1% despite using a\nrelatively small training dataset. Embedded into the macroscopic problem, the\nreduced order model leads to an online speed up of approximately three orders\nof magnitude while maintaining a high accuracy as compared to the FE$^2$\nsolver.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 15:58:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Guo", "Theron", ""], ["Roko\u0161", "Ond\u0159ej", ""], ["Veroy", "Karen", ""]]}, {"id": "2104.04571", "submitter": "Daniel Candeloro Cunha", "authors": "Daniel Candeloro Cunha, Breno Vincenzo de Almeida, Heitor Nigro Lopes,\n  Renato Pavanello", "title": "Finite Variation Sensitivity Analysis for Discrete Topology Optimization\n  of Continuum Structures", "comments": "31 pages, 25 figures, submitted to Structural and Multidisciplinary\n  Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two novel approaches to perform more suitable sensitivity\nanalyses for discrete topology optimization methods. To properly support them,\nwe introduce a more formal description of the Bi-directional Evolutionary\nStructural Optimization (BESO) method, in which the sensitivity analysis is\nbased on finite variations of the objective function. The proposed approaches\nare compared to a naive strategy; to the conventional strategy, referred to as\nFirst-Order Continuous Interpolation (FOCI) approach; and to a strategy\npreviously developed by other researchers, referred to as High-Order Continuous\nInterpolation (HOCI) approach. The novel Woodbury approach provides exact\nsensitivity values and is a better alternative to HOCI. Although HOCI and\nWoodbury approaches may be computationally prohibitive, they provide useful\nexpressions for a better understanding of the problem. The novel Conjugate\nGradient Method (CGM) approach provides sensitivity values with arbitrary\nprecision and is computationally viable for a small number of steps. The CGM\napproach is a better alternative to FOCI since, for appropriate initial\nconditions, it is always more accurate than the conventional strategy. The\nstandard compliance minimization problem with volume constraint is considered\nto illustrate the methodology. Numerical examples are presented together with a\nbroad discussion about BESO-type methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 18:22:50 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 17:44:51 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Cunha", "Daniel Candeloro", ""], ["de Almeida", "Breno Vincenzo", ""], ["Lopes", "Heitor Nigro", ""], ["Pavanello", "Renato", ""]]}, {"id": "2104.04663", "submitter": "Ning Bao", "authors": "Faisal Shah Khan and Ning Bao", "title": "Quantum Prisoner's Dilemma and High Frequency Trading on the Quantum\n  Cloud", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CE cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-frequency trading (HFT) offers an excellent user case and a potential\nkiller application of the commercially available, first generation\nquasi-quantum communication and computation technologies. To this end, we offer\nhere a simple but complete game-theoretic model of HFT as the famous two player\ngame, Prisoner's Dilemma. We explore the implementation of HFT as a game on the\n(quasi) quantum cloud using the Eisert, Wilkens, and Lewenstein quantum\nmediated communication protocol, and how this implementation can increase\ntransaction speed and improve the lot of the players in HFT. Using cooperative\ngame-theoretic reasoning, we also note that in the near future when the\ninternet is properly quantum, players will be able to achieve Pareto-optimality\nin HFT as an instance of reinforced learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 01:45:37 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Khan", "Faisal Shah", ""], ["Bao", "Ning", ""]]}, {"id": "2104.04774", "submitter": "Luigi Frunzo", "authors": "D.B. Panaro, M.R. Mattei, G. Esposito, J.P. Steyer, F. Capone, L.\n  Frunzo", "title": "A modeling and simulation study of anaerobic digestion in plug-flow\n  reactors", "comments": "25 pages, 11 figures, preprint version", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mathematical model for anaerobic digestion in plug-flow reactors is\nproposed on the basis of mass balance considerations. The model consists of a\nsystem of parabolic partial differential equations for the variables\nrepresenting the concentrations of the bio-components constituting the waste\nmatrix and takes into account convective and diffusive phenomena. The plug-flow\nreactor is modelled as a one-dimensional domain; the waste matrix moves in the\ndirection of the reactor axis and undergoes diffusive phenomena which reproduce\nthe movement of the bio-components along the reactor axis due to a gradient in\nconcentration. The velocity characterizing the convection of the waste matrix\nis not fixed a priori but it is considered as an additional unknown of the\nmathematical problem. The variation in the convective velocity allows to\naccount the mass variation occurring along a plug-flow reactor due to the\nconversion of solids. The equation governing the convective velocity is derived\nby considering the density of the waste matrix within the reactor constant over\ntime and the sum of the volume fractions of the bio-components constituting the\nwaste matrix constrained to unity. The waste matrix undergoes biochemical\ntransformations catalysed by anaerobic microbial species which lead to the\nproduction of gaseous methane, the final product of the anaerobic digestion\nprocess. Biochemical processes are modelled using a simplified scheme and a\ndifferential equation is used to describe the dynamics of the produced gaseous\nmethane. A finite difference scheme is used for the numerical integration.\nModel consistency is showed through numerical simulations which investigate the\neffect of the variation of some operating parameters on process performance.\nThe model is then applied to a real case scenario of engineering interest.\nSimulations produce results in good agreement with experimental observations.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 14:22:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Panaro", "D. B.", ""], ["Mattei", "M. R.", ""], ["Esposito", "G.", ""], ["Steyer", "J. P.", ""], ["Capone", "F.", ""], ["Frunzo", "L.", ""]]}, {"id": "2104.05132", "submitter": "Balakrishnan Devarajan", "authors": "Balakrishnan Devarajan", "title": "Analyzing Thermal Buckling in Curvilinearly Stiffened Composite Plates\n  with Arbitrary Shaped Cutouts Using Isogeometric Level Set Method", "comments": "Submitted to Composite Structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we develop a new simple and effective isogeometric analysis for\nmodeling thermal buckling of stiffened laminated composite plates with cutouts\nusing level sets. We employ a first order shear deformation theory to\napproximate the displacement field of the stiffeners and the plate. Numerical\nmodeling with a treatment of trimmed objects, such as internal cutouts in terms\nof NURBS-based isogeometric analysis presents several challenges, primarily due\nto need for using the tensor product of the NURBS basis functions. Due to this\nfeature, the refinement operations can only be performed globally on the domain\nand not locally around the cutout. The new approach can overcome the drawbacks\nin modeling complex geometries with multiple-patches as the level sets are used\nto describe the internal cutouts; while the numerical integration is used only\ninside the physical domain. Results of parametric studies are presented which\nshow the influence of ply orientation, size and orientation of the cutout and\nthe position and profile of the curvilinear stiffeners. The numerical examples\nshow high reliability and efficiency of the present method compared with other\npublished solutions and ABAQUS.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 22:56:25 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 20:08:38 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Devarajan", "Balakrishnan", ""]]}, {"id": "2104.05580", "submitter": "Jonas F. Eichinger", "authors": "Jonas F. Eichinger, Daniel Paukner, Roland C. Aydin, Wolfgang A. Wall,\n  Jay D. Humphrey, Christian J. Cyron", "title": "What do cells regulate in soft tissues on short time scales?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.CB cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cells within living soft biological tissues seem to promote the maintenance\nof a mechanical state within a defined range near a so-called set-point. This\nmechanobiological process is often referred to as mechanical homeostasis.\nDuring this process, cells intimately interact with the fibers of the\nsurrounding extracellular matrix (ECM). It remains poorly understood, however,\nwhat individual cells actually regulate during these interactions, and how\nthese micromechanical regulations are translated to tissue level to lead to\nwhat we macroscopically call mechanical homeostasis. Herein, we examine this\nquestion by a combination of experiments, theoretical analysis and\ncomputational modeling. We demonstrate that on short time scales (hours) -\nduring which deposition and degradation of ECM fibers can largely be neglected\n- cells appear to regulate neither the stress / strain in the ECM nor their own\nshape, but rather only the contractile forces that they exert on the\nsurrounding ECM.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:22:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Eichinger", "Jonas F.", ""], ["Paukner", "Daniel", ""], ["Aydin", "Roland C.", ""], ["Wall", "Wolfgang A.", ""], ["Humphrey", "Jay D.", ""], ["Cyron", "Christian J.", ""]]}, {"id": "2104.05818", "submitter": "Sansit Patnaik", "authors": "Sansit Patnaik and Sai Sidhardh and Fabio Semperlotti", "title": "Displacement-Driven Approach to Nonlocal Elasticity", "comments": "7 figures, 20 pages of main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.app-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a physically consistent displacement-driven reformulation\nof the concept of action-at-a-distance, which is at the foundation of nonlocal\nelasticity. In contrast to existing approaches that adopts an integral\nstress-strain constitutive relation, the displacement-driven approach is\npredicated on an integral strain-displacement relation. The most remarkable\nconsequence of this reformulation is that the (total) strain energy is\nguaranteed to be convex and positive-definite without imposing any constraint\non the symmetry of the kernels. This feature is critical to enable the\napplication of nonlocal formulations to general continua exhibiting asymmetric\ninteractions; ultimately a manifestation of material heterogeneity. Remarkably,\nthe proposed approach also enables a strong satisfaction of the locality\nrecovery condition and of the laws of thermodynamics, which are not foregone\nconclusions in most classical nonlocal elasticity theories. Additionally, the\nformulation is frame-invariant and the nonlocal operator remains physically\nconsistent at boundaries. The study is complemented by a detailed analysis of\nthe dynamic response of the nonlocal continuum and of its intrinsic dispersion\nleading to the consideration that the choice of nonlocal kernels should depend\non the specific material. Examples of exponential or power-law kernels are\npresented in order to demonstrate the applicability of the method to different\nclasses of nonlocal media. The ability to admit generalized kernels reinforces\nthe generalized nature of the displacement-driven approach over existing\nintegral methodologies, which typically lead to simplified differential models\nbased on exponential kernels. The theoretical formulation is also leveraged to\nsimulate the static response of nonlocal beams and plates illustrating the\nintrinsic consistency of the approach, which is free from unwanted boundary\neffects.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 00:28:12 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Patnaik", "Sansit", ""], ["Sidhardh", "Sai", ""], ["Semperlotti", "Fabio", ""]]}, {"id": "2104.05849", "submitter": "Shashank Motepalli", "authors": "Shashank Motepalli and Hans-Arno Jacobsen", "title": "Reward Mechanism for Blockchains Using Evolutionary Game Theory", "comments": "Cite: @inproceedings{motepalli2021reward, title={Reward Mechanism for\n  Blockchains Using Evolutionary Game Theory}, author={Motepalli, Shashank and\n  Jacobsen, Hans-Arno}, booktitle={2021 3rd Conference on Blockchain Research &\n  Applications for Innovative Networks and Services (BRAINS)}, year={2021} }", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have witnessed widespread adoption in the past decade in various\nfields. The growing demand makes their scalability and sustainability\nchallenges more evident than ever. As a result, more and more blockchains have\nbegun to adopt proof-of-stake (PoS) consensus protocols to address those\nchallenges. One of the fundamental characteristics of any blockchain technology\nis its crypto-economics and incentives. Lately, each PoS blockchain has\ndesigned a unique reward mechanism, yet, many of them are prone to free-rider\nand nothing-at-stake problems. To better understand the ad-hoc design of reward\nmechanisms, in this paper, we develop a reward mechanism framework that could\napply to many PoS blockchains. We formulate the block validation game wherein\nthe rewards are distributed for validating the blocks correctly. Using\nevolutionary game theory, we analyze how the participants' behaviour could\npotentially evolve with the reward mechanism. Also, penalties are found to play\na central role in maintaining the integrity of blockchains.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 22:38:32 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 18:56:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Motepalli", "Shashank", ""], ["Jacobsen", "Hans-Arno", ""]]}, {"id": "2104.06621", "submitter": "Mahesh Patil", "authors": "Mahesh B. Patil and Ruchita D. Korgaonkar and Kumar Appaiah", "title": "GSEIM: A General-purpose Simulator with Explicit and Implicit Methods", "comments": "14 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new simulation package, GSEIM, for solving a set of ordinary differential\nequations is presented. The organisation of the program is illustrated with the\nhelp of a block diagram. Various features of GSEIM are discussed. Two ways of\nincorporating new elements in GSEIM, viz., as a template and as a subcircuit,\nare explained by taking a specific example. Simulation examples are described\nto bring out the capabilities of GSEIM.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 04:51:38 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Patil", "Mahesh B.", ""], ["Korgaonkar", "Ruchita D.", ""], ["Appaiah", "Kumar", ""]]}, {"id": "2104.06695", "submitter": "Frederik Geth", "authors": "Frederik Geth, James Foster", "title": "Improving Optimal Power Flow Relaxations Using 3-Cycle Second-Order Cone\n  Constraints", "comments": "3 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a novel second order cone relaxation of the semidefinite\nprogramming formulation of optimal power flow, that does not imply the `angle\nrelaxation'. We build on a technique developed by Kim et al., extend it for\ncomplex matrices, and apply it to 3x3 positive semidefinite matrices to\ngenerate novel second-order cone constraints that augment upon the well-known\n2x2 principal-minor based second-order cone constraints. Finally, we apply it\nto optimal power flow in meshed networks and provide numerical illustrations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 08:37:43 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Geth", "Frederik", ""], ["Foster", "James", ""]]}, {"id": "2104.06777", "submitter": "Christina Schenk", "authors": "Christina Schenk and Volker H. Schulz", "title": "Existence, Uniqueness and Numerical Modeling of Wine Fermentation Based\n  on Integro-Differential Equations", "comments": "26 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.CE cs.NA math.NA q-bio.CB q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive modeling is the key factor for saving time and resources with\nrespect to manufacturing processes such as fermentation processes arising e.g.\\\nin food and chemical manufacturing processes. According to Zhang et al. (2002),\nthe open-loop dynamics of yeast are highly dependent on the initial cell mass\ndistribution. This can be modeled via population balance models describing the\nsingle-cell behavior of the yeast cell. There have already been several\npopulation balance models for wine fermentation in the literature. However, the\nnew model introduced in this paper is much more detailed than the ones studied\npreviously. This new model for the white wine fermentation process is based on\na combination of components previously introduced in literature. It turns it\ninto a system of highly nonlinear weakly hyperbolic partial/ordinary\nintegro-differential equations. This model becomes very challenging from a\ntheoretical and numerical point of view. Existence and uniqueness of solutions\nto a simplified version of the introduced problem is studied based on semigroup\ntheory. For its numerical solution a numerical methodology based on a finite\nvolume scheme combined with a time implicit scheme is derived. The impact of\nthe initial cell mass distribution on the solution is studied and underlined\nwith numerical results. The detailed model is compared to a simpler model based\non ordinary differential equations. The observed differences for different\ninitial distributions and the different models turn out to be smaller than\nexpected. The outcomes of this paper are very interesting and useful for\napplied mathematicians, winemakers and process engineers.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 11:07:34 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Schenk", "Christina", ""], ["Schulz", "Volker H.", ""]]}, {"id": "2104.06784", "submitter": "Yih-Chin Tai", "authors": "Chi-Jyun Ko, Po-Chih Chen, Hock-Kiet Wong and Yih-Chin Tai", "title": "MoSES_2PDF: A GIS-Compatible GPU-accelerated High-Performance Simulation\n  Tool for Grain-Fluid Shallow Flows", "comments": "16 pages, 7 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a GPU-accelerated simulation tool, named Modeling on Shallow\nFlows with Efficient Simulation for Two-Phase Debris Flows (MoSES_2PDF), of\nwhich the input and output data can be linked to the GIS system for engineering\napplication. MoSES_2PDF is developed based on the CUDA structure so that it can\nwell run with different NVIDIA GPU cards, once the CUDA vers. 9.2 (or higher)\nis installed. The performance of the MoSES_2PDF is evaluated, and it is found\nthat the present GPU-CUDA implementation can enhance efficiency by up to 230\nfolds, depending on the PC/workstations, models of GPU card, and the mesh\nnumbers in the computation domain. Two numerical examples are illustrated with\ntwo distinct initial inflow conditions, which are included in two modes of\nMoSES_2PDF, respectively. In the numerical example of a large-scale event, the\n2009 Hsiaolin event, the results computed by two distinct NVIDIA GPU cards\n(RTX-2080-Ti and Tesla-V100) are found to be identical but only tiny deviation\nis figured out in comparison with the results computed by the conventional\nsingle-core CPU-code. It is speculated to be caused by the different structures\nin the source codes and some float/double operations. In addition to the\nillustration in the GIS system, the computed results by MoSES\\_2PDF can also be\nshown with animated 3D graphics in the ANSI-Platform, where the user can\ninteract with 3D scenes. The feasibility, features, and facilities of\nMoSES\\_2PDF are demonstrated with respect to the two numerical examples\nconcerning two real events.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 11:19:39 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Ko", "Chi-Jyun", ""], ["Chen", "Po-Chih", ""], ["Wong", "Hock-Kiet", ""], ["Tai", "Yih-Chin", ""]]}, {"id": "2104.07668", "submitter": "Kan Ziyun", "authors": "Ziyun Kan, Kaijun Dong, Biaosong Chen, Haijun Peng, Xueguan Song", "title": "The direct force correction based framework for general co-rotational\n  analysis", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of nonlinear projection matrix in co-rotational (CR) analysis was\npioneered by Rankin and Nour-Omid in 1990s (Computers & Structures, 30 (1988)\n257-267; Comput. Methods Appl. Mech. Engrg., 93 (1991) 353-384), and has almost\nbecame a standard manner for CR formulations deduction over the past thirty\nyears. This matrix however relies heavily on a hysterical and sophisticated\nderivation of the variation of the local displacements to the global ones,\nleading to complicated expressions for the internal force vector and the\ntangent stiffness matrix, which may devalue the simplicity and convenience for\nthe original intention of using CR approach. This paper begins by making a\ndiscussion on existing element independent CR formulation and the objective is\nto develop a new and simple framework for general CR analysis that avoids using\nconventional nonlinear projection matrix. Multiple numerical examples involving\nvarious kinds of elements and different choices of element local CR frame are\npresented to demonstrate the performance of the proposed framework. The\noutcomes show that for all the examples the accuracy of the results are\ncomparable with those obtained in conjunction with conventional nonlinear\nprojection matrix.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 13:17:21 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Kan", "Ziyun", ""], ["Dong", "Kaijun", ""], ["Chen", "Biaosong", ""], ["Peng", "Haijun", ""], ["Song", "Xueguan", ""]]}, {"id": "2104.07932", "submitter": "Marian-Andrei Rizoiu", "authors": "Marian-Andrei Rizoiu, Alexander Soen, Shidi Li, Pio Calderon, Leanne\n  Dong, Aditya Krishna Menon and Lexing Xie", "title": "Interval-censored Hawkes processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work builds a novel point process and tools to use the Hawkes process\nwith interval-censored data. Such data records the aggregated counts of events\nsolely during specific time intervals -- such as the number of patients\nadmitted to the hospital or the volume of vehicles passing traffic loop\ndetectors -- and not the exact occurrence time of the events. First, we\nestablish the Mean Behavior Poisson (MBP) process, a novel Poisson process with\na direct parameter correspondence to the popular self-exciting Hawkes process.\nThe event intensity function of the MBP is the expected intensity over all\npossible Hawkes realizations with the same parameter set. We fit MBP in the\ninterval-censored setting using an interval-censored Poisson log-likelihood\n(IC-LL). We use the parameter equivalence to uncover the parameters of the\nassociated Hawkes process. Second, we introduce two novel exogenous functions\nto distinguish the exogenous from the endogenous events. We propose the\nmulti-impulse exogenous function when the exogenous events are observed as\nevent time and the latent homogeneous Poisson process exogenous function when\nthe exogenous events are presented as interval-censored volumes. Third, we\nprovide several approximation methods to estimate the intensity and compensator\nfunction of MBP when no analytical solution exists. Fourth and finally, we\nconnect the interval-censored loss of MBP to a broader class of Bregman\ndivergence-based functions. Using the connection, we show that the current\nstate of the art in popularity estimation (Hawkes Intensity Process (HIP)\n(Rizoiu et al.,2017b)) is a particular case of the MBP process. We verify our\nmodels through empirical testing on synthetic data and real-world data. We find\nthat on real-world datasets that our MBP process outperforms HIP for the task\nof popularity prediction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 07:29:04 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 01:58:51 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 00:07:50 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Rizoiu", "Marian-Andrei", ""], ["Soen", "Alexander", ""], ["Li", "Shidi", ""], ["Calderon", "Pio", ""], ["Dong", "Leanne", ""], ["Menon", "Aditya Krishna", ""], ["Xie", "Lexing", ""]]}, {"id": "2104.08132", "submitter": "Emilio Mart\\'inez-Pa\\~neda", "authors": "Yousef Navidtehrani, Covadonga Beteg\\'on, Emilio Mart\\'inez-Pa\\~neda", "title": "A simple and robust Abaqus implementation of the phase field fracture\n  method", "comments": null, "journal-ref": "Applications in Engineering Science (2021)", "doi": null, "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase field fracture method is attracting significant interest. Phase\nfield approaches have enabled predicting - on arbitrary geometries and\ndimensions - complex fracture phenomena such as crack branching, coalescence,\ndeflection and nucleation. In this work, we present a simple and robust\nimplementation of the phase field fracture method in the commercial finite\nelement package Abaqus. The implementation exploits the analogy between the\nphase field evolution law and the heat transfer equation, enabling the use of\nAbaqus' in-built features and circumventing the need for defining user\nelements. The framework is general, and is shown to accommodate different\nsolution schemes (staggered and monolithic), as well as various constitutive\nchoices for preventing damage under compression. The robustness and\napplicability of the numerical framework presented is demonstrated by\naddressing several 2D and 3D boundary value problems of particular interest.\nFocus is on the solution of paradigmatic case studies that are known to be\nparticularly demanding from a convergence perspective. The results reveal that\nour phase field fracture implementation can be readily combined with other\nadvanced computational features, such as contact, and deliver robust and\nprecise solutions. The code developed can be downloaded from\nwww.empaneda.com/codes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 14:29:20 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Navidtehrani", "Yousef", ""], ["Beteg\u00f3n", "Covadonga", ""], ["Mart\u00ednez-Pa\u00f1eda", "Emilio", ""]]}, {"id": "2104.08260", "submitter": "Dmitrii Legatiuk", "authors": "Dmitrii Legatiuk and Daniel Weisz-Patrault", "title": "Coupling of complex function theory and finite element method for crack\n  propagation through energetic formulation: conformal mapping approach and\n  reduction to a Riemann-Hilbert problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CV cs.CE cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a theoretical background of a coupled\nanalytical-numerical approach to model a crack propagation process in\ntwo-dimensional bounded domains. The goal of the coupled analytical-numerical\napproach is to obtain the correct solution behaviour near the crack tip by help\nof the analytical solution constructed by using tools of the complex function\ntheory and couple it continuously with the finite element solution in the\nregion far from singularity. In this way, crack propagation could be modelled\nwithout using remeshing. Possible directions of crack growth can be calculated\nthrough the minimization of the total energy composed of the potential energy\nand the dissipated energy based on the energy release rate. Within this\nsetting, an analytical solution of a mixed boundary value problem based on\ncomplex analysis and conformal mapping techniques is presented in a circular\nregion containing an arbitrary crack path. More precisely, the linear elastic\nproblem is transformed into a Riemann-Hilbert problem in the unit disk for\nholomorphic functions. Utilising advantages of the analytical solution in the\nregion near the crack tip, the total energy could be evaluated within short\ncomputation times for various crack kink angles and lengths leading to a\npotentially efficient way of computing the minimization procedure. To this end,\nthe paper presents a general strategy of the new coupled approach for crack\npropagation modelling. Additionally, we also discuss obstacles on the way of\npractical realisation of this strategy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:46:45 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Legatiuk", "Dmitrii", ""], ["Weisz-Patrault", "Daniel", ""]]}, {"id": "2104.09111", "submitter": "Martin Servin", "authors": "Martin Servin and Folke Vesterlund and Erik Wallin", "title": "Digital twins with distributed particle simulation for mine-to-mill\n  material tracking", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems for transport and processing of granular media are challenging to\nanalyse, operate and optimise. In the mining and mineral processing industries\nthese systems are chains of processes with complex interplay between the\nequipment, control, and the processed material. The material properties have\nnatural variations that are usually only known at certain locations. Therefore,\nwe explore a material-oriented approach to digital twins with a particle\nrepresentation of the granular media. In digital form, the material is treated\nas pseudo-particles, each representing a large collection of real particles of\nvarious sizes, shapes and, mineral properties. Movements and changes in the\nstate of the material are determined by the combined data from control systems,\nsensors, vehicle telematics, and simulation models at locations where no real\nsensors can see. The particle-based representation enables material tracking\nalong the chain of processes. Each digital particle can act as a carrier of\nobservational data generated by the equipment as it interacts with the real\nmaterial. This makes it possible to better learn material properties from\nprocess observations, and to predict the effect on downstream processes. We\ntest the technique on a mining simulator and demonstrate analysis that can be\nperformed using data from cross-system material tracking.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 08:08:52 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Servin", "Martin", ""], ["Vesterlund", "Folke", ""], ["Wallin", "Erik", ""]]}, {"id": "2104.09262", "submitter": "Emma La Malfa Ribolla Dr.", "authors": "Milan Jir\\'asek, Emma La Malfa Ribolla, Martin Hor\\'ak", "title": "Efficient formulation of a geometrically nonlinear beam element", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper presents a two-dimensional geometrically nonlinear formulation of a\nbeam element that can accommodate arbitrarily large rotations of cross\nsections. The formulation is based on the integrated form of equilibrium\nequations, which are combined with the kinematic equations and generalized\nmaterial equations, leading to a set of three first-order differential\nequations. These equations are then discretized by finite differences and the\nboundary value problem is converted into an initial value problem using a\ntechnique inspired by the shooting method. Accuracy of the numerical\napproximation is conveniently increased by refining the integration scheme on\nthe element level while the number of global degrees of freedom is kept\nconstant, which leads to high computational efficiency. The element has been\nimplemented into an open-source finite element code. Numerical examples show a\nfavorable comparison with standard beam elements formulated in the\nfinite-strain framework and with analytical solutions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:08:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jir\u00e1sek", "Milan", ""], ["Ribolla", "Emma La Malfa", ""], ["Hor\u00e1k", "Martin", ""]]}, {"id": "2104.09276", "submitter": "Zhenguo Nie", "authors": "Qingfeng Xu, Zhenguo Nie, Handing Xu, Haosu Zhou, Xinjun Liu", "title": "SuperMeshing: A New Deep Learning Architecture for Increasing the Mesh\n  Density of Metal Forming Stress Field with Attention Mechanism and Perceptual\n  Features", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stress field analysis, the finite element analysis is a crucial approach,\nin which the mesh-density has a significant impact on the results. High mesh\ndensity usually contributes authentic to simulation results but costs more\ncomputing resources, leading to curtailing efficiency during the design\nprocess. To eliminate this drawback, we propose a new data-driven mesh-density\nboost model named SuperMeshingNet that strengthens the advantages of finite\nelement analysis (FEA) with low mesh-density as inputs to the deep learning\nmodel, which consisting of Res-UNet architecture, to acquire high-density\nstress field instantaneously, shortening computing time and cost automatically.\nMoreover, the attention mechanism and the perceptual features are utilized,\nenhancing the performance of SuperMeshingNet. Compared to the baseline that\napplied the linear interpolation method, SuperMeshingNet achieves a prominent\nreduction in the mean squared error (MSE) and mean absolute error (MAE) on test\ndata, which contains prior unseen cases. Based on the data set of metal\nforming, the comparable experiments are proceeded to demonstrate the high\nquality and superior precision of the reconstructed results generated by our\nmodel. The well-trained model can successfully show more excellent performance\nthan the baseline and other methods on the multiple scaled mesh-density,\nincluding $2\\times$, $4\\times$, and $8\\times$. With the refined result owning\nbroaden scaling of mesh density and high precision, the FEA process can be\naccelerated with seldom cost on computation resources. We publicly share our\nwork with full detail of implementation at\nhttps://github.com/zhenguonie/2021_SuperMeshing_2D_Metal_Forming\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 06:02:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Xu", "Qingfeng", ""], ["Nie", "Zhenguo", ""], ["Xu", "Handing", ""], ["Zhou", "Haosu", ""], ["Liu", "Xinjun", ""]]}, {"id": "2104.09355", "submitter": "Sam Partee", "authors": "Sam Partee, Matthew Ellis, Alessandro Rigazzi, Scott Bachman, Gustavo\n  Marques, Andrew Shao, Benjamin Robbins", "title": "Using Machine Learning at Scale in HPC Simulations with SmartSim: An\n  Application to Ocean Climate Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first climate-scale, numerical ocean simulations improved\nthrough distributed, online inference of Deep Neural Networks (DNN) using\nSmartSim. SmartSim is a library dedicated to enabling online analysis and\nMachine Learning (ML) for traditional HPC simulations. In this paper, we detail\nthe SmartSim architecture and provide benchmarks including online inference\nwith a shared ML model on heterogeneous HPC systems. We demonstrate the\ncapability of SmartSim by using it to run a 12-member ensemble of global-scale,\nhigh-resolution ocean simulations, each spanning 19 compute nodes, all\ncommunicating with the same ML architecture at each simulation timestep. In\ntotal, 970 billion inferences are collectively served by running the ensemble\nfor a total of 120 simulated years. Finally, we show our solution is stable\nover the full duration of the model integrations, and that the inclusion of\nmachine learning has minimal impact on the simulation runtimes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 19:27:28 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Partee", "Sam", ""], ["Ellis", "Matthew", ""], ["Rigazzi", "Alessandro", ""], ["Bachman", "Scott", ""], ["Marques", "Gustavo", ""], ["Shao", "Andrew", ""], ["Robbins", "Benjamin", ""]]}, {"id": "2104.09499", "submitter": "Yifeng Che", "authors": "Yifeng Che, Joseph Yurko, Koroush Shirvan", "title": "Machine learning-assisted surrogate construction for full-core fuel\n  performance analysis", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the behavior of a nuclear reactor requires multiphysics\nsimulation of coupled neutronics, thermal-hydraulics and fuel thermo-mechanics.\nThe fuel thermo-mechanical response provides essential information for\noperational limits and safety analysis. Traditionally, fuel performance\nanalysis is performed standalone, using calculated spatial-temporal power\ndistribution and thermal boundary conditions from the coupled\nneutronics-thermal-hydraulics simulation as input. Such one-way coupling is\nresult of the high cost induced by the full-core fuel performance analysis,\nwhich provides more realistic and accurate prediction of the core-wide response\nthan the \"peak rod\" analysis. It is therefore desirable to improve the\ncomputational efficiency of full-core fuel performance modeling by constructing\nfast-running surrogate, such that fuel performance modeling can be utilized in\nthe core reload design optimization. This work presents methodologies for\nfull-core surrogate construction based on several realistic equilibrium PWR\ncore designs. As a fast and conventional approach, look-up tables are only\neffective for certain fuel performance quantities of interest (QoIs). Several\nrepresentative machine-learning algorithms are introduced to capture the\ncomplicated physics for other fuel performance QoIs. Rule-based model is useful\nas a feature extraction technique to account for the spatial-temporal\ncomplexity of operating conditions. Constructed surrogates achieve at least ten\nthousand time acceleration with satisfying prediction accuracy. Current work\nlays foundation for tighter coupling of fuel performance modeling into the core\ndesign optimization framework. It also sets stage for full-core fuel\nperformance analysis with BISON where the computational cost becomes more\nburdensome.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 17:02:50 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Che", "Yifeng", ""], ["Yurko", "Joseph", ""], ["Shirvan", "Koroush", ""]]}, {"id": "2104.09623", "submitter": "Jan N. Fuhg", "authors": "Jan N. Fuhg, Nikolaos Bouklas", "title": "The mixed deep energy method for resolving concentration features in\n  finite strain hyperelasticity", "comments": "17 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The introduction of Physics-informed Neural Networks (PINNs) has led to an\nincreased interest in deep neural networks as universal approximators of PDEs\nin the solid mechanics community. Recently, the Deep Energy Method (DEM) has\nbeen proposed. DEM is based on energy minimization principles, contrary to PINN\nwhich is based on the residual of the PDEs. A significant advantage of DEM, is\nthat it requires the approximation of lower order derivatives compared to\nformulations that are based on strong form residuals. However both DEM and\nclassical PINN formulations struggle to resolve fine features of the stress and\ndisplacement fields, for example concentration features in solid mechanics\napplications. We propose an extension to the Deep Energy Method (DEM) to\nresolve these features for finite strain hyperelasticity. The developed\nframework termed mixed Deep Energy Method (mDEM) introduces stress measures as\nan additional output of the NN to the recently introduced pure displacement\nformulation. Using this approach, Neumann boundary conditions are approximated\nmore accurately and the accuracy around spatial features which are typically\nresponsible for high concentrations is increased. In order to make the proposed\napproach more versatile, we introduce a numerical integration scheme based on\nDelaunay integration, which enables the mDEM framework to be used for random\ntraining point position sets commonly needed for computational domains with\nstress concentrations. We highlight the advantages of the proposed approach\nwhile showing the shortcomings of classical PINN and DEM formulations. The\nmethod is offering comparable results to Finite-Element Method (FEM) on the\nforward calculation of challenging computational experiments involving domains\nwith fine geometric features and concentrated loads.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 22:43:23 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Fuhg", "Jan N.", ""], ["Bouklas", "Nikolaos", ""]]}, {"id": "2104.09746", "submitter": "Wenzhe Shan", "authors": "Wenzhe Shan, Udo Nackenhorst", "title": "Computing Arlequin coupling coefficient for concurrent FE-MD approaches", "comments": "19 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Arlequin coupling coefficient is essential for concurrent FE-MD models with\noverlapping domains, but the calculation of its value is quite difficult when\nthe geometry of the coupling region is complicated. In this work, we introduce\na general procedure for the preprocessing of a concurrent FE-MD model, given\nthat the mesh and atoms have already been created. The procedure is independent\nof the geometry of the coupling region and can be used for both 2D and 3D\nproblems. The procedure includes steps of determining the relative positions of\natoms inside the FE elements in the coupling region, as well as computing the\nArlequin coupling coefficient for an arbitrary point inside the coupling region\nor on its boundary. Two approaches are provided for determining the\ncoefficient: the direct approach and the temperature approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 03:49:08 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Shan", "Wenzhe", ""], ["Nackenhorst", "Udo", ""]]}, {"id": "2104.09749", "submitter": "Wenzhe Shan", "authors": "Wenzhe Shan, Udo Nackenhorst", "title": "Interpolation of Microscale Stress and Strain Fields Based on Mechanical\n  Models", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this short contribution we introduce a new procedure to recover the stress\nand strain fields for particle systems by mechanical models. Numerical tests\nfor simple loading conditions have shown an excellent match between the\nestimated values and the reference values. The estimated stress field is also\nconsistent with the so called Quasicontinuum stress field, which suggests its\npotential application for scale bridging techniques. The estimated stress\nfields for complicated loading conditions such as defect and indentation are\nalso demonstrated\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 04:01:58 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Shan", "Wenzhe", ""], ["Nackenhorst", "Udo", ""]]}, {"id": "2104.09844", "submitter": "Nora Hagmeyer", "authors": "Nora Hagmeyer, Matthias Mayr, Ivo Steinbrecher and Alexander Popp", "title": "Fluid-beam interaction: Capturing the effect of embedded slender bodies\n  on global fluid flow and vice versa", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses research questions arising from the application of\ngeometrically exact beam theory in the context of fluid-structure interaction\n(FSI). Geometrically exact beam theory has proven to be a computationally\nefficient way to model the behavior of slender structures while leading to\nrather well-posed problem descriptions. In particular, we propose a\nmixed-dimensional embedded finite element approach for the coupling of\none-dimensional geometrically exact beam equations to a three-dimensional\nbackground fluid mesh, referred to as fluid-beam interaction (FBI) in analogy\nto the well-established notion of FSI. Here, the fluid is described by the\nincompressible isothermal Navier-Stokes equations for Newtonian fluids. In\nparticular, we present algorithmic aspects regarding the solution of the\nresulting one-way coupling schemes and, through selected numerical examples,\nanalyze their suitability not only as stand-alone methods but also for an\nextension to a full two-way coupling scheme.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 09:14:10 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 08:45:59 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hagmeyer", "Nora", ""], ["Mayr", "Matthias", ""], ["Steinbrecher", "Ivo", ""], ["Popp", "Alexander", ""]]}, {"id": "2104.10118", "submitter": "Luis S\\'anchez De Le\\'on", "authors": "Juan M. Tiz\\'on and Pablo Sierra and Luis S\\'anchez de Le\\'on and\n  Emilio Navarro and Javier Vil\\'a and Jos\\'e F. Moral", "title": "Developing a New Tool to Implement Computer-Supported Active Learning\n  Strategies in the Engineering Classroom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful implementation of active learning strategies in the engineering\nclassroom -- and in particular in certain subjects which are highly\ntechnological in nature such as, for instance, rocket engines and space\npropulsion -- means overcoming certain challenges that arise from the fact that\nthese are extremely complex systems to analyze. In this paper, we address the\nspecific means to overcome one of such challenges: the lack of readily\navailable software tools that are suitable for implementing this sort of\nteaching strategies within the engineering training. In particular, we develop\na new tool for the modeling and simulation of liquid-propellant rocket engines\nspecially tailored for the classroom, taking a systematic approach to the\ndevelopment of such tool based on the needs of modern teaching practices. After\na thorough review of the available literature on the topic, the few most\ncritical features that our tool should have in order to serve its purported\ngoal are identified. Subsequently, a pilot experience to assess the impact of\nthe usage of said tool on the learners' performance was carried out, showcasing\nexcellent results, both in terms of the students' perceived quality of their\ntraining as well as in terms of their grade of retention and understanding of\nthe matter. The conclusions of this study, especially the guidelines for the\ndevelopment of software tools aimed at the classroom, nevertheless, should be\napplicable to any other highly technological discipline, extending the scope of\nthis paper beyond merely the subject of rocket science in engineering.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:56:05 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Tiz\u00f3n", "Juan M.", ""], ["Sierra", "Pablo", ""], ["de Le\u00f3n", "Luis S\u00e1nchez", ""], ["Navarro", "Emilio", ""], ["Vil\u00e1", "Javier", ""], ["Moral", "Jos\u00e9 F.", ""]]}, {"id": "2104.10763", "submitter": "Markus Winklberger", "authors": "Markus Winklberger, Christoph Kralovec and Martin Schagerl", "title": "Development of aircraft spoiler demonstrators to test strain-based SHM\n  under realistic loading", "comments": "21 pages, 11 figures, submitted to AIAA Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An idealized demonstrator of an civil aircraft wing spoiler in scale 1:2 is\ndeveloped to evaluate strain-based structural health monitoring (SHM) methods\nunder realistic loading conditions. SHM promises to increase operational safety\nand reduce maintenance costs of optimized lightweight structures by its early\ndamage detection capabilities. Also localization and size identification of\ndamages could be shown for simple parts, e.g. beams or plates in many\nlaboratory experiments. However, the application of SHM systems on real\nstructures under realistic loading conditions is cost intensive and time\nconsuming. Furthermore, testing facilities which are large enough to fit full\nscale aircraft parts are often not available. The proposed procedure of\ndeveloping a scaled spoiler demonstrator under idealized loading and support\nconditions solves these issues for strain-based SHM. The procedure shows how to\nreproduce the deformation shape of a real aircraft spoiler under a heavy\nloading condition during landing by numerical optimization. Subsequent finite\nelement simulations and experimental measurements proved similar deformations\nand strain states of the idealized demonstrator and the real spoiler. Thus,\nusing the developed idealized spoiler demonstrator strain-based SHM systems can\nbe tested under loading conditions similar to realistic operational loads by\nsignificantly reduced test effort and costs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 06:52:43 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Winklberger", "Markus", ""], ["Kralovec", "Christoph", ""], ["Schagerl", "Martin", ""]]}, {"id": "2104.11079", "submitter": "Tamara Kolda", "authors": "Aydin Buluc, Tamara G. Kolda, Stefan M. Wild, Mihai Anitescu, Anthony\n  DeGennaro, John Jakeman, Chandrika Kamath, Ramakrishnan (Ramki) Kannan, Miles\n  E. Lopes, Per-Gunnar Martinsson, Kary Myers, Jelani Nelson, Juan M. Restrepo,\n  C. Seshadhri, Draguna Vrabie, Brendt Wohlberg, Stephen J. Wright, Chao Yang,\n  Peter Zwart", "title": "Randomized Algorithms for Scientific Computing (RASC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized algorithms have propelled advances in artificial intelligence and\nrepresent a foundational research area in advancing AI for Science. Future\nadvancements in DOE Office of Science priority areas such as climate science,\nastrophysics, fusion, advanced materials, combustion, and quantum computing all\nrequire randomized algorithms for surmounting challenges of complexity,\nrobustness, and scalability. This report summarizes the outcomes of that\nworkshop, \"Randomized Algorithms for Scientific Computing (RASC),\" held\nvirtually across four days in December 2020 and January 2021.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 18:59:26 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Buluc", "Aydin", "", "Ramki"], ["Kolda", "Tamara G.", "", "Ramki"], ["Wild", "Stefan M.", "", "Ramki"], ["Anitescu", "Mihai", "", "Ramki"], ["DeGennaro", "Anthony", "", "Ramki"], ["Jakeman", "John", "", "Ramki"], ["Kamath", "Chandrika", "", "Ramki"], ["Ramakrishnan", "", "", "Ramki"], ["Kannan", "", ""], ["Lopes", "Miles E.", ""], ["Martinsson", "Per-Gunnar", ""], ["Myers", "Kary", ""], ["Nelson", "Jelani", ""], ["Restrepo", "Juan M.", ""], ["Seshadhri", "C.", ""], ["Vrabie", "Draguna", ""], ["Wohlberg", "Brendt", ""], ["Wright", "Stephen J.", ""], ["Yang", "Chao", ""], ["Zwart", "Peter", ""]]}, {"id": "2104.11082", "submitter": "Dixon Vimalajeewa", "authors": "Dixon Vimalajeewa, Sasitharan Balasubramaniam", "title": "Digestive System Dynamics in Molecular Communication Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Consumption of food in excess of the required optimal nutritional\nrequirements has already resulted in a global crisis and this is from the\nperspective of human health, such as obesity, as well as food waste and\nsustainability. In order to minimize the impact of these issues, there is a\nneed to develop novel innovative and effective solutions that can optimally\nmatch the food consumption to the demand. This requires accurate understanding\nof the food digestion dynamics and its impact on each individual's\nphysiological characteristics. This study proposes a model to characterize\ndigestive system dynamics by using concepts from the field of Molecular\nCommunications (MC), and this includes integrating advection-diffusion and\nreaction mechanisms and its role in characterizing the digestion process as a\ncommunication system. The model is then used to explore starch digestion\ndynamics by using communication system metrics such as delay and path loss. Our\nsimulations found that the long gastric emptying time increases the delay in\nstarch digestion and in turn the glucose production and absorption into the\nblood stream. At the same time, the enzyme activity on the hydrolyzed starch\ndirectly impacts the path loss, as higher reaction rates and lower half\nsaturation concentration of starch results in lower path loss. Our work can\nlead to provide insights formulated for each individuals by creating a digital\ntwin digestion model\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:00:30 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Vimalajeewa", "Dixon", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "2104.11114", "submitter": "Nima Noii", "authors": "Nima Noii, Amirreza Khodadadian, Jacinto Ulloa, Fadi Aldakheel, Thomas\n  Wick, Stijn Francois, Peter Wriggers", "title": "Bayesian inversion for unified ductile phase-field fracture", "comments": "61 pages, 21 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of crack initiation and propagation in ductile failure\nprocesses are challenging tasks for the design and fabrication of metallic\nmaterials and structures on a large scale. Numerical aspects of ductile failure\ndictate a sub-optimal calibration of plasticity- and fracture-related\nparameters for a large number of material properties. These parameters enter\nthe system of partial differential equations as a forward model. In this work,\nwe develop a step-wise Bayesian inversion framework for ductile fracture to\nprovide accurate knowledge regarding the effective mechanical parameters. To\nthis end, synthetic and experimental observations are used to estimate the\nposterior density of the unknowns. To model the ductile failure behavior of\nsolid materials, we rely on the phase-field approach to fracture, for which we\npresent a unified formulation that allows recovering different models on a\nvariational basis. In the variational framework, incremental minimization\nprinciples for a class of gradient-type dissipative materials are used to\nderive the governing equations. The overall formulation is revisited and\nextended to the case of anisotropic ductile fracture. Three different models\nare subsequently recovered by certain choices of parameters and constitutive\nfunctions, which are later assessed through Bayesian inversion techniques. To\nestimate the posterior density function of ductile material parameters, three\ncommon Markov chain Monte Carlo (MCMC) techniques are employed: (i) the\nMetropolis-Hastings algorithm, (ii) delayed-rejection adaptive Metropolis, and\n(iii) ensemble Kalman filter combined with MCMC. To examine the computational\nefficiency of the MCMC methods, we employ the R-convergence tool.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 15:03:53 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Noii", "Nima", ""], ["Khodadadian", "Amirreza", ""], ["Ulloa", "Jacinto", ""], ["Aldakheel", "Fadi", ""], ["Wick", "Thomas", ""], ["Francois", "Stijn", ""], ["Wriggers", "Peter", ""]]}, {"id": "2104.11156", "submitter": "Saumik Dana", "authors": "Saumik Dana and Karthik Reddy Lyathakula", "title": "Uncertainty Quantification in Friction Model for Earthquakes using\n  Bayesian inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a framework to inversely quantify uncertainty in the model\nparameters of the friction model using earthquake data via the Bayesian\ninference. The forward model is the popular rate- and state- friction (RSF)\nmodel along with the spring slider damper idealization. The inverse model is to\ndetermine the model parameters using the earthquake data as the response of the\nRSF model. The conventional solution to the inverse problem is the\ndeterministic parameter values, which may not represent the true value, and\nquantifying uncertainty in the model parameters increases confidence in the\nestimation. The uncertainty in the model parameters is estimated by the\nposterior distribution obtained through the Bayesian inversion.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:29:57 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Dana", "Saumik", ""], ["Lyathakula", "Karthik Reddy", ""]]}, {"id": "2104.11184", "submitter": "Egor Dontsov", "authors": "E.V. Dontsov", "title": "A continuous fracture front tracking algorithm with multi layer tip\n  elements (MuLTipEl) for a plane strain hydraulic fracture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CE cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The problem of a plane strain hydraulic fracture propagating in a layered\nformation is considered. Fracture toughness, in-situ stress, and leak-off\ncoefficient are assumed to vary by layer, while the elastic properties are kept\nconstant throughout the domain for simplicity. The purpose of this study is to\ndevelop a numerical algorithm based on a fixed mesh approach, which is capable\nto solve the above problem accurately using elements which can even be larger\nthan the layer size. In order to do this, the concept of fictitious tip stress\nis first introduced for determining the fracture front location. In this\ntechnique, an additional stress is applied to the tip element with the purpose\nto suppress opening and to mimic width corresponding to the actual fracture\nfront location. A theoretical basis for this concept has been established and\nit is further calibrated for piece-wise constant elements. Once the ability to\ntrack the crack front location is developed, the effect of layers is included\nby vary properties as a function of front location. Several numerical examples\nbenchmarking the numerical solution, as well as highlighting capabilities of\nthe algorithm to tackle multiple thin layers accurately are presented.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 17:19:34 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Dontsov", "E. V.", ""]]}, {"id": "2104.11396", "submitter": "Linjian Ma", "authors": "Linjian Ma and Chao Yang", "title": "Low Rank Approximation in Simulations of Quantum Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulating quantum algorithms on classical computers is challenging when the\nsystem size, i.e., the number of qubits used in the quantum algorithm, is\nmoderately large. However, some quantum algorithms and the corresponding\nquantum circuits can be simulated efficiently on a classical computer if the\ninput quantum state is a low-rank tensor and all intermediate states of the\nquantum algorithm can be represented or approximated by low-rank tensors. In\nthis paper, we examine the possibility of simulating a few quantum algorithms\nby using low-rank canonical polyadic (CP) decomposition to represent the input\nand all intermediate states of these algorithms. Two rank reduction algorithms\nare used to enable efficient simulation. We show that some of the algorithms\npreserve the low-rank structure of the input state and can thus be efficiently\nsimulated on a classical computer. However, the rank of the intermediate states\nin other quantum algorithms can increase rapidly, making efficient simulation\nmore difficult. To some extent, such difficulty reflects the advantage or\nsuperiority of a quantum computer over a classical computer. As a result,\nunderstanding the low-rank structure of a quantum algorithm allows us to\nidentify algorithms that can benefit significantly from quantum computers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 03:12:52 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Ma", "Linjian", ""], ["Yang", "Chao", ""]]}, {"id": "2104.12856", "submitter": "Balakrishnan Devarajan", "authors": "Balakrishnan Devarajan", "title": "Free Vibration analysis of Curvilinearly Stiffened Composite plates with\n  an arbitrarily shaped cutout using Isogeometric Analysis", "comments": "Submitted to International Journal of Engineering Science. arXiv\n  admin note: text overlap with arXiv:2104.05132", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focuses on the isogeometric vibration analysis of curvilinearly\nstiffened composite panels. The stiffness matrices and the mass matrices are\nderived using the first-order shear deformation theory (FSDT). The present\nmethod models the plate and the stiffener separately, which allows the\nstiffener element nodes to not coincide with the plate shell-element nodes. The\nstiffness and mass matrices of a stiffener are transformed to those of the\nplate through the displacement compatibility conditions at the plate/stiffener\ninterface by interpolation using NURBS basis functions. Cutouts are modeled\nusing a single NURBS patch generated by creating a ruled surface between two\ncurves. The proposed formulation is first validated by comparing it with\navailable literature. The effects of width-to-thickness ratio, fiber\norientation, ply layups, shape and size of the cutouts and the boundary\nconditions on the response of stiffened composite plates are then analyzed and\nthe numerical results are used to derive useful conclusions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 20:15:39 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Devarajan", "Balakrishnan", ""]]}, {"id": "2104.12860", "submitter": "Balakrishnan Devarajan", "authors": "Balakrishnan Devarajan", "title": "Vibration Analysis of Timoshenko Beams using Isogeometric Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the finite free-form beam element is formulated by the\nisogeometric approach based on the Timoshenko beam theory to investigate the\nfree vibration behavior of the beams. The non-uniform rational B-splines\n(NURBS) functions which define the geometry of the beam are used as the basis\nfunctions for the finite element analysis. In order to enrich the basis\nfunctions and to increase the accuracy of the solution fields, the h-, p-, and\nk-refinement techniques are implemented. The geometry and curvature of the\nbeams are modelled in a unique way based on NURBS. All the effects of the the\nshear deformation, and the rotary inertia are taken into consideration by the\npresent isogeometric model. Results of the beams for non-dimensional\nfrequencies are compared with other available results in order to show the\naccuracy and efficiency of the present isogeometric approach. From numerical\nresults, the present element can produce very accurate values of natural\nfrequencies and the mode shapes due to exact definition of the geometry. With\nhigher order basis functions, there is no shear locking phenomenon in very thin\nbeam situations. Finally, the benchmark tests described in this study are\nprovided as future reference solutions for Timoshenko beam vibration problem.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 20:27:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Devarajan", "Balakrishnan", ""]]}, {"id": "2104.13070", "submitter": "Sijing Li", "authors": "Sijing Li, Cheng Zhang, Zhiwen Zhang, Hongkai Zhao", "title": "A data-driven and model-based accelerated Hamiltonian Monte Carlo method\n  for Bayesian elliptic inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a Bayesian inverse problem modeled by elliptic\npartial differential equations (PDEs). Specifically, we propose a data-driven\nand model-based approach to accelerate the Hamiltonian Monte Carlo (HMC) method\nin solving large-scale Bayesian inverse problems. The key idea is to exploit\n(model-based) and construct (data-based) the intrinsic approximate\nlow-dimensional structure of the underlying problem which consists of two\ncomponents - a training component that computes a set of data-driven basis to\nachieve significant dimension reduction in the solution space, and a fast\nsolving component that computes the solution and its derivatives for a newly\nsampled elliptic PDE with the constructed data-driven basis. Hence we achieve\nan effective data and model-based approach for the Bayesian inverse problem and\novercome the typical computational bottleneck of HMC - repeated evaluation of\nthe Hamiltonian involving the solution (and its derivatives) modeled by a\ncomplex system, a multiscale elliptic PDE in our case. We present numerical\nexamples to demonstrate the accuracy and efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 09:37:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Li", "Sijing", ""], ["Zhang", "Cheng", ""], ["Zhang", "Zhiwen", ""], ["Zhao", "Hongkai", ""]]}, {"id": "2104.13199", "submitter": "Nan Li", "authors": "Hamid Reza Attar, Haosu Zhou, Alistair Foster, Nan Li", "title": "Rapid feasibility assessment of components formed through hot stamping:\n  A deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel non-isothermal Hot Forming and cold die Quenching (HFQ) process can\nenable the cost-effective production of complex shaped, high strength aluminium\nalloy panel components. However, the unfamiliarity of designing for the new\nprocess prevents its widescale adoption in industrial settings. Recent research\nefforts focus on the development of advanced material models for finite element\nsimulations, used to assess the feasibility of new component designs for the\nHFQ process. However, FE simulations take place late in design processes,\nrequire forming process expertise and are unsuitable for early-stage design\nexplorations. To address these limitations, this study presents a novel\napplication of a Convolutional Neural Network (CNN) based surrogate as a means\nof rapid manufacturing feasibility assessment for components to be formed using\nthe HFQ process. A diverse dataset containing variations in component geometry,\nblank shapes, and processing parameters, together with corresponding physical\nfields is generated and used to train the model. The results show that near\nindistinguishable full field predictions are obtained in real time from the\nmodel when compared with HFQ simulations. This technique provides an invaluable\ntool to aid component design and decision making at the onset of a design\nprocess for complex-shaped components formed under HFQ conditions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 21:40:11 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Attar", "Hamid Reza", ""], ["Zhou", "Haosu", ""], ["Foster", "Alistair", ""], ["Li", "Nan", ""]]}, {"id": "2104.13284", "submitter": "Elisa Fevola", "authors": "Elisa Fevola, Francesco Ballarin, Laura Jim\\'enez-Juan, Stephen\n  Fremes, Stefano Grivet-Talocia, Gianluigi Rozza, Piero Triverio", "title": "An optimal control approach to determine resistance-type boundary\n  conditions from in-vivo data for cardiovascular simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of appropriate boundary conditions is a fundamental step in\ncomputational fluid dynamics (CFD) simulations of the cardiovascular system.\nBoundary conditions, in fact, highly affect the computed pressure and flow\nrates, and consequently haemodynamic indicators such as wall shear stress,\nwhich are of clinical interest. Devising automated procedures for the selection\nof boundary conditions is vital to achieve repeatable simulations. However, the\nmost common techniques do not automatically assimilate patient-specific data,\nrelying instead on expensive and time-consuming manual tuning procedures. In\nthis work, we propose a technique for the automated estimation of outlet\nboundary conditions based on optimal control. The values of resistive boundary\nconditions are set as control variables and optimized to match available\npatient-specific data. Experimental results on four aortic arches demonstrate\nthat the proposed framework can assimilate 4D-Flow MRI data more accurately\nthan two other common techniques based on Murray's law and Ohm's law.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:54:45 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 16:47:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Fevola", "Elisa", ""], ["Ballarin", "Francesco", ""], ["Jim\u00e9nez-Juan", "Laura", ""], ["Fremes", "Stephen", ""], ["Grivet-Talocia", "Stefano", ""], ["Rozza", "Gianluigi", ""], ["Triverio", "Piero", ""]]}, {"id": "2104.13554", "submitter": "Scott Roberts", "authors": "Lincoln N. Collins, Scott A. Roberts", "title": "Mesoscale simulation of woven composite design decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Characterizing the connection between material design decisions/parameters\nand their effective properties allows for accelerated materials development and\noptimization. We present a global sensitivity analysis of woven composite\nthermophysical properties, including density, volume fraction, thermal\nconductivity, specific heat, moduli, permeability, and tortuosity, predicted\nusing mesoscale finite element simulations. The mesoscale simulations use\nmicroscale approximations for the tow and matrix phases. We performed Latin\nhypercube sampling of viable input parameter ranges, and the resulting\neffective property distributions are analyzed using a surrogate model to\ndetermine the correlations between material parameters and responses,\ninteractions between properties, and finally Sobol' indices and sensitivities.\nWe demonstrate that both constituent physical properties and the mesoscale\ngeometry strongly influence the composite material properties.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 03:30:26 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Collins", "Lincoln N.", ""], ["Roberts", "Scott A.", ""]]}, {"id": "2104.13758", "submitter": "Shantanu Shahane", "authors": "Anand Radhakrishnan, Michael Xu, Shantanu Shahane, Surya Pratap Vanka", "title": "A Non-Nested Multilevel Method for Meshless Solution of the Poisson\n  Equation in Heat Transfer and Fluid Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a non-nested multilevel algorithm for solving the Poisson equation\ndiscretized at scattered points using polyharmonic radial basis function\n(PHS-RBF) interpolations. We append polynomials to the radial basis functions\nto achieve exponential convergence of discretization errors. The interpolations\nare performed over local clouds of points and the Poisson equation is\ncollocated at each of the scattered points, resulting in a sparse set of\ndiscrete equations for the unkown variables. To solve this set of equations, we\nhave developed a non-nested multilevel algorithm utilizing multiple\nindependently generated coarse sets of points. The restriction and prolongation\noperators are also constructed with the same RBF interpolations procedure. The\nperformance of the algorithm for Dirichlet and all-Neumann boundary conditions\nis evaluated in three model geometries using a manufactured solution. For\nDirichlet boundary conditions, rapid convergence is observed using SOR point\nsolver as the relaxation scheme. For cases of all-Neumann boundary conditions,\nconvergence is seen to slow down with the degree of the appended polynomial.\nHowever, when the multilevel procedure is combined with a GMRES algorithm, the\nconvergence is seen to significantly improve. The GMRES accelerated multilevel\nalgorithm is included in a fractional step method to solve incompressible\nNavier-Stokes equations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 13:38:29 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Radhakrishnan", "Anand", ""], ["Xu", "Michael", ""], ["Shahane", "Shantanu", ""], ["Vanka", "Surya Pratap", ""]]}, {"id": "2104.14068", "submitter": "Eduardo Corona", "authors": "Ryan Kohl, Eduardo Corona, Vani Cheruvu and Shravan Veerapaneni", "title": "Fast and accurate solvers for simulating Janus particle suspensions in\n  Stokes flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cond-mat.soft cs.CE cs.NA math.NA physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel computational framework for simulating suspensions of\nrigid spherical Janus particles in Stokes flow. We show that long-range Janus\nparticle interactions for a wide array of applications may be resolved using\nfast, spectrally accurate boundary integral methods tailored to polydisperse\nsuspensions of spherical particles. These are incorporated into our rigid body\nStokes platform. Our approach features the use of spherical harmonic expansions\nfor spectrally accurate integral operator evaluation, complementarity-based\ncollision resolution, and optimal O(n) scaling with the number of particles\nwhen accelerated via fast summation techniques. We demonstrate the flexibility\nof our platform through three key examples of Janus particle systems prominent\nin biomedical applications: amphiphilic, bipolar electric and phoretic\nparticles. We formulate Janus particle interactions in boundary integral form\nand showcase characteristic self-assembly and complex collective behavior for\neach particle type.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 01:13:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kohl", "Ryan", ""], ["Corona", "Eduardo", ""], ["Cheruvu", "Vani", ""], ["Veerapaneni", "Shravan", ""]]}, {"id": "2104.14119", "submitter": "Jing Lu", "authors": "Jing Lu, Tianli Zhou, Carolina Osorio", "title": "Adaptive Partitioning Strategy for High-Dimensional Discrete\n  Simulation-based Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a technique to enhance the computational\nefficiency of solution algorithms for high-dimensional discrete\nsimulation-based optimization problems. The technique is based on innovative\nadaptive partitioning strategies that partition the feasible region using\nsolutions that has already been simulated as well as prior knowledge of the\nproblem of interesting. We integrate the proposed strategies with the Empirical\nStochastic Branch-and-Bound framework proposed by Xu and Nelson (2013). This\ncombination leads to a general-purpose discrete simulation-based optimization\nalgorithm that is both globally convergent and has good small sample\n(finite-time) performance. The proposed general-purpose discrete\nsimulation-based optimization algorithm is validated on a synthetic discrete\nsimulation-based optimization problem and is then used to address a real-world\ncar-sharing fleet assignment problem. Experiment results show that the proposed\nstrategy can increase the algorithm efficiency significantly.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:34:19 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lu", "Jing", ""], ["Zhou", "Tianli", ""], ["Osorio", "Carolina", ""]]}, {"id": "2104.14214", "submitter": "Xining Zhuang", "authors": "Xi-Ning Zhuang, Zhao-Yun Chen, Yu-Chun Wu, Guo-Ping Guo", "title": "Quantum Quantitative Trading: High-Frequency Statistical Arbitrage\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative trading is an integral part of financial markets with high\ncalculation speed requirements, while no quantum algorithms have been\nintroduced into this field yet. We propose quantum algorithms for\nhigh-frequency statistical arbitrage trading in this work by utilizing variable\ntime condition number estimation and quantum linear regression.The algorithm\ncomplexity has been reduced from the classical benchmark O(N^2d) to\nO(sqrt(d)(kappa)^2(log(1/epsilon))^2 )). It shows quantum advantage, where N is\nthe length of trading data, and d is the number of stocks, kappa is the\ncondition number and epsilon is the desired precision. Moreover, two tool\nalgorithms for condition number estimation and cointegration test are\ndeveloped.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 09:09:28 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Zhuang", "Xi-Ning", ""], ["Chen", "Zhao-Yun", ""], ["Wu", "Yu-Chun", ""], ["Guo", "Guo-Ping", ""]]}, {"id": "2104.14424", "submitter": "Ziliang Kang", "authors": "Ziliang Kang, Daniel A. Tortorelli, Kai A. James", "title": "Parallel Projection -- A New Return Mapping Algorithm for Finite Element\n  Modeling of Shape Memory Alloys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel method for finite element analysis of inelastic structures\ncontaining Shape Memory Alloys (SMAs). Phenomenological constitutive models for\nSMAs lead to material nonlinearities, that require substantial computational\neffort to resolve. Finite element analysis methods, which rely on Gauss\nquadrature integration schemes, must solve two sets of coupled differential\nequations: one at the global level and the other at the local, i.e. Gauss point\nlevel. In contrast to the conventional return mapping algorithm, which solves\nthese two sets of coupled differential equations separately using a nested\nNewton procedure, we propose a scheme to solve the local and global\ndifferential equations simultaneously. In the process we also derive\nclosed-form expressions used to update the internal state variables, and unify\nthe popular closest-point and cutting plane methods with our formulas.\nNumerical testing indicates that our method allows for larger thermomechanical\nloading steps and provides increased computational efficiency, over the\nstandard return mapping algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 15:44:09 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Kang", "Ziliang", ""], ["Tortorelli", "Daniel A.", ""], ["James", "Kai A.", ""]]}, {"id": "2104.14433", "submitter": "Amy Marconnet", "authors": "Meghavin Bhatasana, Amy Marconnet", "title": "Machine-Learning Assisted Optimization Strategies for Phase Change\n  Materials Embedded within Electronic Packages", "comments": "13 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the latent heat of phase change materials (PCMs) can reduce the\npeak temperatures and transient variations in temperature in electronic\ndevices. But as the power levels increase, the thermal conduction pathway from\nthe heat source to the heat sink limits the effectiveness of these systems. In\nthis work, we evaluate embedding the PCM within the silicon device layer of an\nelectronic device to minimize the thermal resistance between the source and the\nPCM to minimize this thermal resistance and enhance the thermal performance of\nthe device. The geometry and material properties of the embedded PCM regions\nare optimized using a combination of parametric and machine learning\nalgorithms. For a fixed geometry, considering commercially available materials,\nSolder 174 significantly outperforms other organic and metallic PCMs. Also with\na fixed geometry, the optimal melting points to minimize the peak temperature\nis higher than the optimal melting point to minimize the amplitude of the\ntransient temperature oscillation, and both optima increase with increasing\nheater power. Extending beyond conventional optimization strategies, genetic\nalgorithms and particle swarm optimization with and without neural network\nsurrogate models are used to enable optimization of many geometric and material\nproperties. For the test case evaluated, the optimized geometries and\nproperties are similar between all ML-assisted algorithms, but the\ncomputational time depends on the technique. Ultimately, the optimized design\nwith embedded phase change materials reduces the maximum temperature rise by\n19% and the fluctuations by up to 88% compared to devices without PCM.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 19:20:04 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bhatasana", "Meghavin", ""], ["Marconnet", "Amy", ""]]}, {"id": "2104.14691", "submitter": "Francesco Cosentino", "authors": "Francesco Cosentino and Harald Oberhauser and Alessandro Abate", "title": "Grid-Free Computation of Probabilistic Safety with Malliavin Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We work with continuous-time, continuous-space stochastic dynamical systems\ndescribed by stochastic differential equations (SDE). We present a new approach\nto compute probabilistic safety regions, namely sets of initial conditions of\nthe SDE associated to trajectories that are safe with a probability larger than\na given threshold. We introduce a functional that is minimised at the border of\nthe probabilistic safety region, then solve an optimisation problem using\ntechniques from Malliavin Calculus that computes such region. Unlike existing\nresults in the literature, this new approach allows one to compute\nprobabilistic safety regions without gridding the state space of the SDE.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 22:55:38 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cosentino", "Francesco", ""], ["Oberhauser", "Harald", ""], ["Abate", "Alessandro", ""]]}, {"id": "2104.14704", "submitter": "Michael Ballard PhD", "authors": "M. Keith Ballard, Roman Amici, Varun Shankar, Lauren A. Ferguson,\n  Michael Braginsky, and Robert M. Kirby", "title": "Towards an Extrinsic, CG-XFEM Approach Based on Hierarchical Enrichments\n  for Modeling Progressive Fracture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose an extrinsic, continuous-Galerkin (CG), extended finite element\nmethod (XFEM) that generalizes the work of Hansbo and Hansbo to allow multiple\nHeaviside enrichments within a single element in a hierarchical manner. This\napproach enables complex, evolving XFEM surfaces in 3D that cannot be captured\nusing existing CG-XFEM approaches. We describe an implementation of the method\nfor 3D static elasticity with linearized strain for modeling open cracks as a\nsalient step towards modeling progressive fracture. The implementation includes\na description of the finite element model, hybrid implicit/explicit\nrepresentation of enrichments, numerical integration method, and novel\ndegree-of-freedom (DoF) enumeration algorithm. This algorithm supports an\narbitrary number of enrichments within an element, while simultaneously\nmaintaining a CG solution across elements. Additionally, our approach easily\nallows an implementation suitable for distributed computing systems. Enabled by\nthe DoF enumeration algorithm, the proposed method lays the groundwork for a\ncomputational tool that efficiently models progressive fracture. To facilitate\na discussion of the complex enrichment hierarchies, we develop enrichment\ndiagrams to succinctly describe and visualize the relationships between the\nenrichments (and the fields they create) within an element. This also provides\na unified language for discussing extrinsic XFEM methods in the literature. We\ncompare several methods, relying on the enrichment diagrams to highlight their\nnuanced differences.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 00:38:09 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ballard", "M. Keith", ""], ["Amici", "Roman", ""], ["Shankar", "Varun", ""], ["Ferguson", "Lauren A.", ""], ["Braginsky", "Michael", ""], ["Kirby", "Robert M.", ""]]}, {"id": "2104.14817", "submitter": "Shunchuan Yang", "authors": "Zekun Zhu, Aipeng Sun, Xiaochao Zhou, Shunchuan Yang, Zhizhang (David)\n  Chen", "title": "Generalized SS-SIE for Electromagnetic Analysis of Arbitrarily Connected\n  Penetrable and PEC Objects with Non-Conformal Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a simple and efficient modular single-source surface integral\nequation (SS-SIE) formulation for electromagnetic analysis of arbitrarily\nconnected penetrable and perfectly electrical conductor (PEC) objects. In this\nformulation, a modular equivalent model for each penetrable object consisting\nof the composite structure is first independently constructed through replacing\nit by the background medium, no matter whether it is surrounded by the\nbackground medium, other media, or partially connected objects, and enforcing\nan equivalent electric current density on the boundary to remain fields in the\nexterior region unchanged. Then, by combining all the modular models and any\npossible PEC objects together, an equivalent model for the composite structure\ncan be derived. The troublesome junction handling techniques are not needed and\nnon-conformal meshes are intrinsically supported. The proposed SS-SIE\nformulation is simple to implement, efficient, and flexible, which shows\nsignificant performance improvement in terms of CPU time compared with the\noriginal SS-SIE formulation and the Poggio-Miller-Chang-Harrington-Wu-Tsai\n(PMCHWT) formulation. Several numerical examples including the coated\ndielectric cuboid, the large lossy objects, the planar layered dielectric\nstructure, and the partially connected dielectric and PEC structure are carried\nout to validate its accuracy, efficiency and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:03:50 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zhu", "Zekun", "", "David"], ["Sun", "Aipeng", "", "David"], ["Zhou", "Xiaochao", "", "David"], ["Yang", "Shunchuan", "", "David"], ["Zhizhang", "", "", "David"], ["Chen", "", ""]]}]