[{"id": "1110.0061", "submitter": "Sergey Pankov", "authors": "Sergey Pankov", "title": "Learning image transformations without training examples", "comments": "15 pages, 1 figure, ISVC11", "journal-ref": "Proc. 7th International Symposium on Visual Computing, part II, pp\n  168-179, 2011", "doi": "10.1007/978-3-642-24031-7_17", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of image transformations is essential for efficient modeling and\nlearning of visual data. But the class of relevant transformations is large:\naffine transformations, projective transformations, elastic deformations, ...\nthe list goes on. Therefore, learning these transformations, rather than hand\ncoding them, is of great conceptual interest. To the best of our knowledge, all\nthe related work so far has been concerned with either supervised or weakly\nsupervised learning (from correlated sequences, video streams, or\nimage-transform pairs). In this paper, on the contrary, we present a simple\nmethod for learning affine and elastic transformations when no examples of\nthese transformations are explicitly given, and no prior knowledge of space\n(such as ordering of pixels) is included either. The system has only access to\na moderately large database of natural images arranged in no particular order.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2011 01:07:03 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Pankov", "Sergey", ""]]}, {"id": "1110.0107", "submitter": "Roland Memisevic", "authors": "Roland Memisevic", "title": "Learning to relate images: Mapping units, complex cells and simultaneous\n  eigenspaces", "comments": "Revised argument in sections 4 and 3.3. Added illustration of\n  subspaces (Figure 13). Added inference Equation (Eq. 17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental operation in many vision tasks, including motion understanding,\nstereopsis, visual odometry, or invariant recognition, is establishing\ncorrespondences between images or between images and data from other\nmodalities. We present an analysis of the role that multiplicative interactions\nplay in learning such correspondences, and we show how learning and inferring\nrelationships between images can be viewed as detecting rotations in the\neigenspaces shared among a set of orthogonal matrices. We review a variety of\nrecent multiplicative sparse coding methods in light of this observation. We\nalso review how the squaring operation performed by energy models and by models\nof complex cells can be thought of as a way to implement multiplicative\ninteractions. This suggests that the main utility of including complex cells in\ncomputational models of vision may be that they can encode relations not\ninvariances.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2011 15:14:16 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2012 21:55:29 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Memisevic", "Roland", ""]]}, {"id": "1110.0169", "submitter": "Gleb Beliakov", "authors": "Gleb Beliakov, Andrei Kelarev, John Yearwood", "title": "Robust artificial neural networks and outlier detection. Technical\n  report", "comments": null, "journal-ref": null, "doi": "10.1080/02331934.2012.674946", "report-no": null, "categories": "math.OC cs.CV cs.NA cs.NE math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large outliers break down linear and nonlinear regression models. Robust\nregression methods allow one to filter out the outliers when building a model.\nBy replacing the traditional least squares criterion with the least trimmed\nsquares criterion, in which half of data is treated as potential outliers, one\ncan fit accurate regression models to strongly contaminated data.\nHigh-breakdown methods have become very well established in linear regression,\nbut have started being applied for non-linear regression only recently. In this\nwork, we examine the problem of fitting artificial neural networks to\ncontaminated data using least trimmed squares criterion. We introduce a\npenalized least trimmed squares criterion which prevents unnecessary removal of\nvalid data. Training of ANNs leads to a challenging non-smooth global\noptimization problem. We compare the efficiency of several derivative-free\noptimization methods in solving it, and show that our approach identifies the\noutliers correctly when ANNs are used for nonlinear regression.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2011 10:56:07 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Beliakov", "Gleb", ""], ["Kelarev", "Andrei", ""], ["Yearwood", "John", ""]]}, {"id": "1110.0214", "submitter": "Ridwan Al Iqbal", "authors": "Ridwan Al Iqbal", "title": "Eclectic Extraction of Propositional Rules from Neural Networks", "comments": "ICCIT 2011, Dhaka, Bangladesh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Network is among the most popular algorithm for supervised\nlearning. However, Neural Networks have a well-known drawback of being a \"Black\nBox\" learner that is not comprehensible to the Users. This lack of transparency\nmakes it unsuitable for many high risk tasks such as medical diagnosis that\nrequires a rational justification for making a decision. Rule Extraction\nmethods attempt to curb this limitation by extracting comprehensible rules from\na trained Network. Many such extraction algorithms have been developed over the\nyears with their respective strengths and weaknesses. They have been broadly\ncategorized into three types based on their approach to use internal model of\nthe Network. Eclectic Methods are hybrid algorithms that combine the other\napproaches to attain more performance. In this paper, we present an Eclectic\nmethod called HERETIC. Our algorithm uses Inductive Decision Tree learning\ncombined with information of the neural network structure for extracting\nlogical rules. Experiments and theoretical analysis show HERETIC to be better\nin terms of speed and performance.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2011 18:59:42 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Iqbal", "Ridwan Al", ""]]}, {"id": "1110.0264", "submitter": "Hanxi Li", "authors": "Hanxi Li, Chunhua Shen and Yongsheng Gao", "title": "Face Recognition using Optimal Representation Ensemble", "comments": "36-page draft for IEEE Transactions on Image Processing (TIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the face recognizers based on linear representations have been\nshown to deliver state-of-the-art performance. In real-world applications,\nhowever, face images usually suffer from expressions, disguises and random\nocclusions. The problematic facial parts undermine the validity of the\nlinear-subspace assumption and thus the recognition performance deteriorates\nsignificantly. In this work, we address the problem in a\nlearning-inference-mixed fashion. By observing that the linear-subspace\nassumption is more reliable on certain face patches rather than on the holistic\nface, some Bayesian Patch Representations (BPRs) are randomly generated and\ninterpreted according to the Bayes' theory. We then train an ensemble model\nover the patch-representations by minimizing the empirical risk w.r.t the\n\"leave-one-out margins\". The obtained model is termed Optimal Representation\nEnsemble (ORE), since it guarantees the optimality from the perspective of\nEmpirical Risk Minimization. To handle the unknown patterns in test faces, a\nrobust version of BPR is proposed by taking the non-face category into\nconsideration. Equipped with the Robust-BPRs, the inference ability of ORE is\nincreased dramatically and several record-breaking accuracies (99.9% on Yale-B\nand 99.5% on AR) and desirable efficiencies (below 20 ms per face in Matlab)\nare achieved. It also overwhelms other modular heuristics on the faces with\nrandom occlusions, extreme expressions and disguises. Furthermore, to\naccommodate immense BPRs sets, a boosting-like algorithm is also derived. The\nboosted model, a.k.a Boosted-ORE, obtains similar performance to its prototype.\nBesides the empirical superiorities, two desirable features of the proposed\nmethods, namely, the training-determined model-selection and the\ndata-weight-free boosting procedure, are also theoretically verified.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 04:44:47 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Li", "Hanxi", ""], ["Shen", "Chunhua", ""], ["Gao", "Yongsheng", ""]]}, {"id": "1110.0585", "submitter": "Jacob Whitehill", "authors": "Jacob Whitehill and Javier Movellan", "title": "Discriminately Decreasing Discriminability with Learned Image Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning and computer vision, input images are often filtered to\nincrease data discriminability. In some situations, however, one may wish to\npurposely decrease discriminability of one classification task (a \"distractor\"\ntask), while simultaneously preserving information relevant to another (the\ntask-of-interest): For example, it may be important to mask the identity of\npersons contained in face images before submitting them to a crowdsourcing site\n(e.g., Mechanical Turk) when labeling them for certain facial attributes.\nAnother example is inter-dataset generalization: when training on a dataset\nwith a particular covariance structure among multiple attributes, it may be\nuseful to suppress one attribute while preserving another so that a trained\nclassifier does not learn spurious correlations between attributes. In this\npaper we present an algorithm that finds optimal filters to give high\ndiscriminability to one task while simultaneously giving low discriminability\nto a distractor task. We present results showing the effectiveness of the\nproposed technique on both simulated data and natural face images.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 06:48:29 GMT"}], "update_date": "2011-10-05", "authors_parsed": [["Whitehill", "Jacob", ""], ["Movellan", "Javier", ""]]}, {"id": "1110.0641", "submitter": "Vladimir Nikulin", "authors": "Vladimir Nikulin", "title": "Identifying relationships between drugs and medical conditions: winning\n  experience in the Challenge 2 of the OMOP 2010 Cup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in using a longitudinal observational databases\nto detect drug safety signal. In this paper we present a novel method, which we\nused online during the OMOP Cup. We consider homogeneous ensembling, which is\nbased on random re-sampling (known, also, as bagging) as a main innovation\ncompared to the previous publications in the related field. This study is based\non a very large simulated database of the 10 million patients records, which\nwas created by the Observational Medical Outcomes Partnership (OMOP). Compared\nto the traditional classification problem, the given data are unlabelled. The\nobjective of this study is to discover hidden associations between drugs and\nconditions. The main idea of the approach, which we used during the OMOP Cup is\nto compare the numbers of observed and expected patterns. This comparison may\nbe organised in several different ways, and the outcomes (base learners) may be\nquite different as well. It is proposed to construct the final decision\nfunction as an ensemble of the base learners. Our method was recognised\nformally by the Organisers of the OMOP Cup as a top performing method for the\nChallenge N2.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 11:17:04 GMT"}], "update_date": "2011-10-05", "authors_parsed": [["Nikulin", "Vladimir", ""]]}, {"id": "1110.0872", "submitter": "Toshiro Kubota", "authors": "Toshiro Kubota", "title": "Non-Gaussian Scale Space Filtering with 2 by 2 Matrix of Linear Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Construction of a scale space with a convolution filter has been studied\nextensively in the past. It has been proven that the only convolution kernel\nthat satisfies the scale space requirements is a Gaussian type. In this paper,\nwe consider a matrix of convolution filters introduced in [1] as a building\nkernel for a scale space, and shows that we can construct a non-Gaussian scale\nspace with a $2\\times 2$ matrix of filters. The paper derives sufficient\nconditions for the matrix of filters for being a scale space kernel, and\npresent some numerical demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 23:58:55 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Kubota", "Toshiro", ""]]}, {"id": "1110.0879", "submitter": "Subhransu Maji", "authors": "Subhransu Maji", "title": "Linearized Additive Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the additive model learning literature and adapt a penalized\nspline formulation due to Eilers and Marx, to train additive classifiers\nefficiently. We also propose two new embeddings based two classes of orthogonal\nbasis with orthogonal derivatives, which can also be used to efficiently learn\nadditive classifiers. This paper follows the popular theme in the current\nliterature where kernel SVMs are learned much more efficiently using a\napproximate embedding and linear machine. In this paper we show that spline\nbasis are especially well suited for learning additive models because of their\nsparsity structure and the ease of computing the embedding which enables one to\ntrain these models in an online manner, without incurring the memory overhead\nof precomputing the storing the embeddings. We show interesting connections\nbetween B-Spline basis and histogram intersection kernel and show that for a\nparticular choice of regularization and degree of the B-Splines, our proposed\nlearning algorithm closely approximates the histogram intersection kernel SVM.\nThis enables one to learn additive models with almost no memory overhead\ncompared to fast a linear solver, such as LIBLINEAR, while being only 5-6X\nslower on average. On two large scale image classification datasets, MNIST and\nDaimler Chrysler pedestrians, the proposed additive classifiers are as accurate\nas the kernel SVM, while being two orders of magnitude faster to train.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 02:11:38 GMT"}], "update_date": "2011-10-06", "authors_parsed": [["Maji", "Subhransu", ""]]}, {"id": "1110.0957", "submitter": "Florent Couzinie-Devy", "authors": "Florent Couzinie-Devy and Julien Mairal and Francis Bach and Jean\n  Ponce", "title": "Dictionary Learning for Deblurring and Digital Zoom", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach to image deblurring and digital zooming\nusing sparse local models of image appearance. These models, where small image\npatches are represented as linear combinations of a few elements drawn from\nsome large set (dictionary) of candidates, have proven well adapted to several\nimage restoration tasks. A key to their success has been to learn dictionaries\nadapted to the reconstruction of small image patches. In contrast, recent works\nhave proposed instead to learn dictionaries which are not only adapted to data\nreconstruction, but also tuned for a specific task. We introduce here such an\napproach to deblurring and digital zoom, using pairs of blurry/sharp (or\nlow-/high-resolution) images for training, as well as an effective stochastic\ngradient algorithm for solving the corresponding optimization task. Although\nthis learning problem is not convex, once the dictionaries have been learned,\nthe sharp/high-resolution image can be recovered via convex optimization at\ntest time. Experiments with synthetic and real data demonstrate the\neffectiveness of the proposed approach, leading to state-of-the-art performance\nfor non-blind image deblurring and digital zoom.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2011 11:49:09 GMT"}], "update_date": "2011-10-07", "authors_parsed": [["Couzinie-Devy", "Florent", ""], ["Mairal", "Julien", ""], ["Bach", "Francis", ""], ["Ponce", "Jean", ""]]}, {"id": "1110.1208", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Divya Jyoti, M. Mani Roja", "title": "Rotation, Scaling and Translation Analysis of Biometric Signature\n  Templates", "comments": "rotation; scaling; translation; RST; image registration; signature\n  verification", "journal-ref": "International Journal of Computer Technology and Applications, Vol\n  2 No 5, 2011, 1419 - 1425", "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.IT cs.MM eess.IV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric authentication systems that make use of signature verification\nmethods often render optimum performance only under limited and restricted\nconditions. Such methods utilize several training samples so as to achieve high\naccuracy. Moreover, several constraints are imposed on the end-user so that the\nsystem may work optimally, and as expected. For example, the user is made to\nsign within a small box, in order to limit their signature to a predefined set\nof dimensions, thus eliminating scaling. Moreover, the angular rotation with\nrespect to the referenced signature that will be inadvertently introduced as\nhuman error, hampers performance of biometric signature verification systems.\nTo eliminate this, traditionally, a user is asked to sign exactly on top of a\nreference line. In this paper, we propose a robust system that optimizes the\nsignature obtained from the user for a large range of variation in\nRotation-Scaling-Translation (RST) and resolves these error parameters in the\nuser signature according to the reference signature stored in the database.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 10:20:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chadha", "Aman", ""], ["Jyoti", "Divya", ""], ["Roja", "M. Mani", ""]]}, {"id": "1110.1358", "submitter": "Richard Peng", "authors": "Hui Han Chin, Aleksander Madry, Gary Miller, Richard Peng", "title": "Runtime Guarantees for Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study theoretical runtime guarantees for a class of optimization problems\nthat occur in a wide variety of inference problems. these problems are\nmotivated by the lasso framework and have applications in machine learning and\ncomputer vision.\n  Our work shows a close connection between these problems and core questions\nin algorithmic graph theory. While this connection demonstrates the\ndifficulties of obtaining runtime guarantees, it also suggests an approach of\nusing techniques originally developed for graph algorithms.\n  We then show that most of these problems can be formulated as a grouped least\nsquares problem, and give efficient algorithms for this formulation. Our\nalgorithms rely on routines for solving quadratic minimization problems, which\nin turn are equivalent to solving linear systems. Finally we present some\nexperimental results on applying our approximation algorithm to image\nprocessing problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 19:24:24 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2012 18:23:58 GMT"}], "update_date": "2012-09-10", "authors_parsed": [["Chin", "Hui Han", ""], ["Madry", "Aleksander", ""], ["Miller", "Gary", ""], ["Peng", "Richard", ""]]}, {"id": "1110.1485", "submitter": "Hafiz Imtiaz", "authors": "Hafiz Imtiaz and Shaikh Anowarul Fattah", "title": "A Face Recognition Scheme using Wavelet Based Dominant Features", "comments": "12 pages, 12 figures, Published in Signal and Image Processing: An\n  International Journal Vol 2 No 3", "journal-ref": "Signal and Image Processing: An International Journal, Vol. 2, No.\n  3, Sept 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a multi-resolution feature extraction algorithm for face\nrecognition is proposed based on two-dimensional discrete wavelet transform\n(2D-DWT), which efficiently exploits the local spatial variations in a face\nimage. For the purpose of feature extraction, instead of considering the entire\nface image, an entropy-based local band selection criterion is developed, which\nselects high-informative horizontal segments from the face image. In order to\ncapture the local spatial variations within these highinformative horizontal\nbands precisely, the horizontal band is segmented into several small spatial\nmodules. Dominant wavelet coefficients corresponding to each local region\nresiding inside those horizontal bands are selected as features. In the\nselection of the dominant coefficients, a threshold criterion is proposed,\nwhich not only drastically reduces the feature dimension but also provides high\nwithin-class compactness and high between-class separability. A principal\ncomponent analysis is performed to further reduce the dimensionality of the\nfeature space. Extensive experimentation is carried out upon standard face\ndatabases and a very high degree of recognition accuracy is achieved by the\nproposed method in comparison to those obtained by some of the existing\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 11:16:17 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Imtiaz", "Hafiz", ""], ["Fattah", "Shaikh Anowarul", ""]]}, {"id": "1110.1509", "submitter": "Abdul Kadir", "authors": "A. Kadir, L.E. Nugroho, A. Susanto, P.I. Santosa", "title": "A Comparative Experiment of Several Shape Methods in Recognizing Plants", "comments": "8 pages; International Journal of Computer Science & Information\n  Technology (IJCSIT), Vol 3, No 3, June 2011", "journal-ref": null, "doi": "10.5121/ijcsit.2011.3318", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape is an important aspects in recognizing plants. Several approaches have\nbeen introduced to identify objects, including plants. Combination of geometric\nfeatures such as aspect ratio, compactness, and dispersion, or moments such as\nmoment invariants were usually used toidentify plants. In this research, a\ncomparative experiment of 4 methods to identify plants using shape features was\naccomplished. Two approaches have never been used in plants identification yet,\nZernike moments and Polar Fourier Transform (PFT), were incorporated. The\nexperimental comparison was done on 52 kinds of plants with various shapes. The\nresult, PFT gave best performance with 64% in accuracy and outperformed the\nother methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 12:43:38 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Kadir", "A.", ""], ["Nugroho", "L. E.", ""], ["Susanto", "A.", ""], ["Santosa", "P. I.", ""]]}, {"id": "1110.1513", "submitter": "Abdul Kadir", "authors": "Abdul Kadir, Lukito Edi Nugroho, Adhi Susanto, Paulus Insap Santosa", "title": "Foliage Plant Retrieval using Polar Fourier Transform, Color Moments and\n  Vein Features", "comments": "13 pages; Signal & Image Processing : An International Journal\n  (SIPIJ) Vol.2, No.3, September 2011", "journal-ref": null, "doi": "10.5121/sipij.2011.2301", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed a method that combines Polar Fourier Transform, color\nmoments, and vein features to retrieve leaf images based on a leaf image. The\nmethod is very useful to help people in recognizing foliage plants. Foliage\nplants are plants that have various colors and unique patterns in the leaf.\nTherefore, the colors and its patterns are information that should be counted\non in the processing of plant identification. To compare the performance of\nretrieving system to other result, the experiments used Flavia dataset, which\nis very popular in recognizing plants. The result shows that the method gave\nbetter performance than PNN, SVM, and Fourier Transform. The method was also\ntested using foliage plants with various colors. The accuracy was 90.80% for 50\nkinds of plants.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 13:00:03 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Kadir", "Abdul", ""], ["Nugroho", "Lukito Edi", ""], ["Susanto", "Adhi", ""], ["Santosa", "Paulus Insap", ""]]}, {"id": "1110.1804", "submitter": "Zhifeng Pang", "authors": "Zhi-Feng Pang, Li-Lian Wang, and Yu-Fei Yang", "title": "The proximal point method for a hybrid model in image restoration", "comments": "Since we find that there are some unsuitale errors, I withdraw this\n  paper from this website!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT math.OC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Models including two $L^1$ -norm terms have been widely used in image\nrestoration. In this paper we first propose the alternating direction method of\nmultipliers (ADMM) to solve this class of models. Based on ADMM, we then\npropose the proximal point method (PPM), which is more efficient than ADMM.\nFollowing the operator theory, we also give the convergence analysis of the\nproposed methods. Furthermore, we use the proposed methods to solve a class of\nhybrid models combining the ROF model with the LLT model. Some numerical\nresults demonstrate the viability and efficiency of the proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2011 07:55:42 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2012 05:18:50 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Pang", "Zhi-Feng", ""], ["Wang", "Li-Lian", ""], ["Yang", "Yu-Fei", ""]]}, {"id": "1110.2053", "submitter": "Stefano Soatto", "authors": "Stefano Soatto", "title": "Steps Towards a Theory of Visual Information: Active Perception,\n  Signal-to-Symbol Conversion and the Interplay Between Sensing and Control", "comments": "151 pages; preliminary version TR UCLA-CSD100028 of September 13,\n  20010", "journal-ref": null, "doi": null, "report-no": "UCLA CSD100028", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript describes the elements of a theory of information tailored to\ncontrol and decision tasks and specifically to visual data. The concept of\nActionable Information is described, that relates to a notion of information\nchampioned by J. Gibson, and a notion of \"complete information\" that relates to\nthe minimal sufficient statistics of a complete representation. It is shown\nthat the \"actionable information gap\" between the two can be reduced by\nexercising control on the sensing process. Thus, senging, control and\ninformation are inextricably tied. This has consequences in the so-called\n\"signal-to-symbol barrier\" problem, as well as in the analysis and design of\nactive sensing systems. It has ramifications in vision-based control,\nnavigation, 3-D reconstruction and rendering, as well as detection,\nlocalization, recognition and categorization of objects and scenes in live\nvideo.\n  This manuscript has been developed from a set of lecture notes for a summer\ncourse at the First International Computer Vision Summer School (ICVSS) in\nScicli, Italy, in July of 2008. They were later expanded and amended for\nsubsequent lectures in the same School in July 2009. Starting on November 1,\n2009, they were further expanded for a special topics course, CS269, taught at\nUCLA in the Spring term of 2010.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 14:28:41 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2012 23:30:37 GMT"}, {"version": "v3", "created": "Fri, 31 Aug 2012 19:05:39 GMT"}, {"version": "v4", "created": "Wed, 27 Dec 2017 07:04:07 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Soatto", "Stefano", ""]]}, {"id": "1110.2210", "submitter": "S. R. Jodogne", "authors": "S. R. Jodogne, J. H. Piater", "title": "Closed-Loop Learning of Visual Control Policies", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 28, pages\n  349-391, 2007", "doi": "10.1613/jair.2110", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a general, flexible framework for learning mappings\nfrom images to actions by interacting with the environment. The basic idea is\nto introduce a feature-based image classifier in front of a reinforcement\nlearning algorithm. The classifier partitions the visual space according to the\npresence or absence of few highly informative local descriptors that are\nincrementally selected in a sequence of attempts to remove perceptual aliasing.\nWe also address the problem of fighting overfitting in such a greedy algorithm.\nFinally, we show how high-level visual features can be generated when the power\nof local descriptors is insufficient for completely disambiguating the aliased\nstates. This is done by building a hierarchy of composite features that consist\nof recursive spatial combinations of visual features. We demonstrate the\nefficacy of our algorithms by solving three visual navigation tasks and a\nvisual version of the classical Car on the Hill control problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 21:56:36 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Jodogne", "S. R.", ""], ["Piater", "J. H.", ""]]}, {"id": "1110.2306", "submitter": "Marco Cuturi", "authors": "Marco Cuturi, David Avis", "title": "Ground Metric Learning", "comments": "32 pages, 4 figures", "journal-ref": "Journal of Machine Learning Research, 15, 533-564. 2014", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation distances have been used for more than a decade now in machine\nlearning to compare histograms of features. They have one parameter: the ground\nmetric, which can be any metric between the features themselves. As is the case\nfor all parameterized distances, transportation distances can only prove useful\nin practice when this parameter is carefully chosen. To date, the only option\navailable to practitioners to set the ground metric parameter was to rely on a\npriori knowledge of the features, which limited considerably the scope of\napplication of transportation distances. We propose to lift this limitation and\nconsider instead algorithms that can learn the ground metric using only a\ntraining set of labeled histograms. We call this approach ground metric\nlearning. We formulate the problem of learning the ground metric as the\nminimization of the difference of two polyhedral convex functions over a convex\nset of distance matrices. We follow the presentation of our algorithms with\npromising experimental results on binary classification tasks using GIST\ndescriptors of images taken in the Caltech-256 set.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2011 09:04:56 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Cuturi", "Marco", ""], ["Avis", "David", ""]]}, {"id": "1110.2855", "submitter": "Louise Benoit", "authors": "Louise Beno\\^it (INRIA Paris - Rocquencourt, LIENS, INRIA Paris -\n  Rocquencourt), Julien Mairal (INRIA Paris - Rocquencourt, LIENS), Francis\n  Bach (INRIA Paris - Rocquencourt), Jean Ponce (INRIA Paris - Rocquencourt)", "title": "Sparse Image Representation with Epitomes", "comments": "Computer Vision and Pattern Recognition, Colorado Springs : United\n  States (2011)", "journal-ref": "Computer Vision and Pattern Recognition, Colorado Springs :\n  \\'Etats-Unis (2011)", "doi": "10.1109/CVPR.2011.5995636", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding, which is the decomposition of a vector using only a few basis\nelements, is widely used in machine learning and image processing. The basis\nset, also called dictionary, is learned to adapt to specific data. This\napproach has proven to be very effective in many image processing tasks.\nTraditionally, the dictionary is an unstructured \"flat\" set of atoms. In this\npaper, we study structured dictionaries which are obtained from an epitome, or\na set of epitomes. The epitome is itself a small image, and the atoms are all\nthe patches of a chosen size inside this image. This considerably reduces the\nnumber of parameters to learn and provides sparse image decompositions with\nshiftinvariance properties. We propose a new formulation and an algorithm for\nlearning the structured dictionaries associated with epitomes, and illustrate\ntheir use in image denoising tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 07:35:05 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Beno\u00eet", "Louise", "", "INRIA Paris - Rocquencourt, LIENS, INRIA Paris -\n  Rocquencourt"], ["Mairal", "Julien", "", "INRIA Paris - Rocquencourt, LIENS"], ["Bach", "Francis", "", "INRIA Paris - Rocquencourt"], ["Ponce", "Jean", "", "INRIA Paris - Rocquencourt"]]}, {"id": "1110.3109", "submitter": "Zhiwu Lu", "authors": "Zhiwu Lu and Yuxin Peng", "title": "Robust Image Analysis by L1-Norm Semi-supervised Learning", "comments": "This is an extension of our long paper in ACM MM 2012", "journal-ref": "IEEE Trans. Image Processing 24(1): 176-188 (2015)", "doi": "10.1109/TIP.2014.2375641", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel L1-norm semi-supervised learning algorithm for\nrobust image analysis by giving new L1-norm formulation of Laplacian\nregularization which is the key step of graph-based semi-supervised learning.\nSince our L1-norm Laplacian regularization is defined directly over the\neigenvectors of the normalized Laplacian matrix, we successfully formulate\nsemi-supervised learning as an L1-norm linear reconstruction problem which can\nbe effectively solved with sparse coding. By working with only a small subset\nof eigenvectors, we further develop a fast sparse coding algorithm for our\nL1-norm semi-supervised learning. Due to the sparsity induced by sparse coding,\nthe proposed algorithm can deal with the noise in the data to some extent and\nthus has important applications to robust image analysis, such as noise-robust\nimage classification and noise reduction for visual and textual bag-of-words\n(BOW) models. In particular, this paper is the first attempt to obtain robust\nimage representation by sparse co-refinement of visual and textual BOW models.\nThe experimental results have shown the promising performance of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 02:05:14 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 23:22:48 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Lu", "Zhiwu", ""], ["Peng", "Yuxin", ""]]}, {"id": "1110.3194", "submitter": "Qiyu Jin", "authors": "Qiyu Jin, Ion Grama and Quansheng Liu", "title": "Controlled Total Variation regularization for inverse problems", "comments": "10 pages, 10 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a new algorithm for solving inverse problems, based on\nthe minimization of the $L^2$ norm and on the control of the Total Variation.\nIt consists in relaxing the role of the Total Variation in the classical Total\nVariation minimization approach, which permits us to get better approximation\nto the inverse problems. The numerical results on the deconvolution problem\nshow that our method outperforms some previous ones.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2011 13:02:36 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Jin", "Qiyu", ""], ["Grama", "Ion", ""], ["Liu", "Quansheng", ""]]}, {"id": "1110.3649", "submitter": "Yaron Lipman", "authors": "D. Boyer and Y. Lipman and E. St. Clair and J. Puente and T.\n  Funkhouser and B. Patel and J. Jernvall and I. Daubechies", "title": "Algorithms to automatically quantify the geometric similarity of\n  anatomical surfaces", "comments": "Changes with respect to v1, v2: an Erratum was added, correcting the\n  references for one of the three datasets. Note that the datasets and code for\n  this paper can be obtained from the Data Conservancy (see Download column on\n  v1, v2)", "journal-ref": "PNAS 2011 108 (45) 18221-18226", "doi": "10.1073/pnas.1112822108", "report-no": null, "categories": "math.NA cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe new approaches for distances between pairs of 2-dimensional\nsurfaces (embedded in 3-dimensional space) that use local structures and global\ninformation contained in inter-structure geometric relationships. We present\nalgorithms to automatically determine these distances as well as geometric\ncorrespondences. This is motivated by the aspiration of students of natural\nscience to understand the continuity of form that unites the diversity of life.\nAt present, scientists using physical traits to study evolutionary\nrelationships among living and extinct animals analyze data extracted from\ncarefully defined anatomical correspondence points (landmarks). Identifying and\nrecording these landmarks is time consuming and can be done accurately only by\ntrained morphologists. This renders these studies inaccessible to\nnon-morphologists, and causes phenomics to lag behind genomics in elucidating\nevolutionary patterns. Unlike other algorithms presented for morphological\ncorrespondences our approach does not require any preliminary marking of\nspecial features or landmarks by the user. It also differs from other seminal\nwork in computational geometry in that our algorithms are polynomial in nature\nand thus faster, making pairwise comparisons feasible for significantly larger\nnumbers of digitized surfaces. We illustrate our approach using three datasets\nrepresenting teeth and different bones of primates and humans, and show that it\nleads to highly accurate results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 12:23:30 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 09:16:12 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2012 13:36:16 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Boyer", "D.", ""], ["Lipman", "Y.", ""], ["Clair", "E. St.", ""], ["Puente", "J.", ""], ["Funkhouser", "T.", ""], ["Patel", "B.", ""], ["Jernvall", "J.", ""], ["Daubechies", "I.", ""]]}, {"id": "1110.3741", "submitter": "Kevin Xu", "authors": "Ko-Jen Hsiao, Kevin S. Xu, Jeff Calder, and Alfred O. Hero III", "title": "Multi-criteria Anomaly Detection using Pareto Depth Analysis", "comments": "Removed an unnecessary line from Algorithm 1", "journal-ref": "Advances in Neural Information Processing Systems 25 (2012)\n  854-862", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying patterns in a data set that exhibit\nanomalous behavior, often referred to as anomaly detection. In most anomaly\ndetection algorithms, the dissimilarity between data samples is calculated by a\nsingle criterion, such as Euclidean distance. However, in many cases there may\nnot exist a single dissimilarity measure that captures all possible anomalous\npatterns. In such a case, multiple criteria can be defined, and one can test\nfor anomalies by scalarizing the multiple criteria using a linear combination\nof them. If the importance of the different criteria are not known in advance,\nthe algorithm may need to be executed multiple times with different choices of\nweights in the linear combination. In this paper, we introduce a novel\nnon-parametric multi-criteria anomaly detection method using Pareto depth\nanalysis (PDA). PDA uses the concept of Pareto optimality to detect anomalies\nunder multiple criteria without having to run an algorithm multiple times with\ndifferent choices of weights. The proposed PDA approach scales linearly in the\nnumber of criteria and is provably better than linear combinations of the\ncriteria.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 17:48:22 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 22:12:52 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2013 17:18:42 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Hsiao", "Ko-Jen", ""], ["Xu", "Kevin S.", ""], ["Calder", "Jeff", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1110.3767", "submitter": "Herve Jegou", "authors": "Herv\\'e J\\'egou (INRIA - IRISA), Teddy Furon (INRIA - IRISA),\n  Jean-Jacques Fuchs (INRIA - IRISA)", "title": "Anti-sparse coding for approximate nearest neighbor search", "comments": "submitted to ICASSP'2012; RR-7771 (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DB cs.IR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a binarization scheme for vectors of high dimension based\non the recent concept of anti-sparse coding, and shows its excellent\nperformance for approximate nearest neighbor search. Unlike other binarization\nschemes, this framework allows, up to a scaling factor, the explicit\nreconstruction from the binary representation of the original vector. The paper\nalso shows that random projections which are used in Locality Sensitive Hashing\nalgorithms, are significantly outperformed by regular frames for both synthetic\nand real data if the number of bits exceeds the vector dimensionality, i.e.,\nwhen high precision is required.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 19:16:16 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2011 06:13:45 GMT"}], "update_date": "2011-10-27", "authors_parsed": [["J\u00e9gou", "Herv\u00e9", "", "INRIA - IRISA"], ["Furon", "Teddy", "", "INRIA - IRISA"], ["Fuchs", "Jean-Jacques", "", "INRIA - IRISA"]]}, {"id": "1110.3907", "submitter": "Peng Sun", "authors": "Peng Sun, Mark D. Reid, Jie Zhou", "title": "AOSO-LogitBoost: Adaptive One-Vs-One LogitBoost for Multi-Class Problem", "comments": "8-pages camera ready version for ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an improvement to model learning when using multi-class\nLogitBoost for classification. Motivated by the statistical view, LogitBoost\ncan be seen as additive tree regression. Two important factors in this setting\nare: 1) coupled classifier output due to a sum-to-zero constraint, and 2) the\ndense Hessian matrices that arise when computing tree node split gain and node\nvalue fittings. In general, this setting is too complicated for a tractable\nmodel learning algorithm. However, too aggressive simplification of the setting\nmay lead to degraded performance. For example, the original LogitBoost is\noutperformed by ABC-LogitBoost due to the latter's more careful treatment of\nthe above two factors.\n  In this paper we propose techniques to address the two main difficulties of\nthe LogitBoost setting: 1) we adopt a vector tree (i.e. each node value is\nvector) that enforces a sum-to-zero constraint, and 2) we use an adaptive block\ncoordinate descent that exploits the dense Hessian when computing tree split\ngain and node values. Higher classification accuracy and faster convergence\nrates are observed for a range of public data sets when compared to both the\noriginal and the ABC-LogitBoost implementations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2011 08:26:59 GMT"}, {"version": "v2", "created": "Thu, 17 May 2012 19:43:06 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2012 07:14:17 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Sun", "Peng", ""], ["Reid", "Mark D.", ""], ["Zhou", "Jie", ""]]}, {"id": "1110.4970", "submitter": "Firouz Wassai", "authors": "Firouz Abdullah Al-Wassai, N.V. Kalyankar and Ali A. Al-Zaky", "title": "Studying Satellite Image Quality Based on the Fusion Techniques", "comments": null, "journal-ref": "International Journal of Advanced Research in Computer\n  Science,Volume 2, No. 5, Sept-Oct 2011,www.ijarcs.info", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. However,\nthe jury is still out on the benefits of a fused image compared to its original\nimages. There is also a lack of measures for assessing the objective quality of\nthe spatial resolution for the fusion methods. Therefore, an objective quality\nof the spatial resolution assessment for fusion images is required. So, this\nstudy attempts to develop a new qualitative assessment to evaluate the spatial\nquality of the pan sharpened images by many spatial quality metrics. Also, this\npaper deals with a comparison of various image fusion techniques based on pixel\nand feature fusion techniques.\n", "versions": [{"version": "v1", "created": "Sat, 22 Oct 2011 13:26:00 GMT"}], "update_date": "2011-10-25", "authors_parsed": [["Al-Wassai", "Firouz Abdullah", ""], ["Kalyankar", "N. V.", ""], ["Al-Zaky", "Ali A.", ""]]}, {"id": "1110.5015", "submitter": "Alex Bronstein", "authors": "Alexander M. Bronstein", "title": "Spectral descriptors for deformable shapes", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.GR math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informative and discriminative feature descriptors play a fundamental role in\ndeformable shape analysis. For example, they have been successfully employed in\ncorrespondence, registration, and retrieval tasks. In the recent years,\nsignificant attention has been devoted to descriptors obtained from the\nspectral decomposition of the Laplace-Beltrami operator associated with the\nshape. Notable examples in this family are the heat kernel signature (HKS) and\nthe wave kernel signature (WKS). Laplacian-based descriptors achieve\nstate-of-the-art performance in numerous shape analysis tasks; they are\ncomputationally efficient, isometry-invariant by construction, and can\ngracefully cope with a variety of transformations. In this paper, we formulate\na generic family of parametric spectral descriptors. We argue that in order to\nbe optimal for a specific task, the descriptor should take into account the\nstatistics of the corpus of shapes to which it is applied (the \"signal\") and\nthose of the class of transformations to which it is made insensitive (the\n\"noise\"). While such statistics are hard to model axiomatically, they can be\nlearned from examples. Following the spirit of the Wiener filter in signal\nprocessing, we show a learning scheme for the construction of optimal spectral\ndescriptors and relate it to Mahalanobis metric learning. The superiority of\nthe proposed approach is demonstrated on the SHREC'10 benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2011 04:26:03 GMT"}], "update_date": "2011-10-25", "authors_parsed": [["Bronstein", "Alexander M.", ""]]}, {"id": "1110.5097", "submitter": "Albert Fannjiang", "authors": "Albert Fannjiang", "title": "Absolute Uniqueness of Phase Retrieval with Random Illumination", "comments": "21 pages, 7 figures", "journal-ref": "Inverse Problems 28 (2012) 075008", "doi": "10.1088/0266-5611/28/7/075008", "report-no": null, "categories": "physics.optics cs.CV math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random illumination is proposed to enforce absolute uniqueness and resolve\nall types of ambiguity, trivial or nontrivial, from phase retrieval. Almost\nsure irreducibility is proved for any complex-valued object of a full rank\nsupport. While the new irreducibility result can be viewed as a probabilistic\nversion of the classical result by Bruck, Sodin and Hayes, it provides a novel\nperspective and an effective method for phase retrieval.\n  In particular, almost sure uniqueness, up to a global phase, is proved for\ncomplex-valued objects under general two-point conditions. Under a tight sector\nconstraint absolute uniqueness is proved to hold with probability exponentially\nclose to unity as the object sparsity increases. Under a magnitude constraint\nwith random amplitude illumination, uniqueness modulo global phase is proved to\nhold with probability exponentially close to unity as object sparsity\nincreases. For general complex-valued objects without any constraint, almost\nsure uniqueness up to global phase is established with two sets of Fourier\nmagnitude data under two independent illuminations. Numerical experiments\nsuggest that random illumination essentially alleviates most, if not all,\nnumerical problems commonly associated with the standard phasing algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2011 23:40:08 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2011 04:17:12 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2011 22:27:45 GMT"}, {"version": "v4", "created": "Mon, 2 Jan 2012 04:22:24 GMT"}, {"version": "v5", "created": "Thu, 19 Apr 2012 02:21:58 GMT"}, {"version": "v6", "created": "Thu, 31 May 2012 23:28:42 GMT"}, {"version": "v7", "created": "Fri, 20 Jul 2012 22:36:28 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Fannjiang", "Albert", ""]]}, {"id": "1110.5102", "submitter": "Congcong Li", "authors": "Congcong Li, Adarsh Kowdle, Ashutosh Saxena, Tsuhan Chen", "title": "Towards Holistic Scene Understanding: Feedback Enabled Cascaded\n  Classification Models", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene understanding includes many related sub-tasks, such as scene\ncategorization, depth estimation, object detection, etc. Each of these\nsub-tasks is often notoriously hard, and state-of-the-art classifiers already\nexist for many of them. These classifiers operate on the same raw image and\nprovide correlated outputs. It is desirable to have an algorithm that can\ncapture such correlation without requiring any changes to the inner workings of\nany classifier.\n  We propose Feedback Enabled Cascaded Classification Models (FE-CCM), that\njointly optimizes all the sub-tasks, while requiring only a `black-box'\ninterface to the original classifier for each sub-task. We use a two-layer\ncascade of classifiers, which are repeated instantiations of the original ones,\nwith the output of the first layer fed into the second layer as input. Our\ntraining method involves a feedback step that allows later classifiers to\nprovide earlier classifiers information about which error modes to focus on. We\nshow that our method significantly improves performance in all the sub-tasks in\nthe domain of scene understanding, where we consider depth estimation, scene\ncategorization, event categorization, object detection, geometric labeling and\nsaliency detection. Our method also improves performance in two robotic\napplications: an object-grasping robot and an object-finding robot.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2011 00:31:00 GMT"}], "update_date": "2011-10-25", "authors_parsed": [["Li", "Congcong", ""], ["Kowdle", "Adarsh", ""], ["Saxena", "Ashutosh", ""], ["Chen", "Tsuhan", ""]]}, {"id": "1110.5404", "submitter": "Thai Le", "authors": "Thai Hoang Le, Len Bui", "title": "Face Recognition Based on SVM and 2DPCA", "comments": "10 pages, 7 figures, 2 tables, International Journal of Signal\n  Processing, Image Processing and Pattern Recognition Vol. 4, No. 3,\n  September, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper will present a novel approach for solving face recognition problem.\nOur method combines 2D Principal Component Analysis (2DPCA), one of the\nprominent methods for extracting feature vectors, and Support Vector Machine\n(SVM), the most powerful discriminative method for classification. Experiments\nbased on proposed method have been conducted on two public data sets FERET and\nAT&T; the results show that the proposed method could improve the\nclassification rates.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2011 03:54:51 GMT"}], "update_date": "2011-10-26", "authors_parsed": [["Le", "Thai Hoang", ""], ["Bui", "Len", ""]]}, {"id": "1110.5450", "submitter": "Andreas Kolb", "authors": "Roberto Cespi, Andreas Kolb, Marvin Lindner", "title": "Hand Tracking based on Hierarchical Clustering of Range Data", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and robust hand segmentation and tracking is an essential basis for\ngesture recognition and thus an important component for contact-less\nhuman-computer interaction (HCI). Hand gesture recognition based on 2D video\ndata has been intensively investigated. However, in practical scenarios purely\nintensity based approaches suffer from uncontrollable environmental conditions\nlike cluttered background colors. In this paper we present a real-time hand\nsegmentation and tracking algorithm using Time-of-Flight (ToF) range cameras\nand intensity data. The intensity and range information is fused into one pixel\nvalue, representing its combined intensity-depth homogeneity. The scene is\nhierarchically clustered using a GPU based parallel merging algorithm, allowing\na robust identification of both hands even for inhomogeneous backgrounds. After\nthe detection, both hands are tracked on the CPU. Our tracking algorithm can\ncope with the situation that one hand is temporarily covered by the other hand.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2011 09:24:25 GMT"}], "update_date": "2011-10-26", "authors_parsed": [["Cespi", "Roberto", ""], ["Kolb", "Andreas", ""], ["Lindner", "Marvin", ""]]}, {"id": "1110.5945", "submitter": "Sudipto Dolui", "authors": "Sudipto Dolui, Alan Kuurstra, Iv\\'an C. Salgado Patarroyo and Oleg V.\n  Michailovich", "title": "A New Similarity Measure for Non-Local Means Filtering of MRI Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acquisition of MRI images offers a trade-off in terms of acquisition\ntime, spatial/temporal resolution and signal-to-noise ratio (SNR). Thus, for\ninstance, increasing the time efficiency of MRI often comes at the expense of\nreduced SNR. This, in turn, necessitates the use of post-processing tools for\nnoise rejection, which makes image de-noising an indispensable component of\ncomputer assistance diagnosis. In the field of MRI, a multitude of image\nde-noising methods have been proposed hitherto. In this paper, the application\nof a particular class of de-noising algorithms - known as non-local mean (NLM)\nfilters - is investigated. Such filters have been recently applied for MRI data\nenhancement and they have been shown to provide more accurate results as\ncompared to many alternative de-noising algorithms. Unfortunately, virtually\nall existing methods for NLM filtering have been derived under the assumption\nof additive white Gaussian (AWG) noise contamination. Since this assumption is\nknown to fail at low values of SNR, an alternative formulation of NLM filtering\nis required, which would take into consideration the correct Rician statistics\nof MRI noise. Accordingly, the contribution of the present paper is two-fold.\nFirst, it points out some principal disadvantages of the earlier methods of NLM\nfiltering of MRI images and suggests means to rectify them. Second, the paper\nintroduces a new similarity measure for NLM filtering of MRI Images, which is\nderived under bona fide statistical assumptions and results in more accurate\nreconstruction of MR scans as compared to alternative NLM approaches. Finally,\nthe utility and viability of the proposed method is demonstrated through a\nseries of numerical experiments using both in silico and in vivo MRI data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2011 23:14:57 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Dolui", "Sudipto", ""], ["Kuurstra", "Alan", ""], ["Patarroyo", "Iv\u00e1n C. Salgado", ""], ["Michailovich", "Oleg V.", ""]]}, {"id": "1110.6483", "submitter": "Nicolaie Popescu-Bodorin", "authors": "N. Popescu-Bodorin, V. E. Balas, I. M. Motoc", "title": "Iris Codes Classification Using Discriminant and Witness Directions", "comments": "6 pages, 5 figures, Proc. 5th IEEE Int. Symp. on Computational\n  Intelligence and Intelligent Informatics (Floriana, Malta, September 15-17),\n  ISBN: 978-1-4577-1861-8 (electronic), 978-1-4577-1860-1 (print)", "journal-ref": "Proc. 5th IEEE Int. Symp. on Computational Intelligence and\n  Intelligent Informatics, pp. 143-148, 2011", "doi": "10.1109/ISCIII.2011.6069760", "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main topic discussed in this paper is how to use intelligence for\nbiometric decision defuzzification. A neural training model is proposed and\ntested here as a possible solution for dealing with natural fuzzification that\nappears between the intra- and inter-class distribution of scores computed\nduring iris recognition tests. It is shown here that the use of proposed neural\nnetwork support leads to an improvement in the artificial perception of the\nseparation between the intra- and inter-class score distributions by moving\nthem away from each other.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2011 23:25:59 GMT"}, {"version": "v2", "created": "Tue, 8 Nov 2011 21:32:22 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Popescu-Bodorin", "N.", ""], ["Balas", "V. E.", ""], ["Motoc", "I. M.", ""]]}]