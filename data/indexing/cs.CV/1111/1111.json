[{"id": "1111.0268", "submitter": "Valerio Capraro", "authors": "Valerio Capraro", "title": "Topology on locally finite metric spaces", "comments": "Second preliminary version - 42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CV cs.DM math.AT math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The necessity of a theory of General Topology and, most of all, of Algebraic\nTopology on locally finite metric spaces comes from many areas of research in\nboth Applied and Pure Mathematics: Molecular Biology, Mathematical Chemistry,\nComputer Science, Topological Graph Theory and Metric Geometry. In this paper\nwe propose the basic notions of such a theory and some applications: we replace\nthe classical notions of continuous function, homeomorphism and homotopic\nequivalence with the notions of NPP-function, NPP-local-isomorphism and\nNPP-homotopy (NPP stands for Nearest Point Preserving); we also introduce the\nnotion of NPP-isomorphism. We construct three invariants under NPP-isomorphisms\nand, in particular, we define the fundamental group of a locally finite metric\nspace. As first applications, we propose the following: motivated by the\nlongstanding question whether there is a purely metric condition which extends\nthe notion of amenability of a group to any metric space, we propose the\nproperty SN (Small Neighborhood); motivated by some applicative problems in\nComputer Science, we prove the analog of the Jordan curve theorem in $\\mathbb\nZ^2$; motivated by a question asked during a lecture at Lausanne, we extend to\nany locally finite metric space a recent inequality of P.N.Jolissaint and\nValette regarding the $\\ell_p$-distortion.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 18:35:21 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2011 14:19:49 GMT"}, {"version": "v3", "created": "Wed, 9 Nov 2011 22:01:42 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Capraro", "Valerio", ""]]}, {"id": "1111.0466", "submitter": "Michael Bronstein", "authors": "Michael M Bronstein", "title": "Kernel diff-hash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a kernel formulation of the recently introduced diff-hash\nalgorithm for the construction of similarity-sensitive hash functions. Our\nkernel diff-hash algorithm that shows superior performance on the problem of\nimage feature descriptor matching.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 11:42:37 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Bronstein", "Michael M", ""]]}, {"id": "1111.0654", "submitter": "Mojtaba Vaezi", "authors": "Mojtaba Vaezi and Fabrice Labeau", "title": "Distributed Lossy Source Coding Using Real-Number Codes", "comments": "5 pages, 5 figures, to appear in VTC_Fall 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how real-number codes can be used to compress correlated sources, and\nestablish a new framework for lossy distributed source coding, in which we\nquantize compressed sources instead of compressing quantized sources. This\nchange in the order of binning and quantization blocks makes it possible to\nmodel correlation between continuous-valued sources more realistically and\ncorrect quantization error when the sources are completely correlated. The\nencoding and decoding procedures are described in detail, for discrete Fourier\ntransform (DFT) codes. Reconstructed signal, in the mean squared error sense,\nis seen to be better than that in the conventional approach.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 20:46:44 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2012 16:54:47 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Vaezi", "Mojtaba", ""], ["Labeau", "Fabrice", ""]]}, {"id": "1111.0885", "submitter": "Roozbeh Rajabi", "authors": "Roozbeh Rajabi, Mahdi Khodadadzadeh, Hassan Ghassemian", "title": "Graph Regularized Nonnegative Matrix Factorization for Hyperspectral\n  Data Unmixing", "comments": "4 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral unmixing is an important tool in hyperspectral data analysis for\nestimating endmembers and abundance fractions in a mixed pixel. This paper\nexamines the applicability of a recently developed algorithm called graph\nregularized nonnegative matrix factorization (GNMF) for this aim. The proposed\napproach exploits the intrinsic geometrical structure of the data besides\nconsidering positivity and full additivity constraints. Simulated data based on\nthe measured spectral signatures, is used for evaluating the proposed\nalgorithm. Results in terms of abundance angle distance (AAD) and spectral\nangle distance (SAD) show that this method can effectively unmix hyperspectral\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 15:46:47 GMT"}], "update_date": "2011-11-04", "authors_parsed": [["Rajabi", "Roozbeh", ""], ["Khodadadzadeh", "Mahdi", ""], ["Ghassemian", "Hassan", ""]]}, {"id": "1111.1014", "submitter": "Arvind Ganesh", "authors": "John Wright, Arvind Ganesh, Allen Yang, Zihan Zhou and Yi Ma", "title": "Sparsity and Robustness in Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report concerns the use of techniques for sparse signal representation\nand sparse error correction for automatic face recognition. Much of the recent\ninterest in these techniques comes from the paper \"Robust Face Recognition via\nSparse Representation\" by Wright et al. (2009), which showed how, under certain\ntechnical conditions, one could cast the face recognition problem as one of\nseeking a sparse representation of a given input face image in terms of a\n\"dictionary\" of training images and images of individual pixels. In this\nreport, we have attempted to clarify some frequently encountered questions\nabout this work and particularly, on the validity of using sparse\nrepresentation techniques for face recognition.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2011 23:50:36 GMT"}], "update_date": "2011-11-07", "authors_parsed": [["Wright", "John", ""], ["Ganesh", "Arvind", ""], ["Yang", "Allen", ""], ["Zhou", "Zihan", ""], ["Ma", "Yi", ""]]}, {"id": "1111.1090", "submitter": "Aman Chadha Mr.", "authors": "Divya Jyoti, Aman Chadha, Pallavi Vaidya, and M. Mani Roja", "title": "A robust, low-cost approach to Face Detection and Face Recognition", "comments": "discrete wavelet transform, face detection, face recognition, person\n  identification", "journal-ref": "CiiT International Journal of Digital Image Processing, Vol. 15,\n  No. 10, October 2011, ISSN 0974 - 9691 (Print) & ISSN 0974 - 9586 (Online)", "doi": null, "report-no": null, "categories": "cs.CV cs.CR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of Biometrics, recognition systems based on iris, fingerprint\nor palm print scans etc. are often considered more dependable due to extremely\nlow variance in the properties of these entities with respect to time. However,\nover the last decade data processing capability of computers has increased\nmanifold, which has made real-time video content analysis possible. This shows\nthat the need of the hour is a robust and highly automated Face Detection and\nRecognition algorithm with credible accuracy rate. The proposed Face Detection\nand Recognition system using Discrete Wavelet Transform (DWT) accepts face\nframes as input from a database containing images from low cost devices such as\nVGA cameras, webcams or even CCTV's, where image quality is inferior. Face\nregion is then detected using properties of L*a*b* color space and only Frontal\nFace is extracted such that all additional background is eliminated. Further,\nthis extracted image is converted to grayscale and its dimensions are resized\nto 128 x 128 pixels. DWT is then applied to entire image to obtain the\ncoefficients. Recognition is carried out by comparison of the DWT coefficients\nbelonging to the test image with those of the registered reference image. On\ncomparison, Euclidean distance classifier is deployed to validate the test\nimage from the database. Accuracy for various levels of DWT Decomposition is\nobtained and hence, compared.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 10:36:43 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Jyoti", "Divya", ""], ["Chadha", "Aman", ""], ["Vaidya", "Pallavi", ""], ["Roja", "M. Mani", ""]]}, {"id": "1111.1093", "submitter": "Sabu Thampi m", "authors": "Sabu M. Thampi, Ann Jisma Jacob", "title": "Securing Biometric Images using Reversible Watermarking", "comments": "8 pages, 7 figures", "journal-ref": "International Journal of Image Processing (IJIP), Volume:\n  5,Issue:4, September/October 2011", "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric security is a fast growing area. Protecting biometric data is very\nimportant since it can be misused by attackers. In order to increase security\nof biometric data there are different methods in which watermarking is widely\naccepted. A more acceptable, new important development in this area is\nreversible watermarking in which the original image can be completely restored\nand the watermark can be retrieved. But reversible watermarking in biometrics\nis an understudied area. Reversible watermarking maintains high quality of\nbiometric data. This paper proposes Rotational Replacement of LSB as a\nreversible watermarking scheme for biometric images. PSNR is the regular method\nused for quality measurement of biometric data. In this paper we also show that\nSSIM Index is a better alternate for effective quality assessment for\nreversible watermarked biometric data by comparing with the well known\nreversible watermarking scheme using Difference Expansion.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 10:50:45 GMT"}], "update_date": "2011-11-07", "authors_parsed": [["Thampi", "Sabu M.", ""], ["Jacob", "Ann Jisma", ""]]}, {"id": "1111.1311", "submitter": "Richard Herrmann", "authors": "Richard Herrmann", "title": "Covariant fractional extension of the modified Laplace-operator used in\n  3D-shape recovery", "comments": "5 pages, 3 figures, draft for proceedings IFAC FDA12 in Nanjing,\n  China", "journal-ref": "Fract. Calc. Appl. Anal. (2012) Vol. 15 Num. 2, 332--343", "doi": "10.2478/s13540-012-0024-1", "report-no": "gigahedron1111.01", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending the Liouville-Caputo definition of a fractional derivative to a\nnonlocal covariant generalization of arbitrary bound operators acting on\nmultidimensional Riemannian spaces an appropriate approach for the 3D shape\nrecovery of aperture afflicted 2D slide sequences is proposed. We demonstrate,\nthat the step from a local to a nonlocal algorithm yields an order of magnitude\nin accuracy and by using the specific fractional approach an additional factor\n2 in accuracy of the derived results.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2011 14:09:05 GMT"}], "update_date": "2012-03-21", "authors_parsed": [["Herrmann", "Richard", ""]]}, {"id": "1111.1373", "submitter": "Jason Spencer", "authors": "Jason Spencer", "title": "Speculative Parallel Evaluation Of Classification Trees On GPGPU Compute\n  Engines", "comments": "14 pages, 4 figures, 5 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of optimizing classification tree evaluation for\non-line and real-time applications by using GPUs. Looking at trees with\ncontinuous attributes often used in image segmentation, we first put the\nexisting algorithms for serial and data-parallel evaluation on solid footings.\nWe then introduce a speculative parallel algorithm designed for single\ninstruction, multiple data (SIMD) architectures commonly found in GPUs. A\ntheoretical analysis shows how the run times of data and speculative\ndecompositions compare assuming independent processors. To compare the\nalgorithms in the SIMD environment, we implement both on a CUDA 2.0\narchitecture machine and compare timings to a serial CPU implementation.\nVarious optimizations and their effects are discussed, and results are given\nfor all algorithms. Our specific tests show a speculative algorithm improves\nrun time by 25% compared to a data decomposition.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 04:49:31 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Spencer", "Jason", ""]]}, {"id": "1111.1423", "submitter": "Aman Chadha Mr.", "authors": "Aman R. Chadha, Pallavi P. Vaidya, M. Mani Roja", "title": "Face Recognition Using Discrete Cosine Transform for Global and Local\n  Features", "comments": "face recognition; biometrics; person identification; authentication;\n  discrete cosine transform; DCT; global local features; Proceedings of the\n  2011 International Conference on Recent Advancements in Electrical,\n  Electronics and Control Engineering (IConRAEeCE) IEEE Xplore: CFP1153R-ART;\n  ISBN: 978-1-4577-2149-6", "journal-ref": null, "doi": "10.1109/ICONRAEeCE.2011.6129742", "report-no": null, "categories": "cs.CV cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face Recognition using Discrete Cosine Transform (DCT) for Local and Global\nFeatures involves recognizing the corresponding face image from the database.\nThe face image obtained from the user is cropped such that only the frontal\nface image is extracted, eliminating the background. The image is restricted to\na size of 128 x 128 pixels. All images in the database are gray level images.\nDCT is applied to the entire image. This gives DCT coefficients, which are\nglobal features. Local features such as eyes, nose and mouth are also extracted\nand DCT is applied to these features. Depending upon the recognition rate\nobtained for each feature, they are given weightage and then combined. Both\nlocal and global features are used for comparison. By comparing the ranks for\nglobal and local features, the false acceptance rate for DCT can be minimized.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 14:05:53 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Chadha", "Aman R.", ""], ["Vaidya", "Pallavi P.", ""], ["Roja", "M. Mani", ""]]}, {"id": "1111.1461", "submitter": "Michael Bronstein", "authors": "Michael M. Bronstein", "title": "Multimodal diff-hash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require comparing multimodal data with different structure\nand dimensionality that cannot be compared directly. Recently, there has been\nincreasing interest in methods for learning and efficiently representing such\nmultimodal similarity. In this paper, we present a simple algorithm for\nmultimodal similarity-preserving hashing, trying to map multimodal data into\nthe Hamming space while preserving the intra- and inter-modal similarities. We\nshow that our method significantly outperforms the state-of-the-art method in\nthe field.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 00:28:37 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Bronstein", "Michael M.", ""]]}, {"id": "1111.1562", "submitter": "Mahmoud   Yassien Shams el den  Eng", "authors": "M. Y. Shams, M. Z. Rashad, O. Nomir, and R. M. El-Awady", "title": "Iris Recognition Based on LBP and Combined LVQ Classifier", "comments": "12 Pages, 12 Figures", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 3, No 5, Oct 2011", "doi": "10.5121/ijcsit.2011.3506", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iris recognition is considered as one of the best biometric methods used for\nhuman identification and verification, this is because of its unique features\nthat differ from one person to another, and its importance in the security\nfield. This paper proposes an algorithm for iris recognition and classification\nusing a system based on Local Binary Pattern and histogram properties as a\nstatistical approaches for feature extraction, and Combined Learning Vector\nQuantization Classifier as Neural Network approach for classification, in order\nto build a hybrid model depends on both features. The localization and\nsegmentation techniques are presented using both Canny edge detection and Hough\nCircular Transform in order to isolate an iris from the whole eye image and for\nnoise detection .Feature vectors results from LBP is applied to a Combined LVQ\nclassifier with different classes to determine the minimum acceptable\nperformance, and the result is based on majority voting among several LVQ\nclassifier. Different iris datasets CASIA, MMU1, MMU2, and LEI with different\nextensions and size are presented. Since LBP is working on a grayscale level so\ncolored iris images should be transformed into a grayscale level. The proposed\nsystem gives a high recognition rate 99.87 % on different iris datasets\ncompared with other methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 12:35:29 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Shams", "M. Y.", ""], ["Rashad", "M. Z.", ""], ["Nomir", "O.", ""], ["El-Awady", "R. M.", ""]]}, {"id": "1111.1599", "submitter": "Colin Lea S", "authors": "Colin S. Lea and Jason J. Corso", "title": "Efficient Hierarchical Markov Random Fields for Object Detection on a\n  Mobile Robot", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Object detection and classification using video is necessary for intelligent\nplanning and navigation on a mobile robot. However, current methods can be too\nslow or not sufficient for distinguishing multiple classes. Techniques that\nrely on binary (foreground/background) labels incorrectly identify areas with\nmultiple overlapping objects as single segment. We propose two Hierarchical\nMarkov Random Field models in efforts to distinguish connected objects using\ntiered, binary label sets. Near-realtime performance has been achieved using\nefficient optimization methods which runs up to 11 frames per second on a dual\ncore 2.2 Ghz processor. Evaluation of both models is done using footage taken\nfrom a robot obstacle course at the 2010 Intelligent Ground Vehicle\nCompetition.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 14:46:16 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Lea", "Colin S.", ""], ["Corso", "Jason J.", ""]]}, {"id": "1111.1752", "submitter": "Abdelghni Lakehal", "authors": "Abdelghni Lakehal and Omar El Beqqali", "title": "New Method for 3D Shape Retrieval", "comments": "10 pages, 5 figures, publication paper", "journal-ref": null, "doi": "10.5121/ijcsit.2011.3508", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent technological progress in acquisition, modeling and processing of\n3D data leads to the proliferation of a large number of 3D objects databases.\nConsequently, the techniques used for content based 3D retrieval has become\nnecessary. In this paper, we introduce a new method for 3D objects recognition\nand retrieval by using a set of binary images CLI (Characteristic level\nimages). We propose a 3D indexing and search approach based on the similarity\nbetween characteristic level images using Hu moments for it indexing. To\nmeasure the similarity between 3D objects we compute the Hausdorff distance\nbetween a vectors descriptor. The performance of this new approach is evaluated\nat set of 3D object of well known database, is NTU (National Taiwan University)\ndatabase.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 21:24:36 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Lakehal", "Abdelghni", ""], ["Beqqali", "Omar El", ""]]}, {"id": "1111.1947", "submitter": "Yi  Chen", "authors": "Yi Chen, Umamahesh Srinivas, Thong T. Do, Vishal Monga, Trac D. Tran", "title": "Discriminative Local Sparse Representations for Robust Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key recent advance in face recognition models a test face image as a sparse\nlinear combination of a set of training face images. The resulting sparse\nrepresentations have been shown to possess robustness against a variety of\ndistortions like random pixel corruption, occlusion and disguise. This approach\nhowever makes the restrictive (in many scenarios) assumption that test faces\nmust be perfectly aligned (or registered) to the training data prior to\nclassification. In this paper, we propose a simple yet robust local block-based\nsparsity model, using adaptively-constructed dictionaries from local features\nin the training data, to overcome this misalignment problem. Our approach is\ninspired by human perception: we analyze a series of local discriminative\nfeatures and combine them to arrive at the final classification decision. We\npropose a probabilistic graphical model framework to explicitly mine the\nconditional dependencies between these distinct sparse local features. In\nparticular, we learn discriminative graphs on sparse representations obtained\nfrom distinct local slices of a face. Conditional correlations between these\nsparse features are first discovered (in the training phase), and subsequently\nexploited to bring about significant improvements in recognition rates.\nExperimental results obtained on benchmark face databases demonstrate the\neffectiveness of the proposed algorithms in the presence of multiple\nregistration errors (such as translation, rotation, and scaling) as well as\nunder variations of pose and illumination.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 16:04:58 GMT"}], "update_date": "2011-11-09", "authors_parsed": [["Chen", "Yi", ""], ["Srinivas", "Umamahesh", ""], ["Do", "Thong T.", ""], ["Monga", "Vishal", ""], ["Tran", "Trac D.", ""]]}, {"id": "1111.2391", "submitter": "Vijaya Lakshmi", "authors": "B. Vijayalakshmi, V. Subbiah Bharathi", "title": "A Novel Approach to Texture classification using statistical feature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texture is an important spatial feature which plays a vital role in content\nbased image retrieval. The enormous growth of the internet and the wide use of\ndigital data have increased the need for both efficient image database creation\nand retrieval procedure. This paper describes a new approach for texture\nclassification by combining statistical texture features of Local Binary\nPattern and Texture spectrum. Since most significant information of a texture\noften appears in the high frequency channels, the features are extracted by the\ncomputation of LBP and Texture Spectrum and Legendre Moments. Euclidean\ndistance is used for similarity measurement. The experimental result shows that\n97.77% classification accuracy is obtained by the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2011 04:28:08 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Vijayalakshmi", "B.", ""], ["Bharathi", "V. Subbiah", ""]]}, {"id": "1111.3000", "submitter": "Martin H\\\"unniger Dr.", "authors": "Martin H\\\"unniger", "title": "Digital Manifolds and the Theorem of Jordan-Brouwer", "comments": "34 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an answer to the question given by T.Y.Kong in his article \"Can 3-D\nDigital Topology be Based on Axiomatically Defined Digital Spaces?\" In this\narticle he asks the question, if so called \"good pairs\" of neighborhood\nrelations can be found on the set Z^n such that the existence of digital\nmanifolds of dimension n-1, that separate their complement in exactly two\nconnected sets, is guaranteed. To achieve this, we use a technique developed by\nM. Khachan et.al. A set given in Z^n is translated into a simplicial complex\nthat can be used to study the topological properties of the original discrete\npoint-set. In this way, one is able to define the notion of a (n-1)-dimensional\ndigital manifold and prove the digital analog of the Jordan-Brouwer-Theorem.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2011 11:01:00 GMT"}], "update_date": "2011-11-15", "authors_parsed": [["H\u00fcnniger", "Martin", ""]]}, {"id": "1111.3281", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Mohamed Cheriet and Thomas Milo and Robert\n  Wisnovsky", "title": "A prototype system for handwritten sub-word recognition: Toward\n  Arabic-manuscript transliteration", "comments": "8 pages, 7 figures, 6 tables", "journal-ref": null, "doi": "10.1109/ISSPA.2012.6310473", "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prototype system for the transliteration of diacritics-less Arabic\nmanuscripts at the sub-word or part of Arabic word (PAW) level is developed.\nThe system is able to read sub-words of the input manuscript using a set of\nskeleton-based features. A variation of the system is also developed which\nreads archigraphemic Arabic manuscripts, which are dot-less, into\narchigraphemes transliteration. In order to reduce the complexity of the\noriginal highly multiclass problem of sub-word recognition, it is redefined\ninto a set of binary descriptor classifiers. The outputs of trained binary\nclassifiers are combined to generate the sequence of sub-word letters. SVMs are\nused to learn the binary classifiers. Two specific Arabic databases have been\ndeveloped to train and test the system. One of them is a database of the Naskh\nstyle. The initial results are promising. The systems could be trained on other\nscripts found in Arabic manuscripts.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 17:03:42 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Cheriet", "Mohamed", ""], ["Milo", "Thomas", ""], ["Wisnovsky", "Robert", ""]]}, {"id": "1111.3818", "submitter": "Martin H\\\"unniger Dr.", "authors": "Martin H\\\"unniger", "title": "Good Pairs of Adjacency Relations in Arbitrary Dimensions", "comments": "29 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this text we show, that the notion of a \"good pair\" that was introduced in\nthe paper \"Digital Manifolds and the Theorem of Jordan-Brouwer\" has actually\nknown models. We will show, how to choose cubical adjacencies, the\ngeneralizations of the well known 4- and 8-neighborhood to arbitrary\ndimensions, in order to find good pairs. Furthermore, we give another proof for\nthe well known fact that the Khalimsky-topology implies good pairs. The outcome\nis consistent with the known theory as presented by T.Y. Kong, A. Rosenfeld,\nG.T. Herman and M. Khachan et.al and gives new insights in higher dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2011 14:37:07 GMT"}], "update_date": "2011-11-17", "authors_parsed": [["H\u00fcnniger", "Martin", ""]]}, {"id": "1111.3969", "submitter": "Luis Quesada", "authors": "Luis Quesada, Alejandro J. Le\\'on", "title": "The Object Projection Feature Estimation Problem in Unsupervised\n  Markerless 3D Motion Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D motion tracking is a critical task in many computer vision applications.\nExisting 3D motion tracking techniques require either a great amount of\nknowledge on the target object or specific hardware. These requirements\ndiscourage the wide spread of commercial applications based on 3D motion\ntracking. 3D motion tracking systems that require no knowledge on the target\nobject and run on a single low-budget camera require estimations of the object\nprojection features (namely, area and position). In this paper, we define the\nobject projection feature estimation problem and we present a novel 3D motion\ntracking system that needs no knowledge on the target object and that only\nrequires a single low-budget camera, as installed in most computers and\nsmartphones. Our system estimates, in real time, the three-dimensional position\nof a non-modeled unmarked object that may be non-rigid, non-convex, partially\noccluded, self occluded, or motion blurred, given that it is opaque, evenly\ncolored, and enough contrasting with the background in each frame. Our system\nis also able to determine the most relevant object to track in the screen. Our\n3D motion tracking system does not impose hard constraints, therefore it allows\na market-wide implementation of applications that use 3D motion tracking.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2011 21:26:55 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2011 11:17:20 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Quesada", "Luis", ""], ["Le\u00f3n", "Alejandro J.", ""]]}, {"id": "1111.4052", "submitter": "Thai Le", "authors": "Le Hoang Thai, Nguyen Do Thai Nguyen and Tran Son Hai", "title": "A Facial Expression Classification System Integrating Canny, Principal\n  Component Analysis and Artificial Neural Network", "comments": "6 pages, 10 figures, International Journal of Machine Learning and\n  Computing, Vol. 1, No. 4, October 2011, ISSN (Online): 2010-3700,\n  http://www.ijmlc.org/", "journal-ref": "International Journal of Machine Learning and Computing, Vol. 1,\n  No. 4, 2011, 388-393", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial Expression Classification is an interesting research problem in recent\nyears. There are a lot of methods to solve this problem. In this research, we\npropose a novel approach using Canny, Principal Component Analysis (PCA) and\nArtificial Neural Network. Firstly, in preprocessing phase, we use Canny for\nlocal region detection of facial images. Then each of local region's features\nwill be presented based on Principal Component Analysis (PCA). Finally, using\nArtificial Neural Network (ANN)applies for Facial Expression Classification. We\napply our proposal method (Canny_PCA_ANN) for recognition of six basic facial\nexpressions on JAFFE database consisting 213 images posed by 10 Japanese female\nmodels. The experimental result shows the feasibility of our proposal method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2011 10:43:08 GMT"}], "update_date": "2011-11-18", "authors_parsed": [["Thai", "Le Hoang", ""], ["Nguyen", "Nguyen Do Thai", ""], ["Hai", "Tran Son", ""]]}, {"id": "1111.4290", "submitter": "Rajkumar G. Benne Benne Mr.Benne", "authors": "B.V.Dhandra, R.G.Benne and Mallikarjun Hangarge", "title": "A Single Euler Number Feature for Multi-font Multi-size Kannada Numeral\n  Recognition", "comments": "4 pages, 1 figure, 5 tables, \"Recent Trends in Information\n  Technology(RTIT-2009)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper a novel approach is proposed based on single Euler number\nfeature which is free from thinning and size normalization for multi-font and\nmulti-size Kannada numeral recognition system. A nearest neighbor\nclassification is used for classification of Kannada numerals by considering\nthe Euclidian distance. A total 1500 numeral images with different font sizes\nbetween (10..84) are tested for algorithm efficiency and the overall the\nclassification accuracy is found to be 99.00% .The said method is thinning\nfree, fast, and showed encouraging results on varying font styles and sizes of\nKannada numerals.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 06:34:07 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Dhandra", "B. V.", ""], ["Benne", "R. G.", ""], ["Hangarge", "Mallikarjun", ""]]}, {"id": "1111.4291", "submitter": "Rajkumar G. Benne Benne Mr.Benne", "authors": "B.V.Dhandra, R.G.Benne, Mallikarjun Hangarge", "title": "Multi-font Multi-size Kannada Numeral Recognition Based on Structural\n  Features", "comments": "5 pages, 5 figures, 4 tables,\"Emerging Trends in Information\n  Technology(eIT-2007), India\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper a fast and novel method is proposed for multi-font multi-size\nKannada numeral recognition which is thinning free and without size\nnormalization approach. The different structural feature are used for numeral\nrecognition namely, directional density of pixels in four directions, water\nreservoirs, maximum profile distances, and fill hole density are used for the\nrecognition of Kannada numerals. A Euclidian minimum distance criterion is used\nto find minimum distances and K-nearest neighbor classifier is used to classify\nthe Kannada numerals by varying the size of numeral image from 16 to 50 font\nsizes for the 20 different font styles from NUDI and BARAHA popular word\nprocessing Kannada software. The total 1150 numeral images are tested and the\noverall accuracy of classification is found to be 100%. The average time taken\nby this method is 0.1476 seconds.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 06:59:35 GMT"}], "update_date": "2011-11-21", "authors_parsed": [["Dhandra", "B. V.", ""], ["Benne", "R. G.", ""], ["Hangarge", "Mallikarjun", ""]]}, {"id": "1111.4619", "submitter": "Idan Ram", "authors": "Idan Ram, Michael Elad, and Israel Cohen", "title": "Redundant Wavelets on Graphs and High Dimensional Data Clouds", "comments": "4 pages, 4 figures, 1 table, submitted to IEEE Signal Processing\n  Letters", "journal-ref": null, "doi": "10.1109/LSP.2012.2190983", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new redundant wavelet transform applicable to\nscalar functions defined on high dimensional coordinates, weighted graphs and\nnetworks. The proposed transform utilizes the distances between the given data\npoints. We modify the filter-bank decomposition scheme of the redundant wavelet\ntransform by adding in each decomposition level linear operators that reorder\nthe approximation coefficients. These reordering operators are derived by\norganizing the tree-node features so as to shorten the path that passes through\nthese points. We explore the use of the proposed transform to image denoising,\nand show that it achieves denoising results that are close to those obtained\nwith the BM3D algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 08:58:45 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Ram", "Idan", ""], ["Elad", "Michael", ""], ["Cohen", "Israel", ""]]}, {"id": "1111.4654", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "A self-portrait of young Leonardo", "comments": "Image processing, digital restoration, Leonardo da Vinci", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most famous drawings by Leonardo da Vinci is a self-portrait in\nred chalk, where he looks quite old. In fact, there is a sketch in one of his\nnotebooks, partially covered by written notes, that can be a self-portrait of\nthe artist when he was young. The use of image processing, to remove the\nhandwritten text and improve the image, allows a comparison of the two\nportraits.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 17:41:01 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1111.4676", "submitter": "Andrew Pickin", "authors": "Andrew Pickin", "title": "Facial Asymmetry and Emotional Expression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report is about facial asymmetry, its connection to emotional\nexpression, and methods of measuring facial asymmetry in videos of faces. The\nresearch was motivated by two factors: firstly, there was a real opportunity to\ndevelop a novel measure of asymmetry that required minimal human involvement\nand that improved on earlier measures in the literature; and secondly, the\nstudy of the relationship between facial asymmetry and emotional expression is\nboth interesting in its own right, and important because it can inform\nneuropsychological theory and answer open questions concerning emotional\nprocessing in the brain. The two aims of the research were: first, to develop\nan automatic frame-by-frame measure of facial asymmetry in videos of faces that\nimproved on previous measures; and second, to use the measure to analyse the\nrelationship between facial asymmetry and emotional expression, and connect our\nfindings with previous research of the relationship.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 20:55:07 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Pickin", "Andrew", ""]]}, {"id": "1111.4800", "submitter": "Soumen  Kanrar", "authors": "Aroop Mukherjee, Soumen Kanrar (Vehere Interactive, Calcutta - India)", "title": "Enhancement of Image Resolution by Binarization", "comments": "5 pages, 8 figures", "journal-ref": "International Journal of Computer Applications 10(10):15-19, 2010", "doi": "10.5120/1519-1942", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is one of the principal approaches of image processing.\nThe choice of the most appropriate Binarization algorithm for each case proved\nto be a very interesting procedure itself. In this paper, we have done the\ncomparison study between the various algorithms based on Binarization\nalgorithms and propose a methodologies for the validation of Binarization\nalgorithms. In this work we have developed two novel algorithms to determine\nthreshold values for the pixels value of the gray scale image. The performance\nestimation of the algorithm utilizes test images with, the evaluation metrics\nfor Binarization of textual and synthetic images. We have achieved better\nresolution of the image by using the Binarization method of optimum\nthresholding techniques.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 09:47:17 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Mukherjee", "Aroop", "", "Vehere Interactive, Calcutta - India"], ["Kanrar", "Soumen", "", "Vehere Interactive, Calcutta - India"]]}, {"id": "1111.4840", "submitter": "Eduardo Montijano", "authors": "Eduardo Montijano, Rosario Aragues, Carlos Sagues", "title": "Distributed Multi-view Matching in Networks with Limited Communications", "comments": "This paper has been withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of distributed matching of features in networks with\nvision systems. Every camera in the network has limited communication\ncapabilities and can only exchange local matches with its neighbors. We propose\na distributed algorithm that takes these local matches and computes global\ncorrespondences by a proper propagation in the network. When the algorithm\nfinishes, each camera knows the global correspondences between its features and\nthe features of all the cameras in the network. The presence of spurious\nintroduced by the local matcher may produce inconsistent global\ncorrespondences, which are association paths between features from the same\ncamera. The contributions of this work are the propagation of the local matches\nand the detection and resolution of these inconsistencies by deleting local\nmatches. Our resolution algorithm considers the quality of each local match,\nwhen this information is provided by the local matcher. We formally prove that\nafter executing the algorithm, the network finishes with a global data\nassociation free of inconsistencies. We provide a fully decentralized solution\nto the problem which does not rely on any particular communication topology.\nSimulations and experimental results with real images show the performance of\nthe method considering different features, matching functions and scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 11:55:01 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2011 13:09:57 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2011 10:20:07 GMT"}, {"version": "v4", "created": "Wed, 11 Apr 2012 09:10:29 GMT"}], "update_date": "2012-04-12", "authors_parsed": [["Montijano", "Eduardo", ""], ["Aragues", "Rosario", ""], ["Sagues", "Carlos", ""]]}, {"id": "1111.5108", "submitter": "Aswin Sankaranarayanan", "authors": "Sriram Nagaraj and Aswin C. Sankaranarayanan and Richard G. Baraniuk", "title": "A Theory for Optical flow-based Transport on Image Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image articulation manifold (IAM) is the collection of images formed when\nan object is articulated in front of a camera. IAMs arise in a variety of image\nprocessing and computer vision applications, where they provide a natural\nlow-dimensional embedding of the collection of high-dimensional images. To date\nIAMs have been studied as embedded submanifolds of Euclidean spaces.\nUnfortunately, their promise has not been realized in practice, because real\nworld imagery typically contains sharp edges that render an IAM\nnon-differentiable and hence non-isometric to the low-dimensional parameter\nspace under the Euclidean metric. As a result, the standard tools from\ndifferential geometry, in particular using linear tangent spaces to transport\nalong the IAM, have limited utility. In this paper, we explore a nonlinear\ntransport operator for IAMs based on the optical flow between images and\ndevelop new analytical tools reminiscent of those from differential geometry\nusing the idea of optical flow manifolds (OFMs). We define a new metric for\nIAMs that satisfies certain local isometry conditions, and we show how to use\nthis metric to develop a new tools such as flow fields on IAMs, parallel flow\nfields, parallel transport, as well as a intuitive notion of curvature. The\nspace of optical flow fields along a path of constant curvature has a natural\nmulti-scale structure via a monoid structure on the space of all flow fields\nalong a path. We also develop lower bounds on approximation errors while\napproximating non-parallel flow fields by parallel flow fields.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 05:55:25 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Nagaraj", "Sriram", ""], ["Sankaranarayanan", "Aswin C.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1111.5135", "submitter": "Nithyanandam Subramanian", "authors": "S. Nithyanandam, K. S. Gayathri, P. L. K. Priyadarshini", "title": "A New IRIS Normalization Process For Recognition System With\n  Cryptographic Techniques", "comments": "7 Pages,16 Figures; ISSN (Online): 1694-0814", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 4, No 1, 2011, 342-348", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometric technologies are the foundation of personal identification systems.\nIt provides an identification based on a unique feature possessed by the\nindividual. This paper provides a walkthrough for image acquisition,\nsegmentation, normalization, feature extraction and matching based on the Human\nIris imaging. A Canny Edge Detection scheme and a Circular Hough Transform, is\nused to detect the iris boundaries in the eye's digital image. The extracted\nIRIS region was normalized by using Image Registration technique. A phase\ncorrelation base method is used for this iris image registration purpose. The\nfeatures of the iris region is encoded by convolving the normalized iris region\nwith 2D Gabor filter. Hamming distance measurement is used to compare the\nquantized vectors and authenticate the users. To improve the security,\nReed-Solomon technique is employed directly to encrypt and decrypt the data.\nExperimental results show that our system is quite effective and provides\nencouraging performance. Keywords: Biometric, Iris Recognition, Phase\ncorrelation, cryptography, Reed-Solomon\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 09:38:39 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Nithyanandam", "S.", ""], ["Gayathri", "K. S.", ""], ["Priyadarshini", "P. L. K.", ""]]}, {"id": "1111.5358", "submitter": "Hema Swetha Koppula", "authors": "Abhishek Anand, Hema Swetha Koppula, Thorsten Joachims, Ashutosh\n  Saxena", "title": "Contextually Guided Semantic Labeling and Search for 3D Point Clouds", "comments": "arXiv admin note: substantial text overlap with arXiv:1106.5551", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RGB-D cameras, which give an RGB image to- gether with depths, are becoming\nincreasingly popular for robotic perception. In this paper, we address the task\nof detecting commonly found objects in the 3D point cloud of indoor scenes\nobtained from such cameras. Our method uses a graphical model that captures\nvarious features and contextual relations, including the local visual\nappearance and shape cues, object co-occurence relationships and geometric\nrelationships. With a large number of object classes and relations, the model's\nparsimony becomes important and we address that by using multiple types of edge\npotentials. We train the model using a maximum-margin learning approach. In our\nexperiments over a total of 52 3D scenes of homes and offices (composed from\nabout 550 views), we get a performance of 84.06% and 73.38% in labeling office\nand home scenes respectively for 17 object classes each. We also present a\nmethod for a robot to search for an object using the learned model and the\ncontextual information available from the current labelings of the scene. We\napplied this algorithm successfully on a mobile robot for the task of finding\n12 object classes in 10 different offices and achieved a precision of 97.56%\nwith 78.43% recall.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 22:39:31 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2012 02:50:50 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2012 15:16:01 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Anand", "Abhishek", ""], ["Koppula", "Hema Swetha", ""], ["Joachims", "Thorsten", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1111.5612", "submitter": "Vijayaraghavan Thirumalai", "authors": "Vijayaraghavan Thirumalai, and Pascal Frossard", "title": "Distributed Representation of Geometrically Correlated Images with\n  Compressed Linear Measurements", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2012.2188035", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of distributed coding of images whose\ncorrelation is driven by the motion of objects or positioning of the vision\nsensors. It concentrates on the problem where images are encoded with\ncompressed linear measurements. We propose a geometry-based correlation model\nin order to describe the common information in pairs of images. We assume that\nthe constitutive components of natural images can be captured by visual\nfeatures that undergo local transformations (e.g., translation) in different\nimages. We first identify prominent visual features by computing a sparse\napproximation of a reference image with a dictionary of geometric basis\nfunctions. We then pose a regularized optimization problem to estimate the\ncorresponding features in correlated images given by quantized linear\nmeasurements. The estimated features have to comply with the compressed\ninformation and to represent consistent transformation between images. The\ncorrelation model is given by the relative geometric transformations between\ncorresponding features. We then propose an efficient joint decoding algorithm\nthat estimates the compressed images such that they stay consistent with both\nthe quantized measurements and the correlation model. Experimental results show\nthat the proposed algorithm effectively estimates the correlation between\nimages in multi-view datasets. In addition, the proposed algorithm provides\neffective decoding performance that compares advantageously to independent\ncoding solutions as well as state-of-the-art distributed coding schemes based\non disparity learning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 15:54:23 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Thirumalai", "Vijayaraghavan", ""], ["Frossard", "Pascal", ""]]}, {"id": "1111.5867", "submitter": "Arian Maleki", "authors": "Arian Maleki, Manjari Narayan, Richard G. Baraniuk", "title": "Suboptimality of Nonlocal Means for Images with Sharp Edges", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV cs.IT math.IT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an asymptotic risk analysis of the nonlocal means image denoising\nalgorithm for the Horizon class of images that are piecewise constant with a\nsharp edge discontinuity. We prove that the mean square risk of an optimally\ntuned nonlocal means algorithm decays according to $n^{-1}\\log^{1/2+\\epsilon}\nn$, for an $n$-pixel image with $\\epsilon>0$. This decay rate is an improvement\nover some of the predecessors of this algorithm, including the linear\nconvolution filter, median filter, and the SUSAN filter, each of which provides\na rate of only $n^{-2/3}$. It is also within a logarithmic factor from\noptimally tuned wavelet thresholding. However, it is still substantially lower\nthan the the optimal minimax rate of $n^{-4/3}$.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2011 22:43:12 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Maleki", "Arian", ""], ["Narayan", "Manjari", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1111.6030", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "An image processing of a Raphael's portrait of Leonardo", "comments": "Image processing. Portrait. Self-portrait. Leonardo da Vinci.\n  Raphael. Raffaello Sanzio Images revised using a high-quality image of\n  Raphael's Plato", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In one of his paintings, the School of Athens, Raphael is depicting Leonardo\nda Vinci as the philosopher Plato. Some image processing tools can help us in\ncomparing this portrait with two Leonardo's portraits, considered as\nself-portraits.\n", "versions": [{"version": "v1", "created": "Fri, 25 Nov 2011 15:46:37 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 13:21:25 GMT"}], "update_date": "2011-12-07", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1111.6276", "submitter": "Vasil Kolev", "authors": "Vasil Kolev", "title": "Compressed sensing of astronomical images: orthogonal wavelets domains", "comments": "8 pages, The ACM proceedings of CompSysTech 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV astro-ph.IM physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple approach for orthogonal wavelets in compressed sensing (CS)\napplications is presented. We compare efficient algorithm for different\northogonal wavelet measurement matrices in CS for image processing from scanned\nphotographic plates (SPP). Some important characteristics were obtained for\nastronomical image processing of SPP. The best orthogonal wavelet choice for\nmeasurement matrix construction in CS for image compression of images of SPP is\ngiven. The image quality measure for linear and nonlinear image compression\nmethod is defined.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 17:09:17 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2011 01:51:23 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Kolev", "Vasil", ""]]}, {"id": "1111.6285", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh and Pierre Legendre", "title": "Ward's Hierarchical Clustering Method: Clustering Criterion and\n  Agglomerative Algorithm", "comments": "20 pages, 21 citations, 4 figures", "journal-ref": "Journal of Classification, 31 (3), 274-295, 2014", "doi": "10.1007/s00357-014-9161-z", "report-no": null, "categories": "stat.ML cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ward error sum of squares hierarchical clustering method has been very\nwidely used since its first description by Ward in a 1963 publication. It has\nalso been generalized in various ways. However there are different\ninterpretations in the literature and there are different implementations of\nthe Ward agglomerative algorithm in commonly used software systems, including\ndiffering expressions of the agglomerative criterion. Our survey work and case\nstudies will be useful for all those involved in developing software for data\nanalysis using Ward's hierarchical clustering method.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 18:39:14 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2011 23:58:45 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Murtagh", "Fionn", ""], ["Legendre", "Pierre", ""]]}, {"id": "1111.6387", "submitter": "Kassimi My Abdellah", "authors": "My Abdellah Kassimi and Omar El beqqali", "title": "3D Model Retrieval Based on Semantic and Shape Indexes", "comments": "IJCSI International Journal of Computer Science Issues, Vol. 8, Issue\n  3, May 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The size of 3D models used on the web or stored in databases is becoming\nincreasingly high. Then, an efficient method that allows users to find similar\n3D objects for a given 3D model query has become necessary. Keywords and the\ngeometry of a 3D model cannot meet the needs of users' retrieval because they\ndo not include the semantic information. In this paper, a new method has been\nproposed to 3D models retrieval using semantic concepts combined with shape\nindexes. To obtain these concepts, we use the machine learning methods to label\n3D models by k-means algorithm in measures and shape indexes space. Moreover,\nsemantic concepts have been organized and represented by ontology language OWL\nand spatial relationships are used to disambiguate among models of similar\nappearance. The SPARQL query language has been used to question the information\ndisplayed in this language and to compute the similarity between two 3D models.\nWe interpret our results using the Princeton Shape Benchmark Database and the\nresults show the performance of the proposed new approach to retrieval 3D\nmodels. Keywords: 3D Model, 3D retrieval, measures, shape indexes, semantic,\nontology\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 10:07:41 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Kassimi", "My Abdellah", ""], ["beqqali", "Omar El", ""]]}, {"id": "1111.6923", "submitter": "Akshay Soni", "authors": "Akshay Soni and Jarvis Haupt", "title": "Efficient Adaptive Compressive Sensing Using Sparse Hierarchical Learned\n  Dictionaries", "comments": "5 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT math.IT math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthrough results in compressed sensing (CS) have established that\nmany high dimensional objects can be accurately recovered from a relatively\nsmall number of non- adaptive linear projection observations, provided that the\nobjects possess a sparse representation in some basis. Subsequent efforts have\nshown that the performance of CS can be improved by exploiting the structure in\nthe location of the non-zero signal coefficients (structured sparsity) or using\nsome form of online measurement focusing (adaptivity) in the sensing process.\nIn this paper we examine a powerful hybrid of these two techniques. First, we\ndescribe a simple adaptive sensing procedure and show that it is a provably\neffective method for acquiring sparse signals that exhibit structured sparsity\ncharacterized by tree-based coefficient dependencies. Next, employing\ntechniques from sparse hierarchical dictionary learning, we show that\nrepresentations exhibiting the appropriate form of structured sparsity can be\nlearned from collections of training data. The combination of these techniques\nresults in an effective and efficient adaptive compressive acquisition\nprocedure.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 18:31:54 GMT"}], "update_date": "2011-11-30", "authors_parsed": [["Soni", "Akshay", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1111.7100", "submitter": "Thorsten Theobald", "authors": "Richard J. Gardner, Paolo Gronchi, Thorsten Theobald", "title": "Determining a rotation of a tetrahedron from a projection", "comments": "16 pages, 3 figures; minor revision based on reviewers' comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following problem, arising from medical imaging, is addressed: Suppose\nthat $T$ is a known tetrahedron in $\\R^3$ with centroid at the origin. Also\nknown is the orthogonal projection $U$ of the vertices of the image $\\phi T$ of\n$T$ under an unknown rotation $\\phi$ about the origin. Under what circumstances\ncan $\\phi$ be determined from $T$ and $U$?\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 09:51:46 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2012 16:10:17 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Gardner", "Richard J.", ""], ["Gronchi", "Paolo", ""], ["Theobald", "Thorsten", ""]]}, {"id": "1111.7271", "submitter": "Uriel Nava", "authors": "Rodrigo Nava and Gabriel Crist\\'obal and Boris Escalante-Ram\\'irez", "title": "Invariant texture analysis through Local Binary Patterns", "comments": "7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many image processing applications, such as segmentation and\nclassification, the selection of robust features descriptors is crucial to\nimprove the discrimination capabilities in real world scenarios. In particular,\nit is well known that image textures constitute power visual cues for feature\nextraction and classification. In the past few years the local binary pattern\n(LBP) approach, a texture descriptor method proposed by Ojala et al., has\ngained increased acceptance due to its computational simplicity and more\nimportantly for encoding a powerful signature for describing textures. However,\nthe original algorithm presents some limitations such as noise sensitivity and\nits lack of rotational invariance which have led to many proposals or\nextensions in order to overcome such limitations. In this paper we performed a\nquantitative study of the Ojala's original LBP proposal together with other\nrecently proposed LBP extensions in the presence of rotational, illumination\nand noisy changes. In the experiments we have considered two different\ndatabases: Brodatz and CUReT for different sizes of LBP masks. Experimental\nresults demonstrated the effectiveness and robustness of the described texture\ndescriptors for images that are subjected to geometric or radiometric changes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 18:58:53 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Nava", "Rodrigo", ""], ["Crist\u00f3bal", "Gabriel", ""], ["Escalante-Ram\u00edrez", "Boris", ""]]}]