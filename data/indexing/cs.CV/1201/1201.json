[{"id": "1201.0022", "submitter": "Lotfi Chaari", "authors": "Lotfi Chaari, S\\'ebastien M\\'eriaux, Jean-Christophe Pesquet and\n  Philippe Ciuciu", "title": "Spatio-temporal wavelet regularization for parallel MRI reconstruction:\n  application to functional MRI", "comments": "arXiv admin note: substantial text overlap with arXiv:1103.3532", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel MRI is a fast imaging technique that enables the acquisition of\nhighly resolved images in space or/and in time. The performance of parallel\nimaging strongly depends on the reconstruction algorithm, which can proceed\neither in the original k-space (GRAPPA, SMASH) or in the image domain\n(SENSE-like methods). To improve the performance of the widely used SENSE\nalgorithm, 2D- or slice-specific regularization in the wavelet domain has been\ndeeply investigated. In this paper, we extend this approach using 3D-wavelet\nrepresentations in order to handle all slices together and address\nreconstruction artifacts which propagate across adjacent slices. The gain\ninduced by such extension (3D-Unconstrained Wavelet Regularized -SENSE:\n3D-UWR-SENSE) is validated on anatomical image reconstruction where no temporal\nacquisition is considered. Another important extension accounts for temporal\ncorrelations that exist between successive scans in functional MRI (fMRI). In\naddition to the case of 2D+t acquisition schemes addressed by some other\nmethods like kt-FOCUSS, our approach allows us to deal with 3D+t acquisition\nschemes which are widely used in neuroimaging. The resulting 3D-UWR-SENSE and\n4D-UWR-SENSE reconstruction schemes are fully unsupervised in the sense that\nall regularization parameters are estimated in the maximum likelihood sense on\na reference scan. The gain induced by such extensions is illustrated on both\nanatomical and functional image reconstruction, and also measured in terms of\nstatistical sensitivity for the 4D-UWR-SENSE approach during a fast\nevent-related fMRI protocol. Our 4D-UWR-SENSE algorithm outperforms the SENSE\nreconstruction at the subject and group levels (15 subjects) for different\ncontrasts of interest (eg, motor or computation tasks) and using different\nparallel acceleration factors (R=2 and R=4) on 2x2x3mm3 EPI images.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 18:26:14 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2013 11:11:30 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2013 21:42:10 GMT"}], "update_date": "2013-10-07", "authors_parsed": [["Chaari", "Lotfi", ""], ["M\u00e9riaux", "S\u00e9bastien", ""], ["Pesquet", "Jean-Christophe", ""], ["Ciuciu", "Philippe", ""]]}, {"id": "1201.0566", "submitter": "Ivana Tosic", "authors": "Ivana Tosic and Sarah Drewes", "title": "Learning joint intensity-depth sparse representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for learning overcomplete dictionaries composed\nof two modalities that describe a 3D scene: image intensity and scene depth. We\npropose a novel Joint Basis Pursuit (JBP) algorithm that finds related sparse\nfeatures in two modalities using conic programming and integrate it into a\ntwo-step dictionary learning algorithm. JBP differs from related convex\nalgorithms because it finds joint sparsity models with different atoms and\ndifferent coefficient values for intensity and depth. This is crucial for\nrecovering generative models where the same sparse underlying causes (3D\nfeatures) give rise to different signals (intensity and depth). We give a\ntheoretical bound for the sparse coefficient recovery error obtained by JBP,\nand show experimentally that JBP is far superior to the state of the art Group\nLasso algorithm. When applied to the Middlebury depth-intensity database, our\nlearning algorithm converges to a set of related features, such as pairs of\ndepth and intensity edges or image textures and depth slants. Finally, we show\nthat the learned dictionary and JBP achieve the state of the art depth\ninpainting performance on time-of-flight 3D data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 03:47:09 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2013 20:56:20 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Tosic", "Ivana", ""], ["Drewes", "Sarah", ""]]}, {"id": "1201.0925", "submitter": "Bijan Afsari", "authors": "Bijan Afsari, Roberto Tron, and Ren\\'e Vidal", "title": "On The Convergence of Gradient Descent for Finding the Riemannian Center\n  of Mass", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CV cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the global Riemannian center of mass of a set\nof data points on a Riemannian manifold. Specifically, we investigate the\nconvergence of constant step-size gradient descent algorithms for solving this\nproblem. The challenge is that often the underlying cost function is neither\nglobally differentiable nor convex, and despite this one would like to have\nguaranteed convergence to the global minimizer. After some necessary\npreparations we state a conjecture which we argue is the best (in a sense\ndescribed) convergence condition one can hope for. The conjecture specifies\nconditions on the spread of the data points, step-size range, and the location\nof the initial condition (i.e., the region of convergence) of the algorithm.\nThese conditions depend on the topology and the curvature of the manifold and\ncan be conveniently described in terms of the injectivity radius and the\nsectional curvatures of the manifold. For manifolds of constant nonnegative\ncurvature (e.g., the sphere and the rotation group in $\\mathbb{R}^{3}$) we show\nthat the conjecture holds true (we do this by proving and using a comparison\ntheorem which seems to be of a different nature from the standard comparison\ntheorems in Riemannian geometry). For manifolds of arbitrary curvature we prove\nconvergence results which are weaker than the conjectured one (but still\nsuperior over the available results). We also briefly study the effect of the\nconfiguration of the data points on the speed of convergence.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2011 17:59:03 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Afsari", "Bijan", ""], ["Tron", "Roberto", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1201.1216", "submitter": "Pierre-Yves Burgi", "authors": "Pierre-Yves Burgi, Alan L. Yuille, and Norberto M. Grzywacz", "title": "Probabilistic Motion Estimation Based on Temporal Coherence", "comments": "40 pages, 7 figures", "journal-ref": "Neural Computation, 2000, vol. 12, no. 8, p. 1839-1867", "doi": "10.1162/089976600300015169", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We develop a theory for the temporal integration of visual motion motivated\nby psychophysical experiments. The theory proposes that input data are\ntemporally grouped and used to predict and estimate the motion flows in the\nimage sequence. This temporal grouping can be considered a generalization of\nthe data association techniques used by engineers to study motion sequences.\nOur temporal-grouping theory is expressed in terms of the Bayesian\ngeneralization of standard Kalman filtering. To implement the theory we derive\na parallel network which shares some properties of cortical networks. Computer\nsimulations of this network demonstrate that our theory qualitatively accounts\nfor psychophysical experiments on motion occlusion and motion outliers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 16:49:01 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Burgi", "Pierre-Yves", ""], ["Yuille", "Alan L.", ""], ["Grzywacz", "Norberto M.", ""]]}, {"id": "1201.1221", "submitter": "Paul Vitanyi", "authors": "P. M. B. Vitanyi (National Research Center for Mathematics and\n  Computer Science in the Netherlands (CWI), Amsterdam)", "title": "Information Distance: New Developments", "comments": "4 pages, Latex; Series of Publications C, Report C-2011-45,\n  Department of Computer Science, University of Helsinki, pp. 71-74", "journal-ref": "Proc. 4th Workshop on Information Theoretic Methods in Science and\n  Engineering (WITSME 2011), 2011, pp. 71-74", "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pattern recognition, learning, and data mining one obtains information\nfrom information-carrying objects. This involves an objective definition of the\ninformation in a single object, the information to go from one object to\nanother object in a pair of objects, the information to go from one object to\nany other object in a multiple of objects, and the shared information between\nobjects. This is called \"information distance.\" We survey a selection of new\ndevelopments in information distance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2012 17:14:18 GMT"}], "update_date": "2012-01-06", "authors_parsed": [["Vitanyi", "P. M. B.", "", "National Research Center for Mathematics and\n  Computer Science in the Netherlands"]]}, {"id": "1201.1417", "submitter": "Hesam Ekhtiyar", "authors": "Hesam Ekhtiyar, Mahdi Sheida and Mahmood Amintoosi", "title": "Picture Collage with Genetic Algorithm and Stereo vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper, a salient region extraction method for creating picture\ncollage based on stereo vision is proposed. Picture collage is a kind of visual\nimage summary to arrange all input images on a given canvas, allowing overlay,\nto maximize visible visual information. The salient regions of each image are\nfirstly extracted and represented as a depth map. The output picture collage\nshows as many visible salient regions (without being overlaid by others) from\nall images as possible. A very efficient Genetic algorithm is used here for the\noptimization. The experimental results showed the superior performance of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 06:24:33 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Ekhtiyar", "Hesam", ""], ["Sheida", "Mahdi", ""], ["Amintoosi", "Mahmood", ""]]}, {"id": "1201.1422", "submitter": "Roli Bansal", "authors": "Roli Bansal, Priti Sehgal, Punam Bedi", "title": "Minutiae Extraction from Fingerprint Images - a Review", "comments": "12 pages; IJCSI International Journal of Computer Science Issues,\n  Vol. 8, Issue 5, September 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprints are the oldest and most widely used form of biometric\nidentification. Everyone is known to have unique, immutable fingerprints. As\nmost Automatic Fingerprint Recognition Systems are based on local ridge\nfeatures known as minutiae, marking minutiae accurately and rejecting false\nones is very important. However, fingerprint images get degraded and corrupted\ndue to variations in skin and impression conditions. Thus, image enhancement\ntechniques are employed prior to minutiae extraction. A critical step in\nautomatic fingerprint matching is to reliably extract minutiae from the input\nfingerprint images. This paper presents a review of a large number of\ntechniques present in the literature for extracting fingerprint minutiae. The\ntechniques are broadly classified as those working on binarized images and\nthose that work on gray scale images directly.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2011 05:42:36 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Bansal", "Roli", ""], ["Sehgal", "Priti", ""], ["Bedi", "Punam", ""]]}, {"id": "1201.1571", "submitter": "Hongyu Lu", "authors": "Hongyu Lu, Yutian Wang, Shanglian Bao", "title": "A United Image Force for Deformable Models and Direct Transforming\n  Geometric Active Contorus to Snakes by Level Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A uniform distribution of the image force field around the object fasts the\nconvergence speed of the segmentation process. However, to achieve this aim, it\ncauses the force constructed from the heat diffusion model unable to indicate\nthe object boundaries accurately. The image force based on electrostatic field\nmodel can perform an exact shape recovery. First, this study introduces a\nfusion scheme of these two image forces, which is capable of extracting the\nobject boundary with high precision and fast speed. Until now, there is no\nsatisfied analysis about the relationship between Snakes and Geometric Active\nContours (GAC). The second contribution of this study addresses that the GAC\nmodel can be deduced directly from Snakes model. It proves that each term in\nGAC and Snakes is correspondent and has similar function. However, the two\nmodels are expressed using different mathematics. Further, since losing the\nability of rotating the contour, adoption of level sets can limits the usage of\nGAC in some circumstances.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jan 2012 15:58:18 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2012 13:17:48 GMT"}, {"version": "v3", "created": "Mon, 7 May 2012 09:52:00 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Lu", "Hongyu", ""], ["Wang", "Yutian", ""], ["Bao", "Shanglian", ""]]}, {"id": "1201.2050", "submitter": "Tina Gebreyohannes Hailemichael", "authors": "Tina Gebreyohannes and Dong-Yoon Kim", "title": "Adaptive Noise Reduction Scheme for Salt and Pepper", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new adaptive noise reduction scheme for images corrupted by\nimpulse noise is presented. The proposed scheme efficiently identifies and\nreduces salt and pepper noise. MAG (Mean Absolute Gradient) is used to identify\npixels which are most likely corrupted by salt and pepper noise that are\ncandidates for further median based noise reduction processing. Directional\nfiltering is then applied after noise reduction to achieve a good tradeoff\nbetween detail preservation and noise removal. The proposed scheme can remove\nsalt and pepper noise with noise density as high as 90% and produce better\nresult in terms of qualitative and quantitative measures of images.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 13:41:56 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Gebreyohannes", "Tina", ""], ["Kim", "Dong-Yoon", ""]]}, {"id": "1201.2395", "submitter": "Jacob Hinkle", "authors": "Jacob Hinkle and Prasanna Muralidharan and P. Thomas Fletcher and\n  Sarang Joshi", "title": "Polynomial Regression on Riemannian Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CV math.DG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop the theory of parametric polynomial regression in\nRiemannian manifolds and Lie groups. We show application of Riemannian\npolynomial regression to shape analysis in Kendall shape space. Results are\npresented, showing the power of polynomial regression on the classic rat skull\ngrowth data of Bookstein as well as the analysis of the shape changes\nassociated with aging of the corpus callosum from the OASIS Alzheimer's study.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 20:27:32 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 17:26:24 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Hinkle", "Jacob", ""], ["Muralidharan", "Prasanna", ""], ["Fletcher", "P. Thomas", ""], ["Joshi", "Sarang", ""]]}, {"id": "1201.2542", "submitter": "Allin Christe", "authors": "S. Allin Christe, M.Vignesh, A.Kandaswamy", "title": "An efficient FPGA implementation of MRI image filtering and tumor\n  characterization using Xilinx system generator", "comments": "15 pages,14 figures,2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient architecture for various image filtering\nalgorithms and tumor characterization using Xilinx System Generator (XSG). This\narchitecture offers an alternative through a graphical user interface that\ncombines MATLAB, Simulink and XSG and explores important aspects concerned to\nhardware implementation. Performance of this architecture implemented in\nSPARTAN-3E Starter kit (XC3S500E-FG320) exceeds those of similar or greater\nresources architectures. The proposed architecture reduces the resources\navailable on target device by 50%.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 12:23:33 GMT"}], "update_date": "2012-01-13", "authors_parsed": [["Christe", "S. Allin", ""], ["Vignesh", "M.", ""], ["Kandaswamy", "A.", ""]]}, {"id": "1201.2605", "submitter": "Zhenwen Dai", "authors": "Zhenwen Dai and J\\\"org L\\\"ucke", "title": "Autonomous Cleaning of Corrupted Scanned Documents - A Generative\n  Modeling Approach", "comments": "oral presentation and Google Student Travel Award; IEEE conference on\n  Computer Vision and Pattern Recognition 2012", "journal-ref": null, "doi": "10.1109/TPAMI.2014.2313126", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of cleaning scanned text documents that are strongly\ncorrupted by dirt such as manual line strokes, spilled ink etc. We aim at\nautonomously removing dirt from a single letter-size page based only on the\ninformation the page contains. Our approach, therefore, has to learn character\nrepresentations without supervision and requires a mechanism to distinguish\nlearned representations from irregular patterns. To learn character\nrepresentations, we use a probabilistic generative model parameterizing pattern\nfeatures, feature variances, the features' planar arrangements, and pattern\nfrequencies. The latent variables of the model describe pattern class, pattern\nposition, and the presence or absence of individual pattern features. The model\nparameters are optimized using a novel variational EM approximation. After\nlearning, the parameters represent, independently of their absolute position,\nplanar feature arrangements and their variances. A quality measure defined\nbased on the learned representation then allows for an autonomous\ndiscrimination between regular character patterns and the irregular patterns\nmaking up the dirt. The irregular patterns can thus be removed to clean the\ndocument. For a full Latin alphabet we found that a single page does not\ncontain sufficiently many character examples. However, even if heavily\ncorrupted by dirt, we show that a page containing a lower number of character\ntypes can efficiently and autonomously be cleaned solely based on the\nstructural regularity of the characters it contains. In different examples\nusing characters from different alphabets, we demonstrate generality of the\napproach and discuss its implications for future developments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 16:09:10 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2012 12:42:01 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Dai", "Zhenwen", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "1201.2843", "submitter": "Mahmoud Ramezani Mayiami", "authors": "Mahmoud Ramezani Mayiami, Babak Seyfe", "title": "Nonparametric Sparse Representation", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests a nonparametric scheme to find the sparse solution of the\nunderdetermined system of linear equations in the presence of unknown impulsive\nor non-Gaussian noise. This approach is robust against any variations of the\nnoise model and its parameters. It is based on minimization of rank pseudo norm\nof the residual signal and l_1-norm of the signal of interest, simultaneously.\nWe use the steepest descent method to find the sparse solution via an iterative\nalgorithm. Simulation results show that our proposed method outperforms the\nexistence methods like OMP, BP, Lasso, and BCS whenever the observation vector\nis contaminated with measurement or environmental non-Gaussian noise with\nunknown parameters. Furthermore, for low SNR condition, the proposed method has\nbetter performance in the presence of Gaussian noise.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 14:05:59 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Mayiami", "Mahmoud Ramezani", ""], ["Seyfe", "Babak", ""]]}, {"id": "1201.2905", "submitter": "Qiyang Zhao", "authors": "Zhao Qiyang", "title": "NegCut: Automatic Image Segmentation based on MRF-MAP", "comments": "Since it's an unlucky failure about length-limit violation, I'd like\n  to save it on arXiv as a record. Any suggestions are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving the Maximum a Posteriori on Markov Random Field, MRF-MAP, is a\nprevailing method in recent interactive image segmentation tools. Although\nmathematically explicit in its computational targets, and impressive for the\nsegmentation quality, MRF-MAP is hard to accomplish without the interactive\ninformation from users. So it is rarely adopted in the automatic style up to\ntoday. In this paper, we present an automatic image segmentation algorithm,\nNegCut, based on the approximation to MRF-MAP. First we prove MRF-MAP is\nNP-hard when the probabilistic models are unknown, and then present an\napproximation function in the form of minimum cuts on graphs with negative\nweights. Finally, the binary segmentation is taken from the largest eigenvector\nof the target matrix, with a tuned version of the Lanczos eigensolver. It is\nshown competitive at the segmentation quality in our experiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 18:18:03 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2012 03:28:43 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Qiyang", "Zhao", ""]]}, {"id": "1201.2995", "submitter": "Rajathilagam Bijoy", "authors": "B.Rajathilagam, Murali Rangarajan, K.P.Soman", "title": "G-Lets: Signal Processing Using Transformation Groups", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm using transformation groups and their irreducible\nrepresentations to generate an orthogonal basis for a signal in the vector\nspace of the signal. It is shown that multiresolution analysis can be done with\namplitudes using a transformation group. G-lets is thus not a single transform,\nbut a group of linear transformations related by group theory. The algorithm\nalso specifies that a multiresolution and multiscale analysis for each\nresolution is possible in terms of frequencies. Separation of low and high\nfrequency components of each amplitude resolution is facilitated by G-lets.\nUsing conjugacy classes of the transformation group, more than one set of basis\nmay be generated, giving a different perspective of the signal through each\nbasis. Applications for this algorithm include edge detection, feature\nextraction, denoising, face recognition, compression, and more. We analyze this\nalgorithm using dihedral groups as an example. We demonstrate the results with\nan ECG signal and the standard `Lena' image.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2012 07:18:06 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Rajathilagam", "B.", ""], ["Rangarajan", "Murali", ""], ["Soman", "K. P.", ""]]}, {"id": "1201.3109", "submitter": "Odemir Bruno PhD", "authors": "Wesley Nunes Gon\\c{c}alves, Odemir Martinez Bruno", "title": "Automatic system for counting cells with elliptical shape", "comments": "Learning and NonLinear Models, Volume 9, Issue 1, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method for automatic quantification of ellipse-like\ncells in images, an important and challenging problem that has been studied by\nthe computer vision community. The proposed method can be described by two main\nsteps. Initially, image segmentation based on the k-means algorithm is\nperformed to separate different types of cells from the background. Then, a\nrobust and efficient strategy is performed on the blob contour for touching\ncells splitting. Due to the contour processing, the method achieves excellent\nresults of detection compared to manual detection performed by specialists.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 17:42:07 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Gon\u00e7alves", "Wesley Nunes", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.3116", "submitter": "Odemir Bruno PhD", "authors": "Jo\\~ao Batista Florindo, M\\'ario de Castro, Odemir Martinez Bruno", "title": "Enhancing Volumetric Bouligand-Minkowski Fractal Descriptors by using\n  Functional Data Analysis", "comments": null, "journal-ref": "International Journal of Modern Physics C, Volume: 22, Issue:\n  9(2011) pp. 929-952", "doi": "10.1142/S0129183111016701", "report-no": null, "categories": "cs.CV physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes and study the concept of Functional Data Analysis\ntransform, applying it to the performance improving of volumetric\nBouligand-Minkowski fractal descriptors. The proposed transform consists\nessentially in changing the descriptors originally defined in the space of the\ncalculus of fractal dimension into the space of coefficients used in the\nfunctional data representation of these descriptors. The transformed decriptors\nare used here in texture classification problems. The enhancement provided by\nthe FDA transform is measured by comparing the transformed to the original\ndescriptors in terms of the correctness rate in the classification of well\nknown datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 19:38:48 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Florindo", "Jo\u00e3o Batista", ""], ["de Castro", "M\u00e1rio", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.3118", "submitter": "Odemir Bruno PhD", "authors": "Andr\\'e R. Backes, Jo\\~ao B. Florindo, Odemir M. Bruno", "title": "Shape analysis using fractal dimension: a curvature based approach", "comments": null, "journal-ref": null, "doi": "10.1063/1.4757226", "report-no": null, "categories": "physics.data-an cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work shows a novel fractal dimension method for shape analysis.\nThe proposed technique extracts descriptors from the shape by applying a\nmultiscale approach to the calculus of the fractal dimension of that shape. The\nfractal dimension is obtained by the application of the curvature scale-space\ntechnique to the original shape. Through the application of a multiscale\ntransform to the dimension calculus, it is obtained a set of numbers\n(descriptors) capable of describing with a high precision the shape in\nanalysis. The obtained descriptors are validated in a classification process.\nThe results demonstrate that the novel technique provides descriptors highly\nreliable, confirming the precision of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 20:19:11 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Backes", "Andr\u00e9 R.", ""], ["Florindo", "Jo\u00e3o B.", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "1201.3133", "submitter": "Odemir Bruno PhD", "authors": "Jo\\~ao Batista Florindo, Odemir Martinez Bruno", "title": "Fractal Descriptors in the Fourier Domain Applied to Color Texture\n  Analysis", "comments": "Chaos, Volume 21, Issue 4, 2011", "journal-ref": null, "doi": "10.1063/1.3650233", "report-no": null, "categories": "physics.data-an cs.CV math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work proposes the development of a novel method to provide\ndescriptors for colored texture images. The method consists in two steps. In\nthe first, we apply a linear transform in the color space of the image aiming\nat highlighting spatial structuring relations among the color of pixels. In a\nsecond moment, we apply a multiscale approach to the calculus of fractal\ndimension based on Fourier transform. From this multiscale operation, we\nextract the descriptors used to discriminate the texture represented in digital\nimages. The accuracy of the method is verified in the classification of two\ncolor texture datasets, by comparing the performance of the proposed technique\nto other classical and state-of-the-art methods for color texture analysis. The\nresults showed an advantage of almost 3% of the proposed technique over the\nsecond best approach.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2012 22:33:43 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2012 01:20:34 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Florindo", "Jo\u00e3o Batista", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.3153", "submitter": "Odemir Bruno PhD", "authors": "Andr\\'e Ricardo Backes, Odemir Martinez Bruno", "title": "Fractal and Multi-Scale Fractal Dimension analysis: a comparative study\n  of Bouligand-Minkowski method", "comments": null, "journal-ref": "INFOCOMP, v. 7, p. 74-83, 2008", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape is one of the most important visual attributes to characterize objects,\nplaying a important role in pattern recognition. There are various approaches\nto extract relevant information of a shape. An approach widely used in shape\nanalysis is the complexity, and Fractal Dimension and Multi-Scale Fractal\nDimension are both well-known methodologies to estimate it. This papers\npresents a comparative study between Fractal Dimension and Multi-Scale Fractal\nDimension in a shape analysis context. Through experimental comparison using a\nshape database previously classified, both methods are compared. Different\nparameters configuration of each method are considered and a discussion about\nthe results of each method is also presented.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 03:18:22 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Backes", "Andr\u00e9 Ricardo", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.3172", "submitter": "Uma Murthy", "authors": "Uma Murthy, David Boardman, Chirag Garg", "title": "Assessing the Value of 3D Reconstruction in Building Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3-dimensional (3D) reconstruction is an emerging field in image processing\nand computer vision that aims to create 3D visualizations/ models of objects/\nscenes from image sets. However, its commercial applications and benefits are\nyet to be fully explored. In this paper, we describe ongoing work towards\nassessing the value of 3D reconstruction in the building construction domain.\nWe present preliminary results from a user study, where our objective is to\nunderstand the use of visual information in building construction in order to\ndetermine problems with the use of visual information and identify potential\nbenefits and scenarios for the use of 3D reconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 07:57:34 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2012 23:51:49 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Murthy", "Uma", ""], ["Boardman", "David", ""], ["Garg", "Chirag", ""]]}, {"id": "1201.3233", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "Variations of images to increase their visibility", "comments": "Keywords: Image visibility, Fringe visibility, Gimp. Layout after\n  revision of misprints", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The calculus of variations applied to the image processing requires some\nnumerical models able to perform the variations of images and the extremization\nof appropriate actions. To produce the variations of images, there are several\npossibilities based on the brightness maps. Before a numerical model, I propose\nan experimental approach, based on a tool of Gimp, GNU Image Manipulation\nProgram, in order to visualize how the image variations can be. After the\ndiscussion of this tool, which is able to strongly increase the visibility of\nimages, the variations and a possible functional for the visibility are\nproposed in the framework of a numerical model. The visibility functional is\nanalogous to the fringe visibility of the optical interference.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 12:31:27 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2012 11:40:37 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1201.3337", "submitter": "Reza Keyvan", "authors": "Fatemeh Alamdar, MohammadReza Keyvanpour", "title": "A New Color Feature Extraction Method Based on Dynamic Color\n  Distribution Entropy of Neighborhoods", "comments": null, "journal-ref": "International Journal of Computer Science Issues, Vol. 8, Issue 5,\n  No 1 (2011) 42-48", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the important requirements in image retrieval, indexing,\nclassification, clustering and etc. is extracting efficient features from\nimages. The color feature is one of the most widely used visual features. Use\nof color histogram is the most common way for representing color feature. One\nof disadvantage of the color histogram is that it does not take the color\nspatial distribution into consideration. In this paper dynamic color\ndistribution entropy of neighborhoods method based on color distribution\nentropy is presented, which effectively describes the spatial information of\ncolors. The image retrieval results in compare to improved color distribution\nentropy show the acceptable efficiency of this approach.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2012 23:36:19 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Alamdar", "Fatemeh", ""], ["Keyvanpour", "MohammadReza", ""]]}, {"id": "1201.3410", "submitter": "Odemir Bruno PhD", "authors": "Jo\\~ao B. Florindo, Mariana S. Sikora, Ernesto C. Pereira, Odemir M.\n  Bruno", "title": "Multiscale Fractal Descriptors Applied to Nanoscale Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.mes-hall cond-mat.mtrl-sci cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the application of fractal descriptors to the analysis of\nnanoscale materials under different experimental conditions. We obtain\ndescriptors for images from the sample applying a multiscale transform to the\ncalculation of fractal dimension of a surface map of such image. Particularly,\nwe have used the}Bouligand-Minkowski fractal dimension. We applied these\ndescriptors to discriminate between two titanium oxide films prepared under\ndifferent experimental conditions. Results demonstrate the discrimination power\nof proposed descriptors in such kind of application.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 01:55:35 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Florindo", "Jo\u00e3o B.", ""], ["Sikora", "Mariana S.", ""], ["Pereira", "Ernesto C.", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "1201.3612", "submitter": "Odemir Bruno PhD", "authors": "Wesley Nunes Gon\\c{c}alves, Bruno Brandoli Machado, Odemir Martinez\n  Bruno", "title": "Spatiotemporal Gabor filters: a new method for dynamic texture\n  recognition", "comments": "Workshop on Computer Vision 2011 http://www.wvc2011.ufpr.br", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method for dynamic texture recognition based on\nspatiotemporal Gabor filters. Dynamic textures have emerged as a new field of\ninvestigation that extends the concept of self-similarity of texture image to\nthe spatiotemporal domain. To model a dynamic texture, we convolve the sequence\nof images to a bank of spatiotemporal Gabor filters. For each response, a\nfeature vector is built by calculating the energy statistic. As far as the\nauthors know, this paper is the first to report an effective method for dynamic\ntexture recognition using spatiotemporal Gabor filters. We evaluate the\nproposed method on two challenging databases and the experimental results\nindicate that the proposed method is a robust approach for dynamic texture\nrecognition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 20:26:04 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Gon\u00e7alves", "Wesley Nunes", ""], ["Machado", "Bruno Brandoli", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.3674", "submitter": "Allen Yang", "authors": "Dheeraj Singaraju, Ehsan Elhamifar, Roberto Tron, Allen Y. Yang, S.\n  Shankar Sastry", "title": "On the Lagrangian Biduality of Sparsity Minimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in Compressive Sensing have shown that, under certain\nconditions, the solution to an underdetermined system of linear equations with\nsparsity-based regularization can be accurately recovered by solving convex\nrelaxations of the original problem. In this work, we present a novel\nprimal-dual analysis on a class of sparsity minimization problems. We show that\nthe Lagrangian bidual (i.e., the Lagrangian dual of the Lagrangian dual) of the\nsparsity minimization problems can be used to derive interesting convex\nrelaxations: the bidual of the $\\ell_0$-minimization problem is the\n$\\ell_1$-minimization problem; and the bidual of the $\\ell_{0,1}$-minimization\nproblem for enforcing group sparsity on structured data is the\n$\\ell_{1,\\infty}$-minimization problem. The analysis provides a means to\ncompute per-instance non-trivial lower bounds on the (group) sparsity of the\ndesired solutions. In a real-world application, the bidual relaxation improves\nthe performance of a sparsity-based classification framework applied to robust\nface recognition.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 00:46:12 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Singaraju", "Dheeraj", ""], ["Elhamifar", "Ehsan", ""], ["Tron", "Roberto", ""], ["Yang", "Allen Y.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1201.3720", "submitter": "Aamir Khan", "authors": "Aamir Khan, Muhammad Farhan, Aasim Khurshid and Adeel Akram", "title": "A Multimodal Biometric System Using Linear Discriminant Analysis For\n  Improved Performance", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 6, No 2, 2011, 122-127", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Essentially a biometric system is a pattern recognition system which\nrecognizes a user by determining the authenticity of a specific anatomical or\nbehavioral characteristic possessed by the user. With the ever increasing\nintegration of computers and Internet into daily life style, it has become\nnecessary to protect sensitive and personal data. This paper proposes a\nmultimodal biometric system which incorporates more than one biometric trait to\nattain higher security and to handle failure to enroll situations for some\nusers. This paper is aimed at investigating a multimodal biometric identity\nsystem using Linear Discriminant Analysis as backbone to both facial and speech\nrecognition and implementing such system in real-time using SignalWAVE.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 08:20:00 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Khan", "Aamir", ""], ["Farhan", "Muhammad", ""], ["Khurshid", "Aasim", ""], ["Akram", "Adeel", ""]]}, {"id": "1201.3803", "submitter": "Manoj Vairalkar Manoj Vairalkar", "authors": "Manoj K. Vairalkar and Sonali. Nimbhorkar", "title": "Image Labeling and Segmentation using Hierarchical Conditional Random\n  Field Model", "comments": "08 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of hierarchical Conditional Random Field model deal with the problem\nof labeling images . At the time of labeling a new image, selection of the\nnearest cluster and using the related CRF model to label this image. When one\ngive input image, one first use the CRF model to get initial pixel labels then\nfinding the cluster with most similar images. Then at last relabeling the input\nimage by the CRF model associated with this cluster. This paper presents a\napproach to label and segment specific image having correct information.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 07:33:56 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Vairalkar", "Manoj K.", ""], ["Nimbhorkar", "Sonali.", ""]]}, {"id": "1201.3821", "submitter": "Carlos Miravet", "authors": "Carlos Miravet and Francisco B. Rodr\\'iguez", "title": "A PCA-Based Super-Resolution Algorithm for Short Image Sequences", "comments": "4 pages, 4 figures. A version of this work was submitted to ICIP 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel, learning-based, two-step super-resolution\n(SR) algorithm well suited to solve the specially demanding problem of\nobtaining SR estimates from short image sequences. The first step, devoted to\nincrease the sampling rate of the incoming images, is performed by fitting\nlinear combinations of functions generated from principal components (PC) to\nreproduce locally the sparse projected image data, and using these models to\nestimate image values at nodes of the high-resolution grid. PCs were obtained\nfrom local image patches sampled at sub-pixel level, which were generated in\nturn from a database of high-resolution images by application of a physically\nrealistic observation model. Continuity between local image models is enforced\nby minimizing an adequate functional in the space of model coefficients. The\nsecond step, dealing with restoration, is performed by a linear filter with\ncoefficients learned to restore residual interpolation artifacts in addition to\nlow-resolution blurring, providing an effective coupling between both steps of\nthe method. Results on a demanding five-image scanned sequence of graphics and\ntext are presented, showing the excellent performance of the proposed method\ncompared to several state-of-the-art two-step and Bayesian Maximum a Posteriori\nSR algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 15:19:03 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Miravet", "Carlos", ""], ["Rodr\u00edguez", "Francisco B.", ""]]}, {"id": "1201.3972", "submitter": "Kapil Kumar Gupta", "authors": "Kapil Kumar Gupta, Rizwan Beg, Jitendra Kumar Niranjan", "title": "A Novel Approach to Fast Image Filtering Algorithm of Infrared Images\n  based on Intro Sort Algorithm", "comments": "7 pages. arXiv admin note: substantial text with articles by\n  Chih-Lung Lin et al.", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 6, No 1, November 2011, 235-241", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we investigate the fast image filtering algorithm based on\nIntro sort algorithm and fast noise reduction of infrared images. Main feature\nof the proposed approach is that no prior knowledge of noise required. It is\ndeveloped based on Stefan- Boltzmann law and the Fourier law. We also\ninvestigate the fast noise reduction approach that has advantage of less\ncomputation load. In addition, it can retain edges, details, text information\neven if the size of the window increases. Intro sort algorithm begins with\nQuick sort and switches to heap sort when the recursion depth exceeds a level\nbased on the number of elements being sorted. This approach has the advantage\nof fast noise reduction by reducing the comparison time. It also significantly\nspeed up the noise reduction process and can apply to real-time image\nprocessing. This approach will extend the Infrared images applications for\nmedicine and video conferencing.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 04:57:36 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Gupta", "Kapil Kumar", ""], ["Beg", "Rizwan", ""], ["Niranjan", "Jitendra Kumar", ""]]}, {"id": "1201.4139", "submitter": "Odemir Bruno PhD", "authors": "Bruno Brandoli Machado, Wesley Nunes Gon\\c{c}alves, Odemir Martinez\n  Bruno", "title": "Image decomposition with anisotropic diffusion applied to leaf-texture\n  analysis", "comments": "Annals of Workshop of Computer Vision 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texture analysis is an important field of investigation that has received a\ngreat deal of interest from computer vision community. In this paper, we\npropose a novel approach for texture modeling based on partial differential\nequation (PDE). Each image $f$ is decomposed into a family of derived\nsub-images. $f$ is split into the $u$ component, obtained with anisotropic\ndiffusion, and the $v$ component which is calculated by the difference between\nthe original image and the $u$ component. After enhancing the texture attribute\n$v$ of the image, Gabor features are computed as descriptors. We validate the\nproposed approach on two texture datasets with high variability. We also\nevaluate our approach on an important real-world application: leaf-texture\nanalysis. Experimental results indicate that our approach can be used to\nproduce higher classification rates and can be successfully employed for\ndifferent texture applications.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 18:39:41 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Machado", "Bruno Brandoli", ""], ["Gon\u00e7alves", "Wesley Nunes", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.4597", "submitter": "Odemir Bruno PhD", "authors": "Jo\\~ao Batista Florindo, Odemir Martinez Bruno", "title": "Fractal Descriptors Based on Fourier Spectrum Applied to Texture\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the development and study of a novel technique for the\ngeneration of fractal descriptors used in texture analysis. The novel\ndescriptors are obtained from a multiscale transform applied to the Fourier\ntechnique of fractal dimension calculus. The power spectrum of the Fourier\ntransform of the image is plotted against the frequency in a log- log scale and\na multiscale transform is applied to this curve. The obtained values are taken\nas the fractal descriptors of the image. The validation of the propose is\nperformed by the use of the descriptors for the classification of a dataset of\ntexture images whose real classes are previously known. The classification\nprecision is compared to other fractal descriptors known in the literature. The\nresults confirm the efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2012 20:43:50 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Florindo", "Jo\u00e3o Batista", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1201.4895", "submitter": "Aswin Sankaranarayanan", "authors": "Aswin C Sankaranarayanan, Pavan K Turaga, Rama Chellappa and Richard G\n  Baraniuk", "title": "Compressive Acquisition of Dynamic Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) is a new approach for the acquisition and recovery\nof sparse signals and images that enables sampling rates significantly below\nthe classical Nyquist rate. Despite significant progress in the theory and\nmethods of CS, little headway has been made in compressive video acquisition\nand recovery. Video CS is complicated by the ephemeral nature of dynamic\nevents, which makes direct extensions of standard CS imaging architectures and\nsignal models difficult. In this paper, we develop a new framework for video CS\nfor dynamic textured scenes that models the evolution of the scene as a linear\ndynamical system (LDS). This reduces the video recovery problem to first\nestimating the model parameters of the LDS from compressive measurements, and\nthen reconstructing the image frames. We exploit the low-dimensional dynamic\nparameters (the state sequence) and high-dimensional static parameters (the\nobservation matrix) of the LDS to devise a novel compressive measurement\nstrategy that measures only the dynamic part of the scene at each instant and\naccumulates measurements over time to estimate the static parameters. This\nenables us to lower the compressive measurement rate considerably. We validate\nour approach with a range of experiments involving both video recovery, sensing\nhyper-spectral data, and classification of dynamic scenes from compressive\ndata. Together, these applications demonstrate the effectiveness of the\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 23:19:59 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2013 18:49:16 GMT"}], "update_date": "2013-06-27", "authors_parsed": [["Sankaranarayanan", "Aswin C", ""], ["Turaga", "Pavan K", ""], ["Chellappa", "Rama", ""], ["Baraniuk", "Richard G", ""]]}, {"id": "1201.5227", "submitter": "Tayenjam Romen Singh", "authors": "T. Romen Singh, Sudipta Roy, O. Imocha Singh, Tejmani Sinam, Kh.\n  Manglem Singh", "title": "A New Local Adaptive Thresholding Technique in Binarization", "comments": "ISSN (Online): 1694-0814 http://www.IJCSI.org 271", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 6, No 2, (2011) 271-277", "doi": null, "report-no": "rs12", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image binarization is the process of separation of pixel values into two\ngroups, white as background and black as foreground. Thresholding plays a major\nin binarization of images. Thresholding can be categorized into global\nthresholding and local thresholding. In images with uniform contrast\ndistribution of background and foreground like document images, global\nthresholding is more appropriate. In degraded document images, where\nconsiderable background noise or variation in contrast and illumination exists,\nthere exists many pixels that cannot be easily classified as foreground or\nbackground. In such cases, binarization with local thresholding is more\nappropriate. This paper describes a locally adaptive thresholding technique\nthat removes background by using local mean and mean deviation. Normally the\nlocal mean computational time depends on the window size. Our technique uses\nintegral sum image as a prior processing to calculate local mean. It does not\ninvolve calculations of standard deviations as in other local adaptive\ntechniques. This along with the fact that calculations of mean is independent\nof window size speed up the process as compared to other local thresholding\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 10:17:30 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["Singh", "T. Romen", ""], ["Roy", "Sudipta", ""], ["Singh", "O. Imocha", ""], ["Sinam", "Tejmani", ""], ["Singh", "Kh. Manglem", ""]]}, {"id": "1201.5404", "submitter": "Guoshen Yu", "authors": "Julio M. Duarte-Carvajalino, Guoshen Yu, Lawrence Carin, Guillermo\n  Sapiro", "title": "Task-Driven Adaptive Statistical Compressive Sensing of Gaussian Mixture\n  Models", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2012.2225054", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework for adaptive and non-adaptive statistical compressive sensing is\ndeveloped, where a statistical model replaces the standard sparsity model of\nclassical compressive sensing. We propose within this framework optimal\ntask-specific sensing protocols specifically and jointly designed for\nclassification and reconstruction. A two-step adaptive sensing paradigm is\ndeveloped, where online sensing is applied to detect the signal class in the\nfirst step, followed by a reconstruction step adapted to the detected class and\nthe observed samples. The approach is based on information theory, here\ntailored for Gaussian mixture models (GMMs), where an information-theoretic\nobjective relationship between the sensed signals and a representation of the\nspecific task of interest is maximized. Experimental results using synthetic\nsignals, Landsat satellite attributes, and natural images of different sizes\nand with different noise levels show the improvements achieved using the\nproposed framework when compared to more standard sensing protocols. The\nunderlying formulation can be applied beyond GMMs, at the price of higher\nmathematical and computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 22:25:27 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Duarte-Carvajalino", "Julio M.", ""], ["Yu", "Guoshen", ""], ["Carin", "Lawrence", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1201.5938", "submitter": "Hossein Khazaei", "authors": "Hajar Moradmand, Saeed Setayeshi, Hossein Khazaei Targhi", "title": "Comparing Methods for segmentation of Microcalcification Clusters in\n  Digitized Mammograms", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 6, No 1, November 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The appearance of microcalcifications in mammograms is one of the early signs\nof breast cancer. So, early detection of microcalcification clusters (MCCs) in\nmammograms can be helpful for cancer diagnosis and better treatment of breast\ncancer. In this paper a computer method has been proposed to support\nradiologists in detection MCCs in digital mammography. First, in order to\nfacilitate and improve the detection step, mammogram images have been enhanced\nwith wavelet transformation and morphology operation. Then for segmentation of\nsuspicious MCCs, two methods have been investigated. The considered methods\nare: adaptive threshold and watershed segmentation. Finally, the detected MCCs\nareas in different algorithms will be compared to find out which segmentation\nmethod is more appropriate for extracting MCCs in mammograms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 09:51:23 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Moradmand", "Hajar", ""], ["Setayeshi", "Saeed", ""], ["Targhi", "Hossein Khazaei", ""]]}, {"id": "1201.5943", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Sima Dimitrijev", "title": "Cognitive Memory Network", "comments": null, "journal-ref": "Electronics Letters,46, 10, 677 - 678, 2010", "doi": "10.1049/el.2010.0279", "report-no": null, "categories": "cs.AI cs.CV cs.ET", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A resistive memory network that has no crossover wiring is proposed to\novercome the hardware limitations to size and functional complexity that is\nassociated with conventional analogue neural networks. The proposed memory\nnetwork is based on simple network cells that are arranged in a hierarchical\nmodular architecture. Cognitive functionality of this network is demonstrated\nby an example of character recognition. The network is trained by an\nevolutionary process to completely recognise characters deformed by random\nnoise, rotation, scaling and shifting\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 11:05:26 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""], ["Dimitrijev", "Sima", ""]]}, {"id": "1201.5946", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Sima Dimitrijev", "title": "Feature selection using nearest attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important problem in high-dimensional data analysis\nand classification. Conventional feature selection approaches focus on\ndetecting the features based on a redundancy criterion using learning and\nfeature searching schemes. In contrast, we present an approach that identifies\nthe need to select features based on their discriminatory ability among\nclasses. Area of overlap between inter-class and intra-class distances\nresulting from feature to feature comparison of an attribute is used as a\nmeasure of discriminatory ability of the feature. A set of nearest attributes\nin a pattern having the lowest area of overlap within a degree of tolerance\ndefined by a selection threshold is selected to represent the best available\ndiscriminable features. State of the art recognition results are reported for\npattern classification problems by using the proposed feature selection scheme\nwith the nearest neighbour classifier. These results are reported with\nbenchmark databases having high dimensional feature vectors in the problems\ninvolving images and micro array data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 11:37:40 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""], ["Dimitrijev", "Sima", ""]]}, {"id": "1201.5947", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Sima Dimitrijev", "title": "Examplers based image fusion features for face recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Examplers of a face are formed from multiple gallery images of a person and\nare used in the process of classification of a test image. We incorporate such\nexamplers in forming a biologically inspired local binary decisions on\nsimilarity based face recognition method. As opposed to single model approaches\nsuch as face averages the exampler based approach results in higher recognition\naccu- racies and stability. Using multiple training samples per person, the\nmethod shows the following recognition accuracies: 99.0% on AR, 99.5% on FERET,\n99.5% on ORL, 99.3% on EYALE, 100.0% on YALE and 100.0% on CALTECH face\ndatabases. In addition to face recognition, the method also detects the natural\nvariability in the face images which can find application in automatic tagging\nof face images.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2012 11:45:07 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["James", "Alex Pappachen", ""], ["Dimitrijev", "Sima", ""]]}]