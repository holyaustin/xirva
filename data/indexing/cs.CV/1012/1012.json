[{"id": "1012.0084", "submitter": "Karthik Shastry R", "authors": "Harshith C, Karthik R. Shastry, Manoj Ravindran, M.V.V.N.S. Srikanth,\n  Naveen Lakshmikhanth", "title": "Survey on Various Gesture Recognition Techniques for Interfacing\n  Machines Based on Ambient Intelligence", "comments": "12 PAGES", "journal-ref": null, "doi": "10.5121/ijcses.2010.1203", "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gesture recognition is mainly apprehensive on analyzing the functionality of\nhuman wits. The main goal of gesture recognition is to create a system which\ncan recognize specific human gestures and use them to convey information or for\ndevice control. Hand gestures provide a separate complementary modality to\nspeech for expressing ones ideas. Information associated with hand gestures in\na conversation is degree,discourse structure, spatial and temporal structure.\nThe approaches present can be mainly divided into Data-Glove Based and Vision\nBased approaches. An important face feature point is the nose tip. Since nose\nis the highest protruding point from the face. Besides that, it is not affected\nby facial expressions.Another important function of the nose is that it is able\nto indicate the head pose. Knowledge of the nose location will enable us to\nalign an unknown 3D face with those in a face database. Eye detection is\ndivided into eye position detection and eye contour detection. Existing works\nin eye detection can be classified into two major categories: traditional\nimage-based passive approaches and the active IR based approaches. The former\nuses intensity and shape of eyes for detection and the latter works on the\nassumption that eyes have a reflection under near IR illumination and produce\nbright/dark pupil effect. The traditional methods can be broadly classified\ninto three categories: template based methods,appearance based methods and\nfeature based methods. The purpose of this paper is to compare various human\nGesture recognition systems for interfacing machines directly to human wits\nwithout any corporeal media in an ambient environment.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 02:54:24 GMT"}], "update_date": "2010-12-02", "authors_parsed": [["C", "Harshith", ""], ["Shastry", "Karthik R.", ""], ["Ravindran", "Manoj", ""], ["Srikanth", "M. V. V. N. S.", ""], ["Lakshmikhanth", "Naveen", ""]]}, {"id": "1012.0223", "submitter": "A Kannan", "authors": "A. Kannan, V. Mohan, N. Anbazhagan", "title": "An Effective Method of Image Retrieval using Image Mining Techniques", "comments": null, "journal-ref": null, "doi": "10.5121/ijma.2010.2402", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present research scholars are having keen interest in doing their\nresearch activities in the area of Data mining all over the world. Especially,\n[13]Mining Image data is the one of the essential features in this present\nscenario since image data plays vital role in every aspect of the system such\nas business for marketing, hospital for surgery, engineering for construction,\nWeb for publication and so on. The other area in the Image mining system is the\nContent-Based Image Retrieval (CBIR) which performs retrieval based on the\nsimilarity defined in terms of extracted features with more objectiveness. The\ndrawback in CBIR is the features of the query image alone are considered.\nHence, a new technique called Image retrieval based on optimum clusters is\nproposed for improving user interaction with image retrieval systems by fully\nexploiting the similarity information. The index is created by describing the\nimages according to their color characteristics, with compact feature vectors,\nthat represent typical color distributions [12].\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 15:34:50 GMT"}], "update_date": "2010-12-02", "authors_parsed": [["Kannan", "A.", ""], ["Mohan", "V.", ""], ["Anbazhagan", "N.", ""]]}, {"id": "1012.1184", "submitter": "Lei Zhang Dr.", "authors": "Weisheng Dong, Lei Zhang, Guangming Shi, Xiaolin Wu", "title": "Image Deblurring and Super-resolution by Adaptive Sparse Domain\n  Selection and Adaptive Regularization", "comments": "35 pages. This paper is under review in IEEE TIP", "journal-ref": null, "doi": "10.1109/TIP.2011.2108306", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a powerful statistical image modeling technique, sparse representation has\nbeen successfully used in various image restoration applications. The success\nof sparse representation owes to the development of l1-norm optimization\ntechniques, and the fact that natural images are intrinsically sparse in some\ndomain. The image restoration quality largely depends on whether the employed\nsparse domain can represent well the underlying image. Considering that the\ncontents can vary significantly across different images or different patches in\na single image, we propose to learn various sets of bases from a pre-collected\ndataset of example image patches, and then for a given patch to be processed,\none set of bases are adaptively selected to characterize the local sparse\ndomain. We further introduce two adaptive regularization terms into the sparse\nrepresentation framework. First, a set of autoregressive (AR) models are\nlearned from the dataset of example image patches. The best fitted AR models to\na given patch are adaptively selected to regularize the image local structures.\nSecond, the image non-local self-similarity is introduced as another\nregularization term. In addition, the sparsity regularization parameter is\nadaptively estimated for better image restoration performance. Extensive\nexperiments on image deblurring and super-resolution validate that by using\nadaptive sparse domain selection and adaptive regularization, the proposed\nmethod achieves much better results than many state-of-the-art algorithms in\nterms of both PSNR and visual perception.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 14:37:14 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Dong", "Weisheng", ""], ["Zhang", "Lei", ""], ["Shi", "Guangming", ""], ["Wu", "Xiaolin", ""]]}, {"id": "1012.1193", "submitter": "Lei Zhang Dr.", "authors": "Bo Peng, Lei Zhang, David Zhang", "title": "Automatic Image Segmentation by Dynamic Region Merging", "comments": "28 pages. This paper is under review in IEEE TIP", "journal-ref": null, "doi": "10.1109/TIP.2011.2157512", "report-no": null, "categories": "cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the automatic image segmentation problem in a region\nmerging style. With an initially over-segmented image, in which the many\nregions (or super-pixels) with homogeneous color are detected, image\nsegmentation is performed by iteratively merging the regions according to a\nstatistical test. There are two essential issues in a region merging algorithm:\norder of merging and the stopping criterion. In the proposed algorithm, these\ntwo issues are solved by a novel predicate, which is defined by the sequential\nprobability ratio test (SPRT) and the maximum likelihood criterion. Starting\nfrom an over-segmented image, neighboring regions are progressively merged if\nthere is an evidence for merging according to this predicate. We show that the\nmerging order follows the principle of dynamic programming. This formulates\nimage segmentation as an inference problem, where the final segmentation is\nestablished based on the observed image. We also prove that the produced\nsegmentation satisfies certain global properties. In addition, a faster\nalgorithm is developed to accelerate the region merging process, which\nmaintains a nearest neighbor graph in each iteration. Experiments on real\nnatural images are conducted to demonstrate the performance of the proposed\ndynamic region merging algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 14:56:12 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Peng", "Bo", ""], ["Zhang", "Lei", ""], ["Zhang", "David", ""]]}, {"id": "1012.2138", "submitter": "Vasileios Zografos", "authors": "Vasileios Zografos, Klas Nordberg, Liam Ellis", "title": "Sparse motion segmentation using multiple six-point consistencies", "comments": null, "journal-ref": "VECTaR workshop (with ACCV) 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for segmenting an arbitrary number of moving objects in\nimage sequences using the geometry of 6 points in 2D to infer motion\nconsistency. The method has been evaluated on the Hopkins 155 database and\nsurpasses current state-of-the-art methods such as SSC, both in terms of\noverall performance on two and three motions but also in terms of maximum\nerrors. The method works by finding initial clusters in the spatial domain, and\nthen classifying each remaining point as belonging to the cluster that\nminimizes a motion consistency score. In contrast to most other motion\nsegmentation methods that are based on an affine camera model, the proposed\nmethod is fully projective.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 22:56:02 GMT"}, {"version": "v2", "created": "Mon, 13 Dec 2010 08:19:01 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Zografos", "Vasileios", ""], ["Nordberg", "Klas", ""], ["Ellis", "Liam", ""]]}, {"id": "1012.2491", "submitter": "Vasileios Zografos", "authors": "Vasileios Zografos and Bernard Buxton", "title": "Affine Invariant, Model-Based Object Recognition Using Robust Metrics\n  and Bayesian Statistics", "comments": null, "journal-ref": "Image Analysis and Recognition Lecture Notes in Computer Science,\n  2005, Volume 3656/2005, 407-414", "doi": "10.1007/11559573_51", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of model-based object recognition for intensity images\nand attempt to address some of the shortcomings of existing Bayesian methods,\nsuch as unsuitable priors and the treatment of residuals with a non-robust\nerror norm. We do so by using a refor- mulation of the Huber metric and\ncarefully chosen prior distributions. Our proposed method is invariant to\n2-dimensional affine transforma- tions and, because it is relatively easy to\ntrain and use, it is suited for general object matching problems.\n", "versions": [{"version": "v1", "created": "Sat, 11 Dec 2010 21:48:51 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Zografos", "Vasileios", ""], ["Buxton", "Bernard", ""]]}, {"id": "1012.2603", "submitter": "Chunhua Shen", "authors": "Hanxi Li, Chunhua Shen, and Qinfeng Shi", "title": "Real-time Visual Tracking Using Sparse Representation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $\\ell_1$ tracker obtains robustness by seeking a sparse representation of\nthe tracking object via $\\ell_1$ norm minimization \\cite{Xue_ICCV_09_Track}.\nHowever, the high computational complexity involved in the $ \\ell_1 $ tracker\nrestricts its further applications in real time processing scenario. Hence we\npropose a Real Time Compressed Sensing Tracking (RTCST) by exploiting the\nsignal recovery power of Compressed Sensing (CS). Dimensionality reduction and\na customized Orthogonal Matching Pursuit (OMP) algorithm are adopted to\naccelerate the CS tracking. As a result, our algorithm achieves a real-time\nspeed that is up to $6,000$ times faster than that of the $\\ell_1$ tracker.\nMeanwhile, RTCST still produces competitive (sometimes even superior) tracking\naccuracy comparing to the existing $\\ell_1$ tracker. Furthermore, for a\nstationary camera, a further refined tracker is designed by integrating a\nCS-based background model (CSBM). This CSBM-equipped tracker coined as RTCST-B,\noutperforms most state-of-the-arts with respect to both accuracy and\nrobustness. Finally, our experimental results on various video sequences, which\nare verified by a new metric---Tracking Success Probability (TSP), show the\nexcellence of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 12 Dec 2010 23:41:56 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Li", "Hanxi", ""], ["Shen", "Chunhua", ""], ["Shi", "Qinfeng", ""]]}, {"id": "1012.3216", "submitter": "Arvind Ganesh", "authors": "Zhengdong Zhang, Arvind Ganesh, Xiao Liang, Yi Ma", "title": "TILT: Transform Invariant Low-rank Textures", "comments": "Submitted to IJCV. Conference version presented at ACCV 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how to efficiently and effectively extract a class of\n\"low-rank textures\" in a 3D scene from 2D images despite significant\ncorruptions and warping. The low-rank textures capture geometrically meaningful\nstructures in an image, which encompass conventional local features such as\nedges and corners as well as all kinds of regular, symmetric patterns\nubiquitous in urban environments and man-made objects. Our approach to finding\nthese low-rank textures leverages the recent breakthroughs in convex\noptimization that enable robust recovery of a high-dimensional low-rank matrix\ndespite gross sparse errors. In the case of planar regions with significant\naffine or projective deformation, our method can accurately recover both the\nintrinsic low-rank texture and the precise domain transformation, and hence the\n3D geometry and appearance of the planar regions. Extensive experimental\nresults demonstrate that this new technique works effectively for many regular\nand near-regular patterns or objects that are approximately low-rank, such as\nsymmetrical patterns, building facades, printed texts, and human faces.\n", "versions": [{"version": "v1", "created": "Wed, 15 Dec 2010 02:55:25 GMT"}], "update_date": "2010-12-16", "authors_parsed": [["Zhang", "Zhengdong", ""], ["Ganesh", "Arvind", ""], ["Liang", "Xiao", ""], ["Ma", "Yi", ""]]}, {"id": "1012.3656", "submitter": "Stephen Luttrell", "authors": "Stephen Luttrell", "title": "Adaptive Cluster Expansion (ACE): A Multilayer Network for Estimating\n  Probability Density Functions", "comments": "20 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an adaptive hierarchical method of estimating high dimensional\nprobability density functions. We call this method of density estimation the\n\"adaptive cluster expansion\" or ACE for short. We present an application of\nthis approach, based on a multilayer topographic mapping network, that\nadaptively estimates the joint probability density function of the pixel values\nof an image, and presents this result as a \"probability image\". We apply this\nto the problem of identifying statistically anomalous regions in otherwise\nstatistically homogeneous images.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 16:21:42 GMT"}], "update_date": "2010-12-17", "authors_parsed": [["Luttrell", "Stephen", ""]]}, {"id": "1012.3705", "submitter": "Stephen Luttrell", "authors": "Stephen Luttrell", "title": "Stochastic Vector Quantisers", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a stochastic generalisation of the standard Linde-Buzo-Gray\n(LBG) approach to vector quantiser (VQ) design is presented, in which the\nencoder is implemented as the sampling of a vector of code indices from a\nprobability distribution derived from the input vector, and the decoder is\nimplemented as a superposition of reconstruction vectors, and the stochastic VQ\nis optimised using a minimum mean Euclidean reconstruction distortion\ncriterion, as in the LBG case. Numerical simulations are used to demonstrate\nhow this leads to self-organisation of the stochastic VQ, where different\nstochastically sampled code indices become associated with different input\nsubspaces. This property may be used to automate the process of splitting\nhigh-dimensional input vectors into low-dimensional blocks before encoding\nthem.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 18:10:46 GMT"}], "update_date": "2010-12-17", "authors_parsed": [["Luttrell", "Stephen", ""]]}, {"id": "1012.3724", "submitter": "Stephen Luttrell", "authors": "Stephen Luttrell", "title": "The Development of Dominance Stripes and Orientation Maps in a\n  Self-Organising Visual Cortex Network (VICON)", "comments": "33 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A self-organising neural network is presented that is based on a rigorous\nBayesian analysis of the information contained in individual neural firing\nevents. This leads to a visual cortex network (VICON) that has many of the\nproperties emerge when a mammalian visual cortex is exposed to data arriving\nfrom two imaging sensors (i.e. the two retinae), such as dominance stripes and\norientation maps.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 19:30:20 GMT"}], "update_date": "2010-12-17", "authors_parsed": [["Luttrell", "Stephen", ""]]}, {"id": "1012.3802", "submitter": "Lin Wu", "authors": "Lin Wu and Yang Wang", "title": "Detecting Image Forgeries using Geometric Cues", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This chapter presents a framework for detecting fake regions by using various\nmethods including watermarking technique and blind approaches. In particular,\nwe describe current categories on blind approaches which can be divided into\nfive: pixel-based techniques, format-based techniques, camera-based techniques,\nphysically-based techniques and geometric-based techniques. Then we take a\nsecond look on the geometric-based techniques and further categorize them in\ndetail. In the following section, the state-of-the-art methods involved in the\ngeometric technique are elaborated.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 03:27:54 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Wu", "Lin", ""], ["Wang", "Yang", ""]]}, {"id": "1012.3951", "submitter": "Alex Bronstein", "authors": "Roee Litman, Alex M. Bronstein, Michael M. Bronstein", "title": "Diffusion-geometric maximally stable component detection in deformable\n  shapes", "comments": null, "journal-ref": null, "doi": "10.1016/j.cag.2011.03.011", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximally stable component detection is a very popular method for feature\nanalysis in images, mainly due to its low computation cost and high\nrepeatability. With the recent advance of feature-based methods in geometric\nshape analysis, there is significant interest in finding analogous approaches\nin the 3D world. In this paper, we formulate a diffusion-geometric framework\nfor stable component detection in non-rigid 3D shapes, which can be used for\ngeometric feature detection and description. A quantitative evaluation of our\nmethod on the SHREC'10 feature detection benchmark shows its potential as a\nsource of high-quality features.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 18:23:35 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Litman", "Roee", ""], ["Bronstein", "Alex M.", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "1012.4116", "submitter": "Gilad Lerman Dr", "authors": "Gilad Lerman and Teng Zhang", "title": "lp-Recovery of the Most Significant Subspace among Multiple Subspaces\n  with Outliers", "comments": "This is a revised version of the part of 1002.1994 that deals with\n  single subspace recovery. V3: Improved estimates (in particular for Lemma 3.1\n  and for estimates relying on it), asymptotic dependence of probabilities and\n  constants on D and d and further clarifications; for simplicity it assumes\n  uniform distributions on spheres. V4: minor revision for the published\n  version", "journal-ref": "Constructive Approximation, December 2014, Volume 40, Issue 3, pp\n  329-385", "doi": "10.1007/s00365-014-9242-6", "report-no": null, "categories": "stat.ML cs.CV math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assume data sampled from a mixture of d-dimensional linear subspaces with\nspherically symmetric distributions within each subspace and an additional\noutlier component with spherically symmetric distribution within the ambient\nspace (for simplicity we may assume that all distributions are uniform on their\ncorresponding unit spheres). We also assume mixture weights for the different\ncomponents. We say that one of the underlying subspaces of the model is most\nsignificant if its mixture weight is higher than the sum of the mixture weights\nof all other subspaces. We study the recovery of the most significant subspace\nby minimizing the lp-averaged distances of data points from d-dimensional\nsubspaces, where p>0. Unlike other lp minimization problems, this minimization\nis non-convex for all p>0 and thus requires different methods for its analysis.\nWe show that if 0<p<=1, then for any fraction of outliers the most significant\nsubspace can be recovered by lp minimization with overwhelming probability\n(which depends on the generating distribution and its parameters). We show that\nwhen adding small noise around the underlying subspaces the most significant\nsubspace can be nearly recovered by lp minimization for any 0<p<=1 with an\nerror proportional to the noise level. On the other hand, if p>1 and there is\nmore than one underlying subspace, then with overwhelming probability the most\nsignificant subspace cannot be recovered or nearly recovered. This last result\ndoes not require spherically symmetric outliers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Dec 2010 20:11:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2012 19:26:55 GMT"}, {"version": "v3", "created": "Thu, 15 Aug 2013 10:45:42 GMT"}, {"version": "v4", "created": "Mon, 13 Jan 2014 14:05:36 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["Lerman", "Gilad", ""], ["Zhang", "Teng", ""]]}, {"id": "1012.4126", "submitter": "Stephen Luttrell", "authors": "Stephen Luttrell", "title": "Self-Organising Stochastic Encoders", "comments": "23 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The processing of mega-dimensional data, such as images, scales linearly with\nimage size only if fixed size processing windows are used. It would be very\nuseful to be able to automate the process of sizing and interconnecting the\nprocessing windows. A stochastic encoder that is an extension of the standard\nLinde-Buzo-Gray vector quantiser, called a stochastic vector quantiser (SVQ),\nincludes this required behaviour amongst its emergent properties, because it\nautomatically splits the input space into statistically independent subspaces,\nwhich it then separately encodes. Various optimal SVQs have been obtained, both\nanalytically and numerically. Analytic solutions which demonstrate how the\ninput space is split into independent subspaces may be obtained when an SVQ is\nused to encode data that lives on a 2-torus (e.g. the superposition of a pair\nof uncorrelated sinusoids). Many numerical solutions have also been obtained,\nusing both SVQs and chains of linked SVQs: (1) images of multiple independent\ntargets (encoders for single targets emerge), (2) images of multiple correlated\ntargets (various types of encoder for single and multiple targets emerge), (3)\nsuperpositions of various waveforms (encoders for the separate waveforms emerge\n- this is a type of independent component analysis (ICA)), (4) maternal and\nfoetal ECGs (another example of ICA), (5) images of textures (orientation maps\nand dominance stripes emerge). Overall, SVQs exhibit a rich variety of\nself-organising behaviour, which effectively discovers the internal structure\nof the training data. This should have an immediate impact on \"intelligent\"\ncomputation, because it reduces the need for expert human intervention in the\ndesign of data processing algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 18 Dec 2010 22:34:21 GMT"}], "update_date": "2010-12-21", "authors_parsed": [["Luttrell", "Stephen", ""]]}, {"id": "1012.4173", "submitter": "Stephen Luttrell", "authors": "S P Luttrell", "title": "A Self-Organising Neural Network for Processing Data from Multiple\n  Sensors", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how a folded Markov chain network can be applied to the\nproblem of processing data from multiple sensors, with an emphasis on the\nspecial case of 2 sensors. It is necessary to design the network so that it can\ntransform a high dimensional input vector into a posterior probability, for\nwhich purpose the partitioned mixture distribution network is ideally suited.\nThe underlying theory is presented in detail, and a simple numerical simulation\nis given that shows the emergence of ocular dominance stripes.\n", "versions": [{"version": "v1", "created": "Sun, 19 Dec 2010 14:48:55 GMT"}], "update_date": "2010-12-21", "authors_parsed": [["Luttrell", "S P", ""]]}, {"id": "1012.4521", "submitter": "Aaron Keys", "authors": "Aaron S. Keys, Christopher R. Iacovella and Sharon C. Glotzer", "title": "Characterizing Structure Through Shape Matching and Applications to Self\n  Assembly", "comments": "19 pages, 9 figures", "journal-ref": "Annual Review of Condensed Matter Physics, Vol. 2 (2011)", "doi": "10.1146/annurev-conmatphys-062910-140526", "report-no": null, "categories": "cond-mat.soft cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural quantities such as order parameters and correlation functions are\noften employed to gain insight into the physical behavior and properties of\ncondensed matter systems. While standard quantities for characterizing\nstructure exist, often they are insufficient for treating problems in the\nemerging field of nano and microscale self-assembly, where the structures\nencountered may be complex and unusual. The computer science field of \"shape\nmatching\" offers a robust solution to this problem by defining diverse methods\nfor quantifying the similarity between arbitrarily complex shapes. Most order\nparameters and correlation functions used in condensed matter apply a specific\nmeasure of structural similarity within the context of a broader scheme. By\nsubstituting shape matching quantities for traditional quantities, we retain\nthe essence of the broader scheme, but extend its applicability to more complex\nstructures. Here we review some standard shape matching techniques and discuss\nhow they might be used to create highly flexible structural metrics for diverse\nsystems such as self-assembled matter. We provide three proof-of-concept\nexample problems applying shape matching methods to identifying local and\nglobal structures, and tracking structural transitions in complex assembled\nsystems. The shape matching methods reviewed here are applicable to a wide\nrange of condensed matter systems, both simulated and experimental, provided\nparticle positions are known or can be accurately imaged.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 01:04:19 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Keys", "Aaron S.", ""], ["Iacovella", "Christopher R.", ""], ["Glotzer", "Sharon C.", ""]]}, {"id": "1012.4527", "submitter": "Aaron Keys", "authors": "Aaron S. Keys, Christopher R. Iacovella and Sharon C. Glotzer", "title": "Harmonic Order Parameters for Characterizing Complex Particle\n  Morphologies", "comments": "13 pages, 9 figures, J. Chem. Phys., submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cs.CV physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Order parameters based on spherical harmonics and Fourier coefficients\nalready play a significant role in condensed matter research in the context of\nsystems of spherical or point particles. Here, we extend these types of order\nparameter to more complex shapes, such as those encountered in nanoscale\nself-assembly applications. To do so, we build on a powerful set of techniques\nthat originate in the computer science field of \"shape matching.\" We\ndemonstrate how shape matching techniques can be applied to identify unknown\nstructures and create highly-specialized \\textit{ad hoc} order parameters.\nAdditionally, we investigate the special symmetry properties of harmonic\ndescriptors, and demonstrate how they can be exploited to provide optimal\nsolutions to certain classes of problems. Our techniques can be applied to\nparticle systems in general, both simulated and experimental, provided the\nparticle positions are known.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 01:51:13 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Keys", "Aaron S.", ""], ["Iacovella", "Christopher R.", ""], ["Glotzer", "Sharon C.", ""]]}, {"id": "1012.5208", "submitter": "Nadia Baaziz", "authors": "Nadia Baaziz, Omar Abahmane and Rokia Missaoui", "title": "Texture feature extraction in the spatial-frequency domain for\n  content-based image retrieval", "comments": "19 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of large scale multimedia databases has led to great challenges in\ncontent-based image retrieval (CBIR). Even though CBIR is considered an\nemerging field of research, however it constitutes a strong background for new\nmethodologies and systems implementations. Therefore, many research\ncontributions are focusing on techniques enabling higher image retrieval\naccuracy while preserving low level of computational complexity. Image\nretrieval based on texture features is receiving special attention because of\nthe omnipresence of this visual feature in most real-world images. This paper\nhighlights the state-of-the-art and current progress relevant to texture-based\nimage retrieval and spatial-frequency image representations. In particular, it\ngives an overview of statistical methodologies and techniques employed for\ntexture feature extraction using most popular spatial-frequency image\ntransforms, namely discrete wavelets, Gabor wavelets, dual-tree complex wavelet\nand contourlets. Indications are also given about used similarity measurement\nfunctions and most important achieved results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Dec 2010 14:10:25 GMT"}], "update_date": "2010-12-24", "authors_parsed": [["Baaziz", "Nadia", ""], ["Abahmane", "Omar", ""], ["Missaoui", "Rokia", ""]]}, {"id": "1012.5933", "submitter": "Dan Raviv", "authors": "Dan Raviv, Alexander M. Bronstein, Michael M. Bronstein, Ron Kimmel,\n  Nir Sochen", "title": "Affine-invariant diffusion geometry for the analysis of deformable 3D\n  shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an (equi-)affine invariant diffusion geometry by which surfaces\nthat go through squeeze and shear transformations can still be properly\nanalyzed. The definition of an affine invariant metric enables us to construct\nan invariant Laplacian from which local and global geometric structures are\nextracted. Applications of the proposed framework demonstrate its power in\ngeneralizing and enriching the existing set of tools for shape analysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Dec 2010 13:11:41 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Raviv", "Dan", ""], ["Bronstein", "Alexander M.", ""], ["Bronstein", "Michael M.", ""], ["Kimmel", "Ron", ""], ["Sochen", "Nir", ""]]}, {"id": "1012.5936", "submitter": "Dan Raviv", "authors": "Dan Raviv, Alexander M. Bronstein, Michael M. Bronstein, Ron Kimmel,\n  Nir Sochen", "title": "Affine-invariant geodesic geometry of deformable 3D shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural objects can be subject to various transformations yet still preserve\nproperties that we refer to as invariants. Here, we use definitions of affine\ninvariant arclength for surfaces in R^3 in order to extend the set of existing\nnon-rigid shape analysis tools. In fact, we show that by re-defining the\nsurface metric as its equi-affine version, the surface with its modified metric\ntensor can be treated as a canonical Euclidean object on which most classical\nEuclidean processing and analysis tools can be applied. The new definition of a\nmetric is used to extend the fast marching method technique for computing\ngeodesic distances on surfaces, where now, the distances are defined with\nrespect to an affine invariant arclength. Applications of the proposed\nframework demonstrate its invariance, efficiency, and accuracy in shape\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Dec 2010 13:33:01 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Raviv", "Dan", ""], ["Bronstein", "Alexander M.", ""], ["Bronstein", "Michael M.", ""], ["Kimmel", "Ron", ""], ["Sochen", "Nir", ""]]}]