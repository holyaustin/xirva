[{"id": "0909.0481", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh, Pedro Contreras and Jean-Luc Starck", "title": "Scale-Based Gaussian Coverings: Combining Intra and Inter Mixture Models\n  in Image Segmentation", "comments": "20 pages, 5 figures", "journal-ref": "Entropy, 11 (3), 513-528, 2009", "doi": "10.3390/e11030513", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By a \"covering\" we mean a Gaussian mixture model fit to observed data.\nApproximations of the Bayes factor can be availed of to judge model fit to the\ndata within a given Gaussian mixture model. Between families of Gaussian\nmixture models, we propose the R\\'enyi quadratic entropy as an excellent and\ntractable model comparison framework. We exemplify this using the segmentation\nof an MRI image volume, based (1) on a direct Gaussian mixture model applied to\nthe marginal distribution function, and (2) Gaussian model fit through k-means\napplied to the 4D multivalued image volume furnished by the wavelet transform.\nVisual preference for one model over another is not immediate. The R\\'enyi\nquadratic entropy allows us to show clearly that one of these modelings is\nsuperior to the other.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2009 17:46:08 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Murtagh", "Fionn", ""], ["Contreras", "Pedro", ""], ["Starck", "Jean-Luc", ""]]}, {"id": "0909.1310", "submitter": "Laura Rebollo-Neira", "authors": "James Bowley and Laura Rebollo-Neira", "title": "Sparse image representation by discrete cosine/spline based dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed dictionaries generated by cosine and B-spline functions are considered.\nIt is shown that, by highly nonlinear approaches such as Orthogonal Matching\nPursuit, the discrete version of the proposed dictionaries yields a significant\ngain in the sparsity of an image representation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2009 18:50:23 GMT"}], "update_date": "2009-09-08", "authors_parsed": [["Bowley", "James", ""], ["Rebollo-Neira", "Laura", ""]]}, {"id": "0909.1605", "submitter": "Guangliang Chen", "authors": "G. Chen, S. Atev, and G. Lerman", "title": "Kernel Spectral Curvature Clustering (KSCC)", "comments": "accepted to 2009 ICCV Workshop on Dynamical Vision", "journal-ref": "Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th\n  International Conference on, 2009, pp. 765 - 772", "doi": "10.1109/ICCVW.2009.5457627", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-manifold modeling is increasingly used in segmentation and data\nrepresentation tasks in computer vision and related fields. While the general\nproblem, modeling data by mixtures of manifolds, is very challenging, several\napproaches exist for modeling data by mixtures of affine subspaces (which is\noften referred to as hybrid linear modeling). We translate some important\ninstances of multi-manifold modeling to hybrid linear modeling in embedded\nspaces, without explicitly performing the embedding but applying the kernel\ntrick. The resulting algorithm, Kernel Spectral Curvature Clustering, uses\nkernels at two levels - both as an implicit embedding method to linearize\nnonflat manifolds and as a principled method to convert a multiway affinity\nproblem into a spectral clustering one. We demonstrate the effectiveness of the\nmethod by comparing it with other state-of-the-art methods on both synthetic\ndata and a real-world problem of segmenting multiple motions from two\nperspective camera views.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2009 01:58:23 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Chen", "G.", ""], ["Atev", "S.", ""], ["Lerman", "G.", ""]]}, {"id": "0909.1608", "submitter": "Guangliang Chen", "authors": "G. Chen and G. Lerman", "title": "Motion Segmentation by SCC on the Hopkins 155 Database", "comments": "Accepted to 2009 ICCV Workshop on Dynamical Vision", "journal-ref": "Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th\n  International Conference on, 2009, pp. 759 - 764", "doi": "10.1109/ICCVW.2009.5457626", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the Spectral Curvature Clustering (SCC) algorithm to a benchmark\ndatabase of 155 motion sequences, and show that it outperforms all other\nstate-of-the-art methods. The average misclassification rate by SCC is 1.41%\nfor sequences having two motions and 4.85% for three motions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2009 02:12:22 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Chen", "G.", ""], ["Lerman", "G.", ""]]}, {"id": "0909.2017", "submitter": "Laura Rebollo-Neira", "authors": "James Bowley and Laura Rebollo-Neira", "title": "Sparsity and `Something Else': An Approach to Encrypted Image Folding", "comments": "Revised manuscript- Software for implementing the Encrypted Image\n  Folding proposed in this paper is available on\n  http://www.nonlinear-approx.info/", "journal-ref": "IEEE Signal Processing Letters, Vol. 8 No 3, 189--192, 2011", "doi": "10.1109/LSP.2011.2106496", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A property of sparse representations in relation to their capacity for\ninformation storage is discussed. It is shown that this feature can be used for\nan application that we term Encrypted Image Folding. The proposed procedure is\nrealizable through any suitable transformation. In particular, in this paper we\nillustrate the approach by recourse to the Discrete Cosine Transform and a\ncombination of redundant Cosine and Dirac dictionaries. The main advantage of\nthe proposed technique is that both storage and encryption can be achieved\nsimultaneously using simple processing steps.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2009 19:21:04 GMT"}, {"version": "v2", "created": "Tue, 26 Oct 2010 14:39:05 GMT"}, {"version": "v3", "created": "Fri, 11 Feb 2011 09:54:37 GMT"}, {"version": "v4", "created": "Wed, 1 Feb 2012 22:26:15 GMT"}, {"version": "v5", "created": "Wed, 12 Sep 2012 16:56:33 GMT"}], "update_date": "2012-09-13", "authors_parsed": [["Bowley", "James", ""], ["Rebollo-Neira", "Laura", ""]]}, {"id": "0909.2373", "submitter": "Nevin Vunka Jungum", "authors": "M. Nageshkumar, P.K. Mahesh and M.N.S. Swamy", "title": "An Efficient Secure Multimodal Biometric Fusion Using Palmprint and Face\n  Image", "comments": "International Journal of Computer Science Issues (IJCSI), Volume 1,\n  pp49-53, August 2009", "journal-ref": "M.Nageshkumar,P.K.Mahesh and M.N.S.Swamy, \"An Efficient Secure\n  Multimodal Biometric Fusion Using Palmprint and Face Image\", International\n  Journal of Computer Science Issues (IJCSI), Volume 1, pp49-53, August 2009", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometrics based personal identification is regarded as an effective method\nfor automatically recognizing, with a high confidence a person's identity. A\nmultimodal biometric systems consolidate the evidence presented by multiple\nbiometric sources and typically better recognition performance compare to\nsystem based on a single biometric modality. This paper proposes an\nauthentication method for a multimodal biometric system identification using\ntwo traits i.e. face and palmprint. The proposed system is designed for\napplication where the training data contains a face and palmprint. Integrating\nthe palmprint and face features increases robustness of the person\nauthentication. The final decision is made by fusion at matching score level\narchitecture in which features vectors are created independently for query\nmeasures and are then compared to the enrolment template, which are stored\nduring database preparation. Multimodal biometric system is developed through\nfusion of face and palmprint recognition.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2009 21:31:22 GMT"}], "update_date": "2009-09-15", "authors_parsed": [["Nageshkumar", "M.", ""], ["Mahesh", "P. K.", ""], ["Swamy", "M. N. S.", ""]]}, {"id": "0909.3123", "submitter": "Gilad Lerman Dr", "authors": "Teng Zhang, Arthur Szlam and Gilad Lerman", "title": "Median K-flats for hybrid linear modeling with many outliers", "comments": null, "journal-ref": "Proc. of 2nd IEEE International Workshop on Subspace Methods\n  (Subspace 2009), pp. 234-241 (2009)", "doi": "10.1109/ICCVW.2009.5457695", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Median K-Flats (MKF) algorithm, a simple online method for\nhybrid linear modeling, i.e., for approximating data by a mixture of flats.\nThis algorithm simultaneously partitions the data into clusters while finding\ntheir corresponding best approximating l1 d-flats, so that the cumulative l1\nerror is minimized. The current implementation restricts d-flats to be\nd-dimensional linear subspaces. It requires a negligible amount of storage, and\nits complexity, when modeling data consisting of N points in D-dimensional\nEuclidean space with K d-dimensional linear subspaces, is of order O(n K d D+n\nd^2 D), where n is the number of iterations required for convergence\n(empirically on the order of 10^4). Since it is an online algorithm, data can\nbe supplied to it incrementally and it can incrementally produce the\ncorresponding output. The performance of the algorithm is carefully evaluated\nusing synthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2009 23:09:16 GMT"}], "update_date": "2010-05-10", "authors_parsed": [["Zhang", "Teng", ""], ["Szlam", "Arthur", ""], ["Lerman", "Gilad", ""]]}, {"id": "0909.3395", "submitter": "Subhajit Karmakar Mr.", "authors": "Subhajit Karmakar and Sandip Sarkar", "title": "A possible low-level explanation of \"temporal dynamics of brightness\n  induction and White's illusion\"", "comments": "11 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based upon physiological observation on time dependent orientation\nselectivity in the cells of macaque's primary visual cortex together with the\npsychophysical studies on the tuning of orientation detectors in human vision\nwe suggest that time dependence in brightness perception can be accommodated\nthrough the time evolution of cortical contribution to the orientation tuning\nof the ODoG filter responses. A set of Difference of Gaussians functions has\nbeen used to mimic the time dependence of orientation tuning. The tuning of\norientation preference and its inversion at a later time have been considered\nin explaining qualitatively the temporal dynamics of brightness perception\nobserved in \"Brief presentations reveal the temporal dynamics of brightness\ninduction and White's illusion\" for 58 and 82 ms of stimulus exposure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2009 09:07:12 GMT"}], "update_date": "2009-09-21", "authors_parsed": [["Karmakar", "Subhajit", ""], ["Sarkar", "Sandip", ""]]}, {"id": "0909.3606", "submitter": "Vinay Jethava", "authors": "Vinay Jethava", "title": "Extension of Path Probability Method to Approximate Inference over Time", "comments": "M.Sc.(Research) Thesis, 64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  There has been a tremendous growth in publicly available digital video\nfootage over the past decade. This has necessitated the development of new\ntechniques in computer vision geared towards efficient analysis, storage and\nretrieval of such data. Many mid-level computer vision tasks such as\nsegmentation, object detection, tracking, etc. involve an inference problem\nbased on the video data available. Video data has a high degree of spatial and\ntemporal coherence. The property must be intelligently leveraged in order to\nobtain better results.\n  Graphical models, such as Markov Random Fields, have emerged as a powerful\ntool for such inference problems. They are naturally suited for expressing the\nspatial dependencies present in video data, It is however, not clear, how to\nextend the existing techniques for the problem of inference over time. This\nthesis explores the Path Probability Method, a variational technique in\nstatistical mechanics, in the context of graphical models and approximate\ninference problems. It extends the method to a general framework for problems\ninvolving inference in time, resulting in an algorithm, \\emph{DynBP}. We\nexplore the relation of the algorithm with existing techniques, and find the\nalgorithm competitive with existing approaches.\n  The main contribution of this thesis are the extended GBP algorithm, the\nextension of Path Probability Methods to the DynBP algorithm and the\nrelationship between them. We have also explored some applications in computer\nvision involving temporal evolution with promising results.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2009 23:46:21 GMT"}], "update_date": "2009-09-22", "authors_parsed": [["Jethava", "Vinay", ""]]}, {"id": "0909.3911", "submitter": "R Doomun", "authors": "Yon Ping Chen, and Tien Der Yeh", "title": "A Method for Extraction and Recognition of Isolated License Plate\n  Characters", "comments": "10 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 5, No. 1, pp. 1-10, August 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to extract and recognize isolated characters in license plates is\nproposed. In extraction stage, the proposed method detects isolated characters\nby using Difference-of-Gaussian (DOG) function, The DOG function, similar to\nLaplacian of Gaussian function, was proven to produce the most stable image\nfeatures compared to a range of other possible image functions. The candidate\ncharacters are extracted by doing connected component analysis on different\nscale DOG images. In recognition stage, a novel feature vector named\naccumulated gradient projection vector (AGPV) is used to compare the candidate\ncharacter with the standard ones. The AGPV is calculated by first projecting\npixels of similar gradient orientations onto specific axes, and then\naccumulates the projected gradient magnitudes by each axis. In the experiments,\nthe AGPVs are proven to be invariant from image scaling and rotation, and\nrobust to noise and illumination change.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2009 05:38:32 GMT"}], "update_date": "2009-09-23", "authors_parsed": [["Chen", "Yon Ping", ""], ["Der Yeh", "Tien", ""]]}, {"id": "0909.5458", "submitter": "Sheng Xu", "authors": "Robert Sheng Xu, Oleg Michailovich, Magdy Salama", "title": "Information tracking approach to segmentation of ultrasound imagery of\n  prostate", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size and geometry of the prostate are known to be pivotal quantities used\nby clinicians to assess the condition of the gland during prostate cancer\nscreening. As an alternative to palpation, an increasing number of methods for\nestimation of the above-mentioned quantities are based on using imagery data of\nprostate. The necessity to process large volumes of such data creates a need\nfor automatic segmentation tools which would allow the estimation to be carried\nout with maximum accuracy and efficiency. In particular, the use of transrectal\nultrasound (TRUS) imaging in prostate cancer screening seems to be becoming a\nstandard clinical practice due to the high benefit-to-cost ratio of this\nimaging modality. Unfortunately, the segmentation of TRUS images is still\nhampered by relatively low contrast and reduced SNR of the images, thereby\nrequiring the segmentation algorithms to incorporate prior knowledge about the\ngeometry of the gland. In this paper, a novel approach to the problem of\nsegmenting the TRUS images is described. The proposed approach is based on the\nconcept of distribution tracking, which provides a unified framework for\nmodeling and fusing image-related and morphological features of the prostate.\nMoreover, the same framework allows the segmentation to be regularized via\nusing a new type of \"weak\" shape priors, which minimally bias the estimation\nprocedure, while rendering the latter stable and robust.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2009 22:39:19 GMT"}], "update_date": "2009-10-01", "authors_parsed": [["Xu", "Robert Sheng", ""], ["Michailovich", "Oleg", ""], ["Salama", "Magdy", ""]]}, {"id": "0909.5460", "submitter": "Elad Shaked", "authors": "E. Shaked and O. Michailovich", "title": "Iterative Shrinkage Approach to Restoration of Optical Imagery", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of reconstruction of digital images from their degraded\nmeasurements is regarded as a problem of central importance in various fields\nof engineering and imaging sciences. In such cases, the degradation is\ntypically caused by the resolution limitations of an imaging device in use\nand/or by the destructive influence of measurement noise. Specifically, when\nthe noise obeys a Poisson probability law, standard approaches to the problem\nof image reconstruction are based on using fixed-point algorithms which follow\nthe methodology first proposed by Richardson and Lucy. The practice of using\nthese methods, however, shows that their convergence properties tend to\ndeteriorate at relatively high noise levels. Accordingly, in the present paper,\na novel method for de-noising and/or de-blurring of digital images corrupted by\nPoisson noise is introduced. The proposed method is derived under the\nassumption that the image of interest can be sparsely represented in the domain\nof a linear transform. Consequently, a shrinkage-based iterative procedure is\nproposed, which guarantees the solution to converge to the global maximizer of\nan associated maximum-a-posteriori criterion. It is shown in a series of both\ncomputer-simulated and real-life experiments that the proposed method\noutperforms a number of existing alternatives in terms of stability, precision,\nand computational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2009 22:33:10 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2010 17:00:21 GMT"}], "update_date": "2010-01-06", "authors_parsed": [["Shaked", "E.", ""], ["Michailovich", "O.", ""]]}, {"id": "0909.5656", "submitter": "Dragos Falie", "authors": "D. Falie", "title": "Improvements of the 3D images captured with Time-of-Flight cameras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Time-of-Flight camera's images are affected by errors due to the diffuse\n(indirect) light and to the flare light. The presented method improves the 3D\nimage reducing the distance's errors to dark surface objects. This is achieved\nby placing one or two contrast tags in the scene at different distances from\nthe ToF camera. The white and black parts of the tags are situated at the same\ndistance to the camera but the distances measured by the camera are different.\nThis difference is used to compute a correction vector. The distance to black\nsurfaces is corrected by subtracting this vector from the captured vector\nimage.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2009 18:50:24 GMT"}], "update_date": "2009-10-01", "authors_parsed": [["Falie", "D.", ""]]}]