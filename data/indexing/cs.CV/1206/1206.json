[{"id": "1206.0238", "submitter": "M. Zahid Hossain", "authors": "M. Zahid Hossain, M. Ashraful Amin, Hong Yan", "title": "Rapid Feature Extraction for Optical Character Recognition", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 16:20:41 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Hossain", "M. Zahid", ""], ["Amin", "M. Ashraful", ""], ["Yan", "Hong", ""]]}, {"id": "1206.0285", "submitter": "Jyotsna  Kumar Prof.", "authors": "J. K. Mandal and Somnath Mukhopadhyay", "title": "Image Filtering using All Neighbor Directional Weighted Pixels:\n  Optimization using Particle Swarm Optimization", "comments": "14 pages", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.2, No.4 (2011)", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel approach for de noising images corrupted by random\nvalued impulses has been proposed. Noise suppression is done in two steps. The\ndetection of noisy pixels is done using all neighbor directional weighted\npixels (ANDWP) in the 5 x 5 window. The filtering scheme is based on minimum\nvariance of the four directional pixels. In this approach, relatively recent\ncategory of stochastic global optimization technique i.e., particle swarm\noptimization (PSO) has also been used for searching the parameters of detection\nand filtering operators required for optimal performance. Results obtained\nshows better de noising and preservation of fine details for highly corrupted\nimages.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 10:36:25 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Mandal", "J. K.", ""], ["Mukhopadhyay", "Somnath", ""]]}, {"id": "1206.0338", "submitter": "Joseph  Salmon", "authors": "Joseph Salmon and Zachary Harmany and Charles-Alban Deledalle and\n  Rebecca Willett", "title": "Poisson noise reduction with non-local PCA", "comments": "erratum: Image man is wrongly name pepper in the journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photon-limited imaging arises when the number of photons collected by a\nsensor array is small relative to the number of detector elements. Photon\nlimitations are an important concern for many applications such as spectral\nimaging, night vision, nuclear medicine, and astronomy. Typically a Poisson\ndistribution is used to model these observations, and the inherent\nheteroscedasticity of the data combined with standard noise removal methods\nyields significant artifacts. This paper introduces a novel denoising algorithm\nfor photon-limited images which combines elements of dictionary learning and\nsparse patch-based representations of images. The method employs both an\nadaptation of Principal Component Analysis (PCA) for Poisson noise and recently\ndeveloped sparsity-regularized convex optimization algorithms for\nphoton-limited images. A comprehensive empirical evaluation of the proposed\nmethod helps characterize the performance of this approach relative to other\nstate-of-the-art denoising methods. The results reveal that, despite its\nconceptual simplicity, Poisson PCA-based denoising appears to be highly\ncompetitive in very low light regimes.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2012 02:44:05 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2012 09:29:18 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2012 23:39:38 GMT"}, {"version": "v4", "created": "Mon, 28 Apr 2014 13:56:09 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Salmon", "Joseph", ""], ["Harmany", "Zachary", ""], ["Deledalle", "Charles-Alban", ""], ["Willett", "Rebecca", ""]]}, {"id": "1206.1515", "submitter": "Manal Abdullah", "authors": "Manal Abdullah, Majda Wazzan and Sahar Bo-saeed", "title": "Optimizing Face Recognition Using PCA", "comments": "9 pages", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.3, No.2, March 2012, 23-31", "doi": "10.5121/ijaia.2012.3203", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principle Component Analysis PCA is a classical feature extraction and data\nrepresentation technique widely used in pattern recognition. It is one of the\nmost successful techniques in face recognition. But it has drawback of high\ncomputational especially for big size database. This paper conducts a study to\noptimize the time complexity of PCA (eigenfaces) that does not affects the\nrecognition performance. The authors minimize the participated eigenvectors\nwhich consequently decreases the computational time. A comparison is done to\ncompare the differences between the recognition time in the original algorithm\nand in the enhanced algorithm. The performance of the original and the enhanced\nproposed algorithm is tested on face94 face database. Experimental results show\nthat the recognition time is reduced by 35% by applying our proposed enhanced\nalgorithm. DET Curves are used to illustrate the experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 14:51:54 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Abdullah", "Manal", ""], ["Wazzan", "Majda", ""], ["Bo-saeed", "Sahar", ""]]}, {"id": "1206.1518", "submitter": "Manal Abdullah", "authors": "Manal A. Abdullah, Lulwah M. Al-Harigy, and Hanadi H. Al-Fraidi", "title": "Off-Line Arabic Handwriting Character Recognition Using Word\n  Segmentation", "comments": "5 pages; Journal of Computing, Volume 4, Issue 3, March 2012, ISSN\n  2151-9617", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ultimate aim of handwriting recognition is to make computers able to read\nand/or authenticate human written texts, with a performance comparable to or\neven better than that of humans. Reading means that the computer is given a\npiece of handwriting and it provides the electronic transcription of that (e.g.\nin ASCII format). Two types of handwriting: on-line and offline. The most\nimportant purpose of off-line handwriting recognition is in protection systems\nand authentication. Arabic Handwriting scripts are much more complicated in\ncomparison to Latin scripts. This paper introduces a simple and novel\nmethodology to authenticate Arabic handwriting characters. Reaching our aim, we\nbuilt our own character database. The research methodology depends on two\nstages: The first is character extraction where preprocessing the word and then\napply segmentation process to obtain the character. The second is the character\nrecognition by matching the characters comprising the word with the letters in\nthe database. Our results ensure character recognition with 81%. We eliminate\nFAR by using similarity percent between 45-55%. Our research is coded using\nMATLAB.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 15:07:08 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Abdullah", "Manal A.", ""], ["Al-Harigy", "Lulwah M.", ""], ["Al-Fraidi", "Hanadi H.", ""]]}, {"id": "1206.1552", "submitter": "Vasanth Kishorebabu Mr", "authors": "K. Vasanth and V. Jawahar Senthil Kumar", "title": "Performance Analysis of Unsymmetrical trimmed median as detector on\n  image noises and its Fpga implementation", "comments": "20 pages,17 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Paper Analyze the performance of Unsymmetrical trimmed median, which is\nused as detector for the detection of impulse noise, Gaussian noise and mixed\nnoise is proposed. The proposed algorithm uses a fixed 3x3 window for the\nincreasing noise densities. The pixels in the current window are arranged in\nsorting order using a improved snake like sorting algorithm with reduced\ncomparator. The processed pixel is checked for the occurrence of outliers, if\nthe absolute difference between processed pixels is greater than fixed\nthreshold. Under high noise densities the processed pixel is also noisy hence\nthe median is checked using the above procedure. if found true then the pixel\nis considered as noisy hence the corrupted pixel is replaced by the median of\nthe current processing window. If median is also noisy then replace the\ncorrupted pixel with unsymmetrical trimmed median else if the pixel is termed\nuncorrupted and left unaltered. The proposed algorithm (PA) is tested on\nvarying detail images for various noises. The proposed algorithm effectively\nremoves the high density fixed value impulse noise, low density random valued\nimpulse noise, low density Gaussian noise and lower proportion of mixed noise.\nThe proposed algorithm is targeted on Xc3e5000-5fg900 FPGA using Xilinx 7.1\ncompiler version which requires less number of slices, optimum speed and low\npower when compared to the other median finding architectures.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 16:49:36 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Vasanth", "K.", ""], ["Kumar", "V. Jawahar Senthil", ""]]}, {"id": "1206.2058", "submitter": "Ali Shadvar", "authors": "Ali Shadvar", "title": "Dimension Reduction by Mutual Information Discriminant Analysis", "comments": "13pages, 3 tables, International Journal of Artificial Intelligence &\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In the past few decades, researchers have proposed many discriminant analysis\n(DA) algorithms for the study of high-dimensional data in a variety of\nproblems. Most DA algorithms for feature extraction are based on\ntransformations that simultaneously maximize the between-class scatter and\nminimize the withinclass scatter matrices. This paper presents a novel DA\nalgorithm for feature extraction using mutual information (MI). However, it is\nnot always easy to obtain an accurate estimation for high-dimensional MI. In\nthis paper, we propose an efficient method for feature extraction that is based\non one-dimensional MI estimations. We will refer to this algorithm as mutual\ninformation discriminant analysis (MIDA). The performance of this proposed\nmethod was evaluated using UCI databases. The results indicate that MIDA\nprovides robust performance over different data sets with different\ncharacteristics and that MIDA always performs better than, or at least\ncomparable to, the best performing algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 21:22:50 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Shadvar", "Ali", ""]]}, {"id": "1206.2061", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hassan A. Kingravi, Fatih Celiker", "title": "Comments on \"On Approximating Euclidean Metrics by Weighted t-Cost\n  Distances in Arbitrary Dimension\"", "comments": "7 pages, 1 figure, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:1008.4870", "journal-ref": "Pattern Recognition Letters 33 (2012) 1422--1425", "doi": "10.1016/j.patrec.2012.03.002", "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mukherjee (Pattern Recognition Letters, vol. 32, pp. 824-831, 2011) recently\nintroduced a class of distance functions called weighted t-cost distances that\ngeneralize m-neighbor, octagonal, and t-cost distances. He proved that weighted\nt-cost distances form a family of metrics and derived an approximation for the\nEuclidean norm in $\\mathbb{Z}^n$. In this note we compare this approximation to\ntwo previously proposed Euclidean norm approximations and demonstrate that the\nempirical average errors given by Mukherjee are significantly optimistic in\n$\\mathbb{R}^n$. We also propose a simple normalization scheme that improves the\naccuracy of his approximation substantially with respect to both average and\nmaximum relative errors.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 22:13:45 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Celebi", "M. Emre", ""], ["Kingravi", "Hassan A.", ""], ["Celiker", "Fatih", ""]]}, {"id": "1206.2068", "submitter": "Chamberlain Fong", "authors": "Chamberlain Fong", "title": "Revolvable Indoor Panoramas Using a Rectified Azimuthal Projection", "comments": "expanded version of \"An Indoor Alternative to Stereographic Spherical\n  Panoramas\" (Bridges 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for converting an indoor spherical panorama into a\nphotograph with a simulated overhead view. The resulting image will have an\nextremely wide field of view covering up to 4{\\pi} steradians of the spherical\npanorama. We argue that our method complements the stereographic projection\ncommonly used in the \"little planet\" effect. The stereographic projection works\nwell in creating little planets of outdoor scenes; whereas our method is a\nwell-suited counterpart for indoor scenes. The main innovation of our method is\nthe introduction of a novel azimuthal map projection that can smoothly blend\nbetween the stereographic projection and the Lambert azimuthal equal-area\nprojection. Our projection has an adjustable parameter that allows one to\ncontrol and compromise between distortions in shape and distortions in size\nwithin the projected panorama. This extra control parameter gives our\nprojection the ability to produce superior results over the stereographic\nprojection.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 23:06:40 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2012 05:23:29 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2013 17:23:06 GMT"}, {"version": "v4", "created": "Mon, 2 May 2016 01:39:16 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Fong", "Chamberlain", ""]]}, {"id": "1206.2437", "submitter": "Md Sahidullah", "authors": "Md. Sahidullah, Goutam Saha", "title": "A Novel Windowing Technique for Efficient Computation of MFCC for\n  Speaker Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2012.2235067", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel family of windowing technique to compute\nMel Frequency Cepstral Coefficient (MFCC) for automatic speaker recognition\nfrom speech. The proposed method is based on fundamental property of discrete\ntime Fourier transform (DTFT) related to differentiation in frequency domain.\nClassical windowing scheme such as Hamming window is modified to obtain\nderivatives of discrete time Fourier transform coefficients. It has been\nmathematically shown that the slope and phase of power spectrum are inherently\nincorporated in newly computed cepstrum. Speaker recognition systems based on\nour proposed family of window functions are shown to attain substantial and\nconsistent performance improvement over baseline single tapered Hamming window\nas well as recently proposed multitaper windowing technique.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 04:23:38 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Sahidullah", "Md.", ""], ["Saha", "Goutam", ""]]}, {"id": "1206.2627", "submitter": "Tanaya Guha", "authors": "Tanaya Guha and Rabab K. Ward", "title": "Image Similarity Using Sparse Representation and Compression Distance", "comments": "submitted journal draft", "journal-ref": null, "doi": "10.1109/TMM.2014.2306175", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new line of research uses compression methods to measure the similarity\nbetween signals. Two signals are considered similar if one can be compressed\nsignificantly when the information of the other is known. The existing\ncompression-based similarity methods, although successful in the discrete one\ndimensional domain, do not work well in the context of images. This paper\nproposes a sparse representation-based approach to encode the information\ncontent of an image using information from the other image, and uses the\ncompactness (sparsity) of the representation as a measure of its\ncompressibility (how much can the image be compressed) with respect to the\nother image. The more sparse the representation of an image, the better it can\nbe compressed and the more it is similar to the other image. The efficacy of\nthe proposed measure is demonstrated through the high accuracies achieved in\nimage clustering, retrieval and classification.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 19:30:57 GMT"}, {"version": "v2", "created": "Tue, 7 May 2013 23:07:29 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Guha", "Tanaya", ""], ["Ward", "Rabab K.", ""]]}, {"id": "1206.2807", "submitter": "Laurent Najman", "authors": "Silvio Jamil F. Guimar\\~aes and Jean Cousty and Yukiko Kenmochi and\n  Laurent Najman", "title": "An efficient hierarchical graph based image segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical image segmentation provides region-oriented scalespace, i.e., a\nset of image segmentations at different detail levels in which the\nsegmentations at finer levels are nested with respect to those at coarser\nlevels. Most image segmentation algorithms, such as region merging algorithms,\nrely on a criterion for merging that does not lead to a hierarchy, and for\nwhich the tuning of the parameters can be difficult. In this work, we propose a\nhierarchical graph based image segmentation relying on a criterion popularized\nby Felzenzwalb and Huttenlocher. We illustrate with both real and synthetic\nimages, showing efficiency, ease of use, and robustness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 13:49:23 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Guimar\u00e3es", "Silvio Jamil F.", ""], ["Cousty", "Jean", ""], ["Kenmochi", "Yukiko", ""], ["Najman", "Laurent", ""]]}, {"id": "1206.3559", "submitter": "Saumil Srivastava", "authors": "Saumil Srivastava", "title": "Real time facial expression recognition using a novel method", "comments": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.4, No.2, April 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a novel method for Facial Expression Recognition System\nwhich performs facial expression analysis in a near real time from a live web\ncam feed. Primary objectives were to get results in a near real time with light\ninvariant, person independent and pose invariant way. The system is composed of\ntwo different entities trainer and evaluator. Each frame of video feed is\npassed through a series of steps including haar classifiers, skin detection,\nfeature extraction, feature points tracking, creating a learned Support Vector\nMachine model to classify emotions to achieve a tradeoff between accuracy and\nresult rate. A processing time of 100-120 ms per 10 frames was achieved with\naccuracy of around 60%. We measure our accuracy in terms of variety of\ninteraction and classification scenarios. We conclude by discussing relevance\nof our work to human computer interaction and exploring further measures that\ncan be taken.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 06:54:41 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Srivastava", "Saumil", ""]]}, {"id": "1206.3564", "submitter": "Nicolas Charon", "authors": "Nicolas Charon, Alain Trouv\\'e", "title": "Functional Currents : a new mathematical tool to model and analyse\n  functional shapes", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": "10.1007/s10851-012-0413-4", "report-no": null, "categories": "cs.CG cs.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of functional current as a mathematical\nframework to represent and treat functional shapes, i.e. sub-manifold supported\nsignals. It is motivated by the growing occurrence, in medical imaging and\ncomputational anatomy, of what can be described as geometrico-functional data,\nthat is a data structure that involves a deformable shape (roughly a finite\ndimensional sub manifold) together with a function defined on this shape taking\nvalue in another manifold.\n  Indeed, if mathematical currents have already proved to be very efficient\ntheoretically and numerically to model and process shapes as curves or\nsurfaces, they are limited to the manipulation of purely geometrical objects.\nWe show that the introduction of the concept of functional currents offers a\ngenuine solution to the simultaneous processing of the geometric and signal\ninformation of any functional shape. We explain how functional currents can be\nequipped with a Hilbertian norm mixing geometrical and functional content of\nfunctional shapes nicely behaving under geometrical and functional\nperturbations and paving the way to various processing algorithms. We\nillustrate this potential on two problems: the redundancy reduction of\nfunctional shapes representations through matching pursuit schemes on\nfunctional currents and the simultaneous geometric and functional registration\nof functional shapes under diffeomorphic transport.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 13:03:36 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Charon", "Nicolas", ""], ["Trouv\u00e9", "Alain", ""]]}, {"id": "1206.3594", "submitter": "Yuriy Bunyak", "authors": "Yu.A.Bunyak, O.Yu.Sofina and R.N.Kvetnyy", "title": "Blind PSF estimation and methods of deconvolution optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have shown that the left side null space of the autoregression (AR) matrix\noperator is the lexicographical presentation of the point spread function (PSF)\non condition the AR parameters are common for original and blurred images. The\nmethod of inverse PSF evaluation with regularization functional as the function\nof surface area is offered. The inverse PSF was used for primary image\nestimation. Two methods of original image estimate optimization were designed\nbasing on maximum entropy generalization of sought and blurred images\nconditional probability density and regularization. The first method uses\nbalanced variations of convolution and deconvolution transforms to obtaining\niterative schema of image optimization. The variations balance was defined by\ndynamic regularization basing on condition of iteration process convergence.\nThe regularization has dynamic character because depends on current and\nprevious image estimate variations. The second method implements the\nregularization of deconvolution optimization in curved space with metric\ndefined on image estimate surface. It is basing on target functional invariance\nto fluctuations of optimal argument value. The given iterative schemas have\nfaster convergence in comparison with known ones, so they can be used for\nreconstruction of high resolution images series in real time.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 20:51:39 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Bunyak", "Yu. A.", ""], ["Sofina", "O. Yu.", ""], ["Kvetnyy", "R. N.", ""]]}, {"id": "1206.3633", "submitter": "Koushik Mondal", "authors": "Koushik Mondal, Paramartha Dutta, Siddhartha Bhattacharyya", "title": "Feature Based Fuzzy Rule Base Design for Image Extraction", "comments": "6 pages, 5 figures, Fuzzy Rule Base; Image Extraction; Fuzzy\n  Inference System (FIS); Membership Functions; Region of Interests; Feature\n  Selection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent advancement of multimedia technologies, it becomes a major\nconcern of detecting visual attention regions in the field of image processing.\nThe popularity of the terminal devices in a heterogeneous environment of the\nmultimedia technology gives us enough scope for the betterment of image\nvisualization. Although there exist numerous methods, feature based image\nextraction becomes a popular one in the field of image processing. The\nobjective of image segmentation is the domain-independent partition of the\nimage into a set of regions, which are visually distinct and uniform with\nrespect to some property, such as grey level, texture or colour. Segmentation\nand subsequent extraction can be considered the first step and key issue in\nobject recognition, scene understanding and image analysis. Its application\narea encompasses mobile devices, industrial quality control, medical\nappliances, robot navigation, geophysical exploration, military applications,\netc. In all these areas, the quality of the final results depends largely on\nthe quality of the preprocessing work. Most of the times, acquiring\nspurious-free preprocessing data requires a lot of application cum mathematical\nintensive background works. We propose a feature based fuzzy rule guided novel\ntechnique that is functionally devoid of any external intervention during\nexecution. Experimental results suggest that this approach is an efficient one\nin comparison to different other techniques extensively addressed in\nliterature. In order to justify the supremacy of performance of our proposed\ntechnique in respect of its competitors, we take recourse to effective metrics\nlike Mean Squared Error (MSE), Mean Absolute Error (MAE) and Peak Signal to\nNoise Ratio (PSNR).\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 07:11:02 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Mondal", "Koushik", ""], ["Dutta", "Paramartha", ""], ["Bhattacharyya", "Siddhartha", ""]]}, {"id": "1206.3714", "submitter": "Santosh Kumar Divvala", "authors": "Santosh K. Divvala and Alexei A. Efros and Martial Hebert", "title": "How important are Deformable Parts in the Deformable Parts Model?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main stated contribution of the Deformable Parts Model (DPM) detector of\nFelzenszwalb et al. (over the Histogram-of-Oriented-Gradients approach of Dalal\nand Triggs) is the use of deformable parts. A secondary contribution is the\nlatent discriminative learning. Tertiary is the use of multiple components. A\ncommon belief in the vision community (including ours, before this study) is\nthat their ordering of contributions reflects the performance of detector in\npractice. However, what we have experimentally found is that the ordering of\nimportance might actually be the reverse. First, we show that by increasing the\nnumber of components, and switching the initialization step from their\naspect-ratio, left-right flipping heuristics to appearance-based clustering,\nconsiderable improvement in performance is obtained. But more intriguingly, we\nshow that with these new components, the part deformations can now be\ncompletely switched off, yet obtaining results that are almost on par with the\noriginal DPM detector. Finally, we also show initial results for using multiple\ncomponents on a different problem -- scene classification, suggesting that this\nidea might have wider applications in addition to object detection.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 23:26:38 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Divvala", "Santosh K.", ""], ["Efros", "Alexei A.", ""], ["Hebert", "Martial", ""]]}, {"id": "1206.3975", "submitter": "Ivan Viola", "authors": "{\\AA}smund Birkeland, Veronika Solteszova, Dieter H\\\"onigmann, Odd\n  Helge Gilja, Svein Brekke, Timo Ropinski and Ivan Viola", "title": "The Ultrasound Visualization Pipeline - A Survey", "comments": null, "journal-ref": null, "doi": "10.1007/978-1-4471-6497-5_24", "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound is one of the most frequently used imaging modality in medicine.\nThe high spatial resolution, its interactive nature and non-invasiveness makes\nit the first choice in many examinations. Image interpretation is one of\nultrasound's main challenges. Much training is required to obtain a confident\nskill level in ultrasound-based diagnostics. State-of-the-art graphics\ntechniques is needed to provide meaningful visualizations of ultrasound in\nreal-time. In this paper we present the process-pipeline for ultrasound\nvisualization, including an overview of the tasks performed in the specific\nsteps. To provide an insight into the trends of ultrasound visualization\nresearch, we have selected a set of significant publications and divided them\ninto a technique-based taxonomy covering the topics pre-processing,\nsegmentation, registration, rendering and augmented reality. For the different\ntechnique types we discuss the difference between ultrasound-based techniques\nand techniques for other modalities.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 16:05:47 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Birkeland", "\u00c5smund", ""], ["Solteszova", "Veronika", ""], ["H\u00f6nigmann", "Dieter", ""], ["Gilja", "Odd Helge", ""], ["Brekke", "Svein", ""], ["Ropinski", "Timo", ""], ["Viola", "Ivan", ""]]}, {"id": "1206.4042", "submitter": "Junyan Wang", "authors": "Junyan Wang and Kap Luk Chan", "title": "The Stability of Convergence of Curve Evolutions in Vector Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Curve evolution is often used to solve computer vision problems. If the curve\nevolution fails to converge, we would not be able to solve the targeted problem\nin a lifetime. This paper studies the theoretical aspect of the convergence of\na type of general curve evolutions. We establish a theory for analyzing and\nimproving the stability of the convergence of the general curve evolutions.\nBased on this theory, we ascertain that the convergence of a known curve\nevolution is marginal stable. We propose a way of modifying the original curve\nevolution equation to improve the stability of the convergence according to our\ntheory. Numerical experiments show that the modification improves the\nconvergence of the curve evolution, which validates our theory.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 11:29:45 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Wang", "Junyan", ""], ["Chan", "Kap Luk", ""]]}, {"id": "1206.4074", "submitter": "Fuxin Li", "authors": "Fuxin Li, Guy Lebanon, Cristian Sminchisescu", "title": "A Linear Approximation to the chi^2 Kernel with Geometric Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new analytical approximation to the $\\chi^2$ kernel that\nconverges geometrically. The analytical approximation is derived with\nelementary methods and adapts to the input distribution for optimal convergence\nrate. Experiments show the new approximation leads to improved performance in\nimage classification and semantic segmentation tasks using a random Fourier\nfeature approximation of the $\\exp-\\chi^2$ kernel. Besides, out-of-core\nprincipal component analysis (PCA) methods are introduced to reduce the\ndimensionality of the approximation and achieve better performance at the\nexpense of only an additional constant factor to the time complexity. Moreover,\nwhen PCA is performed jointly on the training and unlabeled testing data,\nfurther performance improvements can be obtained. Experiments conducted on the\nPASCAL VOC 2010 segmentation and the ImageNet ILSVRC 2010 datasets show\nstatistically significant improvements over alternative approximation methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 21:05:16 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 18:38:28 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2013 19:29:18 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Li", "Fuxin", ""], ["Lebanon", "Guy", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "1206.4326", "submitter": "Vijayaraghavan Thirumalai", "authors": "Vijayaraghavan Thirumalai and Pascal Frossard", "title": "Joint Reconstruction of Multi-view Compressed Images", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2013.2240006", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distributed representation of correlated multi-view images is an\nimportant problem that arise in vision sensor networks. This paper concentrates\non the joint reconstruction problem where the distributively compressed\ncorrelated images are jointly decoded in order to improve the reconstruction\nquality of all the compressed images. We consider a scenario where the images\ncaptured at different viewpoints are encoded independently using common coding\nsolutions (e.g., JPEG, H.264 intra) with a balanced rate distribution among\ndifferent cameras. A central decoder first estimates the underlying correlation\nmodel from the independently compressed images which will be used for the joint\nsignal recovery. The joint reconstruction is then cast as a constrained convex\noptimization problem that reconstructs total-variation (TV) smooth images that\ncomply with the estimated correlation model. At the same time, we add\nconstraints that force the reconstructed images to be consistent with their\ncompressed versions. We show by experiments that the proposed joint\nreconstruction scheme outperforms independent reconstruction in terms of image\nquality, for a given target bit rate. In addition, the decoding performance of\nour proposed algorithm compares advantageously to state-of-the-art distributed\ncoding schemes based on disparity learning and on the DISCOVER.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 20:16:04 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Thirumalai", "Vijayaraghavan", ""], ["Frossard", "Pascal", ""]]}, {"id": "1206.4391", "submitter": "Koushik Mondal", "authors": "Koushik Mondal, Paramartha Dutta, Siddhartha Bhattacharyya", "title": "Gray Image extraction using Fuzzy Logic", "comments": "8 pages, 5 figures, Fuzzy Rule Base, Image Extraction, Fuzzy\n  Inference System (FIS), Membership Functions, Membership values,Image coding\n  and Processing, Soft Computing, Computer Vision Accepted and published in\n  IEEE. arXiv admin note: text overlap with arXiv:1206.3633", "journal-ref": null, "doi": "10.1109/ACCT.2012.60", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy systems concern fundamental methodology to represent and process\nuncertainty and imprecision in the linguistic information. The fuzzy systems\nthat use fuzzy rules to represent the domain knowledge of the problem are known\nas Fuzzy Rule Base Systems (FRBS). On the other hand image segmentation and\nsubsequent extraction from a noise-affected background, with the help of\nvarious soft computing methods, are relatively new and quite popular due to\nvarious reasons. These methods include various Artificial Neural Network (ANN)\nmodels (primarily supervised in nature), Genetic Algorithm (GA) based\ntechniques, intensity histogram based methods etc. providing an extraction\nsolution working in unsupervised mode happens to be even more interesting\nproblem. Literature suggests that effort in this respect appears to be quite\nrudimentary. In the present article, we propose a fuzzy rule guided novel\ntechnique that is functional devoid of any external intervention during\nexecution. Experimental results suggest that this approach is an efficient one\nin comparison to different other techniques extensively addressed in\nliterature. In order to justify the supremacy of performance of our proposed\ntechnique in respect of its competitors, we take recourse to effective metrics\nlike Mean Squared Error (MSE), Mean Absolute Error (MAE), Peak Signal to Noise\nRatio (PSNR).\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 06:16:18 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["Mondal", "Koushik", ""], ["Dutta", "Paramartha", ""], ["Bhattacharyya", "Siddhartha", ""]]}, {"id": "1206.4609", "submitter": "Roland Memisevic", "authors": "Roland Memisevic (University of Frankfurt)", "title": "On multi-view feature learning", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding is a common approach to learning local features for object\nrecognition. Recently, there has been an increasing interest in learning\nfeatures from spatio-temporal, binocular, or other multi-observation data,\nwhere the goal is to encode the relationship between images rather than the\ncontent of a single image. We provide an analysis of multi-view feature\nlearning, which shows that hidden variables encode transformations by detecting\nrotation angles in the eigenspaces shared among multiple image warps. Our\nanalysis helps explain recent experimental results showing that\ntransformation-specific features emerge when training complex cell models on\nvideos. Our analysis also shows that transformation-invariant features can\nemerge as a by-product of learning representations of transformations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:45:17 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Memisevic", "Roland", "", "University of Frankfurt"]]}, {"id": "1206.4610", "submitter": "Andreas Damianou", "authors": "Andreas Damianou (University of Sheffield), Carl Ek (KTH), Michalis\n  Titsias (University of Oxford), Neil Lawrence (University of Sheffield)", "title": "Manifold Relevance Determination", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a fully Bayesian latent variable model which\nexploits conditional nonlinear(in)-dependence structures to learn an efficient\nlatent representation. The latent space is factorized to represent shared and\nprivate information from multiple views of the data. In contrast to previous\napproaches, we introduce a relaxation to the discrete segmentation and allow\nfor a \"softly\" shared latent space. Further, Bayesian techniques allow us to\nautomatically estimate the dimensionality of the latent spaces. The model is\ncapable of capturing structure underlying extremely high dimensional spaces.\nThis is illustrated by modelling unprocessed images with tenths of thousands of\npixels. This also allows us to directly generate novel images from the trained\nmodel by sampling from the discovered latent spaces. We also demonstrate the\nmodel by prediction of human pose in an ambiguous setting. Our Bayesian\nframework allows us to perform disambiguation in a principled manner by\nincluding latent space priors which incorporate the dynamic nature of the data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 14:45:37 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Damianou", "Andreas", "", "University of Sheffield"], ["Ek", "Carl", "", "KTH"], ["Titsias", "Michalis", "", "University of Oxford"], ["Lawrence", "Neil", "", "University of Sheffield"]]}, {"id": "1206.4636", "submitter": "M. Pawan Kumar", "authors": "M. Pawan Kumar (Ecole Centrale Paris), Ben Packer (Stanford\n  University), Daphne Koller (Stanford University)", "title": "Modeling Latent Variable Uncertainty for Loss-based Learning", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of parameter estimation using weakly supervised\ndatasets, where a training sample consists of the input and a partially\nspecified annotation, which we refer to as the output. The missing information\nin the annotation is modeled using latent variables. Previous methods\noverburden a single distribution with two separate tasks: (i) modeling the\nuncertainty in the latent variables during training; and (ii) making accurate\npredictions for the output and the latent variables during testing. We propose\na novel framework that separates the demands of the two tasks using two\ndistributions: (i) a conditional distribution to model the uncertainty of the\nlatent variables for a given input-output pair; and (ii) a delta distribution\nto predict the output and the latent variables for a given input. During\nlearning, we encourage agreement between the two distributions by minimizing a\nloss-based dissimilarity coefficient. Our approach generalizes latent SVM in\ntwo important ways: (i) it models the uncertainty over latent variables instead\nof relying on a pointwise estimate; and (ii) it allows the use of loss\nfunctions that depend on latent variables, which greatly increases its\napplicability. We demonstrate the efficacy of our approach on two challenging\nproblems---object detection and action detection---using publicly available\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:15:13 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Kumar", "M. Pawan", "", "Ecole Centrale Paris"], ["Packer", "Ben", "", "Stanford\n  University"], ["Koller", "Daphne", "", "Stanford University"]]}, {"id": "1206.4641", "submitter": "Tong Lin", "authors": "Tong Lin (Peking University), Hanlin Xue (Peking University), Ling\n  Wang (LTCI, Telecom ParisTech, Paris), Hongbin Zha (Peking University)", "title": "Total Variation and Euler's Elastica for Supervised Learning", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, total variation (TV) and Euler's elastica (EE) have been\nsuccessfully applied to image processing tasks such as denoising and\ninpainting. This paper investigates how to extend TV and EE to the supervised\nlearning settings on high dimensional data. The supervised learning problem can\nbe formulated as an energy functional minimization under Tikhonov\nregularization scheme, where the energy is composed of a squared loss and a\ntotal variation smoothing (or Euler's elastica smoothing). Its solution via\nvariational principles leads to an Euler-Lagrange PDE. However, the PDE is\nalways high-dimensional and cannot be directly solved by common methods.\nInstead, radial basis functions are utilized to approximate the target\nfunction, reducing the problem to finding the linear coefficients of basis\nfunctions. We apply the proposed methods to supervised learning tasks\n(including binary classification, multi-class classification, and regression)\non benchmark data sets. Extensive experiments have demonstrated promising\nresults of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:18:20 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Lin", "Tong", "", "Peking University"], ["Xue", "Hanlin", "", "Peking University"], ["Wang", "Ling", "", "LTCI, Telecom ParisTech, Paris"], ["Zha", "Hongbin", "", "Peking University"]]}, {"id": "1206.4649", "submitter": "Pablo Sprechmann", "authors": "Alex Bronstein (Tel Aviv University), Pablo Sprechmann (University of\n  Minnesota), Guillermo Sapiro (University of Minnesota)", "title": "Learning Efficient Structured Sparse Models", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive framework for structured sparse coding and\nmodeling extending the recent ideas of using learnable fast regressors to\napproximate exact sparse codes. For this purpose, we develop a novel\nblock-coordinate proximal splitting method for the iterative solution of\nhierarchical sparse coding problems, and show an efficient feed forward\narchitecture derived from its iteration. This architecture faithfully\napproximates the exact structured sparse codes with a fraction of the\ncomplexity of the standard optimization methods. We also show that by using\ndifferent training objective functions, learnable sparse encoders are no longer\nrestricted to be mere approximants of the exact sparse code for a pre-given\ndictionary, as in earlier formulations, but can be rather used as full-featured\nsparse encoders or even modelers. A simple implementation shows several orders\nof magnitude speedup compared to the state-of-the-art at minimal performance\ndegradation, making the proposed framework suitable for real time and\nlarge-scale applications.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:23:19 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Bronstein", "Alex", "", "Tel Aviv University"], ["Sprechmann", "Pablo", "", "University of\n  Minnesota"], ["Sapiro", "Guillermo", "", "University of Minnesota"]]}, {"id": "1206.4651", "submitter": "Qinfeng Shi", "authors": "Qinfeng Shi (The University of Adelaide), Chunhua Shen (The University\n  of Adelaide), Rhys Hill (The University of Adelaide), Anton van den Hengel\n  (the University of Adelaide)", "title": "Is margin preserved after random projection?", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projections have been applied in many machine learning algorithms.\nHowever, whether margin is preserved after random projection is non-trivial and\nnot well studied. In this paper we analyse margin distortion after random\nprojection, and give the conditions of margin preservation for binary\nclassification problems. We also extend our analysis to margin for multiclass\nproblems, and provide theoretical bounds on multiclass margin on the projected\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:24:01 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Shi", "Qinfeng", "", "The University of Adelaide"], ["Shen", "Chunhua", "", "The University\n  of Adelaide"], ["Hill", "Rhys", "", "The University of Adelaide"], ["Hengel", "Anton van den", "", "the University of Adelaide"]]}, {"id": "1206.4653", "submitter": "Maya Gupta", "authors": "Nathan Parrish (University of Washington), Maya Gupta (University of\n  Washington)", "title": "Dimensionality Reduction by Local Discriminative Gaussians", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present local discriminative Gaussian (LDG) dimensionality reduction, a\nsupervised dimensionality reduction technique for classification. The LDG\nobjective function is an approximation to the leave-one-out training error of a\nlocal quadratic discriminant analysis classifier, and thus acts locally to each\ntraining point in order to find a mapping where similar data can be\ndiscriminated from dissimilar data. While other state-of-the-art linear\ndimensionality reduction methods require gradient descent or iterative solution\napproaches, LDG is solved with a single eigen-decomposition. Thus, it scales\nbetter for datasets with a large number of feature dimensions or training\nexamples. We also adapt LDG to the transfer learning setting, and show that it\nachieves good performance when the test data distribution differs from that of\nthe training data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:24:49 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Parrish", "Nathan", "", "University of Washington"], ["Gupta", "Maya", "", "University of\n  Washington"]]}, {"id": "1206.4676", "submitter": "Zhirong Yang", "authors": "Zhirong Yang (Aalto University), Erkki Oja (Aalto University)", "title": "Clustering by Low-Rank Doubly Stochastic Matrix Decomposition", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering analysis by nonnegative low-rank approximations has achieved\nremarkable progress in the past decade. However, most approximation approaches\nin this direction are still restricted to matrix factorization. We propose a\nnew low-rank learning method to improve the clustering performance, which is\nbeyond matrix factorization. The approximation is based on a two-step bipartite\nrandom walk through virtual cluster nodes, where the approximation is formed by\nonly cluster assigning probabilities. Minimizing the approximation error\nmeasured by Kullback-Leibler divergence is equivalent to maximizing the\nlikelihood of a discriminative model, which endows our method with a solid\nprobabilistic interpretation. The optimization is implemented by a relaxed\nMajorization-Minimization algorithm that is advantageous in finding good local\nminima. Furthermore, we point out that the regularized algorithm with Dirichlet\nprior only serves as initialization. Experimental results show that the new\nmethod has strong performance in clustering purity for various datasets,\nespecially for large-scale manifold data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:36:49 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Yang", "Zhirong", "", "Aalto University"], ["Oja", "Erkki", "", "Aalto University"]]}, {"id": "1206.4866", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "Portraits of Julius Caesar: a proposal for 3D analysis", "comments": "Key-words: Image processing, 3D Scanner, 3D visualization, Ancient\n  Rome, Julius Caesar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here I suggest the use of a 3D scanning and rendering to create some virtual\ncopies of ancient artifacts to study and compare them. In particular, this\napproach could be interesting for some roman marble busts, two of which are\nportraits of Julius Caesar, and the third is a realistic portrait of a man\nrecently found at Arles, France. The comparison of some images indicates that a\nthree-dimensional visualization is necessary.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 13:14:59 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1206.4880", "submitter": "Jayamohan  M", "authors": "K. Revathy and M. Jayamohan", "title": "Dynamic Domain Classification for Fractal Image Compression", "comments": "8 pages, 4 tables, 1 figure", "journal-ref": null, "doi": "10.5121/ijcsit.2012.4208", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractal image compression is attractive except for its high encoding time\nrequirements. The image is encoded as a set of contractive affine\ntransformations. The image is partitioned into non-overlapping range blocks,\nand a best matching domain block larger than the range block is identified.\nThere are many attempts on improving the encoding time by reducing the size of\nsearch pool for range-domain matching. But these methods are attempting to\nprepare a static domain pool that remains unchanged throughout the encoding\nprocess. This paper proposes dynamic preparation of separate domain pool for\neach range block. This will result in significant reduction in the encoding\ntime. The domain pool for a particular range block can be selected based upon a\nparametric value. Here we use classification based on local fractal dimension.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 17:22:49 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Revathy", "K.", ""], ["Jayamohan", "M.", ""]]}, {"id": "1206.5065", "submitter": "Sofia Zaidenberg", "authors": "Sofia Zaidenberg (INRIA Sophia Antipolis), Bernard Boulay (INRIA\n  Sophia Antipolis), Fran\\c{c}ois Bremond (INRIA Sophia Antipolis)", "title": "A generic framework for video understanding applied to group behavior\n  recognition", "comments": "(20/03/2012)", "journal-ref": "9th IEEE International Conference on Advanced Video and\n  Signal-Based Surveillance (AVSS 2012) (2012) 136 -142", "doi": "10.1109/AVSS.2012.1", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to detect and track groups of people in\nvideo-surveillance applications, and to automatically recognize their behavior.\nThis method keeps track of individuals moving together by maintaining a spacial\nand temporal group coherence. First, people are individually detected and\ntracked. Second, their trajectories are analyzed over a temporal window and\nclustered using the Mean-Shift algorithm. A coherence value describes how well\na set of people can be described as a group. Furthermore, we propose a formal\nevent description language. The group events recognition approach is\nsuccessfully validated on 4 camera views from 3 datasets: an airport, a subway,\na shopping center corridor and an entrance hall.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 06:24:30 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Zaidenberg", "Sofia", "", "INRIA Sophia Antipolis"], ["Boulay", "Bernard", "", "INRIA\n  Sophia Antipolis"], ["Bremond", "Fran\u00e7ois", "", "INRIA Sophia Antipolis"]]}, {"id": "1206.5157", "submitter": "Vini Katyal", "authors": "Vini Katyal, Aviral", "title": "Leaf vein segmentation using Odd Gabor filters and morphological\n  operations", "comments": "International Journal of Advanced Research in Computer Science Volume\n  3, No. 3, May-June 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leaf vein forms the basis of leaf characterization and classification.\nDifferent species have different leaf vein patterns. It is seen that leaf vein\nsegmentation will help in maintaining a record of all the leaves according to\ntheir specific pattern of veins thus provide an effective way to retrieve and\nstore information regarding various plant species in database as well as\nprovide an effective means to characterize plants on the basis of leaf vein\nstructure which is unique for every species. The algorithm proposes a new way\nof segmentation of leaf veins with the use of Odd Gabor filters and the use of\nmorphological operations for producing a better output. The Odd Gabor filter\ngives an efficient output and is robust and scalable as compared with the\nexisting techniques as it detects the fine fiber like veins present in leaves\nmuch more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 14:22:16 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Katyal", "Vini", ""], ["Aviral", "", ""]]}, {"id": "1206.5248", "submitter": "Joshua Dillon", "authors": "Joshua Dillon, Yi Mao, Guy Lebanon, Jian Zhang", "title": "Statistical Translation, Heat Kernels and Expected Distances", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-93-100", "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional structured data such as text and images is often poorly\nunderstood and misrepresented in statistical modeling. The standard histogram\nrepresentation suffers from high variance and performs poorly in general. We\nexplore novel connections between statistical translation, heat kernels on\nmanifolds and graphs, and expected distances. These connections provide a new\nframework for unsupervised metric learning for text documents. Experiments\nindicate that the resulting distances are generally superior to their more\nstandard counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:55:04 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Dillon", "Joshua", ""], ["Mao", "Yi", ""], ["Lebanon", "Guy", ""], ["Zhang", "Jian", ""]]}, {"id": "1206.6418", "submitter": "Honglak Lee", "authors": "Kihyuk Sohn (University of Michigan), Honglak Lee (University of\n  Michigan)", "title": "Learning Invariant Representations with Local Transformations", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning invariant representations is an important problem in machine\nlearning and pattern recognition. In this paper, we present a novel framework\nof transformation-invariant feature learning by incorporating linear\ntransformations into the feature learning algorithms. For example, we present\nthe transformation-invariant restricted Boltzmann machine that compactly\nrepresents data by its weights and their transformations, which achieves\ninvariance of the feature representation via probabilistic max pooling. In\naddition, we show that our transformation-invariant feature learning framework\ncan also be extended to other unsupervised learning methods, such as\nautoencoders or sparse coding. We evaluate our method on several image\nclassification benchmark datasets, such as MNIST variations, CIFAR-10, and\nSTL-10, and show competitive or superior classification performance when\ncompared to the state-of-the-art. Furthermore, our method achieves\nstate-of-the-art performance on phone classification tasks with the TIMIT\ndataset, which demonstrates wide applicability of our proposed algorithms to\nother domains.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Sohn", "Kihyuk", "", "University of Michigan"], ["Lee", "Honglak", "", "University of\n  Michigan"]]}, {"id": "1206.6429", "submitter": "Deepti Pachauri", "authors": "Deepti Pachauri (University of Wisconsin Madison), Maxwell Collins\n  (University of Wisconsin Madison), Vikas SIngh (University of Wisconsin\n  Madison), Risi Kondor (University of Chicago)", "title": "Incorporating Domain Knowledge in Matching Problems via Harmonic\n  Analysis", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching one set of objects to another is a ubiquitous task in machine\nlearning and computer vision that often reduces to some form of the quadratic\nassignment problem (QAP). The QAP is known to be notoriously hard, both in\ntheory and in practice. Here, we investigate if this difficulty can be\nmitigated when some additional piece of information is available: (a) that all\nQAP instances of interest come from the same application, and (b) the correct\nsolution for a set of such QAP instances is given. We propose a new approach to\naccelerate the solution of QAPs based on learning parameters for a modified\nobjective function from prior QAP instances. A key feature of our approach is\nthat it takes advantage of the algebraic structure of permutations, in\nconjunction with special methods for optimizing functions over the symmetric\ngroup Sn in Fourier space. Experiments show that in practical domains the new\nmethod can outperform existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Pachauri", "Deepti", "", "University of Wisconsin Madison"], ["Collins", "Maxwell", "", "University of Wisconsin Madison"], ["SIngh", "Vikas", "", "University of Wisconsin\n  Madison"], ["Kondor", "Risi", "", "University of Chicago"]]}, {"id": "1206.6437", "submitter": "Matthias Seeger", "authors": "Young Jun Ko (Ecole Polytechnique Federale de Lausanne), Matthias\n  Seeger (Ecole Polytechnique Federale de Lausanne)", "title": "Large Scale Variational Bayesian Inference for Structured Scale Mixture\n  Models", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural image statistics exhibit hierarchical dependencies across multiple\nscales. Representing such prior knowledge in non-factorial latent tree models\ncan boost performance of image denoising, inpainting, deconvolution or\nreconstruction substantially, beyond standard factorial \"sparse\" methodology.\nWe derive a large scale approximate Bayesian inference algorithm for linear\nmodels with non-factorial (latent tree-structured) scale mixture priors.\nExperimental results on a range of denoising and inpainting problems\ndemonstrate substantially improved performance compared to MAP estimation or to\ninference with factorial priors.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Ko", "Young Jun", "", "Ecole Polytechnique Federale de Lausanne"], ["Seeger", "Matthias", "", "Ecole Polytechnique Federale de Lausanne"]]}, {"id": "1206.6445", "submitter": "Yichuan Tang", "authors": "Yichuan Tang (University of Toronto), Ruslan Salakhutdinov (University\n  of Toronto), Geoffrey Hinton (University of Toronto)", "title": "Deep Lambertian Networks", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual perception is a challenging problem in part due to illumination\nvariations. A possible solution is to first estimate an illumination invariant\nrepresentation before using it for recognition. The object albedo and surface\nnormals are examples of such representations. In this paper, we introduce a\nmultilayer generative model where the latent variables include the albedo,\nsurface normals, and the light source. Combining Deep Belief Nets with the\nLambertian reflectance assumption, our model can learn good priors over the\nalbedo from 2D images. Illumination variations can be explained by changing\nonly the lighting latent variable in our model. By transferring learned\nknowledge from similar objects, albedo and surface normals estimation from a\nsingle image is possible in our model. Experiments demonstrate that our model\nis able to generalize as well as improve over standard baselines in one-shot\nface recognition.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Tang", "Yichuan", "", "University of Toronto"], ["Salakhutdinov", "Ruslan", "", "University\n  of Toronto"], ["Hinton", "Geoffrey", "", "University of Toronto"]]}, {"id": "1206.6447", "submitter": "Gael Varoquaux", "authors": "Gael Varoquaux (INRIA), Alexandre Gramfort (INRIA), Bertrand Thirion\n  (INRIA)", "title": "Small-sample Brain Mapping: Sparse Recovery on Spatially Correlated\n  Designs with Randomization and Clustering", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional neuroimaging can measure the brain?s response to an external\nstimulus. It is used to perform brain mapping: identifying from these\nobservations the brain regions involved. This problem can be cast into a linear\nsupervised learning task where the neuroimaging data are used as predictors for\nthe stimulus. Brain mapping is then seen as a support recovery problem. On\nfunctional MRI (fMRI) data, this problem is particularly challenging as i) the\nnumber of samples is small due to limited acquisition time and ii) the\nvariables are strongly correlated. We propose to overcome these difficulties\nusing sparse regression models over new variables obtained by clustering of the\noriginal variables. The use of randomization techniques, e.g. bootstrap\nsamples, and clustering of the variables improves the recovery properties of\nsparse methods. We demonstrate the benefit of our approach on an extensive\nsimulation study as well as two fMRI datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Varoquaux", "Gael", "", "INRIA"], ["Gramfort", "Alexandre", "", "INRIA"], ["Thirion", "Bertrand", "", "INRIA"]]}, {"id": "1206.6462", "submitter": "Yun Jiang", "authors": "Yun Jiang (Cornell University), Marcus Lim (Cornell University),\n  Ashutosh Saxena (Cornell University)", "title": "Learning Object Arrangements in 3D Scenes using Human Context", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning object arrangements in a 3D scene. The\nkey idea here is to learn how objects relate to human poses based on their\naffordances, ease of use and reachability. In contrast to modeling\nobject-object relationships, modeling human-object relationships scales\nlinearly in the number of objects. We design appropriate density functions\nbased on 3D spatial features to capture this. We learn the distribution of\nhuman poses in a scene using a variant of the Dirichlet process mixture model\nthat allows sharing of the density function parameters across the same object\ntypes. Then we can reason about arrangements of the objects in the room based\non these meaningful human poses. In our extensive experiments on 20 different\nrooms with a total of 47 objects, our algorithm predicted correct placements\nwith an average error of 1.6 meters from ground truth. In arranging five real\nscenes, it received a score of 4.3/5 compared to 3.7 for the best baseline\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Jiang", "Yun", "", "Cornell University"], ["Lim", "Marcus", "", "Cornell University"], ["Saxena", "Ashutosh", "", "Cornell University"]]}, {"id": "1206.6482", "submitter": "Yuening Hu", "authors": "Ke Zhai (University of Maryland), Yuening Hu (University of Maryland),\n  Sinead Williamson (Carnegie Mellon University), Jordan Boyd-Graber\n  (University of Maryland)", "title": "Modeling Images using Transformed Indian Buffet Processes", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent feature models are attractive for image modeling, since images\ngenerally contain multiple objects. However, many latent feature models ignore\nthat objects can appear at different locations or require pre-segmentation of\nimages. While the transformed Indian buffet process (tIBP) provides a method\nfor modeling transformation-invariant features in unsegmented binary images,\nits current form is inappropriate for real images because of its computational\ncost and modeling assumptions. We combine the tIBP with likelihoods appropriate\nfor real images and develop an efficient inference, using the cross-correlation\nbetween images and features, that is theoretically and empirically faster than\nexisting inference techniques. Our method discovers reasonable components and\nachieve effective image reconstruction in natural images.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Zhai", "Ke", "", "University of Maryland"], ["Hu", "Yuening", "", "University of Maryland"], ["Williamson", "Sinead", "", "Carnegie Mellon University"], ["Boyd-Graber", "Jordan", "", "University of Maryland"]]}, {"id": "1206.6514", "submitter": "Wan Mohd Yaakob Wan Bejuri B.Sc. Dip", "authors": "Wan Mohd Yaakob Wan Bejuri, Mohd Murtadha Mohamad, Maimunah Sapri and\n  Mohd Adly Rosly", "title": "Investigation of Color Constancy for Ubiquitous Wireless LAN/Camera\n  Positioning: An Initial Outcome", "comments": "International Journal of Advancements in Computing Technology (IJACT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper present our color constancy investigation in the hybridization of\nWireless LAN and Camera positioning in the mobile phone. Five typical color\nconstancy schemes are analyzed in different location environment. The results\ncan be used to combine with RF signals from Wireless LAN positioning by using\nmodel fitting approach in order to establish absolute positioning output. There\nis no conventional searching algorithm required, thus it is expected to reduce\nthe complexity of computation. Finally we present our preliminary results to\nillustrate the indoor positioning algorithm performance evaluation for an\nindoor environment set-up.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 20:28:50 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Bejuri", "Wan Mohd Yaakob Wan", ""], ["Mohamad", "Mohd Murtadha", ""], ["Sapri", "Maimunah", ""], ["Rosly", "Mohd Adly", ""]]}, {"id": "1206.6679", "submitter": "Tim Salimans", "authors": "Tim Salimans and David A. Knowles", "title": "Fixed-Form Variational Posterior Approximation through Stochastic Linear\n  Regression", "comments": null, "journal-ref": "Bayesian Analysis, Volume 8, Number 4 (2013), 837-882", "doi": "10.1214/13-BA858", "report-no": null, "categories": "stat.CO cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general algorithm for approximating nonstandard Bayesian\nposterior distributions. The algorithm minimizes the Kullback-Leibler\ndivergence of an approximating distribution to the intractable posterior\ndistribution. Our method can be used to approximate any posterior distribution,\nprovided that it is given in closed form up to the proportionality constant.\nThe approximation can be any distribution in the exponential family or any\nmixture of such distributions, which means that it can be made arbitrarily\nprecise. Several examples illustrate the speed and accuracy of our\napproximation method in practice.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 13:25:04 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2012 11:38:52 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2013 06:22:58 GMT"}, {"version": "v4", "created": "Sat, 26 Oct 2013 15:09:54 GMT"}, {"version": "v5", "created": "Wed, 27 Nov 2013 13:19:48 GMT"}, {"version": "v6", "created": "Mon, 28 Jul 2014 11:16:19 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Salimans", "Tim", ""], ["Knowles", "David A.", ""]]}, {"id": "1206.6872", "submitter": "David Stavens", "authors": "David Stavens, Sebastian Thrun", "title": "A Self-Supervised Terrain Roughness Estimator for Off-Road Autonomous\n  Driving", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-469-476", "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning approach for estimating the second derivative\nof a drivable surface, its roughness. Robot perception generally focuses on the\nfirst derivative, obstacle detection. However, the second derivative is also\nimportant due to its direct relation (with speed) to the shock the vehicle\nexperiences. Knowing the second derivative allows a vehicle to slow down in\nadvance of rough terrain. Estimating the second derivative is challenging due\nto uncertainty. For example, at range, laser readings may be so sparse that\nsignificant information about the surface is missing. Also, a high degree of\nprecision is required in projecting laser readings. This precision may be\nunavailable due to latency or error in the pose estimation. We model these\nsources of error as a multivariate polynomial. Its coefficients are learned\nusing the shock data as ground truth -- the accelerometers are used to train\nthe lasers. The resulting classifier operates on individual laser readings from\na road surface described by a 3D point cloud. The classifier identifies\nsections of road where the second derivative is likely to be large. Thus, the\nvehicle can slow down in advance, reducing the shock it experiences. The\nalgorithm is an evolution of one we used in the 2005 DARPA Grand Challenge. We\nanalyze it using data from that route.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:30:05 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Stavens", "David", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1206.6878", "submitter": "Monika Schaeffer", "authors": "Monika Schaeffer, Ron Parr", "title": "Efficient Selection of Disambiguating Actions for Stereo Vision", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-418-427", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains that involve the use of sensors, such as robotics or sensor\nnetworks, there are opportunities to use some form of active sensing to\ndisambiguate data from noisy or unreliable sensors. These disambiguating\nactions typically take time and expend energy. One way to choose the next\ndisambiguating action is to select the action with the greatest expected\nentropy reduction, or information gain. In this work, we consider active\nsensing in aid of stereo vision for robotics. Stereo vision is a powerful\nsensing technique for mobile robots, but it can fail in scenes that lack strong\ntexture. In such cases, a structured light source, such as vertical laser line\ncan be used for disambiguation. By treating the stereo matching problem as a\nspecially structured HMM-like graphical model, we demonstrate that for a scan\nline with n columns and maximum stereo disparity d, the entropy minimizing aim\npoint for the laser can be selected in O(nd) time - cost no greater than the\nstereo algorithm itself. In contrast, a typical HMM formulation would suggest\nat least O(nd^2) time for the entropy calculation alone.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:31:21 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Schaeffer", "Monika", ""], ["Parr", "Ron", ""]]}]