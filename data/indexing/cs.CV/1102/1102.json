[{"id": "1102.0048", "submitter": "St\\'ephane Mottelet", "authors": "St\\'ephane Mottelet and Luc de Saint Germain and Olivier Mondin", "title": "Smart depth of field optimization applied to a robotised view camera", "comments": "17 pages, 19 figures", "journal-ref": null, "doi": "10.1007/s10851-011-0306-y", "report-no": null, "categories": "math.OC cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The great flexibility of a view camera allows to take high quality\nphotographs that would not be possible any other way. But making a given object\ninto focus is a long and tedious task, although the underlying laws are well\nknown. This paper presents the result of a project which has lead to the design\nof a computer controlled view camera and to its companion software. Thanks to\nthe high precision machining of its components, and to the known optical\nparameters of lenses and sensor, we have been able to consider a reliable\nmathematical model of the view camera, allowing the acquisition of 3D\ncoordinates to build a geometrical model of the object. Then many problems can\nbe solved, e.g. minimizing the f-number while maintaining the object within the\ndepth of field, which takes the form of a constrained optimization problem. All\noptimization algorithms have been validated on a virtual view camera before\nimplementation on the prototype\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 01:05:10 GMT"}, {"version": "v2", "created": "Mon, 18 Apr 2011 11:16:02 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Mottelet", "St\u00e9phane", ""], ["Germain", "Luc de Saint", ""], ["Mondin", "Olivier", ""]]}, {"id": "1102.0059", "submitter": "Donghui Yan", "authors": "Donghui Yan, Pei Wang, Michael Linden, Beatrice Knudsen, Timothy\n  Randolph", "title": "Statistical methods for tissue array images - algorithmic scoring and\n  co-training", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS543 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2012, Vol. 6, No. 3, 1280-1305", "doi": "10.1214/12-AOAS543", "report-no": "IMS-AOAS-AOAS543", "categories": "stat.ME cs.CE cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in tissue microarray technology have allowed\nimmunohistochemistry to become a powerful medium-to-high throughput analysis\ntool, particularly for the validation of diagnostic and prognostic biomarkers.\nHowever, as study size grows, the manual evaluation of these assays becomes a\nprohibitive limitation; it vastly reduces throughput and greatly increases\nvariability and expense. We propose an algorithm - Tissue Array Co-Occurrence\nMatrix Analysis (TACOMA) - for quantifying cellular phenotypes based on\ntextural regularity summarized by local inter-pixel relationships. The\nalgorithm can be easily trained for any staining pattern, is absent of\nsensitive tuning parameters and has the ability to report salient pixels in an\nimage that contribute to its score. Pathologists' input via informative\ntraining patches is an important aspect of the algorithm that allows the\ntraining for any specific marker or cell type. With co-training, the error rate\nof TACOMA can be reduced substantially for a very small training sample (e.g.,\nwith size 30). We give theoretical insights into the success of co-training via\nthinning of the feature set in a high-dimensional setting when there is\n\"sufficient\" redundancy among the features. TACOMA is flexible, transparent and\nprovides a scoring process that can be evaluated with clarity and confidence.\nIn a study based on an estrogen receptor (ER) marker, we show that TACOMA is\ncomparable to, or outperforms, pathologists' performance in terms of accuracy\nand repeatability.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 02:08:00 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2012 09:20:39 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Yan", "Donghui", ""], ["Wang", "Pei", ""], ["Linden", "Michael", ""], ["Knudsen", "Beatrice", ""], ["Randolph", "Timothy", ""]]}, {"id": "1102.0817", "submitter": "Gasper Tkacik", "authors": "Ga\\v{s}per Tka\\v{c}ik and Patrick Garrigan and Charles Ratliff and\n  Grega Mil\\v{c}inski and Jennifer M Klein and Lucia H Seyfarth and Peter\n  Sterling and David Brainard and Vijay Balasubramanian", "title": "Natural images from the birthplace of the human eye", "comments": "Submitted to PLoS ONE", "journal-ref": "PLoS ONE 6: e20409 (2011)", "doi": "10.1371/journal.pone.0020409", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we introduce a database of calibrated natural images publicly available\nthrough an easy-to-use web interface. Using a Nikon D70 digital SLR camera, we\nacquired about 5000 six-megapixel images of Okavango Delta of Botswana, a\ntropical savanna habitat similar to where the human eye is thought to have\nevolved. Some sequences of images were captured unsystematically while\nfollowing a baboon troop, while others were designed to vary a single parameter\nsuch as aperture, object distance, time of day or position on the horizon.\nImages are available in the raw RGB format and in grayscale. Images are also\navailable in units relevant to the physiology of human cone photoreceptors,\nwhere pixel values represent the expected number of photoisomerizations per\nsecond for cones sensitive to long (L), medium (M) and short (S) wavelengths.\nThis database is distributed under a Creative Commons Attribution-Noncommercial\nUnported license to facilitate research in computer vision, psychophysics of\nperception, and visual neuroscience.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 00:27:48 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Tka\u010dik", "Ga\u0161per", ""], ["Garrigan", "Patrick", ""], ["Ratliff", "Charles", ""], ["Mil\u010dinski", "Grega", ""], ["Klein", "Jennifer M", ""], ["Seyfarth", "Lucia H", ""], ["Sterling", "Peter", ""], ["Brainard", "David", ""], ["Balasubramanian", "Vijay", ""]]}, {"id": "1102.0899", "submitter": "Michael Del Rose", "authors": "Michael DelRose, Christian Wagner, Philip Frederick", "title": "Evidence Feed Forward Hidden Markov Model: A New Type of Hidden Markov\n  Model", "comments": "19 pages, International Journal of Artificial Intelligence and\n  Applications", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol. 2, No. 1, Jan 2011", "doi": "10.5121/ijaia.2011.2101", "report-no": null, "categories": "cs.AI cs.CV cs.LG math.NA math.PR", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The ability to predict the intentions of people based solely on their visual\nactions is a skill only performed by humans and animals. The intelligence of\ncurrent computer algorithms has not reached this level of complexity, but there\nare several research efforts that are working towards it. With the number of\nclassification algorithms available, it is hard to determine which algorithm\nworks best for a particular situation. In classification of visual human intent\ndata, Hidden Markov Models (HMM), and their variants, are leading candidates.\n  The inability of HMMs to provide a probability in the observation to\nobservation linkages is a big downfall in this classification technique. If a\nperson is visually identifying an action of another person, they monitor\npatterns in the observations. By estimating the next observation, people have\nthe ability to summarize the actions, and thus determine, with pretty good\naccuracy, the intention of the person performing the action. These visual cues\nand linkages are important in creating intelligent algorithms for determining\nhuman actions based on visual observations.\n  The Evidence Feed Forward Hidden Markov Model is a newly developed algorithm\nwhich provides observation to observation linkages. The following research\naddresses the theory behind Evidence Feed Forward HMMs, provides mathematical\nproofs of their learning of these parameters to optimize the likelihood of\nobservations with a Evidence Feed Forwards HMM, which is important in all\ncomputational intelligence algorithm, and gives comparative examples with\nstandard HMMs in classification of both visual action data and measurement\ndata; thus providing a strong base for Evidence Feed Forward HMMs in\nclassification of many types of problems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 13:00:06 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["DelRose", "Michael", ""], ["Wagner", "Christian", ""], ["Frederick", "Philip", ""]]}, {"id": "1102.1101", "submitter": "Gael Varoquaux", "authors": "Vincent Michel (LNAO, INRIA Saclay - Ile de France), Alexandre\n  Gramfort (LNAO, INRIA Saclay - Ile de France), Ga\\\"el Varoquaux (LNAO,\n  Parietal, LCogn), Evelyn Eger (LCogn), Bertrand Thirion (LNAO, INRIA Saclay -\n  Ile de France)", "title": "Total variation regularization for fMRI-based prediction of behaviour", "comments": null, "journal-ref": "IEEE Transactions on Medical Imaging (2011)", "doi": "10.1109/TMI.2011.2113378", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While medical imaging typically provides massive amounts of data, the\nextraction of relevant information for predictive diagnosis remains a difficult\nchallenge. Functional MRI (fMRI) data, that provide an indirect measure of\ntask-related or spontaneous neuronal activity, are classically analyzed in a\nmass-univariate procedure yielding statistical parametric maps. This analysis\nframework disregards some important principles of brain organization:\npopulation coding, distributed and overlapping representations. Multivariate\npattern analysis, i.e., the prediction of behavioural variables from brain\nactivation patterns better captures this structure. To cope with the high\ndimensionality of the data, the learning method has to be regularized. However,\nthe spatial structure of the image is not taken into account in standard\nregularization methods, so that the extracted features are often hard to\ninterpret. More informative and interpretable results can be obtained with the\nl_1 norm of the image gradient, a.k.a. its Total Variation (TV), as\nregularization. We apply for the first time this method to fMRI data, and show\nthat TV regularization is well suited to the purpose of brain mapping while\nbeing a powerful tool for brain decoding. Moreover, this article presents the\nfirst use of TV regularization for classification.\n", "versions": [{"version": "v1", "created": "Sat, 5 Feb 2011 20:59:45 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Michel", "Vincent", "", "LNAO, INRIA Saclay - Ile de France"], ["Gramfort", "Alexandre", "", "LNAO, INRIA Saclay - Ile de France"], ["Varoquaux", "Ga\u00ebl", "", "LNAO,\n  Parietal, LCogn"], ["Eger", "Evelyn", "", "LCogn"], ["Thirion", "Bertrand", "", "LNAO, INRIA Saclay -\n  Ile de France"]]}, {"id": "1102.1292", "submitter": "Bernard Ghanem", "authors": "Bernard Ghanem and Narendra Ahuja", "title": "Modeling Dynamic Swarms", "comments": "11 pages, 17 figures, conference paper, computer vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the problem of modeling video sequences of dynamic swarms\n(DS). We define DS as a large layout of stochastically repetitive spatial\nconfigurations of dynamic objects (swarm elements) whose motions exhibit local\nspatiotemporal interdependency and stationarity, i.e., the motions are similar\nin any small spatiotemporal neighborhood. Examples of DS abound in nature,\ne.g., herds of animals and flocks of birds. To capture the local spatiotemporal\nproperties of the DS, we present a probabilistic model that learns both the\nspatial layout of swarm elements and their joint dynamics that are modeled as\nlinear transformations. To this end, a spatiotemporal neighborhood is\nassociated with each swarm element, in which local stationarity is enforced\nboth spatially and temporally. We assume that the prior on the swarm dynamics\nis distributed according to an MRF in both space and time. Embedding this model\nin a MAP framework, we iterate between learning the spatial layout of the swarm\nand its dynamics. We learn the swarm transformations using ICM, which iterates\nbetween estimating these transformations and updating their distribution in the\nspatiotemporal neighborhoods. We demonstrate the validity of our method by\nconducting experiments on real video sequences. Real sequences of birds, geese,\nrobot swarms, and pedestrians evaluate the applicability of our model to real\nworld data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Feb 2011 12:29:30 GMT"}], "update_date": "2011-02-08", "authors_parsed": [["Ghanem", "Bernard", ""], ["Ahuja", "Narendra", ""]]}, {"id": "1102.2382", "submitter": "Jan Egger", "authors": "Jan Egger, D\\v{z}enan Zuki\\'c, Miriam H. A. Bauer, Daniela Kuhnt,\n  Barbara Carl, Bernd Freisleben, Andreas Kolb, Christopher Nimsky", "title": "A Comparison of Two Human Brain Tumor Segmentation Methods for MRI Data", "comments": "4 pages, 5 figures, Proc. of the 6th Russian-Bavarian Conference on\n  Bio-Medical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common primary brain tumors are gliomas, evolving from the cerebral\nsupportive cells. For clinical follow-up, the evaluation of the preoperative\ntumor volume is essential. Volumetric assessment of tumor volume with manual\nsegmentation of its outlines is a time-consuming process that can be overcome\nwith the help of computerized segmentation methods. In this contribution, two\nmethods for World Health Organization (WHO) grade IV glioma segmentation in the\nhuman brain are compared using magnetic resonance imaging (MRI) patient data\nfrom the clinical routine. One method uses balloon inflation forces, and relies\non detection of high intensity tumor boundaries that are coupled with the use\nof contrast agent gadolinium. The other method sets up a directed and weighted\ngraph and performs a min-cut for optimal segmentation results. The ground truth\nof the tumor boundaries - for evaluating the methods on 27 cases - is manually\nextracted by neurosurgeons with several years of experience in the resection of\ngliomas. A comparison is performed using the Dice Similarity Coefficient (DSC),\na measure for the spatial overlap of different segmentation results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Feb 2011 09:16:28 GMT"}, {"version": "v2", "created": "Thu, 10 Mar 2011 07:53:57 GMT"}], "update_date": "2011-03-11", "authors_parsed": [["Egger", "Jan", ""], ["Zuki\u0107", "D\u017eenan", ""], ["Bauer", "Miriam H. A.", ""], ["Kuhnt", "Daniela", ""], ["Carl", "Barbara", ""], ["Freisleben", "Bernd", ""], ["Kolb", "Andreas", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1102.2615", "submitter": "Doru Cristian Balcan", "authors": "Doru C. Balcan, Gowri Srinivasa, Matthew Fickus, Jelena Kovacevic", "title": "Guaranteeing Convergence of Iterative Skewed Voting Algorithms for Image\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CV nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide rigorous proof for the convergence of an iterative\nvoting-based image segmentation algorithm called Active Masks. Active Masks\n(AM) was proposed to solve the challenging task of delineating punctate\npatterns of cells from fluorescence microscope images. Each iteration of AM\nconsists of a linear convolution composed with a nonlinear thresholding; what\nmakes this process special in our case is the presence of additive terms whose\nrole is to \"skew\" the voting when prior information is available. In real-world\nimplementation, the AM algorithm always converges to a fixed point. We study\nthe behavior of AM rigorously and present a proof of this convergence. The key\nidea is to formulate AM as a generalized (parallel) majority cellular\nautomaton, adapting proof techniques from discrete dynamical systems.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 16:39:16 GMT"}, {"version": "v2", "created": "Mon, 21 Feb 2011 04:58:16 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Balcan", "Doru C.", ""], ["Srinivasa", "Gowri", ""], ["Fickus", "Matthew", ""], ["Kovacevic", "Jelena", ""]]}, {"id": "1102.2684", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "Chernoff information of exponential families", "comments": null, "journal-ref": "IEEE Signal Processing Letters 20.3 (2013): 269-272", "doi": "10.1109/LSP.2013.2243726", "report-no": null, "categories": "cs.IT cs.CV cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chernoff information upper bounds the probability of error of the optimal\nBayesian decision rule for $2$-class classification problems. However, it turns\nout that in practice the Chernoff bound is hard to calculate or even\napproximate. In statistics, many usual distributions, such as Gaussians,\nPoissons or frequency histograms called multinomials, can be handled in the\nunified framework of exponential families. In this note, we prove that the\nChernoff information for members of the same exponential family can be either\nderived analytically in closed form, or efficiently approximated using a simple\ngeodesic bisection optimization technique based on an exact geometric\ncharacterization of the \"Chernoff point\" on the underlying statistical\nmanifold.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 06:35:51 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1102.2739", "submitter": "Sergey Tarasenko", "authors": "Sergey S. Tarasenko", "title": "A General Framework for Development of the Cortex-like Visual Object\n  Recognition System: Waves of Spikes, Predictive Coding and Universal\n  Dictionary of Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study is focused on the development of the cortex-like visual object\nrecognition system. We propose a general framework, which consists of three\nhierarchical levels (modules). These modules functionally correspond to the V1,\nV4 and IT areas. Both bottom-up and top-down connections between the\nhierarchical levels V4 and IT are employed. The higher the degree of matching\nbetween the input and the preferred stimulus, the shorter the response time of\nthe neuron. Therefore information about a single stimulus is distributed in\ntime and is transmitted by the waves of spikes. The reciprocal connections and\nwaves of spikes implement predictive coding: an initial hypothesis is generated\non the basis of information delivered by the first wave of spikes and is tested\nwith the information carried by the consecutive waves. The development is\nconsidered as extraction and accumulation of features in V4 and objects in IT.\nOnce stored a feature can be disposed, if rarely activated. This cause update\nof feature repository. Consequently, objects in IT are also updated. This\nillustrates the growing process and dynamical change of topological structures\nof V4, IT and connections between these areas.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 11:40:08 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Tarasenko", "Sergey S.", ""]]}, {"id": "1102.2743", "submitter": "Yixiong Liang", "authors": "Yixiong Liang and Lei Wang and Shenghui Liao and Beiji Zou", "title": "Feature selection via simultaneous sparse approximation for person\n  specific face verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing use of some imperceivable and redundant local features\nfor face recognition. While only a relatively small fraction of them is\nrelevant to the final recognition task, the feature selection is a crucial and\nnecessary step to select the most discriminant ones to obtain a compact face\nrepresentation. In this paper, we investigate the sparsity-enforced\nregularization-based feature selection methods and propose a multi-task feature\nselection method for building person specific models for face verification. We\nassume that the person specific models share a common subset of features and\nnovelly reformulated the common subset selection problem as a simultaneous\nsparse approximation problem. To the best of our knowledge, it is the first\ntime to apply the sparsity-enforced regularization methods for person specific\nface verification. The effectiveness of the proposed methods is verified with\nthe challenging LFW face databases.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 11:51:35 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 17:16:19 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Liang", "Yixiong", ""], ["Wang", "Lei", ""], ["Liao", "Shenghui", ""], ["Zou", "Beiji", ""]]}, {"id": "1102.2748", "submitter": "Yixiong Liang", "authors": "Yixiong Liang and Lei Wang and Yao Xiang and Beiji Zou", "title": "Feature Selection via Sparse Approximation for Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biological vision systems, the over-complete local features with\nhuge cardinality are increasingly used for face recognition during the last\ndecades. Accordingly, feature selection has become more and more important and\nplays a critical role for face data description and recognition. In this paper,\nwe propose a trainable feature selection algorithm based on the regularized\nframe for face recognition. By enforcing a sparsity penalty term on the minimum\nsquared error (MSE) criterion, we cast the feature selection problem into a\ncombinatorial sparse approximation problem, which can be solved by greedy\nmethods or convex relaxation methods. Moreover, based on the same frame, we\npropose a sparse Ho-Kashyap (HK) procedure to obtain simultaneously the optimal\nsparse solution and the corresponding margin vector of the MSE criterion. The\nproposed methods are used for selecting the most informative Gabor features of\nface images for recognition and the experimental results on benchmark face\ndatabases demonstrate the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 12:05:47 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Liang", "Yixiong", ""], ["Wang", "Lei", ""], ["Xiang", "Yao", ""], ["Zou", "Beiji", ""]]}, {"id": "1102.2749", "submitter": "Yixiong Liang", "authors": "Yixiong Liang and Lingbo Liu and Ying Xu and Yao Xiang and Beiji Zou", "title": "Multi-task GLOH feature selection for human age estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel age estimation method based on GLOH feature\ndescriptor and multi-task learning (MTL). The GLOH feature descriptor, one of\nthe state-of-the-art feature descriptor, is used to capture the age-related\nlocal and spatial information of face image. As the exacted GLOH features are\noften redundant, MTL is designed to select the most informative feature bins\nfor age estimation problem, while the corresponding weights are determined by\nridge regression. This approach largely reduces the dimensions of feature,\nwhich can not only improve performance but also decrease the computational\nburden. Experiments on the public available FG-NET database show that the\nproposed method can achieve comparable performance over previous approaches\nwhile using much fewer features.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 12:12:56 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 17:19:24 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Liang", "Yixiong", ""], ["Liu", "Lingbo", ""], ["Xu", "Ying", ""], ["Xiang", "Yao", ""], ["Zou", "Beiji", ""]]}, {"id": "1102.3328", "submitter": "Yi Pang", "authors": "Xuan Dong, Jiangtao (Gene) Wen, Weixin Li, Yi (Amy) Pang, Guan Wang,\n  Yao Lu, Wei Meng", "title": "An Efficient and Integrated Algorithm for Video Enhancement in\n  Challenging Lighting Conditions", "comments": "10 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel integrated algorithm for real-time enhancement of video\nacquired under challenging lighting conditions. Such conditions include low\nlighting, haze, and high dynamic range situations. The algorithm automatically\ndetects the dominate source of impairment, then depending on whether it is low\nlighting, haze or others, a corresponding pre-processing is applied to the\ninput video, followed by the core enhancement algorithm. Temporal and spatial\nredundancies in the video input are utilized to facilitate real-time processing\nand to improve temporal and spatial consistency of the output. The proposed\nalgorithm can be used as an independent module, or be integrated in either a\nvideo encoder or a video decoder for further optimizations.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 13:04:18 GMT"}], "update_date": "2011-02-17", "authors_parsed": [["Dong", "Xuan", "", "Gene"], ["Jiangtao", "", "", "Gene"], ["Wen", "", "", "Amy"], ["Li", "Weixin", "", "Amy"], ["Yi", "", "", "Amy"], ["Pang", "", ""], ["Wang", "Guan", ""], ["Lu", "Yao", ""], ["Meng", "Wei", ""]]}, {"id": "1102.3828", "submitter": "Herve Jegou", "authors": "Herv\\'e J\\'egou (INRIA - IRISA), Romain Tavenard (INRIA - IRISA),\n  Matthijs Douze (INRIA Rh\\^one-Alpes / LJK Laboratoire Jean Kuntzmann, SED),\n  Laurent Amsaleg (INRIA - IRISA)", "title": "Searching in one billion vectors: re-rank with source coding", "comments": "International Conference on Acoustics, Speech and Signal Processing,\n  Prague : Czech Republic (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent indexing techniques inspired by source coding have been shown\nsuccessful to index billions of high-dimensional vectors in memory. In this\npaper, we propose an approach that re-ranks the neighbor hypotheses obtained by\nthese compressed-domain indexing methods. In contrast to the usual\npost-verification scheme, which performs exact distance calculation on the\nshort-list of hypotheses, the estimated distances are refined based on short\nquantization codes, to avoid reading the full vectors from disk. We have\nreleased a new public dataset of one billion 128-dimensional vectors and\nproposed an experimental setup to evaluate high dimensional indexing algorithms\non a realistic scale. Experiments show that our method accurately and\nefficiently re-ranks the neighbor hypotheses using little memory compared to\nthe full vectors representation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 13:15:37 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["J\u00e9gou", "Herv\u00e9", "", "INRIA - IRISA"], ["Tavenard", "Romain", "", "INRIA - IRISA"], ["Douze", "Matthijs", "", "INRIA Rh\u00f4ne-Alpes / LJK Laboratoire Jean Kuntzmann, SED"], ["Amsaleg", "Laurent", "", "INRIA - IRISA"]]}, {"id": "1102.3830", "submitter": "Thomas Schoenemann", "authors": "Thomas Schoenemann, Fredrik Kahl, Simon Masnou and Daniel Cremers", "title": "A linear framework for region-based image segmentation and inpainting\n  involving curvature penalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first method to handle curvature regularity in region-based\nimage segmentation and inpainting that is independent of initialization.\n  To this end we start from a new formulation of length-based optimization\nschemes, based on surface continuation constraints, and discuss the connections\nto existing schemes. The formulation is based on a \\emph{cell complex} and\nconsiders basic regions and boundary elements. The corresponding optimization\nproblem is cast as an integer linear program.\n  We then show how the method can be extended to include curvature regularity,\nagain cast as an integer linear program. Here, we are considering pairs of\nboundary elements to reflect curvature. Moreover, a constraint set is derived\nto ensure that the boundary variables indeed reflect the boundary of the\nregions described by the region variables.\n  We show that by solving the linear programming relaxation one gets quite\nclose to the global optimum, and that curvature regularity is indeed much\nbetter suited in the presence of long and thin objects compared to standard\nlength regularity.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 13:20:10 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Schoenemann", "Thomas", ""], ["Kahl", "Fredrik", ""], ["Masnou", "Simon", ""], ["Cremers", "Daniel", ""]]}, {"id": "1102.4258", "submitter": "Michael Bronstein", "authors": "E. Boyer, A. M. Bronstein, M. M. Bronstein, B. Bustos, T. Darom, R.\n  Horaud, I. Hotz, Y. Keller, J. Keustermans, A. Kovnatsky, R. Litman, J.\n  Reininghaus, I. Sipiran, D. Smeets, P. Suetens, D. Vandermeulen, A.\n  Zaharescu, V. Zobel", "title": "SHREC 2011: robust feature detection and description benchmark", "comments": "This is a full version of the SHREC'11 report published in 3DOR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature-based approaches have recently become very popular in computer vision\nand image analysis applications, and are becoming a promising direction in\nshape retrieval. SHREC'11 robust feature detection and description benchmark\nsimulates the feature detection and description stages of feature-based shape\nretrieval algorithms. The benchmark tests the performance of shape feature\ndetectors and descriptors under a wide variety of transformations. The\nbenchmark allows evaluating how algorithms cope with certain classes of\ntransformations and strength of the transformations that can be dealt with. The\npresent paper is a report of the SHREC'11 robust feature detection and\ndescription benchmark results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 15:43:19 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Boyer", "E.", ""], ["Bronstein", "A. M.", ""], ["Bronstein", "M. M.", ""], ["Bustos", "B.", ""], ["Darom", "T.", ""], ["Horaud", "R.", ""], ["Hotz", "I.", ""], ["Keller", "Y.", ""], ["Keustermans", "J.", ""], ["Kovnatsky", "A.", ""], ["Litman", "R.", ""], ["Reininghaus", "J.", ""], ["Sipiran", "I.", ""], ["Smeets", "D.", ""], ["Suetens", "P.", ""], ["Vandermeulen", "D.", ""], ["Zaharescu", "A.", ""], ["Zobel", "V.", ""]]}, {"id": "1102.4803", "submitter": "Mikhail Langovoy", "authors": "Mikhail A. Langovoy and Olaf Wittich", "title": "Detection of objects in noisy images and site percolation on square\n  lattices", "comments": "This paper first appeared as EURANDOM Report 2009-035 on November 11,\n  2009. Link to the paper at the EURANDOM repository:\n  http://www.eurandom.tue.nl/reports/2009/035-report.pdf Link to the abstract\n  at EURANDOM repository:\n  http://www.eurandom.tue.nl/reports/2009/035-abstract.pdf", "journal-ref": null, "doi": null, "report-no": "EURANDOM Report 2009-035", "categories": "math.ST cs.CV math.PR stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel probabilistic method for detection of objects in noisy\nimages. The method uses results from percolation and random graph theories. We\npresent an algorithm that allows to detect objects of unknown shapes in the\npresence of random noise. Our procedure substantially differs from\nwavelets-based algorithms. The algorithm has linear complexity and exponential\naccuracy and is appropriate for real-time systems. We prove results on\nconsistency and algorithmic complexity of our procedure.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 17:28:21 GMT"}], "update_date": "2011-02-24", "authors_parsed": [["Langovoy", "Mikhail A.", ""], ["Wittich", "Olaf", ""]]}, {"id": "1102.4816", "submitter": "Mikhail Langovoy", "authors": "Mikhail A. Langovoy and Olaf Wittich", "title": "Computationally efficient algorithms for statistical image processing.\n  Implementation in R", "comments": "This paper initially appeared in 2010 as EURANDOM Report 2010-053.\n  Link to EURANDOM repository:\n  http://www.eurandom.tue.nl/reports/2010/053-report.pdf Link to the abstract\n  at EURANDOM repository:\n  http://www.eurandom.tue.nl/reports/2010/053-abstract.pdf", "journal-ref": null, "doi": null, "report-no": "EURANDOM Report 2010-053", "categories": "stat.CO cs.CV stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the series of our earlier papers on the subject, we proposed a novel\nstatistical hypothesis testing method for detection of objects in noisy images.\nThe method uses results from percolation theory and random graph theory. We\ndeveloped algorithms that allowed to detect objects of unknown shapes in the\npresence of nonparametric noise of unknown level and of unknown distribution.\nNo boundary shape constraints were imposed on the objects, only a weak bulk\ncondition for the object's interior was required. Our algorithms have linear\ncomplexity and exponential accuracy. In the present paper, we describe an\nimplementation of our nonparametric hypothesis testing method. We provide a\nprogram that can be used for statistical experiments in image processing. This\nprogram is written in the statistical programming language R.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 18:46:56 GMT"}], "update_date": "2011-02-24", "authors_parsed": [["Langovoy", "Mikhail A.", ""], ["Wittich", "Olaf", ""]]}, {"id": "1102.4873", "submitter": "Clio Andris", "authors": "C. Andris", "title": "Weighted Radial Variation for Node Feature Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections created from a node-edge matrix have been traditionally difficult\nto visualize and analyze because of the number of flows to be rendered in a\nlimited feature or cartographic space. Because analyzing connectivity patterns\nis useful for understanding the complex dynamics of human and information flow\nthat connect non-adjacent space, techniques that allow for visual data mining\nor static representations of system dynamics are a growing field of research.\nHere, we create a Weighted Radial Variation (WRV) technique to classify a set\nof nodes based on the configuration of their radially-emanating vector flows.\nEach entity's vector is syncopated in terms of cardinality, direction, length,\nand flow magnitude. The WRV process unravels each star-like entity's individual\nflow vectors on a 0-360{\\deg} spectrum, to form a unique signal whose\ndistribution depends on the flow presence at each step around the entity, and\nis further characterized by flow distance and magnitude. The signals are\nprocessed with an unsupervised classification method that clusters entities\nwith similar signatures in order to provide a typology for each node in the\nsystem of spatial flows. We use a case study of U.S. county-to-county human\nincoming and outgoing migration data to test our method.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 23:13:45 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Andris", "C.", ""]]}, {"id": "1102.5448", "submitter": "Jan Lellmann", "authors": "Jan Lellmann and Christoph Schn\\\"orr", "title": "Continuous Multiclass Labeling Approaches and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study convex relaxations of the image labeling problem on a continuous\ndomain with regularizers based on metric interaction potentials. The generic\nframework ensures existence of minimizers and covers a wide range of\nrelaxations of the originally combinatorial problem. We focus on two specific\nrelaxations that differ in flexibility and simplicity -- one can be used to\ntightly relax any metric interaction potential, while the other one only covers\nEuclidean metrics but requires less computational effort. For solving the\nnonsmooth discretized problem, we propose a globally convergent\nDouglas-Rachford scheme, and show that a sequence of dual iterates can be\nrecovered in order to provide a posteriori optimality bounds. In a quantitative\ncomparison to two other first-order methods, the approach shows competitive\nperformance on synthetical and real-world images. By combining the method with\nan improved binarization technique for nonstandard potentials, we were able to\nroutinely recover discrete solutions within 1%--5% of the global optimum for\nthe combinatorial image labeling problem.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 21:13:57 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2011 01:22:18 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Lellmann", "Jan", ""], ["Schn\u00f6rr", "Christoph", ""]]}, {"id": "1102.5688", "submitter": "Liyakath Unisa", "authors": "Liyakathunisa and C.N .Ravi Kumar", "title": "A novel super resolution reconstruction of low reoslution images\n  progressively using dct and zonal filter based denoising", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the factors like processing power limitations and channel capabilities\nimages are often down sampled and transmitted at low bit rates resulting in a\nlow resolution compressed image. High resolution images can be reconstructed\nfrom several blurred, noisy and down sampled low resolution images using a\ncomputational process know as super resolution reconstruction. Super-resolution\nis the process of combining multiple aliased low-quality images to produce a\nhigh resolution, high-quality image. The problem of recovering a high\nresolution image progressively from a sequence of low resolution compressed\nimages is considered. In this paper we propose a novel DCT based progressive\nimage display algorithm by stressing on the encoding and decoding process. At\nthe encoder we consider a set of low resolution images which are corrupted by\nadditive white Gaussian noise and motion blur. The low resolution images are\ncompressed using 8 by 8 blocks DCT and noise is filtered using our proposed\nnovel zonal filter. Multiframe fusion is performed in order to obtain a single\nnoise free image. At the decoder the image is reconstructed progressively by\ntransmitting the coarser image first followed by the detail image. And finally\na super resolution image is reconstructed by applying our proposed novel\nadaptive interpolation technique. We have performed both objective and\nsubjective analysis of the reconstructed image, and the resultant image has\nbetter super resolution factor, and a higher ISNR and PSNR. A comparative study\ndone with Iterative Back Projection (IBP) and Projection on to Convex Sets\n(POCS),Papoulis Grechberg, FFT based Super resolution Reconstruction shows that\nour method has out performed the previous contributions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Feb 2011 15:24:06 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Liyakathunisa", "", ""], ["Kumar", "C. N . Ravi", ""]]}]