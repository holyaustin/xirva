[{"id": "1011.0093", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi", "title": "Fast Color Quantization Using Weighted Sort-Means Clustering", "comments": "30 pages, 2 figures, 4 tables", "journal-ref": "Journal of the Optical Society of America A 26 (2009) 2434-2443", "doi": "10.1364/JOSAA.26.002434", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color quantization is an important operation with numerous applications in\ngraphics and image processing. Most quantization methods are essentially based\non data clustering algorithms. However, despite its popularity as a general\npurpose clustering algorithm, k-means has not received much respect in the\ncolor quantization literature because of its high computational requirements\nand sensitivity to initialization. In this paper, a fast color quantization\nmethod based on k-means is presented. The method involves several modifications\nto the conventional (batch) k-means algorithm including data reduction, sample\nweighting, and the use of triangle inequality to speed up the nearest neighbor\nsearch. Experiments on a diverse set of images demonstrate that, with the\nproposed modifications, k-means becomes very competitive with state-of-the-art\ncolor quantization methods in terms of both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 30 Oct 2010 16:56:17 GMT"}], "update_date": "2010-11-02", "authors_parsed": [["Celebi", "M. Emre", ""]]}, {"id": "1011.0596", "submitter": "Ayan Chaudhury", "authors": "Ayan Chaudhury, Abhishek Gupta, Sumita Manna, Subhadeep Mukherjee,\n  Amlan Chakrabarti", "title": "Multiple View Reconstruction of Calibrated Images using Singular Value\n  Decomposition", "comments": "In Proceedings of 4th IEEE international conference on Advanced\n  Computing and Communication Technologies(ICACCT2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration in a multi camera network has widely been studied for over\nseveral years starting from the earlier days of photogrammetry. Many authors\nhave presented several calibration algorithms with their relative advantages\nand disadvantages. In a stereovision system, multiple view reconstruction is a\nchallenging task. However, the total computational procedure in detail has not\nbeen presented before. Here in this work, we are dealing with the problem that,\nwhen a world coordinate point is fixed in space, image coordinates of that 3D\npoint vary for different camera positions and orientations. In computer vision\naspect, this situation is undesirable. That is, the system has to be designed\nin such a way that image coordinate of the world coordinate point will be fixed\nirrespective of the position & orientation of the cameras. We have done it in\nan elegant fashion. Firstly, camera parameters are calculated in its local\ncoordinate system. Then, we use global coordinate data to transfer all local\ncoordinate data of stereo cameras into same global coordinate system, so that\nwe can register everything into this global coordinate system. After all the\ntransformations, when the image coordinate of the world coordinate point is\ncalculated, it gives same coordinate value for all camera positions &\norientations. That is, the whole system is calibrated.\n", "versions": [{"version": "v1", "created": "Tue, 2 Nov 2010 12:25:04 GMT"}], "update_date": "2010-11-03", "authors_parsed": [["Chaudhury", "Ayan", ""], ["Gupta", "Abhishek", ""], ["Manna", "Sumita", ""], ["Mukherjee", "Subhadeep", ""], ["Chakrabarti", "Amlan", ""]]}, {"id": "1011.0640", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hitoshi Iyatomi, Gerald Schaefer, William V. Stoecker", "title": "Lesion Border Detection in Dermoscopy Images", "comments": "10 pages, 1 figure, 3 tables", "journal-ref": "Computerized Medical Imaging and Graphics 33 (2009) 148--153", "doi": "10.1016/j.compmedimag.2008.11.002", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, computerized analysis of dermoscopy\nimages has become an important research area. One of the most important steps\nin dermoscopy image analysis is the automated detection of lesion borders.\nMethods: In this article, we present a systematic overview of the recent border\ndetection methods in the literature paying particular attention to\ncomputational issues and evaluation aspects. Conclusion: Common problems with\nthe existing approaches include the acquisition, size, and diagnostic\ndistribution of the test image set, the evaluation of the results, and the\ninadequate description of the employed methods. Border determination by\ndermatologists appears to depend upon higher-level knowledge, therefore it is\nlikely that the incorporation of domain knowledge in automated methods will\nenable them to perform better, especially in sets of images with a variety of\ndiagnoses.\n", "versions": [{"version": "v1", "created": "Sat, 30 Oct 2010 17:17:02 GMT"}], "update_date": "2010-11-13", "authors_parsed": [["Celebi", "M. Emre", ""], ["Iyatomi", "Hitoshi", ""], ["Schaefer", "Gerald", ""], ["Stoecker", "William V.", ""]]}, {"id": "1011.0997", "submitter": "Blake Hunter", "authors": "Blake Hunter and Thomas Strohmer", "title": "Performance Analysis of Spectral Clustering on Compressed, Incomplete\n  and Inaccurate Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most widely used techniques for extracting\nthe underlying global structure of a data set. Compressed sensing and matrix\ncompletion have emerged as prevailing methods for efficiently recovering sparse\nand partially observed signals respectively. We combine the distance preserving\nmeasurements of compressed sensing and matrix completion with the power of\nrobust spectral clustering. Our analysis provides rigorous bounds on how small\nerrors in the affinity matrix can affect the spectral coordinates and\nclusterability. This work generalizes the current perturbation results of\ntwo-class spectral clustering to incorporate multi-class clustering with k\neigenvectors. We thoroughly track how small perturbation from using compressed\nsensing and matrix completion affect the affinity matrix and in succession the\nspectral coordinates. These perturbation results for multi-class clustering\nrequire an eigengap between the kth and (k+1)th eigenvalues of the affinity\nmatrix, which naturally occurs in data with k well-defined clusters. Our\ntheoretical guarantees are complemented with numerical results along with a\nnumber of examples of the unsupervised organization and clustering of image\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 3 Nov 2010 20:02:35 GMT"}], "update_date": "2010-11-05", "authors_parsed": [["Hunter", "Blake", ""], ["Strohmer", "Thomas", ""]]}, {"id": "1011.1035", "submitter": "Marcus Hutter", "authors": "Srimal Jayawardena and Marcus Hutter and Nathan Brewer", "title": "Featureless 2D-3D Pose Estimation by Minimising an\n  Illumination-Invariant Loss", "comments": "18 LaTeX pages, 7 figures", "journal-ref": "Proc. 13th International Conf. on Digital Image Computing:\n  Techniques and Applications (DICTA-2011) 37--44", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of identifying the 3D pose of a known object from a given 2D\nimage has important applications in Computer Vision ranging from robotic vision\nto image analysis. Our proposed method of registering a 3D model of a known\nobject on a given 2D photo of the object has numerous advantages over existing\nmethods: It does neither require prior training nor learning, nor knowledge of\nthe camera parameters, nor explicit point correspondences or matching features\nbetween image and model. Unlike techniques that estimate a partial 3D pose (as\nin an overhead view of traffic or machine parts on a conveyor belt), our method\nestimates the complete 3D pose of the object, and works on a single static\nimage from a given view, and under varying and unknown lighting conditions. For\nthis purpose we derive a novel illumination-invariant distance measure between\n2D photo and projected 3D model, which is then minimised to find the best pose\nparameters. Results for vehicle pose detection are presented.\n", "versions": [{"version": "v1", "created": "Wed, 3 Nov 2010 23:44:46 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Jayawardena", "Srimal", ""], ["Hutter", "Marcus", ""], ["Brewer", "Nathan", ""]]}, {"id": "1011.1876", "submitter": "Jun-ichi Inoue", "authors": "Jun-ichi Inoue, Yohei Saika, Masato Okada", "title": "Statistical mechanics of digital halftoning", "comments": "20 pages, 27 figures, using revtex4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.CV physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of digital halftoning from the view point of\nstatistical mechanics. The digital halftoning is a sort of image processing,\nnamely, representing each grayscale in terms of black and white binary dots.\nThe digital halftoning is achieved by making use of the threshold mask, namely,\nfor each pixel, the halftoned binary pixel is determined as black if the\noriginal grayscale pixel is greater than or equal to the mask value and is\ndetermined as white vice versa. To determine the optimal value of the mask on\neach pixel for a given original grayscale image, we first assume that the\nhuman-eyes might recognize the black and white binary halftoned image as the\ncorresponding grayscale one by linear filters. The Hamiltonian is constructed\nas a distance between the original and the recognized images which is written\nin terms of the threshold mask. We are confirmed that the system described by\nthe Hamiltonian is regarded as a kind of antiferromagnetic Ising model with\nquenched disorders. By searching the ground state of the Hamiltonian, we obtain\nthe optimal threshold mask and the resulting halftoned binary dots\nsimultaneously. From the power-spectrum analysis, we find that the binary dots\nimage is physiologically plausible from the view point of human-eyes modulation\nproperties. We also propose a theoretical framework to investigate statistical\nperformance of inverse digital halftoning, that is, the inverse process of\nhalftoning. From the Bayesian inference view point, we rigorously show that the\nBayes-optimal inverse-halftoning is achieved on a specific condition which is\nvery similar to the so-called Nishimori line in the research field of spin\nglasses.\n", "versions": [{"version": "v1", "created": "Mon, 8 Nov 2010 19:05:42 GMT"}], "update_date": "2010-11-09", "authors_parsed": [["Inoue", "Jun-ichi", ""], ["Saika", "Yohei", ""], ["Okada", "Masato", ""]]}, {"id": "1011.2272", "submitter": "Reji A P", "authors": "A.P. Reji, Thomas Tessamma", "title": "Single Frame Image super Resolution using Learned Directionlets", "comments": "14 pages,6 figures", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.1, No.4, October 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new directionally adaptive, learning based, single image\nsuper resolution method using multiple direction wavelet transform, called\nDirectionlets is presented. This method uses directionlets to effectively\ncapture directional features and to extract edge information along different\ndirections of a set of available high resolution images .This information is\nused as the training set for super resolving a low resolution input image and\nthe Directionlet coefficients at finer scales of its high-resolution image are\nlearned locally from this training set and the inverse Directionlet transform\nrecovers the super-resolved high resolution image. The simulation results\nshowed that the proposed approach outperforms standard interpolation techniques\nlike Cubic spline interpolation as well as standard Wavelet-based learning,\nboth visually and in terms of the mean squared error (mse) values. This method\ngives good result with aliased images also.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 04:43:44 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Reji", "A. P.", ""], ["Tessamma", "Thomas", ""]]}, {"id": "1011.2292", "submitter": "Francois Clement", "authors": "Hend Ben Ameur (LAMSIN, INRIA Rocquencourt), Guy Chavent (INRIA\n  Rocquencourt), Francois Cl\\'ement (INRIA Rocquencourt), Pierre Weis (INRIA\n  Rocquencourt)", "title": "Image Segmentation with Multidimensional Refinement Indicators", "comments": null, "journal-ref": "N&deg; RR-7446 (2010)", "doi": null, "report-no": "RR-7446, RR-7446", "categories": "math.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We transpose an optimal control technique to the image segmentation problem.\nThe idea is to consider image segmentation as a parameter estimation problem.\nThe parameter to estimate is the color of the pixels of the image. We use the\nadaptive parameterization technique which builds iteratively an optimal\nrepresentation of the parameter into uniform regions that form a partition of\nthe domain, hence corresponding to a segmentation of the image. We minimize an\nerror function during the iterations, and the partition of the image into\nregions is optimally driven by the gradient of this error. The resulting\nsegmentation algorithm inherits desirable properties from its optimal control\norigin: soundness, robustness, and flexibility.\n", "versions": [{"version": "v1", "created": "Wed, 10 Nov 2010 08:17:05 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2011 07:35:51 GMT"}, {"version": "v3", "created": "Mon, 23 May 2011 08:12:22 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Ameur", "Hend Ben", "", "LAMSIN, INRIA Rocquencourt"], ["Chavent", "Guy", "", "INRIA\n  Rocquencourt"], ["Cl\u00e9ment", "Francois", "", "INRIA Rocquencourt"], ["Weis", "Pierre", "", "INRIA\n  Rocquencourt"]]}, {"id": "1011.3019", "submitter": "Shriprakash Sinha", "authors": "Shriprakash Sinha and Gert J. ter Horst", "title": "Bounded Multivariate Surfaces On Monovariate Internal Functions", "comments": "23 pages, 15 figures, 1 table", "journal-ref": "IEEE Intl. Conf. on Image Processing, Brussels, Sept. 11 to 14,\n  2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the properties of monovariate internal functions as proposed in\nKolmogorov superimposition theorem, in tandem with the bounds wielded by the\nmultivariate formulation of Chebyshev inequality, a hybrid model is presented,\nthat decomposes images into homogeneous probabilistically bounded multivariate\nsurfaces. Given an image, the model shows a novel way of working on reduced\nimage representation while processing and capturing the interaction among the\nmultidimensional information that describes the content of the same. Further,\nit tackles the practical issues of preventing leakage by bounding the growth of\nsurface and reducing the problem sample size. The model if used, also sheds\nlight on how the Chebyshev parameter relates to the number of pixels and the\ndimensionality of the feature space that associates with a pixel. Initial\nsegmentation results on the Berkeley image segmentation benchmark indicate the\neffectiveness of the proposed decomposition algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 19:48:13 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Sinha", "Shriprakash", ""], ["ter Horst", "Gert J.", ""]]}, {"id": "1011.3023", "submitter": "Joan Bruna", "authors": "Joan Bruna, St\\'ephane Mallat", "title": "Classification with Scattering Operators", "comments": "6 pages. CVPR 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A scattering vector is a local descriptor including multiscale and\nmulti-direction co-occurrence information. It is computed with a cascade of\nwavelet decompositions and complex modulus. This scattering representation is\nlocally translation invariant and linearizes deformations. A supervised\nclassification algorithm is computed with a PCA model selection on scattering\nvectors. State of the art results are obtained for handwritten digit\nrecognition and texture classification.\n", "versions": [{"version": "v1", "created": "Fri, 12 Nov 2010 20:15:25 GMT"}, {"version": "v2", "created": "Tue, 16 Nov 2010 08:42:30 GMT"}, {"version": "v3", "created": "Wed, 17 Nov 2010 18:48:50 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2013 16:42:37 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Bruna", "Joan", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1011.3174", "submitter": "Peihua Li", "authors": "Peihua Li", "title": "Tensor-SIFT based Earth Mover's Distance for Contour Tracking", "comments": "28 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contour tracking in adverse environments is a challenging problem due to\ncluttered background, illumination variation, occlusion, and noise, among\nothers. This paper presents a robust contour tracking method by contributing to\nsome of the key issues involved, including (a) a region functional formulation\nand its optimization; (b) design of a robust and effective feature; and (c)\ndevelopment of an integrated tracking algorithm. First, we formulate a region\nfunctional based on robust Earth Mover's distance (EMD) with kernel density for\ndistribution modeling, and propose a two-phase method for its optimization. In\nthe first phase, letting the candidate contour be fixed, we express EMD as the\ntransportation problem and solve it by the simplex algorithm. Next, using the\ntheory of shape derivative, we make a perturbation analysis of the contour\naround the best solution to the transportation problem. This leads to a partial\ndifferential equation (PDE) that governs the contour evolution. Second, we\ndesign a novel and effective feature for tracking applications. We propose a\ndimensionality reduction method by tensor decomposition, achieving a\nlow-dimensional description of SIFT features called Tensor-SIFT for\ncharacterizing local image region properties. Applicable to both color and\ngray-level images, Tensor-SIFT is very distinctive, insensitive to illumination\nchanges, and noise. Finally, we develop an integrated algorithm that combines\nvarious techniques of the simplex algorithm, narrow-band level set and fast\nmarching algorithms. Particularly, we introduce an inter-frame initialization\nmethod and a stopping criterion for the termination of PDE iteration.\nExperiments in challenging image sequences show that the proposed work has\npromising performance.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 01:52:52 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Li", "Peihua", ""]]}, {"id": "1011.3177", "submitter": "Ricardo Sousa", "authors": "Ricardo Sousa and Jaime S. Cardoso", "title": "The Data Replication Method for the Classification with Reject Option", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the most important tasks of machine learning.\nAlthough the most well studied model is the two-class problem, in many\nscenarios there is the opportunity to label critical items for manual revision,\ninstead of trying to automatically classify every item. In this paper we adapt\na paradigm initially proposed for the classification of ordinal data to address\nthe classification problem with reject option. The technique reduces the\nproblem of classifying with reject option to the standard two-class problem.\nThe introduced method is then mapped into support vector machines and neural\nnetworks. Finally, the framework is extended to multiclass ordinal data with\nreject option. An experimental study with synthetic and real data sets,\nverifies the usefulness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 02:48:02 GMT"}, {"version": "v2", "created": "Tue, 16 Nov 2010 08:49:55 GMT"}, {"version": "v3", "created": "Fri, 15 Jul 2011 08:51:23 GMT"}], "update_date": "2011-07-18", "authors_parsed": [["Sousa", "Ricardo", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "1011.3189", "submitter": "Chamberlain Fong", "authors": "Chamberlain Fong, Brian K. Vogel", "title": "Warping Peirce Quincuncial Panoramas", "comments": "updated source code with figures and explanation of the software\n  implementation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Peirce quincuncial projection is a mapping of the surface of a sphere to\nthe interior of a square. It is a conformal map except for four points on the\nequator. These points of non-conformality cause significant artifacts in\nphotographic applications. In this paper, we propose an algorithm and\nuser-interface to mitigate these artifacts. Moreover, in order to facilitate an\ninteractive user-interface, we present a fast algorithm for calculating the\nPeirce quincuncial projection of spherical imagery. We then promote the Peirce\nquincuncial projection as a viable alternative to the more popular\nstereographic projection in some scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 14 Nov 2010 07:53:26 GMT"}, {"version": "v2", "created": "Tue, 16 Nov 2010 17:28:34 GMT"}, {"version": "v3", "created": "Mon, 25 Jul 2011 03:51:45 GMT"}, {"version": "v4", "created": "Sun, 19 Feb 2012 19:55:47 GMT"}, {"version": "v5", "created": "Sat, 26 Sep 2015 21:26:34 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Fong", "Chamberlain", ""], ["Vogel", "Brian K.", ""]]}, {"id": "1011.4058", "submitter": "Kilian Koepsell", "authors": "Charles F. Cadieu and Kilian Koepsell", "title": "Modeling Image Structure with Factorized Phase-Coupled Boltzmann\n  Machines", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cond-mat.dis-nn q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a model for capturing the statistical structure of local\namplitude and local spatial phase in natural images. The model is based on a\nrecently developed, factorized third-order Boltzmann machine that was shown to\nbe effective at capturing higher-order structure in images by modeling\ndependencies among squared filter outputs (Ranzato and Hinton, 2010). Here, we\nextend this model to $L_p$-spherically symmetric subspaces. In order to model\nlocal amplitude and phase structure in images, we focus on the case of two\ndimensional subspaces, and the $L_2$-norm. When trained on natural images the\nmodel learns subspaces resembling quadrature-pair Gabor filters. We then\nintroduce an additional set of hidden units that model the dependencies among\nsubspace phases. These hidden units form a combinatorial mixture of phase\ncoupling distributions, concentrated in the sum and difference of phase pairs.\nWhen adapted to natural images, these distributions capture local spatial phase\nstructure in natural images.\n", "versions": [{"version": "v1", "created": "Wed, 17 Nov 2010 20:55:02 GMT"}], "update_date": "2010-11-18", "authors_parsed": [["Cadieu", "Charles F.", ""], ["Koepsell", "Kilian", ""]]}, {"id": "1011.4321", "submitter": "Zahra Razaee", "authors": "M.H.Fazel Zarandi, Zahra S. Razaee", "title": "A Fuzzy Clustering Model for Fuzzy Data with Outliers", "comments": "18 pages, Journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a fuzzy clustering model for fuzzy data with outliers is\nproposed. The model is based on Wasserstein distance between interval valued\ndata which is generalized to fuzzy data. In addition, Keller's approach is used\nto identify outliers and reduce their influences. We have also defined a\ntransformation to change our distance to the Euclidean distance. With the help\nof this approach, the problem of fuzzy clustering of fuzzy data is reduced to\nfuzzy clustering of crisp data. In order to show the performance of the\nproposed clustering algorithm, two simulation experiments are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 18 Nov 2010 22:20:45 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Zarandi", "M. H. Fazel", ""], ["Razaee", "Zahra S.", ""]]}, {"id": "1011.4615", "submitter": "Idan Ram", "authors": "Idan Ram, Michael Elad, and Israel Cohen", "title": "Generalized Tree-Based Wavelet Transform", "comments": "10 pages, 4 algorithms, 8 figures, 3 tables, submitted to IEEE\n  Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2011.2158428", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new wavelet transform applicable to functions\ndefined on graphs, high dimensional data and networks. The proposed method\ngeneralizes the Haar-like transform proposed in [1], and it is defined via a\nhierarchical tree, which is assumed to capture the geometry and structure of\nthe input data. It is applied to the data using a modified version of the\ncommon one-dimensional (1D) wavelet filtering and decimation scheme, which can\nemploy different wavelet filters. In each level of this wavelet decomposition\nscheme, a permutation derived from the tree is applied to the approximation\ncoefficients, before they are filtered. We propose a tree construction method\nthat results in an efficient representation of the input function in the\ntransform domain. We show that the proposed transform is more efficient than\nboth the 1D and two-dimensional (2D) separable wavelet transforms in\nrepresenting images. We also explore the application of the proposed transform\nto image denoising, and show that combined with a subimage averaging scheme, it\nachieves denoising results which are similar to those obtained with the K-SVD\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 20 Nov 2010 21:32:36 GMT"}, {"version": "v2", "created": "Mon, 28 Feb 2011 22:09:40 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Ram", "Idan", ""], ["Elad", "Michael", ""], ["Cohen", "Israel", ""]]}, {"id": "1011.4829", "submitter": "Guangcan Liu", "authors": "Guangcan Liu, Ju Sun and Shuicheng Yan", "title": "Closed-Form Solutions to A Category of Nuclear Norm Minimization\n  Problems", "comments": null, "journal-ref": "NIPS Workshop on Low-Rank Methods for Large-Scale Machine\n  Learning, 2010", "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is an efficient and effective strategy to utilize the nuclear norm\napproximation to learn low-rank matrices, which arise frequently in machine\nlearning and computer vision. So the exploration of nuclear norm minimization\nproblems is gaining much attention recently. In this paper we shall prove that\nthe following Low-Rank Representation (LRR) \\cite{icml_2010_lrr,lrr_extention}\nproblem: {eqnarray*} \\min_{Z} \\norm{Z}_*, & {s.t.,} & X=AZ, {eqnarray*} has a\nunique and closed-form solution, where $X$ and $A$ are given matrices. The\nproof is based on proving a lemma that allows us to get closed-form solutions\nto a category of nuclear norm minimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Nov 2010 14:52:22 GMT"}, {"version": "v2", "created": "Tue, 23 Nov 2010 03:59:14 GMT"}], "update_date": "2010-11-24", "authors_parsed": [["Liu", "Guangcan", ""], ["Sun", "Ju", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1011.5694", "submitter": "Kaushik Tiwari", "authors": "Kaushik K Tiwari", "title": "Formulation Of A N-Degree Polynomial For Depth Estimation using a Single\n  Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math-ph math.MP physics.comp-ph physics.ed-ph physics.pop-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The depth of a visible surface of a scene is the distance between the surface\nand the sensor. Recovering depth information from two-dimensional images of a\nscene is an important task in computer vision that can assist numerous\napplications such as object recognition, scene interpretation, obstacle\navoidance, inspection and assembly. Various passive depth computation\ntechniques have been developed for computer vision applications. They can be\nclassified into two groups. The first group operates using just one image. The\nsecond group requires more than one image which can be acquired using either\nmultiple cameras or a camera whose parameters and positioning can be changed.\nThis project is aimed to find the real depth of the object from the camera\nwhich had been used to click the photograph. An n-degree polynomial was\nformulated, which maps the pixel depth of an image to the real depth. In order\nto find the coefficients of the polynomial, an experiment was carried out for a\nparticular lens and thus, these coefficients are a unique feature of a\nparticular camera. The procedure explained in this report is a monocular\napproach for estimation of depth of a scene. The idea involves mapping the\nPixel Depth of the object photographed in the image with the Real Depth of the\nobject from the camera lens with an interpolation function. In order to find\nthe parameters of the interpolation function, a set of lines with predefined\ndistance from camera is used, and then the distance of each line from the\nbottom edge of the picture (as the origin line) is calculated.\n", "versions": [{"version": "v1", "created": "Fri, 26 Nov 2010 02:27:34 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Tiwari", "Kaushik K", ""]]}, {"id": "1011.5962", "submitter": "Pantelis Bouboulis", "authors": "Pantelis Bouboulis and Sergios Theodoridis", "title": "Edge Preserving Image Denoising in Reproducing Kernel Hilbert Spaces", "comments": "This work has been selected for the Best Scientific Paper Award\n  (Track III: Signal, Speech, Image and Video Processing) at the ICPR 2010", "journal-ref": "Proceedings of the 20th International Conference on Pattern\n  Recognition, Istanbul: Turkey, 23-26 August 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is the development of a novel approach for the problem\nof Noise Removal, based on the theory of Reproducing Kernels Hilbert Spaces\n(RKHS). The problem is cast as an optimization task in a RKHS, by taking\nadvantage of the celebrated semiparametric Representer Theorem. Examples verify\nthat in the presence of gaussian noise the proposed method performs relatively\nwell compared to wavelet based technics and outperforms them significantly in\nthe presence of impulse or mixed noise.\n  A more detailed version of this work has been published in the IEEE Trans.\nIm. Proc. : P. Bouboulis, K. Slavakis and S. Theodoridis, Adaptive Kernel-based\nImage Denoising employing Semi-Parametric Regularization, IEEE Transactions on\nImage Processing, vol 19(6), 2010, 1465 - 1479.\n", "versions": [{"version": "v1", "created": "Sat, 27 Nov 2010 10:24:12 GMT"}], "update_date": "2010-11-30", "authors_parsed": [["Bouboulis", "Pantelis", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "1011.6656", "submitter": "Ivana Tosic", "authors": "Ivana Tosic, Bruno A. Olshausen and Benjamin J. Culpepper", "title": "Learning sparse representations of depth", "comments": "12 pages", "journal-ref": null, "doi": "10.1109/JSTSP.2011.2158063", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new method for learning and inferring sparse\nrepresentations of depth (disparity) maps. The proposed algorithm relaxes the\nusual assumption of the stationary noise model in sparse coding. This enables\nlearning from data corrupted with spatially varying noise or uncertainty,\ntypically obtained by laser range scanners or structured light depth cameras.\nSparse representations are learned from the Middlebury database disparity maps\nand then exploited in a two-layer graphical model for inferring depth from\nstereo, by including a sparsity prior on the learned features. Since they\ncapture higher-order dependencies in the depth structure, these priors can\ncomplement smoothness priors commonly used in depth inference based on Markov\nRandom Field (MRF) models. Inference on the proposed graph is achieved using an\nalternating iterative optimization technique, where the first layer is solved\nusing an existing MRF-based stereo matching algorithm, then held fixed as the\nsecond layer is solved using the proposed non-stationary sparse coding\nalgorithm. This leads to a general method for improving solutions of state of\nthe art MRF-based depth estimation algorithms. Our experimental results first\nshow that depth inference using learned representations leads to state of the\nart denoising of depth maps obtained from laser range scanners and a time of\nflight camera. Furthermore, we show that adding sparse priors improves the\nresults of two depth estimation methods: the classical graph cut algorithm by\nBoykov et al. and the more recent algorithm of Woodford et al.\n", "versions": [{"version": "v1", "created": "Tue, 30 Nov 2010 19:55:21 GMT"}, {"version": "v2", "created": "Tue, 12 Apr 2011 18:40:24 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Tosic", "Ivana", ""], ["Olshausen", "Bruno A.", ""], ["Culpepper", "Benjamin J.", ""]]}]