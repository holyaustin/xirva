[{"id": "0806.0689", "submitter": "Hongjun Jia", "authors": "Hongjun Jia, Li Zhang", "title": "Directional Cross Diamond Search Algorithm for Fast Block Motion\n  Estimation", "comments": "23 pages, 9 figures, technical report, related paper under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In block-matching motion estimation (BMME), the search patterns have a\nsignificant impact on the algorithm's performance, both the search speed and\nthe search quality. The search pattern should be designed to fit the motion\nvector probability (MVP) distribution characteristics of the real-world\nsequences. In this paper, we build a directional model of MVP distribution to\ndescribe the directional-center-biased characteristic of the MVP distribution\nand the directional characteristics of the conditional MVP distribution more\nexactly based on the detailed statistical data of motion vectors of eighteen\npopular sequences. Three directional search patterns are firstly designed by\nutilizing the directional characteristics and they are the smallest search\npatterns among the popular ones. A new algorithm is proposed using the\nhorizontal cross search pattern as the initial step and the horizontal/vertical\ndiamond search pattern as the subsequent step for the fast BMME, which is\ncalled the directional cross diamond search (DCDS) algorithm. The DCDS\nalgorithm can obtain the motion vector with fewer search points than CDS, DS or\nHEXBS while maintaining the similar or even better search quality. The gain on\nspeedup of DCDS over CDS or DS can be up to 54.9%. The simulation results show\nthat DCDS is efficient, effective and robust, and it can always give the faster\nsearch speed on different sequences than other fast block-matching algorithm in\ncommon use.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2008 05:05:19 GMT"}], "update_date": "2008-06-05", "authors_parsed": [["Jia", "Hongjun", ""], ["Zhang", "Li", ""]]}, {"id": "0806.0870", "submitter": "Laurent Younes", "authors": "Darryl D. Holm, Alain Trouve and Laurent Younes", "title": "The Euler-Poincare theory of Metamorphosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the pattern matching approach to imaging science, the process of\n``metamorphosis'' is template matching with dynamical templates. Here, we\nrecast the metamorphosis equations of into the Euler-Poincare variational\nframework of and show that the metamorphosis equations contain the equations\nfor a perfect complex fluid \\cite{Ho2002}. This result connects the ideas\nunderlying the process of metamorphosis in image matching to the physical\nconcept of order parameter in the theory of complex fluids. After developing\nthe general theory, we reinterpret various examples, including point set, image\nand density metamorphosis. We finally discuss the issue of matching measures\nwith metamorphosis, for which we provide existence theorems for the initial and\nboundary value problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2008 22:58:41 GMT"}], "update_date": "2008-06-14", "authors_parsed": [["Holm", "Darryl D.", ""], ["Trouve", "Alain", ""], ["Younes", "Laurent", ""]]}, {"id": "0806.0899", "submitter": "Victor Patrangenaru", "authors": "V. Patrangenaru, X. Liu, S. Sugathadasa", "title": "A Nonparametric Approach to 3D Shape Analysis from Digital Camera Images\n  - I. in Memory of W.P. Dayawansa", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, for the first time, one develops a nonparametric methodology\nfor an analysis of shapes of configurations of landmarks on real 3D objects\nfrom regular camera photographs, thus making 3D shape analysis very accessible.\nA fundamental result in computer vision by Faugeras (1992), Hartley, Gupta and\nChang (1992) is that generically, a finite 3D configuration of points can be\nretrieved up to a projective transformation, from corresponding configurations\nin a pair of camera images. Consequently, the projective shape of a 3D\nconfiguration can be retrieved from two of its planar views. Given the inherent\nregistration errors, the 3D projective shape can be estimated from a sample of\nphotos of the scene containing that configuration. Projective shapes are here\nregarded as points on projective shape manifolds. Using large sample and\nnonparametric bootstrap methodology for extrinsic means on manifolds, one gives\nconfidence regions and tests for the mean projective shape of a 3D\nconfiguration from its 2D camera images.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2008 04:26:49 GMT"}], "update_date": "2008-06-14", "authors_parsed": [["Patrangenaru", "V.", ""], ["Liu", "X.", ""], ["Sugathadasa", "S.", ""]]}, {"id": "0806.1446", "submitter": "Guoshen Yu", "authors": "Guoshen Yu and Jean-Jacques Slotine", "title": "Fast Wavelet-Based Visual Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a biologically motivated approach to fast visual\nclassification, directly inspired by the recent work of Serre et al.\nSpecifically, trading-off biological accuracy for computational efficiency, we\nexplore using wavelet and grouplet-like transforms to parallel the tuning of\nvisual cortex V1 and V2 cells, alternated with max operations to achieve scale\nand translation invariance. A feature selection procedure is applied during\nlearning to accelerate recognition. We introduce a simple attention-like\nfeedback mechanism, significantly improving recognition and robustness in\nmultiple-object scenes. In experiments, the proposed algorithm achieves or\nexceeds state-of-the-art success rate on object recognition, texture and\nsatellite image classification, language identification and sound\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jun 2008 10:15:04 GMT"}], "update_date": "2008-06-10", "authors_parsed": [["Yu", "Guoshen", ""], ["Slotine", "Jean-Jacques", ""]]}, {"id": "0806.1796", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2), Hicham Laanaya (E3I2), Andreas Arnold-Bos (E3I2)", "title": "Evaluation for Uncertain Image Classification and Segmentation", "comments": null, "journal-ref": "Pattern Recognition 39, 11 (2006) 1987-1995", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year, numerous segmentation and classification algorithms are invented\nor reused to solve problems where machine vision is needed. Generally, the\nefficiency of these algorithms is compared against the results given by one or\nmany human experts. However, in many situations, the location of the real\nboundaries of the objects as well as their classes are not known with certainty\nby the human experts. Furthermore, only one aspect of the segmentation and\nclassification problem is generally evaluated. In this paper we present a new\nevaluation method for classification and segmentation of image, where we take\ninto account both the classification and segmentation results as well as the\nlevel of certainty given by the experts. As a concrete example of our method,\nwe evaluate an automatic seabed characterization algorithm based on sonar\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jun 2008 07:02:45 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"], ["Laanaya", "Hicham", "", "E3I2"], ["Arnold-Bos", "Andreas", "", "E3I2"]]}, {"id": "0806.1798", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2), Christophe Osswald (E3I2)", "title": "Human expert fusion for image classification", "comments": null, "journal-ref": "Information & Security. An International Journal 20 (2006) 122-141", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image classification, merging the opinion of several human experts is very\nimportant for different tasks such as the evaluation or the training. Indeed,\nthe ground truth is rarely known before the scene imaging. We propose here\ndifferent models in order to fuse the informations given by two or more\nexperts. The considered unit for the classification, a small tile of the image,\ncan contain one or more kind of the considered classes given by the experts. A\nsecond problem that we have to take into account, is the amount of certainty of\nthe expert has for each pixel of the tile. In order to solve these problems we\ndefine five models in the context of the Dempster-Shafer Theory and in the\ncontext of the Dezert-Smarandache Theory and we study the possible decisions\nwith these models.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jun 2008 07:09:15 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"], ["Osswald", "Christophe", "", "E3I2"]]}, {"id": "0806.1984", "submitter": "Irina Kogan A", "authors": "S. Feng, I. A. Kogan, H. Krim", "title": "Classification of curves in 2D and 3D via affine integral signatures", "comments": "30 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust classification algorithm for curves in 2D and 3D, under\nthe special and full groups of affine transformations. To each plane or spatial\ncurve we assign a plane signature curve. Curves, equivalent under an affine\ntransformation, have the same signature. The signatures introduced in this\npaper are based on integral invariants, which behave much better on noisy\nimages than classically known differential invariants. The comparison with\nother types of invariants is given in the introduction. Though the integral\ninvariants for planar curves were known before, the affine integral invariants\nfor spatial curves are proposed here for the first time. Using the inductive\nvariation of the moving frame method we compute affine invariants in terms of\nEuclidean invariants. We present two types of signatures, the global signature\nand the local signature. Both signatures are independent of parameterization\n(curve sampling). The global signature depends on the choice of the initial\npoint and does not allow us to compare fragments of curves, and is therefore\nsensitive to occlusions. The local signature, although is slightly more\nsensitive to noise, is independent of the choice of the initial point and is\nnot sensitive to occlusions in an image. It helps establish local equivalence\nof curves. The robustness of these invariants and signatures in their\napplication to the problem of classification of noisy spatial curves extracted\nfrom a 3D object is analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2008 01:12:25 GMT"}], "update_date": "2008-06-13", "authors_parsed": [["Feng", "S.", ""], ["Kogan", "I. A.", ""], ["Krim", "H.", ""]]}, {"id": "0806.2006", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2)", "title": "Fusion de classifieurs pour la classification d'images sonar", "comments": null, "journal-ref": "Revue Nationale des Technologies de l'Information E, 5 (2005)\n  259-268", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present some high level information fusion approaches for\nnumeric and symbolic data. We study the interest of such method particularly\nfor classifier fusion. A comparative study is made in a context of sea bed\ncharacterization from sonar images. The classi- fication of kind of sediment is\na difficult problem because of the data complexity. We compare high level\ninformation fusion and give the obtained performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2008 06:42:07 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2012 20:39:14 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"]]}, {"id": "0806.2007", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2), Christophe Osswald (E3I2)", "title": "Experts Fusion and Multilayer Perceptron Based on Belief Learning for\n  Sonar Image Classification", "comments": "International Conference on Information & Communication Technologies:\n  from Theory to Applications (ICTTA), Damascus : Syrie (2008)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sonar images provide a rapid view of the seabed in order to characterize\nit. However, in such as uncertain environment, real seabed is unknown and the\nonly information we can obtain, is the interpretation of different human\nexperts, sometimes in conflict. In this paper, we propose to manage this\nconflict in order to provide a robust reality for the learning step of\nclassification algorithms. The classification is conducted by a multilayer\nperceptron, taking into account the uncertainty of the reality in the learning\nstage. The results of this seabed characterization are presented on real sonar\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2008 06:44:55 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"], ["Osswald", "Christophe", "", "E3I2"]]}, {"id": "0806.2008", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2), Christophe Osswald (E3I2)", "title": "Generalized proportional conflict redistribution rule applied to Sonar\n  imagery and Radar targets classification", "comments": null, "journal-ref": "Advances and Applications of DSmT for Information Fusion,\n  Florentin Smarandache & Jean Dezert (Ed.) (2006) 289-304", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we present two applications in information fusion in order\nto evaluate the generalized proportional conflict redistribution rule presented\nin the chapter \\cite{Martin06a}. Most of the time the combination rules are\nevaluated only on simple examples. We study here different combination rules\nand compare them in terms of decision on real data. Indeed, in real\napplications, we need a reliable decision and it is the final results that\nmatter. Two applications are presented here: a fusion of human experts opinions\non the kind of underwater sediments depict on sonar image and a classifier\nfusion for radar targets recognition.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2008 06:47:26 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"], ["Osswald", "Christophe", "", "E3I2"]]}, {"id": "0806.2890", "submitter": "Julian McAuley", "authors": "Tiberio S. Caetano, Julian J. McAuley, Li Cheng, Quoc V. Le and Alex\n  J. Smola", "title": "Learning Graph Matching", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a fundamental problem in pattern recognition, graph matching has\napplications in a variety of fields, from computer vision to computational\nbiology. In graph matching, patterns are modeled as graphs and pattern\nrecognition amounts to finding a correspondence between the nodes of different\ngraphs. Many formulations of this problem can be cast in general as a quadratic\nassignment problem, where a linear term in the objective function encodes node\ncompatibility and a quadratic term encodes edge compatibility. The main\nresearch focus in this theme is about designing efficient algorithms for\napproximately solving the quadratic assignment problem, since it is NP-hard. In\nthis paper we turn our attention to a different question: how to estimate\ncompatibility functions such that the solution of the resulting graph matching\nproblem best matches the expected solution that a human would manually provide.\nWe present a method for learning graph matching: the training examples are\npairs of graphs and the `labels' are matches between them. Our experimental\nresults reveal that learning can substantially improve the performance of\nstandard graph matching algorithms. In particular, we find that simple linear\nassignment with such a learning scheme outperforms Graduated Assignment with\nbistochastic normalisation, a state-of-the-art quadratic assignment relaxation\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jun 2008 23:28:08 GMT"}], "update_date": "2008-06-19", "authors_parsed": [["Caetano", "Tiberio S.", ""], ["McAuley", "Julian J.", ""], ["Cheng", "Li", ""], ["Le", "Quoc V.", ""], ["Smola", "Alex J.", ""]]}, {"id": "0806.3885", "submitter": "Vincent Tariel", "authors": "Vincent Tariel", "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  1: the framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adams and Bishop have proposed in 1994 a novel region growing algorithm\ncalled seeded region growing by pixels aggregation (SRGPA). This paper\nintroduces a framework to implement an algorithm using SRGPA. This framework is\nbuilt around two concepts: localization and organization of applied action.\nThis conceptualization gives a quick implementation of algorithms, a direct\ntranslation between the mathematical idea and the numerical implementation, and\nan improvement of algorithms efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2008 13:43:06 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Tariel", "Vincent", ""]]}, {"id": "0806.3887", "submitter": "Vincent Tariel", "authors": "Vincent Tariel", "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  2: how to localize a final partition invariant about the seeded region\n  initialisation order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the previous paper, we have conceptualized the localization and the\norganization of seeded region growing by pixels aggregation (SRGPA) but we do\nnot give the issue when there is a collision between two distinct regions\nduring the growing process. In this paper, we propose two implementations to\nmanage two classical growing processes: one without a boundary region region to\ndivide the other regions and another with. Unfortunately, as noticed by Mehnert\nand Jakway (1997), this partition depends on the seeded region initialisation\norder (SRIO). We propose a growing process, invariant about SRIO such as the\nboundary region is the set of ambiguous pixels.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2008 13:34:15 GMT"}], "update_date": "2008-06-25", "authors_parsed": [["Tariel", "Vincent", ""]]}, {"id": "0806.3928", "submitter": "Vincent Tariel", "authors": "Vincent Tariel", "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  3: a wide range of algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the two previous papers of this serie, we have created a library, called\nPopulation, dedicated to seeded region growing by pixels aggregation and we\nhave proposed different growing processes to get a partition with or without a\nboundary region to divide the other regions or to get a partition invariant\nabout the seeded region initialisation order. Using this work, we implement\nsome algorithms belonging to the field of SRGPA using this library and these\ngrowing processes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2008 17:02:47 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Tariel", "Vincent", ""]]}, {"id": "0806.3939", "submitter": "Vincent Tariel", "authors": "Vincent Tariel", "title": "Conceptualization of seeded region growing by pixels aggregation. Part\n  4: Simple, generic and robust extraction of grains in granular materials\n  obtained by X-ray tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple, generic and robust method to extract the grains\nfrom experimental tridimensionnal images of granular materials obtained by\nX-ray tomography. This extraction has two steps: segmentation and splitting.\nFor the segmentation step, if there is a sufficient contrast between the\ndifferent components, a classical threshold procedure followed by a succession\nof morphological filters can be applied. If not, and if the boundary needs to\nbe localized precisely, a watershed transformation controlled by labels is\napplied. The basement of this transformation is to localize a label included in\nthe component and another label in the component complementary. A \"soft\"\nthreshold following by an opening is applied on the initial image to localize a\nlabel in a component. For any segmentation procedure, the visualisation shows a\nproblem: some groups of two grains, close one to each other, become connected.\nSo if a classical cluster procedure is applied on the segmented binary image,\nthese numerical connected grains are considered as a single grain. To overcome\nthis problem, we applied a procedure introduced by L. Vincent in 1993. This\ngrains extraction is tested for various complexes porous media and granular\nmaterial, to predict various properties (diffusion, electrical conductivity,\ndeformation field) in a good agreement with experiment data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jun 2008 17:40:25 GMT"}, {"version": "v2", "created": "Wed, 23 Jul 2008 15:09:43 GMT"}], "update_date": "2008-07-23", "authors_parsed": [["Tariel", "Vincent", ""]]}]