[{"id": "1404.0106", "submitter": "Shiu Kumar", "authors": "Shiu Kumar, Eun Sik Ham and Seong Ro Lee", "title": "Traffic Monitoring Using M2M Communication", "comments": "2 pages, 2 figures, presented in local conference in Korea South", "journal-ref": "General Fall Conference of Korea Information and Communications\n  Society (KICS) 2012, Seoul, South Korea, 2012, pp. 233-234", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an intelligent traffic monitoring system using wireless\nvision sensor network that captures and processes the real-time video image to\nobtain the traffic flow rate and vehicle speeds along different urban roadways.\nThis system will display the traffic states on the front roadways that can\nguide the drivers to select the right way and avoid potential traffic\ncongestions. On the other hand, it will also monitor the vehicle speeds and\nstore the vehicle details, for those breaking the roadway speed limits, in its\ndatabase. The real-time traffic data is processed by the Personal Computer (PC)\nat the sub roadway station and the traffic flow rate data is transmitted to the\nmain roadway station Arduino 3G via email, where the data is extracted and\ntraffic flow rate displayed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 02:05:55 GMT"}], "update_date": "2014-04-02", "authors_parsed": [["Kumar", "Shiu", ""], ["Ham", "Eun Sik", ""], ["Lee", "Seong Ro", ""]]}, {"id": "1404.0334", "submitter": "Menglong Zhu", "authors": "Menglong Zhu, Nikolay Atanasov, George J. Pappas, Kostas Daniilidis", "title": "Active Deformable Part Models", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an active approach for part-based object detection, which\noptimizes the order of part filter evaluations and the time at which to stop\nand make a prediction. Statistics, describing the part responses, are learned\nfrom training data and are used to formalize the part scheduling problem as an\noffline optimization. Dynamic programming is applied to obtain a policy, which\nbalances the number of part evaluations with the classification accuracy.\nDuring inference, the policy is used as a look-up table to choose the part\norder and the stopping time based on the observed filter responses. The method\nis faster than cascade detection with deformable part models (which does not\noptimize the part order) with negligible loss in accuracy when evaluated on the\nPASCAL VOC 2007 and 2010 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 18:07:58 GMT"}, {"version": "v2", "created": "Wed, 2 Apr 2014 19:00:29 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Zhu", "Menglong", ""], ["Atanasov", "Nikolay", ""], ["Pappas", "George J.", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "1404.0336", "submitter": "John Stuart Haberl Baxter", "authors": "John S.H. Baxter, Martin Rajchl, Jing Yuan, and Terry M. Peters", "title": "A Continuous Max-Flow Approach to General Hierarchical Multi-Labeling\n  Problems", "comments": "11 pages, 1 figure, 3 algorithms -v2: Fixed typos / grammatical\n  errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-region segmentation algorithms often have the onus of incorporating\ncomplex anatomical knowledge representing spatial or geometric relationships\nbetween objects, and general-purpose methods of addressing this knowledge in an\noptimization-based manner have thus been lacking. This paper presents\nGeneralized Hierarchical Max-Flow (GHMF) segmentation, which captures simple\nanatomical part-whole relationships in the form of an unconstrained hierarchy.\nRegularization can then be applied to both parts and wholes independently,\nallowing for spatial grouping and clustering of labels in a globally optimal\nconvex optimization framework. For the purposes of ready integration into a\nvariety of segmentation tasks, the hierarchies can be presented in run-time,\nallowing for the segmentation problem to be readily specified and alternatives\nexplored without undue programming effort or recompilation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2014 18:27:52 GMT"}, {"version": "v2", "created": "Thu, 5 Jun 2014 21:08:26 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Baxter", "John S. H.", ""], ["Rajchl", "Martin", ""], ["Yuan", "Jing", ""], ["Peters", "Terry M.", ""]]}, {"id": "1404.0437", "submitter": "Nasser Mohieddin Abukhdeir", "authors": "Robert Suderman and Daniel Lizotte and Nasser Mohieddin Abukhdeir", "title": "Theory and Application of Shapelets to the Analysis of Surface\n  Self-assembly Imaging", "comments": "11 pages, 8 figures, submitted to the Journal of Computational\n  Physics", "journal-ref": null, "doi": "10.1103/PhysRevE.00.003300", "report-no": null, "categories": "cs.CV physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for quantitative analysis of local pattern strength and defects in\nsurface self-assembly imaging is presented and applied to images of stripe and\nhexagonal ordered domains. The presented method uses \"shapelet\" functions which\nwere originally developed for quantitative analysis of images of galaxies\n($\\propto 10^{20}\\mathrm{m}$). In this work, they are used instead to quantify\nthe presence of translational order in surface self-assembled films ($\\propto\n10^{-9}\\mathrm{m}$) through reformulation into \"steerable\" filters. The\nresulting method is both computationally efficient (with respect to the number\nof filter evaluations), robust to variation in pattern feature shape, and,\nunlike previous approaches, is applicable to a wide variety of pattern types.\nAn application of the method is presented which uses a nearest-neighbour\nanalysis to distinguish between uniform (defect-free) and non-uniform\n(strained, defect-containing) regions within imaged self-assembled domains,\nboth with striped and hexagonal patterns.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 03:01:39 GMT"}], "update_date": "2015-02-27", "authors_parsed": [["Suderman", "Robert", ""], ["Lizotte", "Daniel", ""], ["Abukhdeir", "Nasser Mohieddin", ""]]}, {"id": "1404.0533", "submitter": "Joerg Kappes", "authors": "J\\\"org H. Kappes, Bjoern Andres, Fred A. Hamprecht, Christoph\n  Schn\\\"orr, Sebastian Nowozin, Dhruv Batra, Sungwoong Kim, Bernhard X.\n  Kausler, Thorben Kr\\\"oger, Jan Lellmann, Nikos Komodakis, Bogdan Savchynskyy,\n  Carsten Rother", "title": "A Comparative Study of Modern Inference Techniques for Structured\n  Discrete Energy Minimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Szeliski et al. published an influential study in 2006 on energy minimization\nmethods for Markov Random Fields (MRF). This study provided valuable insights\nin choosing the best optimization technique for certain classes of problems.\nWhile these insights remain generally useful today, the phenomenal success of\nrandom field models means that the kinds of inference problems that have to be\nsolved changed significantly. Specifically, the models today often include\nhigher order interactions, flexible connectivity structures, large\nla\\-bel-spaces of different cardinalities, or learned energy tables. To reflect\nthese changes, we provide a modernized and enlarged study. We present an\nempirical comparison of 32 state-of-the-art optimization techniques on a corpus\nof 2,453 energy minimization instances from diverse applications in computer\nvision. To ensure reproducibility, we evaluate all methods in the OpenGM 2\nframework and report extensive results regarding runtime and solution quality.\nKey insights from our study agree with the results of Szeliski et al. for the\ntypes of models they studied. However, on new and challenging types of models\nour findings disagree and suggest that polyhedral methods and integer\nprogramming solvers are competitive in terms of runtime and solution quality\nover a large range of model types.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 12:27:27 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Kappes", "J\u00f6rg H.", ""], ["Andres", "Bjoern", ""], ["Hamprecht", "Fred A.", ""], ["Schn\u00f6rr", "Christoph", ""], ["Nowozin", "Sebastian", ""], ["Batra", "Dhruv", ""], ["Kim", "Sungwoong", ""], ["Kausler", "Bernhard X.", ""], ["Kr\u00f6ger", "Thorben", ""], ["Lellmann", "Jan", ""], ["Komodakis", "Nikos", ""], ["Savchynskyy", "Bogdan", ""], ["Rother", "Carsten", ""]]}, {"id": "1404.0566", "submitter": "Lenka H\\'akov\\'a", "authors": "Goce Chadzitaskos, Lenka H\\'akov\\'a, Ond\\v{r}ej Kaj\\'inek", "title": "Weyl group orbit functions in image processing", "comments": "12 pages, 5 figures", "journal-ref": "Applied Mathematics, Vol. 5 No. 3, 2014, pp. 501-511", "doi": "10.4236/am.2014.53049.", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with the Fourier-like analysis of functions on discrete grids in\ntwo-dimensional simplexes using $C-$ and $E-$ Weyl group orbit functions. For\nthese cases we present the convolution theorem. We provide an example of\napplication of image processing using the $C-$ functions and the convolutions\nfor spatial filtering of the treated image.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2014 09:42:37 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Chadzitaskos", "Goce", ""], ["H\u00e1kov\u00e1", "Lenka", ""], ["Kaj\u00ednek", "Ond\u0159ej", ""]]}, {"id": "1404.0600", "submitter": "Oscar Esteban", "authors": "Oscar Esteban, Gert Wollny, Subrahmanyam Gorthi, Maria-J.\n  Ledesma-Carbayo, Jean-Philippe Thiran, Andres Santos and Meritxell\n  Bach-Cuadra", "title": "MBIS: Multivariate Bayesian Image Segmentation Tool", "comments": null, "journal-ref": "Comput. Meth. Prog. Bio. 115(2):76-94 (2014)", "doi": "10.1016/j.cmpb.2014.03.003", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present MBIS (Multivariate Bayesian Image Segmentation tool), a clustering\ntool based on the mixture of multivariate normal distributions model. MBIS\nsupports multi-channel bias field correction based on a B-spline model. A\nsecond methodological novelty is the inclusion of graph-cuts optimization for\nthe stationary anisotropic hidden Markov random field model. Along with MBIS,\nwe release an evaluation framework that contains three different experiments on\nmulti-site data. We first validate the accuracy of segmentation and the\nestimated bias field for each channel. MBIS outperforms a widely used\nsegmentation tool in a cross-comparison evaluation. The second experiment\ndemonstrates the robustness of results on atlas-free segmentation of two image\nsets from scan-rescan protocols on 21 healthy subjects. Multivariate\nsegmentation is more replicable than the monospectral counterpart on\nT1-weighted images. Finally, we provide a third experiment to illustrate how\nMBIS can be used in a large-scale study of tissue volume change with increasing\nage in 584 healthy subjects. This last result is meaningful as multivariate\nsegmentation performs robustly without the need for prior knowledge\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 16:10:39 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2014 11:12:12 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Esteban", "Oscar", ""], ["Wollny", "Gert", ""], ["Gorthi", "Subrahmanyam", ""], ["Ledesma-Carbayo", "Maria-J.", ""], ["Thiran", "Jean-Philippe", ""], ["Santos", "Andres", ""], ["Bach-Cuadra", "Meritxell", ""]]}, {"id": "1404.0627", "submitter": "Mohammed  Javed", "authors": "Mohammed Javed, P. Nagabhushan, B.B. Chaudhuri", "title": "Extraction of Projection Profile, Run-Histogram and Entropy Features\n  Straight from Run-Length Compressed Text-Documents", "comments": "Published by IEEE in Proceedings of ACPR-2013. arXiv admin note: text\n  overlap with arXiv:1403.7783", "journal-ref": "2013 Second IAPR Asian Conference on Pattern Recognition, Pages\n  813-817", "doi": "10.1109/ACPR.2013.147", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document Image Analysis, like any Digital Image Analysis requires\nidentification and extraction of proper features, which are generally extracted\nfrom uncompressed images, though in reality images are made available in\ncompressed form for the reasons such as transmission and storage efficiency.\nHowever, this implies that the compressed image should be decompressed, which\nindents additional computing resources. This limitation induces the motivation\nto research in extracting features directly from the compressed image. In this\nresearch, we propose to extract essential features such as projection profile,\nrun-histogram and entropy for text document analysis directly from run-length\ncompressed text-documents. The experimentation illustrates that features are\nextracted directly from the compressed image without going through the stage of\ndecompression, because of which the computing time is reduced. The feature\nvalues so extracted are exactly identical to those extracted from uncompressed\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 17:34:13 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Javed", "Mohammed", ""], ["Nagabhushan", "P.", ""], ["Chaudhuri", "B. B.", ""]]}, {"id": "1404.0736", "submitter": "Emily Denton", "authors": "Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, Rob Fergus", "title": "Exploiting Linear Structure Within Convolutional Networks for Efficient\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present techniques for speeding up the test-time evaluation of large\nconvolutional networks, designed for object recognition tasks. These models\ndeliver impressive accuracy but each image evaluation requires millions of\nfloating point operations, making their deployment on smartphones and\nInternet-scale clusters problematic. The computation is dominated by the\nconvolution operations in the lower layers of the model. We exploit the linear\nstructure present within the convolutional filters to derive approximations\nthat significantly reduce the required computation. Using large\nstate-of-the-art models, we demonstrate we demonstrate speedups of\nconvolutional layers on both CPU and GPU by a factor of 2x, while keeping the\naccuracy within 1% of the original model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 23:31:12 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2014 15:53:55 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Denton", "Emily", ""], ["Zaremba", "Wojciech", ""], ["Bruna", "Joan", ""], ["LeCun", "Yann", ""], ["Fergus", "Rob", ""]]}, {"id": "1404.0774", "submitter": "Md. Enamul Haque", "authors": "Md. Enamul Haque, Abdullah Al Kaisan, Mahmudur R Saniat, and Aminur\n  Rahman", "title": "GPU Accelerated Fractal Image Compression for Medical Imaging in\n  Parallel Computing Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we implemented both sequential and parallel version of fractal\nimage compression algorithms using CUDA (Compute Unified Device Architecture)\nprogramming model for parallelizing the program in Graphics Processing Unit for\nmedical images, as they are highly similar within the image itself. There are\nseveral improvement in the implementation of the algorithm as well. Fractal\nimage compression is based on the self similarity of an image, meaning an image\nhaving similarity in majority of the regions. We take this opportunity to\nimplement the compression algorithm and monitor the effect of it using both\nparallel and sequential implementation. Fractal compression has the property of\nhigh compression rate and the dimensionless scheme. Compression scheme for\nfractal image is of two kind, one is encoding and another is decoding. Encoding\nis very much computational expensive. On the other hand decoding is less\ncomputational. The application of fractal compression to medical images would\nallow obtaining much higher compression ratios. While the fractal magnification\nan inseparable feature of the fractal compression would be very useful in\npresenting the reconstructed image in a highly readable form. However, like all\nirreversible methods, the fractal compression is connected with the problem of\ninformation loss, which is especially troublesome in the medical imaging. A\nvery time consuming encoding pro- cess, which can last even several hours, is\nanother bothersome drawback of the fractal compression.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 06:27:12 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Haque", "Md. Enamul", ""], ["Kaisan", "Abdullah Al", ""], ["Saniat", "Mahmudur R", ""], ["Rahman", "Aminur", ""]]}, {"id": "1404.1116", "submitter": "Ayush Bhandari", "authors": "Ayush Bhandari, Achuta Kadambi, Refael Whyte, Christopher Barsi, Micha\n  Feigin, Adrian Dorrington, and Ramesh Raskar", "title": "Resolving Multi-path Interference in Time-of-Flight Imaging via\n  Modulation Frequency Diversity and Sparse Regularization", "comments": "11 Pages, 4 figures, appeared with minor changes in Optics Letters", "journal-ref": "Optics Letters, Vol. 39, Issue 6, pp. 1705-1708 (2014)", "doi": "10.1364/OL.39.001705", "report-no": null, "categories": "cs.CV cs.IT math.IT physics.optics", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Time-of-flight (ToF) cameras calculate depth maps by reconstructing phase\nshifts of amplitude-modulated signals. For broad illumination or transparent\nobjects, reflections from multiple scene points can illuminate a given pixel,\ngiving rise to an erroneous depth map. We report here a sparsity regularized\nsolution that separates K-interfering components using multiple modulation\nfrequency measurements. The method maps ToF imaging to the general framework of\nspectral estimation theory and has applications in improving depth profiles and\nexploiting multiple scattering.\n", "versions": [{"version": "v1", "created": "Thu, 3 Apr 2014 23:22:48 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Bhandari", "Ayush", ""], ["Kadambi", "Achuta", ""], ["Whyte", "Refael", ""], ["Barsi", "Christopher", ""], ["Feigin", "Micha", ""], ["Dorrington", "Adrian", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1404.1129", "submitter": "Chengyu  Peng", "authors": "Chengyu Peng, Hong Cheng, Manchor Ko", "title": "An Efficient Two-Stage Sparse Representation Method", "comments": "21 pages, 2 figures, 4 tables", "journal-ref": null, "doi": "10.1142/S0218001416510010", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a large number of methods for solving under-determined linear\ninverse problem. Many of them have very high time complexity for large\ndatasets. We propose a new method called Two-Stage Sparse Representation (TSSR)\nto tackle this problem. We decompose the representing space of signals into two\nparts, the measurement dictionary and the sparsifying basis. The dictionary is\ndesigned to approximate a sub-Gaussian distribution to exploit its\nconcentration property. We apply sparse coding to the signals on the dictionary\nin the first stage, and obtain the training and testing coefficients\nrespectively. Then we design the basis to approach an identity matrix in the\nsecond stage, to acquire the Restricted Isometry Property (RIP) and\nuniversality property. The testing coefficients are encoded over the basis and\nthe final representing coefficients are obtained. We verify that the projection\nof testing coefficients onto the basis is a good approximation of the signal\nonto the representing space. Since the projection is conducted on a much\nsparser space, the runtime is greatly reduced. For concrete realization, we\nprovide an instance for the proposed TSSR. Experiments on four biometrics\ndatabases show that TSSR is effective and efficient, comparing with several\nclassical methods for solving linear inverse problem.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2014 01:57:25 GMT"}, {"version": "v2", "created": "Fri, 25 Jul 2014 14:31:31 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Peng", "Chengyu", ""], ["Cheng", "Hong", ""], ["Ko", "Manchor", ""]]}, {"id": "1404.1151", "submitter": "Sadanand Kulkarni A", "authors": "Sadanand A. Kulkarni, Prashant L. Borde, Ramesh R. Manza, Pravin L.\n  Yannawar", "title": "Recognition of Handwritten MODI Numerals using Hu and Zernike features", "comments": "This paper has been withdrawn by the author due to the paper was\n  rejected by journal with a reson \"paper was not suitable for the journal\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwritten automatic character recognition has attracted many researchers\nall over the world to contribute automatic character recognition domain. Shape\nidentification and feature extraction is very important part of any character\nrecognition system and success of method is highly dependent on selection of\nfeatures. However feature extraction is the most important step in defining the\nshape of the character as precisely and as uniquely as possible. This is indeed\nthe most important step and complex task as well and achieved success by using\ninvariance property, irrespective of position and orientation. Zernike moments\ndescribes shape, identify rotation invariant due to its Orthogonality property.\nMODI is an ancient script of India had cursive and complex representation of\ncharacters. The work described in this paper presents efficiency of Zernike\nmoments over Hus moment for automatic recognition of handwritten MODI numerals.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2014 04:31:52 GMT"}, {"version": "v2", "created": "Thu, 3 Jul 2014 06:21:13 GMT"}, {"version": "v3", "created": "Mon, 27 Oct 2014 13:17:22 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Kulkarni", "Sadanand A.", ""], ["Borde", "Prashant L.", ""], ["Manza", "Ramesh R.", ""], ["Yannawar", "Pravin L.", ""]]}, {"id": "1404.1292", "submitter": "Omaima Al-Allaf Nazar", "authors": "Omaima N. A. AL-Allaf", "title": "Review of Face Detection Systems Based Artificial Neural Networks\n  Algorithms", "comments": "16 pages, 12 figures, 1 table, IJMA Journal", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.6, No.1, February 2014", "doi": "10.5121/ijma.2013.6101", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face detection is one of the most relevant applications of image processing\nand biometric systems. Artificial neural networks (ANN) have been used in the\nfield of image processing and pattern recognition. There is lack of literature\nsurveys which give overview about the studies and researches related to the\nusing of ANN in face detection. Therefore, this research includes a general\nreview of face detection studies and systems which based on different ANN\napproaches and algorithms. The strengths and limitations of these literature\nstudies and systems were included also.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 19:47:58 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["AL-Allaf", "Omaima N. A.", ""]]}, {"id": "1404.1514", "submitter": "Avinash Bhute", "authors": "Avinash N Bhute, B.B. Meshram", "title": "Text Based Approach For Indexing And Retrieval Of Image And Video: A\n  Review", "comments": "12 pages", "journal-ref": "Advances in Vision: An International Journal, Vol 1, no. 1, March\n  2014", "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.DL cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Text data present in multimedia contain useful information for automatic\nannotation, indexing. Extracted information used for recognition of the overlay\nor scene text from a given video or image. The Extracted text can be used for\nretrieving the videos and images. In this paper, firstly, we are discussed the\ndifferent techniques for text extraction from images and videos. Secondly, we\nare reviewed the techniques for indexing and retrieval of image and videos by\nusing extracted text.\n", "versions": [{"version": "v1", "created": "Sat, 5 Apr 2014 19:58:38 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Bhute", "Avinash N", ""], ["Meshram", "B. B.", ""]]}, {"id": "1404.1561", "submitter": "Chunhua Shen", "authors": "Guosheng Lin, Chunhua Shen, Qinfeng Shi, Anton van den Hengel, David\n  Suter", "title": "Fast Supervised Hashing with Decision Trees for High-Dimensional Data", "comments": "Appearing in Proc. IEEE Conf. Computer Vision and Pattern\n  Recognition, 2014, Ohio, USA", "journal-ref": null, "doi": "10.1109/CVPR.2014.253", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised hashing aims to map the original features to compact binary codes\nthat are able to preserve label based similarity in the Hamming space.\nNon-linear hash functions have demonstrated the advantage over linear ones due\nto their powerful generalization capability. In the literature, kernel\nfunctions are typically used to achieve non-linearity in hashing, which achieve\nencouraging retrieval performance at the price of slow evaluation and training\ntime. Here we propose to use boosted decision trees for achieving non-linearity\nin hashing, which are fast to train and evaluate, hence more suitable for\nhashing with high dimensional data. In our approach, we first propose\nsub-modular formulations for the hashing binary code inference problem and an\nefficient GraphCut based block search method for solving large-scale inference.\nThen we learn hash functions by training boosted decision trees to fit the\nbinary codes. Experiments demonstrate that our proposed method significantly\noutperforms most state-of-the-art methods in retrieval precision and training\ntime. Especially for high-dimensional data, our method is orders of magnitude\nfaster than many methods in terms of training time.\n", "versions": [{"version": "v1", "created": "Sun, 6 Apr 2014 10:42:36 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 00:25:43 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lin", "Guosheng", ""], ["Shen", "Chunhua", ""], ["Shi", "Qinfeng", ""], ["Hengel", "Anton van den", ""], ["Suter", "David", ""]]}, {"id": "1404.1664", "submitter": "Basant Agarwal", "authors": "Namita Mittal, Basant Agarwal, Ajay Gupta, Hemant Madhur", "title": "Icon Based Information Retrieval and Disease Identification in\n  Agriculture", "comments": "Iconic Interface, Image Processing, Pattern Recognition, Data Mining,\n  Information Retrieval", "journal-ref": "International Journal of Advanced Studies in Computer Science &\n  Engineering IJASCSE, Volume 3, Issue 3, 2014", "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the ICT industry in past few decades has enabled the\nquick and easy access to the information available on the internet. But,\ndigital literacy is the pre-requisite for its use. The main purpose of this\npaper is to provide an interface for digitally illiterate users, especially\nfarmers to efficiently and effectively retrieve information through Internet.\nIn addition, to enable the farmers to identify the disease in their crop, its\ncause and symptoms using digital image processing and pattern recognition\ninstantly without waiting for an expert to visit the farms and identify the\ndisease.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 06:20:53 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Mittal", "Namita", ""], ["Agarwal", "Basant", ""], ["Gupta", "Ajay", ""], ["Madhur", "Hemant", ""]]}, {"id": "1404.1682", "submitter": "Carmine Clemente Dr", "authors": "Carmine Clemente, Luca Pallotta, Ian Proudler, Antonio De Maio, John\n  J. Soraghan and Alfonso Farina", "title": "Pseudo-Zernike Based Multi-Pass Automatic Target Recognition From\n  Multi-Channel SAR", "comments": "The paper has been withdrawn due to conceptual errors in the\n  performance analysis and to the fact that a substantial restructuring of the\n  paper is required", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to exploit multiple sources of information is of fundamental\nimportance in a battlefield scenario. Information obtained from different\nsources, and separated in space and time, provide the opportunity to exploit\ndiversities in order to mitigate uncertainty. For the specific challenge of\nAutomatic Target Recognition (ATR) from radar platforms, both channel (e.g.\npolarization) and spatial diversity can provide useful information for such a\nspecific and critical task. In this paper the use of pseudo-Zernike moments\napplied to multi-channel multi-pass data is presented exploiting diversities\nand invariant properties leading to high confidence ATR, small computational\ncomplexity and data transfer requirements. The effectiveness of the proposed\napproach, in different configurations and data source availability is\ndemonstrated using real data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 08:00:59 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 15:39:05 GMT"}, {"version": "v3", "created": "Wed, 6 Aug 2014 08:13:26 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Clemente", "Carmine", ""], ["Pallotta", "Luca", ""], ["Proudler", "Ian", ""], ["De Maio", "Antonio", ""], ["Soraghan", "John J.", ""], ["Farina", "Alfonso", ""]]}, {"id": "1404.1777", "submitter": "Victor Lempitsky", "authors": "Artem Babenko, Anton Slesarev, Alexandr Chigorin and Victor Lempitsky", "title": "Neural Codes for Image Retrieval", "comments": "to appear at ECCV 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that the activations invoked by an image within the top\nlayers of a large convolutional neural network provide a high-level descriptor\nof the visual content of the image. In this paper, we investigate the use of\nsuch descriptors (neural codes) within the image retrieval application. In the\nexperiments with several standard retrieval benchmarks, we establish that\nneural codes perform competitively even when the convolutional neural network\nhas been trained for an unrelated classification task (e.g.\\ Image-Net). We\nalso evaluate the improvement in the retrieval performance of neural codes,\nwhen the network is retrained on a dataset of images that are similar to images\nencountered at test time.\n  We further evaluate the performance of the compressed neural codes and show\nthat a simple PCA compression provides very good short codes that give\nstate-of-the-art accuracy on a number of datasets. In general, neural codes\nturn out to be much more resilient to such compression in comparison other\nstate-of-the-art descriptors. Finally, we show that discriminative\ndimensionality reduction trained on a dataset of pairs of matched photographs\nimproves the performance of PCA-compressed neural codes even further. Overall,\nour quantitative experiments demonstrate the promise of neural codes as visual\ndescriptors for image retrieval.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 13:08:08 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 07:51:04 GMT"}], "update_date": "2014-07-08", "authors_parsed": [["Babenko", "Artem", ""], ["Slesarev", "Anton", ""], ["Chigorin", "Alexandr", ""], ["Lempitsky", "Victor", ""]]}, {"id": "1404.1831", "submitter": "Artem Babenko", "authors": "Artem Babenko and Victor Lempitsky", "title": "Improving Bilayer Product Quantization for Billion-Scale Approximate\n  Nearest Neighbors in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top-performing systems for billion-scale high-dimensional approximate\nnearest neighbor (ANN) search are all based on two-layer architectures that\ninclude an indexing structure and a compressed datapoints layer. An indexing\nstructure is crucial as it allows to avoid exhaustive search, while the lossy\ndata compression is needed to fit the dataset into RAM. Several of the most\nsuccessful systems use product quantization (PQ) for both the indexing and the\ndataset compression layers. These systems are however limited in the way they\nexploit the interaction of product quantization processes that happen at\ndifferent stages of these systems.\n  Here we introduce and evaluate two approximate nearest neighbor search\nsystems that both exploit the synergy of product quantization processes in a\nmore efficient way. The first system, called Fast Bilayer Product Quantization\n(FBPQ), speeds up the runtime of the baseline system (Multi-D-ADC) by several\ntimes, while achieving the same accuracy. The second system, Hierarchical\nBilayer Product Quantization (HBPQ) provides a significantly better recall for\nthe same runtime at a cost of small memory footprint increase. For the BIGANN\ndataset of billion SIFT descriptors, the 10% increase in Recall@1 and the 17%\nincrease in Recall@10 is observed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 16:08:13 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Babenko", "Artem", ""], ["Lempitsky", "Victor", ""]]}, {"id": "1404.1869", "submitter": "Forrest Iandola", "authors": "Forrest Iandola, Matt Moskewicz, Sergey Karayev, Ross Girshick, Trevor\n  Darrell, Kurt Keutzer", "title": "DenseNet: Implementing Efficient ConvNet Descriptor Pyramids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) can provide accurate object\nclassification. They can be extended to perform object detection by iterating\nover dense or selected proposed object regions. However, the runtime of such\ndetectors scales as the total number and/or area of regions to examine per\nimage, and training such detectors may be prohibitively slow. However, for some\nCNN classifier topologies, it is possible to share significant work among\noverlapping regions to be classified. This paper presents DenseNet, an open\nsource system that computes dense, multiscale features from the convolutional\nlayers of a CNN based object classifier. Future work will involve training\nefficient object detectors with DenseNet feature descriptors.\n", "versions": [{"version": "v1", "created": "Mon, 7 Apr 2014 18:08:56 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Iandola", "Forrest", ""], ["Moskewicz", "Matt", ""], ["Karayev", "Sergey", ""], ["Girshick", "Ross", ""], ["Darrell", "Trevor", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1404.2005", "submitter": "Duc Phu Chau", "authors": "Duc Phu Chau (INRIA Sophia Antipolis), Fran\\c{c}ois Bremond (INRIA\n  Sophia Antipolis), Monique Thonnat (INRIA Sophia Antipolis), Slawomir Bak\n  (INRIA Sophia Antipolis)", "title": "Automatic Tracker Selection w.r.t Object Detection Performance", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV 2014)\n  (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tracking algorithm performance depends on video content. This paper\npresents a new multi-object tracking approach which is able to cope with video\ncontent variations. First the object detection is improved using Kanade-\nLucas-Tomasi (KLT) feature tracking. Second, for each mobile object, an\nappropriate tracker is selected among a KLT-based tracker and a discriminative\nappearance-based tracker. This selection is supported by an online tracking\nevaluation. The approach has been experimented on three public video datasets.\nThe experimental results show a better performance of the proposed approach\ncompared to recent state of the art trackers.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2014 04:09:32 GMT"}], "update_date": "2014-04-09", "authors_parsed": [["Chau", "Duc Phu", "", "INRIA Sophia Antipolis"], ["Bremond", "Fran\u00e7ois", "", "INRIA\n  Sophia Antipolis"], ["Thonnat", "Monique", "", "INRIA Sophia Antipolis"], ["Bak", "Slawomir", "", "INRIA Sophia Antipolis"]]}, {"id": "1404.2014", "submitter": "Mohammed  Javed", "authors": "P. Nagabhushan, Mohammed Javed, B.B. Chaudhuri", "title": "Entropy Computation of Document Images in Run-Length Compressed Domain", "comments": "Published in IEEE Proceedings 2014 Fifth International Conference on\n  Signals and Image Processing", "journal-ref": "In IEEE Proceedings 2014 Fifth International Conference on Signals\n  and Image Processing, Pages 287-291", "doi": "10.1109/ICSIP.2014.51", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compression of documents, images, audios and videos have been traditionally\npracticed to increase the efficiency of data storage and transfer. However, in\norder to process or carry out any analytical computations, decompression has\nbecome an unavoidable pre-requisite. In this research work, we have attempted\nto compute the entropy, which is an important document analytic directly from\nthe compressed documents. We use Conventional Entropy Quantifier (CEQ) and\nSpatial Entropy Quantifiers (SEQ) for entropy computations [1]. The entropies\nobtained are useful in applications like establishing equivalence, word\nspotting and document retrieval. Experiments have been performed with all the\ndata sets of [1], at character, word and line levels taking compressed\ndocuments in run-length compressed domain. The algorithms developed are\ncomputational and space efficient, and results obtained match 100% with the\nresults reported in [1].\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2014 05:15:18 GMT"}], "update_date": "2014-04-09", "authors_parsed": [["Nagabhushan", "P.", ""], ["Javed", "Mohammed", ""], ["Chaudhuri", "B. B.", ""]]}, {"id": "1404.2086", "submitter": "Uwe Schmidt", "authors": "Uwe Schmidt, Jeremy Jancsary, Sebastian Nowozin, Stefan Roth, Carsten\n  Rother", "title": "Cascades of Regression Tree Fields for Image Restoration", "comments": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2015.2441053", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional random fields (CRFs) are popular discriminative models for\ncomputer vision and have been successfully applied in the domain of image\nrestoration, especially to image denoising. For image deblurring, however,\ndiscriminative approaches have been mostly lacking. We posit two reasons for\nthis: First, the blur kernel is often only known at test time, requiring any\ndiscriminative approach to cope with considerable variability. Second, given\nthis variability it is quite difficult to construct suitable features for\ndiscriminative prediction. To address these challenges we first show a\nconnection between common half-quadratic inference for generative image priors\nand Gaussian CRFs. Based on this analysis, we then propose a cascade model for\nimage restoration that consists of a Gaussian CRF at each stage. Each stage of\nour cascade is semi-parametric, i.e. it depends on the instance-specific\nparameters of the restoration problem, such as the blur kernel. We train our\nmodel by loss minimization with synthetically generated training data. Our\nexperiments show that when applied to non-blind image deblurring, the proposed\napproach is efficient and yields state-of-the-art restoration quality on images\ncorrupted with synthetic and real blur. Moreover, we demonstrate its\nsuitability for image denoising, where we achieve competitive results for\ngrayscale and color images.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2014 10:52:41 GMT"}, {"version": "v2", "created": "Fri, 21 Nov 2014 03:25:24 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Schmidt", "Uwe", ""], ["Jancsary", "Jeremy", ""], ["Nowozin", "Sebastian", ""], ["Roth", "Stefan", ""], ["Rother", "Carsten", ""]]}, {"id": "1404.2268", "submitter": "Junyan Wang", "authors": "Junyan Wang and Sai-Kit Yeung", "title": "A Compact Linear Programming Relaxation for Binary Sub-modular MRF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel compact linear programming (LP) relaxation for binary\nsub-modular MRF in the context of object segmentation. Our model is obtained by\nlinearizing an $l_1^+$-norm derived from the quadratic programming (QP) form of\nthe MRF energy. The resultant LP model contains significantly fewer variables\nand constraints compared to the conventional LP relaxation of the MRF energy.\nIn addition, unlike QP which can produce ambiguous labels, our model can be\nviewed as a quasi-total-variation minimization problem, and it can therefore\npreserve the discontinuities in the labels. We further establish a relaxation\nbound between our LP model and the conventional LP model. In the experiments,\nwe demonstrate our method for the task of interactive object segmentation. Our\nLP model outperforms QP when converting the continuous labels to binary labels\nusing different threshold values on the entire Oxford interactive segmentation\ndataset. The computational complexity of our LP is of the same order as that of\nthe QP, and it is significantly lower than the conventional LP relaxation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2014 16:33:44 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Wang", "Junyan", ""], ["Yeung", "Sai-Kit", ""]]}, {"id": "1404.2571", "submitter": "Martin Rajchl MSc", "authors": "Martin Rajchl, John S.H. Baxter, Wu Qiu, Ali R. Khan, Aaron Fenster,\n  Terry M. Peters, and Jing Yuan", "title": "RANCOR: Non-Linear Image Registration with Total Variation\n  Regularization", "comments": "9 pages, 1 figure, technical note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization techniques have been widely used in deformable registration,\nallowing for the incorporation of similarity metrics with regularization\nmechanisms. These regularization mechanisms are designed to mitigate the\neffects of trivial solutions to ill-posed registration problems and to\notherwise ensure the resulting deformation fields are well-behaved. This paper\nintroduces a novel deformable registration algorithm, RANCOR, which uses\niterative convexification to address deformable registration problems under\ntotal-variation regularization. Initial comparative results against four\nstate-of-the-art registration algorithms are presented using the Internet Brain\nSegmentation Repository (IBSR) database.\n", "versions": [{"version": "v1", "created": "Wed, 9 Apr 2014 18:30:38 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Rajchl", "Martin", ""], ["Baxter", "John S. H.", ""], ["Qiu", "Wu", ""], ["Khan", "Ali R.", ""], ["Fenster", "Aaron", ""], ["Peters", "Terry M.", ""], ["Yuan", "Jing", ""]]}, {"id": "1404.2728", "submitter": "Wei Hu", "authors": "Wei Hu and Wei Li and Fan Zhang and Qian Du", "title": "Real-time Decolorization using Dominant Colors", "comments": "This paper has been withdrawn by the author due to some errors in\n  equation 9 related descriptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decolorization is the process to convert a color image or video to its\ngrayscale version, and it has received great attention in recent years. An\nideal decolorization algorithm should preserve the original color contrast as\nmuch as possible. Meanwhile, it should provide the final decolorized result as\nfast as possible. However, most of the current methods are suffering from\neither unsatisfied color information preservation or high computational cost,\nlimiting their application value. In this paper, a simple but effective\ntechnique is proposed for real-time decolorization. Based on the typical\nrgb2gray() color conversion model, which produces a grayscale image by linearly\ncombining R, G, and B channels, we propose a dominant color hypothesis and a\ncorresponding distance measurement metric to evaluate the quality of grayscale\nconversion. The local optimum scheme provides several \"good\" candidates in a\nconfidence interval, from which the \"best\" result can be extracted.\nExperimental results demonstrate that remarkable simplicity of the proposed\nmethod facilitates the process of high resolution images and videos in\nreal-time using a common CPU.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2014 08:25:20 GMT"}, {"version": "v2", "created": "Tue, 22 Apr 2014 02:26:25 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Hu", "Wei", ""], ["Li", "Wei", ""], ["Zhang", "Fan", ""], ["Du", "Qian", ""]]}, {"id": "1404.2903", "submitter": "Marius Leordeanu", "authors": "Marius Leordeanu and Rahul Sukthankar", "title": "Thoughts on a Recursive Classifier Graph: a Multiclass Network for Deep\n  Object Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general multi-class visual recognition model, termed the\nClassifier Graph, which aims to generalize and integrate ideas from many of\ntoday's successful hierarchical recognition approaches. Our graph-based model\nhas the advantage of enabling rich interactions between classes from different\nlevels of interpretation and abstraction. The proposed multi-class system is\nefficiently learned using step by step updates. The structure consists of\nsimple logistic linear layers with inputs from features that are automatically\nselected from a large pool. Each newly learned classifier becomes a potential\nnew feature. Thus, our feature pool can consist both of initial manually\ndesigned features as well as learned classifiers from previous steps (graph\nnodes), each copied many times at different scales and locations. In this\nmanner we can learn and grow both a deep, complex graph of classifiers and a\nrich pool of features at different levels of abstraction and interpretation.\nOur proposed graph of classifiers becomes a multi-class system with a recursive\nstructure, suitable for deep detection and recognition of several classes\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 2 Apr 2014 11:38:35 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Leordeanu", "Marius", ""], ["Sukthankar", "Rahul", ""]]}, {"id": "1404.2999", "submitter": "Tianlin Shi", "authors": "Tianlin Shi, Liang Ming, Xiaolin Hu", "title": "A Reverse Hierarchy Model for Predicting Eye Fixations", "comments": "CVPR 2014, 27th IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR). CVPR 2014", "journal-ref": null, "doi": "10.1109/CVPR.2014.361", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of psychological and physiological evidences suggest that early\nvisual attention works in a coarse-to-fine way, which lays a basis for the\nreverse hierarchy theory (RHT). This theory states that attention propagates\nfrom the top level of the visual hierarchy that processes gist and abstract\ninformation of input, to the bottom level that processes local details.\nInspired by the theory, we develop a computational model for saliency detection\nin images. First, the original image is downsampled to different scales to\nconstitute a pyramid. Then, saliency on each layer is obtained by image\nsuper-resolution reconstruction from the layer above, which is defined as\nunpredictability from this coarse-to-fine reconstruction. Finally, saliency on\neach layer of the pyramid is fused into stochastic fixations through a\nprobabilistic model, where attention initiates from the top layer and\npropagates downward through the pyramid. Extensive experiments on two standard\neye-tracking datasets show that the proposed method can achieve competitive\nresults with state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2014 04:39:21 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Shi", "Tianlin", ""], ["Ming", "Liang", ""], ["Hu", "Xiaolin", ""]]}, {"id": "1404.3012", "submitter": "Shun Kataoka", "authors": "Kazuyuki Tanaka, Shun Kataoka, Muneki Yasuda, Yuji Waizumi and\n  Chiou-Ting Hsu", "title": "Bayesian image segmentations by Potts prior and loopy belief propagation", "comments": "24 pages, 9 figures", "journal-ref": "Journal of the Physical Society of Japan 83 (2014) 124002", "doi": "10.7566/JPSJ.83.124002", "report-no": null, "categories": "cs.CV cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Bayesian image segmentation model based on Potts prior\nand loopy belief propagation. The proposed Bayesian model involves several\nterms, including the pairwise interactions of Potts models, and the average\nvectors and covariant matrices of Gauss distributions in color image modeling.\nThese terms are often referred to as hyperparameters in statistical machine\nlearning theory. In order to determine these hyperparameters, we propose a new\nscheme for hyperparameter estimation based on conditional maximization of\nentropy in the Potts prior. The algorithm is given based on loopy belief\npropagation. In addition, we compare our conditional maximum entropy framework\nwith the conventional maximum likelihood framework, and also clarify how the\nfirst order phase transitions in LBP's for Potts models influence our\nhyperparameter estimation procedures.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2014 06:31:03 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 10:26:46 GMT"}, {"version": "v3", "created": "Wed, 4 Jun 2014 11:18:44 GMT"}, {"version": "v4", "created": "Fri, 15 Aug 2014 00:58:40 GMT"}, {"version": "v5", "created": "Mon, 18 Aug 2014 04:45:26 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Tanaka", "Kazuyuki", ""], ["Kataoka", "Shun", ""], ["Yasuda", "Muneki", ""], ["Waizumi", "Yuji", ""], ["Hsu", "Chiou-Ting", ""]]}, {"id": "1404.3184", "submitter": "Xiangrong Zeng", "authors": "Xiangrong Zeng and M\\'ario A. T. Figueiredo", "title": "Decreasing Weighted Sorted $\\ell_1$ Regularization", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a new family of regularizers, termed {\\it weighted sorted\n$\\ell_1$ norms} (WSL1), which generalizes the recently introduced {\\it\noctagonal shrinkage and clustering algorithm for regression} (OSCAR) and also\ncontains the $\\ell_1$ and $\\ell_{\\infty}$ norms as particular instances. We\nfocus on a special case of the WSL1, the {\\sl decreasing WSL1} (DWSL1), where\nthe elements of the argument vector are sorted in non-increasing order and the\nweights are also non-increasing. In this paper, after showing that the DWSL1 is\nindeed a norm, we derive two key tools for its use as a regularizer: the dual\nnorm and the Moreau proximity operator.\n", "versions": [{"version": "v1", "created": "Fri, 11 Apr 2014 18:50:34 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Zeng", "Xiangrong", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "1404.3290", "submitter": "Yehuda Dar", "authors": "Yehuda Dar, Alfred M. Bruckstein", "title": "Motion-Compensated Coding and Frame-Rate Up-Conversion: Models and\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block-based motion estimation (ME) and compensation (MC) techniques are\nwidely used in modern video processing algorithms and compression systems. The\ngreat variety of video applications and devices results in numerous compression\nspecifications. Specifically, there is a diversity of frame-rates and\nbit-rates. In this paper, we study the effect of frame-rate and compression\nbit-rate on block-based ME and MC as commonly utilized in inter-frame coding\nand frame-rate up conversion (FRUC). This joint examination yields a\ncomprehensive foundation for comparing MC procedures in coding and FRUC. First,\nthe video signal is modeled as a noisy translational motion of an image. Then,\nwe theoretically model the motion-compensated prediction of an available and\nabsent frames as in coding and FRUC applications, respectively. The theoretic\nMC-prediction error is further analyzed and its autocorrelation function is\ncalculated for coding and FRUC applications. We show a linear relation between\nthe variance of the MC-prediction error and temporal-distance. While the\naffecting distance in MC-coding is between the predicted and reference frames,\nMC-FRUC is affected by the distance between the available frames used for the\ninterpolation. Moreover, the dependency in temporal-distance implies an inverse\neffect of the frame-rate. FRUC performance analysis considers the prediction\nerror variance, since it equals to the mean-squared-error of the interpolation.\nHowever, MC-coding analysis requires the entire autocorrelation function of the\nerror; hence, analytic simplicity is beneficial. Therefore, we propose two\nconstructions of a separable autocorrelation function for prediction error in\nMC-coding. We conclude by comparing our estimations with experimental results.\n", "versions": [{"version": "v1", "created": "Sat, 12 Apr 2014 14:21:21 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Dar", "Yehuda", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "1404.3291", "submitter": "Michael Wilber", "authors": "Michael J. Wilber and Iljung S. Kwak and Serge J. Belongie", "title": "Cost-Effective HITs for Relative Similarity Comparisons", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity comparisons of the form \"Is object a more similar to b than to c?\"\nare useful for computer vision and machine learning applications.\nUnfortunately, an embedding of $n$ points is specified by $n^3$ triplets,\nmaking collecting every triplet an expensive task. In noticing this difficulty,\nother researchers have investigated more intelligent triplet sampling\ntechniques, but they do not study their effectiveness or their potential\ndrawbacks. Although it is important to reduce the number of collected triplets,\nit is also important to understand how best to display a triplet collection\ntask to a user. In this work we explore an alternative display for collecting\ntriplets and analyze the monetary cost and speed of the display. We propose\nbest practices for creating cost effective human intelligence tasks for\ncollecting triplets. We show that rather than changing the sampling algorithm,\nsimple changes to the crowdsourcing UI can lead to much higher quality\nembeddings. We also provide a dataset as well as the labels collected from\ncrowd workers.\n", "versions": [{"version": "v1", "created": "Sat, 12 Apr 2014 14:33:18 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Wilber", "Michael J.", ""], ["Kwak", "Iljung S.", ""], ["Belongie", "Serge J.", ""]]}, {"id": "1404.3312", "submitter": "Xu  Chen", "authors": "Xu Chen, Alfred Hero, Silvio Savarese", "title": "Shrinkage Optimized Directed Information using Pictorial Structures for\n  Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper, we propose a novel action recognition framework. The method\nuses pictorial structures and shrinkage optimized directed information\nassessment (SODA) coupled with Markov Random Fields called SODA+MRF to model\nthe directional temporal dependency and bidirectional spatial dependency. As a\nvariant of mutual information, directional information captures the directional\ninformation flow and temporal structure of video sequences across frames.\nMeanwhile, within each frame, Markov random fields are utilized to model the\nspatial relations among different parts of a human body and the body parts of\ndifferent people. The proposed SODA+MRF model is robust to view point\ntransformations and detect complex interactions accurately. We compare the\nproposed method against several baseline methods to highlight the effectiveness\nof the SODA+MRF model. We demonstrate that our algorithm has superior action\nrecognition performance on the UCF action recognition dataset, the Olympic\nsports dataset and the collective activity dataset over several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Apr 2014 19:01:36 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Chen", "Xu", ""], ["Hero", "Alfred", ""], ["Savarese", "Silvio", ""]]}, {"id": "1404.3366", "submitter": "Chunhua Shen", "authors": "Fayao Liu, Chunhua Shen", "title": "Learning Deep Convolutional Features for MRI Based Alzheimer's Disease\n  Classification", "comments": "This paper has been withdrawn by the author due to an error in the\n  MRI data used in the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective and accurate diagnosis of Alzheimer's disease (AD) or mild\ncognitive impairment (MCI) can be critical for early treatment and thus has\nattracted more and more attention nowadays. Since first introduced, machine\nlearning methods have been gaining increasing popularity for AD related\nresearch. Among the various identified biomarkers, magnetic resonance imaging\n(MRI) are widely used for the prediction of AD or MCI. However, before a\nmachine learning algorithm can be applied, image features need to be extracted\nto represent the MRI images. While good representations can be pivotal to the\nclassification performance, almost all the previous studies typically rely on\nhuman labelling to find the regions of interest (ROI) which may be correlated\nto AD, such as hippocampus, amygdala, precuneus, etc. This procedure requires\ndomain knowledge and is costly and tedious.\n  Instead of relying on extraction of ROI features, it is more promising to\nremove manual ROI labelling from the pipeline and directly work on the raw MRI\nimages. In other words, we can let the machine learning methods to figure out\nthese informative and discriminative image structures for AD classification. In\nthis work, we propose to learn deep convolutional image features using\nunsupervised and supervised learning. Deep learning has emerged as a powerful\ntool in the machine learning community and has been successfully applied to\nvarious tasks. We thus propose to exploit deep features of MRI images based on\na pre-trained large convolutional neural network (CNN) for AD and MCI\nclassification, which spares the effort of manual ROI annotation process.\n", "versions": [{"version": "v1", "created": "Sun, 13 Apr 2014 10:45:38 GMT"}, {"version": "v2", "created": "Mon, 28 Apr 2014 01:20:20 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Liu", "Fayao", ""], ["Shen", "Chunhua", ""]]}, {"id": "1404.3538", "submitter": "Emilie Morvant", "authors": "Vladimir Kolmogorov, Christoph Lampert, Emilie Morvant, Rustem\n  Takhanov", "title": "Proceedings of The 38th Annual Workshop of the Austrian Association for\n  Pattern Recognition (\\\"OAGM), 2014", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 38th Annual Workshop of the Austrian Association for Pattern Recognition\n(\\\"OAGM) will be held at IST Austria, on May 22-23, 2014. The workshop provides\na platform for researchers and industry to discuss traditional and new areas of\ncomputer vision. This year the main topic is: Pattern Recognition:\ninterdisciplinary challenges and opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 11:01:04 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 09:53:00 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Kolmogorov", "Vladimir", ""], ["Lampert", "Christoph", ""], ["Morvant", "Emilie", ""], ["Takhanov", "Rustem", ""]]}, {"id": "1404.3543", "submitter": "Ping Luo", "authors": "Zhenyao Zhu and Ping Luo and Xiaogang Wang and Xiaoou Tang", "title": "Recover Canonical-View Faces in the Wild with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face images in the wild undergo large intra-personal variations, such as\nposes, illuminations, occlusions, and low resolutions, which cause great\nchallenges to face-related applications. This paper addresses this challenge by\nproposing a new deep learning framework that can recover the canonical view of\nface images. It dramatically reduces the intra-person variances, while\nmaintaining the inter-person discriminativeness. Unlike the existing face\nreconstruction methods that were either evaluated in controlled 2D environment\nor employed 3D information, our approach directly learns the transformation\nfrom the face images with a complex set of variations to their canonical views.\nAt the training stage, to avoid the costly process of labeling canonical-view\nimages from the training set by hand, we have devised a new measurement to\nautomatically select or synthesize a canonical-view image for each identity. As\nan application, this face recovery approach is used for face verification.\nFacial features are learned from the recovered canonical-view face images by\nusing a facial component-based convolutional neural network. Our approach\nachieves the state-of-the-art performance on the LFW dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 11:32:17 GMT"}, {"version": "v2", "created": "Wed, 16 Apr 2014 04:35:34 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Zhu", "Zhenyao", ""], ["Luo", "Ping", ""], ["Wang", "Xiaogang", ""], ["Tang", "Xiaoou", ""]]}, {"id": "1404.3596", "submitter": "Adrian Barbu", "authors": "Adrian Barbu, Nathan Lay, Gary Gramajo", "title": "Face Detection with a 3D Model", "comments": "14 pages, 11 figures", "journal-ref": "Academic Press Library in Signal Processing Volume 6: Image and\n  Video Processing and Analysis and Computer Vision, pp 237-259, 2018. Editors:\n  R. Chellappa and S. Theodoridis", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a part-based face detection approach where the spatial\nrelationship between the face parts is represented by a hidden 3D model with\nsix parameters. The computational complexity of the search in the six\ndimensional pose space is addressed by proposing meaningful 3D pose candidates\nby image-based regression from detected face keypoint locations. The 3D pose\ncandidates are evaluated using a parameter sensitive classifier based on\ndifference features relative to the 3D pose. A compatible subset of candidates\nis then obtained by non-maximal suppression. Experiments on two standard face\ndetection datasets show that the proposed 3D model based approach obtains\nresults comparable to or better than state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 14:31:32 GMT"}, {"version": "v2", "created": "Sun, 4 May 2014 01:15:12 GMT"}, {"version": "v3", "created": "Wed, 21 Jan 2015 20:20:23 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2015 21:01:07 GMT"}, {"version": "v5", "created": "Tue, 9 Jun 2015 21:50:40 GMT"}, {"version": "v6", "created": "Wed, 17 Jun 2015 23:32:13 GMT"}, {"version": "v7", "created": "Tue, 3 Nov 2015 16:28:03 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Barbu", "Adrian", ""], ["Lay", "Nathan", ""], ["Gramajo", "Gary", ""]]}, {"id": "1404.3606", "submitter": "Tsung-Han  Chan", "authors": "Tsung-Han Chan, Kui Jia, Shenghua Gao, Jiwen Lu, Zinan Zeng and Yi Ma", "title": "PCANet: A Simple Deep Learning Baseline for Image Classification?", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2015.2475625", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a very simple deep learning network for image\nclassification which comprises only the very basic data processing components:\ncascaded principal component analysis (PCA), binary hashing, and block-wise\nhistograms. In the proposed architecture, PCA is employed to learn multistage\nfilter banks. It is followed by simple binary hashing and block histograms for\nindexing and pooling. This architecture is thus named as a PCA network (PCANet)\nand can be designed and learned extremely easily and efficiently. For\ncomparison and better understanding, we also introduce and study two simple\nvariations to the PCANet, namely the RandNet and LDANet. They share the same\ntopology of PCANet but their cascaded filters are either selected randomly or\nlearned from LDA. We have tested these basic networks extensively on many\nbenchmark visual datasets for different tasks, such as LFW for face\nverification, MultiPIE, Extended Yale B, AR, FERET datasets for face\nrecognition, as well as MNIST for hand-written digits recognition.\nSurprisingly, for all tasks, such a seemingly naive PCANet model is on par with\nthe state of the art features, either prefixed, highly hand-crafted or\ncarefully learned (by DNNs). Even more surprisingly, it sets new records for\nmany classification tasks in Extended Yale B, AR, FERET datasets, and MNIST\nvariations. Additional experiments on other public datasets also demonstrate\nthe potential of the PCANet serving as a simple but highly competitive baseline\nfor texture classification and object recognition.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2014 15:02:17 GMT"}, {"version": "v2", "created": "Thu, 28 Aug 2014 15:20:44 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Chan", "Tsung-Han", ""], ["Jia", "Kui", ""], ["Gao", "Shenghua", ""], ["Lu", "Jiwen", ""], ["Zeng", "Zinan", ""], ["Ma", "Yi", ""]]}, {"id": "1404.3840", "submitter": "Chaochao Lu", "authors": "Chaochao Lu, Xiaoou Tang", "title": "Surpassing Human-Level Face Verification Performance on LFW with\n  GaussianFace", "comments": "Appearing in Proceedings of the 29th AAAI Conference on Artificial\n  Intelligence (AAAI-15), Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face verification remains a challenging problem in very complex conditions\nwith large variations such as pose, illumination, expression, and occlusions.\nThis problem is exacerbated when we rely unrealistically on a single training\ndata source, which is often insufficient to cover the intrinsically complex\nface variations. This paper proposes a principled multi-task learning approach\nbased on Discriminative Gaussian Process Latent Variable Model, named\nGaussianFace, to enrich the diversity of training data. In comparison to\nexisting methods, our model exploits additional data from multiple\nsource-domains to improve the generalization performance of face verification\nin an unknown target-domain. Importantly, our model can adapt automatically to\ncomplex data distributions, and therefore can well capture complex face\nvariations inherent in multiple sources. Extensive experiments demonstrate the\neffectiveness of the proposed model in learning from diverse data sources and\ngeneralize to unseen domain. Specifically, the accuracy of our algorithm\nachieves an impressive accuracy rate of 98.52% on the well-known and\nchallenging Labeled Faces in the Wild (LFW) benchmark. For the first time, the\nhuman-level performance in face verification (97.53%) on LFW is surpassed.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 07:51:23 GMT"}, {"version": "v2", "created": "Mon, 16 Jun 2014 14:37:38 GMT"}, {"version": "v3", "created": "Sat, 20 Dec 2014 03:37:36 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Lu", "Chaochao", ""], ["Tang", "Xiaoou", ""]]}, {"id": "1404.3933", "submitter": "Philip Lee", "authors": "Philip G. Lee and Ying Wu", "title": "Scalable Matting: A Sub-linear Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural image matting, which separates foreground from background, is a very\nimportant intermediate step in recent computer vision algorithms. However, it\nis severely underconstrained and difficult to solve. State-of-the-art\napproaches include matting by graph Laplacian, which significantly improves the\nunderconstrained nature by reducing the solution space. However, matting by\ngraph Laplacian is still very difficult to solve and gets much harder as the\nimage size grows: current iterative methods slow down as $\\mathcal{O}\\left(n^2\n\\right)$ in the resolution $n$. This creates uncomfortable practical limits on\nthe resolution of images that we can matte. Current literature mitigates the\nproblem, but they all remain super-linear in complexity. We expose properties\nof the problem that remain heretofore unexploited, demonstrating that an\noptimization technique originally intended to solve PDEs can be adapted to take\nadvantage of this knowledge to solve the matting problem, not heuristically,\nbut exactly and with sub-linear complexity. This makes ours the most efficient\nmatting solver currently known by a very wide margin and allows matting finally\nto be practical and scalable in the future as consumer photos exceed many\ndozens of megapixels, and also relieves matting from being a bottleneck for\nvision algorithms that depend on it.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 14:39:20 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Lee", "Philip G.", ""], ["Wu", "Ying", ""]]}, {"id": "1404.3991", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam, Mohamed Cheriet", "title": "Spiralet Sparse Representation", "comments": "10 pages, Working Paper Number: WP-RFM-14-01", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first report on Working Paper WP-RFM-14-01. The potential and\ncapability of sparse representations is well-known. However, their\n(multivariate variable) vectorial form, which is completely fine in many fields\nand disciplines, results in removal and filtering of important \"spatial\"\nrelations that are implicitly carried by two-dimensional [or multi-dimensional]\nobjects, such as images. In this paper, a new approach, called spiralet sparse\nrepresentation, is proposed in order to develop an augmented representation and\ntherefore a modified sparse representation and theory, which is capable to\npreserve the data associated to the spatial relations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 17:12:40 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1404.4104", "submitter": "Jianing Shi", "authors": "Jianing V. Shi, Yangyang Xu, and Richard G. Baraniuk", "title": "Sparse Bilinear Logistic Regression", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the concept of sparse bilinear logistic\nregression for decision problems involving explanatory variables that are\ntwo-dimensional matrices. Such problems are common in computer vision,\nbrain-computer interfaces, style/content factorization, and parallel factor\nanalysis. The underlying optimization problem is bi-convex; we study its\nsolution and develop an efficient algorithm based on block coordinate descent.\nWe provide a theoretical guarantee for global convergence and estimate the\nasymptotical convergence rate using the Kurdyka-{\\L}ojasiewicz inequality. A\nrange of experiments with simulated and real data demonstrate that sparse\nbilinear logistic regression outperforms current techniques in several\nimportant applications.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 22:54:21 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Shi", "Jianing V.", ""], ["Xu", "Yangyang", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1404.4316", "submitter": "Xiaoyu Wang", "authors": "Will Y. Zou, Xiaoyu Wang, Miao Sun, Yuanqing Lin", "title": "Generic Object Detection With Dense Neural Patterns and Regionlets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenge of establishing a bridge between deep\nconvolutional neural networks and conventional object detection frameworks for\naccurate and efficient generic object detection. We introduce Dense Neural\nPatterns, short for DNPs, which are dense local features derived from\ndiscriminatively trained deep convolutional neural networks. DNPs can be easily\nplugged into conventional detection frameworks in the same way as other dense\nlocal features(like HOG or LBP). The effectiveness of the proposed approach is\ndemonstrated with the Regionlets object detection framework. It achieved 46.1%\nmean average precision on the PASCAL VOC 2007 dataset, and 44.1% on the PASCAL\nVOC 2010 dataset, which dramatically improves the original Regionlets approach\nwithout DNPs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2014 17:23:47 GMT"}], "update_date": "2014-04-17", "authors_parsed": [["Zou", "Will Y.", ""], ["Wang", "Xiaoyu", ""], ["Sun", "Miao", ""], ["Lin", "Yuanqing", ""]]}, {"id": "1404.4412", "submitter": "Guoxu Zhou", "authors": "Guoxu Zhou and Andrzej Cichocki and Qibin Zhao and Shengli Xie", "title": "Efficient Nonnegative Tucker Decompositions: Algorithms and Uniqueness", "comments": "appears in IEEE Transactions on Image Processing, 2015", "journal-ref": null, "doi": "10.1109/TIP.2015.2478396", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative Tucker decomposition (NTD) is a powerful tool for the extraction\nof nonnegative parts-based and physically meaningful latent components from\nhigh-dimensional tensor data while preserving the natural multilinear structure\nof data. However, as the data tensor often has multiple modes and is\nlarge-scale, existing NTD algorithms suffer from a very high computational\ncomplexity in terms of both storage and computation time, which has been one\nmajor obstacle for practical applications of NTD. To overcome these\ndisadvantages, we show how low (multilinear) rank approximation (LRA) of\ntensors is able to significantly simplify the computation of the gradients of\nthe cost function, upon which a family of efficient first-order NTD algorithms\nare developed. Besides dramatically reducing the storage complexity and running\ntime, the new algorithms are quite flexible and robust to noise because any\nwell-established LRA approaches can be applied. We also show how nonnegativity\nincorporating sparsity substantially improves the uniqueness property and\npartially alleviates the curse of dimensionality of the Tucker decompositions.\nSimulation results on synthetic and real-world data justify the validity and\nhigh efficiency of the proposed NTD algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 01:52:09 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 08:58:14 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Zhou", "Guoxu", ""], ["Cichocki", "Andrzej", ""], ["Zhao", "Qibin", ""], ["Xie", "Shengli", ""]]}, {"id": "1404.4467", "submitter": "Jan Egger", "authors": "Robert Schwarzenberg, Bernd Freisleben, Christopher Nimsky, Jan Egger", "title": "Cube-Cut: Vertebral Body Segmentation in MRI-Data through Cubic-Shaped\n  Divergences", "comments": "23 figures, 2 tables, 43 references, PLoS ONE 9(4): e93389", "journal-ref": null, "doi": "10.1371/journal.pone.0093389", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a graph-based method using a cubic template for\nvolumetric segmentation of vertebrae in magnetic resonance imaging (MRI)\nacquisitions. The user can define the degree of deviation from a regular cube\nvia a smoothness value Delta. The Cube-Cut algorithm generates a directed graph\nwith two terminal nodes (s-t-network), where the nodes of the graph correspond\nto a cubic-shaped subset of the image's voxels. The weightings of the graph's\nterminal edges, which connect every node with a virtual source s or a virtual\nsink t, represent the affinity of a voxel to the vertebra (source) and to the\nbackground (sink). Furthermore, a set of infinite weighted and non-terminal\nedges implements the smoothness term. After graph construction, a minimal\ns-t-cut is calculated within polynomial computation time, which splits the\nnodes into two disjoint units. Subsequently, the segmentation result is\ndetermined out of the source-set. A quantitative evaluation of a C++\nimplementation of the algorithm resulted in an average Dice Similarity\nCoefficient (DSC) of 81.33% and a running time of less than a minute.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 09:58:28 GMT"}, {"version": "v2", "created": "Tue, 22 Jul 2014 17:40:56 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Schwarzenberg", "Robert", ""], ["Freisleben", "Bernd", ""], ["Nimsky", "Christopher", ""], ["Egger", "Jan", ""]]}, {"id": "1404.4661", "submitter": "Jiang Wang", "authors": "Jiang Wang, Yang song, Thomas Leung, Chuck Rosenberg, Jinbin Wang,\n  James Philbin, Bo Chen, Ying Wu", "title": "Learning Fine-grained Image Similarity with Deep Ranking", "comments": "CVPR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning fine-grained image similarity is a challenging task. It needs to\ncapture between-class and within-class image differences. This paper proposes a\ndeep ranking model that employs deep learning techniques to learn similarity\nmetric directly from images.It has higher learning capability than models based\non hand-crafted features. A novel multiscale network structure has been\ndeveloped to describe the images effectively. An efficient triplet sampling\nalgorithm is proposed to learn the model with distributed asynchronized\nstochastic gradient. Extensive experiments show that the proposed algorithm\noutperforms models based on hand-crafted visual features and deep\nclassification models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Apr 2014 22:09:16 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Wang", "Jiang", ""], ["song", "Yang", ""], ["Leung", "Thomas", ""], ["Rosenberg", "Chuck", ""], ["Wang", "Jinbin", ""], ["Philbin", "James", ""], ["Chen", "Bo", ""], ["Wu", "Ying", ""]]}, {"id": "1404.4774", "submitter": "Jing Wang", "authors": "Wang Jing, Zhao Zhong-Qiu, Hu Xuegang, Cheung Yiu-ming, Wang Meng, Wu\n  Xindong", "title": "Online Group Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online feature selection with dynamic features has become an active research\narea in recent years. However, in some real-world applications such as image\nanalysis and email spam filtering, features may arrive by groups. Existing\nonline feature selection methods evaluate features individually, while existing\ngroup feature selection methods cannot handle online processing. Motivated by\nthis, we formulate the online group feature selection problem, and propose a\nnovel selection approach for this problem. Our proposed approach consists of\ntwo stages: online intra-group selection and online inter-group selection. In\nthe intra-group selection, we use spectral analysis to select discriminative\nfeatures in each group when it arrives. In the inter-group selection, we use\nLasso to select a globally optimal subset of features. This 2-stage procedure\ncontinues until there are no more features to come or some predefined stopping\nconditions are met. Extensive experiments conducted on benchmark and real-world\ndata sets demonstrate that our proposed approach outperforms other\nstate-of-the-art online feature selection methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 12:51:24 GMT"}, {"version": "v2", "created": "Tue, 30 Sep 2014 03:29:44 GMT"}, {"version": "v3", "created": "Thu, 23 Oct 2014 03:31:43 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Jing", "Wang", ""], ["Zhong-Qiu", "Zhao", ""], ["Xuegang", "Hu", ""], ["Yiu-ming", "Cheung", ""], ["Meng", "Wang", ""], ["Xindong", "Wu", ""]]}, {"id": "1404.4780", "submitter": "Jing Wang", "authors": "Jing Wang, Canyi Lu, Meng Wang, Peipei Li, Shuicheng Yan, Xuegang Hu", "title": "Robust Face Recognition via Adaptive Sparse Representation", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2014.2307067", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Representation (or coding) based Classification (SRC) has gained great\nsuccess in face recognition in recent years. However, SRC emphasizes the\nsparsity too much and overlooks the correlation information which has been\ndemonstrated to be critical in real-world face recognition problems. Besides,\nsome work considers the correlation but overlooks the discriminative ability of\nsparsity. Different from these existing techniques, in this paper, we propose a\nframework called Adaptive Sparse Representation based Classification (ASRC) in\nwhich sparsity and correlation are jointly considered. Specifically, when the\nsamples are of low correlation, ASRC selects the most discriminative samples\nfor representation, like SRC; when the training samples are highly correlated,\nASRC selects most of the correlated and discriminative samples for\nrepresentation, rather than choosing some related samples randomly. In general,\nthe representation model is adaptive to the correlation structure, which\nbenefits from both $\\ell_1$-norm and $\\ell_2$-norm.\n  Extensive experiments conducted on publicly available data sets verify the\neffectiveness and robustness of the proposed algorithm by comparing it with\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 13:24:29 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Wang", "Jing", ""], ["Lu", "Canyi", ""], ["Wang", "Meng", ""], ["Li", "Peipei", ""], ["Yan", "Shuicheng", ""], ["Hu", "Xuegang", ""]]}, {"id": "1404.4800", "submitter": "Ayushi Sinha", "authors": "Ayushi Sinha, William Gray Roncal, Narayanan Kasthuri, Ming Chuang,\n  Priya Manavalan, Dean M. Kleissas, Joshua T. Vogelstein, R. Jacob Vogelstein,\n  Randal Burns, Jeff W. Lichtman, Michael Kazhdan", "title": "Automatic Annotation of Axoplasmic Reticula in Pursuit of Connectomes", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new pipeline which automatically identifies and\nannotates axoplasmic reticula, which are small subcellular structures present\nonly in axons. We run our algorithm on the Kasthuri11 dataset, which was color\ncorrected using gradient-domain techniques to adjust contrast. We use a\nbilateral filter to smooth out the noise in this data while preserving edges,\nwhich highlights axoplasmic reticula. These axoplasmic reticula are then\nannotated using a morphological region growing algorithm. Additionally, we\nperform Laplacian sharpening on the bilaterally filtered data to enhance edges,\nand repeat the morphological region growing algorithm to annotate more\naxoplasmic reticula. We track our annotations through the slices to improve\nprecision, and to create long objects to aid in segment merging. This method\nannotates axoplasmic reticula with high precision. Our algorithm can easily be\nadapted to annotate axoplasmic reticula in different sets of brain data by\nchanging a few thresholds. The contribution of this work is the introduction of\na straightforward and robust pipeline which annotates axoplasmic reticula with\nhigh precision, contributing towards advancements in automatic feature\nannotations in neural EM data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2014 20:09:37 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Sinha", "Ayushi", ""], ["Roncal", "William Gray", ""], ["Kasthuri", "Narayanan", ""], ["Chuang", "Ming", ""], ["Manavalan", "Priya", ""], ["Kleissas", "Dean M.", ""], ["Vogelstein", "Joshua T.", ""], ["Vogelstein", "R. Jacob", ""], ["Burns", "Randal", ""], ["Lichtman", "Jeff W.", ""], ["Kazhdan", "Michael", ""]]}, {"id": "1404.4805", "submitter": "Yunjin Chen", "authors": "Peter Ochs and Yunjin Chen and Thomas Brox and Thomas Pock", "title": "iPiano: Inertial Proximal Algorithm for Non-Convex Optimization", "comments": "32pages, 7 figures, to appear in SIAM Journal on Imaging Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study an algorithm for solving a minimization problem\ncomposed of a differentiable (possibly non-convex) and a convex (possibly\nnon-differentiable) function. The algorithm iPiano combines forward-backward\nsplitting with an inertial force. It can be seen as a non-smooth split version\nof the Heavy-ball method from Polyak. A rigorous analysis of the algorithm for\nthe proposed class of problems yields global convergence of the function values\nand the arguments. This makes the algorithm robust for usage on non-convex\nproblems. The convergence result is obtained based on the \\KL inequality. This\nis a very weak restriction, which was used to prove convergence for several\nother gradient methods. First, an abstract convergence theorem for a generic\nalgorithm is proved, and, then iPiano is shown to satisfy the requirements of\nthis theorem. Furthermore, a convergence rate is established for the general\nproblem class. We demonstrate iPiano on computer vision problems: image\ndenoising with learned priors and diffusion based image compression.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 15:00:07 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Ochs", "Peter", ""], ["Chen", "Yunjin", ""], ["Brox", "Thomas", ""], ["Pock", "Thomas", ""]]}, {"id": "1404.4880", "submitter": "Alejandro Frery", "authors": "Abra\\~ao D. C. Nascimento and Alejandro C. Frery and Renato J. Cintra", "title": "Bias Correction and Modified Profile Likelihood under the Wishart\n  Complex Distribution", "comments": null, "journal-ref": "IEEE Transactions on Geoscience and Remote Sensing, vol. 52, issue\n  8, August, pages 4932--4941, 2014", "doi": "10.1109/TGRS.2013.2285927", "report-no": null, "categories": "cs.CV stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes improved methods for the maximum likelihood (ML)\nestimation of the equivalent number of looks $L$. This parameter has a\nmeaningful interpretation in the context of polarimetric synthetic aperture\nradar (PolSAR) images. Due to the presence of coherent illumination in their\nprocessing, PolSAR systems generate images which present a granular noise\ncalled speckle. As a potential solution for reducing such interference, the\nparameter $L$ controls the signal-noise ratio. Thus, the proposal of efficient\nestimation methodologies for $L$ has been sought. To that end, we consider\nfirstly that a PolSAR image is well described by the scaled complex Wishart\ndistribution. In recent years, Anfinsen et al. derived and analyzed estimation\nmethods based on the ML and on trace statistical moments for obtaining the\nparameter $L$ of the unscaled version of such probability law. This paper\ngeneralizes that approach. We present the second-order bias expression proposed\nby Cox and Snell for the ML estimator of this parameter. Moreover, the formula\nof the profile likelihood modified by Barndorff-Nielsen in terms of $L$ is\ndiscussed. Such derivations yield two new ML estimators for the parameter $L$,\nwhich are compared to the estimators proposed by Anfinsen et al. The\nperformance of these estimators is assessed by means of Monte Carlo\nexperiments, adopting three statistical measures as comparison criterion: the\nmean square error, the bias, and the coefficient of variation. Equivalently to\nthe simulation study, an application to actual PolSAR data concludes that the\nproposed estimators outperform all the others in homogeneous scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 18 Apr 2014 20:19:02 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["Nascimento", "Abra\u00e3o D. C.", ""], ["Frery", "Alejandro C.", ""], ["Cintra", "Renato J.", ""]]}, {"id": "1404.4923", "submitter": "Jie Shen", "authors": "Jie Shen, Guangcan Liu, Jia Chen, Yuqiang Fang, Jianbin Xie, Yong Yu,\n  Shuicheng Yan", "title": "Unified Structured Learning for Simultaneous Human Pose Estimation and\n  Garment Attribute Classification", "comments": "Accepted to IEEE Trans. on Image Processing", "journal-ref": null, "doi": "10.1109/TIP.2014.2358082", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we utilize structured learning to simultaneously address two\nintertwined problems: human pose estimation (HPE) and garment attribute\nclassification (GAC), which are valuable for a variety of computer vision and\nmultimedia applications. Unlike previous works that usually handle the two\nproblems separately, our approach aims to produce a jointly optimal estimation\nfor both HPE and GAC via a unified inference procedure. To this end, we adopt a\npreprocessing step to detect potential human parts from each image (i.e., a set\nof \"candidates\") that allows us to have a manageable input space. In this way,\nthe simultaneous inference of HPE and GAC is converted to a structured learning\nproblem, where the inputs are the collections of candidate ensembles, the\noutputs are the joint labels of human parts and garment attributes, and the\njoint feature representation involves various cues such as pose-specific\nfeatures, garment-specific features, and cross-task features that encode\ncorrelations between human parts and garment attributes. Furthermore, we\nexplore the \"strong edge\" evidence around the potential human parts so as to\nderive more powerful representations for oriented human parts. Such evidences\ncan be seamlessly integrated into our structured learning model as a kind of\nenergy function, and the learning process could be performed by standard\nstructured Support Vector Machines (SVM) algorithm. However, the joint\nstructure of the two problems is a cyclic graph, which hinders efficient\ninference. To resolve this issue, we compute instead approximate optima by\nusing an iterative procedure, where in each iteration the variables of one\nproblem are fixed. In this way, satisfactory solutions can be efficiently\ncomputed by dynamic programming. Experimental results on two benchmark datasets\nshow the state-of-the-art performance of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Apr 2014 04:51:06 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 19:50:41 GMT"}, {"version": "v3", "created": "Mon, 22 Sep 2014 19:09:38 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Shen", "Jie", ""], ["Liu", "Guangcan", ""], ["Chen", "Jia", ""], ["Fang", "Yuqiang", ""], ["Xie", "Jianbin", ""], ["Yu", "Yong", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1404.4942", "submitter": "Thomas Holzmann", "authors": "Thomas Holzmann, Christof Hoppe, Stefan Kluckner, Horst Bischof", "title": "Geometric Abstraction from Noisy Image-Based 3D Reconstructions", "comments": "Part of the OAGM 2014 proceedings (arXiv:1404.3538)", "journal-ref": null, "doi": null, "report-no": "OAGM/2014/02", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating geometric abstracted models from image-based scene reconstructions\nis difficult due to noise and irregularities in the reconstructed model. In\nthis paper, we present a geometric modeling method for noisy reconstructions\ndominated by planar horizontal and orthogonal vertical structures. We partition\nthe scene into horizontal slices and create an inside/outside labeling\nrepresented by a floor plan for each slice by solving an energy minimization\nproblem. Consecutively, we create an irregular discretization of the volume\naccording to the individual floor plans and again label each cell as\ninside/outside by minimizing an energy function. By adjusting the smoothness\nparameter, we introduce different levels of detail. In our experiments, we show\nresults with varying regularization levels using synthetically generated and\nreal-world data.\n", "versions": [{"version": "v1", "created": "Sat, 19 Apr 2014 09:55:00 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["Holzmann", "Thomas", ""], ["Hoppe", "Christof", ""], ["Kluckner", "Stefan", ""], ["Bischof", "Horst", ""]]}, {"id": "1404.5009", "submitter": "Chunhua Shen", "authors": "Peng Wang, Chunhua Shen, Anton van den Hengel, Philip Torr", "title": "Efficient Semidefinite Branch-and-Cut for MAP-MRF Inference", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Branch-and-Cut (B&C) method for solving general MAP-MRF\ninference problems. The core of our method is a very efficient bounding\nprocedure, which combines scalable semidefinite programming (SDP) and a\ncutting-plane method for seeking violated constraints. In order to further\nspeed up the computation, several strategies have been exploited, including\nmodel reduction, warm start and removal of inactive constraints.\n  We analyze the performance of the proposed method under different settings,\nand demonstrate that our method either outperforms or performs on par with\nstate-of-the-art approaches. Especially when the connectivities are dense or\nwhen the relative magnitudes of the unary costs are low, we achieve the best\nreported results. Experiments show that the proposed algorithm achieves better\napproximation than the state-of-the-art methods within a variety of time\nbudgets on challenging non-submodular MAP-MRF inference problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Apr 2014 04:47:04 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2014 03:43:41 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 08:23:09 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2015 04:35:30 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Wang", "Peng", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""], ["Torr", "Philip", ""]]}, {"id": "1404.5344", "submitter": "Yunjin Chen", "authors": "Yunjin Chen, Wensen Feng, Ren\\'e Ranftl, Hong Qiao and Thomas Pock", "title": "A higher-order MRF based variational model for multiplicative noise\n  reduction", "comments": "5 pages, 5 figures, to appear in IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2014.2337274", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fields of Experts (FoE) image prior model, a filter-based higher-order\nMarkov Random Fields (MRF) model, has been shown to be effective for many image\nrestoration problems. Motivated by the successes of FoE-based approaches, in\nthis letter, we propose a novel variational model for multiplicative noise\nreduction based on the FoE image prior model. The resulted model corresponds to\na non-convex minimization problem, which can be solved by a recently published\nnon-convex optimization algorithm. Experimental results based on synthetic\nspeckle noise and real synthetic aperture radar (SAR) images suggest that the\nperformance of our proposed method is on par with the best published\ndespeckling algorithm. Besides, our proposed model comes along with an\nadditional advantage, that the inference is extremely efficient. {Our GPU based\nimplementation takes less than 1s to produce state-of-the-art despeckling\nperformance.}\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2014 22:19:31 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 16:17:18 GMT"}, {"version": "v3", "created": "Mon, 7 Jul 2014 21:55:25 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Chen", "Yunjin", ""], ["Feng", "Wensen", ""], ["Ranftl", "Ren\u00e9", ""], ["Qiao", "Hong", ""], ["Pock", "Thomas", ""]]}, {"id": "1404.5351", "submitter": "Raffay Hamid", "authors": "Raffay Hamid, Atish Das Sarma, Dennis DeCoste, Neel Sundaresan", "title": "Fast Approximate Matching of Cell-Phone Videos for Robust Background\n  Subtraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We identify a novel instance of the background subtraction problem that\nfocuses on extracting near-field foreground objects captured using handheld\ncameras. Given two user-generated videos of a scene, one with and the other\nwithout the foreground object(s), our goal is to efficiently generate an output\nvideo with only the foreground object(s) present in it. We cast this challenge\nas a spatio-temporal frame matching problem, and propose an efficient solution\nfor it that exploits the temporal smoothness of the video sequences. We present\ntheoretical analyses for the error bounds of our approach, and validate our\nfindings using a detailed set of simulation experiments. Finally, we present\nthe results of our approach tested on multiple real videos captured using\nhandheld cameras, and compare them to several alternate foreground extraction\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 00:02:14 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Hamid", "Raffay", ""], ["Sarma", "Atish Das", ""], ["DeCoste", "Dennis", ""], ["Sundaresan", "Neel", ""]]}, {"id": "1404.5588", "submitter": "Jim Wang", "authors": "Jim Jing-Yan Wang, Majed Alzahrani, Xin Gao", "title": "Large Margin Image Set Representation and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel image set representation and classification\nmethod by maximizing the margin of image sets. The margin of an image set is\ndefined as the difference of the distance to its nearest image set from\ndifferent classes and the distance to its nearest image set of the same class.\nBy modeling the image sets by using both their image samples and their affine\nhull models, and maximizing the margins of the images sets, the image set\nrepresentation parameter learning problem is formulated as an minimization\nproblem, which is further optimized by an expectation -maximization (EM)\nstrategy with accelerated proximal gradient (APG) optimization in an iterative\nalgorithm. To classify a given test image set, we assign it to the class which\ncould provide the largest margin. Experiments on two applications of\nvideo-sequence-based face recognition demonstrate that the proposed method\nsignificantly outperforms state-of-the-art image set classification methods in\nterms of both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 22 Apr 2014 18:41:42 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Wang", "Jim Jing-Yan", ""], ["Alzahrani", "Majed", ""], ["Gao", "Xin", ""]]}, {"id": "1404.5765", "submitter": "Daniel Wolf", "authors": "Daniel Wolf, Markus Bajones, Johann Prankl, Markus Vincze", "title": "Find my mug: Efficient object search with a mobile robot using semantic\n  segmentation", "comments": "Part of the OAGM 2014 proceedings (arXiv:1404.3538)", "journal-ref": null, "doi": null, "report-no": "OAGM/2014/14", "categories": "cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an efficient semantic segmentation framework for\nindoor scenes, tailored to the application on a mobile robot. Semantic\nsegmentation can help robots to gain a reasonable understanding of their\nenvironment, but to reach this goal, the algorithms not only need to be\naccurate, but also fast and robust. Therefore, we developed an optimized 3D\npoint cloud processing framework based on a Randomized Decision Forest,\nachieving competitive results at sufficiently high frame rates. We evaluate the\ncapabilities of our method on the popular NYU depth dataset and our own data\nand demonstrate its feasibility by deploying it on a mobile service robot, for\nwhich we could optimize an object search procedure using our results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Apr 2014 09:48:30 GMT"}], "update_date": "2014-04-24", "authors_parsed": [["Wolf", "Daniel", ""], ["Bajones", "Markus", ""], ["Prankl", "Johann", ""], ["Vincze", "Markus", ""]]}, {"id": "1404.6031", "submitter": "Vishnu Naresh Boddeti", "authors": "Vishnu Naresh Boddeti and B.V.K. Vijaya Kumar", "title": "Maximum Margin Vector Correlation Filter", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation Filters (CFs) are a class of classifiers which are designed for\naccurate pattern localization. Traditionally CFs have been used with scalar\nfeatures only, which limits their ability to be used with vector feature\nrepresentations like Gabor filter banks, SIFT, HOG, etc. In this paper we\npresent a new CF named Maximum Margin Vector Correlation Filter (MMVCF) which\nextends the traditional CF designs to vector features. MMVCF further combines\nthe generalization capability of large margin based classifiers like Support\nVector Machines (SVMs) and the localization properties of CFs for better\nrobustness to outliers. We demonstrate the efficacy of MMVCF for object\ndetection and landmark localization on a variety of databases and demonstrate\nthat MMVCF consistently shows improved pattern localization capability in\ncomparison to SVMs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 05:43:54 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Boddeti", "Vishnu Naresh", ""], ["Kumar", "B. V. K. Vijaya", ""]]}, {"id": "1404.6039", "submitter": "Nicolas Charon", "authors": "Benjamin Charlier (UM2), Nicolas Charon (DIKU, CMLA), Alain Trouv\\'e\n  (CMLA)", "title": "The fshape framework for the variability analysis of functional shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a full mathematical and numerical framework for\ntreating functional shapes (or fshapes) following the landmarks of shape spaces\nand shape analysis. Functional shapes can be described as signal functions\nsupported on varying geometrical supports. Analysing variability of fshapes'\nensembles require the modelling and quantification of joint variations in\ngeometry and signal, which have been treated separately in previous approaches.\nInstead, building on the ideas of shape spaces for purely geometrical objects,\nwe propose the extended concept of fshape bundles and define Riemannian metrics\nfor fshape metamorphoses to model geometrico-functional transformations within\nthese bundles. We also generalize previous works on data attachment terms based\non the notion of varifolds and demonstrate the utility of these distances.\nBased on these, we propose variational formulations of the atlas estimation\nproblem on populations of fshapes and prove existence of solutions for the\ndifferent models. The second part of the article examines the numerical\nimplementation of the models by detailing discrete expressions for the metrics\nand gradients and proposing an optimization scheme for the atlas estimation\nproblem. We present a few results of the methodology on a synthetic dataset as\nwell as on a population of retinal membranes with thickness maps.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 06:23:30 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Charlier", "Benjamin", "", "UM2"], ["Charon", "Nicolas", "", "DIKU, CMLA"], ["Trouv\u00e9", "Alain", "", "CMLA"]]}, {"id": "1404.6055", "submitter": "Ziqiang Chen", "authors": "Feng Lu and Ziqiang Chen", "title": "A General Homogeneous Matrix Formulation to 3D Rotation Geometric\n  Transformations", "comments": "8 pages, 13 references, 1 table. arXiv admin note: substantial text\n  overlap with arXiv:1307.0998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algebraic projective geometry definitions of 3D rotations so as to\nbridge a small gap between the applications and the definitions of 3D rotations\nin homogeneous matrix form. A general homogeneous matrix formulation to 3D\nrotation geometric transformations is proposed which suits for the cases when\nthe rotation axis is unnecessarily through the coordinate system origin given\ntheir rotation axes and rotation angles.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 08:49:52 GMT"}, {"version": "v2", "created": "Wed, 14 May 2014 03:50:17 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Lu", "Feng", ""], ["Chen", "Ziqiang", ""]]}, {"id": "1404.6071", "submitter": "Chandranath  Adak", "authors": "Chandranath Adak", "title": "Rough Clustering Based Unsupervised Image Change Detection", "comments": "Proc. IEEE Conf. #30853, International Conference on Human Computer\n  Interactions (ICHCI'13), Chennai, India, 23-24 Aug., 2013. (In Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an unsupervised technique to detect the changed region\nof multitemporal images on a same reference plane with the help of rough\nclustering. The proposed technique is a soft-computing approach, based on the\nconcept of rough set with rough clustering and Pawlak's accuracy. It is less\nnoisy and avoids pre-deterministic knowledge about the distribution of the\nchanged and unchanged regions. To show the effectiveness, the proposed\ntechnique is compared with some other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 10:09:41 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Adak", "Chandranath", ""]]}, {"id": "1404.6075", "submitter": "Chandranath  Adak", "authors": "Chandranath Adak", "title": "Unsupervised Text Extraction from G-Maps", "comments": "Proc. IEEE Conf. #30853, International Conference on Human Computer\n  Interactions (ICHCI'13), Chennai, India, 23-24 Aug., 2013", "journal-ref": null, "doi": "10.1109/ICHCI-IEEE.2013.6887782", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper represents an text extraction method from Google maps, GIS\nmaps/images. Due to an unsupervised approach there is no requirement of any\nprior knowledge or training set about the textual and non-textual parts. Fuzzy\nCMeans clustering technique is used for image segmentation and Prewitt method\nis used to detect the edges. Connected component analysis and gridding\ntechnique enhance the correctness of the results. The proposed method reaches\n98.5% accuracy level on the basis of experimental data sets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 10:24:49 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Adak", "Chandranath", ""]]}, {"id": "1404.6272", "submitter": "Zhaowen Wang", "authors": "Zhaowen Wang, Jianchao Yang, Zhe Lin, Jonathan Brandt, Shiyu Chang,\n  Thomas Huang", "title": "Scalable Similarity Learning using Large Margin Neighborhood Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying large-scale image data into object categories is an important\nproblem that has received increasing research attention. Given the huge amount\nof data, non-parametric approaches such as nearest neighbor classifiers have\nshown promising results, especially when they are underpinned by a learned\ndistance or similarity measurement. Although metric learning has been well\nstudied in the past decades, most existing algorithms are impractical to handle\nlarge-scale data sets. In this paper, we present an image similarity learning\nmethod that can scale well in both the number of images and the dimensionality\nof image descriptors. To this end, similarity comparison is restricted to each\nsample's local neighbors and a discriminative similarity measure is induced\nfrom large margin neighborhood embedding. We also exploit the ensemble of\nprojections so that high-dimensional features can be processed in a set of\nlower-dimensional subspaces in parallel without much performance compromise.\nThe similarity function is learned online using a stochastic gradient descent\nalgorithm in which the triplet sampling strategy is customized for quick\nconvergence of classification performance. The effectiveness of our proposed\nmodel is validated on several data sets with scales varying from tens of\nthousands to one million images. Recognition accuracies competitive with the\nstate-of-the-art performance are achieved with much higher efficiency and\nscalability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 21:23:41 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Wang", "Zhaowen", ""], ["Yang", "Jianchao", ""], ["Lin", "Zhe", ""], ["Brandt", "Jonathan", ""], ["Chang", "Shiyu", ""], ["Huang", "Thomas", ""]]}, {"id": "1404.6351", "submitter": "Harald Ganster", "authors": "Harald Ganster, Martina Uray, Sylwia Steginska, Gerardus Croonen,\n  Rudolf Kaltenb\\\"ock, Karin Hennermann", "title": "Improving weather radar by fusion and classification", "comments": "Part of the OAGM 2014 proceedings (arXiv:1404.3538)", "journal-ref": null, "doi": null, "report-no": "OAGM/2014/04", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In air traffic management (ATM) all necessary operations (tactical planing,\nsector configuration, required staffing, runway configuration, routing of\napproaching aircrafts) rely on accurate measurements and predictions of the\ncurrent weather situation. An essential basis of information is delivered by\nweather radar images (WXR), which, unfortunately, exhibit a vast amount of\ndisturbances. Thus, the improvement of these datasets is the key factor for\nmore accurate predictions of weather phenomena and weather conditions. Image\nprocessing methods based on texture analysis and geometric operators allow to\nidentify regions including artefacts as well as zones of missing information.\nCorrection of these zones is implemented by exploiting multi-spectral satellite\ndata (Meteosat Second Generation). Results prove that the proposed system for\nartefact detection and data correction significantly improves the quality of\nWXR data and, thus, enables more reliable weather now- and forecast leading to\nincreased ATM safety.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2014 08:32:51 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Ganster", "Harald", ""], ["Uray", "Martina", ""], ["Steginska", "Sylwia", ""], ["Croonen", "Gerardus", ""], ["Kaltenb\u00f6ck", "Rudolf", ""], ["Hennermann", "Karin", ""]]}, {"id": "1404.6413", "submitter": "Georg Waltner", "authors": "Georg Waltner and Thomas Mauthner and Horst Bischof", "title": "Indoor Activity Detection and Recognition for Sport Games Analysis", "comments": "Part of the OAGM 2014 proceedings (arXiv:1404.3538)", "journal-ref": null, "doi": null, "report-no": "OAGM/2014/03", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity recognition in sport is an attractive field for computer vision\nresearch. Game, player and team analysis are of great interest and research\ntopics within this field emerge with the goal of automated analysis. The very\nspecific underlying rules of sports can be used as prior knowledge for the\nrecognition task and present a constrained environment for evaluation. This\npaper describes recognition of single player activities in sport with special\nemphasis on volleyball. Starting from a per-frame player-centered activity\nrecognition, we incorporate geometry and contextual information via an activity\ncontext descriptor that collects information about all player's activities over\na certain timespan relative to the investigated player. The benefit of this\ncontext information on single player activity recognition is evaluated on our\nnew real-life dataset presenting a total amount of almost 36k annotated frames\ncontaining 7 activity classes within 6 videos of professional volleyball games.\nOur incorporation of the contextual information improves the average\nplayer-centered classification performance of 77.56% by up to 18.35% on\nspecific classes, proving that spatio-temporal context is an important clue for\nactivity recognition.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2014 13:25:09 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Waltner", "Georg", ""], ["Mauthner", "Thomas", ""], ["Bischof", "Horst", ""]]}, {"id": "1404.6535", "submitter": "Aritanan Gruber", "authors": "Martin Anthony, Endre Boros, Yves Crama, Aritanan Gruber", "title": "Quadratization of Symmetric Pseudo-Boolean Functions", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.CV math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pseudo-Boolean function is a real-valued function\n$f(x)=f(x_1,x_2,\\ldots,x_n)$ of $n$ binary variables; that is, a mapping from\n$\\{0,1\\}^n$ to $\\mathbb{R}$. For a pseudo-Boolean function $f(x)$ on\n$\\{0,1\\}^n$, we say that $g(x,y)$ is a quadratization of $f$ if $g(x,y)$ is a\nquadratic polynomial depending on $x$ and on $m$ auxiliary binary variables\n$y_1,y_2,\\ldots,y_m$ such that $f(x)= \\min \\{g(x,y) : y \\in \\{0,1\\}^m \\}$ for\nall $x \\in \\{0,1\\}^n$. By means of quadratizations, minimization of $f$ is\nreduced to minimization (over its extended set of variables) of the quadratic\nfunction $g(x,y)$. This is of some practical interest because minimization of\nquadratic functions has been thoroughly studied for the last few decades, and\nmuch progress has been made in solving such problems exactly or heuristically.\nA related paper \\cite{ABCG} initiated a systematic study of the minimum number\nof auxiliary $y$-variables required in a quadratization of an arbitrary\nfunction $f$ (a natural question, since the complexity of minimizing the\nquadratic function $g(x,y)$ depends, among other factors, on the number of\nbinary variables). In this paper, we determine more precisely the number of\nauxiliary variables required by quadratizations of symmetric pseudo-Boolean\nfunctions $f(x)$, those functions whose value depends only on the Hamming\nweight of the input $x$ (the number of variables equal to $1$).\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2014 20:00:22 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Anthony", "Martin", ""], ["Boros", "Endre", ""], ["Crama", "Yves", ""], ["Gruber", "Aritanan", ""]]}, {"id": "1404.6538", "submitter": "Aritanan Gruber", "authors": "Endre Boros, Aritanan Gruber", "title": "On Quadratization of Pseudo-Boolean Functions", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey current term-wise techniques for quadratizing high-degree\npseudo-Boolean functions and introduce a new one, which allows multiple splits\nof terms. We also introduce the first aggregative approach, which splits a\ncollection of terms based on their common parts.\n", "versions": [{"version": "v1", "created": "Fri, 25 Apr 2014 20:06:21 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Boros", "Endre", ""], ["Gruber", "Aritanan", ""]]}, {"id": "1404.6691", "submitter": "Clemens Schiffer", "authors": "Clemens Schiffer and Kristian Bredies", "title": "Sinogram constrained TV-minimization for metal artifact reduction in CT", "comments": "Part of the OAGM 2014 proceedings (arXiv:1404.3538)", "journal-ref": null, "doi": null, "report-no": "OAGM/2014/13", "categories": "math.NA cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for reducing metal artifacts in X-ray computed tomography (CT)\nimages is presented. It bases on the solution of a convex optimization problem\nwith inequality constraints on the sinogram, and total variation regularization\nfor the reconstructed image. The Chambolle-Pock algorithm is used to\nnumerically solve the discretized version of the optimization problem. As proof\nof concept we present and discuss numerical results for synthetic data.\n", "versions": [{"version": "v1", "created": "Sat, 26 Apr 2014 22:41:20 GMT"}], "update_date": "2014-04-30", "authors_parsed": [["Schiffer", "Clemens", ""], ["Bredies", "Kristian", ""]]}, {"id": "1404.6736", "submitter": "Canyi Lu", "authors": "Can-Yi Lu, Hai Min, Zhong-Qiu Zhao, Lin Zhu, De-Shuang Huang,\n  Shuicheng Yan", "title": "Robust and Efficient Subspace Segmentation via Least Squares Regression", "comments": "European Conference on Computer Vision, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the subspace segmentation problem which aims to segment\ndata drawn from a union of multiple linear subspaces. Recent works by using\nsparse representation, low rank representation and their extensions attract\nmuch attention. If the subspaces from which the data drawn are independent or\northogonal, they are able to obtain a block diagonal affinity matrix, which\nusually leads to a correct segmentation. The main differences among them are\ntheir objective functions. We theoretically show that if the objective function\nsatisfies some conditions, and the data are sufficiently drawn from independent\nsubspaces, the obtained affinity matrix is always block diagonal. Furthermore,\nthe data sampling can be insufficient if the subspaces are orthogonal. Some\nexisting methods are all special cases. Then we present the Least Squares\nRegression (LSR) method for subspace segmentation. It takes advantage of data\ncorrelation, which is common in real data. LSR encourages a grouping effect\nwhich tends to group highly correlated data together. Experimental results on\nthe Hopkins 155 database and Extended Yale Database B show that our method\nsignificantly outperforms state-of-the-art methods. Beyond segmentation\naccuracy, all experiments demonstrate that LSR is much more efficient.\n", "versions": [{"version": "v1", "created": "Sun, 27 Apr 2014 11:01:17 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Lu", "Can-Yi", ""], ["Min", "Hai", ""], ["Zhao", "Zhong-Qiu", ""], ["Zhu", "Lin", ""], ["Huang", "De-Shuang", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1404.6871", "submitter": "Canyi Lu", "authors": "Canyi Lu, Yunchao Wei, Zhouchen Lin, Shuicheng Yan", "title": "Proximal Iteratively Reweighted Algorithm with Multiple Splitting for\n  Nonconvex Sparsity Optimization", "comments": null, "journal-ref": "Twenty-Eighth AAAI Conference on Artificial Intelligence, 2014", "doi": null, "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the Proximal Iteratively REweighted (PIRE) algorithm for\nsolving a general problem, which involves a large body of nonconvex sparse and\nstructured sparse related problems. Comparing with previous iterative solvers\nfor nonconvex sparse problem, PIRE is much more general and efficient. The\ncomputational cost of PIRE in each iteration is usually as low as the\nstate-of-the-art convex solvers. We further propose the PIRE algorithm with\nParallel Splitting (PIRE-PS) and PIRE algorithm with Alternative Updating\n(PIRE-AU) to handle the multi-variable problems. In theory, we prove that our\nproposed methods converge and any limit solution is a stationary point.\nExtensive experiments on both synthesis and real data sets demonstrate that our\nmethods achieve comparative learning performance, but are much more efficient,\nby comparing with previous nonconvex solvers.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 05:52:30 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Lu", "Canyi", ""], ["Wei", "Yunchao", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1404.7059", "submitter": "Dana Menaker", "authors": "Dana Menaker, Shai Avidan", "title": "Stereo on a budget", "comments": "update flowchart in Fig. 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for recovering depth using less than two images.\nInstead of having both cameras send their entire image to the host computer,\nthe left camera sends its image to the host while the right camera sends only a\nfraction $\\epsilon$ of its image. The key aspect is that the cameras send the\ninformation without communicating at all. Hence, the required communication\nbandwidth is significantly reduced.\n  While standard image compression techniques can reduce the communication\nbandwidth, this requires additional computational resources on the part of the\nencoder (camera). We aim at designing a light weight encoder that only touches\na fraction of the pixels. The burden of decoding is placed on the decoder\n(host).\n  We show that it is enough for the encoder to transmit a sparse set of pixels.\nUsing only $1+\\epsilon$ images, with $\\epsilon$ as little as 2% of the image,\nthe decoder can compute a depth map. The depth map's accuracy is comparable to\ntraditional stereo matching algorithms that require both images as input. Using\nthe depth map and the left image, the right image can be synthesized. No\ncomputations are required at the encoder, and the decoder's runtime is linear\nin the images' size.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 17:06:28 GMT"}, {"version": "v2", "created": "Tue, 29 Apr 2014 08:11:19 GMT"}], "update_date": "2014-04-30", "authors_parsed": [["Menaker", "Dana", ""], ["Avidan", "Shai", ""]]}, {"id": "1404.7174", "submitter": "Sagi Eppel", "authors": "Sagi Eppel and Tal Kachman", "title": "Computer vision-based recognition of liquid surfaces and phase\n  boundaries in transparent vessels, with emphasis on chemistry applications", "comments": "Source code for phase boundary and liquid surface recognition\n  available at:\n  http://www.mathworks.com/matlabcentral/fileexchange/46893-computer-vision-based-recognition-of-liquid-surface-and-liquid-level-of-liquid-of-transparent-vessel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The ability to recognize the liquid surface and the liquid level in\ntransparent containers is perhaps the most commonly used evaluation method when\ndealing with fluids. Such recognition is essential in determining the liquid\nvolume, fill level, phase boundaries and phase separation in various fluid\nsystems. The recognition of liquid surfaces is particularly important in\nsolution chemistry, where it is essential to many laboratory techniques (e.g.,\nextraction, distillation, titration). A general method for the recognition of\ninterfaces between liquid and air or between phase-separating liquids could\nhave a wide range of applications and contribute to the understanding of the\nvisual properties of such interfaces. This work examines a computer vision\nmethod for the recognition of liquid surfaces and liquid levels in various\ntransparent containers. The method can be applied to recognition of both\nliquid-air and liquid-liquid surfaces. No prior knowledge of the number of\nphases is required. The method receives the image of the liquid container and\nthe boundaries of the container in the image and scans all possible curves that\ncould correspond to the outlines of liquid surfaces in the image. The method\nthen compares each curve to the image to rate its correspondence with the\noutline of the real liquid surface by examining various image properties in the\narea surrounding each point of the curve. The image properties that were found\nto give the best indication of the liquid surface are the relative intensity\nchange, the edge density change and the gradient direction relative to the\ncurve normal.\n", "versions": [{"version": "v1", "created": "Mon, 28 Apr 2014 21:41:30 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 17:35:36 GMT"}, {"version": "v3", "created": "Sat, 17 May 2014 11:03:04 GMT"}, {"version": "v4", "created": "Mon, 2 Jun 2014 17:18:17 GMT"}, {"version": "v5", "created": "Fri, 13 Jun 2014 23:01:55 GMT"}, {"version": "v6", "created": "Sat, 23 Aug 2014 01:06:48 GMT"}, {"version": "v7", "created": "Thu, 6 Nov 2014 23:03:29 GMT"}], "update_date": "2014-11-10", "authors_parsed": [["Eppel", "Sagi", ""], ["Kachman", "Tal", ""]]}, {"id": "1404.7211", "submitter": "Jian Zhang", "authors": "Jian Zhang, Debin Zhao, Feng Jiang", "title": "Spatially Directional Predictive Coding for Block-based Compressive\n  Sensing of Natural Images", "comments": "5 pages, 3 tables, 3 figures, published at IEEE International\n  Conference on Image Processing (ICIP) 2013 Code Avaiable:\n  http://idm.pku.edu.cn/staff/zhangjian/SDPC/", "journal-ref": null, "doi": "10.1109/ICIP.2013.6738211", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel coding strategy for block-based compressive sens-ing named spatially\ndirectional predictive coding (SDPC) is proposed, which efficiently utilizes\nthe intrinsic spatial cor-relation of natural images. At the encoder, for each\nblock of compressive sensing (CS) measurements, the optimal pre-diction is\nselected from a set of prediction candidates that are generated by four\ndesigned directional predictive modes. Then, the resulting residual is\nprocessed by scalar quantiza-tion (SQ). At the decoder, the same prediction is\nadded onto the de-quantized residuals to produce the quantized CS measurements,\nwhich is exploited for CS reconstruction. Experimental results substantiate\nsignificant improvements achieved by SDPC-plus-SQ in rate distortion\nperformance as compared with SQ alone and DPCM-plus-SQ.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 02:10:09 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhang", "Jian", ""], ["Zhao", "Debin", ""], ["Jiang", "Feng", ""]]}, {"id": "1404.7212", "submitter": "Jian Zhang", "authors": "Jian Zhang, Debin Zhao, Feng Jiang, Wen Gao", "title": "Structural Group Sparse Representation for Image Compressive Sensing\n  Recovery", "comments": "10 pages, 4 figures, 1 table, published at IEEE Data Compression\n  Conference (DCC) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive Sensing (CS) theory shows that a signal can be decoded from many\nfewer measurements than suggested by the Nyquist sampling theory, when the\nsignal is sparse in some domain. Most of conventional CS recovery approaches,\nhowever, exploited a set of fixed bases (e.g. DCT, wavelet, contourlet and\ngradient domain) for the entirety of a signal, which are irrespective of the\nnonstationarity of natural signals and cannot achieve high enough degree of\nsparsity, thus resulting in poor rate-distortion performance. In this paper, we\npropose a new framework for image compressive sensing recovery via structural\ngroup sparse representation (SGSR) modeling, which enforces image sparsity and\nself-similarity simultaneously under a unified framework in an adaptive group\ndomain, thus greatly confining the CS solution space. In addition, an efficient\niterative shrinkage/thresholding algorithm based technique is developed to\nsolve the above optimization problem. Experimental results demonstrate that the\nnovel CS recovery strategy achieves significant performance improvements over\nthe current state-of-the-art schemes and exhibits nice convergence.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 02:15:42 GMT"}], "update_date": "2014-04-30", "authors_parsed": [["Zhang", "Jian", ""], ["Zhao", "Debin", ""], ["Jiang", "Feng", ""], ["Gao", "Wen", ""]]}, {"id": "1404.7298", "submitter": "Christian Br\\\"auer-Burchardt", "authors": "Christian Br\\\"auer-Burchardt, Peter K\\\"uhmstedt, Gunther Notni", "title": "Code Minimization for Fringe Projection Based 3D Stereo Sensors by\n  Calibration Improvement", "comments": "8 pages, 5 figures, OAGM 2014 paper", "journal-ref": null, "doi": null, "report-no": "OAGM/2014/06", "categories": "math.MG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code minimization provides a speed-up of the processing time of fringe\nprojection based stereo sensors and possibly makes them real-time applicable.\nThis paper reports a methodology which enables such sensors to completely omit\nGray code or other additional code. Only a sequence of sinusoidal images is\nnecessary. The code reduction is achieved by involvement of the projection unit\ninto the measurement, double triangulation, and a precise projector calibration\nor significant projector calibration improvement, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 10:26:00 GMT"}], "update_date": "2014-04-30", "authors_parsed": [["Br\u00e4uer-Burchardt", "Christian", ""], ["K\u00fchmstedt", "Peter", ""], ["Notni", "Gunther", ""]]}, {"id": "1404.7306", "submitter": "Canyi Lu", "authors": "Canyi Lu, Jinhui Tang, Shuicheng Yan, Zhouchen Lin", "title": "Generalized Nonconvex Nonsmooth Low-Rank Minimization", "comments": "IEEE International Conference on Computer Vision and Pattern\n  Recognition, 2014", "journal-ref": null, "doi": "10.1109/CVPR.2014.526", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As surrogate functions of $L_0$-norm, many nonconvex penalty functions have\nbeen proposed to enhance the sparse vector recovery. It is easy to extend these\nnonconvex penalty functions on singular values of a matrix to enhance low-rank\nmatrix recovery. However, different from convex optimization, solving the\nnonconvex low-rank minimization problem is much more challenging than the\nnonconvex sparse minimization problem. We observe that all the existing\nnonconvex penalty functions are concave and monotonically increasing on\n$[0,\\infty)$. Thus their gradients are decreasing functions. Based on this\nproperty, we propose an Iteratively Reweighted Nuclear Norm (IRNN) algorithm to\nsolve the nonconvex nonsmooth low-rank minimization problem. IRNN iteratively\nsolves a Weighted Singular Value Thresholding (WSVT) problem. By setting the\nweight vector as the gradient of the concave penalty function, the WSVT problem\nhas a closed form solution. In theory, we prove that IRNN decreases the\nobjective function value monotonically, and any limit point is a stationary\npoint. Extensive experiments on both synthetic data and real images demonstrate\nthat IRNN enhances the low-rank matrix recovery compared with state-of-the-art\nconvex algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 29 Apr 2014 10:45:22 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lu", "Canyi", ""], ["Tang", "Jinhui", ""], ["Yan", "Shuicheng", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1404.7566", "submitter": "Jian Zhang", "authors": "Jian Zhang, Chen Zhao, Debin Zhao, Wen Gao", "title": "Image Compressive Sensing Recovery Using Adaptively Learned Sparsifying\n  Basis via L0 Minimization", "comments": "31 pages, 4 tables, 12 figures, to be published at Signal Processing,\n  Code available: http://idm.pku.edu.cn/staff/zhangjian/ALSB/", "journal-ref": null, "doi": "10.1016/j.sigpro.2013.09.025", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From many fewer acquired measurements than suggested by the Nyquist sampling\ntheory, compressive sensing (CS) theory demonstrates that, a signal can be\nreconstructed with high probability when it exhibits sparsity in some domain.\nMost of the conventional CS recovery approaches, however, exploited a set of\nfixed bases (e.g. DCT, wavelet and gradient domain) for the entirety of a\nsignal, which are irrespective of the non-stationarity of natural signals and\ncannot achieve high enough degree of sparsity, thus resulting in poor CS\nrecovery performance. In this paper, we propose a new framework for image\ncompressive sensing recovery using adaptively learned sparsifying basis via L0\nminimization. The intrinsic sparsity of natural images is enforced\nsubstantially by sparsely representing overlapped image patches using the\nadaptively learned sparsifying basis in the form of L0 norm, greatly reducing\nblocking artifacts and confining the CS solution space. To make our proposed\nscheme tractable and robust, a split Bregman iteration based technique is\ndeveloped to solve the non-convex L0 minimization problem efficiently.\nExperimental results on a wide range of natural images for CS recovery have\nshown that our proposed algorithm achieves significant performance improvements\nover many current state-of-the-art schemes and exhibits good convergence\nproperty.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 00:56:40 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Zhang", "Jian", ""], ["Zhao", "Chen", ""], ["Zhao", "Debin", ""], ["Gao", "Wen", ""]]}, {"id": "1404.7584", "submitter": "Jo\\~ao F. Henriques", "authors": "Jo\\~ao F. Henriques, Rui Caseiro, Pedro Martins, Jorge Batista", "title": "High-Speed Tracking with Kernelized Correlation Filters", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2014.2345390", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core component of most modern trackers is a discriminative classifier,\ntasked with distinguishing between the target and the surrounding environment.\nTo cope with natural image changes, this classifier is typically trained with\ntranslated and scaled sample patches. Such sets of samples are riddled with\nredundancies -- any overlapping pixels are constrained to be the same. Based on\nthis simple observation, we propose an analytic model for datasets of thousands\nof translated patches. By showing that the resulting data matrix is circulant,\nwe can diagonalize it with the Discrete Fourier Transform, reducing both\nstorage and computation by several orders of magnitude. Interestingly, for\nlinear regression our formulation is equivalent to a correlation filter, used\nby some of the fastest competitive trackers. For kernel regression, however, we\nderive a new Kernelized Correlation Filter (KCF), that unlike other kernel\nalgorithms has the exact same complexity as its linear counterpart. Building on\nit, we also propose a fast multi-channel extension of linear correlation\nfilters, via a linear kernel, which we call Dual Correlation Filter (DCF). Both\nKCF and DCF outperform top-ranking trackers such as Struck or TLD on a 50\nvideos benchmark, despite running at hundreds of frames-per-second, and being\nimplemented in a few lines of code (Algorithm 1). To encourage further\ndevelopments, our tracking framework was made open-source.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 04:16:38 GMT"}, {"version": "v2", "created": "Fri, 11 Jul 2014 23:04:01 GMT"}, {"version": "v3", "created": "Wed, 5 Nov 2014 01:32:56 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Henriques", "Jo\u00e3o F.", ""], ["Caseiro", "Rui", ""], ["Martins", "Pedro", ""], ["Batista", "Jorge", ""]]}, {"id": "1404.7592", "submitter": "Jacob Grosek", "authors": "Jacob Grosek and J. Nathan Kutz", "title": "Dynamic Mode Decomposition for Real-Time Background/Foreground\n  Separation in Video", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the method of dynamic mode decomposition (DMD) for\nrobustly separating video frames into background (low-rank) and foreground\n(sparse) components in real-time. The method is a novel application of a\ntechnique used for characterizing nonlinear dynamical systems in an\nequation-free manner by decomposing the state of the system into low-rank terms\nwhose Fourier components in time are known. DMD terms with Fourier frequencies\nnear the origin (zero-modes) are interpreted as background (low-rank) portions\nof the given video frames, and the terms with Fourier frequencies bounded away\nfrom the origin are their sparse counterparts. An approximate low-rank/sparse\nseparation is achieved at the computational cost of just one singular value\ndecomposition and one linear equation solve, thus producing results orders of\nmagnitude faster than a leading separation method, namely robust principal\ncomponent analysis (RPCA). The DMD method that is developed here is\ndemonstrated to work robustly in real-time with personal laptop-class computing\npower and without any parameter tuning, which is a transformative improvement\nin performance that is ideal for video surveillance and recognition\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 05:21:27 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Grosek", "Jacob", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1404.7594", "submitter": "Jacob Grosek", "authors": "Jacob Grosek and J. Nathan Kutz", "title": "Selecting a Small Set of Optimal Gestures from an Extensive Lexicon", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the best set of gestures to use for a given computer recognition\nproblem is an essential part of optimizing the recognition performance while\nbeing mindful to those who may articulate the gestures. An objective function,\ncalled the ellipsoidal distance ratio metric (EDRM), for determining the best\ngestures from a larger lexicon library is presented, along with a numerical\nmethod for incorporating subjective preferences. In particular, we demonstrate\nan efficient algorithm that chooses the best $n$ gestures from a lexicon of $m$\ngestures where typically $n \\ll m$ using a weighting of both subjective and\nobjective measures.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 05:37:44 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Grosek", "Jacob", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1404.7748", "submitter": "Laurent Najman", "authors": "Laurent Najman and Jean Cousty", "title": "A graph-based mathematical morphology reader", "comments": null, "journal-ref": "Pattern Recognition Letters 47 (2014) 3-17", "doi": "10.1016/j.patrec.2014.05.007", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey paper aims at providing a \"literary\" anthology of mathematical\nmorphology on graphs. It describes in the English language many ideas stemming\nfrom a large number of different papers, hence providing a unified view of an\nactive and diverse field of research.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 14:54:19 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Najman", "Laurent", ""], ["Cousty", "Jean", ""]]}]