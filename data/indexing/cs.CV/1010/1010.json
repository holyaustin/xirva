[{"id": "1010.0012", "submitter": "James Coughlan", "authors": "James M. Coughlan, Huiying Shen", "title": "An Embarrassingly Simple Speed-Up of Belief Propagation with Robust\n  Potentials", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an exact method of greatly speeding up belief propagation (BP) for\na wide variety of potential functions in pairwise MRFs and other graphical\nmodels. Specifically, our technique applies whenever the pairwise potentials\nhave been {\\em truncated} to a constant value for most pairs of states, as is\ncommonly done in MRF models with robust potentials (such as stereo) that impose\nan upper bound on the penalty assigned to discontinuities; for each of the $M$\npossible states in one node, only a smaller number $m$ of compatible states in\na neighboring node are assigned milder penalties. The computational complexity\nof our method is $O(mM)$, compared with $O(M^2)$ for standard BP, and we\nemphasize that the method is {\\em exact}, in contrast with related techniques\nsuch as pruning; moreover, the method is very simple and easy to implement.\nUnlike some previous work on speeding up BP, our method applies both to\nsum-product and max-product BP, which makes it useful in any applications where\nmarginal probabilities are required, such as maximum likelihood estimation. We\ndemonstrate the technique on a stereo MRF example, confirming that the\ntechnique speeds up BP without altering the solution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 20:17:03 GMT"}], "update_date": "2010-10-04", "authors_parsed": [["Coughlan", "James M.", ""], ["Shen", "Huiying", ""]]}, {"id": "1010.0301", "submitter": "Sugata Sanyal", "authors": "Anjan Kumar Kundu, Bijoy Bandopadhyay, Sugata Sanyal", "title": "A Microwave Imaging and Enhancement Technique from Noisy Synthetic Data", "comments": "8 Pages, 10 Figures, International Symposium on Advanced Engineering\n  and Applied Management-40th Anniversary in Higher Education-Image\n  Processing-University Politegnica, Timisoara, 4-5 November, 2010, Hunedoara,\n  ROMANIA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inverse iterative algorithm for microwave imaging based on moment method\nsolution is presented here. The iterative scheme has been developed on\nconstrained optimization technique and is certain to converge. Different mesh\nsize for the model has been used here to overcome the Inverse Crime. The\nsynthetic data at the receivers is contaminated with different percentage of\nnoise. The ill-posedness of the problem is solved by Levenberg-Marquardt\nmethod. The algorithm is applied to synthetic data and the reconstructed image\nis then further enhanced through the Image enhancement technique\n", "versions": [{"version": "v1", "created": "Sat, 2 Oct 2010 07:52:48 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Kundu", "Anjan Kumar", ""], ["Bandopadhyay", "Bijoy", ""], ["Sanyal", "Sugata", ""]]}, {"id": "1010.0417", "submitter": "Yu Su", "authors": "Yu Su and Margaret H. Dunham", "title": "Visual-hint Boundary to Segment Algorithm for Image Segmentation", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Image segmentation has been a very active research topic in image analysis\narea. Currently, most of the image segmentation algorithms are designed based\non the idea that images are partitioned into a set of regions preserving\nhomogeneous intra-regions and inhomogeneous inter-regions. However, human\nvisual intuition does not always follow this pattern. A new image segmentation\nmethod named Visual-Hint Boundary to Segment (VHBS) is introduced, which is\nmore consistent with human perceptions. VHBS abides by two visual hint rules\nbased on human perceptions: (i) the global scale boundaries tend to be the real\nboundaries of the objects; (ii) two adjacent regions with quite different\ncolors or textures tend to result in the real boundaries between them. It has\nbeen demonstrated by experiments that, compared with traditional image\nsegmentation method, VHBS has better performance and also preserves higher\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 3 Oct 2010 15:27:56 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Su", "Yu", ""], ["Dunham", "Margaret H.", ""]]}, {"id": "1010.0422", "submitter": "Arthur Szlam", "authors": "Arthur Szlam, Koray Kavukcuoglu, and Yann LeCun", "title": "Convolutional Matching Pursuit and Dictionary Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Matching pursuit and K-SVD is demonstrated in the translation invariant\nsetting\n", "versions": [{"version": "v1", "created": "Sun, 3 Oct 2010 16:55:56 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Szlam", "Arthur", ""], ["Kavukcuoglu", "Koray", ""], ["LeCun", "Yann", ""]]}, {"id": "1010.0608", "submitter": "Chenlu Qiu", "authors": "Chenlu Qiu and Namrata Vaswani", "title": "Real-time Robust Principal Components' Pursuit", "comments": "8 pages, 4 figures, Allerton 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent work of Candes et al, the problem of recovering low rank matrix\ncorrupted by i.i.d. sparse outliers is studied and a very elegant solution,\nprincipal component pursuit, is proposed. It is motivated as a tool for video\nsurveillance applications with the background image sequence forming the low\nrank part and the moving objects/persons/abnormalities forming the sparse part.\nEach image frame is treated as a column vector of the data matrix made up of a\nlow rank matrix and a sparse corruption matrix. Principal component pursuit\nsolves the problem under the assumptions that the singular vectors of the low\nrank matrix are spread out and the sparsity pattern of the sparse matrix is\nuniformly random. However, in practice, usually the sparsity pattern and the\nsignal values of the sparse part (moving persons/objects) change in a\ncorrelated fashion over time, for e.g., the object moves slowly and/or with\nroughly constant velocity. This will often result in a low rank sparse matrix.\n  For video surveillance applications, it would be much more useful to have a\nreal-time solution. In this work, we study the online version of the above\nproblem and propose a solution that automatically handles correlated sparse\noutliers. The key idea of this work is as follows. Given an initial estimate of\nthe principal directions of the low rank part, we causally keep estimating the\nsparse part at each time by solving a noisy compressive sensing type problem.\nThe principal directions of the low rank part are updated every-so-often. In\nbetween two update times, if new Principal Components' directions appear, the\n\"noise\" seen by the Compressive Sensing step may increase. This problem is\nsolved, in part, by utilizing the time correlation model of the low rank part.\nWe call the proposed solution \"Real-time Robust Principal Components' Pursuit\".\n", "versions": [{"version": "v1", "created": "Mon, 4 Oct 2010 14:50:43 GMT"}, {"version": "v2", "created": "Wed, 6 Oct 2010 14:36:12 GMT"}, {"version": "v3", "created": "Sat, 12 Feb 2011 15:12:50 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Qiu", "Chenlu", ""], ["Vaswani", "Namrata", ""]]}, {"id": "1010.1496", "submitter": "Vishwakarma Singh", "authors": "Vishwakarma Singh, Ambuj K. Singh", "title": "Profile Based Sub-Image Search in Image Databases", "comments": "Sub-Image Retrieval, New Feature Vector, Similarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sub-image search with high accuracy in natural images still remains a\nchallenging problem. This paper proposes a new feature vector called profile\nfor a keypoint in a bag of visual words model of an image. The profile of a\nkeypoint captures the spatial geometry of all the other keypoints in an image\nwith respect to itself, and is very effective in discriminating true matches\nfrom false matches. Sub-image search using profiles is a single-phase process\nrequiring no geometric validation, yields high precision on natural images, and\nworks well on small visual codebook. The proposed search technique differs from\ntraditional methods that first generate a set of candidates disregarding\nspatial information and then verify them geometrically. Conventional methods\nalso use large codebooks. We achieve a precision of 81% on a combined data set\nof synthetic and real natural images using a codebook size of 500 for top-10\nqueries; that is 31% higher than the conventional candidate generation\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 7 Oct 2010 17:42:09 GMT"}], "update_date": "2010-10-08", "authors_parsed": [["Singh", "Vishwakarma", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "1010.2733", "submitter": "Talbot Hugues", "authors": "Camille Couprie (LIGM), Leo Grady, Hugues Talbot (LIGM), Laurent\n  Najman (LIGM)", "title": "Combinatorial Continuous Maximal Flows", "comments": "26 pages", "journal-ref": "SIAM Journal on Imaging Sciences 4 (2011) 905-930", "doi": "10.1137/100799186", "report-no": null, "categories": "cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum flow (and minimum cut) algorithms have had a strong impact on\ncomputer vision. In particular, graph cuts algorithms provide a mechanism for\nthe discrete optimization of an energy functional which has been used in a\nvariety of applications such as image segmentation, stereo, image stitching and\ntexture synthesis. Algorithms based on the classical formulation of max-flow\ndefined on a graph are known to exhibit metrication artefacts in the solution.\nTherefore, a recent trend has been to instead employ a spatially continuous\nmaximum flow (or the dual min-cut problem) in these same applications to\nproduce solutions with no metrication errors. However, known fast continuous\nmax-flow algorithms have no stopping criteria or have not been proved to\nconverge. In this work, we revisit the continuous max-flow problem and show\nthat the analogous discrete formulation is different from the classical\nmax-flow problem. We then apply an appropriate combinatorial optimization\ntechnique to this combinatorial continuous max-flow CCMF problem to find a\nnull-divergence solution that exhibits no metrication artefacts and may be\nsolved exactly by a fast, efficient algorithm with provable convergence.\nFinally, by exhibiting the dual problem of our CCMF formulation, we clarify the\nfact, already proved by Nozawa in the continuous setting, that the max-flow and\nthe total variation problems are not always equivalent.\n", "versions": [{"version": "v1", "created": "Wed, 13 Oct 2010 19:08:02 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2011 07:26:41 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Couprie", "Camille", "", "LIGM"], ["Grady", "Leo", "", "LIGM"], ["Talbot", "Hugues", "", "LIGM"], ["Najman", "Laurent", "", "LIGM"]]}, {"id": "1010.2955", "submitter": "Guangcan Liu", "authors": "Guangcan Liu, Zhouchen Lin, Shuicheng Yan, Ju Sun, Yong Yu, Yi Ma", "title": "Robust Recovery of Subspace Structures by Low-Rank Representation", "comments": "IEEE Trans. Pattern Analysis and Machine Intelligence", "journal-ref": "IEEE Trans. Pattern Analysis and Machine Intelligence, 35(2013)\n  171-184", "doi": "10.1109/TPAMI.2012.88", "report-no": null, "categories": "cs.IT cs.CV cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the subspace recovery problem. Given a set of data\nsamples (vectors) approximately drawn from a union of multiple subspaces, our\ngoal is to segment the samples into their respective subspaces and correct the\npossible errors as well. To this end, we propose a novel method termed Low-Rank\nRepresentation (LRR), which seeks the lowest-rank representation among all the\ncandidates that can represent the data samples as linear combinations of the\nbases in a given dictionary. It is shown that LRR well solves the subspace\nrecovery problem: when the data is clean, we prove that LRR exactly captures\nthe true subspace structures; for the data contaminated by outliers, we prove\nthat under certain conditions LRR can exactly recover the row space of the\noriginal data and detect the outlier as well; for the data corrupted by\narbitrary errors, LRR can also approximately recover the row space with\ntheoretical guarantees. Since the subspace membership is provably determined by\nthe row space, these further imply that LRR can perform robust subspace\nsegmentation and error correction, in an efficient way.\n", "versions": [{"version": "v1", "created": "Thu, 14 Oct 2010 15:38:48 GMT"}, {"version": "v2", "created": "Tue, 9 Nov 2010 14:07:04 GMT"}, {"version": "v3", "created": "Mon, 22 Nov 2010 09:27:15 GMT"}, {"version": "v4", "created": "Thu, 8 Sep 2011 09:02:03 GMT"}, {"version": "v5", "created": "Wed, 28 Mar 2012 05:09:27 GMT"}, {"version": "v6", "created": "Sun, 6 May 2012 08:23:16 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Liu", "Guangcan", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""], ["Sun", "Ju", ""], ["Yu", "Yong", ""], ["Ma", "Yi", ""]]}, {"id": "1010.3460", "submitter": "Gilad Lerman Dr", "authors": "Teng Zhang, Arthur Szlam, Yi Wang, Gilad Lerman", "title": "Hybrid Linear Modeling via Local Best-fit Flats", "comments": "This version adds some clarifications and numerical experiments as\n  well as strengthens the previous theorem. For face experiments, we use here\n  the Extended Yale Face Database B (cropped faces unlike previous version).\n  This database points to a failure mode of our algorithms, but we suggest and\n  successfully test a workaround", "journal-ref": "International Journal of Computer Vision Volume 100, Issue 3\n  (2012), Page 217-240", "doi": "10.1007/s11263-012-0535-6", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and fast geometric method for modeling data by a union of\naffine subspaces. The method begins by forming a collection of local best-fit\naffine subspaces, i.e., subspaces approximating the data in local\nneighborhoods. The correct sizes of the local neighborhoods are determined\nautomatically by the Jones' $\\beta_2$ numbers (we prove under certain geometric\nconditions that our method finds the optimal local neighborhoods). The\ncollection of subspaces is further processed by a greedy selection procedure or\na spectral method to generate the final model. We discuss applications to\ntracking-based motion segmentation and clustering of faces under different\nilluminating conditions. We give extensive experimental evidence demonstrating\nthe state of the art accuracy and speed of the suggested algorithms on these\nproblems and also on synthetic hybrid linear data as well as the MNIST\nhandwritten digits data; and we demonstrate how to use our algorithms for fast\ndetermination of the number of affine subspaces.\n", "versions": [{"version": "v1", "created": "Sun, 17 Oct 2010 23:27:35 GMT"}, {"version": "v2", "created": "Tue, 1 May 2012 21:26:48 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Zhang", "Teng", ""], ["Szlam", "Arthur", ""], ["Wang", "Yi", ""], ["Lerman", "Gilad", ""]]}, {"id": "1010.3467", "submitter": "Koray Kavukcuoglu", "authors": "Koray Kavukcuoglu, Marc'Aurelio Ranzato and Yann LeCun", "title": "Fast Inference in Sparse Coding Algorithms with Applications to Object\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": "CBLL-TR-2008-12-01", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive sparse coding methods learn a possibly overcomplete set of basis\nfunctions, such that natural image patches can be reconstructed by linearly\ncombining a small subset of these bases. The applicability of these methods to\nvisual object recognition tasks has been limited because of the prohibitive\ncost of the optimization algorithms required to compute the sparse\nrepresentation. In this work we propose a simple and efficient algorithm to\nlearn basis functions. After training, this model also provides a fast and\nsmooth approximator to the optimal representation, achieving even better\naccuracy than exact sparse coding algorithms on visual object recognition\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Oct 2010 02:31:21 GMT"}], "update_date": "2010-10-19", "authors_parsed": [["Kavukcuoglu", "Koray", ""], ["Ranzato", "Marc'Aurelio", ""], ["LeCun", "Yann", ""]]}, {"id": "1010.3867", "submitter": "Fabien Moutarde", "authors": "Alexandre Bargeton (CAOR), Fabien Moutarde (CAOR), Fawzi Nashashibi\n  (CAOR), Anne-Sophie Puthon (CAOR)", "title": "Joint interpretation of on-board vision and static GPS cartography for\n  determination of correct speed limit", "comments": null, "journal-ref": "17th ITS world congress (ITSwc'2010), Busan : Korea, Republic Of\n  (2010)", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here a first prototype of a \"Speed Limit Support\" Advance Driving\nAssistance System (ADAS) producing permanent reliable information on the\ncurrent speed limit applicable to the vehicle. Such a module can be used either\nfor information of the driver, or could even serve for automatic setting of the\nmaximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on\na joint interpretation of cartographic information (for static reference\ninformation) with on-board vision, used for traffic sign detection and\nrecognition (including supplementary sub-signs) and visual road lines\nlocalization (for detection of lane changes). The visual traffic sign detection\npart is quite robust (90% global correct detection and recognition for main\nspeed signs, and 80% for exit-lane sub-signs detection). Our approach for joint\ninterpretation with cartography is original, and logic-based rather than\nprobability-based, which allows correct behaviour even in cases, which do\nhappen, when both vision and cartography may provide the same erroneous\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 12:03:16 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Bargeton", "Alexandre", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"], ["Nashashibi", "Fawzi", "", "CAOR"], ["Puthon", "Anne-Sophie", "", "CAOR"]]}, {"id": "1010.3935", "submitter": "Pedro Aguiar", "authors": "Pedro M. Q. Aguiar, Rui F. C. Guerreiro, and Bruno B. Gon\\c{c}alves", "title": "3-D Rigid Models from Partial Views - Global Factorization", "comments": "21 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The so-called factorization methods recover 3-D rigid structure from motion\nby factorizing an observation matrix that collects 2-D projections of features.\nThese methods became popular due to their robustness - they use a large number\nof views, which constrains adequately the solution - and computational\nsimplicity - the large number of unknowns is computed through an SVD, avoiding\nnon-linear optimization. However, they require that all the entries of the\nobservation matrix are known. This is unlikely to happen in practice, due to\nself-occlusion and limited field of view. Also, when processing long videos,\nregions that become occluded often appear again later. Current factorization\nmethods process these as new regions, leading to less accurate estimates of 3-D\nstructure. In this paper, we propose a global factorization method that infers\ncomplete 3-D models directly from the 2-D projections in the entire set of\navailable video frames. Our method decides whether a region that has become\nvisible is a region that was seen before, or a previously unseen region, in a\nglobal way, i.e., by seeking the simplest rigid object that describes well the\nentire set of observations. This global approach increases significantly the\naccuracy of the estimates of the 3-D shape of the scene and the 3-D motion of\nthe camera. Experiments with artificial and real videos illustrate the good\nperformance of our method.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 14:45:55 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Aguiar", "Pedro M. Q.", ""], ["Guerreiro", "Rui F. C.", ""], ["Gon\u00e7alves", "Bruno B.", ""]]}, {"id": "1010.3947", "submitter": "Pedro Aguiar", "authors": "Bernardo Esteves Pires and Pedro M. Q. Aguiar", "title": "Maximum Likelihood Mosaics", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of the approaches to the automatic recovery of a panoramic image\nfrom a set of partial views are suboptimal in the sense that the input images\nare aligned, or registered, pair by pair, e.g., consecutive frames of a video\nclip. These approaches lead to propagation errors that may be very severe,\nparticularly when dealing with videos that show the same region at disjoint\ntime intervals. Although some authors have proposed a post-processing step to\nreduce the registration errors in these situations, there have not been\nattempts to compute the optimal solution, i.e., the registrations leading to\nthe panorama that best matches the entire set of partial views}. This is our\ngoal. In this paper, we use a generative model for the partial views of the\npanorama and develop an algorithm to compute in an efficient way the Maximum\nLikelihood estimate of all the unknowns involved: the parameters describing the\nalignment of all the images and the panorama itself.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 15:13:40 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Pires", "Bernardo Esteves", ""], ["Aguiar", "Pedro M. Q.", ""]]}, {"id": "1010.4021", "submitter": "Pedro Aguiar", "authors": "Jos\\'e J. Rodrigues, Jo\\~ao M. F. Xavier, and Pedro M. Q. Aguiar", "title": "ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of\n  Unlabeled Points)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image analysis, many tasks require representing two-dimensional (2D)\nshape, often specified by a set of 2D points, for comparison purposes. The\nchallenge of the representation is that it must not only capture the\ncharacteristics of the shape but also be invariant to relevant transformations.\nInvariance to geometric transformations, such as translation, rotation, and\nscale, has received attention in the past, usually under the assumption that\nthe points are previously labeled, i.e., that the shape is characterized by an\nordered set of landmarks. However, in many practical scenarios, the points\ndescribing the shape are obtained from automatic processes, e.g., edge or\ncorner detection, thus without labels or natural ordering. Obviously, the\ncombinatorial problem of computing the correspondences between the points of\ntwo shapes in the presence of the aforementioned geometrical distortions\nbecomes a quagmire when the number of points is large. We circumvent this\nproblem by representing shapes in a way that is invariant to the permutation of\nthe landmarks, i.e., we represent bags of unlabeled 2D points. Within our\nframework, a shape is mapped to an analytic function on the complex plane,\nleading to what we call its analytic signature (ANSIG). To store an ANSIG, it\nsuffices to sample it along a closed contour in the complex plane. We show that\nthe ANSIG is a maximal invariant with respect to the permutation group, i.e.,\nthat different shapes have different ANSIGs and shapes that differ by a\npermutation (or re-labeling) of the landmarks have the same ANSIG. We further\nshow how easy it is to factor out geometric transformations when comparing\nshapes using the ANSIG representation. Finally, we illustrate these\ncapabilities with shape-based image classification experiments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 19:48:41 GMT"}], "update_date": "2010-10-20", "authors_parsed": [["Rodrigues", "Jos\u00e9 J.", ""], ["Xavier", "Jo\u00e3o M. F.", ""], ["Aguiar", "Pedro M. Q.", ""]]}, {"id": "1010.4059", "submitter": "Vasil Kolev", "authors": "Vasil Kolev", "title": "Multiplierless Modules for Forward and Backward Integer Wavelet\n  Transform", "comments": "7 pages, The ACM proceedings of CompSysTech 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about the architecture of a lossless wavelet filter bank with\nreprogrammable logic. It is based on second generation of wavelets with a\nreduced of number of operations. A new basic structure for parallel\narchitecture and modules to forward and backward integer discrete wavelet\ntransform is proposed.\n", "versions": [{"version": "v1", "created": "Tue, 19 Oct 2010 21:58:14 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2011 19:01:09 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Kolev", "Vasil", ""]]}, {"id": "1010.4203", "submitter": "Pedro Aguiar", "authors": "Jo\\~ao B. F. P. Crespo and Pedro M. Q. Aguiar", "title": "Revisiting Complex Moments For 2D Shape Representation and Image\n  Normalization", "comments": "69 pages, 20 figures", "journal-ref": null, "doi": "10.1109/TIP.2011.2146264", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing 2D shapes, a key issue is their normalization. Translation and\nscale are easily taken care of by removing the mean and normalizing the energy.\nHowever, defining and computing the orientation of a 2D shape is not so simple.\nIn fact, although for elongated shapes the principal axis can be used to define\none of two possible orientations, there is no such tool for general shapes. As\nwe show in the paper, previous approaches fail to compute the orientation of\neven noiseless observations of simple shapes. We address this problem. In the\npaper, we show how to uniquely define the orientation of an arbitrary 2D shape,\nin terms of what we call its Principal Moments. We show that a small subset of\nthese moments suffice to represent the underlying 2D shape and propose a new\nmethod to efficiently compute the shape orientation: Principal Moment Analysis.\nFinally, we discuss how this method can further be applied to normalize\ngrey-level images. Besides the theoretical proof of correctness, we describe\nexperiments demonstrating robustness to noise and illustrating the method with\nreal images.\n", "versions": [{"version": "v1", "created": "Mon, 18 Oct 2010 20:12:29 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Crespo", "Jo\u00e3o B. F. P.", ""], ["Aguiar", "Pedro M. Q.", ""]]}, {"id": "1010.4314", "submitter": "Guoshen Yu", "authors": "Guoshen Yu, Guillermo Sapiro", "title": "Statistical Compressive Sensing of Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new framework of compressive sensing (CS), namely statistical compressive\nsensing (SCS), that aims at efficiently sampling a collection of signals that\nfollow a statistical distribution and achieving accurate reconstruction on\naverage, is introduced. For signals following a Gaussian distribution, with\nGaussian or Bernoulli sensing matrices of O(k) measurements, considerably\nsmaller than the O(k log(N/k)) required by conventional CS, where N is the\nsignal dimension, and with an optimal decoder implemented with linear\nfiltering, significantly faster than the pursuit decoders applied in\nconventional CS, the error of SCS is shown tightly upper bounded by a constant\ntimes the k-best term approximation error, with overwhelming probability. The\nfailure probability is also significantly smaller than that of conventional CS.\nStronger yet simpler results further show that for any sensing matrix, the\nerror of Gaussian SCS is upper bounded by a constant times the k-best term\napproximation with probability one, and the bound constant can be efficiently\ncalculated. For signals following Gaussian mixture models, SCS with a piecewise\nlinear decoder is introduced and shown to produce for real images better\nresults than conventional CS based on sparse models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 20:22:26 GMT"}], "update_date": "2010-10-22", "authors_parsed": [["Yu", "Guoshen", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1010.4893", "submitter": "Pablo Sprechmann", "authors": "Pablo Sprechmann, Ignacio Ramirez, Pablo Cancela, and Guillermo Sapiro", "title": "Collaborative Sources Identification in Mixed Signals via Hierarchical\n  Sparse Modeling", "comments": "4 pages, 3 figures, submitted to ICASSP 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collaborative framework for detecting the different sources in mixed\nsignals is presented in this paper. The approach is based on C-HiLasso, a\nconvex collaborative hierarchical sparse model, and proceeds as follows. First,\nwe build a structured dictionary for mixed signals by concatenating a set of\nsub-dictionaries, each one of them learned to sparsely model one of a set of\npossible classes. Then, the coding of the mixed signal is performed by\nefficiently solving a convex optimization problem that combines standard\nsparsity with group and collaborative sparsity. The present sources are\nidentified by looking at the sub-dictionaries automatically selected in the\ncoding. The collaborative filtering in C-HiLasso takes advantage of the\ntemporal/spatial redundancy in the mixed signals, letting collections of\nsamples collaborate in identifying the classes, while allowing individual\nsamples to have different internal sparse representations. This collaboration\nis critical to further stabilize the sparse representation of signals, in\nparticular the class/sub-dictionary selection. The internal sparsity inside the\nsub-dictionaries, as naturally incorporated by the hierarchical aspects of\nC-HiLasso, is critical to make the model consistent with the essence of the\nsub-dictionaries that have been trained for sparse representation of each\nindividual class. We present applications from speaker and instrument\nidentification and texture separation. In the case of audio signals, we use\nsparse modeling to describe the short-term power spectrum envelopes of harmonic\nsounds. The proposed pitch independent method automatically detects the number\nof sources on a recording.\n", "versions": [{"version": "v1", "created": "Sat, 23 Oct 2010 16:47:16 GMT"}], "update_date": "2010-10-26", "authors_parsed": [["Sprechmann", "Pablo", ""], ["Ramirez", "Ignacio", ""], ["Cancela", "Pablo", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1010.4951", "submitter": "Mahmoud Khademi", "authors": "Mahmoud Khademi, Mohammad T. Manzuri-Shalmani, and Meharn safayani", "title": "Local Component Analysis for Nonparametric Bayes Classifier", "comments": "This paper has been withdrawn by the author due to an error in\n  experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision boundaries of Bayes classifier are optimal because they lead to\nmaximum probability of correct decision. It means if we knew the prior\nprobabilities and the class-conditional densities, we could design a classifier\nwhich gives the lowest probability of error. However, in classification based\non nonparametric density estimation methods such as Parzen windows, the\ndecision regions depend on the choice of parameters such as window width.\nMoreover, these methods suffer from curse of dimensionality of the feature\nspace and small sample size problem which severely restricts their practical\napplications. In this paper, we address these problems by introducing a novel\ndimension reduction and classification method based on local component\nanalysis. In this method, by adopting an iterative cross-validation algorithm,\nwe simultaneously estimate the optimal transformation matrices (for dimension\nreduction) and classifier parameters based on local information. The proposed\nmethod can classify the data with complicated boundary and also alleviate the\ncourse of dimensionality dilemma. Experiments on real data show the superiority\nof the proposed algorithm in term of classification accuracies for pattern\nclassification applications like age, facial expression and character\nrecognition. Keywords: Bayes classifier, curse of dimensionality dilemma,\nParzen window, pattern classification, subspace learning.\n", "versions": [{"version": "v1", "created": "Sun, 24 Oct 2010 11:28:11 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2012 01:17:25 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Khademi", "Mahmoud", ""], ["Manzuri-Shalmani", "Mohammad T.", ""], ["safayani", "Meharn", ""]]}, {"id": "1010.5610", "submitter": "Ju Sun", "authors": "Ju Sun, Qiang Chen, Shuicheng Yan, Loong-Fah Cheong", "title": "Selective Image Super-Resolution", "comments": "20 pages, 5 figures. Submitted to Computer Vision and Image\n  Understanding in March 2010. Keywords: image super resolution, semantic image\n  segmentation, vision system, vision application", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a vision system that performs image Super Resolution\n(SR) with selectivity. Conventional SR techniques, either by multi-image fusion\nor example-based construction, have failed to capitalize on the intrinsic\nstructural and semantic context in the image, and performed \"blind\" resolution\nrecovery to the entire image area. By comparison, we advocate example-based\nselective SR whereby selectivity is exemplified in three aspects: region\nselectivity (SR only at object regions), source selectivity (object SR with\ntrained object dictionaries), and refinement selectivity (object boundaries\nrefinement using matting). The proposed system takes over-segmented\nlow-resolution images as inputs, assimilates recent learning techniques of\nsparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to\na framework for joint figure-ground separation and interest object SR. The\nefficiency of our framework is manifested in our experiments with subsets of\nthe VOC2009 and MSRC datasets. We also demonstrate several interesting vision\napplications that can build on our system.\n", "versions": [{"version": "v1", "created": "Wed, 27 Oct 2010 08:58:48 GMT"}], "update_date": "2010-10-28", "authors_parsed": [["Sun", "Ju", ""], ["Chen", "Qiang", ""], ["Yan", "Shuicheng", ""], ["Cheong", "Loong-Fah", ""]]}]