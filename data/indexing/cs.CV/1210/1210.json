[{"id": "1210.0026", "submitter": "Artiom Kovnatsky Artiom Kovnatsky", "authors": "A. Kovnatsky, M.M.Bronstein, A.M.Bronstein, K. Glashoff, R. Kimmel", "title": "Coupled quasi-harmonic bases", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Laplacian eigenbases has been shown to be fruitful in many\ncomputer graphics applications. Today, state-of-the-art approaches to shape\nanalysis, synthesis, and correspondence rely on these natural harmonic bases\nthat allow using classical tools from harmonic analysis on manifolds. However,\nmany applications involving multiple shapes are obstacled by the fact that\nLaplacian eigenbases computed independently on different shapes are often\nincompatible with each other. In this paper, we propose the construction of\ncommon approximate eigenbases for multiple shapes using approximate joint\ndiagonalization algorithms. We illustrate the benefits of the proposed approach\non tasks from shape editing, pose transfer, correspondence, and similarity.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 20:29:37 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Kovnatsky", "A.", ""], ["Bronstein", "M. M.", ""], ["Bronstein", "A. M.", ""], ["Glashoff", "K.", ""], ["Kimmel", "R.", ""]]}, {"id": "1210.0052", "submitter": "ELkebir Sarhrouni", "authors": "ELkebir Sarhrouni, Ahmed Hammouch and Driss Aboutajdine", "title": "Dimensionality Reduction and Classification feature using Mutual\n  Information applied to Hyperspectral Images : A Filter strategy based\n  algorithm", "comments": "11 pages, 5 figures, journal paper", "journal-ref": "Applied Mathematical Sciences, Vol. 6, 2012, no. 102, 5085 - 5095", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral images (HIS) classification is a high technical remote sensing\ntool. The goal is to reproduce a thematic map that will be compared with a\nreference ground truth map (GT), constructed by expecting the region. The HIS\ncontains more than a hundred bidirectional measures, called bands (or simply\nimages), of the same region. They are taken at juxtaposed frequencies.\nUnfortunately, some bands contain redundant information, others are affected by\nthe noise, and the high dimensionality of features made the accuracy of\nclassification lower. The problematic is how to find the good bands to classify\nthe pixels of regions. Some methods use Mutual Information (MI) and threshold,\nto select relevant bands, without treatment of redundancy. Others control and\neliminate redundancy by selecting the band top ranking the MI, and if its\nneighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll accept the useful redundancy.\nA band contains useful redundancy if it contributes to produce an estimated\nreference map that has higher MI with the GT.nTo control redundancy, we\nintroduce a complementary threshold added to last value of MI. This process is\na Filter strategy; it gets a better performance of classification accuracy and\nnot expensive, but less preferment than Wrapper strategy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 23:03:00 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Sarhrouni", "ELkebir", ""], ["Hammouch", "Ahmed", ""], ["Aboutajdine", "Driss", ""]]}, {"id": "1210.0115", "submitter": "Zhou Xiaofei", "authors": "Guangling Sun", "title": "Demosaicing and Superresolution for Color Filter Array via Residual\n  Image Reconstruction and Sparse Representation", "comments": "the paper has been accepted by a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A framework of demosaicing and superresolution for color filter array (CFA)\nvia residual image reconstruction and sparse representation is presented.Given\nthe intermediate image produced by certain demosaicing and interpolation\ntechnique, a residual image between the final reconstruction image and the\nintermediate image is reconstructed using sparse representation.The final\nreconstruction image has richer edges and details than that of the intermediate\nimage. Specifically, a generic dictionary is learned from a large set of\ncomposite training data composed of intermediate data and residual data. The\nlearned dictionary implies a mapping between the two data. A specific\ndictionary adaptive to the input CFA is learned thereafter. Using the adaptive\ndictionary, the sparse coefficients of intermediate data are computed and\ntransformed to predict residual image. The residual image is added back into\nthe intermediate image to obtain the final reconstruction image. Experimental\nresults demonstrate the state-of-the-art performance in terms of PSNR and\nsubjective visual perception.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2012 15:24:37 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2013 01:29:16 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Sun", "Guangling", ""]]}, {"id": "1210.0153", "submitter": "Wazir Zada Khan", "authors": "Mohammed Y Aalsalem, Wazir Zada Khan and Quratul Ain Arshad", "title": "A Low Cost Vision Based Hybrid Fiducial Mark Tracking Technique for\n  Mobile Industrial Robots", "comments": "6 pages, 7 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 4, No 2, July 2012 ISSN (Online): 1694-0814 www.IJCSI.org", "doi": null, "report-no": null, "categories": "cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of robotic vision is developing rapidly. Robots can react\nintelligently and provide assistance to user activities through sentient\ncomputing. Since industrial applications pose complex requirements that cannot\nbe handled by humans, an efficient low cost and robust technique is required\nfor the tracking of mobile industrial robots. The existing sensor based\ntechniques for mobile robot tracking are expensive and complex to deploy,\nconfigure and maintain. Also some of them demand dedicated and often expensive\nhardware. This paper presents a low cost vision based technique called Hybrid\nFiducial Mark Tracking (HFMT) technique for tracking mobile industrial robot.\nHFMT technique requires off-the-shelf hardware (CCD cameras) and printable 2-D\ncircular marks used as fiducials for tracking a mobile industrial robot on a\npre-defined path. This proposed technique allows the robot to track on a\npredefined path by using fiducials for the detection of Right and Left turns on\nthe path and White Strip for tracking the path. The HFMT technique is\nimplemented and tested on an indoor mobile robot at our laboratory.\nExperimental results from robot navigating in real environments have confirmed\nthat our approach is simple and robust and can be adopted in any hostile\nindustrial environment where humans are unable to work.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2012 22:00:19 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Aalsalem", "Mohammed Y", ""], ["Khan", "Wazir Zada", ""], ["Arshad", "Quratul Ain", ""]]}, {"id": "1210.0310", "submitter": "Rahele Kafieh", "authors": "Raheleh Kafieh, Hossein Rabbani, Michael D. Abramoff, Milan Sonka", "title": "Intra-Retinal Layer Segmentation of 3D Optical Coherence Tomography\n  Using Coarse Grained Diffusion Map", "comments": "30 pages,32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical coherence tomography (OCT) is a powerful and noninvasive method for\nretinal imaging. In this paper, we introduce a fast segmentation method based\non a new variant of spectral graph theory named diffusion maps. The research is\nperformed on spectral domain (SD) OCT images depicting macular and optic nerve\nhead appearance. The presented approach does not require edge-based image\ninformation and relies on regional image texture. Consequently, the proposed\nmethod demonstrates robustness in situations of low image contrast or poor\nlayer-to-layer image gradients. Diffusion mapping is applied to 2D and 3D OCT\ndatasets composed of two steps, one for partitioning the data into important\nand less important sections, and another one for localization of internal\nlayers.In the first step, the pixels/voxels are grouped in rectangular/cubic\nsets to form a graph node.The weights of a graph are calculated based on\ngeometric distances between pixels/voxels and differences of their mean\nintensity.The first diffusion map clusters the data into three parts, the\nsecond of which is the area of interest. The other two sections are eliminated\nfrom the remaining calculations. In the second step, the remaining area is\nsubjected to another diffusion map assessment and the internal layers are\nlocalized based on their textural similarities.The proposed method was tested\non 23 datasets from two patient groups (glaucoma and normals). The mean\nunsigned border positioning errors(mean - SD) was 8.52 - 3.13 and 7.56 - 2.95\nmicrometer for the 2D and 3D methods, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 08:52:29 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2012 11:05:28 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Kafieh", "Raheleh", ""], ["Rabbani", "Hossein", ""], ["Abramoff", "Michael D.", ""], ["Sonka", "Milan", ""]]}, {"id": "1210.0347", "submitter": "Sasirekha D Mrs", "authors": "D. Sasirekha, E. Chandra", "title": "Enhanced Techniques for PDF Image Segmentation and Text Extraction", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Extracting text objects from the PDF images is a challenging problem. The\ntext data present in the PDF images contain certain useful information for\nautomatic annotation, indexing etc. However variations of the text due to\ndifferences in text style, font, size, orientation, alignment as well as\ncomplex structure make the problem of automatic text extraction extremely\ndifficult and challenging job. This paper presents two techniques under\nblock-based classification. After a brief introduction of the classification\nmethods, two methods were enhanced and results were evaluated. The performance\nmetrics for segmentation and time consumption are tested for both the models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 10:38:08 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Sasirekha", "D.", ""], ["Chandra", "E.", ""]]}, {"id": "1210.0386", "submitter": "Junlin Hu", "authors": "Junlin Hu and Ping Guo", "title": "Combined Descriptors in Spatial Pyramid Domain for Image Classification", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently spatial pyramid matching (SPM) with scale invariant feature\ntransform (SIFT) descriptor has been successfully used in image classification.\nUnfortunately, the codebook generation and feature quantization procedures\nusing SIFT feature have the high complexity both in time and space. To address\nthis problem, in this paper, we propose an approach which combines local binary\npatterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid\ndomain. The proposed method does not need to learn the codebook and feature\nquantization processing, hence it becomes very efficient. Experiments on two\npopular benchmark datasets demonstrate that the proposed method always\nsignificantly outperforms the very popular SPM based SIFT descriptor method\nboth in time and classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 13:05:20 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2012 06:03:23 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2012 02:48:47 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Hu", "Junlin", ""], ["Guo", "Ping", ""]]}, {"id": "1210.0528", "submitter": "ELkebir Sarhrouni", "authors": "Elkebir Sarhrouni, Ahmed Hammouch and Driss Aboutajdine", "title": "Band Selection and Classification of Hyperspectral Images using Mutual\n  Information: An algorithm based on minimizing the error probability using the\n  inequality of Fano", "comments": "5 pages, 5 figures, ieee conference ICMCS'12 Tanger, Morocco. arXiv\n  admin note: text overlap with arXiv:1210.0052", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral image is a substitution of more than a hundred images, called\nbands, of the same region. They are taken at juxtaposed frequencies. The\nreference image of the region is called Ground Truth map (GT). the problematic\nis how to find the good bands to classify the pixels of regions; because the\nbands can be not only redundant, but a source of confusion, and decreasing so\nthe accuracy of classification. Some methods use Mutual Information (MI) and\nthreshold, to select relevant bands. Recently there's an algorithm selection\nbased on mutual information, using bandwidth rejection and a threshold to\ncontrol and eliminate redundancy. The band top ranking the MI is selected, and\nif its neighbors have sensibly the same MI with the GT, they will be considered\nredundant and so discarded. This is the most inconvenient of this method,\nbecause this avoids the advantage of hyperspectral images: some precious\ninformation can be discarded. In this paper we'll make difference between\nuseful and useless redundancy. A band contains useful redundancy if it\ncontributes to decreasing error probability. According to this scheme, we\nintroduce new algorithm using also mutual information, but it retains only the\nbands minimizing the error probability of classification. To control\nredundancy, we introduce a complementary threshold. So the good band candidate\nmust contribute to decrease the last error probability augmented by the\nthreshold. This process is a wrapper strategy; it gets high performance of\nclassification accuracy but it is expensive than filter strategy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 23:36:26 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Sarhrouni", "Elkebir", ""], ["Hammouch", "Ahmed", ""], ["Aboutajdine", "Driss", ""]]}, {"id": "1210.0564", "submitter": "Tao Hu", "authors": "Tao Hu, Juan Nunez-Iglesias, Shiv Vitaladevuni, Lou Scheffer, Shan Xu,\n  Mehdi Bolorizadeh, Harald Hess, Richard Fetter and Dmitri Chklovskii", "title": "Super-resolution using Sparse Representations over Learned Dictionaries:\n  Reconstruction of Brain Structure using Electron Microscopy", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in neuroscience is reconstructing neuronal circuits on the\nsynapse level. Due to a wide range of scales in brain architecture such\nreconstruction requires imaging that is both high-resolution and\nhigh-throughput. Existing electron microscopy (EM) techniques possess required\nresolution in the lateral plane and either high-throughput or high depth\nresolution but not both. Here, we exploit recent advances in unsupervised\nlearning and signal processing to obtain high depth-resolution EM images\ncomputationally without sacrificing throughput. First, we show that the brain\ntissue can be represented as a sparse linear combination of localized basis\nfunctions that are learned using high-resolution datasets. We then develop\ncompressive sensing-inspired techniques that can reconstruct the brain tissue\nfrom very few (typically 5) tomographic views of each section. This enables\ntracing of neuronal processes and, hence, high throughput reconstruction of\nneural circuits on the level of individual synapses.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 20:30:36 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Hu", "Tao", ""], ["Nunez-Iglesias", "Juan", ""], ["Vitaladevuni", "Shiv", ""], ["Scheffer", "Lou", ""], ["Xu", "Shan", ""], ["Bolorizadeh", "Mehdi", ""], ["Hess", "Harald", ""], ["Fetter", "Richard", ""], ["Chklovskii", "Dmitri", ""]]}, {"id": "1210.0754", "submitter": "Tony Lindeberg", "authors": "Tony Lindeberg", "title": "Invariance of visual operations at the level of receptive fields", "comments": "40 pages, 17 figures", "journal-ref": "PLoS ONE 8(7):e66990, 2013", "doi": "10.1371/journal.pone.0066990", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Receptive field profiles registered by cell recordings have shown that\nmammalian vision has developed receptive fields tuned to different sizes and\norientations in the image domain as well as to different image velocities in\nspace-time. This article presents a theoretical model by which families of\nidealized receptive field profiles can be derived mathematically from a small\nset of basic assumptions that correspond to structural properties of the\nenvironment. The article also presents a theory for how basic invariance\nproperties to variations in scale, viewing direction and relative motion can be\nobtained from the output of such receptive fields, using complementary\nselection mechanisms that operate over the output of families of receptive\nfields tuned to different parameters. Thereby, the theory shows how basic\ninvariance properties of a visual system can be obtained already at the level\nof receptive fields, and we can explain the different shapes of receptive field\nprofiles found in biological vision from a requirement that the visual system\nshould be invariant to the natural types of image transformations that occur in\nits environment.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 12:43:18 GMT"}], "update_date": "2014-04-09", "authors_parsed": [["Lindeberg", "Tony", ""]]}, {"id": "1210.0818", "submitter": "Harbi AlMahafzah", "authors": "Harbi AlMahafzah, Mohammad Imran, and H.S. Sheshadri", "title": "Multibiometric: Feature Level Fusion Using FKP Multi-Instance biometric", "comments": "8 pages paper", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 4, No 3, July 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed the use of multi-instance feature level fusion as a means\nto improve the performance of Finger Knuckle Print (FKP) verification. A\nlog-Gabor filter has been used to extract the image local orientation\ninformation, and represent the FKP features. Experiments are performed using\nthe FKP database, which consists of 7,920 images. Results indicate that the\nmulti-instance verification approach outperforms higher performance than using\nany single instance. The influence on biometric performance using feature level\nfusion under different fusion rules have been demonstrated in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 16:03:58 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["AlMahafzah", "Harbi", ""], ["Imran", "Mohammad", ""], ["Sheshadri", "H. S.", ""]]}, {"id": "1210.0822", "submitter": "Martin Rumpf", "authors": "Martin Rumpf and Benedikt Wirth", "title": "Discrete geodesic calculus in the space of viscous fluidic objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a local approximation of the Riemannian distance on a manifold by a\ncomputationally cheap dissimilarity measure, a time discrete geodesic calculus\nis developed, and applications to shape space are explored. The dissimilarity\nmeasure is derived from a deformation energy whose Hessian reproduces the\nunderlying Riemannian metric, and it is used to define length and energy of\ndiscrete paths in shape space. The notion of discrete geodesics defined as\nenergy minimizing paths gives rise to a discrete logarithmic map, a variational\ndefinition of a discrete exponential map, and a time discrete parallel\ntransport. This new concept is applied to a shape space in which shapes are\nconsidered as boundary contours of physical objects consisting of viscous\nmaterial. The flexibility and computational efficiency of the approach is\ndemonstrated for topology preserving shape morphing, the representation of\npaths in shape space via local shape variations as path generators, shape\nextrapolation via discrete geodesic flow, and the transfer of geometric\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 16:07:41 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Rumpf", "Martin", ""], ["Wirth", "Benedikt", ""]]}, {"id": "1210.0829", "submitter": "Harbi AlMahafzah", "authors": "Harbi AlMahafzah and Maen Zaid AlRwashdeh", "title": "A Survey of Multibiometric Systems", "comments": null, "journal-ref": "International Journal of Computer Application volume 43 No 15\n  April 2012", "doi": "10.5120/6182-8612", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most biometric systems deployed in real-world applications are unimodal.\nUsing unimodal biometric systems have to contend with a variety of problems\nsuch as: Noise in sensed data; Intra-class variations; Inter-class\nsimilarities; Non-universality; Spoof attacks. These problems have addressed by\nusing multibiometric systems, which expected to be more reliable due to the\npresence of multiple, independent pieces of evidence.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 16:26:39 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["AlMahafzah", "Harbi", ""], ["AlRwashdeh", "Maen Zaid", ""]]}, {"id": "1210.0866", "submitter": "Aaron Adcock", "authors": "Aaron Adcock and Daniel Rubin and Gunnar Carlsson", "title": "Classification of Hepatic Lesions using the Matching Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a methodology of classifying hepatic (liver) lesions\nusing multidimensional persistent homology, the matching metric (also called\nthe bottleneck distance), and a support vector machine. We present our\nclassification results on a dataset of 132 lesions that have been outlined and\nannotated by radiologists. We find that topological features are useful in the\nclassification of hepatic lesions. We also find that two-dimensional persistent\nhomology outperforms one-dimensional persistent homology in this application.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 18:08:54 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Adcock", "Aaron", ""], ["Rubin", "Daniel", ""], ["Carlsson", "Gunnar", ""]]}, {"id": "1210.0880", "submitter": "Jose A. Iglesias", "authors": "Jose A. Iglesias, Ron Kimmel", "title": "Schr\\\"{o}dinger Diffusion for Shape Analysis with Texture", "comments": "Extended version of NORDIA'12 paper. Includes one more figure and\n  appendix with proof", "journal-ref": "ECCV 2012. Workshops and Demonstrations, Lecture Notes in Computer\n  Science 7583, pp. 123-132, Springer, 2012", "doi": "10.1007/978-3-642-33863-2_13", "report-no": null, "categories": "cs.CV cs.CG cs.GR math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, quantities derived from the heat equation have become\npopular in shape processing and analysis of triangulated surfaces. Such\nmeasures are often robust with respect to different kinds of perturbations,\nincluding near-isometries, topological noise and partialities. Here, we propose\nto exploit the semigroup of a Schr\\\"{o}dinger operator in order to deal with\ntexture data, while maintaining the desirable properties of the heat kernel. We\ndefine a family of Schr\\\"{o}dinger diffusion distances analogous to the ones\nassociated to the heat kernels, and show that they are continuous under\nperturbations of the data. As an application, we introduce a method for\nretrieval of textured shapes through comparison of Schr\\\"{o}dinger diffusion\ndistance histograms with the earth's mover distance, and present some numerical\nexperiments showing superior performance compared to an analogous method that\nignores the texture.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 19:03:04 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Iglesias", "Jose A.", ""], ["Kimmel", "Ron", ""]]}, {"id": "1210.0999", "submitter": "Pierrick Tranouez", "authors": "Thomas Palfray (LITIS), David H\\'ebert (LITIS), St\\'ephane Nicolas\n  (LITIS), Pierrick Tranouez (LITIS), Thierry Paquet (LITIS)", "title": "Logical segmentation for article extraction in digitized old newspapers", "comments": "ACM Document Engineering, France (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newspapers are documents made of news item and informative articles. They are\nnot meant to be red iteratively: the reader can pick his items in any order he\nfancies. Ignoring this structural property, most digitized newspaper archives\nonly offer access by issue or at best by page to their content. We have built a\ndigitization workflow that automatically extracts newspaper articles from\nimages, which allows indexing and retrieval of information at the article\nlevel. Our back-end system extracts the logical structure of the page to\nproduce the informative units: the articles. Each image is labelled at the\npixel level, through a machine learning based method, then the page logical\nstructure is constructed up from there by the detection of structuring entities\nsuch as horizontal and vertical separators, titles and text lines. This logical\nstructure is stored in a METS wrapper associated to the ALTO file produced by\nthe system including the OCRed text. Our front-end system provides a web high\ndefinition visualisation of images, textual indexing and retrieval facilities,\nsearching and reading at the article level. Articles transcriptions can be\ncollaboratively corrected, which as a consequence allows for better indexing.\nWe are currently testing our system on the archives of the Journal de Rouen,\none of France eldest local newspaper. These 250 years of publication amount to\n300 000 pages of very variable image quality and layout complexity. Test year\n1808 can be consulted at plair.univ-rouen.fr.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 06:24:25 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Palfray", "Thomas", "", "LITIS"], ["H\u00e9bert", "David", "", "LITIS"], ["Nicolas", "St\u00e9phane", "", "LITIS"], ["Tranouez", "Pierrick", "", "LITIS"], ["Paquet", "Thierry", "", "LITIS"]]}, {"id": "1210.1029", "submitter": "Zhou Xiaofei", "authors": "Guangling Sun, Guoqing Li, Jie Yin", "title": "Blurred Image Classification based on Adaptive Dictionary", "comments": "10 pages,2 figures", "journal-ref": "The International Journal of Multimedia & Its Applications.\n  5(1):1-9, 2013", "doi": "10.5121/ijma.2013.5101", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Two types of framework for blurred image classification based on adaptive\ndictionary are proposed. Given a blurred image, instead of image deblurring,\nthe semantic category of the image is determined by blur insensitive sparse\ncoefficients calculated depending on an adaptive dictionary. The dictionary is\nadaptive to the Point Spread Function (PSF) estimated from input blurred image.\nThe PSF is assumed to be space invariant and inferred separately in one\nframework or updated combining with sparse coefficients calculation in an\nalternative and iterative algorithm in the other framework. The experiment has\nevaluated three types of blur, naming defocus blur, simple motion blur and\ncamera shake blur. The experiment results confirm the effectiveness of the\nproposed frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 08:54:01 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Sun", "Guangling", ""], ["Li", "Guoqing", ""], ["Yin", "Jie", ""]]}, {"id": "1210.1033", "submitter": "Zhou Xiaofei", "authors": "Guangling Sun, Guoqing Li, Xinpeng Zhang", "title": "Robust Degraded Face Recognition Using Enhanced Local Frequency\n  Descriptor and Multi-scale Competition", "comments": "7 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recognizing degraded faces from low resolution and blurred images are common\nyet challenging task. Local Frequency Descriptor (LFD) has been proved to be\neffective for this task yet it is extracted from a spatial neighborhood of a\npixel of a frequency plane independently regardless of correlations between\nfrequencies. In addition, it uses a fixed window size named single scale of\nshort-term Frequency transform (STFT). To explore the frequency correlations\nand preserve low resolution and blur insensitive simultaneously, we propose\nEnhanced LFD in which information in space and frequency is jointly utilized so\nas to be more descriptive and discriminative than LFD. The multi-scale\ncompetition strategy that extracts multiple descriptors corresponding to\nmultiple window sizes of STFT and take one corresponding to maximum confidence\nas the final recognition result. The experiments conducted on Yale and FERET\ndatabases demonstrate that promising results have been achieved by the proposed\nEnhanced LFD and multi-scale competition strategy.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 09:02:51 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Sun", "Guangling", ""], ["Li", "Guoqing", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "1210.1207", "submitter": "Hema Swetha Koppula", "authors": "Hema Swetha Koppula, Rudhir Gupta, Ashutosh Saxena", "title": "Learning Human Activities and Object Affordances from RGB-D Videos", "comments": "arXiv admin note: substantial text overlap with arXiv:1208.0967", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human activities and object affordances are two very important\nskills, especially for personal robots which operate in human environments. In\nthis work, we consider the problem of extracting a descriptive labeling of the\nsequence of sub-activities being performed by a human, and more importantly, of\ntheir interactions with the objects in the form of associated affordances.\nGiven a RGB-D video, we jointly model the human activities and object\naffordances as a Markov random field where the nodes represent objects and\nsub-activities, and the edges represent the relationships between object\naffordances, their relations with sub-activities, and their evolution over\ntime. We formulate the learning problem using a structural support vector\nmachine (SSVM) approach, where labelings over various alternate temporal\nsegmentations are considered as latent variables. We tested our method on a\nchallenging dataset comprising 120 activity videos collected from 4 subjects,\nand obtained an accuracy of 79.4% for affordance, 63.4% for sub-activity and\n75.0% for high-level activity labeling. We then demonstrate the use of such\ndescriptive labeling in performing assistive tasks by a PR2 robot.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 04:53:42 GMT"}, {"version": "v2", "created": "Mon, 6 May 2013 01:13:39 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Koppula", "Hema Swetha", ""], ["Gupta", "Rudhir", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1210.1230", "submitter": "AbdelHameed Badawy", "authors": "AbdelHameed A. Badawy and Michelle M. Hugue", "title": "Evaluating Discussion Boards on BlackBoard as a Collaborative Learning\n  Tool A Students Survey and Reflections", "comments": "5 pages, 12 tables, appears in proceedings of the IEEE International\n  Conference on Education and Management Technology (ICEMT 2010), Cairo, Egypt\n  November 2010. arXiv admin note: substantial text overlap with\n  arXiv:1210.1178", "journal-ref": "In proceedings of the IEEE International Conference on Education\n  and Management Technology (ICEMT 2010), pages 79 - 82, Cairo, Egypt November\n  2010", "doi": "10.1109/ICEMT.2010.5657540", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate how the students think of their experience in a\njunior level course that has a blackboard course presence where the students\nuse the discussion boards extensively. A survey is set up through blackboard as\na voluntary quiz and the student who participated were given a freebie point.\nThe results and the participation were very interesting in terms of the\nfeedback we got via open comments from the students as well as the statistics\nwe gathered from the answers to the questions. The students have shown\nunderstanding and willingness to participate in pedagogy-enhancing endeavors.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 20:31:39 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Badawy", "AbdelHameed A.", ""], ["Hugue", "Michelle M.", ""]]}, {"id": "1210.1316", "submitter": "Xi Peng", "authors": "Xi Peng, Lei Zhang, Zhang Yi, Kok Kiong Tan", "title": "Learning Locality-Constrained Collaborative Representation for Face\n  Recognition", "comments": "16 pages, v2", "journal-ref": "Pattern Recognition, 47 (9), 2794-2806, 2014", "doi": "10.1016/j.patcog.2014.03.013", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model of low-dimensional manifold and sparse representation are two\nwell-known concise models that suggest each data can be described by a few\ncharacteristics. Manifold learning is usually investigated for dimension\nreduction by preserving some expected local geometric structures from the\noriginal space to a low-dimensional one. The structures are generally\ndetermined by using pairwise distance, e.g., Euclidean distance. Alternatively,\nsparse representation denotes a data point as a linear combination of the\npoints from the same subspace. In practical applications, however, the nearby\npoints in terms of pairwise distance may not belong to the same subspace, and\nvice versa. Consequently, it is interesting and important to explore how to get\na better representation by integrating these two models together. To this end,\nthis paper proposes a novel coding algorithm, called Locality-Constrained\nCollaborative Representation (LCCR), which improves the robustness and\ndiscrimination of data representation by introducing a kind of local\nconsistency. The locality term derives from a biologic observation that the\nsimilar inputs have similar code. The objective function of LCCR has an\nanalytical solution, and it does not involve local minima. The empirical\nstudies based on four public facial databases, ORL, AR, Extended Yale B, and\nMultiple PIE, show that LCCR is promising in recognizing human faces from\nfrontal views with varying expression and illumination, as well as various\ncorruptions and occlusions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 07:12:49 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2013 07:12:30 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Peng", "Xi", ""], ["Zhang", "Lei", ""], ["Yi", "Zhang", ""], ["Tan", "Kok Kiong", ""]]}, {"id": "1210.1916", "submitter": "Meftah Ur Rahman", "authors": "Meftah Ur Rahman", "title": "A comparative study on face recognition techniques and neural network", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern times, face recognition has become one of the key aspects of\ncomputer vision. There are at least two reasons for this trend; the first is\nthe commercial and law enforcement applications, and the second is the\navailability of feasible technologies after years of research. Due to the very\nnature of the problem, computer scientists, neuro-scientists and psychologists\nall share a keen interest in this field. In plain words, it is a computer\napplication for automatically identifying a person from a still image or video\nframe. One of the ways to accomplish this is by comparing selected features\nfrom the image and a facial database. There are hundreds if not thousand\nfactors associated with this. In this paper some of the most common techniques\navailable including applications of neural network in facial recognition are\nstudied and compared with respect to their performance.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2012 06:37:51 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Rahman", "Meftah Ur", ""]]}, {"id": "1210.2162", "submitter": "Peter Welinder", "authors": "Peter Welinder and Max Welling and Pietro Perona", "title": "Semisupervised Classifier Evaluation and Recalibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many labeled examples are needed to estimate a classifier's performance\non a new dataset? We study the case where data is plentiful, but labels are\nexpensive. We show that by making a few reasonable assumptions on the structure\nof the data, it is possible to estimate performance curves, with confidence\nbounds, using a small number of ground truth labels. Our approach, which we\ncall Semisupervised Performance Evaluation (SPE), is based on a generative\nmodel for the classifier's confidence scores. In addition to estimating the\nperformance of classifiers on new datasets, SPE can be used to recalibrate a\nclassifier by re-estimating the class-conditional confidence distributions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 07:15:57 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Welinder", "Peter", ""], ["Welling", "Max", ""], ["Perona", "Pietro", ""]]}, {"id": "1210.2352", "submitter": "Valerio Capraro", "authors": "Valerio Capraro", "title": "A notion of continuity in discrete spaces and applications", "comments": "arXiv admin note: text overlap with arXiv:1111.0268", "journal-ref": "Applied General Topology 14 (1) (2013) 61-72", "doi": null, "report-no": null, "categories": "math.MG cs.CV math.CO math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a notion of continuous path for locally finite metric spaces,\ntaking inspiration from the recent development of A-theory for locally finite\nconnected graphs. We use this notion of continuity to derive an analogue in Z^2\nof the Jordan curve theorem and to extend to a quite large class of locally\nfinite metric spaces (containing all finite metric spaces) an inequality for\nthe \\ell^p-distortion of a metric space that has been recently proved by\nPierre-Nicolas Jolissaint and Alain Valette for finite connected graphs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 17:33:46 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2013 05:39:19 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Capraro", "Valerio", ""]]}, {"id": "1210.2380", "submitter": "Felix Krahmer", "authors": "Felix Krahmer and Rachel Ward", "title": "Stable and robust sampling strategies for compressive imaging", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many signal processing applications, one wishes to acquire images that are\nsparse in transform domains such as spatial finite differences or wavelets\nusing frequency domain samples. For such applications, overwhelming empirical\nevidence suggests that superior image reconstruction can be obtained through\nvariable density sampling strategies that concentrate on lower frequencies. The\nwavelet and Fourier transform domains are not incoherent because low-order\nwavelets and low-order frequencies are correlated, so compressive sensing\ntheory does not immediately imply sampling strategies and reconstruction\nguarantees. In this paper we turn to a more refined notion of coherence -- the\nso-called local coherence -- measuring for each sensing vector separately how\ncorrelated it is to the sparsity basis. For Fourier measurements and Haar\nwavelet sparsity, the local coherence can be controlled and bounded explicitly,\nso for matrices comprised of frequencies sampled from a suitable inverse square\npower-law density, we can prove the restricted isometry property with\nnear-optimal embedding dimensions. Consequently, the variable-density sampling\nstrategy we provide allows for image reconstructions that are stable to\nsparsity defects and robust to measurement noise. Our results cover both\nreconstruction by $\\ell_1$-minimization and by total variation minimization.\nThe local coherence framework developed in this paper should be of independent\ninterest in sparse recovery problems more generally, as it implies that for\noptimal sparse recovery results, it suffices to have bounded \\emph{average}\ncoherence from sensing basis to sparsity basis -- as opposed to bounded maximal\ncoherence -- as long as the sampling strategy is adapted accordingly.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 19:00:39 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 18:53:47 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2013 13:30:40 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Krahmer", "Felix", ""], ["Ward", "Rachel", ""]]}, {"id": "1210.2388", "submitter": "Yadong Mu", "authors": "Yadong Mu and Wei Liu and Shuicheng Yan", "title": "Video De-fencing", "comments": "To appear in IEEE transactions on Circuits and Systems for Video\n  Technology (T-CSVT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes and provides an initial solution to a novel video\nediting task, i.e., video de-fencing. It targets automatic restoration of the\nvideo clips that are corrupted by fence-like occlusions during capture. Our key\nobservation lies in the visual parallax between fences and background scenes,\nwhich is caused by the fact that the former are typically closer to the camera.\nUnlike in traditional image inpainting, fence-occluded pixels in the videos\ntend to appear later in the temporal dimension and are therefore recoverable\nvia optimized pixel selection from relevant frames. To eventually produce\nfence-free videos, major challenges include cross-frame sub-pixel image\nalignment under diverse scene depth, and \"correct\" pixel selection that is\nrobust to dominating fence pixels. Several novel tools are developed in this\npaper, including soft fence detection, weighted truncated optical flow method\nand robust temporal median filter. The proposed algorithm is validated on\nseveral real-world video clips with fences.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 19:58:59 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Mu", "Yadong", ""], ["Liu", "Wei", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1210.2474", "submitter": "Akshay Soni", "authors": "Akshay Soni and Jarvis Haupt", "title": "Level Set Estimation from Compressive Measurements using Box Constrained\n  Total Variation Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the level set of a signal from measurements is a task that arises\nin a variety of fields, including medical imaging, astronomy, and digital\nelevation mapping. Motivated by scenarios where accurate and complete\nmeasurements of the signal may not available, we examine here a simple\nprocedure for estimating the level set of a signal from highly incomplete\nmeasurements, which may additionally be corrupted by additive noise. The\nproposed procedure is based on box-constrained Total Variation (TV)\nregularization. We demonstrate the performance of our approach, relative to\nexisting state-of-the-art techniques for level set estimation from compressive\nmeasurements, via several simulation examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 02:57:12 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Soni", "Akshay", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1210.2629", "submitter": "Dimitris Arabadjis", "authors": "Dimitris Arabadjis, Panayiotis Rousopoulos, Constantin Papaodysseus,\n  Michalis Exarhos, Michalis Panagopoulos and Lena Papazoglou-Manioudaki", "title": "Optimization in Differentiable Manifolds in Order to Determine the\n  Method of Construction of Prehistoric Wall-Paintings", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 33, no. 11, pp. 2229-2244, November 2011", "doi": "10.1109/TPAMI.2011.65", "report-no": null, "categories": "cs.CV cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a general methodology is introduced for the determination of\npotential prototype curves used for the drawing of prehistoric wall-paintings.\nThe approach includes a) preprocessing of the wall-paintings contours to\nproperly partition them, according to their curvature, b) choice of prototype\ncurves families, c) analysis and optimization in 4-manifold for a first\nestimation of the form of these prototypes, d) clustering of the contour parts\nand the prototypes, to determine a minimal number of potential guides, e)\nfurther optimization in 4-manifold, applied to each cluster separately, in\norder to determine the exact functional form of the potential guides, together\nwith the corresponding drawn contour parts. The introduced methodology\nsimultaneously deals with two problems: a) the arbitrariness in data-points\norientation and b) the determination of one proper form for a prototype curve\nthat optimally fits the corresponding contour data. Arbitrariness in\norientation has been dealt with a novel curvature based error, while the proper\nforms of curve prototypes have been exhaustively determined by embedding\ncurvature deformations of the prototypes into 4-manifolds. Application of this\nmethodology to celebrated wall-paintings excavated at Tyrins, Greece and the\nGreek island of Thera, manifests it is highly probable that these\nwall-paintings had been drawn by means of geometric guides that correspond to\nlinear spirals and hyperbolae. These geometric forms fit the drawings' lines\nwith an exceptionally low average error, less than 0.39mm. Hence, the approach\nsuggests the existence of accurate realizations of complicated geometric\nentities, more than 1000 years before their axiomatic formulation in Classical\nAges.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 15:03:16 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Arabadjis", "Dimitris", ""], ["Rousopoulos", "Panayiotis", ""], ["Papaodysseus", "Constantin", ""], ["Exarhos", "Michalis", ""], ["Panagopoulos", "Michalis", ""], ["Papazoglou-Manioudaki", "Lena", ""]]}, {"id": "1210.2646", "submitter": "Dimitris Arabadjis", "authors": "Dimitris Arabadjis, Panayiotis Rousopoulos, Constantin Papaodysseus,\n  Michalis Panagopoulos, Panayiota Loumou and Georgios Theodoropoulos", "title": "A General Methodology for the Determination of 2D Bodies Elastic\n  Deformation Invariants. Application to the Automatic Identification of\n  Parasites", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 32, no. 5, pp. 799-814, 2010", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel methodology is introduced here that exploits 2D images of arbitrary\nelastic body deformation instances, so as to quantify mechano-elastic\ncharacteristics that are deformation invariant. Determination of such\ncharacteristics allows for developing methods offering an image of the\nundeformed body. General assumptions about the mechano-elastic properties of\nthe bodies are stated, which lead to two different approaches for obtaining\nbodies' deformation invariants. One was developed to spot deformed body's\nneutral line and its cross sections, while the other solves deformation PDEs by\nperforming a set of equivalent image operations on the deformed body images.\nBoth these processes may furnish a body undeformed version from its deformed\nimage. This was confirmed by obtaining the undeformed shape of deformed\nparasites, cells (protozoa), fibers and human lips. In addition, the method has\nbeen applied to the important problem of parasite automatic classification from\ntheir microscopic images. To achieve this, we first apply the previous method\nto straighten the highly deformed parasites and then we apply a dedicated curve\nclassification method to the straightened parasite contours. It is demonstrated\nthat essentially different deformations of the same parasite give rise to\npractically the same undeformed shape, thus confirming the consistency of the\nintroduced methodology. Finally, the developed pattern recognition method\nclassifies the unwrapped parasites into 6 families, with an accuracy rate of\n97.6 %.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 15:45:23 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Arabadjis", "Dimitris", ""], ["Rousopoulos", "Panayiotis", ""], ["Papaodysseus", "Constantin", ""], ["Panagopoulos", "Michalis", ""], ["Loumou", "Panayiota", ""], ["Theodoropoulos", "Georgios", ""]]}, {"id": "1210.2687", "submitter": "Mario Figueiredo", "authors": "Mariana S. C. Almeida and M\\'ario A. T. Figueiredo", "title": "Deconvolving Images with Unknown Boundaries Using the Alternating\n  Direction Method of Multipliers", "comments": "Submitted to the IEEE Transactions on Image Processing in August 2012", "journal-ref": null, "doi": "10.1109/TIP.2013.2258354", "report-no": null, "categories": "math.OC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alternating direction method of multipliers (ADMM) has recently sparked\ninterest as a flexible and efficient optimization tool for imaging inverse\nproblems, namely deconvolution and reconstruction under non-smooth convex\nregularization. ADMM achieves state-of-the-art speed by adopting a divide and\nconquer strategy, wherein a hard problem is split into simpler, efficiently\nsolvable sub-problems (e.g., using fast Fourier or wavelet transforms, or\nsimple proximity operators). In deconvolution, one of these sub-problems\ninvolves a matrix inversion (i.e., solving a linear system), which can be done\nefficiently (in the discrete Fourier domain) if the observation operator is\ncirculant, i.e., under periodic boundary conditions. This paper extends\nADMM-based image deconvolution to the more realistic scenario of unknown\nboundary, where the observation operator is modeled as the composition of a\nconvolution (with arbitrary boundary conditions) with a spatial mask that keeps\nonly pixels that do not depend on the unknown boundary. The proposed approach\nalso handles, at no extra cost, problems that combine the recovery of missing\npixels (i.e., inpainting) with deconvolution. We show that the resulting\nalgorithms inherit the convergence guarantees of ADMM and illustrate its\nperformance on non-periodic deblurring (with and without inpainting of interior\npixels) under total-variation and frame-based regularization.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 18:42:10 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2013 19:33:02 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Almeida", "Mariana S. C.", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "1210.2826", "submitter": "Anne Collard", "authors": "Anne Collard, Silv\\`ere Bonnabel, Christophe Phillips and Rodolphe\n  Sepulchre", "title": "An anisotropy preserving metric for DTI processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis of Diffusion Tensor Imaging (DTI) data requires a\ncomputational framework that is both numerically tractable (to account for the\nhigh dimensional nature of the data) and geometric (to account for the\nnonlinear nature of diffusion tensors). Building upon earlier studies that have\nshown that a Riemannian framework is appropriate to address these challenges,\nthe present paper proposes a novel metric and an accompanying computational\nframework for DTI data processing. The proposed metric retains the geometry and\nthe computational tractability of earlier methods grounded in the affine\ninvariant metric. In addition, and in contrast to earlier methods, it provides\nan interpolation method which preserves anisotropy, a central information\ncarried by diffusion tensor data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 08:25:32 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Collard", "Anne", ""], ["Bonnabel", "Silv\u00e8re", ""], ["Phillips", "Christophe", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1210.2838", "submitter": "Stefan Seer", "authors": "Stefan Seer, Norbert Br\\\"andle, Carlo Ratti", "title": "Kinects and Human Kinetics: A New Approach for Studying Crowd Behavior", "comments": "Preprint submitted to Transportation Research Part C: Emerging\n  Technologies, September 11, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling crowd behavior relies on accurate data of pedestrian movements at a\nhigh level of detail. Imaging sensors such as cameras provide a good basis for\ncapturing such detailed pedestrian motion data. However, currently available\ncomputer vision technologies, when applied to conventional video footage, still\ncannot automatically unveil accurate motions of groups of people or crowds from\nthe image sequences. We present a novel data collection approach for studying\ncrowd behavior which uses the increasingly popular low-cost sensor Microsoft\nKinect. The Kinect captures both standard camera data and a three-dimensional\ndepth map. Our human detection and tracking algorithm is based on agglomerative\nclustering of depth data captured from an elevated view - in contrast to the\nlateral view used for gesture recognition in Kinect gaming applications. Our\napproach transforms local Kinect 3D data to a common world coordinate system in\norder to stitch together human trajectories from multiple Kinects, which allows\nfor a scalable and flexible capturing area. At a testbed with real-world\npedestrian traffic we demonstrate that our approach can provide accurate\ntrajectories from three Kinects with a Pedestrian Detection Rate of up to 94%\nand a Multiple Object Tracking Precision of 4 cm. Using a comprehensive dataset\nof 2240 captured human trajectories we calibrate three variations of the Social\nForce model. The results of our model validations indicate their particular\nability to reproduce the observed crowd behavior in microscopic simulations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 09:06:04 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Seer", "Stefan", ""], ["Br\u00e4ndle", "Norbert", ""], ["Ratti", "Carlo", ""]]}, {"id": "1210.2877", "submitter": "Dimitris Arabadjis", "authors": "Constantin Papaodysseus, Dimitris Arabadjis, Michalis Exarhos,\n  Panayiotis Rousopoulos, Solomon Zannos, Michail Panagopoulos and Lena\n  Papazoglou-Manioudaki", "title": "Efficient Solution to the 3D Problem of Automatic Wall Paintings\n  Reassembly", "comments": null, "journal-ref": "Mathematics & Computers with Applications, vol. 64, pp. 2712-2734,\n  2012", "doi": "10.1016/j.bbr.2011.03.031", "report-no": null, "categories": "cs.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach for the automated reconstruction -\nreassembly of fragmented objects having one surface near to plane, on the basis\nof the 3D representation of their constituent fragments. The whole process\nstarts by 3D scanning of the available fragments. The obtained representations\nare properly processed so that they can be tested for possible matches. Next,\nfour novel criteria are introduced, that lead to the determination of pairs of\nmatching fragments. These criteria have been chosen so as the whole process\nimitates the instinctive reassembling method dedicated scholars apply. The\nfirst criterion exploits the volume of the gap between two properly placed\nfragments. The second one considers the fragments' overlapping in each possible\nmatching position. Criteria 3,4 employ principles from calculus of variations\nto obtain bounds for the area and the mean curvature of the contact surfaces\nand the length of contact curves, which must hold if the two fragments match.\nThe method has been applied, with great success, both in the reconstruction of\nobjects artificially broken by the authors and, most importantly, in the\nvirtual reassembling of parts of wall paintings belonging to the Mycenaic\ncivilization (c. 1300 B.C.), excavated in a highly fragmented condition in\nTyrins, Greece.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 11:41:12 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Papaodysseus", "Constantin", ""], ["Arabadjis", "Dimitris", ""], ["Exarhos", "Michalis", ""], ["Rousopoulos", "Panayiotis", ""], ["Zannos", "Solomon", ""], ["Panagopoulos", "Michail", ""], ["Papazoglou-Manioudaki", "Lena", ""]]}, {"id": "1210.3098", "submitter": "Deanna Needell", "authors": "Deanna Needell and Rachel Ward", "title": "Near-optimal compressed sensing guarantees for total variation\n  minimization", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2013.2264681", "report-no": null, "categories": "math.NA cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of reconstructing a multidimensional signal from an\nunderdetermined set of measurements, as in the setting of compressed sensing.\nWithout any additional assumptions, this problem is ill-posed. However, for\nsignals such as natural images or movies, the minimal total variation estimate\nconsistent with the measurements often produces a good approximation to the\nunderlying signal, even if the number of measurements is far smaller than the\nambient dimensionality. This paper extends recent reconstruction guarantees for\ntwo-dimensional images to signals of arbitrary dimension d>1 and to isotropic\ntotal variation problems. To be precise, we show that a multidimensional signal\nx can be reconstructed from O(sd*log(N^d)) linear measurements using total\nvariation minimization to within a factor of the best s-term approximation of\nits gradient. The reconstruction guarantees we provide are necessarily optimal\nup to polynomial factors in the spatial dimension d.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 00:44:03 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2013 20:35:28 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Needell", "Deanna", ""], ["Ward", "Rachel", ""]]}, {"id": "1210.3165", "submitter": "Ayatullah Faruk Mollah", "authors": "Ayatullah Faruk Mollah, Subhadip Basu, Mita Nasipuri", "title": "Computationally Efficient Implementation of Convolution-based Locally\n  Adaptive Binarization Techniques", "comments": null, "journal-ref": "Proc. of Int'l Conf. on Information Processing, Springer, CCIS\n  292, pp. 159-168, 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important steps of document image processing is binarization.\nThe computational requirements of locally adaptive binarization techniques make\nthem unsuitable for devices with limited computing facilities. In this paper,\nwe have presented a computationally efficient implementation of convolution\nbased locally adaptive binarization techniques keeping the performance\ncomparable to the original implementation. The computational complexity has\nbeen reduced from O(W2N2) to O(WN2) where WxW is the window size and NxN is the\nimage size. Experiments over benchmark datasets show that the computation time\nhas been reduced by 5 to 15 times depending on the window size while memory\nconsumption remains the same with respect to the state-of-the-art algorithmic\nimplementation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 10:04:44 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Mollah", "Ayatullah Faruk", ""], ["Basu", "Subhadip", ""], ["Nasipuri", "Mita", ""]]}, {"id": "1210.3288", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Frank Wood", "title": "Unsupervised Detection and Tracking of Arbitrary Objects with Dependent\n  Dirichlet Process Mixtures", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a technique for the unsupervised detection and tracking\nof arbitrary objects in videos. It is intended to reduce the need for detection\nand localization methods tailored to specific object types and serve as a\ngeneral framework applicable to videos with varied objects, backgrounds, and\nimage qualities. The technique uses a dependent Dirichlet process mixture\n(DDPM) known as the Generalized Polya Urn (GPUDDPM) to model image pixel data\nthat can be easily and efficiently extracted from the regions in a video that\nrepresent objects. This paper describes a specific implementation of the model\nusing spatial and color pixel data extracted via frame differencing and gives\ntwo algorithms for performing inference in the model to accomplish detection\nand tracking. This technique is demonstrated on multiple synthetic and\nbenchmark video datasets that illustrate its ability to, without modification,\ndetect and track objects with diverse physical characteristics moving over\nnon-uniform backgrounds and through occlusion.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 16:30:15 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Neiswanger", "Willie", ""], ["Wood", "Frank", ""]]}, {"id": "1210.3326", "submitter": "Michel Gross", "authors": "Fr\\'ed\\'eric Verpillat (LKB - Lhomond), Fadwa Joud (LKB - Lhomond),\n  Pierre Desbiolles (LKB - Lhomond), Michel Gross (L2C)", "title": "Three dimensional tracking of gold nanoparticles using digital\n  holographic microscopy", "comments": null, "journal-ref": "Novel Biophotonic Techniques and Applications, Munich : Germany\n  (2011)", "doi": "10.1117/12.896523", "report-no": null, "categories": "physics.optics cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a digital holographic microscope to track gold\ncolloids in three dimensions. We report observations of 100nm gold particles in\nmotion in water. The expected signal and the chosen method of reconstruction\nare described. We also discuss about how to implement the numerical calculation\nto reach real-time 3D tracking.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 19:14:58 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Verpillat", "Fr\u00e9d\u00e9ric", "", "LKB - Lhomond"], ["Joud", "Fadwa", "", "LKB - Lhomond"], ["Desbiolles", "Pierre", "", "LKB - Lhomond"], ["Gross", "Michel", "", "L2C"]]}, {"id": "1210.3350", "submitter": "Virginia Estellers", "authors": "Virginia Estellers and Jean-Philippe Thiran and Xavier Bresson", "title": "Enhanced Compressed Sensing Recovery with Level Set Normals", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2013.2253484", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a compressive sensing algorithm that exploits geometric properties\nof images to recover images of high quality from few measurements. The image\nreconstruction is done by iterating the two following steps: 1) estimation of\nnormal vectors of the image level curves and 2) reconstruction of an image\nfitting the normal vectors, the compressed sensing measurements and the\nsparsity constraint. The proposed technique can naturally extend to non local\noperators and graphs to exploit the repetitive nature of textured images in\norder to recover fine detail structures. In both cases, the problem is reduced\nto a series of convex minimization problems that can be efficiently solved with\na combination of variable splitting and augmented Lagrangian methods, leading\nto fast and easy-to-code algorithms. Extended experiments show a clear\nimprovement over related state-of-the-art algorithms in the quality of the\nreconstructed images and the robustness of the proposed method to noise,\ndifferent kind of images and reduced measurements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 19:53:44 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Estellers", "Virginia", ""], ["Thiran", "Jean-Philippe", ""], ["Bresson", "Xavier", ""]]}, {"id": "1210.3404", "submitter": "St\\'efan van der Walt", "authors": "St\\'efan J. van der Walt and B. M. Herbst", "title": "A polygon-based interpolation operator for super-resolution imaging", "comments": "10 pages; update typo in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline the super-resolution reconstruction problem posed as a\nmaximization of probability. We then introduce an interpolation method based on\npolygonal pixel overlap, express it as a linear operator, and use it to improve\nreconstruction. Polygon interpolation outperforms the simpler bilinear\ninterpolation operator and, unlike Gaussian modeling of pixels, requires no\nparameter estimation. A free software implementation that reproduces the\nresults shown is provided.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 00:31:46 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2012 20:47:33 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["van der Walt", "St\u00e9fan J.", ""], ["Herbst", "B. M.", ""]]}, {"id": "1210.3448", "submitter": "Antonio Torralba", "authors": "Adela Barriuso and Antonio Torralba", "title": "Notes on image annotation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are under the illusion that seeing is effortless, but frequently the\nvisual system is lazy and makes us believe that we understand something when in\nfact we don't. Labeling a picture forces us to become aware of the difficulties\nunderlying scene understanding. Suddenly, the act of seeing is not effortless\nanymore. We have to make an effort in order to understand parts of the picture\nthat we neglected at first glance.\n  In this report, an expert image annotator relates her experience on\nsegmenting and labeling tens of thousands of images. During this process, the\nnotes she took try to highlight the difficulties encountered, the solutions\nadopted, and the decisions made in order to get a consistent set of\nannotations. Those annotations constitute the SUN database.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 07:52:38 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Barriuso", "Adela", ""], ["Torralba", "Antonio", ""]]}, {"id": "1210.3718", "submitter": "Mariano Tepper", "authors": "Mariano Tepper, Pablo Mus\\'e, and Andr\\'es Almansa", "title": "On the Role of Contrast and Regularity in Perceptual Boundary Saliency", "comments": null, "journal-ref": null, "doi": "10.1007/s10851-012-0411-6", "report-no": null, "categories": "cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical Morphology proposes to extract shapes from images as connected\ncomponents of level sets. These methods prove very suitable for shape\nrecognition and analysis. We present a method to select the perceptually\nsignificant (i.e., contrasted) level lines (boundaries of level sets), using\nthe Helmholtz principle as first proposed by Desolneux et al. Contrarily to the\nclassical formulation by Desolneux et al. where level lines must be entirely\nsalient, the proposed method allows to detect partially salient level lines,\nthus resulting in more robust and more stable detections. We then tackle the\nproblem of combining two gestalts as a measure of saliency and propose a method\nthat reinforces detections. Results in natural images show the good performance\nof the proposed methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 16:27:52 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Tepper", "Mariano", ""], ["Mus\u00e9", "Pablo", ""], ["Almansa", "Andr\u00e9s", ""]]}, {"id": "1210.3729", "submitter": "Tanmoy Chakraborty", "authors": "Tanmoy Chakraborty and Sivaji Bandyopadhyay", "title": "Inference of Fine-grained Attributes of Bengali Corpus for Stylometry\n  Detection", "comments": "5 pages, 2 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1208.6268", "journal-ref": "Polibits (44) 2011, pp. 79-83", "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylometry, the science of inferring characteristics of the author from the\ncharacteristics of documents written by that author, is a problem with a long\nhistory and belongs to the core task of Text categorization that involves\nauthorship identification, plagiarism detection, forensic investigation,\ncomputer security, copyright and estate disputes etc. In this work, we present\na strategy for stylometry detection of documents written in Bengali. We adopt a\nset of fine-grained attribute features with a set of lexical markers for the\nanalysis of the text and use three semi-supervised measures for making\ndecisions. Finally, a majority voting approach has been taken for final\nclassification. The system is fully automatic and language-independent.\nEvaluation results of our attempt for Bengali author's stylometry detection\nshow reasonably promising accuracy in comparison to the baseline model.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 18:02:26 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Chakraborty", "Tanmoy", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "1210.3832", "submitter": "Idan Ram", "authors": "Idan Ram, Michael Elad, Israel Cohen", "title": "Image Processing using Smooth Ordering of its Patches", "comments": "8 pages, 7 figures, 4 tables, submitted to IEEE Transactions on Image\n  Processing", "journal-ref": null, "doi": "10.1109/TIP.2013.2257813", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an image processing scheme based on reordering of its patches. For\na given corrupted image, we extract all patches with overlaps, refer to these\nas coordinates in high-dimensional space, and order them such that they are\nchained in the \"shortest possible path\", essentially solving the traveling\nsalesman problem. The obtained ordering applied to the corrupted image, implies\na permutation of the image pixels to what should be a regular signal. This\nenables us to obtain good recovery of the clean image by applying relatively\nsimple 1D smoothing operations (such as filtering or interpolation) to the\nreordered set of pixels. We explore the use of the proposed approach to image\ndenoising and inpainting, and show promising results in both cases.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 20:17:33 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Ram", "Idan", ""], ["Elad", "Michael", ""], ["Cohen", "Israel", ""]]}, {"id": "1210.4081", "submitter": "Bogdan Savchynskyy", "authors": "Bogdan Savchynskyy and Stefan Schmidt", "title": "Getting Feasible Variable Estimates From Infeasible Ones: MRF Local\n  Polytope Study", "comments": "20 page, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for construction of approximate feasible primal\nsolutions from dual ones for large-scale optimization problems possessing\ncertain separability properties. Whereas infeasible primal estimates can\ntypically be produced from (sub-)gradients of the dual function, it is often\nnot easy to project them to the primal feasible set, since the projection\nitself has a complexity comparable to the complexity of the initial problem. We\npropose an alternative efficient method to obtain feasibility and show that its\nproperties influencing the convergence to the optimum are similar to the\nproperties of the Euclidean projection. We apply our method to the local\npolytope relaxation of inference problems for Markov Random Fields and\ndemonstrate its superiority over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 15:55:34 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Savchynskyy", "Bogdan", ""], ["Schmidt", "Stefan", ""]]}, {"id": "1210.4481", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Xinqi Chu, Tian-Tsong Ng, Alex Yong-Sang Chia,\n  Shuicheng Yan, Thomas S. Huang", "title": "Epitome for Automatic Image Colorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image colorization adds color to grayscale images. It not only increases the\nvisual appeal of grayscale images, but also enriches the information contained\nin scientific images that lack color information. Most existing methods of\ncolorization require laborious user interaction for scribbles or image\nsegmentation. To eliminate the need for human labor, we develop an automatic\nimage colorization method using epitome. Built upon a generative graphical\nmodel, epitome is a condensed image appearance and shape model which also\nproves to be an effective summary of color information for the colorization\ntask. We train the epitome from the reference images and perform inference in\nthe epitome to colorize grayscale images, rendering better colorization results\nthan previous method in our experiments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 06:35:04 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Yang", "Yingzhen", ""], ["Chu", "Xinqi", ""], ["Ng", "Tian-Tsong", ""], ["Chia", "Alex Yong-Sang", ""], ["Yan", "Shuicheng", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1210.4855", "submitter": "Sunil Kumar Gupta", "authors": "Sunil Kumar Gupta, Dinh Q. Phung, Svetha Venkatesh", "title": "A Slice Sampler for Restricted Hierarchical Beta Process with\n  Applications to Shared Subspace Learning", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-316-325", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical beta process has found interesting applications in recent years.\nIn this paper we present a modified hierarchical beta process prior with\napplications to hierarchical modeling of multiple data sources. The novel use\nof the prior over a hierarchical factor model allows factors to be shared\nacross different sources. We derive a slice sampler for this model, enabling\ntractable inference even when the likelihood and the prior over parameters are\nnon-conjugate. This allows the application of the model in much wider contexts\nwithout restrictions. We present two different data generative models a linear\nGaussianGaussian model for real valued data and a linear Poisson-gamma model\nfor count data. Encouraging transfer learning results are shown for two real\nworld applications text modeling and content based image retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:37:29 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Gupta", "Sunil Kumar", ""], ["Phung", "Dinh Q.", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1210.4863", "submitter": "Severine Dubuisson", "authors": "Severine Dubuisson, Christophe Gonzales, Xuan Son NGuyen", "title": "DBN-Based Combinatorial Resampling for Articulated Object Tracking", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-237-246", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Filter is an effective solution to track objects in video sequences\nin complex situations. Its key idea is to estimate the density over the\npossible states of the object using a weighted sample whose elements are called\nparticles. One of its crucial step is a resampling step in which particles are\nresampled to avoid some degeneracy problem. In this paper, we introduce a new\nresampling method called Combinatorial Resampling that exploits some features\nof articulated objects to resample over an implicitly created sample of an\nexponential size better representing the density to estimate. We prove that it\nis sound and, through experimentations both on challenging synthetic and real\nvideo sequences, we show that it outperforms all classical resampling methods\nboth in terms of the quality of its results and in terms of response times.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:38:55 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Dubuisson", "Severine", ""], ["Gonzales", "Christophe", ""], ["NGuyen", "Xuan Son", ""]]}, {"id": "1210.4872", "submitter": "Lingbo Li", "authors": "Lingbo Li, XianXing Zhang, Mingyuan Zhou, Lawrence Carin", "title": "Nested Dictionary Learning for Hierarchical Organization of Imagery and\n  Text", "comments": "Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty\n  in Artificial Intelligence (UAI2012)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2012-PG-469-478", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tree-based dictionary learning model is developed for joint analysis of\nimagery and associated text. The dictionary learning may be applied directly to\nthe imagery from patches, or to general feature vectors extracted from patches\nor superpixels (using any existing method for image feature extraction). Each\nimage is associated with a path through the tree (from root to a leaf), and\neach of the multiple patches in a given image is associated with one node in\nthat path. Nodes near the tree root are shared between multiple paths,\nrepresenting image characteristics that are common among different types of\nimages. Moving toward the leaves, nodes become specialized, representing\ndetails in image classes. If available, words (text) are also jointly modeled,\nwith a path-dependent probability over words. The tree structure is inferred\nvia a nested Dirichlet process, and a retrospective stick-breaking sampler is\nused to infer the tree depth and width.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 17:41:42 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Li", "Lingbo", ""], ["Zhang", "XianXing", ""], ["Zhou", "Mingyuan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1210.5034", "submitter": "Pierre Machart", "authors": "Pierre Machart (LIF, LSIS), Sandrine Anthoine (LATP), Luca Baldassarre\n  (EPFL)", "title": "Optimal Computational Trade-Off of Inexact Proximal Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the trade-off between convergence rate and\ncomputational cost when minimizing a composite functional with\nproximal-gradient methods, which are popular optimisation tools in machine\nlearning. We consider the case when the proximity operator is computed via an\niterative procedure, which provides an approximation of the exact proximity\noperator. In that case, we obtain algorithms with two nested loops. We show\nthat the strategy that minimizes the computational cost to reach a solution\nwith a desired accuracy in finite time is to set the number of inner iterations\nto a constant, which differs from the strategy indicated by a convergence rate\nanalysis. In the process, we also present a new procedure called SIP (that is\nSpeedy Inexact Proximal-gradient algorithm) that is both computationally\nefficient and easy to implement. Our numerical experiments confirm the\ntheoretical findings and suggest that SIP can be a very competitive alternative\nto the standard procedure.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 06:27:10 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2012 06:17:08 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Machart", "Pierre", "", "LIF, LSIS"], ["Anthoine", "Sandrine", "", "LATP"], ["Baldassarre", "Luca", "", "EPFL"]]}, {"id": "1210.5041", "submitter": "Thomas Maugey", "authors": "Thomas Maugey, Ismael Daribo, Gene Cheung, Pascal Frossard", "title": "Navigation domain representation for interactive multiview imaging", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2013.2270183", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling users to interactively navigate through different viewpoints of a\nstatic scene is a new interesting functionality in 3D streaming systems. While\nit opens exciting perspectives towards rich multimedia applications, it\nrequires the design of novel representations and coding techniques in order to\nsolve the new challenges imposed by interactive navigation. Interactivity\nclearly brings new design constraints: the encoder is unaware of the exact\ndecoding process, while the decoder has to reconstruct information from\nincomplete subsets of data since the server can generally not transmit images\nfor all possible viewpoints due to resource constrains. In this paper, we\npropose a novel multiview data representation that permits to satisfy bandwidth\nand storage constraints in an interactive multiview streaming system. In\nparticular, we partition the multiview navigation domain into segments, each of\nwhich is described by a reference image and some auxiliary information. The\nauxiliary information enables the client to recreate any viewpoint in the\nnavigation segment via view synthesis. The decoder is then able to navigate\nfreely in the segment without further data request to the server; it requests\nadditional data only when it moves to a different segment. We discuss the\nbenefits of this novel representation in interactive navigation systems and\nfurther propose a method to optimize the partitioning of the navigation domain\ninto independent segments, under bandwidth and storage constraints.\nExperimental results confirm the potential of the proposed representation;\nnamely, our system leads to similar compression performance as classical\ninter-view coding, while it provides the high level of flexibility that is\nrequired for interactive streaming. Hence, our new framework represents a\npromising solution for 3D data representation in novel interactive multimedia\nservices.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 07:41:17 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 09:32:50 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Maugey", "Thomas", ""], ["Daribo", "Ismael", ""], ["Cheung", "Gene", ""], ["Frossard", "Pascal", ""]]}, {"id": "1210.5502", "submitter": "Quentin Geissmann", "authors": "Quentin Geissmann", "title": "OpenCFU, a New Free and Open-Source Software to Count Cell Colonies and\n  Other Circular Objects", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0054072", "report-no": null, "categories": "q-bio.QM cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Counting circular objects such as cell colonies is an important source of\ninformation for biologists. Although this task is often time-consuming and\nsubjective, it is still predominantly performed manually. The aim of the\npresent work is to provide a new tool to enumerate circular objects from\ndigital pictures and video streams. Here, I demonstrate that the created\nprogram, OpenCFU, is very robust, accurate and fast. In addition, it provides\ncontrol over the processing parameters and is implemented in an in- tuitive and\nmodern interface. OpenCFU is a cross-platform and open-source software freely\navailable at http://opencfu.sourceforge.net.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 14:05:17 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2012 13:33:19 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2012 12:01:26 GMT"}], "update_date": "2012-12-14", "authors_parsed": [["Geissmann", "Quentin", ""]]}, {"id": "1210.5644", "submitter": "Philipp Kr\\\"ahenb\\\"uhl", "authors": "Philipp Kr\\\"ahenb\\\"uhl and Vladlen Koltun", "title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge\n  Potentials", "comments": "NIPS 2011", "journal-ref": "Advances in Neural Information Processing Systems 24 (2011)\n  109-117", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art techniques for multi-class image segmentation and\nlabeling use conditional random fields defined over pixels or image regions.\nWhile region-level models often feature dense pairwise connectivity,\npixel-level models are considerably larger and have only permitted sparse graph\nstructures. In this paper, we consider fully connected CRF models defined on\nthe complete set of pixels in an image. The resulting graphs have billions of\nedges, making traditional inference algorithms impractical. Our main\ncontribution is a highly efficient approximate inference algorithm for fully\nconnected CRF models in which the pairwise edge potentials are defined by a\nlinear combination of Gaussian kernels. Our experiments demonstrate that dense\nconnectivity at the pixel level substantially improves segmentation and\nlabeling accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2012 17:41:23 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1210.5653", "submitter": "Sudipta Roy", "authors": "Prof. Samir K. Bandyopadhyay, Biswajita Datta, Sudipta Roy", "title": "Identifications of concealed weapon in a Human Body", "comments": "6 pages, International Journal of Scientific & Engineering Research\n  (ISSN 2229-5518) 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The detection of weapons concealed underneath a person cloths is very much\nimportant to the improvement of the security of the public as well as the\nsafety of public assets like airports, buildings and railway stations etc.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2012 20:37:22 GMT"}], "update_date": "2012-10-23", "authors_parsed": [["Bandyopadhyay", "Prof. Samir K.", ""], ["Datta", "Biswajita", ""], ["Roy", "Sudipta", ""]]}, {"id": "1210.5732", "submitter": "Jaswinder  Dilawari Singh", "authors": "Jaswinder Singh Dilawari, Ravinder Khanna", "title": "Developing ICC Profile Using Gray Level Control In Offset Printing\n  Process", "comments": "4 Pages, 3 figures, 1 Tables, International Journal of Computer\n  Science and Network Security, Volume 12, No 10, October 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In prepress department RGB image has to be converted to CMYK image. To\ncontrol that amount of black, cyan, magenta and yellow has to be controlled by\nusing color separation method. Graycolor separation method is selected to\ncontrol the amounts of these colors because it increase the quality of printing\nalso. A single printer used for printing the same image on different paper also\nresults in different printed images. To remove this problem a different ICC\nprofile based on gray level control is developedand a sheet offset printer is\ncalibrated using that profile and a subjective evaluation shows satisfactory\nresults for different quality papers.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2012 14:49:30 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Dilawari", "Jaswinder Singh", ""], ["Khanna", "Ravinder", ""]]}, {"id": "1210.6157", "submitter": "Nishtha Kesswani", "authors": "Vibekananda Dutta, Dr Nishtha Kesswani, Deepti Gahalot", "title": "Novel Architecture for 3D model in virtual communities from detected\n  face", "comments": "7 pages", "journal-ref": "http://www.ijascse.in/publications-2012--2", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper we suggest how to extract a face from an image, modify\nit, characterize it in terms of high-level properties, and apply it to the\ncreation of a personalized avatar. In this research work we tested, we\nimplemented the algorithm on several hundred facial images, including many\ntaken under uncontrolled acquisition conditions, and found to exhibit\nsatisfactory performance for immediate practical use.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 07:57:24 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Dutta", "Vibekananda", ""], ["Kesswani", "Dr Nishtha", ""], ["Gahalot", "Deepti", ""]]}, {"id": "1210.6192", "submitter": "Kasturika B Ray", "authors": "Rachita Misra, Kasturika B ray", "title": "Textural Approach to Palmprint Identification", "comments": "9 pages", "journal-ref": "http://www.ijascse.in/publications-2012--2", "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biometrics which use of human physiological characteristics for identifying\nan individual is now a widespread method of identification and authentication.\nBiometric identification is a technology which uses several image processing\ntechniques and describes the general procedure for identification and\nverification using feature extraction, storage and matching from the digitized\nimage of biometric characters such as Finger Print, Face, Iris or Palm Print.\nThe current paper uses palm print biometrics. Here we have presented an\nidentification approach using textural properties of palm print images. The\nelegance of the method is that the conventional edge detection technique is\nextended to suitably describe the texture features. In this technique all the\ncharacteristics of the palm such as principal lines, edges and wrinkles are\nconsidered with equal importance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 10:52:31 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Misra", "Rachita", ""], ["ray", "Kasturika B", ""]]}, {"id": "1210.6293", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, James R. Cline, N.P. Slagle, William B. March,\n  Parikshit Ram, Nishant A. Mehta, Alexander G. Gray", "title": "MLPACK: A Scalable C++ Machine Learning Library", "comments": "Submitted to JMLR MLOSS (http://jmlr.csail.mit.edu/mloss/)", "journal-ref": "Journal of Machine Learning Research 14 (2013) 801-805", "doi": null, "report-no": null, "categories": "cs.MS cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning\nlibrary released in late 2011 offering both a simple, consistent API accessible\nto novice users and high performance and flexibility to expert users by\nleveraging modern features of C++. MLPACK provides cutting-edge algorithms\nwhose benchmarks exhibit far better performance than other leading machine\nlearning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available\nat http://www.mlpack.org.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 17:15:03 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Cline", "James R.", ""], ["Slagle", "N. P.", ""], ["March", "William B.", ""], ["Ram", "Parikshit", ""], ["Mehta", "Nishant A.", ""], ["Gray", "Alexander G.", ""]]}, {"id": "1210.6649", "submitter": "Roberto Baena", "authors": "Roberto Baena Gall\\'e, Jorge N\\'u\\~nez and Szymon Gladysz", "title": "Extended object reconstruction in adaptive-optics imaging: the\n  multiresolution approach", "comments": "In revision in Astronomy & Astrophysics. 19 pages, 13 figures", "journal-ref": null, "doi": "10.1051/0004-6361/201219489", "report-no": null, "categories": "astro-ph.IM cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the application of multiresolution transforms, such as wavelets\n(WT) and curvelets (CT), to the reconstruction of images of extended objects\nthat have been acquired with adaptive optics (AO) systems. Such multichannel\napproaches normally make use of probabilistic tools in order to distinguish\nsignificant structures from noise and reconstruction residuals. Furthermore, we\naim to check the historical assumption that image-reconstruction algorithms\nusing static PSFs are not suitable for AO imaging. We convolve an image of\nSaturn taken with the Hubble Space Telescope (HST) with AO PSFs from the 5-m\nHale telescope at the Palomar Observatory and add both shot and readout noise.\nSubsequently, we apply different approaches to the blurred and noisy data in\norder to recover the original object. The approaches include multi-frame blind\ndeconvolution (with the algorithm IDAC), myopic deconvolution with\nregularization (with MISTRAL) and wavelets- or curvelets-based static PSF\ndeconvolution (AWMLE and ACMLE algorithms). We used the mean squared error\n(MSE) and the structural similarity index (SSIM) to compare the results. We\ndiscuss the strengths and weaknesses of the two metrics. We found that CT\nproduces better results than WT, as measured in terms of MSE and SSIM.\nMultichannel deconvolution with a static PSF produces results which are\ngenerally better than the results obtained with the myopic/blind approaches\n(for the images we tested) thus showing that the ability of a method to\nsuppress the noise and to track the underlying iterative process is just as\ncritical as the capability of the myopic/blind approaches to update the PSF.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 10:08:00 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Gall\u00e9", "Roberto Baena", ""], ["N\u00fa\u00f1ez", "Jorge", ""], ["Gladysz", "Szymon", ""]]}, {"id": "1210.6707", "submitter": "Emanuele Coviello", "authors": "Emanuele Coviello and Antoni B. Chan and Gert R.G. Lanckriet", "title": "Clustering hidden Markov models with variational HEM", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hidden Markov model (HMM) is a widely-used generative model that copes\nwith sequential data, assuming that each observation is conditioned on the\nstate of a hidden Markov chain. In this paper, we derive a novel algorithm to\ncluster HMMs based on the hierarchical EM (HEM) algorithm. The proposed\nalgorithm i) clusters a given collection of HMMs into groups of HMMs that are\nsimilar, in terms of the distributions they represent, and ii) characterizes\neach group by a \"cluster center\", i.e., a novel HMM that is representative for\nthe group, in a manner that is consistent with the underlying generative model\nof the HMM. To cope with intractable inference in the E-step, the HEM algorithm\nis formulated as a variational optimization problem, and efficiently solved for\nthe HMM case by leveraging an appropriate variational approximation. The\nbenefits of the proposed algorithm, which we call variational HEM (VHEM), are\ndemonstrated on several tasks involving time-series data, such as hierarchical\nclustering of motion capture sequences, and automatic annotation and retrieval\nof music and of online hand-writing data, showing improvements over current\nmethods. In particular, our variational HEM algorithm effectively leverages\nlarge amounts of data when learning annotation models by using an efficient\nhierarchical estimation procedure, which reduces learning times and memory\nrequirements, while improving model robustness through better regularization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 23:57:35 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Coviello", "Emanuele", ""], ["Chan", "Antoni B.", ""], ["Lanckriet", "Gert R. G.", ""]]}, {"id": "1210.7014", "submitter": "Mariano Tepper", "authors": "Jordan Hashemi, Thiago Vallin Spina, Mariano Tepper, Amy Esler,\n  Vassilios Morellas, Nikolaos Papanikolopoulos, Guillermo Sapiro", "title": "Computer vision tools for the non-invasive assessment of autism-related\n  behavioral markers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early detection of developmental disorders is key to child outcome,\nallowing interventions to be initiated that promote development and improve\nprognosis. Research on autism spectrum disorder (ASD) suggests behavioral\nmarkers can be observed late in the first year of life. Many of these studies\ninvolved extensive frame-by-frame video observation and analysis of a child's\nnatural behavior. Although non-intrusive, these methods are extremely\ntime-intensive and require a high level of observer training; thus, they are\nimpractical for clinical and large population research purposes. Diagnostic\nmeasures for ASD are available for infants but are only accurate when used by\nspecialists experienced in early diagnosis. This work is a first milestone in a\nlong-term multidisciplinary project that aims at helping clinicians and general\npractitioners accomplish this early detection/measurement task automatically.\nWe focus on providing computer vision tools to measure and identify ASD\nbehavioral markers based on components of the Autism Observation Scale for\nInfants (AOSI). In particular, we develop algorithms to measure three critical\nAOSI activities that assess visual attention. We augment these AOSI activities\nwith an additional test that analyzes asymmetrical patterns in unsupported\ngait. The first set of algorithms involves assessing head motion by tracking\nfacial features, while the gait analysis relies on joint foreground\nsegmentation and 2D body pose estimation in video. We show results that provide\ninsightful knowledge to augment the clinician's behavioral observations\nobtained from real in-clinic assessments.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 22:30:40 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2012 03:03:45 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Hashemi", "Jordan", ""], ["Spina", "Thiago Vallin", ""], ["Tepper", "Mariano", ""], ["Esler", "Amy", ""], ["Morellas", "Vassilios", ""], ["Papanikolopoulos", "Nikolaos", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1210.7038", "submitter": "Reza Oji", "authors": "Reza Oji and Farshad Tajeripour", "title": "Full Object Boundary Detection by Applying Scale Invariant Features in a\n  Region Merging Segmentation Algorithm", "comments": "10 pages - 7 figures", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA) (2012) Volume 3, Number 5, pp: 41-50", "doi": "10.5121/ijaia.2012.3504", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a fundamental task in computer vision and has many\napplications in image processing. This paper proposes a new approach for object\ndetection by applying scale invariant feature transform (SIFT) in an automatic\nsegmentation algorithm. SIFT is an invariant algorithm respect to scale,\ntranslation and rotation. The features are very distinct and provide stable\nkeypoints that can be used for matching an object in different images. At\nfirst, an object is trained with different aspects for finding best keypoints.\nThe object can be recognized in the other images by using achieved keypoints.\nThen, a robust segmentation algorithm is used to detect the object with full\nboundary based on SIFT keypoints. In segmentation algorithm, a merging role is\ndefined to merge the regions in image with the assistance of keypoints. The\nresults show that the proposed approach is reliable for object detection and\ncan extract object boundary well.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 01:15:38 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Oji", "Reza", ""], ["Tajeripour", "Farshad", ""]]}, {"id": "1210.7053", "submitter": "Khoat Than", "authors": "Khoat Than and Tu Bao Ho", "title": "Managing sparsity, time, and quality of inference in topic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference is an integral part of probabilistic topic models, but is often\nnon-trivial to derive an efficient algorithm for a specific model. It is even\nmuch more challenging when we want to find a fast inference algorithm which\nalways yields sparse latent representations of documents. In this article, we\nintroduce a simple framework for inference in probabilistic topic models,\ndenoted by FW. This framework is general and flexible enough to be easily\nadapted to mixture models. It has a linear convergence rate, offers an easy way\nto incorporate prior knowledge, and provides us an easy way to directly trade\noff sparsity against quality and time. We demonstrate the goodness and\nflexibility of FW over existing inference methods by a number of tasks.\nFinally, we show how inference in topic models with nonconjugate priors can be\ndone efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 05:23:25 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2013 00:09:46 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Than", "Khoat", ""], ["Ho", "Tu Bao", ""]]}, {"id": "1210.7070", "submitter": "Shai Bagon", "authors": "Shai Bagon and Meirav Galun", "title": "A Multiscale Framework for Challenging Discrete Optimization", "comments": "5 pages, 1 figure, To appear in NIPS Workshop on Optimization for\n  Machine Learning (December 2012). Camera-ready version. Fixed typos,\n  acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Current state-of-the-art discrete optimization methods struggle behind when\nit comes to challenging contrast-enhancing discrete energies (i.e., favoring\ndifferent labels for neighboring variables). This work suggests a multiscale\napproach for these challenging problems. Deriving an algebraic representation\nallows us to coarsen any pair-wise energy using any interpolation in a\nprincipled algebraic manner. Furthermore, we propose an energy-aware\ninterpolation operator that efficiently exposes the multiscale landscape of the\nenergy yielding an effective coarse-to-fine optimization scheme. Results on\nchallenging contrast-enhancing energies show significant improvement over\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 09:08:55 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2012 13:26:02 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2012 10:11:10 GMT"}], "update_date": "2012-11-05", "authors_parsed": [["Bagon", "Shai", ""], ["Galun", "Meirav", ""]]}, {"id": "1210.7102", "submitter": "Harivinod N", "authors": "B. H. Shekar, N. Harivinod, M. Sharmila Kumari, K. Raghurama Holla", "title": "3D Face Recognition using Significant Point based SULD Descriptor", "comments": null, "journal-ref": null, "doi": "10.1109/ICRTIT.2011.5972443", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this work, we present a new 3D face recognition method based on Speeded-Up\nLocal Descriptor (SULD) of significant points extracted from the range images\nof faces. The proposed model consists of a method for extracting distinctive\ninvariant features from range images of faces that can be used to perform\nreliable matching between different poses of range images of faces. For a given\n3D face scan, range images are computed and the potential interest points are\nidentified by searching at all scales. Based on the stability of the interest\npoint, significant points are extracted. For each significant point we compute\nthe SULD descriptor which consists of vector made of values from the convolved\nHaar wavelet responses located on concentric circles centred on the significant\npoint, and where the amount of Gaussian smoothing is proportional to the radii\nof the circles. Experimental results show that the newly proposed method\nprovides higher recognition rate compared to other existing contemporary models\ndeveloped for 3D face recognition.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 11:27:33 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Shekar", "B. H.", ""], ["Harivinod", "N.", ""], ["Kumari", "M. Sharmila", ""], ["Holla", "K. Raghurama", ""]]}, {"id": "1210.7362", "submitter": "Shai Bagon", "authors": "Shai Bagon", "title": "Discrete Energy Minimization, beyond Submodularity: Applications and\n  Approximations", "comments": "Doctoral dissertation, Weizmann Institute of Science. Under the\n  supervision of Prof. Michal Irani and Dr Meirav Galun Corrected typos.\n  Citation added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this thesis I explore challenging discrete energy minimization problems\nthat arise mainly in the context of computer vision tasks. This work motivates\nthe use of such \"hard-to-optimize\" non-submodular functionals, and proposes\nmethods and algorithms to cope with the NP-hardness of their optimization.\nConsequently, this thesis revolves around two axes: applications and\napproximations. The applications axis motivates the use of such\n\"hard-to-optimize\" energies by introducing new tasks. As the energies become\nless constrained and structured one gains more expressive power for the\nobjective function achieving more accurate models. Results show how\nchallenging, hard-to-optimize, energies are more adequate for certain computer\nvision applications. To overcome the resulting challenging optimization tasks\nthe second axis of this thesis proposes approximation algorithms to cope with\nthe NP-hardness of the optimization. Experiments show that these new methods\nyield good results for representative challenging problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2012 19:12:49 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2012 21:09:53 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Bagon", "Shai", ""]]}, {"id": "1210.7403", "submitter": "Arnav Bhavsar", "authors": "Arnav Bhavsar", "title": "Resolution Enhancement of Range Images via Color-Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a method for super-resolution of range images. Our approach\nleverages the interpretation of LR image as sparse samples on the HR grid.\nBased on this interpretation, we demonstrate that our recently reported\napproach, which reconstructs dense range images from sparse range data by\nexploiting a registered colour image, can be applied for the task of resolution\nenhancement of range images. Our method only uses a single colour image in\naddition to the range observation in the super-resolution process. Using the\nproposed approach, we demonstrate super-resolution results for large factors\n(e.g. 4) with good localization accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 05:27:55 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Bhavsar", "Arnav", ""]]}, {"id": "1210.7461", "submitter": "Cesar Roberto de Souza", "authors": "C\\'esar Roberto de Souza, Ednaldo Brigante Pizzolato, Mauro dos Santos\n  Anjo", "title": "Recognizing Static Signs from the Brazilian Sign Language: Comparing\n  Large-Margin Decision Directed Acyclic Graphs, Voting Support Vector Machines\n  and Artificial Neural Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore and detail our experiments in a\nhigh-dimensionality, multi-class image classification problem often found in\nthe automatic recognition of Sign Languages. Here, our efforts are directed\ntowards comparing the characteristics, advantages and drawbacks of creating and\ntraining Support Vector Machines disposed in a Directed Acyclic Graph and\nArtificial Neural Networks to classify signs from the Brazilian Sign Language\n(LIBRAS). We explore how the different heuristics, hyperparameters and\nmulti-class decision schemes affect the performance, efficiency and ease of use\nfor each classifier. We provide hyperparameter surface maps capturing accuracy\nand efficiency, comparisons between DDAGs and 1-vs-1 SVMs, and effects of\nheuristics when training ANNs with Resilient Backpropagation. We report\nstatistically significant results using Cohen's Kappa statistic for contingency\ntables.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 13:55:07 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["de Souza", "C\u00e9sar Roberto", ""], ["Pizzolato", "Ednaldo Brigante", ""], ["Anjo", "Mauro dos Santos", ""]]}, {"id": "1210.7631", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "The fortresses of Ejin: an example of outlining a site from satellite\n  images", "comments": "Keywords: Satellite Imagery, Image processing, GIS, fortresses, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From 1960's to 1970's, the Chinese Army built some fortified artificial\nhills. Some of them are located in the Inner Mongolia, Western China. These\nlarge fortresses are surrounded by moats. For some of them it is still possible\nto see earthworks, trenches and ditches, the planning of which could have a\nsymbolic meaning. We can argue this result form their digital outlining,\nobtained after an image processing of satellite images, based on edge\ndetection.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 11:53:35 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1210.7669", "submitter": "Pooja Maknikar", "authors": "Pooja Maknikar", "title": "Performance Evaluation of Different Techniques for texture\n  Classification", "comments": "Performance evaluation of Wavelet transform and Co-occurrence matrix\n  method was done using energy as extracted feature on the basis of Time\n  complexity and accuracy basis; pp.353-361,2012", "journal-ref": null, "doi": "10.5121/csit.2012.2434", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Texture is the term used to characterize the surface of a given object or\nphenomenon and is an important feature used in image processing and pattern\nrecognition. Our aim is to compare various Texture analyzing methods and\ncompare the results based on time complexity and accuracy of classification.\nThe project describes texture classification using Wavelet Transform and Co\noccurrence Matrix. Comparison of features of a sample texture with database of\ndifferent textures is performed. In wavelet transform we use the Haar, Symlets\nand Daubechies wavelets. We find that, thee Haar wavelet proves to be the most\nefficient method in terms of performance assessment parameters mentioned above.\nComparison of Haar wavelet and Co-occurrence matrix method of classification\nalso goes in the favor of Haar. Though the time requirement is high in the\nlater method, it gives excellent results for classification accuracy except if\nthe image is rotated.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 14:05:27 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Maknikar", "Pooja", ""]]}, {"id": "1210.7956", "submitter": "Michel Owayjan", "authors": "Roger Achkar and Michel Owayjan", "title": "Implementation of a Vision System for a Landmine Detecting Robot Using\n  Artificial Neural Network", "comments": "20 pages, 14 figures, 4 tables", "journal-ref": "Achkar R, Owayjan M. Implementation of a Vision System for a\n  Landmine Detecting Robot Using Artificial Neural Network. International\n  Journal of Artificial Intelligence & Applications (IJAIA), Vol 3, No. 5, pp.\n  73-92, September 2012", "doi": "10.5121/ijaia.2012.3507", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landmines, specifically anti-tank mines, cluster bombs, and unexploded\nordnance form a serious problem in many countries. Several landmine sweeping\ntechniques are used for minesweeping. This paper presents the design and the\nimplementation of the vision system of an autonomous robot for landmines\nlocalization. The proposed work develops state-of-the-art techniques in digital\nimage processing for pre-processing captured images of the contaminated area.\nAfter enhancement, Artificial Neural Network (ANN) is used in order to\nidentify, recognize and classify the landmines' make and model. The\nBack-Propagation algorithm is used for training the network. The proposed work\nproved to be able to identify and classify different types of landmines under\nvarious conditions (rotated landmine, partially covered landmine) with a\nsuccess rate of up to 90%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 10:41:30 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Achkar", "Roger", ""], ["Owayjan", "Michel", ""]]}, {"id": "1210.8262", "submitter": "Nicola Rebagliati", "authors": "Nicola Rebagliati and Albert Sol\\'e-Ribalta and Marcello Pelillo and\n  Francesc Serratosa", "title": "On the Relation Between the Common Labelling and the Median Graph", "comments": "12 pages, 2 figures. Published in Structural, Syntactic, And\n  Statistical Pattern Recognition Lecture Notes in Computer Science, 2012. The\n  original publication is available at\n  http://www.springerlink.com/content/e524g4483g146383/", "journal-ref": "Lecture Notes in Computer Science, 2012, Volume 7626/2012, 107-115", "doi": "10.1007/978-3-642-34166-31_2", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In structural pattern recognition, given a set of graphs, the computation of\na Generalized Median Graph is a well known problem. Some methods approach the\nproblem by assuming a relation between the Generalized Median Graph and the\nCommon Labelling problem. However, this relation has still not been formally\nproved. In this paper, we analyse such relation between both problems. The main\nresult proves that the cost of the common labelling upper-bounds the cost of\nthe median with respect to the given set. In addition, we show that the two\nproblems are equivalent in some cases.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 08:29:58 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Rebagliati", "Nicola", ""], ["Sol\u00e9-Ribalta", "Albert", ""], ["Pelillo", "Marcello", ""], ["Serratosa", "Francesc", ""]]}, {"id": "1210.8318", "submitter": "H.R.  Chennamma", "authors": "H. R. Chennamma and Lalitha Rangarajan", "title": "Mugshot Identification from Manipulated Facial Images", "comments": "8 pages, 5 figures, 1 table, journal. arXiv admin note: substantial\n  text overlap with arXiv:1106.4907", "journal-ref": "International Journal of Machine Intelligence, Volume 4, Issue 1,\n  pp. 407, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Editing on digital images is ubiquitous. Identification of deliberately\nmodified facial images is a new challenge for face identification system. In\nthis paper, we address the problem of identification of a face or person from\nheavily altered facial images. In this face identification problem, the input\nto the system is a manipulated or transformed face image and the system reports\nback the determined identity from a database of known individuals. Such a\nsystem can be useful in mugshot identification in which mugshot database\ncontains two views (frontal and profile) of each criminal. We considered only\nfrontal view from the available database for face identification and the query\nimage is a manipulated face generated by face transformation software tool\navailable online. We propose SIFT features for efficient face identification in\nthis scenario. Further comparative analysis has been given with well known\neigenface approach. Experiments have been conducted with real case images to\nevaluate the performance of both methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 12:55:57 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Chennamma", "H. R.", ""], ["Rangarajan", "Lalitha", ""]]}]