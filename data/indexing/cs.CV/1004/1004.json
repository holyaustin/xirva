[{"id": "1004.0085", "submitter": "Akisato Kimura", "authors": "Akisato kimura, Derek Pang, Tatsuto Takeuchi, Kouji Miyazato, Junji\n  Yamato and Kunio Kashino", "title": "A stochastic model of human visual attention with a dynamic Bayesian\n  network", "comments": "24 pages, single-column, 13 figures excluding portlaits, submitted to\n  IEEE Transactions on Pattern Analysis and Machine Intelligence.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recent studies in the field of human vision science suggest that the human\nresponses to the stimuli on a visual display are non-deterministic. People may\nattend to different locations on the same visual input at the same time. Based\non this knowledge, we propose a new stochastic model of visual attention by\nintroducing a dynamic Bayesian network to predict the likelihood of where\nhumans typically focus on a video scene. The proposed model is composed of a\ndynamic Bayesian network with 4 layers. Our model provides a framework that\nsimulates and combines the visual saliency response and the cognitive state of\na person to estimate the most probable attended regions. Sample-based inference\nwith Markov chain Monte-Carlo based particle filter and stream processing with\nmulti-core processors enable us to estimate human visual attention in near real\ntime. Experimental results have demonstrated that our model performs\nsignificantly better in predicting human visual attention compared to the\nprevious deterministic models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2010 08:51:32 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["kimura", "Akisato", ""], ["Pang", "Derek", ""], ["Takeuchi", "Tatsuto", ""], ["Miyazato", "Kouji", ""], ["Yamato", "Junji", ""], ["Kashino", "Kunio", ""]]}, {"id": "1004.0258", "submitter": "Lennart Nacke Ph.D.", "authors": "Sophie Stellmach, Lennart E. Nacke, Raimund Dachselt, Craig A. Lindley", "title": "Trends and Techniques in Visual Gaze Analysis", "comments": "pages 89-93, The 5th Conference on Communication by Gaze Interaction\n  - COGAIN 2009: Gaze Interaction For Those Who Want It Most, ISBN:\n  978-87-643-0475-6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing gaze data is an effective way for the quick interpretation of eye\ntracking results. This paper presents a study investigation benefits and\nlimitations of visual gaze analysis among eye tracking professionals and\nresearchers. The results were used to create a tool for visual gaze analysis\nwithin a Master's project.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2010 23:48:23 GMT"}], "update_date": "2010-04-05", "authors_parsed": [["Stellmach", "Sophie", ""], ["Nacke", "Lennart E.", ""], ["Dachselt", "Raimund", ""], ["Lindley", "Craig A.", ""]]}, {"id": "1004.0378", "submitter": "Mahmoud Khademi", "authors": "Mahmoud Khademi, Mohammad H. Kiapour, Mehran Safayani, Mohammad T.\n  Manzuri, and M. Shojaei", "title": "Facial Expression Representation and Recognition Using 2DHLDA, Gabor\n  Wavelets, and Ensemble Learning", "comments": "This paper has been withdrawn by the author due to an error in\n  experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel method for representation and recognition of the\nfacial expressions in two-dimensional image sequences is presented. We apply a\nvariation of two-dimensional heteroscedastic linear discriminant analysis\n(2DHLDA) algorithm, as an efficient dimensionality reduction technique, to\nGabor representation of the input sequence. 2DHLDA is an extension of the\ntwo-dimensional linear discriminant analysis (2DLDA) approach and it removes\nthe equal within-class covariance. By applying 2DHLDA in two directions, we\neliminate the correlations between both image columns and image rows. Then, we\nperform a one-dimensional LDA on the new features. This combined method can\nalleviate the small sample size problem and instability encountered by HLDA.\nAlso, employing both geometric and appearance features and using an ensemble\nlearning scheme based on data fusion, we create a classifier which can\nefficiently classify the facial expressions. The proposed method is robust to\nillumination changes and it can properly represent temporal information as well\nas subtle changes in facial muscles. We provide experiments on Cohn-Kanade\ndatabase that show the superiority of the proposed method. KEYWORDS:\ntwo-dimensional heteroscedastic linear discriminant analysis (2DHLDA), subspace\nlearning, facial expression analysis, Gabor wavelets, ensemble learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2010 19:26:47 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2010 10:57:58 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2010 15:37:54 GMT"}, {"version": "v4", "created": "Wed, 20 Oct 2010 14:21:14 GMT"}, {"version": "v5", "created": "Tue, 9 Nov 2010 18:35:29 GMT"}, {"version": "v6", "created": "Tue, 8 Mar 2011 20:52:07 GMT"}, {"version": "v7", "created": "Fri, 20 Jul 2012 01:21:59 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Khademi", "Mahmoud", ""], ["Kiapour", "Mohammad H.", ""], ["Safayani", "Mehran", ""], ["Manzuri", "Mohammad T.", ""], ["Shojaei", "M.", ""]]}, {"id": "1004.0393", "submitter": "Irina Kogan A", "authors": "Joseph M. Burdis and Irina A. Kogan", "title": "Object-image correspondence for curves under finite and affine cameras", "comments": "19 pages, 2 figures. This version considers the case of rational\n  algebraic curves", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide criteria for deciding whether a given planar curve is an image of\na given spatial curve, obtained by a central or a parallel projection with\nunknown parameters. These criteria reduce the projection problem to a certain\nmodification of the equivalence problem of planar curves under affine and\nprojective transformations. The latter problem can be addressed using Cartan's\nmoving frame method. This leads to a novel algorithmic solution of the\nprojection problem for curves. The computational advantage of the algorithms\npresented here, in comparison to algorithms based on a straightforward\nsolution, lies in a significant reduction of a number of real parameters that\nhas to be eliminated in order to establish existence or non-existence of a\nprojection that maps a given spatial curve to a given planar curve. The same\napproach can be used to decide whether a given finite set of ordered points on\na plane is an image of a given finite set of ordered points in R^3. The\nmotivation comes from the problem of establishing a correspondence between an\nobject and an image, taken by a camera with unknown position and parameters.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2010 21:52:07 GMT"}, {"version": "v2", "created": "Mon, 28 Feb 2011 20:02:42 GMT"}], "update_date": "2015-03-14", "authors_parsed": [["Burdis", "Joseph M.", ""], ["Kogan", "Irina A.", ""]]}, {"id": "1004.0512", "submitter": "Mahmoud Khademi", "authors": "Mahmoud Khademi, Mohammad Hadi Kiapour, Mohammad T. Manzuri-Shalmani,\n  and Ali A. Kiaei", "title": "Analysis, Interpretation, and Recognition of Facial Action Units and\n  Expressions Using Neuro-Fuzzy Modeling", "comments": null, "journal-ref": "LNAI vol. 5998, pp. 161--172, Springer, Heidelberg (Proc. of 4th\n  IAPR Workshop on Artificial Neural Networks in Pattern Recognition), 2010.", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an accurate real-time sequence-based system for representation,\nrecognition, interpretation, and analysis of the facial action units (AUs) and\nexpressions is presented. Our system has the following characteristics: 1)\nemploying adaptive-network-based fuzzy inference systems (ANFIS) and temporal\ninformation, we developed a classification scheme based on neuro-fuzzy modeling\nof the AU intensity, which is robust to intensity variations, 2) using both\ngeometric and appearance-based features, and applying efficient dimension\nreduction techniques, our system is robust to illumination changes and it can\nrepresent the subtle changes as well as temporal information involved in\nformation of the facial expressions, and 3) by continuous values of intensity\nand employing top-down hierarchical rule-based classifiers, we can develop\naccurate human-interpretable AU-to-expression converters. Extensive experiments\non Cohn-Kanade database show the superiority of the proposed method, in\ncomparison with support vector machines, hidden Markov models, and neural\nnetwork classifiers. Keywords: biased discriminant analysis (BDA), classifier\ndesign and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy\nmodeling.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2010 15:20:27 GMT"}], "update_date": "2010-04-06", "authors_parsed": [["Khademi", "Mahmoud", ""], ["Kiapour", "Mohammad Hadi", ""], ["Manzuri-Shalmani", "Mohammad T.", ""], ["Kiaei", "Ali A.", ""]]}, {"id": "1004.0515", "submitter": "Mahmoud Khademi", "authors": "Mahmoud Khademi, Mohammad T. Manzuri-Shalmani, Mohammad H. Kiapour,\n  and Ali A. Kiaei", "title": "Recognizing Combinations of Facial Action Units with Different Intensity\n  Using a Mixture of Hidden Markov Models and Neural Network", "comments": null, "journal-ref": "LNCS vol. 5997, pp. 304--313, Springer, Heidelberg (Proc. of 9th\n  IAPR Workshop on Multiple Classifier Systems), 2010.", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial Action Coding System consists of 44 action units (AUs) and more than\n7000 combinations. Hidden Markov models (HMMs) classifier has been used\nsuccessfully to recognize facial action units (AUs) and expressions due to its\nability to deal with AU dynamics. However, a separate HMM is necessary for each\nsingle AU and each AU combination. Since combinations of AU numbering in\nthousands, a more efficient method will be needed. In this paper an accurate\nreal-time sequence-based system for representation and recognition of facial\nAUs is presented. Our system has the following characteristics: 1) employing a\nmixture of HMMs and neural network, we develop a novel accurate classifier,\nwhich can deal with AU dynamics, recognize subtle changes, and it is also\nrobust to intensity variations, 2) although we use an HMM for each single AU\nonly, by employing a neural network we can recognize each single and\ncombination AU, and 3) using both geometric and appearance-based features, and\napplying efficient dimension reduction techniques, our system is robust to\nillumination changes and it can represent the temporal information involved in\nformation of the facial expressions. Extensive experiments on Cohn-Kanade\ndatabase show the superiority of the proposed method, in comparison with other\nclassifiers. Keywords: classifier design and evaluation, data fusion, facial\naction units (AUs), hidden Markov models (HMMs), neural network (NN).\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2010 16:23:53 GMT"}], "update_date": "2010-04-06", "authors_parsed": [["Khademi", "Mahmoud", ""], ["Manzuri-Shalmani", "Mohammad T.", ""], ["Kiapour", "Mohammad H.", ""], ["Kiaei", "Ali A.", ""]]}, {"id": "1004.0517", "submitter": "Mahmoud Khademi", "authors": "Mahmoud Khademi, Mehran Safayani, and Mohammad T. Manzuri-Shalmani", "title": "Multilinear Biased Discriminant Analysis: A Novel Method for Facial\n  Action Unit Representation", "comments": "Proc. of 16th Korea-Japan Joint Workshop on Frontiers of Computer\n  Vision, Hiroshima, Japan, 2010.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel efficient method for representation of facial action\nunits by encoding an image sequence as a fourth-order tensor is presented. The\nmultilinear tensor-based extension of the biased discriminant analysis (BDA)\nalgorithm, called multilinear biased discriminant analysis (MBDA), is first\nproposed. Then, we apply the MBDA and two-dimensional BDA (2DBDA) algorithms,\nas the dimensionality reduction techniques, to Gabor representations and the\ngeometric features of the input image sequence respectively. The proposed\nscheme can deal with the asymmetry between positive and negative samples as\nwell as curse of dimensionality dilemma. Extensive experiments on Cohn-Kanade\ndatabase show the superiority of the proposed method for representation of the\nsubtle changes and the temporal information involved in formation of the facial\nexpressions. As an accurate tool, this representation can be applied to many\nareas such as recognition of spontaneous and deliberate facial expressions,\nmulti modal/media human computer interaction and lie detection efforts.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2010 16:40:39 GMT"}], "update_date": "2010-04-06", "authors_parsed": [["Khademi", "Mahmoud", ""], ["Safayani", "Mehran", ""], ["Manzuri-Shalmani", "Mohammad T.", ""]]}, {"id": "1004.0755", "submitter": "Mahmoud Khademi", "authors": "Mehran Safayani, Mohammad T. Manzuri-Shalmani, Mahmoud Khademi", "title": "Extended Two-Dimensional PCA for Efficient Face Representation and\n  Recognition", "comments": "Proc. of 4th International Conference on Intelligent Computer\n  Communication and Processing (ICCP), Cluj-Napoca, Romania, pp. 295--298,\n  2008.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel method called Extended Two-Dimensional PCA (E2DPCA) is\nproposed which is an extension to the original 2DPCA. We state that the\ncovariance matrix of 2DPCA is equivalent to the average of the main diagonal of\nthe covariance matrix of PCA. This implies that 2DPCA eliminates some\ncovariance information that can be useful for recognition. E2DPCA instead of\njust using the main diagonal considers a radius of r diagonals around it and\nexpands the averaging so as to include the covariance information within those\ndiagonals. The parameter r unifies PCA and 2DPCA. r = 1 produces the covariance\nof 2DPCA, r = n that of PCA. Hence, by controlling r it is possible to control\nthe trade-offs between recognition accuracy and energy compression (fewer\ncoefficients), and between training and recognition complexity. Experiments on\nORL face database show improvement in both recognition accuracy and recognition\ntime over the original 2DPCA.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2010 02:27:58 GMT"}], "update_date": "2010-04-07", "authors_parsed": [["Safayani", "Mehran", ""], ["Manzuri-Shalmani", "Mohammad T.", ""], ["Khademi", "Mahmoud", ""]]}, {"id": "1004.1215", "submitter": "Oleg Michailovich", "authors": "Elad Shaked and Oleg Michailovich", "title": "Regularized Richardson-Lucy Algorithm for Sparse Reconstruction of\n  Poissonian Images", "comments": "The paper was submitted for consideration of possible publication in\n  the IEEE Transactions on Image Processing on April 7, 2010.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restoration of digital images from their degraded measurements has always\nbeen a problem of great theoretical and practical importance in numerous\napplications of imaging sciences. A specific solution to the problem of image\nrestoration is generally determined by the nature of degradation phenomenon as\nwell as by the statistical properties of measurement noises. The present study\nis concerned with the case in which the images of interest are corrupted by\nconvolutional blurs and Poisson noises. To deal with such problems, there\nexists a range of solution methods which are based on the principles\noriginating from the fixed-point algorithm of Richardson and Lucy (RL). In this\npaper, we provide conceptual and experimental proof that such methods tend to\nconverge to sparse solutions, which makes them applicable only to those images\nwhich can be represented by a relatively small number of non-zero samples in\nthe spatial domain. Unfortunately, the set of such images is relatively small,\nwhich restricts the applicability of RL-type methods. On the other hand,\nvirtually all practical images admit sparse representations in the domain of a\nproperly designed linear transform. To take advantage of this fact, it is\ntherefore tempting to modify the RL algorithm so as to make it recover\nrepresentation coefficients, rather than the values of their associated image.\nSuch modification is introduced in this paper. Apart from the generality of its\nassumptions, the proposed method is also superior to many established\nreconstruction approaches in terms of estimation accuracy and computational\ncomplexity. This and other conclusions of this study are validated through a\nseries of numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2010 01:08:30 GMT"}], "update_date": "2010-04-09", "authors_parsed": [["Shaked", "Elad", ""], ["Michailovich", "Oleg", ""]]}, {"id": "1004.1227", "submitter": "Rdv Ijcsis", "authors": "Ismail A. Ismail, Mohammed A. Ramadan, Talaat S. El danaf, Ahmed H.\n  Samak", "title": "Signature Recognition using Multi Scale Fourier Descriptor And Wavelet\n  Transform", "comments": "IEEE Publication format, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "IJCSIS, Vol. 7 No. 3, March 2010,", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper present a novel off-line signature recognition method based on\nmulti scale Fourier Descriptor and wavelet transform . The main steps of\nconstructing a signature recognition system are discussed and experiments on\nreal data sets show that the average error rate can reach 1%. Finally we\ncompare 8 distance measures between feature vectors with respect to the\nrecognition performance.\n  Key words: signature recognition; Fourier Descriptor; Wavelet transform;\npersonal verification\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2010 02:39:49 GMT"}], "update_date": "2010-04-09", "authors_parsed": [["Ismail", "Ismail A.", ""], ["Ramadan", "Mohammed A.", ""], ["danaf", "Talaat S. El", ""], ["Samak", "Ahmed H.", ""]]}, {"id": "1004.1679", "submitter": "Rdv Ijcsis", "authors": "S. Zulaikha Beevi, M. Mohammed Sathik, K. Senthamaraikannan", "title": "A Robust Fuzzy Clustering Technique with Spatial Neighborhood\n  Information for Effective Medical Image Segmentation", "comments": "IEEE Publication format, International Journal of Computer Science\n  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947\n  5500, http://sites.google.com/site/ijcsis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Medical image segmentation demands an efficient and robust segmentation\nalgorithm against noise. The conventional fuzzy c-means algorithm is an\nefficient clustering algorithm that is used in medical image segmentation. But\nFCM is highly vulnerable to noise since it uses only intensity values for\nclustering the images. This paper aims to develop a novel and efficient fuzzy\nspatial c-means clustering algorithm which is robust to noise. The proposed\nclustering algorithm uses fuzzy spatial information to calculate membership\nvalue. The input image is clustered using proposed ISFCM algorithm. A\ncomparative study has been made between the conventional FCM and proposed\nISFCM. The proposed approach is found to be outperforming the conventional FCM.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2010 04:04:12 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Beevi", "S. Zulaikha", ""], ["Sathik", "M. Mohammed", ""], ["Senthamaraikannan", "K.", ""]]}, {"id": "1004.1686", "submitter": "Rdv Ijcsis", "authors": "H. B. Kekre, Tanuja K. Sarode", "title": "New Clustering Algorithm for Vector Quantization using Rotation of Error\n  Vector", "comments": "IEEE Publication format, International Journal of Computer Science\n  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947\n  5500, http://sites.google.com/site/ijcsis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The paper presents new clustering algorithm. The proposed algorithm gives\nless distortion as compared to well known Linde Buzo Gray (LBG) algorithm and\nKekre's Proportionate Error (KPE) Algorithm. Constant error is added every time\nto split the clusters in LBG, resulting in formation of cluster in one\ndirection which is 1350 in 2-dimensional case. Because of this reason\nclustering is inefficient resulting in high MSE in LBG. To overcome this\ndrawback of LBG proportionate error is added to change the cluster orientation\nin KPE. Though the cluster orientation in KPE is changed its variation is\nlimited to +/- 450 over 1350. The proposed algorithm takes care of this problem\nby introducing new orientation every time to split the clusters. The proposed\nmethod reduces PSNR by 2db to 5db for codebook size 128 to 1024 with respect to\nLBG.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2010 05:18:02 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Kekre", "H. B.", ""], ["Sarode", "Tanuja K.", ""]]}, {"id": "1004.1768", "submitter": "Rdv Ijcsis", "authors": "M. Gomathi, P.Thangaraj", "title": "A New Approach to Lung Image Segmentation using Fuzzy Possibilistic\n  C-Means Algorithm", "comments": "IEEE Publication format, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "IJCSIS, Vol. 7 No. 3, March 2010, 222-228", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Image segmentation is a vital part of image processing. Segmentation has its\napplication widespread in the field of medical images in order to diagnose\ncurious diseases. The same medical images can be segmented manually. But the\naccuracy of image segmentation using the segmentation algorithms is more when\ncompared with the manual segmentation. In the field of medical diagnosis an\nextensive diversity of imaging techniques is presently available, such as\nradiography, computed tomography (CT) and magnetic resonance imaging (MRI).\nMedical image segmentation is an essential step for most consequent image\nanalysis tasks. Although the original FCM algorithm yields good results for\nsegmenting noise free images, it fails to segment images corrupted by noise,\noutliers and other imaging artifact. This paper presents an image segmentation\napproach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic\nc-means algorithm (FPCM). This approach is a generalized version of standard\nFuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM\ntechnique is eliminated in modifying the standard technique. The Modified FCM\nalgorithm is formulated by modifying the distance measurement of the standard\nFCM algorithm to permit the labeling of a pixel to be influenced by other\npixels and to restrain the noise effect during segmentation. Instead of having\none term in the objective function, a second term is included, forcing the\nmembership to be as high as possible without a maximum limit constraint of one.\nExperiments are conducted on real images to investigate the performance of the\nproposed modified FCM technique in segmenting the medical images. Standard FCM,\nModified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to\nexplore the accuracy of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2010 08:01:08 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Gomathi", "M.", ""], ["Thangaraj", "P.", ""]]}, {"id": "1004.1789", "submitter": "Rdv Ijcsis", "authors": "H. B. Kekre, Saylee Gharge, Tanuja K. Sarode", "title": "SAR Image Segmentation using Vector Quantization Technique on Entropy\n  Images", "comments": "IEEE Publication format, International Journal of Computer Science\n  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947\n  5500, http://sites.google.com/site/ijcsis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The development and application of various remote sensing platforms result in\nthe production of huge amounts of satellite image data. Therefore, there is an\nincreasing need for effective querying and browsing in these image databases.\nIn order to take advantage and make good use of satellite images data, we must\nbe able to extract meaningful information from the imagery. Hence we proposed a\nnew algorithm for SAR image segmentation. In this paper we propose segmentation\nusing vector quantization technique on entropy image. Initially, we obtain\nentropy image and in second step we use Kekre's Fast Codebook Generation (KFCG)\nalgorithm for segmentation of the entropy image. Thereafter, a codebook of size\n128 was generated for the Entropy image. These code vectors were further\nclustered in 8 clusters using same KFCG algorithm and converted into 8 images.\nThese 8 images were displayed as a result. This approach does not lead to over\nsegmentation or under segmentation. We compared these results with well known\nGray Level Co-occurrence Matrix. The proposed algorithm gives better\nsegmentation with less complexity.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2010 11:05:33 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Kekre", "H. B.", ""], ["Gharge", "Saylee", ""], ["Sarode", "Tanuja K.", ""]]}, {"id": "1004.1886", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing", "title": "Feature Level Fusion of Face and Palmprint Biometrics by Isomorphic\n  Graph-based Improved K-Medoids Partitioning", "comments": "13 pages, 4 figures", "journal-ref": "ISA 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a feature level fusion approach which uses the improved\nK-medoids clustering algorithm and isomorphic graph for face and palmprint\nbiometrics. Partitioning around medoids (PAM) algorithm is used to partition\nthe set of n invariant feature points of the face and palmprint images into k\nclusters. By partitioning the face and palmprint images with scale invariant\nfeatures SIFT points, a number of clusters is formed on both the images. Then\non each cluster, an isomorphic graph is drawn. In the next step, the most\nprobable pair of graphs is searched using iterative relaxation algorithm from\nall possible isomorphic graphs for a pair of corresponding face and palmprint\nimages. Finally, graphs are fused by pairing the isomorphic graphs into\naugmented groups in terms of addition of invariant SIFT points and in terms of\ncombining pair of keypoint descriptors by concatenation rule. Experimental\nresults obtained from the extensive evaluation show that the proposed feature\nlevel fusion with the improved K-medoids partitioning algorithm increases the\nperformance of the system with utmost level of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 07:34:39 GMT"}], "update_date": "2010-04-13", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Gupta", "Phalguni", ""], ["Sing", "Jamuna Kanta", ""]]}, {"id": "1004.1887", "submitter": "Dakshina Ranjan Kisku", "authors": "Phalguni Gupta, Dakshina Ranjan Kisku, Jamuna Kanta Sing, Massimo\n  Tistarelli", "title": "Maximized Posteriori Attributes Selection from Facial Salient Landmarks\n  for Face Recognition", "comments": "8 pages, 2 figures", "journal-ref": "ISA 2010", "doi": "10.1007/978-3-642-13365-7_1", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a robust and dynamic face recognition technique based on\nthe extraction and matching of devised probabilistic graphs drawn on SIFT\nfeatures related to independent face areas. The face matching strategy is based\non matching individual salient facial graph characterized by SIFT features as\nconnected to facial landmarks such as the eyes and the mouth. In order to\nreduce the face matching errors, the Dempster-Shafer decision theory is applied\nto fuse the individual matching scores obtained from each pair of salient\nfacial features. The proposed algorithm is evaluated with the ORL and the IITK\nface databases. The experimental results demonstrate the effectiveness and\npotential of the proposed face recognition technique also in case of partially\noccluded faces.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 07:42:09 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Gupta", "Phalguni", ""], ["Kisku", "Dakshina Ranjan", ""], ["Sing", "Jamuna Kanta", ""], ["Tistarelli", "Massimo", ""]]}, {"id": "1004.3257", "submitter": "Vishal Goyal", "authors": "Rahul Kala, Harsh Vazirani, Anupam Shukla, Ritu Tiwari", "title": "Offline Handwriting Recognition using Genetic Algorithm", "comments": "International Journal of Computer Science Issues at\n  http://ijcsi.org/articles/Offline-Handwriting-Recognition-using-Genetic-Algorithm.php", "journal-ref": "IJCSI, Volume 7, Issue 2, March 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting Recognition enables a person to scribble something on a piece of\npaper and then convert it into text. If we look into the practical reality\nthere are enumerable styles in which a character may be written. These styles\ncan be self combined to generate more styles. Even if a small child knows the\nbasic styles a character can be written, he would be able to recognize\ncharacters written in styles intermediate between them or formed by their\nmixture. This motivates the use of Genetic Algorithms for the problem. In order\nto prove this, we made a pool of images of characters. We converted them to\ngraphs. The graph of every character was intermixed to generate styles\nintermediate between the styles of parent character. Character recognition\ninvolved the matching of the graph generated from the unknown character image\nwith the graphs generated by mixing. Using this method we received an accuracy\nof 98.44%.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2010 17:49:28 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Kala", "Rahul", ""], ["Vazirani", "Harsh", ""], ["Shukla", "Anupam", ""], ["Tiwari", "Ritu", ""]]}, {"id": "1004.3276", "submitter": "Vishal Goyal", "authors": "G. K. Kharate, V. H. Patil", "title": "Color Image Compression Based On Wavelet Packet Best Tree", "comments": "International Journal of Computer Science Issues online at\n  http://ijcsi.org/articles/Color-Image-Compression-Based-On-Wavelet-Packet-Best-Tree.php", "journal-ref": "IJCSI, Volume 7, Issue 2, March 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Image Compression, the researchers' aim is to reduce the number of bits\nrequired to represent an image by removing the spatial and spectral\nredundancies. Recently discrete wavelet transform and wavelet packet has\nemerged as popular techniques for image compression. The wavelet transform is\none of the major processing components of image compression. The result of the\ncompression changes as per the basis and tap of the wavelet used. It is\nproposed that proper selection of mother wavelet on the basis of nature of\nimages, improve the quality as well as compression ratio remarkably. We suggest\nthe novel technique, which is based on wavelet packet best tree based on\nThreshold Entropy with enhanced run-length encoding. This method reduces the\ntime complexity of wavelet packets decomposition as complete tree is not\ndecomposed. Our algorithm selects the sub-bands, which include significant\ninformation based on threshold entropy. The enhanced run length encoding\ntechnique is suggested provides better results than RLE. The result when\ncompared with JPEG-2000 proves to be better.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2010 18:28:46 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Kharate", "G. K.", ""], ["Patil", "V. H.", ""]]}, {"id": "1004.3549", "submitter": "Vishal Goyal", "authors": "Bassam Al-Mahadeen, Mokhled S. AlTarawneh, Islam H. AlTarawneh", "title": "Signature Region of Interest using Auto cropping", "comments": "International Journal of Computer Science Issues online at\n  http://ijcsi.org/articles/Signature-Region-of-Interest-using-Auto-cropping.php", "journal-ref": "IJCSI, Volume 7, Issue 2, March 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach for signature region of interest pre-processing was presented.\nIt used new auto cropping preparation on the basis of the image content, where\nthe intensity value of pixel is the source of cropping. This approach provides\nboth the possibility of improving the performance of security systems based on\nsignature images, and also the ability to use only the region of interest of\nthe used image to suit layout design of biometric systems. Underlying the\napproach is a novel segmentation method which identifies the exact region of\nforeground of signature for feature extraction usage. Evaluation results of\nthis approach shows encouraging prospects by eliminating the need for false\nregion isolating, reduces the time cost associated with signature false points\ndetection, and addresses enhancement issues. A further contribution of this\npaper is an automated cropping stage in bio-secure based systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 20:04:17 GMT"}], "update_date": "2010-04-22", "authors_parsed": [["Al-Mahadeen", "Bassam", ""], ["AlTarawneh", "Mokhled S.", ""], ["AlTarawneh", "Islam H.", ""]]}, {"id": "1004.3629", "submitter": "Jun-ichi Inoue", "authors": "Yuya Inagaki, Jun-ichi Inoue", "title": "Simultaneous Bayesian inference of motion velocity fields and\n  probabilistic models in successive video-frames described by spatio-temporal\n  MRFs", "comments": "10 pages, 21 figures, using IEEEtran.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We numerically investigate a mean-field Bayesian approach with the assistance\nof the Markov chain Monte Carlo method to estimate motion velocity fields and\nprobabilistic models simultaneously in consecutive digital images described by\nspatio-temporal Markov random fields. Preliminary to construction of our\nprocedure, we find that mean-field variables in the iteration diverge due to\nimproper normalization factor of regularization terms appearing in the\nposterior. To avoid this difficulty, we rescale the regularization term by\nintroducing a scaling factor and optimizing it by means of minimization of the\nmean-square error. We confirm that the optimal scaling factor stabilizes the\nmean-field iterative process of the motion velocity estimation. We next attempt\nto estimate the optimal values of hyper-parameters including the regularization\nterm, which define our probabilistic model macroscopically, by using the\nBoltzmann-machine type learning algorithm based on gradient descent of marginal\nlikelihood (type-II likelihood) with respect to the hyper-parameters. In our\nframework, one can estimate both the probabilistic model (hyper-parameters) and\nmotion velocity fields simultaneously. We find that our motion estimation is\nmuch better than the result obtained by Zhang and Hanouer (1995) in which the\nhyper-parameters are set to some ad-hoc values without any theoretical\njustification.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2010 06:27:47 GMT"}], "update_date": "2010-04-22", "authors_parsed": [["Inagaki", "Yuya", ""], ["Inoue", "Jun-ichi", ""]]}, {"id": "1004.3708", "submitter": "Uwe Aickelin", "authors": "Yongnan Ji, Pierre-Yves Herve, Uwe Aickelin, Alain Pitiot", "title": "Parcellation of fMRI Datasets with ICA and PLS-A Data Driven Approach", "comments": "8 pages, 5 figures, P12th International Conference of Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2009)", "journal-ref": "Proceedings of the 12th International Conference of Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2009), Part I, Lecture\n  Notes in Computer Science 5761, London, UK, 2009", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-subject parcellation of functional Magnetic Resonance Imaging (fMRI)\ndata based on a standard General Linear Model (GLM)and spectral clustering was\nrecently proposed as a means to alleviate the issues associated with spatial\nnormalization in fMRI. However, for all its appeal, a GLM-based parcellation\napproach introduces its own biases, in the form of a priori knowledge about the\nshape of Hemodynamic Response Function (HRF) and task-related signal changes,\nor about the subject behaviour during the task. In this paper, we introduce a\ndata-driven version of the spectral clustering parcellation, based on\nIndependent Component Analysis (ICA) and Partial Least Squares (PLS) instead of\nthe GLM. First, a number of independent components are automatically selected.\nSeed voxels are then obtained from the associated ICA maps and we compute the\nPLS latent variables between the fMRI signal of the seed voxels (which covers\nregional variations of the HRF) and the principal components of the signal\nacross all voxels. Finally, we parcellate all subjects data with a spectral\nclustering of the PLS latent variables. We present results of the application\nof the proposed method on both single-subject and multi-subject fMRI datasets.\nPreliminary experimental results, evaluated with intra-parcel variance of GLM\nt-values and PLS derived t-values, indicate that this data-driven approach\noffers improvement in terms of parcellation accuracy over GLM based techniques.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2010 13:50:55 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Ji", "Yongnan", ""], ["Herve", "Pierre-Yves", ""], ["Aickelin", "Uwe", ""], ["Pitiot", "Alain", ""]]}, {"id": "1004.3980", "submitter": "Mithun Das Gupta", "authors": "Mithun Das Gupta", "title": "Hashing Image Patches for Zooming", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a Bayesian image zooming/super-resolution algorithm\nbased on a patch based representation. We work on a patch based model with\noverlap and employ a Locally Linear Embedding (LLE) based approach as our data\nfidelity term in the Bayesian inference. The image prior imposes continuity\nconstraints across the overlapping patches. We apply an error back-projection\ntechnique, with an approximate cross bilateral filter. The problem of nearest\nneighbor search is handled by a variant of the locality sensitive hashing (LSH)\nscheme. The novelty of our work lies in the speed up achieved by the hashing\nscheme and the robustness and inherent modularity and parallel structure\nachieved by the LLE setup. The ill-posedness of the image reconstruction\nproblem is handled by the introduction of regularization priors which encode\nthe knowledge present in vast collections of natural images. We present\ncomparative results for both run-time as well as visual image quality based\nmeasurements.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2010 18:42:03 GMT"}], "update_date": "2010-04-23", "authors_parsed": [["Gupta", "Mithun Das", ""]]}, {"id": "1004.4373", "submitter": "Joseph Shtok", "authors": "Joseph Shtok, Michael Zibulevsky and Michael Elad", "title": "Spatially-Adaptive Reconstruction in Computed Tomography Based on\n  Statistical Learning", "comments": "Submitted to IEEE Transactions on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a direct reconstruction algorithm for Computed Tomography, based\non a local fusion of a few preliminary image estimates by means of a non-linear\nfusion rule. One such rule is based on a signal denoising technique which is\nspatially adaptive to the unknown local smoothness. Another, more powerful\nfusion rule, is based on a neural network trained off-line with a high-quality\ntraining set of images. Two types of linear reconstruction algorithms for the\npreliminary images are employed for two different reconstruction tasks. For an\nentire image reconstruction from full projection data, the proposed scheme uses\na sequence of Filtered Back-Projection algorithms with a gradually growing\ncut-off frequency. To recover a Region Of Interest only from local projections,\nstatistically-trained linear reconstruction algorithms are employed. Numerical\nexperiments display the improvement in reconstruction quality when compared to\nlinear reconstruction algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2010 19:10:26 GMT"}], "update_date": "2010-04-27", "authors_parsed": [["Shtok", "Joseph", ""], ["Zibulevsky", "Michael", ""], ["Elad", "Michael", ""]]}, {"id": "1004.4448", "submitter": "William Jackson", "authors": "Salem Saleh Al-amri, N.V. Kalyankar and Khamitkar S.D", "title": "Deblured Gaussian Blurred Images", "comments": "Journal of Computing online at\n  https://sites.google.com/site/journalofcomputing/", "journal-ref": "Journal of Computing, Volume 2, Issue 4, April 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to undertake the study of Restored Gaussian Blurred\nImages. by using four types of techniques of deblurring image as Wiener filter,\nRegularized filter, Lucy Richardson deconvlutin algorithm and Blind\ndeconvlution algorithm with an information of the Point Spread Function (PSF)\ncorrupted blurred image with Different values of Size and Alfa and then\ncorrupted by Gaussian noise. The same is applied to the remote sensing image\nand they are compared with one another, So as to choose the base technique for\nrestored or deblurring image.This paper also attempts to undertake the study of\nrestored Gaussian blurred image with no any information about the Point Spread\nFunction (PSF) by using same four techniques after execute the guess of the\nPSF, the number of iterations and the weight threshold of it. To choose the\nbase guesses for restored or deblurring image of this techniques.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2010 09:32:28 GMT"}], "update_date": "2010-04-27", "authors_parsed": [["Al-amri", "Salem Saleh", ""], ["Kalyankar", "N. V.", ""], ["D", "Khamitkar S.", ""]]}, {"id": "1004.4467", "submitter": "William Jackson", "authors": "Er. Deepak Aggarwal, Er. Sandeep Kaur and Er. Anantdeep", "title": "An Efficient Watermarking Algorithm to Improve Payload and Robustness\n  without Affecting Image Perceptual Quality", "comments": "https://sites.google.com/site/journalofcomputing/", "journal-ref": "Journal of Computing, Volume 2, Issue 4, April 2010, 105-109", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capacity, Robustness, & Perceptual quality of watermark data are very\nimportant issues to be considered. A lot of research is going on to increase\nthese parameters for watermarking of the digital images, as there is always a\ntradeoff among them. . In this paper an efficient watermarking algorithm to\nimprove payload and robustness without affecting perceptual quality of image\ndata based on DWT is discussed. The aim of the paper is to employ the nested\nwatermarks in wavelet domain which increases the capacity and ultimately the\nrobustness against attacks and selection of different scaling factor values for\nLL & HH bands and during embedding not to create the visible artifacts in the\noriginal image and therefore the original and watermarked image is similar.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2010 10:17:53 GMT"}], "update_date": "2010-04-27", "authors_parsed": [["Aggarwal", "Er. Deepak", ""], ["Kaur", "Er. Sandeep", ""], ["Anantdeep", "Er.", ""]]}, {"id": "1004.4793", "submitter": "Roman Fedorov", "authors": "R.K. Fedorov", "title": "Logical methods of object recognition on satellite images using spatial\n  constraints", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A logical approach to object recognition on image is proposed. The main idea\nof the approach is to perform the object recognition as a logical inference on\na set of rules describing an object shape.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2010 13:22:36 GMT"}], "update_date": "2010-04-28", "authors_parsed": [["Fedorov", "R. K.", ""]]}, {"id": "1004.4965", "submitter": "Mikhail Zaslavskiy", "authors": "Mikhail Zaslavskiy (CBIO), Francis Bach (INRIA Rocquencourt, LIENS),\n  Jean-Philippe Vert (CBIO)", "title": "Many-to-Many Graph Matching: a Continuous Relaxation Approach", "comments": "19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs provide an efficient tool for object representation in various\ncomputer vision applications. Once graph-based representations are constructed,\nan important question is how to compare graphs. This problem is often\nformulated as a graph matching problem where one seeks a mapping between\nvertices of two graphs which optimally aligns their structure. In the classical\nformulation of graph matching, only one-to-one correspondences between vertices\nare considered. However, in many applications, graphs cannot be matched\nperfectly and it is more interesting to consider many-to-many correspondences\nwhere clusters of vertices in one graph are matched to clusters of vertices in\nthe other graph. In this paper, we formulate the many-to-many graph matching\nproblem as a discrete optimization problem and propose an approximate algorithm\nbased on a continuous relaxation of the combinatorial problem. We compare our\nmethod with other existing methods on several benchmark computer vision\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2010 07:46:55 GMT"}], "update_date": "2010-04-30", "authors_parsed": [["Zaslavskiy", "Mikhail", "", "CBIO"], ["Bach", "Francis", "", "INRIA Rocquencourt, LIENS"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1004.5305", "submitter": "Marcio Marim", "authors": "Marcio Marim (TSI, AIQ), Michael Atlan, Elsa Angelini (TSI),\n  Jean-Christophe Olivo-Marin (AIQ)", "title": "Compressed Sensing with off-axis frequency-shifting holography", "comments": "vol 35, pp 871-873", "journal-ref": null, "doi": "10.1364/OL.35.000871", "report-no": null, "categories": "physics.optics cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work reveals an experimental microscopy acquisition scheme successfully\ncombining Compressed Sensing (CS) and digital holography in off-axis and\nfrequency-shifting conditions. CS is a recent data acquisition theory involving\nsignal reconstruction from randomly undersampled measurements, exploiting the\nfact that most images present some compact structure and redundancy. We propose\na genuine CS-based imaging scheme for sparse gradient images, acquiring a\ndiffraction map of the optical field with holographic microscopy and recovering\nthe signal from as little as 7% of random measurements. We report experimental\nresults demonstrating how CS can lead to an elegant and effective way to\nreconstruct images, opening the door for new microscopy applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 14:32:27 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Marim", "Marcio", "", "TSI, AIQ"], ["Atlan", "Michael", "", "TSI"], ["Angelini", "Elsa", "", "TSI"], ["Olivo-Marin", "Jean-Christophe", "", "AIQ"]]}, {"id": "1004.5351", "submitter": "Emil Saucan", "authors": "Emil Saucan", "title": "Isometric Embeddings in Imaging and Vision: Facts and Fiction", "comments": "23 pages, 1 figure Second version: Corrections made, subsection added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.CV math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the practicability of Nash's Embedding Theorem in vision and\nimaging sciences. In particular, we investigate the relevance of a result of\nBurago and Zalgaller regarding the existence of isometric embeddings of\npolyhedral surfaces in $\\mathbb{R}^3$ and we show that their proof does not\nextended directly to higher dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2010 17:56:47 GMT"}, {"version": "v2", "created": "Tue, 11 May 2010 19:04:22 GMT"}], "update_date": "2010-05-12", "authors_parsed": [["Saucan", "Emil", ""]]}, {"id": "1004.5424", "submitter": "Muhammad Muzzamil  Luqman", "authors": "Muhammad Muzzamil Luqman, Thierry Brouard and Jean-Yves Ramel", "title": "Graphic Symbol Recognition using Graph Based Signature and Bayesian\n  Network Classifier", "comments": "5 pages, 8 figures, Tenth International Conference on Document\n  Analysis and Recognition (ICDAR), IEEE Computer Society, 2009, volume 10,\n  1325-1329", "journal-ref": null, "doi": "10.1109/ICDAR.2009.92", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach for recognition of complex graphic symbols in\ntechnical documents. Graphic symbol recognition is a well known challenge in\nthe field of document image analysis and is at heart of most graphic\nrecognition systems. Our method uses structural approach for symbol\nrepresentation and statistical classifier for symbol recognition. In our system\nwe represent symbols by their graph based signatures: a graphic symbol is\nvectorized and is converted to an attributed relational graph, which is used\nfor computing a feature vector for the symbol. This signature corresponds to\ngeometry and topology of the symbol. We learn a Bayesian network to encode\njoint probability distribution of symbol signatures and use it in a supervised\nlearning scenario for graphic symbol recognition. We have evaluated our method\non synthetically deformed and degraded images of pre-segmented 2D architectural\nand electronic symbols from GREC databases and have obtained encouraging\nrecognition rates.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2010 00:04:39 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Luqman", "Muhammad Muzzamil", ""], ["Brouard", "Thierry", ""], ["Ramel", "Jean-Yves", ""]]}, {"id": "1004.5427", "submitter": "Muhammad Muzzamil  Luqman", "authors": "Muhammad Muzzamil Luqman, Mathieu Delalandre, Thierry Brouard,\n  Jean-Yves Ramel and Josep Llad\\'os", "title": "Employing fuzzy intervals and loop-based methodology for designing\n  structural signature: an application to symbol recognition", "comments": "10 pages, Eighth IAPR International Workshop on Graphics RECognition\n  (GREC), 2009, volume 8, 22-31", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation of our work is to present a new methodology for symbol\nrecognition. We support structural methods for representing visual associations\nin graphic documents. The proposed method employs a structural approach for\nsymbol representation and a statistical classifier for recognition. We\nvectorize a graphic symbol, encode its topological and geometrical information\nby an ARG and compute a signature from this structural graph. To address the\nsensitivity of structural representations to deformations and degradations, we\nuse data adapted fuzzy intervals while computing structural signature. The\njoint probability distribution of signatures is encoded by a Bayesian network.\nThis network in fact serves as a mechanism for pruning irrelevant features and\nchoosing a subset of interesting features from structural signatures, for\nunderlying symbol set. Finally we deploy the Bayesian network in supervised\nlearning scenario for recognizing query symbols. We have evaluated the\nrobustness of our method against noise, on synthetically deformed and degraded\nimages of pre-segmented 2D architectural and electronic symbols from GREC\ndatabases and have obtained encouraging recognition rates. A second set of\nexperimentation was carried out for evaluating the performance of our method\nagainst context noise i.e. symbols cropped from complete documents. The results\nsupport the use of our signature by a symbol spotting system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2010 00:16:22 GMT"}], "update_date": "2010-05-03", "authors_parsed": [["Luqman", "Muhammad Muzzamil", ""], ["Delalandre", "Mathieu", ""], ["Brouard", "Thierry", ""], ["Ramel", "Jean-Yves", ""], ["Llad\u00f3s", "Josep", ""]]}, {"id": "1004.5538", "submitter": "Francois Orieux", "authors": "Francois Orieux, Jean-Francois Giovannelli, Thomas Rodet", "title": "Bayesian estimation of regularization and PSF parameters for Wiener-Hunt\n  deconvolution", "comments": null, "journal-ref": null, "doi": "10.1364/JOSAA.27.001593", "report-no": null, "categories": "stat.CO cs.CV physics.data-an stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper tackles the problem of image deconvolution with joint estimation\nof PSF parameters and hyperparameters. Within a Bayesian framework, the\nsolution is inferred via a global a posteriori law for unknown parameters and\nobject. The estimate is chosen as the posterior mean, numerically calculated by\nmeans of a Monte-Carlo Markov chain algorithm. The estimates are efficiently\ncomputed in the Fourier domain and the effectiveness of the method is shown on\nsimulated examples. Results show precise estimates for PSF parameters and\nhyperparameters as well as precise image estimates including restoration of\nhigh-frequencies and spatial details, within a global and coherent approach.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2010 14:23:46 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Orieux", "Francois", ""], ["Giovannelli", "Jean-Francois", ""], ["Rodet", "Thomas", ""]]}]