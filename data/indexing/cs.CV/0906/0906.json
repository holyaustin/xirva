[{"id": "0906.0065", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Lee Wei Huynh, Jian Li (Concordia University,\n  Montreal, Canada)", "title": "Managing Distributed MARF with SNMP", "comments": "39 pages, 16 figures, TOC, index. A large portion of this report has\n  been published at PDPTA'08. This 2007 report is a successor of the original\n  DMARF work documented at arXiv:0905.2459 ; v2 adds missing .ind file for the\n  index", "journal-ref": "Proceedings of PDPTA'08 (2008), Volume 2, pp. 948-954", "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The scope of this project's work focuses on the research and prototyping of\nthe extension of the Distributed MARF such that its services can be managed\nthrough the most popular management protocol familiarly, SNMP. The rationale\nbehind SNMP vs. MARF's proprietary management protocols, is that can be\nintegrated with the use of common network service and device management, so the\nadministrators can manage MARF nodes via a already familiar protocol, as well\nas monitor their performance, gather statistics, set desired configuration,\netc. perhaps using the same management tools they've been using for other\nnetwork devices and application servers.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2009 06:42:55 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2009 23:00:45 GMT"}], "update_date": "2009-07-27", "authors_parsed": [["Mokhov", "Serguei A.", "", "Concordia University,\n  Montreal, Canada"], ["Huynh", "Lee Wei", "", "Concordia University,\n  Montreal, Canada"], ["Li", "Jian", "", "Concordia University,\n  Montreal, Canada"]]}, {"id": "0906.0434", "submitter": "Heng Lian", "authors": "Aditya Chopra, Heng Lian", "title": "Total Variation, Adaptive Total Variation and Nonconvex Smoothly Clipped\n  Absolute Deviation Penalty for Denoising Blocky Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The total variation-based image denoising model has been generalized and\nextended in numerous ways, improving its performance in different contexts. We\npropose a new penalty function motivated by the recent progress in the\nstatistical literature on high-dimensional variable selection. Using a\nparticular instantiation of the majorization-minimization algorithm, the\noptimization problem can be efficiently solved and the computational procedure\nrealized is similar to the spatially adaptive total variation model. Our\ntwo-pixel image model shows theoretically that the new penalty function solves\nthe bias problem inherent in the total variation model. The superior\nperformance of the new penalty is demonstrated through several experiments. Our\ninvestigation is limited to \"blocky\" images which have small total variation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2009 07:34:27 GMT"}], "update_date": "2011-07-28", "authors_parsed": [["Chopra", "Aditya", ""], ["Lian", "Heng", ""]]}, {"id": "0906.0667", "submitter": "Harald Kosch", "authors": "Florian Niedermeier, Michael Niedermeier, and Harald Kosch", "title": "Quality assessment of the MPEG-4 scalable video CODEC", "comments": null, "journal-ref": "published in a shorter version at ICIAP 2009 Conference", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the performance of the emerging MPEG-4 SVC CODEC is evaluated.\nIn the first part, a brief introduction on the subject of quality assessment\nand the development of the MPEG-4 SVC CODEC is given. After that, the used test\nmethodologies are described in detail, followed by an explanation of the actual\ntest scenarios. The main part of this work concentrates on the performance\nanalysis of the MPEG-4 SVC CODEC - both objective and subjective.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 09:31:34 GMT"}], "update_date": "2009-06-04", "authors_parsed": [["Niedermeier", "Florian", ""], ["Niedermeier", "Michael", ""], ["Kosch", "Harald", ""]]}, {"id": "0906.1763", "submitter": "Behnood Gholami", "authors": "Behnood Gholami (1), Allen R. Tannenbaum (2 and 3) and Wassim M.\n  Haddad (1) ((1) School of Aerospace Engineering, Georgia Institute of\n  Technology (2) School of Electrical & Computer Engineering, Georgia Institute\n  of Technology, (3) Department of Biomedical Engineering, Georgia Institute of\n  Technology)", "title": "Segmentation of Facial Expressions Using Semi-Definite Programming and\n  Generalized Principal Component Analysis", "comments": "Corrected for typos and spacing errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use semi-definite programming and generalized principal\ncomponent analysis (GPCA) to distinguish between two or more different facial\nexpressions. In the first step, semi-definite programming is used to reduce the\ndimension of the image data and \"unfold\" the manifold which the data points\n(corresponding to facial expressions) reside on. Next, GPCA is used to fit a\nseries of subspaces to the data points and associate each data point with a\nsubspace. Data points that belong to the same subspace are claimed to belong to\nthe same facial expression category. An example is provided.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2009 19:50:10 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2009 20:53:21 GMT"}], "update_date": "2009-06-10", "authors_parsed": [["Gholami", "Behnood", "", "2 and 3"], ["Tannenbaum", "Allen R.", "", "2 and 3"], ["Haddad", "Wassim M.", ""]]}, {"id": "0906.1905", "submitter": "Patrick Guio", "authors": "P. Guio and N. Achilleos", "title": "The VOISE Algorithm: a Versatile Tool for Automatic Segmentation of\n  Astronomical Images", "comments": "9 pages, 7 figures; accepted for publication in MNRAS", "journal-ref": "Mon. Not. R. Astron. Soc. 398 (2009) 1254-1262", "doi": "10.1111/j.1365-2966.2009.15218.x", "report-no": null, "categories": "astro-ph.IM astro-ph.EP cs.CV physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The auroras on Jupiter and Saturn can be studied with a high sensitivity and\nresolution by the Hubble Space Telescope (HST) ultraviolet (UV) and\nfar-ultraviolet (FUV) Space Telescope spectrograph (STIS) and Advanced Camera\nfor Surveys (ACS) instruments. We present results of automatic detection and\nsegmentation of Jupiter's auroral emissions as observed by HST ACS instrument\nwith VOronoi Image SEgmentation (VOISE). VOISE is a dynamic algorithm for\npartitioning the underlying pixel grid of an image into regions according to a\nprescribed homogeneity criterion. The algorithm consists of an iterative\nprocedure that dynamically constructs a tessellation of the image plane based\non a Voronoi Diagram, until the intensity of the underlying image within each\nregion is classified as homogeneous. The computed tessellations allow the\nextraction of quantitative information about the auroral features such as mean\nintensity, latitudinal and longitudinal extents and length scales. These\noutputs thus represent a more automated and objective method of characterising\nauroral emissions than manual inspection.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2009 10:48:33 GMT"}], "update_date": "2009-09-11", "authors_parsed": [["Guio", "P.", ""], ["Achilleos", "N.", ""]]}, {"id": "0906.2716", "submitter": "Jacques-Olivier Lachaud", "authors": "F. De Vieilleville (LaBRI), Jacques-Olivier Lachaud (LaBRI), F.\n  Feschet (LLAIC1)", "title": "Maximal digital straight segments and convergence of discrete geometric\n  estimators", "comments": null, "journal-ref": "Proc. 14th Scandinavian Conference on Image Analysis (SCIA2005),\n  Joensuu : Finlande (2005)", "doi": "10.1007/11499145_100", "report-no": null, "categories": "cs.CV cs.CG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete geometric estimators approach geometric quantities on digitized\nshapes without any knowledge of the continuous shape. A classical yet difficult\nproblem is to show that an estimator asymptotically converges toward the true\ngeometric quantity as the resolution increases. We study here the convergence\nof local estimators based on Digital Straight Segment (DSS) recognition. It is\nclosely linked to the asymptotic growth of maximal DSS, for which we show\nbounds both about their number and sizes. These results not only give better\ninsights about digitized curves but indicate that curvature estimators based on\nlocal DSS recognition are not likely to converge. We indeed invalidate an\nhypothesis which was essential in the only known convergence theorem of a\ndiscrete curvature estimator. The proof involves results from arithmetic\nproperties of digital lines, digital convexity, combinatorics, continued\nfractions and random polytopes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 15:13:42 GMT"}], "update_date": "2009-06-16", "authors_parsed": [["De Vieilleville", "F.", "", "LaBRI"], ["Lachaud", "Jacques-Olivier", "", "LaBRI"], ["Feschet", "F.", "", "LLAIC1"]]}, {"id": "0906.2767", "submitter": "Jacques-Olivier Lachaud", "authors": "Jacques-Olivier Lachaud (LaBRI)", "title": "Coding cells of digital spaces: a framework to write generic digital\n  topology algorithms", "comments": null, "journal-ref": "Proc. Int. Work. Combinatorial Image Analysis (IWCIA2003), Palermo\n  : Italie (2003)", "doi": "10.1016/S1571-0653(04)00497-4", "report-no": null, "categories": "cs.DM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a concise coding of the cells of n-dimensional finite\nregular grids. It induces a simple, generic and efficient framework for\nimplementing classical digital topology data structures and algorithms.\nDiscrete subsets of multidimensional images (e.g. regions, digital surfaces,\ncubical cell complexes) have then a common and compact representation.\nMoreover, algorithms have a straightforward and efficient implementation, which\nis independent from the dimension or sizes of digital images. We illustrate\nthat point with generic hypersurface boundary extraction algorithms by scanning\nor tracking. This framework has been implemented and basic operations as well\nas the presented applications have been benchmarked.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 19:32:48 GMT"}], "update_date": "2009-06-16", "authors_parsed": [["Lachaud", "Jacques-Olivier", "", "LaBRI"]]}, {"id": "0906.2770", "submitter": "Jacques-Olivier Lachaud", "authors": "Martin Braure De Calignon (LaBRI), Luc Brun (GREYC), Jacques-Olivier\n  Lachaud (LaBRI)", "title": "Combinatorial pyramids and discrete geometry for energy-minimizing\n  segmentation", "comments": null, "journal-ref": "Proc. Int. Symposium on Visual Computing (ISVC2006), Lake Tahoe,\n  Nevada : \\'Etats-Unis d'Am\\'erique (2006)", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines the basis of a new hierarchical framework for segmentation\nalgorithms based on energy minimization schemes. This new framework is based on\ntwo formal tools. First, a combinatorial pyramid encode efficiently a hierarchy\nof partitions. Secondly, discrete geometric estimators measure precisely some\nimportant geometric parameters of the regions. These measures combined with\nphotometrical and topological features of the partition allows to design energy\nterms based on discrete measures. Our segmentation framework exploits these\nenergies to build a pyramid of image partitions with a minimization scheme.\nSome experiments illustrating our framework are shown and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2009 19:33:21 GMT"}], "update_date": "2009-06-16", "authors_parsed": [["De Calignon", "Martin Braure", "", "LaBRI"], ["Brun", "Luc", "", "GREYC"], ["Lachaud", "Jacques-Olivier", "", "LaBRI"]]}, {"id": "0906.3068", "submitter": "Jacques-Olivier Lachaud", "authors": "Jacques-Olivier Lachaud (LaBRI), Benjamin Taton (LaBRI)", "title": "Deformable Model with a Complexity Independent from Image Resolution", "comments": null, "journal-ref": "Computer Vision and Image Understanding 99 (2005) 453-475", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parametric deformable model which recovers image components with\na complexity independent from the resolution of input images. The proposed\nmodel also automatically changes its topology and remains fully compatible with\nthe general framework of deformable models. More precisely, the image space is\nequipped with a metric that expands salient image details according to their\nstrength and their curvature. During the whole evolution of the model, the\nsampling of the contour is kept regular with respect to this metric. By this\nway, the vertex density is reduced along most parts of the curve while a high\nquality of shape representation is preserved. The complexity of the deformable\nmodel is thus improved and is no longer influenced by feature-preserving\nchanges in the resolution of input images. Building the metric requires a prior\nestimation of contour curvature. It is obtained using a robust estimator which\ninvestigates the local variations in the orientation of image gradient.\nExperimental results on both computer generated and biomedical images are\npresented to illustrate the advantages of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 04:42:39 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Lachaud", "Jacques-Olivier", "", "LaBRI"], ["Taton", "Benjamin", "", "LaBRI"]]}, {"id": "0906.3323", "submitter": "Andriy Myronenko", "authors": "Andriy Myronenko, Xubo Song", "title": "Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid\n  Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an adaptive regularization approach. In contrast to conventional\nTikhonov regularization, which specifies a fixed regularization operator, we\nestimate it simultaneously with parameters. From a Bayesian perspective we\nestimate the prior distribution on parameters assuming that it is close to some\ngiven model distribution. We constrain the prior distribution to be a\nGauss-Markov random field (GMRF), which allows us to solve for the prior\ndistribution analytically and provides a fast optimization algorithm. We apply\nour approach to non-rigid image registration to estimate the spatial\ntransformation between two images. Our evaluation shows that the adaptive\nregularization approach significantly outperforms standard variational methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 23:24:38 GMT"}], "update_date": "2009-06-19", "authors_parsed": [["Myronenko", "Andriy", ""], ["Song", "Xubo", ""]]}, {"id": "0906.3585", "submitter": "Arnab Bhattacharya", "authors": "Vishwakarma Singh, Arnab Bhattacharya, Ambuj K. Singh", "title": "Finding Significant Subregions in Large Image Databases", "comments": "16 pages, 48 figures", "journal-ref": "Extending Database Technology (EDBT) 2010", "doi": null, "report-no": null, "categories": "cs.DB cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images have become an important data source in many scientific and commercial\ndomains. Analysis and exploration of image collections often requires the\nretrieval of the best subregions matching a given query. The support of such\ncontent-based retrieval requires not only the formulation of an appropriate\nscoring function for defining relevant subregions but also the design of new\naccess methods that can scale to large databases. In this paper, we propose a\nsolution to this problem of querying significant image subregions. We design a\nscoring scheme to measure the similarity of subregions. Our similarity measure\nextends to any image descriptor. All the images are tiled and each alignment of\nthe query and a database image produces a tile score matrix. We show that the\nproblem of finding the best connected subregion from this matrix is NP-hard and\ndevelop a dynamic programming heuristic. With this heuristic, we develop two\nindex based scalable search strategies, TARS and SPARS, to query patterns in a\nlarge image repository. These strategies are general enough to work with other\nscoring schemes and heuristics. Experimental results on real image datasets\nshow that TARS saves more than 87% query time on small queries, and SPARS saves\nup to 52% query time on large queries as compared to linear search. Qualitative\ntests on synthetic and real datasets achieve precision of more than 80%.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2009 06:57:51 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Singh", "Vishwakarma", ""], ["Bhattacharya", "Arnab", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "0906.3722", "submitter": "Nidhal Bouaynaya", "authors": "Nidhal Bouaynaya, Jerzy Zielinski and Dan Schonfeld", "title": "Two-Dimensional ARMA Modeling for Breast Cancer Detection and\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model-based computer-aided diagnosis (CAD) system for tumor\ndetection and classification (cancerous v.s. benign) in breast images.\nSpecifically, we show that (x-ray, ultrasound and MRI) images can be accurately\nmodeled by two-dimensional autoregressive-moving average (ARMA) random fields.\nWe derive a two-stage Yule-Walker Least-Squares estimates of the model\nparameters, which are subsequently used as the basis for statistical inference\nand biophysical interpretation of the breast image. We use a k-means classifier\nto segment the breast image into three regions: healthy tissue, benign tumor,\nand cancerous tumor. Our simulation results on ultrasound breast images\nillustrate the power of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2009 17:56:16 GMT"}], "update_date": "2009-06-22", "authors_parsed": [["Bouaynaya", "Nidhal", ""], ["Zielinski", "Jerzy", ""], ["Schonfeld", "Dan", ""]]}, {"id": "0906.3770", "submitter": "R Doomun", "authors": "G. M. Atiqur Rahaman, Md. Mobarak Hossain", "title": "Automatic Defect Detection and Classification Technique from Image: A\n  Special Case Using Ceramic Tiles", "comments": "9 pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "IJCSIS, June 2009, Vol. 1", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality control is an important issue in the ceramic tile industry. On the\nother hand maintaining the rate of production with respect to time is also a\nmajor issue in ceramic tile manufacturing. Again, price of ceramic tiles also\ndepends on purity of texture, accuracy of color, shape etc. Considering this\ncriteria, an automated defect detection and classification technique has been\nproposed in this report that can have ensured the better quality of tiles in\nmanufacturing process as well as production rate. Our proposed method plays an\nimportant role in ceramic tiles industries to detect the defects and to control\nthe quality of ceramic tiles. This automated classification method helps us to\nacquire knowledge about the pattern of defect within a very short period of\ntime and also to decide about the recovery process so that the defected tiles\nmay not be mixed with the fresh tiles.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2009 03:00:37 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Rahaman", "G. M. Atiqur", ""], ["Hossain", "Md. Mobarak", ""]]}, {"id": "0906.4036", "submitter": "Hongyu Lu", "authors": "Hongyu Lu, Shanglian Bao", "title": "Physical Modeling Techniques in Active Contours for Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Physical modeling method, represented by simulation and visualization of the\nprinciples in physics, is introduced in the shape extraction of the active\ncontours. The objectives of adopting this concept are to address the several\nmajor difficulties in the application of Active Contours. Primarily, a\ntechnique is developed to realize the topological changes of Parametric Active\nContours (Snakes). The key strategy is to imitate the process of a balloon\nexpanding and filling in a closed space with several objects. After removing\nthe touched balloon surfaces, the objects can be identified by surrounded\nremaining balloon surfaces. A burned region swept by Snakes is utilized to\ntrace the contour and to give a criterion for stopping the movement of Snake\ncurve. When the Snakes terminates evolution totally, through ignoring this\ncriterion, it can form a connected area by evolving the Snakes again and\ncontinuing the region burning. The contours extracted from the boundaries of\nthe burned area can represent the child snake of each object respectively.\nSecondly, a novel scheme is designed to solve the problems of leakage of the\ncontour from the large gaps, and the segmentation error in Geometric Active\nContours (GAC). It divides the segmentation procedure into two processing\nstages. By simulating the wave propagating in the isotropic substance at the\nfinal stage, it can significantly enhance the effect of image force in GAC\nbased on Level Set and give the satisfied solutions to the two problems.\nThirdly, to support the physical models for active contours above, we introduce\na general image force field created on a template plane over the image plane.\nThis force is more adaptable to noisy images with complicated geometric shapes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 16:38:30 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2009 03:03:04 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2009 15:53:02 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Lu", "Hongyu", ""], ["Bao", "Shanglian", ""]]}, {"id": "0906.4131", "submitter": "Josna Rao", "authors": "Josna Rao, Ghassan Hamarneh, Rafeef Abugharbieh", "title": "Automatic Spatially-Adaptive Balancing of Energy Terms for Image\n  Segmentation", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation techniques are predominately based on parameter-laden\noptimization. The objective function typically involves weights for balancing\ncompeting image fidelity and segmentation regularization cost terms. Setting\nthese weights suitably has been a painstaking, empirical process. Even if such\nideal weights are found for a novel image, most current approaches fix the\nweight across the whole image domain, ignoring the spatially-varying properties\nof object shape and image appearance. We propose a novel technique that\nautonomously balances these terms in a spatially-adaptive manner through the\nincorporation of image reliability in a graph-based segmentation framework. We\nvalidate on synthetic data achieving a reduction in mean error of 47% (p-value\n<< 0.05) when compared to the best fixed parameter segmentation. We also\npresent results on medical images (including segmentations of the corpus\ncallosum and brain tissue in MRI data) and on natural images.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 21:10:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2009 21:57:29 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Rao", "Josna", ""], ["Hamarneh", "Ghassan", ""], ["Abugharbieh", "Rafeef", ""]]}, {"id": "0906.4582", "submitter": "Patrick J. Wolfe", "authors": "Mohamed-Ali Belabbas and Patrick J. Wolfe", "title": "On landmark selection and sampling in high-dimensional data analysis", "comments": "18 pages, 6 figures, submitted for publication", "journal-ref": "Philosophical Transactions of the Royal Society, Series A, vol.\n  367, pp. 4295-4312, 2009", "doi": "10.1098/rsta.2009.0161", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the spectral analysis of appropriately defined kernel\nmatrices has emerged as a principled way to extract the low-dimensional\nstructure often prevalent in high-dimensional data. Here we provide an\nintroduction to spectral methods for linear and nonlinear dimension reduction,\nemphasizing ways to overcome the computational limitations currently faced by\npractitioners with massive datasets. In particular, a data subsampling or\nlandmark selection process is often employed to construct a kernel based on\npartial information, followed by an approximate spectral analysis termed the\nNystrom extension. We provide a quantitative framework to analyse this\nprocedure, and use it to demonstrate algorithmic performance bounds on a range\nof practical approaches designed to optimize the landmark selection process. We\ncompare the practical implications of these bounds by way of real-world\nexamples drawn from the field of computer vision, whereby low-dimensional\nmanifold structure is shown to emerge from high-dimensional video data streams.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2009 23:40:22 GMT"}], "update_date": "2010-04-20", "authors_parsed": [["Belabbas", "Mohamed-Ali", ""], ["Wolfe", "Patrick J.", ""]]}, {"id": "0906.4789", "submitter": "R Doomun", "authors": "Amir Azizi, Hamid Reza Pourreza", "title": "Efficient IRIS Recognition through Improvement of Feature Extraction and\n  subset Selection", "comments": "10 pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS JUne 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of the optimal feature subset and the classification has become\nan important issue in the field of iris recognition. In this paper we propose\nseveral methods for iris feature subset selection and vector creation. The\ndeterministic feature sequence is extracted from the iris image by using the\ncontourlet transform technique. Contourlet transform captures the intrinsic\ngeometrical structures of iris image. It decomposes the iris image into a set\nof directional sub-bands with texture details captured in different\norientations at various scales so for reducing the feature vector dimensions we\nuse the method for extract only significant bit and information from normalized\niris images. In this method we ignore fragile bits. And finally we use SVM\n(Support Vector Machine) classifier for approximating the amount of people\nidentification in our proposed system. Experimental result show that most\nproposed method reduces processing time and increase the classification\naccuracy and also the iris feature vector length is much smaller versus the\nother methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 20:14:42 GMT"}], "update_date": "2009-06-29", "authors_parsed": [["Azizi", "Amir", ""], ["Pourreza", "Hamid Reza", ""]]}, {"id": "0906.5039", "submitter": "R Doomun", "authors": "Ahmed Ben Jmaa, Walid Mahdi, Yousra Ben Jemaa, Abdelmajid Ben Hamadou", "title": "A new approach for digit recognition based on hand gesture analysis", "comments": "8 Pages, International Journal of Computer Science and Information\n  Security", "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a new approach for hand gesture analysis that allows\ndigit recognition. The analysis is based on extracting a set of features from a\nhand image and then combining them by using an induction graph. The most\nimportant features we extract from each image are the fingers locations, their\nheights and the distance between each pair of fingers. Our approach consists of\nthree steps: (i) Hand detection and localization, (ii) fingers extraction and\n(iii) features identification and combination to digit recognition. Each input\nimage is assumed to contain only one person, thus we apply a fuzzy classifier\nto identify the skin pixels. In the finger extraction step, we attempt to\nremove all the hand components except the fingers, this process is based on the\nhand anatomy properties. The final step consists on representing histogram of\nthe detected fingers in order to extract features that will be used for digit\nrecognition. The approach is invariant to scale, rotation and translation of\nthe hand. Some experiments have been undertaken to show the effectiveness of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2009 04:46:23 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Jmaa", "Ahmed Ben", ""], ["Mahdi", "Walid", ""], ["Jemaa", "Yousra Ben", ""], ["Hamadou", "Abdelmajid Ben", ""]]}, {"id": "0906.5120", "submitter": "Arnaud Martin", "authors": "Jean Dezert (ONERA), Arnaud Martin (E3I2), Florentin Smarandache (UNM)", "title": "Comments on \"A new combination of evidence based on compromise\" by K.\n  Yamada", "comments": null, "journal-ref": "Fuzzy Sets and Systems 160, 6 (2009) 853-855", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comments on ``A new combination of evidence based on compromise'' by K.\nYamada\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2009 08:10:33 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Dezert", "Jean", "", "ONERA"], ["Martin", "Arnaud", "", "E3I2"], ["Smarandache", "Florentin", "", "UNM"]]}]