[{"id": "1211.0055", "submitter": "ELkebir Sarhrouni", "authors": "Elkebir Sarhrouni, Ahmed Hammouch and Driss Aboutajdine", "title": "Dimensionality Reduction and Classification Feature Using Mutual\n  Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm\n  Based on Minimizing the Error Probability Using the Inequality of Fano", "comments": "12 page, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1210.0528, arXiv:1210.0052", "journal-ref": "Applied Mathematical Sciences, Vol. 6, 2012, no. 102, 5073 - 5084", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In the feature classification domain, the choice of data affects widely the\nresults. For the Hyperspectral image, the bands dont all contain the\ninformation; some bands are irrelevant like those affected by various\natmospheric effects, see Figure.4, and decrease the classification accuracy.\nAnd there exist redundant bands to complicate the learning system and product\nincorrect prediction [14]. Even the bands contain enough information about the\nscene they may can't predict the classes correctly if the dimension of space\nimages, see Figure.3, is so large that needs many cases to detect the\nrelationship between the bands and the scene (Hughes phenomenon) [10]. We can\nreduce the dimensionality of hyperspectral images by selecting only the\nrelevant bands (feature selection or subset selection methodology), or\nextracting, from the original bands, new bands containing the maximal\ninformation about the classes, using any functions, logical or numerical\n(feature extraction methodology) [11][9]. Here we focus on the feature\nselection using mutual information. Hyperspectral images have three advantages\nregarding the multispectral images [6],\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 23:30:59 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Sarhrouni", "Elkebir", ""], ["Hammouch", "Ahmed", ""], ["Aboutajdine", "Driss", ""]]}, {"id": "1211.0135", "submitter": "Jayakrishnan Unnikrishnan", "authors": "Jayakrishnan Unnikrishnan and Martin Vetterli", "title": "Sampling and Reconstruction of Spatial Fields using Mobile Sensors", "comments": "Submitted to IEEE Transactions on Signal Processing May 2012; revised\n  Oct 2012", "journal-ref": null, "doi": "10.1109/TSP.2013.2247599", "report-no": null, "categories": "cs.MM cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial sampling is traditionally studied in a static setting where static\nsensors scattered around space take measurements of the spatial field at their\nlocations. In this paper we study the emerging paradigm of sampling and\nreconstructing spatial fields using sensors that move through space. We show\nthat mobile sensing offers some unique advantages over static sensing in\nsensing time-invariant bandlimited spatial fields. Since a moving sensor\nencounters such a spatial field along its path as a time-domain signal, a\ntime-domain anti-aliasing filter can be employed prior to sampling the signal\nreceived at the sensor. Such a filtering procedure, when used by a\nconfiguration of sensors moving at constant speeds along equispaced parallel\nlines, leads to a complete suppression of spatial aliasing in the direction of\nmotion of the sensors. We analytically quantify the advantage of using such a\nsampling scheme over a static sampling scheme by computing the reduction in\nsampling noise due to the filter. We also analyze the effects of non-uniform\nsensor speeds on the reconstruction accuracy. Using simulation examples we\ndemonstrate the advantages of mobile sampling over static sampling in practical\nproblems.\n  We extend our analysis to sampling and reconstruction schemes for monitoring\ntime-varying bandlimited fields using mobile sensors. We demonstrate that in\nsome situations we require a lower density of sensors when using a mobile\nsensing scheme instead of the conventional static sensing scheme. The exact\nadvantage is quantified for a problem of sampling and reconstructing an audio\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 10:05:46 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Unnikrishnan", "Jayakrishnan", ""], ["Vetterli", "Martin", ""]]}, {"id": "1211.0191", "submitter": "Branko Ristic", "authors": "Branko Ristic, Jamie Sherrah and \\'Angel F. Garc\\'ia-Fern\\'andez", "title": "Performance Evaluation of Random Set Based Pedestrian Tracking\n  Algorithms", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper evaluates the error performance of three random finite set based\nmulti-object trackers in the context of pedestrian video tracking. The\nevaluation is carried out using a publicly available video dataset of 4500\nframes (town centre street) for which the ground truth is available. The input\nto all pedestrian tracking algorithms is an identical set of head and body\ndetections, obtained using the Histogram of Oriented Gradients (HOG) detector.\nThe tracking error is measured using the recently proposed OSPA metric for\ntracks, adopted as the only known mathematically rigorous metric for measuring\nthe distance between two sets of tracks. A comparative analysis is presented\nunder various conditions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 23:21:46 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Ristic", "Branko", ""], ["Sherrah", "Jamie", ""], ["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""]]}, {"id": "1211.0602", "submitter": "Jie Zhao", "authors": "Jie Zhao, Wei Zheng, Li Zhang, Hua Tian", "title": "Segmentation of ultrasound images of thyroid nodule for assisting fine\n  needle aspiration cytology", "comments": "15pages,13figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The incidence of thyroid nodule is very high and generally increases with the\nage. Thyroid nodule may presage the emergence of thyroid cancer. The thyroid\nnodule can be completely cured if detected early. Fine needle aspiration\ncytology is a recognized early diagnosis method of thyroid nodule. There are\nstill some limitations in the fine needle aspiration cytology, and the\nultrasound diagnosis of thyroid nodule has become the first choice for\nauxiliary examination of thyroid nodular disease. If we could combine medical\nimaging technology and fine needle aspiration cytology, the diagnostic rate of\nthyroid nodule would be improved significantly. The properties of ultrasound\nwill degrade the image quality, which makes it difficult to recognize the edges\nfor physicians. Image segmentation technique based on graph theory has become a\nresearch hotspot at present. Normalized cut (Ncut) is a representative one,\nwhich is suitable for segmentation of feature parts of medical image. However,\nhow to solve the normalized cut has become a problem, which needs large memory\ncapacity and heavy calculation of weight matrix. It always generates over\nsegmentation or less segmentation which leads to inaccurate in the\nsegmentation. The speckle noise in B ultrasound image of thyroid tumor makes\nthe quality of the image deteriorate. In the light of this characteristic, we\ncombine the anisotropic diffusion model with the normalized cut in this paper.\nAfter the enhancement of anisotropic diffusion model, it removes the noise in\nthe B ultrasound image while preserves the important edges and local details.\nThis reduces the amount of computation in constructing the weight matrix of the\nimproved normalized cut and improves the accuracy of the final segmentation\nresults. The feasibility of the method is proved by the experimental results.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2012 06:55:03 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Zhao", "Jie", ""], ["Zheng", "Wei", ""], ["Zhang", "Li", ""], ["Tian", "Hua", ""]]}, {"id": "1211.0613", "submitter": "ELkebir Sarhrouni", "authors": "ELkebir Sarhrouni, Ahmed Hammouch and Driss Aboutajdine", "title": "Application of Symmetric Uncertainty and Mutual Information to\n  Dimensionality Reduction and Classification of Hyperspectral Images", "comments": "14 pages, 7 Figure, 2 Tables, Paper keywords: Hyperspectral images,\n  Classification, Feature Selection, Mutual information, Redundancy. arXiv\n  admin note: text overlap with arXiv:1210.0052, arXiv:1211.0055", "journal-ref": "International Journal of Engineering and Technology (IJET)\n  VOL:4({\\deg}5).P. 268--276. 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Remote sensing is a technology to acquire data for disatant substances,\nnecessary to construct a model knowledge for applications as classification.\nRecently Hyperspectral Images (HSI) becomes a high technical tool that the main\ngoal is to classify the point of a region. The HIS is more than a hundred\nbidirectional measures, called bands (or simply images), of the same region\ncalled Ground Truth Map (GT). But some bands are not relevant because they are\naffected by different atmospheric effects; others contain redundant\ninformation; and high dimensionality of HSI features make the accuracy of\nclassification lower. All these bands can be important for some applications;\nbut for the classification a small subset of these is relevant. The problematic\nrelated to HSI is the dimensionality reduction. Many studies use mutual\ninformation (MI) to select the relevant bands. Others studies use the MI\nnormalized forms, like Symmetric Uncertainty, in medical imagery applications.\nIn this paper we introduce an algorithm based also on MI to select relevant\nbands and it apply the Symmetric Uncertainty coefficient to control redundancy\nand increase the accuracy of classification. This algorithm is feature\nselection tool and a Filter strategy. We establish this study on HSI AVIRIS\n92AV3C. This is an effectiveness, and fast scheme to control redundancy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2012 14:01:29 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 23:35:05 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Sarhrouni", "ELkebir", ""], ["Hammouch", "Ahmed", ""], ["Aboutajdine", "Driss", ""]]}, {"id": "1211.0757", "submitter": "Ju Sun", "authors": "Ju Sun, Yuqian Zhang, John Wright", "title": "Efficient Point-to-Subspace Query in $\\ell^1$: Theory and Applications\n  in Computer Vision", "comments": "To appear in NIPS workshop on big learning, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Motivated by vision tasks such as robust face and object recognition, we\nconsider the following general problem: given a collection of low-dimensional\nlinear subspaces in a high-dimensional ambient (image) space and a query point\n(image), efficiently determine the nearest subspace to the query in $\\ell^1$\ndistance. We show in theory that Cauchy random embedding of the objects into\nsignificantly-lower-dimensional spaces helps preserve the identity of the\nnearest subspace with constant probability. This offers the possibility of\nefficiently selecting several candidates for accurate search. We sketch\npreliminary experiments on robust face and digit recognition to corroborate our\ntheory.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 04:15:25 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Sun", "Ju", ""], ["Zhang", "Yuqian", ""], ["Wright", "John", ""]]}, {"id": "1211.1127", "submitter": "Erik Rodner", "authors": "Erik Rodner", "title": "Visual Transfer Learning: Informal Introduction and Literature Overview", "comments": "part of my PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning techniques are important to handle small training sets and\nto allow for quick generalization even from only a few examples. The following\npaper is the introduction as well as the literature overview part of my thesis\nrelated to the topic of transfer learning for visual recognition problems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 07:26:49 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Rodner", "Erik", ""]]}, {"id": "1211.1252", "submitter": "Md. Hossain Ali", "authors": "Md. Ali Hossain, Ahsan-Ul-Ambia, Md.Aktaruzzaman, Md. Ahaduzzaman Khan", "title": "Implementation of Radon Transformation for Electrical Impedance\n  Tomography (EIT)", "comments": "12 pages", "journal-ref": "International Journal of Information Sciences and Techniques\n  (IJIST) Vol.2, No.5, September 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radon Transformation is generally used to construct optical image (like CT\nimage) from the projection data in biomedical imaging. In this paper, the\nconcept of Radon Transformation is implemented to reconstruct Electrical\nImpedance Topographic Image (conductivity or resistivity distribution) of a\ncircular subject. A parallel resistance model of a subject is proposed for\nElectrical Impedance Topography(EIT) or Magnetic Induction Tomography(MIT). A\ncircular subject with embedded circular objects is segmented into equal width\nslices from different angles. For each angle, Conductance and Conductivity of\neach slice is calculated and stored in an array. A back projection method is\nused to generate a two-dimensional image from one-dimensional projections. As a\nback projection method, Inverse Radon Transformation is applied on the\ncalculated conductance and conductivity to reconstruct two dimensional images.\nThese images are compared to the target image. In the time of image\nreconstruction, different filters are used and these images are compared with\neach other and target image.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 09:46:12 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Hossain", "Md. Ali", ""], ["Ahsan-Ul-Ambia", "", ""], ["Aktaruzzaman", "Md.", ""], ["Khan", "Md. Ahaduzzaman", ""]]}, {"id": "1211.1255", "submitter": "Antonio Giuliano Zippo Dr.", "authors": "Antonio G. Zippo, Giuliana Gelsomino, Sara Nencini, Gabriele E. M.\n  Biella", "title": "Handwritten digit recognition by bio-inspired hierarchical networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain processes information showing learning and prediction\nabilities but the underlying neuronal mechanisms still remain unknown.\nRecently, many studies prove that neuronal networks are able of both\ngeneralizations and associations of sensory inputs. In this paper, following a\nset of neurophysiological evidences, we propose a learning framework with a\nstrong biological plausibility that mimics prominent functions of cortical\ncircuitries. We developed the Inductive Conceptual Network (ICN), that is a\nhierarchical bio-inspired network, able to learn invariant patterns by\nVariable-order Markov Models implemented in its nodes. The outputs of the\ntop-most node of ICN hierarchy, representing the highest input generalization,\nallow for automatic classification of inputs. We found that the ICN clusterized\nMNIST images with an error of 5.73% and USPS images with an error of 12.56%.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 15:15:48 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Zippo", "Antonio G.", ""], ["Gelsomino", "Giuliana", ""], ["Nencini", "Sara", ""], ["Biella", "Gabriele E. M.", ""]]}, {"id": "1211.1265", "submitter": "Emmanuel d'Angelo", "authors": "Emmanuel d'Angelo, Laurent jacques, Alexandre Alahi, Pierre\n  Vandergheynst", "title": "From Bits to Images: Inversion of Local Binary Descriptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Binary Descriptors are becoming more and more popular for image\nmatching tasks, especially when going mobile. While they are extensively\nstudied in this context, their ability to carry enough information in order to\ninfer the original image is seldom addressed.\n  In this work, we leverage an inverse problem approach to show that it is\npossible to directly reconstruct the image content from Local Binary\nDescriptors. This process relies on very broad assumptions besides the\nknowledge of the pattern of the descriptor at hand. This generalizes previous\nresults that required either a prior learning database or non-binarized\nfeatures.\n  Furthermore, our reconstruction scheme reveals differences in the way\ndifferent Local Binary Descriptors capture and encode image information. Hence,\nthe potential applications of our work are multiple, ranging from privacy\nissues caused by eavesdropping image keypoints streamed by mobile devices to\nthe design of better descriptors through the visualization and the analysis of\ntheir geometric content.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 15:32:34 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["d'Angelo", "Emmanuel", ""], ["jacques", "Laurent", ""], ["Alahi", "Alexandre", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1211.1482", "submitter": "Sajid Ali", "authors": "Sajid Ali", "title": "Gender Recognition in Walk Gait through 3D Motion by Quadratic Bezier\n  Curve and Statistical Techniques", "comments": "wrongly uploaded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion capture is the process of recording the movement of objects or people.\nIt is used in military, entertainment, sports, and medical applications, and\nfor validation of computer vision[2] and robotics. In filmmaking and video game\ndevelopment, it refers to recording actions of human actors, and using that\ninformation to animate digital character models in 2D or 3D computer animation.\nWhen it includes face and fingers or captures subtle\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 08:19:04 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2013 02:50:52 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2013 04:05:00 GMT"}, {"version": "v4", "created": "Wed, 16 Jan 2013 03:05:42 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Ali", "Sajid", ""]]}, {"id": "1211.1544", "submitter": "Harold Christopher Burger Harold Christopher Burger", "authors": "Harold Christopher Burger, Christian J. Schuler, Stefan Harmeling", "title": "Image denoising with multi-layer perceptrons, part 1: comparison with\n  existing algorithms and with bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising can be described as the problem of mapping from a noisy image\nto a noise-free image. The best currently available denoising methods\napproximate this mapping with cleverly engineered algorithms. In this work we\nattempt to learn this mapping directly with plain multi layer perceptrons (MLP)\napplied to image patches. We will show that by training on large image\ndatabases we are able to outperform the current state-of-the-art image\ndenoising methods. In addition, our method achieves results that are superior\nto one type of theoretical bound and goes a large way toward closing the gap\nwith a second type of theoretical bound. Our approach is easily adapted to less\nextensively studied types of noise, such as mixed Poisson-Gaussian noise, JPEG\nartifacts, salt-and-pepper noise and noise resembling stripes, for which we\nachieve excellent results as well. We will show that combining a block-matching\nprocedure with MLPs can further improve the results on certain images. In a\nsecond paper, we detail the training trade-offs and the inner mechanisms of our\nMLPs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 13:35:52 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2012 09:23:10 GMT"}, {"version": "v3", "created": "Fri, 9 Nov 2012 10:36:22 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Burger", "Harold Christopher", ""], ["Schuler", "Christian J.", ""], ["Harmeling", "Stefan", ""]]}, {"id": "1211.1552", "submitter": "Harold Christopher Burger Harold Christopher Burger", "authors": "Harold Christopher Burger, Christian J. Schuler, Stefan Harmeling", "title": "Image denoising with multi-layer perceptrons, part 2: training\n  trade-offs and analysis of their mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising can be described as the problem of mapping from a noisy image\nto a noise-free image. In another paper, we show that multi-layer perceptrons\ncan achieve outstanding image denoising performance for various types of noise\n(additive white Gaussian noise, mixed Poisson-Gaussian noise, JPEG artifacts,\nsalt-and-pepper noise and noise resembling stripes). In this work we discuss in\ndetail which trade-offs have to be considered during the training procedure. We\nwill show how to achieve good results and which pitfalls to avoid. By analysing\nthe activation patterns of the hidden units we are able to make observations\nregarding the functioning principle of multi-layer perceptrons trained for\nimage denoising.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 13:50:19 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Burger", "Harold Christopher", ""], ["Schuler", "Christian J.", ""], ["Harmeling", "Stefan", ""]]}, {"id": "1211.1650", "submitter": "Jaswinder  Dilawari Singh", "authors": "Jaswinder Singh Dilawari and Ravinder Khanna", "title": "Different Operating Systems Compatible for Image Prepress Process in\n  Color Management: Analysis and Performance Testing", "comments": "6 Pages", "journal-ref": "International Journal of Electrical, Electronics and Computer\n  Systems, Volume 11, Issue1, November2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image computing has become a real catchphrase over the past few years and the\ninterpretations of the meaning of the term vary greatly. The Imagecomputing\nmarket is currently rapidly evolving with high growth prospects and almost\ndaily announcements of new devices and application platforms, which results in\nan increasing diversification of devices, operating system and development\nplatforms. Compared to more traditional information technology markets like the\none of desktop computing, mobile computing is much less consolidated and\nneither standards nor even industry standards have yet been established. There\nare various platforms and interfaces which may be used to perform the desired\ntasks through the device. We have tried to compare the various mobile operating\nsystems and their trade-offs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 19:52:50 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Dilawari", "Jaswinder Singh", ""], ["Khanna", "Ravinder", ""]]}, {"id": "1211.1654", "submitter": "Yue Wu", "authors": "Yue Wu, Sos Agaian, and Joseph P. Noonan", "title": "A New Randomness Evaluation Method with Applications to Image Shuffling\n  and Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter discusses the problem of testing the degree of randomness within\nan image, particularly for a shuffled or encrypted image. Its key contributions\nare: 1) a mathematical model of perfectly shuffled images; 2) the derivation of\nthe theoretical distribution of pixel differences; 3) a new $Z$-test based\napproach to differentiate whether or not a test image is perfectly shuffled;\nand 4) a randomized algorithm to unbiasedly evaluate the degree of randomness\nwithin a given image. Simulation results show that the proposed method is\nrobust and effective in evaluating the degree of randomness within an image,\nand may often be more suitable for image applications than commonly used\ntesting schemes designed for binary data like NIST 800-22. The developed method\nmay be also useful as a first step in determining whether or not a shuffling or\nencryption scheme is suitable for a particular cryptographic application.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 19:57:13 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Wu", "Yue", ""], ["Agaian", "Sos", ""], ["Noonan", "Joseph P.", ""]]}, {"id": "1211.1656", "submitter": "Yue Wu", "authors": "Yue Wu, Brian Tracey, and Joseph P. Noonan", "title": "James-Stein Type Center Pixel Weights for Non-Local Means Image\n  Denoising", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2013.2247755", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Local Means (NLM) and variants have been proven to be effective and\nrobust in many image denoising tasks. In this letter, we study the parameter\nselection problem of center pixel weights (CPW) in NLM. Our key contributions\nare: 1) we give a novel formulation of the CPW problem from the statistical\nshrinkage perspective; 2) we introduce the James-Stein type CPWs for NLM; and\n3) we propose a new adaptive CPW that is locally tuned for each image pixel.\nOur experimental results showed that compared to existing CPW solutions, the\nnew proposed CPWs are more robust and effective under various noise levels. In\nparticular, the NLM with the James-Stein type CPWs attain higher means with\nsmaller variances in terms of the peak signal and noise ratio, implying they\nimprove the NLM robustness and make it less sensitive to parameter selection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 20:10:24 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Wu", "Yue", ""], ["Tracey", "Brian", ""], ["Noonan", "Joseph P.", ""]]}, {"id": "1211.1690", "submitter": "Debadeepta Dey", "authors": "Stephane Ross, Narek Melik-Barkhudarov, Kumar Shaurya Shankar, Andreas\n  Wendel, Debadeepta Dey, J. Andrew Bagnell, Martial Hebert", "title": "Learning Monocular Reactive UAV Control in Cluttered Natural\n  Environments", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous navigation for large Unmanned Aerial Vehicles (UAVs) is fairly\nstraight-forward, as expensive sensors and monitoring devices can be employed.\nIn contrast, obstacle avoidance remains a challenging task for Micro Aerial\nVehicles (MAVs) which operate at low altitude in cluttered environments. Unlike\nlarge vehicles, MAVs can only carry very light sensors, such as cameras, making\nautonomous navigation through obstacles much more challenging. In this paper,\nwe describe a system that navigates a small quadrotor helicopter autonomously\nat low altitude through natural forest environments. Using only a single cheap\ncamera to perceive the environment, we are able to maintain a constant velocity\nof up to 1.5m/s. Given a small set of human pilot demonstrations, we use recent\nstate-of-the-art imitation learning techniques to train a controller that can\navoid trees by adapting the MAVs heading. We demonstrate the performance of our\nsystem in a more controlled environment indoors, and in real natural forest\nenvironments outdoors.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 21:20:23 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Ross", "Stephane", ""], ["Melik-Barkhudarov", "Narek", ""], ["Shankar", "Kumar Shaurya", ""], ["Wendel", "Andreas", ""], ["Dey", "Debadeepta", ""], ["Bagnell", "J. Andrew", ""], ["Hebert", "Martial", ""]]}, {"id": "1211.1752", "submitter": "Abhishek Anand Abhishek", "authors": "Abhishek Anand and Sherwin Li", "title": "3D Scene Grammar for Parsing RGB-D Pointclouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We pose 3D scene-understanding as a problem of parsing in a grammar. A\ngrammar helps us capture the compositional structure of real-word objects,\ne.g., a chair is composed of a seat, a back-rest and some legs. Having multiple\nrules for an object helps us capture structural variations in objects, e.g., a\nchair can optionally also have arm-rests. Finally, having rules to capture\ncomposition at different levels helps us formulate the entire scene-processing\npipeline as a single problem of finding most likely parse-tree---small segments\ncombine to form parts of objects, parts to objects and objects to a scene. We\nattach a generative probability model to our grammar by having a\nfeature-dependent probability function for every rule. We evaluated it by\nextracting labels for every segment and comparing the results with the\nstate-of-the-art segment-labeling algorithm. Our algorithm was outperformed by\nthe state-or-the-art method. But, Our model can be trained very efficiently\n(within seconds), and it scales only linearly in with the number of rules in\nthe grammar. Also, we think that this is an important problem for the 3D vision\ncommunity. So, we are releasing our dataset and related code.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2012 03:11:53 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Anand", "Abhishek", ""], ["Li", "Sherwin", ""]]}, {"id": "1211.1800", "submitter": "Hamdi Hassen Hamdi Hassen", "authors": "Hamdi Hassen and Maher khemakhem", "title": "A Comparative study of Arabic handwritten characters invariant feature", "comments": null, "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 2, No. 12, 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper is practically interested in the unchangeable feature of Arabic\nhandwritten character. It presents results of comparative study achieved on\ncertain features extraction techniques of handwritten character, based on Hough\ntransform, Fourier transform, Wavelet transform and Gabor Filter. Obtained\nresults show that Hough Transform and Gabor filter are insensible to the\nrotation and translation, Fourier Transform is sensible to the rotation but\ninsensible to the translation, in contrast to Hough Transform and Gabor filter,\nWavelets Transform is sensitive to the rotation as well as to the translation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2012 09:24:21 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Hassen", "Hamdi", ""], ["khemakhem", "Maher", ""]]}, {"id": "1211.1893", "submitter": "Sofia Karygianni", "authors": "Sofia Karygianni and Pascal Frossard", "title": "Tangent-based manifold approximation with locally linear models", "comments": null, "journal-ref": null, "doi": "10.1016/j.sigpro.2014.03.047", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of manifold approximation with affine\nsubspaces. Our objective is to discover a set of low dimensional affine\nsubspaces that represents manifold data accurately while preserving the\nmanifold's structure. For this purpose, we employ a greedy technique that\npartitions manifold samples into groups that can be each approximated by a low\ndimensional subspace. We start by considering each manifold sample as a\ndifferent group and we use the difference of tangents to determine appropriate\ngroup mergings. We repeat this procedure until we reach the desired number of\nsample groups. The best low dimensional affine subspaces corresponding to the\nfinal groups constitute our approximate manifold representation. Our\nexperiments verify the effectiveness of the proposed scheme and show its\nsuperior performance compared to state-of-the-art methods for manifold\napproximation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 19:13:21 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Karygianni", "Sofia", ""], ["Frossard", "Pascal", ""]]}, {"id": "1211.1968", "submitter": "Zhizhen Zhao", "authors": "Zhizhen Zhao and Amit Singer", "title": "Fourier-Bessel rotational invariant eigenimages", "comments": "7 pages", "journal-ref": "JOSA A, Vol. 30, Issue 5, pp. 871-877 (2013)", "doi": "10.1364/JOSAA.30.000871", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient and accurate algorithm for principal component\nanalysis (PCA) of a large set of two dimensional images, and, for each image,\nthe set of its uniform rotations in the plane and its reflection. The algorithm\nstarts by expanding each image, originally given on a Cartesian grid, in the\nFourier-Bessel basis for the disk. Because the images are bandlimited in the\nFourier domain, we use a sampling criterion to truncate the Fourier-Bessel\nexpansion such that the maximum amount of information is preserved without the\neffect of aliasing. The constructed covariance matrix is invariant to rotation\nand reflection and has a special block diagonal structure. PCA is efficiently\ndone for each block separately. This Fourier-Bessel based PCA detects more\nmeaningful eigenimages and has improved denoising capability compared to\ntraditional PCA for a finite number of noisy images.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2012 20:59:49 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2013 20:29:22 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Zhao", "Zhizhen", ""], ["Singer", "Amit", ""]]}, {"id": "1211.2007", "submitter": "Ridha Ejbali", "authors": "Ridha Ejbali, Mourad Zaied and Chokri Ben Amar", "title": "Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic\n  Units for Speech Recognition", "comments": "7 pages, 10 figures", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications,Vol. 3, No.4, 2012, 38-44", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel architecture of wavelet network called\nMulti-input Multi-output Wavelet Network MIMOWN as a generalization of the old\narchitecture of wavelet network. This newel prototype was applied to speech\nrecognition application especially to model acoustic unit of speech. The\noriginality of our work is the proposal of MIMOWN to model acoustic unit of\nspeech. This approach was proposed to overcome limitation of old wavelet\nnetwork model. The use of the multi-input multi-output architecture will allows\ntraining wavelet network on various examples of acoustic units.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2012 22:23:54 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Ejbali", "Ridha", ""], ["Zaied", "Mourad", ""], ["Amar", "Chokri Ben", ""]]}, {"id": "1211.2037", "submitter": "Rehna V J", "authors": "Rehna V. J., M. K. Jeyakumar", "title": "Time Complexity Analysis of Binary Space Partitioning Scheme for Image\n  Compression", "comments": "5 pages, 5 figures, 2 tables, International Journal of Engineering\n  and Innovative Technology; ISSN: 2277-3754 ISO 9001:2008", "journal-ref": "Certified International Journal of Engineering and Innovative\n  Technology (IJEIT) Volume 2, Issue 3, 2012, 109-113", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation-based image coding methods provide high compression ratios when\ncompared with traditional image coding approaches like the transform and sub\nband coding for low bit-rate compression applications. In this paper, a\nsegmentation-based image coding method, namely the Binary Space Partition\nscheme, that divides the desired image using a recursive procedure for coding\nis presented. The BSP approach partitions the desired image recursively by\nusing bisecting lines, selected from a collection of discrete optional lines,\nin a hierarchical manner. This partitioning procedure generates a binary tree,\nwhich is referred to as the BSP-tree representation of the desired image. The\nalgorithm is extremely complex in computation and has high execution time. The\ntime complexity of the BSP scheme is explored in this work.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 03:59:48 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["J.", "Rehna V.", ""], ["Jeyakumar", "M. K.", ""]]}, {"id": "1211.2082", "submitter": "Praveen Kumar P U", "authors": "C. J. Prabhakar and P. U. Praveen Kumar", "title": "3D Surface Reconstruction of Underwater Objects", "comments": "International Journal of Computer Applications (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel technique to reconstruct 3D surface of an\nunderwater object using stereo images. Reconstructing the 3D surface of an\nunderwater object is really a challenging task due to degraded quality of\nunderwater images. There are various reason of quality degradation of\nunderwater images i.e., non-uniform illumination of light on the surface of\nobjects, scattering and absorption effects. Floating particles present in\nunderwater produces Gaussian noise on the captured underwater images which\ndegrades the quality of images. The degraded underwater images are preprocessed\nby applying homomorphic, wavelet denoising and anisotropic filtering\nsequentially. The uncalibrated rectification technique is applied to\npreprocessed images to rectify the left and right images. The rectified left\nand right image lies on a common plane. To find the correspondence points in a\nleft and right images, we have applied dense stereo matching technique i.e.,\ngraph cut method. Finally, we estimate the depth of images using triangulation\ntechnique. The experimental result shows that the proposed method reconstruct\n3D surface of underwater objects accurately using captured underwater stereo\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 09:17:26 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Prabhakar", "C. J.", ""], ["Kumar", "P. U. Praveen", ""]]}, {"id": "1211.2116", "submitter": "S Arunkumar", "authors": "S Arunkumar, Pallab Kumar Sahu, Sudeep Gorai, Kalyan Ghosh", "title": "Localisation of Numerical Date Field in an Indian Handwritten Document", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method to localise all those areas which may\nconstitute the date field in an Indian handwritten document. Spatial patterns\nof the date field are studied from various handwritten documents and an\nalgorithm is developed through statistical analysis to identify those sets of\nconnected components which may constitute the date. Common date patterns\nfollowed in India are considered to classify the date formats in different\nclasses. Reported results demonstrate promising performance of the proposed\napproach\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 12:59:11 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Arunkumar", "S", ""], ["Sahu", "Pallab Kumar", ""], ["Gorai", "Sudeep", ""], ["Ghosh", "Kalyan", ""]]}, {"id": "1211.2150", "submitter": "Mohamed Ben Halima", "authors": "Mohamed Ben Halima, Hichem karray, Adel. M. Alimi and Ana Fern\\'andez\n  Vila", "title": "NF-SAVO: Neuro-Fuzzy system for Arabic Video OCR", "comments": "09 pages", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, Vol. 3, No. 10, 2012, 128-136", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a robust approach for text extraction and\nrecognition from video clips which is called Neuro-Fuzzy system for Arabic\nVideo OCR. In Arabic video text recognition, a number of noise components\nprovide the text relatively more complicated to separate from the background.\nFurther, the characters can be moving or presented in a diversity of colors,\nsizes and fonts that are not uniform. Added to this, is the fact that the\nbackground is usually moving making text extraction a more intricate process.\nVideo include two kinds of text, scene text and artificial text. Scene text is\nusually text that becomes part of the scene itself as it is recorded at the\ntime of filming the scene. But artificial text is produced separately and away\nfrom the scene and is laid over it at a later stage or during the post\nprocessing time. The emergence of artificial text is consequently vigilantly\ndirected. This type of text carries with it important information that helps in\nvideo referencing, indexing and retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 14:57:53 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Halima", "Mohamed Ben", ""], ["karray", "Hichem", ""], ["Alimi", "Adel. M.", ""], ["Vila", "Ana Fern\u00e1ndez", ""]]}, {"id": "1211.2500", "submitter": "Mohamed A. El-Sayed", "authors": "Mohamed A. El-Sayed", "title": "A New Algorithm Based Entropic Threshold for Edge Detection in Images", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 5, No 1, 2011, 71-78", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge detection is one of the most critical tasks in automatic image analysis.\nThere exists no universal edge detection method which works well under all\nconditions. This paper shows the new approach based on the one of the most\nefficient techniques for edge detection, which is entropy-based thresholding.\nThe main advantages of the proposed method are its robustness and its\nflexibility. We present experimental results for this method, and compare\nresults of the algorithm against several leading edge detection methods, such\nas Canny, LOG, and Sobel. Experimental results demonstrate that the proposed\nmethod achieves better result than some classic methods and the quality of the\nedge detector of the output images is robust and decrease the computation time.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 02:56:08 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["El-Sayed", "Mohamed A.", ""]]}, {"id": "1211.2502", "submitter": "Mohamed A. El-Sayed", "authors": "Mohamed A. El-Sayed and Tarek Abd-El Hafeez", "title": "New Edge Detection Technique based on the Shannon Entropy in Gray Level\n  Images", "comments": null, "journal-ref": "International Journal on Computer Science and Engineering (IJCSE),\n  Vol. 3 No. 6, 2011, 2224-2232", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge detection is an important field in image processing. Edges characterize\nobject boundaries and are therefore useful for segmentation, registration,\nfeature extraction, and identification of objects in a scene. In this paper, an\napproach utilizing an improvement of Baljit and Amar method which uses Shannon\nentropy other than the evaluation of derivatives of the image in detecting\nedges in gray level images has been proposed. The proposed method can reduce\nthe CPU time required for the edge detection process and the quality of the\nedge detector of the output images is robust. A standard test images, the\nreal-world and synthetic images are used to compare the results of the proposed\nedge detector with the Baljit and Amar edge detector method. In order to\nvalidate the results, the run time of the proposed method and the pervious\nmethod are presented. It has been observed that the proposed edge detector\nworks effectively for different gray scale digital images. The performance\nevaluation of the proposed technique in terms of the measured CPU time and the\nquality of edge detector method are presented. Experimental results demonstrate\nthat the proposed method achieve better result than the relevant classic\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 03:06:18 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["El-Sayed", "Mohamed A.", ""], ["Hafeez", "Tarek Abd-El", ""]]}, {"id": "1211.2556", "submitter": "Fatai Anifowose", "authors": "Fatai Adesina Anifowose", "title": "A Comparative Study of Gaussian Mixture Model and Radial Basis Function\n  for Voice Recognition", "comments": "9 pages, 10 figures; International Journal of Advanced Computer\n  Science and Applications (IJACSA), Vol. 1, No.3, September 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comparative study of the application of Gaussian Mixture Model (GMM) and\nRadial Basis Function (RBF) in biometric recognition of voice has been carried\nout and presented. The application of machine learning techniques to biometric\nauthentication and recognition problems has gained a widespread acceptance. In\nthis research, a GMM model was trained, using Expectation Maximization (EM)\nalgorithm, on a dataset containing 10 classes of vowels and the model was used\nto predict the appropriate classes using a validation dataset. For experimental\nvalidity, the model was compared to the performance of two different versions\nof RBF model using the same learning and validation datasets. The results\nshowed very close recognition accuracy between the GMM and the standard RBF\nmodel, but with GMM performing better than the standard RBF by less than 1% and\nthe two models outperformed similar models reported in literature. The DTREG\nversion of RBF outperformed the other two models by producing 94.8% recognition\naccuracy. In terms of recognition time, the standard RBF was found to be the\nfastest among the three models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 10:42:58 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Anifowose", "Fatai Adesina", ""]]}, {"id": "1211.2699", "submitter": "Abdur Shahid Rahman Bin", "authors": "Abdur Shahid, Shahriar Badsha, Md. Rethwan Kabeer, Junaid Ahsan and\n  Mufti Mahmud", "title": "A Non-Blind Watermarking Scheme for Gray Scale Images in Discrete\n  Wavelet Transform Domain using Two Subbands", "comments": "9 pages, 7 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 5, No 1, September 2012, page 101-109", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Digital watermarking is the process to hide digital pattern directly into a\ndigital content. Digital watermarking techniques are used to address digital\nrights management, protect information and conceal secrets. An invisible\nnon-blind watermarking approach for gray scale images is proposed in this\npaper. The host image is decomposed into 3-levels using Discrete Wavelet\nTransform. Based on the parent-child relationship between the wavelet\ncoefficients the Set Partitioning in Hierarchical Trees (SPIHT) compression\nalgorithm is performed on the LH3, LH2, HL3 and HL2 subbands to find out the\nsignificant coefficients. The most significant coefficients of LH2 and HL2\nbands are selected to embed a binary watermark image. The selected significant\ncoefficients are modulated using Noise Visibility Function, which is considered\nas the best strength to ensure better imperceptibility. The approach is tested\nagainst various image processing attacks such as addition of noise, filtering,\ncropping, JPEG compression, histogram equalization and contrast adjustment. The\nexperimental results reveal the high effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 17:15:41 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Shahid", "Abdur", ""], ["Badsha", "Shahriar", ""], ["Kabeer", "Md. Rethwan", ""], ["Ahsan", "Junaid", ""], ["Mahmud", "Mufti", ""]]}, {"id": "1211.2742", "submitter": "Venkateshwara Prasad Tangirala", "authors": "Vasudha Vashisht, Tanupriya Choudhury and T. V. Prasad", "title": "Sketch Recognition using Domain Classification", "comments": "9 pages; International Journal of Advanced Computer Science and\n  Applications, Special Issue on Image Processing and Analysis 1, 2011, 1-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptualizing away the sketch processing details in a user interface will\nenable general users and domain experts to create more complex sketches. There\nare many domains for which sketch recognition systems are being developed. But\nthey entail image-processing skill if they are to handle the details of each\ndomain, and also they are lengthy to build. The implemented system goal is to\nenable user interface designers and domain experts who may not have proficiency\nin sketch recognition to be able to construct these sketch systems. This sketch\nrecognition system takes in rough sketches from user drawn with the help of\nmouse as its input. It then recognizes the sketch using segmentation and domain\nclassification, the properties of the user drawn sketch and segments are\nsearched heuristically in the domains and each figures of each domain, and\nfinally it shows its domain, the figure name and properties. It also draws the\nsketch smoothly. The work is resulted through extensive research and study of\nmany existing image processing and pattern matching algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 19:18:28 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Vashisht", "Vasudha", ""], ["Choudhury", "Tanupriya", ""], ["Prasad", "T. V.", ""]]}, {"id": "1211.2863", "submitter": "Alon Schclar", "authors": "Alon Schclar", "title": "Multi-Sensor Fusion via Reduction of Dimensionality", "comments": "PhD Thesis, Tel Aviv Univ, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large high-dimensional datasets are becoming more and more popular in an\nincreasing number of research areas. Processing the high dimensional data\nincurs a high computational cost and is inherently inefficient since many of\nthe values that describe a data object are redundant due to noise and inner\ncorrelations. Consequently, the dimensionality, i.e. the number of values that\nare used to describe a data object, needs to be reduced prior to any other\nprocessing of the data. The dimensionality reduction removes, in most cases,\nnoise from the data and reduces substantially the computational cost of\nalgorithms that are applied to the data.\n  In this thesis, a novel coherent integrated methodology is introduced\n(theory, algorithm and applications) to reduce the dimensionality of\nhigh-dimensional datasets. The method constructs a diffusion process among the\ndata coordinates via a random walk. The dimensionality reduction is obtained\nbased on the eigen-decomposition of the Markov matrix that is associated with\nthe random walk. The proposed method is utilized for: (a) segmentation and\ndetection of anomalies in hyper-spectral images; (b) segmentation of\nmulti-contrast MRI images; and (c) segmentation of video sequences.\n  We also present algorithms for: (a) the characterization of materials using\ntheir spectral signatures to enable their identification; (b) detection of\nvehicles according to their acoustic signatures; and (c) classification of\nvascular vessels recordings to detect hyper-tension and cardio-vascular\ndiseases.\n  The proposed methodology and algorithms produce excellent results that\nsuccessfully compete with current state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 01:05:42 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Schclar", "Alon", ""]]}, {"id": "1211.2881", "submitter": "Junyoung Chung", "authors": "Junyoung Chung, Donghoon Lee, Youngjoo Seo, and Chang D. Yoo", "title": "Deep Attribute Networks", "comments": "This paper has been withdrawn by the author due to a crucial\n  grammatical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining compact and discriminative features is one of the major challenges\nin many of the real-world image classification tasks such as face verification\nand object recognition. One possible approach is to represent input image on\nthe basis of high-level features that carry semantic meaning which humans can\nunderstand. In this paper, a model coined deep attribute network (DAN) is\nproposed to address this issue. For an input image, the model outputs the\nattributes of the input image without performing any classification. The\nefficacy of the proposed model is evaluated on unconstrained face verification\nand real-world object recognition tasks using the LFW and the a-PASCAL\ndatasets. We demonstrate the potential of deep learning for attribute-based\nclassification by showing comparable results with existing state-of-the-art\nresults. Once properly trained, the DAN is fast and does away with calculating\nlow-level features which are maybe unreliable and computationally expensive.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 03:41:31 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2012 11:30:46 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2012 08:39:03 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["Chung", "Junyoung", ""], ["Lee", "Donghoon", ""], ["Seo", "Youngjoo", ""], ["Yoo", "Chang D.", ""]]}, {"id": "1211.3901", "submitter": "Hedvig Kjellstr\\\"om", "authors": "Saad Akram, Jonas Beskow, Hedvig Kjellstrom", "title": "Visual Recognition of Isolated Swedish Sign Language Signs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for recognition of isolated Swedish Sign Language signs.\nThe method will be used in a game intended to help children training signing at\nhome, as a complement to training with a teacher. The target group is not\nprimarily deaf children, but children with language disorders. Using sign\nlanguage as a support in conversation has been shown to greatly stimulate the\nspeech development of such children. The signer is captured with an RGB-D\n(Kinect) sensor, which has three advantages over a regular RGB camera. Firstly,\nit allows complex backgrounds to be removed easily. We segment the hands and\nface based on skin color and depth information. Secondly, it helps with the\nresolution of hand over face occlusion. Thirdly, signs take place in 3D; some\naspects of the signs are defined by hand motion vertically to the image plane.\nThis motion can be estimated if the depth is observable. The 3D motion of the\nhands relative to the torso are used as a cue together with the hand shape, and\nHMMs trained with this input are used for classification. To obtain higher\nrobustness towards differences across signers, Fisher Linear Discriminant\nAnalysis is used to find the combinations of features that are most descriptive\nfor each sign, regardless of signer. Experiments show that the system can\ndistinguish signs from a challenging 94 word vocabulary with a precision of up\nto 94% in the signer dependent case and up to 47% in the signer independent\ncase.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 14:29:31 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Akram", "Saad", ""], ["Beskow", "Jonas", ""], ["Kjellstrom", "Hedvig", ""]]}, {"id": "1211.4264", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal N. Chaudhury, Amit Singer", "title": "Non-Local Patch Regression: Robust Image Denoising in Patch Space", "comments": "Submitted", "journal-ref": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2013", "doi": "10.1109/ICASSP.2013.6637870", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was recently demonstrated in [Chaudhury et al.,Non-Local Euclidean\nMedians,2012] that the denoising performance of Non-Local Means (NLM) can be\nimproved at large noise levels by replacing the mean by the robust Euclidean\nmedian. Numerical experiments on synthetic and natural images showed that the\nlatter consistently performed better than NLM beyond a certain noise level, and\nsignificantly so for images with sharp edges. The Euclidean mean and median can\nbe put into a common regression (on the patch space) framework, in which the\nl_2 norm of the residuals is considered in the former, while the l_1 norm is\nconsidered in the latter. The natural question then is what happens if we\nconsider l_p (0<p<1) regression? We investigate this possibility in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2012 22:36:43 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Chaudhury", "Kunal N.", ""], ["Singer", "Amit", ""]]}, {"id": "1211.4307", "submitter": "Han Li", "authors": "Han Li, Kun Gai, Pinghua Gong, Changshui Zhang", "title": "Efficient Superimposition Recovering Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we address the issue of recovering latent transparent layers\nfrom superimposition images. Here, we assume we have the estimated\ntransformations and extracted gradients of latent layers. To rapidly recover\nhigh-quality image layers, we propose an Efficient Superimposition Recovering\nAlgorithm (ESRA) by extending the framework of accelerated gradient method. In\naddition, a key building block (in each iteration) in our proposed method is\nthe proximal operator calculating. Here we propose to employ a dual approach\nand present our Parallel Algorithm with Constrained Total Variation (PACTV)\nmethod. Our recovering method not only reconstructs high-quality layers without\ncolor-bias problem, but also theoretically guarantees good convergence\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 05:44:24 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Li", "Han", ""], ["Gai", "Kun", ""], ["Gong", "Pinghua", ""], ["Zhang", "Changshui", ""]]}, {"id": "1211.4385", "submitter": "Vivek Shrivastava", "authors": "Vivek Shrivastava and Navdeep Sharma", "title": "Artificial Neural Network Based Optical Character Recognition", "comments": "Signal & Image Processing : An International Journal (SIPIJ) Vol.3,\n  No.5, October 2012", "journal-ref": null, "doi": "10.5121/sipij.2012.3506", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Character Recognition deals in recognition and classification of\ncharacters from an image. For the recognition to be accurate, certain\ntopological and geometrical properties are calculated, based on which a\ncharacter is classified and recognized. Also, the Human psychology perceives\ncharacters by its overall shape and features such as strokes, curves,\nprotrusions, enclosures etc. These properties, also called Features are\nextracted from the image by means of spatial pixel-based calculation. A\ncollection of such features, called Vectors, help in defining a character\nuniquely, by means of an Artificial Neural Network that uses these Feature\nVectors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 12:21:49 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Shrivastava", "Vivek", ""], ["Sharma", "Navdeep", ""]]}, {"id": "1211.4499", "submitter": "Boshra Rajaei", "authors": "Boshra Rajaei, Thomas Maugey, Hamid-Reza Pourreza, Pascal Frossard", "title": "Rate-Distortion Analysis of Multiview Coding in a DIBR Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth image based rendering techniques for multiview applications have been\nrecently introduced for efficient view generation at arbitrary camera\npositions. Encoding rate control has thus to consider both texture and depth\ndata. Due to different structures of depth and texture images and their\ndifferent roles on the rendered views, distributing the available bit budget\nbetween them however requires a careful analysis. Information loss due to\ntexture coding affects the value of pixels in synthesized views while errors in\ndepth information lead to shift in objects or unexpected patterns at their\nboundaries. In this paper, we address the problem of efficient bit allocation\nbetween textures and depth data of multiview video sequences. We adopt a\nrate-distortion framework based on a simplified model of depth and texture\nimages. Our model preserves the main features of depth and texture images.\nUnlike most recent solutions, our method permits to avoid rendering at encoding\ntime for distortion estimation so that the encoding complexity is not\naugmented. In addition to this, our model is independent of the underlying\ninpainting method that is used at decoder. Experiments confirm our theoretical\nresults and the efficiency of our rate allocation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 17:09:56 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Rajaei", "Boshra", ""], ["Maugey", "Thomas", ""], ["Pourreza", "Hamid-Reza", ""], ["Frossard", "Pascal", ""]]}, {"id": "1211.4503", "submitter": "Monowar  Bhuyan H", "authors": "Monowar H. Bhuyan and D. K. Bhattacharyya", "title": "An Effective Fingerprint Classification and Search Method", "comments": "10 pages, 8 figures, 6 tables, referred journal publication", "journal-ref": "International Journal of Computer Science and Network Security,\n  Vol. 9, No.11, pp. 39-48, 2009", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an effective fingerprint classification method designed\nbased on a hierarchical agglomerative clustering technique. The performance of\nthe technique was evaluated in terms of several real-life datasets and a\nsignificant improvement in reducing the misclassification error has been\nnoticed. This paper also presents a query based faster fingerprint search\nmethod over the clustered fingerprint databases. The retrieval accuracy of the\nsearch method has been found effective in light of several real-life databases.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 17:13:26 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Bhuyan", "Monowar H.", ""], ["Bhattacharyya", "D. K.", ""]]}, {"id": "1211.4524", "submitter": "Saeid Pashazadeh", "authors": "Mohammad Javad Parseh and Saeid Pashazadeh", "title": "Applying Dynamic Model for Multiple Manoeuvring Target Tracking Using\n  Particle Filtering", "comments": "13 pages, 7 Figures, 1 Table", "journal-ref": "International Journal of Information Technology, Control and\n  Automation (IJITCA), Vol. 2, No. 4, pp. 37-49, 2012", "doi": "10.5121/ijitca.2012.2404", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we applied a dynamic model for manoeuvring targets in SIR\nparticle filter algorithm for improving tracking accuracy of multiple\nmanoeuvring targets. In our proposed approach, a color distribution model is\nused to detect changes of target's model . Our proposed approach controls\ndeformation of target's model. If deformation of target's model is larger than\na predetermined threshold, then the model will be updated. Global Nearest\nNeighbor (GNN) algorithm is used as data association algorithm. We named our\nproposed method as Deformation Detection Particle Filter (DDPF) . DDPF approach\nis compared with basic SIR-PF algorithm on real airshow videos. Comparisons\nresults show that, the basic SIR-PF algorithm is not able to track the\nmanoeuvring targets when the rotation or scaling is occurred in target' s\nmodel. However, DDPF approach updates target's model when the rotation or\nscaling is occurred. Thus, the proposed approach is able to track the\nmanoeuvring targets more efficiently and accurately.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 18:07:44 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Parseh", "Mohammad Javad", ""], ["Pashazadeh", "Saeid", ""]]}, {"id": "1211.4591", "submitter": "Firas Ajil Jassim", "authors": "Firas A. Jassim, Hind E. Qassim", "title": "Five Modulus Method For Image Compression", "comments": "10 pages, 2 figures, 9 tables", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ),\n  Vol.3, No.5, October 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is compressed by reducing its redundancy, but this also makes the data\nless reliable, more prone to errors. In this paper a novel approach of image\ncompression based on a new method that has been created for image compression\nwhich is called Five Modulus Method (FMM). The new method consists of\nconverting each pixel value in an 8-by-8 block into a multiple of 5 for each of\nthe R, G and B arrays. After that, the new values could be divided by 5 to get\nnew values which are 6-bit length for each pixel and it is less in storage\nspace than the original value which is 8-bits. Also, a new protocol for\ncompression of the new values as a stream of bits has been presented that gives\nthe opportunity to store and transfer the new compressed image easily.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 21:02:58 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Jassim", "Firas A.", ""], ["Qassim", "Hind E.", ""]]}, {"id": "1211.4657", "submitter": "Chen Chen", "authors": "Chen Chen and Yeqing Li and Junzhou Huang", "title": "Forest Sparsity for Multi-channel Compressive Sensing", "comments": "Accepted by IEEE Transactions on Signal Processing, 2014", "journal-ref": null, "doi": "10.1109/TSP.2014.2318138", "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a new compressive sensing model for\nmulti-channel sparse data where each channel can be represented as a\nhierarchical tree and different channels are highly correlated. Therefore, the\nfull data could follow the forest structure and we call this property as\n\\emph{forest sparsity}. It exploits both intra- and inter- channel correlations\nand enriches the family of existing model-based compressive sensing theories.\nThe proposed theory indicates that only $\\mathcal{O}(Tk+\\log(N/k))$\nmeasurements are required for multi-channel data with forest sparsity, where\n$T$ is the number of channels, $N$ and $k$ are the length and sparsity number\nof each channel respectively. This result is much better than\n$\\mathcal{O}(Tk+T\\log(N/k))$ of tree sparsity, $\\mathcal{O}(Tk+k\\log(N/k))$ of\njoint sparsity, and far better than $\\mathcal{O}(Tk+Tk\\log(N/k))$ of standard\nsparsity. In addition, we extend the forest sparsity theory to the multiple\nmeasurement vectors problem, where the measurement matrix is a block-diagonal\nmatrix. The result shows that the required measurement bound can be the same as\nthat for dense random measurement matrix, when the data shares equal energy in\neach channel. A new algorithm is developed and applied on four example\napplications to validate the benefit of the proposed model. Extensive\nexperiments demonstrate the effectiveness and efficiency of the proposed theory\nand algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 03:22:45 GMT"}, {"version": "v2", "created": "Thu, 1 May 2014 15:56:00 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Chen", "Chen", ""], ["Li", "Yeqing", ""], ["Huang", "Junzhou", ""]]}, {"id": "1211.4658", "submitter": "Monowar  Bhuyan H", "authors": "Monowar H. Bhuyan, Sarat Saharia, and Dhruba Kr Bhattacharyya", "title": "An Effective Method for Fingerprint Classification", "comments": "9 pages, 7 figures, 6 tables referred journal publication. arXiv\n  admin note: substantial text overlap with arXiv:1211.4503", "journal-ref": "International A. Journal of e-Technology, Vol. 1, No. 3, pp.\n  89-97, January, 2010", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an effective method for fingerprint classification using\ndata mining approach. Initially, it generates a numeric code sequence for each\nfingerprint image based on the ridge flow patterns. Then for each class, a seed\nis selected by using a frequent itemsets generation technique. These seeds are\nsubsequently used for clustering the fingerprint images. The proposed method\nwas tested and evaluated in terms of several real-life datasets and a\nsignificant improvement in reducing the misclassification errors has been\nnoticed in comparison to its other counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 03:25:57 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Bhuyan", "Monowar H.", ""], ["Saharia", "Sarat", ""], ["Bhattacharyya", "Dhruba Kr", ""]]}, {"id": "1211.4683", "submitter": "Bhavesh Patel", "authors": "B. V. Patel and B. B. Meshram", "title": "Content based video retrieval", "comments": null, "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.4, No.5, October 2012", "doi": "10.5121/ijma.2012.4506", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content based video retrieval is an approach for facilitating the searching\nand browsing of large image collections over World Wide Web. In this approach,\nvideo analysis is conducted on low level visual properties extracted from video\nframe. We believed that in order to create an effective video retrieval system,\nvisual perception must be taken into account. We conjectured that a technique\nwhich employs multiple features for indexing and retrieval would be more\neffective in the discrimination and search tasks of videos. In order to\nvalidate this claim, content based indexing and retrieval systems were\nimplemented using color histogram, various texture features and other\napproaches. Videos were stored in Oracle 9i Database and a user study measured\ncorrectness of response.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 08:22:56 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Patel", "B. V.", ""], ["Meshram", "B. B.", ""]]}, {"id": "1211.4771", "submitter": "Ganesh Sundaramoorthi", "authors": "Ganesh Sundaramoorthi and Yanchao Yang", "title": "Matching Through Features and Features Through Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses how to construct features for the problem of image\ncorrespondence, in particular, the paper addresses how to construct features so\nas to maintain the right level of invariance versus discriminability. We show\nthat without additional prior knowledge of the 3D scene, the right tradeoff\ncannot be established in a pre-processing step of the images as is typically\ndone in most feature-based matching methods. However, given knowledge of the\nsecond image to match, the tradeoff between invariance and discriminability of\nfeatures in the first image is less ambiguous. This suggests to setup the\nproblem of feature extraction and matching as a joint estimation problem. We\ndevelop a possible mathematical framework, a possible computational algorithm,\nand we give example demonstration on finding correspondence on images related\nby a scene that undergoes large 3D deformation of non-planar objects and camera\nviewpoint change.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 15:15:56 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Sundaramoorthi", "Ganesh", ""], ["Yang", "Yanchao", ""]]}, {"id": "1211.4860", "submitter": "Oscar Beijbom Mr", "authors": "Oscar Beijbom", "title": "Domain Adaptations for Computer Vision Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic assumption of statistical learning theory is that train and test data\nare drawn from the same underlying distribution. Unfortunately, this assumption\ndoesn't hold in many applications. Instead, ample labeled data might exist in a\nparticular `source' domain while inference is needed in another, `target'\ndomain. Domain adaptation methods leverage labeled data from both domains to\nimprove classification on unseen data in the target domain. In this work we\nsurvey domain transfer learning methods for various application domains with\nfocus on recent work in Computer Vision.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 20:54:30 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Beijbom", "Oscar", ""]]}, {"id": "1211.4907", "submitter": "Luis Pedro Coelho", "authors": "Luis Pedro Coelho", "title": "Mahotas: Open source software for scriptable computer vision", "comments": null, "journal-ref": "Journal of Open Research Software 1(1):e3 2013", "doi": "10.5334/jors.ac", "report-no": null, "categories": "cs.CV cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mahotas is a computer vision library for Python. It contains traditional\nimage processing functionality such as filtering and morphological operations\nas well as more modern computer vision functions for feature computation,\nincluding interest point detection and local descriptors.\n  The interface is in Python, a dynamic programming language, which is very\nappropriate for fast development, but the algorithms are implemented in C++ and\nare tuned for speed. The library is designed to fit in with the scientific\nsoftware ecosystem in this language and can leverage the existing\ninfrastructure developed in that language.\n  Mahotas is released under a liberal open source license (MIT License) and is\navailable from (http://github.com/luispedro/mahotas) and from the Python\nPackage Index (http://pypi.python.org/pypi/mahotas).\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2012 00:51:10 GMT"}, {"version": "v2", "created": "Sat, 5 Jan 2013 01:16:00 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Coelho", "Luis Pedro", ""]]}, {"id": "1211.5355", "submitter": "Raka Kundu", "authors": "Raka Kundu, Amlan Chakrabarti, Prasanna K. Lenka", "title": "Cobb Angle Measurement of Scoliosis with Reduced Variability", "comments": "MedImage2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cobb angle, which is a measure of spinal curvature is the standard method for\nquantifying the magnitude of Scoliosis related to spinal deformity in\northopedics. Determining the Cobb angle through manual process is subject to\nhuman errors. In this work, we propose a methodology to measure the magnitude\nof Cobb angle, which appreciably reduces the variability related to its\nmeasurement compared to the related works. The proposed methodology is\nfacilitated by using a suitable new improved version of Non-Local Means for\nimage denoisation and Otsus automatic threshold selection for Canny edge\ndetection. We have selected NLM for preprocessing of the image as it is one of\nthe fine states of art for image denoisation and helps in retaining the image\nquality. Trimmedmean, median are more robust to outliners than mean and\nfollowing this concept we observed that NLM denoising quality performance can\nbe enhanced by using Euclidean trimmed-mean replacing the mean. To prove the\nbetter performance of the Non-Local Euclidean Trimmed-mean denoising filter, we\nhave provided some comparative study results of the proposed denoising\ntechnique with traditional NLM and NonLocal Euclidean Medians. The experimental\nresults for Cobb angle measurement over intra observer and inter observer\nexperimental data reveals the better performance and superiority of the\nproposed approach compared to the related works. MATLAB2009b image processing\ntoolbox was used for the purpose of simulation and verification of the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2012 19:09:29 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Kundu", "Raka", ""], ["Chakrabarti", "Amlan", ""], ["Lenka", "Prasanna K.", ""]]}, {"id": "1211.5556", "submitter": "Ofir Pele", "authors": "Ofir Pele and Michael Werman", "title": "Improving Perceptual Color Difference using Basic Color Terms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new color distance based on two observations. First, perceptual\ncolor differences were designed to be used to compare very similar colors. They\ndo not capture human perception for medium and large color differences well.\nThresholding was proposed to solve the problem for large color differences,\ni.e. two totally different colors are always the same distance apart. We show\nthat thresholding alone cannot improve medium color differences. We suggest to\nalleviate this problem using basic color terms. Second, when a color distance\nis used for edge detection, many small distances around the just noticeable\ndifference may account for false edges. We suggest to reduce the effect of\nsmall distances.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 17:13:07 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Pele", "Ofir", ""], ["Werman", "Michael", ""]]}, {"id": "1211.5614", "submitter": "Ankit Chaudhary", "authors": "Ankit Chaudhary, J. Vasavada, J.L. Raheja, S. Kumar, M. Sharma", "title": "A Hash based Approach for Secure Keyless Steganography in Lossless RGB\n  Images", "comments": "The paper is withdrawn due to license issue", "journal-ref": "The 22nd International Conference on Computer Graphics and Vision,\n  2012, pp.80-83", "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improved steganography approach for hiding text\nmessages in lossless RGB images. The objective of this work is to increase the\nsecurity level and to improve the storage capacity with compression techniques.\nThe security level is increased by randomly distributing the text message over\nthe entire image instead of clustering within specific image portions. Storage\ncapacity is increased by utilizing all the color channels for storing\ninformation and providing the source text message compression. The degradation\nof the images can be minimized by changing only one least significant bit per\ncolor channel for hiding the message, incurring a very little change in the\noriginal image. Using steganography alone with simple LSB has a potential\nproblem that the secret message is easily detectable from the histogram\nanalysis method. To improve the security as well as the image embedding\ncapacity indirectly, a compression based scheme is introduced. Various tests\nhave been done to check the storage capacity and message distribution. These\ntestes show the superiority of the proposed approach with respect to other\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 21:34:53 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 16:41:40 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 01:27:39 GMT"}, {"version": "v4", "created": "Sun, 10 Mar 2013 08:21:45 GMT"}, {"version": "v5", "created": "Wed, 17 Apr 2013 00:20:00 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Chaudhary", "Ankit", ""], ["Vasavada", "J.", ""], ["Raheja", "J. L.", ""], ["Kumar", "S.", ""], ["Sharma", "M.", ""]]}, {"id": "1211.5712", "submitter": "Krzysztof Misztal M.Sc.", "authors": "Jacek Tabor and Krzysztof Misztal", "title": "Detection of elliptical shapes via cross-entropy clustering", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-38628-2_78", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding elliptical shapes in an image will be considered. We\ndiscuss the solution which uses cross-entropy clustering. The proposed method\nallows the search for ellipses with predefined sizes and position in the space.\nMoreover, it works well for search of ellipsoids in higher dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2012 23:08:15 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Tabor", "Jacek", ""], ["Misztal", "Krzysztof", ""]]}, {"id": "1211.5829", "submitter": "Reza Oji", "authors": "Reza Oji", "title": "An Automatic Algorithm for Object Recognition and Detection Based on\n  ASIFT Keypoints", "comments": "11 pages - 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1210.7038", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.3, No.5, 2012, pp 29-39", "doi": "10.5121/sipij.2012.3503", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object recognition is an important task in image processing and computer\nvision. This paper presents a perfect method for object recognition with full\nboundary detection by combining affine scale invariant feature transform\n(ASIFT) and a region merging algorithm. ASIFT is a fully affine invariant\nalgorithm that means features are invariant to six affine parameters namely\ntranslation (2 parameters), zoom, rotation and two camera axis orientations.\nThe features are very reliable and give us strong keypoints that can be used\nfor matching between different images of an object. We trained an object in\nseveral images with different aspects for finding best keypoints of it. Then, a\nrobust region merging algorithm is used to recognize and detect the object with\nfull boundary in the other images based on ASIFT keypoints and a similarity\nmeasure for merging regions in the image. Experimental results show that the\npresented method is very efficient and powerful to recognize the object and\ndetect it with high accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2012 01:10:15 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Oji", "Reza", ""]]}, {"id": "1211.6675", "submitter": "Dalton Lunga", "authors": "Dalton Lunga 'and' Okan Ersoy", "title": "Nonlinear Dynamic Field Embedding: On Hyperspectral Scene Visualization", "comments": "49 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": "TR-ECE-12-14", "categories": "cs.CV cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding techniques are useful to characterize spectral signature\nrelations for hyperspectral images. However, such images consists of disjoint\nclasses due to spatial details that are often ignored by existing graph\ncomputing tools. Robust parameter estimation is a challenge for kernel\nfunctions that compute such graphs. Finding a corresponding high quality\ncoordinate system to map signature relations remains an open research question.\nWe answer positively on these challenges by first proposing a kernel function\nof spatial and spectral information in computing neighborhood graphs. Secondly,\nthe study exploits the force field interpretation from mechanics and devise a\nunifying nonlinear graph embedding framework. The generalized framework leads\nto novel unsupervised multidimensional artificial field embedding techniques\nthat rely on the simple additive assumption of pair-dependent attraction and\nrepulsion functions. The formulations capture long range and short range\ndistance related effects often associated with living organisms and help to\nestablish algorithmic properties that mimic mutual behavior for the purpose of\ndimensionality reduction. The main benefits from the proposed models includes\nthe ability to preserve the local topology of data and produce quality\nvisualizations i.e. maintaining disjoint meaningful neighborhoods. As part of\nevaluation, visualization, gradient field trajectories, and semisupervised\nclassification experiments are conducted for image scenes acquired by multiple\nsensors at various spatial resolutions over different types of objects. The\nresults demonstrate the superiority of the proposed embedding framework over\nvarious widely used methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 17:39:16 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["Ersoy", "Dalton Lunga 'and' Okan", ""]]}, {"id": "1211.6971", "submitter": "Issam Qaffou", "authors": "Issam Qaffou, Mohamed Sadgal, Aziz Elfazziki", "title": "A New Automatic Method to Adjust Parameters for Object Recognition", "comments": null, "journal-ref": "IJACSA 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To recognize an object in an image, the user must apply a combination of\noperators, where each operator has a set of parameters. These parameters must\nbe well adjusted in order to reach good results. Usually, this adjustment is\nmade manually by the user. In this paper we propose a new method to automate\nthe process of parameter adjustment for an object recognition task. Our method\nis based on reinforcement learning, we use two types of agents: User Agent that\ngives the necessary information and Parameter Agent that adjusts the parameters\nof each operator. Due to the nature of reinforcement learning the results do\nnot depend only on the system characteristics but also on the user favorite\nchoices.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 16:35:07 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Qaffou", "Issam", ""], ["Sadgal", "Mohamed", ""], ["Elfazziki", "Aziz", ""]]}, {"id": "1211.7102", "submitter": "Rowayda Sadek", "authors": "Rowayda A. Sadek", "title": "SVD Based Image Processing Applications: State of The Art, Contributions\n  and Research Challenges", "comments": null, "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 3, No. 7, 2012 26-34", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Value Decomposition (SVD) has recently emerged as a new paradigm for\nprocessing different types of images. SVD is an attractive algebraic transform\nfor image processing applications. The paper proposes an experimental survey\nfor the SVD as an efficient transform in image processing applications. Despite\nthe well-known fact that SVD offers attractive properties in imaging, the\nexploring of using its properties in various image applications is currently at\nits infancy. Since the SVD has many attractive properties have not been\nutilized, this paper contributes in using these generous properties in newly\nimage applications and gives a highly recommendation for more research\nchallenges. In this paper, the SVD properties for images are experimentally\npresented to be utilized in developing new SVD-based image processing\napplications. The paper offers survey on the developed SVD based image\napplications. The paper also proposes some new contributions that were\noriginated from SVD properties analysis in different image processing. The aim\nof this paper is to provide a better understanding of the SVD in image\nprocessing and identify important various applications and open research\ndirections in this increasingly important area; SVD based image processing in\nthe future research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 21:52:00 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Sadek", "Rowayda A.", ""]]}, {"id": "1211.7180", "submitter": "Huiyi Hu", "authors": "Huiyi Hu, Yves van Gennip, Blake Hunter, Mason A. Porter, Andrea L.\n  Bertozzi", "title": "Multislice Modularity Optimization in Community Detection and Image\n  Segmentation", "comments": "3 pages, 2 figures, to appear in IEEE International Conference on\n  Data Mining PhD forum conference proceedings", "journal-ref": null, "doi": "10.1109/ICDMW.2012.72", "report-no": null, "categories": "cs.SI cs.CV physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because networks can be used to represent many complex systems, they have\nattracted considerable attention in physics, computer science, sociology, and\nmany other disciplines. One of the most important areas of network science is\nthe algorithmic detection of cohesive groups (i.e., \"communities\") of nodes. In\nthis paper, we algorithmically detect communities in social networks and image\ndata by optimizing multislice modularity. A key advantage of modularity\noptimization is that it does not require prior knowledge of the number or sizes\nof communities, and it is capable of finding network partitions that are\ncomposed of communities of different sizes. By optimizing multislice modularity\nand subsequently calculating diagnostics on the resulting network partitions,\nit is thereby possible to obtain information about network structure across\nmultiple system scales. We illustrate this method on data from both social\nnetworks and images, and we find that optimization of multislice modularity\nperforms well on these two tasks without the need for extensive\nproblem-specific adaptation. However, improving the computational speed of this\nmethod remains a challenging open problem.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 08:24:12 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Hu", "Huiyi", ""], ["van Gennip", "Yves", ""], ["Hunter", "Blake", ""], ["Porter", "Mason A.", ""], ["Bertozzi", "Andrea L.", ""]]}, {"id": "1211.7219", "submitter": "Qian Zhao", "authors": "Qian Zhao and Deyu Meng and Zongben Xu", "title": "A recursive divide-and-conquer approach for sparse principal component\n  analysis", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new method is proposed for sparse PCA based on the recursive\ndivide-and-conquer methodology. The main idea is to separate the original\nsparse PCA problem into a series of much simpler sub-problems, each having a\nclosed-form solution. By recursively solving these sub-problems in an\nanalytical way, an efficient algorithm is constructed to solve the sparse PCA\nproblem. The algorithm only involves simple computations and is thus easy to\nimplement. The proposed method can also be very easily extended to other sparse\nPCA problems with certain constraints, such as the nonnegative sparse PCA\nproblem. Furthermore, we have shown that the proposed algorithm converges to a\nstationary point of the problem, and its computational complexity is\napproximately linear in both data size and dimensionality. The effectiveness of\nthe proposed method is substantiated by extensive experiments implemented on a\nseries of synthetic and real data in both reconstruction-error-minimization and\ndata-variance-maximization viewpoints.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 11:50:21 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Zhao", "Qian", ""], ["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}]