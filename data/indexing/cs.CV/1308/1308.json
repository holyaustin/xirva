[{"id": "1308.0271", "submitter": "Qiang Qiu", "authors": "Qiang Qiu, Rama Chellappa", "title": "Compositional Dictionaries for Domain Adaptive Face Recognition", "comments": "Transactions on Image Processing, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dictionary learning approach to compensate for the\ntransformation of faces due to changes in view point, illumination, resolution,\netc. The key idea of our approach is to force domain-invariant sparse coding,\ni.e., design a consistent sparse representation of the same face in different\ndomains. In this way, classifiers trained on the sparse codes in the source\ndomain consisting of frontal faces for example can be applied to the target\ndomain (consisting of faces in different poses, illumination conditions, etc)\nwithout much loss in recognition accuracy. The approach is to first learn a\ndomain base dictionary, and then describe each domain shift (identity, pose,\nillumination) using a sparse representation over the base dictionary. The\ndictionary adapted to each domain is expressed as sparse linear combinations of\nthe base dictionary. In the context of face recognition, with the proposed\ncompositional dictionary approach, a face image can be decomposed into sparse\nrepresentations for a given subject, pose and illumination respectively. This\napproach has three advantages: first, the extracted sparse representation for a\nsubject is consistent across domains and enables pose and illumination\ninsensitive face recognition. Second, sparse representations for pose and\nillumination can subsequently be used to estimate the pose and illumination\ncondition of a face image. Finally, by composing sparse representations for\nsubject and the different domains, we can also perform pose alignment and\nillumination normalization. Extensive experiments using two public face\ndatasets are presented to demonstrate the effectiveness of our approach for\nface recognition.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 17:27:31 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2015 20:55:51 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Qiu", "Qiang", ""], ["Chellappa", "Rama", ""]]}, {"id": "1308.0273", "submitter": "Qiang Qiu", "authors": "Qiang Qiu, Guillermo Sapiro", "title": "Learning Robust Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a low-rank transformation-learning framework to robustify subspace\nclustering. Many high-dimensional data, such as face images and motion\nsequences, lie in a union of low-dimensional subspaces. The subspace clustering\nproblem has been extensively studied in the literature to partition such\nhigh-dimensional data into clusters corresponding to their underlying\nlow-dimensional subspaces. However, low-dimensional intrinsic structures are\noften violated for real-world observations, as they can be corrupted by errors\nor deviate from ideal models. We propose to address this by learning a linear\ntransformation on subspaces using matrix rank, via its convex surrogate nuclear\nnorm, as the optimization criteria. The learned linear transformation restores\na low-rank structure for data from the same subspace, and, at the same time,\nforces a high-rank structure for data from different subspaces. In this way, we\nreduce variations within the subspaces, and increase separations between the\nsubspaces for more accurate subspace clustering. This proposed learned robust\nsubspace clustering framework significantly enhances the performance of\nexisting subspace clustering methods. To exploit the low-rank structures of the\ntransformed subspaces, we further introduce a subspace clustering technique,\ncalled Robust Sparse Subspace Clustering, which efficiently combines robust PCA\nwith sparse modeling. We also discuss the online learning of the\ntransformation, and learning of the transformation while simultaneously\nreducing the data dimensionality. Extensive experiments using public datasets\nare presented, showing that the proposed approach significantly outperforms\nstate-of-the-art subspace clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 17:31:37 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Qiu", "Qiang", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1308.0275", "submitter": "Qiang Qiu", "authors": "Qiang Qiu, Guillermo Sapiro, Ching-Hui Chen", "title": "Domain-invariant Face Recognition using Learned Low-rank Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a low-rank transformation approach to compensate for face\nvariations due to changes in visual domains, such as pose and illumination. The\nkey idea is to learn discriminative linear transformations for face images\nusing matrix rank as the optimization criteria. The learned linear\ntransformations restore a shared low-rank structure for faces from the same\nsubject, and, at the same time, force a high-rank structure for faces from\ndifferent subjects. In this way, among the transformed faces, we reduce\nvariations caused by domain changes within the classes, and increase\nseparations between the classes for better face recognition across domains.\nExtensive experiments using public datasets are presented to demonstrate the\neffectiveness of our approach for face recognition across domains. The\npotential of the approach for feature extraction in generic object recognition\nand coded aperture design are discussed as well.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 17:34:36 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Qiu", "Qiang", ""], ["Sapiro", "Guillermo", ""], ["Chen", "Ching-Hui", ""]]}, {"id": "1308.0290", "submitter": "Qiang Qiu", "authors": "Qiang Qiu, Zhuolin Jiang, Rama Chellappa", "title": "Sparse Dictionary-based Attributes for Action Recognition and\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for dictionary learning of action attributes via\ninformation maximization. We unify the class distribution and appearance\ninformation into an objective function for learning a sparse dictionary of\naction attributes. The objective function maximizes the mutual information\nbetween what has been learned and what remains to be learned in terms of\nappearance information and class distribution for each dictionary atom. We\npropose a Gaussian Process (GP) model for sparse representation to optimize the\ndictionary objective function. The sparse coding property allows a kernel with\ncompact support in GP to realize a very efficient dictionary learning process.\nHence we can describe an action video by a set of compact and discriminative\naction attributes. More importantly, we can recognize modeled action categories\nin a sparse feature space, which can be generalized to unseen and unmodeled\naction categories. Experimental results demonstrate the effectiveness of our\napproach in action recognition and summarization.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 18:25:16 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Qiu", "Qiang", ""], ["Jiang", "Zhuolin", ""], ["Chellappa", "Rama", ""]]}, {"id": "1308.0315", "submitter": "Ali Wali", "authors": "Mohamed Chakroun, Ali Wali and Adel M. Alimi", "title": "MAS for video objects segmentation and tracking based on active contours\n  and SURF descriptor", "comments": "6 pages", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 10,\n  Issue 2, No 3, March 2013", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision, video segmentation and tracking is an important\nchallenging issue. In this paper, we describe a new video sequences\nsegmentation and tracking algorithm based on MAS \"multi-agent systems\" and SURF\n\"Speeded Up Robust Features\". Our approach consists in modelling a multi-agent\nsystem for segmenting the first image from a video sequence and tracking\nobjects in the video sequences. The used agents are supervisor and explorator\nagents, they are communicating between them and they inspire in their behavior\nfrom active contours approaches. The tracking of objects is based on SURF\ndescriptors \"Speed Up Robust Features\". We used the DIMA platform and \"API\nAteji PX\" (an extension of the Java language to facilitate parallel programming\non heterogeneous architectures) to implement this algorithm. The experimental\nresults indicate that the proposed algorithm is more robust and faster than\nprevious approaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 19:45:23 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Chakroun", "Mohamed", ""], ["Wali", "Ali", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1308.0365", "submitter": "Khurom Kiyani", "authors": "Emanuel Aldea and Khurom H. Kiyani", "title": "Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes", "comments": "13 pages, 6 figures, submitted to Machine Vision and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of multiple camera calibration in the\npresence of a homogeneous scene, and without the possibility of employing\ncalibration object based methods. The proposed solution exploits salient\nfeatures present in a larger field of view, but instead of employing active\nvision we replace the cameras with stereo rigs featuring a long focal analysis\ncamera, as well as a short focal registration camera. Thus, we are able to\npropose an accurate solution which does not require intrinsic variation models\nas in the case of zooming cameras. Moreover, the availability of the two views\nsimultaneously in each rig allows for pose re-estimation between rigs as often\nas necessary. The algorithm has been successfully validated in an indoor\nsetting, as well as on a difficult scene featuring a highly dense pilgrim crowd\nin Makkah.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 21:58:33 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Aldea", "Emanuel", ""], ["Kiyani", "Khurom H.", ""]]}, {"id": "1308.0371", "submitter": "Benjamin Graham", "authors": "Benjamin Graham", "title": "Sparse arrays of signatures for online character recognition", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mathematics the signature of a path is a collection of iterated integrals,\ncommonly used for solving differential equations. We show that the path\nsignature, used as a set of features for consumption by a convolutional neural\nnetwork (CNN), improves the accuracy of online character recognition---that is\nthe task of reading characters represented as a collection of paths. Using\ndatasets of letters, numbers, Assamese and Chinese characters, we show that the\nfirst, second, and even the third iterated integrals contain useful information\nfor consumption by a CNN.\n  On the CASIA-OLHWDB1.1 3755 Chinese character dataset, our approach gave a\ntest error of 3.58%, compared with 5.61% for a traditional CNN [Ciresan et\nal.]. A CNN trained on the CASIA-OLHWDB1.0-1.2 datasets won the ICDAR2013\nOnline Isolated Chinese Character recognition competition.\n  Computationally, we have developed a sparse CNN implementation that make it\npractical to train CNNs with many layers of max-pooling. Extending the MNIST\ndataset by translations, our sparse CNN gets a test error of 0.31%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2013 22:29:41 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2013 17:17:06 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Graham", "Benjamin", ""]]}, {"id": "1308.0890", "submitter": "Karen  Das", "authors": "Parimita Saikia, Karen Das", "title": "Head Gesture Recognition using Optical Flow based Classification with\n  Reinforcement of GMM based Background Subtraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a technique of real time head gesture recognition\nsystem. The method includes Gaussian mixture model (GMM) accompanied by optical\nflow algorithm which provided us the required information regarding head\nmovement. The proposed model can be implemented in various control system. We\nare also presenting the result and implementation of both mentioned method.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 05:17:26 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Saikia", "Parimita", ""], ["Das", "Karen", ""]]}, {"id": "1308.1126", "submitter": "Wang-Q Lim", "authors": "H. Lakshman, W.-Q Lim, H. Schwarz, D. Marpe, G. Kutyniok, and T.\n  Wiegand", "title": "Image interpolation using Shearlet based iterative refinement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an image interpolation algorithm exploiting sparse\nrepresentation for natural images. It involves three main steps: (a) obtaining\nan initial estimate of the high resolution image using linear methods like FIR\nfiltering, (b) promoting sparsity in a selected dictionary through iterative\nthresholding, and (c) extracting high frequency information from the\napproximation to refine the initial estimate. For the sparse modeling, a\nshearlet dictionary is chosen to yield a multiscale directional representation.\nThe proposed algorithm is compared to several state-of-the-art methods to\nassess its objective as well as subjective performance. Compared to the cubic\nspline interpolation method, an average PSNR gain of around 0.8 dB is observed\nover a dataset of 200 images.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 21:33:06 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Lakshman", "H.", ""], ["Lim", "W. -Q", ""], ["Schwarz", "H.", ""], ["Marpe", "D.", ""], ["Kutyniok", "G.", ""], ["Wiegand", "T.", ""]]}, {"id": "1308.1150", "submitter": "Ali Wali", "authors": "Ali Wali and Adel M. Alimi", "title": "Multimodal Approach for Video Surveillance Indexing and Retrieval", "comments": "7 pages", "journal-ref": "Journal of Intelligent Computing, Volume: 1, Issue: 4 (December\n  2010), Page: 165-175", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an overview of a multimodal system to indexing and\nsearching video sequence by the content that has been developed within the\nREGIMVid project. A large part of our system has been developed as part of\nTRECVideo evaluation. The MAVSIR platform provides High-level feature\nextraction from audio-visual content and concept/event-based video retrieval.\nWe illustrate the architecture of the system as well as provide an overview of\nthe descriptors supported to date. Then we demonstrate the usefulness of the\ntoolbox in the context of feature extraction, concepts/events learning and\nretrieval in large collections of video surveillance dataset. The results are\nencouraging as we are able to get good results on several event categories,\nwhile for all events we have gained valuable insights and experience.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 01:21:35 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Wali", "Ali", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1308.1187", "submitter": "Abbas Hosseini", "authors": "Ali Soltani-Farani, Hamid R. Rabiee, Seyyed Abbas Hosseini", "title": "Spatial-Aware Dictionary Learning for Hyperspectral Image Classification", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a structured dictionary-based model for hyperspectral\ndata that incorporates both spectral and contextual characteristics of a\nspectral sample, with the goal of hyperspectral image classification. The idea\nis to partition the pixels of a hyperspectral image into a number of spatial\nneighborhoods called contextual groups and to model each pixel with a linear\ncombination of a few dictionary elements learned from the data. Since pixels\ninside a contextual group are often made up of the same materials, their linear\ncombinations are constrained to use common elements from the dictionary. To\nthis end, dictionary learning is carried out with a joint sparse regularizer to\ninduce a common sparsity pattern in the sparse coefficients of each contextual\ngroup. The sparse coefficients are then used for classification using a linear\nSVM. Experimental results on a number of real hyperspectral images confirm the\neffectiveness of the proposed representation for hyperspectral image\nclassification. Moreover, experiments with simulated multispectral data show\nthat the proposed model is capable of finding representations that may\neffectively be used for classification of multispectral-resolution samples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 05:57:08 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Soltani-Farani", "Ali", ""], ["Rabiee", "Hamid R.", ""], ["Hosseini", "Seyyed Abbas", ""]]}, {"id": "1308.1374", "submitter": "Hyuntaek Oh", "authors": "Hyuntaek Oh", "title": "Bayesian ensemble learning for image denoising", "comments": "computer vision and image understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural images are often affected by random noise and image denoising has\nlong been a central topic in Computer Vision. Many algorithms have been\nintroduced to remove the noise from the natural images, such as Gaussian,\nWiener filtering and wavelet thresholding. However, many of these algorithms\nremove the fine edges and make them blur. Recently, many promising denoising\nalgorithms have been introduced such as Non-local Means, Fields of Experts, and\nBM3D. In this paper, we explore Bayesian method of ensemble learning for image\ndenoising. Ensemble methods seek to combine multiple different algorithms to\nretain the strengths of all methods and the weaknesses of none. Bayesian\nensemble models are Non-local Means and Fields of Experts, the very successful\nrecent algorithms. The Non-local Means presumes that the image contains an\nextensive amount of self-similarity. The approach of the Fields of Experts\nmodel extends traditional Markov Random Field model by learning potential\nfunctions over extended pixel neighborhoods. The two models are implemented and\nimage denoising is performed on natural images. The experimental results\nobtained are used to compare with the single algorithm and discuss the ensemble\nlearning and their approaches. Comparing to the results of Non-local Means and\nFields of Experts, Ensemble learning showed improvement nearly 1dB.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 18:46:18 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Oh", "Hyuntaek", ""]]}, {"id": "1308.1801", "submitter": "Mina Farmanbar Ms", "authors": "Jamshid Tamouk, Nasser Lotfi, Mina Farmanbar", "title": "Satellite image classification methods and Landsat 5TM bands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to find the most accurate classification method among\nparallelepiped, minimum distance and chain methods. Moreover, this study also\nchallenges to find the suitable combination of bands, which can lead to better\nresults in case combinations of bands occur. After comparing these three\nmethods, the chain method over perform the other methods with 79% overall\naccuracy. Hence, it is more accurate than minimum distance with 67% and\nparallelepiped with 65%. On the other hand, based on bands features, and also\nby combining several researchers' findings, a table was created which includes\nthe main objects on the land and the suitable combination of the bands for\naccurately detecting of landcover objects. During this process, it was observed\nthat band 4 (out of 7 bands of Landsat 5TM) is the band, which can be used for\nincreasing the accuracy of the combined bands in detecting objects on the land.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 09:48:10 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Tamouk", "Jamshid", ""], ["Lotfi", "Nasser", ""], ["Farmanbar", "Mina", ""]]}, {"id": "1308.1981", "submitter": "Oliver Cossairt", "authors": "Kaushik Mitra, Oliver Cossairt, Ashok Veeraraghavan", "title": "A Framework for the Analysis of Computational Imaging Systems with\n  Practical Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, a number of Computational Imaging (CI) systems have\nbeen proposed for tasks such as motion deblurring, defocus deblurring and\nmultispectral imaging. These techniques increase the amount of light reaching\nthe sensor via multiplexing and then undo the deleterious effects of\nmultiplexing by appropriate reconstruction algorithms. Given the widespread\nappeal and the considerable enthusiasm generated by these techniques, a\ndetailed performance analysis of the benefits conferred by this approach is\nimportant.\n  Unfortunately, a detailed analysis of CI has proven to be a challenging\nproblem because performance depends equally on three components: (1) the\noptical multiplexing, (2) the noise characteristics of the sensor, and (3) the\nreconstruction algorithm. A few recent papers have performed analysis taking\nmultiplexing and noise characteristics into account. However, analysis of CI\nsystems under state-of-the-art reconstruction algorithms, most of which exploit\nsignal prior models, has proven to be unwieldy. In this paper, we present a\ncomprehensive analysis framework incorporating all three components.\n  In order to perform this analysis, we model the signal priors using a\nGaussian Mixture Model (GMM). A GMM prior confers two unique characteristics.\nFirstly, GMM satisfies the universal approximation property which says that any\nprior density function can be approximated to any fidelity using a GMM with\nappropriate number of mixtures. Secondly, a GMM prior lends itself to\nanalytical tractability allowing us to derive simple expressions for the\n`minimum mean square error' (MMSE), which we use as a metric to characterize\nthe performance of CI systems. We use our framework to analyze several\npreviously proposed CI techniques, giving conclusive answer to the question:\n`How much performance gain is due to use of a signal prior and how much is due\nto multiplexing?\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 21:21:54 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2013 23:13:43 GMT"}, {"version": "v3", "created": "Thu, 13 Mar 2014 16:13:08 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Mitra", "Kaushik", ""], ["Cossairt", "Oliver", ""], ["Veeraraghavan", "Ashok", ""]]}, {"id": "1308.2292", "submitter": "Heike Benninghoff", "authors": "Heike Benninghoff and Harald Garcke", "title": "Fast image segmentation and restoration using parametric curve evolution\n  with junctions and topology changes", "comments": "26 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curve evolution schemes for image segmentation based on a region based\ncontour model allowing for junctions, vector-valued images and topology changes\nare introduced. Together with an a posteriori denoising in the segmented\nhomogeneous regions this leads to a fast and efficient method for image\nsegmentation and restoration. An uneven spread of mesh points is avoided by\nusing the tangential degrees of freedom. Several numerical simulations on\nartificial test problems and on real images illustrate the performance of the\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2013 08:19:02 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Benninghoff", "Heike", ""], ["Garcke", "Harald", ""]]}, {"id": "1308.2350", "submitter": "Bonny Banerjee", "authors": "Jayanta K. Dutta, Bonny Banerjee", "title": "Learning Features and their Transformations by Spatial and Temporal\n  Spherical Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning features invariant to arbitrary transformations in the data is a\nrequirement for any recognition system, biological or artificial. It is now\nwidely accepted that simple cells in the primary visual cortex respond to\nfeatures while the complex cells respond to features invariant to different\ntransformations. We present a novel two-layered feedforward neural model that\nlearns features in the first layer by spatial spherical clustering and\ninvariance to transformations in the second layer by temporal spherical\nclustering. Learning occurs in an online and unsupervised manner following the\nHebbian rule. When exposed to natural videos acquired by a camera mounted on a\ncat's head, the first and second layer neurons in our model develop simple and\ncomplex cell-like receptive field properties. The model can predict by learning\nlateral connections among the first layer neurons. A topographic map to their\nspatial features emerges by exponentially decaying the flow of activation with\ndistance from one neuron to another in the first layer that fire in close\ntemporal proximity, thereby minimizing the pooling length in an online manner\nsimultaneously with feature learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2013 22:56:26 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dutta", "Jayanta K.", ""], ["Banerjee", "Bonny", ""]]}, {"id": "1308.2464", "submitter": "Uri Ascher", "authors": "Hui Huang and Uri Ascher", "title": "Faster gradient descent and the efficient recovery of images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent attention has been devoted to gradient descent algorithms where\nthe steepest descent step size is replaced by a similar one from a previous\niteration or gets updated only once every second step, thus forming a {\\em\nfaster gradient descent method}. For unconstrained convex quadratic\noptimization these methods can converge much faster than steepest descent. But\nthe context of interest here is application to certain ill-posed inverse\nproblems, where the steepest descent method is known to have a smoothing,\nregularizing effect, and where a strict optimization solution is not necessary.\n  Specifically, in this paper we examine the effect of replacing steepest\ndescent by a faster gradient descent algorithm in the practical context of\nimage deblurring and denoising tasks. We also propose several highly efficient\nschemes for carrying out these tasks independently of the step size selection,\nas well as a scheme for the case where both blur and significant noise are\npresent.\n  In the above context there are situations where many steepest descent steps\nare required, thus building slowness into the solution procedure. Our general\nconclusion regarding gradient descent methods is that in such cases the faster\ngradient descent methods offer substantial advantages. In other situations\nwhere no such slowness buildup arises the steepest descent method can still be\nvery effective.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 05:33:39 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Huang", "Hui", ""], ["Ascher", "Uri", ""]]}, {"id": "1308.2654", "submitter": "Jose Maria Celaya Padilla Sr", "authors": "Jos\\'e M. Celaya-Padilla (1), Juan Rodriguez-Rojas (1), Victor Trevino\n  (1), Jos\\'e G. Gerardo Tamez-Pena (2) ((1) Instituto Tecnol\\'ogico y de\n  Estudios Superiores de Monterrey, Eugenio Garza Sada, Monterrey, Nuevo\n  Le\\'on, M\\'exico, (2) Dept. of Investigaci\\'on e Inovaci\\'on, Escuela de\n  Medicina, ITESM, Monterrey, NL, M\\'exico)", "title": "Local image registration a comparison for bilateral registration\n  mammography", "comments": "9 pages, Submitted to The 9th International Seminar on Medical\n  Information Processing and Analysis (formerly International Seminar on\n  Medical Image Processing and Analysis) (pending approval)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early tumor detection is key in reducing the number of breast cancer death\nand screening mammography is one of the most widely available and reliable\nmethod for early detection. However, it is difficult for the radiologist to\nprocess with the same attention each case, due the large amount of images to be\nread. Computer aided detection (CADe) systems improve tumor detection rate; but\nthe current efficiency of these systems is not yet adequate and the correct\ninterpretation of CADe outputs requires expert human intervention. Computer\naided diagnosis systems (CADx) are being designed to improve cancer diagnosis\naccuracy, but they have not been efficiently applied in breast cancer. CADx\nefficiency can be enhanced by considering the natural mirror symmetry between\nthe right and left breast. The objective of this work is to evaluate\nco-registration algorithms for the accurate alignment of the left to right\nbreast for CADx enhancement. A set of mammograms were artificially altered to\ncreate a ground truth set to evaluate the registration efficiency of DEMONs,\nand SPLINE deformable registration algorithms. The registration accuracy was\nevaluated using mean square errors, mutual information and correlation. The\nresults on the 132 images proved that the SPLINE deformable registration\nover-perform the DEMONS on mammography images.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 19:29:49 GMT"}], "update_date": "2013-08-13", "authors_parsed": [["Celaya-Padilla", "Jos\u00e9 M.", ""], ["Rodriguez-Rojas", "Juan", ""], ["Trevino", "Victor", ""], ["Tamez-Pena", "Jos\u00e9 G. Gerardo", ""]]}, {"id": "1308.3052", "submitter": "Wufeng Xue", "authors": "Wufeng Xue, Lei Zhang, Xuanqin Mou, and Alan C. Bovik", "title": "Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual\n  Image Quality Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  It is an important task to faithfully evaluate the perceptual quality of\noutput images in many applications such as image compression, image restoration\nand multimedia streaming. A good image quality assessment (IQA) model should\nnot only deliver high quality prediction accuracy but also be computationally\nefficient. The efficiency of IQA metrics is becoming particularly important due\nto the increasing proliferation of high-volume visual data in high-speed\nnetworks. We present a new effective and efficient IQA model, called gradient\nmagnitude similarity deviation (GMSD). The image gradients are sensitive to\nimage distortions, while different local structures in a distorted image suffer\ndifferent degrees of degradations. This motivates us to explore the use of\nglobal variation of gradient based local quality map for overall image quality\nprediction. We find that the pixel-wise gradient magnitude similarity (GMS)\nbetween the reference and distorted images combined with a novel pooling\nstrategy the standard deviation of the GMS map can predict accurately\nperceptual image quality. The resulting GMSD algorithm is much faster than most\nstate-of-the-art IQA methods, and delivers highly competitive prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 07:25:10 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 03:55:01 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Xue", "Wufeng", ""], ["Zhang", "Lei", ""], ["Mou", "Xuanqin", ""], ["Bovik", "Alan C.", ""]]}, {"id": "1308.3101", "submitter": "Christian H\\\"ane", "authors": "Christopher Zach and Christian H\\\"ane", "title": "Compact Relaxations for MAP Inference in Pairwise MRFs with Piecewise\n  Linear Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label assignment problems with large state spaces are important tasks\nespecially in computer vision. Often the pairwise interaction (or smoothness\nprior) between labels assigned at adjacent nodes (or pixels) can be described\nas a function of the label difference. Exact inference in such labeling tasks\nis still difficult, and therefore approximate inference methods based on a\nlinear programming (LP) relaxation are commonly used in practice. In this work\nwe study how compact linear programs can be constructed for general piecwise\nlinear smoothness priors. The number of unknowns is O(LK) per pairwise clique\nin terms of the state space size $L$ and the number of linear segments K. This\ncompares to an O(L^2) size complexity of the standard LP relaxation if the\npiecewise linear structure is ignored. Our compact construction and the\nstandard LP relaxation are equivalent and lead to the same (approximate) label\nassignment.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 12:27:24 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 17:51:30 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Zach", "Christopher", ""], ["H\u00e4ne", "Christian", ""]]}, {"id": "1308.3225", "submitter": "Mohamed Ben Halima", "authors": "M. Ben Halima, M. Hamroun, S. Ben Moussa and A. M. Alimi", "title": "An interactive engine for multilingual video browsing using semantic\n  content", "comments": "4 pages, IGS 2013 Conference; IGS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of audio-visual information has increased dramatically with the\nadvent of High Speed Internet. Furthermore, technological advances in recent\nyears in the field of information technology, have simplified the use of video\ndata in various fields by the general public. This made it possible to store\nlarge collections of video documents into computer systems. To enable efficient\nuse of these collections, it is necessary to develop tools to facilitate access\nto these documents and handling them. In this paper we propose a method for\nindexing and retrieval of video sequences in a video database of large\ndimension, based on a weighting technique to calculate the degree of membership\nof a concept in a video also a structuring of the data of the audio-visual\n(context / concept / video) and a relevance feedback mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 19:54:11 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Halima", "M. Ben", ""], ["Hamroun", "M.", ""], ["Moussa", "S. Ben", ""], ["Alimi", "A. M.", ""]]}, {"id": "1308.3243", "submitter": "Mohamed Ben Halima", "authors": "M. Ben Halima, H. Karray and A. M. Alimi", "title": "Arabic Text Recognition in Video Sequences", "comments": "10 pages - International Journal of Computational Linguistics\n  Research. arXiv admin note: substantial text overlap with arXiv:1211.2150", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a robust approach for text extraction and\nrecognition from Arabic news video sequence. The text included in video\nsequences is an important needful for indexing and searching system. However,\nthis text is difficult to detect and recognize because of the variability of\nits size, their low resolution characters and the complexity of the\nbackgrounds. To solve these problems, we propose a system performing in two\nmain tasks: extraction and recognition of text. Our system is tested on a\nvaried database composed of different Arabic news programs and the obtained\nresults are encouraging and show the merits of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 20:15:44 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Halima", "M. Ben", ""], ["Karray", "H.", ""], ["Alimi", "A. M.", ""]]}, {"id": "1308.3383", "submitter": "Twan van Laarhoven", "authors": "Twan van Laarhoven, Elena Marchiori", "title": "Axioms for graph clustering quality functions", "comments": "23 pages. Full text and sources available on:\n  http://www.cs.ru.nl/~T.vanLaarhoven/graph-clustering-axioms-2014/", "journal-ref": "Journal of Machine Learning Research, 15(Jan):193-215, 2014", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate properties that intuitively ought to be satisfied by graph\nclustering quality functions, that is, functions that assign a score to a\nclustering of a graph. Graph clustering, also known as network community\ndetection, is often performed by optimizing such a function. Two axioms\ntailored for graph clustering quality functions are introduced, and the four\naxioms introduced in previous work on distance based clustering are\nreformulated and generalized for the graph setting. We show that modularity, a\nstandard quality function for graph clustering, does not satisfy all of these\nsix properties. This motivates the derivation of a new family of quality\nfunctions, adaptive scale modularity, which does satisfy the proposed axioms.\nAdaptive scale modularity has two parameters, which give greater flexibility in\nthe kinds of clusterings that can be found. Standard graph clustering quality\nfunctions, such as normalized cut and unnormalized cut, are obtained as special\ncases of adaptive scale modularity.\n  In general, the results of our investigation indicate that the considered\naxiomatic framework covers existing `good' quality functions for graph\nclustering, and can be used to derive an interesting new family of quality\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 13:22:24 GMT"}, {"version": "v2", "created": "Tue, 22 Jul 2014 16:22:29 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""]]}, {"id": "1308.4189", "submitter": "Andrei Barbu", "authors": "N. Siddharth, Andrei Barbu, Jeffrey Mark Siskind", "title": "Seeing What You're Told: Sentence-Guided Activity Recognition In Video", "comments": "To appear in CVPR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that demonstrates how the compositional structure of\nevents, in concert with the compositional structure of language, can interplay\nwith the underlying focusing mechanisms in video action recognition, thereby\nproviding a medium, not only for top-down and bottom-up integration, but also\nfor multi-modal integration between vision and language. We show how the roles\nplayed by participants (nouns), their characteristics (adjectives), the actions\nperformed (verbs), the manner of such actions (adverbs), and changing spatial\nrelations between participants (prepositions) in the form of whole sentential\ndescriptions mediated by a grammar, guides the activity-recognition process.\nFurther, the utility and expressiveness of our framework is demonstrated by\nperforming three separate tasks in the domain of multi-activity videos:\nsentence-guided focus of attention, generation of sentential descriptions of\nvideo, and query-based video search, simply by leveraging the framework in\ndifferent manners.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 23:28:47 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 18:50:35 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Siddharth", "N.", ""], ["Barbu", "Andrei", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1308.4200", "submitter": "Erik Rodner", "authors": "Erik Rodner, Judy Hoffman, Jeff Donahue, Trevor Darrell, Kate Saenko", "title": "Towards Adapting ImageNet to Reality: Scalable Domain Adaptation with\n  Implicit Low-rank Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images seen during test time are often not from the same distribution as\nimages used for learning. This problem, known as domain shift, occurs when\ntraining classifiers from object-centric internet image databases and trying to\napply them directly to scene understanding tasks. The consequence is often\nsevere performance degradation and is one of the major barriers for the\napplication of classifiers in real-world systems. In this paper, we show how to\nlearn transform-based domain adaptation classifiers in a scalable manner. The\nkey idea is to exploit an implicit rank constraint, originated from a\nmax-margin domain adaptation formulation, to make optimization tractable.\nExperiments show that the transformation between domains can be very\nefficiently learned from data and easily applied to new categories. This begins\nto bridge the gap between large-scale internet image collections and object\nimages captured in everyday life environments.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 01:07:35 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Rodner", "Erik", ""], ["Hoffman", "Judy", ""], ["Donahue", "Jeff", ""], ["Darrell", "Trevor", ""], ["Saenko", "Kate", ""]]}, {"id": "1308.4338", "submitter": "Leonardo Torres", "authors": "Leonardo Torres and Alejandro C. Frery", "title": "SAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal\n  Means", "comments": "Accepted for publication in Workshop of Theses and Dissertations\n  (WTD) in Conference on Graphics, Patterns, and Images (SIBGRAPI 2013). This\n  paper received the first best work award in the Dissertation category at the\n  WTD-SIBGRAPI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two approaches for filter design based on stochastic\ndistances for intensity speckle reduction. A window is defined around each\npixel, overlapping samples are compared and only those which pass a\ngoodness-of-fit test are used to compute the filtered value. The tests stem\nfrom stochastic divergences within the Information Theory framework. The\ntechnique is applied to intensity Synthetic Aperture Radar (SAR) data with\nhomogeneous regions using the Gamma model. The first approach uses a\nNagao-Matsuyama-type procedure for setting the overlapping samples, and the\nsecond uses the nonlocal method. The proposals are compared with the Improved\nSigma filter and with anisotropic diffusion for speckled data (SRAD) using a\nprotocol based on Monte Carlo simulation. Among the criteria used to quantify\nthe quality of filters, we employ the equivalent number of looks, and line and\nedge preservation. Moreover, we also assessed the filters by the Universal\nImage Quality Index and by the Pearson correlation between edges. Applications\nto real images are also discussed. The proposed methods show good results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 15:58:19 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Torres", "Leonardo", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1308.4440", "submitter": "Firouz AL-Wassai", "authors": "AL-Wassai Firouz, N.V.Kalyankar", "title": "Influences Combination of Multi-Sensor Images on Classification Accuracy", "comments": "Available Online at http://www.ijarcs.info/ Volume 4, No. 9,\n  July-August 2013", "journal-ref": "International Journal of Advanced Research in Computer\n  Science,Volume 4, No. 9, July-August 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on two main issues; first one is the impact of combination\nof multi-sensor images on the supervised learning classification accuracy using\nsegment Fusion (SF). The second issue attempts to undertake the study of\nsupervised machine learning classification technique of remote sensing images\nby using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD),\nMaximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their\naccuracies have been evaluated on their respected classification to choose the\nbest technique for classification of remote sensing images. QuickBird\nmultispectral data (MS) and panchromatic data (PAN) have been used in this\nstudy to demonstrate the enhancement and accuracy assessment of fused image\nover the original images using ALwassaiProcess software. According to\nexperimental result of this study, is that the test results indicate the\nsupervised classification results of fusion image, which generated better than\nthe MS did. As well as the result with Euclidean classifier is robust and\nprovides better results than the other classifiers do, despite of the popular\nbelief that the maximum-likelihood classifier is the most accurate classifier.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 21:34:47 GMT"}], "update_date": "2013-08-22", "authors_parsed": [["Firouz", "AL-Wassai", ""], ["Kalyankar", "N. V.", ""]]}, {"id": "1308.4718", "submitter": "Radu Balan", "authors": "Radu Balan, Yang Wang", "title": "Invertibility and Robustness of Phaseless Reconstruction", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the question of reconstructing a vector in a\nfinite-dimensional real Hilbert space when only the magnitudes of the\ncoefficients of the vector under a redundant linear map are known. We analyze\nvarious Lipschitz bounds of the nonlinear analysis map and we establish\ntheoretical performance bounds of any reconstruction algorithm. We show that\nrobust and stable reconstruction requires additional redundancy than the\ncritical threshold.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2013 21:06:42 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Balan", "Radu", ""], ["Wang", "Yang", ""]]}, {"id": "1308.4902", "submitter": "Azmi Aini Najwa", "authors": "Aini Najwa Azmi, Dewi Nasien and Siti Mariyam Shamsuddin", "title": "A review on handwritten character and numeral recognition for Roman,\n  Arabic, Chinese and Indian scripts", "comments": "8 pages", "journal-ref": "International Journal of advanced studies in Computers, Science &\n  Engineering (IJASCSE), Volume 2, Issue 4, 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a lot of intensive researches on handwritten character recognition\n(HCR) for almost past four decades. The research has been done on some of\npopular scripts such as Roman, Arabic, Chinese and Indian. In this paper we\npresent a review on HCR work on the four popular scripts. We have summarized\nmost of the published paper from 2005 to recent and also analyzed the various\nmethods in creating a robust HCR system. We also added some future direction of\nresearch on HCR.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 15:38:15 GMT"}], "update_date": "2013-08-28", "authors_parsed": [["Azmi", "Aini Najwa", ""], ["Nasien", "Dewi", ""], ["Shamsuddin", "Siti Mariyam", ""]]}, {"id": "1308.4908", "submitter": "Joel Kronander", "authors": "Joel Kronander, Stefan Gustavson, Gerhard Bonnet, Anders Ynnerman and\n  Jonas Unger", "title": "A Unified Framework for Multi-Sensor HDR Video Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most successful approaches to modern high quality HDR-video\ncapture is to use camera setups with multiple sensors imaging the scene through\na common optical system. However, such systems pose several challenges for HDR\nreconstruction algorithms. Previous reconstruction techniques have considered\ndebayering, denoising, resampling (align- ment) and exposure fusion as separate\nproblems. In contrast, in this paper we present a unifying approach, performing\nHDR assembly directly from raw sensor data. Our framework includes a camera\nnoise model adapted to HDR video and an algorithm for spatially adaptive HDR\nreconstruction based on fitting of local polynomial approximations to observed\nsensor data. The method is easy to implement and allows reconstruction to an\narbitrary resolution and output mapping. We present an implementation in CUDA\nand show real-time performance for an experimental 4 Mpixel multi-sensor HDR\nvideo system. We further show that our algorithm has clear advantages over\nexisting methods, both in terms of flexibility and reconstruction quality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2013 15:58:01 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Kronander", "Joel", ""], ["Gustavson", "Stefan", ""], ["Bonnet", "Gerhard", ""], ["Ynnerman", "Anders", ""], ["Unger", "Jonas", ""]]}, {"id": "1308.5038", "submitter": "Ivan Selesnick", "authors": "Po-Yu Chen, Ivan W. Selesnick", "title": "Group-Sparse Signal Denoising: Non-Convex Regularization, Convex\n  Optimization", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": "10.1109/TSP.2014.2329274", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex optimization with sparsity-promoting convex regularization is a\nstandard approach for estimating sparse signals in noise. In order to promote\nsparsity more strongly than convex regularization, it is also standard practice\nto employ non-convex optimization. In this paper, we take a third approach. We\nutilize a non-convex regularization term chosen such that the total cost\nfunction (consisting of data consistency and regularization terms) is convex.\nTherefore, sparsity is more strongly promoted than in the standard convex\nformulation, but without sacrificing the attractive aspects of convex\noptimization (unique minimum, robust algorithms, etc.). We use this idea to\nimprove the recently developed 'overlapping group shrinkage' (OGS) algorithm\nfor the denoising of group-sparse signals. The algorithm is applied to the\nproblem of speech enhancement with favorable results in terms of both SNR and\nperceptual quality.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 03:32:57 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2013 19:18:49 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Chen", "Po-Yu", ""], ["Selesnick", "Ivan W.", ""]]}, {"id": "1308.5063", "submitter": "Yan  Zhang", "authors": "Panqu Wang, Yan Zhang", "title": "Suspicious Object Recognition Method in Video Stream Based on Visual\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a state of the art method for intelligent object recognition and\nvideo surveillance based on human visual attention. Bottom up and top down\nattention are applied respectively in the process of acquiring interested\nobject(saliency map) and object recognition. The revision of 4 channel PFT\nmethod is proposed for bottom up attention and enhances the speed and accuracy.\nInhibit of return (IOR) is applied in judging the sequence of saliency object\npop out. Euclidean distance of color distribution, object center coordinates\nand speed are considered in judging whether the target is match and suspicious.\nThe extensive tests on videos and images show that our method in video analysis\nhas high accuracy and fast speed compared with traditional method. The method\ncan be applied into many fields such as video surveillance and security.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 07:26:56 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Wang", "Panqu", ""], ["Zhang", "Yan", ""]]}, {"id": "1308.5315", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "Edge-detection applied to moving sand dunes on Mars", "comments": "Keywords: Edge detection, Sobel filter, GIMP, Image processing,\n  Google Mars, Dune motion, Mars Reconnaissance Orbiter, Mars Global Surveyor;\n  Ref.14 available at\n  http://www.scribd.com/doc/162390676/Moving-Sand-Dunes-on-Mars", "journal-ref": "International Journal of Sciences, 2013, 2(8):102-104", "doi": "10.18483/ijSci.251", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we discuss the application of an edge detection filter, the Sobel filter\nof GIMP, to the recently discovered motion of some sand dunes on Mars. The\nfilter allows a good comparison of an image HiRISE of 2007 and an image of 1999\nrecorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,\nmeasuring therefore the motion of the dunes on a longer period of time than\nthat previously investigated.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2013 11:07:05 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1308.5465", "submitter": "Radu Balan", "authors": "Radu Balan", "title": "Stability of Phase Retrievable Frames", "comments": "13 pages, presented at SPIE 2013 conference", "journal-ref": null, "doi": "10.1117/12.2026135", "report-no": null, "categories": "math.FA cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the property of phase retrievability by redundant\nsysems of vectors under perturbations of the frame set. Specifically we show\nthat if a set $\\fc$ of $m$ vectors in the complex Hilbert space of dimension n\nallows for vector reconstruction from magnitudes of its coefficients, then\nthere is a perturbation bound $\\rho$ so that any frame set within $\\rho$ from\n$\\fc$ has the same property. In particular this proves the recent construction\nin \\cite{BH13} is stable under perturbations. By the same token we reduce the\ncritical cardinality conjectured in \\cite{BCMN13a} to proving a stability\nresult for non phase-retrievable frames.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2013 23:59:15 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Balan", "Radu", ""]]}, {"id": "1308.5661", "submitter": "Nathalie Diane Wandji Nanda", "authors": "Nathalie Diane Wandji, Sun Xingming, Moise Fah Kue", "title": "Detection of copy-move forgery in digital images based on DCT", "comments": "Published in IJCSI (International Journal of Computer Science\n  Issues), Volume 10, Issue 2, No 1, March 2013", "journal-ref": "ISSN (Print): 1694-0814 | ISSN (Online): 1694-0784, International\n  Journal of Computer Science Issues (IJCSI), Volume 10, Issue 2, No 1, March\n  2013", "doi": null, "report-no": null, "categories": "cs.CV cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid advances in digital information processing systems, and more\nspecifically in digital image processing software, there is a widespread\ndevelopment of advanced tools and techniques for digital image forgery. One of\nthe techniques most commonly used is the Copy-move forgery which proceeds by\ncopying a part of an image and pasting it into the same image, in order to\nmaliciously hide an object or a region. In this paper, we propose a method to\ndetect this specific kind of counterfeit. Firstly, the color image is converted\nfrom RGB color space to YCbCr color space and then the R, G, B and Y-component\nare splitted into fixed-size overlapping blocks and, features are extracted\nfrom the R, G and B-components image blocks on one hand and on the other, from\nthe DCT representation of the R, G, B and Ycomponent image block. The feature\nvectors obtained are then lexicographically sorted to make similar image blocks\nneighbors and duplicated image blocks are identified using Euclidean distance\nas similarity criterion. Experimental results showed that the proposed method\ncan detect the duplicated regions when there is more than one copy move forged\narea in the image and even in case of slight rotations, JPEG compression,\nshift, scale, blur and noise addition.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 19:15:33 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Wandji", "Nathalie Diane", ""], ["Xingming", "Sun", ""], ["Kue", "Moise Fah", ""]]}, {"id": "1308.5876", "submitter": "Laura Rebollo-Neira", "authors": "Laura Rebollo-Neira, Ryszard Maciol and Shabnam Bibi", "title": "Hierarchized block wise image approximation by greedy pursuit strategies", "comments": "4 pages. An example and the computing routines for implementing the\n  approach are available on\n  http://www.nonlinear-approx.info/examples/node0.html", "journal-ref": null, "doi": "10.1109/LSP.2013.2283510", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach for effective implementation of greedy selection methodologies,\nto approximate an image partitioned into blocks, is proposed. The method is\nspecially designed for approximating partitions on a transformed image. It\nevolves by selecting, at each iteration step, i) the elements for approximating\neach of the blocks partitioning the image and ii) the hierarchized sequence in\nwhich the blocks are approximated to reach the required global condition on\nsparsity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 13:57:16 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Rebollo-Neira", "Laura", ""], ["Maciol", "Ryszard", ""], ["Bibi", "Shabnam", ""]]}, {"id": "1308.6056", "submitter": "Surya Prasath", "authors": "Juan C. Moreno, V. B. S. Prasath, Hugo Proenca, K. Palaniappan", "title": "Brain MRI Segmentation with Fast and Globally Convex Multiphase Active\n  Contours", "comments": null, "journal-ref": "Computer Vision and Image Understanding, 125, 237-250, 2014", "doi": "10.1016/j.cviu.2014.04.010", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiphase active contour based models are useful in identifying multiple\nregions with different characteristics such as the mean values of regions. This\nis relevant in brain magnetic resonance images (MRIs), allowing the\ndifferentiation of white matter against gray matter. We consider a well defined\nglobally convex formulation of Vese and Chan multiphase active contour model\nfor segmenting brain MRI images. A well-established theory and an efficient\ndual minimization scheme are thoroughly described which guarantees optimal\nsolutions and provides stable segmentations. Moreover, under the dual\nminimization implementation our model perfectly describes disjoint regions by\navoiding local minima solutions. Experimental results indicate that the\nproposed approach provides better accuracy than other related multiphase active\ncontour algorithms even under severe noise, intensity inhomogeneities, and\npartial volume effects.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 04:48:00 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Moreno", "Juan C.", ""], ["Prasath", "V. B. S.", ""], ["Proenca", "Hugo", ""], ["Palaniappan", "K.", ""]]}, {"id": "1308.6309", "submitter": "Nizar Zaghden", "authors": "Nizar Zaghden, Badreddine Khelifi, Adel M. Alimi, Remy Mullot", "title": "Text recognition in both ancient and cartographic documents", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the recognition and matching of text in both\ncartographic maps and ancient documents. The purpose of this work is to find\nsimilar text regions based on statistical and global features. A phase of\nnormalization is done first, in object to well categorize the same quantity of\ninformation. A phase of wordspotting is done next by combining local and global\nfeatures. We make different experiments by combining the different techniques\nof extracting features in order to obtain better results in recognition phase.\nWe applied fontspotting on both ancient documents and cartographic ones. We\nalso applied the wordspotting in which we adopted a new technique which tries\nto compare the images of character and not the entire images words. We present\nthe precision and recall values obtained with three methods for the new method\nof wordspotting applied on characters only.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 20:59:55 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Zaghden", "Nizar", ""], ["Khelifi", "Badreddine", ""], ["Alimi", "Adel M.", ""], ["Mullot", "Remy", ""]]}, {"id": "1308.6311", "submitter": "Nizar Zaghden", "authors": "Nizar Zaghden, Remy Mullot, Mohamed Adel Alimi", "title": "Categorizing ancient documents", "comments": "10 pages", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 10,\n  Issue 2, No 2, March 2013 ISSN (Print): 1694-0814 | ISSN (Online): 1694-0784\n  www.IJCSI.org", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of historical documents is still a topical issue given the\nimportance of information that can be extracted and also the importance given\nby the institutions to preserve their heritage. The main idea in order to\ncharacterize the content of the images of ancient documents after attempting to\nclean the image is segmented blocks texts from the same image and tries to find\nsimilar blocks in either the same image or the entire image database. Most\napproaches of offline handwriting recognition proceed by segmenting words into\nsmaller pieces (usually characters) which are recognized separately.\nRecognition of a word then requires the recognition of all characters (OCR)\nthat compose it. Our work focuses mainly on the characterization of classes in\nimages of old documents. We use Som toolbox for finding classes in documents.\nWe applied also fractal dimensions and points of interest to categorize and\nmatch ancient documents.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 21:09:35 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Zaghden", "Nizar", ""], ["Mullot", "Remy", ""], ["Alimi", "Mohamed Adel", ""]]}, {"id": "1308.6319", "submitter": "Nizar Zaghden", "authors": "Nizar Zaghden, Remy Mullot, Mohamed Adel Alimi", "title": "A proposition of a robust system for historical document images\n  indexation", "comments": "7 pages", "journal-ref": "International Journal of Computer Applications, volume 11 N 2,\n  December 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing noisy or ancient documents is a challenging problem up to now.\nMany techniques have been done in order to effectuate feature extraction and\nimage indexation for such documents. Global approaches are in general less\nrobust and exact than local approaches. That's why, we propose in this paper, a\nhybrid system based on global approach(fractal dimension), and a local one\nbased on SIFT descriptor. The Scale Invariant Feature Transform seems to do\nwell with our application since it's rotation invariant and relatively robust\nto changing illumination.In the first step the calculation of fractal dimension\nis applied to images in order to eliminate images which have distant features\nthan image request characteristics. Next, the SIFT is applied to show which\nimages match well the request. However the average matching time using the\nhybrid approach is better than \"fractal dimension\" and \"SIFT descriptor\" if\nthey are used alone.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 21:37:08 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Zaghden", "Nizar", ""], ["Mullot", "Remy", ""], ["Alimi", "Mohamed Adel", ""]]}, {"id": "1308.6388", "submitter": "Zhi-Yong Liu", "authors": "Zhi-Yong Liu and Hong Qiao", "title": "GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the Graduated NonConvexity and Graduated Concavity\nProcedure (GNCGCP) as a general optimization framework to approximately solve\nthe combinatorial optimization problems on the set of partial permutation\nmatrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC)\nwhich realizes a convex relaxation and graduated concavity (GC) which realizes\na concave relaxation. It is proved that GNCGCP realizes exactly a type of\nconvex-concave relaxation procedure (CCRP), but with a much simpler formulation\nwithout needing convex or concave relaxation in an explicit way. Actually,\nGNCGCP involves only the gradient of the objective function and is therefore\nvery easy to use in practical applications. Two typical NP-hard problems,\n(sub)graph matching and quadratic assignment problem (QAP), are employed to\ndemonstrate its simplicity and state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 08:00:20 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Liu", "Zhi-Yong", ""], ["Qiao", "Hong", ""]]}, {"id": "1308.6401", "submitter": "Karim Hammoudi KH", "authors": "Karim Hammoudi, Fadi Dornaika, Bahman Soheilian, Bruno Vallet, John\n  McDonald, Nicolas Paparoditis", "title": "A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of\n  Urban Facades from Heterogeneous Cartographic Data", "comments": null, "journal-ref": "International Journal of Advanced Robotic Systems, vol. 10, 10p.,\n  2013", "doi": "10.5772/56570", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper we present a practical approach for generating an\nocclusion-free textured 3D map of urban facades by the synergistic use of\nterrestrial images, 3D point clouds and area-based information. Particularly in\ndense urban environments, the high presence of urban objects in front of the\nfacades causes significant difficulties for several stages in computational\nbuilding modeling. Major challenges lie on the one hand in extracting complete\n3D facade quadrilateral delimitations and on the other hand in generating\nocclusion-free facade textures. For these reasons, we describe a\nstraightforward approach for completing and recovering facade geometry and\ntextures by exploiting the data complementarity of terrestrial multi-source\nimagery and area-based information.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 08:47:09 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Hammoudi", "Karim", ""], ["Dornaika", "Fadi", ""], ["Soheilian", "Bahman", ""], ["Vallet", "Bruno", ""], ["McDonald", "John", ""], ["Paparoditis", "Nicolas", ""]]}, {"id": "1308.6487", "submitter": "Leonardo Torres", "authors": "Leonardo Torres and Tamer Cavalcante and Alejandro C. Frery", "title": "A New Algorithm of Speckle Filtering using Stochastic Distances", "comments": "Accepted for publication on the proceedings of the IEEE Geoscience\n  and Remote Sensing Symposium (IGARSS 2012), to be published in IEEE Press.\n  Available: http://www.igarss2012.org/Papers/viewpapers.asp?papernum=4877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for filter design based on stochastic\ndistances and tests between distributions. A window is defined around each\npixel, overlapping samples are compared and only those which pass a\ngoodness-of-fit test are used to compute the filtered value. The technique is\napplied to intensity SAR data with homogeneous regions using the Gamma model.\nThe proposal is compared with the Lee's filter using a protocol based on Monte\nCarlo. Among the criteria used to quantify the quality of filters, we employ\nthe equivalent number of looks, line and edge preservation. Moreover, we also\nassessed the filters by the Universal Image Quality Index and the Pearson's\ncorrelation on edges regions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 14:56:01 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Torres", "Leonardo", ""], ["Cavalcante", "Tamer", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1308.6628", "submitter": "Kewei Tu", "authors": "Kewei Tu, Meng Meng, Mun Wai Lee, Tae Eun Choe, Song-Chun Zhu", "title": "Joint Video and Text Parsing for Understanding Events and Answering\n  Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for parsing video and text jointly for understanding\nevents and answering user queries. Our framework produces a parse graph that\nrepresents the compositional structures of spatial information (objects and\nscenes), temporal information (actions and events) and causal information\n(causalities between events and fluents) in the video and text. The knowledge\nrepresentation of our framework is based on a spatial-temporal-causal And-Or\ngraph (S/T/C-AOG), which jointly models possible hierarchical compositions of\nobjects, scenes and events as well as their interactions and mutual contexts,\nand specifies the prior probabilistic distribution of the parse graphs. We\npresent a probabilistic generative model for joint parsing that captures the\nrelations between the input video/text, their corresponding parse graphs and\nthe joint parse graph. Based on the probabilistic model, we propose a joint\nparsing system consisting of three modules: video parsing, text parsing and\njoint inference. Video parsing and text parsing produce two parse graphs from\nthe input video and text respectively. The joint inference module produces a\njoint parse graph by performing matching, deduction and revision on the video\nand text parse graphs. The proposed framework has the following objectives:\nFirstly, we aim at deep semantic parsing of video and text that goes beyond the\ntraditional bag-of-words approaches; Secondly, we perform parsing and reasoning\nacross the spatial, temporal and causal dimensions based on the joint S/T/C-AOG\nrepresentation; Thirdly, we show that deep joint parsing facilitates subsequent\napplications such as generating narrative text descriptions and answering\nqueries in the forms of who, what, when, where and why. We empirically\nevaluated our system based on comparison against ground-truth as well as\naccuracy of query answering and obtained satisfactory results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2013 23:45:02 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2014 05:24:09 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Tu", "Kewei", ""], ["Meng", "Meng", ""], ["Lee", "Mun Wai", ""], ["Choe", "Tae Eun", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1308.6687", "submitter": "Pengfei Zhu", "authors": "Pengfei Zhu, Wangmeng Zuo, Lei Zhang, Simon C.K. Shiu, David Zhang", "title": "Image Set based Collaborative Representation for Face Recognition", "comments": null, "journal-ref": "IEEE Transactions on Information Forensics and Security, Volume 9,\n  Issue 7, May 2014, Pages 1120-1132", "doi": "10.1109/TIFS.2014.2324277", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  With the rapid development of digital imaging and communication technologies,\nimage set based face recognition (ISFR) is becoming increasingly important. One\nkey issue of ISFR is how to effectively and efficiently represent the query\nface image set by using the gallery face image sets. The set-to-set distance\nbased methods ignore the relationship between gallery sets, while representing\nthe query set images individually over the gallery sets ignores the correlation\nbetween query set images. In this paper, we propose a novel image set based\ncollaborative representation and classification method for ISFR. By modeling\nthe query set as a convex or regularized hull, we represent this hull\ncollaboratively over all the gallery sets. With the resolved representation\ncoefficients, the distance between the query set and each gallery set can then\nbe calculated for classification. The proposed model naturally and effectively\nextends the image based collaborative representation to an image set based one,\nand our extensive experiments on benchmark ISFR databases show the superiority\nof the proposed method to state-of-the-art ISFR methods under different set\nsizes in terms of both recognition rate and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 09:08:56 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Zhu", "Pengfei", ""], ["Zuo", "Wangmeng", ""], ["Zhang", "Lei", ""], ["Shiu", "Simon C. K.", ""], ["Zhang", "David", ""]]}, {"id": "1308.6721", "submitter": "Puneet Kumar", "authors": "Pierre-Yves Baudin (INRIA Saclay - Ile de France), Danny Goodman,\n  Puneet Kumar (INRIA Saclay - Ile de France, CVN), Noura Azzabou (MIRCEN,\n  UPMC), Pierre G. Carlier (UPMC), Nikos Paragios (INRIA Saclay - Ile de\n  France, MAS, LIGM, ENPC), M. Pawan Kumar (INRIA Saclay - Ile de France, CVN)", "title": "Discriminative Parameter Estimation for Random Walks Segmentation", "comments": "Medical Image Computing and Computer Assisted Interventaion (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use\nprobabilistic segmentation methods. By combining contrast terms with prior\nterms, it provides accurate segmentations of medical images in a fully\nautomated manner. However, one of the main drawbacks of using the RW algorithm\nis that its parameters have to be hand-tuned. we propose a novel discriminative\nlearning framework that estimates the parameters using a training dataset. The\nmain challenge we face is that the training samples are not fully supervised.\nSpeci cally, they provide a hard segmentation of the images, instead of a\nproba- bilistic segmentation. We overcome this challenge by treating the opti-\nmal probabilistic segmentation that is compatible with the given hard\nsegmentation as a latent variable. This allows us to employ the latent support\nvector machine formulation for parameter estimation. We show that our approach\nsigni cantly outperforms the baseline methods on a challenging dataset\nconsisting of real clinical 3D MRI volumes of skeletal muscles.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 12:13:11 GMT"}], "update_date": "2013-09-02", "authors_parsed": [["Baudin", "Pierre-Yves", "", "INRIA Saclay - Ile de France"], ["Goodman", "Danny", "", "INRIA Saclay - Ile de France, CVN"], ["Kumar", "Puneet", "", "INRIA Saclay - Ile de France, CVN"], ["Azzabou", "Noura", "", "MIRCEN,\n  UPMC"], ["Carlier", "Pierre G.", "", "UPMC"], ["Paragios", "Nikos", "", "INRIA Saclay - Ile de\n  France, MAS, LIGM, ENPC"], ["Kumar", "M. Pawan", "", "INRIA Saclay - Ile de France, CVN"]]}, {"id": "1308.6804", "submitter": "Alan Brunton", "authors": "Alan Brunton, Michael Wand, Stefanie Wuhrer, Hans-Peter Seidel, Tino\n  Weinkauf", "title": "A Low-Dimensional Representation for Robust Partial Isometric\n  Correspondences Computation", "comments": "17 pages, 12 figures", "journal-ref": "Graphical Models, 76(2), pp. 70--85, March 2014", "doi": "10.1016/j.gmod.2013.11.003", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic isometric shape matching has become the standard approach for pose\ninvariant correspondence estimation among deformable shapes. Most existing\napproaches assume global consistency, i.e., the metric structure of the whole\nmanifold must not change significantly. While global isometric matching is well\nunderstood, only a few heuristic solutions are known for partial matching.\nPartial matching is particularly important for robustness to topological noise\n(incomplete data and contacts), which is a common problem in real-world 3D\nscanner data. In this paper, we introduce a new approach to partial, intrinsic\nisometric matching. Our method is based on the observation that isometries are\nfully determined by purely local information: a map of a single point and its\ntangent space fixes an isometry for both global and the partial maps. From this\nidea, we develop a new representation for partial isometric maps based on\nequivalence classes of correspondences between pairs of points and their\ntangent spaces. From this, we derive a local propagation algorithm that find\nsuch mappings efficiently. In contrast to previous heuristics based on RANSAC\nor expectation maximization, our method is based on a simple and sound\ntheoretical model and fully deterministic. We apply our approach to register\npartial point clouds and compare it to the state-of-the-art methods, where we\nobtain significant improvements over global methods for real-world data and\nstronger guarantees than previous heuristic partial matching algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 17:38:40 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2014 11:20:26 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Brunton", "Alan", ""], ["Wand", "Michael", ""], ["Wuhrer", "Stefanie", ""], ["Seidel", "Hans-Peter", ""], ["Weinkauf", "Tino", ""]]}]