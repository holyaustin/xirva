[{"id": "1002.0382", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Massimo Tistarelli, Jamuna Kanta Sing, Phalguni\n  Gupta", "title": "Face Recognition by Fusion of Local and Global Matching Scores using DS\n  Theory: An Evaluation with Uni-classifier and Multi-classifier Paradigm", "comments": "7 pages, 6 figures, IEEE Computer Vision and Pattern Recognition\n  Workshop on Biometrics", "journal-ref": null, "doi": "10.1109/CVPRW.2009.5204298", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faces are highly deformable objects which may easily change their appearance\nover time. Not all face areas are subject to the same variability. Therefore\ndecoupling the information from independent areas of the face is of paramount\nimportance to improve the robustness of any face recognition technique. This\npaper presents a robust face recognition technique based on the extraction and\nmatching of SIFT features related to independent face areas. Both a global and\nlocal (as recognition from parts) matching strategy is proposed. The local\nstrategy is based on matching individual salient facial SIFT features as\nconnected to facial landmarks such as the eyes and the mouth. As for the global\nmatching strategy, all SIFT features are combined together to form a single\nfeature. In order to reduce the identification errors, the Dempster-Shafer\ndecision theory is applied to fuse the two matching techniques. The proposed\nalgorithms are evaluated with the ORL and the IITK face databases. The\nexperimental results demonstrate the effectiveness and potential of the\nproposed face recognition techniques also in the case of partially occluded\nfaces or with missing information.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 02:22:58 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Tistarelli", "Massimo", ""], ["Sing", "Jamuna Kanta", ""], ["Gupta", "Phalguni", ""]]}, {"id": "1002.0383", "submitter": "Dakshina Ranjan Kisku", "authors": "Hunny Mehrotra, Dakshina Ranjan Kisku, V. Bhawani Radhika, Banshidhar\n  Majhi, Phalguni Gupta", "title": "Feature Level Clustering of Large Biometric Database", "comments": "4 pages, 2 figures, IAPR International Conference on Machine Vision\n  Applications, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient technique for partitioning large biometric\ndatabase during identification. In this technique feature vector which\ncomprises of global and local descriptors extracted from offline signature are\nused by fuzzy clustering technique to partition the database. As biometric\nfeatures posses no natural order of sorting, thus it is difficult to index them\nalphabetically or numerically. Hence, some supervised criteria is required to\npartition the search space. At the time of identification the fuzziness\ncriterion is introduced to find the nearest clusters for declaring the identity\nof query sample. The system is tested using bin-miss rate and performs better\nin comparison to traditional k-means approach.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 02:30:22 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Mehrotra", "Hunny", ""], ["Kisku", "Dakshina Ranjan", ""], ["Radhika", "V. Bhawani", ""], ["Majhi", "Banshidhar", ""], ["Gupta", "Phalguni", ""]]}, {"id": "1002.0411", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Ajita Rattani, Enrico Grosso, Massimo\n  Tistarelli", "title": "Face Identification by SIFT-based Complete Graph Topology", "comments": "6 pages, 7 figures, AutoId 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents a new face identification system based on Graph Matching\nTechnique on SIFT features extracted from face images. Although SIFT features\nhave been successfully used for general object detection and recognition, only\nrecently they were applied to face recognition. This paper further investigates\nthe performance of identification techniques based on Graph matching topology\ndrawn on SIFT features which are invariant to rotation, scaling and\ntranslation. Face projections on images, represented by a graph, can be matched\nonto new images by maximizing a similarity function taking into account spatial\ndistortions and the similarities of the local features. Two graph based\nmatching techniques have been investigated to deal with false pair assignment\nand reducing the number of features to find the optimal feature set between\ndatabase and query face SIFT features. The experimental results, performed on\nthe BANCA database, demonstrate the effectiveness of the proposed system for\nautomatic face identification.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 08:00:33 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Rattani", "Ajita", ""], ["Grosso", "Enrico", ""], ["Tistarelli", "Massimo", ""]]}, {"id": "1002.0412", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Hunny Mehrotra, Phalguni Gupta, and Jamuna\n  Kanta Sing", "title": "SIFT-based Ear Recognition by Fusion of Detected Keypoints from Color\n  Similarity Slice Regions", "comments": "6 pages, 4 figures, ACTEA 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Ear biometric is considered as one of the most reliable and invariant\nbiometrics characteristics in line with iris and fingerprint characteristics.\nIn many cases, ear biometrics can be compared with face biometrics regarding\nmany physiological and texture characteristics. In this paper, a robust and\nefficient ear recognition system is presented, which uses Scale Invariant\nFeature Transform (SIFT) as feature descriptor for structural representation of\near images. In order to make it more robust to user authentication, only the\nregions having color probabilities in a certain ranges are considered for\ninvariant SIFT feature extraction, where the K-L divergence is used for keeping\ncolor consistency. Ear skin color model is formed by Gaussian mixture model and\nclustering the ear color pattern using vector quantization. Finally, K-L\ndivergence is applied to the GMM framework for recording the color similarity\nin the specified ranges by comparing color similarity between a pair of\nreference model and probe ear images. After segmentation of ear images in some\ncolor slice regions, SIFT keypoints are extracted and an augmented vector of\nextracted SIFT features are created for matching, which is accomplished between\na pair of reference model and probe ear images. The proposed technique has been\ntested on the IITK Ear database and the experimental results show improvements\nin recognition accuracy while invariant features are extracted from color slice\nregions to maintain the robustness of the system.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 08:06:04 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Mehrotra", "Hunny", ""], ["Gupta", "Phalguni", ""], ["Sing", "Jamuna Kanta", ""]]}, {"id": "1002.0414", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing", "title": "Feature Level Fusion of Biometrics Cues: Human Identification with\n  Doddingtons Caricature", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents a multimodal biometric system of fingerprint and ear\nbiometrics. Scale Invariant Feature Transform (SIFT) descriptor based feature\nsets extracted from fingerprint and ear are fused. The fused set is encoded by\nK-medoids partitioning approach with less number of feature points in the set.\nK-medoids partition the whole dataset into clusters to minimize the error\nbetween data points belonging to the clusters and its center. Reduced feature\nset is used to match between two biometric sets. Matching scores are generated\nusing wolf-lamb user-dependent feature weighting scheme introduced by\nDoddington. The technique is tested to exhibit its robust performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 08:12:23 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Gupta", "Phalguni", ""], ["Sing", "Jamuna Kanta", ""]]}, {"id": "1002.0416", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Phalguni Gupta, Jamuna Kanta Sing", "title": "Fusion of Multiple Matchers using SVM for Offline Signature\n  Identification", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers\nfor an offline signature system. From the signature images, global and local\nfeatures are extracted and the signatures are verified with the help of\nGaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.\nSVM is used to fuse matching scores of these matchers. Finally, recognition of\nquery signatures is done by comparing it with all signatures of the database.\nThe proposed system is tested on a signature database contains 5400 offline\nsignatures of 600 individuals and the results are found to be promising.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 08:15:20 GMT"}], "update_date": "2010-02-04", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Gupta", "Phalguni", ""], ["Sing", "Jamuna Kanta", ""]]}, {"id": "1002.1148", "submitter": "Vishal Goyal", "authors": "Salem Saleh Al-amri, N. V. Kalyankar, S.D. Khamitkar", "title": "A Comparative Study of Removal Noise from Remote Sensing Image", "comments": "International Journal of Computer Science Issues, IJCSI, Vol. 7,\n  Issue 1, No. 1, January 2010,\n  http://ijcsi.org/articles/A-Comparative-Study-of-Removal-Noise-from-Remote-Sensing-Image.php", "journal-ref": "International Journal of Computer Science Issues, IJCSI, Vol. 7,\n  Issue 1, No. 1, January 2010,\n  http://ijcsi.org/articles/A-Comparative-Study-of-Removal-Noise-from-Remote-Sensing-Image.php", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to undertake the study of three types of noise such as\nSalt and Pepper (SPN), Random variation Impulse Noise (RVIN), Speckle (SPKN).\nDifferent noise densities have been removed between 10% to 60% by using five\ntypes of filters as Mean Filter (MF), Adaptive Wiener Filter (AWF), Gaussian\nFilter (GF), Standard Median Filter (SMF) and Adaptive Median Filter (AMF). The\nsame is applied to the Saturn remote sensing image and they are compared with\none another. The comparative study is conducted with the help of Mean Square\nErrors (MSE) and Peak-Signal to Noise Ratio (PSNR). So as to choose the base\nmethod for removal of noise from remote sensing image.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2010 08:34:39 GMT"}], "update_date": "2010-02-08", "authors_parsed": [["Al-amri", "Salem Saleh", ""], ["Kalyankar", "N. V.", ""], ["Khamitkar", "S. D.", ""]]}, {"id": "1002.1285", "submitter": "Ula\\c{s} Ba\\u{g}ci", "authors": "Ulas Bagci, Jayaram K. Udupa, Li Bai", "title": "The Influence of Intensity Standardization on Medical Image Registration", "comments": "SPIE Medical Imaging 2010 conference paper, and the complete version\n  of this paper was published in Elsevier Pattern Recognition Letters, volume\n  31, 2010", "journal-ref": null, "doi": "10.1117/12.843969", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquisition-to-acquisition signal intensity variations (non-standardness) are\ninherent in MR images. Standardization is a post processing method for\ncorrecting inter-subject intensity variations through transforming all images\nfrom the given image gray scale into a standard gray scale wherein similar\nintensities achieve similar tissue meanings. The lack of a standard image\nintensity scale in MRI leads to many difficulties in tissue characterizability,\nimage display, and analysis, including image segmentation. This phenomenon has\nbeen documented well; however, effects of standardization on medical image\nregistration have not been studied yet. In this paper, we investigate the\ninfluence of intensity standardization in registration tasks with systematic\nand analytic evaluations involving clinical MR images. We conducted nearly\n20,000 clinical MR image registration experiments and evaluated the quality of\nregistrations both quantitatively and qualitatively. The evaluations show that\nintensity variations between images degrades the accuracy of registration\nperformance. The results imply that the accuracy of image registration not only\ndepends on spatial and geometric similarity but also on the similarity of the\nintensity values for the same tissues in different images.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2010 17:35:49 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bagci", "Ulas", ""], ["Udupa", "Jayaram K.", ""], ["Bai", "Li", ""]]}, {"id": "1002.1288", "submitter": "Ula\\c{s} Ba\\u{g}ci", "authors": "Ulas Bagci, Jayaram K. Udupa, Xinjian Chen", "title": "Ball-Scale Based Hierarchical Multi-Object Recognition in 3D Medical\n  Images", "comments": "This paper was published and presented in SPIE Medical Imaging 2010", "journal-ref": null, "doi": "10.1117/12.839920", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates, using prior shape models and the concept of ball\nscale (b-scale), ways of automatically recognizing objects in 3D images without\nperforming elaborate searches or optimization. That is, the goal is to place\nthe model in a single shot close to the right pose (position, orientation, and\nscale) in a given image so that the model boundaries fall in the close vicinity\nof object boundaries in the image. This is achieved via the following set of\nkey ideas: (a) A semi-automatic way of constructing a multi-object shape model\nassembly. (b) A novel strategy of encoding, via b-scale, the pose relationship\nbetween objects in the training images and their intensity patterns captured in\nb-scale images. (c) A hierarchical mechanism of positioning the model, in a\none-shot way, in a given image from a knowledge of the learnt pose relationship\nand the b-scale image of the given image to be segmented. The evaluation\nresults on a set of 20 routine clinical abdominal female and male CT data sets\nindicate the following: (1) Incorporating a large number of objects improves\nthe recognition accuracy dramatically. (2) The recognition algorithm can be\nthought as a hierarchical framework such that quick replacement of the model\nassembly is defined as coarse recognition and delineation itself is known as\nfinest recognition. (3) Scale yields useful information about the relationship\nbetween the model assembly and any given image such that the recognition\nresults in a placement of the model close to the actual pose without doing any\nelaborate searches or optimization. (4) Effective object recognition can make\ndelineation most accurate.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2010 17:54:36 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bagci", "Ulas", ""], ["Udupa", "Jayaram K.", ""], ["Chen", "Xinjian", ""]]}, {"id": "1002.1727", "submitter": "Shujun Li Dr.", "authors": "Shujun Li, Junaid Jameel Ahmad, Dietmar Saupe and C.-C. Jay Kuo", "title": "An Improved DC Recovery Method from AC Coefficients of DCT-Transformed\n  Images", "comments": "6 pages, 6 figures, ICIP 2010", "journal-ref": "Proceedings of 2010 17th IEEE International Conference on Image\n  Processing (ICIP 2010), pages 2085-2088, IEEE, 2010", "doi": "10.1109/ICIP.2010.5653467", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the work of Uehara et al. [1], an improved method to recover DC\ncoefficients from AC coefficients of DCT-transformed images is investigated in\nthis work, which finds applications in cryptanalysis of selective multimedia\nencryption. The proposed under/over-flow rate minimization (FRM) method employs\nan optimization process to get a statistically more accurate estimation of\nunknown DC coefficients, thus achieving a better recovery performance. It was\nshown by experimental results based on 200 test images that the proposed DC\nrecovery method significantly improves the quality of most recovered images in\nterms of the PSNR values and several state-of-the-art objective image quality\nassessment (IQA) metrics such as SSIM and MS-SSIM.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2010 22:05:04 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2010 12:56:41 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2010 20:50:53 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Li", "Shujun", ""], ["Ahmad", "Junaid Jameel", ""], ["Saupe", "Dietmar", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1002.2050", "submitter": "Bo Zhang", "authors": "Mingyu Fan, Nannan Gu, Hong Qiao, Bo Zhang", "title": "Intrinsic dimension estimation of data by principal component analysis", "comments": "8 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating intrinsic dimensionality of data is a classic problem in pattern\nrecognition and statistics. Principal Component Analysis (PCA) is a powerful\ntool in discovering dimensionality of data sets with a linear structure; it,\nhowever, becomes ineffective when data have a nonlinear structure. In this\npaper, we propose a new PCA-based method to estimate intrinsic dimension of\ndata with nonlinear structures. Our method works by first finding a minimal\ncover of the data set, then performing PCA locally on each subset in the cover\nand finally giving the estimation result by checking up the data variance on\nall small neighborhood regions. The proposed method utilizes the whole data set\nto estimate its intrinsic dimension and is convenient for incremental learning.\nIn addition, our new PCA procedure can filter out noise in data and converge to\na stable estimation with the neighborhood region size increasing. Experiments\non synthetic and real world data sets show effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 10:16:57 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Fan", "Mingyu", ""], ["Gu", "Nannan", ""], ["Qiao", "Hong", ""], ["Zhang", "Bo", ""]]}, {"id": "1002.2182", "submitter": "Rdv Ijcsis", "authors": "T. Balakumaran, I.L.A. Vennila, C. Gowri Shankar", "title": "Detection of Microcalcification in Mammograms Using Wavelet Transform\n  and Fuzzy Shell Clustering", "comments": "IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 121-125, January 2010, USA", "doi": null, "report-no": "Journal of Computer Science, ISSN 19475500", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microcalcifications in mammogram have been mainly targeted as a reliable\nearliest sign of breast cancer and their early detection is vital to improve\nits prognosis. Since their size is very small and may be easily overlooked by\nthe examining radiologist, computer-based detection output can assist the\nradiologist to improve the diagnostic accuracy. In this paper, we have proposed\nan algorithm for detecting microcalcification in mammogram. The proposed\nmicrocalcification detection algorithm involves mammogram quality enhancement\nusing multirresolution analysis based on the dyadic wavelet transform and\nmicrocalcification detection by fuzzy shell clustering. It may be possible to\ndetect nodular components such as microcalcification accurately by introducing\nshape information. The effectiveness of the proposed algorithm for\nmicrocalcification detection is confirmed by experimental results.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 19:22:25 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Balakumaran", "T.", ""], ["Vennila", "I. L. A.", ""], ["Shankar", "C. Gowri", ""]]}, {"id": "1002.2184", "submitter": "Rdv Ijcsis", "authors": "V. Ashok, T. Balakumaran, C. Gowrishankar, I.L.A. Vennila, A. Nirmal\n  kumar", "title": "The Fast Haar Wavelet Transform for Signal & Image Processing", "comments": "IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 126-130, January 2010, USA", "doi": null, "report-no": "Journal of Computer Science, ISSN 19475500", "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for the design of Fast Haar wavelet for signal processing and image\nprocessing has been proposed. In the proposed work, the analysis bank and\nsynthesis bank of Haar wavelet is modified by using polyphase structure.\nFinally, the Fast Haar wavelet was designed and it satisfies alias free and\nperfect reconstruction condition. Computational time and computational\ncomplexity is reduced in Fast Haar wavelet transform.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 19:27:25 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Ashok", "V.", ""], ["Balakumaran", "T.", ""], ["Gowrishankar", "C.", ""], ["Vennila", "I. L. A.", ""], ["kumar", "A. Nirmal", ""]]}, {"id": "1002.2191", "submitter": "Rdv Ijcsis", "authors": "S. Sumathi, S. K. Srivatsa, M. Uma Maheswari", "title": "Vision Based Game Development Using Human Computer Interaction", "comments": "IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 147-153, January 2010, USA", "doi": null, "report-no": "Journal of Computer Science, ISSN 19475500", "categories": "cs.HC cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Human Computer Interface (HCI) System for playing games is designed here\nfor more natural communication with the machines. The system presented here is\na vision-based system for detection of long voluntary eye blinks and\ninterpretation of blink patterns for communication between man and machine.\nThis system replaces the mouse with the human face as a new way to interact\nwith the computer. Facial features (nose tip and eyes) are detected and tracked\nin realtime to use their actions as mouse events. The coordinates and movement\nof the nose tip in the live video feed are translated to become the coordinates\nand movement of the mouse pointer on the application. The left or right eye\nblinks fire left or right mouse click events. The system works with inexpensive\nUSB cameras and runs at a frame rate of 30 frames per second.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 19:46:07 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Sumathi", "S.", ""], ["Srivatsa", "S. K.", ""], ["Maheswari", "M. Uma", ""]]}, {"id": "1002.2408", "submitter": "Rdv Ijcsis", "authors": "D. Jayanthi, N. Devi, S. SwarnaParvathi", "title": "Automatic diagnosis of retinal diseases from color retinal images", "comments": "IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 234-238, January 2010, USA", "doi": null, "report-no": "Journal of Computer Science, ISSN 1947 5500", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teleophthalmology holds a great potential to improve the quality, access, and\naffordability in health care. For patients, it can reduce the need for travel\nand provide the access to a superspecialist. Ophthalmology lends itself easily\nto telemedicine as it is a largely image based diagnosis. The main goal of the\nproposed system is to diagnose the type of disease in the retina and to\nautomatically detect and segment retinal diseases without human supervision or\ninteraction. The proposed system will diagnose the disease present in the\nretina using a neural network based classifier.The extent of the disease spread\nin the retina can be identified by extracting the textural features of the\nretina. This system will diagnose the following type of diseases: Diabetic\nRetinopathy and Drusen.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2010 19:54:08 GMT"}], "update_date": "2010-02-12", "authors_parsed": [["Jayanthi", "D.", ""], ["Devi", "N.", ""], ["SwarnaParvathi", "S.", ""]]}, {"id": "1002.2418", "submitter": "Rdv Ijcsis", "authors": "S. M. Ramesh, A. Shanmugam", "title": "Medical Image Compression using Wavelet Decomposition for Prediction\n  Method", "comments": "IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 262-265, January 2010, USA", "doi": null, "report-no": "Journal of Computer Science, ISSN 1947 5500", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper offers a simple and lossless compression method for compression\nof medical images. Method is based on wavelet decomposition of the medical\nimages followed by the correlation analysis of coefficients. The correlation\nanalyses are the basis of prediction equation for each sub band. Predictor\nvariable selection is performed through coefficient graphic method to avoid\nmulticollinearity problem and to achieve high prediction accuracy and\ncompression rate. The method is applied on MRI and CT images. Results show that\nthe proposed approach gives a high compression rate for MRI and CT images\ncomparing with state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2010 20:16:33 GMT"}], "update_date": "2010-02-12", "authors_parsed": [["Ramesh", "S. M.", ""], ["Shanmugam", "A.", ""]]}, {"id": "1002.2523", "submitter": "Dakshina Ranjan Kisku", "authors": "Ajita Rattani, Dakshina Ranjan Kisku, Manuele Bicego, Massimo\n  Tistarelli", "title": "Feature Level Fusion of Face and Fingerprint Biometrics", "comments": "6 pages, 7 figures, conference", "journal-ref": "BTAS 2007", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to study the fusion at feature extraction level for\nface and fingerprint biometrics. The proposed approach is based on the fusion\nof the two traits by extracting independent feature pointsets from the two\nmodalities, and making the two pointsets compatible for concatenation.\nMoreover, to handle the problem of curse of dimensionality, the feature\npointsets are properly reduced in dimension. Different feature reduction\ntechniques are implemented, prior and after the feature pointsets fusion, and\nthe results are duly recorded. The fused feature pointset for the database and\nthe query face and fingerprint images are matched using techniques based on\neither the point pattern matching, or the Delaunay triangulation. Comparative\nexperiments are conducted on chimeric and real databases, to assess the actual\nadvantage of the fusion performed at the feature extraction level, in\ncomparison to the matching score level.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2010 11:14:57 GMT"}], "update_date": "2010-02-15", "authors_parsed": [["Rattani", "Ajita", ""], ["Kisku", "Dakshina Ranjan", ""], ["Bicego", "Manuele", ""], ["Tistarelli", "Massimo", ""]]}, {"id": "1002.2654", "submitter": "Evgeny Norman D.", "authors": "Evgeny D. Norman", "title": "Assessment Of The Wind Farm Impact On The Radar", "comments": "Master's Thesis, 62 pages, LaTeX. Submitted to ENSIETA & Thales Air\n  Systems. Paris area, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This study shows the means to evaluate the wind farm impact on the radar. It\nproposes the set of tools, which can be used to realise this objective. The big\npart of report covers the study of complex pattern propagation factor as the\ncritical issue of the Advanced Propagation Model (APM). Finally, the reader can\nfind here the implementation of this algorithm - the real scenario in Inverness\nairport (the United Kingdom), where the ATC radar STAR 2000, developed by\nThales Air Systems, operates in the presence of several wind farms. Basically,\nthe project is based on terms of the department \"Strategy Technology &\nInnovation\", where it has been done. Also you can find here how the radar\nindustry can act with the problem engendered by wind farms. The current\nstrategies in this area are presented, such as a wind turbine production,\nimprovements of air traffic handling procedures and the collaboration between\ndevelopers of radars and wind turbines. The possible strategy for Thales as a\nmain pioneer was given as well.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2010 01:19:53 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Norman", "Evgeny D.", ""]]}, {"id": "1002.2755", "submitter": "Dakshina Ranjan Kisku", "authors": "Dakshina Ranjan Kisku, Jamuna Kanta Sing, Phalguni Gupta", "title": "Multibiometrics Belief Fusion", "comments": "4 pages, 3 figures", "journal-ref": "ICMV 2009", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a multimodal biometric system through Gaussian Mixture\nModel (GMM) for face and ear biometrics with belief fusion of the estimated\nscores characterized by Gabor responses and the proposed fusion is accomplished\nby Dempster-Shafer (DS) decision theory. Face and ear images are convolved with\nGabor wavelet filters to extracts spatially enhanced Gabor facial features and\nGabor ear features. Further, GMM is applied to the high-dimensional Gabor face\nand Gabor ear responses separately for quantitive measurements. Expectation\nMaximization (EM) algorithm is used to estimate density parameters in GMM. This\nproduces two sets of feature vectors which are then fused using Dempster-Shafer\ntheory. Experiments are conducted on multimodal database containing face and\near images of 400 individuals. It is found that use of Gabor wavelet filters\nalong with GMM and DS theory can provide robust and efficient multimodal fusion\nstrategy.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2010 07:38:45 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Kisku", "Dakshina Ranjan", ""], ["Sing", "Jamuna Kanta", ""], ["Gupta", "Phalguni", ""]]}, {"id": "1002.2959", "submitter": "Emil Saucan", "authors": "Emil Saucan, Eli Appleboim and Yehoshua Y. Zeevi", "title": "Geometric approach to sampling and communication", "comments": "19 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.DG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relationships that exist between the classical, Shannon-type, and\ngeometric-based approaches to sampling are investigated. Some aspects of coding\nand communication through a Gaussian channel are considered. In particular, a\nconstructive method to determine the quantizing dimension in Zador's theorem is\nprovided. A geometric version of Shannon's Second Theorem is introduced.\nApplications to Pulse Code Modulation and Vector Quantization of Images are\naddressed.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 21:48:06 GMT"}], "update_date": "2010-02-17", "authors_parsed": [["Saucan", "Emil", ""], ["Appleboim", "Eli", ""], ["Zeevi", "Yehoshua Y.", ""]]}, {"id": "1002.3344", "submitter": "Alireza Avanaki", "authors": "Alireza Avanaki", "title": "Iterative exact global histogram specification and SSIM gradient ascent:\n  a proof of convergence, step size and parameter selection", "comments": "Supplement to published work, on SSIM-optimized exact global\n  histogram specification; please see arXiv:0901.0065", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SSIM-optimized exact global histogram specification (EGHS) is shown to\nconverge in the sense that the first order approximation of the result's\nquality (i.e., its structural similarity with input) does not decrease in an\niteration, when the step size is small. Each iteration is composed of SSIM\ngradient ascent and basic EGHS with the specified target histogram. Selection\nof step size and other parameters is also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2010 18:29:09 GMT"}], "update_date": "2010-02-18", "authors_parsed": [["Avanaki", "Alireza", ""]]}, {"id": "1002.3985", "submitter": "William Jackson", "authors": "Md. Imran Hossain, Syed Golam Rajib", "title": "Supervised Learning of Digital image restoration based on Quantization\n  Nearest Neighbor algorithm", "comments": null, "journal-ref": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an algorithm is proposed for Image Restoration. Such algorithm\nis different from the traditional approaches in this area, by utilizing priors\nthat are learned from similar images. Original images and their degraded\nversions by the known degradation operators are utilized for designing the\nQuantization. The code vectors are designed using the blurred images. For each\nsuch vector, the high frequency information obtained from the original images\nis also available. During restoration, the high frequency information of a\ngiven degraded image is estimated from its low frequency information based on\nthe artificial noise. For the restoration problem, a number of techniques are\ndesigned corresponding to various versions of the blurring function. Given a\nnoisy and blurred image, one of the techniques is chosen based on a similarity\nmeasure, therefore providing the identification of the blur. To make the\nrestoration process computationally efficient, the Quantization Nearest\nNeighborhood approaches are utilized.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2010 18:34:10 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Hossain", "Md. Imran", ""], ["Rajib", "Syed Golam", ""]]}, {"id": "1002.4040", "submitter": "William Jackson", "authors": "Nibaran Das, Bindaban Das, Ram Sarkar, Subhadip Basu, Mahantapas\n  Kundu, Mita Nasipuri", "title": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier", "comments": null, "journal-ref": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2010 02:58:49 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2010 06:44:32 GMT"}], "update_date": "2010-03-25", "authors_parsed": [["Das", "Nibaran", ""], ["Das", "Bindaban", ""], ["Sarkar", "Ram", ""], ["Basu", "Subhadip", ""], ["Kundu", "Mahantapas", ""], ["Nasipuri", "Mita", ""]]}, {"id": "1002.4046", "submitter": "William Jackson", "authors": "K. Perumal, R. Bhaskaran", "title": "Supervised Classification Performance of Multispectral Images", "comments": null, "journal-ref": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays government and private agencies use remote sensing imagery for a\nwide range of applications from military applications to farm development. The\nimages may be a panchromatic, multispectral, hyperspectral or even\nultraspectral of terra bytes. Remote sensing image classification is one\namongst the most significant application worlds for remote sensing. A few\nnumber of image classification algorithms have proved good precision in\nclassifying remote sensing data. But, of late, due to the increasing\nspatiotemporal dimensions of the remote sensing data, traditional\nclassification algorithms have exposed weaknesses necessitating further\nresearch in the field of remote sensing image classification. So an efficient\nclassifier is needed to classify the remote sensing images to extract\ninformation. We are experimenting with both supervised and unsupervised\nclassification. Here we compare the different classification methods and their\nperformances. It is found that Mahalanobis classifier performed the best in our\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2010 03:12:14 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Perumal", "K.", ""], ["Bhaskaran", "R.", ""]]}, {"id": "1002.4317", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna, Roberto Marazzato", "title": "CLD-shaped Brushstrokes in Non-Photorealistic Rendering", "comments": "Keywords: Image processing, Non-photorealistic processing,\n  Image-based rendering Coherence Length Diagram", "journal-ref": "International Journal of Software Engineering and Computing, 2011,\n  Volume 3, Issue 1, Pages 11-15", "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rendering techniques based on a random grid can be improved by adapting\nbrushstrokes to the shape of different areas of the original picture. In this\npaper, the concept of Coherence Length Diagram is applied to determine the\nadaptive brushstrokes, in order to simulate an impressionist painting. Some\nexamples are provided to instance the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2010 12:32:34 GMT"}], "update_date": "2014-09-12", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""], ["Marazzato", "Roberto", ""]]}]