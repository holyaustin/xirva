[{"id": "1109.0090", "submitter": "Arup Pal", "authors": "Arup Kumar Pal and Anup Sar", "title": "An Efficient Codebook Initialization Approach for LBG Algorithm", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsea.2011.1407", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In VQ based image compression technique has three major steps namely (i)\nCodebook Design, (ii) VQ Encoding Process and (iii) VQ Decoding Process. The\nperformance of VQ based image compression technique depends upon the\nconstructed codebook. A widely used technique for VQ codebook design is the\nLinde-Buzo-Gray (LBG) algorithm. However the performance of the standard LBG\nalgorithm is highly dependent on the choice of the initial codebook. In this\npaper, we have proposed a simple and very effective approach for codebook\ninitialization for LBG algorithm. The simulation results show that the proposed\nscheme is computationally efficient and gives expected performance as compared\nto the standard LBG algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 04:47:08 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Pal", "Arup Kumar", ""], ["Sar", "Anup", ""]]}, {"id": "1109.0138", "submitter": "Atef Boujelben Atef boujelben", "authors": "Atef Boujelben, Hedi Tmar, Jameleddine Mnif, Mohamed Abid", "title": "Automatic Application Level Set Approach in Detection Calcifications in\n  Mammographic Image", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is considered as one of a major health problem that constitutes\nthe strongest cause behind mortality among women in the world. So, in this\ndecade, breast cancer is the second most common type of cancer, in term of\nappearance frequency, and the fifth most common cause of cancer related death.\nIn order to reduce the workload on radiologists, a variety of CAD systems;\nComputer-Aided Diagnosis (CADi) and Computer-Aided Detection (CADe) have been\nproposed. In this paper, we interested on CADe tool to help radiologist to\ndetect cancer. The proposed CADe is based on a three-step work flow; namely,\ndetection, analysis and classification. This paper deals with the problem of\nautomatic detection of Region Of Interest (ROI) based on Level Set approach\ndepended on edge and region criteria. This approach gives good visual\ninformation from the radiologist. After that, the features extraction using\ntextures characteristics and the vector classification using Multilayer\nPerception (MLP) and k-Nearest Neighbours (KNN) are adopted to distinguish\ndifferent ACR (American College of Radiology) classification. Moreover, we use\nthe Digital Database for Screening Mammography (DDSM) for experiments and these\nresults in term of accuracy varied between 60 % and 70% are acceptable and must\nbe ameliorated to aid radiologist.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 09:51:42 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Boujelben", "Atef", ""], ["Tmar", "Hedi", ""], ["Mnif", "Jameleddine", ""], ["Abid", "Mohamed", ""]]}, {"id": "1109.0217", "submitter": "Xiaohao Cai", "authors": "Xiaohao Cai, Raymond Chan, Serena Morigi, Fiorella Sgallari", "title": "Vessel Segmentation in Medical Imaging Using a Tight-Frame Based\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Tight-frame, a generalization of orthogonal wavelets, has been used\nsuccessfully in various problems in image processing, including inpainting,\nimpulse noise removal, super-resolution image restoration, etc. Segmentation is\nthe process of identifying object outlines within images. There are quite a few\nefficient algorithms for segmentation that depend on the variational approach\nand the partial differential equation (PDE) modeling.\n  In this paper, we propose to apply the tight-frame approach to automatically\nidentify tube-like structures such as blood vessels in Magnetic Resonance\nAngiography (MRA) images. Our method iteratively refines a region that encloses\nthe possible boundary or surface of the vessels. In each iteration, we apply\nthe tight-frame algorithm to denoise and smooth the possible boundary and\nsharpen the region. We prove the convergence of our algorithm. Numerical\nexperiments on real 2D/3D MRA images demonstrate that our method is very\nefficient with convergence usually within a few iterations, and it outperforms\nexisting PDE and variational methods as it can extract more tubular objects and\nfine details in the images.\n", "versions": [{"version": "v1", "created": "Sat, 13 Aug 2011 16:24:12 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Cai", "Xiaohao", ""], ["Chan", "Raymond", ""], ["Morigi", "Serena", ""], ["Sgallari", "Fiorella", ""]]}, {"id": "1109.0820", "submitter": "Shai Shalev-Shwartz", "authors": "Shai Shalev-Shwartz and Yonatan Wexler and Amnon Shashua", "title": "ShareBoost: Efficient Multiclass Learning with Feature Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiclass prediction is the problem of classifying an object into a relevant\ntarget class. We consider the problem of learning a multiclass predictor that\nuses only few features, and in particular, the number of used features should\nincrease sub-linearly with the number of possible classes. This implies that\nfeatures should be shared by several classes. We describe and analyze the\nShareBoost algorithm for learning a multiclass predictor that uses few shared\nfeatures. We prove that ShareBoost efficiently finds a predictor that uses few\nshared features (if such a predictor exists) and that it has a small\ngeneralization error. We also describe how to use ShareBoost for learning a\nnon-linear predictor that has a fast evaluation time. In a series of\nexperiments with natural data sets we demonstrate the benefits of ShareBoost\nand evaluate its success relatively to other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 07:52:17 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Wexler", "Yonatan", ""], ["Shashua", "Amnon", ""]]}, {"id": "1109.0882", "submitter": "Xiaowei Zhou", "authors": "Xiaowei Zhou, Can Yang, Weichuan Yu", "title": "Moving Object Detection by Detecting Contiguous Outliers in the Low-Rank\n  Representation", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a fundamental step for automated video analysis in many\nvision applications. Object detection in a video is usually performed by object\ndetectors or background subtraction techniques. Often, an object detector\nrequires manually labeled examples to train a binary classifier, while\nbackground subtraction needs a training sequence that contains no objects to\nbuild a background model. To automate the analysis, object detection without a\nseparate training phase becomes a critical task. People have tried to tackle\nthis task by using motion information. But existing motion-based methods are\nusually limited when coping with complex scenarios such as nonrigid motion and\ndynamic background. In this paper, we show that above challenges can be\naddressed in a unified framework named DEtecting Contiguous Outliers in the\nLOw-rank Representation (DECOLOR). This formulation integrates object detection\nand background learning into a single process of optimization, which can be\nsolved by an alternating algorithm efficiently. We explain the relations\nbetween DECOLOR and other sparsity-based methods. Experiments on both simulated\ndata and real sequences demonstrate that DECOLOR outperforms the\nstate-of-the-art approaches and it can work effectively on a wide range of\ncomplex scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 13:08:24 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2012 00:07:06 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Zhou", "Xiaowei", ""], ["Yang", "Can", ""], ["Yu", "Weichuan", ""]]}, {"id": "1109.1057", "submitter": "Risheng Liu", "authors": "Risheng Liu and Zhouchen Lin and Wei Zhang and Kewei Tang and Zhixun\n  Su", "title": "Toward Designing Intelligent PDEs for Computer Vision: An Optimal\n  Control Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision and image processing problems can be posed as solving\npartial differential equations (PDEs). However, designing PDE system usually\nrequires high mathematical skills and good insight into the problems. In this\npaper, we consider designing PDEs for various problems arising in computer\nvision and image processing in a lazy manner: \\emph{learning PDEs from real\ndata via data-based optimal control}. We first propose a general intelligent\nPDE system which holds the basic translational and rotational invariance rule\nfor most vision problems. By introducing a PDE-constrained optimal control\nframework, it is possible to use the training data resulting from multiple ways\n(ground truth, results from other methods, and manual results from humans) to\nlearn PDEs for different computer vision tasks. The proposed optimal control\nbased training framework aims at learning a PDE-based regressor to approximate\nthe unknown (and usually nonlinear) mapping of different vision tasks. The\nexperimental results show that the learnt PDEs can solve different vision\nproblems reasonably well. In particular, we can obtain PDEs not only for\nproblems that traditional PDEs work well but also for problems that PDE-based\nmethods have never been tried before, due to the difficulty in describing those\nproblems in a mathematical way.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 04:26:44 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Liu", "Risheng", ""], ["Lin", "Zhouchen", ""], ["Zhang", "Wei", ""], ["Tang", "Kewei", ""], ["Su", "Zhixun", ""]]}, {"id": "1109.1067", "submitter": "Padma Nanthagopal", "authors": "A. Padma and Dr.R. Sukanesh", "title": "Automatic Diagnosis of Abnormal Tumor Region from Brain Computed\n  Tomography Images Using Wavelet Based Statistical Texture Features", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The research work presented in this paper is to achieve the tissue\nclassification and automatically diagnosis the abnormal tumor region present in\nComputed Tomography (CT) images using the wavelet based statistical texture\nanalysis method. Comparative studies of texture analysis method are performed\nfor the proposed wavelet based texture analysis method and Spatial Gray Level\nDependence Method (SGLDM). Our proposed system consists of four phases i)\nDiscrete Wavelet Decomposition (ii) Feature extraction (iii) Feature selection\n(iv) Analysis of extracted texture features by classifier. A wavelet based\nstatistical texture feature set is derived from normal and tumor regions.\nGenetic Algorithm (GA) is used to select the optimal texture features from the\nset of extracted texture features. We construct the Support Vector Machine\n(SVM) based classifier and evaluate the performance of classifier by comparing\nthe classification results of the SVM based classifier with the Back\nPropagation Neural network classifier(BPN). The results of Support Vector\nMachine (SVM), BPN classifiers for the texture analysis methods are evaluated\nusing Receiver Operating Characteristic (ROC) analysis. Experimental results\nshow that the classification accuracy of SVM is 96% for 10 fold cross\nvalidation method. The system has been tested with a number of real Computed\nTomography brain images and has achieved satisfactory results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 05:31:26 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Padma", "A.", ""], ["Sukanesh", "Dr. R.", ""]]}, {"id": "1109.1068", "submitter": "Karteeka Pavan Kanadam", "authors": "K. Karteeka Pavan, Allam Appa Rao, A. V. Dattatreya Rao", "title": "An Automatic Clustering Technique for Optimal Clusters", "comments": "12 pages, 5 figures, 2 tables", "journal-ref": "International journal of Computer Sciene Engineering and\n  Applications, Vol., No.4, 2011, pp 133-144", "doi": "10.5121/ijcsea.2011.1412", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple, automatic and efficient clustering algorithm,\nnamely, Automatic Merging for Optimal Clusters (AMOC) which aims to generate\nnearly optimal clusters for the given datasets automatically. The AMOC is an\nextension to standard k-means with a two phase iterative procedure combining\ncertain validation techniques in order to find optimal clusters with automation\nof merging of clusters. Experiments on both synthetic and real data have proved\nthat the proposed algorithm finds nearly optimal clustering structures in terms\nof number of clusters, compactness and separation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 05:34:28 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Pavan", "K. Karteeka", ""], ["Rao", "Allam Appa", ""], ["Rao", "A. V. Dattatreya", ""]]}, {"id": "1109.1133", "submitter": "Shervan Fekri ershad", "authors": "Shervan Fekri Ershad", "title": "Color Texture Classification Approach Based on Combination of Primitive\n  Pattern Units and Statistical Features", "comments": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.3, No.3, August 2011", "journal-ref": null, "doi": "10.5121/ijma.2011.3301", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Texture classification became one of the problems which has been paid much\nattention on by image processing scientists since late 80s. Consequently, since\nnow many different methods have been proposed to solve this problem. In most of\nthese methods the researchers attempted to describe and discriminate textures\nbased on linear and non-linear patterns. The linear and non-linear patterns on\nany window are based on formation of Grain Components in a particular order.\nGrain component is a primitive unit of morphology that most meaningful\ninformation often appears in the form of occurrence of that. The approach which\nis proposed in this paper could analyze the texture based on its grain\ncomponents and then by making grain components histogram and extracting\nstatistical features from that would classify the textures. Finally, to\nincrease the accuracy of classification, proposed approach is expanded to color\nimages to utilize the ability of approach in analyzing each RGB channels,\nindividually. Although, this approach is a general one and it could be used in\ndifferent applications, the method has been tested on the stone texture and the\nresults can prove the quality of approach.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 10:24:07 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Ershad", "Shervan Fekri", ""]]}, {"id": "1109.1149", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Vaclav Hlavac", "title": "On Partial Opimality by Auxiliary Submodular Problems", "comments": "9 pages, 0 figures; Control Systems and Computers #2/2011, Special\n  issue: \"Optimal Labeling Problem in Structural Pattern Recognition\", pp.\n  71-78, issn 0130-5395", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we prove several relations between three different energy\nminimization techniques. A recently proposed methods for determining a provably\noptimal partial assignment of variables by Ivan Kovtun (IK), the linear\nprogramming relaxation approach (LP) and the popular expansion move algorithm\nby Yuri Boykov. We propose a novel sufficient condition of optimal partial\nassignment, which is based on LP relaxation and called LP-autarky. We show that\nmethods of Kovtun, which build auxiliary submodular problems, fulfill this\nsufficient condition. The following link is thus established: LP relaxation\ncannot be tightened by IK. For non-submodular problems this is a non-trivial\nresult. In the case of two labels, LP relaxation provides optimal partial\nassignment, known as persistency, which, as we show, dominates IK. Relating IK\nwith expansion move, we show that the set of fixed points of expansion move\nwith any \"truncation\" rule for the initial problem and the problem restricted\nby one-vs-all method of IK would coincide -- i.e. expansion move cannot be\nimproved by this method. In the case of two labels, expansion move with a\nparticular truncation rule coincide with one-vs-all method.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 11:33:38 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Hlavac", "Vaclav", ""]]}, {"id": "1109.1175", "submitter": "Stefanie Wuhrer", "authors": "Stefanie Wuhrer and Chang Shu", "title": "Estimating 3D Human Shapes from Measurements", "comments": "Added more experiments", "journal-ref": "Machine Vision and Applications, 24(6):1133-1147, 2013", "doi": "10.1007/s00138-012-0472-y", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in 3-D imaging technologies give rise to databases of\nhuman shapes, from which statistical shape models can be built. These\nstatistical models represent prior knowledge of the human shape and enable us\nto solve shape reconstruction problems from partial information. Generating\nhuman shape from traditional anthropometric measurements is such a problem,\nsince these 1-D measurements encode 3-D shape information. Combined with a\nstatistical shape model, these easy-to-obtain measurements can be leveraged to\ncreate 3D human shapes. However, existing methods limit the creation of the\nshapes to the space spanned by the database and thus require a large amount of\ntraining data. In this paper, we introduce a technique that extrapolates the\nstatistically inferred shape to fit the measurement data using nonlinear\noptimization. This method ensures that the generated shape is both human-like\nand satisfies the measurement conditions. We demonstrate the effectiveness of\nthe method and compare it to existing approaches through extensive experiments,\nusing both synthetic data and real human measurements.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 13:22:49 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2012 15:01:54 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Wuhrer", "Stefanie", ""], ["Shu", "Chang", ""]]}, {"id": "1109.1247", "submitter": "Vikas Dongre", "authors": "Vikas J Dongre, Vijay H Mankar", "title": "Devnagari document segmentation using histogram approach", "comments": "8 pages; 4 figures; 8 tables; journal paper: International Journal of\n  Computer Science, Engineering and Information Technology (IJCSEIT), Vol.1,\n  No.3, August 2011", "journal-ref": "International Journal of Computer Science, Engineering and\n  Information Technology (IJCSEIT), Vol.1, No.3, 2011, 46-53", "doi": "10.5121/ijcseit.2011.1305", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document segmentation is one of the critical phases in machine recognition of\nany language. Correct segmentation of individual symbols decides the accuracy\nof character recognition technique. It is used to decompose image of a sequence\nof characters into sub images of individual symbols by segmenting lines and\nwords. Devnagari is the most popular script in India. It is used for writing\nHindi, Marathi, Sanskrit and Nepali languages. Moreover, Hindi is the third\nmost popular language in the world. Devnagari documents consist of vowels,\nconsonants and various modifiers. Hence proper segmentation of Devnagari word\nis challenging. A simple histogram based approach to segment Devnagari\ndocuments is proposed in this paper. Various challenges in segmentation of\nDevnagari script are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 17:56:58 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Dongre", "Vikas J", ""], ["Mankar", "Vijay H", ""]]}, {"id": "1109.1480", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov, Pushmeet Kohli, Carsten Rother", "title": "Curvature Prior for MRF-based Segmentation and Shape Inpainting", "comments": "17 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": "CTU--CMP--2011--11", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most image labeling problems such as segmentation and image reconstruction\nare fundamentally ill-posed and suffer from ambiguities and noise. Higher order\nimage priors encode high level structural dependencies between pixels and are\nkey to overcoming these problems. However, these priors in general lead to\ncomputationally intractable models. This paper addresses the problem of\ndiscovering compact representations of higher order priors which allow\nefficient inference. We propose a framework for solving this problem which uses\na recently proposed representation of higher order functions where they are\nencoded as lower envelopes of linear functions. Maximum a Posterior inference\non our learned models reduces to minimizing a pairwise function of discrete\nvariables, which can be done approximately using standard methods. Although\nthis is a primarily theoretical paper, we also demonstrate the practical\neffectiveness of our framework on the problem of learning a shape prior for\nimage segmentation and reconstruction. We show that our framework can learn a\ncompact representation that approximates a prior that encourages low curvature\nshapes. We evaluate the approximation accuracy, discuss properties of the\ntrained model, and show various results for shape inpainting and image\nsegmentation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 14:53:51 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Kohli", "Pushmeet", ""], ["Rother", "Carsten", ""]]}, {"id": "1109.1646", "submitter": "Guangcan Liu", "authors": "Guangcan Liu, Huan Xu, Shuicheng Yan", "title": "Exact Subspace Segmentation and Outlier Detection by Low-Rank\n  Representation", "comments": "Proceedings of the Fifteenth International Conference on Artificial\n  Intelligence and Statistics, AISTATS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the following matrix recovery problem: suppose we\nare given a set of data points containing two parts, one part consists of\nsamples drawn from a union of multiple subspaces and the other part consists of\noutliers. We do not know which data points are outliers, or how many outliers\nthere are. The rank and number of the subspaces are unknown either. Can we\ndetect the outliers and segment the samples into their right subspaces,\nefficiently and exactly? We utilize a so-called {\\em Low-Rank Representation}\n(LRR) method to solve this problem, and prove that under mild technical\nconditions, any solution to LRR exactly recovers the row space of the samples\nand detect the outliers as well. Since the subspace membership is provably\ndetermined by the row space, this further implies that LRR can perform exact\nsubspace segmentation and outlier detection, in an efficient way.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 07:51:54 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2011 06:34:48 GMT"}, {"version": "v3", "created": "Sun, 30 Mar 2014 19:22:16 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Liu", "Guangcan", ""], ["Xu", "Huan", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1109.1865", "submitter": "Ashok Veeraraghavan", "authors": "Rohit Pandharkar, Ashok Veeraraghavan, Ramesh Raskar", "title": "Progressive versus Random Projections for Compressive Capture of Images,\n  Lightfields and Higher Dimensional Visual Signals", "comments": "Draft of working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational photography involves sophisticated capture methods. A new trend\nis to capture projection of higher dimensional visual signals such as videos,\nmulti-spectral data and lightfields on lower dimensional sensors. Carefully\ndesigned capture methods exploit the sparsity of the underlying signal in a\ntransformed domain to reduce the number of measurements and use an appropriate\nreconstruction method. Traditional progressive methods may capture successively\nmore detail using a sequence of simple projection basis, such as DCT or\nwavelets and employ straightforward backprojection for reconstruction.\nRandomized projection methods do not use any specific sequence and use L0\nminimization for reconstruction. In this paper, we analyze the statistical\nproperties of natural images, videos, multi-spectral data and light-fields and\ncompare the effectiveness of progressive and random projections. We define\neffectiveness by plotting reconstruction SNR against compression factor. The\nkey idea is a procedure to measure best-case effectiveness that is fast,\nindependent of specific hardware and independent of the reconstruction\nprocedure. We believe this is the first empirical study to compare different\nlossy capture strategies without the complication of hardware or reconstruction\nambiguity. The scope is limited to linear non-adaptive sensing. The results\nshow that random projections produce significant advantages over other\nprojections only for higher dimensional signals, and suggest more research to\nnascent adaptive and non-linear projection methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 00:33:10 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Pandharkar", "Rohit", ""], ["Veeraraghavan", "Ashok", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1109.2227", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal Narayan Chaudhury", "title": "A radial version of the Central Limit Theorem", "comments": "3 pages, 2 figures; minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we give a probabilistic interpretation of the Central Limit\nTheorem used for approximating isotropic Gaussians in [1].\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 15:13:00 GMT"}, {"version": "v2", "created": "Sat, 24 Sep 2011 12:44:32 GMT"}, {"version": "v3", "created": "Wed, 28 Sep 2011 13:45:10 GMT"}], "update_date": "2011-09-29", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""]]}, {"id": "1109.2304", "submitter": "Chris Russell", "authors": "Srikumar Ramalingam and Chris Russell and Lubor Ladicky and Philip\n  H.S. Torr", "title": "Efficient Minimization of Higher Order Submodular Functions using\n  Monotonic Boolean Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular function minimization is a key problem in a wide variety of\napplications in machine learning, economics, game theory, computer vision, and\nmany others. The general solver has a complexity of $O(n^3 \\log^2 n . E +n^4\n{\\log}^{O(1)} n)$ where $E$ is the time required to evaluate the function and\n$n$ is the number of variables \\cite{Lee2015}. On the other hand, many computer\nvision and machine learning problems are defined over special subclasses of\nsubmodular functions that can be written as the sum of many submodular cost\nfunctions defined over cliques containing few variables. In such functions, the\npseudo-Boolean (or polynomial) representation \\cite{BorosH02} of these\nsubclasses are of degree (or order, or clique size) $k$ where $k \\ll n$. In\nthis work, we develop efficient algorithms for the minimization of this useful\nsubclass of submodular functions. To do this, we define novel mapping that\ntransform submodular functions of order $k$ into quadratic ones. The underlying\nidea is to use auxiliary variables to model the higher order terms and the\ntransformation is found using a carefully constructed linear program. In\nparticular, we model the auxiliary variables as monotonic Boolean functions,\nallowing us to obtain a compact transformation using as few auxiliary variables\nas possible.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 10:58:44 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 19:10:05 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Ramalingam", "Srikumar", ""], ["Russell", "Chris", ""], ["Ladicky", "Lubor", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1109.2388", "submitter": "Emre Akbas", "authors": "Emre Akbas, Bernard Ghanem, Narendra Ahuja", "title": "MIS-Boost: Multiple Instance Selection Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new multiple instance learning (MIL) method,\ncalled MIS-Boost, which learns discriminative instance prototypes by explicit\ninstance selection in a boosting framework. Unlike previous instance selection\nbased MIL methods, we do not restrict the prototypes to a discrete set of\ntraining instances but allow them to take arbitrary values in the instance\nfeature space. We also do not restrict the total number of prototypes and the\nnumber of selected-instances per bag; these quantities are completely\ndata-driven. We show that MIS-Boost outperforms state-of-the-art MIL methods on\na number of benchmark datasets. We also apply MIS-Boost to large-scale image\nclassification, where we show that the automatically selected prototypes map to\nvisually meaningful image regions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 07:31:34 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Akbas", "Emre", ""], ["Ghanem", "Bernard", ""], ["Ahuja", "Narendra", ""]]}, {"id": "1109.2389", "submitter": "Bernard Ghanem", "authors": "Bernard Ghanem and Narendra Ahuja", "title": "A Probabilistic Framework for Discriminative Dictionary Learning", "comments": "10 pages, 4 figures, conference, dictionary learning, sparse coding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of discriminative dictionary learning\n(DDL), where sparse linear representation and classification are combined in a\nprobabilistic framework. As such, a single discriminative dictionary and linear\nbinary classifiers are learned jointly. By encoding sparse representation and\ndiscriminative classification models in a MAP setting, we propose a general\noptimization framework that allows for a data-driven tradeoff between faithful\nrepresentation and accurate classification. As opposed to previous work, our\nlearning methodology is capable of incorporating a diverse family of\nclassification cost functions (including those used in popular boosting\nmethods), while avoiding the need for involved optimization techniques. We show\nthat DDL can be solved by a sequence of updates that make use of well-known and\nwell-studied sparse coding and dictionary learning algorithms from the\nliterature. To validate our DDL framework, we apply it to digit classification\nand face recognition and test it on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 07:45:03 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Ghanem", "Bernard", ""], ["Ahuja", "Narendra", ""]]}, {"id": "1109.2449", "submitter": "Jan Funke", "authors": "Jan Funke, Bj\\\"orn Andres, Fred Hamprecht, Albert Cardona and Matthew\n  Cook", "title": "Multi-Hypothesis CRF-Segmentation of Neural Tissue in Anisotropic EM\n  Volumes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for the joint segmentation and grouping of similar\ncomponents in anisotropic 3D image data and use it to segment neural tissue in\nserial sections electron microscopy (EM) images.\n  We first construct a nested set of neuron segmentation hypotheses for each\nslice. A conditional random field (CRF) then allows us to evaluate both the\ncompatibility of a specific segmentation and a specific inter-slice assignment\nof neuron candidates with the underlying observations. The model is solved\noptimally for an entire image stack simultaneously using integer linear\nprogramming (ILP), which yields the maximum a posteriori solution in amortized\nlinear time in the number of slices.\n  We evaluate the performance of our approach on an annotated sample of the\nDrosophila larva neuropil and show that the consideration of different\nsegmentation hypotheses in each slice leads to a significant improvement in the\nsegmentation and assignment accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 12:57:25 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2011 17:45:45 GMT"}, {"version": "v3", "created": "Thu, 15 Sep 2011 15:00:05 GMT"}, {"version": "v4", "created": "Sun, 18 Sep 2011 02:34:17 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Funke", "Jan", ""], ["Andres", "Bj\u00f6rn", ""], ["Hamprecht", "Fred", ""], ["Cardona", "Albert", ""], ["Cook", "Matthew", ""]]}, {"id": "1109.3126", "submitter": "Evgeniy Martyushev", "authors": "Evgeniy Martyushev", "title": "A Non-Iterative Solution to the Four-Point Three-Views Pose Problem in\n  Case of Collinear Cameras", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a non-iterative solution to a particular case of the four-point\nthree-views pose problem when three camera centers are collinear. Using the\nwell-known Cayley representation of orthogonal matrices, we derive from the\nepipolar constraints a system of three polynomial equations in three variables.\nThe eliminant of that system is a multiple of a 36th degree univariate\npolynomial. The true (unique) solution to the problem can be expressed in terms\nof one of real roots of that polynomial. Experiments on synthetic data confirm\nthat our method is robust enough even in case of planar configurations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 16:24:26 GMT"}], "update_date": "2011-09-15", "authors_parsed": [["Martyushev", "Evgeniy", ""]]}, {"id": "1109.3317", "submitter": "Ayatullah Faruk Mollah", "authors": "Ayatullah Faruk Mollah, Nabamita Majumder, Subhadip Basu, Mita\n  Nasipuri", "title": "Design of an Optical Character Recognition System for Camera-based\n  Handheld Devices", "comments": null, "journal-ref": "Int'l J. of Computer Science Issues, Vol. 8, Issue 4, pp. 283-289,\n  July 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a complete Optical Character Recognition (OCR) system for\ncamera captured image/graphics embedded textual documents for handheld devices.\nAt first, text regions are extracted and skew corrected. Then, these regions\nare binarized and segmented into lines and characters. Characters are passed\ninto the recognition module. Experimenting with a set of 100 business card\nimages, captured by cell phone camera, we have achieved a maximum recognition\naccuracy of 92.74%. Compared to Tesseract, an open source desktop-based\npowerful OCR engine, present recognition accuracy is worth contributing.\nMoreover, the developed technique is computationally efficient and consumes low\nmemory so as to be applicable on handheld devices.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 11:24:41 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Mollah", "Ayatullah Faruk", ""], ["Majumder", "Nabamita", ""], ["Basu", "Subhadip", ""], ["Nasipuri", "Mita", ""]]}, {"id": "1109.3637", "submitter": "Pedro Aguiar", "authors": "Rui F. C. Guerreiro and Pedro M. Q. Aguiar", "title": "Connectivity-Enforcing Hough Transform for the Robust Extraction of Line\n  Segments", "comments": "Submitted for publication", "journal-ref": null, "doi": "10.1109/TIP.2012.2202673", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global voting schemes based on the Hough transform (HT) have been widely used\nto robustly detect lines in images. However, since the votes do not take line\nconnectivity into account, these methods do not deal well with cluttered\nimages. In opposition, the so-called local methods enforce connectivity but\nlack robustness to deal with challenging situations that occur in many\nrealistic scenarios, e.g., when line segments cross or when long segments are\ncorrupted. In this paper, we address the critical limitations of the HT as a\nline segment extractor by incorporating connectivity in the voting process.\nThis is done by only accounting for the contributions of edge points lying in\nincreasingly larger neighborhoods and whose position and directional content\nagree with potential line segments. As a result, our method, which we call\nSTRAIGHT (Segment exTRAction by connectivity-enforcInG HT), extracts the\nlongest connected segments in each location of the image, thus also integrating\ninto the HT voting process the usually separate step of individual segment\nextraction. The usage of the Hough space mapping and a corresponding\nhierarchical implementation make our approach computationally feasible. We\npresent experiments that illustrate, with synthetic and real images, how\nSTRAIGHT succeeds in extracting complete segments in several situations where\ncurrent methods fail.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 14:56:25 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Guerreiro", "Rui F. C.", ""], ["Aguiar", "Pedro M. Q.", ""]]}, {"id": "1109.3767", "submitter": "Othman Ahmad", "authors": "Othman Ahmad", "title": "Generalised Object Detection and Semantic Analysis: Casino Example using\n  Matlab", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matlab version 7.1 had been used to detect playing cards on a Casino table\nand the suits and ranks of these cards had been identified. The process gives\nan example of an application of computer vision to a problem where rectangular\nobjects are to be detected and the information content of the objects are\nextracted out. In the case of playing cards, it is the suit and rank of each\ncard. The image processing system is done in two passes. Pass 1 detects\nrectangular shapes and template matched with a template of the left and right\nedges of the cards. Pass 2 extracts the suit and rank of the cards by matching\nthe top left portion of the card that contains both rank and suit information,\nwith stored templates of ranks and suits of the playing cards using a series of\nif-then statements.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2011 10:09:02 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Ahmad", "Othman", ""]]}, {"id": "1109.3827", "submitter": "Jun He", "authors": "Jun He, Laura Balzano, John C.S. Lui", "title": "Online Robust Subspace Tracking from Partial Information", "comments": "28 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.SY math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents GRASTA (Grassmannian Robust Adaptive Subspace Tracking\nAlgorithm), an efficient and robust online algorithm for tracking subspaces\nfrom highly incomplete information. The algorithm uses a robust $l^1$-norm cost\nfunction in order to estimate and track non-stationary subspaces when the\nstreaming data vectors are corrupted with outliers. We apply GRASTA to the\nproblems of robust matrix completion and real-time separation of background\nfrom foreground in video. In this second application, we show that GRASTA\nperforms high-quality separation of moving objects from background at\nexceptional speeds: In one popular benchmark video example, GRASTA achieves a\nrate of 57 frames per second, even when run in MATLAB on a personal laptop.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 00:53:53 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2011 13:02:04 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["He", "Jun", ""], ["Balzano", "Laura", ""], ["Lui", "John C. S.", ""]]}, {"id": "1109.3850", "submitter": "Dae-Woong Lee", "authors": "Dae-Woong Lee", "title": "Digital (co)homology modules and digital Pontryagin algebras", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current study, we explore digital homology and cohomology modules, and\ninvestigate their fundamental properties on pointed digital images. We also\nexamine pointed digital Hopf spaces and base point preserving digital Hopf\nfunctions between the pointed digital Hopf spaces with suitable digital\nmultiplications, and explore the digital primitive homology and cohomology\nclasses, the digital Pontryagin algebras and coalgebras on the digital Hopf\nspaces as digital images.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 07:48:36 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 03:19:40 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Lee", "Dae-Woong", ""]]}, {"id": "1109.4683", "submitter": "Alper Ayvaci", "authors": "Alper Ayvaci and Stefano Soatto", "title": "Detachable Object Detection: Segmentation and Depth Ordering From\n  Short-Baseline Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach for segmenting an image into regions that correspond\nto surfaces in the scene that are partially surrounded by the medium. It\nintegrates both appearance and motion statistics into a cost functional, that\nis seeded with occluded regions and minimized efficiently by solving a linear\nprogramming problem. Where a short observation time is insufficient to\ndetermine whether the object is detachable, the results of the minimization can\nbe used to seed a more costly optimization based on a longer sequence of video\ndata. The result is an entirely unsupervised scheme to detect and segment an\narbitrary and unknown number of objects. We test our scheme to highlight the\npotential, as well as limitations, of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 00:55:32 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Ayvaci", "Alper", ""], ["Soatto", "Stefano", ""]]}, {"id": "1109.4744", "submitter": "Shankar Deepak  Srinivasan", "authors": "S. Deepak Srinivasan, Klaus Obermayer", "title": "Probabilistic prototype models for attributed graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution proposes a new approach towards developing a class of\nprobabilistic methods for classifying attributed graphs. The key concept is\nrandom attributed graph, which is defined as an attributed graph whose nodes\nand edges are annotated by random variables. Every node/edge has two random\nprocesses associated with it- occurence probability and the probability\ndistribution over the attribute values. These are estimated within the maximum\nlikelihood framework. The likelihood of a random attributed graph to generate\nan outcome graph is used as a feature for classification. The proposed approach\nis fast and robust to noise.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 09:26:23 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Srinivasan", "S. Deepak", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1109.4909", "submitter": "Allen Yang", "authors": "Chris Slaughter and Allen Y. Yang and Justin Bagwell and Costa\n  Checkles and Luis Sentis and Sriram Vishwanath", "title": "Sparse Online Low-Rank Projection and Outlier Rejection (SOLO) for 3-D\n  Rigid-Body Motion Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by an emerging theory of robust low-rank matrix representation, in\nthis paper, we introduce a novel solution for online rigid-body motion\nregistration. The goal is to develop algorithmic techniques that enable a\nrobust, real-time motion registration solution suitable for low-cost, portable\n3-D camera devices. Assuming 3-D image features are tracked via a standard\ntracker, the algorithm first utilizes Robust PCA to initialize a low-rank shape\nrepresentation of the rigid body. Robust PCA finds the global optimal solution\nof the initialization, while its complexity is comparable to singular value\ndecomposition. In the online update stage, we propose a more efficient\nalgorithm for sparse subspace projection to sequentially project new feature\nobservations onto the shape subspace. The lightweight update stage guarantees\nthe real-time performance of the solution while maintaining good registration\neven when the image sequence is contaminated by noise, gross data corruption,\noutlying features, and missing data. The state-of-the-art accuracy of the\nsolution is validated through extensive simulation and a real-world experiment,\nwhile the system enjoys one to two orders of magnitude speed-up compared to\nwell-established RANSAC solutions. The new algorithm will be released online to\naid peer evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 18:41:00 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Slaughter", "Chris", ""], ["Yang", "Allen Y.", ""], ["Bagwell", "Justin", ""], ["Checkles", "Costa", ""], ["Sentis", "Luis", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1109.4920", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Mohamed Cheriet", "title": "Beyond pixels and regions: A non local patch means (NLPM) method for\n  content-level restoration, enhancement, and reconstruction of degraded\n  document images", "comments": "This paper has been withdrawn by the author to avoid duplication on\n  the DBLP bibliography", "journal-ref": "Pattern Recognition 44 (2011) 363-374", "doi": "10.1016/j.patcog.2010.07.027", "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A patch-based non-local restoration and reconstruction method for\npreprocessing degraded document images is introduced. The method collects\nrelative data from the whole input image, while the image data are first\nrepresented by a content-level descriptor based on patches. This\npatch-equivalent representation of the input image is then corrected based on\nsimilar patches identified using a modified genetic algorithm (GA) resulting in\na low computational load. The corrected patch-equivalent is then converted to\nthe output restored image. The fact that the method uses the patches at the\ncontent level allows it to incorporate high-level restoration in an objective\nand self-sufficient way. The method has been applied to several degraded\ndocument images, including the DIBCO'09 contest dataset with promising results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 19:24:58 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2011 16:46:52 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2011 22:33:13 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1109.5114", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal N. Chaudhury and Sebanti Sanyal", "title": "Improvements on \"Fast space-variant elliptical filtering using box\n  splines\"", "comments": "7 figures", "journal-ref": "IEEE Transactions on Image Processing, vol. 21(9), pp. 3915 -\n  3923, 2012", "doi": "10.1109/TIP.2012.2198222", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that box filters can be efficiently computed using\npre-integrations and local finite-differences\n[Crow1984,Heckbert1986,Viola2001]. By generalizing this idea and by combining\nit with a non-standard variant of the Central Limit Theorem, a constant-time or\nO(1) algorithm was proposed in [Chaudhury2010] that allowed one to perform\nspace-variant filtering using Gaussian-like kernels. The algorithm was based on\nthe observation that both isotropic and anisotropic Gaussians could be\napproximated using certain bivariate splines called box splines. The attractive\nfeature of the algorithm was that it allowed one to continuously control the\nshape and size (covariance) of the filter, and that it had a fixed\ncomputational cost per pixel, irrespective of the size of the filter. The\nalgorithm, however, offered a limited control on the covariance and accuracy of\nthe Gaussian approximation. In this work, we propose some improvements by\nappropriately modifying the algorithm in [Chaudhury2010].\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 15:43:21 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2011 00:42:11 GMT"}, {"version": "v3", "created": "Wed, 22 Feb 2012 18:18:06 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Chaudhury", "Kunal N.", ""], ["Sanyal", "Sebanti", ""]]}, {"id": "1109.5323", "submitter": "Jeremy Lee", "authors": "Jeremy Lee", "title": "Squiggle - A Glyph Recognizer for Gesture Input", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Squiggle is a template-based glyph recognizer in the lineage of `$1\nRecognizer' and `Protractor'. It seeks a good fit linear affine mapping between\nthe input and template glyphs which are represented as a list of milestone\npoints along the glyph path. The algorithm can recognize input glyphs invariant\nof rotation, scaling, skew, and reflection symmetries. In practice the\nalgorithm is fast and robust enough to recognize user-generated glyphs as they\nare being drawn in real time, and to project `shadows' of the matching\ntemplates as feedback.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2011 04:41:35 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Lee", "Jeremy", ""]]}, {"id": "1109.5370", "submitter": "Jia Zeng", "authors": "Jia Zeng, Wei Feng, William K. Cheung, Chun-Hung Li", "title": "Higher-Order Markov Tag-Topic Models for Tagged Documents and Images", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the topic modeling problem of tagged documents and images.\nHigher-order relations among tagged documents and images are major and\nubiquitous characteristics, and play positive roles in extracting reliable and\ninterpretable topics. In this paper, we propose the tag-topic models (TTM) to\ndepict such higher-order topic structural dependencies within the Markov random\nfield (MRF) framework. First, we use the novel factor graph representation of\nlatent Dirichlet allocation (LDA)-based topic models from the MRF perspective,\nand present an efficient loopy belief propagation (BP) algorithm for\napproximate inference and parameter estimation. Second, we propose the factor\nhypergraph representation of TTM, and focus on both pairwise and higher-order\nrelation modeling among tagged documents and images. Efficient loopy BP\nalgorithm is developed to learn TTM, which encourages the topic labeling\nsmoothness among tagged documents and images. Extensive experimental results\nconfirm the incorporation of higher-order relations to be effective in\nenhancing the overall topic modeling performance, when compared with current\nstate-of-the-art topic models, in many text and image mining tasks of broad\ninterests such as word and link prediction, document classification, and tag\nrecommendation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2011 16:58:06 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Zeng", "Jia", ""], ["Feng", "Wei", ""], ["Cheung", "William K.", ""], ["Li", "Chun-Hung", ""]]}, {"id": "1109.5453", "submitter": "Takayuki Katsuki", "authors": "Takayuki Katsuki, Akira Torii, and Masato Inoue", "title": "Posterior Mean Super-resolution with a Causal Gaussian Markov Random\n  Field Prior", "comments": "11 pages, 20 figures, submitted to IEEE Transactions on Image\n  Processing", "journal-ref": null, "doi": "10.1109/TIP.2012.2189578", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian image super-resolution (SR) method with a causal\nGaussian Markov random field (MRF) prior. SR is a technique to estimate a\nspatially high-resolution image from given multiple low-resolution images. An\nMRF model with the line process supplies a preferable prior for natural images\nwith edges. We improve the existing image transformation model, the compound\nMRF model, and its hyperparameter prior model. We also derive the optimal\nestimator -- not the joint maximum a posteriori (MAP) or marginalized maximum\nlikelihood (ML), but the posterior mean (PM) -- from the objective function of\nthe L2-norm (mean square error) -based peak signal-to-noise ratio (PSNR). Point\nestimates such as MAP and ML are generally not stable in ill-posed\nhigh-dimensional problems because of overfitting, while PM is a stable\nestimator because all the parameters in the model are evaluated as\ndistributions. The estimator is numerically determined by using variational\nBayes. Variational Bayes is a widely used method that approximately determines\na complicated posterior distribution, but it is generally hard to use because\nit needs the conjugate prior. We solve this problem with simple Taylor\napproximations. Experimental results have shown that the proposed method is\nmore accurate or comparable to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 06:23:09 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2011 08:51:27 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2012 09:41:20 GMT"}, {"version": "v4", "created": "Tue, 3 Apr 2012 13:46:31 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Katsuki", "Takayuki", ""], ["Torii", "Akira", ""], ["Inoue", "Masato", ""]]}, {"id": "1109.5730", "submitter": "Diego Rother", "authors": "Diego Rother, Siddharth Mahendran, Ren\\'e Vidal", "title": "Hypothesize and Bound: A Computational Focus of Attention Mechanism for\n  Simultaneous 3D Shape Reconstruction, Pose Estimation and Classification from\n  a Single 2D Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a mathematical framework to simultaneously tackle the\nproblems of 3D reconstruction, pose estimation and object classification, from\na single 2D image. In sharp contrast with state of the art methods that rely\nprimarily on 2D information and solve each of these three problems separately\nor iteratively, we propose a mathematical framework that incorporates prior\n\"knowledge\" about the 3D shapes of different object classes and solves these\nproblems jointly and simultaneously, using a hypothesize-and-bound (H&B)\nalgorithm. In the proposed H&B algorithm one hypothesis is defined for each\npossible pair [object class, object pose], and the algorithm selects the\nhypothesis H that maximizes a function L(H) encoding how well each hypothesis\n\"explains\" the input image. To find this maximum efficiently, the function L(H)\nis not evaluated exactly for each hypothesis H, but rather upper and lower\nbounds for it are computed at a much lower cost. In order to obtain bounds for\nL(H) that are tight yet inexpensive to compute, we extend the theory of shapes\ndescribed in [14] to handle projections of shapes. This extension allows us to\ndefine a probabilistic relationship between the prior knowledge given in 3D and\nthe 2D input image. This relationship is derived from first principles and is\nproven to be the only relationship having the properties that we intuitively\nexpect from a \"projection.\" In addition to the efficiency and optimality\ncharacteristics of H&B algorithms, the proposed framework has the desirable\nproperty of integrating information in the 2D image with information in the 3D\nprior to estimate the optimal reconstruction. While this article focuses\nprimarily on the problem mentioned above, we believe that the theory presented\nherein has multiple other potential applications.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 21:40:59 GMT"}], "update_date": "2011-09-28", "authors_parsed": [["Rother", "Diego", ""], ["Mahendran", "Siddharth", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1109.6442", "submitter": "Ankit Chaudhary", "authors": "Ankit Chaudhary, Jagdish L. Raheja", "title": "ABHIVYAKTI: A Vision Based Intelligent System for Elder and Sick Persons", "comments": "Proceedings of 3rd IEEE International Conference on Machine Vision,\n  Hong Kong, ICMV 2010\n  (http://www.ieee.org/conferences_events/conferences/conferencedetails/index.html?Conf_ID=18047),\n  28-30 Dec, 2010, pp. 361-364", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an intelligent system ABHIVYAKTI, which would be\npervasive in nature and based on the Computer Vision. It would be very easy in\nuse and deployment. Elder and sick people who are not able to talk or walk,\nthey are dependent on other human beings and need continuous monitoring, while\nour system provides flexibility to the sick or elder person to announce his or\nher need to their caretaker by just showing a particular gesture with the\ndeveloped system, if the caretaker is not nearby. This system will use\nfingertip detection techniques for acquiring gesture and Artificial Neural\nNetworks (ANNs) will be used for gesture recognition.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 08:59:29 GMT"}, {"version": "v2", "created": "Fri, 21 Oct 2011 08:32:23 GMT"}], "update_date": "2011-10-24", "authors_parsed": [["Chaudhary", "Ankit", ""], ["Raheja", "Jagdish L.", ""]]}, {"id": "1109.6638", "submitter": "James Bergstra", "authors": "James Bergstra, Aaron Courville, Yoshua Bengio", "title": "The Statistical Inefficiency of Sparse Coding for Images (or, One Gabor\n  to Rule them All)", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding is a proven principle for learning compact representations of\nimages. However, sparse coding by itself often leads to very redundant\ndictionaries. With images, this often takes the form of similar edge detectors\nwhich are replicated many times at various positions, scales and orientations.\nAn immediate consequence of this observation is that the estimation of the\ndictionary components is not statistically efficient. We propose a factored\nmodel in which factors of variation (e.g. position, scale and orientation) are\nuntangled from the underlying Gabor-like filters. There is so much redundancy\nin sparse codes for natural images that our model requires only a single\ndictionary element (a Gabor-like edge detector) to outperform standard sparse\ncoding. Our model scales naturally to arbitrary-sized images while achieving\nmuch greater statistical efficiency during learning. We validate this claim\nwith a number of experiments showing, in part, superior compression of\nout-of-sample data using a sparse coding dictionary learned with only a single\nimage.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 19:47:00 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2011 15:27:25 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Bergstra", "James", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1109.6840", "submitter": "Sumita Mishra", "authors": "Sumita Mishra", "title": "A Novel comprehensive method for real time Video Motion Detection\n  Surveillance", "comments": "5 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a comprehensive system for surveillance and monitoring\napplications. The development of an efficient real time video motion detection\nsystem is motivated by their potential for deployment in the areas where\nsecurity is the main concern. The paper presents a platform for real time video\nmotion detection and subsequent generation of an alarm condition as set by the\nparameters of the control system. The prototype consists of a mobile platform\nmounted with RF camera which provides continuous feedback of the environment.\nThe received visual information is then analyzed by user for appropriate\ncontrol action, thus enabling the user to operate the system from a remote\nlocation. The system is also equipped with the ability to process the image of\nan object and generate control signals which are automatically transmitted to\nthe mobile platform to track the object.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 14:48:51 GMT"}], "update_date": "2011-10-03", "authors_parsed": [["Mishra", "Sumita", ""]]}]