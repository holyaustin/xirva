[{"id": "1305.0020", "submitter": "Firas Ajil Jassim", "authors": "Firas A. Jassim", "title": "Image Compression By Embedding Five Modulus Method Into JPEG", "comments": "9 pages, 6 tables, 6 figures", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.4, No.2, April 2013", "doi": "10.5121/sipij.2013.4203", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The standard JPEG format is almost the optimum format in image compression.\nThe compression ratio in JPEG sometimes reaches 30:1. The compression ratio of\nJPEG could be increased by embedding the Five Modulus Method (FMM) into the\nJPEG algorithm. The novel algorithm gives twice the time as the standard JPEG\nalgorithm or more. The novel algorithm was called FJPEG (Five-JPEG). The\nquality of the reconstructed image after compression is approximately\napproaches the JPEG. Standard test images have been used to support and\nimplement the suggested idea in this paper and the error metrics have been\ncomputed and compared with JPEG.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 20:28:37 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Jassim", "Firas A.", ""]]}, {"id": "1305.0218", "submitter": "Alon Schclar", "authors": "Dina Dushnik and Alon Schclar and Amir Averbuch", "title": "Video Segmentation via Diffusion Bases", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying moving objects in a video sequence, which is produced by a static\ncamera, is a fundamental and critical task in many computer-vision\napplications. A common approach performs background subtraction, which\nidentifies moving objects as the portion of a video frame that differs\nsignificantly from a background model. A good background subtraction algorithm\nhas to be robust to changes in the illumination and it should avoid detecting\nnon-stationary background objects such as moving leaves, rain, snow, and\nshadows. In addition, the internal background model should quickly respond to\nchanges in background such as objects that start to move or stop. We present a\nnew algorithm for video segmentation that processes the input video sequence as\na 3D matrix where the third axis is the time domain. Our approach identifies\nthe background by reducing the input dimension using the \\emph{diffusion bases}\nmethodology. Furthermore, we describe an iterative method for extracting and\ndeleting the background. The algorithm has two versions and thus covers the\ncomplete range of backgrounds: one for scenes with static backgrounds and the\nother for scenes with dynamic (moving) backgrounds.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2013 16:22:55 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Dushnik", "Dina", ""], ["Schclar", "Alon", ""], ["Averbuch", "Amir", ""]]}, {"id": "1305.0311", "submitter": "Zhenyu Guo", "authors": "Zhenyu Guo and Z.Jane Wang", "title": "An Adaptive Descriptor Design for Object Recognition in the Wild", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/ICCV.2013.319", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital images nowadays have various styles of appearance, in the aspects of\ncolor tones, contrast, vignetting, and etc. These 'picture styles' are directly\nrelated to the scene radiance, image pipeline of the camera, and post\nprocessing functions. Due to the complexity and nonlinearity of these causes,\npopular gradient-based image descriptors won't be invariant to different\npicture styles, which will decline the performance of object recognition. Given\nthat images shared online or created by individual users are taken with a wide\nrange of devices and may be processed by various post processing functions, to\nfind a robust object recognition system is useful and challenging. In this\npaper, we present the first study on the influence of picture styles for object\nrecognition, and propose an adaptive approach based on the kernel view of\ngradient descriptors and multiple kernel learning, without estimating or\nspecifying the styles of images used in training and testing. We conduct\nexperiments on Domain Adaptation data set and Oxford Flower data set. The\nexperiments also include several variants of the flower data set by processing\nthe images with popular photo effects. The results demonstrate that our\nproposed method improve from standard descriptors in all cases.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2013 23:11:36 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Guo", "Zhenyu", ""], ["Wang", "Z. Jane", ""]]}, {"id": "1305.0871", "submitter": "Weifeng Liu", "authors": "Hui Li, Xiaomeng Wang, Weifeng Liu, Yanjiang Wang", "title": "Dictionary learning based image enhancement for rarity detection", "comments": "4 pages, International Conferences on Signal Processing 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image enhancement is an important image processing technique that processes\nimages suitably for a specific application e.g. image editing. The conventional\nsolutions of image enhancement are grouped into two categories which are\nspatial domain processing method and transform domain processing method such as\ncontrast manipulation, histogram equalization, homomorphic filtering. This\npaper proposes a new image enhance method based on dictionary learning.\nParticularly, the proposed method adjusts the image by manipulating the rarity\nof dictionary atoms. Firstly, learn the dictionary through sparse coding\nalgorithms on divided sub-image blocks. Secondly, compute the rarity of\ndictionary atoms on statistics of the corresponding sparse coefficients.\nThirdly, adjust the rarity according to specific application and form a new\ndictionary. Finally, reconstruct the image using the updated dictionary and\nsparse coefficients. Compared with the traditional techniques, the proposed\nmethod enhances image based on the image content not on distribution of pixel\ngrey value or frequency. The advantages of the proposed method lie in that it\nis in better correspondence with the response of the human visual system and\nmore suitable for salient objects extraction. The experimental results\ndemonstrate the effectiveness of the proposed image enhance method.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2013 03:14:46 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 01:38:19 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Li", "Hui", ""], ["Wang", "Xiaomeng", ""], ["Liu", "Weifeng", ""], ["Wang", "Yanjiang", ""]]}, {"id": "1305.1052", "submitter": "Firas Ajil Jassim", "authors": "Firas Ajil Jassim, Fawzi H. Altaani", "title": "Hybridization of Otsu Method and Median Filter for Color Image\n  Segmentation", "comments": "6 pages, 7 figures", "journal-ref": "International Journal of Soft Computing and Engineering, Volume-3,\n  Issue-2, May 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this article a novel algorithm for color image segmentation has been\ndeveloped. The proposed algorithm based on combining two existing methods in\nsuch a novel way to obtain a significant method to partition the color image\ninto significant regions. On the first phase, the traditional Otsu method for\ngray channel image segmentation were applied for each of the R,G, and B\nchannels separately to determine the suitable automatic threshold for each\nchannel. After that, the new modified channels are integrated again to\nformulate a new color image. The resulted image suffers from some kind of\ndistortion. To get rid of this distortion, the second phase is arise which is\nthe median filter to smooth the image and increase the segmented regions. This\nprocess looks very significant by the ocular eye. Experimental results were\npresented on a variety of test images to support the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2013 20:49:54 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Jassim", "Firas Ajil", ""], ["Altaani", "Fawzi H.", ""]]}, {"id": "1305.1163", "submitter": "Katrin  Santner", "authors": "Lucas Paletta, Katrin Santner, Gerald Fritz, Albert Hofmann, Gerald\n  Lodron, Georg Thallinger, Heinz Mayer", "title": "A Computer Vision System for Attention Mapping in SLAM based 3D Models", "comments": "Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)", "journal-ref": null, "doi": null, "report-no": "OAGM-AAPR/2013/10", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of human factors in the frame of interaction studies has been\nrelevant for usability engi-neering and ergonomics for decades. Today, with the\nadvent of wearable eye-tracking and Google glasses, monitoring of human factors\nwill soon become ubiquitous. This work describes a computer vision system that\nenables pervasive mapping and monitoring of human attention. The key\ncontribu-tion is that our methodology enables full 3D recovery of the gaze\npointer, human view frustum and associated human centred measurements directly\ninto an automatically computed 3D model in real-time. We apply RGB-D SLAM and\ndescriptor matching methodologies for the 3D modelling, locali-zation and fully\nautomated annotation of ROIs (regions of interest) within the acquired 3D\nmodel. This innovative methodology will open new avenues for attention studies\nin real world environments, bringing new potential into automated processing\nfor human factors technologies.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2013 12:35:52 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Paletta", "Lucas", ""], ["Santner", "Katrin", ""], ["Fritz", "Gerald", ""], ["Hofmann", "Albert", ""], ["Lodron", "Gerald", ""], ["Thallinger", "Georg", ""], ["Mayer", "Heinz", ""]]}, {"id": "1305.1199", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "How to find real-world applications for compressive sensing", "comments": "10 pages", "journal-ref": "Proceedings of SPIE DSS 2013, Conference 8717 Compressive Sensing\n  II", "doi": "10.1117/12.2018244", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The potential of compressive sensing (CS) has spurred great interest in the\nresearch community and is a fast growing area of research. However, research\ntranslating CS theory into practical hardware and demonstrating clear and\nsignificant benefits with this hardware over current, conventional imaging\ntechniques has been limited. This article helps researchers to find those niche\napplications where the CS approach provides substantial gain over conventional\napproaches by articulating lessons learned in finding one such application; sea\nskimming missile detection. As a proof of concept, it is demonstrated that a\nsimplified CS missile detection architecture and algorithm provides comparable\nresults to the conventional imaging approach but using a smaller FPA. The\nprimary message is that all of the excitement surrounding CS is necessary and\nappropriate for encouraging our creativity but we all must also take off our\n\"rose colored glasses\" and critically judge our ideas, methods and results\nrelative to conventional imaging approaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2013 14:00:07 GMT"}, {"version": "v2", "created": "Wed, 22 May 2013 16:47:22 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2013 16:10:26 GMT"}, {"version": "v4", "created": "Wed, 26 Jun 2013 14:20:09 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1305.1206", "submitter": "Juan Cardelino", "authors": "Juan Cardelino, Vicent Caselles, Marcelo Bertalmio and Gregory Randall", "title": "A Contrario Selection of Optimal Partitions for Image Segmentation", "comments": "Siam Journal on Imaging Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel segmentation algorithm based on a hierarchical\nrepresentation of images. The main contribution of this work is to explore the\ncapabilities of the A Contrario reasoning when applied to the segmentation\nproblem, and to overcome the limitations of current algorithms within that\nframework. This exploratory approach has three main goals.\n  Our first goal is to extend the search space of greedy merging algorithms to\nthe set of all partitions spanned by a certain hierarchy, and to cast the\nsegmentation as a selection problem within this space. In this way we increase\nthe number of tested partitions and thus we potentially improve the\nsegmentation results. In addition, this space is considerably smaller than the\nspace of all possible partitions, thus we still keep the complexity controlled.\n  Our second goal aims to improve the locality of region merging algorithms,\nwhich usually merge pairs of neighboring regions. In this work, we overcome\nthis limitation by introducing a validation procedure for complete partitions,\nrather than for pairs of regions.\n  The third goal is to perform an exhaustive experimental evaluation\nmethodology in order to provide reproducible results.\n  Finally, we embed the selection process on a statistical A Contrario\nframework which allows us to have only one free parameter related to the\ndesired scale.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2013 14:17:11 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Cardelino", "Juan", ""], ["Caselles", "Vicent", ""], ["Bertalmio", "Marcelo", ""], ["Randall", "Gregory", ""]]}, {"id": "1305.1256", "submitter": "Alessandro Mirone", "authors": "Alessandro Mirone, Emmanuel Brun, Paola Coan", "title": "A Convex Functional for Image Denoising based on Patches with\n  Constrained Overlaps and its vectorial application to Low Dose Differential\n  Phase Tomography", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0114325", "report-no": null, "categories": "math.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve the image denoising problem with a dictionary learning technique by\nwriting a convex functional of a new form. This functional contains beside the\nusual sparsity inducing term and fidelity term, a new term which induces\nsimilarity between overlapping patches in the overlap regions. The functional\ndepends on two free regularization parameters: a coefficient multiplying the\nsparsity-inducing $L_{1}$ norm of the patch basis functions coefficients, and a\ncoefficient multiplying the $L_{2}$ norm of the differences between patches in\nthe overlapping regions. The solution is found by applying the iterative\nproximal gradient descent method with FISTA acceleration. In the case of\ntomography reconstruction we calculate the gradient by applying projection of\nthe solution and its error backprojection at each iterative step. We study the\nquality of the solution, as a function of the regularization parameters and\nnoise, on synthetic datas for which the solution is a-priori known. We apply\nthe method on experimental data in the case of Differential Phase Tomography.\nFor this case we use an original approach which consists in using vectorial\npatches, each patch having two components: one per each gradient component. The\nresulting algorithm, implemented in the ESRF tomography reconstruction code\nPyHST, results to be robust, efficient, and well adapted to strongly reduce the\nrequired dose and the number of projections in medical tomography.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2013 17:47:44 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Mirone", "Alessandro", ""], ["Brun", "Emmanuel", ""], ["Coan", "Paola", ""]]}, {"id": "1305.1344", "submitter": "Faouzi Benzarti", "authors": "Faouzi Benzarti and Hamid Amiri", "title": "Speckle Noise Reduction in Medical Ultrasound Images", "comments": null, "journal-ref": "International Journal of Computer Science Issues, Vol 9, Issue 2,\n  No 3, March 2012 ISSN 1694-0814", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound imaging is an incontestable vital tool for diagnosis, it provides\nin non-invasive manner the internal structure of the body to detect eventually\ndiseases or abnormalities tissues. Unfortunately, the presence of speckle noise\nin these images affects edges and fine details which limit the contrast\nresolution and make diagnostic more difficult. In this paper, we propose a\ndenoising approach which combines logarithmic transformation and a non linear\ndiffusion tensor. Since speckle noise is multiplicative and nonwhite process,\nthe logarithmic transformation is a reasonable choice to convert\nsignaldependent or pure multiplicative noise to an additive one. The key idea\nfrom using diffusion tensor is to adapt the flow diffusion towards the local\norientation by applying anisotropic diffusion along the coherent structure\ndirection of interesting features in the image. To illustrate the effective\nperformance of our algorithm, we present some experimental results on\nsynthetically and real echographic images.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2013 22:25:52 GMT"}], "update_date": "2013-05-08", "authors_parsed": [["Benzarti", "Faouzi", ""], ["Amiri", "Hamid", ""]]}, {"id": "1305.1396", "submitter": "Marcelo Fiori", "authors": "Mat\\'ias Di Martino, Guzman Hern\\'andez, Marcelo Fiori, Alicia\n  Fern\\'andez", "title": "A new framework for optimal classifier design", "comments": null, "journal-ref": "Pattern Recognition, Volume 46, Issue 8, August 2013, Pages\n  2249-2255", "doi": "10.1016/j.patcog.2013.01.006", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of alternative measures to evaluate classifier performance is gaining\nattention, specially for imbalanced problems. However, the use of these\nmeasures in the classifier design process is still unsolved. In this work we\npropose a classifier designed specifically to optimize one of these alternative\nmeasures, namely, the so-called F-measure. Nevertheless, the technique is\ngeneral, and it can be used to optimize other evaluation measures. An algorithm\nto train the novel classifier is proposed, and the numerical scheme is tested\nwith several databases, showing the optimality and robustness of the presented\nclassifier.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2013 04:05:24 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2013 16:09:55 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["Di Martino", "Mat\u00edas", ""], ["Hern\u00e1ndez", "Guzman", ""], ["Fiori", "Marcelo", ""], ["Fern\u00e1ndez", "Alicia", ""]]}, {"id": "1305.1443", "submitter": "Umut Uludag", "authors": "Mehmet Kayaoglu, Berkay Topcu, Umut Uludag", "title": "Standard Fingerprint Databases: Manual Minutiae Labeling and Matcher\n  Performance Analyses", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprint verification and identification algorithms based on minutiae\nfeatures are used in many biometric systems today (e.g., governmental e-ID\nprograms, border control, AFIS, personal authentication for portable devices).\nResearchers in industry/academia are now able to utilize many publicly\navailable fingerprint databases (e.g., Fingerprint Verification Competition\n(FVC) & NIST databases) to compare/evaluate their feature extraction and/or\nmatching algorithm performances against those of others. The results from these\nevaluations are typically utilized by decision makers responsible for\nimplementing the cited biometric systems, in selecting/tuning specific sensors,\nfeature extractors and matchers. In this study, for a subset of the cited\npublic fingerprint databases, we report fingerprint minutiae matching results,\nwhich are based on (i) minutiae extracted automatically from fingerprint\nimages, and (ii) minutiae extracted manually by human subjects. By doing so, we\nare able to (i) quantitatively judge the performance differences between these\ntwo cases, (ii) elaborate on performance upper bounds of minutiae matching,\nutilizing what can be termed as \"ground truth\" minutiae features, (iii) analyze\nminutiae matching performance, without coupling it with the minutiae extraction\nperformance beforehand. Further, as we will freely distribute the minutiae\ntemplates, originating from this manual labeling study, in a standard minutiae\ntemplate exchange format (ISO 19794-2), we believe that other researchers in\nthe biometrics community will be able to utilize the associated results &\ntemplates to create their own evaluations pertaining to their fingerprint\nminutiae extractors/matchers.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2013 09:03:38 GMT"}, {"version": "v2", "created": "Wed, 8 May 2013 07:43:13 GMT"}], "update_date": "2013-05-09", "authors_parsed": [["Kayaoglu", "Mehmet", ""], ["Topcu", "Berkay", ""], ["Uludag", "Umut", ""]]}, {"id": "1305.1495", "submitter": "Lorenzo Del Castello", "authors": "Alessandro Attanasi, Andrea Cavagna, Lorenzo Del Castello, Irene\n  Giardina, Asja Jelic, Stefania Melillo, Leonardo Parisi, Fabio Pellacini,\n  Edward Shen, Edmondo Silvestri, Massimiliano Viale", "title": "GReTA - a novel Global and Recursive Tracking Algorithm in three\n  dimensions", "comments": "13 pages, 6 figures, 3 tables. Version 3 was slightly shortened, and\n  new comprative results on the public datasets (thermal infrared videos of\n  flying bats) by Z. Wu and coworkers (2014) were included. in A. Attanasi et\n  al., \"GReTA - A Novel Global and Recursive Tracking Algorithm in Three\n  Dimensions\", IEEE Trans. Pattern Anal. Mach. Intell., vol.37 (2015)", "journal-ref": null, "doi": "10.1109/TPAMI.2015.2414427", "report-no": null, "categories": "q-bio.QM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking multiple moving targets allows quantitative measure of the dynamic\nbehavior in systems as diverse as animal groups in biology, turbulence in fluid\ndynamics and crowd and traffic control. In three dimensions, tracking several\ntargets becomes increasingly hard since optical occlusions are very likely,\ni.e. two featureless targets frequently overlap for several frames. Occlusions\nare particularly frequent in biological groups such as bird flocks, fish\nschools, and insect swarms, a fact that has severely limited collective animal\nbehavior field studies in the past. This paper presents a 3D tracking method\nthat is robust in the case of severe occlusions. To ensure robustness, we adopt\na global optimization approach that works on all objects and frames at once. To\nachieve practicality and scalability, we employ a divide and conquer\nformulation, thanks to which the computational complexity of the problem is\nreduced by orders of magnitude. We tested our algorithm with synthetic data,\nwith experimental data of bird flocks and insect swarms and with public\nbenchmark datasets, and show that our system yields high quality trajectories\nfor hundreds of moving targets with severe overlap. The results obtained on\nvery heterogeneous data show the potential applicability of our method to the\nmost diverse experimental situations.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2013 12:45:30 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 14:55:59 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2015 16:36:59 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Attanasi", "Alessandro", ""], ["Cavagna", "Andrea", ""], ["Del Castello", "Lorenzo", ""], ["Giardina", "Irene", ""], ["Jelic", "Asja", ""], ["Melillo", "Stefania", ""], ["Parisi", "Leonardo", ""], ["Pellacini", "Fabio", ""], ["Shen", "Edward", ""], ["Silvestri", "Edmondo", ""], ["Viale", "Massimiliano", ""]]}, {"id": "1305.1520", "submitter": "Ney Renau-Ferrer", "authors": "Ney Renau-Ferrer (LAMIA), C\\'eline Remi (LAMIA)", "title": "A Method for Visuo-Spatial Classification of Freehand Shapes Freely\n  Sketched", "comments": "IPCV'10 - 14th International Conference on Image Processing, Computer\n  Vision, \\& Pattern Recognition, \\'Etats-Unis (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the principle and the main steps of a new method for the\nvisuo-spatial analysis of geometrical sketches recorded online. Visuo-spatial\nanalysis is a necessary step for multi-level analysis. Multi-level analysis\nsimultaneously allows classification, comparison or clustering of the\nconstituent parts of a pattern according to their visuo-spatial properties,\ntheir procedural strategies, their structural or temporal parameters, or any\ncombination of two or more of those parameters. The first results provided by\nthis method concern the comparison of sketches to some perfect patterns of\nsimple geometrical figures and the measure of dissimilarity between real\nsketches. The mean rates of good decision higher than 95% obtained are\npromising in both cases.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2013 14:02:46 GMT"}], "update_date": "2013-05-08", "authors_parsed": [["Renau-Ferrer", "Ney", "", "LAMIA"], ["Remi", "C\u00e9line", "", "LAMIA"]]}, {"id": "1305.1912", "submitter": "Alexander Mamonov V", "authors": "Alexander V. Mamonov, Isabel N. Figueiredo, Pedro N. Figueiredo,\n  Yen-Hsi Richard Tsai", "title": "Automated polyp detection in colon capsule endoscopy", "comments": "16 pages, 9 figures, 4 tables", "journal-ref": "IEEE Transactions on Medical Imaging 33(7):1488-1502, 2014", "doi": "10.1109/TMI.2014.2314959", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal polyps are important precursors to colon cancer, a major health\nproblem. Colon capsule endoscopy (CCE) is a safe and minimally invasive\nexamination procedure, in which the images of the intestine are obtained via\ndigital cameras on board of a small capsule ingested by a patient. The video\nsequence is then analyzed for the presence of polyps. We propose an algorithm\nthat relieves the labor of a human operator analyzing the frames in the video\nsequence. The algorithm acts as a binary classifier, which labels the frame as\neither containing polyps or not, based on the geometrical analysis and the\ntexture content of the frame. The geometrical analysis is based on a\nsegmentation of an image with the help of a mid-pass filter. The features\nextracted by the segmentation procedure are classified according to an\nassumption that the polyps are characterized as protrusions that are mostly\nround in shape. Thus, we use a best fit ball radius as a decision parameter of\na binary classifier. We present a statistical study of the performance of our\napproach on a data set containing over 18,900 frames from the endoscopic video\nsequences of five adult patients. The algorithm demonstrates a solid\nperformance, achieving 47% sensitivity per frame and over 81% sensitivity per\npolyp at a specificity level of 90%. On average, with a video sequence length\nof 3747 frames, only 367 false positive frames need to be inspected by a human\noperator.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2013 18:33:28 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2013 20:02:40 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 16:57:38 GMT"}, {"version": "v4", "created": "Thu, 27 Mar 2014 22:52:11 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Mamonov", "Alexander V.", ""], ["Figueiredo", "Isabel N.", ""], ["Figueiredo", "Pedro N.", ""], ["Tsai", "Yen-Hsi Richard", ""]]}, {"id": "1305.1986", "submitter": "Madhur Srivastava", "authors": "Madhur Srivastava, Satish K. Singh, and Prasanta K. Panigrahi", "title": "An Adaptive Statistical Non-uniform Quantizer for Detail Wavelet\n  Components in Lossy JPEG2000 Image Compression", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a non-uniform quantization method for the Detail\ncomponents in the JPEG2000 standard. Incorporating the fact that the\ncoefficients lying towards the ends of the histogram plot of each Detail\ncomponent represent the structural information of an image, the quantization\nstep sizes become smaller at they approach the ends of the histogram plot. The\nvariable quantization step sizes are determined by the actual statistics of the\nwavelet coefficients. Mean and standard deviation are the two statistical\nparameters used iteratively to obtain the variable step sizes. Moreover, the\nmean of the coefficients lying within the step size is chosen as the quantized\nvalue, contrary to the deadzone uniform quantizer which selects the midpoint of\nthe quantization step size as the quantized value. The experimental results of\nthe deadzone uniform quantizer and the proposed non-uniform quantizer are\nobjectively compared by using Mean-Squared Error (MSE) and Mean Structural\nSimilarity Index Measure (MSSIM), to evaluate the quantization error and\nreconstructed image quality, respectively. Subjective analysis of the\nreconstructed images is also carried out. Through the objective and subjective\nassessments, it is shown that the non-uniform quantizer performs better than\nthe deadzone uniform quantizer in the perceptual quality of the reconstructed\nimage, especially at low bitrates. More importantly, unlike the deadzone\nuniform quantizer, the non-uniform quantizer accomplishes better visual quality\nwith a few quantized values.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2013 01:10:11 GMT"}, {"version": "v2", "created": "Sat, 12 Jul 2014 22:22:29 GMT"}, {"version": "v3", "created": "Thu, 14 Aug 2014 20:30:55 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Srivastava", "Madhur", ""], ["Singh", "Satish K.", ""], ["Panigrahi", "Prasanta K.", ""]]}, {"id": "1305.2221", "submitter": "Faouzi Benzarti", "authors": "Faouzi Benzarti, Hamid Amiri", "title": "Repairing and Inpainting Damaged Images using Diffusion Tensor", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol 9,\n  Issue 4, No 3, July 2012 ISSN 1694-0814", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Removing or repairing the imperfections of a digital images or videos is a\nvery active and attractive field of research belonging to the image inpainting\ntechnique. This later has a wide range of applications, such as removing\nscratches in old photographic image, removing text and logos or creating\ncartoon and artistic effects. In this paper, we propose an efficient method to\nrepair a damaged image based on a non linear diffusion tensor. The idea is to\ntrack perfectly the local geometry of the damaged image and allowing diffusion\nonly in the isophotes curves direction. To illustrate the effective performance\nof our method, we present some experimental results on test and real\nphotographic color images\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2013 22:10:36 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Benzarti", "Faouzi", ""], ["Amiri", "Hamid", ""]]}, {"id": "1305.2269", "submitter": "Fang Wang", "authors": "Fang Wang and Yi Li", "title": "Beyond Physical Connections: Tree Models in Human Pose Estimation", "comments": "CVPR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simple tree models for articulated objects prevails in the last decade.\nHowever, it is also believed that these simple tree models are not capable of\ncapturing large variations in many scenarios, such as human pose estimation.\nThis paper attempts to address three questions: 1) are simple tree models\nsufficient? more specifically, 2) how to use tree models effectively in human\npose estimation? and 3) how shall we use combined parts together with single\nparts efficiently?\n  Assuming we have a set of single parts and combined parts, and the goal is to\nestimate a joint distribution of their locations. We surprisingly find that no\nlatent variables are introduced in the Leeds Sport Dataset (LSP) during\nlearning latent trees for deformable model, which aims at approximating the\njoint distributions of body part locations using minimal tree structure. This\nsuggests one can straightforwardly use a mixed representation of single and\ncombined parts to approximate their joint distribution in a simple tree model.\nAs such, one only needs to build Visual Categories of the combined parts, and\nthen perform inference on the learned latent tree. Our method outperformed the\nstate of the art on the LSP, both in the scenarios when the training images are\nfrom the same dataset and from the PARSE dataset. Experiments on animal images\nfrom the VOC challenge further support our findings.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 07:09:14 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Wang", "Fang", ""], ["Li", "Yi", ""]]}, {"id": "1305.2362", "submitter": "David Wipf", "authors": "David Wipf and Haichao Zhang", "title": "Revisiting Bayesian Blind Deconvolution", "comments": "This paper has been submitted to JMLR. A conference version will\n  appear at EMMCVPR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind deconvolution involves the estimation of a sharp signal or image given\nonly a blurry observation. Because this problem is fundamentally ill-posed,\nstrong priors on both the sharp image and blur kernel are required to\nregularize the solution space. While this naturally leads to a standard MAP\nestimation framework, performance is compromised by unknown trade-off parameter\nsettings, optimization heuristics, and convergence issues stemming from\nnon-convexity and/or poor prior selections. To mitigate some of these problems,\na number of authors have recently proposed substituting a variational Bayesian\n(VB) strategy that marginalizes over the high-dimensional image space leading\nto better estimates of the blur kernel. However, the underlying cost function\nnow involves both integrals with no closed-form solution and complex,\nfunction-valued arguments, thus losing the transparency of MAP. Beyond standard\nBayesian-inspired intuitions, it thus remains unclear by exactly what mechanism\nthese methods are able to operate, rendering understanding, improvements and\nextensions more difficult. To elucidate these issues, we demonstrate that the\nVB methodology can be recast as an unconventional MAP problem with a very\nparticular penalty/prior that couples the image, blur kernel, and noise level\nin a principled way. This unique penalty has a number of useful characteristics\npertaining to relative concavity, local minima avoidance, and scale-invariance\nthat allow us to rigorously explain the success of VB including its existing\nimplementational heuristics and approximations. It also provides strict\ncriteria for choosing the optimal image prior that, perhaps\ncounter-intuitively, need not reflect the statistics of natural scenes. In so\ndoing we challenge the prevailing notion of why VB is successful for blind\ndeconvolution while providing a transparent platform for introducing\nenhancements.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 15:09:11 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Wipf", "David", ""], ["Zhang", "Haichao", ""]]}, {"id": "1305.2395", "submitter": "Toshiro Kubota", "authors": "Toshiro Kubota, Jessica Ranck, Briley Acker, and Herman De Haan", "title": "Shape Reconstruction and Recognition with Isolated Non-directional Cues", "comments": "28 pages, 14 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates a hypothesis that our visual system groups visual cues\nbased on how they form a surface, or more specifically triangulation derived\nfrom the visual cues. To test our hypothesis, we compare shape recognition with\nthree different representations of visual cues: a set of isolated dots\ndelineating the outline of the shape, a set of triangles obtained from Delaunay\ntriangulation of the set of dots, and a subset of Delaunay triangles excluding\nthose outside of the shape. Each participant was assigned to one particular\nrepresentation type and increased the number of dots (and consequentially\ntriangles) until the underlying shape could be identified. We compare the\naverage number of dots needed for identification among three types of\nrepresentations. Our hypothesis predicts that the results from the three\nrepresentations will be similar. However, they show statistically significant\ndifferences. The paper also presents triangulation based algorithms for\nreconstruction and recognition of a shape from a set of isolated dots.\nExperiments showed that the algorithms were more effective and perceptually\nagreeable than similar contour based ones. From these experiments, we conclude\nthat triangulation does affect our shape recognition. However, the surface\nbased approach presents a number of computational advantages over the contour\nbased one and should be studied further.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 17:35:02 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Kubota", "Toshiro", ""], ["Ranck", "Jessica", ""], ["Acker", "Briley", ""], ["De Haan", "Herman", ""]]}, {"id": "1305.2687", "submitter": "Duc Phu Chau", "authors": "Duc Phu Chau (INRIA Sophia Antipolis), Monique Thonnat (INRIA Sophia\n  Antipolis), Fran\\c{c}ois Bremond (INRIA Sophia Antipolis)", "title": "Automatic Parameter Adaptation for Multi-object Tracking", "comments": "International Conference on Computer Vision Systems (ICVS) (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object tracking quality usually depends on video context (e.g. object\nocclusion level, object density). In order to decrease this dependency, this\npaper presents a learning approach to adapt the tracker parameters to the\ncontext variations. In an offline phase, satisfactory tracking parameters are\nlearned for video context clusters. In the online control phase, once a context\nchange is detected, the tracking parameters are tuned using the learned values.\nThe experimental results show that the proposed approach outperforms the recent\ntrackers in state of the art. This paper brings two contributions: (1) a\nclassification method of video sequences to learn offline tracking parameters,\n(2) a new method to tune online tracking parameters using tracking context.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2013 07:14:07 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Chau", "Duc Phu", "", "INRIA Sophia Antipolis"], ["Thonnat", "Monique", "", "INRIA Sophia\n  Antipolis"], ["Bremond", "Fran\u00e7ois", "", "INRIA Sophia Antipolis"]]}, {"id": "1305.2713", "submitter": "Ijaz Bukhari ijaz bukhari", "authors": "Ijaz Bukhari", "title": "Early Detection of Alzheimer's - A Crucial Requirement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's, an old age disease of people over 65 years causes problems with\nmemory, thinking and behavior. This disease progresses very slow and its\nidentification in early stages is very difficult. The symptoms of Alzheimer's\nappear slowly and gradually will have worse effects. In its early stages, not\nonly the patients themselves but their loved ones are generally unable to\naccept that the patient is suffering from disease. In this paper, we have\nproposed a new algorithm to detect patients of Alzheimer's at early stages by\ncomparing the Magnetic Resonance Images (MRI) of the patients with normal\npersons of their age. The progress of the disease can also be monitored by\nperiodic comparison of the previous and current MRI.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2013 09:19:59 GMT"}, {"version": "v2", "created": "Tue, 14 May 2013 08:27:55 GMT"}], "update_date": "2013-05-15", "authors_parsed": [["Bukhari", "Ijaz", ""]]}, {"id": "1305.2827", "submitter": "Urmila Shrawankar Ms", "authors": "Preeti Badar and Urmila Shrawankar", "title": "Human Mood Detection For Human Computer Interaction", "comments": "Pages: 04 Figures: 06 Tables: 01, Proceedings of ICETETS-08, Rajkot,\n  India, 13-14 January 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an easiest approach for facial expression\nrecognition. Here we are using concept of SVM for Expression Classification.\nMain problem is sub divided in three main modules. First one is Face detection\nin which we are using skin filter and Face segmentation. We are given more\nstress on feature Extraction. This method is effective enough for application\nwhere fast execution is required. Second, Facial Feature Extraction which is\nessential part for expression recognition. In this module we used Edge\nProjection Analysis. Finally extracted features vector is passed towards SVM\nclassifier for Expression Recognition. We are considering six basic Expressions\n(Anger, Fear, Disgust, Joy, Sadness, and Surprise)\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 08:58:01 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Badar", "Preeti", ""], ["Shrawankar", "Urmila", ""]]}, {"id": "1305.2828", "submitter": "Urmila Shrawankar Ms", "authors": "Shweta Jain and Urmila Shrawankar", "title": "Image Optimization and Prediction", "comments": "Pages: 08 Figures: 02, Proceedings of International Conferences\n  CAAM-09 BITS, Durg, India, 10 Jan 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image Processing, Optimization and Prediction of an Image play a key role in\nComputer Science. Image processing provides a way to analyze and identify an\nimage .Many areas like medical image processing, Satellite images, natural\nimages and artificial images requires lots of analysis and research on\noptimization. In Image Optimization and Prediction we are combining the\nfeatures of Query Optimization, Image Processing and Prediction . Image\noptimization is used in Pattern analysis, object recognition, in medical Image\nprocessing to predict the type of diseases, in satellite images for predicting\nweather forecast, availability of water or mineral etc. Image Processing,\nOptimization and analysis is a wide open area for research .Lots of research\nhas been conducted in the area of Image analysis and many techniques are\navailable for image analysis but, a single technique is not yet identified for\nimage analysis and prediction .our research is focused on identifying a global\ntechnique for image analysis and Prediction.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 08:43:59 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Jain", "Shweta", ""], ["Shrawankar", "Urmila", ""]]}, {"id": "1305.2876", "submitter": "Ricardo Fabbri", "authors": "Ricardo Fabbri, Ivan N. Bastos, Francisco D. Moura Neto, Francisco J.\n  P. Lopes, Wesley N. Goncalves, Odemir M. Bruno", "title": "Multi-q Pattern Classification of Polarization Curves", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.physa.2013.09.048", "report-no": null, "categories": "cs.CE cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Several experimental measurements are expressed in the form of\none-dimensional profiles, for which there is a scarcity of methodologies able\nto classify the pertinence of a given result to a specific group. The\npolarization curves that evaluate the corrosion kinetics of electrodes in\ncorrosive media are an application where the behavior is chiefly analyzed from\nprofiles. Polarization curves are indeed a classic method to determine the\nglobal kinetics of metallic electrodes, but the strong nonlinearity from\ndifferent metals and alloys can overlap and the discrimination becomes a\nchallenging problem. Moreover, even finding a typical curve from replicated\ntests requires subjective judgement. In this paper we used the so-called\nmulti-q approach based on the Tsallis statistics in a classification engine to\nseparate multiple polarization curve profiles of two stainless steels. We\ncollected 48 experimental polarization curves in aqueous chloride medium of two\nstainless steel types, with different resistance against localized corrosion.\nMulti-q pattern analysis was then carried out on a wide potential range, from\ncathodic up to anodic regions. An excellent classification rate was obtained,\nat a success rate of 90%, 80%, and 83% for low (cathodic), high (anodic), and\nboth potential ranges, respectively, using only 2% of the original profile\ndata. These results show the potential of the proposed approach towards\nefficient, robust, systematic and automatic classification of highly non-linear\nprofile curves.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 04:31:49 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Fabbri", "Ricardo", ""], ["Bastos", "Ivan N.", ""], ["Neto", "Francisco D. Moura", ""], ["Lopes", "Francisco J. P.", ""], ["Goncalves", "Wesley N.", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "1305.2949", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Fereydoun Farrahi Moghaddam and Mohamed\n  Cheriet", "title": "Unsupervised ensemble of experts (EoE) framework for automatic\n  binarization of document images", "comments": "6-page version, Accepted to be presented in ICDAR'13", "journal-ref": "ICDAR 2013, pp 703-707", "doi": "10.1109/ICDAR.2013.144", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a large number of binarization methods have been developed,\nwith varying performance generalization and strength against different\nbenchmarks. In this work, to leverage on these methods, an ensemble of experts\n(EoE) framework is introduced, to efficiently combine the outputs of various\nmethods. The proposed framework offers a new selection process of the\nbinarization methods, which are actually the experts in the ensemble, by\nintroducing three concepts: confidentness, endorsement and schools of experts.\nThe framework, which is highly objective, is built based on two general\nprinciples: (i) consolidation of saturated opinions and (ii) identification of\nschools of experts. After building the endorsement graph of the ensemble for an\ninput document image based on the confidentness of the experts, the saturated\nopinions are consolidated, and then the schools of experts are identified by\nthresholding the consolidated endorsement graph. A variation of the framework,\nin which no selection is made, is also introduced that combines the outputs of\nall experts using endorsement-dependent weights. The EoE framework is evaluated\non the set of participating methods in the H-DIBCO'12 contest and also on an\nensemble generated from various instances of grid-based Sauvola method with\npromising performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2013 20:37:29 GMT"}, {"version": "v2", "created": "Wed, 29 May 2013 14:36:35 GMT"}], "update_date": "2013-09-02", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Moghaddam", "Fereydoun Farrahi", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1305.3006", "submitter": "Dai-Qiang Chen", "authors": "Dai-Qiang Chen and Li-Zhi Cheng", "title": "Fast Linearized Alternating Direction Minimization Algorithm with\n  Adaptive Parameter Selection for Multiplicative Noise Removal", "comments": "23pages", "journal-ref": "Journal of Computational and Applied Mathematics 257 (2014) 29-45", "doi": "10.1016/j.cam.2013.08.012", "report-no": null, "categories": "cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the edge preserving ability and low computational cost of the total\nvariation (TV), variational models with the TV regularization have been widely\ninvestigated in the field of multiplicative noise removal. The key points of\nthe successful application of these models lie in: the optimal selection of the\nregularization parameter which balances the data-fidelity term with the TV\nregularizer; the efficient algorithm to compute the solution. In this paper, we\npropose two fast algorithms based on the linearized technique, which are able\nto estimate the regularization parameter and recover the image simultaneously.\nIn the iteration step of the proposed algorithms, the regularization parameter\nis adjusted by a special discrepancy function defined for multiplicative noise.\nThe convergence properties of the proposed algorithms are proved under certain\nconditions, and numerical experiments demonstrate that the proposed algorithms\noverall outperform some state-of-the-art methods in the PSNR values and\ncomputational time.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2013 02:57:01 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Chen", "Dai-Qiang", ""], ["Cheng", "Li-Zhi", ""]]}, {"id": "1305.3013", "submitter": "Dai-Qiang Chen", "authors": "Dai-Qiang Chen and Li-Zhi Cheng", "title": "Novel variational model for inpainting in the wavelet domain", "comments": "20pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wavelet domain inpainting refers to the process of recovering the missing\ncoefficients during the image compression or transmission stage. Recently, an\nefficient algorithm framework which is called Bregmanized operator splitting\n(BOS) was proposed for solving the classical variational model of wavelet\ninpainting. However, it is still time-consuming to some extent due to the inner\niteration. In this paper, a novel variational model is established to formulate\nthis reconstruction problem from the view of image decomposition. Then an\nefficient iterative algorithm based on the split-Bregman method is adopted to\ncalculate an optimal solution, and it is also proved to be convergent. Compared\nwith the BOS algorithm the proposed algorithm avoids the inner iteration and\nhence is more simple. Numerical experiments demonstrate that the proposed\nmethod is very efficient and outperforms the current state-of-the-art methods,\nespecially in the computational time.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2013 03:45:09 GMT"}], "update_date": "2013-05-15", "authors_parsed": [["Chen", "Dai-Qiang", ""], ["Cheng", "Li-Zhi", ""]]}, {"id": "1305.3189", "submitter": "Wassim Bouachir", "authors": "Wassim Bouachir, Atousa Torabi, Guillaume-Alexandre Bilodeau, Pascal\n  Blais", "title": "A Bag of Words Approach for Semantic Segmentation of Monitored Scenes", "comments": "\\'Ecole Polytechnique de Montr\\'eal, iWatchLife Inc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a semantic segmentation method for outdoor scenes\ncaptured by a surveillance camera. Our algorithm classifies each perceptually\nhomogenous region as one of the predefined classes learned from a collection of\nmanually labelled images. The proposed approach combines two different types of\ninformation. First, color segmentation is performed to divide the scene into\nperceptually similar regions. Then, the second step is based on SIFT keypoints\nand uses the bag of words representation of the regions for the classification.\nThe prediction is done using a Na\\\"ive Bayesian Network as a generative\nclassifier. Compared to existing techniques, our method provides more compact\nrepresentations of scene contents and the segmentation result is more\nconsistent with human perception due to the combination of the color\ninformation with the image keypoints. The experiments conducted on a publicly\navailable data set demonstrate the validity of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2013 15:58:38 GMT"}], "update_date": "2013-05-15", "authors_parsed": [["Bouachir", "Wassim", ""], ["Torabi", "Atousa", ""], ["Bilodeau", "Guillaume-Alexandre", ""], ["Blais", "Pascal", ""]]}, {"id": "1305.3250", "submitter": "Cristian Popescu", "authors": "Marian Popescu, Peter J. Dugan, Mohammad Pourhomayoun, Denise Risch,\n  Harold W. Lewis III, Christopher W. Clark", "title": "Bioacoustical Periodic Pulse Train Signal Detection and Classification\n  using Spectrogram Intensity Binarization and Energy Projection", "comments": "ICML 2013 Workshop on Machine Learning for Bioacoustics, 2013, 6\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following work outlines an approach for automatic detection and\nrecognition of periodic pulse train signals using a multi-stage process based\non spectrogram edge detection, energy projection and classification. The method\nhas been implemented to automatically detect and recognize pulse train songs of\nminke whales. While the long term goal of this work is to properly identify and\ndetect minke songs from large multi-year datasets, this effort was developed\nusing sounds off the coast of Massachusetts, in the Stellwagen Bank National\nMarine Sanctuary. The detection methodology is presented and evaluated on 232\ncontinuous hours of acoustic recordings and a qualitative analysis of machine\nlearning classifiers and their performance is described. The trained automatic\ndetection and classification system is applied to 120 continuous hours,\ncomprised of various challenges such as broadband and narrowband noises, low\nSNR, and other pulse train signatures. This automatic system achieves a TPR of\n63% for FPR of 0.6% (or 0.87 FP/h), at a Precision (PPV) of 84% and an F1 score\nof 71%.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2013 18:49:52 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 20:09:07 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2013 17:33:59 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Popescu", "Marian", ""], ["Dugan", "Peter J.", ""], ["Pourhomayoun", "Mohammad", ""], ["Risch", "Denise", ""], ["Lewis", "Harold W.", "III"], ["Clark", "Christopher W.", ""]]}, {"id": "1305.3633", "submitter": "Mohammad Pourhomayoun", "authors": "Mohammad Pourhomayoun, Peter Dugan, Marian Popescu, Denise Risch, Hal\n  Lewis, Christopher Clark", "title": "Classification for Big Dataset of Bioacoustic Signals Based on Human\n  Scoring System and Artificial Neural Network", "comments": "To be Submitted to \"ICML 2013 Workshop on Machine Learning for\n  Bioacoustics\", 6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method to improve sound classification\nperformance by combining signal features, derived from the time-frequency\nspectrogram, with human perception. The method presented herein exploits an\nartificial neural network (ANN) and learns the signal features based on the\nhuman perception knowledge. The proposed method is applied to a large acoustic\ndataset containing 24 months of nearly continuous recordings. The results show\na significant improvement in performance of the detection-classification\nsystem; yielding as much as 20% improvement in true positive rate for a given\nfalse positive rate.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2013 20:53:39 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 20:29:14 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Pourhomayoun", "Mohammad", ""], ["Dugan", "Peter", ""], ["Popescu", "Marian", ""], ["Risch", "Denise", ""], ["Lewis", "Hal", ""], ["Clark", "Christopher", ""]]}, {"id": "1305.3635", "submitter": "Mohammad Pourhomayoun", "authors": "Mohammad Pourhomayoun, Peter Dugan, Marian Popescu, Christopher Clark", "title": "Bioacoustic Signal Classification Based on Continuous Region Processing,\n  Grid Masking and Artificial Neural Network", "comments": "To be Submitted to \"ICML 2013 Workshop on Machine Learning for\n  Bioacoustics\", 6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a novel method based on machine-learning and image\nprocessing to identify North Atlantic right whale (NARW) up-calls in the\npresence of high levels of ambient and interfering noise. We apply a continuous\nregion algorithm on the spectrogram to extract the regions of interest, and\nthen use grid masking techniques to generate a small feature set that is then\nused in an artificial neural network classifier to identify the NARW up-calls.\nIt is shown that the proposed technique is effective in detecting and capturing\neven very faint up-calls, in the presence of ambient and interfering noises.\nThe method is evaluated on a dataset recorded in Massachusetts Bay, United\nStates. The dataset includes 20000 sound clips for training, and 10000 sound\nclips for testing. The results show that the proposed technique can achieve an\nerror rate of less than FPR = 4.5% for a 90% true positive rate.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2013 20:59:03 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 20:28:33 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Pourhomayoun", "Mohammad", ""], ["Dugan", "Peter", ""], ["Popescu", "Marian", ""], ["Clark", "Christopher", ""]]}, {"id": "1305.3885", "submitter": "Dilip K. Prasad", "authors": "Dilip K. Prasad", "title": "Geometric primitive feature extraction - concepts, algorithms, and\n  applications", "comments": "333 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents important insights and concepts related to the topic of\nthe extraction of geometric primitives from the edge contours of digital\nimages. Three specific problems related to this topic have been studied, viz.,\npolygonal approximation of digital curves, tangent estimation of digital\ncurves, and ellipse fitting anddetection from digital curves. For the problem\nof polygonal approximation, two fundamental problems have been addressed.\nFirst, the nature of the performance evaluation metrics in relation to the\nlocal and global fitting characteristics has been studied. Second, an explicit\nerror bound of the error introduced by digitizing a continuous line segment has\nbeen derived and used to propose a generic non-heuristic parameter independent\nframework which can be used in several dominant point detection methods. For\nthe problem of tangent estimation for digital curves, a simple method of\ntangent estimation has been proposed. It is shown that the method has a\ndefinite upper bound of the error for conic digital curves. It has been shown\nthat the method performs better than almost all (seventy two) existing tangent\nestimation methods for conic as well as several non-conic digital curves. For\nthe problem of fitting ellipses on digital curves, a geometric distance\nminimization model has been considered. An unconstrained, linear,\nnon-iterative, and numerically stable ellipse fitting method has been proposed\nand it has been shown that the proposed method has better selectivity for\nelliptic digital curves (high true positive and low false positive) as compared\nto several other ellipse fitting methods. For the problem of detecting ellipses\nin a set of digital curves, several innovative and fast pre-processing,\ngrouping, and hypotheses evaluation concepts applicable for digital curves have\nbeen proposed and combined to form an ellipse detection method.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2013 18:42:19 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Prasad", "Dilip K.", ""]]}, {"id": "1305.3939", "submitter": "Djimeli Tsajio Alain Bernard", "authors": "A. Djimeli, D. Tchiotsop, and R. Tchinda", "title": "Analysis Of Interest Points Of Curvelet Coefficients Contributions Of\n  Microscopic Images And Improvement Of Edges", "comments": "9 pages, 7 figures", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.4, No.2, April 2013", "doi": "10.5121/sipij.2013.4201", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper focuses on improved edge model based on Curvelet coefficients\nanalysis. Curvelet transform is a powerful tool for multiresolution\nrepresentation of object with anisotropic edge. Curvelet coefficients\ncontributions have been analyzed using Scale Invariant Feature Transform\n(SIFT), commonly used to study local structure in images. The permutation of\nCurvelet coefficients from original image and edges image obtained from\ngradient operator is used to improve original edges. Experimental results show\nthat this method brings out details on edges when the decomposition scale\nincreases.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2013 21:25:54 GMT"}], "update_date": "2013-05-20", "authors_parsed": [["Djimeli", "A.", ""], ["Tchiotsop", "D.", ""], ["Tchinda", "R.", ""]]}, {"id": "1305.3971", "submitter": "Mingli Song", "authors": "Chengxi Ye, Dacheng Tao, Mingli Song, David W. Jacobs, Min Wu", "title": "Sparse Norm Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization-based filtering smoothes an image by minimizing a fidelity\nfunction and simultaneously preserves edges by exploiting a sparse norm penalty\nover gradients. It has obtained promising performance in practical problems,\nsuch as detail manipulation, HDR compression and deblurring, and thus has\nreceived increasing attentions in fields of graphics, computer vision and image\nprocessing. This paper derives a new type of image filter called sparse norm\nfilter (SNF) from optimization-based filtering. SNF has a very simple form,\nintroduces a general class of filtering techniques, and explains several\nclassic filters as special implementations of SNF, e.g. the averaging filter\nand the median filter. It has advantages of being halo free, easy to implement,\nand low time and memory costs (comparable to those of the bilateral filter).\nThus, it is more generic than a smoothing operator and can better adapt to\ndifferent tasks. We validate the proposed SNF by a wide variety of applications\nincluding edge-preserving smoothing, outlier tolerant filtering, detail\nmanipulation, HDR compression, non-blind deconvolution, image segmentation, and\ncolorization.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2013 03:13:28 GMT"}], "update_date": "2013-05-20", "authors_parsed": [["Ye", "Chengxi", ""], ["Tao", "Dacheng", ""], ["Song", "Mingli", ""], ["Jacobs", "David W.", ""], ["Wu", "Min", ""]]}, {"id": "1305.4064", "submitter": "Syed Muhammad Arsalan Bashir Mr.", "authors": "Syed Muhammad Arsalan Bashir", "title": "Font Acknowledgment and Character Extraction of Digital and Scanned\n  Images", "comments": "5 pages, 5 figures, 1 table, Published with International Journal of\n  Computer Applications (IJCA)", "journal-ref": "International Journal of Computer Applications 70(8):1-5, May 2013", "doi": "10.5120/11979-7850", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The font recognition and character extraction is of immense importance as\nthese are many scenarios where data are in such a form, which cannot be\nprocessed like in image form or as a hard copy. So the procedure developed in\nthis paper is basically related to identifying the font (Times New Roman, Arial\nand Comic Sans MS) and afterwards recovering the text using simple correlation\nbased method where the binary templates are correlated to the input image text\ncharacters. All of this extraction is done in the presence of a little noise as\nimages may have noisy patterns due to photocopying. The significance of this\nmethod exists in extraction of data from various monitoring (Surveillance)\ncamera footages or even more. The method is developed on Matlab\\c{opyright}\nwhich takes input image and recovers text and font information from it in a\ntext file.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2013 13:05:31 GMT"}], "update_date": "2013-05-20", "authors_parsed": [["Bashir", "Syed Muhammad Arsalan", ""]]}, {"id": "1305.4077", "submitter": "Riadh Bouslimi", "authors": "Abir Messaoudi, Riadh Bouslimi, Jalel Akaichi", "title": "Indexing Medical Images based on Collaborative Experts Reports", "comments": "9 pages, 8 figures. International Journal of Computer Applications,\n  May 2013", "journal-ref": null, "doi": "10.5120/11955-7787", "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A patient is often willing to quickly get, from his physician, reliable\nanalysis and concise explanation according to provided linked medical images.\nThe fact of making choices individually by the patient's physician may lead to\nmalpractices and consequently generates unforeseeable damages. The Institute of\nMedicine of the National Sciences Academy(IMNAS) in USA published a study\nestimating that up to 98,000 hospital deathseach year can be attributed to\nmedical malpractice [1]. Moreover, physician, in charge of medical image\nanalysis, might be unavailable at the right time, which may complicate the\npatient's state. The goal of this paper is to provide to physicians and\npatients, a social network that permits to foster cooperation and to overcome\nthe problem of unavailability of doctors on site any time. Therefore, patients\ncan submit their medical images to be diagnosed and commented by several\nexperts instantly. Consequently, the need to process opinions and to extract\ninformation automatically from the proposed social network became a necessity\ndue to the huge number of comments expressing specialist's reviews. For this\nreason, we propose a kind of comments' summary keywords-based method which\nextracts the major current terms and relevant words existing on physicians'\nannotations. The extracted keywords will present a new and robust method for\nimage indexation. In fact, significant extracted terms will be used later to\nindex images in order to facilitate their discovery for any appropriate use. To\novercome this challenge, we propose our Terminology Extraction of Annotation\n(TEA) mixed approach which focuses on algorithms mainly based on statistical\nmethods and on external semantic resources.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2013 13:43:57 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2013 18:01:35 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Messaoudi", "Abir", ""], ["Bouslimi", "Riadh", ""], ["Akaichi", "Jalel", ""]]}, {"id": "1305.4168", "submitter": "Florian Willomitzer", "authors": "Florian Willomitzer, Svenja Ettl, Christian Faber, Gerd H\\\"ausler", "title": "Flying Triangulation - towards the 3D movie camera", "comments": "Proceedings of the 7th International Fringe Workshop on Advanced\n  Optical Imaging and Metrology, 2013, N\\\"urtingen, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flying Triangulation sensors enable a free-hand and motion-robust 3D data\nacquisition of complex shaped objects. The measurement principle is based on a\nmulti-line light-sectioning approach and uses sophisticated algorithms for\nreal-time registration (S. Ettl et al., Appl. Opt. 51 (2012) 281-289). As\n\"single-shot principle\", light sectioning enables the option to get surface\ndata from one single camera exposure. But there is a drawback: A pixel-dense\nmeasurement is not possible because of fundamental information-theoretical\nreasons. By \"pixel-dense\" we understand that each pixel displays individually\nmeasured distance information, neither interpolated from its neighbour pixels\nnor using lateral context information. Hence, for monomodal single-shot\nprinciples, the 3D data generated from one 2D raw image display a significantly\nlower space-bandwidth than the camera permits. This is the price one must pay\nfor motion robustness. Currently, our sensors project about 10 lines (each with\n1000 pixels), reaching an considerable lower data efficiency than theoretically\npossible for a single-shot sensor. Our aim is to push Flying Triangulation to\nits information-theoretical limits. Therefore, the line density as well as the\nmeasurement depth needs to be significantly increased. This causes serious\nindexing ambiguities. On the road to a single-shot 3D movie camera, we are\nworking on solutions to overcome the problem of false line indexing by\nutilizing yet unexploited information. We will present several approaches and\nwill discuss profound information-theoretical questions about the information\nefficiency of 3D sensors.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2013 19:52:32 GMT"}], "update_date": "2013-05-20", "authors_parsed": [["Willomitzer", "Florian", ""], ["Ettl", "Svenja", ""], ["Faber", "Christian", ""], ["H\u00e4usler", "Gerd", ""]]}, {"id": "1305.4204", "submitter": "Joel Ratsaby", "authors": "Uzi Chester, Joel Ratsaby", "title": "Machine learning on images using a string-distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for image feature-extraction which is based on\nrepresenting an image by a finite-dimensional vector of distances that measure\nhow different the image is from a set of image prototypes. We use the recently\nintroduced Universal Image Distance (UID) \\cite{RatsabyChesterIEEE2012} to\ncompare the similarity between an image and a prototype image. The advantage in\nusing the UID is the fact that no domain knowledge nor any image analysis need\nto be done. Each image is represented by a finite dimensional feature vector\nwhose components are the UID values between the image and a finite set of image\nprototypes from each of the feature categories. The method is automatic since\nonce the user selects the prototype images, the feature vectors are\nautomatically calculated without the need to do any image analysis. The\nprototype images can be of different size, in particular, different than the\nimage size. Based on a collection of such cases any supervised or unsupervised\nlearning algorithm can be used to train and produce an image classifier or\nimage cluster analysis. In this paper we present the image feature-extraction\nmethod and use it on several supervised and unsupervised learning experiments\nfor satellite image data.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2013 22:40:14 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Chester", "Uzi", ""], ["Ratsaby", "Joel", ""]]}, {"id": "1305.4298", "submitter": "Yue Wu Dr.", "authors": "Yue Wu, Brian Tracey, Premkumar Natarajan and Joseph P. Noonan", "title": "Blockwise SURE Shrinkage for Non-Local Means", "comments": null, "journal-ref": "Signal Processing 103 (2014): 45-59", "doi": "10.1016/j.sigpro.2014.01.007", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we investigate the shrinkage problem for the non-local means\n(NLM) image denoising. In particular, we derive the closed-form of the optimal\nblockwise shrinkage for NLM that minimizes the Stein's unbiased risk estimator\n(SURE). We also propose a constant complexity algorithm allowing fast blockwise\nshrinkage. Simulation results show that the proposed blockwise shrinkage method\nimproves NLM performance in attaining higher peak signal noise ratio (PSNR) and\nstructural similarity index (SSIM), and makes NLM more robust against parameter\nchanges. Similar ideas can be applicable to other patchwise image denoising\ntechniques.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2013 20:45:40 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Wu", "Yue", ""], ["Tracey", "Brian", ""], ["Natarajan", "Premkumar", ""], ["Noonan", "Joseph P.", ""]]}, {"id": "1305.4537", "submitter": "Nenad Marku\\v{s}", "authors": "Nenad Marku\\v{s} and Miroslav Frljak and Igor S. Pand\\v{z}i\\'c and\n  J\\\"orgen Ahlberg and Robert Forchheimer", "title": "Object Detection with Pixel Intensity Comparisons Organized in Decision\n  Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for visual object detection based on an ensemble of\noptimized decision trees organized in a cascade of rejectors. The trees use\npixel intensity comparisons in their internal nodes and this makes them able to\nprocess image regions very fast. Experimental analysis is provided through a\nface detection problem. The obtained results are encouraging and demonstrate\nthat the method has practical value. Additionally, we analyse its sensitivity\nto noise and show how to perform fast rotation invariant object detection.\nComplete source code is provided at https://github.com/nenadmarkus/pico.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2013 14:35:47 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 14:06:09 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2014 11:15:48 GMT"}, {"version": "v4", "created": "Thu, 27 Mar 2014 00:23:44 GMT"}, {"version": "v5", "created": "Tue, 19 Aug 2014 15:38:23 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Marku\u0161", "Nenad", ""], ["Frljak", "Miroslav", ""], ["Pand\u017ei\u0107", "Igor S.", ""], ["Ahlberg", "J\u00f6rgen", ""], ["Forchheimer", "Robert", ""]]}, {"id": "1305.4544", "submitter": "Govind Salvi", "authors": "Govind Salvi, Puneet Sharma, and Shanmuganathan Raman", "title": "Efficient Image Retargeting for High Dynamic Range Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the real world scenes have a very high dynamic range (HDR). The\nmobile phone cameras and the digital cameras available in markets are limited\nin their capability in both the range and spatial resolution. Same argument can\nbe posed about the limited dynamic range display devices which also differ in\nthe spatial resolution and aspect ratios.\n  In this paper, we address the problem of displaying the high contrast low\ndynamic range (LDR) image of a HDR scene in a display device which has\ndifferent spatial resolution compared to that of the capturing digital camera.\nThe optimal solution proposed in this work can be employed with any camera\nwhich has the ability to shoot multiple differently exposed images of a scene.\nFurther, the proposed solutions provide the flexibility in the depiction of\nentire contrast of the HDR scene as a LDR image with an user specified spatial\nresolution. This task is achieved through an optimized content aware\nretargeting framework which preserves salient features along with the algorithm\nto combine multi-exposure images. We show the proposed approach performs\nexceedingly well in the generation of high contrast LDR image of varying\nspatial resolution compared to an alternate approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2013 14:54:56 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Salvi", "Govind", ""], ["Sharma", "Puneet", ""], ["Raman", "Shanmuganathan", ""]]}, {"id": "1305.5160", "submitter": "Bo Xiao", "authors": "Bo Xiao, Yuefeng Jing, and Yonghong Guan", "title": "A novel automatic thresholding segmentation method with local adaptive\n  thresholds", "comments": "3 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for segmenting bright objects from dark background for\ngrayscale image is proposed. The concept of this method can be stated simply\nas: to pick out the local-thinnest bands on the grayscale grade-map. It turns\nout to be a threshold-based method with local adaptive thresholds, where each\nlocal threshold is determined by requiring the average normal-direction\ngradient on the object boundary to be local minimal. The method is highly\nautomatic and the segmentation mimics a man's natural expectation even the\nobject boundaries are fuzzy.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2013 15:00:43 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Xiao", "Bo", ""], ["Jing", "Yuefeng", ""], ["Guan", "Yonghong", ""]]}, {"id": "1305.5306", "submitter": "Yin Zheng", "authors": "Yin Zheng, Yu-Jin Zhang, Hugo Larochelle", "title": "A Supervised Neural Autoregressive Topic Model for Simultaneous Image\n  Classification and Annotation", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling based on latent Dirichlet allocation (LDA) has been a\nframework of choice to perform scene recognition and annotation. Recently, a\nnew type of topic model called the Document Neural Autoregressive Distribution\nEstimator (DocNADE) was proposed and demonstrated state-of-the-art performance\nfor document modeling. In this work, we show how to successfully apply and\nextend this model to the context of visual scene modeling. Specifically, we\npropose SupDocNADE, a supervised extension of DocNADE, that increases the\ndiscriminative power of the hidden topic features by incorporating label\ninformation into the training objective of the model. We also describe how to\nleverage information about the spatial position of the visual words and how to\nembed additional image annotations, so as to simultaneously perform image\nclassification and annotation. We test our model on the Scene15, LabelMe and\nUIUC-Sports datasets and show that it compares favorably to other topic models\nsuch as the supervised variant of LDA.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2013 03:35:31 GMT"}], "update_date": "2013-05-24", "authors_parsed": [["Zheng", "Yin", ""], ["Zhang", "Yu-Jin", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1305.5663", "submitter": "Eckhard Hitzer", "authors": "Eckhard Hitzer, Tohru Nitta and Yasuaki Kuroe", "title": "Applications of Clifford's Geometric Algebra", "comments": "26 pages, 91 references", "journal-ref": "Advances in Applied Clifford Algebras: Volume 23, Issue 2 (2013),\n  Page 377-404", "doi": "10.1007/s00006-013-0378-4", "report-no": null, "categories": "math.RA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey the development of Clifford's geometric algebra and some of its\nengineering applications during the last 15 years. Several recently developed\napplications and their merits are discussed in some detail. We thus hope to\nclearly demonstrate the benefit of developing problem solutions in a unified\nframework for algebra and geometry with the widest possible scope: from quantum\ncomputing and electromagnetism to satellite navigation, from neural computing\nto camera geometry, image processing, robotics and beyond.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2013 09:22:27 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Hitzer", "Eckhard", ""], ["Nitta", "Tohru", ""], ["Kuroe", "Yasuaki", ""]]}, {"id": "1305.5728", "submitter": "Wafaa Al-jibory", "authors": "Ali El-Zaart and Wafaa Kamel Al-Jibory", "title": "Edge Detection in Radar Images Using Weibull Distribution", "comments": "9 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar images can reveal information about the shape of the surface terrain as\nwell as its physical and biophysical properties. Radar images have long been\nused in geological studies to map structural features that are revealed by the\nshape of the landscape. Radar imagery also has applications in vegetation and\ncrop type mapping, landscape ecology, hydrology, and volcanology. Image\nprocessing is using for detecting for objects in radar images. Edge detection;\nwhich is a method of determining the discontinuities in gray level images; is a\nvery important initial step in Image processing. Many classical edge detectors\nhave been developed over time. Some of the well-known edge detection operators\nbased on the first derivative of the image are Roberts, Prewitt, Sobel which is\ntraditionally implemented by convolving the image with masks. Also Gaussian\ndistribution has been used to build masks for the first and second derivative.\nHowever, this distribution has limit to only symmetric shape. This paper will\nuse to construct the masks, the Weibull distribution which was more general\nthan Gaussian because it has symmetric and asymmetric shape. The constructed\nmasks are applied to images and we obtained good results.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2013 13:39:18 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["El-Zaart", "Ali", ""], ["Al-Jibory", "Wafaa Kamel", ""]]}, {"id": "1305.5756", "submitter": "Fernand  Meyer", "authors": "Fernand Meyer", "title": "Flooding edge or node weighted graphs", "comments": "165 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction closings have all properties of a physical flooding of a\ntopographic surface. They are precious for simplifying gradient images or,\nfilling unwanted catchment basins, on which a subsequent watershed transform\nextracts the targeted objects. Flooding a topographic surface may be modeled as\nflooding a node weighted graph (TG), with unweighted edges, the node weights\nrepresenting the ground level. The progression of a flooding may also be\nmodeled on the region adjacency graph (RAG) of a topographic surface. On a RAG\neach node represents a catchment basin and edges connect neighboring nodes. The\nedges are weighted by the altitude of the pass point between both adjacent\nregions. The graph is flooded from sources placed at the marker positions and\neach node is assigned to the source by which it has been flooded. The level of\nthe flood is represented on the nodes on each type of graphs. The same flooding\nmay thus be modeled on a TG or on a RAG. We characterize all valid floodings on\nboth types of graphs, as they should verify the laws of hydrostatics. We then\nshow that each flooding of a node weighted graph also is a flooding of an edge\nweighted graph with appropriate edge weights. The highest flooding under a\nceiling function may be interpreted as the shortest distance to the root for\nthe ultrametric flooding distance in an augmented graph. The ultrametric\ndistance between two nodes is the minimal altitude of a flooding for which both\nnodes are flooded. This remark permits to flood edge or node weighted graphs by\nusing shortest path algorithms. It appears that the collection of all lakes of\na RAG has the structure of a dendrogram, on which the highest flooding under a\nceiling function may be rapidly found.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2013 14:47:40 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Meyer", "Fernand", ""]]}, {"id": "1305.5777", "submitter": "Qun Li", "authors": "Shmuel Friedland, Qun Li and Dan Schonfeld", "title": "Compressive Sensing of Sparse Tensors", "comments": "10 pages, 83 figures", "journal-ref": null, "doi": "10.1109/TIP.2014.2348796", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) has triggered enormous research activity since its\nfirst appearance. CS exploits the signal's sparsity or compressibility in a\nparticular domain and integrates data compression and acquisition, thus\nallowing exact reconstruction through relatively few non-adaptive linear\nmeasurements. While conventional CS theory relies on data representation in the\nform of vectors, many data types in various applications such as color imaging,\nvideo sequences, and multi-sensor networks, are intrinsically represented by\nhigher-order tensors. Application of CS to higher-order data representation is\ntypically performed by conversion of the data to very long vectors that must be\nmeasured using very large sampling matrices, thus imposing a huge computational\nand memory burden. In this paper, we propose Generalized Tensor Compressive\nSensing (GTCS)--a unified framework for compressive sensing of higher-order\ntensors which preserves the intrinsic structure of tensor data with reduced\ncomputational complexity at reconstruction. GTCS offers an efficient means for\nrepresentation of multidimensional data by providing simultaneous acquisition\nand compression from all tensor modes. In addition, we propound two\nreconstruction procedures, a serial method (GTCS-S) and a parallelizable method\n(GTCS-P). We then compare the performance of the proposed method with Kronecker\ncompressive sensing (KCS) and multi way compressive sensing (MWCS). We\ndemonstrate experimentally that GTCS outperforms KCS and MWCS in terms of both\nreconstruction accuracy (within a range of compression ratios) and processing\nspeed. The major disadvantage of our methods (and of MWCS as well), is that the\ncompression ratios may be worse than that offered by KCS.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2013 16:01:15 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2013 17:42:25 GMT"}, {"version": "v3", "created": "Sat, 12 Apr 2014 20:58:59 GMT"}, {"version": "v4", "created": "Wed, 3 Sep 2014 15:29:16 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Friedland", "Shmuel", ""], ["Li", "Qun", ""], ["Schonfeld", "Dan", ""]]}, {"id": "1305.5905", "submitter": "Justus Piater", "authors": "Justus Piater and Antonio J. Rodr\\'iguez S\\'anchez", "title": "\\\"OAGM/AAPR 2013 - The 37th Annual Workshop of the Austrian Association\n  for Pattern Recognition", "comments": "Part of the OAGM/AAPR 2013 proceedings (arXiv:1304.1876)", "journal-ref": null, "doi": null, "report-no": "OAGM-AAPR/2013/00", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this editorial, the organizers summarize facts and background about the\nevent.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2013 09:30:49 GMT"}], "update_date": "2013-05-28", "authors_parsed": [["Piater", "Justus", ""], ["S\u00e1nchez", "Antonio J. Rodr\u00edguez", ""]]}, {"id": "1305.6387", "submitter": "Joerg Kappes", "authors": "Joerg Hendrik Kappes and Markus Speth and Gerhard Reinelt and\n  Christoph Schnoerr", "title": "Higher-order Segmentation via Multicuts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicuts enable to conveniently represent discrete graphical models for\nunsupervised and supervised image segmentation, in the case of local energy\nfunctions that exhibit symmetries. The basic Potts model and natural extensions\nthereof to higher-order models provide a prominent class of such objectives,\nthat cover a broad range of segmentation problems relevant to image analysis\nand computer vision. We exhibit a way to systematically take into account such\nhigher-order terms for computational inference. Furthermore, we present results\nof a comprehensive and competitive numerical evaluation of a variety of\ndedicated cutting-plane algorithms. Our approach enables the globally optimal\nevaluation of a significant subset of these models, without compromising\nruntime. Polynomially solvable relaxations are studied as well, along with\nadvanced rounding schemes for post-processing.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2013 07:23:39 GMT"}, {"version": "v2", "created": "Fri, 4 Jul 2014 07:37:03 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2015 08:55:42 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Kappes", "Joerg Hendrik", ""], ["Speth", "Markus", ""], ["Reinelt", "Gerhard", ""], ["Schnoerr", "Christoph", ""]]}, {"id": "1305.6441", "submitter": "Pavel Chebotarev", "authors": "Pavel Chebotarev and Rafig Agaev", "title": "Matrices of forests, analysis of networks, and ranking problems", "comments": "8 pages. This article draws heavily from arXiv:math/0508171.\n  Published in Proceedings of the First International Conference on Information\n  Technology and Quantitative Management (ITQM 2013). This version contains\n  some corrections and additions", "journal-ref": null, "doi": "10.1016/j.procs.2013.05.145", "report-no": null, "categories": "math.CO cs.CV cs.DM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The matrices of spanning rooted forests are studied as a tool for analysing\nthe structure of networks and measuring their properties. The problems of\nrevealing the basic bicomponents, measuring vertex proximity, and ranking from\npreference relations / sports competitions are considered. It is shown that the\nvertex accessibility measure based on spanning forests has a number of\ndesirable properties. An interpretation for the stochastic matrix of\nout-forests in terms of information dissemination is given.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2013 10:43:55 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Chebotarev", "Pavel", ""], ["Agaev", "Rafig", ""]]}, {"id": "1305.6650", "submitter": "Sheeraz Ahmad", "authors": "Sheeraz Ahmad and Angela J. Yu", "title": "Active Sensing as Bayes-Optimal Sequential Decision Making", "comments": "Scheduled to appear in UAI 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory inference under conditions of uncertainty is a major problem in both\nmachine learning and computational neuroscience. An important but poorly\nunderstood aspect of sensory processing is the role of active sensing. Here, we\npresent a Bayes-optimal inference and control framework for active sensing,\nC-DAC (Context-Dependent Active Controller). Unlike previously proposed\nalgorithms that optimize abstract statistical objectives such as information\nmaximization (Infomax) [Butko & Movellan, 2010] or one-step look-ahead accuracy\n[Najemnik & Geisler, 2005], our active sensing model directly minimizes a\ncombination of behavioral costs, such as temporal delay, response error, and\neffort. We simulate these algorithms on a simple visual search task to\nillustrate scenarios in which context-sensitivity is particularly beneficial\nand optimization with respect to generic statistical objectives particularly\ninadequate. Motivated by the geometric properties of the C-DAC policy, we\npresent both parametric and non-parametric approximations, which retain\ncontext-sensitivity while significantly reducing computational complexity.\nThese approximations enable us to investigate the more complex problem\ninvolving peripheral vision, and we notice that the difference between C-DAC\nand statistical policies becomes even more evident in this scenario.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2013 22:46:35 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Ahmad", "Sheeraz", ""], ["Yu", "Angela J.", ""]]}, {"id": "1305.6883", "submitter": "Joscha Diehl", "authors": "Joscha Diehl", "title": "Rotation invariants of two dimensional curves based on iterated\n  integrals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel class of rotation invariants of two dimensional curves\nbased on iterated integrals. The invariants we present are in some sense\ncomplete and we describe an algorithm to calculate them, giving explicit\ncomputations up to order six. We present an application to online\n(stroke-trajectory based) character recognition. This seems to be the first\ntime in the literature that the use of iterated integrals of a curve is\nproposed for (invariant) feature extraction in machine learning applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2013 17:58:04 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Diehl", "Joscha", ""]]}, {"id": "1305.6918", "submitter": "Thiago Vallin Spina", "authors": "Thiago V. Spina, Mariano Tepper, Amy Esler, Vassilios Morellas,\n  Nikolaos Papanikolopoulos, Alexandre X. Falc\\~ao, Guillermo Sapiro", "title": "Video Human Segmentation using Fuzzy Object Models and its Application\n  to Body Pose Estimation of Toddlers for Behavior Studies", "comments": "arXiv admin note: text overlap with arXiv:1210.7014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video object segmentation is a challenging problem due to the presence of\ndeformable, connected, and articulated objects, intra- and inter-object\nocclusions, object motion, and poor lighting. Some of these challenges call for\nobject models that can locate a desired object and separate it from its\nsurrounding background, even when both share similar colors and textures. In\nthis work, we extend a fuzzy object model, named cloud system model (CSM), to\nhandle video segmentation, and evaluate it for body pose estimation of toddlers\nat risk of autism. CSM has been successfully used to model the parts of the\nbrain (cerebrum, left and right brain hemispheres, and cerebellum) in order to\nautomatically locate and separate them from each other, the connected brain\nstem, and the background in 3D MR-images. In our case, the objects are\narticulated parts (2D projections) of the human body, which can deform, cause\nself-occlusions, and move along the video. The proposed CSM extension handles\narticulation by connecting the individual clouds, body parts, of the system\nusing a 2D stickman model. The stickman representation naturally allows us to\nextract 2D body pose measures of arm asymmetry patterns during unsupported gait\nof toddlers, a possible behavioral marker of autism. The results show that our\nmethod can provide insightful knowledge to assist the specialist's observations\nduring real in-clinic assessments.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2013 19:46:19 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Spina", "Thiago V.", ""], ["Tepper", "Mariano", ""], ["Esler", "Amy", ""], ["Morellas", "Vassilios", ""], ["Papanikolopoulos", "Nikolaos", ""], ["Falc\u00e3o", "Alexandre X.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1305.7053", "submitter": "Kaihua Zhang", "authors": "Kaihua Zhang, Lei Zhang, Kin-Man Lam, and David Zhang", "title": "A Local Active Contour Model for Image Segmentation with Intensity\n  Inhomogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A novel locally statistical active contour model (ACM) for image segmentation\nin the presence of intensity inhomogeneity is presented in this paper. The\ninhomogeneous objects are modeled as Gaussian distributions of different means\nand variances, and a moving window is used to map the original image into\nanother domain, where the intensity distributions of inhomogeneous objects are\nstill Gaussian but are better separated. The means of the Gaussian\ndistributions in the transformed domain can be adaptively estimated by\nmultiplying a bias field with the original signal within the window. A\nstatistical energy functional is then defined for each local region, which\ncombines the bias field, the level set function, and the constant approximating\nthe true signal of the corresponding object. Experiments on both synthetic and\nreal images demonstrate the superiority of our proposed algorithm to\nstate-of-the-art and representative methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2013 10:14:14 GMT"}], "update_date": "2013-05-31", "authors_parsed": [["Zhang", "Kaihua", ""], ["Zhang", "Lei", ""], ["Lam", "Kin-Man", ""], ["Zhang", "David", ""]]}, {"id": "1305.7181", "submitter": "Hong Jiang", "authors": "Gang Huang, Hong Jiang, Kim Matthews and Paul Wilford", "title": "Lensless Imaging by Compressive Sensing", "comments": "Accepted ICIP 2013. 5 Pages, 7 Figures. arXiv admin note: substantial\n  text overlap with arXiv:1302.1789", "journal-ref": "IEEE International Conference on Image Processing, ICIP 2013,\n  Paper #2393", "doi": "10.1109/ICIP.2013.6738433", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a lensless compressive imaging architecture. The\narchitecture consists of two components, an aperture assembly and a sensor. No\nlens is used. The aperture assembly consists of a two dimensional array of\naperture elements. The transmittance of each aperture element is independently\ncontrollable. The sensor is a single detection element. A compressive sensing\nmatrix is implemented by adjusting the transmittance of the individual aperture\nelements according to the values of the sensing matrix. The proposed\narchitecture is simple and reliable because no lens is used. The architecture\ncan be used for capturing images of visible and other spectra such as infrared,\nor millimeter waves, in surveillance applications for detecting anomalies or\nextracting features such as speed of moving objects. Multiple sensors may be\nused with a single aperture assembly to capture multi-view images\nsimultaneously. A prototype was built by using a LCD panel and a photoelectric\nsensor for capturing images of visible spectrum.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2013 17:56:03 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Huang", "Gang", ""], ["Jiang", "Hong", ""], ["Matthews", "Kim", ""], ["Wilford", "Paul", ""]]}, {"id": "1305.7311", "submitter": "Ying Wang", "authors": "Ying Wang and Chunhong Pan and Shiming Xiang and Feiyun Zhu", "title": "Robust Hyperspectral Unmixing with Correntropy based Metric", "comments": "arXiv admin note: text overlap with arXiv:1202.6294 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral unmixing is one of the crucial steps for many hyperspectral\napplications. The problem of hyperspectral unmixing has proven to be a\ndifficult task in unsupervised work settings where the endmembers and\nabundances are both unknown. What is more, this task becomes more challenging\nin the case that the spectral bands are degraded with noise. This paper\npresents a robust model for unsupervised hyperspectral unmixing. Specifically,\nour model is developed with the correntropy based metric where the non-negative\nconstraints on both endmembers and abundances are imposed to keep physical\nsignificance. In addition, a sparsity prior is explicitly formulated to\nconstrain the distribution of the abundances of each endmember. To solve our\nmodel, a half-quadratic optimization technique is developed to convert the\noriginal complex optimization problem into an iteratively re-weighted NMF with\nsparsity constraints. As a result, the optimization of our model can adaptively\nassign small weights to noisy bands and give more emphasis on noise-free bands.\nIn addition, with sparsity constraints, our model can naturally generate sparse\nabundances. Experiments on synthetic and real data demonstrate the\neffectiveness of our model in comparison to the related state-of-the-art\nunmixing models.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2013 06:43:31 GMT"}], "update_date": "2013-06-03", "authors_parsed": [["Wang", "Ying", ""], ["Pan", "Chunhong", ""], ["Xiang", "Shiming", ""], ["Zhu", "Feiyun", ""]]}]