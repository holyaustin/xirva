[{"id": "1302.0077", "submitter": "Zai Yang", "authors": "Zai Yang, Cishen Zhang, and Lihua Xie", "title": "Sparse MRI for motion correction", "comments": "To appear in Proceedings of ISBI 2013. 4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV physics.bio-ph physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MR image sparsity/compressibility has been widely exploited for imaging\nacceleration with the development of compressed sensing. A sparsity-based\napproach to rigid-body motion correction is presented for the first time in\nthis paper. A motion is sought after such that the compensated MR image is\nmaximally sparse/compressible among the infinite candidates. Iterative\nalgorithms are proposed that jointly estimate the motion and the image content.\nThe proposed method has a lot of merits, such as no need of additional data and\nloose requirement for the sampling sequence. Promising results are presented to\ndemonstrate its performance.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 05:08:58 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Yang", "Zai", ""], ["Zhang", "Cishen", ""], ["Xie", "Lihua", ""]]}, {"id": "1302.0435", "submitter": "Yu Zhang", "authors": "Yu Zhang, James Z. Wang and Jia Li", "title": "Parallel D2-Clustering: Large-Scale Clustering of Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrete distribution clustering algorithm, namely D2-clustering, has\ndemonstrated its usefulness in image classification and annotation where each\nobject is represented by a bag of weighed vectors. The high computational\ncomplexity of the algorithm, however, limits its applications to large-scale\nproblems. We present a parallel D2-clustering algorithm with substantially\nimproved scalability. A hierarchical structure for parallel computing is\ndevised to achieve a balance between the individual-node computation and the\nintegration process of the algorithm. Additionally, it is shown that even with\na single CPU, the hierarchical structure results in significant speed-up.\nExperiments on real-world large-scale image data, Youtube video data, and\nprotein sequence data demonstrate the efficiency and wide applicability of the\nparallel D2-clustering algorithm. The loss in clustering accuracy is minor in\ncomparison with the original sequential algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2013 22:56:26 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2013 15:55:39 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Zhang", "Yu", ""], ["Wang", "James Z.", ""], ["Li", "Jia", ""]]}, {"id": "1302.0439", "submitter": "Paul Shearer", "authors": "Paul Shearer, Anna C. Gilbert, Alfred O. Hero III", "title": "Correcting Camera Shake by Incremental Sparse Approximation", "comments": "5 pages, 3 figures. Conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of deblurring an image when the blur kernel is unknown remains\nchallenging after decades of work. Recently there has been rapid progress on\ncorrecting irregular blur patterns caused by camera shake, but there is still\nmuch room for improvement. We propose a new blind deconvolution method using\nincremental sparse edge approximation to recover images blurred by camera\nshake. We estimate the blur kernel first from only the strongest edges in the\nimage, then gradually refine this estimate by allowing for weaker and weaker\nedges. Our method competes with the benchmark deblurring performance of the\nstate-of-the-art while being significantly faster and easier to generalize.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2013 00:46:11 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2013 14:34:17 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Shearer", "Paul", ""], ["Gilbert", "Anna C.", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1302.0446", "submitter": "Dacheng Tao", "authors": "Mingli Song, Dachent Tao, Stephen J. Maybank", "title": "Sparse Camera Network for Visual Surveillance -- A Comprehensive Survey", "comments": "41 pages, 5 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological advances in sensor manufacture, communication, and computing\nare stimulating the development of new applications that are transforming\ntraditional vision systems into pervasive intelligent camera networks. The\nanalysis of visual cues in multi-camera networks enables a wide range of\napplications, from smart home and office automation to large area surveillance\nand traffic surveillance. While dense camera networks - in which most cameras\nhave large overlapping fields of view - are well studied, we are mainly\nconcerned with sparse camera networks. A sparse camera network undertakes large\narea surveillance using as few cameras as possible, and most cameras have\nnon-overlapping fields of view with one another. The task is challenging due to\nthe lack of knowledge about the topological structure of the network,\nvariations in the appearance and motion of specific tracking targets in\ndifferent views, and the difficulties of understanding composite events in the\nnetwork. In this review paper, we present a comprehensive survey of recent\nresearch results to address the problems of intra-camera tracking, topological\nstructure learning, target appearance modeling, and global activity\nunderstanding in sparse camera networks. A number of current open research\nissues are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2013 02:40:29 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Song", "Mingli", ""], ["Tao", "Dachent", ""], ["Maybank", "Stephen J.", ""]]}, {"id": "1302.0494", "submitter": "Binjie Qin", "authors": "Binjie Qin, Zhuangming Shen, Zien Zhou, Jiawei Zhou, Jiuai Sun, Hui\n  Zhang, Mingxing Hu, and Yisong Lv", "title": "Local Structure Matching Driven by Joint-Saliency-Structure Adaptive\n  Kernel Regression", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  For nonrigid image registration, matching the particular structures (or the\noutliers) that have missing correspondence and/or local large deformations, can\nbe more difficult than matching the common structures with small deformations\nin the two images. Most existing works depend heavily on the outlier\nsegmentation to remove the outlier effect in the registration. Moreover, these\nworks do not handle simultaneously the missing correspondences and local large\ndeformations. In this paper, we defined the nonrigid image registration as a\nlocal adaptive kernel regression which locally reconstruct the moving image's\ndense deformation vectors from the sparse deformation vectors in the\nmulti-resolution block matching. The kernel function of the kernel regression\nadapts its shape and orientation to the reference image's structure to gather\nmore deformation vector samples of the same structure for the iterative\nregression computation, whereby the moving image's local deformations could be\ncompliant with the reference image's local structures. To estimate the local\ndeformations around the outliers, we use joint saliency map that highlights the\ncorresponding saliency structures (called Joint Saliency Structures, JSSs) in\nthe two images to guide the dense deformation reconstruction by emphasizing\nthose JSSs' sparse deformation vectors in the kernel regression. The\nexperimental results demonstrate that by using local JSS adaptive kernel\nregression, the proposed method achieves almost the best performance in\nalignment of all challenging image pairs with outlier structures compared with\nother five state-of-the-art nonrigid registration algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2013 14:14:27 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2013 23:05:32 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2013 08:48:37 GMT"}, {"version": "v4", "created": "Mon, 15 Apr 2013 14:59:51 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Qin", "Binjie", ""], ["Shen", "Zhuangming", ""], ["Zhou", "Zien", ""], ["Zhou", "Jiawei", ""], ["Sun", "Jiuai", ""], ["Zhang", "Hui", ""], ["Hu", "Mingxing", ""], ["Lv", "Yisong", ""]]}, {"id": "1302.0689", "submitter": "Anh Cat Le Ngo", "authors": "Anh Cat Le Ngo, Li-Minn Ang, Guoping Qiu, Kah-Phooi Seng", "title": "Multi-scale Visual Attention & Saliency Modelling with Decision Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bottom-up saliency, an early human visual processing, behaves like binary\nclassification of interest and null hypothesis. Its discriminant power, mutual\ninformation of image features and class distribution, is closely related to\nsaliency value by the well-known centre-surround theory. As classification\naccuracy very much depends on window sizes, the discriminant saliency (power)\nvaries according to sampling scales. Discriminating power estimation in\nmulti-scales framework needs integrating with wavelet transformation and then\nestimating statistical discrepancy of two consecutive scales (centre-surround\nwindows) by Hidden Markov Tree (HMT) model. Finally, multi-scale discriminant\nsaliency (MDIS) maps are combined by the maximum information rule to synthesize\na final saliency map. All MDIS maps are evaluated with standard quantitative\ntools (NSS,LCC,AUC) on N.Bruce's database with ground truth data as\neye-tracking locations ; as well assessed qualitatively by visual examination\nof individual cases. For evaluating MDIS against well-known AIM saliency\nmethod, simulations are needed and described in details with several\ninteresting conclusions, drawn for further research directions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 14:00:52 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Ngo", "Anh Cat Le", ""], ["Ang", "Li-Minn", ""], ["Qiu", "Guoping", ""], ["Seng", "Kah-Phooi", ""]]}, {"id": "1302.0870", "submitter": "Brian Baingana Mr", "authors": "Brian Baingana, Georgios B. Giannakis", "title": "Centrality-constrained graph embedding", "comments": "Submitted to ICASSP May, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual rendering of graphs is a key task in the mapping of complex network\ndata. Although most graph drawing algorithms emphasize aesthetic appeal,\ncertain applications such as travel-time maps place more importance on\nvisualization of structural network properties. The present paper advocates a\ngraph embedding approach with centrality considerations to comply with node\nhierarchy. The problem is formulated as one of constrained multi-dimensional\nscaling (MDS), and it is solved via block coordinate descent iterations with\nsuccessive approximations and guaranteed convergence to a KKT point. In\naddition, a regularization term enforcing graph smoothness is incorporated with\nthe goal of reducing edge crossings. Experimental results demonstrate that the\nalgorithm converges, and can be used to efficiently embed large graphs on the\norder of thousands of nodes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 21:26:47 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Baingana", "Brian", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1302.1007", "submitter": "Firas Ajil Jassim", "authors": "Firas Ajil Jassim", "title": "Image Denoising Using Interquartile Range Filter with Local Averaging", "comments": "5 pages, 8 figures, 2 tables", "journal-ref": "International Journal of Soft Computing and Engineering (IJSCE)\n  ISSN: 2231-2307, Volume-2, Issue-6, January 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Image denoising is one of the fundamental problems in image processing. In\nthis paper, a novel approach to suppress noise from the image is conducted by\napplying the interquartile range (IQR) which is one of the statistical methods\nused to detect outlier effect from a dataset. A window of size kXk was\nimplemented to support IQR filter. Each pixel outside the IQR range of the kXk\nwindow is treated as noisy pixel. The estimation of the noisy pixels was\nobtained by local averaging. The essential advantage of applying IQR filter is\nto preserve edge sharpness better of the original image. A variety of test\nimages have been used to support the proposed filter and PSNR was calculated\nand compared with median filter. The experimental results on standard test\nimages demonstrate this filter is simpler and better performing than median\nfilter.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 12:02:53 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Jassim", "Firas Ajil", ""]]}, {"id": "1302.1294", "submitter": "Firas Ajil Jassim", "authors": "Firas Ajil Jassim and Fawzi Hasan Altaany", "title": "Image Interpolation Using Kriging Technique for Spatial Data", "comments": "6 pages, 8 figures, 3 tables", "journal-ref": "Canadian Journal on Image Processing and Computer Vision, Vol. 4\n  No. 2, February 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Image interpolation has been used spaciously by customary interpolation\ntechniques. Recently, Kriging technique has been widely implemented in\nsimulation area and geostatistics for prediction. In this article, Kriging\ntechnique was used instead of the classical interpolation methods to predict\nthe unknown points in the digital image array. The efficiency of the proposed\ntechnique was proven using the PSNR and compared with the traditional\ninterpolation techniques. The results showed that Kriging technique is almost\naccurate as cubic interpolation and in some images Kriging has higher accuracy.\nA miscellaneous test images have been used to consolidate the proposed\ntechnique.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 09:22:58 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Jassim", "Firas Ajil", ""], ["Altaany", "Fawzi Hasan", ""]]}, {"id": "1302.1296", "submitter": "Firas Ajil Jassim", "authors": "Firas Ajil Jassim", "title": "Hybrid Image Segmentation using Discerner Cluster in FCM and Histogram\n  Thresholding", "comments": "4 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1005.4020 by other authors", "journal-ref": "International Journal of Graphics & Image Processing, Vol 2, issue\n  4, November 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Image thresholding has played an important role in image segmentation. This\npaper presents a hybrid approach for image segmentation based on the\nthresholding by fuzzy c-means (THFCM) algorithm for image segmentation. The\ngoal of the proposed approach is to find a discerner cluster able to find an\nautomatic threshold. The algorithm is formulated by applying the standard FCM\nclustering algorithm to the frequencies (y-values) on the smoothed histogram.\nHence, the frequencies of an image can be used instead of the conventional\nwhole data of image. The cluster that has the highest peak which represents the\nmaximum frequency in the image histogram will play as an excellent role in\ndetermining a discerner cluster to the grey level image. Then, the pixels\nbelong to the discerner cluster represent an object in the gray level histogram\nwhile the other clusters represent a background. Experimental results with\nstandard test images have been obtained through the proposed approach (THFCM).\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 09:31:59 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Jassim", "Firas Ajil", ""]]}, {"id": "1302.1300", "submitter": "Firas Ajil Jassim", "authors": "Firas Ajil Jassim", "title": "Kriging Interpolation Filter to Reduce High Density Salt and Pepper\n  Noise", "comments": "6 pages, 10 figures, 2 tables", "journal-ref": "World of Computer Science and Information Technology Journal\n  (WCSIT), Vol. 3, No. 1, pp.8-14, 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Image denoising is a critical issue in the field of digital image processing.\nThis paper proposes a novel Salt & Pepper noise suppression by developing a\nKriging Interpolation Filter (KIF) for image denoising. Gray-level images\ndegraded with Salt & Pepper noise have been considered. A sequential search for\nnoise detection was made using kXk window size to determine non-noisy pixels\nonly. The non-noisy pixels are passed into Kriging interpolation method to\npredict their absent neighbor pixels that were noisy pixels at the first phase.\nThe utilization of Kriging interpolation filter proves that it is very\nimpressive to suppress high noise density. It has been found that Kriging\nInterpolation filter achieves noise reduction without loss of edges and\ndetailed information. Comparisons with existing algorithms are done using\nquality metrics like PSNR and MSE to assess the proposed filter.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 09:45:18 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Jassim", "Firas Ajil", ""]]}, {"id": "1302.1326", "submitter": "Yu Zhou", "authors": "Yu Zhou", "title": "Cloud Computing framework for Computer Vision Research:An Introduction", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing offers the potential to help scientists to process massive\nnumber of computing resources often required in machine learning application\nsuch as computer vision problems. This proposal would like to show that which\nbenefits can be obtained from cloud in order to help medical image analysis\nusers (including scientists, clinicians, and research institutes). As security\nand privacy of algorithms are important for most of algorithms inventors, these\nalgorithms can be hidden in a cloud to allow the users to use the algorithms as\na package without any access to see/change their inside. In another word, in\nthe user part, users send their images to the cloud and configure the algorithm\nvia an interface. In the cloud part, the algorithms are applied to this image\nand the results are returned back to the user. My proposal has two parts: (1)\ninvestigate the potential of cloud computing for computer vision problems and\n(2) study the components of a proposed cloud-based framework for medical image\nanalysis application and develop them (depending on the length of the\ninternship). The investigation part will involve a study on several aspects of\nthe problem including security, usability (for medical end users of the\nservice), appropriate programming abstractions for vision problems, scalability\nand resource requirements. In the second part of this proposal I am going to\nthoroughly study of the proposed framework components and their relations and\ndevelop them. The proposed cloud-based framework includes an integrated\nenvironment to enable scientists and clinicians to access to the previous and\ncurrent medical image analysis algorithms using a handful user interface\nwithout any access to the algorithm codes and procedures.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 11:41:26 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Zhou", "Yu", ""]]}, {"id": "1302.1539", "submitter": "Nir Friedman", "authors": "Nir Friedman, Stuart Russell", "title": "Image Segmentation in Video Sequences: A Probabilistic Approach", "comments": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1997)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1997-PG-175-181", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Background subtraction\" is an old technique for finding moving objects in a\nvideo sequence for example, cars driving on a freeway. The idea is that\nsubtracting the current image from a timeaveraged background image will leave\nonly nonstationary objects. It is, however, a crude approximation to the task\nof classifying each pixel of the current image; it fails with slow-moving\nobjects and does not distinguish shadows from moving objects. The basic idea of\nthis paper is that we can classify each pixel using a model of how that pixel\nlooks when it is part of different classes. We learn a mixture-of-Gaussians\nclassification model for each pixel using an unsupervised technique- an\nefficient, incremental version of EM. Unlike the standard image-averaging\napproach, this automatically updates the mixture component for each class\naccording to likelihood of membership; hence slow-moving objects are handled\nperfectly. Our approach also identifies and eliminates shadows much more\neffectively than other techniques such as thresholding. Application of this\nmethod as part of the Roadwatch traffic surveillance project is expected to\nresult in significant improvements in vehicle identification and tracking.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 15:55:26 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Friedman", "Nir", ""], ["Russell", "Stuart", ""]]}, {"id": "1302.1610", "submitter": "Hong Jiang", "authors": "Fei Yang, Hong Jiang, Zuowei Shen, Wei Deng and Dimitris Metaxas", "title": "Adaptive low rank and sparse decomposition of video using compressive\n  sensing", "comments": "Accepted ICIP 2013", "journal-ref": "IEEE International Conference on Image Processing, ICIP 2013,\n  Paper #1870", "doi": "10.1109/ICIP.2013.6738210", "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of reconstructing and analyzing surveillance videos\nusing compressive sensing. We develop a new method that performs video\nreconstruction by low rank and sparse decomposition adaptively. Background\nsubtraction becomes part of the reconstruction. In our method, a background\nmodel is used in which the background is learned adaptively as the compressive\nmeasurements are processed. The adaptive method has low latency, and is more\nrobust than previous methods. We will present experimental results to\ndemonstrate the advantages of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 23:19:07 GMT"}, {"version": "v2", "created": "Fri, 31 May 2013 20:45:03 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Yang", "Fei", ""], ["Jiang", "Hong", ""], ["Shen", "Zuowei", ""], ["Deng", "Wei", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1302.1649", "submitter": "Rommel Anacan", "authors": "Rommel Anacan, James Greggory Alcayde, Retchel Antegra and Leah Luna", "title": "Eye-GUIDE (Eye-Gaze User Interface Design) Messaging for\n  Physically-Impaired People", "comments": null, "journal-ref": null, "doi": "10.5121/ijdps.2013.4104", "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye-GUIDE is an assistive communication tool designed for the paralyzed or\nphysically impaired people who were unable to move parts of their bodies\nespecially people whose communications are limited only to eye movements. The\nprototype consists of a camera and a computer. Camera captures images then it\nwill be send to the computer, where the computer will be the one to interpret\nthe data. Thus, Eye-GUIDE focuses on camera-based gaze tracking. The proponent\ndesigned the prototype to perform simple tasks and provides graphical user\ninterface in order the paralyzed or physically impaired person can easily use\nit.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 06:47:54 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Anacan", "Rommel", ""], ["Alcayde", "James Greggory", ""], ["Antegra", "Retchel", ""], ["Luna", "Leah", ""]]}, {"id": "1302.1690", "submitter": "Jonathan Masci", "authors": "Jonathan Masci, Alessandro Giusti, Dan Cire\\c{s}an, Gabriel Fricout,\n  J\\\"urgen Schmidhuber", "title": "A Fast Learning Algorithm for Image Segmentation with Max-Pooling\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast algorithm for training MaxPooling Convolutional Networks to\nsegment images. This type of network yields record-breaking performance in a\nvariety of tasks, but is normally trained on a computationally expensive\npatch-by-patch basis. Our new method processes each training image in a single\npass, which is vastly more efficient.\n  We validate the approach in different scenarios and report a 1500-fold\nspeed-up. In an application to automated steel defect detection and\nsegmentation, we obtain excellent performance with short training times.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 10:17:07 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Masci", "Jonathan", ""], ["Giusti", "Alessandro", ""], ["Cire\u015fan", "Dan", ""], ["Fricout", "Gabriel", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1302.1700", "submitter": "Dan Ciresan", "authors": "Alessandro Giusti, Dan C. Cire\\c{s}an, Jonathan Masci, Luca M.\n  Gambardella, J\\\"urgen Schmidhuber", "title": "Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks", "comments": "11 pages, 2 figures, 3 tables, 21 references, submitted to ICIP 2013", "journal-ref": "International Conference on Image Processing (ICIP) 2013,\n  Melbourne", "doi": null, "report-no": "IDSIA-01-13", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks now excel at image classification, detection and\nsegmentation. When used to scan images by means of a sliding window, however,\ntheir high computational complexity can bring even the most powerful hardware\nto its knees. We show how dynamic programming can speedup the process by orders\nof magnitude, even when max-pooling layers are present.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 10:33:47 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Giusti", "Alessandro", ""], ["Cire\u015fan", "Dan C.", ""], ["Masci", "Jonathan", ""], ["Gambardella", "Luca M.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1302.1772", "submitter": "Vahid Majidnezhad", "authors": "Vahid Majidnezhad and Igor Kheidorov", "title": "An ANN-based Method for Detecting Vocal Fold Pathology", "comments": "4 pages, 3 figures, Published with International Journal of Computer\n  Applications (IJCA)", "journal-ref": "International Journal of Computer Applications 62(7):1-4, January\n  2013", "doi": "10.5120/10089-4722", "report-no": null, "categories": "cs.LG cs.CV cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are different algorithms for vocal fold pathology diagnosis. These\nalgorithms usually have three stages which are Feature Extraction, Feature\nReduction and Classification. While the third stage implies a choice of a\nvariety of machine learning methods, the first and second stages play a\ncritical role in performance and accuracy of the classification system. In this\npaper we present initial study of feature extraction and feature reduction in\nthe task of vocal fold pathology diagnosis. A new type of feature vector, based\non wavelet packet decomposition and Mel-Frequency-Cepstral-Coefficients\n(MFCCs), is proposed. Also Principal Component Analysis (PCA) is used for\nfeature reduction. An Artificial Neural Network is used as a classifier for\nevaluating the performance of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 15:03:24 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Majidnezhad", "Vahid", ""], ["Kheidorov", "Igor", ""]]}, {"id": "1302.1789", "submitter": "Hong Jiang", "authors": "Gang Huang, Hong Jiang, Kim Matthews and Paul Wilford", "title": "Lensless Compressive Sensing Imaging", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a lensless compressive sensing imaging\narchitecture. The architecture consists of two components, an aperture assembly\nand a sensor. No lens is used. The aperture assembly consists of a two\ndimensional array of aperture elements. The transmittance of each aperture\nelement is independently controllable. The sensor is a single detection\nelement, such as a single photo-conductive cell. Each aperture element together\nwith the sensor defines a cone of a bundle of rays, and the cones of the\naperture assembly define the pixels of an image. Each pixel value of an image\nis the integration of the bundle of rays in a cone. The sensor is used for\ntaking compressive measurements. Each measurement is the integration of rays in\nthe cones modulated by the transmittance of the aperture elements. A\ncompressive sensing matrix is implemented by adjusting the transmittance of the\nindividual aperture elements according to the values of the sensing matrix. The\nproposed architecture is simple and reliable because no lens is used.\nFurthermore, the sharpness of an image from our device is only limited by the\nresolution of the aperture assembly, but not affected by blurring due to\ndefocus. The architecture can be used for capturing images of visible lights,\nand other spectra such as infrared, or millimeter waves. Such devices may be\nused in surveillance applications for detecting anomalies or extracting\nfeatures such as speed of moving objects. Multiple sensors may be used with a\nsingle aperture assembly to capture multi-view images simultaneously. A\nprototype was built by using a LCD panel and a photoelectric sensor for\ncapturing images of visible spectrum.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 16:00:35 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Huang", "Gang", ""], ["Jiang", "Hong", ""], ["Matthews", "Kim", ""], ["Wilford", "Paul", ""]]}, {"id": "1302.1942", "submitter": "Hong Jiang", "authors": "Hong Jiang, Wei Deng and Zuowei Shen", "title": "Surveillance Video Processing Using Compressive Sensing", "comments": "14 pages, 5 figures", "journal-ref": "Inverse Problems and Imaging, Volume 6, No. 2, 2012, 201-214", "doi": "10.3934/ipi.2012.6.201", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compressive sensing method combined with decomposition of a matrix formed\nwith image frames of a surveillance video into low rank and sparse matrices is\nproposed to segment the background and extract moving objects in a surveillance\nvideo. The video is acquired by compressive measurements, and the measurements\nare used to reconstruct the video by a low rank and sparse decomposition of\nmatrix. The low rank component represents the background, and the sparse\ncomponent is used to identify moving objects in the surveillance video. The\ndecomposition is performed by an augmented Lagrangian alternating direction\nmethod. Experiments are carried out to demonstrate that moving objects can be\nreliably extracted with a small amount of measurements.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 04:47:22 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Jiang", "Hong", ""], ["Deng", "Wei", ""], ["Shen", "Zuowei", ""]]}, {"id": "1302.1947", "submitter": "Hong Jiang", "authors": "Chengbo Li, Hong Jiang and Paul Wilford and Yin Zhang and Mike\n  Scheutzow", "title": "A new compressive video sensing framework for mobile broadcast", "comments": "9 pages, 12 figures", "journal-ref": "IEEE Transactions on Broadcasting VOL 59 NO 1 MARCH 2013 pp. 197 -\n  205", "doi": "10.1109/TBC.2012.2226509", "report-no": null, "categories": "cs.MM cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new video coding method based on compressive sampling is proposed. In this\nmethod, a video is coded using compressive measurements on video cubes. Video\nreconstruction is performed by minimization of total variation (TV) of the\npixelwise DCT coefficients along the temporal direction. A new reconstruction\nalgorithm is developed from TVAL3, an efficient TV minimization algorithm based\non the alternating minimization and augmented Lagrangian methods. Video coding\nwith this method is inherently scalable, and has applications in mobile\nbroadcast.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 05:18:49 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Li", "Chengbo", ""], ["Jiang", "Hong", ""], ["Wilford", "Paul", ""], ["Zhang", "Yin", ""], ["Scheutzow", "Mike", ""]]}, {"id": "1302.2073", "submitter": "Clemens Hage", "authors": "Florian Seidel and Clemens Hage and Martin Kleinsteuber", "title": "pROST : A Smoothed Lp-norm Robust Online Subspace Tracking Method for\n  Realtime Background Subtraction in Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of methods for background subtraction use Robust PCA to\nidentify sparse foreground objects. While many algorithms use the L1-norm as a\nconvex relaxation of the ideal sparsifying function, we approach the problem\nwith a smoothed Lp-norm and present pROST, a method for robust online subspace\ntracking. The algorithm is based on alternating minimization on manifolds.\nImplemented on a graphics processing unit it achieves realtime performance.\nExperimental results on a state-of-the-art benchmark for background subtraction\non real-world video data indicate that the method succeeds at a broad variety\nof background subtraction scenarios, and it outperforms competing approaches\nwhen video quality is deteriorated by camera jitter.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 16:14:14 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2013 15:11:00 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Seidel", "Florian", ""], ["Hage", "Clemens", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "1302.2575", "submitter": "Patrick Llull", "authors": "Patrick Llull, Xuejun Liao, Xin Yuan, Jianbo Yang, David Kittle,\n  Lawrence Carin, Guillermo Sapiro, and David J. Brady", "title": "Coded aperture compressive temporal imaging", "comments": "19 pages (when compiled with Optics Express' TEX template), 15\n  figures", "journal-ref": null, "doi": "10.1364/OE.21.010526", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use mechanical translation of a coded aperture for code division multiple\naccess compression of video. We present experimental results for reconstruction\nat 148 frames per coded snapshot.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2013 22:52:13 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Llull", "Patrick", ""], ["Liao", "Xuejun", ""], ["Yuan", "Xin", ""], ["Yang", "Jianbo", ""], ["Kittle", "David", ""], ["Carin", "Lawrence", ""], ["Sapiro", "Guillermo", ""], ["Brady", "David J.", ""]]}, {"id": "1302.2606", "submitter": "Yasmina teldja Amghar", "authors": "Amghar Yasmina Teldja, Fizazi Hadria", "title": "A new bio-inspired method for remote sensing imagery classification", "comments": "13 pages, 17 figures. Updated author's affiliation and corrected\n  co-author's name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of supervised classification of the satellite image is considered\nto be the task of grouping pixels into a number of homogeneous regions in space\nintensity. This paper proposes a novel approach that combines a radial basic\nfunction clustering network with a growing neural gas include utility factor\nclassifier to yield improved solutions, obtained with previous networks. The\ndouble objective technique is first used to the development of a method to\nperform the satellite images classification, and finally, the implementation to\naddress the issue of the number of nodes in the hidden layer of the classic\nRadial Basis functions network. Results demonstrating the effectiveness of the\nproposed technique are provided for numeric remote sensing imagery. Moreover,\nthe remotely sensed image of Oran city in Algeria has been classified using the\nproposed technique to establish its utility.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2013 20:43:47 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2013 14:42:51 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Teldja", "Amghar Yasmina", ""], ["Hadria", "Fizazi", ""]]}, {"id": "1302.2712", "submitter": "John Paisley", "authors": "Yue Huang, John Paisley, Qin Lin, Xinghao Ding, Xueyang Fu and\n  Xiao-ping Zhang", "title": "Bayesian Nonparametric Dictionary Learning for Compressed Sensing MRI", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2014.2360122", "report-no": null, "categories": "cs.CV physics.med-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian nonparametric model for reconstructing magnetic\nresonance images (MRI) from highly undersampled k-space data. We perform\ndictionary learning as part of the image reconstruction process. To this end,\nwe use the beta process as a nonparametric dictionary learning prior for\nrepresenting an image patch as a sparse combination of dictionary elements. The\nsize of the dictionary and the patch-specific sparsity pattern are inferred\nfrom the data, in addition to other dictionary learning variables. Dictionary\nlearning is performed directly on the compressed image, and so is tailored to\nthe MRI being considered. In addition, we investigate a total variation penalty\nterm in combination with the dictionary learning model, and show how the\ndenoising property of dictionary learning removes dependence on regularization\nparameters in the noisy setting. We derive a stochastic optimization algorithm\nbased on Markov Chain Monte Carlo (MCMC) for the Bayesian model, and use the\nalternating direction method of multipliers (ADMM) for efficiently performing\ntotal variation minimization. We present empirical results on several MRI,\nwhich show that the proposed regularization framework can improve\nreconstruction accuracy over other methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2013 06:17:02 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 20:02:45 GMT"}, {"version": "v3", "created": "Sat, 26 Jul 2014 11:23:53 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Huang", "Yue", ""], ["Paisley", "John", ""], ["Lin", "Qin", ""], ["Ding", "Xinghao", ""], ["Fu", "Xueyang", ""], ["Zhang", "Xiao-ping", ""]]}, {"id": "1302.3119", "submitter": "Govindraj Chittapur Mr.", "authors": "S.Murali, Govindraj B. Chittapur, Prabhakara H.S and Basavaraj S.\n  Anami", "title": "Comparision and analysis of photo image forgery detection techniques", "comments": "12 pages, International Journal on Computational Sciences &\n  Applications (IJCSA) Vo2, No.6, December 2012", "journal-ref": null, "doi": "10.5121/ijcsa.2012.2605", "report-no": null, "categories": "cs.CV cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Photo images are everywhere, on the covers of magazines, in\nnewspapers, in courtrooms, and all over the Internet. We are exposed to them\nthroughout the day and most of the time. Ease with which images can be\nmanipulated; we need to be aware that seeing does not always imply believing.\nWe propose methodologies to identify such unbelievable photo images and\nsucceeded to identify forged region by given only the forged image. Formats are\nadditive tag for every file system and contents are relatively expressed with\nextension based on most popular digital camera uses JPEG and Other image\nformats like png, bmp etc. We have designed algorithm running behind with the\nconcept of abnormal anomalies and identify the forgery regions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 13:18:07 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Murali", "S.", ""], ["Chittapur", "Govindraj B.", ""], ["S", "Prabhakara H.", ""], ["Anami", "Basavaraj S.", ""]]}, {"id": "1302.3123", "submitter": "Nizar Banu P K", "authors": "P. K. Nizar Banu, H. Hannah Inbarani", "title": "An Analysis of Gene Expression Data using Penalized Fuzzy C-Means\n  Approach", "comments": "14; IJCCI, Vol. 1, Issue 2,(January-July)2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advances of microarray technologies, large amounts of\nhigh-dimensional gene expression data are being generated, which poses\nsignificant computational challenges. A first step towards addressing this\nchallenge is the use of clustering techniques, which is essential in the data\nmining process to reveal natural structures and identify interesting patterns\nin the underlying data. A robust gene expression clustering approach to\nminimize undesirable clustering is proposed. In this paper, Penalized Fuzzy\nC-Means (PFCM) Clustering algorithm is described and compared with the most\nrepresentative off-line clustering techniques: K-Means Clustering, Rough\nK-Means Clustering and Fuzzy C-Means clustering. These techniques are\nimplemented and tested for a Brain Tumor gene expression Dataset. Analysis of\nthe performance of the proposed approach is presented through qualitative\nvalidation experiments. From experimental results, it can be observed that\nPenalized Fuzzy C-Means algorithm shows a much higher usability than the other\nprojected clustering algorithms used in our comparison study. Significant and\npromising clustering results are presented using Brain Tumor Gene expression\ndataset. Thus patterns seen in genome-wide expression experiments can be\ninterpreted as indications of the status of cellular processes. In these\nclustering results, we find that Penalized Fuzzy C-Means algorithm provides\nuseful information as an aid to diagnosis in oncology.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 17:16:39 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Banu", "P. K. Nizar", ""], ["Inbarani", "H. Hannah", ""]]}, {"id": "1302.3155", "submitter": "Anirban Mukhopadhyay", "authors": "Anirban Mukhopadhyay, Zhen Qian, Suchendra M. Bhandarkar, Tianming\n  Liu, Sarah Rinehart, Szilard Voros", "title": "Morphological Analusis Of The Left Ventricular Eendocardial Surface\n  Using A Bag-Of-Features Descriptor", "comments": "Submitted to Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The limitations of conventional imaging techniques have hitherto precluded a\nthorough and formal investigation of the complex morphology of the left\nventricular (LV) endocardial surface and its relation to the severity of\nCoronary Artery Disease (CAD). Recent developments in high-resolution\nMultirow-Detector Computed Tomography (MDCT) scanner technology have enabled\nthe imaging of LV endocardial surface morphology in a single heart beat.\nAnalysis of high-resolution Computed Tomography (CT) images from a 320-MDCT\nscanner allows the study of the relationship between percent Diameter Stenosis\n(DS) of the major coronary arteries and localization of the cardiac segments\naffected by coronary arterial stenosis. In this paper a novel approach for the\nanalysis using a combination of rigid transformation-invariant shape\ndescriptors and a more generalized isometry-invariant Bag-of-Features (BoF)\ndescriptor, is proposed and implemented. The proposed approach is shown to be\nsuccessful in identifying, localizing and quantifying the incidence and extent\nof CAD and thus, is seen to have a potentially significant clinical impact.\nSpecifically, the association between the incidence and extent of CAD,\ndetermined via the percent DS measurements of the major coronary arteries, and\nthe alterations in the endocardial surface morphology is formally quantified. A\nmultivariate regression test performed on a strict leave-one-out basis are\nshown to exhibit a distinct pattern in terms of the correlation coefficient\nwithin the cardiac segments where the incidence of coronary arterial stenosis\nis localized.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 16:25:19 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Mukhopadhyay", "Anirban", ""], ["Qian", "Zhen", ""], ["Bhandarkar", "Suchendra M.", ""], ["Liu", "Tianming", ""], ["Rinehart", "Sarah", ""], ["Voros", "Szilard", ""]]}, {"id": "1302.3446", "submitter": "Xin Yuan", "authors": "Xin Yuan, Jianbo Yang, Patrick Llull, Xuejun Liao, Guillermo Sapiro,\n  David J. Brady and Lawrence Carin", "title": "Adaptive Temporal Compressive Sensing for Video", "comments": "IEEE Interonal International Conference on Image Processing\n  (ICIP),2013", "journal-ref": null, "doi": "10.1109/ICIP.2013.6738004", "report-no": null, "categories": "stat.AP cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of adaptive temporal compressive sensing\n(CS) for video. We propose a CS algorithm to adapt the compression ratio based\non the scene's temporal complexity, computed from the compressed data, without\ncompromising the quality of the reconstructed video. The temporal adaptivity is\nmanifested by manipulating the integration time of the camera, opening the\npossibility to real-time implementation. The proposed algorithm is a\ngeneralized temporal CS approach that can be incorporated with a diverse set of\nexisting hardware systems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 15:54:25 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2013 04:40:52 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2013 23:25:59 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Yuan", "Xin", ""], ["Yang", "Jianbo", ""], ["Llull", "Patrick", ""], ["Liao", "Xuejun", ""], ["Sapiro", "Guillermo", ""], ["Brady", "David J.", ""], ["Carin", "Lawrence", ""]]}, {"id": "1302.3556", "submitter": "Claude Barrouil", "authors": "Claude Barrouil, Jerome Lemaire", "title": "Object Recognition with Imperfect Perception and Redundant Description", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-65-72", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a scene recognition system in a robotics contex. The\ngeneral problem is to match images with <I>a priori</I> descriptions. A typical\nmission would consist in identifying an object in an installation with a vision\nsystem situated at the end of a manipulator and with a human operator provided\ndescription, formulated in a pseudo-natural language, and possibly redundant.\nThe originality of this work comes from the nature of the description, from the\nspecial attention given to the management of imprecision and uncertainty in the\ninterpretation process and from the way to assess the description redundancy so\nas to reinforce the overall matching likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:12:00 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Barrouil", "Claude", ""], ["Lemaire", "Jerome", ""]]}, {"id": "1302.3702", "submitter": "Dai-Gyoung Kim", "authors": "Muhammad Nazeer, Bibi Nargis, Yasir Mehmood Malik, and Dai-Gyoung Kim", "title": "A Fresnelet-Based Encryption of Medical Images using Arnold Transform", "comments": "16 pages, 11 figures, Journal Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images are commonly stored in digital media and transmitted via\nInternet for certain uses. If a medical information image alters, this can lead\nto a wrong diagnosis which may create a serious health problem. Moreover,\nmedical images in digital form can easily be modified by wiping off or adding\nsmall pieces of information intentionally for certain illegal purposes. Hence,\nthe reliability of medical images is an important criterion in a hospital\ninformation system. In this paper, Fresnelet transform is employed along with\nappropriate handling of the Arnold transform and the discrete cosine transform\nto provide secure distribution of medical images. This method presents a new\ndata hiding system in which steganography and cryptography are used to prevent\nunauthorized data access. The experimental results exhibit high\nimperceptibility for embedded images and significant encryption of information\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 09:06:05 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Nazeer", "Muhammad", ""], ["Nargis", "Bibi", ""], ["Malik", "Yasir Mehmood", ""], ["Kim", "Dai-Gyoung", ""]]}, {"id": "1302.3785", "submitter": "Elif Vural", "authors": "Elif Vural and Pascal Frossard", "title": "Analysis of Descent-Based Image Registration", "comments": null, "journal-ref": "SIAM Journal on Imaging Sciences, Vol. 6, No. 4, pp 2310-2349,\n  2013", "doi": "10.1137/130909858", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a performance analysis for image registration with gradient\ndescent methods. We consider a typical multiscale registration setting where\nthe global 2-D translation between a pair of images is estimated by smoothing\nthe images and minimizing the distance between them with gradient descent. Our\nstudy particularly concentrates on the effect of noise and low-pass filtering\non the alignment accuracy. We adopt an analytic representation for images and\nanalyze the well-behavedness of the image distance function by estimating the\nneighborhood of translations for which it is free of undesired local minima.\nThis corresponds to the neighborhood of translation vectors that are correctly\ncomputable with a simple gradient descent minimization. We show that the area\nof this neighborhood increases at least quadratically with the smoothing filter\nsize, which justifies the use of a smoothing step in image registration with\nlocal optimizers such as gradient descent. We then examine the effect of noise\non the alignment accuracy and derive an upper bound for the alignment error in\nterms of the noise properties and filter size. Our main finding is that the\nerror increases at a rate that is at least linear with respect to the filter\nsize. Therefore, smoothing improves the well-behavedness of the distance\nfunction; however, this comes at the cost of amplifying the alignment error in\nnoisy settings. Our results provide a mathematical insight about why\nhierarchical techniques are effective in image registration, suggesting that\nthe multiscale coarse-to-fine alignment strategy of these techniques is very\nsuitable from the perspective of the trade-off between the well-behavedness of\nthe objective function and the registration accuracy. To the best of our\nknowledge, this is the first such study for descent-based image registration.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 15:45:32 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2013 17:23:24 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Vural", "Elif", ""], ["Frossard", "Pascal", ""]]}, {"id": "1302.3900", "submitter": "Franz Graf", "authors": "Franz Graf, Hans-Peter Kriegel, Michael Weiler", "title": "Robust Image Segmentation in Low Depth Of Field Images", "comments": "Extended Version of the short paper published in \"Robust Image\n  Segmentation in Low Depth Of Field Images\", IEEE International Conference on\n  Image Processing 2011 (ICIP). The paper contains a lot more details about the\n  algorithm and more evaluation", "journal-ref": "Extended Version of \"Robust Image Segmentation in Low Depth Of\n  Field Images\", IEEE International Conference on Image Processing 2011 (ICIP)", "doi": "10.1109/TIP.2005.846030", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In photography, low depth of field (DOF) is an important technique to\nemphasize the object of interest (OOI) within an image. Thus, low DOF images\nare widely used in the application area of macro, portrait or sports\nphotography. When viewing a low DOF image, the viewer implicitly concentrates\non the regions that are sharper regions of the image and thus segments the\nimage into regions of interest and non regions of interest which has a major\nimpact on the perception of the image. Thus, a robust algorithm for the fully\nautomatic detection of the OOI in low DOF images provides valuable information\nfor subsequent image processing and image retrieval. In this paper we propose a\nrobust and parameterless algorithm for the fully automatic segmentation of low\nDOF images. We compare our method with three similar methods and show the\nsuperior robustness even though our algorithm does not require any parameters\nto be set by hand. The experiments are conducted on a real world data set with\nhigh and low DOF images.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 21:49:26 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Graf", "Franz", ""], ["Kriegel", "Hans-Peter", ""], ["Weiler", "Michael", ""]]}, {"id": "1302.4043", "submitter": "Belhassen Akrout", "authors": "Belhassen Akrout, Imen Khanfir Kallel, Chokri Ben Amar", "title": "A new scheme of signature extraction for iris authentication", "comments": "7 pages, 13 figures,International Multi-Conference on Systems Signals\n  and Devices", "journal-ref": "IEEE 6th International Multi-Conference on Systems, Signals and\n  Devices. (2009) 1-8", "doi": "10.1109/SSD.2009.4956749", "report-no": "REGIM-2009-03", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iris recognition, a relatively new biometric technology, has great\nadvantages, such as variability, stability and security, thus is the most\npromising for high security environment. Iris recognition is proposed in this\nreport. We describe some methods, the first one is based on grey level\nhistogram to extract the pupil, the second is based on elliptic and parabolic\nHOUGH transformation to determinate the edge of iris, upper and lower eyelids,\nthe third we used 2D Gabor Wavelets to encode the iris and finally we used the\nHamming distance for authentication.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2013 08:11:58 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Akrout", "Belhassen", ""], ["Kallel", "Imen Khanfir", ""], ["Amar", "Chokri Ben", ""]]}, {"id": "1302.4673", "submitter": "Michael Wilber", "authors": "Walter J. Scheirer, Michael J. Wilber, Michael Eckmann, Terrance E.\n  Boult", "title": "Good Recognition is Non-Metric", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition is the fundamental task of visual cognition, yet how to formalize\nthe general recognition problem for computer vision remains an open issue. The\nproblem is sometimes reduced to the simplest case of recognizing matching\npairs, often structured to allow for metric constraints. However, visual\nrecognition is broader than just pair matching -- especially when we consider\nmulti-class training data and large sets of features in a learning context.\nWhat we learn and how we learn it has important implications for effective\nalgorithms. In this paper, we reconsider the assumption of recognition as a\npair matching test, and introduce a new formal definition that captures the\nbroader context of the problem. Through a meta-analysis and an experimental\nassessment of the top algorithms on popular data sets, we gain a sense of how\noften metric properties are violated by good recognition algorithms. By\nstudying these violations, useful insights come to light: we make the case that\nlocally metric algorithms should leverage outside information to solve the\ngeneral recognition problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 17:02:34 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Scheirer", "Walter J.", ""], ["Wilber", "Michael J.", ""], ["Eckmann", "Michael", ""], ["Boult", "Terrance E.", ""]]}, {"id": "1302.4784", "submitter": "Yizhou Tan", "authors": "Tan Yi-zhou, Liu Hai-bo, Huang Shui-hua, Sheng Ben-jian, Pan\n  Zhong-ming", "title": "An Optical Watermarking Solution for Color Personal Identification\n  Pictures", "comments": null, "journal-ref": "2009 International Conference on Optical Instruments and\n  Technology: Optoelectronic", "doi": "10.1117/12.839630", "report-no": null, "categories": "cs.MM cs.CV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for embedding authentication information\ninto image on printed materials based on optical projection technique. Our\nexperimental setup consists of two parts, one is a common camera, and the other\nis a LCD projector, which project a pattern on personnel's body (especially on\nthe face). The pattern, generated by a computer, act as the illumination light\nsource with sinusoidal distribution and it is also the watermark signal. For a\ncolor image, the watermark is embedded into the blue channel. While we take\npictures (256 *256 and 512*512, 567*390 pixels, respectively), an invisible\nmark is embedded directly into magnitude oefficients of Discrete Fourier\ntransform (DFT) at exposure moment. Both optical an d digital correlation is\nsuitable for detection of this type of watermark. The decoded watermark is a\nset of concentric circles or sectors in the DFT domain (middle frequencies\nregion) which is robust to photographing, printing and scanning. The unlawful\npeople modify or replace the original photograph, and make fake passport\n(drivers' license and so on). Experiments show, it is difficult to forge\ncertificates in which a watermark was embedded by our projector-camera\ncombination based on analogue watermark method rather than classical digital\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 01:06:59 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Yi-zhou", "Tan", ""], ["Hai-bo", "Liu", ""], ["Shui-hua", "Huang", ""], ["Ben-jian", "Sheng", ""], ["Zhong-ming", "Pan", ""]]}, {"id": "1302.5010", "submitter": "Mingkui Tan", "authors": "Mingkui Tan and Ivor W. Tsang and Li Wang", "title": "Matching Pursuit LASSO Part II: Applications and Sparse Recovery over\n  Batch Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching Pursuit LASSIn Part I \\cite{TanPMLPart1}, a Matching Pursuit LASSO\n({MPL}) algorithm has been presented for solving large-scale sparse recovery\n(SR) problems. In this paper, we present a subspace search to further improve\nthe performance of MPL, and then continue to address another major challenge of\nSR -- batch SR with many signals, a consideration which is absent from most of\nprevious $\\ell_1$-norm methods. As a result, a batch-mode {MPL} is developed to\nvastly speed up sparse recovery of many signals simultaneously. Comprehensive\nnumerical experiments on compressive sensing and face recognition tasks\ndemonstrate the superior performance of MPL and BMPL over other methods\nconsidered in this paper, in terms of sparse recovery ability and efficiency.\nIn particular, BMPL is up to 400 times faster than existing $\\ell_1$-norm\nmethods considered to be state-of-the-art.O Part II: Applications and Sparse\nRecovery over Batch Signals\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 16:09:38 GMT"}, {"version": "v2", "created": "Wed, 24 Dec 2014 00:14:31 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Tan", "Mingkui", ""], ["Tsang", "Ivor W.", ""], ["Wang", "Li", ""]]}, {"id": "1302.5056", "submitter": "Yangqing Jia", "authors": "Yangqing Jia, Oriol Vinyals, Trevor Darrell", "title": "Pooling-Invariant Image Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised dictionary learning has been a key component in state-of-the-art\ncomputer vision recognition architectures. While highly effective methods exist\nfor patch-based dictionary learning, these methods may learn redundant features\nafter the pooling stage in a given early vision architecture. In this paper, we\noffer a novel dictionary learning scheme to efficiently take into account the\ninvariance of learned features after the spatial pooling stage. The algorithm\nis built on simple clustering, and thus enjoys efficiency and scalability. We\ndiscuss the underlying mechanism that justifies the use of clustering\nalgorithms, and empirically show that the algorithm finds better dictionaries\nthan patch-based methods with the same dictionary size.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 18:47:11 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Jia", "Yangqing", ""], ["Vinyals", "Oriol", ""], ["Darrell", "Trevor", ""]]}, {"id": "1302.5186", "submitter": "Ana Georgina Flesia MS", "authors": "Javier Gimenez, Jorge Martinez, Ana Georgina Flesia", "title": "Unsupervised edge map scoring: a statistical complexity approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Statistical Complexity Measure (SCM) to qualify edge maps\nwithout Ground Truth (GT) knowledge. The measure is the product of two indices,\nan \\emph{Equilibrium} index $\\mathcal{E}$ obtained by projecting the edge map\ninto a family of edge patterns, and an \\emph{Entropy} index $\\mathcal{H}$,\ndefined as a function of the Kolmogorov Smirnov (KS) statistic.\n  This new measure can be used for performance characterization which includes:\n(i)~the specific evaluation of an algorithm (intra-technique process) in order\nto identify its best parameters, and (ii)~the comparison of different\nalgorithms (inter-technique process) in order to classify them according to\ntheir quality.\n  Results made over images of the South Florida and Berkeley databases show\nthat our approach significantly improves over Pratt's Figure of Merit (PFoM)\nwhich is the objective reference-based edge map evaluation standard, as it\ntakes into account more features in its evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 05:56:41 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 18:28:23 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Gimenez", "Javier", ""], ["Martinez", "Jorge", ""], ["Flesia", "Ana Georgina", ""]]}, {"id": "1302.5189", "submitter": "Dilip K. Prasad", "authors": "Dilip K. Prasad", "title": "Object Detection in Real Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection and recognition are important problems in computer vision.\nSince these problems are meta-heuristic, despite a lot of research, practically\nusable, intelligent, real-time, and dynamic object detection/recognition\nmethods are still unavailable. We propose a new object detection/recognition\nmethod, which improves over the existing methods in every stage of the object\ndetection/recognition process. In addition to the usual features, we propose to\nuse geometric shapes, like linear cues, ellipses and quadrangles, as additional\nfeatures. The full potential of geometric cues is exploited by using them to\nextract other features in a robust, computationally efficient, and less\nmeta-heuristic manner. We also propose a new hierarchical codebook, which\nprovides good generalization and discriminative properties. The codebook\nenables fast multi-path inference mechanisms based on propagation of\nconditional likelihoods, that make it robust to occlusion and noise. It has the\ncapability of dynamic learning. We also propose a new learning method that has\ngenerative and discriminative learning capabilities, does not need large and\nfully supervised training dataset, and is capable of online learning. The\npreliminary work of detecting geometric shapes in real images has been\ncompleted. This preliminary work is the focus of this report. Future path for\nrealizing the proposed object detection/recognition method is also discussed in\nbrief.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 06:06:47 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Prasad", "Dilip K.", ""]]}, {"id": "1302.5449", "submitter": "Juan Andres Bazerque", "authors": "Juan Andres Bazerque and Georgios B. Giannakis", "title": "Nonparametric Basis Pursuit via Sparse Kernel-based Learning", "comments": "IEEE SIGNAL PROCESSING MAGAZINE, 2013 (TO APPEAR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal processing tasks as fundamental as sampling, reconstruction, minimum\nmean-square error interpolation and prediction can be viewed under the prism of\nreproducing kernel Hilbert spaces. Endowing this vantage point with\ncontemporary advances in sparsity-aware modeling and processing, promotes the\nnonparametric basis pursuit advocated in this paper as the overarching\nframework for the confluence of kernel-based learning (KBL) approaches\nleveraging sparse linear regression, nuclear-norm regularization, and\ndictionary learning. The novel sparse KBL toolbox goes beyond translating\nsparse parametric approaches to their nonparametric counterparts, to\nincorporate new possibilities such as multi-kernel selection and matrix\nsmoothing. The impact of sparse KBL to signal processing applications is\nillustrated through test cases from cognitive radio sensing, microarray data\nimputation, and network traffic prediction.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 22:59:12 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Bazerque", "Juan Andres", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1302.5554", "submitter": "Patrick Heas", "authors": "Patrick H\\'eas, Fr\\'ed\\'eric Lavancier, Souleymane Kadri-Harouna", "title": "Self-similar prior and wavelet bases for hidden incompressible turbulent\n  motion", "comments": "SIAM Journal on Imaging Sciences, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV cs.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is concerned with the ill-posed inverse problem of estimating\nturbulent flows from the observation of an image sequence. From a Bayesian\nperspective, a divergence-free isotropic fractional Brownian motion (fBm) is\nchosen as a prior model for instantaneous turbulent velocity fields. This\nself-similar prior characterizes accurately second-order statistics of velocity\nfields in incompressible isotropic turbulence. Nevertheless, the associated\nmaximum a posteriori involves a fractional Laplacian operator which is delicate\nto implement in practice. To deal with this issue, we propose to decompose the\ndivergent-free fBm on well-chosen wavelet bases. As a first alternative, we\npropose to design wavelets as whitening filters. We show that these filters are\nfractional Laplacian wavelets composed with the Leray projector. As a second\nalternative, we use a divergence-free wavelet basis, which takes implicitly\ninto account the incompressibility constraint arising from physics. Although\nthe latter decomposition involves correlated wavelet coefficients, we are able\nto handle this dependence in practice. Based on these two wavelet\ndecompositions, we finally provide effective and efficient algorithms to\napproach the maximum a posteriori. An intensive numerical evaluation proves the\nrelevance of the proposed wavelet-based self-similar priors.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 11:28:07 GMT"}, {"version": "v2", "created": "Thu, 13 Mar 2014 07:43:12 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["H\u00e9as", "Patrick", ""], ["Lavancier", "Fr\u00e9d\u00e9ric", ""], ["Kadri-Harouna", "Souleymane", ""]]}, {"id": "1302.5762", "submitter": "Yue Wu", "authors": "Yue Wu and Brian Tracey and Premkumar Natarajan and Joseph P. Noonan", "title": "Probabilistic Non-Local Means", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.1109/LSP.2013.2263135", "report-no": null, "categories": "cs.CV stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a so-called probabilistic non-local means (PNLM)\nmethod for image denoising. Our main contributions are: 1) we point out defects\nof the weight function used in the classic NLM; 2) we successfully derive all\ntheoretical statistics of patch-wise differences for Gaussian noise; and 3) we\nemploy this prior information and formulate the probabilistic weights truly\nreflecting the similarity between two noisy patches. The probabilistic nature\nof the new weight function also provides a theoretical basis to choose\nthresholds rejecting dissimilar patches for fast computations. Our simulation\nresults indicate the PNLM outperforms the classic NLM and many NLM recent\nvariants in terms of peak signal noise ratio (PSNR) and structural similarity\n(SSIM) index. Encouraging improvements are also found when we replace the NLM\nweights with the probabilistic weights in tested NLM variants.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 04:48:14 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Wu", "Yue", ""], ["Tracey", "Brian", ""], ["Natarajan", "Premkumar", ""], ["Noonan", "Joseph P.", ""]]}, {"id": "1302.5894", "submitter": "Sonya Eini", "authors": "Sonya Eini and Abdolah Chalechale", "title": "Four Side Distance: A New Fourier Shape Signature", "comments": "6 pages, 7 figures, International Journal of Advanced Studies in\n  Computers, Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape is one of the main features in content based image retrieval (CBIR).\nThis paper proposes a new shape signature. In this technique, features of each\nshape are extracted based on four sides of the rectangle that covers the shape.\nThe proposed technique is Fourier based and it is invariant to translation,\nscaling and rotation. The retrieval performance between some commonly used\nFourier based signatures and the proposed four sides distance (FSD) signature\nhas been tested using MPEG-7 database. Experimental results are shown that the\nFSD signature has better performance compared with those signatures.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 10:49:39 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Eini", "Sonya", ""], ["Chalechale", "Abdolah", ""]]}, {"id": "1302.5957", "submitter": "Sergey Komech Mr", "authors": "Xavier Descombes, Serguei Komech", "title": "Shape Characterization via Boundary Distortion", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive new shape descriptors based on a directional\ncharacterization. The main idea is to study the behavior of the shape\nneighborhood under family of transformations. We obtain a description invariant\nwith respect to rotation, reflection, translation and scaling. A well-defined\nmetric is then proposed on the associated feature space. We show the continuity\nof this metric. Some results on shape retrieval are provided on two databases\nto show the accuracy of the proposed shape metric.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 21:38:20 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Descombes", "Xavier", ""], ["Komech", "Serguei", ""]]}, {"id": "1302.5985", "submitter": "Xiaodi Hou", "authors": "Xiaodi Hou and Alan Yuille and Christof Koch", "title": "A Meta-Theory of Boundary Detection Benchmarks", "comments": "NIPS 2012 Workshop on Human Computation for Science and Computational\n  Sustainability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human labeled datasets, along with their corresponding evaluation algorithms,\nplay an important role in boundary detection. We here present a psychophysical\nexperiment that addresses the reliability of such benchmarks. To find better\nremedies to evaluate the performance of any boundary detection algorithm, we\npropose a computational framework to remove inappropriate human labels and\nestimate the intrinsic properties of boundaries.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 03:12:12 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Hou", "Xiaodi", ""], ["Yuille", "Alan", ""], ["Koch", "Christof", ""]]}, {"id": "1302.6105", "submitter": "Paul Escande", "authors": "Paul Escande (ITAV), Pierre Weiss (ITAV), Francois Malgouyres (IMT)", "title": "Image restoration using sparse approximations of spatially varying blur\n  operators in the wavelet domain", "comments": "6 pages", "journal-ref": null, "doi": "10.1088/1742-6596/464/1/012004", "report-no": null, "categories": "math.OC cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restoration of images degraded by spatially varying blurs is an issue of\nincreasing importance in the context of photography, satellite or microscopy\nimaging. One of the main difficulty to solve this problem comes from the huge\ndimensions of the blur matrix. It prevents the use of naive approaches for\nperforming matrix-vector multiplications. In this paper, we propose to\napproximate the blur operator by a matrix sparse in the wavelet domain. We\njustify this approach from a mathematical point of view and investigate the\napproximation quality numerically. We finish by showing that the sparsity\npattern of the matrix can be pre-defined, which is central in tasks such as\nblind deconvolution.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2013 14:36:33 GMT"}, {"version": "v2", "created": "Thu, 30 May 2013 19:04:48 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Escande", "Paul", "", "ITAV"], ["Weiss", "Pierre", "", "ITAV"], ["Malgouyres", "Francois", "", "IMT"]]}, {"id": "1302.6379", "submitter": "Faizan Ahmad", "authors": "Faizan Ahmad, Aaima Najam, Zeeshan Ahmed", "title": "Image-based Face Detection and Recognition: \"State of the Art\"", "comments": "4 pages, 3 table, 4 figure", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 6, No 1, November 2012 ISSN (Online): 1694-0814", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition from image or video is a popular topic in biometrics\nresearch. Many public places usually have surveillance cameras for video\ncapture and these cameras have their significant value for security purpose. It\nis widely acknowledged that the face recognition have played an important role\nin surveillance system as it doesn't need the object's cooperation. The actual\nadvantages of face based identification over other biometrics are uniqueness\nand acceptance. As human face is a dynamic object having high degree of\nvariability in its appearance, that makes face detection a difficult problem in\ncomputer vision. In this field, accuracy and speed of identification is a main\nissue.\n  The goal of this paper is to evaluate various face detection and recognition\nmethods, provide complete solution for image based face detection and\nrecognition with higher accuracy, better response rate as an initial step for\nvideo surveillance. Solution is proposed based on performed tests on various\nface rich databases in terms of subjects, pose, emotions, race and light.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 10:12:30 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Ahmad", "Faizan", ""], ["Najam", "Aaima", ""], ["Ahmed", "Zeeshan", ""]]}, {"id": "1302.6557", "submitter": "Richard M Jiang", "authors": "Richard M Jiang", "title": "Geodesic-based Salient Object Detection", "comments": "The manuscript was submitted to a conference. Due to anonymous review\n  policy by the conference, I'd like to withdraw it temporarily", "journal-ref": "This is a revised version of our submissions to CVPR 2012, SIGRAPH\n  Asia 2012, and CVPR 2013;", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency detection has been an intuitive way to provide useful cues for\nobject detection and segmentation, as desired for many vision and graphics\napplications. In this paper, we provided a robust method for salient object\ndetection and segmentation. Other than using various pixel-level contrast\ndefinitions, we exploited global image structures and proposed a new geodesic\nmethod dedicated for salient object detection. In the proposed approach, a new\ngeodesic scheme, namely geodesic tunneling is proposed to tackle with textures\nand local chaotic structures. With our new geodesic approach, a geodesic\nsaliency map is estimated in correspondence to spatial structures in an image.\nExperimental evaluation on a salient object benchmark dataset validated that\nour algorithm consistently outperformed a number of the state-of-art saliency\nmethods, yielding higher precision and better recall rates. With the robust\nsaliency estimation, we also present an unsupervised hierarchical salient\nobject cut scheme simply using adaptive saliency thresholding, which attained\nthe highest score in our F-measure test. We also applied our geodesic cut\nscheme to a number of image editing tasks as demonstrated in additional\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 19:52:02 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2013 18:41:55 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Jiang", "Richard M", ""]]}, {"id": "1302.6957", "submitter": "Jayaraman J. Thiagarajan", "authors": "Karthikeyan Natesan Ramamurthy, Jayaraman J. Thiagarajan, Prasanna\n  Sattigeri and Andreas Spanias", "title": "Ensemble Sparse Models for Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse representations with learned dictionaries have been successful in\nseveral image analysis applications. In this paper, we propose and analyze the\nframework of ensemble sparse models, and demonstrate their utility in image\nrestoration and unsupervised clustering. The proposed ensemble model\napproximates the data as a linear combination of approximations from multiple\n\\textit{weak} sparse models. Theoretical analysis of the ensemble model reveals\nthat even in the worst-case, the ensemble can perform better than any of its\nconstituent individual models. The dictionaries corresponding to the individual\nsparse models are obtained using either random example selection or boosted\napproaches. Boosted approaches learn one dictionary per round such that the\ndictionary learned in a particular round is optimized for the training examples\nhaving high reconstruction error in the previous round. Results with compressed\nrecovery show that the ensemble representations lead to a better performance\ncompared to using a single dictionary obtained with the conventional\nalternating minimization approach. The proposed ensemble models are also used\nfor single image superresolution, and we show that they perform comparably to\nthe recent approaches. In unsupervised clustering, experiments show that the\nproposed model performs better than baseline approaches in several standard\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 18:58:36 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Ramamurthy", "Karthikeyan Natesan", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Sattigeri", "Prasanna", ""], ["Spanias", "Andreas", ""]]}, {"id": "1302.7039", "submitter": "Mounira Taileb", "authors": "Mounira Taileb", "title": "Content Based Image Retrieval System Using NOHIS-tree", "comments": "6 pages, 10th International Conference on Advances in Mobile\n  Computing & Multimedia (MoMM2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-based image retrieval (CBIR) has been one of the most important\nresearch areas in computer vision. It is a widely used method for searching\nimages in huge databases. In this paper we present a CBIR system called\nNOHIS-Search. The system is based on the indexing technique NOHIS-tree. The two\nphases of the system are described and the performance of the system is\nillustrated with the image database ImagEval. NOHIS-Search system was compared\nto other two CBIR systems; the first that using PDDP indexing algorithm and the\nsecond system is that using the sequential search. Results show that\nNOHIS-Search system outperforms the two other systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 00:21:38 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Taileb", "Mounira", ""]]}, {"id": "1302.7082", "submitter": "Meena Kabilan", "authors": "A.Meena, K.Raja", "title": "K Means Segmentation of Alzheimers Disease in PET scan datasets: An\n  implementation", "comments": "International Joint Conference on Advances in Signal Processing and\n  Information Technology, SPIT2012", "journal-ref": "LNICST, ISSN:1867 To 8211 pp. 158 To 162, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Positron Emission Tomography (PET) scan image requires expertise in the\nsegmentation where clustering algorithm plays an important role in the\nautomation process. The algorithm optimization is concluded based on the\nperformance, quality and number of clusters extracted. This paper is proposed\nto study the commonly used K Means clustering algorithm and to discuss a brief\nlist of toolboxes for reproducing and extending works presented in medical\nimage analysis. This work is compiled using AForge .NET framework in windows\nenvironment and MATrix LABoratory (MATLAB 7.0.1)\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 04:50:31 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Meena", "A.", ""], ["Raja", "K.", ""]]}, {"id": "1302.7180", "submitter": "Dong Yi", "authors": "Dong Yi, Zhen Lei, Yang Hu and Stan Z. Li", "title": "Fast Matching by 2 Lines of Code for Large Scale Face Recognition\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method to apply the popular cascade classifier\ninto face recognition to improve the computational efficiency while keeping\nhigh recognition rate. In large scale face recognition systems, because the\nprobability of feature templates coming from different subjects is very high,\nmost of the matching pairs will be rejected by the early stages of the cascade.\nTherefore, the cascade can improve the matching speed significantly. On the\nother hand, using the nested structure of the cascade, we could drop some\nstages at the end of feature to reduce the memory and bandwidth usage in some\nresources intensive system while not sacrificing the performance too much. The\ncascade is learned by two steps. Firstly, some kind of prepared features are\ngrouped into several nested stages. And then, the threshold of each stage is\nlearned to achieve user defined verification rate (VR). In the paper, we take a\nlandmark based Gabor+LDA face recognition system as baseline to illustrate the\nprocess and advantages of the proposed method. However, the use of this method\nis very generic and not limited in face recognition, which can be easily\ngeneralized to other biometrics as a post-processing module. Experiments on the\nFERET database show the good performance of our baseline and an experiment on a\nself-collected large scale database illustrates that the cascade can improve\nthe matching speed significantly.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 12:59:41 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Yi", "Dong", ""], ["Lei", "Zhen", ""], ["Hu", "Yang", ""], ["Li", "Stan Z.", ""]]}]