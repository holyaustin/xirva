[{"id": "1207.0151", "submitter": "Matthew Zeiler", "authors": "Matthew D. Zeiler and Rob Fergus", "title": "Differentiable Pooling for Hierarchical Feature Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a parametric form of pooling, based on a Gaussian, which can be\noptimized alongside the features in a single global objective function. By\ncontrast, existing pooling schemes are based on heuristics (e.g. local maximum)\nand have no clear link to the cost function of the model. Furthermore, the\nvariables of the Gaussian explicitly store location information, distinct from\nthe appearance captured by the features, thus providing a what/where\ndecomposition of the input signal. Although the differentiable pooling scheme\ncan be incorporated in a wide range of hierarchical models, we demonstrate it\nin the context of a Deconvolutional Network model (Zeiler et al. ICCV 2011). We\nalso explore a number of secondary issues within this model and present\ndetailed experiments on MNIST digits.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2012 21:04:13 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Zeiler", "Matthew D.", ""], ["Fergus", "Rob", ""]]}, {"id": "1207.0170", "submitter": "M Taghizadeh-Popp", "authors": "M. Taghizadeh-Popp, S. Heinis and A. S. Szalay", "title": "Single parameter galaxy classification: The Principal Curve through the\n  multi-dimensional space of galaxy properties", "comments": "Full abstract in downloadable version", "journal-ref": null, "doi": "10.1088/0004-637X/755/2/143", "report-no": null, "categories": "astro-ph.CO cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to describe the variety of galaxies from SDSS by using only one\naffine parameter. To this aim, we build the Principal Curve (P-curve) passing\nthrough the spine of the data point cloud, considering the eigenspace derived\nfrom Principal Component Analysis of morphological, physical and photometric\ngalaxy properties. Thus, galaxies can be labeled, ranked and classified by a\nsingle arc length value of the curve, measured at the unique closest projection\nof the data points on the P-curve. We find that the P-curve has a \"W\" letter\nshape with 3 turning points, defining 4 branches that represent distinct galaxy\npopulations. This behavior is controlled mainly by 2 properties, namely u-r and\nSFR. We further present the variations of several galaxy properties as a\nfunction of arc length. Luminosity functions variate from steep Schechter fits\nat low arc length, to double power law and ending in Log-normal fits at high\narc length. Galaxy clustering shows increasing autocorrelation power at large\nscales as arc length increases. PCA analysis allowed to find peculiar galaxy\npopulations located apart from the main cloud of data points, such as small red\ngalaxies dominated by a disk, of relatively high stellar mass-to-light ratio\nand surface mass density. The P-curve allows not only dimensionality reduction,\nbut also provides supporting evidence for relevant physical models and\nscenarios in extragalactic astronomy: 1) Evidence for the hierarchical merging\nscenario in the formation of a selected group of red massive galaxies. These\ngalaxies present a log-normal r-band luminosity function, which might arise\nfrom multiplicative processes involved in this scenario. 2) Connection between\nthe onset of AGN activity and star formation quenching, which appears in green\ngalaxies when transitioning from blue to red populations. (Full abstract in\ndownloadable version)\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 00:32:15 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Taghizadeh-Popp", "M.", ""], ["Heinis", "S.", ""], ["Szalay", "A. S.", ""]]}, {"id": "1207.0580", "submitter": "Nitish Srivastava", "authors": "Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya\n  Sutskever, Ruslan R. Salakhutdinov", "title": "Improving neural networks by preventing co-adaptation of feature\n  detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a large feedforward neural network is trained on a small training set,\nit typically performs poorly on held-out test data. This \"overfitting\" is\ngreatly reduced by randomly omitting half of the feature detectors on each\ntraining case. This prevents complex co-adaptations in which a feature detector\nis only helpful in the context of several other specific feature detectors.\nInstead, each neuron learns to detect a feature that is generally helpful for\nproducing the correct answer given the combinatorially large variety of\ninternal contexts in which it must operate. Random \"dropout\" gives big\nimprovements on many benchmark tasks and sets new records for speech and object\nrecognition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 06:35:15 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Hinton", "Geoffrey E.", ""], ["Srivastava", "Nitish", ""], ["Krizhevsky", "Alex", ""], ["Sutskever", "Ilya", ""], ["Salakhutdinov", "Ruslan R.", ""]]}, {"id": "1207.0677", "submitter": "Romain Giot", "authors": "Romain Giot (GREYC), Christophe Charrier (GREYC), Maxime Descoteaux\n  (SCIL)", "title": "Local Water Diffusion Phenomenon Clustering From High Angular Resolution\n  Diffusion Imaging (HARDI)", "comments": "IAPR International Conference on Pattern Recognition (ICPR), Tsukuba,\n  Japan : France (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of neurodegenerative diseases undoubtedly passes through\nthe study of human brain white matter fiber tracts. To date, diffusion magnetic\nresonance imaging (dMRI) is the unique technique to obtain information about\nthe neural architecture of the human brain, thus permitting the study of white\nmatter connections and their integrity. However, a remaining challenge of the\ndMRI community is to better characterize complex fiber crossing configurations,\nwhere diffusion tensor imaging (DTI) is limited but high angular resolution\ndiffusion imaging (HARDI) now brings solutions. This paper investigates the\ndevelopment of both identification and classification process of the local\nwater diffusion phenomenon based on HARDI data to automatically detect imaging\nvoxels where there are single and crossing fiber bundle populations. The\ntechnique is based on knowledge extraction processes and is validated on a dMRI\nphantom dataset with ground truth.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 13:52:19 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Giot", "Romain", "", "GREYC"], ["Charrier", "Christophe", "", "GREYC"], ["Descoteaux", "Maxime", "", "SCIL"]]}, {"id": "1207.0704", "submitter": "Alejandro Frery", "authors": "Leonardo Torres, Tamer Cavalcante and Alejandro C. Frery", "title": "Speckle Reduction using Stochastic Distances", "comments": "Accepted for publication on the proceedings of the 17th Iberoamerican\n  Congress on Patter Recognition (CIARP), to be published in the Lecture Notes\n  in Computer Science series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for filter design based on stochastic\ndistances and tests between distributions. A window is defined around each\npixel, samples are compared and only those which pass a goodness-of-fit test\nare used to compute the filtered value. The technique is applied to intensity\nSynthetic Aperture Radar (SAR) data, using the Gamma model with varying number\nof looks allowing, thus, changes in heterogeneity. Modified Nagao-Matsuyama\nwindows are used to define the samples. The proposal is compared with the Lee's\nfilter which is considered a standard, using a protocol based on simulation.\nAmong the criteria used to quantify the quality of filters, we employ the\nequivalent number of looks (related to the signal-to-noise ratio), line\ncontrast, and edge preservation. Moreover, we also assessed the filters by the\nUniversal Image Quality Index and the Pearson's correlation between edges.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 14:57:44 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Torres", "Leonardo", ""], ["Cavalcante", "Tamer", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1207.0771", "submitter": "Alejandro Frery", "authors": "Leonardo Torres, Antonio C. Medeiros and Alejandro C. Frery", "title": "Polarimetric SAR Image Smoothing with Stochastic Distances", "comments": "Accepted for publication in the proceedings of the 17th Iberoamerican\n  Conference on Pattern Recognition, to be published in the Lecture Notes in\n  Computer Science series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.GR math.IT stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an\nimportant source of information in remote sensing applications. The most\ncomplete format this type of imaging produces consists of complex-valued\nHermitian matrices in every image coordinate and, as such, their visualization\nis challenging. They also suffer from speckle noise which reduces the\nsignal-to-noise ratio. Smoothing techniques have been proposed in the\nliterature aiming at preserving different features and, analogously,\nprojections from the cone of Hermitian positive matrices to different color\nrepresentation spaces are used for enhancing certain characteristics. In this\nwork we propose the use of stochastic distances between models that describe\nthis type of data in a Nagao-Matsuyama-type of smoothing technique. The\nresulting images are shown to present good visualization properties (noise\nreduction with preservation of fine details) in all the considered\nvisualization spaces.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 18:11:46 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Torres", "Leonardo", ""], ["Medeiros", "Antonio C.", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1207.0805", "submitter": "Pallavali Radha Krishna Reddy", "authors": "G.Geethu Lakshmi", "title": "Anatomical Structure Segmentation in Liver MRI Images", "comments": "Withdrawn by author for final modification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Segmentation of medical images is a challenging task owing to their\ncomplexity. A standard segmentation problem within Magnetic Resonance Imaging\n(MRI) is the task of labeling voxels according to their tissue type. Image\nsegmentation provides volumetric quantification of liver area and thus helps in\nthe diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice,\nHemochromatosis etc.This work deals with comparison of segmentation by applying\nLevel Set Method,Fuzzy Level Information C-Means Clustering Algorithm and\nGradient Vector Flow Snake Algorithm.The results are compared using the\nparameters such as Number of pixels correctly classified, and percentage of\narea segmented.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 14:32:20 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2012 10:48:33 GMT"}, {"version": "v3", "created": "Sat, 30 Mar 2013 05:25:58 GMT"}], "update_date": "2013-04-02", "authors_parsed": [["Lakshmi", "G. Geethu", ""]]}, {"id": "1207.1019", "submitter": "Emilie Morvant", "authors": "Emilie Morvant (LIF), Amaury Habrard (LAHC), St\\'ephane Ayache (LIF)", "title": "PAC-Bayesian Majority Vote for Late Classifier Fusion", "comments": "7 pages, Research report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of attention has been devoted to multimedia indexing over the past few\nyears. In the literature, we often consider two kinds of fusion schemes: The\nearly fusion and the late fusion. In this paper we focus on late classifier\nfusion, where one combines the scores of each modality at the decision level.\nTo tackle this problem, we investigate a recent and elegant well-founded\nquadratic program named MinCq coming from the Machine Learning PAC-Bayes\ntheory. MinCq looks for the weighted combination, over a set of real-valued\nfunctions seen as voters, leading to the lowest misclassification rate, while\nmaking use of the voters' diversity. We provide evidence that this method is\nnaturally adapted to late fusion procedure. We propose an extension of MinCq by\nadding an order- preserving pairwise loss for ranking, helping to improve Mean\nAveraged Precision measure. We confirm the good behavior of the MinCq-based\nfusion approaches with experiments on a real image benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 15:09:05 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Morvant", "Emilie", "", "LIF"], ["Habrard", "Amaury", "", "LAHC"], ["Ayache", "St\u00e9phane", "", "LIF"]]}, {"id": "1207.1114", "submitter": "Yao Lu", "authors": "Yao Lu, Kaizhu Huang, Cheng-Lin Liu", "title": "A Fast Projected Fixed-Point Algorithm for Large Graph Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast approximate algorithm for large graph matching. A new\nprojected fixed-point method is defined and a new doubly stochastic projection\nis adopted to derive the algorithm. Previous graph matching algorithms suffer\nfrom high computational complexity and therefore do not have good scalability\nwith respect to graph size. For matching two weighted graphs of $n$ nodes, our\nalgorithm has time complexity only $O(n^3)$ per iteration and space complexity\n$O(n^2)$. In addition to its scalability, our algorithm is easy to implement,\nrobust, and able to match undirected weighted attributed graphs of different\nsizes. While the convergence rate of previous iterative graph matching\nalgorithms is unknown, our algorithm is theoretically guaranteed to converge at\na linear rate. Extensive experiments on large synthetic and real graphs (more\nthan 1,000 nodes) were conducted to evaluate the performance of various\nalgorithms. Results show that in most cases our proposed algorithm achieves\nbetter performance than previous state-of-the-art algorithms in terms of both\nspeed and accuracy in large graph matching. In particular, with high accuracy,\nour algorithm takes only a few seconds (in a PC) to match two graphs of 1,000\nnodes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 18:20:25 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2012 14:50:16 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2012 08:51:17 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Lu", "Yao", ""], ["Huang", "Kaizhu", ""], ["Liu", "Cheng-Lin", ""]]}, {"id": "1207.1522", "submitter": "Jonathan Masci", "authors": "Jonathan Masci and Michael M. Bronstein and Alexander A. Bronstein and\n  J\\\"urgen Schmidhuber", "title": "Multimodal similarity-preserving hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient computational framework for hashing data belonging\nto multiple modalities into a single representation space where they become\nmutually comparable. The proposed approach is based on a novel coupled siamese\nneural network architecture and allows unified treatment of intra- and\ninter-modality similarity learning. Unlike existing cross-modality similarity\nlearning approaches, our hashing functions are not limited to binarized linear\nprojections and can assume arbitrarily complex forms. We show experimentally\nthat our method significantly outperforms state-of-the-art hashing approaches\non multimedia retrieval tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 04:58:52 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Masci", "Jonathan", ""], ["Bronstein", "Michael M.", ""], ["Bronstein", "Alexander A.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1207.1551", "submitter": "Shervan Fekri ershad", "authors": "Shervan Fekri-Ershad, Mohammad Saberi, Farshad Tajeripour", "title": "An Innovative Skin Detection Approach Using Color Based Image Retrieval\n  Technique", "comments": "9 Pages, 4 Figures", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.4, No.3, June 2012, 57-65", "doi": "10.5121/ijma.2012.4305", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From The late 90th, \"Skin Detection\" becomes one of the major problems in\nimage processing. If \"Skin Detection\" will be done in high accuracy, it can be\nused in many cases as face recognition, Human Tracking and etc. Until now so\nmany methods were presented for solving this problem. In most of these methods,\ncolor space was used to extract feature vector for classifying pixels, but the\nmost of them have not good accuracy in detecting types of skin. The proposed\napproach in this paper is based on \"Color based image retrieval\" (CBIR)\ntechnique. In this method, first by means of CBIR method and image tiling and\nconsidering the relation between pixel and its neighbors, a feature vector\nwould be defined and then with using a training step, detecting the skin in the\ntest stage. The result shows that the presenting approach, in addition to its\nhigh accuracy in detecting type of skin, has no sensitivity to illumination\nintensity and moving face orientation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 08:04:38 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Fekri-Ershad", "Shervan", ""], ["Saberi", "Mohammad", ""], ["Tajeripour", "Farshad", ""]]}, {"id": "1207.1649", "submitter": "Odemir Bruno PhD", "authors": "N\\'ubia Rosa da Silva and Odemir Martinez Bruno", "title": "Analysis of Multi-Scale Fractal Dimension to Classify Human Motion", "comments": "6 pages, Paper presented on WVC 2012 (Workshop of Computer Vision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been considerable interest in human action\nrecognition. Several approaches have been developed in order to enhance the\nautomatic video analysis. Although some developments have been achieved by the\ncomputer vision community, the properly classification of human motion is still\na hard and challenging task. The objective of this study is to investigate the\nuse of 3D multi-scale fractal dimension to recognize motion patterns in videos.\nIn order to develop a robust strategy for human motion classification, we\nproposed a method where the Fourier transform is used to calculate the\nderivative in which all data points are deemed. Our results shown that\ndifferent accuracy rates can be found for different databases. We believe that\nin specific applications our results are the first step to develop an automatic\nmonitoring system, which can be applied in security systems, traffic\nmonitoring, biology, physical therapy, cardiovascular disease among many\nothers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 15:10:49 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["da Silva", "N\u00fabia Rosa", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1207.1765", "submitter": "Jonathan Masci", "authors": "Jonathan Masci and Ueli Meier and Gabriel Fricout and J\\\"urgen\n  Schmidhuber", "title": "Object Recognition with Multi-Scale Pyramidal Pooling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Multi-Scale Pyramidal Pooling Network, featuring a novel\npyramidal pooling layer at multiple scales and a novel encoding layer. Thanks\nto the former the network does not require all images of a given classification\ntask to be of equal size. The encoding layer improves generalisation\nperformance in comparison to similar neural network architectures, especially\nwhen training data is scarce. We evaluate and compare our system to\nconvolutional neural networks and state-of-the-art computer vision methods on\nvarious benchmark datasets. We also present results on industrial steel defect\nclassification, where existing architectures are not applicable because of the\nconstraint on equally sized input images. The proposed architecture can be seen\nas a fully supervised hierarchical bag-of-features extension that is trained\nonline and can be fine-tuned for any given task.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2012 06:27:52 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Masci", "Jonathan", ""], ["Meier", "Ueli", ""], ["Fricout", "Gabriel", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1207.1915", "submitter": "Alejandro Frery", "authors": "Edwin Gir\\'on, Alejandro C. Frery and Francisco Cribari-Neto", "title": "Nonparametric Edge Detection in Speckled Imagery", "comments": "Accepted for publication in Mathematics and Computers in Simulation", "journal-ref": "Mathematics and Computers in Simulation, vol. 82, pages 2182-2198,\n  2012", "doi": "10.1016/j.matcom.2012.04.013", "report-no": null, "categories": "stat.AP cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of edge detection in Synthetic Aperture Radar imagery.\nIn particular, we propose nonparametric methods for edge detection, and\nnumerically compare them to an alternative method that has been recently\nproposed in the literature. Our results show that some of the proposed methods\ndisplay superior results and are computationally simpler than the existing\nmethod. An application to real (not simulated) data is presented and discussed.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 21:45:43 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["Gir\u00f3n", "Edwin", ""], ["Frery", "Alejandro C.", ""], ["Cribari-Neto", "Francisco", ""]]}, {"id": "1207.1922", "submitter": "Firouz Wassai", "authors": "Firouz Abdullah Al-Wassai, N. V. Kalyankar, Ali A. Al-Zaky", "title": "Spatial And Spectral Quality Evaluation Based On Edges Regions Of\n  Satellite Image Fusion", "comments": "2nd International Conference on Advanced Computing & Communication\n  Technologies (ACCT12),7 -- 8 January 2012", "journal-ref": "International Journal of Latest Technology in\n  Engineering,Management & Applied Science (IJLTEMAS),Vol. I, Issue V, 2012,\n  124-138", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Quality of image fusion is an essential determinant of the value of\nprocessing images fusion for many applications. Spatial and spectral qualities\nare the two important indexes that used to evaluate the quality of any fused\nimage. However, the jury is still out of fused image's benefits if it compared\nwith its original images. In addition, there is a lack of measures for\nassessing the objective quality of the spatial resolution for the fusion\nmethods. Therefore, an objective quality of the spatial resolution assessment\nfor fusion images is required. Most important details of the image are in edges\nregions, but most standards of image estimation do not depend upon specifying\nthe edges in the image and measuring their edges. However, they depend upon the\ngeneral estimation or estimating the uniform region, so this study deals with\nnew method proposed to estimate the spatial resolution by Contrast Statistical\nAnalysis (CSA) depending upon calculating the contrast of the edge, non edge\nregions and the rate for the edges regions. Specifying the edges in the image\nis made by using Soble operator with different threshold values. In addition,\nestimating the color distortion added by image fusion based on Histogram\nAnalysis of the edge brightness values of all RGB-color bands and Lcomponent.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 23:06:38 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Al-Wassai", "Firouz Abdullah", ""], ["Kalyankar", "N. V.", ""], ["Al-Zaky", "Ali A.", ""]]}, {"id": "1207.2268", "submitter": "Imen Chaabouni Masmoudi", "authors": "Imen Chaabouni and Wiem Fourati and Med Salim Bouhlel", "title": "Improvement of ISOM by using filter", "comments": "6 pages, 3 figures, 2 tables; JCSI (May 2012 issue, Volume 9, Issue\n  3) and having paper id IJCSI-2012-9-3-2860", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image compression helps in storing the transmitted data in proficient way by\ndecreasing its redundancy. This technique helps in transferring more digital or\nmultimedia data over internet as it increases the storage space. It is\nimportant to maintain the image quality even if it is compressed to certain\nextent. Depend upon this the image compression is classified into two\ncategories : lossy and lossless image compression. There are many lossy digital\nimage compression techniques exists. Among this Incremental Self Organizing Map\nis a familiar one. The good pictures quality can be retrieved if image\ndenoising technique is used for compression and also provides better\ncompression ratio. Image denoising is an important pre-processing step for many\nimage analysis and computer vision system. It refers to the task of recovering\na good estimate of the true image from a degraded observation without altering\nand changing useful structure in the image such as discontinuities and edges.\nMany approaches have been proposed to remove the noise effectively while\npreserving the original image details and features as much as possible. This\npaper proposes a technique for image compression using Incremental Self\nOrganizing Map (ISOM) with Discret Wavelet Transform (DWT) by applying\nfiltering techniques which play a crucial role in enhancing the quality of a\nreconstructed image. The experimental result shows that the proposed technique\nobtained better compression ratio value.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 08:49:48 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Chaabouni", "Imen", ""], ["Fourati", "Wiem", ""], ["Bouhlel", "Med Salim", ""]]}, {"id": "1207.2346", "submitter": "Rocio Gonzalez-Diaz", "authors": "Rocio Gonalez-Diaz, Javier Lamar, Ronald Umble", "title": "Cups Products in Z2-Cohomology of 3D Polyhedral Complexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $I=(\\mathbb{Z}^3,26,6,B)$ be a 3D digital image, let $Q(I)$ be the\nassociated cubical complex and let $\\partial Q(I)$ be the subcomplex of $Q(I)$\nwhose maximal cells are the quadrangles of $Q(I)$ shared by a voxel of $B$ in\nthe foreground -- the object under study -- and by a voxel of\n$\\mathbb{Z}^3\\smallsetminus B$ in the background -- the ambient space. We show\nhow to simplify the combinatorial structure of $\\partial Q(I)$ and obtain a 3D\npolyhedral complex $P(I)$ homeomorphic to $\\partial Q(I)$ but with fewer cells.\nWe introduce an algorithm that computes cup products on\n$H^*(P(I);\\mathbb{Z}_2)$ directly from the combinatorics. The computational\nmethod introduced here can be effectively applied to any polyhedral complex\nembedded in $\\mathbb{R}^3$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 13:40:40 GMT"}, {"version": "v2", "created": "Mon, 20 May 2013 18:40:34 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2013 21:18:05 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Gonalez-Diaz", "Rocio", ""], ["Lamar", "Javier", ""], ["Umble", "Ronald", ""]]}, {"id": "1207.2422", "submitter": "David Wipf", "authors": "David Wipf, Yi Wu", "title": "Dual-Space Analysis of the Sparse Linear Model", "comments": "9 pages, 2 figures, submission to NIPS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear (or generalized linear) models combine a standard likelihood\nfunction with a sparse prior on the unknown coefficients. These priors can\nconveniently be expressed as a maximization over zero-mean Gaussians with\ndifferent variance hyperparameters. Standard MAP estimation (Type I) involves\nmaximizing over both the hyperparameters and coefficients, while an empirical\nBayesian alternative (Type II) first marginalizes the coefficients and then\nmaximizes over the hyperparameters, leading to a tractable posterior\napproximation. The underlying cost functions can be related via a dual-space\nframework from Wipf et al. (2011), which allows both the Type I or Type II\nobjectives to be expressed in either coefficient or hyperparmeter space. This\nperspective is useful because some analyses or extensions are more conducive to\ndevelopment in one space or the other. Herein we consider the estimation of a\ntrade-off parameter balancing sparsity and data fit. As this parameter is\neffectively a variance, natural estimators exist by assessing the problem in\nhyperparameter (variance) space, transitioning natural ideas from Type II to\nsolve what is much less intuitive for Type I. In contrast, for analyses of\nupdate rules and sparsity properties of local and global solutions, as well as\nextensions to more general likelihood models, we can leverage coefficient-space\ntechniques developed for Type I and apply them to Type II. For example, this\nallows us to prove that Type II-inspired techniques can be successful\nrecovering sparse coefficients when unfavorable restricted isometry properties\n(RIP) lead to failure of popular L1 reconstructions. It also facilitates the\nanalysis of Type II when non-Gaussian likelihood models lead to intractable\nintegrations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 17:38:18 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Wipf", "David", ""], ["Wu", "Yi", ""]]}, {"id": "1207.2426", "submitter": "Issam Qaffou", "authors": "Issam Qaffou, Mohammed Sadgal, Abdelaziz Elfazziki", "title": "A Multi-Agents Architecture to Learn Vision Operators and their\n  Parameters", "comments": "IJCSI, May 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In a vision system, every task needs that the operators to apply should be\n{\\guillemotleft} well chosen {\\guillemotright} and their parameters should be\nalso {\\guillemotleft} well adjusted {\\guillemotright}. The diversity of\noperators and the multitude of their parameters constitute a big challenge for\nusers. As it is very difficult to make the {\\guillemotleft} right\n{\\guillemotright} choice, lack of a specific rule, many disadvantages appear\nand affect the computation time and especially the quality of results. In this\npaper we present a multi-agent architecture to learn the best operators to\napply and their best parameters for a class of images. Our architecture\nconsists of three types of agents: User Agent, Operator Agent and Parameter\nAgent. The User Agent determines the phases of treatment, a library of\noperators and the possible values of their parameters. The Operator Agent\nconstructs all possible combinations of operators and the Parameter Agent, the\ncore of the architecture, adjusts the parameters of each combination by\ntreating a large number of images. Through the reinforcement learning\nmechanism, our architecture does not consider only the system opportunities but\nalso the user preferences.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 17:56:00 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Qaffou", "Issam", ""], ["Sadgal", "Mohammed", ""], ["Elfazziki", "Abdelaziz", ""]]}, {"id": "1207.2440", "submitter": "David Wipf", "authors": "David Wipf", "title": "Non-Convex Rank Minimization via an Empirical Bayesian Approach", "comments": "10 pages, 6 figures, UAI 2012 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications that require matrix solutions of minimal rank, the\nunderlying cost function is non-convex leading to an intractable, NP-hard\noptimization problem. Consequently, the convex nuclear norm is frequently used\nas a surrogate penalty term for matrix rank. The problem is that in many\npractical scenarios there is no longer any guarantee that we can correctly\nestimate generative low-rank matrices of interest, theoretical special cases\nnotwithstanding. Consequently, this paper proposes an alternative empirical\nBayesian procedure build upon a variational approximation that, unlike the\nnuclear norm, retains the same globally minimizing point estimate as the rank\nfunction under many useful constraints. However, locally minimizing solutions\nare largely smoothed away via marginalization, allowing the algorithm to\nsucceed when standard convex relaxations completely fail. While the proposed\nmethodology is generally applicable to a wide range of low-rank applications,\nwe focus our attention on the robust principal component analysis problem\n(RPCA), which involves estimating an unknown low-rank matrix with unknown\nsparse corruptions. Theoretical and empirical evidence are presented to show\nthat our method is potentially superior to related MAP-based approaches, for\nwhich the convex principle component pursuit (PCP) algorithm (Candes et al.,\n2011) can be viewed as a special case.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 18:41:04 GMT"}], "update_date": "2012-07-11", "authors_parsed": [["Wipf", "David", ""]]}, {"id": "1207.2488", "submitter": "Mehrdad Gangeh", "authors": "Mehrdad J. Gangeh, Ali Ghodsi, Mohamed S. Kamel", "title": "Kernelized Supervised Dictionary Learning", "comments": "This paper has been withdrawn by the author as it has been already\n  published by the IEEE Trans. on Signal Processing and is now available online", "journal-ref": null, "doi": "10.1109/TSP.2013.2274276", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose supervised dictionary learning (SDL) by\nincorporating information on class labels into the learning of the dictionary.\nTo this end, we propose to learn the dictionary in a space where the dependency\nbetween the signals and their corresponding labels is maximized. To maximize\nthis dependency, the recently introduced Hilbert Schmidt independence criterion\n(HSIC) is used. One of the main advantages of this novel approach for SDL is\nthat it can be easily kernelized by incorporating a kernel, particularly a\ndata-derived kernel such as normalized compression distance, into the\nformulation. The learned dictionary is compact and the proposed approach is\nfast. We show that it outperforms other unsupervised and supervised dictionary\nlearning approaches in the literature, using real-world data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 20:52:46 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2012 17:44:27 GMT"}, {"version": "v3", "created": "Fri, 10 May 2013 17:57:55 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2013 17:29:04 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Gangeh", "Mehrdad J.", ""], ["Ghodsi", "Ali", ""], ["Kamel", "Mohamed S.", ""]]}, {"id": "1207.2537", "submitter": "Amrita Biswas Mrs", "authors": "Sambhunath Biswas and Amrita Biswas", "title": "Face Recognition Algorithms based on Transformed Shape Features", "comments": "7 pages", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 3, No 3, May 2012,pg 445-451", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human face recognition is, indeed, a challenging task, especially under the\nillumination and pose variations. We examine in the present paper effectiveness\nof two simple algorithms using coiflet packet and Radon transforms to recognize\nhuman faces from some databases of still gray level images, under the\nenvironment of illumination and pose variations. Both the algorithms convert\n2-D gray level training face images into their respective depth maps or\nphysical shape which are subsequently transformed by Coiflet packet and Radon\ntransforms to compute energy for feature extraction. Experiments show that such\ntransformed shape features are robust to illumination and pose variations. With\nthe features extracted, training classes are optimally separated through linear\ndiscriminant analysis (LDA), while classification for test face images is made\nthrough a k-NN classifier, based on L1 norm and Mahalanobis distance measures.\nProposed algorithms are then tested on face images that differ in\nillumination,expression or pose separately, obtained from three\ndatabases,namely, ORL, Yale and Essex-Grimace databases. Results, so obtained,\nare compared with two different existing algorithms.Performance using\nDaubechies wavelets is also examined. It is seen that the proposed Coiflet\npacket and Radon transform based algorithms have significant performance,\nespecially under different illumination conditions and pose variation.\nComparison shows the proposed algorithms are superior.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 03:45:18 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Biswas", "Sambhunath", ""], ["Biswas", "Amrita", ""]]}, {"id": "1207.2597", "submitter": "Saket Warade Mr.", "authors": "Saket Warade, Jagannath Aghav, Petitpierre Claude, Sandeep Udayagiri", "title": "Automated Training and Maintenance through Kinect", "comments": "14 pages, 5 figures, 1 Algorithm", "journal-ref": "Warades, S; Aghav, J; Claude, P; Udayagiri, S;,\"Automated Training\n  and Maintenance through Kinect,\"International Journal of Computer Science,\n  Engineering and Applications (IJCSEA) Vol.2, No.3, June 2012", "doi": "10.5121/ijcsea.2012.2315", "report-no": null, "categories": "cs.CV cs.ET cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have worked on reducing burden on mechanic involving\ncomplex automobile maintenance activities that are performed in centralised\nworkshops. We have presented a system prototype that combines Augmented Reality\nwith Kinect. With the use of Kinect, very high quality sensors are available at\nconsiderably low costs, thus reducing overall expenditure for system design.\nThe system can be operated either in Speech mode or in Gesture mode. The system\ncan be controlled by various audio commands if user opts for Speech mode. The\nsame controlling can also be done by using a set of Gestures in Gesture mode.\n  Gesture recognition is the task performed by Kinect system. This system,\nbundled with RGB and Depth camera, processes the skeletal data by keeping track\nof 20 different body joints. Recognizing Gestures is done by verifying user\nmovements and checking them against predefined condition. Augmented Reality\nmodule captures real-time image data streams from high resolution camera. This\nmodule then generates 3D model that is superimposed on real time data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 11:17:28 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Warade", "Saket", ""], ["Aghav", "Jagannath", ""], ["Claude", "Petitpierre", ""], ["Udayagiri", "Sandeep", ""]]}, {"id": "1207.2600", "submitter": "Sokyna Alqatawneh Dr", "authors": "Sokyna Qatawneh, Afaf Alneaimi, Thamer Rawashdeh, Mmohammad Muhairat,\n  Rami Qahwaji and Stan Ipson", "title": "Efficient Prediction of DNA-Binding Proteins Using Machine Learning", "comments": null, "journal-ref": "S. Qatawneh, A. Alneaimi, Th. Rawashdeh, M. Muhairat, R. Qahwaji\n  and S. Ipson,\"Efficient Prediction of DNA-Binding Proteins using Machine\n  Learning\", International Journal on Bioinformatics & Biosciences (IJBB)\n  Vol.2, No.2, June 2012", "doi": null, "report-no": null, "categories": "cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA-binding proteins are a class of proteins which have a specific or general\naffinity to DNA and include three important components: transcription factors;\nnucleases, and histones. DNA-binding proteins also perform important roles in\nmany types of cellular activities. In this paper we describe machine learning\nsystems for the prediction of DNA- binding proteins where a Support Vector\nMachine and a Cascade Correlation Neural Network are optimized and then\ncompared to determine the learning algorithm that achieves the best prediction\nperformance. The information used for classification is derived from\ncharacteristics that include overall charge, patch size and amino acids\ncomposition. In total 121 DNA- binding proteins and 238 non-binding proteins\nare used to build and evaluate the system. For SVM using the ANOVA Kernel with\nJack-knife evaluation, an accuracy of 86.7% has been achieved with 91.1% for\nsensitivity and 85.3% for specificity. For CCNN optimized over the entire\ndataset with Jack knife evaluation we report an accuracy of 75.4%, while the\nvalues of specificity and sensitivity achieved were 72.3% and 82.6%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 11:28:57 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Qatawneh", "Sokyna", ""], ["Alneaimi", "Afaf", ""], ["Rawashdeh", "Thamer", ""], ["Muhairat", "Mmohammad", ""], ["Qahwaji", "Rami", ""], ["Ipson", "Stan", ""]]}, {"id": "1207.2602", "submitter": "Seyed Amir Mohammadi Mr", "authors": "Seyed Amir Mohammadi and Mohammad Reza Mahzoun", "title": "A Novel Approach Coloured Object Tracker with Adaptive Model and\n  Bandwidth using Mean Shift Algorithm", "comments": "15 pages,7 figures, 2 graph, 1 tabel, journal", "journal-ref": "Signal & Image Processing : An International Journal(SIPIJ),\n  Volume 3, Number 3, June 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional color-based mean-shift tracking algorithm is popular among\ntracking methods due to its simple and efficient procedure, however, the lack\nof dynamism in its target model makes it unsuitable for tracking objects which\nhave changes in their sizes and shapes. In this paper, we propose a fast novel\nthreephase colored object tracker algorithm based on mean shift idea while\nutilizing adaptive model. The proposed method can improve the mentioned\nweaknesses of the original mean-shift algorithm. The experimental results show\nthat the new method is feasible, robust and has acceptable speed in comparison\nwith other algorithms.15 page,\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 11:29:36 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Mohammadi", "Seyed Amir", ""], ["Mahzoun", "Mohammad Reza", ""]]}, {"id": "1207.2641", "submitter": "Zeno Geradts", "authors": "Teun Baar, Wiger van Houten, Zeno Geradts", "title": "Camera identification by grouping images from database, based on shared\n  noise patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research showed that camera specific noise patterns, so-called\nPRNU-patterns, are extracted from images and related images could be found. In\nthis particular research the focus is on grouping images from a database, based\non a shared noise pattern as an identification method for cameras. Using the\nmethod as described in this article, groups of images, created using the same\ncamera, could be linked from a large database of images. Using MATLAB\nprogramming, relevant image noise patterns are extracted from images much\nquicker than common methods by the use of faster noise extraction filters and\nimprovements to reduce the calculation costs. Relating noise patterns, with a\ncorrelation above a certain threshold value, can quickly be matched. Hereby,\nfrom a database of images, groups of relating images could be linked and the\nmethod could be used to scan a large number of images for suspect noise\npatterns.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 13:58:35 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2012 08:42:34 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Baar", "Teun", ""], ["van Houten", "Wiger", ""], ["Geradts", "Zeno", ""]]}, {"id": "1207.2922", "submitter": "Surbhi", "authors": "Surbhi, Vishal Arora", "title": "ROI Segmentation for Feature Extraction from Human Facial Images", "comments": "4 pages, 2 figures; International Journal of Research in Computer\n  Science, pp. 61-64 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Computer Interaction (HCI) is the biggest goal of computer vision\nresearchers. Features form the different facial images are able to provide a\nvery deep knowledge about the activities performed by the different facial\nmovements. In this paper we presented a technique for feature extraction from\nvarious regions of interest with the help of Skin color segmentation technique,\nThresholding, knowledge based technique for face recognition.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 11:11:35 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Surbhi", "", ""], ["Arora", "Vishal", ""]]}, {"id": "1207.3056", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal N. Chaudhury, Amit Singer", "title": "Non-Local Euclidean Medians", "comments": "6 figures, 1 table", "journal-ref": "IEEE Signal Processing Letters, vol. 19(11), pp. 745 - 748, 2012", "doi": "10.1109/LSP.2012.2217329", "report-no": null, "categories": "cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we note that the denoising performance of Non-Local Means\n(NLM) at large noise levels can be improved by replacing the mean by the\nEuclidean median. We call this new denoising algorithm the Non-Local Euclidean\nMedians (NLEM). At the heart of NLEM is the observation that the median is more\nrobust to outliers than the mean. In particular, we provide a simple geometric\ninsight that explains why NLEM performs better than NLM in the vicinity of\nedges, particularly at large noise levels. NLEM can be efficiently implemented\nusing iteratively reweighted least squares, and its computational complexity is\ncomparable to that of NLM. We provide some preliminary results to study the\nproposed algorithm and to compare it with NLM.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 18:39:10 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2012 21:25:51 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Chaudhury", "Kunal N.", ""], ["Singer", "Amit", ""]]}, {"id": "1207.3071", "submitter": "Mehrdad Gangeh", "authors": "Mehrdad J. Gangeh, Ali Ghodsi, and Mohamed S. Kamel", "title": "Supervised Texture Classification Using a Novel Compression-Based\n  Similarity Measure", "comments": "This paper has been withdrawn by the author since it has already been\n  appeared in the proceedings of International Conference on Computer vision\n  and Graphics (ICCVG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised pixel-based texture classification is usually performed in the\nfeature space. We propose to perform this task in (dis)similarity space by\nintroducing a new compression-based (dis)similarity measure. The proposed\nmeasure utilizes two dimensional MPEG-1 encoder, which takes into consideration\nthe spatial locality and connectivity of pixels in the images. The proposed\nformulation has been carefully designed based on MPEG encoder functionality. To\nthis end, by design, it solely uses P-frame coding to find the (dis)similarity\namong patches/images. We show that the proposed measure works properly on both\nsmall and large patch sizes. Experimental results show that the proposed\napproach significantly improves the performance of supervised pixel-based\ntexture classification on Brodatz and outdoor images compared to other\ncompression-based dissimilarity measures as well as approaches performed in\nfeature space. It also improves the computation speed by about 40% compared to\nits rivals.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 19:37:13 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 17:32:56 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Gangeh", "Mehrdad J.", ""], ["Ghodsi", "Ali", ""], ["Kamel", "Mohamed S.", ""]]}, {"id": "1207.3127", "submitter": "Quan Wang", "authors": "Quan Wang, Yan Ou, A. Agung Julius, Kim L. Boyer, Min Jun Kim", "title": "Tracking Tetrahymena Pyriformis Cells using Decision Trees", "comments": "21st International Conference on Pattern Recognition, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.CB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching cells over time has long been the most difficult step in cell\ntracking. In this paper, we approach this problem by recasting it as a\nclassification problem. We construct a feature set for each cell, and compute a\nfeature difference vector between a cell in the current frame and a cell in a\nprevious frame. Then we determine whether the two cells represent the same cell\nover time by training decision trees as our binary classifiers. With the output\nof decision trees, we are able to formulate an assignment problem for our cell\nassociation task and solve it using a modified version of the Hungarian\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 01:22:04 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Wang", "Quan", ""], ["Ou", "Yan", ""], ["Julius", "A. Agung", ""], ["Boyer", "Kim L.", ""], ["Kim", "Min Jun", ""]]}, {"id": "1207.3142", "submitter": "Bing Li", "authors": "Bing Li, Weihua Xiong, Weiming Hu", "title": "Color Constancy based on Image Similarity via Bilayer Sparse Coding", "comments": "14pages, 2figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational color constancy is a very important topic in computer vision\nand has attracted many researchers' attention. Recently, lots of research has\nshown the effects of high level visual content information for illumination\nestimation. However, all of these existing methods are essentially\ncombinational strategies in which image's content analysis is only used to\nguide the combination or selection from a variety of individual illumination\nestimation methods. In this paper, we propose a novel bilayer sparse coding\nmodel for illumination estimation that considers image similarity in terms of\nboth low level color distribution and high level image scene content\nsimultaneously. For the purpose, the image's scene content information is\nintegrated with its color distribution to obtain optimal illumination\nestimation model. The experimental results on two real-world image sets show\nthat our algorithm is superior to other prevailing illumination estimation\nmethods, even better than combinational methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 04:46:19 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2012 06:36:29 GMT"}], "update_date": "2012-11-09", "authors_parsed": [["Li", "Bing", ""], ["Xiong", "Weihua", ""], ["Hu", "Weiming", ""]]}, {"id": "1207.3370", "submitter": "Alejandro Frery", "authors": "Talita Perciano, Matthew Urban, Nelson D. A. Mascarenhas, Mostafa\n  Fatemi, Alejandro C. Frery, Glauber T. Silva", "title": "Deconvolution of vibroacoustic images using a simulation model based on\n  a three dimensional point spread function", "comments": "Accepted for publication in Ultrasonics", "journal-ref": null, "doi": "10.1016/j.ultras.2012.03.011", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vibro-acoustography (VA) is a medical imaging method based on the\ndifference-frequency generation produced by the mixture of two focused\nultrasound beams. VA has been applied to different problems in medical imaging\nsuch as imaging bones, microcalcifications in the breast, mass lesions, and\ncalcified arteries. The obtained images may have a resolution of 0.7--0.8 mm.\nCurrent VA systems based on confocal or linear array transducers generate\nC-scan images at the beam focal plane. Images on the axial plane are also\npossible, however the system resolution along depth worsens when compared to\nthe lateral one. Typical axial resolution is about 1.0 cm. Furthermore, the\nelevation resolution of linear array systems is larger than that in lateral\ndirection. This asymmetry degrades C-scan images obtained using linear arrays.\nThe purpose of this article is to study VA image restoration based on a 3D\npoint spread function (PSF) using classical deconvolution algorithms: Wiener,\nconstrained least-squares (CLSs), and geometric mean filters. To assess the\nfilters' performance, we use an image quality index that accounts for\ncorrelation loss, luminance and contrast distortion. Results for simulated VA\nimages show that the quality index achieved with the Wiener filter is 0.9 (1\nindicates perfect restoration). This filter yielded the best result in\ncomparison with the other ones. Moreover, the deconvolution algorithms were\napplied to an experimental VA image of a phantom composed of three stretched\n0.5 mm wires. Experiments were performed using transducer driven at two\nfrequencies, 3075 kHz and 3125 kHz, which resulted in the difference-frequency\nof 50 kHz. Restorations with the theoretical line spread function (LSF) did not\nrecover sufficient information to identify the wires in the images. However,\nusing an estimated LSF the obtained results displayed enough information to\nspot the wires in the images.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 21:37:04 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Perciano", "Talita", ""], ["Urban", "Matthew", ""], ["Mascarenhas", "Nelson D. A.", ""], ["Fatemi", "Mostafa", ""], ["Frery", "Alejandro C.", ""], ["Silva", "Glauber T.", ""]]}, {"id": "1207.3389", "submitter": "Chunhua Shen", "authors": "Xi Li and Anthony Dick and Chunhua Shen and Anton van den Hengel and\n  Hanzi Wang", "title": "Incremental Learning of 3D-DCT Compact Representations for Robust Visual\n  Tracking", "comments": "21 pages. Appearing in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual tracking usually requires an object appearance model that is robust to\nchanging illumination, pose and other factors encountered in video. In this\npaper, we construct an appearance model using the 3D discrete cosine transform\n(3D-DCT). The 3D-DCT is based on a set of cosine basis functions, which are\ndetermined by the dimensions of the 3D signal and thus independent of the input\nvideo data. In addition, the 3D-DCT can generate a compact energy spectrum\nwhose high-frequency coefficients are sparse if the appearance samples are\nsimilar. By discarding these high-frequency coefficients, we simultaneously\nobtain a compact 3D-DCT based object representation and a signal\nreconstruction-based similarity measure (reflecting the information loss from\nsignal reconstruction). To efficiently update the object representation, we\npropose an incremental 3D-DCT algorithm, which decomposes the 3D-DCT into\nsuccessive operations of the 2D discrete cosine transform (2D-DCT) and 1D\ndiscrete cosine transform (1D-DCT) on the input video data.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2012 04:44:17 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2012 07:36:12 GMT"}], "update_date": "2012-07-21", "authors_parsed": [["Li", "Xi", ""], ["Dick", "Anthony", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""], ["Wang", "Hanzi", ""]]}, {"id": "1207.3394", "submitter": "Ali Shadvar", "authors": "Ali Shadvar", "title": "Dimension Reduction by Mutual Information Feature Extraction", "comments": "International Journal of Computer Science & Information Technology\n  (IJCSIT). arXiv admin note: substantial text overlap with arXiv:1206.2058", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  During the past decades, to study high-dimensional data in a large variety of\nproblems, researchers have proposed many Feature Extraction algorithms. One of\nthe most effective approaches for optimal feature extraction is based on mutual\ninformation (MI). However it is not always easy to get an accurate estimation\nfor high dimensional MI. In terms of MI, the optimal feature extraction is\ncreating a feature set from the data which jointly have the largest dependency\non the target class and minimum redundancy. In this paper, a\ncomponent-by-component gradient ascent method is proposed for feature\nextraction which is based on one-dimensional MI estimates. We will refer to\nthis algorithm as Mutual Information Feature Extraction (MIFX). The performance\nof this proposed method is evaluated using UCI databases. The results indicate\nthat MIFX provides a robust performance over different data sets which are\nalmost always the best or comparable to the best ones.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2012 06:13:48 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Shadvar", "Ali", ""]]}, {"id": "1207.3510", "submitter": "Quan Wang", "authors": "Quan Wang", "title": "HMRF-EM-image: Implementation of the Hidden Markov Random Field Model\n  and its Expectation-Maximization Algorithm", "comments": "This work originally appears as the final project of Prof. Birsen\n  Yazici's course Detection and Estimation Theory at RPI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we study the hidden Markov random field (HMRF) model and its\nexpectation-maximization (EM) algorithm. We implement a MATLAB toolbox named\nHMRF-EM-image for 2D image segmentation using the HMRF-EM framework. This\ntoolbox also implements edge-prior-preserving image segmentation, and can be\neasily reconfigured for other problems, such as 3D image segmentation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2012 14:50:17 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2012 22:15:36 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Wang", "Quan", ""]]}, {"id": "1207.3538", "submitter": "Quan Wang", "authors": "Quan Wang", "title": "Kernel Principal Component Analysis and its Applications in Face\n  Recognition and Active Shape Models", "comments": "This work originally appears as the final project of Professor Qiang\n  Ji's course Pattern Recognition at RPI, Troy, NY, USA, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a popular tool for linear\ndimensionality reduction and feature extraction. Kernel PCA is the nonlinear\nform of PCA, which better exploits the complicated spatial structure of\nhigh-dimensional features. In this paper, we first review the basic ideas of\nPCA and kernel PCA. Then we focus on the reconstruction of pre-images for\nkernel PCA. We also give an introduction on how PCA is used in active shape\nmodels (ASMs), and discuss how kernel PCA can be applied to improve traditional\nASMs. Then we show some experimental results to compare the performance of\nkernel PCA and standard PCA for classification problems. We also implement the\nkernel PCA-based ASMs, and use it to construct human face models.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2012 20:28:26 GMT"}, {"version": "v2", "created": "Wed, 23 Apr 2014 03:48:58 GMT"}, {"version": "v3", "created": "Sun, 31 Aug 2014 02:33:17 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Wang", "Quan", ""]]}, {"id": "1207.3554", "submitter": "Akisato Kimura", "authors": "Akisato Kimura, Masashi Sugiyama, Sakano Hitoshi, Hirokazu Kameoka", "title": "Designing various component analysis at will", "comments": "Accepted to IAPR International Conference on Pattern Recognition,\n  submitted to IPSJ Transactions on Mathematical Modeling and its Applications\n  (TOM). Just only one-page abstract for new due to novelty violation for\n  journal submission. The details will be disclosed in late September", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a generic framework of component analysis (CA) methods\nintroducing a new expression for scatter matrices and Gram matrices, called\nGeneralized Pairwise Expression (GPE). This expression is quite compact but\nhighly powerful: The framework includes not only (1) the standard CA methods\nbut also (2) several regularization techniques, (3) weighted extensions, (4)\nsome clustering methods, and (5) their semi-supervised extensions. This paper\nalso presents quite a simple methodology for designing a desired CA method from\nthe proposed framework: Adopting the known GPEs as templates, and generating a\nnew method by combining these templates appropriately.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 00:07:44 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2012 23:45:32 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Kimura", "Akisato", ""], ["Sugiyama", "Masashi", ""], ["Hitoshi", "Sakano", ""], ["Kameoka", "Hirokazu", ""]]}, {"id": "1207.3576", "submitter": "Padmavathi S", "authors": "S. Padmavathi, N. Archana, K. P. Soman", "title": "Hierarchical Approach for Total Variation Digital Image Inpainting", "comments": "7 pages, 7 figures; International Journal of Computer Science,\n  Engineering and Applications (IJCSEA), Voulume 2, Number 3, June 2012, ISSN :\n  2230 - 9616 [Online] ; 2231 - 0088 [Print]", "journal-ref": null, "doi": "10.5121/ijcsea.2012.2316", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The art of recovering an image from damage in an undetectable form is known\nas inpainting. The manual work of inpainting is most often a very time\nconsuming process. Due to digitalization of this technique, it is automatic and\nfaster. In this paper, after the user selects the regions to be reconstructed,\nthe algorithm automatically reconstruct the lost regions with the help of the\ninformation surrounding them. The existing methods perform very well when the\nregion to be reconstructed is very small, but fails in proper reconstruction as\nthe area increases. This paper describes a Hierarchical method by which the\narea to be inpainted is reduced in multiple levels and Total Variation(TV)\nmethod is used to inpaint in each level. This algorithm gives better\nperformance when compared with other existing algorithms such as nearest\nneighbor interpolation, Inpainting through Blurring and Sobolev Inpainting.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 04:51:07 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2013 04:25:46 GMT"}], "update_date": "2013-07-15", "authors_parsed": [["Padmavathi", "S.", ""], ["Archana", "N.", ""], ["Soman", "K. P.", ""]]}, {"id": "1207.3598", "submitter": "Fabian Pedregosa", "authors": "Fabian Pedregosa (INRIA Paris - Rocquencourt, INRIA Saclay - Ile de\n  France), Alexandre Gramfort (INRIA Saclay - Ile de France, LNAO), Ga\\\"el\n  Varoquaux (INRIA Saclay - Ile de France, LNAO), Elodie Cauvet (NEUROSPIN),\n  Christophe Pallier (NEUROSPIN), Bertrand Thirion (INRIA Saclay - Ile de\n  France)", "title": "Learning to rank from medical imaging data", "comments": null, "journal-ref": "MLMI 2012 - 3rd International Workshop on Machine Learning in\n  Medical Imaging (2012)", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images can be used to predict a clinical score coding for the\nseverity of a disease, a pain level or the complexity of a cognitive task. In\nall these cases, the predicted variable has a natural order. While a standard\nclassifier discards this information, we would like to take it into account in\norder to improve prediction performance. A standard linear regression does\nmodel such information, however the linearity assumption is likely not be\nsatisfied when predicting from pixel intensities in an image. In this paper we\naddress these modeling challenges with a supervised learning procedure where\nthe model aims to order or rank images. We use a linear model for its\nrobustness in high dimension and its possible interpretation. We show on\nsimulations and two fMRI datasets that this approach is able to predict the\ncorrect ordering on pairs of images, yielding higher prediction accuracy than\nstandard regression and multiclass classification techniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 08:22:36 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2012 17:04:22 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Pedregosa", "Fabian", "", "INRIA Paris - Rocquencourt, INRIA Saclay - Ile de\n  France"], ["Gramfort", "Alexandre", "", "INRIA Saclay - Ile de France, LNAO"], ["Varoquaux", "Ga\u00ebl", "", "INRIA Saclay - Ile de France, LNAO"], ["Cauvet", "Elodie", "", "NEUROSPIN"], ["Pallier", "Christophe", "", "NEUROSPIN"], ["Thirion", "Bertrand", "", "INRIA Saclay - Ile de\n  France"]]}, {"id": "1207.3603", "submitter": "Hocine Cherifi", "authors": "G\\\"unce Orman (Le2i), Vincent Labatut (BIT Lab), Hocine Cherifi (Le2i)", "title": "Qualitative Comparison of Community Detection Algorithms", "comments": "DICTAP 2011, The International Conference on Digital Information and\n  Communication Technology and its Applications, Dijon : France (2011)", "journal-ref": "Communications in Computer and Information Science, 167:265-279,\n  2011", "doi": "10.1007/978-3-642-22027-2_23", "report-no": null, "categories": "cs.SI cs.CV physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is a very active field in complex networks analysis,\nconsisting in identifying groups of nodes more densely interconnected\nrelatively to the rest of the network. The existing algorithms are usually\ntested and compared on real-world and artificial networks, their performance\nbeing assessed through some partition similarity measure. However, artificial\nnetworks realism can be questioned, and the appropriateness of those measures\nis not obvious. In this study, we take advantage of recent advances concerning\nthe characterization of community structures to tackle these questions. We\nfirst generate networks thanks to the most realistic model available to date.\nTheir analysis reveals they display only some of the properties observed in\nreal-world community structures. We then apply five community detection\nalgorithms on these networks and find out the performance assessed\nquantitatively does not necessarily agree with a qualitative analysis of the\nidentified communities. It therefore seems both approaches should be applied to\nperform a relevant comparison of the algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 08:49:05 GMT"}], "update_date": "2012-08-16", "authors_parsed": [["Orman", "G\u00fcnce", "", "Le2i"], ["Labatut", "Vincent", "", "BIT Lab"], ["Cherifi", "Hocine", "", "Le2i"]]}, {"id": "1207.3607", "submitter": "Hocine Cherifi", "authors": "Can Demirkesen (BIT Lab, LJK), Hocine Cherifi (BIT Lab, Le2i)", "title": "Fusing image representations for classification using support vector\n  machines", "comments": "Image and Vision Computing New Zealand, 2009. IVCNZ '09. 24th\n  International Conference, Wellington : Nouvelle-Z\\'elande (2009)", "journal-ref": null, "doi": "10.1109/IVCNZ.2009.5378367", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to improve classification accuracy different image representations\nare usually combined. This can be done by using two different fusing schemes.\nIn feature level fusion schemes, image representations are combined before the\nclassification process. In classifier fusion, the decisions taken separately\nbased on individual representations are fused to make a decision. In this paper\nthe main methods derived for both strategies are evaluated. Our experimental\nresults show that classifier fusion performs better. Specifically Bayes belief\nintegration is the best performing strategy for image classification task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 09:23:06 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Demirkesen", "Can", "", "BIT Lab, LJK"], ["Cherifi", "Hocine", "", "BIT Lab, Le2i"]]}, {"id": "1207.3809", "submitter": "Julian McAuley", "authors": "Julian McAuley and Jure Leskovec", "title": "Image Labeling on a Network: Using Social-Network Metadata for Image\n  Classification", "comments": "ECCV 2012; 14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale image retrieval benchmarks invariably consist of images from the\nWeb. Many of these benchmarks are derived from online photo sharing networks,\nlike Flickr, which in addition to hosting images also provide a highly\ninteractive social community. Such communities generate rich metadata that can\nnaturally be harnessed for image classification and retrieval. Here we study\nfour popular benchmark datasets, extending them with social-network metadata,\nsuch as the groups to which each image belongs, the comment thread associated\nwith the image, who uploaded it, their location, and their network of friends.\nSince these types of data are inherently relational, we propose a model that\nexplicitly accounts for the interdependencies between images sharing common\nproperties. We model the task as a binary labeling problem on a network, and\nuse structured learning techniques to learn model parameters. We find that\nsocial-network metadata are useful in a variety of classification tasks, in\nmany cases outperforming methods based on image content.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 20:04:12 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["McAuley", "Julian", ""], ["Leskovec", "Jure", ""]]}, {"id": "1207.3944", "submitter": "Alejandro Frery", "authors": "Alejandro C. Frery and Julio Jacobo-Berlles and Juliana Gambini and\n  Marta Mejail", "title": "Polarimetric SAR Image Segmentation with B-Splines and a New Statistical\n  Model", "comments": null, "journal-ref": "Multidimensional Systems and Signal Processing, vol. 21, 319-342,\n  2010", "doi": "10.1007/s11045-010-0113-4", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for polarimetric Synthetic Aperture Radar (SAR) image\nregion boundary detection based on the use of B-Spline active contours and a\nnew model for polarimetric SAR data: the GHP distribution. In order to detect\nthe boundary of a region, initial B-Spline curves are specified, either\nautomatically or manually, and the proposed algorithm uses a deformable\ncontours technique to find the boundary. In doing this, the parameters of the\npolarimetric GHP model for the data are estimated, in order to find the\ntransition points between the region being segmented and the surrounding area.\nThis is a local algorithm since it works only on the region to be segmented.\nResults of its performance are presented.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 11:09:37 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Frery", "Alejandro C.", ""], ["Jacobo-Berlles", "Julio", ""], ["Gambini", "Juliana", ""], ["Mejail", "Marta", ""]]}, {"id": "1207.3962", "submitter": "Ludmila Scharf", "authors": "Helmut Alt and Ludmila Scharf", "title": "Computation of the Hausdorff distance between sets of line segments in\n  parallel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Hausdorff distance for two sets of non-intersecting line\nsegments can be computed in parallel in $O(\\log^2 n)$ time using O(n)\nprocessors in a CREW-PRAM computation model. We discuss how some parts of the\nsequential algorithm can be performed in parallel using previously known\nparallel algorithms; and identify the so-far unsolved part of the problem for\nthe parallel computation, which is the following: Given two sets of\n$x$-monotone curve segments, red and blue, for each red segment find its\nextremal intersection points with the blue set, i.e. points with the minimal\nand maximal $x$-coordinate. Each segment set is assumed to be intersection\nfree. For this intersection problem we describe a parallel algorithm which\ncompletes the Hausdorff distance computation within the stated time and\nprocessor bounds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 11:58:08 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Alt", "Helmut", ""], ["Scharf", "Ludmila", ""]]}, {"id": "1207.4089", "submitter": "Mehrdad Gangeh", "authors": "Mehrdad J. Gangeh, Robert P. W. Duin, Bart M. ter Haar Romeny, Mohamed\n  S. Kamel", "title": "A Two-Stage Combined Classifier in Scale Space Texture Classification", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textures often show multiscale properties and hence multiscale techniques are\nconsidered useful for texture analysis. Scale-space theory as a biologically\nmotivated approach may be used to construct multiscale textures. In this paper\nvarious ways are studied to combine features on different scales for texture\nclassification of small image patches. We use the N-jet of derivatives up to\nthe second order at different scales to generate distinct pattern\nrepresentations (DPR) of feature subsets. Each feature subset in the DPR is\ngiven to a base classifier (BC) of a two-stage combined classifier. The\ndecisions made by these BCs are combined in two stages over scales and\nderivatives. Various combining systems and their significances and differences\nare discussed. The learning curves are used to evaluate the performances. We\nfound for small sample sizes combining classifiers performs significantly\nbetter than combining feature spaces (CFS). It is also shown that combining\nclassifiers performs better than the support vector machine on CFS in\nmultiscale texture classification.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 19:05:18 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Gangeh", "Mehrdad J.", ""], ["Duin", "Robert P. W.", ""], ["Romeny", "Bart M. ter Haar", ""], ["Kamel", "Mohamed S.", ""]]}, {"id": "1207.4129", "submitter": "Dragomir Anguelov", "authors": "Dragomir Anguelov, Daphne Koller, Hoi-Cheung Pang, Praveen Srinivasan,\n  Sebastian Thrun", "title": "Recovering Articulated Object Models from 3D Range Data", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-18-26", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised learning of complex articulated object\nmodels from 3D range data. We describe an algorithm whose input is a set of\nmeshes corresponding to different configurations of an articulated object. The\nalgorithm automatically recovers a decomposition of the object into\napproximately rigid parts, the location of the parts in the different object\ninstances, and the articulated object skeleton linking the parts. Our algorithm\nfirst registers allthe meshes using an unsupervised non-rigid technique\ndescribed in a companion paper. It then segments the meshes using a graphical\nmodel that captures the spatial contiguity of parts. The segmentation is done\nusing the EM algorithm, iterating between finding a decomposition of the object\ninto rigid parts, and finding the location of the parts in the object\ninstances. Although the graphical model is densely connected, the object\ndecomposition step can be performed optimally and efficiently, allowing us to\nidentify a large number of object parts while avoiding local maxima. We\ndemonstrate the algorithm on real world datasets, recovering a 15-part\narticulated model of a human puppet from just 7 different puppet\nconfigurations, as well as a 4 part model of a fiexing arm where significant\nnon-rigid deformation was present.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:48:13 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Anguelov", "Dragomir", ""], ["Koller", "Daphne", ""], ["Pang", "Hoi-Cheung", ""], ["Srinivasan", "Praveen", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1207.4179", "submitter": "Nebojsa Jojic", "authors": "Nebojsa Jojic, Yaron Caspi, Manuel Reyes-Gomez", "title": "Probabilistic index maps for modeling natural signals", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-293-300", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major problems in modeling natural signals is that signals with\nvery similar structure may locally have completely different measurements,\ne.g., images taken under different illumination conditions, or the speech\nsignal captured in different environments. While there have been many\nsuccessful attempts to address these problems in application-specific settings,\nwe believe that underlying a large set of problems in signal representation is\na representational deficiency of intensity-derived local measurements that are\nthe basis of most efficient models. We argue that interesting structure in\nsignals is better captured when the signal is de- fined as a matrix whose\nentries are discrete indices to a separate palette of possible measurements. In\norder to model the variability in signal structure, we define a signal class\nnot by a single index map, but by a probability distribution over the index\nmaps, which can be estimated from the data, and which we call probabilistic\nindex maps. The existing algorithm can be adapted to work with this\nrepresentation. Furthermore, the probabilistic index map representation leads\nto algorithms with computational costs proportional to either the size of the\npalette or the log of the size of the palette, making the cost of significantly\nincreased invariance to non-structural changes quite bearable. We illustrate\nthe benefits of the probabilistic index map representation in several\napplications in computer vision and speech processing.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 19:47:14 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Jojic", "Nebojsa", ""], ["Caspi", "Yaron", ""], ["Reyes-Gomez", "Manuel", ""]]}, {"id": "1207.4259", "submitter": "Mohammad  Nabil Almunawar Dr", "authors": "Mohammad Nabil Almunawar", "title": "Content Based Multimedia Information Retrieval to Support Digital\n  Libraries", "comments": "15 pages, conference paper", "journal-ref": "International Conference on New Information Technologies, 23-26\n  July, 2001, Brunei Darussalam", "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-based multimedia information retrieval is an interesting research\narea since it allows retrieval based on inherent characteristic of multimedia\nobjects. For example retrieval based on visual characteristics such as colour,\nshapes or textures of objects in images or retrieval based on spatial\nrelationships among objects in the media (images or video clips). This paper\nreviews some work done in image and video retrieval and then proposes an\nintegrated model that can handle images and video clips uniformly. Using this\nmodel retrieval on images or video clips can be done based on the same\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 04:11:55 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Almunawar", "Mohammad Nabil", ""]]}, {"id": "1207.4308", "submitter": "Alejandro Frery", "authors": "Maria E. Buemi, Marta Mejail, Julio Jacobo, Alejandro C. Frery and\n  Heitor S. Ramos", "title": "Assessment of SAR Image Filtering using Adaptive Stack Filters", "comments": null, "journal-ref": "Proceedings 16th Iberoamerican Congress on Pattern Recognition\n  (CIARP 2011), Lecture Notes in Computer Science vol. 7042, p. 89--96", "doi": "10.1007/978-3-642-25085-9_10", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stack filters are a special case of non-linear filters. They have a good\nperformance for filtering images with different types of noise while preserving\nedges and details. A stack filter decomposes an input image into several binary\nimages according to a set of thresholds. Each binary image is then filtered by\na Boolean function, which characterizes the filter. Adaptive stack filters can\nbe designed to be optimal; they are computed from a pair of images consisting\nof an ideal noiseless image and its noisy version. In this work we study the\nperformance of adaptive stack filters when they are applied to Synthetic\nAperture Radar (SAR) images. This is done by evaluating the quality of the\nfiltered images through the use of suitable image quality indexes and by\nmeasuring the classification accuracy of the resulting images.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 09:16:07 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Buemi", "Maria E.", ""], ["Mejail", "Marta", ""], ["Jacobo", "Julio", ""], ["Frery", "Alejandro C.", ""], ["Ramos", "Heitor S.", ""]]}, {"id": "1207.4417", "submitter": "Jingwei  Liu", "authors": "Jingwei Liu, Meizhi Xu", "title": "Penalty Constraints and Kernelization of M-Estimation Based Fuzzy\n  C-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework of M-estimation based fuzzy C-means clustering (MFCM) algorithm\nis proposed with iterative reweighted least squares (IRLS) algorithm, and\npenalty constraint and kernelization extensions of MFCM algorithms are also\ndeveloped. Introducing penalty information to the object functions of MFCM\nalgorithms, the spatially constrained fuzzy C-means (SFCM) is extended to\npenalty constraints MFCM algorithms(abbr. pMFCM).Substituting the Euclidean\ndistance with kernel method, the MFCM and pMFCM algorithms are extended to\nkernelized MFCM (abbr. KMFCM) and kernelized pMFCM (abbr.pKMFCM) algorithms.\nThe performances of MFCM, pMFCM, KMFCM and pKMFCM algorithms are evaluated in\nthree tasks: pattern recognition on 10 standard data sets from UCI Machine\nLearning databases, noise image segmentation performances on a synthetic image,\na magnetic resonance brain image (MRI), and image segmentation of a standard\nimages from Berkeley Segmentation Dataset and Benchmark. The experimental\nresults demonstrate the effectiveness of our proposed algorithms in pattern\nrecognition and image segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 17:20:32 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2013 10:33:02 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Liu", "Jingwei", ""], ["Xu", "Meizhi", ""]]}, {"id": "1207.5007", "submitter": "Madhur Srivastava", "authors": "Madhur Srivastava, Yashwant Yashu, Satish K. Singh, Prasanta K.\n  Panigrahi", "title": "Multisegmentation through wavelets: Comparing the efficacy of Daubechies\n  vs Coiflets", "comments": "4 pages", "journal-ref": "Proceedings in Signal Processing and Real Time Operating System (\n  SPRTOS), March 26 - 27 , 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we carry out a comparative study of the efficacy of wavelets\nbelonging to Daubechies and Coiflet family in achieving image segmentation\nthrough a fast statistical algorithm.The fact that wavelets belonging to\nDaubechies family optimally capture the polynomial trends and those of Coiflet\nfamily satisfy mini-max condition, makes this comparison interesting. In the\ncontext of the present algorithm, it is found that the performance of Coiflet\nwavelets is better, as compared to Daubechies wavelet.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 17:37:27 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Srivastava", "Madhur", ""], ["Yashu", "Yashwant", ""], ["Singh", "Satish K.", ""], ["Panigrahi", "Prasanta K.", ""]]}, {"id": "1207.5064", "submitter": "Firouz Wassai", "authors": "Firouz Abdullah Al-Wassai and Dr. N.V. Kalyankar", "title": "A Novel Metric Approach Evaluation For The Spatial Enhancement Of\n  Pan-Sharpened Images", "comments": "arXiv admin note: substantial text overlap with arXiv:1110.4970", "journal-ref": "International Conference of Advanced Computer Science &\n  Information Technology (ACSIT-2012),July 15, 2012, Chennai, India", "doi": "10.5121/csit.2012.2347", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various and different methods can be used to produce high-resolution\nmultispectral images from high-resolution panchromatic image (PAN) and\nlow-resolution multispectral images (MS), mostly on the pixel level. The\nQuality of image fusion is an essential determinant of the value of processing\nimages fusion for many applications. Spatial and spectral qualities are the two\nimportant indexes that used to evaluate the quality of any fused image.\nHowever, the jury is still out of fused image's benefits if it compared with\nits original images. In addition, there is a lack of measures for assessing the\nobjective quality of the spatial resolution for the fusion methods. So, an\nobjective quality of the spatial resolution assessment for fusion images is\nrequired. Therefore, this paper describes a new approach proposed to estimate\nthe spatial resolution improve by High Past Division Index (HPDI) upon\ncalculating the spatial-frequency of the edge regions of the image and it deals\nwith a comparison of various analytical techniques for evaluating the Spatial\nquality, and estimating the colour distortion added by image fusion including:\nMG, SG, FCC, SD, En, SNR, CC and NRMSE. In addition, this paper devotes to\nconcentrate on the comparison of various image fusion techniques based on pixel\nand feature fusion technique.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 21:30:35 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Al-Wassai", "Firouz Abdullah", ""], ["Kalyankar", "Dr. N. V.", ""]]}, {"id": "1207.5113", "submitter": "Junyan Wang", "authors": "Junyan Wang and Kap Luk Chan", "title": "Piecewise Linear Patch Reconstruction for Segmentation and Description\n  of Non-smooth Image Structures", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2013.2274385", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper, we propose a unified energy minimization model for the\nsegmentation of non-smooth image structures. The energy of piecewise linear\npatch reconstruction is considered as an objective measure of the quality of\nthe segmentation of non-smooth structures. The segmentation is achieved by\nminimizing the single energy without any separate process of feature\nextraction. We also prove that the error of segmentation is bounded by the\nproposed energy functional, meaning that minimizing the proposed energy leads\nto reducing the error of segmentation. As a by-product, our method produces a\ndictionary of optimized orthonormal descriptors for each segmented region. The\nunique feature of our method is that it achieves the simultaneous segmentation\nand description for non-smooth image structures under the same optimization\nframework. The experiments validate our theoretical claims and show the clear\nsuperior performance of our methods over other related methods for segmentation\nof various image textures. We show that our model can be coupled with the\npiecewise smooth model to handle both smooth and non-smooth structures, and we\ndemonstrate that the proposed model is capable of coping with multiple\ndifferent regions through the one-against-all strategy.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2012 09:38:45 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Wang", "Junyan", ""], ["Chan", "Kap Luk", ""]]}, {"id": "1207.5326", "submitter": "Ziqiang Shi", "authors": "Ziqiang Shi, Jiqing Han, Tieran Zheng, Shiwen Deng, Ji Li", "title": "Guarantees of Augmented Trace Norm Models in Tensor Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the recovery guarantees of the models of minimizing\n$\\|\\mathcal{X}\\|_*+\\frac{1}{2\\alpha}\\|\\mathcal{X}\\|_F^2$ where $\\mathcal{X}$ is\na tensor and $\\|\\mathcal{X}\\|_*$ and $\\|\\mathcal{X}\\|_F$ are the trace and\nFrobenius norm of respectively. We show that they can efficiently recover\nlow-rank tensors. In particular, they enjoy exact guarantees similar to those\nknown for minimizing $\\|\\mathcal{X}\\|_*$ under the conditions on the sensing\noperator such as its null-space property, restricted isometry property, or\nspherical section property. To recover a low-rank tensor $\\mathcal{X}^0$,\nminimizing $\\|\\mathcal{X}\\|_*+\\frac{1}{2\\alpha}\\|\\mathcal{X}\\|_F^2$ returns the\nsame solution as minimizing $\\|\\mathcal{X}\\|_*$ almost whenever\n$\\alpha\\geq10\\mathop {\\max}\\limits_{i}\\|X^0_{(i)}\\|_2$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 08:59:58 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Shi", "Ziqiang", ""], ["Han", "Jiqing", ""], ["Zheng", "Tieran", ""], ["Deng", "Shiwen", ""], ["Li", "Ji", ""]]}, {"id": "1207.5371", "submitter": "Aasa Feragen", "authors": "Aasa Feragen, Pechin Lo, Marleen de Bruijne, Mads Nielsen, Francois\n  Lauze", "title": "Towards a theory of statistical tree-shape analysis", "comments": "36 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to develop statistical methods for shapes with a tree-structure, we\nconstruct a shape space framework for tree-like shapes and study metrics on the\nshape space. This shape space has singularities, corresponding to topological\ntransitions in the represented trees. We study two closely related metrics on\nthe shape space, TED and QED. QED is a quotient Euclidean distance arising\nnaturally from the shape space formulation, while TED is the classical tree\nedit distance. Using Gromov's metric geometry we gain new insight into the\ngeometries defined by TED and QED. We show that the new metric QED has nice\ngeometric properties which facilitate statistical analysis, such as existence\nand local uniqueness of geodesics and averages. TED, on the other hand, does\nnot share the geometric advantages of QED, but has nice algorithmic properties.\nWe provide a theoretical framework and experimental results on synthetic data\ntrees as well as airway trees from pulmonary CT scans. This way, we effectively\nillustrate that our framework has both the theoretical and qualitative\nproperties necessary to build a theory of statistical tree-shape analysis.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 12:25:50 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Feragen", "Aasa", ""], ["Lo", "Pechin", ""], ["de Bruijne", "Marleen", ""], ["Nielsen", "Mads", ""], ["Lauze", "Francois", ""]]}, {"id": "1207.5774", "submitter": "Lou Marvin Caraig", "authors": "Lou Marvin Caraig", "title": "A New Training Algorithm for Kanerva's Sparse Distributed Memory", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sparse Distributed Memory proposed by Pentii Kanerva (SDM in short) was\nthought to be a model of human long term memory. The architecture of the SDM\npermits to store binary patterns and to retrieve them using partially matching\npatterns. However Kanerva's model is especially efficient only in handling\nrandom data. The purpose of this article is to introduce a new approach of\ntraining Kanerva's SDM that can handle efficiently non-random data, and to\nprovide it the capability to recognize inverted patterns. This approach uses a\nsignal model which is different from the one proposed for different purposes by\nHely, Willshaw and Hayes in [4]. This article additionally suggests a different\nway of creating hard locations in the memory despite the Kanerva's static\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 16:30:07 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2012 05:04:18 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2012 08:24:51 GMT"}], "update_date": "2012-07-30", "authors_parsed": [["Caraig", "Lou Marvin", ""]]}, {"id": "1207.6774", "submitter": "Revathi Rajendran", "authors": "A. R. Revathi, Dhananjay Kumar", "title": "A Survey Of Activity Recognition And Understanding The Behavior In Video\n  Survelliance", "comments": "14 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a review of human activity recognition and behaviour\nunderstanding in video sequence. The key objective of this paper is to provide\na general review on the overall process of a surveillance system used in the\ncurrent trend. Visual surveillance system is directed on automatic\nidentification of events of interest, especially on tracking and classification\nof moving objects. The processing step of the video surveillance system\nincludes the following stages: Surrounding model, object representation, object\ntracking, activity recognition and behaviour understanding. It describes\ntechniques that use to define a general set of activities that are applicable\nto a wide range of scenes and environments in video sequence.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2012 13:07:09 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Revathi", "A. R.", ""], ["Kumar", "Dhananjay", ""]]}, {"id": "1207.7244", "submitter": "Liujuan Cao", "authors": "Liujuan Cao", "title": "Visual Vocabulary Learning and Its Application to 3D and Mobile Visual\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we review related works and recent trends in visual\nvocabulary based web image search, object recognition, mobile visual search,\nand 3D object retrieval. Especial focuses would be also given for the recent\ntrends in supervised/unsupervised vocabulary optimization, compact descriptor\nfor visual search, as well as in multi-view based 3D object representation.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 15:07:26 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Cao", "Liujuan", ""]]}, {"id": "1207.7245", "submitter": "Xinhua Mao", "authors": "Xinhua Mao, Daiyin Zhu, and Zhaoda Zhu", "title": "Autofocus Correction of Azimuth Phase Error and Residual Range Cell\n  Migration in Spotlight SAR Polar Format Imagery", "comments": "29 pages, 14 figures", "journal-ref": "Aerospace and Electronic Systems, IEEE Transactions on (Volume:49\n  , Issue: 4 ), 2013", "doi": "10.1109/TAES.2013.6621846", "report-no": null, "categories": "astro-ph.IM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic aperture radar (SAR) images are often blurred by phase\nperturbations induced by uncompensated sensor motion and /or unknown\npropagation effects caused by turbulent media. To get refocused images,\nautofocus proves to be useful post-processing technique applied to estimate and\ncompensate the unknown phase errors. However, a severe drawback of the\nconventional autofocus algorithms is that they are only capable of removing\none-dimensional azimuth phase errors (APE). As the resolution becomes finer,\nresidual range cell migration (RCM), which makes the defocus inherently\ntwo-dimensional, becomes a new challenge. In this paper, correction of APE and\nresidual RCM are presented in the framework of polar format algorithm (PFA).\nFirst, an insight into the underlying mathematical mechanism of polar\nreformatting is presented. Then based on this new formulation, the effect of\npolar reformatting on the uncompensated APE and residual RCM is investigated in\ndetail. By using the derived analytical relationship between APE and residual\nRCM, an efficient two-dimensional (2-D) autofocus method is proposed.\nExperimental results indicate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 06:25:30 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Mao", "Xinhua", ""], ["Zhu", "Daiyin", ""], ["Zhu", "Zhaoda", ""]]}]