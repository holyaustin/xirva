[{"id": "1303.0018", "submitter": "Alireza Aghasi", "authors": "Alireza Aghasi and Justin Romberg", "title": "Sparse Shape Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.CV math-ph math.DG math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new shape-based image reconstruction technique\napplicable to a large class of imaging problems formulated in a variational\nsense. Given a collection of shape priors (a shape dictionary), we define our\nproblem as choosing the right elements and geometrically composing them through\nbasic set operations to characterize desired regions in the image. This\ncombinatorial problem can be relaxed and then solved using classical descent\nmethods. The main component of this relaxation is forming certain compactly\nsupported functions which we call \"knolls\", and reformulating the shape\nrepresentation as a basis expansion in terms of such functions. To select\nsuitable elements of the dictionary, our problem ultimately reduces to solving\na nonlinear program with sparsity constraints. We provide a new sparse\nnonlinear reconstruction technique to approach this problem. The performance of\nproposed technique is demonstrated with some standard imaging problems\nincluding image segmentation, X-ray tomography and diffusive tomography.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 21:12:38 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Aghasi", "Alireza", ""], ["Romberg", "Justin", ""]]}, {"id": "1303.0417", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal N. Chaudhury", "title": "On the convergence of the IRLS algorithm in Non-Local Patch Regression", "comments": null, "journal-ref": "IEEE Signal Processing Letters, vol. 20(8), 815 - 818, 2013", "doi": "10.1109/LSP.2013.2268248", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it was demonstrated in [CS2012,CS2013] that the robustness of the\nclassical Non-Local Means (NLM) algorithm [BCM2005] can be improved by\nincorporating $\\ell^p (0 < p \\leq 2)$ regression into the NLM framework. This\ngeneral optimization framework, called Non-Local Patch Regression (NLPR),\ncontains NLM as a special case. Denoising results on synthetic and natural\nimages show that NLPR consistently performs better than NLM beyond a moderate\nnoise level, and significantly so when $p$ is close to zero. An iteratively\nreweighted least-squares (IRLS) algorithm was proposed for solving the\nregression problem in NLPR, where the NLM output was used to initialize the\niterations. Based on exhaustive numerical experiments, we observe that the IRLS\nalgorithm is globally convergent (for arbitrary initialization) in the convex\nregime $1 \\leq p \\leq 2$, and locally convergent (fails very rarely using NLM\ninitialization) in the non-convex regime $0 < p < 1$. In this letter, we adapt\nthe \"majorize-minimize\" framework introduced in [Voss1980] to explain these\nobservations.\n  [CS2012] Chaudhury et al. (2012), \"Non-local Euclidean medians,\" IEEE Signal\nProcessing Letters.\n  [CS2013] Chaudhury et al. (2013), \"Non-local patch regression: Robust image\ndenoising in patch space,\" IEEE ICASSP.\n  [BCM2005] Buades et al. (2005), \"A review of image denoising algorithms, with\na new one,\" Multiscale Modeling and Simulation.\n  [Voss1980] Voss et al. (1980), \"Linear convergence of generalized Weiszfeld's\nmethod,\" Computing.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2013 19:06:01 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2013 12:06:30 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Chaudhury", "Kunal N.", ""]]}, {"id": "1303.0448", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy and Andreas\n  Spanias", "title": "Learning Stable Multilevel Dictionaries for Sparse Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse representations using learned dictionaries are being increasingly used\nwith success in several data processing and machine learning applications. The\navailability of abundant training data necessitates the development of\nefficient, robust and provably good dictionary learning algorithms. Algorithmic\nstability and generalization are desirable characteristics for dictionary\nlearning algorithms that aim to build global dictionaries which can efficiently\nmodel any test data similar to the training samples. In this paper, we propose\nan algorithm to learn dictionaries for sparse representations from large scale\ndata, and prove that the proposed learning algorithm is stable and\ngeneralizable asymptotically. The algorithm employs a 1-D subspace clustering\nprocedure, the K-hyperline clustering, in order to learn a hierarchical\ndictionary with multiple levels. We also propose an information-theoretic\nscheme to estimate the number of atoms needed in each level of learning and\ndevelop an ensemble approach to learn robust dictionaries. Using the proposed\ndictionaries, the sparse code for novel test data can be computed using a\nlow-complexity pursuit procedure. We demonstrate the stability and\ngeneralization characteristics of the proposed algorithm using simulations. We\nalso evaluate the utility of the multilevel dictionaries in compressed recovery\nand subspace learning applications.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 01:49:56 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2013 19:21:54 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1303.0460", "submitter": "Priya Dharshini", "authors": "N. Priyadharshini, M.S. Vijaya", "title": "Genetic Programming for Document Segmentation and Region Classification\n  Using Discipulus", "comments": "8 pages,13 figures", "journal-ref": "(IJARAI) International Journal of Advanced Research in Artificial\n  Intelligence, Vol. 2, No. 2, 2013", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Document segmentation is a method of rending the document into distinct\nregions. A document is an assortment of information and a standard mode of\nconveying information to others. Pursuance of data from documents involves ton\nof human effort, time intense and might severely prohibit the usage of data\nsystems. So, automatic information pursuance from the document has become a big\nissue. It is been shown that document segmentation will facilitate to beat such\nproblems. This paper proposes a new approach to segment and classify the\ndocument regions as text, image, drawings and table. Document image is divided\ninto blocks using Run length smearing rule and features are extracted from\nevery blocks. Discipulus tool has been used to construct the Genetic\nprogramming based classifier model and located 97.5% classification accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 05:31:42 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Priyadharshini", "N.", ""], ["Vijaya", "M. S.", ""]]}, {"id": "1303.0479", "submitter": "Binjie Qin", "authors": "Zhuangming Shen, Jiuai Sun, Hui Zhang, and Binjie Qin", "title": "Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for\n  Nonrigid Image Registration", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Joint saliency map (JSM) [1] was developed to assign high joint saliency\nvalues to the corresponding saliency structures (called Joint Saliency\nStructures, JSSs) but zero or low joint saliency values to the outliers (or\nmismatches) that are introduced by missing correspondence or local large\ndeformations between the reference and moving images to be registered. JSM\nguides the local structure matching in nonrigid registration by emphasizing\nthese JSSs' sparse deformation vectors in adaptive kernel regression of\nhierarchical sparse deformation vectors for iterative dense deformation\nreconstruction. By designing an effective superpixel-based local structure\nscale estimator to compute the reference structure's structure scale, we\nfurther propose to determine the scale (the width) of kernels in the adaptive\nkernel regression through combining the structure scales to JSM-based scales of\nmismatch between the local saliency structures. Therefore, we can adaptively\nselect the sample size of sparse deformation vectors to reconstruct the dense\ndeformation vectors for accurately matching the every local structures in the\ntwo images. The experimental results demonstrate better accuracy of our method\nin aligning two images with missing correspondence and local large deformation\nthan the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 09:15:25 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 17:32:36 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Shen", "Zhuangming", ""], ["Sun", "Jiuai", ""], ["Zhang", "Hui", ""], ["Qin", "Binjie", ""]]}, {"id": "1303.0582", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy and Andreas\n  Spanias", "title": "Multiple Kernel Sparse Representations for Supervised and Unsupervised\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2014.2322938", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex visual recognition tasks it is typical to adopt multiple\ndescriptors, that describe different aspects of the images, for obtaining an\nimproved recognition performance. Descriptors that have diverse forms can be\nfused into a unified feature space in a principled manner using kernel methods.\nSparse models that generalize well to the test data can be learned in the\nunified kernel space, and appropriate constraints can be incorporated for\napplication in supervised and unsupervised learning. In this paper, we propose\nto perform sparse coding and dictionary learning in the multiple kernel space,\nwhere the weights of the ensemble kernel are tuned based on graph-embedding\nprinciples such that class discrimination is maximized. In our proposed\nalgorithm, dictionaries are inferred using multiple levels of 1-D subspace\nclustering in the kernel space, and the sparse codes are obtained using a\nsimple levelwise pursuit scheme. Empirical results for object recognition and\nimage clustering show that our algorithm outperforms existing sparse coding\nbased approaches, and compares favorably to other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 23:41:34 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2013 22:06:06 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Spanias", "Andreas", ""]]}, {"id": "1303.0633", "submitter": "Karen  Das", "authors": "Subra Mukherjee, Karen Das", "title": "Omega Model for Human Detection and Counting for application in Smart\n  Surveillance System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the significant advancements in technology and social issues such\nas security management, there is a strong need for Smart Surveillance System in\nour society today. One of the key features of a Smart Surveillance System is\nefficient human detection and counting such that the system can decide and\nlabel events on its own. In this paper we propose a new, novel and robust\nmodel, The Omega Model, for detecting and counting human beings present in the\nscene. The proposed model employs a set of four distinct descriptors for\nidentifying the unique features of the head, neck and shoulder regions of a\nperson. This unique head neck shoulder signature given by the Omega Model\nexploits the challenges such as inter person variations in size and shape of\npeoples head, neck and shoulder regions to achieve robust detection of human\nbeings even under partial occlusion, dynamically changing background and\nvarying illumination conditions. After experimentation we observe and analyze\nthe influences of each of the four descriptors on the system performance and\ncomputation speed and conclude that a weight based decision making system\nproduces the best results. Evaluation results on a number of images indicate\nthe validation of our method in actual situation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 08:01:36 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Mukherjee", "Subra", ""], ["Das", "Karen", ""]]}, {"id": "1303.0634", "submitter": "Karen  Das", "authors": "Joyeeta Singha, Karen Das", "title": "Indian Sign Language Recognition Using Eigen Value Weighted Euclidean\n  Distance Based Classification Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign Language Recognition is one of the most growing fields of research\ntoday. Many new techniques have been developed recently in these fields. Here\nin this paper, we have proposed a system using Eigen value weighted Euclidean\ndistance as a classification technique for recognition of various Sign\nLanguages of India. The system comprises of four parts: Skin Filtering, Hand\nCropping, Feature Extraction and Classification. Twenty four signs were\nconsidered in this paper, each having ten samples, thus a total of two hundred\nforty images was considered for which recognition rate obtained was 97 percent.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 08:06:07 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Singha", "Joyeeta", ""], ["Das", "Karen", ""]]}, {"id": "1303.0635", "submitter": "Karen  Das", "authors": "Jeemoni Kalita, Karen Das", "title": "Recognition of Facial Expression Using Eigenvector Based Distributed\n  Features and Euclidean Distance Based Decision Making Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an Eigenvector based system has been presented to recognize\nfacial expressions from digital facial images. In the approach, firstly the\nimages were acquired and cropping of five significant portions from the image\nwas performed to extract and store the Eigenvectors specific to the\nexpressions. The Eigenvectors for the test images were also computed, and\nfinally the input facial image was recognized when similarity was obtained by\ncalculating the minimum Euclidean distance between the test image and the\ndifferent expressions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 08:09:22 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Kalita", "Jeemoni", ""], ["Das", "Karen", ""]]}, {"id": "1303.0644", "submitter": "Meena Kabilan", "authors": "A. Meena and K. Raja", "title": "Automatic symmetry based cluster approach for anomalous brain\n  identification in PET scan image : An Analysis", "comments": "International Conference on Mathematics and Computer Science: ICMCS\n  2011,ISBN: 978-81-920490-0-7, January 2011,pp.no.387 - 391", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image segmentation is referred to the segmentation of known anatomic\nstructures from different medical images. Normally, the medical data researches\nare more complicated and an exclusive structures. This computer aided diagnosis\nis used for assisting doctors in evaluating medical imagery or in recognizing\nabnormal findings in a medical image. To integrate the specialized knowledge\nfor medical data processing is helpful to form a real useful healthcare\ndecision making system. This paper studies the different symmetry based\ndistances applied in clustering algorithms and analyzes symmetry approach for\nPositron Emission Tomography (PET) scan image segmentation. Unlike CT and MRI,\nthe PET scan identifies the structure of blood flow to and from organs. PET\nscan also helps in early diagnosis of cancer and heart, brain and gastro\nintestinal ailments and to detect the progress of treatment. In this paper, the\nscope diagnostic task expands for PET image in various brain functions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 08:52:45 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Meena", "A.", ""], ["Raja", "K.", ""]]}, {"id": "1303.0645", "submitter": "Meena Kabilan", "authors": "A. Meena and R. Raja", "title": "Symmetry Based Cluster Approach for Automatic Recognition of the\n  Epileptic Focus in Brain Using PET Scan Image : An Analysis", "comments": "National Conference:NC4T 2011, Sathyabama University,PP. No. 61 - 63", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of epileptic focal point is the important diagnosis when\nscreening the epilepsy patients for latent surgical cures. The accurate\nlocalization is challenging one because of the low spatial resolution images\nwith more noisy data. Positron Emission Tomography (PET) has now replaced the\nissues and caring a high resolution. This paper focuses the research of\nautomated localization of epileptic seizures in brain functional images using\nsymmetry based cluster approach. This approach presents a fully automated\nsymmetry based brain abnormality detection method for PET sequences. PET images\nare spatially normalized to Digital Imaging and Communications in Medicine\n(DICOM) standard and then it has been trained using symmetry based cluster\napproach using Medical Image Processing, Analysis & Visualization (MIPAV) tool.\nThe performance evolution is considered by the metric like accuracy of\ndiagnosis. The obtained result is surely assists the surgeon for the automated\nidentification of seizures focus.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 09:00:23 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Meena", "A.", ""], ["Raja", "R.", ""]]}, {"id": "1303.0647", "submitter": "Meena Kabilan", "authors": "A. Meena and R. Raja", "title": "Spatial Fuzzy C Means PET Image Segmentation of Neurodegenerative\n  Disorder", "comments": null, "journal-ref": "Indian Journal of Computer Science and Engineering (IJCSE), ISSN :\n  0976-5166 Vol. 4 No.1 Feb-Mar 2013, pp.no: 50-55", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear image has emerged as a promising research work in medical field.\nImages from different modality meet its own challenge. Positron Emission\nTomography (PET) image may help to precisely localize disease to assist in\nplanning the right treatment for each case and saving valuable time. In this\npaper, a novel approach of Spatial Fuzzy C Means (PET SFCM) clustering\nalgorithm is introduced on PET scan image datasets. The proposed algorithm is\nincorporated the spatial neighborhood information with traditional FCM and\nupdating the objective function of each cluster. This algorithm is implemented\nand tested on huge data collection of patients with brain neuro degenerative\ndisorder such as Alzheimers disease. It has demonstrated its effectiveness by\ntesting it for real world patient data sets. Experimental results are compared\nwith conventional FCM and K Means clustering algorithm. The performance of the\nPET SFCM provides satisfactory results compared with other two algorithms\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 09:08:34 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Meena", "A.", ""], ["Raja", "R.", ""]]}, {"id": "1303.0964", "submitter": "Jan Egger", "authors": "Jan Egger, Tina Kapur, Andriy Fedorov, Steve Pieper, James V. Miller,\n  Harini Veeraraghavan, Bernd Freisleben, Alexandra Golby, Christopher Nimsky,\n  Ron Kikinis", "title": "GBM Volumetry using the 3D Slicer Medical Image Computing Platform", "comments": "7 pages, 6 figures, 2 tables, 1 equation, 43 references", "journal-ref": "Sci. Rep. 3, 1364, 2013", "doi": "10.1038/srep01364", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric change in glioblastoma multiforme (GBM) over time is a critical\nfactor in treatment decisions. Typically, the tumor volume is computed on a\nslice-by-slice basis using MRI scans obtained at regular intervals. (3D)Slicer\n- a free platform for biomedical research - provides an alternative to this\nmanual slice-by-slice segmentation process, which is significantly faster and\nrequires less user interaction. In this study, 4 physicians segmented GBMs in\n10 patients, once using the competitive region-growing based GrowCut\nsegmentation module of Slicer, and once purely by drawing boundaries completely\nmanually on a slice-by-slice basis. Furthermore, we provide a variability\nanalysis for three physicians for 12 GBMs. The time required for GrowCut\nsegmentation was on an average 61% of the time required for a pure manual\nsegmentation. A comparison of Slicer-based segmentation with manual\nslice-by-slice segmentation resulted in a Dice Similarity Coefficient of 88.43\n+/- 5.23% and a Hausdorff Distance of 2.32 +/- 5.23 mm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2013 09:40:46 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["Egger", "Jan", ""], ["Kapur", "Tina", ""], ["Fedorov", "Andriy", ""], ["Pieper", "Steve", ""], ["Miller", "James V.", ""], ["Veeraraghavan", "Harini", ""], ["Freisleben", "Bernd", ""], ["Golby", "Alexandra", ""], ["Nimsky", "Christopher", ""], ["Kikinis", "Ron", ""]]}, {"id": "1303.1420", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras, Gadea Mata, Ana Romero, Julio Rubio, Rub\\'en S\\'aenz", "title": "Verifying a platform for digital imaging: a multi-tool strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fiji is a Java platform widely used by biologists and other experimental\nscientists to process digital images. In particular, in our research - made\ntogether with a biologists team; we use Fiji in some pre-processing steps\nbefore undertaking a homological digital processing of images. In a previous\nwork, we have formalised the correctness of the programs which use homological\ntechniques to analyse digital images. However, the verification of Fiji's\npre-processing step was missed. In this paper, we present a multi-tool approach\nfilling this gap, based on the combination of Why/Krakatoa, Coq and ACL2.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2013 11:07:55 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 07:58:50 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Mata", "Gadea", ""], ["Romero", "Ana", ""], ["Rubio", "Julio", ""], ["S\u00e1enz", "Rub\u00e9n", ""]]}, {"id": "1303.1460", "submitter": "Steven M. LaValle", "authors": "Steven M. LaValle, Seth A. Hutchinson", "title": "On Considering Uncertainty and Alternatives in Low-Level Vision", "comments": "Appears in Proceedings of the Ninth Conference on Uncertainty in\n  Artificial Intelligence (UAI1993)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1993-PG-55-63", "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the uncertainty issues involved in the low-level\nvision task of image segmentation. Researchers in computer vision have worked\nextensively on this problem, in which the goal is to partition (or segment) an\nimage into regions that are homogeneous or uniform in some sense. This\nsegmentation is often utilized by some higher level process, such as an object\nrecognition system. We show that by considering uncertainty in a Bayesian\nformalism, we can use statistical image models to build an approximate\nrepresentation of a probability distribution over a space of alternative\nsegmentations. We give detailed descriptions of the various levels of\nuncertainty associated with this problem, discuss the interaction of prior and\nposterior distributions, and provide the operations for constructing this\nrepresentation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 14:18:58 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["LaValle", "Steven M.", ""], ["Hutchinson", "Seth A.", ""]]}, {"id": "1303.1624", "submitter": "Conrad Sanderson", "authors": "Yongkang Wong, Mehrtash T. Harandi, Conrad Sanderson", "title": "On Robust Face Recognition via Sparse Encoding: the Good, the Bad, and\n  the Ugly", "comments": null, "journal-ref": "IET Biometrics, Vol. 3, No. 4, pp. 176-189, 2014", "doi": "10.1049/iet-bmt.2013.0033", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of face recognition, Sparse Representation (SR) has received\nconsiderable attention during the past few years. Most of the relevant\nliterature focuses on holistic descriptors in closed-set identification\napplications. The underlying assumption in SR-based methods is that each class\nin the gallery has sufficient samples and the query lies on the subspace\nspanned by the gallery of the same class. Unfortunately, such assumption is\neasily violated in the more challenging face verification scenario, where an\nalgorithm is required to determine if two faces (where one or both have not\nbeen seen before) belong to the same person. In this paper, we first discuss\nwhy previous attempts with SR might not be applicable to verification problems.\nWe then propose an alternative approach to face verification via SR.\nSpecifically, we propose to use explicit SR encoding on local image patches\nrather than the entire face. The obtained sparse signals are pooled via\naveraging to form multiple region descriptors, which are then concatenated to\nform an overall face descriptor. Due to the deliberate loss spatial relations\nwithin each region (caused by averaging), the resulting descriptor is robust to\nmisalignment & various image deformations. Within the proposed framework, we\nevaluate several SR encoding techniques: l1-minimisation, Sparse Autoencoder\nNeural Network (SANN), and an implicit probabilistic technique based on\nGaussian Mixture Models. Thorough experiments on AR, FERET, exYaleB, BANCA and\nChokePoint datasets show that the proposed local SR approach obtains\nconsiderably better and more robust performance than several previous\nstate-of-the-art holistic SR methods, in both verification and closed-set\nidentification problems. The experiments also show that l1-minimisation based\nencoding has a considerably higher computational than the other techniques, but\nleads to higher recognition rates.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 09:30:10 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Wong", "Yongkang", ""], ["Harandi", "Mehrtash T.", ""], ["Sanderson", "Conrad", ""]]}, {"id": "1303.1667", "submitter": "Almir Artero Olivette", "authors": "Francisco Assis da Silva, Almir Olivette Artero, Maria Stela Veludo de\n  Paiva, Ricardo Luis Barbosa", "title": "ALPRS - A New Approach for License Plate Recognition using the Sift\n  Algorithm", "comments": null, "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.4, No.1, February 2013", "doi": "10.5121/sipij.2013.4102", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for the automatic license plate\nrecognition, which includes the SIFT algorithm in step to locate the plate in\nthe input image. In this new approach, besides the comparison of the features\nobtained with the SIFT algorithm, the correspondence between the spatial\norientations and the positioning associated with the keypoints is also\nobserved. Afterwards, an algorithm is used for the character recognition of the\nplates, very fast, which makes it possible its application in real time. The\nresults obtained with the proposed approach presented very good success rates,\nso much for locating the characters in the input image, as for their\nrecognition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 12:49:49 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["da Silva", "Francisco Assis", ""], ["Artero", "Almir Olivette", ""], ["de Paiva", "Maria Stela Veludo", ""], ["Barbosa", "Ricardo Luis", ""]]}, {"id": "1303.1749", "submitter": "Yuri Boykov", "authors": "Carl Olsson, Johannes Ulen, Yuri Boykov, Vladimir Kolmogorov", "title": "Simplifying Energy Optimization using Partial Enumeration", "comments": "13 pages, 16 figures. \"Partial Enumeration and Curvature\n  Regularization\" In International Conference on Computer Vision (ICCV), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energies with high-order non-submodular interactions have been shown to be\nvery useful in vision due to their high modeling power. Optimization of such\nenergies, however, is generally NP-hard. A naive approach that works for small\nproblem instances is exhaustive search, that is, enumeration of all possible\nlabelings of the underlying graph. We propose a general minimization approach\nfor large graphs based on enumeration of labelings of certain small patches.\nThis partial enumeration technique reduces complex high-order energy\nformulations to pairwise Constraint Satisfaction Problems with unary costs\n(uCSP), which can be efficiently solved using standard methods like TRW-S. Our\napproach outperforms a number of existing state-of-the-art algorithms on well\nknown difficult problems (e.g. curvature regularization, stereo,\ndeconvolution); it gives near global minimum and better speed.\n  Our main application of interest is curvature regularization. In the context\nof segmentation, our partial enumeration technique allows to evaluate curvature\ndirectly on small patches using a novel integral geometry approach.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 16:59:11 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2013 18:53:23 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Olsson", "Carl", ""], ["Ulen", "Johannes", ""], ["Boykov", "Yuri", ""], ["Kolmogorov", "Vladimir", ""]]}, {"id": "1303.1761", "submitter": "Togerchety Hitendra sarma", "authors": "Mayank Bhargava, Tim Polzehl", "title": "Improving Automatic Emotion Recognition from speech using Rhythm and\n  Temporal feature", "comments": "Appeared in ICECIT-2012, Srinivasa Ramanujan Institute of Technology,\n  Anantapur", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to improve automatic emotion recognition from speech by\nincorporating rhythm and temporal features. Research on automatic emotion\nrecognition so far has mostly been based on applying features like MFCCs, pitch\nand energy or intensity. The idea focuses on borrowing rhythm features from\nlinguistic and phonetic analysis and applying them to the speech signal on the\nbasis of acoustic knowledge only. In addition to this we exploit a set of\ntemporal and loudness features. A segmentation unit is employed in starting to\nseparate the voiced/unvoiced and silence parts and features are explored on\ndifferent segments. Thereafter different classifiers are used for\nclassification. After selecting the top features using an IGR filter we are\nable to achieve a recognition rate of 80.60 % on the Berlin Emotion Database\nfor the speaker dependent framework.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 17:33:06 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["Bhargava", "Mayank", ""], ["Polzehl", "Tim", ""]]}, {"id": "1303.1829", "submitter": "Fernand  Meyer", "authors": "Fernand Meyer", "title": "Watersheds on edge or node weighted graphs \"par l'exemple\"", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watersheds have been defined both for node and edge weighted graphs. We show\nthat they are identical: for each edge (resp.\\ node) weighted graph exists a\nnode (resp. edge) weighted graph with the same minima and catchment basin.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2013 21:15:29 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Meyer", "Fernand", ""]]}, {"id": "1303.2071", "submitter": "J. G. Wolff", "authors": "J. Gerard Wolff", "title": "Application of the SP theory of intelligence to the understanding of\n  natural vision and the development of computer vision", "comments": "40 pages, 16 figures", "journal-ref": "SpringerPlus, 3, 552, 2014", "doi": "10.1186/2193-1801-3-552", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SP theory of intelligence aims to simplify and integrate concepts in\ncomputing and cognition, with information compression as a unifying theme. This\narticle discusses how it may be applied to the understanding of natural vision\nand the development of computer vision. The theory, which is described quite\nfully elsewhere, is described here in outline but with enough detail to ensure\nthat the rest of the article makes sense.\n  Low level perceptual features such as edges or corners may be identified by\nthe extraction of redundancy in uniform areas in a manner that is comparable\nwith the run-length encoding technique for information compression.\n  The concept of multiple alignment in the SP theory may be applied to the\nrecognition of objects, and to scene analysis, with a hierarchy of parts and\nsub-parts, and at multiple levels of abstraction.\n  The theory has potential for the unsupervised learning of visual objects and\nclasses of objects, and suggests how coherent concepts may be derived from\nfragments.\n  As in natural vision, both recognition and learning in the SP system is\nrobust in the face of errors of omission, commission and substitution.\n  The theory suggests how, via vision, we may piece together a knowledge of the\nthree-dimensional structure of objects and of our environment, it provides an\naccount of how we may see things that are not objectively present in an image,\nand how we recognise something despite variations in the size of its retinal\nimage. And it has things to say about the phenomena of lightness constancy and\ncolour constancy, the role of context in recognition, and ambiguities in visual\nperception.\n  A strength of the SP theory is that it provides for the integration of vision\nwith other sensory modalities and with other aspects of intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 18:21:17 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2015 09:59:14 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Wolff", "J. Gerard", ""]]}, {"id": "1303.2108", "submitter": "Alejandro Frery", "authors": "Wagner Barreto da Silva, Corina da Costa Freitas, Sidnei Jo\\~ao\n  Siqueira Sant'Anna and Alejandro C. Frery", "title": "Classification of Segments in PolSAR Imagery by Minimum Stochastic\n  Distances Between Wishart Distributions", "comments": "Accepted for publication on the IEEE Journal of Selected Topics in\n  Applied Earth Observations and Remote Sensing", "journal-ref": null, "doi": "10.1109/JSTARS.2013.2248132", "report-no": null, "categories": "cs.CV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new classifier for Polarimetric SAR (PolSAR) images is proposed and\nassessed in this paper. Its input consists of segments, and each one is\nassigned the class which minimizes a stochastic distance. Assuming the complex\nWishart model, several stochastic distances are obtained from the h-phi family\nof divergences, and they are employed to derive hypothesis test statistics that\nare also used in the classification process. This article also presents, as a\nnovelty, analytic expressions for the test statistics based on the following\nstochastic distances between complex Wishart models: Kullback-Leibler,\nBhattacharyya, Hellinger, R\\'enyi, and Chi-Square; also, the test statistic\nbased on the Bhattacharyya distance between multivariate Gaussian distributions\nis presented. The classifier performance is evaluated using simulated and real\nPolSAR data. The simulated data are based on the complex Wishart model, aiming\nat the analysis of the proposal well controlled data. The real data refer to\nthe complex L-band image, acquired during the 1994 SIR-C mission. The results\nof the proposed classifier are compared with those obtained by a Wishart\nper-pixel/contextual classifier, and we show the better performance of the\nregion-based classification. The influence of the statistical modeling is\nassessed by comparing the results using the Bhattacharyya distance between\nmultivariate Gaussian distributions for amplitude data. The results with\nsimulated data indicate that the proposed classification method has a very good\nperformance when the data follow the Wishart model. The proposed classifier\nalso performs better than the per-pixel/contextual classifier and the\nBhattacharyya Gaussian distance using SIR-C PolSAR data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 18:39:52 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["da Silva", "Wagner Barreto", ""], ["Freitas", "Corina da Costa", ""], ["Sant'Anna", "Sidnei Jo\u00e3o Siqueira", ""], ["Frery", "Alejandro C.", ""]]}, {"id": "1303.2211", "submitter": "Nilanjan  Dey", "authors": "Nilanjan Dey, Suvojit Acharjee, Debalina Biswas, Achintya Das, Sheli\n  Sinha Chaudhuri", "title": "Medical Information Embedding in Compressed Watermarked Intravascular\n  Ultrasound Video", "comments": "Pages-7 Fig.-15 Tables-2", "journal-ref": "Scientific Bulletin of the Politehnica University of Timisoara -\n  Transactions on Electronics and Communications p-ISSN 1583-3380 , vol.\n  57(71), no. 2, 2012", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical field, intravascular ultrasound (IVUS) is a tomographic imaging\nmodality, which can identify the boundaries of different layers of blood\nvessels. IVUS can detect myocardial infarction (heart attack) that remains\nignored and unattended when only angioplasty is done. During the past decade,\nit became easier for some individuals or groups to copy and transmits digital\ninformation without the permission of the owner. For increasing authentication\nand security of copyrights, digital watermarking, an information hiding\ntechnique, was introduced. Achieving watermarking technique with lesser amount\nof distortion in biomedical data is a challenging task. Watermark can be\nembedded into an image or in a video. As video data is a huge amount of\ninformation, therefore a large storage area is needed which is not feasible. In\nthis case motion vector based video compression is done to reduce size. In this\npresent paper, an Electronic Patient Record (EPR) is embedded as watermark\nwithin an IVUS video and then motion vector is calculated. This proposed method\nproves robustness as the extracted watermark has good PSNR value and less MSE.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2013 14:08:23 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Dey", "Nilanjan", ""], ["Acharjee", "Suvojit", ""], ["Biswas", "Debalina", ""], ["Das", "Achintya", ""], ["Chaudhuri", "Sheli Sinha", ""]]}, {"id": "1303.2221", "submitter": "Xiaowen Dong", "authors": "Xiaowen Dong, Pascal Frossard, Pierre Vandergheynst, Nikolai Nefedov", "title": "Clustering on Multi-Layer Graphs via Subspace Analysis on Grassmann\n  Manifolds", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, vol. 62, no. 4, pp.\n  905-918, February 2014", "doi": "10.1109/TSP.2013.2295553", "report-no": null, "categories": "cs.LG cs.CV cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relationships between entities in datasets are often of multiple nature, like\ngeographical distance, social relationships, or common interests among people\nin a social network, for example. This information can naturally be modeled by\na set of weighted and undirected graphs that form a global multilayer graph,\nwhere the common vertex set represents the entities and the edges on different\nlayers capture the similarities of the entities in term of the different\nmodalities. In this paper, we address the problem of analyzing multi-layer\ngraphs and propose methods for clustering the vertices by efficiently merging\nthe information provided by the multiple modalities. To this end, we propose to\ncombine the characteristics of individual graph layers using tools from\nsubspace analysis on a Grassmann manifold. The resulting combination can then\nbe viewed as a low dimensional representation of the original data which\npreserves the most important information from diverse relationships between\nentities. We use this information in new clustering methods and test our\nalgorithm on several synthetic and real world datasets where we demonstrate\nsuperior or competitive performances compared to baseline and state-of-the-art\ntechniques. Our generic framework further extends to numerous analysis and\nlearning problems that involve different types of information on graphs.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2013 15:31:48 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Dong", "Xiaowen", ""], ["Frossard", "Pascal", ""], ["Vandergheynst", "Pierre", ""], ["Nefedov", "Nikolai", ""]]}, {"id": "1303.2292", "submitter": "Ankit Chaudhary", "authors": "Ankit Chaudhary, J. L. Raheja, Karen Das, Sonia Raheja", "title": "Intelligent Approaches to interact with Machines using Hand Gesture\n  Recognition in Natural way: A Survey", "comments": null, "journal-ref": "IJCSES, 2011", "doi": null, "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand gestures recognition (HGR) is one of the main areas of research for the\nengineers, scientists and bioinformatics. HGR is the natural way of Human\nMachine interaction and today many researchers in the academia and industry are\nworking on different application to make interactions more easy, natural and\nconvenient without wearing any extra device. HGR can be applied from games\ncontrol to vision enabled robot control, from virtual reality to smart home\nsystems. In this paper we are discussing work done in the area of hand gesture\nrecognition where focus is on the intelligent approaches including soft\ncomputing based methods like artificial neural network, fuzzy logic, genetic\nalgorithms etc. The methods in the preprocessing of image for segmentation and\nhand image construction also taken into study. Most researchers used fingertips\nfor hand detection in appearance based modeling. Finally the comparison of\nresults given by different researchers is also presented.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2013 08:29:48 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Chaudhary", "Ankit", ""], ["Raheja", "J. L.", ""], ["Das", "Karen", ""], ["Raheja", "Sonia", ""]]}, {"id": "1303.2330", "submitter": "Sreelakshmi M S", "authors": "M.S.Sreelakshmi, D. Venkataraman", "title": "Image compression using anti-forensics method", "comments": "9 pages 8 figures IJCSEA journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of image forensics methods are available which are capable of\nidentifying image tampering. But these techniques are not capable of addressing\nthe anti-forensics method which is able to hide the trace of image tampering.\nIn this paper anti-forensics method for digital image compression has been\nproposed. This anti-forensics method is capable of removing the traces of image\ncompression. Additionally, technique is also able to remove the traces of\nblocking artifact that are left by image compression algorithms that divide an\nimage into segments during compression process. This method is targeted to\nremove the compression fingerprints of JPEG compression.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2013 15:29:26 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Sreelakshmi", "M. S.", ""], ["Venkataraman", "D.", ""]]}, {"id": "1303.2437", "submitter": "Joseph Paul", "authors": "Joseph Suresh Paul, Uma Krishna Swamy Pillai, Nyjin Thomas", "title": "Least-Squares FIR Models of Low-Resolution MR data for Efficient\n  Phase-Error Compensation with Simultaneous Artefact Removal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal space models in both phase-encode, and frequency-encode directions are\npresented for extrapolation of 2D partial kspace. Using the boxcar\nrepresentation of low-resolution spatial data, and a geometrical representation\nof signal space vectors in both positive and negative phase-encode directions,\na robust predictor is constructed using a series of signal space projections.\nCompared to some of the existing phase-correction methods that require\nacquisition of a pre-determined set of fractional kspace lines, the proposed\npredictor is found to be more efficient, due to its capability of exhibiting an\nequivalent degree of performance using only half the number of fractional\nlines. Robust filtering of noisy data is achieved using a second signal space\nmodel in the frequency-encode direction, bypassing the requirement of a prior\nhighpass filtering operation. The signal space is constructed from Fourier\nTransformed samples of each row in the low-resolution image. A set of FIR\nfilters are estimated by fitting a least squares model to this signal space.\nPartial kspace extrapolation using the FIR filters is shown to result in\nartifact-free reconstruction, particularly in respect of Gibbs ringing and\nstreaking type artifacts.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 06:40:02 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Paul", "Joseph Suresh", ""], ["Pillai", "Uma Krishna Swamy", ""], ["Thomas", "Nyjin", ""]]}, {"id": "1303.2439", "submitter": "Joseph Paul", "authors": "Joseph Suresh Paul, Joshin John Mathew, Souparnika Kandoth Naroth, and\n  Chandrasekar Kesavadas", "title": "Voxel-wise Weighted MR Image Enhancement using an Extended Neighborhood\n  Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an edge preserving and denoising filter for enhancing the features\nin images, which contain an ROI having a narrow spatial extent. Typical\nexamples include angiograms, or ROI spatially distributed in multiple locations\nand contained within an outlying region, such as in multiple-sclerosis. The\nfiltering involves determination of multiplicative weights in the spatial\ndomain using an extended set of neighborhood directions. Equivalently, the\nfiltering operation may be interpreted as a combination of directional filters\nin the frequency domain, with selective weighting for spatial frequencies\ncontained within each direction. The advantages of the proposed filter in\ncomparison to specialized non-linear filters, which operate on diffusion\nprinciple, are illustrated using numerical phantom data. The performance\nevaluation is carried out on simulated images from BrainWeb database for\nmultiple-sclerosis, acute ischemic stroke using clinically acquired FLAIR\nimages and MR angiograms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 06:54:26 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Paul", "Joseph Suresh", ""], ["Mathew", "Joshin John", ""], ["Naroth", "Souparnika Kandoth", ""], ["Kesavadas", "Chandrasekar", ""]]}, {"id": "1303.2465", "submitter": "Conrad Sanderson", "authors": "Vikas Reddy, Conrad Sanderson, Brian C. Lovell", "title": "A Low-Complexity Algorithm for Static Background Estimation from\n  Cluttered Image Sequences in Surveillance Contexts", "comments": null, "journal-ref": "EURASIP Journal on Image and Video Processing, 2011", "doi": "10.1155/2011/164956", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  For the purposes of foreground estimation, the true background model is\nunavailable in many practical circumstances and needs to be estimated from\ncluttered image sequences. We propose a sequential technique for static\nbackground estimation in such conditions, with low computational and memory\nrequirements. Image sequences are analysed on a block-by-block basis. For each\nblock location a representative set is maintained which contains distinct\nblocks obtained along its temporal line. The background estimation is carried\nout in a Markov Random Field framework, where the optimal labelling solution is\ncomputed using iterated conditional modes. The clique potentials are computed\nbased on the combined frequency response of the candidate block and its\nneighbourhood. It is assumed that the most appropriate block results in the\nsmoothest response, indirectly enforcing the spatial continuity of structures\nwithin a scene. Experiments on real-life surveillance videos demonstrate that\nthe proposed method obtains considerably better background estimates (both\nqualitatively and quantitatively) than median filtering and the recently\nproposed \"intervals of stable intensity\" method. Further experiments on the\nWallflower dataset suggest that the combination of the proposed method with a\nforeground segmentation algorithm results in improved foreground segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 09:57:49 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Reddy", "Vikas", ""], ["Sanderson", "Conrad", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1303.2607", "submitter": "Yuri Boykov", "authors": "Hossam Isack and Yuri Boykov", "title": "Joint optimization of fitting & matching in multi-view reconstruction", "comments": "33 pages, 8 figures, 2 tables, to appear in IEEE conference on\n  Computer Vision and Pattern Recognition (CVPR), June 2014", "journal-ref": null, "doi": null, "report-no": "Technical Report 755, Computer Science department, UWO, London,\n  Canada, ISBN: 978-0-7714-2980-4", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many standard approaches for geometric model fitting are based on pre-matched\nimage features. Typically, such pre-matching uses only feature appearances\n(e.g. SIFT) and a large number of non-unique features must be discarded in\norder to control the false positive rate. In contrast, we solve feature\nmatching and multi-model fitting problems in a joint optimization framework.\nThis paper proposes several fit-&-match energy formulations based on a\ngeneralization of the assignment problem. We developed an efficient solver\nbased on min-cost-max-flow algorithm that finds near optimal solutions. Our\napproach significantly increases the number of detected matches. In practice,\nenergy-based joint fitting & matching allows to increase the distance between\nview-points previously restricted by robustness of local SIFT-matching and to\nimprove the model fitting accuracy when compared to state-of-the-art\nmulti-model fitting techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 18:14:42 GMT"}, {"version": "v2", "created": "Wed, 9 Apr 2014 21:10:01 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Isack", "Hossam", ""], ["Boykov", "Yuri", ""]]}, {"id": "1303.2610", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy, Deepta\n  Rajan, Anup Puri, David Frakes, and Andreas Spanias", "title": "Kernel Sparse Models for Automated Tumor Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose sparse coding-based approaches for segmentation of\ntumor regions from MR images. Sparse coding with data-adapted dictionaries has\nbeen successfully employed in several image recovery and vision problems. The\nproposed approaches obtain sparse codes for each pixel in brain magnetic\nresonance images considering their intensity values and location information.\nSince it is trivial to obtain pixel-wise sparse codes, and combining multiple\nfeatures in the sparse coding setup is not straightforward, we propose to\nperform sparse coding in a high-dimensional feature space where non-linear\nsimilarities can be effectively modeled. We use the training data from\nexpert-segmented images to obtain kernel dictionaries with the kernel K-lines\nclustering procedure. For a test image, sparse codes are computed with these\nkernel dictionaries, and they are used to identify the tumor regions. This\napproach is completely automated, and does not require user intervention to\ninitialize the tumor regions in a test image. Furthermore, a low complexity\nsegmentation approach based on kernel sparse codes, which allows the user to\ninitialize the tumor region, is also presented. Results obtained with both the\nproposed approaches are validated against manual segmentation by an expert\nradiologist, and the proposed methods lead to accurate tumor identification.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 18:33:01 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Rajan", "Deepta", ""], ["Puri", "Anup", ""], ["Frakes", "David", ""], ["Spanias", "Andreas", ""]]}, {"id": "1303.2685", "submitter": "Sunil K.  Narang", "authors": "Akshay Gadde, Sunil K Narang and Antonio Ortega", "title": "Bilateral Filter: Graph Spectral Interpretation and Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the bilateral filter proposed by Tomasi and Manduchi,\nas a spectral domain transform defined on a weighted graph. The nodes of this\ngraph represent the pixels in the image and a graph signal defined on the nodes\nrepresents the intensity values. Edge weights in the graph correspond to the\nbilateral filter coefficients and hence are data adaptive. Spectrum of a graph\nis defined in terms of the eigenvalues and eigenvectors of the graph Laplacian\nmatrix. We use this spectral interpretation to generalize the bilateral filter\nand propose more flexible and application specific spectral designs of\nbilateral-like filters. We show that these spectral filters can be implemented\nwith k-iterative bilateral filtering operations and do not require expensive\ndiagonalization of the Laplacian matrix.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2013 20:52:57 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Gadde", "Akshay", ""], ["Narang", "Sunil K", ""], ["Ortega", "Antonio", ""]]}, {"id": "1303.2751", "submitter": "Togerchety Hitendra sarma", "authors": "Mallikarjun Hangarge", "title": "Gaussian Mixture Model for Handwritten Script Identification", "comments": "Appeared in ICECIT-2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Gaussian Mixture Model (GMM) to identify the script of\nhandwritten words of Roman, Devanagari, Kannada and Telugu scripts. It\nemphasizes the significance of directional energies for identification of\nscript of the word. It is robust to varied image sizes and different styles of\nwriting. A GMM is modeled using a set of six novel features derived from\ndirectional energy distributions of the underlying image. The standard\ndeviation of directional energy distributions are computed by decomposing an\nimage matrix into right and left diagonals. Furthermore, deviation of\nhorizontal and vertical distributions of energies is also built-in to GMM. A\ndataset of 400 images out of 800 (200 of each script) are used for training GMM\nand the remaining is for testing. An exhaustive experimentation is carried out\nat bi-script, tri-script and multi-script level and achieved script\nidentification accuracies in percentage as 98.7, 98.16 and 96.91 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 02:32:02 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Hangarge", "Mallikarjun", ""]]}, {"id": "1303.2783", "submitter": "Conrad Sanderson", "authors": "Conrad Sanderson, Mehrtash T. Harandi, Yongkang Wong, Brian C. Lovell", "title": "Combined Learning of Salient Local Descriptors and Distance Metrics for\n  Image Set Face Verification", "comments": null, "journal-ref": "IEEE International Conference on Advanced Video and Signal-Based\n  Surveillance (AVSS), pp, 294-299, 2012", "doi": "10.1109/AVSS.2012.23", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to comparing faces via single exemplars, matching sets of face\nimages increases robustness and discrimination performance. Recent image set\nmatching approaches typically measure similarities between subspaces or\nmanifolds, while representing faces in a rigid and holistic manner. Such\nrepresentations are easily affected by variations in terms of alignment,\nillumination, pose and expression. While local feature based representations\nare considerably more robust to such variations, they have received little\nattention within the image set matching area. We propose a novel image set\nmatching technique, comprised of three aspects: (i) robust descriptors of face\nregions based on local features, partly inspired by the hierarchy in the human\nvisual system, (ii) use of several subspace and exemplar metrics to compare\ncorresponding face regions, (iii) jointly learning which regions are the most\ndiscriminative while finding the optimal mixing weights for combining metrics.\nFace recognition experiments on LFW, PIE and MOBIO face datasets show that the\nproposed algorithm obtains considerably better performance than several recent\nstate-of-the-art techniques, such as Local Principal Angle and the Kernel\nAffine Hull Method.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 06:12:59 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Sanderson", "Conrad", ""], ["Harandi", "Mehrtash T.", ""], ["Wong", "Yongkang", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1303.2844", "submitter": "Pedro Felzenszwalb", "authors": "Pedro F. Felzenszwalb", "title": "A Stochastic Grammar for Natural Shapes", "comments": null, "journal-ref": null, "doi": "10.1007/978-1-4471-5195-1_21", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider object detection using a generic model for natural shapes. A\ncommon approach for object recognition involves matching object models directly\nto images. Another approach involves building intermediate representations via\na generic grouping processes. We argue that these two processes (model-based\nrecognition and grouping) may use similar computational mechanisms. By defining\na generic model for shapes we can use model-based techniques to implement a\nmid-level vision grouping process.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 11:23:47 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Felzenszwalb", "Pedro F.", ""]]}, {"id": "1303.3067", "submitter": "Chuan Kai Kenneth Lim", "authors": "Chuan Kai Kenneth. Lim, T. Prodromakis", "title": "Computing Motion with 3D Memristive Grid", "comments": "Supplementary Materials not uploaded online yet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the relative motion of objects is an important navigation task that\nwe routinely perform by relying on inherently unreliable biological cells in\nthe retina. The non-linear and adaptive response of memristive devices make\nthem excellent building blocks for realizing complex synaptic-like\narchitectures that are common in the human retina. Here, we introduce a novel\nmemristive thresholding scheme that facilitates the detection of moving edges.\nIn addition, a double-layered 3-D memristive network is employed for modeling\nthe motion computations that take place in both the Outer Plexiform Layer (OPL)\nand Inner Plexiform Layer (IPL) that enables the detection of on-center and\noff-center transient responses. Applying the transient detection results, it is\nshown that it is possible to generate an estimation of the speed and direction\na moving object.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 00:11:15 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Lim", "Chuan Kai Kenneth.", ""], ["Prodromakis", "T.", ""]]}, {"id": "1303.3087", "submitter": "Togerchety Hitendra sarma", "authors": "Mallikarjun Hangarge, K.C. Santosh, Srikanth Doddamani, Rajmohan\n  Pardeshi", "title": "Statistical Texture Features based Handwritten and Printed Text\n  Classification in South Indian Documents", "comments": "Appeared in ICECIT-2102", "journal-ref": null, "doi": null, "report-no": "Volume 1,Number 32", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use statistical texture features for handwritten and\nprinted text classification. We primarily aim for word level classification in\nsouth Indian scripts. Words are first extracted from the scanned document. For\neach extracted word, statistical texture features are computed such as mean,\nstandard deviation, smoothness, moment, uniformity, entropy and local range\nincluding local entropy. These feature vectors are then used to classify words\nvia k-NN classifier. We have validated the approach over several different\ndatasets. Scripts like Kannada, Telugu, Malayalam and Hindi i.e., Devanagari\nare primarily employed where an average classification rate of 99.26% is\nachieved. In addition, to provide an extensibility of the approach, we address\nRoman script by using publicly available dataset and interesting results are\nreported.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 04:51:22 GMT"}], "update_date": "2013-04-11", "authors_parsed": [["Hangarge", "Mallikarjun", ""], ["Santosh", "K. C.", ""], ["Doddamani", "Srikanth", ""], ["Pardeshi", "Rajmohan", ""]]}, {"id": "1303.3134", "submitter": "Vincent Buso", "authors": "Hugo Boujut (LaBRI), Vincent Buso (LaBRI), Guillaume Bourmaud (IMS),\n  Jenny Benois-Pineau (LaBRI), R\\'emi M\\'egret (IMS), Jean-Philippe Domenger\n  (LaBRI), Yann Ga\\\"estel (ISPED), Jean-Fran\\c{c}ois Dartigues", "title": "Egocentric vision IT technologies for Alzheimer disease assessment and\n  studies", "comments": "RITS - Recherche en Imagerie et Technologies pour la Sant\\'e, France\n  (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Egocentric vision technology consists in capturing the actions of persons\nfrom their own visual point of view using wearable camera sensors. We apply\nthis new paradigm to instrumental activities monitoring with the objective of\nproviding new tools for the clinical evaluation of the impact of the disease on\npersons with dementia. In this paper, we introduce the current state of the\ndevelopment of this technology and focus on two technology modules: automatic\nlocation estimation and visual saliency estimation for content interpretation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 10:58:38 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Boujut", "Hugo", "", "LaBRI"], ["Buso", "Vincent", "", "LaBRI"], ["Bourmaud", "Guillaume", "", "IMS"], ["Benois-Pineau", "Jenny", "", "LaBRI"], ["M\u00e9gret", "R\u00e9mi", "", "IMS"], ["Domenger", "Jean-Philippe", "", "LaBRI"], ["Ga\u00ebstel", "Yann", "", "ISPED"], ["Dartigues", "Jean-Fran\u00e7ois", ""]]}, {"id": "1303.3152", "submitter": "Odemir Bruno PhD", "authors": "Bruno Brandoli Machado, Wesley Nunes Gon\\c{c}alves, Odemir Martinez\n  Bruno", "title": "Material quality assessment of silk nanofibers based on swarm\n  intelligence", "comments": "11 pages 6 figures", "journal-ref": "J. Phys.: Conf. Ser. 410 012163 2013", "doi": "10.1088/1742-6596/410/1/012163", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for texture analysis based on\nartificial crawler model. Our method assumes that each agent can interact with\nthe environment and each other. The evolution process converges to an\nequilibrium state according to the set of rules. For each textured image, the\nfeature vector is composed by signatures of the live agents curve at each time.\nExperimental results revealed that combining the minimum and maximum signatures\ninto one increase the classification rate. In addition, we pioneer the use of\nautonomous agents for characterizing silk fibroin scaffolds. The results\nstrongly suggest that our approach can be successfully employed for texture\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 13:23:21 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Machado", "Bruno Brandoli", ""], ["Gon\u00e7alves", "Wesley Nunes", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1303.3240", "submitter": "Mihalis A. Nicolaou", "authors": "Mihalis A. Nicolaou, Stefanos Zafeiriou and Maja Pantic", "title": "A Unified Framework for Probabilistic Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unifying framework which reduces the construction of\nprobabilistic component analysis techniques to a mere selection of the latent\nneighbourhood, thus providing an elegant and principled framework for creating\nnovel component analysis models as well as constructing probabilistic\nequivalents of deterministic component analysis methods. Under our framework,\nwe unify many very popular and well-studied component analysis algorithms, such\nas Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA),\nLocality Preserving Projections (LPP) and Slow Feature Analysis (SFA), some of\nwhich have no probabilistic equivalents in literature thus far. We firstly\ndefine the Markov Random Fields (MRFs) which encapsulate the latent\nconnectivity of the aforementioned component analysis techniques; subsequently,\nwe show that the projection directions produced by all PCA, LDA, LPP and SFA\nare also produced by the Maximum Likelihood (ML) solution of a single joint\nprobability density function, composed by selecting one of the defined MRF\npriors while utilising a simple observation model. Furthermore, we propose\nnovel Expectation Maximization (EM) algorithms, exploiting the proposed joint\nPDF, while we generalize the proposed methodologies to arbitrary connectivities\nvia parameterizable MRF products. Theoretical analysis and experiments on both\nsimulated and real world data show the usefulness of the proposed framework, by\nderiving methods which well outperform state-of-the-art equivalents.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 18:18:14 GMT"}, {"version": "v2", "created": "Fri, 14 Nov 2014 15:33:29 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Nicolaou", "Mihalis A.", ""], ["Zafeiriou", "Stefanos", ""], ["Pantic", "Maja", ""]]}, {"id": "1303.3605", "submitter": "Adheen Ajay", "authors": "Adheen Ajay and D. Venkataraman", "title": "A survey on sensing methods and feature extraction algorithms for SLAM\n  problem", "comments": "5 pages, 1 figure,2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper is a survey work for a bigger project for designing a Visual SLAM\nrobot to generate 3D dense map of an unknown unstructured environment. A lot of\nfactors have to be considered while designing a SLAM robot. Sensing method of\nthe SLAM robot should be determined by considering the kind of environment to\nbe modeled. Similarly the type of environment determines the suitable feature\nextraction method. This paper goes through the sensing methods used in some\nrecently published papers. The main objective of this survey is to conduct a\ncomparative study among the current sensing methods and feature extraction\nalgorithms and to extract out the best for our work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 20:51:29 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Ajay", "Adheen", ""], ["Venkataraman", "D.", ""]]}, {"id": "1303.3987", "submitter": "Liping  Wang", "authors": "Liping Wang and Songcan Chen", "title": "$l_{2,p}$ Matrix Norm and Its Application in Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, $l_{2,1}$ matrix norm has been widely applied to many areas such as\ncomputer vision, pattern recognition, biological study and etc. As an extension\nof $l_1$ vector norm, the mixed $l_{2,1}$ matrix norm is often used to find\njointly sparse solutions. Moreover, an efficient iterative algorithm has been\ndesigned to solve $l_{2,1}$-norm involved minimizations. Actually,\ncomputational studies have showed that $l_p$-regularization ($0<p<1$) is\nsparser than $l_1$-regularization, but the extension to matrix norm has been\nseldom considered. This paper presents a definition of mixed $l_{2,p}$ $(p\\in\n(0, 1])$ matrix pseudo norm which is thought as both generalizations of $l_p$\nvector norm to matrix and $l_{2,1}$-norm to nonconvex cases $(0<p<1)$.\nFortunately, an efficient unified algorithm is proposed to solve the induced\n$l_{2,p}$-norm $(p\\in (0, 1])$ optimization problems. The convergence can also\nbe uniformly demonstrated for all $p\\in (0, 1]$. Typical $p\\in (0,1]$ are\napplied to select features in computational biology and the experimental\nresults show that some choices of $0<p<1$ do improve the sparse pattern of\nusing $p=1$.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2013 15:06:12 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Wang", "Liping", ""], ["Chen", "Songcan", ""]]}, {"id": "1303.4160", "submitter": "Conrad Sanderson", "authors": "Vikas Reddy, Conrad Sanderson, Brian C. Lovell", "title": "Improved Foreground Detection via Block-based Classifier Cascade with\n  Probabilistic Decision Integration", "comments": null, "journal-ref": "IEEE Transactions on Circuits and Systems for Video Technology,\n  Vol. 23, No. 1, pp. 83-93, 2013", "doi": "10.1109/TCSVT.2012.2203199", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background subtraction is a fundamental low-level processing task in numerous\ncomputer vision applications. The vast majority of algorithms process images on\na pixel-by-pixel basis, where an independent decision is made for each pixel. A\ngeneral limitation of such processing is that rich contextual information is\nnot taken into account. We propose a block-based method capable of dealing with\nnoise, illumination variations and dynamic backgrounds, while still obtaining\nsmooth contours of foreground objects. Specifically, image sequences are\nanalysed on an overlapping block-by-block basis. A low-dimensional texture\ndescriptor obtained from each block is passed through an adaptive classifier\ncascade, where each stage handles a distinct problem. A probabilistic\nforeground mask generation approach then exploits block overlaps to integrate\ninterim block-level decisions into final pixel-level foreground segmentation.\nUnlike many pixel-based methods, ad-hoc post-processing of foreground masks is\nnot required. Experiments on the difficult Wallflower and I2R datasets show\nthat the proposed approach obtains on average better results (both\nqualitatively and quantitatively) than several prominent methods. We\nfurthermore propose the use of tracking performance as an unbiased approach for\nassessing the practical usefulness of foreground segmentation methods, and show\nthat the proposed approach leads to considerable improvements in tracking\naccuracy on the CAVIAR dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 05:48:40 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Reddy", "Vikas", ""], ["Sanderson", "Conrad", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1303.4614", "submitter": "Santosh K.C.", "authors": "Abdel Bela\\\"id (LORIA), K.C. Santosh (LORIA), Vincent Poulain D'Andecy", "title": "Handwritten and Printed Text Separation in Real Document", "comments": "Machine Vision Applications (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the paper is to separate handwritten and printed text from a real\ndocument embedded with noise, graphics including annotations. Relying on\nrun-length smoothing algorithm (RLSA), the extracted pseudo-lines and\npseudo-words are used as basic blocks for classification. To handle this, a\nmulti-class support vector machine (SVM) with Gaussian kernel performs a first\nlabelling of each pseudo-word including the study of local neighbourhood. It\nthen propagates the context between neighbours so that we can correct possible\nlabelling errors. Considering running time complexity issue, we propose linear\ncomplexity methods where we use k-NN with constraint. When using a kd-tree, it\nis almost linearly proportional to the number of pseudo-words. The performance\nof our system is close to 90%, even when very small learning dataset where\nsamples are basically composed of complex administrative documents.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 14:23:24 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Bela\u00efd", "Abdel", "", "LORIA"], ["Santosh", "K. C.", "", "LORIA"], ["D'Andecy", "Vincent Poulain", ""]]}, {"id": "1303.4803", "submitter": "Chunhua Shen", "authors": "Xi Li, Weiming Hu, Chunhua Shen, Zhongfei Zhang, Anthony Dick, Anton\n  van den Hengel", "title": "A Survey of Appearance Models in Visual Object Tracking", "comments": "Appearing in ACM Transactions on Intelligent Systems and Technology,\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual object tracking is a significant computer vision task which can be\napplied to many domains such as visual surveillance, human computer\ninteraction, and video compression. In the literature, researchers have\nproposed a variety of 2D appearance models. To help readers swiftly learn the\nrecent advances in 2D appearance models for visual object tracking, we\ncontribute this survey, which provides a detailed review of the existing 2D\nappearance models. In particular, this survey takes a module-based architecture\nthat enables readers to easily grasp the key points of visual object tracking.\nIn this survey, we first decompose the problem of appearance modeling into two\ndifferent processing stages: visual representation and statistical modeling.\nThen, different 2D appearance models are categorized and discussed with respect\nto their composition modules. Finally, we address several issues of interest as\nwell as the remaining challenges for future research on this topic. The\ncontributions of this survey are four-fold. First, we review the literature of\nvisual representations according to their feature-construction mechanisms\n(i.e., local and global). Second, the existing statistical modeling schemes for\ntracking-by-detection are reviewed according to their model-construction\nmechanisms: generative, discriminative, and hybrid generative-discriminative.\nThird, each type of visual representations or statistical modeling techniques\nis analyzed and discussed from a theoretical or practical viewpoint. Fourth,\nthe existing benchmark resources (e.g., source code and video datasets) are\nexamined in this survey.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 01:08:33 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Li", "Xi", ""], ["Hu", "Weiming", ""], ["Shen", "Chunhua", ""], ["Zhang", "Zhongfei", ""], ["Dick", "Anthony", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1303.4839", "submitter": "Firoj Parwej Dr.", "authors": "Dr. Firoj Parwej", "title": "The State of the Art Recognize in Arabic Script through Combination of\n  Online and Offline", "comments": "Pages 7, Figure 6, Table 2. arXiv admin note: text overlap with\n  arXiv:1110.1488 by other authors", "journal-ref": "International Journal of Computer Science and Telecommunications\n  (IJCST), UK, London (http://www.ijcst.org) , ISSN 2047-3338 , Vol. 4, Issue\n  3, pages 60 - 66, March 2013. Link - http://www.ijcst.org/Volume4/Issue3.html", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting recognition refers to the identification of written characters.\nHandwriting recognition has become an acute research area in recent years for\nthe ease of access of computer science. In this paper primarily discussed\nOn-line and Off-line handwriting recognition methods for Arabic words which are\noften used among then across the Middle East and North Africa People. Arabic\nword online handwriting recognition is a very challenging task due to its\ncursive nature. Because of the characteristic of the whole body of the Arabic\nscript, namely connectivity between the characters, thereby the segmentation of\nAn Arabic script is very difficult. In this paper we introduced an Arabic\nscript multiple classifier system for recognizing notes written on a Starboard.\nThis Arabic script multiple classifier system combines one off-line and on-line\nhandwriting recognition systems. The Arabic script recognizers are all based on\nHidden Markov Models but vary in the way of preprocessing and normalization. To\ncombine the Arabic script output sequences of the recognizers, we incrementally\nalign the word sequences using a norm string matching algorithm. The Arabic\nscript combination we could increase the system performance over the excellent\ncharacter recognizer by about 3%. The proposed technique is also the necessary\nstep towards character recognition, person identification, personality\ndetermination where input data is processed from all perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 04:54:44 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Parwej", "Dr. Firoj", ""]]}, {"id": "1303.4840", "submitter": "Igor Polk", "authors": "Igor Polkovnikov", "title": "Asynchronous Cellular Operations on Gray Images Extracting Topographic\n  Shape Features and Their Relations", "comments": "19 pages, 37 figures, 10 function classes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of operations of cellular automata on gray images is presented. All\noperations are of a wave-front nature finishing in a stable state. They are\nused to extract shape descripting gray objects robust to a variety of pattern\ndistortions. Topographic terms are used: \"lakes\", \"dales\", \"dales of dales\". It\nis shown how mutual object relations like \"above\" can be presented in terms of\ngray image analysis and how it can be used for character classification and for\ngray pattern decomposition. Algorithms can be realized with a parallel\nasynchronous architecture. Keywords: Pattern Recognition, Mathematical\nMorphology, Cellular Automata, Wave-front Algorithms, Gray Image Analysis,\nTopographical Shape Descriptors, Asynchronous Parallel Processors, Holes,\nCavities, Concavities, Graphs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 04:59:08 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Polkovnikov", "Igor", ""]]}, {"id": "1303.4845", "submitter": "Hyong-Chol O", "authors": "Myong-Song Ho, Gwang-Hui Ju, Yong-Bom O and Gwang-Ho Jong", "title": "On Constructing the Value Function for Optimal Trajectory Problem and\n  its Application to Image Processing", "comments": "5 pages, presented in International Symposium in Commemoration of the\n  65th Anniversary of the Foundation of Kim Il Sung University\n  (Mathematics)20-21. Sep. Juche100(2011), Pyongyang DPR Korea; v2:added\n  authors and revised introduction", "journal-ref": "International Symposium in Commemoration of the 65th Anniversary\n  of the Foundation of Kim Il Sung University (Mathematics)20-21. Sep.\n  Juche100(2011), Pyongyang DPR Korea, 120-124", "doi": null, "report-no": "KISU-MATH-2011-E-C-016", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed an algorithm for solving Hamilton-Jacobi equation associated to\nan optimal trajectory problem for a vehicle moving inside the pre-specified\ndomain with the speed depending upon the direction of the motion and current\nposition of the vehicle. The dynamics of the vehicle is defined by an ordinary\ndifferential equation, the right hand of which is given by product of control(a\ntime dependent fuction) and a function dependent on trajectory and control. At\nsome unspecified terminal time, the vehicle reaches the boundary of the\npre-specified domain and incurs a terminal cost. We also associate the\ntraveling cost with a type of integral to the trajectory followed by vehicle.\nWe are interested in a numerical method for finding a trajectory that minimizes\nthe sum of the traveling cost and terminal cost. We developed an algorithm\nsolving the value function for general trajectory optimization problem. Our\nalgorithm is closely related to the Tsitsiklis's Fast Marching Method and J. A.\nSethian's OUM and SLF-LLL[1-4] and is a generalization of them. On the basis of\nthese results, We applied our algorithm to the image processing such as\nfingerprint verification.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 06:16:55 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2013 02:59:58 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Ho", "Myong-Song", ""], ["Ju", "Gwang-Hui", ""], ["O", "Yong-Bom", ""], ["Jong", "Gwang-Ho", ""]]}, {"id": "1303.4866", "submitter": "Ankit Chadha", "authors": "Ankit R. Chadha, Neha S. Satam", "title": "A Robust Rapid Approach to Image Segmentation with Optimal Thresholding\n  and Watershed Transform", "comments": null, "journal-ref": "International Journal of Computer Applications (2013)", "doi": "10.5120/10949-5908", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel method for partitioning image into meaningful\nsegments. The proposed method employs watershed transform, a well-known image\nsegmentation technique. Along with that, it uses various auxiliary schemes such\nas Binary Gradient Masking, dilation which segment the image in proper way. The\nalgorithm proposed in this paper considers all these methods in effective way\nand takes little time. It is organized in such a manner so that it operates on\ninput image adaptively. Its robustness and efficiency makes it more convenient\nand suitable for all types of images.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2013 08:15:07 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Chadha", "Ankit R.", ""], ["Satam", "Neha S.", ""]]}, {"id": "1303.5244", "submitter": "Martin Kleinsteuber", "authors": "Simon Hawe, Matthias Seibert, and Martin Kleinsteuber", "title": "Separable Dictionary Learning", "comments": "12 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many techniques in computer vision, machine learning, and statistics rely on\nthe fact that a signal of interest admits a sparse representation over some\ndictionary. Dictionaries are either available analytically, or can be learned\nfrom a suitable training set. While analytic dictionaries permit to capture the\nglobal structure of a signal and allow a fast implementation, learned\ndictionaries often perform better in applications as they are more adapted to\nthe considered class of signals. In imagery, unfortunately, the numerical\nburden for (i) learning a dictionary and for (ii) employing the dictionary for\nreconstruction tasks only allows to deal with relatively small image patches\nthat only capture local image information. The approach presented in this paper\naims at overcoming these drawbacks by allowing a separable structure on the\ndictionary throughout the learning process. On the one hand, this permits\nlarger patch-sizes for the learning phase, on the other hand, the dictionary is\napplied efficiently in reconstruction tasks. The learning procedure is based on\noptimizing over a product of spheres which updates the dictionary as a whole,\nthus enforces basic dictionary properties such as mutual coherence explicitly\nduring the learning procedure. In the special case where no separable structure\nis enforced, our method competes with state-of-the-art dictionary learning\nmethods like K-SVD.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 12:40:05 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Hawe", "Simon", ""], ["Seibert", "Matthias", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "1303.5248", "submitter": "Mikhail Salin", "authors": "Boris M. Salin, Mikhail B. Salin", "title": "Methods Of Measurement The Three-Dimensional Wind Waves Spectra, Based\n  On The Processing Of Video Images Of The Sea Surface", "comments": "36 pages, 9 figures, 1 table. Grammar and spelling was carefully\n  edited in version 2", "journal-ref": "Radiophysics and Quantum Electronics. 58(2015), No.2, P.114-123", "doi": "10.1007/s11141-015-9586-1", "report-no": null, "categories": "physics.ao-ph cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical instruments for measuring surface-wave characteristics provide a\nbetter spatial and temporal resolution than other methods, but they face\ndifficulties while converting the results of indirect measurements into\nabsolute levels of the waves. We have solved this problem to some extent. In\nthis paper, we propose an optical method for measuring the 3D power spectral\ndensity of the surface waves and spatio-temporal samples of the wave profiles.\nThe method involves, first, synchronous recording of the brightness field over\na patch of a rough surface and measurement of surface oscillations at one or\nmore points and, second, filtering of the spatial image spectrum. Filter\nparameters are chosen to maximize the correlation of the surface oscillations\nrecovered and measured at one or two points. In addition to the measurement\nprocedure, the paper provides experimental results of measuring\nmultidimensional spectra of roughness, which generally agree with theoretical\nexpectations and the results of other authors.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2013 13:02:21 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 07:46:48 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Salin", "Boris M.", ""], ["Salin", "Mikhail B.", ""]]}, {"id": "1303.5403", "submitter": "Dan Geiger", "authors": "Dan Geiger", "title": "An Entropy-based Learning Algorithm of Bayesian Conditional Trees", "comments": "Appears in Proceedings of the Eighth Conference on Uncertainty in\n  Artificial Intelligence (UAI1992)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1992-PG-92-97", "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article offers a modification of Chow and Liu's learning algorithm in\nthe context of handwritten digit recognition. The modified algorithm directs\nthe user to group digits into several classes consisting of digits that are\nhard to distinguish and then constructing an optimal conditional tree\nrepresentation for each class of digits instead of for each single digit as\ndone by Chow and Liu (1968). Advantages and extensions of the new method are\ndiscussed. Related works of Wong and Wang (1977) and Wong and Poon (1989) which\noffer a different entropy-based learning algorithm are shown to rest on\ninappropriate assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 12:52:37 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Geiger", "Dan", ""]]}, {"id": "1303.5492", "submitter": "Chunli Guo", "authors": "Chunli Guo, Mike E. Davies", "title": "Sample Distortion for Compressed Imaging", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TSP.2013.2286775", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the notion of a sample distortion (SD) function for independent\nand identically distributed (i.i.d) compressive distributions to fundamentally\nquantify the achievable reconstruction performance of compressed sensing for\ncertain encoder-decoder pairs at a given sampling ratio. Two lower bounds on\nthe achievable performance and the intrinsic convexity property is derived. A\nzeroing procedure is then introduced to improve non convex SD functions. The SD\nframework is then applied to analyse compressed imaging with a multi-resolution\nstatistical image model using both the generalized Gaussian distribution and\nthe two-state Gaussian mixture distribution. We subsequently focus on the\nGaussian encoder-Bayesian optimal approximate message passing (AMP) decoder\npair, whose theoretical SD function is provided by the rigorous analysis of the\nAMP algorithm. Given the image statistics, analytic bandwise sample allocation\nfor bandwise independent model is derived as a reverse water-filling scheme.\nSom and Schniter's turbo message passing approach is further deployed to\nintegrate the bandwise sampling with the exploitation of the hidden Markov tree\nstructure of wavelet coefficients. Natural image simulations confirm that with\noracle image statistics, the SD function associated with the optimized sample\nallocation can accurately predict the possible compressed sensing gains.\nFinally, a general sample allocation profile based on average image statistics\nnot only illustrates preferable performance but also makes the scheme\npractical.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 00:58:53 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2013 20:19:47 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Guo", "Chunli", ""], ["Davies", "Mike E.", ""]]}, {"id": "1303.5508", "submitter": "George Chen", "authors": "George H. Chen, Christian Wachinger, Polina Golland", "title": "Sparse Projections of Medical Images onto Manifolds", "comments": "International Conference on Information Processing in Medical Imaging\n  (IPMI 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning has been successfully applied to a variety of medical\nimaging problems. Its use in real-time applications requires fast projection\nonto the low-dimensional space. To this end, out-of-sample extensions are\napplied by constructing an interpolation function that maps from the input\nspace to the low-dimensional manifold. Commonly used approaches such as the\nNystr\\\"{o}m extension and kernel ridge regression require using all training\npoints. We propose an interpolation function that only depends on a small\nsubset of the input training data. Consequently, in the testing phase each new\npoint only needs to be compared against a small number of input training data\nin order to project the point onto the low-dimensional space. We interpret our\nmethod as an out-of-sample extension that approximates kernel ridge regression.\nOur method involves solving a simple convex optimization problem and has the\nattractive property of guaranteeing an upper bound on the approximation error,\nwhich is crucial for medical applications. Tuning this error bound controls the\nsparsity of the resulting interpolation function. We illustrate our method in\ntwo clinical applications that require fast mapping of input images onto a\nlow-dimensional space.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 03:24:10 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2013 19:21:33 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Chen", "George H.", ""], ["Wachinger", "Christian", ""], ["Golland", "Polina", ""]]}, {"id": "1303.5691", "submitter": "Martin Rumpf", "authors": "Benjamin Berkels, Ivan Cabrilo, Sven Haller, Martin Rumpf, Carlo\n  Schaller", "title": "Cortical Surface Co-Registration based on MRI Images and Photos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain shift, i.e. the change in configuration of the brain after opening the\ndura mater, is a key problem in neuronavigation. We present an approach to\nco-register intra-operative microscope images with pre-operative MRI to adapt\nand optimize intra-operative neuronavigation. The tools are a robust\nclassification of sulci on MRI extracted cortical surfaces, guided user marking\nof most prominent sulci on a microscope image, and the actual variational\nregistration method with a fidelity energy for 3D deformations of the cortical\nsurface combined with a higher order, linear elastica type prior energy.\nFurthermore, the actual registration is validated on an artificial testbed with\nknown ground truth deformation and on real data of a neuro clinical patient.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 19:07:13 GMT"}], "update_date": "2013-03-25", "authors_parsed": [["Berkels", "Benjamin", ""], ["Cabrilo", "Ivan", ""], ["Haller", "Sven", ""], ["Rumpf", "Martin", ""], ["Schaller", "Carlo", ""]]}, {"id": "1303.5913", "submitter": "Marcus Chen", "authors": "Marcus Chen, Cham Tat Jen, Pang Sze Kim, Alvina Goh", "title": "A Diffusion Process on Riemannian Manifold for Visual Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust visual tracking for long video sequences is a research area that has\nmany important applications. The main challenges include how the target image\ncan be modeled and how this model can be updated. In this paper, we model the\ntarget using a covariance descriptor, as this descriptor is robust to problems\nsuch as pixel-pixel misalignment, pose and illumination changes, that commonly\noccur in visual tracking. We model the changes in the template using a\ngenerative process. We introduce a new dynamical model for the template update\nusing a random walk on the Riemannian manifold where the covariance descriptors\nlie in. This is done using log-transformed space of the manifold to free the\nconstraints imposed inherently by positive semidefinite matrices. Modeling\ntemplate variations and poses kinetics together in the state space enables us\nto jointly quantify the uncertainties relating to the kinematic states and the\ntemplate in a principled way. Finally, the sequential inference of the\nposterior distribution of the kinematic states and the template is done using a\nparticle filter. Our results shows that this principled approach can be robust\nto changes in illumination, poses and spatial affine transformation. In the\nexperiments, our method outperformed the current state-of-the-art algorithm -\nthe incremental Principal Component Analysis method, particularly when a target\nunderwent fast poses changes and also maintained a comparable performance in\nstable target tracking cases.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2013 04:55:40 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Chen", "Marcus", ""], ["Jen", "Cham Tat", ""], ["Kim", "Pang Sze", ""], ["Goh", "Alvina", ""]]}, {"id": "1303.6001", "submitter": "Bal\\'azs Szalkai", "authors": "Bal\\'azs Szalkai", "title": "Generalizing k-means for an arbitrary distance matrix", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original k-means clustering method works only if the exact vectors\nrepresenting the data points are known. Therefore calculating the distances\nfrom the centroids needs vector operations, since the average of abstract data\npoints is undefined. Existing algorithms can be extended for those cases when\nthe sole input is the distance matrix, and the exact representing vectors are\nunknown. This extension may be named relational k-means after a notation for a\nsimilar algorithm invented for fuzzy clustering. A method is then proposed for\ngeneralizing k-means for scenarios when the data points have absolutely no\nconnection with a Euclidean space.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2013 22:33:15 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Szalkai", "Bal\u00e1zs", ""]]}, {"id": "1303.6021", "submitter": "Conrad Sanderson", "authors": "Andres Sanin, Conrad Sanderson, Mehrtash T. Harandi, Brian C. Lovell", "title": "Spatio-Temporal Covariance Descriptors for Action and Gesture\n  Recognition", "comments": null, "journal-ref": "IEEE Workshop on Applications of Computer Vision, pp. 103-110,\n  2013", "doi": "10.1109/WACV.2013.6475006", "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new action and gesture recognition method based on\nspatio-temporal covariance descriptors and a weighted Riemannian locality\npreserving projection approach that takes into account the curved space formed\nby the descriptors. The weighted projection is then exploited during boosting\nto create a final multiclass classification algorithm that employs the most\nuseful spatio-temporal regions. We also show how the descriptors can be\ncomputed quickly through the use of integral video representations. Experiments\non the UCF sport, CK+ facial expression and Cambridge hand gesture datasets\nindicate superior performance of the proposed method compared to several recent\nstate-of-the-art techniques. The proposed method is robust and does not require\nadditional processing of the videos, such as foreground detection,\ninterest-point detection or tracking.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 03:16:08 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Sanin", "Andres", ""], ["Sanderson", "Conrad", ""], ["Harandi", "Mehrtash T.", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1303.6066", "submitter": "Chunhua Shen", "authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel", "title": "Asymmetric Pruning for Learning Cascade Detectors", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascade classifiers are one of the most important contributions to real-time\nobject detection. Nonetheless, there are many challenging problems arising in\ntraining cascade detectors. One common issue is that the node classifier is\ntrained with a symmetric classifier. Having a low misclassification error rate\ndoes not guarantee an optimal node learning goal in cascade classifiers, i.e.,\nan extremely high detection rate with a moderate false positive rate. In this\nwork, we present a new approach to train an effective node classifier in a\ncascade detector. The algorithm is based on two key observations: 1) Redundant\nweak classifiers can be safely discarded; 2) The final detector should satisfy\nthe asymmetric learning objective of the cascade architecture. To achieve this,\nwe separate the classifier training into two steps: finding a pool of\ndiscriminative weak classifiers/features and training the final classifier by\npruning weak classifiers which contribute little to the asymmetric learning\ncriterion (asymmetric classifier construction). Our model reduction approach\nhelps accelerate the learning time while achieving the pre-determined learning\nobjective. Experimental results on both face and car data sets verify the\neffectiveness of the proposed algorithm. On the FDDB face data sets, our\napproach achieves the state-of-the-art performance, which demonstrates the\nadvantage of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 10:01:19 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 13:42:17 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Paisitkriangkrai", "Sakrapee", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1303.6163", "submitter": "Juan Nunez-Iglesias", "authors": "Juan Nunez-Iglesias, Ryan Kennedy, Toufiq Parag, Jianbo Shi, Dmitri B.\n  Chklovskii", "title": "Machine learning of hierarchical clustering to segment 2D and 3D images", "comments": "15 pages, 8 figures", "journal-ref": "PLoS ONE, 2013, 8(8): e71715", "doi": "10.1371/journal.pone.0071715", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We aim to improve segmentation through the use of machine learning tools\nduring region agglomeration. We propose an active learning approach for\nperforming hierarchical agglomerative segmentation from superpixels. Our method\ncombines multiple features at all scales of the agglomerative process, works\nfor data with an arbitrary number of dimensions, and scales to very large\ndatasets. We advocate the use of variation of information to measure\nsegmentation accuracy, particularly in 3D electron microscopy (EM) images of\nneural tissue, and using this metric demonstrate an improvement over competing\nalgorithms in EM and natural images.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 15:20:09 GMT"}, {"version": "v2", "created": "Mon, 13 May 2013 17:37:05 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2013 11:15:25 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Nunez-Iglesias", "Juan", ""], ["Kennedy", "Ryan", ""], ["Parag", "Toufiq", ""], ["Shi", "Jianbo", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1303.6361", "submitter": "Conrad Sanderson", "authors": "Sandra Mau, Shaokang Chen, Conrad Sanderson, Brian C. Lovell", "title": "Video Face Matching using Subset Selection and Clustering of\n  Probabilistic Multi-Region Histograms", "comments": null, "journal-ref": "International Conference of Image and Vision Computing New Zealand\n  (IVCNZ), 2010", "doi": "10.1109/IVCNZ.2010.6148860", "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing computational efficiency with recognition accuracy is one of the\nmajor challenges in real-world video-based face recognition. A significant\ndesign decision for any such system is whether to process and use all possible\nfaces detected over the video frames, or whether to select only a few \"best\"\nfaces. This paper presents a video face recognition system based on\nprobabilistic Multi-Region Histograms to characterise performance trade-offs\nin: (i) selecting a subset of faces compared to using all faces, and (ii)\ncombining information from all faces via clustering. Three face selection\nmetrics are evaluated for choosing a subset: face detection confidence, random\nsubset, and sequential selection. Experiments on the recently introduced MOBIO\ndataset indicate that the usage of all faces through clustering always\noutperformed selecting only a subset of faces. The experiments also show that\nthe face selection metric based on face detection confidence generally provides\nbetter recognition performance than random or sequential sampling. Moreover,\nthe optimal number of faces varies drastically across selection metric and\nsubsets of MOBIO. Given the trade-offs between computational effort,\nrecognition accuracy and robustness, it is recommended that face feature\nclustering would be most advantageous in batch processing (particularly for\nvideo-based watchlists), whereas face selection methods should be limited to\napplications with significant computational restrictions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 01:34:42 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["Mau", "Sandra", ""], ["Chen", "Shaokang", ""], ["Sanderson", "Conrad", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1303.6377", "submitter": "Zachary Gelbaum", "authors": "Zachary Gelbaum, Mathew Titus", "title": "Simulation of Fractional Brownian Surfaces via Spectral Synthesis on\n  Manifolds", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2014.2348793", "report-no": null, "categories": "cs.CG cs.CV math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the spectral decomposition of the Laplace-Beltrami operator we simulate\nfractal surfaces as random series of eigenfunctions. This approach allows us to\ngenerate random fields over smooth manifolds of arbitrary dimension,\ngeneralizing previous work with fractional Brownian motion with\nmulti-dimensional parameter. We give examples of surfaces with and without\nboundary and discuss implementation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 03:42:23 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Gelbaum", "Zachary", ""], ["Titus", "Mathew", ""]]}, {"id": "1303.6455", "submitter": "Shaode Yu", "authors": "Shaode Yu, Qingsong Zhu, Shibin Wu and Yaoqin Xie", "title": "Performance Evaluation of Edge-Directed Interpolation Methods for Images", "comments": "9 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interpolation methods have been developed for high visual quality, but\nfail for inability to preserve image structures. Edges carry heavy structural\ninformation for detection, determination and classification. Edge-adaptive\ninterpolation approaches become a center of focus. In this paper, performance\nof four edge-directed interpolation methods comparing with two traditional\nmethods is evaluated on two groups of images. These methods include new\nedge-directed interpolation (NEDI), edge-guided image interpolation (EGII),\niterative curvature-based interpolation (ICBI), directional cubic convolution\ninterpolation (DCCI) and two traditional approaches, bi-linear and bi-cubic.\nMeanwhile, no parameters are mentioned to measure edge-preserving ability of\nedge-adaptive interpolation approaches and we proposed two. One evaluates\naccuracy and the other measures robustness of edge-preservation ability.\nPerformance evaluation is based on six parameters. Objective assessment and\nvisual analysis are illustrated and conclusions are drawn from theoretical\nbackgrounds and practical results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 12:35:46 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Yu", "Shaode", ""], ["Zhu", "Qingsong", ""], ["Wu", "Shibin", ""], ["Xie", "Yaoqin", ""]]}, {"id": "1303.6619", "submitter": "Arun P V Arun P V", "authors": "Arun p V and S.K. Katiyar", "title": "An N-dimensional approach towards object based classification of\n  remotely sensed imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensing techniques are widely used for land cover classification and\nurban analysis. The availability of high resolution remote sensing imagery\nlimits the level of classification accuracy attainable from pixel-based\napproach. In this paper object-based classification scheme based on a\nhierarchical support vector machine is introduced. By combining spatial and\nspectral information, the amount of overlap between classes can be decreased;\nthereby yielding higher classification accuracy and more accurate land cover\nmaps. We have adopted certain automatic approaches based on the advanced\ntechniques as Cellular automata and Genetic Algorithm for kernel and tuning\nparameter selection. Performance evaluation of the proposed methodology in\ncomparison with the existing approaches is performed with reference to the\nBhopal city study area.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2013 19:39:20 GMT"}], "update_date": "2013-03-27", "authors_parsed": [["p", "Arun", "V"], ["Katiyar", "S. K.", ""]]}, {"id": "1303.6711", "submitter": "Arun P V Arun P V", "authors": "P. V. Arun, S.K. Katiyar", "title": "An intelligent approach towards automatic shape modeling and object\n  extraction from satellite images using cellular automata based algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic feature extraction domain has witnessed the application of many\nintelligent methodologies over past decade; however detection accuracy of these\napproaches were limited as object geometry and contextual knowledge were not\ngiven enough consideration. In this paper, we propose a frame work for accurate\ndetection of features along with automatic interpolation, and interpretation by\nmodeling feature shape as well as contextual knowledge using advanced\ntechniques such as SVRF, Cellular Neural Network, Core set, and MACA. Developed\nmethodology has been compared with contemporary methods using different\nstatistical measures. Investigations over various satellite images revealed\nthat considerable success was achieved with the CNN approach. CNN has been\neffective in modeling different complex features effectively and complexity of\nthe approach has been considerably reduced using corset optimization. The\nsystem has dynamically used spectral and spatial information for representing\ncontextual knowledge using CNN-prolog approach. System has been also proved to\nbe effective in providing intelligent interpolation and interpretation of\nrandom features.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 00:33:52 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["Arun", "P. V.", ""], ["Katiyar", "S. K.", ""]]}, {"id": "1303.6926", "submitter": "Arun P V Arun P V", "authors": "Dr. S.K. Katiyar, Arun P. V.", "title": "A Comparative Analysis on the Applicability of Entropy in remote sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\nMethodologies were implemented in Matlab and were enhanced with entropy\nvariations. Evaluation of various implementations was based on different\nstatistical parameters with reference to the study area The popular available\nversions like Tsalli's, Shanon's, and Renyi's entropies were analysed in\ncontext of various remote sensing operations namely thresholding, clustering\nand registration.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 18:57:12 GMT"}], "update_date": "2014-05-25", "authors_parsed": [["Katiyar", "Dr. S. K.", ""], ["V.", "Arun P.", ""]]}, {"id": "1303.6927", "submitter": "Arun P V Arun P V", "authors": "Arun P. V., Dr. S.K. Katiyar", "title": "An investigation towards wavelet based optimization of automatic image\n  registration techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is the process of transforming different sets of data into\none coordinate system and is required for various remote sensing applications\nlike change detection, image fusion, and other related areas. The effect of\nincreased relief displacement, requirement of more control points, and\nincreased data volume are the challenges associated with the registration of\nhigh resolution image data. The objective of this research work is to study the\nmost efficient techniques and to investigate the extent of improvement\nachievable by enhancing them with Wavelet transform. The SIFT feature based\nmethod uses the Eigen value for extracting thousands of key points based on\nscale invariant features and these feature points when further enhanced by the\nwavelet transform yields the best results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2013 19:02:02 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["V.", "Arun P.", ""], ["Katiyar", "Dr. S. K.", ""]]}, {"id": "1303.7186", "submitter": "Thouis Jones", "authors": "Verena Kaynig, Amelio Vazquez-Reina, Seymour Knowles-Barley, Mike\n  Roberts, Thouis R. Jones, Narayanan Kasthuri, Eric Miller, Jeff Lichtman,\n  Hanspeter Pfister", "title": "Large-Scale Automatic Reconstruction of Neuronal Processes from Electron\n  Microscopy Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated sample preparation and electron microscopy enables acquisition of\nvery large image data sets. These technical advances are of special importance\nto the field of neuroanatomy, as 3D reconstructions of neuronal processes at\nthe nm scale can provide new insight into the fine grained structure of the\nbrain. Segmentation of large-scale electron microscopy data is the main\nbottleneck in the analysis of these data sets. In this paper we present a\npipeline that provides state-of-the art reconstruction performance while\nscaling to data sets in the GB-TB range. First, we train a random forest\nclassifier on interactive sparse user annotations. The classifier output is\ncombined with an anisotropic smoothing prior in a Conditional Random Field\nframework to generate multiple segmentation hypotheses per image. These\nsegmentations are then combined into geometrically consistent 3D objects by\nsegmentation fusion. We provide qualitative and quantitative evaluation of the\nautomatic segmentation and demonstrate large-scale 3D reconstructions of\nneuronal processes from a $\\mathbf{27,000}$ $\\mathbf{\\mu m^3}$ volume of brain\ntissue over a cube of $\\mathbf{30 \\; \\mu m}$ in each dimension corresponding to\n1000 consecutive image sections. We also introduce Mojo, a proofreading tool\nincluding semi-automated correction of merge errors based on sparse user\nscribbles.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 17:20:20 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Kaynig", "Verena", ""], ["Vazquez-Reina", "Amelio", ""], ["Knowles-Barley", "Seymour", ""], ["Roberts", "Mike", ""], ["Jones", "Thouis R.", ""], ["Kasthuri", "Narayanan", ""], ["Miller", "Eric", ""], ["Lichtman", "Jeff", ""], ["Pfister", "Hanspeter", ""]]}, {"id": "1303.7390", "submitter": "Aasa Feragen", "authors": "Aasa Feragen, Jens Petersen, Dominik Grimm, Asger Dirksen, Jesper\n  Holst Pedersen, Karsten Borgwardt and Marleen de Bruijne", "title": "Geometric tree kernels: Classification of COPD from airway tree geometry", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methodological contributions: This paper introduces a family of kernels for\nanalyzing (anatomical) trees endowed with vector valued measurements made along\nthe tree. While state-of-the-art graph and tree kernels use combinatorial\ntree/graph structure with discrete node and edge labels, the kernels presented\nin this paper can include geometric information such as branch shape, branch\nradius or other vector valued properties. In addition to being flexible in\ntheir ability to model different types of attributes, the presented kernels are\ncomputationally efficient and some of them can easily be computed for large\ndatasets (N of the order 10.000) of trees with 30-600 branches. Combining the\nkernels with standard machine learning tools enables us to analyze the relation\nbetween disease and anatomical tree structure and geometry. Experimental\nresults: The kernels are used to compare airway trees segmented from low-dose\nCT, endowed with branch shape descriptors and airway wall area percentage\nmeasurements made along the tree. Using kernelized hypothesis testing we show\nthat the geometric airway trees are significantly differently distributed in\npatients with Chronic Obstructive Pulmonary Disease (COPD) than in healthy\nindividuals. The geometric tree kernels also give a significant increase in the\nclassification accuracy of COPD from geometric tree structure endowed with\nairway wall thickness measurements in comparison with state-of-the-art methods,\ngiving further insight into the relationship between airway wall thickness and\nCOPD. Software: Software for computing kernels and statistical tests is\navailable at http://image.diku.dk/aasa/software.php.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 13:25:17 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2013 12:11:24 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Feragen", "Aasa", ""], ["Petersen", "Jens", ""], ["Grimm", "Dominik", ""], ["Dirksen", "Asger", ""], ["Pedersen", "Jesper Holst", ""], ["Borgwardt", "Karsten", ""], ["de Bruijne", "Marleen", ""]]}]