[{"id": "0908.1185", "submitter": "Carlos Javier Hernandez-Castro", "authors": "Carlos Javier Hernandez-Castro, Arturo Ribagorda, Yago Saez", "title": "Side-channel attack on labeling CAPTCHAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scheme of attack on the Microsoft's ASIRRA CAPTCHA which\nrepresents a significant shortcut to the intended attacking path, as it is not\nbased in any advance in the state of the art on the field of image recognition.\nAfter studying the ASIRRA Public Corpus, we conclude that the security margin\nas stated by their authors seems to be quite optimistic. Then, we analyze which\nof the studied parameters for the image files seems to disclose the most\nvaluable information for helping in correct classification, arriving at a\nsurprising discovery. This represents a completely new approach to breaking\nCAPTCHAs that can be applied to many of the currently proposed image-labeling\nalgorithms, and to prove this point we show how to use the very same approach\nagainst the HumanAuth CAPTCHA. Lastly, we investigate some measures that could\nbe used to secure the ASIRRA and HumanAuth schemes, but conclude no easy\nsolutions are at hand.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2009 19:54:01 GMT"}], "update_date": "2009-08-11", "authors_parsed": [["Hernandez-Castro", "Carlos Javier", ""], ["Ribagorda", "Arturo", ""], ["Saez", "Yago", ""]]}, {"id": "0908.1369", "submitter": "Meijun Zhu", "authors": "Meijun Zhu and Pengfei Zhang", "title": "Segmentation for radar images based on active contour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exam various geometric active contour methods for radar image\nsegmentation. Due to special properties of radar images, we propose our new\nmodel based on modified Chan-Vese functional. Our method is efficient in\nseparating non-meteorological noises from meteorological images.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2009 18:33:51 GMT"}], "update_date": "2009-08-11", "authors_parsed": [["Zhu", "Meijun", ""], ["Zhang", "Pengfei", ""]]}, {"id": "0908.1919", "submitter": "Patrick Erik Bradley", "authors": "Patrick Erik Bradley", "title": "A dyadic solution of relative pose problems", "comments": "7 pages; references added; typos and Thm 2 corrected (not affecting\n  the other results)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hierarchical interval subdivision is shown to lead to a $p$-adic encoding\nof image data. This allows in the case of the relative pose problem in computer\nvision and photogrammetry to derive equations having 2-adic numbers as\ncoefficients, and to use Hensel's lifting method to their solution. This method\nis applied to the linear and non-linear equations coming from eight, seven or\nfive point correspondences. An inherent property of the method is its\nrobustness.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2009 15:41:44 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2009 14:01:20 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2009 06:50:18 GMT"}], "update_date": "2009-10-01", "authors_parsed": [["Bradley", "Patrick Erik", ""]]}, {"id": "0908.2656", "submitter": "Pooyan Fazli", "authors": "Scott Helmer, David Meger, Pooja Viswanathan, Sancho McCann, Matthew\n  Dockrey, Pooyan Fazli, Tristram Southey, Marius Muja, Michael Joya, Jim\n  Little, David Lowe, Alan Mackworth", "title": "Semantic Robot Vision Challenge: Current State and Future Directions", "comments": "The IJCAI-09 Workshop on Competitions in Artificial Intelligence and\n  Robotics, Pasadena, California, USA, July 11-17, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Robot Vision Competition provided an excellent opportunity for\nour research lab to integrate our many ideas under one umbrella, inspiring both\ncollaboration and new research. The task, visual search for an unknown object,\nis relevant to both the vision and robotics communities. Moreover, since the\ninterplay of robotics and vision is sometimes ignored, the competition provides\na venue to integrate two communities. In this paper, we outline a number of\nmodifications to the competition to both improve the state-of-the-art and\nincrease participation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2009 02:13:27 GMT"}], "update_date": "2009-08-20", "authors_parsed": [["Helmer", "Scott", ""], ["Meger", "David", ""], ["Viswanathan", "Pooja", ""], ["McCann", "Sancho", ""], ["Dockrey", "Matthew", ""], ["Fazli", "Pooyan", ""], ["Southey", "Tristram", ""], ["Muja", "Marius", ""], ["Joya", "Michael", ""], ["Little", "Jim", ""], ["Lowe", "David", ""], ["Mackworth", "Alan", ""]]}, {"id": "0908.3252", "submitter": "Jean-Fran\\c{c}ois Giovannelli", "authors": "R. Boubertakh, J.-F. Giovannelli, A. Herment, A. De Cesare", "title": "Non-quadratic convex regularized reconstruction of MR images from spiral\n  acquisitions", "comments": null, "journal-ref": "Signal Processing, vol. 86, pp. 2479-2494, 2006", "doi": null, "report-no": null, "categories": "cs.CV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining fast MR acquisition sequences and high resolution imaging is a\nmajor issue in dynamic imaging. Reducing the acquisition time can be achieved\nby using non-Cartesian and sparse acquisitions. The reconstruction of MR images\nfrom these measurements is generally carried out using gridding that\ninterpolates the missing data to obtain a dense Cartesian k-space filling. The\nMR image is then reconstructed using a conventional Fast Fourier Transform. The\nestimation of the missing data unavoidably introduces artifacts in the image\nthat remain difficult to quantify.\n  A general reconstruction method is proposed to take into account these\nlimitations. It can be applied to any sampling trajectory in k-space, Cartesian\nor not, and specifically takes into account the exact location of the measured\ndata, without making any interpolation of the missing data in k-space.\nInformation about the expected characteristics of the imaged object is\nintroduced to preserve the spatial resolution and improve the signal to noise\nratio in a regularization framework. The reconstructed image is obtained by\nminimizing a non-quadratic convex objective function. An original rewriting of\nthis criterion is shown to strongly improve the reconstruction efficiency.\nResults on simulated data and on a real spiral acquisition are presented and\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2009 14:03:03 GMT"}], "update_date": "2009-08-25", "authors_parsed": [["Boubertakh", "R.", ""], ["Giovannelli", "J. -F.", ""], ["Herment", "A.", ""], ["De Cesare", "A.", ""]]}, {"id": "0908.3359", "submitter": "Jacek Turski", "authors": "Jacek Turski", "title": "Geometric Analysis of the Conformal Camera for Intermediate-Level Vision\n  and Perisaccadic Perception", "comments": "Ver2 with figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A binocular system developed by the author in terms of projective Fourier\ntransform (PFT) of the conformal camera, which numerically integrates the head,\neyes, and visual cortex, is used to process visual information during saccadic\neye movements. Although we make three saccades per second at the eyeball's\nmaximum speed of 700 deg/sec, our visual system accounts for these incisive eye\nmovements to produce a stable percept of the world. This visual constancy is\nmaintained by neuronal receptive field shifts in various retinotopically\norganized cortical areas prior to saccade onset, giving the brain access to\nvisual information from the saccade's target before the eyes' arrival. It\nintegrates visual information acquisition across saccades. Our modeling\nutilizes basic properties of PFT. First, PFT is computable by FFT in complex\nlogarithmic coordinates that approximate the retinotopy. Second, a translation\nin retinotopic (logarithmic) coordinates, modeled by the shift property of the\nFourier transform, remaps the presaccadic scene into a postsaccadic reference\nframe. It also accounts for the perisaccadic mislocalization observed by human\nsubjects in laboratory experiments. Because our modeling involves\ncross-disciplinary areas of conformal geometry, abstract and computational\nharmonic analysis, computational vision, and visual neuroscience, we include\nthe corresponding background material and elucidate how these different areas\ninterwove in our modeling of primate perception. In particular, we present the\nphysiological and behavioral facts underlying the neural processes related to\nour modeling. We also emphasize the conformal camera's geometry and discuss how\nit is uniquely useful in the intermediate-level vision computational aspects of\nnatural scene understanding.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2009 04:28:59 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2009 06:24:40 GMT"}], "update_date": "2009-08-29", "authors_parsed": [["Turski", "Jacek", ""]]}, {"id": "0908.3380", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal Narayan Chaudhury and Michael Unser", "title": "Construction of Hilbert Transform Pairs of Wavelet Bases and Gabor-like\n  Transforms", "comments": "36 pages, 8 figures", "journal-ref": "IEEE Transactions on Signal Processing, vol 7, no. 9, pp.\n  3411-3425, 2009", "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for constructing Hilbert transform (HT) pairs of\nwavelet bases based on a fundamental approximation-theoretic characterization\nof scaling functions--the B-spline factorization theorem. In particular,\nstarting from well-localized scaling functions, we construct HT pairs of\nbiorthogonal wavelet bases of L^2(R) by relating the corresponding wavelet\nfilters via a discrete form of the continuous HT filter. As a concrete\napplication of this methodology, we identify HT pairs of spline wavelets of a\nspecific flavor, which are then combined to realize a family of complex\nwavelets that resemble the optimally-localized Gabor function for sufficiently\nlarge orders.\n  Analytic wavelets, derived from the complexification of HT wavelet pairs,\nexhibit a one-sided spectrum. Based on the tensor-product of such analytic\nwavelets, and, in effect, by appropriately combining four separable\nbiorthogonal wavelet bases of L^2(R^2), we then discuss a methodology for\nconstructing 2D directional-selective complex wavelets. In particular,\nanalogous to the HT correspondence between the components of the 1D\ncounterpart, we relate the real and imaginary components of these complex\nwavelets using a multi-dimensional extension of the HT--the directional HT.\nNext, we construct a family of complex spline wavelets that resemble the\ndirectional Gabor functions proposed by Daugman. Finally, we present an\nefficient FFT-based filterbank algorithm for implementing the associated\ncomplex wavelet transform.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2009 15:27:09 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Unser", "Michael", ""]]}, {"id": "0908.3383", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal Narayan Chaudhury and Michael Unser", "title": "On the Shiftability of Dual-Tree Complex Wavelet Transforms", "comments": "to appear in IEEE Transactions on Signal Processing", "journal-ref": "IEEE Transactions on Signal Processing, vol. 58(1), pp. 221 - 232,\n  2010", "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dual-tree complex wavelet transform (DT-CWT) is known to exhibit better\nshift-invariance than the conventional discrete wavelet transform. We propose\nan amplitude-phase representation of the DT-CWT which, among other things,\noffers a direct explanation for the improvement in the shift-invariance. The\nrepresentation is based on the shifting action of the group of fractional\nHilbert transform (fHT) operators, which extends the notion of arbitrary\nphase-shifts from sinusoids to finite-energy signals (wavelets in particular).\nIn particular, we characterize the shiftability of the DT-CWT in terms of the\nshifting property of the fHTs. At the heart of the representation are certain\nfundamental invariances of the fHT group, namely that of translation, dilation,\nand norm, which play a decisive role in establishing the key properties of the\ntransform. It turns out that these fundamental invariances are exclusive to\nthis group.\n  Next, by introducing a generalization of the Bedrosian theorem for the fHT\noperator, we derive an explicitly understanding of the shifting action of the\nfHT for the particular family of wavelets obtained through the modulation of\nlowpass functions (e.g., the Shannon and Gabor wavelet). This, in effect, links\nthe corresponding dual-tree transform with the framework of windowed-Fourier\nanalysis. Finally, we extend these ideas to the multi-dimensional setting by\nintroducing a directional extension of the fHT, the fractional directional\nHilbert transform. In particular, we derive a signal representation involving\nthe superposition of direction-selective wavelets with appropriate\nphase-shifts, which helps explain the improved shift-invariance of the\ntransform along certain preferential directions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2009 15:18:41 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Unser", "Michael", ""]]}, {"id": "0908.3855", "submitter": "Kunal Narayan Chaudhury Dr.", "authors": "Kunal Narayan Chaudhury and Michael Unser", "title": "Gabor wavelet analysis and the fractional Hilbert transform", "comments": "7 pages, 1 figure", "journal-ref": "SPIE Proceedings: Wavelets XIII 2009", "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an amplitude-phase representation of the dual-tree complex wavelet\ntransform (DT-CWT) which provides an intuitive interpretation of the associated\ncomplex wavelet coefficients. The representation, in particular, is based on\nthe shifting action of the group of fractional Hilbert transforms (fHT) which\nallow us to extend the notion of arbitrary phase-shifts beyond pure sinusoids.\nWe explicitly characterize this shifting action for a particular family of\nGabor-like wavelets which, in effect, links the corresponding dual-tree\ntransform with the framework of windowed-Fourier analysis.\n  We then extend these ideas to the bivariate DT-CWT based on certain\ndirectional extensions of the fHT. In particular, we derive a signal\nrepresentation involving the superposition of direction-selective wavelets\naffected with appropriate phase-shifts.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2009 16:24:08 GMT"}], "update_date": "2010-03-11", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Unser", "Michael", ""]]}, {"id": "0908.3861", "submitter": "Kunal Narayan Chaudhury Dr.", "authors": "Kunal Narayan Chaudhury, Arrate Munoz Barrutia and Michael Unser", "title": "Fast adaptive elliptical filtering using box splines", "comments": "9 pages, 1 figure", "journal-ref": "Proceedings IEEE International Conference on Image Processing,\n  2008", "doi": "10.1109/ICIP.2008.4711872", "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that it is possible to filter an image with an elliptic window\nof varying size, elongation and orientation with a fixed computational cost per\npixel. Our method involves the application of a suitable global pre-integrator\nfollowed by a pointwise-adaptive localization mesh. We present the basic theory\nfor the 1D case using a B-spline formalism and then appropriately extend it to\n2D using radially-uniform box splines. The size and ellipticity of these\nradially-uniform box splines is adaptively controlled. Moreover, they converge\nto Gaussians as the order increases. Finally, we present a fast and practical\ndirectional filtering algorithm that has the capability of adapting to the\nlocal image features.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2009 16:44:42 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2009 12:53:35 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Barrutia", "Arrate Munoz", ""], ["Unser", "Michael", ""]]}, {"id": "0908.4310", "submitter": "Beatriz Susana Marron", "authors": "Beatriz Marron", "title": "Co-occurrence Matrix and Fractal Dimension for Image Segmentation", "comments": "This paper has been withdrawn by the author", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important tasks in image processing problem and machine\nvision is object recognition, and the success of many proposed methods relies\non a suitable choice of algorithm for the segmentation of an image. This paper\nfocuses on how to apply texture operators based on the concept of fractal\ndimension and cooccurence matrix, to the problem of object recognition and a\nnew method based on fractal dimension is introduced. Several images, in which\nthe result of the segmentation can be shown, are used to illustrate the use of\neach method and a comparative study of each operator is made.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2009 01:48:16 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 11:53:23 GMT"}], "update_date": "2011-12-07", "authors_parsed": [["Marron", "Beatriz", ""]]}, {"id": "0908.4386", "submitter": "R Doomun", "authors": "Reza Gharoie Ahangar, Mohammad Farajpoor Ahangar", "title": "Handwritten Farsi Character Recognition using Artificial Neural Network", "comments": "4 pages IEEE format, International Journal Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 4, No. 1 & 2, August 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks are being used for character recognition from last many years\nbut most of the work was confined to English character recognition. Till date,\na very little work has been reported for Handwritten Farsi Character\nrecognition. In this paper, we have made an attempt to recognize handwritten\nFarsi characters by using a multilayer perceptron with one hidden layer. The\nerror backpropagation algorithm has been used to train the MLP network. In\naddition, an analysis has been carried out to determine the number of hidden\nnodes to achieve high performance of backpropagation network in the recognition\nof handwritten Farsi characters. The system has been trained using several\ndifferent forms of handwriting provided by both male and female participants of\ndifferent age groups. Finally, this rigorous training results an automatic HCR\nsystem using MLP network. In this work, the experiments were carried out on two\nhundred fifty samples of five writers. The results showed that the MLP networks\ntrained by the error backpropagation algorithm are superior in recognition\naccuracy and memory usage. The result indicates that the backpropagation\nnetwork provides good recognition accuracy of more than 80% of handwritten\nFarsi characters.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2009 11:55:48 GMT"}], "update_date": "2009-09-01", "authors_parsed": [["Ahangar", "Reza Gharoie", ""], ["Ahangar", "Mohammad Farajpoor", ""]]}]