[{"id": "1105.0079", "submitter": "Azrulhizam Shapi'i", "authors": "Azrulhizam Shapi'i, Riza Sulaiman, Mohammad Khatim Hasan and Abdul\n  Yazid Mohd Kassim", "title": "An Automated Size Recognition Technique for Acetabular Implant in Total\n  Hip Replacement", "comments": null, "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT), Vol 3, No 2, April 2011", "doi": "10.5121/ijcsit.2011.3218", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preoperative templating in Total Hip Replacement (THR) is a method to\nestimate the optimal size and position of the implant. Today, observational\n(manual) size recognition techniques are still used to find a suitable implant\nfor the patient. Therefore, a digital and automated technique should be\ndeveloped so that the implant size recognition process can be effectively\nimplemented. For this purpose, we have introduced the new technique for\nacetabular implant size recognition in THR preoperative planning based on the\ndiameter of acetabulum size. This technique enables the surgeon to recognise a\ndigital acetabular implant size automatically. Ten randomly selected X-rays of\nunidentified patients were used to test the accuracy and utility of an\nautomated implant size recognition technique. Based on the testing result, the\nnew technique yielded very close results to those obtained by the observational\nmethod in nine studies (90%).\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2011 12:07:11 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Shapi'i", "Azrulhizam", ""], ["Sulaiman", "Riza", ""], ["Hasan", "Mohammad Khatim", ""], ["Kassim", "Abdul Yazid Mohd", ""]]}, {"id": "1105.0121", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh and Pedro Contreras", "title": "Methods of Hierarchical Clustering", "comments": "21 pages, 2 figures, 1 table, 69 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey agglomerative hierarchical clustering algorithms and discuss\nefficient implementations that are available in R and other software\nenvironments. We look at hierarchical self-organizing maps, and mixture models.\nWe review grid-based clustering, focusing on hierarchical density-based\napproaches. Finally we describe a recently developed very efficient (linear\ntime) hierarchical clustering algorithm, which can also be viewed as a\nhierarchical grid-based algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2011 21:29:08 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Murtagh", "Fionn", ""], ["Contreras", "Pedro", ""]]}, {"id": "1105.0821", "submitter": "Radu Arsinte", "authors": "Radu Arsinte, Ciprian Ilioaei", "title": "Considerations and Results in Multimedia and DVB Application Development\n  on Philips Nexperia Platform", "comments": "3 pages, 1 figure", "journal-ref": "Scientific Bulletin of the \"Politehnica\" University Timi\\c{s}oara,\n  Transaction on Electronics and Telecomunications, Tom 49(63), Fascicola 2,\n  2004, pag. 138-141", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents some experiments regarding applications development on\nhigh performance media processors included in Philips Nexperia Family. The\nPNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded\nto overcome these limitations and to make possible a general-purpose use of\nthis kit. For exemplification two typical applications, important both for\nmultimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio\ndecoding. These original implementations are compared (in speed, memory\nrequirements and costs) with Philips Nexperia Library.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 13:40:16 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Arsinte", "Radu", ""], ["Ilioaei", "Ciprian", ""]]}, {"id": "1105.0826", "submitter": "Radu Arsinte", "authors": "Radu Arsinte, Eugen Lupu", "title": "Streaming Multimedia Information Using the Features of the DVB-S Card", "comments": "4 pages, 5 figures", "journal-ref": "Scientific Bulletin of the \"Politehnica\" University Timi\\c{s}oara,\n  Transaction on Electronics and Telecomunications, Tom 51(65), Fascicola 1-2,\n  pag. 181-184, 2006", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of audio-video streaming using the additional\npossibilities of a DVB-S card. The board used for experiments (Technisat\nSkyStar 2) is one of the most frequently used cards for this purpose. Using the\nmain blocks of the board's software support it is possible the implement a\nreally useful and full functional system for audio-video streaming. The\nstreaming is possible to be implemented either for decoded MPEG stream or for\ntransport stream. In this last case it is possible to view not only a program,\nbut any program from the same multiplex. This allows us to implement\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 13:46:31 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Arsinte", "Radu", ""], ["Lupu", "Eugen", ""]]}, {"id": "1105.1302", "submitter": "Wooram Park", "authors": "Wooram Park and Gregory S. Chirikjian", "title": "A Modified Cross Correlation Algorithm for Reference-free Image\n  Alignment of Non-Circular Projections in Single-Particle Electron Microscopy", "comments": "29pages", "journal-ref": null, "doi": "10.1016/j.bpj.2010.12.1961", "report-no": null, "categories": "q-bio.QM cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a modified cross correlation method to align images\nfrom the same class in single-particle electron microscopy of highly\nnon-spherical structures. In this new method, First we coarsely align\nprojection images, and then re-align the resulting images using the cross\ncorrelation (CC) method. The coarse alignment is obtained by matching the\ncenters of mass and the principal axes of the images. The distribution of\nmisalignment in this coarse alignment can be quantified based on the\nstatistical properties of the additive background noise. As a consequence, the\nsearch space for re-alignment in the cross correlation method can be reduced to\nachieve better alignment. In order to overcome problems associated with false\npeaks in the cross correlations function, we use artificially blurred images\nfor the early stage of the iterative cross correlation method and segment the\nintermediate class average from every iteration step. These two additional\nmanipulations combined with the reduced search space size in the cross\ncorrelation method yield better alignments for low signal-to-noise ratio images\nthan both classical cross correlation and maximum likelihood(ML) methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 15:25:25 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Park", "Wooram", ""], ["Chirikjian", "Gregory S.", ""]]}, {"id": "1105.2491", "submitter": "Riccardo Satta", "authors": "Riccardo Satta, Giorgio Fumera, Fabio Roli, Marco Cristani and\n  Vittorio Murino", "title": "A Multiple Component Matching Framework for Person Re-Identification", "comments": "Accepted paper, 16th Int. Conf. on Image Analysis and Processing\n  (ICIAP 2011), Ravenna, Italy, 14/09/2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification consists in recognizing an individual that has\nalready been observed over a network of cameras. It is a novel and challenging\nresearch topic in computer vision, for which no reference framework exists yet.\nDespite this, previous works share similar representations of human body based\non part decomposition and the implicit concept of multiple instances. Building\non these similarities, we propose a Multiple Component Matching (MCM) framework\nfor the person re-identification problem, which is inspired by Multiple\nComponent Learning, a framework recently proposed for object detection. We show\nthat previous techniques for person re-identification can be considered\nparticular implementations of our MCM framework. We then present a novel person\nre-identification technique as a direct, simple implementation of our\nframework, focused in particular on robustness to varying lighting conditions,\nand show that it can attain state of the art performances.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 14:46:01 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 10:54:55 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Satta", "Riccardo", ""], ["Fumera", "Giorgio", ""], ["Roli", "Fabio", ""], ["Cristani", "Marco", ""], ["Murino", "Vittorio", ""]]}, {"id": "1105.2782", "submitter": "Yong Zhang", "authors": "Yong Zhang, Bin Dong and Zhaosong Lu", "title": "$\\ell_0$ Minimization for Wavelet Frame Based Image Restoration", "comments": "17 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.FA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of (tight) wavelet frames has been extensively studied in the past\ntwenty years and they are currently widely used for image restoration and other\nimage processing and analysis problems. The success of wavelet frame based\nmodels, including balanced approach and analysis based approach, is due to\ntheir capability of sparsely approximating piecewise smooth functions like\nimages. Motivated by the balanced approach and analysis based approach, we\nshall propose a wavelet frame based $\\ell_0$ minimization model, where the\n$\\ell_0$ \"norm\" of the frame coefficients is penalized. We adapt the penalty\ndecomposition (PD) method to solve the proposed optimization problem. Numerical\nresults showed that the proposed model solved by the PD method can generate\nimages with better quality than those obtained by either analysis based\napproach or balanced approach in terms of restoring sharp features as well as\nmaintaining smoothness of the recovered images. Some convergence analysis of\nthe PD method will also be provided.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 17:23:27 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2011 17:23:20 GMT"}], "update_date": "2011-10-31", "authors_parsed": [["Zhang", "Yong", ""], ["Dong", "Bin", ""], ["Lu", "Zhaosong", ""]]}, {"id": "1105.2795", "submitter": "Afzal  Godil", "authors": "Helin Dutagaci, Afzal Godil, Bulent Sankur, Y\\\"ucel Yemez", "title": "View subspaces for indexing and retrieval of 3D models", "comments": "Three-Dimensional Image Processing (3DIP) and Applications\n  (Proceedings Volume) Proceedings of SPIE Volume: 7526 Editor(s): Atilla M.\n  Baskurt ISBN: 9780819479198 Date: 2 February 2010", "journal-ref": null, "doi": "10.1117/12.839186", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  View-based indexing schemes for 3D object retrieval are gaining popularity\nsince they provide good retrieval results. These schemes are coherent with the\ntheory that humans recognize objects based on their 2D appearances. The\nviewbased techniques also allow users to search with various queries such as\nbinary images, range images and even 2D sketches. The previous view-based\ntechniques use classical 2D shape descriptors such as Fourier invariants,\nZernike moments, Scale Invariant Feature Transform-based local features and 2D\nDigital Fourier Transform coefficients. These methods describe each object\nindependent of others. In this work, we explore data driven subspace models,\nsuch as Principal Component Analysis, Independent Component Analysis and\nNonnegative Matrix Factorization to describe the shape information of the\nviews. We treat the depth images obtained from various points of the view\nsphere as 2D intensity images and train a subspace to extract the inherent\nstructure of the views within a database. We also show the benefit of\ncategorizing shapes according to their eigenvalue spread. Both the shape\ncategorization and data-driven feature set conjectures are tested on the PSB\ndatabase and compared with the competitor view-based 3D shape retrieval\nalgorithms\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 18:24:10 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Dutagaci", "Helin", ""], ["Godil", "Afzal", ""], ["Sankur", "Bulent", ""], ["Yemez", "Y\u00fccel", ""]]}, {"id": "1105.2796", "submitter": "Afzal  Godil", "authors": "Afzal Godil, Asim Imdad Wagan", "title": "Salient Local 3D Features for 3D Shape Retrieval", "comments": "Three-Dimensional Imaging, Interaction, and Measurement. Edited by\n  Beraldin, J. Angelo; Cheok, Geraldine S.; McCarthy, Michael B.;\n  Neuschaefer-Rube, Ulrich; Baskurt, Atilla M.; McDowall, Ian E.; Dolinsky,\n  Margaret. Proceedings of the SPIE, Volume 7864, pp. 78640S-78640S-8 (2011).\n  Conference Location: San Francisco Airport, California, USA ISBN:\n  9780819484017 Date: 10 March 2011", "journal-ref": null, "doi": "10.1117/12.872984", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper we describe a new formulation for the 3D salient local features\nbased on the voxel grid inspired by the Scale Invariant Feature Transform\n(SIFT). We use it to identify the salient keypoints (invariant points) on a 3D\nvoxelized model and calculate invariant 3D local feature descriptors at these\nkeypoints. We then use the bag of words approach on the 3D local features to\nrepresent the 3D models for shape retrieval. The advantages of the method are\nthat it can be applied to rigid as well as to articulated and deformable 3D\nmodels. Finally, this approach is applied for 3D Shape Retrieval on the McGill\narticulated shape benchmark and then the retrieval results are presented and\ncompared to other methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 18:25:15 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Godil", "Afzal", ""], ["Wagan", "Asim Imdad", ""]]}, {"id": "1105.2797", "submitter": "Afzal  Godil", "authors": "Afzal Godil, Sandy Ressler and Patrick Grother", "title": "Face Recognition using 3D Facial Shape and Color Map Information:\n  Comparison and Combination", "comments": "Proceedings of SPIE Vol. 5404 Biometric Technology for Human\n  Identification, Anil K. Jain; Nalini K. Ratha, Editors, pp.351-361, ISBN:\n  9780819453273 Date: 25 August 2004", "journal-ref": null, "doi": "10.1117/12.540754", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper, we investigate the use of 3D surface geometry for face\nrecognition and compare it to one based on color map information. The 3D\nsurface and color map data are from the CAESAR anthropometric database. We find\nthat the recognition performance is not very different between 3D surface and\ncolor map information using a principal component analysis algorithm. We also\ndiscuss the different techniques for the combination of the 3D surface and\ncolor map information for multi-modal recognition by using different fusion\napproaches and show that there is significant improvement in results. The\neffectiveness of various techniques is compared and evaluated on a dataset with\n200 subjects in two different positions.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 18:25:28 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Godil", "Afzal", ""], ["Ressler", "Sandy", ""], ["Grother", "Patrick", ""]]}, {"id": "1105.2800", "submitter": "Afzal  Godil", "authors": "Afzal Godil, Sandy Ressler", "title": "Retrieval and Clustering from a 3D Human Database based on Body and Head\n  Shape", "comments": "Published in Proceedings of the 2006 Digital Human Modeling for\n  Design and Engineering Conference, July 2006, Lyon, FRANCE, Session: Advanced\n  Size/Shape Analysis Paper Number: 2006-01-2355\n  http://papers.sae.org/2006-01-2355", "journal-ref": null, "doi": "10.4271/2006-01-2355", "report-no": null, "categories": "cs.CV cs.CG", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper, we describe a framework for similarity based retrieval and\nclustering from a 3D human database. Our technique is based on both body and\nhead shape representation and the retrieval is based on similarity of both of\nthem. The 3D human database used in our study is the CAESAR anthropometric\ndatabase which contains approximately 5000 bodies. We have developed a\nweb-based interface for specifying the queries to interact with the retrieval\nsystem. Our approach performs the similarity based retrieval in a reasonable\namount of time and is a practical approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 18:38:36 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Godil", "Afzal", ""], ["Ressler", "Sandy", ""]]}, {"id": "1105.2831", "submitter": "Brandon Rowekamp", "authors": "Brandon Rowekamp", "title": "Planar Pixelations and Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any subset of the plane can be approximated by a set of square pixels. This\ntransition from a shape to its pixelation is rather brutal since it destroys\ngeometric and topological information about the shape. Using a technique\ninspired by Morse Theory, we algorithmically produce a PL approximation of the\noriginal shape using only information from its pixelation. This approximation\nconverges to the original shape in a very strong sense: as the size of the\npixels goes to zero we can recover important geometric and topological\ninvariants of the original shape such as Betti numbers, area, perimeter and\ncurvature measures.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 20:21:09 GMT"}], "update_date": "2011-05-17", "authors_parsed": [["Rowekamp", "Brandon", ""]]}, {"id": "1105.3270", "submitter": "J\\\"urgen Pannek", "authors": "Maria H\\\"anel, Stefan Kuhn, Dominik Henrich, Lars Gr\\\"une and J\\\"urgen\n  Pannek", "title": "Optimal Camera Placement to measure Distances Conservativly Regarding\n  Static and Dynamic Obstacles", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern production facilities industrial robots and humans are supposed to\ninteract sharing a common working area. In order to avoid collisions, the\ndistances between objects need to be measured conservatively which can be done\nby a camera network. To estimate the acquired distance, unmodelled objects,\ne.g., an interacting human, need to be modelled and distinguished from\npremodelled objects like workbenches or robots by image processing such as the\nbackground subtraction method.\n  The quality of such an approach massively depends on the settings of the\ncamera network, that is the positions and orientations of the individual\ncameras. Of particular interest in this context is the minimization of the\nerror of the distance using the objects modelled by the background subtraction\nmethod instead of the real objects. Here, we show how this minimization can be\nformulated as an abstract optimization problem. Moreover, we state various\naspects on the implementation as well as reasons for the selection of a\nsuitable optimization method, analyze the complexity of the proposed method and\npresent a basic version used for extensive experiments.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2011 03:03:45 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["H\u00e4nel", "Maria", ""], ["Kuhn", "Stefan", ""], ["Henrich", "Dominik", ""], ["Gr\u00fcne", "Lars", ""], ["Pannek", "J\u00fcrgen", ""]]}, {"id": "1105.3559", "submitter": "Rocio Gonzalez-Diaz", "authors": "Rocio Gonzalez-Diaz, Adrian Ion, Mabel Iglesias-Ham, Walter G.\n  Kropatsch", "title": "Invariant Representative Cocycles of Cohomology Generators using\n  Irregular Graph Pyramids", "comments": "Special issue on Graph-Based Representations in Computer Vision", "journal-ref": "Computer Vision and Image Understanding, Volume 115, Issue 7, July\n  2011, Pages 1011-1022", "doi": "10.1016/j.cviu.2010.12.009", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural pattern recognition describes and classifies data based on the\nrelationships of features and parts. Topological invariants, like the Euler\nnumber, characterize the structure of objects of any dimension. Cohomology can\nprovide more refined algebraic invariants to a topological space than does\nhomology. It assigns `quantities' to the chains used in homology to\ncharacterize holes of any dimension. Graph pyramids can be used to describe\nsubdivisions of the same object at multiple levels of detail. This paper\npresents cohomology in the context of structural pattern recognition and\nintroduces an algorithm to efficiently compute representative cocycles (the\nbasic elements of cohomology) in 2D using a graph pyramid. An extension to\nobtain scanning and rotation invariant cocycles is given.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 08:18:42 GMT"}, {"version": "v2", "created": "Fri, 20 May 2011 22:19:35 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2011 08:43:19 GMT"}, {"version": "v4", "created": "Wed, 13 Jul 2011 13:34:55 GMT"}], "update_date": "2011-07-14", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Ion", "Adrian", ""], ["Iglesias-Ham", "Mabel", ""], ["Kropatsch", "Walter G.", ""]]}, {"id": "1105.3617", "submitter": "Abhishek Dutta", "authors": "Abhishek Dutta", "title": "Face Shape and Reflectance Acquisition using a Multispectral Light Stage", "comments": "MSc thesis submitted for the degree of Master of Science (M.Sc.) to\n  Department of Computer Science (University of York, UK) on Oct. 26, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this thesis, we discuss the design and calibration (geometric and\nradiometric) of a novel shape and reflectance acquisition device called the\n\"Multispectral Light Stage\". This device can capture highly detailed facial\ngeometry (down to the level of skin pores detail) and Multispectral reflectance\nmap which can be used to estimate biophysical skin parameters such as the\ndistribution of pigmentation and blood beneath the surface of the skin. We\nextend the analysis of the original spherical gradient photometric stereo\nmethod to study the effects of deformed diffuse lobes on the quality of\nrecovered surface normals. Based on our modified radiance equations, we develop\na minimal image set method to recover high quality photometric normals using\nonly four, instead of six, spherical gradient images. Using the same radiance\nequations, we explore a Quadratic Programming (QP) based algorithm for\ncorrection of surface normals obtained using spherical gradient photometric\nstereo. Based on the proposed minimal image sets method, we present a\nperformance capture sequence that significantly reduces the data capture\nrequirement and post-processing computational cost of existing photometric\nstereo based performance geometry capture methods. Furthermore, we explore the\nuse of images captured in our Light Stage to generate stimuli images for a\npsychology experiment exploring the neural representation of 3D shape and\ntexture of a human face.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 13:00:44 GMT"}], "update_date": "2011-05-19", "authors_parsed": [["Dutta", "Abhishek", ""]]}, {"id": "1105.3685", "submitter": "Afzal  Godil", "authors": "Afzal Godil, Zhouhui Lian, Helin Dutagaci, Rui Fang, Vanamali T.P.,\n  Chun Pan Cheung", "title": "Benchmarks, Performance Evaluation and Contests for 3D Shape Retrieval", "comments": "Performance Metrics for Intelligent Systems (PerMIS'10) Workshop,\n  September, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Benchmarking of 3D Shape retrieval allows developers and researchers to\ncompare the strengths of different algorithms on a standard dataset. Here we\ndescribe the procedures involved in developing a benchmark and issues involved.\nWe then discuss some of the current 3D shape retrieval benchmarks efforts of\nour group and others. We also review the different performance evaluation\nmeasures that are developed and used by researchers in the community. After\nthat we give an overview of the 3D shape retrieval contest (SHREC) tracks run\nunder the EuroGraphics Workshop on 3D Object Retrieval and give details of\ntracks that we organized for SHREC 2010. Finally we demonstrate some of the\nresults based on the different SHREC contest tracks and the NIST shape\nbenchmark.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2011 16:48:47 GMT"}], "update_date": "2011-05-19", "authors_parsed": [["Godil", "Afzal", ""], ["Lian", "Zhouhui", ""], ["Dutagaci", "Helin", ""], ["Fang", "Rui", ""], ["P.", "Vanamali T.", ""], ["Cheung", "Chun Pan", ""]]}, {"id": "1105.3828", "submitter": "Evgeniy Martyushev", "authors": "Evgeniy Martyushev", "title": "An Algorithmic Solution to the Five-Point Pose Problem Based on the\n  Cayley Representation of Rotations", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new algorithmic solution to the well-known five-point relative pose\nproblem. Our approach does not deal with the famous cubic constraint on an\nessential matrix. Instead, we use the Cayley representation of rotations in\norder to obtain a polynomial system from epipolar constraints. Solving that\nsystem, we directly get relative rotation and translation parameters of the\ncameras in terms of roots of a 10th degree polynomial.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 09:50:01 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2013 07:28:58 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Martyushev", "Evgeniy", ""]]}, {"id": "1105.3829", "submitter": "Alexander Alekseychuk Dr.-Ing.", "authors": "Alexander Alekseychuk", "title": "Hierarchical Recursive Running Median", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, the histogram-based running median filter of Perreault and H\\'ebert\nis considered the fastest for 8-bit images, being roughly O(1) in average case.\nWe present here another approximately constant time algorithm which further\nimproves the aforementioned one and exhibits lower associated constant, being\nat the time of writing the lowest theoretical complexity algorithm for\ncalculation of 2D and higher dimensional median filters. The algorithm scales\nnaturally to higher precision (e.g. 16-bit) integer data without any\nmodifications. Its adaptive version offers additional speed-up for images\nshowing compact modes in gray-value distribution. The experimental comparison\nto the previous constant-time algorithm defines the application domain of this\nnew development, besides theoretical interest, as high bit depth data and/or\nhardware without SIMD extensions. The C/C++ implementation of the algorithm is\navailable under GPL for research purposes.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 09:50:31 GMT"}, {"version": "v2", "created": "Wed, 25 May 2011 12:58:15 GMT"}, {"version": "v3", "created": "Mon, 16 Jan 2012 22:27:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Alekseychuk", "Alexander", ""]]}, {"id": "1105.3834", "submitter": "Andrea Spadaccini", "authors": "Andrea Spadaccini and Vanni Rizzo", "title": "A Multiple-Choice Test Recognition System based on the Gamera Framework", "comments": "11 pages, 4 figures", "journal-ref": "C. Dalitz (Ed.): \"Document Image Analysis with the Gamera\n  Framework.\" Schriftenreihe des Fachbereichs Elektrotechnik und Informatik,\n  Hochschule Niederrhein, vol. 8, pp.5-15, Shaker Verlag (2009)", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes JECT-OMR, a system that analyzes digital images\nrepresenting scans of multiple-choice tests compiled by students. The system\nperforms a structural analysis of the document in order to get the chosen\nanswer for each question, and it also contains a bar-code decoder, used for the\nidentification of additional information encoded in the document. JECT-OMR was\nimplemented using the Python programming language, and leverages the power of\nthe Gamera framework in order to accomplish its task. The system exhibits an\naccuracy of over 99% in the recognition of marked and non-marked squares\nrepresenting answers, thus making it suitable for real world applications\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 10:09:44 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Spadaccini", "Andrea", ""], ["Rizzo", "Vanni", ""]]}, {"id": "1105.4058", "submitter": "Andrea Spadaccini", "authors": "Francesco Beritelli and Andrea Spadaccini", "title": "Human Identity Verification based on Heart Sounds: Recent Advances and\n  Future Directions", "comments": "18 pages, chapter to be published in the book \"Biometrics / Book 1\",\n  ISBN 978-953-307-618-8, by InTech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Identity verification is an increasingly important process in our daily\nlives, and biometric recognition is a natural solution to the authentication\nproblem.\n  One of the most important research directions in the field of biometrics is\nthe characterization of novel biometric traits that can be used in conjunction\nwith other traits, to limit their shortcomings or to enhance their performance.\n  The aim of this work is to introduce the reader to the usage of heart sounds\nfor biometric recognition, describing the strengths and the weaknesses of this\nnovel trait and analyzing in detail the methods developed so far by different\nresearch groups and their performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 11:08:48 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Beritelli", "Francesco", ""], ["Spadaccini", "Andrea", ""]]}, {"id": "1105.4183", "submitter": "Rocio Gonzalez-Diaz", "authors": "Rocio Gonzalez-Diaz, Maria Jose Jimenez, Belen Medrano", "title": "Cubical Cohomology Ring of 3D Photographs", "comments": null, "journal-ref": "Cubical cohomology ring of 3D photographs. International Journal\n  of Imaging Systems and Technology. Volume 21, Issue 1, March 2011, Pages:\n  76--85, Rocio Gonzalez-Diaz, Maria Jose Jimenez and Belen Medrano", "doi": "10.1002/ima.20271", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cohomology and cohomology ring of three-dimensional (3D) objects are\ntopological invariants that characterize holes and their relations. Cohomology\nring has been traditionally computed on simplicial complexes. Nevertheless,\ncubical complexes deal directly with the voxels in 3D images, no additional\ntriangulation is necessary, facilitating efficient algorithms for the\ncomputation of topological invariants in the image context. In this paper, we\npresent formulas to directly compute the cohomology ring of 3D cubical\ncomplexes without making use of any additional triangulation. Starting from a\ncubical complex $Q$ that represents a 3D binary-valued digital picture whose\nforeground has one connected component, we compute first the cohomological\ninformation on the boundary of the object, $\\partial Q$ by an incremental\ntechnique; then, using a face reduction algorithm, we compute it on the whole\nobject; finally, applying the mentioned formulas, the cohomology ring is\ncomputed from such information.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 22:12:41 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Jimenez", "Maria Jose", ""], ["Medrano", "Belen", ""]]}, {"id": "1105.4204", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal Narayan Chaudhury, Daniel Sage, and Michael Unser", "title": "Fast O(1) bilateral filtering using trigonometric range kernels", "comments": "Accepted in IEEE Transactions on Image Processing. Also see addendum:\n  https://sites.google.com/site/kunalspage/home/Addendum.pdf", "journal-ref": "IEEE Transactions on Image Processing, vol. 20(12), pp. 3376 -\n  3382, 2011", "doi": null, "report-no": null, "categories": "cs.CV cs.CE cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that spatial averaging can be realized (in space or\nfrequency domain) using algorithms whose complexity does not depend on the size\nor shape of the filter. These fast algorithms are generally referred to as\nconstant-time or O(1) algorithms in the image processing literature. Along with\nthe spatial filter, the edge-preserving bilateral filter [Tomasi1998] involves\nan additional range kernel. This is used to restrict the averaging to those\nneighborhood pixels whose intensity are similar or close to that of the pixel\nof interest. The range kernel operates by acting on the pixel intensities. This\nmakes the averaging process non-linear and computationally intensive,\nespecially when the spatial filter is large. In this paper, we show how the\nO(1) averaging algorithms can be leveraged for realizing the bilateral filter\nin constant-time, by using trigonometric range kernels. This is done by\ngeneralizing the idea in [Porikli2008] of using polynomial range kernels. The\nclass of trigonometric kernels turns out to be sufficiently rich, allowing for\nthe approximation of the standard Gaussian bilateral filter. The attractive\nfeature of our approach is that, for a fixed number of terms, the quality of\napproximation achieved using trigonometric kernels is much superior to that\nobtained in [Porikli2008] using polynomials.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 01:44:38 GMT"}, {"version": "v2", "created": "Thu, 26 May 2011 01:50:38 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2011 17:33:32 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Sage", "Daniel", ""], ["Unser", "Michael", ""]]}, {"id": "1105.4354", "submitter": "Abhishek Das", "authors": "Abhishek Das, Avijit Kar, Debasis Bhattacharyya", "title": "Preprocessing for Automating Early Detection of Cervical Cancer", "comments": "15th International Conference on Information Visualisation (Track:\n  8th International Conference BioMedical Visualization) at London, UK (IEEE\n  Computer Society)", "journal-ref": null, "doi": "10.1109/IV.2011.89", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uterine Cervical Cancer is one of the most common forms of cancer in women\nworldwide. Most cases of cervical cancer can be prevented through screening\nprograms aimed at detecting precancerous lesions. During Digital Colposcopy,\ncolposcopic images or cervigrams are acquired in raw form. They contain\nspecular reflections which appear as bright spots heavily saturated with white\nlight and occur due to the presence of moisture on the uneven cervix surface\nand. The cervix region occupies about half of the raw cervigram image. Other\nparts of the image contain irrelevant information, such as equipment, frames,\ntext and non-cervix tissues. This irrelevant information can confuse automatic\nidentification of the tissues within the cervix. Therefore we focus on the\ncervical borders, so that we have a geometric boundary on the relevant image\narea. Our novel technique eliminates the SR, identifies the region of interest\nand makes the cervigram ready for segmentation algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2011 17:06:59 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2011 09:16:12 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Das", "Abhishek", ""], ["Kar", "Avijit", ""], ["Bhattacharyya", "Debasis", ""]]}, {"id": "1105.4477", "submitter": "Rocio Gonzalez-Diaz", "authors": "Rocio Gonzalez-Diaz, Pedro Real", "title": "On the Cohomology of 3D Digital Images", "comments": "Special Issue: Advances in Discrete Geometry and Topology", "journal-ref": "Discrete Applied Mathematics, Volume 147, Issues 2-3, 15 April\n  2005, Pages 245-263", "doi": "10.1016/j.dam.2004.09.014", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for computing the cohomology ring of three--dimensional\n(3D) digital binary-valued pictures. We obtain the cohomology ring of a 3D\ndigital binary--valued picture $I$, via a simplicial complex K(I)topologically\nrepresenting (up to isomorphisms of pictures) the picture I. The usefulness of\na simplicial description of the \"digital\" cohomology ring of 3D digital\nbinary-valued pictures is tested by means of a small program visualizing the\ndifferent steps of the method. Some examples concerning topological thinning,\nthe visualization of representative (co)cycles of (co)homology generators and\nthe computation of the cup product on the cohomology of simple pictures are\nshowed.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 12:06:18 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Real", "Pedro", ""]]}, {"id": "1105.4480", "submitter": "Rocio Gonzalez-Diaz", "authors": "Rocio Gonzalez-Diaz, Maria Jose Jimenez, Belen Medrano, Pedro Real", "title": "A Tool for Integer Homology Computation: Lambda-At Model", "comments": "Journal Image and Vision Computing, Volume 27 Issue 7, June, 2009", "journal-ref": null, "doi": "10.1016/j.imavis.2008.10.001", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formalize the notion of lambda-AT-model (where $\\lambda$ is\na non-null integer) for a given chain complex, which allows the computation of\nhomological information in the integer domain avoiding using the Smith Normal\nForm of the boundary matrices. We present an algorithm for computing such a\nmodel, obtaining Betti numbers, the prime numbers p involved in the invariant\nfactors of the torsion subgroup of homology, the amount of invariant factors\nthat are a power of p and a set of representative cycles of generators of\nhomology mod p, for each p. Moreover, we establish the minimum valid lambda for\nsuch a construction, what cuts down the computational costs related to the\ntorsion subgroup. The tools described here are useful to determine topological\ninformation of nD structured objects such as simplicial, cubical or simploidal\ncomplexes and are applicable to extract such an information from digital\npictures.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 12:40:06 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Jimenez", "Maria Jose", ""], ["Medrano", "Belen", ""], ["Real", "Pedro", ""]]}, {"id": "1105.4712", "submitter": "H.R.  Chennamma", "authors": "H. R. Chennamma, Lalitha Rangarajan", "title": "Image Splicing Detection Using Inherent Lens Radial Distortion", "comments": "10 pages, 23 figures, 6 tables, Published in IJCSI", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 7,\n  Issue 6, November 2010, pp. 149-158, ISSN (OnlinePrint): 1694-0814", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image splicing is a common form of image forgery. Such alterations may leave\nno visual clues of tampering. In recent works camera characteristics\nconsistency across the image has been used to establish the authenticity and\nintegrity of digital images. Such constant camera characteristic properties are\ninherent from camera manufacturing processes and are unique. The majority of\ndigital cameras are equipped with spherical lens and this introduces radial\ndistortions on images. This aberration is often disturbed and fails to be\nconsistent across the image, when an image is spliced. This paper describes the\ndetection of splicing operation on images by estimating radial distortion from\ndifferent portions of the image using line-based calibration. For the first\ntime, the detection of image splicing through the verification of consistency\nof lens radial distortion has been explored in this paper. The conducted\nexperiments demonstrate the efficacy of our proposed approach for the detection\nof image splicing on both synthetic and real images.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2011 09:05:04 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Chennamma", "H. R.", ""], ["Rangarajan", "Lalitha", ""]]}, {"id": "1105.5307", "submitter": "Karol Gregor", "authors": "Karol Gregor and Yann LeCun", "title": "Efficient Learning of Sparse Invariant Representations", "comments": "9 pages + 6 supplement pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and efficient algorithm for learning sparse invariant\nrepresentations from unlabeled data with fast inference. When trained on short\nmovies sequences, the learned features are selective to a range of orientations\nand spatial frequencies, but robust to a wide range of positions, similar to\ncomplex cells in the primary visual cortex. We give a hierarchical version of\nthe algorithm, and give guarantees of fast convergence under certain\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 14:31:58 GMT"}], "update_date": "2011-05-27", "authors_parsed": [["Gregor", "Karol", ""], ["LeCun", "Yann", ""]]}, {"id": "1105.5675", "submitter": "Jierui Xie", "authors": "Jierui Xie and Mandis S. Beigi", "title": "Scale-Invariant Local Descriptor for Event Recognition in 1D Sensor\n  Signals", "comments": null, "journal-ref": "IEEE International Conference on Multimedia &\n  Expo(ICME),Page(s):1226 - 1229, 2009", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a shape-based, time-scale invariant feature\ndescriptor for 1-D sensor signals. The time-scale invariance of the feature\nallows us to use feature from one training event to describe events of the same\nsemantic class which may take place over varying time scales such as walking\nslow and walking fast. Therefore it requires less training set. The descriptor\ntakes advantage of the invariant location detection in the scale space theory\nand employs a high level shape encoding scheme to capture invariant local\nfeatures of events. Based on this descriptor, a scale-invariant classifier with\n\"R\" metric (SIC-R) is designed to recognize multi-scale events of human\nactivities. The R metric combines the number of matches of keypoint in scale\nspace with the Dynamic Time Warping score. SICR is tested on various types of\n1-D sensors data from passive infrared, accelerometer and seismic sensors with\nmore than 90% classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2011 00:44:54 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Xie", "Jierui", ""], ["Beigi", "Mandis S.", ""]]}, {"id": "1105.6014", "submitter": "Michael Lew", "authors": "Yafei Sun", "title": "Neural Networks for Emotion Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is argued that for the computer to be able to interact with humans, it\nneeds to have the communication skills of humans. One of these skills is the\nability to understand the emotional state of the person. This thesis describes\na neural network-based approach for emotion classification. We learn a\nclassifier that can recognize six basic emotions with an average accuracy of\n77% over the Cohn-Kanade database. The novelty of this work is that instead of\nempirically selecting the parameters of the neural network, i.e. the learning\nrate, activation function parameter, momentum number, the number of nodes in\none layer, etc. we developed a strategy that can automatically select\ncomparatively better combination of these parameters. We also introduce another\nway to perform back propagation. Instead of using the partial differential of\nthe error function, we use optimal algorithm; namely Powell's direction set to\nminimize the error function. We were also interested in construction an\nauthentic emotion databases. This is a very important task because nowadays\nthere is no such database available. Finally, we perform several experiments\nand show that our neural network approach can be successfully used for emotion\nrecognition.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 15:19:55 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Sun", "Yafei", ""]]}, {"id": "1105.6060", "submitter": "Michael Lew", "authors": "Feiyang Yu, Ard Oerlemans, and Erwin M. Bakker", "title": "Alignment of Microtubule Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work discusses preliminary work aimed at simulating and visualizing the\ngrowth process of a tiny structure inside the cell---the microtubule.\nDifficulty of recording the process lies in the fact that the tissue\npreparation method for electronic microscopes is highly destructive to live\ncells. Here in this paper, our approach is to take pictures of microtubules at\ndifferent time slots and then appropriately combine these images into a\ncoherent video. Experimental results are given on real data.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 18:30:51 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Yu", "Feiyang", ""], ["Oerlemans", "Ard", ""], ["Bakker", "Erwin M.", ""]]}, {"id": "1105.6084", "submitter": "Ahmed Kosba", "authors": "Ahmed E. Kosba, Ahmed Saeed and Moustafa Youssef", "title": "RASID: A Robust WLAN Device-free Passive Motion Detection System", "comments": "V1: 14 pages, 11 figures. V2: 16 Pages, 15 figures. The\n  non-parametric model of the system is compared with a parametric model of the\n  system operation. Added 2-sample KS-Test for evaluating the profile update\n  mechanism. Latency in detection decisions was allowed, and parameters\n  configurations tuned accordingly. Same Conclusions. The effect of network\n  activity on system profiles is analyzed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WLAN Device-free passive DfP indoor localization is an emerging technology\nenabling the localization of entities that do not carry any devices nor\nparticipate actively in the localization process using the already installed\nwireless infrastructure. This technology is useful for a variety of\napplications such as intrusion detection, smart homes and border protection. We\npresent the design, implementation and evaluation of RASID, a DfP system for\nhuman motion detection. RASID combines different modules for statistical\nanomaly detection while adapting to changes in the environment to provide\naccurate, robust, and low-overhead detection of human activities using standard\nWiFi hardware. Evaluation of the system in two different testbeds shows that it\ncan achieve an accurate detection capability in both environments with an\nF-measure of at least 0.93. In addition, the high accuracy and low overhead\nperformance are robust to changes in the environment as compared to the current\nstate of the art DfP detection systems. We also relay the lessons learned\nduring building our system and discuss future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 19:39:19 GMT"}, {"version": "v2", "created": "Sun, 12 Feb 2012 03:08:44 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Kosba", "Ahmed E.", ""], ["Saeed", "Ahmed", ""], ["Youssef", "Moustafa", ""]]}, {"id": "1105.6277", "submitter": "Hoi Sim Wong", "authors": "Hoi Sim Wong, Tat-Jun Chin, Jin Yu and David Suter", "title": "Incremental Top-k List Comparison Approach to Robust Multi-Structure\n  Model Fitting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random hypothesis sampling lies at the core of many popular robust fitting\ntechniques such as RANSAC. In this paper, we propose a novel hypothesis\nsampling scheme based on incremental computation of distances between partial\nrankings (top-$k$ lists) derived from residual sorting information. Our method\nsimultaneously (1) guides the sampling such that hypotheses corresponding to\nall true structures can be quickly retrieved and (2) filters the hypotheses\nsuch that only a small but very promising subset remain. This permits the usage\nof simple agglomerative clustering on the surviving hypotheses for accurate\nmodel selection. The outcome is a highly efficient multi-structure robust\nestimation technique. Experiments on synthetic and real data show the superior\nperformance of our approach over previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 13:45:46 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Wong", "Hoi Sim", ""], ["Chin", "Tat-Jun", ""], ["Yu", "Jin", ""], ["Suter", "David", ""]]}]