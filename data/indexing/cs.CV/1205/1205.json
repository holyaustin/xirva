[{"id": "1205.1144", "submitter": "Gianluca Setti", "authors": "Mauro Mangia, Riccardo Rovatti, Gianluca Setti", "title": "Rakeness in the design of Analog-to-Information Conversion of Sparse and\n  Localized Signals", "comments": null, "journal-ref": "IEEE Transactions on Circuits and Systems, Part I, vol. 59, n. 5,\n  pp. 1001-1014, 2012", "doi": "10.1109/TCSI.2012.2191312", "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of Random Modulation Pre-Integration systems based on the\nrestricted-isometry property may be suboptimal when the energy of the signals\nto be acquired is not evenly distributed, i.e. when they are both sparse and\nlocalized. To counter this, we introduce an additional design criterion, that\nwe call rakeness, accounting for the amount of energy that the measurements\ncapture from the signal to be acquired. Hence, for localized signals a proper\nsystem tuning increases the rakeness as well as the average SNR of the samples\nused in its reconstruction. Yet, maximizing average SNR may go against the need\nof capturing all the components that are potentially non-zero in a sparse\nsignal, i.e., against the restricted isometry requirement ensuring\nreconstructability. What we propose is to administer the trade-off between\nrakeness and restricted isometry in a statistical way by laying down an\noptimization problem. The solution of such an optimization problem is the\nstatistic of the process generating the random waveforms onto which the signal\nis projected to obtain the measurements. The formal definition of such a\nproblems is given as well as its solution for signals that are either localized\nin frequency or in more generic domain. Sample applications, to ECG signals and\nsmall images of printed letters and numbers, show that rakeness-based design\nleads to non-negligible improvements in both cases.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2012 14:50:04 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Mangia", "Mauro", ""], ["Rovatti", "Riccardo", ""], ["Setti", "Gianluca", ""]]}, {"id": "1205.1225", "submitter": "Romeil Sandhu", "authors": "Romeil Sandhu, Ayelet Dominitz, Yi Gao, and Allen Tannenbaum", "title": "Volumetric Mapping of Genus Zero Objects via Mass Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a technique to map any genus zero solid object onto\na hexahedral decomposition of a solid cube. This problem appears in many\napplications ranging from finite element methods to visual tracking. From this,\none can then hopefully utilize the proposed technique for shape analysis,\nregistration, as well as other related computer graphics tasks. More\nimportantly, given that we seek to establish a one-to-one correspondence of an\ninput volume to that of a solid cube, our algorithm can naturally generate a\nquality hexahedral mesh as an output. In addition, we constrain the mapping\nitself to be volume preserving allowing for the possibility of further mesh\nsimplification. We demonstrate our method both qualitatively and quantitatively\non various 3D solid models\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 15:32:21 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Sandhu", "Romeil", ""], ["Dominitz", "Ayelet", ""], ["Gao", "Yi", ""], ["Tannenbaum", "Allen", ""]]}, {"id": "1205.1365", "submitter": "Soumen  Kanrar", "authors": "Aroop Mukherjee and Soumen Kanrar", "title": "Image Enhancement with Statistical Estimation", "comments": "9 pages,6 figures; ISSN:0975-5578 (Online); 0975-5934 (Print)", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  April 2012, Volume 4, Number 2, page 59-67", "doi": "10.5121/ijma.2012.4205", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrast enhancement is an important area of research for the image analysis.\nOver the decade, the researcher worked on this domain to develop an efficient\nand adequate algorithm. The proposed method will enhance the contrast of image\nusing Binarization method with the help of Maximum Likelihood Estimation (MLE).\nThe paper aims to enhance the image contrast of bimodal and multi-modal images.\nThe proposed methodology use to collect mathematical information retrieves from\nthe image. In this paper, we are using binarization method that generates the\ndesired histogram by separating image nodes. It generates the enhanced image\nusing histogram specification with binarization method. The proposed method has\nshowed an improvement in the image contrast enhancement compare with the other\nimage.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 12:49:42 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Mukherjee", "Aroop", ""], ["Kanrar", "Soumen", ""]]}, {"id": "1205.1639", "submitter": "Sajilal Divakaran", "authors": "Sajilal Divakaran", "title": "Spectral Analysis of Projection Histogram for Enhancing Close matching\n  character Recognition in Malayalam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success rates of Optical Character Recognition (OCR) systems for printed\nMalayalam documents is quite impressive with the state of the art accuracy\nlevels in the range of 85-95% for various. However for real applications,\nfurther enhancement of this accuracy levels are required. One of the bottle\nnecks in further enhancement of the accuracy is identified as close-matching\ncharacters. In this paper, we delineate the close matching characters in\nMalayalam and report the development of a specialised classifier for these\nclose-matching characters. The output of a state of the art of OCR is taken and\ncharacters falling into the close-matching character set is further fed into\nthis specialised classifier for enhancing the accuracy. The classifier is based\non support vector machine algorithm and uses feature vectors derived out of\nspectral coefficients of projection histogram signals of close-matching\ncharacters.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 09:25:14 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Divakaran", "Sajilal", ""]]}, {"id": "1205.1644", "submitter": "Jagadeesh H S", "authors": "H S Jagadeesh, K Suresh Babu, and K B Raja", "title": "DBC based Face Recognition using DWT", "comments": "15 pages,9 figures, 4 tables", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.3, No.2, April 2012", "doi": "10.5121/sipij.2012.3208", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applications using face biometric has proved its reliability in last\ndecade. In this paper, we propose DBC based Face Recognition using DWT (DBC-\nFR) model. The Poly-U Near Infra Red (NIR) database images are scanned and\ncropped to get only the face part in pre-processing. The face part is resized\nto 100*100 and DWT is applied to derive LL, LH, HL and HH subbands. The LL\nsubband of size 50*50 is converted into 100 cells with 5*5 dimention of each\ncell. The Directional Binary Code (DBC) is applied on each 5*5 cell to derive\n100 features. The Euclidian distance measure is used to compare the features of\ntest image and database images. The proposed algorithm render better percentage\nrecognition rate compared to the existing algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 09:44:03 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Jagadeesh", "H S", ""], ["Babu", "K Suresh", ""], ["Raja", "K B", ""]]}, {"id": "1205.1648", "submitter": "Manu Valiyakallingal Thankappan", "authors": "Manu V T and Philomina Simon", "title": "A novel statistical fusion rule for image fusion and its comparison in\n  non subsampled contourlet transform domain and wavelet domain", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image fusion produces a single fused image from a set of input images. A new\nmethod for image fusion is proposed based on Weighted Average Merging Method\n(WAMM) in the NonSubsampled Contourlet Transform (NSCT) domain. A performance\nanalysis on various statistical fusion rules are also analysed both in NSCT and\nWavelet domain. Analysis has been made on medical images, remote sensing images\nand multi focus images. Experimental results shows that the proposed method,\nWAMM obtained better results in NSCT domain than the wavelet domain as it\npreserves more edges and keeps the visual quality intact in the fused image.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 09:52:46 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["T", "Manu V", ""], ["Simon", "Philomina", ""]]}, {"id": "1205.2031", "submitter": "Sreejini Ks", "authors": "K. S. Sreejini, A. Lijiya and V. K. Govindan", "title": "M-FISH Karyotyping - A New Approach Based on Watershed Transform", "comments": "13 pages,7 figures", "journal-ref": null, "doi": "10.5121/ijcseit.2012.2210", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Karyotyping is a process in which chromosomes in a dividing cell are properly\nstained, identified and displayed in a standard format, which helps geneticist\nto study and diagnose genetic factors behind various genetic diseases and for\nstudying cancer. M-FISH (Multiplex Fluorescent In-Situ Hybridization) provides\ncolor karyotyping. In this paper, an automated method for M-FISH chromosome\nsegmentation based on watershed transform followed by naive Bayes\nclassification of each region using the features, mean and standard deviation,\nis presented. Also, a post processing step is added to re-classify the small\nchromosome segments to the neighboring larger segment for reducing the chances\nof misclassification. The approach provided improved accuracy when compared to\nthe pixel-by-pixel approach. The approach was tested on 40 images from the\ndataset and achieved an accuracy of 84.21 %.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 16:52:23 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Sreejini", "K. S.", ""], ["Lijiya", "A.", ""], ["Govindan", "V. K.", ""]]}, {"id": "1205.2164", "submitter": "Ankit Kumar", "authors": "Ankit Kumar, Tushar Patnaik, Vivek Kr Verma", "title": "Discrimination of English to other Indian languages (Kannada and Hindi)\n  for OCR system", "comments": "9 Pages, 5 Figure, 5 Tables, International Journal of Computer\n  Science, Engineering and Applications (IJCSEA) Vol.2, No.2, April 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  India is a multilingual multi-script country. In every state of India there\nare two languages one is state local language and the other is English. For\nexample in Andhra Pradesh, a state in India, the document may contain text\nwords in English and Telugu script. For Optical Character Recognition (OCR) of\nsuch a bilingual document, it is necessary to identify the script before\nfeeding the text words to the OCRs of individual scripts. In this paper, we are\nintroducing a simple and efficient technique of script identification for\nKannada, English and Hindi text words of a printed document. The proposed\napproach is based on the horizontal and vertical projection profile for the\ndiscrimination of the three scripts. The feature extraction is done based on\nthe horizontal projection profile of each text words. We analysed 700 different\nwords of Kannada, English and Hindi in order to extract the discrimination\nfeatures and for the development of knowledge base. We use the horizontal\nprojection profile of each text word and based on the horizontal projection\nprofile we extract the appropriate features. The proposed system is tested on\n100 different document images containing more than 1000 text words of each\nscript and a classification rate of 98.25%, 99.25% and 98.87% is achieved for\nKannada, English and Hindi respectively.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 06:14:51 GMT"}], "update_date": "2012-05-11", "authors_parsed": [["Kumar", "Ankit", ""], ["Patnaik", "Tushar", ""], ["Verma", "Vivek Kr", ""]]}, {"id": "1205.2345", "submitter": "Salah A. Aly", "authors": "Hossam Zawbaa and Salah A. Aly", "title": "Hajj and Umrah Event Recognition Datasets", "comments": "4 pages, 18 figures with 33 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, new Hajj and Umrah Event Recognition datasets (HUER) are\npresented. The demonstrated datasets are based on videos and images taken\nduring 2011-2012 Hajj and Umrah seasons. HUER is the first collection of\ndatasets covering the six types of Hajj and Umrah ritual events (rotating in\nTawaf around Kabaa, performing Sa'y between Safa and Marwa, standing on the\nmount of Arafat, staying overnight in Muzdalifah, staying two or three days in\nMina, and throwing Jamarat). The HUER datasets also contain video and image\ndatabases for nine types of human actions during Hajj and Umrah (walking,\ndrinking from Zamzam water, sleeping, smiling, eating, praying, sitting,\nshaving hairs and ablutions, reading the holy Quran and making duaa). The\nspatial resolutions are 1280 x 720 pixels for images and 640 x 480 pixels for\nvideos and have lengths of 20 seconds in average with 30 frame per second\nrates.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 19:10:18 GMT"}], "update_date": "2012-05-11", "authors_parsed": [["Zawbaa", "Hossam", ""], ["Aly", "Salah A.", ""]]}, {"id": "1205.2382", "submitter": "Mete Ozay", "authors": "Mete Ozay, Ilke \\\"Oztekin, Uygar \\\"Oztekin, Fatos T. Yarman Vural", "title": "Mesh Learning for Classifying Cognitive Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relatively recent advance in cognitive neuroscience has been multi-voxel\npattern analysis (MVPA), which enables researchers to decode brain states\nand/or the type of information represented in the brain during a cognitive\noperation. MVPA methods utilize machine learning algorithms to distinguish\namong types of information or cognitive states represented in the brain, based\non distributed patterns of neural activity. In the current investigation, we\npropose a new approach for representation of neural data for pattern analysis,\nnamely a Mesh Learning Model. In this approach, at each time instant, a star\nmesh is formed around each voxel, such that the voxel corresponding to the\ncenter node is surrounded by its p-nearest neighbors. The arc weights of each\nmesh are estimated from the voxel intensity values by least squares method. The\nestimated arc weights of all the meshes, called Mesh Arc Descriptors (MADs),\nare then used to train a classifier, such as Neural Networks, k-Nearest\nNeighbor, Na\\\"ive Bayes and Support Vector Machines. The proposed Mesh Model\nwas tested on neuroimaging data acquired via functional magnetic resonance\nimaging (fMRI) during a recognition memory experiment using categorized word\nlists, employing a previously established experimental paradigm (\\\"Oztekin &\nBadre, 2011). Results suggest that the proposed Mesh Learning approach can\nprovide an effective algorithm for pattern analysis of brain activity during\ncognitive processing.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 20:22:17 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2012 17:44:03 GMT"}, {"version": "v3", "created": "Thu, 5 Feb 2015 21:50:00 GMT"}], "update_date": "2015-02-09", "authors_parsed": [["Ozay", "Mete", ""], ["\u00d6ztekin", "Ilke", ""], ["\u00d6ztekin", "Uygar", ""], ["Vural", "Fatos T. Yarman", ""]]}, {"id": "1205.2631", "submitter": "Jun Liu", "authors": "Jun Liu, Shuiwang Ji, Jieping Ye", "title": "Multi-Task Feature Learning Via Efficient l2,1-Norm Minimization", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-339-348", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of joint feature selection across a group of related tasks has\napplications in many areas including biomedical informatics and computer\nvision. We consider the l2,1-norm regularized regression model for joint\nfeature selection from multiple tasks, which can be derived in the\nprobabilistic framework by assuming a suitable prior from the exponential\nfamily. One appealing feature of the l2,1-norm regularization is that it\nencourages multiple predictors to share similar sparsity patterns. However, the\nresulting optimization problem is challenging to solve due to the\nnon-smoothness of the l2,1-norm regularization. In this paper, we propose to\naccelerate the computation by reformulating it as two equivalent smooth convex\noptimization problems which are then solved via the Nesterov's method-an\noptimal first-order black-box method for smooth convex optimization. A key\nbuilding block in solving the reformulations is the Euclidean projection. We\nshow that the Euclidean projection for the first reformulation can be\nanalytically computed, while the Euclidean projection for the second one can be\ncomputed in linear time. Empirical evaluations on several data sets verify the\nefficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 17:09:42 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Liu", "Jun", ""], ["Ji", "Shuiwang", ""], ["Ye", "Jieping", ""]]}, {"id": "1205.2663", "submitter": "Ot\\'avio Penatti", "authors": "Otavio A. B. Penatti, Eduardo Valle, Ricardo da S. Torres", "title": "Are visual dictionaries generalizable?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mid-level features based on visual dictionaries are today a cornerstone of\nsystems for classification and retrieval of images. Those state-of-the-art\nrepresentations depend crucially on the choice of a codebook (visual\ndictionary), which is usually derived from the dataset. In general-purpose,\ndynamic image collections (e.g., the Web), one cannot have the entire\ncollection in order to extract a representative dictionary. However, based on\nthe hypothesis that the dictionary reflects only the diversity of low-level\nappearances and does not capture semantics, we argue that a dictionary based on\na small subset of the data, or even on an entirely different dataset, is able\nto produce a good representation, provided that the chosen images span a\ndiverse enough portion of the low-level feature space. Our experiments confirm\nthat hypothesis, opening the opportunity to greatly alleviate the burden in\ngenerating the codebook, and confirming the feasibility of employing visual\ndictionaries in large-scale dynamic environments.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 18:54:12 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Penatti", "Otavio A. B.", ""], ["Valle", "Eduardo", ""], ["Torres", "Ricardo da S.", ""]]}, {"id": "1205.2821", "submitter": "Odemir Bruno PhD", "authors": "J. B. Florindo and O. M. Bruno", "title": "Texture Analysis And Characterization Using Probability Fractal\n  Descriptors", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A gray-level image texture descriptors based on fractal dimension estimation\nis proposed in this work. The proposed method estimates the fractal dimension\nusing probability (Voss) method. The descriptors are computed applying a\nmultiscale transform to the fractal dimension curves of the texture image. The\nproposed texture descriptor method is evaluated in a classification task of\nwell known benchmark texture datasets. The results show the great performance\nof the proposed method as a tool for texture images analysis and\ncharacterization.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2012 02:20:52 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Florindo", "J. B.", ""], ["Bruno", "O. M.", ""]]}, {"id": "1205.3137", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Abhinav Gupta, Alexei A. Efros", "title": "Unsupervised Discovery of Mid-Level Discriminative Patches", "comments": null, "journal-ref": "European Conference on Computer Vision, 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to discover a set of discriminative patches which\ncan serve as a fully unsupervised mid-level visual representation. The desired\npatches need to satisfy two requirements: 1) to be representative, they need to\noccur frequently enough in the visual world; 2) to be discriminative, they need\nto be different enough from the rest of the visual world. The patches could\ncorrespond to parts, objects, \"visual phrases\", etc. but are not restricted to\nbe any one of them. We pose this as an unsupervised discriminative clustering\nproblem on a huge dataset of image patches. We use an iterative procedure which\nalternates between clustering and training discriminative classifiers, while\napplying careful cross-validation at each step to prevent overfitting. The\npaper experimentally demonstrates the effectiveness of discriminative patches\nas an unsupervised mid-level visual representation, suggesting that it could be\nused in place of visual words for many tasks. Furthermore, discriminative\npatches can also be used in a supervised regime, such as scene classification,\nwhere they demonstrate state-of-the-art performance on the MIT Indoor-67\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 18:52:57 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2012 04:16:13 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Singh", "Saurabh", ""], ["Gupta", "Abhinav", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1205.3336", "submitter": "Antonio J. Tall\\'on-Ballesteros", "authors": "A.J. Tall\\'on-Ballesteros, P.A. Guti\\'errez-Pe\\~na, C.\n  Herv\\'as-Mart\\'inez", "title": "Distribution of the search of evolutionary product unit neural networks\n  for classification", "comments": "8 pages, 2 figures, in Proc. IADIS International Conference Applied\n  Computing 2007 (AC 2007), ISBN 978-972-8924-30-0, pp. 266-273, Spain. Note:\n  \"This is a reprint from a paper published in the Proceedings of the IADIS\n  International Conference Applied Comupting 2007, http://www.iadis.org\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the distributed processing in the search for an optimum\nclassification model using evolutionary product unit neural networks. For this\ndistributed search we used a cluster of computers. Our objective is to obtain a\nmore efficient design than those net architectures which do not use a\ndistributed process and which thus result in simpler designs. In order to get\nthe best classification models we use evolutionary algorithms to train and\ndesign neural networks, which require a very time consuming computation. The\nreasons behind the need for this distribution are various. It is complicated to\ntrain this type of nets because of the difficulty entailed in determining their\narchitecture due to the complex error surface. On the other hand, the use of\nevolutionary algorithms involves running a great number of tests with different\nseeds and parameters, thus resulting in a high computational cost\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2012 11:51:02 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Tall\u00f3n-Ballesteros", "A. J.", ""], ["Guti\u00e9rrez-Pe\u00f1a", "P. A.", ""], ["Herv\u00e1s-Mart\u00ednez", "C.", ""]]}, {"id": "1205.3766", "submitter": "Jason Chang", "authors": "Jason Chang and John W. Fisher III", "title": "Efficient Topology-Controlled Sampling of Implicit Shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from distributions of implicitly defined shapes enables analysis of\nvarious energy functionals used for image segmentation. Recent work describes a\ncomputationally efficient Metropolis-Hastings method for accomplishing this\ntask. Here, we extend that framework so that samples are accepted at every\niteration of the sampler, achieving an order of magnitude speed up in\nconvergence. Additionally, we show how to incorporate topological constraints.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 19:11:51 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Chang", "Jason", ""], ["Fisher", "John W.", "III"]]}, {"id": "1205.3776", "submitter": "Luke Oeding", "authors": "Chris Aholt, Luke Oeding", "title": "The ideal of the trifocal variety", "comments": null, "journal-ref": null, "doi": "10.1090/S0025-5718-2014-02842-1", "report-no": null, "categories": "math.AG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques from representation theory, symbolic computational algebra, and\nnumerical algebraic geometry are used to find the minimal generators of the\nideal of the trifocal variety. An effective test for determining whether a\ngiven tensor is a trifocal tensor is also given.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 19:58:52 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Aholt", "Chris", ""], ["Oeding", "Luke", ""]]}, {"id": "1205.3966", "submitter": "Yusuf Perwej", "authors": "Yusuf Perwej, Ashish Chaturvedi", "title": "Neural Networks for Handwritten English Alphabet Recognition", "comments": "5 pages, 3 Figure, ISSN:0975 - 8887", "journal-ref": "International Journal of Computer Applications(IJCA), April 2011,\n  Volume 20, Number 7, Pages 1-5", "doi": "10.5120/2449-2824", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates the use of neural networks for developing a system\nthat can recognize hand-written English alphabets. In this system, each English\nalphabet is represented by binary values that are used as input to a simple\nfeature extraction system, whose output is fed to our neural network system.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 15:57:24 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Perwej", "Yusuf", ""], ["Chaturvedi", "Ashish", ""]]}, {"id": "1205.3999", "submitter": "Qiyu Jin", "authors": "Qiyu Jin, Ion Grama and Quansheng Liu", "title": "Optimal Weights Mixed Filter for Removing Mixture of Gaussian and\n  Impulse Noises", "comments": "9 pages, 3 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the character of Gaussian, we modify the Rank-Ordered Absolute\nDifferences (ROAD) to Rank-Ordered Absolute Differences of mixture of Gaussian\nand impulse noises (ROADG). It will be more effective to detect impulse noise\nwhen the impulse is mixed with Gaussian noise. Combining rightly the ROADG with\nOptimal Weights Filter (OWF), we obtain a new method to deal with the mixed\nnoise, called Optimal Weights Mixed Filter (OWMF). The simulation results show\nthat the method is effective to remove the mixed noise.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 18:15:45 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Jin", "Qiyu", ""], ["Grama", "Ion", ""], ["Liu", "Quansheng", ""]]}, {"id": "1205.4336", "submitter": "R Roselin", "authors": "K.Thangavel and R.Roselin", "title": "Fuzzy - Rough Feature Selection With {\\Pi}- Membership Function For\n  Mammogram Classification", "comments": "Due to Crucial Error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the second leading cause for death among women and it is\ndiagnosed with the help of mammograms. Oncologists are miserably failed in\nidentifying the micro calcification at the early stage with the help of the\nmammogram visually. In order to improve the performance of the breast cancer\nscreening, most of the researchers have proposed Computer Aided Diagnosis using\nimage processing. In this study mammograms are preprocessed and features are\nextracted, then the abnormality is identified through the classification. If\nall the extracted features are used, most of the cases are misidentified. Hence\nfeature selection procedure is sought. In this paper, Fuzzy-Rough feature\nselection with {\\pi} membership function is proposed. The selected features are\nused to classify the abnormalities with help of Ant-Miner and Weka tools. The\nexperimental analysis shows that the proposed method improves the mammograms\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 15:19:38 GMT"}, {"version": "v2", "created": "Thu, 24 May 2012 03:31:21 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Thangavel", "K.", ""], ["Roselin", "R.", ""]]}, {"id": "1205.4377", "submitter": "Kirill Trapeznikov", "authors": "Kirill Trapeznikov, Venkatesh Saligrama, David Castanon", "title": "Multi-Stage Classifier Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many classification systems, sensing modalities have different acquisition\ncosts. It is often {\\it unnecessary} to use every modality to classify a\nmajority of examples. We study a multi-stage system in a prediction time cost\nreduction setting, where the full data is available for training, but for a\ntest example, measurements in a new modality can be acquired at each stage for\nan additional cost. We seek decision rules to reduce the average measurement\nacquisition cost. We formulate an empirical risk minimization problem (ERM) for\na multi-stage reject classifier, wherein the stage $k$ classifier either\nclassifies a sample using only the measurements acquired so far or rejects it\nto the next stage where more attributes can be acquired for a cost. To solve\nthe ERM problem, we show that the optimal reject classifier at each stage is a\ncombination of two binary classifiers, one biased towards positive examples and\nthe other biased towards negative examples. We use this parameterization to\nconstruct stage-by-stage global surrogate risk, develop an iterative algorithm\nin the boosting framework and present convergence and generalization results.\nWe test our work on synthetic, medical and explosives detection datasets. Our\nresults demonstrate that substantial cost reduction without a significant\nsacrifice in accuracy is achievable.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 03:15:13 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 16:54:30 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Trapeznikov", "Kirill", ""], ["Saligrama", "Venkatesh", ""], ["Castanon", "David", ""]]}, {"id": "1205.4450", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Yuxu Lin, Mingli Song, Chun Chen, David W. Jacobs", "title": "Spectral Graph Cut from a Filtering Point of View", "comments": "This version is uploaded for better readability, and was last\n  modified in Oct, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral graph theory is well known and widely used in computer vision. In\nthis paper, we analyze image segmentation algorithms that are based on spectral\ngraph theory, e.g., normalized cut, and show that there is a natural connection\nbetween spectural graph theory based image segmentationand and edge preserving\nfiltering. Based on this connection we show that the normalized cut algorithm\nis equivalent to repeated iterations of bilateral filtering. Then, using this\nequivalence we present and implement a fast normalized cut algorithm for image\nsegmentation. Experiments show that our implementation can solve the original\noptimization problem in the normalized cut algorithm 10 to 100 times faster.\nFurthermore, we present a new algorithm called conditioned normalized cut for\nimage segmentation that can easily incorporate color image patches and\ndemonstrate how this segmentation problem can be solved with edge preserving\nfiltering.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 19:30:26 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2012 19:34:54 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2016 17:07:29 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Ye", "Chengxi", ""], ["Lin", "Yuxu", ""], ["Song", "Mingli", ""], ["Chen", "Chun", ""], ["Jacobs", "David W.", ""]]}, {"id": "1205.4463", "submitter": "Salah A. Aly", "authors": "Salah A. Aly", "title": "Pilgrims Face Recognition Dataset -- HUFRD", "comments": "5 pages, 13 images, 1 table of a new HUFRD work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we define a new pilgrims face recognition dataset, called HUFRD\ndataset. The new developed dataset presents various pilgrims' images taken from\noutside the Holy Masjid El-Harram in Makkah during the 2011-2012 Hajj and Umrah\nseasons. Such dataset will be used to test our developed facial recognition and\ndetection algorithms, as well as assess in the missing and found recognition\nsystem \\cite{crowdsensing}.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 22:07:27 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2012 00:58:09 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Aly", "Salah A.", ""]]}, {"id": "1205.4831", "submitter": "Bino Sebastian v", "authors": "Bino Sebastian V, A. Unnikrishnan and Kannan Balakrishnan", "title": "Gray Level Co-Occurrence Matrices: Generalisation and Some New Features", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gray Level Co-occurrence Matrices (GLCM) are one of the earliest techniques\nused for image texture analysis. In this paper we defined a new feature called\ntrace extracted from the GLCM and its implications in texture analysis are\ndiscussed in the context of Content Based Image Retrieval (CBIR). The\ntheoretical extension of GLCM to n-dimensional gray scale images are also\ndiscussed. The results indicate that trace features outperform Haralick\nfeatures when applied to CBIR.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 08:00:45 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Sebastian", "Bino", "V"], ["Unnikrishnan", "A.", ""], ["Balakrishnan", "Kannan", ""]]}, {"id": "1205.5012", "submitter": "Jason Lee", "authors": "Jason D. Lee and Trevor J. Hastie", "title": "Learning Mixed Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the structure of a pairwise graphical\nmodel over continuous and discrete variables. We present a new pairwise model\nfor graphical models with both continuous and discrete variables that is\namenable to structure learning. In previous work, authors have considered\nstructure learning of Gaussian graphical models and structure learning of\ndiscrete models. Our approach is a natural generalization of these two lines of\nwork to the mixed case. The penalization scheme involves a novel symmetric use\nof the group-lasso norm and follows naturally from a particular parametrization\nof the model.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 19:20:07 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2012 06:46:47 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2013 23:06:52 GMT"}], "update_date": "2013-07-05", "authors_parsed": [["Lee", "Jason D.", ""], ["Hastie", "Trevor J.", ""]]}, {"id": "1205.5097", "submitter": "Vijayalaxmi Biradar", "authors": "Vijayalaxmi, P. Sudhakara Rao, S. Sreehari", "title": "Neural Network Approach for Eye Detection", "comments": "12 PAGES, 8 FIGURES, CCSEA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driving support systems, such as car navigation systems are becoming common\nand they support driver in several aspects. Non-intrusive method of detecting\nFatigue and drowsiness based on eye-blink count and eye directed instruction\ncontrolhelps the driver to prevent from collision caused by drowsy driving. Eye\ndetection and tracking under various conditions such as illumination,\nbackground, face alignment and facial expression makes the problem\ncomplex.Neural Network based algorithm is proposed in this paper to detect the\neyes efficiently. In the proposed algorithm, first the neural Network is\ntrained to reject the non-eye regionbased on images with features of eyes and\nthe images with features of non-eye using Gabor filter and Support Vector\nMachines to reduce the dimension and classify efficiently. In the algorithm,\nfirst the face is segmented using L*a*btransform color space, then eyes are\ndetected using HSV and Neural Network approach. The algorithm is tested on\nnearly 100 images of different persons under different conditions and the\nresults are satisfactory with success rate of 98%.The Neural Network is trained\nwith 50 non-eye images and 50 eye images with different angles using Gabor\nfilter. This paper is a part of research work on \"Development of Non-Intrusive\nsystem for real-time Monitoring and Prediction of Driver Fatigue and\ndrowsiness\" project sponsored by Department of Science & Technology, Govt. of\nIndia, New Delhi at Vignan Institute of Technology and Sciences, Vignan Hills,\nHyderabad.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2012 05:14:20 GMT"}], "update_date": "2012-05-24", "authors_parsed": [["Vijayalaxmi", "", ""], ["Rao", "P. Sudhakara", ""], ["Sreehari", "S.", ""]]}, {"id": "1205.5351", "submitter": "Xiang Ren", "authors": "Xiang Ren, Zhouchen Lin", "title": "Linearized Alternating Direction Method with Adaptive Penalty and Warm\n  Starts for Fast Solving Transform Invariant Low-Rank Textures", "comments": "Accepted by International Journal of Computer Vision (IJCV)", "journal-ref": null, "doi": "10.1007/s11263-013-0611-6", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transform Invariant Low-rank Textures (TILT) is a novel and powerful tool\nthat can effectively rectify a rich class of low-rank textures in 3D scenes\nfrom 2D images despite significant deformation and corruption. The existing\nalgorithm for solving TILT is based on the alternating direction method (ADM).\nIt suffers from high computational cost and is not theoretically guaranteed to\nconverge to a correct solution. In this paper, we propose a novel algorithm to\nspeed up solving TILT, with guaranteed convergence. Our method is based on the\nrecently proposed linearized alternating direction method with adaptive penalty\n(LADMAP). To further reduce computation, warm starts are also introduced to\ninitialize the variables better and cut the cost on singular value\ndecomposition. Extensive experimental results on both synthetic and real data\ndemonstrate that this new algorithm works much more efficiently and robustly\nthan the existing algorithm. It could be at least five times faster than the\nprevious method.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 07:16:14 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 20:19:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Ren", "Xiang", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1205.5425", "submitter": "Sune Darkner", "authors": "Sune Darkner and Jon Sporring", "title": "Locally Orderless Registration", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is an important tool for medical image analysis and is\nused to bring images into the same reference frame by warping the coordinate\nfield of one image, such that some similarity measure is minimized. We study\nsimilarity in image registration in the context of Locally Orderless Images\n(LOI), which is the natural way to study density estimates and reveals the 3\nfundamental scales: the measurement scale, the intensity scale, and the\nintegration scale.\n  This paper has three main contributions: Firstly, we rephrase a large set of\npopular similarity measures into a common framework, which we refer to as\nLocally Orderless Registration, and which makes full use of the features of\nlocal histograms. Secondly, we extend the theoretical understanding of the\nlocal histograms. Thirdly, we use our framework to compare two state-of-the-art\nintensity density estimators for image registration: The Parzen Window (PW) and\nthe Generalized Partial Volume (GPV), and we demonstrate their differences on a\npopular similarity measure, Normalized Mutual Information (NMI).\n  We conclude, that complicated similarity measures such as NMI may be\nevaluated almost as fast as simple measures such as Sum of Squared Distances\n(SSD) regardless of the choice of PW and GPV. Also, GPV is an asymmetric\nmeasure, and PW is our preferred choice.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 12:56:45 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Darkner", "Sune", ""], ["Sporring", "Jon", ""]]}, {"id": "1205.6154", "submitter": "Gil Shabat", "authors": "Gil Shabat", "title": "Potentials and Limits of Super-Resolution Algorithms and Signal\n  Reconstruction from Sparse Data", "comments": null, "journal-ref": "Journal of the Optical Society A 26(3), pp. 566-575, 2009", "doi": null, "report-no": null, "categories": "physics.optics cs.CV math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common distortion in videos is image instability in the form of chaotic\n(global and local displacements). Those instabilities can be used to enhance\nimage resolution by using subpixel elastic registration. In this work, we\ninvestigate the performance of such methods over the ability to improve the\nresolution by accumulating several frames. The second part of this work deals\nwith reconstruction of discrete signals from a subset of samples under\ndifferent basis functions such as DFT, Haar, Walsh, Daubechies wavelets and CT\n(Radon) projections.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2012 16:35:33 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Shabat", "Gil", ""]]}, {"id": "1205.6352", "submitter": "Vladimir Kolmogorov", "authors": "Vladimir Kolmogorov and Thomas Schoenemann", "title": "Generalized sequential tree-reweighted message passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of approximate MAP-MRF inference in general\ngraphical models. Following [36], we consider a family of linear programming\nrelaxations of the problem where each relaxation is specified by a set of\nnested pairs of factors for which the marginalization constraint needs to be\nenforced. We develop a generalization of the TRW-S algorithm [9] for this\nproblem, where we use a decomposition into junction chains, monotonic w.r.t.\nsome ordering on the nodes. This generalizes the monotonic chains in [9] in a\nnatural way. We also show how to deal with nested factors in an efficient way.\nExperiments show an improvement over min-sum diffusion, MPLP and subgradient\nascent algorithms on a number of computer vision and natural language\nprocessing problems.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 13:06:58 GMT"}, {"version": "v2", "created": "Wed, 30 May 2012 19:04:03 GMT"}, {"version": "v3", "created": "Thu, 31 May 2012 11:40:40 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2012 12:18:13 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Kolmogorov", "Vladimir", ""], ["Schoenemann", "Thomas", ""]]}, {"id": "1205.6391", "submitter": "Shu Kong", "authors": "Kong Shu, Wang Donghui", "title": "A Brief Summary of Dictionary Learning Based Approach for Classification", "comments": "Due to personal mistake, the authors' name are incorrectly written,\n  thus we withdraw this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 15:28:54 GMT"}, {"version": "v2", "created": "Wed, 30 May 2012 05:02:04 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Shu", "Kong", ""], ["Donghui", "Wang", ""]]}, {"id": "1205.6544", "submitter": "Shu Kong", "authors": "Shu Kong, Donghui Wang", "title": "A Brief Summary of Dictionary Learning Based Approach for Classification\n  (revised)", "comments": "a note revised from a withdrawn one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note presents some representative methods which are based on dictionary\nlearning (DL) for classification. We do not review the sophisticated methods or\nframeworks that involve DL for classification, such as online DL and spatial\npyramid matching (SPM), but rather, we concentrate on the direct DL-based\nclassification methods. Here, the \"so-called direct DL-based method\" is the\napproach directly deals with DL framework by adding some meaningful penalty\nterms. By listing some representative methods, we can roughly divide them into\ntwo categories, i.e. (1) directly making the dictionary discriminative and (2)\nforcing the sparse coefficients discriminative to push the discrimination power\nof the dictionary. From this taxonomy, we can expect some extensions of them as\nfuture researches.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 05:07:55 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Kong", "Shu", ""], ["Wang", "Donghui", ""]]}, {"id": "1205.6572", "submitter": "Amiya Halder", "authors": "Amiya Halder and Soumajit Pramanik", "title": "An Unsupervised Dynamic Image Segmentation using Fuzzy Hopfield Neural\n  Network based Genetic Algorithm", "comments": "8 pages", "journal-ref": "IJCSI March 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Genetic Algorithm based segmentation method that can\nautomatically segment gray-scale images. The proposed method mainly consists of\nspatial unsupervised grayscale image segmentation that divides an image into\nregions. The aim of this algorithm is to produce precise segmentation of images\nusing intensity information along with neighborhood relationships. In this\npaper, Fuzzy Hopfield Neural Network (FHNN) clustering helps in generating the\npopulation of Genetic algorithm which there by automatically segments the\nimage. This technique is a powerful method for image segmentation and works for\nboth single and multiple-feature data with spatial information. Validity index\nhas been utilized for introducing a robust technique for finding the optimum\nnumber of components in an image. Experimental results shown that the algorithm\ngenerates good quality segmented image.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 08:10:59 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Halder", "Amiya", ""], ["Pramanik", "Soumajit", ""]]}, {"id": "1205.6605", "submitter": "Jan Egger", "authors": "Jan Egger, Bernd Freisleben, Christopher Nimsky, Tina Kapur", "title": "Template-Cut: A Pattern-Based Segmentation Paradigm", "comments": "8 pages, 6 figures, 3 tables, 6 equations, 51 references", "journal-ref": "J. Egger, B. Freisleben, C. Nimsky, T. Kapur. Template-Cut: A\n  Pattern-Based Segmentation Paradigm. Nature - Scientific Reports, Nature\n  Publishing Group (NPG), 2(420), 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a scale-invariant, template-based segmentation paradigm that sets\nup a graph and performs a graph cut to separate an object from the background.\nTypically graph-based schemes distribute the nodes of the graph uniformly and\nequidistantly on the image, and use a regularizer to bias the cut towards a\nparticular shape. The strategy of uniform and equidistant nodes does not allow\nthe cut to prefer more complex structures, especially when areas of the object\nare indistinguishable from the background. We propose a solution by introducing\nthe concept of a \"template shape\" of the target object in which the nodes are\nsampled non-uniformly and non-equidistantly on the image. We evaluate it on\n2D-images where the object's textures and backgrounds are similar, and large\nareas of the object have the same gray level appearance as the background. We\nalso evaluate it in 3D on 60 brain tumor datasets for neurosurgical planning\npurposes.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 09:44:43 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Egger", "Jan", ""], ["Freisleben", "Bernd", ""], ["Nimsky", "Christopher", ""], ["Kapur", "Tina", ""]]}, {"id": "1205.6745", "submitter": "Gnanasivam Pachaiyappan", "authors": "P Gnanasivam and Dr. S Muttan", "title": "Fingerprint Gender Classification using Wavelet Transform and Singular\n  Value Decomposition", "comments": "12 figures and 6 tables", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 2, No 3, March 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method of gender Classification from fingerprint is proposed based on\ndiscrete wavelet transform (DWT) and singular value decomposition (SVD). The\nclassification is achieved by extracting the energy computed from all the\nsub-bands of DWT combined with the spatial features of non-zero singular values\nobtained from the SVD of fingerprint images. K nearest neighbor (KNN) used as a\nclassifier. This method is experimented with the internal database of 3570\nfingerprints finger prints in which 1980 were male fingerprints and 1590 were\nfemale fingerprints. Finger-wise gender classification is achieved which is\n94.32% for the left hand little fingers of female persons and 95.46% for the\nleft hand index finger of male persons. Gender classification for any finger of\nmale persons tested is attained as 91.67% and 84.69% for female persons\nrespectively. Overall classification rate is 88.28% has been achieved.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 16:26:23 GMT"}], "update_date": "2012-05-31", "authors_parsed": [["Gnanasivam", "P", ""], ["Muttan", "Dr. S", ""]]}]