[{"id": "1310.0036", "submitter": "Saptarshi Bhattacharjee", "authors": "Saptarshi Bhattacharjee, S Arunkumar, Samir Kumar Bandyopadhyay", "title": "Personal Identification from Lip-Print Features using a Statistical\n  Model", "comments": "5 pages, 7 images, Published with International Journal of Computer\n  Applications (IJCA)", "journal-ref": null, "doi": "10.5120/8817-2801", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach towards identification of human beings\nfrom the statistical analysis of their lip prints. Lip features are extracted\nby studying the spatial orientations of the grooves present in lip prints of\nindividuals using standard edge detection techniques. Horizontal, vertical and\ndiagonal groove features are analysed using connected-component analysis to\ngenerate the region-specific edge datasets. Comparison between test and\nreference sample datasets against a threshold value to define a match yield\nsatisfactory results. FAR, FRR and ROC metrics have been used to gauge the\nperformance of the algorithm for real-world deployment in unimodal and\nmultimodal biometric verification systems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 20:12:02 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Bhattacharjee", "Saptarshi", ""], ["Arunkumar", "S", ""], ["Bandyopadhyay", "Samir Kumar", ""]]}, {"id": "1310.0097", "submitter": "Martin Welk", "authors": "Martin Welk", "title": "Analysis of Amoeba Active Contours", "comments": "Revised version with several improvements for clarity, slightly\n  extended experiments and discussion. Accepted for publication in Journal of\n  Mathematical Imaging and Vision", "journal-ref": "Journal of Mathematical Imaging and Vision, 52 (2015) 37-54", "doi": "10.1007/s10851-014-0524-1", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subject of this paper is the theoretical analysis of structure-adaptive\nmedian filter algorithms that approximate curvature-based PDEs for image\nfiltering and segmentation. These so-called morphological amoeba filters are\nbased on a concept introduced by Lerallut et al. They achieve similar results\nas the well-known geodesic active contour and self-snakes PDEs. In the present\nwork, the PDE approximated by amoeba active contours is derived for a general\ngeometric situation and general amoeba metric. This PDE is structurally similar\nbut not identical to the geodesic active contour equation. It reproduces the\nprevious PDE approximation results for amoeba median filters as special cases.\nFurthermore, modifications of the basic amoeba active contour algorithm are\nanalysed that are related to the morphological force terms frequently used with\ngeodesic active contours. Experiments demonstrate the basic behaviour of amoeba\nactive contours and its similarity to geodesic active contours.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2013 23:57:08 GMT"}, {"version": "v2", "created": "Sat, 12 Jul 2014 21:26:12 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Welk", "Martin", ""]]}, {"id": "1310.0171", "submitter": "Marcelo Hashimoto", "authors": "Marcelo Hashimoto, Roberto Marcondes Cesar Junior", "title": "Object Detection Using Keygraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for object detection based on a generalization of\nthe keypoint correspondence framework. This framework is based on replacing\nkeypoints by keygraphs, i.e. isomorph directed graphs whose vertices are\nkeypoints, in order to explore relative and structural information. Unlike\nsimilar works in the literature, we deal directly with graphs in the entire\npipeline: we search for graph correspondences instead of searching for\nindividual point correspondences and then building graph correspondences from\nthem afterwards. We also estimate the pose from graph correspondences instead\nof falling back to point correspondences through a voting table. The\ncontributions of this paper are the proposed framework and an implementation\nthat properly handles its inherent issues of loss of locality and combinatorial\nexplosion, showing its viability for real-time applications. In particular, we\nintroduce the novel concept of keytuples to solve a running time issue. The\naccuracy of the implementation is shown by results of over 800 experiments with\na well-known database of images. The speed is illustrated by real-time tracking\nwith two different cameras in ordinary hardware.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 07:45:26 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Hashimoto", "Marcelo", ""], ["Junior", "Roberto Marcondes Cesar", ""]]}, {"id": "1310.0302", "submitter": "Tomislav Petkovi\\'c", "authors": "Vedran Hrgeti\\'c and Tomislav Pribani\\'c", "title": "Surface Registration Using Genetic Algorithm in Reduced Search Space", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0018", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Surface registration is a technique that is used in various areas such as\nobject recognition and 3D model reconstruction. Problem of surface registration\ncan be analyzed as an optimization problem of seeking a rigid motion between\ntwo different views. Genetic algorithms can be used for solving this\noptimization problem, both for obtaining the robust parameter estimation and\nfor its fine-tuning. The main drawback of genetic algorithms is that they are\ntime consuming which makes them unsuitable for online applications. Modern\nacquisition systems enable the implementation of the solutions that would\nimmediately give the information on the rotational angles between the different\nviews, thus reducing the dimension of the optimization problem. The paper gives\nan analysis of the genetic algorithm implemented in the conditions when the\nrotation matrix is known and a comparison of these results with results when\nthis information is not available.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:06:33 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Hrgeti\u0107", "Vedran", ""], ["Pribani\u0107", "Tomislav", ""]]}, {"id": "1310.0305", "submitter": "Tomislav Petkovi\\'c", "authors": "Mario Mu\\v{s}tra and Mislav Grgi\\'c", "title": "Filtering for More Accurate Dense Tissue Segmentation in Digitized\n  Mammograms", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0019", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Breast tissue segmentation into dense and fat tissue is important for\ndetermining the breast density in mammograms. Knowing the breast density is\nimportant both in diagnostic and computer-aided detection applications. There\nare many different ways to express the density of a breast and good quality\nsegmentation should provide the possibility to perform accurate classification\nno matter which classification rule is being used. Knowing the right breast\ndensity and having the knowledge of changes in the breast density could give a\nhint of a process which started to happen within a patient. Mammograms\ngenerally suffer from a problem of different tissue overlapping which results\nin the possibility of inaccurate detection of tissue types. Fibroglandular\ntissue presents rather high attenuation of X-rays and is visible as brighter in\nthe resulting image but overlapping fibrous tissue and blood vessels could\neasily be replaced with fibroglandular tissue in automatic segmentation\nalgorithms. Small blood vessels and microcalcifications are also shown as\nbright objects with similar intensities as dense tissue but do have some\nproperties which makes possible to suppress them from the final results. In\nthis paper we try to divide dense and fat tissue by suppressing the scattered\nstructures which do not represent glandular or dense tissue in order to divide\nmammograms more accurately in the two major tissue types. For suppressing blood\nvessels and microcalcifications we have used Gabor filters of different size\nand orientation and a combination of morphological operations on filtered image\nwith enhanced contrast.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:09:21 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Mu\u0161tra", "Mario", ""], ["Grgi\u0107", "Mislav", ""]]}, {"id": "1310.0306", "submitter": "Tomislav Petkovi\\'c", "authors": "Tomislav Petkovi\\'c, Darko Juri\\'c and Sven Lon\\v{c}ari\\'c", "title": "Flexible Visual Quality Inspection in Discrete Manufacturing", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0020", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Most visual quality inspections in discrete manufacturing are composed of\nlength, surface, angle or intensity measurements. Those are implemented as\nend-user configurable inspection tools that should not require an image\nprocessing expert to set up. Currently available software solutions providing\nsuch capability use a flowchart based programming environment, but do not fully\naddress an inspection flowchart robustness and can require a redefinition of\nthe flowchart if a small variation is introduced. In this paper we propose an\nacquire-register-analyze image processing pattern designed for discrete\nmanufacturing that aims to increase the robustness of the inspection flowchart\nby consistently addressing variations in product position, orientation and\nsize. A proposed pattern is transparent to the end-user and simplifies the\nflowchart. We describe a developed software solution that is a practical\nimplementation of the proposed pattern. We give an example of its real-life use\nin industrial production of electric components.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:12:01 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Petkovi\u0107", "Tomislav", ""], ["Juri\u0107", "Darko", ""], ["Lon\u010dari\u0107", "Sven", ""]]}, {"id": "1310.0307", "submitter": "Nikola Bani\\'c", "authors": "Nikola Bani\\'c and Sven Lon\\v{c}ari\\'c", "title": "Using the Random Sprays Retinex Algorithm for Global Illumination\n  Estimation", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": "10.1109/LSP.2013.2285960", "report-no": "UniZg-CRV-CCVW/2013/0010", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper the use of Random Sprays Retinex (RSR) algorithm for global\nillumination estimation is proposed and its feasibility tested. Like other\nalgorithms based on the Retinex model, RSR also provides local illumination\nestimation and brightness adjustment for each pixel and it is faster than other\npath-wise Retinex algorithms. As the assumption of the uniform illumination\nholds in many cases, it should be possible to use the mean of local\nillumination estimations of RSR as a global illumination estimation for images\nwith (assumed) uniform illumination allowing also the accuracy to be easily\nmeasured. Therefore we propose a method for estimating global illumination\nestimation based on local RSR results. To our best knowledge this is the first\ntime that RSR algorithm is used to obtain global illumination estimation. For\nour tests we use a publicly available color constancy image database for\ntesting. The results are presented and discussed and it turns out that the\nproposed method outperforms many existing unsupervised color constancy\nalgorithms. The source code is available at\nhttp://www.fer.unizg.hr/ipg/resources/color_constancy/.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:13:24 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2013 13:11:27 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Bani\u0107", "Nikola", ""], ["Lon\u010dari\u0107", "Sven", ""]]}, {"id": "1310.0308", "submitter": "Tomislav Petkovi\\'c", "authors": "Karla Brki\\'c, Sr{\\dj}an Ra\\v{s}i\\'c, Axel Pinz, Sini\\v{s}a\n  \\v{S}egvi\\'c and Zoran Kalafati\\'c", "title": "Combining Spatio-Temporal Appearance Descriptors and Optical Flow for\n  Human Action Recognition in Video Data", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0011", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper proposes combining spatio-temporal appearance (STA) descriptors\nwith optical flow for human action recognition. The STA descriptors are local\nhistogram-based descriptors of space-time, suitable for building a partial\nrepresentation of arbitrary spatio-temporal phenomena. Because of the\npossibility of iterative refinement, they are interesting in the context of\nonline human action recognition. We investigate the use of dense optical flow\nas the image function of the STA descriptor for human action recognition, using\ntwo different algorithms for computing the flow: the Farneb\\\"ack algorithm and\nthe TVL1 algorithm. We provide a detailed analysis of the influencing optical\nflow algorithm parameters on the produced optical flow fields. An extensive\nexperimental validation of optical flow-based STA descriptors in human action\nrecognition is performed on the KTH human action dataset. The encouraging\nexperimental results suggest the potential of our approach in online human\naction recognition.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:13:40 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Brki\u0107", "Karla", ""], ["Ra\u0161i\u0107", "Sr\u0111an", ""], ["Pinz", "Axel", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""], ["Kalafati\u0107", "Zoran", ""]]}, {"id": "1310.0310", "submitter": "Tomislav Petkovi\\'c", "authors": "Ivan Kre\\v{s}o, Marko \\v{S}evrovi\\'c and Sini\\v{s}a \\v{S}egvi\\'c", "title": "A Novel Georeferenced Dataset for Stereo Visual Odometry", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0017", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this work, we present a novel dataset for assessing the accuracy of stereo\nvisual odometry. The dataset has been acquired by a small-baseline stereo rig\nmounted on the top of a moving car. The groundtruth is supplied by a consumer\ngrade GPS device without IMU. Synchronization and alignment between GPS\nreadings and stereo frames are recovered after the acquisition. We show that\nthe attained groundtruth accuracy allows to draw useful conclusions in\npractice. The presented experiments address influence of camera calibration,\nbaseline distance and zero-disparity features to the achieved reconstruction\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:15:48 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Kre\u0161o", "Ivan", ""], ["\u0160evrovi\u0107", "Marko", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""]]}, {"id": "1310.0311", "submitter": "Tomislav Petkovi\\'c", "authors": "Valentina Zadrija and Sini\\v{s}a \\v{S}egvi\\'c", "title": "Multiclass Road Sign Detection using Multiplicative Kernel", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0016", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We consider the problem of multiclass road sign detection using a\nclassification function with multiplicative kernel comprised from two kernels.\nWe show that problems of detection and within-foreground classification can be\njointly solved by using one kernel to measure object-background differences and\nanother one to account for within-class variations. The main idea behind this\napproach is that road signs from different foreground variations can share\nfeatures that discriminate them from backgrounds. The classification function\ntraining is accomplished using SVM, thus feature sharing is obtained through\nsupport vector sharing. Training yields a family of linear detectors, where\neach detector corresponds to a specific foreground training sample. The\nredundancy among detectors is alleviated using k-medoids clustering. Finally,\nwe report detection and classification results on a set of road sign images\nobtained from a camera on a moving vehicle.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:16:06 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Zadrija", "Valentina", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""]]}, {"id": "1310.0314", "submitter": "Tomislav Petkovi\\'c", "authors": "Robert Cupec, Emmanuel Karlo Nyarko, Damir Filko, Andrej Kitanov and\n  Ivan Petrovi\\'c", "title": "Global Localization Based on 3D Planar Surface Segments", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0015", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Global localization of a mobile robot using planar surface segments extracted\nfrom depth images is considered. The robot's environment is represented by a\ntopological map consisting of local models, each representing a particular\nlocation modeled by a set of planar surface segments. The discussed\nlocalization approach segments a depth image acquired by a 3D camera into\nplanar surface segments which are then matched to model surface segments. The\nrobot pose is estimated by the Extended Kalman Filter using surface segment\npairs as measurements. The reliability and accuracy of the considered approach\nare experimentally evaluated using a mobile robot equipped by a Microsoft\nKinect sensor.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:18:52 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Cupec", "Robert", ""], ["Nyarko", "Emmanuel Karlo", ""], ["Filko", "Damir", ""], ["Kitanov", "Andrej", ""], ["Petrovi\u0107", "Ivan", ""]]}, {"id": "1310.0315", "submitter": "Tomislav Petkovi\\'c", "authors": "Kristian Kova\\v{c}i\\'c, Edouard Ivanjko and Hrvoje Gold", "title": "Computer Vision Systems in Road Vehicles: A Review", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0014", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The number of road vehicles significantly increased in recent decades. This\ntrend accompanied a build-up of road infrastructure and development of various\ncontrol systems to increase road traffic safety, road capacity and travel\ncomfort. In traffic safety significant development has been made and today's\nsystems more and more include cameras and computer vision methods. Cameras are\nused as part of the road infrastructure or in vehicles. In this paper a review\non computer vision systems in vehicles from the stand point of traffic\nengineering is given. Safety problems of road vehicles are presented, current\nstate of the art in-vehicle vision systems is described and open problems with\nfuture research directions are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:19:11 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Kova\u010di\u0107", "Kristian", ""], ["Ivanjko", "Edouard", ""], ["Gold", "Hrvoje", ""]]}, {"id": "1310.0316", "submitter": "Tomislav Petkovi\\'c", "authors": "Ivan Sikiri\\'c, Karla Brki\\'c and Sini\\v{s}a \\v{S}egvi\\'c", "title": "Classifying Traffic Scenes Using The GIST Image Descriptor", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0013", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper investigates classification of traffic scenes in a very low\nbandwidth scenario, where an image should be coded by a small number of\nfeatures. We introduce a novel dataset, called the FM1 dataset, consisting of\n5615 images of eight different traffic scenes: open highway, open road,\nsettlement, tunnel, tunnel exit, toll booth, heavy traffic and the overpass. We\nevaluate the suitability of the GIST descriptor as a representation of these\nimages, first by exploring the descriptor space using PCA and k-means\nclustering, and then by using an SVM classifier and recording its 10-fold\ncross-validation performance on the introduced FM1 dataset. The obtained\nrecognition rates are very encouraging, indicating that the use of the GIST\ndescriptor alone could be sufficiently descriptive even when very high\nperformance is required.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:19:26 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Sikiri\u0107", "Ivan", ""], ["Brki\u0107", "Karla", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""]]}, {"id": "1310.0317", "submitter": "Tomislav Petkovi\\'c", "authors": "Markan Lopar and Slobodan Ribari\\'c", "title": "An Overview and Evaluation of Various Face and Eyes Detection Algorithms\n  for Driver Fatigue Monitoring Systems", "comments": "Part of the Proceedings of the Croatian Computer Vision Workshop,\n  CCVW 2013, Year 1", "journal-ref": null, "doi": null, "report-no": "UniZg-CRV-CCVW/2013/0012", "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this work various methods and algorithms for face and eyes detection are\nexamined in order to decide which of them are applicable for use in a driver\nfatigue monitoring system. In the case of face detection the standard\nViola-Jones face detector has shown best results, while the method of finding\nthe eye centers by means of gradients has proven to be most appropriate in the\ncase of eyes detection. The later method has also a potential for retrieving\nbehavioral parameters needed for estimation of the level of driver fatigue.\nThis possibility will be examined in future work.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:19:42 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Lopar", "Markan", ""], ["Ribari\u0107", "Slobodan", ""]]}, {"id": "1310.0319", "submitter": "Tomislav Petkovi\\'c", "authors": "Sven Lon\\v{c}ari\\'c and Sini\\v{s}a \\v{S}egvi\\'c", "title": "Second Croatian Computer Vision Workshop (CCVW 2013)", "comments": "Papers presented at the Second Croatian Computer Vision Workshop CCVW\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,\nhttp://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,\nCroatia. Workshop was organized by the Center of Excellence for Computer Vision\nof the University of Zagreb.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:26:29 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2013 07:48:17 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2013 08:37:46 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Lon\u010dari\u0107", "Sven", ""], ["\u0160egvi\u0107", "Sini\u0161a", ""]]}, {"id": "1310.0322", "submitter": "Lukas F. Lang", "authors": "Clemens Kirisits, Lukas F. Lang, Otmar Scherzer", "title": "Optical Flow on Evolving Surfaces with Space and Time Regularisation", "comments": "The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s10851-014-0513-4. This is an extended version of\n  arXiv:1301.1576", "journal-ref": null, "doi": "10.1007/s10851-014-0513-4", "report-no": null, "categories": "math.OC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the concept of optical flow with spatiotemporal regularisation to a\ndynamic non-Euclidean setting. Optical flow is traditionally computed from a\nsequence of flat images. The purpose of this paper is to introduce variational\nmotion estimation for images that are defined on an evolving surface.\nVolumetric microscopy images depicting a live zebrafish embryo serve as both\nbiological motivation and test data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 14:36:14 GMT"}, {"version": "v2", "created": "Wed, 25 Jun 2014 15:29:08 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Kirisits", "Clemens", ""], ["Lang", "Lukas F.", ""], ["Scherzer", "Otmar", ""]]}, {"id": "1310.0354", "submitter": "Gary Huang", "authors": "Gary B. Huang and Viren Jain", "title": "Deep and Wide Multiscale Recursive Networks for Robust Image Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward multilayer networks trained by supervised learning have recently\ndemonstrated state of the art performance on image labeling problems such as\nboundary prediction and scene parsing. As even very low error rates can limit\npractical usage of such systems, methods that perform closer to human accuracy\nremain desirable. In this work, we propose a new type of network with the\nfollowing properties that address what we hypothesize to be limiting aspects of\nexisting methods: (1) a `wide' structure with thousands of features, (2) a\nlarge field of view, (3) recursive iterations that exploit statistical\ndependencies in label space, and (4) a parallelizable architecture that can be\ntrained in a fraction of the time compared to benchmark multilayer\nconvolutional networks. For the specific image labeling problem of boundary\nprediction, we also introduce a novel example weighting algorithm that improves\nsegmentation accuracy. Experiments in the challenging domain of connectomic\nreconstruction of neural circuity from 3d electron microscopy data show that\nthese \"Deep And Wide Multiscale Recursive\" (DAWMR) networks lead to new levels\nof image labeling performance. The highest performing architecture has twelve\nlayers, interwoven supervised and unsupervised stages, and uses an input field\nof view of 157,464 voxels ($54^3$) to make a prediction at each image location.\nWe present an associated open source software package that enables the simple\nand flexible creation of DAWMR networks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 15:42:54 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 21:16:45 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2013 17:00:03 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Huang", "Gary B.", ""], ["Jain", "Viren", ""]]}, {"id": "1310.0365", "submitter": "Pavel Golovinski", "authors": "P.A. Golovinski, V.A. Astapenko", "title": "The complex-valued encoding for dicision-making based on aliasing data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is proposed a complex valued channel encoding for multidimensional data.\nThe basic approach contains overlapping of complex nonlinear mappings. Its\ndevelopment leads to sparse representation of multi-channel data, increasing\ntheir dimensions and the distance between the images.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 16:06:00 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Golovinski", "P. A.", ""], ["Astapenko", "V. A.", ""]]}, {"id": "1310.0900", "submitter": "Chunhua Shen", "authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel", "title": "Efficient pedestrian detection by directly optimize the partial area\n  under the ROC curve", "comments": "10 pages. Appearing in Int. Conf. Computer Vision (ICCV) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many typical applications of object detection operate within a prescribed\nfalse-positive range. In this situation the performance of a detector should be\nassessed on the basis of the area under the ROC curve over that range, rather\nthan over the full curve, as the performance outside the range is irrelevant.\n  This measure is labelled as the partial area under the ROC curve (pAUC).\nEffective cascade-based classification, for example, depends on training node\nclassifiers that achieve the maximal detection rate at a moderate false\npositive rate, e.g., around 40% to 50%. We propose a novel ensemble learning\nmethod which achieves a maximal detection rate at a user-defined range of false\npositive rates by directly optimizing the partial AUC using structured\nlearning. By optimizing for different ranges of false positive rates, the\nproposed method can be used to train either a single strong classifier or a\nnode classifier forming part of a cascade classifier. Experimental results on\nboth synthetic and real-world data sets demonstrate the effectiveness of our\napproach, and we show that it is possible to train state-of-the-art pedestrian\ndetectors using the proposed structured ensemble learning method.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 05:50:40 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Paisitkriangkrai", "Sakrapee", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1310.1221", "submitter": "Diego Valsesia", "authors": "Diego Valsesia, Enrico Magli", "title": "Spatially Scalable Compressed Image Sensing with Hybrid Transform and\n  Inter-layer Prediction Model", "comments": "Proceedings of the 15th International Workshop on Multimedia Signal\n  Processing, September 30-October 3, 2013, Pula, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive imaging is an emerging application of compressed sensing, devoted\nto acquisition, encoding and reconstruction of images using random projections\nas measurements. In this paper we propose a novel method to provide a scalable\nencoding of an image acquired by means of compressed sensing techniques. Two\nbit-streams are generated to provide two distinct quality levels: a\nlow-resolution base layer and full-resolution enhancement layer. In the\nproposed method we exploit a fast preview of the image at the encoder in order\nto perform inter-layer prediction and encode the prediction residuals only. The\nproposed method successfully provides resolution and quality scalability with\nmodest complexity and it provides gains in the quality of the reconstructed\nimages with respect to separate encoding of the quality layers. Remarkably, we\nalso show that the scheme can also provide significant gains with respect to a\ndirect, non-scalable system, thus accomplishing two features at once:\nscalability and improved reconstruction performance.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2013 10:45:02 GMT"}], "update_date": "2013-10-07", "authors_parsed": [["Valsesia", "Diego", ""], ["Magli", "Enrico", ""]]}, {"id": "1310.1257", "submitter": "Fabian Pedregosa", "authors": "Michael Eickenberg (INRIA Saclay - Ile de France, LNAO), Fabian\n  Pedregosa (INRIA Saclay - Ile de France, INRIA Paris - Rocquencourt),\n  Senoussi Mehdi (INRIA Saclay - Ile de France), Alexandre Gramfort (LTCI),\n  Bertrand Thirion (INRIA Saclay - Ile de France)", "title": "Second order scattering descriptors predict fMRI activity due to visual\n  textures", "comments": "3nd International Workshop on Pattern Recognition in NeuroImaging\n  (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second layer scattering descriptors are known to provide good classification\nperformance on natural quasi-stationary processes such as visual textures due\nto their sensitivity to higher order moments and continuity with respect to\nsmall deformations. In a functional Magnetic Resonance Imaging (fMRI)\nexperiment we present visual textures to subjects and evaluate the predictive\npower of these descriptors with respect to the predictive power of simple\ncontour energy - the first scattering layer. We are able to conclude not only\nthat invariant second layer scattering coefficients better encode voxel\nactivity, but also that well predicted voxels need not necessarily lie in known\nretinotopic regions.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2013 13:00:39 GMT"}], "update_date": "2013-10-07", "authors_parsed": [["Eickenberg", "Michael", "", "INRIA Saclay - Ile de France, LNAO"], ["Pedregosa", "Fabian", "", "INRIA Saclay - Ile de France, INRIA Paris - Rocquencourt"], ["Mehdi", "Senoussi", "", "INRIA Saclay - Ile de France"], ["Gramfort", "Alexandre", "", "LTCI"], ["Thirion", "Bertrand", "", "INRIA Saclay - Ile de France"]]}, {"id": "1310.1259", "submitter": "Giulio Coluccia", "authors": "Giulio Coluccia, Enrico Magli", "title": "A Novel Progressive Image Scanning and Reconstruction Scheme based on\n  Compressed Sensing and Linear Prediction", "comments": "2012 IEEE International Conference on Multimedia and Expo (ICME),\n  Melbourne, Australia, 9-13 July 2012, pp.866-871", "journal-ref": null, "doi": "10.1109/ICME.2012.71", "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) is an innovative technique allowing to represent\nsignals through a small number of their linear projections. In this paper we\naddress the application of CS to the scenario of progressive acquisition of 2D\nvisual signals in a line-by-line fashion. This is an important setting which\nencompasses diverse systems such as flatbed scanners and remote sensing\nimagers. The use of CS in such setting raises the problem of reconstructing a\nvery high number of samples, as are contained in an image, from their linear\nprojections. Conventional reconstruction algorithms, whose complexity is cubic\nin the number of samples, are computationally intractable. In this paper we\ndevelop an iterative reconstruction algorithm that reconstructs an image by\niteratively estimating a row, and correlating adjacent rows by means of linear\nprediction. We develop suitable predictors and test the proposed algorithm in\nthe context of flatbed scanners and remote sensing imaging systems. We show\nthat this approach can significantly improve the results of separate\nreconstruction of each row, providing very good reconstruction quality with\nreasonable complexity.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2013 13:28:29 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Coluccia", "Giulio", ""], ["Magli", "Enrico", ""]]}, {"id": "1310.1341", "submitter": "Vijay Singh", "authors": "Vijay Singh, Martin Tchernookov, Rebecca Butterfield, and Ilya\n  Nemenman", "title": "Director Field Model of the Primary Visual Cortex for Contour Detection", "comments": "9 pages, 7 figures", "journal-ref": "PLoS ONE 9(10): e108991 (2014)", "doi": "10.1371/journal.pone.0108991", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to build the simplest possible model capable of detecting long, noisy\ncontours in a cluttered visual scene. For this, we model the neural dynamics in\nthe primate primary visual cortex in terms of a continuous director field that\ndescribes the average rate and the average orientational preference of active\nneurons at a particular point in the cortex. We then use a linear-nonlinear\ndynamical model with long range connectivity patterns to enforce long-range\nstatistical context present in the analyzed images. The resulting model has\nsubstantially fewer degrees of freedom than traditional models, and yet it can\ndistinguish large contiguous objects from the background clutter by suppressing\nthe clutter and by filling-in occluded elements of object contours. This\nresults in high-precision, high-recall detection of large objects in cluttered\nscenes. Parenthetically, our model has a direct correspondence with the Landau\n- de Gennes theory of nematic liquid crystal in two dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2013 17:27:48 GMT"}, {"version": "v2", "created": "Sat, 18 Oct 2014 23:20:40 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Singh", "Vijay", ""], ["Tchernookov", "Martin", ""], ["Butterfield", "Rebecca", ""], ["Nemenman", "Ilya", ""]]}, {"id": "1310.1371", "submitter": "Eldad Afik", "authors": "Eldad Afik", "title": "Robust and highly performant ring detection algorithm for 3d particle\n  tracking using 2d microscope imaging", "comments": "Software source-code is available at\n  https://github.com/eldad-a/ridge-directed-ring-detector, as well as the\n  linking (tracking) procedure and the natural cubic smoothing splines under\n  particle-tracking & natural-cubic-smoothing-splines, correspondingly. 20\n  manuscript pages, including 7 SI & 3 references pages, 2 manuscript figures &\n  3 supporting figures", "journal-ref": "Sci. Rep. 5, 13584, (2015)", "doi": "10.1038/srep13584", "report-no": null, "categories": "cs.CV cond-mat.soft physics.flu-dyn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Three-dimensional particle tracking is an essential tool in studying dynamics\nunder the microscope, namely, fluid dynamics in microfluidic devices, bacteria\ntaxis, cellular trafficking. The 3d position can be determined using 2d imaging\nalone by measuring the diffraction rings generated by an out-of-focus\nfluorescent particle, imaged on a single camera. Here I present a ring\ndetection algorithm exhibiting a high detection rate, which is robust to the\nchallenges arising from ring occlusion, inclusions and overlaps, and allows\nresolving particles even when near to each other. It is capable of real time\nanalysis thanks to its high performance and low memory footprint. The proposed\nalgorithm, an offspring of the circle Hough transform, addresses the need to\nefficiently trace the trajectories of many particles concurrently, when their\nnumber in not necessarily fixed, by solving a classification problem, and\novercomes the challenges of finding local maxima in the complex parameter space\nwhich results from ring clusters and noise. Several algorithmic concepts\nintroduced here can be advantageous in other cases, particularly when dealing\nwith noisy and sparse data. The implementation is based on open-source and\ncross-platform software packages only, making it easy to distribute and modify.\nIt is implemented in a microfluidic experiment allowing real-time\nmulti-particle tracking at 70 Hz, achieving a detection rate which exceeds 94%\nand only 1% false-detection.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2013 08:36:32 GMT"}, {"version": "v2", "created": "Thu, 2 Oct 2014 19:34:09 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2015 12:25:12 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Afik", "Eldad", ""]]}, {"id": "1310.1531", "submitter": "Yangqing Jia", "authors": "Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang,\n  Eric Tzeng, Trevor Darrell", "title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate whether features extracted from the activation of a deep\nconvolutional network trained in a fully supervised fashion on a large, fixed\nset of object recognition tasks can be re-purposed to novel generic tasks. Our\ngeneric tasks may differ significantly from the originally trained tasks and\nthere may be insufficient labeled or unlabeled data to conventionally train or\nadapt a deep architecture to the new tasks. We investigate and visualize the\nsemantic clustering of deep convolutional features with respect to a variety of\nsuch tasks, including scene recognition, domain adaptation, and fine-grained\nrecognition challenges. We compare the efficacy of relying on various network\nlevels to define a fixed feature, and report novel results that significantly\noutperform the state-of-the-art on several important vision challenges. We are\nreleasing DeCAF, an open-source implementation of these deep convolutional\nactivation features, along with all associated network parameters to enable\nvision researchers to be able to conduct experimentation with deep\nrepresentations across a range of visual concept learning paradigms.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2013 02:48:17 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Donahue", "Jeff", ""], ["Jia", "Yangqing", ""], ["Vinyals", "Oriol", ""], ["Hoffman", "Judy", ""], ["Zhang", "Ning", ""], ["Tzeng", "Eric", ""], ["Darrell", "Trevor", ""]]}, {"id": "1310.1690", "submitter": "Chunhua Shen", "authors": "Fayao Liu, Chunhua Shen, Ian Reid, Anton van den Hengel", "title": "Online Unsupervised Feature Learning for Visual Tracking", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature encoding with respect to an over-complete dictionary learned by\nunsupervised methods, followed by spatial pyramid pooling, and linear\nclassification, has exhibited powerful strength in various vision applications.\nHere we propose to use the feature learning pipeline for visual tracking.\nTracking is implemented using tracking-by-detection and the resulted framework\nis very simple yet effective. First, online dictionary learning is used to\nbuild a dictionary, which captures the appearance changes of the tracking\ntarget as well as the background changes. Given a test image window, we extract\nlocal image patches from it and each local patch is encoded with respect to the\ndictionary. The encoded features are then pooled over a spatial pyramid to form\nan aggregated feature vector. Finally, a simple linear classifier is trained on\nthese features.\n  Our experiments show that the proposed powerful---albeit simple---tracker,\noutperforms all the state-of-the-art tracking methods that we have tested.\nMoreover, we evaluate the performance of different dictionary learning and\nfeature encoding methods in the proposed tracking framework, and analyse the\nimpact of each component in the tracking scenario. We also demonstrate the\nflexibility of feature learning by plugging it into Hare et al.'s tracking\nmethod. The outcome is, to our knowledge, the best tracker ever reported, which\nfacilitates the advantages of both feature learning and structured output\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 07:32:17 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Liu", "Fayao", ""], ["Shen", "Chunhua", ""], ["Reid", "Ian", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1310.1771", "submitter": "Vladimir Kolmogorov", "authors": "Igor Gridchyn and Vladimir Kolmogorov", "title": "Potts model, parametric maxflow and k-submodular functions", "comments": "Accepted to ICCV 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of minimizing the Potts energy function frequently occurs in\ncomputer vision applications. One way to tackle this NP-hard problem was\nproposed by Kovtun [19,20]. It identifies a part of an optimal solution by\nrunning $k$ maxflow computations, where $k$ is the number of labels. The number\nof \"labeled\" pixels can be significant in some applications, e.g. 50-93% in our\ntests for stereo. We show how to reduce the runtime to $O(\\log k)$ maxflow\ncomputations (or one {\\em parametric maxflow} computation). Furthermore, the\noutput of our algorithm allows to speed-up the subsequent alpha expansion for\nthe unlabeled part, or can be used as it is for time-critical applications.\n  To derive our technique, we generalize the algorithm of Felzenszwalb et al.\n[7] for {\\em Tree Metrics}. We also show a connection to {\\em $k$-submodular\nfunctions} from combinatorial optimization, and discuss {\\em $k$-submodular\nrelaxations} for general energy functions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 13:17:09 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Gridchyn", "Igor", ""], ["Kolmogorov", "Vladimir", ""]]}, {"id": "1310.1811", "submitter": "Ouais Alsharif", "authors": "Ouais Alsharif and Joelle Pineau", "title": "End-to-End Text Recognition with Hybrid HMM Maxout Models", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting and recognizing text in natural scenes has proved to\nbe more challenging than its counterpart in documents, with most of the\nprevious work focusing on a single part of the problem. In this work, we\npropose new solutions to the character and word recognition problems and then\nshow how to combine these solutions in an end-to-end text-recognition system.\nWe do so by leveraging the recently introduced Maxout networks along with\nhybrid HMM models that have proven useful for voice recognition. Using these\nelements, we build a tunable and highly accurate recognition system that beats\nstate-of-the-art results on all the sub-problems for both the ICDAR 2003 and\nSVT benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 15:08:53 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Alsharif", "Ouais", ""], ["Pineau", "Joelle", ""]]}, {"id": "1310.1855", "submitter": "Junzhou Chen", "authors": "Junzhou Chen and Yong You", "title": "Early Fire Detection Using HEP and Space-time Analysis", "comments": "9 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this article, a video base early fire alarm system is developed by\nmonitoring the smoke in the scene. There are two major contributions in this\nwork. First, to find the best texture feature for smoke detection, a general\nframework, named Histograms of Equivalent Patterns (HEP), is adopted to achieve\nan extensive evaluation of various kinds of texture features. Second, the\n\\emph{Block based Inter-Frame Difference} (BIFD) and a improved version of\nLBP-TOP are proposed and ensembled to describe the space-time characteristics\nof the smoke. In order to reduce the false alarms, the Smoke History Image\n(SHI) is utilized to register the recent classification results of candidate\nsmoke blocks. Experimental results using SVM show that the proposed method can\nachieve better accuracy and less false alarm compared with the state-of-the-art\ntechnologies.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 16:41:23 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Chen", "Junzhou", ""], ["You", "Yong", ""]]}, {"id": "1310.1869", "submitter": "Vasil Kolev", "authors": "Vasil Kolev, Katya Tsvetkova, and Milcho Tsvetkov", "title": "Singular Value Decomposition of Images from Scanned Photographic Plates", "comments": "pages 15, Proceedings of the VII Bulgarian-Serbian Astronomical\n  Conference,Bulgaria,2010", "journal-ref": "Proceedings of the VII Bulgarian-Serbian Astronomical Conference\n  (VII BSAC) Chepelare, Bulgaria, June 1-4,pp.187-200, 2010,", "doi": null, "report-no": null, "categories": "cs.CV astro-ph.IM cs.CE", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We want to approximate the mxn image A from scanned astronomical photographic\nplates (from the Sofia Sky Archive Data Center) by using far fewer entries than\nin the original matrix. By using rank of a matrix, k we remove the redundant\ninformation or noise and use as Wiener filter, when rank k<m or k<n. With this\napproximation more than 98% compression ration of image of astronomical plate\nwithout that image details, is obtained. The SVD of images from scanned\nphotographic plates (SPP) is considered and its possible image compression.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 17:36:48 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Kolev", "Vasil", ""], ["Tsvetkova", "Katya", ""], ["Tsvetkov", "Milcho", ""]]}, {"id": "1310.1976", "submitter": "Ciro Donalek", "authors": "Ciro Donalek, Arun Kumar A., S.G. Djorgovski, Ashish A. Mahabal,\n  Matthew J. Graham, Thomas J. Fuchs, Michael J. Turmon, N. Sajeeth Philip,\n  Michael Ting-Chang Yang, Giuseppe Longo", "title": "Feature Selection Strategies for Classifying High Dimensional\n  Astronomical Data Sets", "comments": "7 pages, to appear in refereed proceedings of Scalable Machine\n  Learning: Theory and Applications, IEEE BigData 2013", "journal-ref": null, "doi": "10.1109/BigData.2013.6691731", "report-no": null, "categories": "astro-ph.IM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of collected data in many scientific fields is increasing, all of\nthem requiring a common task: extract knowledge from massive, multi parametric\ndata sets, as rapidly and efficiently possible. This is especially true in\nastronomy where synoptic sky surveys are enabling new research frontiers in the\ntime domain astronomy and posing several new object classification challenges\nin multi dimensional spaces; given the high number of parameters available for\neach object, feature selection is quickly becoming a crucial task in analyzing\nastronomical data sets. Using data sets extracted from the ongoing Catalina\nReal-Time Transient Surveys (CRTS) and the Kepler Mission we illustrate a\nvariety of feature selection strategies used to identify the subsets that give\nthe most information and the results achieved applying these techniques to\nthree major astronomical problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 00:53:10 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Donalek", "Ciro", ""], ["A.", "Arun Kumar", ""], ["Djorgovski", "S. G.", ""], ["Mahabal", "Ashish A.", ""], ["Graham", "Matthew J.", ""], ["Fuchs", "Thomas J.", ""], ["Turmon", "Michael J.", ""], ["Philip", "N. Sajeeth", ""], ["Yang", "Michael Ting-Chang", ""], ["Longo", "Giuseppe", ""]]}, {"id": "1310.2050", "submitter": "Kai Berger", "authors": "Kai Berger", "title": "A State Of the Art Report on Research in Multiple RGB-D sensor Setups", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  That the Microsoft Kinect, an RGB-D sensor, transformed the gaming and end\nconsumer sector has been anticipated by the developers. That it also impacted\nin rigorous computer vision research has probably been a surprise to the whole\ncommunity. Shortly before the commercial deployment of its successor, Kinect\nOne, the research literature fills with resumees and state-of-the art papers to\nsummarize the development over the past 3 years. This particular report\ndescribes significant research projects which have built on sensoring setups\nthat include two or more RGB-D sensors in one scene.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 09:04:34 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Berger", "Kai", ""]]}, {"id": "1310.2053", "submitter": "Kai Berger", "authors": "Kai Berger", "title": "The role of RGB-D benchmark datasets: an overview", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the Microsoft Kinect three years ago stimulated not only the\ncomputer vision community for new algorithms and setups to tackle well-known\nproblems in the community but also sparked the launch of several new benchmark\ndatasets to which future algorithms can be compared 019 to. This review of the\nliterature and industry developments concludes that the current RGB-D benchmark\ndatasets can be useful to determine the accuracy of a variety of applications\nof a single or multiple RGB-D sensors.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 09:16:56 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Berger", "Kai", ""]]}, {"id": "1310.2085", "submitter": "Martin Welk", "authors": "Martin Welk", "title": "A Robust Variational Model for Positive Image Deconvolution", "comments": null, "journal-ref": "Signal, Image and Video Processing, 10 (2016) 369-378", "doi": "10.1007/s11760-015-0750-z", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an iterative method for robust deconvolution with positivity\nconstraints is discussed. It is based on the known variational interpretation\nof the Richardson-Lucy iterative deconvolution as fixed-point iteration for the\nminimisation of an information divergence functional under a multiplicative\nperturbation model. The asymmetric penaliser function involved in this\nfunctional is then modified into a robust penaliser, and complemented with a\nregulariser. The resulting functional gives rise to a fixed point iteration\nthat we call robust and regularised Richardson-Lucy deconvolution. It achieves\nan image restoration quality comparable to state-of-the-art robust variational\ndeconvolution with a computational efficiency similar to that of the original\nRichardson-Lucy method. Experiments on synthetic and real-world image data\ndemonstrate the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 10:44:58 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Welk", "Martin", ""]]}, {"id": "1310.2418", "submitter": "Aur\\'elie Leborgne Ms.", "authors": "Aur\\'elie Leborgne, Julien Mille and Laure Tougne", "title": "Linear Algorithm for Digital Euclidean Connected Skeleton", "comments": "This paper has been withdrawn by the author because it was not\n  correct and not accepted by CVIU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The skeleton is an essential shape characteristic providing a compact\nrepresentation of the studied shape. Its computation on the image grid raises\nmany issues. Due to the effects of discretization, the required properties of\nthe skeleton - thinness, homotopy to the shape, reversibility, connectivity -\nmay become incompatible. However, as regards practical use, the choice of a\nspecific skeletonization algorithm depends on the application. This allows to\nclassify the desired properties by order of importance, and tend towards the\nmost critical ones. Our goal is to make a skeleton dedicated to shape matching\nfor recognition. So, the discrete skeleton has to be thin - so that it can be\nrepresented by a graph -, robust to noise, reversible - so that the initial\nshape can be fully reconstructed - and homotopic to the shape. We propose a\nlinear-time skeletonization algorithm based on the squared Euclidean distance\nmap from which we extract the maximal balls and ridges. After a thinning and\npruning process, we obtain the skeleton. The proposed method is finally\ncompared to fairly recent methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 09:58:41 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 13:14:38 GMT"}, {"version": "v3", "created": "Mon, 2 Jun 2014 11:19:19 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Leborgne", "Aur\u00e9lie", ""], ["Mille", "Julien", ""], ["Tougne", "Laure", ""]]}, {"id": "1310.2842", "submitter": "Han Wang", "authors": "Habib Ammari, St\\'ephane Mallat, Ir\\`ene Waldspurger, Han Wang", "title": "Wavelet methods for shape perception in electro-sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at presenting a new approach to the electro-sensing problem\nusing wavelets. It provides an efficient algorithm for recognizing the shape of\na target from micro-electrical impedance measurements. Stability and resolution\ncapabilities of the proposed algorithm are quantified in numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 14:49:31 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["Ammari", "Habib", ""], ["Mallat", "St\u00e9phane", ""], ["Waldspurger", "Ir\u00e8ne", ""], ["Wang", "Han", ""]]}, {"id": "1310.2880", "submitter": "Adrian Barbu", "authors": "Adrian Barbu, Yiyuan She, Liangjing Ding, Gary Gramajo", "title": "Feature Selection with Annealing for Computer Vision and Big Data\n  Learning", "comments": "18 pages, 9 figures", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 39, no 2, pp 272 - 286, 2017", "doi": "10.1109/TPAMI.2016.2544315", "report-no": null, "categories": "stat.ML cs.CV cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision and medical imaging problems are faced with learning\nfrom large-scale datasets, with millions of observations and features. In this\npaper we propose a novel efficient learning scheme that tightens a sparsity\nconstraint by gradually removing variables based on a criterion and a schedule.\nThe attractive fact that the problem size keeps dropping throughout the\niterations makes it particularly suitable for big data learning. Our approach\napplies generically to the optimization of any differentiable loss function,\nand finds applications in regression, classification and ranking. The resultant\nalgorithms build variable screening into estimation and are extremely simple to\nimplement. We provide theoretical guarantees of convergence and selection\nconsistency. In addition, one dimensional piecewise linear response functions\nare used to account for nonlinearity and a second order prior is imposed on\nthese functions to avoid overfitting. Experiments on real and synthetic data\nshow that the proposed method compares very well with other state of the art\nmethods in regression, classification and ranking while being computationally\nvery efficient and scalable.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 16:47:22 GMT"}, {"version": "v2", "created": "Wed, 4 Jun 2014 22:42:51 GMT"}, {"version": "v3", "created": "Tue, 30 Sep 2014 00:33:36 GMT"}, {"version": "v4", "created": "Wed, 1 Oct 2014 20:03:42 GMT"}, {"version": "v5", "created": "Thu, 3 Sep 2015 13:20:26 GMT"}, {"version": "v6", "created": "Wed, 24 Feb 2016 02:02:20 GMT"}, {"version": "v7", "created": "Thu, 17 Mar 2016 14:55:09 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Barbu", "Adrian", ""], ["She", "Yiyuan", ""], ["Ding", "Liangjing", ""], ["Gramajo", "Gary", ""]]}, {"id": "1310.2916", "submitter": "Ayan Chakrabarti", "authors": "Ying Xiong, Ayan Chakrabarti, Ronen Basri, Steven J. Gortler, David W.\n  Jacobs, Todd Zickler", "title": "From Shading to Local Shape", "comments": null, "journal-ref": "IEEE Trans. PAMI 37 (2015) 67-79", "doi": "10.1109/TPAMI.2014.2343211", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for extracting a concise representation of the shape\ninformation available from diffuse shading in a small image patch. This\nproduces a mid-level scene descriptor, comprised of local shape distributions\nthat are inferred separately at every image patch across multiple scales. The\nframework is based on a quadratic representation of local shape that, in the\nabsence of noise, has guarantees on recovering accurate local shape and\nlighting. And when noise is present, the inferred local shape distributions\nprovide useful shape information without over-committing to any particular\nimage explanation. These local shape distributions naturally encode the fact\nthat some smooth diffuse regions are more informative than others, and they\nenable efficient and robust reconstruction of object-scale shape. Experimental\nresults show that this approach to surface reconstruction compares well against\nthe state-of-art on both synthetic images and captured photographs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 18:49:57 GMT"}, {"version": "v2", "created": "Mon, 7 Apr 2014 19:20:20 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Xiong", "Ying", ""], ["Chakrabarti", "Ayan", ""], ["Basri", "Ronen", ""], ["Gortler", "Steven J.", ""], ["Jacobs", "David W.", ""], ["Zickler", "Todd", ""]]}, {"id": "1310.3233", "submitter": "ANqi Qiu DR", "authors": "Jia Du, Alvina Goh, Anqi Qiu", "title": "Bayesian Estimation of White Matter Atlas from High Angular Resolution\n  Diffusion Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian probabilistic model to estimate the brain white matter\natlas from high angular resolution diffusion imaging (HARDI) data. This model\nincorporates a shape prior of the white matter anatomy and the likelihood of\nindividual observed HARDI datasets. We first assume that the atlas is generated\nfrom a known hyperatlas through a flow of diffeomorphisms and its shape prior\ncan be constructed based on the framework of large deformation diffeomorphic\nmetric mapping (LDDMM). LDDMM characterizes a nonlinear diffeomorphic shape\nspace in a linear space of initial momentum uniquely determining diffeomorphic\ngeodesic flows from the hyperatlas. Therefore, the shape prior of the HARDI\natlas can be modeled using a centered Gaussian random field (GRF) model of the\ninitial momentum. In order to construct the likelihood of observed HARDI\ndatasets, it is necessary to study the diffeomorphic transformation of\nindividual observations relative to the atlas and the probabilistic\ndistribution of orientation distribution functions (ODFs). To this end, we\nconstruct the likelihood related to the transformation using the same\nconstruction as discussed for the shape prior of the atlas. The probabilistic\ndistribution of ODFs is then constructed based on the ODF Riemannian manifold.\nWe assume that the observed ODFs are generated by an exponential map of random\ntangent vectors at the deformed atlas ODF. Hence, the likelihood of the ODFs\ncan be modeled using a GRF of their tangent vectors in the ODF Riemannian\nmanifold. We solve for the maximum a posteriori using the\nExpectation-Maximization algorithm and derive the corresponding update\nequations. Finally, we illustrate the HARDI atlas constructed based on a\nChinese aging cohort of 94 adults and compare it with that generated by\naveraging the coefficients of spherical harmonics of the ODF across subjects.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 00:32:01 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Du", "Jia", ""], ["Goh", "Alvina", ""], ["Qiu", "Anqi", ""]]}, {"id": "1310.3366", "submitter": "Jan Egger", "authors": "Jan Egger", "title": "PCG-Cut: Graph Driven Segmentation of the Prostate Central Gland", "comments": "6 pages, 6 figures, 2 tables, 52 references", "journal-ref": "PLoS ONE 8(10): e76645 (2013)", "doi": "10.1371/journal.pone.0076645", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prostate cancer is the most abundant cancer in men, with over 200,000\nexpected new cases and around 28,000 deaths in 2012 in the US alone. In this\nstudy, the segmentation results for the prostate central gland (PCG) in MR\nscans are presented. The aim of this research study is to apply a graph-based\nalgorithm to automated segmentation (i.e. delineation) of organ limits for the\nprostate central gland. The ultimate goal is to apply automated segmentation\napproach to facilitate efficient MR-guided biopsy and radiation treatment\nplanning. The automated segmentation algorithm used is graph-driven based on a\nspherical template. Therefore, rays are sent through the surface points of a\npolyhedron to sample the graph's nodes. After graph construction - which only\nrequires the center of the polyhedron defined by the user and located inside\nthe prostate center gland - the minimal cost closed set on the graph is\ncomputed via a polynomial time s-t-cut, which results in the segmentation of\nthe prostate center gland's boundaries and volume. The algorithm has been\nrealized as a C++ modul within the medical research platform MeVisLab and the\nground truth of the central gland boundaries were manually extracted by\nclinical experts (interventional radiologists) with several years of experience\nin prostate treatment. For evaluation the automated segmentations of the\nproposed scheme have been compared with the manual segmentations, yielding an\naverage Dice Similarity Coefficient (DSC) of 78.94 +/- 10.85%.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 12:53:01 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Egger", "Jan", ""]]}, {"id": "1310.3399", "submitter": "Prashanth  B.U.V", "authors": "B U V Prashanth, P Narahari Sastry, V Rajesh", "title": "An Improved K-means Clustering Based Approach to Detect a DNA Structure\n  in H&E Image of Mouse Tissue Reacted with CD4-Green Antigen", "comments": "This paper has been withdrawn by the author to perform more\n  comprehensive evaluations in the research work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this manuscript we present the technique to detect and analyze the DNA\nrich structure in Haemotoxylin & Eosin (H&E) image of a tissue treated with\nanti CD4 green antigen. The detection of DNA rich structure can be considered\nas a detection of blue nuclei present through the biomedical signal/image\nprocessing technique performed on the image of the tissue obtained by the\nScanning Electron Microscope(SEM). Earlier the tissue treated with the anti CD4\ngreen antigen, is stained with the H&E staining solution.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 16:04:35 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2013 08:47:53 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Prashanth", "B U V", ""], ["Sastry", "P Narahari", ""], ["Rajesh", "V", ""]]}, {"id": "1310.3447", "submitter": "Jun Liu", "authors": "Jun Liu, Ting-Zhu Huang, Ivan W. Selesnick, Xiao-Guang Lv, Po-Yu Chen", "title": "Image Restoration using Total Variation with Overlapping Group Sparsity", "comments": "11 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image restoration is one of the most fundamental issues in imaging science.\nTotal variation (TV) regularization is widely used in image restoration\nproblems for its capability to preserve edges. In the literature, however, it\nis also well known for producing staircase-like artifacts. Usually, the\nhigh-order total variation (HTV) regularizer is an good option except its\nover-smoothing property. In this work, we study a minimization problem where\nthe objective includes an usual $l_2$ data-fidelity term and an overlapping\ngroup sparsity total variation regularizer which can avoid staircase effect and\nallow edges preserving in the restored image. We also proposed a fast algorithm\nfor solving the corresponding minimization problem and compare our method with\nthe state-of-the-art TV based methods and HTV based method. The numerical\nexperiments illustrate the efficiency and effectiveness of the proposed method\nin terms of PSNR, relative error and computing time.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2013 05:03:41 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2013 07:48:25 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Liu", "Jun", ""], ["Huang", "Ting-Zhu", ""], ["Selesnick", "Ivan W.", ""], ["Lv", "Xiao-Guang", ""], ["Chen", "Po-Yu", ""]]}, {"id": "1310.3452", "submitter": "Qiong Yan", "authors": "Qiong Yan, Li Xu, Jiaya Jia", "title": "Dense Scattering Layer Removal", "comments": "10 pages, 10 figures, Siggraph Asia 2013 Technial Briefs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model, together with advanced optimization, to separate a\nthick scattering media layer from a single natural image. It is able to handle\nchallenging underwater scenes and images taken in fog and sandstorm, both of\nwhich are with significantly reduced visibility. Our method addresses the\ncritical issue -- this is, originally unnoticeable impurities will be greatly\nmagnified after removing the scattering media layer -- with transmission-aware\noptimization. We introduce non-local structure-aware regularization to properly\nconstrain transmission estimation without introducing the halo artifacts. A\nselective-neighbor criterion is presented to convert the unconventional\nconstrained optimization problem to an unconstrained one where the latter can\nbe efficiently solved.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2013 06:58:57 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Yan", "Qiong", ""], ["Xu", "Li", ""], ["Jia", "Jiaya", ""]]}, {"id": "1310.3717", "submitter": "Anish Bahri", "authors": "Anish Bahri, V Sugumaran, S Babu Devasenapati", "title": "Misfire Detection in IC Engine using Kstar Algorithm", "comments": "12 Pages, 8 Figures, 4 Tables. International Journal of Research in\n  Mechanical Engineering, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misfire in an IC Engine continues to be a problem leading to reduced fuel\nefficiency, increased power loss and emissions containing heavy concentration\nof hydrocarbons. Misfiring creates a unique vibration pattern attributed to a\nparticular cylinder. Useful features can be extracted from these patterns and\ncan be analyzed to detect misfire. Statistical features from these vibration\nsignals were extracted. Out of these, useful features were identified using the\nJ48 decision tree algorithm and selected features were used for classification\nusing the Kstar algorithm. In this paper performance analysis of Kstar\nalgorithm is presented.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 15:19:45 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Bahri", "Anish", ""], ["Sugumaran", "V", ""], ["Devasenapati", "S Babu", ""]]}, {"id": "1310.4217", "submitter": "Bingni Brunton", "authors": "B. W. Brunton, S. L. Brunton, J. L. Proctor, and J. N. Kutz", "title": "Optimal Sensor Placement and Enhanced Sparsity for Classification", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of compressive sensing is efficient reconstruction of data from few\nmeasurements, sometimes leading to a categorical decision. If only\nclassification is required, reconstruction can be circumvented and the\nmeasurements needed are orders-of-magnitude sparser still. We define enhanced\nsparsity as the reduction in number of measurements required for classification\nover reconstruction. In this work, we exploit enhanced sparsity and learn\nspatial sensor locations that optimally inform a categorical decision. The\nalgorithm solves an l1-minimization to find the fewest entries of the full\nmeasurement vector that exactly reconstruct the discriminant vector in feature\nspace. Once the sensor locations have been identified from the training data,\nsubsequent test samples are classified with remarkable efficiency, achieving\nperformance comparable to that obtained by discrimination using the full image.\nSensor locations may be learned from full images, or from a random subsample of\npixels. For classification between more than two categories, we introduce a\ncoupling parameter whose value tunes the number of sensors selected, trading\naccuracy for economy. We demonstrate the algorithm on example datasets from\nimage recognition using PCA for feature extraction and LDA for discrimination;\nhowever, the method can be broadly applied to non-image data and adapted to\nwork with other methods for feature extraction and discrimination.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 21:41:17 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Brunton", "B. W.", ""], ["Brunton", "S. L.", ""], ["Proctor", "J. L.", ""], ["Kutz", "J. N.", ""]]}, {"id": "1310.4249", "submitter": "Gordon Berman", "authors": "Gordon J. Berman, Daniel M. Choi, William Bialek, and Joshua W.\n  Shaevitz", "title": "Mapping the stereotyped behaviour of freely-moving fruit flies", "comments": "21 pages, 17 figures. Email GJB (gberman@princeton.edu) to see\n  supplementary movies, Journal of the Royal Society Interface, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most animals possess the ability to actuate a vast diversity of movements,\nostensibly constrained only by morphology and physics. In practice, however, a\nfrequent assumption in behavioral science is that most of an animal's\nactivities can be described in terms of a small set of stereotyped motifs. Here\nwe introduce a method for mapping the behavioral space of organisms, relying\nonly upon the underlying structure of postural movement data to organize and\nclassify behaviors. We find that six different drosophilid species each perform\na mix of non-stereotyped actions and over one hundred hierarchically-organized,\nstereotyped behaviors. Moreover, we use this approach to compare these species'\nbehavioral spaces, systematically identifying subtle behavioral differences\nbetween closely-related species.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 02:44:56 GMT"}, {"version": "v2", "created": "Tue, 12 Aug 2014 02:26:51 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Berman", "Gordon J.", ""], ["Choi", "Daniel M.", ""], ["Bialek", "William", ""], ["Shaevitz", "Joshua W.", ""]]}, {"id": "1310.4389", "submitter": "Ming-Ming Cheng Dr", "authors": "Ming-Ming Cheng, Shuai Zheng, Wen-Yan Lin, Jonathan Warrell, Vibhav\n  Vineet, Paul Sturgess, Nigel Crook, Niloy Mitra, Philip Torr", "title": "ImageSpirit: Verbal Guided Image Parsing", "comments": "http://mmcheng.net/imagespirit/", "journal-ref": "ACM Transactions on Graphics, 2014", "doi": "10.1145/2682628", "report-no": null, "categories": "cs.GR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans describe images in terms of nouns and adjectives while algorithms\noperate on images represented as sets of pixels. Bridging this gap between how\nhumans would like to access images versus their typical representation is the\ngoal of image parsing, which involves assigning object and attribute labels to\npixel. In this paper we propose treating nouns as object labels and adjectives\nas visual attribute labels. This allows us to formulate the image parsing\nproblem as one of jointly estimating per-pixel object and attribute labels from\na set of training images. We propose an efficient (interactive time) solution.\nUsing the extracted labels as handles, our system empowers a user to verbally\nrefine the results. This enables hands-free parsing of an image into pixel-wise\nobject/attribute labels that correspond to human semantics. Verbally selecting\nobjects of interests enables a novel and natural interaction modality that can\npossibly be used to interact with new generation devices (e.g. smart phones,\nGoogle Glass, living room devices). We demonstrate our system on a large number\nof real-world images with varying complexity. To help understand the tradeoffs\ncompared to traditional mouse based interactions, results are reported for both\na large scale quantitative evaluation and a user study.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 14:16:31 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 16:56:03 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Cheng", "Ming-Ming", ""], ["Zheng", "Shuai", ""], ["Lin", "Wen-Yan", ""], ["Warrell", "Jonathan", ""], ["Vineet", "Vibhav", ""], ["Sturgess", "Paul", ""], ["Crook", "Nigel", ""], ["Mitra", "Niloy", ""], ["Torr", "Philip", ""]]}, {"id": "1310.4713", "submitter": "Junzhou Chen", "authors": "Junzhou Chen and Kin Hong Wong", "title": "Calibration of an Articulated Camera System with Scale Factor Estimation", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Multiple Camera Systems (MCS) have been widely used in many vision\napplications and attracted much attention recently. There are two principle\ntypes of MCS, one is the Rigid Multiple Camera System (RMCS); the other is the\nArticulated Camera System (ACS). In a RMCS, the relative poses (relative 3-D\nposition and orientation) between the cameras are invariant. While, in an ACS,\nthe cameras are articulated through movable joints, the relative pose between\nthem may change. Therefore, through calibration of an ACS we want to find not\nonly the relative poses between the cameras but also the positions of the\njoints in the ACS.\n  In this paper, we developed calibration algorithms for the ACS using a simple\nconstraint: the joint is fixed relative to the cameras connected with it during\nthe transformations of the ACS. When the transformations of the cameras in an\nACS can be estimated relative to the same coordinate system, the positions of\nthe joints in the ACS can be calculated by solving linear equations. However,\nin a non-overlapping view ACS, only the ego-transformations of the cameras and\ncan be estimated. We proposed a two-steps method to deal with this problem. In\nboth methods, the ACS is assumed to have performed general transformations in a\nstatic environment. The efficiency and robustness of the proposed methods are\ntested by simulation and real experiments. In the real experiment, the\nintrinsic and extrinsic parameters of the ACS are obtained simultaneously by\nour calibration procedure using the same image sequences, no extra data\ncapturing step is required. The corresponding trajectory is recovered and\nillustrated using the calibration results of the ACS. Since the estimated\ntranslations of different cameras in an ACS may scaled by different scale\nfactors, a scale factor estimation algorithm is also proposed. To our\nknowledge, we are the first to study the calibration of ACS.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 14:26:58 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Chen", "Junzhou", ""], ["Wong", "Kin Hong", ""]]}, {"id": "1310.4759", "submitter": "Erik Rodner", "authors": "Christoph G\\\"oring, Alexander Freytag, Erik Rodner, Joachim Denzler", "title": "Fine-grained Categorization -- Short Summary of our Entry for the\n  ImageNet Challenge 2012", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of visual categorization of dog breeds,\nwhich is a surprisingly challenging task due to simultaneously present low\ninterclass distances and high intra-class variances. Our approach combines\nseveral techniques well known in our community but often not utilized for\nfine-grained recognition:\n  (1) automatic segmentation, (2) efficient part detection, and (3) combination\nof multiple features. In particular, we demonstrate that a simple head detector\nembedded in an off-the-shelf recognition pipeline can improve recognition\naccuracy quite significantly, highlighting the importance of part features for\nfine-grained recognition tasks. Using our approach, we achieved a 24.59% mean\naverage precision performance on the Stanford dog dataset.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 16:11:53 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["G\u00f6ring", "Christoph", ""], ["Freytag", "Alexander", ""], ["Rodner", "Erik", ""], ["Denzler", "Joachim", ""]]}, {"id": "1310.4822", "submitter": "Hugo Jair  Escalante", "authors": "Hugo Jair Escalante, Isabelle Guyon, Vassilis Athitsos, Pat\n  Jangyodsuk, Jun Wan", "title": "Principal motion components for gesture recognition using a\n  single-example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces principal motion components (PMC), a new method for\none-shot gesture recognition. In the considered scenario a single\ntraining-video is available for each gesture to be recognized, which limits the\napplication of traditional techniques (e.g., HMMs). In PMC, a 2D map of motion\nenergy is obtained per each pair of consecutive frames in a video. Motion maps\nassociated to a video are processed to obtain a PCA model, which is used for\nrecognition under a reconstruction-error approach. The main benefits of the\nproposed approach are its simplicity, easiness of implementation, competitive\nperformance and efficiency. We report experimental results in one-shot gesture\nrecognition using the ChaLearn Gesture Dataset; a benchmark comprising more\nthan 50,000 gestures, recorded as both RGB and depth video with a Kinect\ncamera. Results obtained with PMC are competitive with alternative methods\nproposed for the same data set.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 19:52:50 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2014 12:04:41 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Escalante", "Hugo Jair", ""], ["Guyon", "Isabelle", ""], ["Athitsos", "Vassilis", ""], ["Jangyodsuk", "Pat", ""], ["Wan", "Jun", ""]]}, {"id": "1310.4891", "submitter": "Chunhua Shen", "authors": "Mehrtash Harandi, Conrad Sanderson, Chunhua Shen, Brian C. Lovell", "title": "Dictionary Learning and Sparse Coding on Grassmann Manifolds: An\n  Extrinsic Solution", "comments": "9 pages. Appearing in Int. Conf. Computer Vision, 2013, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recent advances in computer vision and machine learning suggest that a wide\nrange of problems can be addressed more appropriately by considering\nnon-Euclidean geometry. In this paper we explore sparse dictionary learning\nover the space of linear subspaces, which form Riemannian structures known as\nGrassmann manifolds. To this end, we propose to embed Grassmann manifolds into\nthe space of symmetric matrices by an isometric mapping, which enables us to\ndevise a closed-form solution for updating a Grassmann dictionary, atom by\natom. Furthermore, to handle non-linearity in data, we propose a kernelised\nversion of the dictionary learning algorithm. Experiments on several\nclassification tasks (face recognition, action recognition, dynamic texture\nclassification) show that the proposed approach achieves considerable\nimprovements in discrimination accuracy, in comparison to state-of-the-art\nmethods such as kernelised Affine Hull Method and graph-embedding Grassmann\ndiscriminant analysis.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 03:04:47 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Harandi", "Mehrtash", ""], ["Sanderson", "Conrad", ""], ["Shen", "Chunhua", ""], ["Lovell", "Brian C.", ""]]}, {"id": "1310.4945", "submitter": "Xiangrong Zeng", "authors": "Xiangrong Zeng and M\\'ario A. T. Figueiredo", "title": "A novel sparsity and clustering regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel SPARsity and Clustering (SPARC) regularizer, which is a\nmodified version of the previous octagonal shrinkage and clustering algorithm\nfor regression (OSCAR), where, the proposed regularizer consists of a\n$K$-sparse constraint and a pair-wise $\\ell_{\\infty}$ norm restricted on the\n$K$ largest components in magnitude. The proposed regularizer is able to\nseparably enforce $K$-sparsity and encourage the non-zeros to be equal in\nmagnitude. Moreover, it can accurately group the features without shrinking\ntheir magnitude. In fact, SPARC is closely related to OSCAR, so that the\nproximity operator of the former can be efficiently computed based on that of\nthe latter, allowing using proximal splitting algorithms to solve problems with\nSPARC regularization. Experiments on synthetic data and with benchmark breast\ncancer data show that SPARC is a competitive group-sparsity inducing\nregularizer for regression and classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 08:31:54 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 16:41:40 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Zeng", "Xiangrong", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "1310.5082", "submitter": "Gustavo Camps-Valls", "authors": "Gustavo Camps-Valls, Juan Guti\\'errez, Gabriel G\\'omez-P\\'erez,\n  Jes\\'us Malo", "title": "On the Suitable Domain for SVM Training in Image Coding", "comments": null, "journal-ref": "Journal of Machine Learning Research, JMLR, 9(1), 49-66, 2008", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional SVM-based image coding methods are founded on independently\nrestricting the distortion in every image coefficient at some particular image\nrepresentation. Geometrically, this implies allowing arbitrary signal\ndistortions in an $n$-dimensional rectangle defined by the\n$\\varepsilon$-insensitivity zone in each dimension of the selected image\nrepresentation domain. Unfortunately, not every image representation domain is\nwell-suited for such a simple, scalar-wise, approach because statistical and/or\nperceptual interactions between the coefficients may exist. These interactions\nimply that scalar approaches may induce distortions that do not follow the\nimage statistics and/or are perceptually annoying. Taking into account these\nrelations would imply using non-rectangular $\\varepsilon$-insensitivity regions\n(allowing coupled distortions in different coefficients), which is beyond the\nconventional SVM formulation.\n  In this paper, we report a condition on the suitable domain for developing\nefficient SVM image coding schemes. We analytically demonstrate that no linear\ndomain fulfills this condition because of the statistical and perceptual\ninter-coefficient relations that exist in these domains. This theoretical\nresult is experimentally confirmed by comparing SVM learning in previously\nreported linear domains and in a recently proposed non-linear perceptual domain\nthat simultaneously reduces the statistical and perceptual relations (so it is\ncloser to fulfilling the proposed condition). These results highlight the\nrelevance of an appropriate choice of the image representation before SVM\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 16:34:04 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Camps-Valls", "Gustavo", ""], ["Guti\u00e9rrez", "Juan", ""], ["G\u00f3mez-P\u00e9rez", "Gabriel", ""], ["Malo", "Jes\u00fas", ""]]}, {"id": "1310.5107", "submitter": "Gustavo Camps-Valls", "authors": "Gustavo Camps-Valls, Devis Tuia, Lorenzo Bruzzone and J\\'on Atli\n  Benediktsson", "title": "Advances in Hyperspectral Image Classification: Earth monitoring with\n  statistical learning methods", "comments": "IEEE Signal Processing Magazine, 2013", "journal-ref": null, "doi": "10.1109/MSP.2013.2279179", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral images show similar statistical properties to natural grayscale\nor color photographic images. However, the classification of hyperspectral\nimages is more challenging because of the very high dimensionality of the\npixels and the small number of labeled examples typically available for\nlearning. These peculiarities lead to particular signal processing problems,\nmainly characterized by indetermination and complex manifolds. The framework of\nstatistical learning has gained popularity in the last decade. New methods have\nbeen presented to account for the spatial homogeneity of images, to include\nuser's interaction via active learning, to take advantage of the manifold\nstructure with semisupervised learning, to extract and encode invariances, or\nto adapt classifiers and image representations to unseen yet similar scenes.\nThis tutuorial reviews the main advances for hyperspectral remote sensing image\nclassification through illustrative examples.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 17:49:45 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Camps-Valls", "Gustavo", ""], ["Tuia", "Devis", ""], ["Bruzzone", "Lorenzo", ""], ["Benediktsson", "J\u00f3n Atli", ""]]}, {"id": "1310.5542", "submitter": "Alexander Kadyrov", "authors": "Alexander Kadyrov, Hui Yu and Honghai Liu", "title": "Ship Detection and Segmentation using Image Correlation", "comments": "8 pages, to be published in proc. of conference IEEE SMC 2013", "journal-ref": null, "doi": "10.1109/SMC.2013.532", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been intensive research interests in ship detection and\nsegmentation due to high demands on a wide range of civil applications in the\nlast two decades. However, existing approaches, which are mainly based on\nstatistical properties of images, fail to detect smaller ships and boats.\nSpecifically, known techniques are not robust enough in view of inevitable\nsmall geometric and photometric changes in images consisting of ships. In this\npaper a novel approach for ship detection is proposed based on correlation of\nmaritime images. The idea comes from the observation that a fine pattern of the\nsea surface changes considerably from time to time whereas the ship appearance\nbasically keeps unchanged. We want to examine whether the images have a common\nunaltered part, a ship in this case. To this end, we developed a method -\nFocused Correlation (FC) to achieve robustness to geometric distortions of the\nimage content. Various experiments have been conducted to evaluate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 13:48:52 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kadyrov", "Alexander", ""], ["Yu", "Hui", ""], ["Liu", "Honghai", ""]]}, {"id": "1310.5619", "submitter": "Vikas Dongre", "authors": "Vikas J. Dongre, Vijay H. Mankar", "title": "Devnagari Handwritten Numeral Recognition using Geometric Features and\n  Statistical Combination Classifier", "comments": "8 pages, 6 figures, 1 table, journal paper", "journal-ref": "International Journal on Computer Science and Engineering (IJCSE)\n  ISSN : 0975-3397, Vol. 5 No. 10 pp. 856-863, Oct 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a Devnagari Numerical recognition method based on\nstatistical discriminant functions. 17 geometric features based on pixel\nconnectivity, lines, line directions, holes, image area, perimeter,\neccentricity, solidity, orientation etc. are used for representing the\nnumerals. Five discriminant functions viz. Linear, Quadratic, Diaglinear,\nDiagquadratic and Mahalanobis distance are used for classification. 1500\nhandwritten numerals are used for training. Another 1500 handwritten numerals\nare used for testing. Experimental results show that Linear, Quadratic and\nMahalanobis discriminant functions provide better results. Results of these\nthree Discriminants are fed to a majority voting type Combination classifier.\nIt is found that Combination classifier offers better results over individual\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 16:04:25 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Dongre", "Vikas J.", ""], ["Mankar", "Vijay H.", ""]]}, {"id": "1310.5715", "submitter": "Deanna Needell", "authors": "Deanna Needell, Nathan Srebro, Rachel Ward", "title": "Stochastic Gradient Descent, Weighted Sampling, and the Randomized\n  Kaczmarz algorithm", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain an improved finite-sample guarantee on the linear convergence of\nstochastic gradient descent for smooth and strongly convex objectives,\nimproving from a quadratic dependence on the conditioning $(L/\\mu)^2$ (where\n$L$ is a bound on the smoothness and $\\mu$ on the strong convexity) to a linear\ndependence on $L/\\mu$. Furthermore, we show how reweighting the sampling\ndistribution (i.e. importance sampling) is necessary in order to further\nimprove convergence, and obtain a linear dependence in the average smoothness,\ndominating previous results. We also discuss importance sampling for SGD more\nbroadly and show how it can improve convergence also in other scenarios. Our\nresults are based on a connection we make between SGD and the randomized\nKaczmarz algorithm, which allows us to transfer ideas between the separate\nbodies of literature studying each of the two methods. In particular, we recast\nthe randomized Kaczmarz algorithm as an instance of SGD, and apply our results\nto prove its exponential convergence, but to the solution of a weighted least\nsquares problem rather than the original least squares problem. We then present\na modified Kaczmarz algorithm with partially biased sampling which does\nconverge to the original least squares solution with the same exponential\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 20:15:44 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2014 01:43:32 GMT"}, {"version": "v3", "created": "Thu, 20 Mar 2014 16:51:23 GMT"}, {"version": "v4", "created": "Thu, 27 Nov 2014 05:10:09 GMT"}, {"version": "v5", "created": "Fri, 16 Jan 2015 17:11:24 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Needell", "Deanna", ""], ["Srebro", "Nathan", ""], ["Ward", "Rachel", ""]]}, {"id": "1310.5755", "submitter": "Jan Egger", "authors": "Jan Egger, Miriam H. A. Bauer, Stefan Gro{\\ss}kopf, Christina\n  Biermann, Bernd Freisleben, Christopher Nimsky", "title": "Determination, Calculation and Representation of the Upper and Lower\n  Sealing Zones During Virtual Stenting of Aneurysms", "comments": "4 pages, 2 figures, 10 references", "journal-ref": "Int J CARS, Vol. 5, Suppl. 1, pp. 13-14, Springer Press, June 2010", "doi": null, "report-no": null, "categories": "cs.CV physics.med-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, a novel method for stent simulation in preoperative\ncomputed tomography angiography (CTA) acquisitions of patients is presented\nwhere the sealing zones are automatically calculated and visualized. The method\nis eligible for non-bifurcated and bifurcated stents (Y-stents). Results of the\nproposed stent simulation with an automatic calculation of the sealing zones\nfor specific diseases (abdominal aortic aneurysms (AAA), thoracic aortic\naneurysms (TAA), iliac aneurysms) are presented. The contribution is organized\nas follows. Section 2 presents the proposed approach. In Section 3,\nexperimental results are discussed. Section 4 concludes the contribution and\noutlines areas for future work.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 23:12:43 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Egger", "Jan", ""], ["Bauer", "Miriam H. A.", ""], ["Gro\u00dfkopf", "Stefan", ""], ["Biermann", "Christina", ""], ["Freisleben", "Bernd", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1310.5767", "submitter": "Chunhua Shen", "authors": "Xi Li, Yao Li, Chunhua Shen, Anthony Dick, Anton van den Hengel", "title": "Contextual Hypergraph Modelling for Salient Object Detection", "comments": "Appearing in Proc. Int. Conf. Computer Vision 2013, Sydney, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Salient object detection aims to locate objects that capture human attention\nwithin images. Previous approaches often pose this as a problem of image\ncontrast analysis. In this work, we model an image as a hypergraph that\nutilizes a set of hyperedges to capture the contextual properties of image\npixels or regions. As a result, the problem of salient object detection becomes\none of finding salient vertices and hyperedges in the hypergraph. The main\nadvantage of hypergraph modeling is that it takes into account each pixel's (or\nregion's) affinity with its neighborhood as well as its separation from image\nbackground. Furthermore, we propose an alternative approach based on\ncenter-versus-surround contextual contrast analysis, which performs salient\nobject detection by optimizing a cost-sensitive support vector machine (SVM)\nobjective function. Experimental results on four challenging datasets\ndemonstrate the effectiveness of the proposed approaches against the\nstate-of-the-art approaches to salient object detection.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 00:38:59 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Li", "Xi", ""], ["Li", "Yao", ""], ["Shen", "Chunhua", ""], ["Dick", "Anthony", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1310.5781", "submitter": "David Budden", "authors": "Madison Flannery, Shannon Fenn and David Budden", "title": "RANSAC: Identification of Higher-Order Geometric Features and\n  Applications in Humanoid Robot Soccer", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability for an autonomous agent to self-localise is directly proportional\nto the accuracy and precision with which it can perceive salient features\nwithin its local environment. The identification of such features by\nrecognising geometric profile allows robustness against lighting variations,\nwhich is necessary in most industrial robotics applications. This paper details\na framework by which the random sample consensus (RANSAC) algorithm, often\napplied to parameter fitting in linear models, can be extended to identify\nhigher-order geometric features. Goalpost identification within humanoid robot\nsoccer is investigated as an application, with the developed system yielding an\norder-of-magnitude improvement in classification performance relative to a\ntraditional histogramming methodology.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 02:38:30 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Flannery", "Madison", ""], ["Fenn", "Shannon", ""], ["Budden", "David", ""]]}, {"id": "1310.5965", "submitter": "Roozbeh Rajabi", "authors": "Roozbeh Rajabi, Hassan Ghassemian", "title": "Fusion of Hyperspectral and Panchromatic Images using Spectral Uumixing\n  Results", "comments": "4 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral imaging, due to providing high spectral resolution images, is\none of the most important tools in the remote sensing field. Because of\ntechnological restrictions hyperspectral sensors has a limited spatial\nresolution. On the other hand panchromatic image has a better spatial\nresolution. Combining this information together can provide a better\nunderstanding of the target scene. Spectral unmixing of mixed pixels in\nhyperspectral images results in spectral signature and abundance fractions of\nendmembers but gives no information about their location in a mixed pixel. In\nthis paper we have used spectral unmixing results of hyperspectral images and\nsegmentation results of panchromatic image for data fusion. The proposed method\nhas been applied on simulated data using AVRIS Indian Pines datasets. Results\nshow that this method can effectively combine information in hyperspectral and\npanchromatic images.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 15:44:51 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Rajabi", "Roozbeh", ""], ["Ghassemian", "Hassan", ""]]}, {"id": "1310.5999", "submitter": "Nidhal El-Abbadi", "authors": "Nidhal Khdhair El Abbadi, Enas Hamood Al Saadi", "title": "Improvement of Automatic Hemorrhages Detection Methods Using Shapes\n  Recognition", "comments": "6-pages,3 figures", "journal-ref": "Journal of Computer Science 9 (9): 1205-1210, 2013", "doi": "10.3844/jcssp.2013.1205.1210", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic Retinopathy is a medical condition where the retina is damaged\nbecause fluid leaks from blood vessels into the retina. The presence of\nhemorrhages in the retina is the earliest symptom of diabetic retinopathy. The\nnumber and shape of hemorrhages is used to indicate the severity of the\ndisease. Early automated hemorrhage detection can help reduce the incidence of\nblindness. This paper introduced new method depending on the hemorrhage shape\nto detect the dot hemorrhage (DH), its number, and size at early stage, this\ncan be achieved by reducing the retinal image details. Detection and recognize\nthe DH by following three sequential steps, removing the fovea, removing the\nvasculature and recognize DH by determining the circularity for all the objects\nin the image, finally determine the shape factor which is related to DH\nrecognition, this stage strengthens the recognition process. The proposed\nmethod recognizes and separates all the DH.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 17:58:52 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Abbadi", "Nidhal Khdhair El", ""], ["Saadi", "Enas Hamood Al", ""]]}, {"id": "1310.6063", "submitter": "Sayantan Sarkar", "authors": "Sayantan Sarkar", "title": "Word Spotting in Cursive Handwritten Documents using Modified Character\n  Shape Codes", "comments": "10 Pages Advances In Computing And Information Technology:\n  Proceedings Of The Second International Conference On Advances In Computing\n  And Information Technology, July, 2012. ISBN13: 9783642315992", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  There is a large collection of Handwritten English paper documents of\nHistorical and Scientific importance. But paper documents are not recognized\ndirectly by computer. Hence the closest way of indexing these documents is by\nstoring their document digital image. Hence a large database of document images\ncan replace the paper documents. But the document and data corresponding to\neach image cannot be directly recognized by the computer.\n  This paper applies the technique of word spotting using Modified Character\nShape Code to Handwritten English document images for quick and efficient query\nsearch of words on a database of document images. It is different from other\nWord Spotting techniques as it implements two level of selection for word\nsegments to match search query. First based on word size and then based on\ncharacter shape code of query. It makes the process faster and more efficient\nand reduces the need of multiple pre-processing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 21:39:25 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Sarkar", "Sayantan", ""]]}, {"id": "1310.6066", "submitter": "Sayantan Sarkar", "authors": "Sayantan Sarkar", "title": "Skin Segmentation based Elastic Bunch Graph Matching for efficient\n  multiple Face Recognition", "comments": "10 Pages Advances in Computer Science, Engineering Applications, May,\n  2012", "journal-ref": null, "doi": "10.1007/978-3-642-30157-5_4", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is aimed at developing and combining different algorithms for face\ndetection and face recognition to generate an efficient mechanism that can\ndetect and recognize the facial regions of input image. For the detection of\nface from complex region, skin segmentation isolates the face-like regions in a\ncomplex image and following operations of morphology and template matching\nrejects false matches to extract facial region. For the recognition of the\nface, the image database is now converted into a database of facial segments.\nHence, implementing the technique of Elastic Bunch Graph matching (EBGM) after\nskin segmentation generates Face Bunch Graphs that acutely represents the\nfeatures of an individual face enhances the quality of the training set. This\nincreases the matching probability significantly.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 21:45:26 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Sarkar", "Sayantan", ""]]}, {"id": "1310.6092", "submitter": "Jan Egger", "authors": "Miriam H. A. Bauer, Sebastiano Barbieri, Jan Klein, Jan Egger, Daniela\n  Kuhnt, Bernd Freisleben, Horst K. Hahn, Christopher Nimsky", "title": "A Ray-based Approach for Boundary Estimation of Fiber Bundles Derived\n  from Diffusion Tensor Imaging", "comments": "5 pages, 2 figures, 7 references", "journal-ref": "Int J CARS, Vol. 5, Suppl. 1, pp. 47-48, Springer Press, June 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion Tensor Imaging (DTI) is a non-invasive imaging technique that\nallows estimation of the location of white matter tracts in-vivo, based on the\nmeasurement of water diffusion properties. For each voxel, a second-order\ntensor can be calculated by using diffusion-weighted sequences (DWI) that are\nsensitive to the random motion of water molecules. Given at least 6\ndiffusion-weighted images with different gradients and one unweighted image,\nthe coefficients of the symmetric diffusion tensor matrix can be calculated.\nDeriving the eigensystem of the tensor, the eigenvectors and eigenvalues can be\ncalculated to describe the three main directions of diffusion and its\nmagnitude. Using DTI data, fiber bundles can be determined, to gain information\nabout eloquent brain structures. Especially in neurosurgery, information about\nlocation and dimension of eloquent structures like the corticospinal tract or\nthe visual pathways is of major interest. Therefore, the fiber bundle boundary\nhas to be determined. In this paper, a novel ray-based approach for boundary\nestimation of tubular structures is presented.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 02:05:02 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Bauer", "Miriam H. A.", ""], ["Barbieri", "Sebastiano", ""], ["Klein", "Jan", ""], ["Egger", "Jan", ""], ["Kuhnt", "Daniela", ""], ["Freisleben", "Bernd", ""], ["Hahn", "Horst K.", ""], ["Nimsky", "Christopher", ""]]}, {"id": "1310.6376", "submitter": "Abhishek Dutta", "authors": "Abhishek Dutta, Raymond Veldhuis, Luuk Spreeuwers", "title": "Can Facial Uniqueness be Inferred from Impostor Scores?", "comments": "A 6 page paper presented in the Biometric Technologies in Forensic\n  Science (BTFS) 2013 Conference, Oct 14-15 2013, Nijmegen, Netherlands. Full\n  proceeding is available at http://www.ru.nl/clst/btfs/btfs-2013/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Biometrics, facial uniqueness is commonly inferred from impostor\nsimilarity scores. In this paper, we show that such uniqueness measures are\nhighly unstable in the presence of image quality variations like pose, noise\nand blur. We also experimentally demonstrate the instability of a recently\nintroduced impostor-based uniqueness measure of [Klare and Jain 2013] when\nsubject to poor quality facial images.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 20:10:36 GMT"}], "update_date": "2013-10-25", "authors_parsed": [["Dutta", "Abhishek", ""], ["Veldhuis", "Raymond", ""], ["Spreeuwers", "Luuk", ""]]}, {"id": "1310.6654", "submitter": "Sahil  Sikka", "authors": "Sahil Sikka and Karan Sikka and M.K. Bhuyan and Yuji Iwahori", "title": "Pseudo vs. True Defect Classification in Printed Circuits Boards using\n  Wavelet Features", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Printed Circuit Boards (PCB) have become the backbone of a\nlarge number of consumer electronic devices leading to a surge in their\nproduction. This has made it imperative to employ automatic inspection systems\nto identify manufacturing defects in PCB before they are installed in the\nrespective systems. An important task in this regard is the classification of\ndefects as either true or pseudo defects, which decides if the PCB is to be\nre-manufactured or not. This work proposes a novel approach to detect most\ncommon defects in the PCBs. The problem has been approached by employing highly\ndiscriminative features based on multi-scale wavelet transform, which are\nfurther boosted by using a kernalized version of the support vector machines\n(SVM). A real world printed circuit board dataset has been used for\nquantitative analysis. Experimental results demonstrated the efficacy of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 16:11:28 GMT"}], "update_date": "2013-10-25", "authors_parsed": [["Sikka", "Sahil", ""], ["Sikka", "Karan", ""], ["Bhuyan", "M. K.", ""], ["Iwahori", "Yuji", ""]]}, {"id": "1310.6719", "submitter": "Sujeet Patole", "authors": "Sujeet Patole and Murat Torlak", "title": "Two Dimensional Array Imaging with Beam Steered Data", "comments": null, "journal-ref": "IEEE Transactions on Image Processing Dec. 2013 (Volume:22, Issue:\n  12, Page(s):5181 - 5189 )", "doi": "10.1109/TIP.2013.2282115", "report-no": "ISSN: 1057-7149", "categories": "cs.CV cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses different approaches used for millimeter wave imaging of\ntwo-dimensional objects. Imaging of a two dimensional object requires reflected\nwave data to be collected across two distinct dimensions. In this paper, we\npropose a reconstruction method that uses narrowband waveforms along with two\ndimensional beam steering. The beam is steered in azimuthal and elevation\ndirection, which forms the two distinct dimensions required for the\nreconstruction. The Reconstruction technique uses inverse Fourier transform\nalong with amplitude and phase correction factors. In addition, this\nreconstruction technique does not require interpolation of the data in either\nwavenumber or spatial domain. Use of the two dimensional beam steering offers\nbetter performance in the presence of noise compared with the existing methods,\nsuch as switched array imaging system. Effects of RF impairments such as\nquantization of the phase of beam steering weights and timing jitter which add\nto phase noise, are analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 19:33:50 GMT"}, {"version": "v2", "created": "Thu, 17 Apr 2014 23:01:54 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Patole", "Sujeet", ""], ["Torlak", "Murat", ""]]}, {"id": "1310.6736", "submitter": "Amit Kale", "authors": "Rahul Thota, Sharan Vaswani, Amit Kale and Nagavijayalakshmi\n  Vydyanathan", "title": "Fast 3D Salient Region Detection in Medical Images using GPUs", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated detection of visually salient regions is an active area of research\nin computer vision. Salient regions can serve as inputs for object detectors as\nwell as inputs for region based registration algorithms. In this paper we\nconsider the problem of speeding up computationally intensive bottom-up salient\nregion detection in 3D medical volumes.The method uses the Kadir Brady\nformulation of saliency. We show that in the vicinity of a salient region,\nentropy is a monotonically increasing function of the degree of overlap of a\ncandidate window with the salient region. This allows us to initialize a sparse\nseed-point grid as the set of tentative salient region centers and iteratively\nconverge to the local entropy maxima, thereby reducing the computation\ncomplexity compared to the Kadir Brady approach of performing this computation\nat every point in the image. We propose two different approaches for achieving\nthis. The first approach involves evaluating entropy in the four quadrants\naround the seed point and iteratively moving in the direction that increases\nentropy. The second approach we propose makes use of mean shift tracking\nframework to affect entropy maximizing moves. Specifically, we propose the use\nof uniform pmf as the target distribution to seek high entropy regions. We\ndemonstrate the use of our algorithm on medical volumes for left ventricle\ndetection in PET images and tumor localization in brain MR sequences.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 01:50:24 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Thota", "Rahul", ""], ["Vaswani", "Sharan", ""], ["Kale", "Amit", ""], ["Vydyanathan", "Nagavijayalakshmi", ""]]}, {"id": "1310.6808", "submitter": "Dr. Mohammad Shahidul Islam", "authors": "Mohammad shahidul Islam", "title": "Gender Classification Using Gradient Direction Pattern", "comments": "3 pages, 5 figures, 3 tables, SCI journal", "journal-ref": "Sci.Int(Lahore),25(4),797-799,2013 ISSN 1013-5316; CODEN: SINTE 8", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel methodology for gender classification is presented in this paper. It\nextracts feature from local region of a face using gray color intensity\ndifference. The facial area is divided into sub-regions and GDP histogram\nextracted from those regions are concatenated into a single vector to represent\nthe face. The classification accuracy obtained by using support vector machine\nhas outperformed all traditional feature descriptors for gender classification.\nIt is evaluated on the images collected from FERET database and obtained very\nhigh accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2013 02:37:44 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Islam", "Mohammad shahidul", ""]]}, {"id": "1310.7114", "submitter": "Christian Bauckhage", "authors": "Christian Bauckhage and Kristian Kersting", "title": "Efficient Information Theoretic Clustering on Discrete Lattices", "comments": "This paper has been presented at the workshop LWA 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering data that reside on discrete, low\ndimensional lattices. Canonical examples for this setting are found in image\nsegmentation and key point extraction. Our solution is based on a recent\napproach to information theoretic clustering where clusters result from an\niterative procedure that minimizes a divergence measure. We replace costly\nprocessing steps in the original algorithm by means of convolutions. These\nallow for highly efficient implementations and thus significantly reduce\nruntime. This paper therefore bridges a gap between machine learning and signal\nprocessing.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2013 14:21:06 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Bauckhage", "Christian", ""], ["Kersting", "Kristian", ""]]}, {"id": "1310.7170", "submitter": "Andrew Gleibman Ph.D.", "authors": "Andrew Gleibman", "title": "Object Recognition System Design in Computer Vision: a Universal\n  Approach", "comments": "18 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first contribution of this paper is architecture of a multipurpose\nsystem, which delegates a range of object detection tasks to a classifier,\napplied in special grid positions of the tested image. The second contribution\nis Gray Level-Radius Co-occurrence Matrix, which describes local image texture\nand topology and, unlike common second order statistics methods, is robust to\nimage resolution. The third contribution is a parametrically controlled\nautomatic synthesis of unlimited number of numerical features for\nclassification. The fourth contribution is a method of optimizing parameters C\nand gamma in LibSVM-based classifier, which is 20-100 times faster than the\ncommonly applied method. The work is essentially experimental, with\ndemonstration of various methods for definition of objects of interest in\nimages and video sequences.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 07:56:24 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2013 18:45:50 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Gleibman", "Andrew", ""]]}, {"id": "1310.7217", "submitter": "Jian Fang JIAN FANG", "authors": "Jian Fang, Zongben Xu, Bingchen Zhang, Wen Hong, Yirong Wu", "title": "Compressed Sensing SAR Imaging with Multilook Processing", "comments": "Will be submitted to GRS letter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilook processing is a widely used speckle reduction approach in synthetic\naperture radar (SAR) imaging. Conventionally, it is achieved by incoherently\nsumming of some independent low-resolution images formulated from overlapping\nsubbands of the SAR signal. However, in the context of compressive sensing (CS)\nSAR imaging, where the samples are collected at sub-Nyquist rate, the data\nspectrum is highly aliased that hinders the direct application of the existing\nmultilook techniques. In this letter, we propose a new CS-SAR imaging method\nthat can realize multilook processing simultaneously during image\nreconstruction. The main idea is to replace the SAR observation matrix by the\ninverse of multilook procedures, which is then combined with random sampling\nmatrix to yield a multilook CS-SAR observation model. Then a joint sparse\nregularization model, considering pixel dependency of subimages, is derived to\nform multilook images. The suggested SAR imaging method can not only\nreconstruct sparse scene efficiently below Nyquist rate, but is also able to\nachieve a comparable reduction of speckles during reconstruction. Simulation\nresults are finally provided to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 17:24:38 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Fang", "Jian", ""], ["Xu", "Zongben", ""], ["Zhang", "Bingchen", ""], ["Hong", "Wen", ""], ["Wu", "Yirong", ""]]}, {"id": "1310.7440", "submitter": "Boulbaba Ben Ammar", "authors": "Boulbaba Ben Ammar", "title": "Neural perceptual model to global-local vision for recognition of the\n  logical structure of administrative documents", "comments": "17 pages, International Journal of Artificial Intelligence &\n  Applications (IJAIA), Vol. 4, No. 5, September 2013", "journal-ref": null, "doi": "10.5121/ijaia", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives the definition of Transparent Neural Network \"TNN\" for the\nsimulation of the globallocal vision and its application to the segmentation of\nadministrative document image. We have developed and have adapted a recognition\nmethod which models the contextual effects reported from studies in\nexperimental psychology. Then, we evaluated and tested the TNN and the\nmulti-layer perceptron \"MLP\", which showed its effectiveness in the field of\nthe recognition, in order to show that the TNN is clearer for the user and more\npowerful on the level of the recognition. Indeed, the TNN is the only system\nwhich makes it possible to recognize the document and its structure.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 08:29:32 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Ammar", "Boulbaba Ben", ""]]}, {"id": "1310.7441", "submitter": "Nicolas Gillis", "authors": "Nicolas Gillis, Da Kuang and Haesun Park", "title": "Hierarchical Clustering of Hyperspectral Images using Rank-Two\n  Nonnegative Matrix Factorization", "comments": "29 pages, 19 figures. New experiment on Terrain data set. Accepted in\n  IEEE Trans. Geosci. Remote Sens", "journal-ref": "IEEE Trans. on Geoscience and Remote Sensing 53 (4), pp.\n  2066-2078, 2015", "doi": "10.1109/TGRS.2014.2352857", "report-no": null, "categories": "cs.CV cs.IR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we design a hierarchical clustering algorithm for\nhigh-resolution hyperspectral images. At the core of the algorithm, a new\nrank-two nonnegative matrix factorizations (NMF) algorithm is used to split the\nclusters, which is motivated by convex geometry concepts. The method starts\nwith a single cluster containing all pixels, and, at each step, (i) selects a\ncluster in such a way that the error at the next step is minimized, and (ii)\nsplits the selected cluster into two disjoint clusters using rank-two NMF in\nsuch a way that the clusters are well balanced and stable. The proposed method\ncan also be used as an endmember extraction algorithm in the presence of pure\npixels. The effectiveness of this approach is illustrated on several synthetic\nand real-world hyperspectral images, and shown to outperform standard\nclustering techniques such as k-means, spherical k-means and standard NMF.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2013 09:54:59 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2013 08:53:00 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2014 10:04:55 GMT"}, {"version": "v4", "created": "Tue, 19 Aug 2014 12:49:54 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Gillis", "Nicolas", ""], ["Kuang", "Da", ""], ["Park", "Haesun", ""]]}, {"id": "1310.7443", "submitter": "Surya Prasath", "authors": "V. B. S. Prasath, Juan C. Moreno", "title": "On Convergent Finite Difference Schemes for Variational - PDE Based\n  Image Processing", "comments": "23 pages, 12 figures, 2 tables", "journal-ref": "Computational and Applied Mathematics, 2017", "doi": "10.1007/s40314-016-0414-9", "report-no": null, "categories": "cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an adaptive anisotropic Huber functional based image restoration\nscheme. By using a combination of L2-L1 regularization functions, an adaptive\nHuber functional based energy minimization model provides denoising with edge\npreservation in noisy digital images. We study a convergent finite difference\nscheme based on continuous piecewise linear functions and use a variable\nsplitting scheme, namely the Split Bregman, to obtain the discrete minimizer.\nExperimental results are given in image denoising and comparison with additive\noperator splitting, dual fixed point, and projected gradient schemes illustrate\nthat the best convergence rates are obtained for our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 23:07:39 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Prasath", "V. B. S.", ""], ["Moreno", "Juan C.", ""]]}, {"id": "1310.7447", "submitter": "Rajeev Nongpiur", "authors": "R. C. Nongpiur", "title": "Impulse Noise Removal In Speech Using Wavelets", "comments": "Icassp 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for removing impulse noise from speech in the wavelet transform\ndomain is proposed. The method utilizes the multiresolution property of the\nwavelet transform, which provides finer time resolution at the higher\nfrequencies than the short-time Fourier transform (STFT), to effectively\nidentify and remove impulse noise. It uses two features of speech to\ndiscriminate speech from impulse noise: one is the slow time-varying nature of\nspeech and the other is the Lipschitz regularity of the speech components. On\nthe basis of these features, an algorithm has been developed to identify and\nsuppress wavelet coefficients that correspond to impulse noise. Experiment\nresults show that the new method is able to significantly reduce impulse noise\nwithout degrading the quality of the speech signal or introducing any audible\nartifacts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2013 21:52:32 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Nongpiur", "R. C.", ""]]}, {"id": "1310.7448", "submitter": "YuLi Sun", "authors": "Yuli Sun, Jinxu Tao, Conggui Liu", "title": "An iterative algorithm for computed tomography image reconstruction from\n  limited-angle projections", "comments": "14 pages, 1 figure, 1 table", "journal-ref": null, "doi": "10.1007/s12204-015-1608-9", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In application of tomography imaging, limited-angle problem is a quite\npractical and important issue. In this paper, an iterative\nreprojection-reconstruction (IRR) algorithm using a modified Papoulis-Gerchberg\n(PG) iterative scheme is developed for reconstruction from limited-angle\nprojections which contain noise. The proposed algorithm has two iterative\nupdate processes, one is the extrapolation of unknown data, and the other is\nthe modification of the known noisy observation data. And the algorithm\nintroduces scaling factors to control the two processes, respectively. The\nconvergence of the algorithm is guaranteed, and the method of choosing the\nscaling factors is given with energy constraints. The simulation result\ndemonstrates our conclusions and indicates that the algorithm proposed in this\npaper can obviously improve the reconstruction quality.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 07:52:16 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Sun", "Yuli", ""], ["Tao", "Jinxu", ""], ["Liu", "Conggui", ""]]}, {"id": "1310.7813", "submitter": "Giulio Coluccia", "authors": "Giulio Coluccia, Diego Valsesia, Enrico Magli", "title": "Smoothness-Constrained Image Recovery from Block-Based Random\n  Projections", "comments": null, "journal-ref": "Proceedings of the 15th International Workshop on Multimedia\n  Signal Processing (MMSP), Pula (Sardinia), Italy, September 30 - October 2,\n  2013, pp. 129-134", "doi": "10.1109/MMSP.2013.6659276", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of visual quality of images\nreconstructed from block-wise random projections. Independent reconstruction of\nthe blocks can severely affect visual quality, by displaying artifacts along\nblock borders. We propose a method to enforce smoothness across block borders\nby modifying the sensing and reconstruction process so as to employ partially\noverlapping blocks. The proposed algorithm accomplishes this by computing a\nfast preview from the blocks, whose purpose is twofold. On one hand, it allows\nto enforce a set of constraints to drive the reconstruction algorithm towards a\nsmooth solution, imposing the similarity of block borders. On the other hand,\nthe preview is used as a predictor of the entire block, allowing to recover the\nprediction error, only. The quality improvement over the result of independent\nreconstruction can be easily assessed both visually and in terms of PSNR and\nSSIM index.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 08:51:10 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Coluccia", "Giulio", ""], ["Valsesia", "Diego", ""], ["Magli", "Enrico", ""]]}]