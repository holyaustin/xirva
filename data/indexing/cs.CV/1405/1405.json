[{"id": "1405.0006", "submitter": "William Patera", "authors": "Moritz Kassner, William Patera, Andreas Bulling", "title": "Pupil: An Open Source Platform for Pervasive Eye Tracking and Mobile\n  Gaze-based Interaction", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Commercial head-mounted eye trackers provide useful features to customers in\nindustry and research but are expensive and rely on closed source hardware and\nsoftware. This limits the application areas and use of mobile eye tracking to\nexpert users and inhibits user-driven development, customisation, and\nextension. In this paper we present Pupil -- an accessible, affordable, and\nextensible open source platform for mobile eye tracking and gaze-based\ninteraction. Pupil comprises 1) a light-weight headset with high-resolution\ncameras, 2) an open source software framework for mobile eye tracking, as well\nas 3) a graphical user interface (GUI) to playback and visualize video and gaze\ndata. Pupil features high-resolution scene and eye cameras for monocular and\nbinocular gaze estimation. The software and GUI are platform-independent and\ninclude state-of-the-art algorithms for real-time pupil detection and tracking,\ncalibration, and accurate gaze estimation. Results of a performance evaluation\nshow that Pupil can provide an average gaze estimation accuracy of 0.6 degree\nof visual angle (0.08 degree precision) with a latency of the processing\npipeline of only 0.045 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 16:21:56 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Kassner", "Moritz", ""], ["Patera", "William", ""], ["Bulling", "Andreas", ""]]}, {"id": "1405.0085", "submitter": "Mahmoud Khademi", "authors": "Mahmoud Khademi and Louis-Philippe Morency", "title": "Relative Facial Action Unit Detection", "comments": "Accepted at IEEE Winter Conference on Applications of Computer\n  Vision, Steamboat Springs Colorado, USA, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a subject-independent facial action unit (AU) detection\nmethod by introducing the concept of relative AU detection, for scenarios where\nthe neutral face is not provided. We propose a new classification objective\nfunction which analyzes the temporal neighborhood of the current frame to\ndecide if the expression recently increased, decreased or showed no change.\nThis approach is a significant change from the conventional absolute method\nwhich decides about AU classification using the current frame, without an\nexplicit comparison with its neighboring frames. Our proposed method improves\nrobustness to individual differences such as face scale and shape, age-related\nwrinkles, and transitions among expressions (e.g., lower intensity of\nexpressions). Our experiments on three publicly available datasets (Extended\nCohn-Kanade (CK+), Bosphorus, and DISFA databases) show significant improvement\nof our approach over conventional absolute techniques. Keywords: facial action\ncoding system (FACS); relative facial action unit detection; temporal\ninformation;\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 03:53:36 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Khademi", "Mahmoud", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1405.0174", "submitter": "Karim Mahmoud", "authors": "Karim M. Mohamed, Mohamed A. Ismail, Nagia M. Ghanem", "title": "VSCAN: An Enhanced Video Summarization using Density-based Spatial\n  Clustering", "comments": "arXiv admin note: substantial text overlap with arXiv:1401.3590 by\n  other authors without attribution", "journal-ref": null, "doi": "10.1007/978-3-642-41181-6_74", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present VSCAN, a novel approach for generating static video\nsummaries. This approach is based on a modified DBSCAN clustering algorithm to\nsummarize the video content utilizing both color and texture features of the\nvideo frames. The paper also introduces an enhanced evaluation method that\ndepends on color and texture features. Video Summaries generated by VSCAN are\ncompared with summaries generated by other approaches found in the literature\nand those created by users. Experimental results indicate that the video\nsummaries generated by VSCAN have a higher quality than those generated by\nother approaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 14:36:35 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Mohamed", "Karim M.", ""], ["Ismail", "Mohamed A.", ""], ["Ghanem", "Nagia M.", ""]]}, {"id": "1405.0234", "submitter": "Mohamed Elgharib", "authors": "Greg Castanon, Mohamed Elgharib, Venkatesh Saligrama, Pierre-Marc\n  Jodoin", "title": "Retrieval in Long Surveillance Videos using User Described Motion and\n  Object Attributes", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a content-based retrieval method for long surveillance videos both\nfor wide-area (Airborne) as well as near-field imagery (CCTV). Our goal is to\nretrieve video segments, with a focus on detecting objects moving on routes,\nthat match user-defined events of interest. The sheer size and remote locations\nwhere surveillance videos are acquired, necessitates highly compressed\nrepresentations that are also meaningful for supporting user-defined queries.\nTo address these challenges we archive long-surveillance video through\nlightweight processing based on low-level local spatio-temporal extraction of\nmotion and object features. These are then hashed into an inverted index using\nlocality-sensitive hashing (LSH). This local approach allows for query\nflexibility as well as leads to significant gains in compression. Our second\ntask is to extract partial matches to the user-created query and assembles them\ninto full matches using Dynamic Programming (DP). DP exploits causality to\nassemble the indexed low level features into a video segment which matches the\nquery route. We examine CCTV and Airborne footage, whose low contrast makes\nmotion extraction more difficult. We generate robust motion estimates for\nAirborne data using a tracklets generation algorithm while we use Horn and\nSchunck approach to generate motion estimates for CCTV. Our approach handles\nlong routes, low contrasts and occlusion. We derive bounds on the rate of false\npositives and demonstrate the effectiveness of the approach for counting,\nmotion pattern recognition and abandoned object applications.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 17:40:51 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Castanon", "Greg", ""], ["Elgharib", "Mohamed", ""], ["Saligrama", "Venkatesh", ""], ["Jodoin", "Pierre-Marc", ""]]}, {"id": "1405.0312", "submitter": "Piotr Doll\\'ar", "authors": "Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross\n  Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, Piotr\n  Doll\\'ar", "title": "Microsoft COCO: Common Objects in Context", "comments": "1) updated annotation pipeline description and figures; 2) added new\n  section describing datasets splits; 3) updated author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new dataset with the goal of advancing the state-of-the-art in\nobject recognition by placing the question of object recognition in the context\nof the broader question of scene understanding. This is achieved by gathering\nimages of complex everyday scenes containing common objects in their natural\ncontext. Objects are labeled using per-instance segmentations to aid in precise\nobject localization. Our dataset contains photos of 91 objects types that would\nbe easily recognizable by a 4 year old. With a total of 2.5 million labeled\ninstances in 328k images, the creation of our dataset drew upon extensive crowd\nworker involvement via novel user interfaces for category detection, instance\nspotting and instance segmentation. We present a detailed statistical analysis\nof the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide\nbaseline performance analysis for bounding box and segmentation detection\nresults using a Deformable Parts Model.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 21:43:32 GMT"}, {"version": "v2", "created": "Sat, 5 Jul 2014 18:39:56 GMT"}, {"version": "v3", "created": "Sat, 21 Feb 2015 01:48:49 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Lin", "Tsung-Yi", ""], ["Maire", "Michael", ""], ["Belongie", "Serge", ""], ["Bourdev", "Lubomir", ""], ["Girshick", "Ross", ""], ["Hays", "James", ""], ["Perona", "Pietro", ""], ["Ramanan", "Deva", ""], ["Zitnick", "C. Lawrence", ""], ["Doll\u00e1r", "Piotr", ""]]}, {"id": "1405.0545", "submitter": "Sergei Gepshtein", "authors": "Sergei Gepshtein and Ivan Tyukin", "title": "Optimal measurement of visual motion across spatial and temporal scales", "comments": "28 pages, 10 figures, 2 appendices; in press in Favorskaya MN and\n  Jain LC (Eds), Computer Vision in Advanced Control Systems using Conventional\n  and Intelligent Paradigms, Intelligent Systems Reference Library,\n  Springer-Verlag, Berlin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory systems use limited resources to mediate the perception of a great\nvariety of objects and events. Here a normative framework is presented for\nexploring how the problem of efficient allocation of resources can be solved in\nvisual perception. Starting with a basic property of every measurement,\ncaptured by Gabor's uncertainty relation about the location and frequency\ncontent of signals, prescriptions are developed for optimal allocation of\nsensors for reliable perception of visual motion. This study reveals that a\nlarge-scale characteristic of human vision (the spatiotemporal contrast\nsensitivity function) is similar to the optimal prescription, and it suggests\nthat some previously puzzling phenomena of visual sensitivity, adaptation, and\nperceptual organization have simple principled explanations.\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 01:37:45 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Gepshtein", "Sergei", ""], ["Tyukin", "Ivan", ""]]}, {"id": "1405.0601", "submitter": "Xuehan Xiong", "authors": "Xuehan Xiong and Fernando De la Torre", "title": "Supervised Descent Method for Solving Nonlinear Least Squares Problems\n  in Computer Vision", "comments": "15 pages. In submission to TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer vision problems (e.g., camera calibration, image alignment,\nstructure from motion) are solved with nonlinear optimization methods. It is\ngenerally accepted that second order descent methods are the most robust, fast,\nand reliable approaches for nonlinear optimization of a general smooth\nfunction. However, in the context of computer vision, second order descent\nmethods have two main drawbacks: (1) the function might not be analytically\ndifferentiable and numerical approximations are impractical, and (2) the\nHessian may be large and not positive definite. To address these issues, this\npaper proposes generic descent maps, which are average \"descent directions\" and\nrescaling factors learned in a supervised fashion. Using generic descent maps,\nwe derive a practical algorithm - Supervised Descent Method (SDM) - for\nminimizing Nonlinear Least Squares (NLS) problems. During training, SDM learns\na sequence of decent maps that minimize the NLS. In testing, SDM minimizes the\nNLS objective using the learned descent maps without computing the Jacobian or\nthe Hessian. We prove the conditions under which the SDM is guaranteed to\nconverge. We illustrate the effectiveness and accuracy of SDM in three computer\nvision problems: rigid image alignment, non-rigid image alignment, and 3D pose\nestimation. In particular, we show how SDM achieves state-of-the-art\nperformance in the problem of facial feature detection. The code has been made\navailable at www.humansensing.cs.cmu.edu/intraface.\n", "versions": [{"version": "v1", "created": "Sat, 3 May 2014 15:37:27 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Xiong", "Xuehan", ""], ["De la Torre", "Fernando", ""]]}, {"id": "1405.0632", "submitter": "Mario Mastriani", "authors": "Mario Mastriani", "title": "Rule of Three for Superresolution of Still Images with Applications to\n  Compression and Denoising", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new method for superresolution of still images (in the wavelet\ndomain) based on the reconstruction of missing details subbands pixels at a\ngiven ith level via Rule of Three (Ro3) between pixels of approximation subband\nof such level, and pixels of approximation and detail subbands of (i+1)th\nlevel. The histogramic profiles demonstrate that Ro3 is the appropriate\nmechanism to recover missing detail subband pixels in these cases. Besides,\nwith the elimination of the details subbands pixels (in an eventual compression\nscheme), we obtain a bigger compression rate. Experimental results demonstrate\nthat our approach compares favorably to more typical methods of denoising and\ncompression in wavelet domain. Our method does not compress, but facilitates\nthe action of the real compressor, in our case, Joint Photographic Experts\nGroup (JPEG) and JPEg2000, that is, Ro3 acts as a catalyst compression\n", "versions": [{"version": "v1", "created": "Sun, 4 May 2014 00:02:45 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Mastriani", "Mario", ""]]}, {"id": "1405.0892", "submitter": "John Stuart Haberl Baxter", "authors": "John S.H. Baxter, Martin Rajchl, Jing Yuan, and Terry M. Peters", "title": "A Continuous Max-Flow Approach to Multi-Labeling Problems under\n  Arbitrary Region Regularization", "comments": "10 pages, 2 figures, 3 algorithms - v2: Fixed typos / grammatical\n  errors and mathematical errors in the primal/dual formulation. Extended\n  methods for weighted DAGs rather than DAGs with edge multiplicity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incorporation of region regularization into max-flow segmentation has\ntraditionally focused on ordering and part-whole relationships. A side effect\nof the development of such models is that it constrained regularization only to\nthose cases, rather than allowing for arbitrary region regularization. Directed\nAcyclic Graphical Max-Flow (DAGMF) segmentation overcomes these limitations by\nallowing for the algorithm designer to specify an arbitrary directed acyclic\ngraph to structure a max-flow segmentation. This allows for individual 'parts'\nto be a member of multiple distinct 'wholes.'\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 13:19:00 GMT"}, {"version": "v2", "created": "Thu, 5 Jun 2014 21:09:48 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Baxter", "John S. H.", ""], ["Rajchl", "Martin", ""], ["Yuan", "Jing", ""], ["Peters", "Terry M.", ""]]}, {"id": "1405.0921", "submitter": "Chandranath  Adak", "authors": "Chandranath Adak", "title": "Gabor Filter and Rough Clustering Based Edge Detection", "comments": "Proc. IEEE Conf. #30853, International Conference on Human Computer\n  Interactions (ICHCI'13), Chennai, India, 23-24 Aug., 2013", "journal-ref": null, "doi": "10.1109/ICHCI-IEEE.2013.6887768", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an efficient edge detection method based on Gabor\nfilter and rough clustering. The input image is smoothed by Gabor function, and\nthe concept of rough clustering is used to focus on edge detection with soft\ncomputational approach. Hysteresis thresholding is used to get the actual\noutput, i.e. edges of the input image. To show the effectiveness, the proposed\ntechnique is compared with some other edge detection methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 06:30:19 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Adak", "Chandranath", ""]]}, {"id": "1405.1005", "submitter": "Mohammad Rastegari", "authors": "Mohammad Rastegari, Shobeir Fakhraei, Jonghyun Choi, David Jacobs,\n  Larry S. Davis", "title": "Comparing apples to apples in the evaluation of binary coding methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss methodological issues related to the evaluation of unsupervised\nbinary code construction methods for nearest neighbor search. These issues have\nbeen widely ignored in literature. These coding methods attempt to preserve\neither Euclidean distance or angular (cosine) distance in the binary embedding\nspace. We explain why when comparing a method whose goal is preserving cosine\nsimilarity to one designed for preserving Euclidean distance, the original\nfeatures should be normalized by mapping them to the unit hypersphere before\nlearning the binary mapping functions. To compare a method whose goal is to\npreserves Euclidean distance to one that preserves cosine similarity, the\noriginal feature data must be mapped to a higher dimension by including a bias\nterm in binary mapping functions. These conditions ensure the fair comparison\nbetween different binary code methods for the task of nearest neighbor search.\nOur experiments show under these conditions the very simple methods (e.g. LSH\nand ITQ) often outperform recent state-of-the-art methods (e.g. MDSH and\nOK-means).\n", "versions": [{"version": "v1", "created": "Mon, 5 May 2014 19:26:58 GMT"}, {"version": "v2", "created": "Sat, 27 Sep 2014 18:35:35 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Rastegari", "Mohammad", ""], ["Fakhraei", "Shobeir", ""], ["Choi", "Jonghyun", ""], ["Jacobs", "David", ""], ["Davis", "Larry S.", ""]]}, {"id": "1405.1020", "submitter": "Siddhartha Mukherjee", "authors": "Siddhartha Mukherjee", "title": "Study on performance improvement of oil paint image filter algorithm\n  using parallel pattern library", "comments": "12 pages, 4 figures, 4 code snippets, 4 tables, 2 graphs, 2 images of\n  experimental result, Conference: CCSEA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a detailed study on the performance of oil paint image\nfilter algorithm with various parameters applied on an image of RGB model. Oil\nPaint image processing, being very performance hungry, current research tries\nto find improvement using parallel pattern library. With increasing\nkernel-size, the processing time of oil paint image filter algorithm increases\nexponentially.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 07:32:37 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Mukherjee", "Siddhartha", ""]]}, {"id": "1405.1207", "submitter": "Jian Yang", "authors": "Jian Yang, Jianjun Qian, Lei Luo, Fanlong Zhang, Yicheng Gao", "title": "Nuclear Norm based Matrix Regression with Applications to Face\n  Recognition with Occlusion and Illumination Changes", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently regression analysis becomes a popular tool for face recognition. The\nexisting regression methods all use the one-dimensional pixel-based error\nmodel, which characterizes the representation error pixel by pixel individually\nand thus neglects the whole structure of the error image. We observe that\nocclusion and illumination changes generally lead to a low-rank error image. To\nmake use of this low-rank structural information, this paper presents a\ntwo-dimensional image matrix based error model, i.e. matrix regression, for\nface representation and classification. Our model uses the minimal nuclear norm\nof representation error image as a criterion, and the alternating direction\nmethod of multipliers method to calculate the regression coefficients. Compared\nwith the current regression methods, the proposed Nuclear Norm based Matrix\nRegression (NMR) model is more robust for alleviating the effect of\nillumination, and more intuitive and powerful for removing the structural noise\ncaused by occlusion. We experiment using four popular face image databases, the\nExtended Yale B database, the AR database, the Multi-PIE and the FRGC database.\nExperimental results demonstrate the performance advantage of NMR over the\nstate-of-the-art regression based face recognition methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 09:46:28 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Yang", "Jian", ""], ["Qian", "Jianjun", ""], ["Luo", "Lei", ""], ["Zhang", "Fanlong", ""], ["Gao", "Yicheng", ""]]}, {"id": "1405.1213", "submitter": "Oscar Danielsson", "authors": "Oscar Danielsson and Omid Aghazadeh", "title": "Human Pose Estimation from RGB Input Using Synthetic Training Data", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating the pose of humans using RGB image\ninput. More specifically, we are using a random forest classifier to classify\npixels into joint-based body part categories, much similar to the famous Kinect\npose estimator [11], [12]. However, we are using pure RGB input, i.e. no depth.\nSince the random forest requires a large number of training examples, we are\nusing computer graphics generated, synthetic training data. In addition, we\nassume that we have access to a large number of real images with bounding box\nlabels, extracted for example by a pedestrian detector or a tracking system. We\npropose a new objective function for random forest training that uses the\nweakly labeled data from the target domain to encourage the learner to select\nfeatures that generalize from the synthetic source domain to the real target\ndomain. We demonstrate on a publicly available dataset [6] that the proposed\nobjective function yields a classifier that significantly outperforms a\nbaseline classifier trained using the standard entropy objective [10].\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 10:13:08 GMT"}, {"version": "v2", "created": "Tue, 27 May 2014 12:23:54 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Danielsson", "Oscar", ""], ["Aghazadeh", "Omid", ""]]}, {"id": "1405.1402", "submitter": "Jeremie Clement", "authors": "Thomas Bourgeat, Julien Bringer, Herve Chabanne, Robin Champenois,\n  Jeremie Clement, Houda Ferradi, Marc Heinrich, Paul Melotti, David Naccache,\n  Antoine Voizard", "title": "New Algorithmic Approaches to Point Constellation Recognition", "comments": "14 pages, short version submitted to SEC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Point constellation recognition is a common problem with many pattern\nmatching applications. Whilst useful in many contexts, this work is mainly\nmotivated by fingerprint matching. Fingerprints are traditionally modelled as\nconstellations of oriented points called minutiae. The fingerprint verifier's\ntask consists in comparing two point constellations. The compared\nconstellations may differ by rotation and translation or by much more involved\ntransforms such as distortion or occlusion. This paper presents three new\nconstellation matching algorithms. The first two methods generalize an\nalgorithm by Bringer and Despiegel. Our third proposal creates a very\ninteresting analogy between mechanical system simulation and the constellation\nrecognition problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 16:57:22 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Bourgeat", "Thomas", ""], ["Bringer", "Julien", ""], ["Chabanne", "Herve", ""], ["Champenois", "Robin", ""], ["Clement", "Jeremie", ""], ["Ferradi", "Houda", ""], ["Heinrich", "Marc", ""], ["Melotti", "Paul", ""], ["Naccache", "David", ""], ["Voizard", "Antoine", ""]]}, {"id": "1405.1403", "submitter": "Hyunsuk Ko", "authors": "Rui Song, Hyunsuk Ko and C.C. Jay Kuo", "title": "MCL-3D: a database for stereoscopic image quality assessment using\n  2D-image-plus-depth source", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new stereoscopic image quality assessment database rendered using the\n2D-image-plus-depth source, called MCL-3D, is described and the performance\nbenchmarking of several known 2D and 3D image quality metrics using the MCL-3D\ndatabase is presented in this work. Nine image-plus-depth sources are first\nselected, and a depth image-based rendering (DIBR) technique is used to render\nstereoscopic image pairs. Distortions applied to either the texture image or\nthe depth image before stereoscopic image rendering include: Gaussian blur,\nadditive white noise, down-sampling blur, JPEG and JPEG-2000 (JP2K) compression\nand transmission error. Furthermore, the distortion caused by imperfect\nrendering is also examined. The MCL-3D database contains 693 stereoscopic image\npairs, where one third of them are of resolution 1024x728 and two thirds are of\nresolution 1920x1080. The pair-wise comparison was adopted in the subjective\ntest for user friendliness, and the Mean Opinion Score (MOS) can be computed\naccordingly. Finally, we evaluate the performance of several 2D and 3D image\nquality metrics applied to MCL-3D. All texture images, depth images, rendered\nimage pairs in MCL-3D and their MOS values obtained in the subjective test are\navailable to the public (http://mcl.usc.edu/mcl-3d-database/) for future\nresearch and development.\n", "versions": [{"version": "v1", "created": "Sun, 23 Mar 2014 23:31:49 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Song", "Rui", ""], ["Ko", "Hyunsuk", ""], ["Kuo", "C. C. Jay", ""]]}, {"id": "1405.1678", "submitter": "Chinh Dang", "authors": "Chinh Dang, Abdolreza Moghadam, and Hayder Radha", "title": "RPCA-KFE: Key Frame Extraction for Consumer Video based Robust Principal\n  Component Analysis", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key frame extraction algorithms consider the problem of selecting a subset of\nthe most informative frames from a video to summarize its content.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 17:51:52 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 13:57:11 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2015 12:38:13 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Dang", "Chinh", ""], ["Moghadam", "Abdolreza", ""], ["Radha", "Hayder", ""]]}, {"id": "1405.1681", "submitter": "Chinh Dang", "authors": "Chinh Dang, Hayder Radha", "title": "Representative Selection for Big Data via Sparse Graph and Geodesic\n  Grassmann Manifold Distance", "comments": "This paper has been withdrawn by the author due to lacking details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of identifying a very small subset of data\npoints that belong to a significantly larger massive dataset (i.e., Big Data).\nThe small number of selected data points must adequately represent and\nfaithfully characterize the massive Big Data. Such identification process is\nknown as representative selection [19]. We propose a novel representative\nselection framework by generating an l1 norm sparse graph for a given Big-Data\ndataset. The Big Data is partitioned recursively into clusters using a spectral\nclustering algorithm on the generated sparse graph. We consider each cluster as\none point in a Grassmann manifold, and measure the geodesic distance among\nthese points. The distances are further analyzed using a min-max algorithm [1]\nto extract an optimal subset of clusters. Finally, by considering a sparse\nsubgraph of each selected cluster, we detect a representative using principal\ncomponent centrality [11]. We refer to the proposed representative selection\nframework as a Sparse Graph and Grassmann Manifold (SGGM) based approach. To\nvalidate the proposed SGGM framework, we apply it onto the problem of video\nsummarization where only few video frames, known as key frames, are selected\namong a much longer video sequence. A comparison of the results obtained by the\nproposed algorithm with the ground truth, which is agreed by multiple human\njudges, and with some state-of-the-art methods clearly indicates the viability\nof the SGGM framework.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 17:57:25 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2015 13:57:52 GMT"}], "update_date": "2015-03-12", "authors_parsed": [["Dang", "Chinh", ""], ["Radha", "Hayder", ""]]}, {"id": "1405.1717", "submitter": "Kutlu Emre  Yilmaz", "authors": "Kutlu Emre Yilmaz", "title": "Entropy Based Cartoon Texture Separation", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating an image into cartoon and texture components comes useful in image\nprocessing applications, such as image compression, image segmentation, image\ninpainting. Yves Meyer's influential cartoon texture decomposition model\ninvolves deriving an energy functional by choosing appropriate spaces and\nfunctionals. Minimizers of the derived energy functional are cartoon and\ntexture components of an image. In this study, cartoon part of an image is\nseparated, by reconstructing it from pixels of multi scale Total-Variation\nfiltered versions of the original image which is sought to be decomposed into\ncartoon and texture parts. An information theoretic pixel by pixel selection\ncriteria is employed to choose the contributing pixels and their scales.\n", "versions": [{"version": "v1", "created": "Wed, 7 May 2014 19:39:10 GMT"}], "update_date": "2014-05-08", "authors_parsed": [["Yilmaz", "Kutlu Emre", ""]]}, {"id": "1405.1815", "submitter": "Deepjoy Das", "authors": "Deepjoy Das and Dr. Sarat Saharia", "title": "Implementation And Performance Evaluation Of Background Subtraction\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsa.2014.4206", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study evaluates three background subtraction techniques. The techniques\nranges from very basic algorithm to state of the art published techniques\ncategorized based on speed, memory requirements and accuracy. Such a review can\neffectively guide the designer to select the most suitable method for a given\napplication in a principled way. The algorithms used in the study ranges from\nvarying levels of accuracy and computational complexity. Few of them can also\ndeal with real time challenges like rain, snow, hails, swaying branches,\nobjects overlapping, varying light intensity or slow moving objects.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 06:49:41 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Das", "Deepjoy", ""], ["Saharia", "Dr. Sarat", ""]]}, {"id": "1405.1965", "submitter": "Ayushi Sinha", "authors": "Ayushi Sinha (1), William Gray Roncal (1 and 2), Narayanan Kasthuri (3\n  and 4), Jeff W. Lichtman (3 and 4), Randal Burns (1), Michael Kazhdan (1)\n  ((1) Department of Computer Science, The Johns Hopkins University, Baltimore,\n  MD, (2) The Johns Hopkins University Applied Physics Laboratory, Laurel, MD,\n  (3) Department of Molecular and Cellular Biology, Harvard University,\n  Cambridge, MA, (4) Center for Brain Science, Harvard University, Cambridge,\n  MA)", "title": "Automatic Annotation of Axoplasmic Reticula in Pursuit of Connectomes\n  using High-Resolution Neural EM Data", "comments": "2 pages, 1 figure; The 3rd Annual Hopkins Imaging Conference, The\n  Johns Hopkins University, Baltimore, MD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately estimating the wiring diagram of a brain, known as a connectome,\nat an ultrastructure level is an open research problem. Specifically, precisely\ntracking neural processes is difficult, especially across many image slices.\nHere, we propose a novel method to automatically identify and annotate small\nsubcellular structures present in axons, known as axoplasmic reticula, through\na 3D volume of high-resolution neural electron microscopy data. Our method\nproduces high precision annotations, which can help improve automatic\nsegmentation by using our results as seeds for segmentation, and as cues to aid\nsegment merging.\n", "versions": [{"version": "v1", "created": "Wed, 16 Apr 2014 20:57:19 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Sinha", "Ayushi", "", "1 and 2"], ["Roncal", "William Gray", "", "1 and 2"], ["Kasthuri", "Narayanan", "", "3\n  and 4"], ["Lichtman", "Jeff W.", "", "3 and 4"], ["Burns", "Randal", ""], ["Kazhdan", "Michael", ""]]}, {"id": "1405.1966", "submitter": "Rajalakshmi  M", "authors": "M.Rajalakshmi and Dr. P.Subashini", "title": "Texture Based Image Segmentation of Chili Pepper X-Ray Images Using\n  Gabor Filter", "comments": "7 pages, 2 figures, 8 tables", "journal-ref": "IJASCSE, Volume 3, Issue 3, 2014, pg 44-51", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texture segmentation is the process of partitioning an image into regions\nwith different textures containing a similar group of pixels. Detecting the\ndiscontinuity of the filter's output and their statistical properties help in\nsegmenting and classifying a given image with different texture regions. In\nthis proposed paper, chili x-ray image texture segmentation is performed by\nusing Gabor filter. The texture segmented result obtained from Gabor filter fed\ninto three texture filters, namely Entropy, Standard Deviation and Range\nfilter. After performing texture analysis, features can be extracted by using\nStatistical methods. In this paper Gray Level Co-occurrence Matrices and First\norder statistics are used as feature extraction methods. Features extracted\nfrom statistical methods are given to Support Vector Machine (SVM) classifier.\nUsing this methodology, it is found that texture segmentation is followed by\nthe Gray Level Co-occurrence Matrix feature extraction method gives a higher\naccuracy rate of 84% when compared with First order feature extraction method.\n  Key Words: Texture segmentation, Texture filter, Gabor filter, Feature\nextraction methods, SVM classifier.\n", "versions": [{"version": "v1", "created": "Tue, 15 Apr 2014 16:52:38 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Rajalakshmi", "M.", ""], ["Subashini", "Dr. P.", ""]]}, {"id": "1405.1967", "submitter": "Prajakta Khairnar", "authors": "Prajakta P. Khairnar, C. A. Manjare", "title": "Image Resolution and Contrast Enhancement of Satellite Geographical\n  Images with Removal of Noise using Wavelet Transforms", "comments": "5 pages, 10 figures", "journal-ref": "International Journal of Engineering Trends and Technology\n  (IJETT),Volume 10, Number 12,Apr-2014 International Conference of Recent\n  Trends in Engineering and Technology (ICRTET-2014),paper code 223", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the technique for resolution and contrast enhancement of\nsatellite geographical images based on discrete wavelet transform (DWT),\nstationary wavelet transform (SWT) and singular value decomposition (SVD) has\nbeen proposed. In this, the noise is added in the input low resolution and low\ncontrast image. The median filter is used remove noise from the input image.\nThis low resolution, low contrast image without noise is decomposed into four\nsub-bands by using DWT and SWT. The resolution enhancement technique is based\non the interpolation of high frequency components obtained by DWT and input\nimage. SWT is used to enhance input image. DWT is used to decompose an image\ninto four frequency sub bands and these four sub-bands are interpolated using\nbicubic interpolation technique. All these sub-bands are reconstructed as high\nresolution image by using inverse DWT (IDWT). To increase the contrast the\nproposed technique uses DWT and SVD. GHE is used to equalize an image. The\nequalized image is decomposed into four sub-bands using DWT and new LL sub-band\nis reconstructed using SVD. All sub-bands are reconstructed using IDWT to\ngenerate high resolution and contrast image over conventional techniques. The\nexperimental result shows superiority of the proposed technique over\nconventional techniques.\n  Key words: Discrete wavelet transform (DWT), General histogram equalization\n(GHE), Median filter, Singular value decomposition (SVD), Stationary wavelet\ntransform (SWT).\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 15:32:00 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Khairnar", "Prajakta P.", ""], ["Manjare", "C. A.", ""]]}, {"id": "1405.1999", "submitter": "Selcuk Bayin S", "authors": "William A. Sethares and Sel\\c{c}uk \\c{S}. Bay{\\i}n", "title": "Model-Driven Applications of Fractional Derivatives and Integrals", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractional order derivatives and integrals (differintegrals) are viewed from\na frequency-domain perspective using the formalism of Riesz, providing a\ncomputational tool as well as a way to interpret the operations in the\nfrequency domain. Differintegrals provide a logical extension of current\ntechniques, generalizing the notion of integral and differential operators and\nacting as kind of frequency-domain filtering that has many of the advantages of\na nonlocal linear operator. Several important properties of differintegrals are\npresented, and sample applications are given to one- and two-dimensional\nsignals. Computer code to carry out the computations is made available on the\nauthor's website.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 07:42:11 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Sethares", "William A.", ""], ["Bay\u0131n", "Sel\u00e7uk \u015e.", ""]]}, {"id": "1405.2062", "submitter": "Pengfei Wan", "authors": "Pengfei Wan, Gene Cheung, Philip A. Chou, Dinei Florencio, Cha Zhang,\n  Oscar C. Au", "title": "Precision Enhancement of 3D Surfaces from Multiple Compressed Depth Maps", "comments": "This work was accepted as ongoing work paper in IEEE MMSP'2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In texture-plus-depth representation of a 3D scene, depth maps from different\ncamera viewpoints are typically lossily compressed via the classical transform\ncoding / coefficient quantization paradigm. In this paper we propose to reduce\ndistortion of the decoded depth maps due to quantization. The key observation\nis that depth maps from different viewpoints constitute multiple descriptions\n(MD) of the same 3D scene. Considering the MD jointly, we perform a POCS-like\niterative procedure to project a reconstructed signal from one depth map to the\nother and back, so that the converged depth maps have higher precision than the\noriginal quantized versions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 01:00:19 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Wan", "Pengfei", ""], ["Cheung", "Gene", ""], ["Chou", "Philip A.", ""], ["Florencio", "Dinei", ""], ["Zhang", "Cha", ""], ["Au", "Oscar C.", ""]]}, {"id": "1405.2102", "submitter": "Anna Ma", "authors": "Anna Ma, Arjuna Flenner, Deanna Needell, Allon G. Percus", "title": "Improving Image Clustering using Sparse Text and the Wisdom of the\n  Crowds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to improve image clustering using sparse text and the\nwisdom of the crowds. In particular, we present a method to fuse two different\nkinds of document features, image and text features, and use a common\ndictionary or \"wisdom of the crowds\" as the connection between the two\ndifferent kinds of documents. With the proposed fusion matrix, we use topic\nmodeling via non-negative matrix factorization to cluster documents.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 21:29:04 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Ma", "Anna", ""], ["Flenner", "Arjuna", ""], ["Needell", "Deanna", ""], ["Percus", "Allon G.", ""]]}, {"id": "1405.2128", "submitter": "Xiaohao Cai", "authors": "Xiaohao Cai", "title": "Variational Image Segmentation Model Coupled with Image Restoration\n  Achievements", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Image segmentation and image restoration are two important topics in image\nprocessing with great achievements. In this paper, we propose a new multiphase\nsegmentation model by combining image restoration and image segmentation\nmodels. Utilizing image restoration aspects, the proposed segmentation model\ncan effectively and robustly tackle high noisy images, blurry images, images\nwith missing pixels, and vector-valued images. In particular, one of the most\nimportant segmentation models, the piecewise constant Mumford-Shah model, can\nbe extended easily in this way to segment gray and vector-valued images\ncorrupted for example by noise, blur or missing pixels after coupling a new\ndata fidelity term which comes from image restoration topics. It can be solved\nefficiently using the alternating minimization algorithm, and we prove the\nconvergence of this algorithm with three variables under mild condition.\nExperiments on many synthetic and real-world images demonstrate that our method\ngives better segmentation results in comparison to others state-of-the-art\nsegmentation models especially for blurry images and images with missing pixels\nvalues.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 00:51:55 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Cai", "Xiaohao", ""]]}, {"id": "1405.2220", "submitter": "Li-Xin Wang", "authors": "Li-Xin Wang", "title": "Gaussian-Chain Filters for Heavy-Tailed Noise with Application to\n  Detecting Big Buyers and Big Sellers in Stock Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.CV cs.SY q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new heavy-tailed distribution --- Gaussian-Chain (GC)\ndistribution, which is inspirited by the hierarchical structures prevailing in\nsocial organizations. We determine the mean, variance and kurtosis of the\nGaussian-Chain distribution to show its heavy-tailed property, and compute the\ntail distribution table to give specific numbers showing how heavy is the\nheavy-tails. To filter out the heavy-tailed noise, we construct two filters ---\n2nd and 3rd-order GC filters --- based on the maximum likelihood principle.\nSimulation results show that the GC filters perform much better than the\nbenchmark least-squares algorithm when the noise is heavy-tail distributed.\nUsing the GC filters, we propose a trading strategy, named Ride-the-Mood, to\nfollow the mood of the market by detecting the actions of the big buyers and\nthe big sellers in the market based on the noisy, heavy-tailed price data.\nApplication of the Ride-the-Mood strategy to five blue-chip Hong Kong stocks\nover the recent two-year period from April 2, 2012 to March 31, 2014 shows that\ntheir returns are higher than the returns of the benchmark Buy-and-Hold\nstrategy and the Hang Seng Index Fund.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 13:06:27 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Wang", "Li-Xin", ""]]}, {"id": "1405.2227", "submitter": "Dhrubajyoti Das", "authors": "Saptarshi Chakraborty and Dhrubajyoti Das", "title": "An Overview of Face Liveness Detection", "comments": "International Journal on Information Theory (IJIT), Vol.3, No.2,\n  April 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition is a widely used biometric approach. Face recognition\ntechnology has developed rapidly in recent years and it is more direct, user\nfriendly and convenient compared to other methods. But face recognition systems\nare vulnerable to spoof attacks made by non-real faces. It is an easy way to\nspoof face recognition systems by facial pictures such as portrait photographs.\nA secure system needs Liveness detection in order to guard against such\nspoofing. In this work, face liveness detection approaches are categorized\nbased on the various types techniques used for liveness detection. This\ncategorization helps understanding different spoof attacks scenarios and their\nrelation to the developed solutions. A review of the latest works regarding\nface liveness detection works is presented. The main aim is to provide a simple\npath for the future development of novel and more secured face liveness\ndetection approach.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 13:47:09 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Chakraborty", "Saptarshi", ""], ["Das", "Dhrubajyoti", ""]]}, {"id": "1405.2246", "submitter": "Le Li", "authors": "Le Li, Jianjun Yang, Kaili Zhao, Yang Xu, Honggang Zhang, Zhuoyi Fan", "title": "Graph Regularized Non-negative Matrix Factorization By Maximizing\n  Correntropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) has proved effective in many\nclustering and classification tasks. The classic ways to measure the errors\nbetween the original and the reconstructed matrix are $l_2$ distance or\nKullback-Leibler (KL) divergence. However, nonlinear cases are not properly\nhandled when we use these error measures. As a consequence, alternative\nmeasures based on nonlinear kernels, such as correntropy, are proposed.\nHowever, the current correntropy-based NMF only targets on the low-level\nfeatures without considering the intrinsic geometrical distribution of data. In\nthis paper, we propose a new NMF algorithm that preserves local invariance by\nadding graph regularization into the process of max-correntropy-based matrix\nfactorization. Meanwhile, each feature can learn corresponding kernel from the\ndata. The experiment results of Caltech101 and Caltech256 show the benefits of\nsuch combination against other NMF algorithms for the unsupervised image\nclustering.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 14:44:03 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Li", "Le", ""], ["Yang", "Jianjun", ""], ["Zhao", "Kaili", ""], ["Xu", "Yang", ""], ["Zhang", "Honggang", ""], ["Fan", "Zhuoyi", ""]]}, {"id": "1405.2316", "submitter": "Bryan Poling", "authors": "Bryan Poling, Gilad Lerman, Arthur Szlam", "title": "Better Feature Tracking Through Subspace Constraints", "comments": "8 pages, 2 figures. CVPR 2014", "journal-ref": "Proceedings of CVPR, 2014, pages 3454-3461", "doi": "10.1109/CVPR.2014.441", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature tracking in video is a crucial task in computer vision. Usually, the\ntracking problem is handled one feature at a time, using a single-feature\ntracker like the Kanade-Lucas-Tomasi algorithm, or one of its derivatives.\nWhile this approach works quite well when dealing with high-quality video and\n\"strong\" features, it often falters when faced with dark and noisy video\ncontaining low-quality features. We present a framework for jointly tracking a\nset of features, which enables sharing information between the different\nfeatures in the scene. We show that our method can be employed to track\nfeatures for both rigid and nonrigid motions (possibly of few moving bodies)\neven when some features are occluded. Furthermore, it can be used to\nsignificantly improve tracking results in poorly-lit scenes (where there is a\nmix of good and bad features). Our approach does not require direct modeling of\nthe structure or the motion of the scene, and runs in real time on a single CPU\ncore.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 18:49:49 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Poling", "Bryan", ""], ["Lerman", "Gilad", ""], ["Szlam", "Arthur", ""]]}, {"id": "1405.2362", "submitter": "Yan Fang", "authors": "Yan Fang, Matthew J. Cotter, Donald M. Chiarulli, Steven P. Levitan", "title": "Image Segmentation Using Frequency Locking of Coupled Oscillators", "comments": "7 pages, 14 figures, the 51th Design Automation Conference 2014, Work\n  in Progress Poster Session", "journal-ref": null, "doi": "10.1109/CNNA.2014.6888657", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronization of coupled oscillators is observed at multiple levels of\nneural systems, and has been shown to play an important function in visual\nperception. We propose a computing system based on locally coupled oscillator\nnetworks for image segmentation. The system can serve as the preprocessing\nfront-end of an image processing pipeline where the common frequencies of\nclusters of oscillators reflect the segmentation results. To demonstrate the\nfeasibility of our design, the system is simulated and tested on a human face\nimage dataset and its performance is compared with traditional intensity\nthreshold based algorithms. Our system shows both better performance and higher\nnoise tolerance than traditional methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 21:53:05 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Fang", "Yan", ""], ["Cotter", "Matthew J.", ""], ["Chiarulli", "Donald M.", ""], ["Levitan", "Steven P.", ""]]}, {"id": "1405.2403", "submitter": "Alexis Huck", "authors": "Alexis Huck, Fran\\c{c}ois de Vieilleville, Pierre Weiss, Manuel\n  Grizonnet", "title": "Hyperspectral pan-sharpening: a variational convex constrained\n  formulation to impose parallel level lines, solved with ADMM", "comments": "4 pages, detailed version of proceedings of conference IEEE WHISPERS\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the issue of hyperspectral pan-sharpening, which\nconsists in fusing a (low spatial resolution) hyperspectral image HX and a\n(high spatial resolution) panchromatic image P to obtain a high spatial\nresolution hyperspectral image. The problem is addressed under a variational\nconvex constrained formulation. The objective favors high resolution spectral\nbands with level lines parallel to those of the panchromatic image. This term\nis balanced with a total variation term as regularizer. Fit-to-P data and\nfit-to-HX data constraints are effectively considered as mathematical\nconstraints, which depend on the statistics of the data noise measurements. The\ndeveloped Alternating Direction Method of Multipliers (ADMM) optimization\nscheme enables us to solve this problem efficiently despite the non\ndifferentiabilities and the huge number of unknowns.\n", "versions": [{"version": "v1", "created": "Sat, 10 May 2014 07:38:19 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Huck", "Alexis", ""], ["de Vieilleville", "Fran\u00e7ois", ""], ["Weiss", "Pierre", ""], ["Grizonnet", "Manuel", ""]]}, {"id": "1405.2496", "submitter": "Stefano Gonella", "authors": "Jeffrey M. Druce, Jarvis D. Haupt, Stefano Gonella", "title": "Anomaly-Sensitive Dictionary Learning for Unsupervised Diagnostics of\n  Solid Media", "comments": "Submitted to the Proceedings of the Royal Society A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a strategy for the detection and triangulation of\nstructural anomalies in solid media. The method revolves around the\nconstruction of sparse representations of the medium's dynamic response,\nobtained by learning instructive dictionaries which form a suitable basis for\nthe response data. The resulting sparse coding problem is recast as a modified\ndictionary learning task with additional spatial sparsity constraints enforced\non the atoms of the learned dictionaries, which provides them with a prescribed\nspatial topology that is designed to unveil anomalous regions in the physical\ndomain. The proposed methodology is model agnostic, i.e., it forsakes the need\nfor a physical model and requires virtually no a priori knowledge of the\nstructure's material properties, as all the inferences are exclusively informed\nby the data through the layers of information that are available in the\nintrinsic salient structure of the material's dynamic response. This\ncharacteristic makes the approach powerful for anomaly identification in\nsystems with unknown or heterogeneous property distribution, for which a model\nis unsuitable or unreliable. The method is validated using both synthetically\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 04:24:35 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Druce", "Jeffrey M.", ""], ["Haupt", "Jarvis D.", ""], ["Gonella", "Stefano", ""]]}, {"id": "1405.2539", "submitter": "Dushyant Vaghela Mr.", "authors": "Dushyant Vaghela and Prof. Kapildev Naina", "title": "A Review of Image Mosaicing Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Image Mosaicing is a method of constructing multiple images of the same scene\ninto a larger image. The output of the image mosaic will be the union of two\ninput images. Image-mosaicing algorithms are used to get mosaiced image. Image\nMosaicing processed is basically divided in to 5 phases. Which includes;\nFeature point extraction, Image registration, Homography computation, Warping\nand Blending if Image. Various corner detection algorithm is being used for\nFeature extraction. This corner produces an efficient and informative output\nmosaiced image. Image mosaicing is widely used in creating 3D images, medical\nimaging, computer vision, data from satellites, and military automatic target\nrecognition.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 15:13:56 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Vaghela", "Dushyant", ""], ["Naina", "Prof. Kapildev", ""]]}, {"id": "1405.2641", "submitter": "Jyothi K", "authors": "Jyothi K and Prabhakar C.J", "title": "Multi Modal Face Recognition Using Block Based Curvelet Features", "comments": "17 pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present multimodal 2D +3D face recognition method using\nblock based curvelet features. The 3D surface of face (Depth Map) is computed\nfrom the stereo face images using stereo vision technique. The statistical\nmeasures such as mean, standard deviation, variance and entropy are extracted\nfrom each block of curvelet subband for both depth and intensity images\nindependently.In order to compute the decision score, the KNN classifier is\nemployed independently for both intensity and depth map. Further, computed\ndecision scoresof intensity and depth map are combined at decision level to\nimprove the face recognition rate. The combination of intensity and depth map\nis verified experimentally using benchmark face database. The experimental\nresults show that the proposed multimodal method is better than individual\nmodality.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 06:51:08 GMT"}, {"version": "v2", "created": "Wed, 21 May 2014 11:30:51 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["K", "Jyothi", ""], ["J", "Prabhakar C.", ""]]}, {"id": "1405.2908", "submitter": "Johny Paul", "authors": "Johny Paul, Walter Stechele, Manfred Kr\\\"ohnert, Tamim Asfour", "title": "Resource-Aware Programming for Robotic Vision", "comments": "Presented at 1st Workshop on Resource Awareness and Adaptivity in\n  Multi-Core Computing (Racing 2014) (arXiv:1405.2281)", "journal-ref": null, "doi": null, "report-no": "Racing/2014/02", "categories": "cs.CV cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanoid robots are designed to operate in human centered environments. They\nface changing, dynamic environments in which they need to fulfill a multitude\nof challenging tasks. Such tasks differ in complexity, resource requirements,\nand execution time. Latest computer architectures of humanoid robots consist of\nseveral industrial PCs containing single- or dual-core processors. According to\nthe SIA roadmap for semiconductors, many-core chips with hundreds to thousands\nof cores are expected to be available in the next decade. Utilizing the full\npower of a chip with huge amounts of resources requires new computing paradigms\nand methodologies.\n  In this paper, we analyze a resource-aware computing methodology named\nInvasive Computing, to address these challenges. The benefits and limitations\nof the new programming model is analyzed using two widely used computer vision\nalgorithms, the Harris Corner detector and SIFT (Scale Invariant Feature\nTransform) feature matching. The result indicate that the new programming model\ntogether with the extensions within the application layer, makes them highly\nadaptable; leading to better quality in the results obtained.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:40:04 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Paul", "Johny", ""], ["Stechele", "Walter", ""], ["Kr\u00f6hnert", "Manfred", ""], ["Asfour", "Tamim", ""]]}, {"id": "1405.2941", "submitter": "Jiang Wang Mr.", "authors": "Jiang wang, Xiaohan Nie, Yin Xia, Ying Wu, Song-Chun Zhu", "title": "Cross-view Action Modeling, Learning and Recognition", "comments": "CVPR 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods on video-based action recognition are generally\nview-dependent, i.e., performing recognition from the same views seen in the\ntraining data. We present a novel multiview spatio-temporal AND-OR graph\n(MST-AOG) representation for cross-view action recognition, i.e., the\nrecognition is performed on the video from an unknown and unseen view. As a\ncompositional model, MST-AOG compactly represents the hierarchical\ncombinatorial structures of cross-view actions by explicitly modeling the\ngeometry, appearance and motion variations. This paper proposes effective\nmethods to learn the structure and parameters of MST-AOG. The inference based\non MST-AOG enables action recognition from novel views. The training of MST-AOG\ntakes advantage of the 3D human skeleton data obtained from Kinect cameras to\navoid annotating enormous multi-view video frames, which is error-prone and\ntime-consuming, but the recognition does not need 3D information and is based\non 2D video input. A new Multiview Action3D dataset has been created and will\nbe released. Extensive experiments have demonstrated that this new action\nrepresentation significantly improves the accuracy and robustness for\ncross-view action recognition on 2D videos.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 20:21:53 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["wang", "Jiang", ""], ["Nie", "Xiaohan", ""], ["Xia", "Yin", ""], ["Wu", "Ying", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1405.3173", "submitter": "Jian Zhang", "authors": "Jian Zhang, Debin Zhao, Ruiqin Xiong, Siwei Ma, Wen Gao", "title": "Image Restoration Using Joint Statistical Modeling in Space-Transform\n  Domain", "comments": "14 pages, 18 figures, 7 Tables, to be published in IEEE Transactions\n  on Circuits System and Video Technology (TCSVT). High resolution pdf version\n  and Code can be found at: http://idm.pku.edu.cn/staff/zhangjian/IRJSM/", "journal-ref": null, "doi": "10.1109/TCSVT.2014.2302380", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel strategy for high-fidelity image restoration by\ncharacterizing both local smoothness and nonlocal self-similarity of natural\nimages in a unified statistical manner. The main contributions are three-folds.\nFirst, from the perspective of image statistics, a joint statistical modeling\n(JSM) in an adaptive hybrid space-transform domain is established, which offers\na powerful mechanism of combining local smoothness and nonlocal self-similarity\nsimultaneously to ensure a more reliable and robust estimation. Second, a new\nform of minimization functional for solving image inverse problem is formulated\nusing JSM under regularization-based framework. Finally, in order to make JSM\ntractable and robust, a new Split-Bregman based algorithm is developed to\nefficiently solve the above severely underdetermined inverse problem associated\nwith theoretical proof of convergence. Extensive experiments on image\ninpainting, image deblurring and mixed Gaussian plus salt-and-pepper noise\nremoval applications verify the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 08:45:07 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Zhang", "Jian", ""], ["Zhao", "Debin", ""], ["Xiong", "Ruiqin", ""], ["Ma", "Siwei", ""], ["Gao", "Wen", ""]]}, {"id": "1405.3195", "submitter": "Kaeser Sabrin", "authors": "Kaeser M Sabrin and M Haider Ali", "title": "An Intelligent Pixel Replication Technique by Binary Decomposition for\n  Digital Image Zooming", "comments": null, "journal-ref": "Proceedings of the 26th Image and Vision Computing New Zealand\n  Conference (IVCNZ 2011), P.Delmas, B.Wuensche, J. James, Eds., 29 Nov - 1 Dec\n  2011, Auckland, New Zealand, IVCNZ, pp. 547 - 552, 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image zooming is the process of enlarging the spatial resolution of a given\ndigital image. We present a novel technique that intelligently modifies the\nclassical pixel replication method for zooming. Our method decomposes a given\nimage into layer of binary images, interpolates them by magnifying the binary\npatterns preserving their geometric shape and finally aggregates them all to\nobtain the zoomed image. Although the quality of our zoomed images is much\nhigher than that of nearest neighbor and bilinear interpolation and comparable\nwith bicubic interpolation, the running time of our technique is extremely fast\nlike nearest neighbor interpolation and much faster than bilinear and bicubic\ninterpolation.\n", "versions": [{"version": "v1", "created": "Tue, 13 May 2014 15:45:46 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Sabrin", "Kaeser M", ""], ["Ali", "M Haider", ""]]}, {"id": "1405.3351", "submitter": "Jian Zhang", "authors": "Jian Zhang, Debin Zhao, Wen Gao", "title": "Group-based Sparse Representation for Image Restoration", "comments": "34 pages, 6 tables, 19 figures, to be published in IEEE Transactions\n  on Image Processing; Project, Code and High resolution PDF version can be\n  found: http://idm.pku.edu.cn/staff/zhangjian/. arXiv admin note: text overlap\n  with arXiv:1404.7566", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional patch-based sparse representation modeling of natural images\nusually suffer from two problems. First, it has to solve a large-scale\noptimization problem with high computational complexity in dictionary learning.\nSecond, each patch is considered independently in dictionary learning and\nsparse coding, which ignores the relationship among patches, resulting in\ninaccurate sparse coding coefficients. In this paper, instead of using patch as\nthe basic unit of sparse representation, we exploit the concept of group as the\nbasic unit of sparse representation, which is composed of nonlocal patches with\nsimilar structures, and establish a novel sparse representation modeling of\nnatural images, called group-based sparse representation (GSR). The proposed\nGSR is able to sparsely represent natural images in the domain of group, which\nenforces the intrinsic local sparsity and nonlocal self-similarity of images\nsimultaneously in a unified framework. Moreover, an effective self-adaptive\ndictionary learning method for each group with low complexity is designed,\nrather than dictionary learning from natural images. To make GSR tractable and\nrobust, a split Bregman based technique is developed to solve the proposed\nGSR-driven minimization problem for image restoration efficiently. Extensive\nexperiments on image inpainting, image deblurring and image compressive sensing\nrecovery manifest that the proposed GSR modeling outperforms many current\nstate-of-the-art schemes in both PSNR and visual perception.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 03:15:59 GMT"}], "update_date": "2014-05-15", "authors_parsed": [["Zhang", "Jian", ""], ["Zhao", "Debin", ""], ["Gao", "Wen", ""]]}, {"id": "1405.3352", "submitter": "Ziqiang Chen", "authors": "F. Lu and Z. Chen", "title": "Newton-Type Iterative Solver for Multiple View $L2$ Triangulation", "comments": "15 pages, 1 figure, 4 tables, 30 references, C++ source codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we show that the L2 optimal solutions to most real multiple\nview L2 triangulation problems can be efficiently obtained by two-stage\nNewton-like iterative methods, while the difficulty of such problems mainly\nlies in how to verify the L2 optimality. Such a working two-stage bundle\nadjustment approach features: first, the algorithm is initialized by symmedian\npoint triangulation, a multiple-view generalization of the mid-point method;\nsecond, a symbolic-numeric method is employed to compute derivatives\naccurately; third, globalizing strategy such as line search or trust region is\nsmoothly applied to the underlying iteration which assures algorithm robustness\nin general cases.\n  Numerical comparison with tfml method shows that the local minimizers\nobtained by the two-stage iterative bundle adjustment approach proposed here\nare also the L2 optimal solutions to all the calibrated data sets available\nonline by the Oxford visual geometry group. Extensive numerical experiments\nindicate the bundle adjustment approach solves more than 99% the real\ntriangulation problems optimally. An IEEE 754 double precision C++\nimplementation shows that it takes only about 0.205 second tocompute allthe\n4983 points in the Oxford dinosaur data setvia Gauss-Newton iteration hybrid\nwith a line search strategy on a computer with a 3.4GHz Intel i7 CPU.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 03:35:56 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2014 23:39:32 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Lu", "F.", ""], ["Chen", "Z.", ""]]}, {"id": "1405.3382", "submitter": "Samaneh Khoshrou", "authors": "Samaneh Khoshrou, Jaime S. Cardoso, Luis F. Teixeira", "title": "Active Mining of Parallel Video Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practicality of a video surveillance system is adversely limited by the\namount of queries that can be placed on human resources and their vigilance in\nresponse. To transcend this limitation, a major effort under way is to include\nsoftware that (fully or at least semi) automatically mines video footage,\nreducing the burden imposed to the system. Herein, we propose a semi-supervised\nincremental learning framework for evolving visual streams in order to develop\na robust and flexible track classification system. Our proposed method learns\nfrom consecutive batches by updating an ensemble in each time. It tries to\nstrike a balance between performance of the system and amount of data which\nneeds to be labelled. As no restriction is considered, the system can address\nmany practical problems in an evolving multi-camera scenario, such as concept\ndrift, class evolution and various length of video streams which have not been\naddressed before. Experiments were performed on synthetic as well as real-world\nvisual data in non-stationary environments, showing high accuracy with fairly\nlittle human collaboration.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 07:00:38 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Khoshrou", "Samaneh", ""], ["Cardoso", "Jaime S.", ""], ["Teixeira", "Luis F.", ""]]}, {"id": "1405.3531", "submitter": "Ken Chatfield", "authors": "Ken Chatfield, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman", "title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets", "comments": "Published in proceedings of BMVC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest generation of Convolutional Neural Networks (CNN) have achieved\nimpressive results in challenging benchmarks on image recognition and object\ndetection, significantly raising the interest of the community in these\nmethods. Nevertheless, it is still unclear how different CNN methods compare\nwith each other and with previous state-of-the-art shallow representations such\nas the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts\na rigorous evaluation of these new techniques, exploring different deep\narchitectures and comparing them on a common ground, identifying and disclosing\nimportant implementation details. We identify several useful properties of\nCNN-based representations, including the fact that the dimensionality of the\nCNN output layer can be reduced significantly without having an adverse effect\non performance. We also identify aspects of deep and shallow methods that can\nbe successfully shared. In particular, we show that the data augmentation\ntechniques commonly applied to CNN-based methods can also be applied to shallow\nmethods, and result in an analogous performance boost. Source code and models\nto reproduce the experiments in the paper is made publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 15:19:22 GMT"}, {"version": "v2", "created": "Thu, 15 May 2014 19:48:38 GMT"}, {"version": "v3", "created": "Tue, 22 Jul 2014 15:09:39 GMT"}, {"version": "v4", "created": "Wed, 5 Nov 2014 08:34:48 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Chatfield", "Ken", ""], ["Simonyan", "Karen", ""], ["Vedaldi", "Andrea", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1405.3866", "submitter": "Max Jaderberg", "authors": "Max Jaderberg, Andrea Vedaldi, Andrew Zisserman", "title": "Speeding up Convolutional Neural Networks with Low Rank Expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is speeding up the evaluation of convolutional neural\nnetworks. While delivering impressive results across a range of computer vision\nand machine learning tasks, these networks are computationally demanding,\nlimiting their deployability. Convolutional layers generally consume the bulk\nof the processing time, and so in this work we present two simple schemes for\ndrastically speeding up these layers. This is achieved by exploiting\ncross-channel or filter redundancy to construct a low rank basis of filters\nthat are rank-1 in the spatial domain. Our methods are architecture agnostic,\nand can be easily applied to existing CPU and GPU convolutional frameworks for\ntuneable speedup performance. We demonstrate this with a real world network\ndesigned for scene text character recognition, showing a possible 2.5x speedup\nwith no loss in accuracy, and 4.5x speedup with less than 1% drop in accuracy,\nstill achieving state-of-the-art on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 14:41:06 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Jaderberg", "Max", ""], ["Vedaldi", "Andrea", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1405.4054", "submitter": "Jianfeng Wang", "authors": "Jianfeng Wang, Jingdong Wang, Jingkuan Song, Xin-Shun Xu, Heng Tao\n  Shen, Shipeng Li", "title": "Optimized Cartesian $K$-Means", "comments": "to appear in IEEE TKDE, accepted in Apr. 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product quantization-based approaches are effective to encode\nhigh-dimensional data points for approximate nearest neighbor search. The space\nis decomposed into a Cartesian product of low-dimensional subspaces, each of\nwhich generates a sub codebook. Data points are encoded as compact binary codes\nusing these sub codebooks, and the distance between two data points can be\napproximated efficiently from their codes by the precomputed lookup tables.\nTraditionally, to encode a subvector of a data point in a subspace, only one\nsub codeword in the corresponding sub codebook is selected, which may impose\nstrict restrictions on the search accuracy. In this paper, we propose a novel\napproach, named Optimized Cartesian $K$-Means (OCKM), to better encode the data\npoints for more accurate approximate nearest neighbor search. In OCKM, multiple\nsub codewords are used to encode the subvector of a data point in a subspace.\nEach sub codeword stems from different sub codebooks in each subspace, which\nare optimally generated with regards to the minimization of the distortion\nerrors. The high-dimensional data point is then encoded as the concatenation of\nthe indices of multiple sub codewords from all the subspaces. This can provide\nmore flexibility and lower distortion errors than traditional methods.\nExperimental results on the standard real-life datasets demonstrate the\nsuperiority over state-of-the-art approaches for approximate nearest neighbor\nsearch.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 03:09:01 GMT"}], "update_date": "2014-05-19", "authors_parsed": [["Wang", "Jianfeng", ""], ["Wang", "Jingdong", ""], ["Song", "Jingkuan", ""], ["Xu", "Xin-Shun", ""], ["Shen", "Heng Tao", ""], ["Li", "Shipeng", ""]]}, {"id": "1405.4308", "submitter": "Le Lu", "authors": "Meizhu Liu, Le Lu, Xiaojing Ye, Shipeng Yu", "title": "Coarse-to-Fine Classification via Parametric and Nonparametric Models\n  for Computer-Aided Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the core problems in Computer-Aided Diagnosis (CAD),\ntargeting for early cancer detection using 3D medical imaging interpretation.\nHigh detection sensitivity with desirably low false positive (FP) rate is\ncritical for a CAD system to be accepted as a valuable or even indispensable\ntool in radiologists' workflow. Given various spurious imagery noises which\ncause observation uncertainties, this remains a very challenging task. In this\npaper, we propose a novel, two-tiered coarse-to-fine (CTF) classification\ncascade framework to tackle this problem. We first obtain\nclassification-critical data samples (e.g., samples on the decision boundary)\nextracted from the holistic data distributions using a robust parametric model\n(e.g., \\cite{Raykar08}); then we build a graph-embedding based nonparametric\nclassifier on sampled data, which can more accurately preserve or formulate the\ncomplex classification boundary. These two steps can also be considered as\neffective \"sample pruning\" and \"feature pursuing + $k$NN/template matching\",\nrespectively. Our approach is validated comprehensively in colorectal polyp\ndetection and lung nodule detection CAD systems, as the top two deadly cancers,\nusing hospital scale, multi-site clinical datasets. The results show that our\nmethod achieves overall better classification/detection performance than\nexisting state-of-the-art algorithms using single-layer classifiers, such as\nthe support vector machine variants \\cite{Wang08}, boosting \\cite{Slabaugh10},\nlogistic regression \\cite{Ravesteijn10}, relevance vector machine\n\\cite{Raykar08}, $k$-nearest neighbor \\cite{Murphy09} or spectral projections\non graph \\cite{Cai08}.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 21:13:01 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Liu", "Meizhu", ""], ["Lu", "Le", ""], ["Ye", "Xiaojing", ""], ["Yu", "Shipeng", ""]]}, {"id": "1405.4389", "submitter": "Shraddha Mehta N.", "authors": "Shraddha Mehta, Vaishali Kalariya", "title": "Efficient Tracking of a Moving Object using Inter-Frame Coding", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video surveillance has long been in use to monitor security sensitive areas\nsuch as banks, department stores, highways, crowded public places and\nborders.The advance in computing power, availability of large-capacity storage\ndevices and high speed network infrastructure paved the way for cheaper,\nmulti-sensor video surveillance systems.Traditionally, the video outputs are\nprocessed online by human operators and are usually saved to tapes for later\nuse only after a forensic event.The increase in the number of cameras in\nordinary surveillance systems overloaded both the human operators and the\nstorage devices with high volumes of data and made it in-feasible to ensure\nproper monitoring of sensitive areas for long times.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 12:33:29 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Mehta", "Shraddha", ""], ["Kalariya", "Vaishali", ""]]}, {"id": "1405.4390", "submitter": "Shraddha Mehta N.", "authors": "Shraddha Mehta, Vaishali Kalariya", "title": "Real Time Object Tracking Based on Inter-frame Coding: A Review", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-frame Coding plays significant role for video Compression and Computer\nVision. Computer vision systems have been incorporated in many real life\napplications (e.g. surveillance systems, medical imaging, robot navigation and\nidentity verification systems). Object tracking is a key computer vision topic,\nwhich aims at detecting the position of a moving object from a video sequence.\nThe application of Inter-frame Coding for low frame rate video, as well as for\nlow resolution video. Various methods based on Top-down approach just like\nkernel based or mean shift technique are used to track the object for video,\nSo, Inter-frame Coding algorithms are widely adopted by video coding standards,\nmainly due to their simplicity and good distortion performance for object\ntracking.\n", "versions": [{"version": "v1", "created": "Sat, 17 May 2014 12:41:33 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Mehta", "Shraddha", ""], ["Kalariya", "Vaishali", ""]]}, {"id": "1405.4506", "submitter": "Limin Wang", "authors": "Xiaojiang Peng and Limin Wang and Xingxing Wang and Yu Qiao", "title": "Bag of Visual Words and Fusion Methods for Action Recognition:\n  Comprehensive Study and Good Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video based action recognition is one of the important and challenging\nproblems in computer vision research. Bag of Visual Words model (BoVW) with\nlocal features has become the most popular method and obtained the\nstate-of-the-art performance on several realistic datasets, such as the HMDB51,\nUCF50, and UCF101. BoVW is a general pipeline to construct a global\nrepresentation from a set of local features, which is mainly composed of five\nsteps: (i) feature extraction, (ii) feature pre-processing, (iii) codebook\ngeneration, (iv) feature encoding, and (v) pooling and normalization. Many\nefforts have been made in each step independently in different scenarios and\ntheir effect on action recognition is still unknown. Meanwhile, video data\nexhibits different views of visual pattern, such as static appearance and\nmotion dynamics. Multiple descriptors are usually extracted to represent these\ndifferent views. Many feature fusion methods have been developed in other areas\nand their influence on action recognition has never been investigated before.\nThis paper aims to provide a comprehensive study of all steps in BoVW and\ndifferent fusion methods, and uncover some good practice to produce a\nstate-of-the-art action recognition system. Specifically, we explore two kinds\nof local features, ten kinds of encoding methods, eight kinds of pooling and\nnormalization strategies, and three kinds of fusion methods. We conclude that\nevery step is crucial for contributing to the final recognition rate.\nFurthermore, based on our comprehensive study, we propose a simple yet\neffective representation, called hybrid representation, by exploring the\ncomplementarity of different BoVW frameworks and local descriptors. Using this\nrepresentation, we obtain the state-of-the-art on the three challenging\ndatasets: HMDB51 (61.1%), UCF50 (92.3%), and UCF101 (87.9%).\n", "versions": [{"version": "v1", "created": "Sun, 18 May 2014 13:56:07 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Peng", "Xiaojiang", ""], ["Wang", "Limin", ""], ["Wang", "Xingxing", ""], ["Qiao", "Yu", ""]]}, {"id": "1405.4574", "submitter": "Kristjan Greenewald", "authors": "Kristjan H. Greenewald and Alfred O. Hero III", "title": "Kronecker PCA Based Spatio-Temporal Modeling of Video for Dismount\n  Classification", "comments": "8 pages. To appear in Proceeding of SPIE DSS. arXiv admin note: text\n  overlap with arXiv:1402.5568", "journal-ref": null, "doi": "10.1117/12.2050184", "report-no": null, "categories": "cs.CV stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the application of KronPCA spatio-temporal modeling techniques\n[Greenewald et al 2013, Tsiligkaridis et al 2013] to the extraction of\nspatiotemporal features for video dismount classification. KronPCA performs a\nlow-rank type of dimensionality reduction that is adapted to spatio-temporal\ndata and is characterized by the T frame multiframe mean and covariance of p\nspatial features. For further regularization and improved inverse estimation,\nwe also use the diagonally corrected KronPCA shrinkage methods we presented in\n[Greenewald et al 2013]. We apply this very general method to the modeling of\nthe multivariate temporal behavior of HOG features extracted from pedestrian\nbounding boxes in video, with gender classification in a challenging dataset\nchosen as a specific application. The learned covariances for each class are\nused to extract spatiotemporal features which are then classified, achieving\ncompetitive classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 01:22:34 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Greenewald", "Kristjan H.", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "1405.4583", "submitter": "Wei Feng", "authors": "Wei Feng and Jiaya Jia and Zhi-Qiang Liu", "title": "ESSP: An Efficient Approach to Minimizing Dense and Nonsubmodular Energy\n  Functions", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in computer vision have demonstrated the impressive\npower of dense and nonsubmodular energy functions in solving visual labeling\nproblems. However, minimizing such energies is challenging. None of existing\ntechniques (such as s-t graph cut, QPBO, BP and TRW-S) can individually do this\nwell. In this paper, we present an efficient method, namely ESSP, to optimize\nbinary MRFs with arbitrary pairwise potentials, which could be nonsubmodular\nand with dense connectivity. We also provide a comparative study of our\napproach and several recent promising methods. From our study, we make some\nreasonable recommendations of combining existing methods that perform the best\nin different situations for this challenging problem. Experimental results\nvalidate that for dense and nonsubmodular energy functions, the proposed\napproach can usually obtain lower energies than the best combination of other\ntechniques using comparably reasonable time.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 03:06:14 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Feng", "Wei", ""], ["Jia", "Jiaya", ""], ["Liu", "Zhi-Qiang", ""]]}, {"id": "1405.4802", "submitter": "Paritosh Parmar", "authors": "Paritosh Parmar", "title": "Use of Computer Vision to Detect Tangles in Tangled Objects", "comments": "IEEE International Conference on Image Information Processing;\n  untangle; untangling; computer vision; robotic vision; untangling by robot;\n  Tangled-100 dataset; tangled linear deformable objects; personal robotics;\n  image processing", "journal-ref": null, "doi": "10.1109/ICIIP.2013.6707551", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Untangling of structures like ropes and wires by autonomous robots can be\nuseful in areas such as personal robotics, industries and electrical wiring &\nrepairing by robots. This problem can be tackled by using computer vision\nsystem in robot. This paper proposes a computer vision based method for\nanalyzing visual data acquired from camera for perceiving the overlap of wires,\nropes, hoses i.e. detecting tangles. Information obtained after processing\nimage according to the proposed method comprises of position of tangles in\ntangled object and which wire passes over which wire. This information can then\nbe used to guide robot to untangle wire/s. Given an image, preprocessing is\ndone to remove noise. Then edges of wire are detected. After that, the image is\ndivided into smaller blocks and each block is checked for wire overlap/s and\nfinding other relevant information. TANGLED-100 dataset was introduced, which\nconsists of images of tangled linear deformable objects. Method discussed in\nhere was tested on the TANGLED-100 dataset. Accuracy achieved during\nexperiments was found to be 74.9%. Robotic simulations were carried out to\ndemonstrate the use of the proposed method in applications of robot. Proposed\nmethod is a general method that can be used by robots working in different\nsituations.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 16:51:11 GMT"}, {"version": "v2", "created": "Sat, 11 Oct 2014 04:50:24 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Parmar", "Paritosh", ""]]}, {"id": "1405.4807", "submitter": "Yuxin Chen", "authors": "Qixing Huang, Yuxin Chen, and Leonidas Guibas", "title": "Scalable Semidefinite Relaxation for Maximum A Posterior Estimation", "comments": "accepted to International Conference on Machine Learning (ICML 2014)", "journal-ref": "International Conference on Machine Learning (ICML), vol. 32, pp.\n  64-72, June 2014", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum a posteriori (MAP) inference over discrete Markov random fields is a\nfundamental task spanning a wide spectrum of real-world applications, which is\nknown to be NP-hard for general graphs. In this paper, we propose a novel\nsemidefinite relaxation formulation (referred to as SDR) to estimate the MAP\nassignment. Algorithmically, we develop an accelerated variant of the\nalternating direction method of multipliers (referred to as SDPAD-LR) that can\neffectively exploit the special structure of the new relaxation. Encouragingly,\nthe proposed procedure allows solving SDR for large-scale problems, e.g.,\nproblems on a grid graph comprising hundreds of thousands of variables with\nmultiple states per node. Compared with prior SDP solvers, SDPAD-LR is capable\nof attaining comparable accuracy while exhibiting remarkably improved\nscalability, in contrast to the commonly held belief that semidefinite\nrelaxation can only been applied on small-scale MRF problems. We have evaluated\nthe performance of SDR on various benchmark datasets including OPENGM2 and PIC\nin terms of both the quality of the solutions and computation time.\nExperimental results demonstrate that for a broad class of problems, SDPAD-LR\noutperforms state-of-the-art algorithms in producing better MAP assignment in\nan efficient manner.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 16:58:24 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Huang", "Qixing", ""], ["Chen", "Yuxin", ""], ["Guibas", "Leonidas", ""]]}, {"id": "1405.4930", "submitter": "Shiv Ram Dubey", "authors": "Shiv Ram Dubey, Anand Singh Jalal", "title": "Adapted Approach for Fruit Disease Identification using Images", "comments": "15 pages, 8 figures, 1 table", "journal-ref": "International Journal of Computer Vision and Image Processing\n  (IJCVIP) 2, no. 3 (2012): 44-58", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diseases in fruit cause devastating problem in economic losses and production\nin agricultural industry worldwide. In this paper, an adaptive approach for the\nidentification of fruit diseases is proposed and experimentally validated. The\nimage processing based proposed approach is composed of the following main\nsteps; in the first step K-Means clustering technique is used for the defect\nsegmentation, in the second step some state of the art features are extracted\nfrom the segmented image, and finally images are classified into one of the\nclasses by using a Multi-class Support Vector Machine. We have considered\ndiseases of apple as a test case and evaluated our approach for three types of\napple diseases namely apple scab, apple blotch and apple rot. Our experimental\nresults express that the proposed solution can significantly support accurate\ndetection and automatic identification of fruit diseases. The classification\naccuracy for the proposed solution is achieved up to 93%.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 01:40:38 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2014 04:21:07 GMT"}, {"version": "v3", "created": "Tue, 15 Jul 2014 15:32:39 GMT"}, {"version": "v4", "created": "Fri, 1 Aug 2014 00:08:07 GMT"}, {"version": "v5", "created": "Mon, 4 Aug 2014 00:31:32 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Dubey", "Shiv Ram", ""], ["Jalal", "Anand Singh", ""]]}, {"id": "1405.4969", "submitter": "Raja Giryes", "authors": "Raja Giryes and Michael Elad and Alfred M. Bruckstein", "title": "Sparsity Based Methods for Overparameterized Variational Problems", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two complementary approaches have been extensively used in signal and image\nprocessing leading to novel results, the sparse representation methodology and\nthe variational strategy. Recently, a new sparsity based model has been\nproposed, the cosparse analysis framework, which may potentially help in\nbridging sparse approximation based methods to the traditional total-variation\nminimization. Based on this, we introduce a sparsity based framework for\nsolving overparameterized variational problems. The latter has been used to\nimprove the estimation of optical flow and also for general denoising of\nsignals and images. However, the recovery of the space varying parameters\ninvolved was not adequately addressed by traditional variational methods. We\nfirst demonstrate the efficiency of the new framework for one dimensional\nsignals in recovering a piecewise linear and polynomial function. Then, we\nillustrate how the new technique can be used for denoising and segmentation of\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 06:56:04 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 20:59:26 GMT"}, {"version": "v3", "created": "Thu, 15 Jan 2015 17:43:54 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2015 14:24:49 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2015 17:19:06 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Giryes", "Raja", ""], ["Elad", "Michael", ""], ["Bruckstein", "Alfred M.", ""]]}, {"id": "1405.5047", "submitter": "Michael Burke Mr", "authors": "Michael Burke and Joan Lasenby", "title": "Single camera pose estimation using Bayesian filtering and Kinect motion\n  priors", "comments": "25 pages, Technical report, related to Burke and Lasenby, AMDO 2014\n  conference paper. Code sample: https://github.com/mgb45/SignerBodyPose Video:\n  https://www.youtube.com/watch?v=dJMTSo7-uFE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to upper body pose estimation using monocular vision\nrely on complex body models and a large variety of geometric constraints. We\nargue that this is not ideal and somewhat inelegant as it results in large\nprocessing burdens, and instead attempt to incorporate these constraints\nthrough priors obtained directly from training data. A prior distribution\ncovering the probability of a human pose occurring is used to incorporate\nlikely human poses. This distribution is obtained offline, by fitting a\nGaussian mixture model to a large dataset of recorded human body poses, tracked\nusing a Kinect sensor. We combine this prior information with a random walk\ntransition model to obtain an upper body model, suitable for use within a\nrecursive Bayesian filtering framework. Our model can be viewed as a mixture of\ndiscrete Ornstein-Uhlenbeck processes, in that states behave as random walks,\nbut drift towards a set of typically observed poses. This model is combined\nwith measurements of the human head and hand positions, using recursive\nBayesian estimation to incorporate temporal information. Measurements are\nobtained using face detection and a simple skin colour hand detector, trained\nusing the detected face. The suggested model is designed with analytical\ntractability in mind and we show that the pose tracking can be\nRao-Blackwellised using the mixture Kalman filter, allowing for computational\nefficiency while still incorporating bio-mechanical properties of the upper\nbody. In addition, the use of the proposed upper body model allows reliable\nthree-dimensional pose estimates to be obtained indirectly for a number of\njoints that are often difficult to detect using traditional object recognition\nstrategies. Comparisons with Kinect sensor results and the state of the art in\n2D pose estimation highlight the efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 11:54:04 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2014 12:15:42 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Burke", "Michael", ""], ["Lasenby", "Joan", ""]]}, {"id": "1405.5164", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Maurici Gonzalez, Daniel Zaldivar and Marco Perez", "title": "Multi-ellipses detection on images inspired by collective animal\n  behavior", "comments": "21 pages", "journal-ref": "Neural Computing and Applications, 24(5), (2014), 1019-1033", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel and effective technique for extracting multiple\nellipses from an image. The approach employs an evolutionary algorithm to mimic\nthe way animals behave collectively assuming the overall detection process as a\nmulti-modal optimization problem. In the algorithm, searcher agents emulate a\ngroup of animals that interact to each other using simple biological rules\nwhich are modeled as evolutionary operators. In turn, such operators are\napplied to each agent considering that the complete group has a memory to store\noptimal solutions (ellipses) seen so-far by applying a competition principle.\nThe detector uses a combination of five edge points as parameters to determine\nellipse candidates (possible solutions) while a matching function determines if\nsuch ellipse candidates are actually present in the image. Guided by the values\nof such matching functions, the set of encoded candidate ellipses are evolved\nthrough the evolutionary algorithm so that the best candidates can be fitted\ninto the actual ellipses within the image. Just after the optimization process\nends, an analysis over the embedded memory is executed in order to find the\nbest obtained solution (the best ellipse) and significant local minima\n(remaining ellipses). Experimental results over several complex synthetic and\nnatural images have validated the efficiency of the proposed technique\nregarding accuracy, speed and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 17:40:23 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Cuevas", "Erik", ""], ["Gonzalez", "Maurici", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""]]}, {"id": "1405.5248", "submitter": "Mohamed Ali Mahjoub", "authors": "Khaoula jayech, Nesrine Trimech, Mohamed Ali Mahjoub, Najoua Essoukri\n  Ben Amara", "title": "Dynamic Hierarchical Bayesian Network for Arabic Handwritten Word\n  Recognition", "comments": "Fourth International Conference on Information and Communication\n  Technology and Accessibility (ICTA), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new probabilistic graphical model used to model and\nrecognize words representing the names of Tunisian cities. In fact, this work\nis based on a dynamic hierarchical Bayesian network. The aim is to find the\nbest model of Arabic handwriting to reduce the complexity of the recognition\nprocess by permitting the partial recognition. Actually, we propose a\nsegmentation of the word based on smoothing the vertical histogram projection\nusing different width values to reduce the error of segmentation. Then, we\nextract the characteristics of each cell using the Zernike and HU moments,\nwhich are invariant to rotation, translation and scaling. Our approach is\ntested using the IFN / ENIT database, and the experiment results are very\npromising.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 22:02:54 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["jayech", "Khaoula", ""], ["Trimech", "Nesrine", ""], ["Mahjoub", "Mohamed Ali", ""], ["Amara", "Najoua Essoukri Ben", ""]]}, {"id": "1405.5406", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Fernando Wario, Daniel Zaldivar and Marco Perez", "title": "Circle detection on images using Learning Automata", "comments": "26 Pages", "journal-ref": "ET Computer Vision 6 (2), (2012), pp. 121-132", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circle detection over digital images has received considerable attention from\nthe computer vision community over the last few years devoting a tremendous\namount of research seeking for an optimal detector. This article presents an\nalgorithm for the automatic detection of circular shapes from complicated and\nnoisy images with no consideration of conventional Hough transform principles.\nThe proposed algorithm is based on Learning Automata (LA) which is a\nprobabilistic optimization method that explores an unknown random environment\nby progressively improving the performance via a reinforcement signal\n(objective function). The approach uses the encoding of three non-collinear\npoints as a candidate circle over the edge image. A reinforcement signal\n(matching function) indicates if such candidate circles are actually present in\nthe edge map. Guided by the values of such reinforcement signal, the\nprobability set of the encoded candidate circles is modified through the LA\nalgorithm so that they can fit to the actual circles on the edge map.\nExperimental results over several complex synthetic and natural images have\nvalidated the efficiency of the proposed technique regarding accuracy, speed\nand robustness.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 13:20:44 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Cuevas", "Erik", ""], ["Wario", "Fernando", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""]]}, {"id": "1405.5422", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Daniel Zaldivar, Marco Perez, Edgar Sanchez and Marte\n  Ramirez", "title": "Robust Fuzzy corner detector", "comments": "15 Pages", "journal-ref": "Intelligent Automation and Soft Computing, 17 (4), (2011), pp.\n  415-429", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable corner detection is an important task in determining the shape of\ndifferent regions within an image. Real-life image data are always imprecise\ndue to inherent uncertainties that may arise from the imaging process such as\ndefocusing, illumination changes, noise, etc. Therefore, the localization and\ndetection of corners has become a difficult task to accomplish under such\nimperfect situations. On the other hand, Fuzzy systems are well known for their\nefficient handling of impreciseness and incompleteness, which make them\ninherently suitable for modelling corner properties by means of a rule-based\nfuzzy system. The paper presents a corner detection algorithm which employs\nsuch fuzzy reasoning. The robustness of the proposed algorithm is compared to\nwell-known conventional corner detectors and its performance is also tested\nover a number of benchmark images to illustrate the efficiency of the algorithm\nunder uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 13:44:50 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Cuevas", "Erik", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""], ["Sanchez", "Edgar", ""], ["Ramirez", "Marte", ""]]}, {"id": "1405.5488", "submitter": "Marc'Aurelio Ranzato", "authors": "Marc'Aurelio Ranzato", "title": "On Learning Where To Look", "comments": "deep learning, vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current automatic vision systems face two major challenges: scalability and\nextreme variability of appearance. First, the computational time required to\nprocess an image typically scales linearly with the number of pixels in the\nimage, therefore limiting the resolution of input images to thumbnail size.\nSecond, variability in appearance and pose of the objects constitute a major\nhurdle for robust recognition and detection. In this work, we propose a model\nthat makes baby steps towards addressing these challenges. We describe a\nlearning based method that recognizes objects through a series of glimpses.\nThis system performs an amount of computation that scales with the complexity\nof the input rather than its number of pixels. Moreover, the proposed method is\npotentially more robust to changes in appearance since its parameters are\nlearned in a data driven manner. Preliminary experiments on a handwritten\ndataset of digits demonstrate the computational advantages of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Apr 2014 02:29:19 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1405.5494", "submitter": "Greg Ongie", "authors": "Yasir Q. Moshin, Greg Ongie, Mathews Jacob", "title": "Iterative Non-Local Shrinkage Algorithm for MR Image Reconstruction", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fast iterative non-local shrinkage algorithm to recover MRI\ndata from undersampled Fourier measurements. This approach is enabled by the\nreformulation of current non-local schemes as an alternating algorithm to\nminimize a global criterion. The proposed algorithm alternates between a\nnon-local shrinkage step and a quadratic subproblem. We derive analytical\nshrinkage rules for several penalties that are relevant in non-local\nregularization. The redundancy in the searches used to evaluate the shrinkage\nsteps are exploited using filtering operations. The resulting algorithm is\nobserved to be considerably faster than current alternating non-local\nalgorithms. The comparisons of the proposed scheme with state-of-the-art\nregularization schemes show a considerable reduction in alias artifacts and\npreservation of edges.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 22:42:55 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Moshin", "Yasir Q.", ""], ["Ongie", "Greg", ""], ["Jacob", "Mathews", ""]]}, {"id": "1405.5531", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Fernando Wario, Valentin Osuna, Daniel Zaldivar and Marco\n  Perez", "title": "Fast algorithm for Multiple-Circle detection on images using Learning\n  Automata", "comments": "30 Pages. arXiv admin note: text overlap with arXiv:1405.5406", "journal-ref": "IET Image Processing 6 (8) , (2012), pp. 1124-1135", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hough transform (HT) has been the most common method for circle detection\nexhibiting robustness but adversely demanding a considerable computational load\nand large storage. Alternative approaches include heuristic methods that employ\niterative optimization procedures for detecting multiple circles under the\ninconvenience that only one circle can be marked at each optimization cycle\ndemanding a longer execution time. On the other hand, Learning Automata (LA) is\na heuristic method to solve complex multi-modal optimization problems. Although\nLA converges to just one global minimum, the final probability distribution\nholds valuable information regarding other local minima which have emerged\nduring the optimization process. The detection process is considered as a\nmulti-modal optimization problem, allowing the detection of multiple circular\nshapes through only one optimization procedure. The algorithm uses a\ncombination of three edge points as parameters to determine circles candidates.\nA reinforcement signal determines if such circle candidates are actually\npresent at the image. Guided by the values of such reinforcement signal, the\nset of encoded candidate circles are evolved using the LA so that they can fit\ninto actual circular shapes over the edge-only map of the image. The overall\napproach is a fast multiple-circle detector despite facing complicated\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 13:31:46 GMT"}], "update_date": "2014-05-23", "authors_parsed": [["Cuevas", "Erik", ""], ["Wario", "Fernando", ""], ["Osuna", "Valentin", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""]]}, {"id": "1405.5732", "submitter": "Hossein Azizpour", "authors": "Hossein Azizpour, Stefan Carlsson", "title": "Self-tuned Visual Subclass Learning with Shared Samples An Incremental\n  Approach", "comments": "Updated ICCV 2013 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision tasks are traditionally defined and evaluated using semantic\ncategories. However, it is known to the field that semantic classes do not\nnecessarily correspond to a unique visual class (e.g. inside and outside of a\ncar). Furthermore, many of the feasible learning techniques at hand cannot\nmodel a visual class which appears consistent to the human eye. These problems\nhave motivated the use of 1) Unsupervised or supervised clustering as a\npreprocessing step to identify the visual subclasses to be used in a\nmixture-of-experts learning regime. 2) Felzenszwalb et al. part model and other\nworks model mixture assignment with latent variables which is optimized during\nlearning 3) Highly non-linear classifiers which are inherently capable of\nmodelling multi-modal input space but are inefficient at the test time. In this\nwork, we promote an incremental view over the recognition of semantic classes\nwith varied appearances. We propose an optimization technique which\nincrementally finds maximal visual subclasses in a regularized risk\nminimization framework. Our proposed approach unifies the clustering and\nclassification steps in a single algorithm. The importance of this approach is\nits compliance with the classification via the fact that it does not need to\nknow about the number of clusters, the representation and similarity measures\nused in pre-processing clustering methods a priori. Following this approach we\nshow both qualitatively and quantitatively significant results. We show that\nthe visual subclasses demonstrate a long tail distribution. Finally, we show\nthat state of the art object detection methods (e.g. DPM) are unable to use the\ntails of this distribution comprising 50\\% of the training samples. In fact we\nshow that DPM performance slightly increases on average by the removal of this\nhalf of the data.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 12:47:15 GMT"}, {"version": "v2", "created": "Mon, 26 May 2014 18:47:09 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Azizpour", "Hossein", ""], ["Carlsson", "Stefan", ""]]}, {"id": "1405.5737", "submitter": "Arif Mahmood", "authors": "Arif Mahmood and Ajmal S. Mian", "title": "Semi-supervised Spectral Clustering for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Classification Via Clustering (CVC) algorithm which enables\nexisting clustering methods to be efficiently employed in classification\nproblems. In CVC, training and test data are co-clustered and class-cluster\ndistributions are used to find the label of the test data. To determine an\nefficient number of clusters, a Semi-supervised Hierarchical Clustering (SHC)\nalgorithm is proposed. Clusters are obtained by hierarchically applying two-way\nNCut by using signs of the Fiedler vector of the normalized graph Laplacian. To\nthis end, a Direct Fiedler Vector Computation algorithm is proposed. The graph\ncut is based on the data structure and does not consider labels. Labels are\nused only to define the stopping criterion for graph cut. We propose clustering\nto be performed on the Grassmannian manifolds facilitating the formation of\nspectral ensembles. The proposed algorithm outperformed state-of-the-art\nimage-set classification algorithms on five standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 13:05:27 GMT"}, {"version": "v2", "created": "Fri, 26 Sep 2014 04:01:41 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Mahmood", "Arif", ""], ["Mian", "Ajmal S.", ""]]}, {"id": "1405.5769", "submitter": "Philipp Fischer", "authors": "Philipp Fischer, Alexey Dosovitskiy, Thomas Brox", "title": "Descriptor Matching with Convolutional Neural Networks: a Comparison to\n  SIFT", "comments": "This paper has been merged with arXiv:1406.6909", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest results indicate that features learned via convolutional neural\nnetworks outperform previous descriptors on classification tasks by a large\nmargin. It has been shown that these networks still work well when they are\napplied to datasets or recognition tasks different from those they were trained\non. However, descriptors like SIFT are not only used in recognition but also\nfor many correspondence problems that rely on descriptor matching. In this\npaper we compare features from various layers of convolutional neural nets to\nstandard SIFT descriptors. We consider a network that was trained on ImageNet\nand another one that was trained without supervision. Surprisingly,\nconvolutional neural networks clearly outperform SIFT on descriptor matching.\nThis paper has been merged with arXiv:1406.6909\n", "versions": [{"version": "v1", "created": "Thu, 22 May 2014 14:35:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 09:16:28 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Fischer", "Philipp", ""], ["Dosovitskiy", "Alexey", ""], ["Brox", "Thomas", ""]]}, {"id": "1405.6012", "submitter": "Qi Xie", "authors": "Qi Xie, Deyu Meng, Shuhang Gu, Lei Zhang, Wangmeng Zuo, Xiangchu Feng\n  and Zongben Xu", "title": "On the Optimal Solution of Weighted Nuclear Norm Minimization", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the nuclear norm minimization (NNM) problem has been\nattracting much attention in computer vision and machine learning. The NNM\nproblem is capitalized on its convexity and it can be solved efficiently. The\nstandard nuclear norm regularizes all singular values equally, which is however\nnot flexible enough to fit real scenarios. Weighted nuclear norm minimization\n(WNNM) is a natural extension and generalization of NNM. By assigning properly\ndifferent weights to different singular values, WNNM can lead to\nstate-of-the-art results in applications such as image denoising. Nevertheless,\nso far the global optimal solution of WNNM problem is not completely solved yet\ndue to its non-convexity in general cases. In this article, we study the\ntheoretical properties of WNNM and prove that WNNM can be equivalently\ntransformed into a quadratic programming problem with linear constraints. This\nimplies that WNNM is equivalent to a convex problem and its global optimum can\nbe readily achieved by off-the-shelf convex optimization solvers. We further\nshow that when the weights are non-descending, the globally optimal solution of\nWNNM can be obtained in closed-form.\n", "versions": [{"version": "v1", "created": "Fri, 23 May 2014 10:15:04 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Xie", "Qi", ""], ["Meng", "Deyu", ""], ["Gu", "Shuhang", ""], ["Zhang", "Lei", ""], ["Zuo", "Wangmeng", ""], ["Feng", "Xiangchu", ""], ["Xu", "Zongben", ""]]}, {"id": "1405.6130", "submitter": "Drashti Bhatt", "authors": "Ms.Drashti H. Bhatt, Mr.Kirit R. Rathod, Mr.Shardul J. Agravat", "title": "A Study of Local Binary Pattern Method for Facial Expression Detection", "comments": "3 pages, 2 images, International Journal of Computer Trends and\n  Technology (IJCTT)", "journal-ref": "Ms.Drashti H. Bhatt , Mr.Kirit R. Rathod , Mr.Shardul J. Agravat.\n  Article: A Study of Local Binary Pattern Method for Facial Expression\n  Detection. IJCTT 7(3):151-153, January 2014. Published by Seventh Sense\n  Research Group", "doi": "10.14445/22312803/IJCTT-V7P143", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Face detection is a basic task for expression recognition. The reliability of\nface detection & face recognition approach has a major role on the performance\nand usability of the entire system. There are several ways to undergo face\ndetection & recognition. We can use Image Processing Operations, various\nclassifiers, filters or virtual machines for the former. Various strategies are\nbeing available for Facial Expression Detection. The field of facial expression\ndetection can have various applications along with its importance & can be\ninteracted between human being & computer. Many few options are available to\nidentify a face in an image in accurate & efficient manner. Local Binary\nPattern (LBP) based texture algorithms have gained popularity in these years.\nLBP is an effective approach to have facial expression recognition & is a\nfeature-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 09:53:02 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Bhatt", "Ms. Drashti H.", ""], ["Rathod", "Mr. Kirit R.", ""], ["Agravat", "Mr. Shardul J.", ""]]}, {"id": "1405.6132", "submitter": "Arun P V", "authors": "S.K. Katiyar and P.V. Arun", "title": "Comparative analysis of common edge detection techniques in context of\n  object extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edges characterize boundaries and are therefore a problem of practical\nimportance in remote sensing.In this paper a comparative study of various edge\ndetection techniques and band wise analysis of these algorithms in the context\nof object extraction with regard to remote sensing satellite images from the\nIndian Remote Sensing Satellite (IRS) sensors LISS 3, LISS 4 and Cartosat1 as\nwell as Google Earth is presented.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 00:46:18 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Katiyar", "S. K.", ""], ["Arun", "P. V.", ""]]}, {"id": "1405.6133", "submitter": "Arun P V", "authors": "S.K. Katiyar, P.V. Arun", "title": "A review over the applicability of image entropy in analyses of remote\n  sensing datasets", "comments": "arXiv admin note: substantial text overlap with arXiv:1303.6926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy is the measure of uncertainty in any data and is adopted for\nmaximisation of mutual information in many remote sensing operations. The\navailability of wide entropy variations motivated us for an investigation over\nthe suitability preference of these versions to specific operations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 14:49:36 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Katiyar", "S. K.", ""], ["Arun", "P. V.", ""]]}, {"id": "1405.6135", "submitter": "Arun P V", "authors": "S.K. Katiyar, P.V. Arun", "title": "Cellular Automata based adaptive resampling technique for the processing\n  of remotely sensed imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resampling techniques are being widely used at different stages of satellite\nimage processing. The existing methodologies cannot perfectly recover features\nfrom a completely under sampled image and hence an intelligent adaptive\nresampling methodology is required. We address these issues and adopt an error\nmetric from the available literature to define interpolation quality. We also\npropose a new resampling scheme that adapts itself with regard to the pixel and\ntexture variation in the image. The proposed CNN based hybrid method has been\nfound to perform better than the existing methods as it adapts itself with\nreference to the image features.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 16:14:36 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Katiyar", "S. K.", ""], ["Arun", "P. V.", ""]]}, {"id": "1405.6136", "submitter": "Arun P V", "authors": "P.V. Arun and S.K. Katiyar", "title": "An evolutionary computational based approach towards automatic image\n  registration", "comments": "arXiv admin note: substantial text overlap with arXiv:1303.6711", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is a key component of various image processing operations\nwhich involve the analysis of different image data sets. Automatic image\nregistration domains have witnessed the application of many intelligent\nmethodologies over the past decade; however inability to properly model object\nshape as well as contextual information had limited the attainable accuracy. In\nthis paper, we propose a framework for accurate feature shape modeling and\nadaptive resampling using advanced techniques such as Vector Machines, Cellular\nNeural Network (CNN), SIFT, coreset, and Cellular Automata. CNN has found to be\neffective in improving feature matching as well as resampling stages of\nregistration and complexity of the approach has been considerably reduced using\ncorset optimization The salient features of this work are cellular neural\nnetwork approach based SIFT feature point optimisation, adaptive resampling and\nintelligent object modelling. Developed methodology has been compared with\ncontemporary methods using different statistical measures. Investigations over\nvarious satellite images revealed that considerable success was achieved with\nthe approach. System has dynamically used spectral and spatial information for\nrepresenting contextual knowledge using CNN-prolog approach. Methodology also\nillustrated to be effective in providing intelligent interpretation and\nadaptive resampling.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 17:09:45 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Arun", "P. V.", ""], ["Katiyar", "S. K.", ""]]}, {"id": "1405.6137", "submitter": "Arun P V", "authors": "S.K. Katiyar and P.V. Arun", "title": "An enhanced neural network based approach towards object extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The improvements in spectral and spatial resolution of the satellite images\nhave facilitated the automatic extraction and identification of the features\nfrom satellite images and aerial photographs. An automatic object extraction\nmethod is presented for extracting and identifying the various objects from\nsatellite images and the accuracy of the system is verified with regard to IRS\nsatellite images. The system is based on neural network and simulates the\nprocess of visual interpretation from remote sensing images and hence increases\nthe efficiency of image analysis. This approach obtains the basic\ncharacteristics of the various features and the performance is enhanced by the\nautomatic learning approach, intelligent interpretation, and intelligent\ninterpolation. The major advantage of the method is its simplicity and that the\nsystem identifies the features not only based on pixel value but also based on\nthe shape, haralick features etc of the objects. Further the system allows\nflexibility for identifying the features within the same category based on size\nand shape. The successful application of the system verified its effectiveness\nand the accuracy of the system were assessed by ground truth verification.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 20:05:34 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Katiyar", "S. K.", ""], ["Arun", "P. V.", ""]]}, {"id": "1405.6159", "submitter": "Mariano Tepper", "authors": "Mariano Tepper and Guillermo Sapiro", "title": "A Bi-clustering Framework for Consensus Problems", "comments": null, "journal-ref": null, "doi": "10.1137/140967325", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider grouping as a general characterization for problems such as\nclustering, community detection in networks, and multiple parametric model\nestimation. We are interested in merging solutions from different grouping\nalgorithms, distilling all their good qualities into a consensus solution. In\nthis paper, we propose a bi-clustering framework and perspective for reaching\nconsensus in such grouping problems. In particular, this is the first time that\nthe task of finding/fitting multiple parametric models to a dataset is formally\nposed as a consensus problem. We highlight the equivalence of these tasks and\nestablish the connection with the computational Gestalt program, that seeks to\nprovide a psychologically-inspired detection theory for visual events. We also\npresent a simple but powerful bi-clustering algorithm, specially tuned to the\nnature of the problem we address, though general enough to handle many\ndifferent instances inscribed within our characterization. The presentation is\naccompanied with diverse and extensive experimental results in clustering,\ncommunity detection, and multiple parametric model estimation in image\nprocessing applications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2014 21:58:10 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2014 17:44:55 GMT"}, {"version": "v3", "created": "Wed, 20 Aug 2014 22:12:15 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Tepper", "Mariano", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1405.6166", "submitter": "Seshadri P.R.", "authors": "D.Sachin Kumar, P.R.Seshadri, N.Vaishnav and Dr.Saraswathi Janaki", "title": "Real Time Speckle Image De-Noising", "comments": "9 pages", "journal-ref": "Advances in Vision Computing: An International Journal (AVC)\n  Vol.1, No.1, March 2014", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents real time speckle de-noising based on activity computation\nalgorithm and wavelet transform. Speckles arise in an image when laser light is\nreflected from an illuminated surface. The process involves detection of\nspeckles in an image by obtaining a number of frames of the same object under\ndifferent illumination or angle and comparing the frames for the granular\ncomputation and de-noising the same on presence of greater activity index. The\nproject can be implemented in FPGA (Field Programmable Gate Array) technology.\nThe results can be shown that the used activity computation algorithm and\nwavelet transform has better accuracy in the process of speckle detection and\nde-noising.\n", "versions": [{"version": "v1", "created": "Thu, 10 Apr 2014 12:17:52 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Kumar", "D. Sachin", ""], ["Seshadri", "P. R.", ""], ["Vaishnav", "N.", ""], ["Janaki", "Dr. Saraswathi", ""]]}, {"id": "1405.6168", "submitter": "Harco Leslie Hendric Spits Warnars", "authors": "Spits Warnars", "title": "Human Face as human single identity", "comments": "6 pages, 5 figures, the 4th Indonesia Japan Joint Scientific\n  Symposium (IJJSS), Bali, Indonesia, Sept 29- Oct 1 2010. (ISSN : 2087-577)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human face as a physical human recognition can be used as a unique identity\nfor computer to recognize human by transforming human face with face algorithm\nas simple text number which can be primary key for human. Human face as single\nidentity for human will be done by making a huge and large world centre human\nface database, where the human face around the world will be recorded from time\nto time and from generation to generation. Architecture database will be\ndivided become human face image database which will save human face images and\nhuman face output code which will save human face output code as a\ntransformation human face image with face algorithm. As an improvement the\nslightly and simple human face output code database will make human face\nsearching process become more fast. Transaction with human face as a\ntransaction without card can make human no need their card for the transaction\nand office automation and banking system as an example for implementation\narchitecture. As an addition suspect human face database can be extended for\nfighting crime and terrorism by doing surveillance and searching suspect human\nface around the world.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2014 03:01:33 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Warnars", "Spits", ""]]}, {"id": "1405.6177", "submitter": "Md. Tarek Habib", "authors": "Md. Tarek Habib, Rahat Hossain Faisal, M. Rokonuzzaman, Farruk Ahmed", "title": "Automated Fabric Defect Inspection: A Survey of Classifiers", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": "10.5121/ijfcst.2014.4102", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality control at each stage of production in textile industry has become a\nkey factor to retaining the existence in the highly competitive global market.\nProblems of manual fabric defect inspection are lack of accuracy and high time\nconsumption, where early and accurate fabric defect detection is a significant\nphase of quality control. Computer vision based, i.e. automated fabric defect\ninspection systems are thought by many researchers of different countries to be\nvery useful to resolve these problems. There are two major challenges to be\nresolved to attain a successful automated fabric defect inspection system. They\nare defect detection and defect classification. In this work, we discuss\ndifferent techniques used for automated fabric defect classification, then show\na survey of classifiers used in automated fabric defect inspection systems, and\nfinally, compare these classifiers by using performance metrics. This work is\nexpected to be very useful for the researchers in the area of automated fabric\ndefect inspection to understand and evaluate the many potential options in this\nfield.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 20:53:43 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Habib", "Md. Tarek", ""], ["Faisal", "Rahat Hossain", ""], ["Rokonuzzaman", "M.", ""], ["Ahmed", "Farruk", ""]]}, {"id": "1405.6261", "submitter": "Mayank Bansal", "authors": "Mayank Bansal and Kostas Daniilidis", "title": "Geometric Polynomial Constraints in Higher-Order Graph Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Correspondence is a ubiquitous problem in computer vision and graph matching\nhas been a natural way to formalize correspondence as an optimization problem.\nRecently, graph matching solvers have included higher-order terms representing\naffinities beyond the unary and pairwise level. Such higher-order terms have a\nparticular appeal for geometric constraints that include three or more\ncorrespondences like the PnP 2D-3D pose problems. In this paper, we address the\nproblem of finding correspondences in the absence of unary or pairwise\nconstraints as it emerges in problems where unary appearance similarity like\nSIFT matches is not available. Current higher order matching approaches have\ntargeted problems where higher order affinity can simply be formulated as a\ndifference of invariances such as lengths, angles, or cross-ratios. In this\npaper, we present a method of how to apply geometric constraints modeled as\npolynomial equation systems. As opposed to RANSAC where such systems have to be\nsolved and then tested for inlier hypotheses, our constraints are derived as a\nsingle affinity weight based on $n>2$ hypothesized correspondences without\nsolving the polynomial system. Since the result is directly a correspondence\nwithout a transformation model, our approach supports correspondence matching\nin the presence of multiple geometric transforms like articulated motions.\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2014 03:27:01 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Bansal", "Mayank", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "1405.6275", "submitter": "Dong Liang", "authors": "Dong Liang, Shun'ichi Kaneko", "title": "Improvements and Experiments of a Compact Statistical Background Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change detection plays an important role in most video-based applications.\nThe first stage is to build appropriate background model, which is now becoming\nincreasingly complex as more sophisticated statistical approaches are\nintroduced to cover challenging situations and provide reliable detection. This\npaper reports a simple and intuitive statistical model based on deeper learning\nspatial correlation among pixels: For each observed pixel, we select a group of\nsupporting pixels with high correlation, and then use a single Gaussian to\nmodel the intensity deviations between the observed pixel and the supporting\nones. In addition, a multi-channel model updating is integrated on-line and a\ntemporal intensity constraint for each pixel is defined. Although this method\nis mainly designed for coping with sudden illumination changes, experimental\nresults using all the video sequences provided on changedetection.net validate\nit is comparable with other recent methods under various situations.\n", "versions": [{"version": "v1", "created": "Sat, 24 May 2014 07:30:31 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Liang", "Dong", ""], ["Kaneko", "Shun'ichi", ""]]}, {"id": "1405.6434", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Lingbo Wang, Yanwen Guo", "title": "Multi-view Metric Learning for Multi-view Video Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods on video summarization are designed to generate summaries\nfor single-view video records; and thus they cannot fully exploit the\nredundancy in multi-view video records. In this paper, we present a multi-view\nmetric learning framework for multi-view video summarization that combines the\nadvantages of maximum margin clustering with the disagreement minimization\ncriterion. The learning framework thus has the ability to find a metric that\nbest separates the data, and meanwhile to force the learned metric to maintain\noriginal intrinsic information between data points, for example geometric\ninformation. Facilitated by such a framework, a systematic solution to the\nmulti-view video summarization problem is developed. To the best of our\nknowledge, it is the first time to address multi-view video summarization from\nthe viewpoint of metric learning. The effectiveness of the proposed method is\ndemonstrated by experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 May 2014 22:35:19 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 22:56:21 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Fu", "Yanwei", ""], ["Wang", "Lingbo", ""], ["Guo", "Yanwen", ""]]}, {"id": "1405.6472", "submitter": "Julien Mairal", "authors": "Yuansi Chen (EECS, INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire Jean\n  Kuntzmann), Julien Mairal (INRIA Grenoble Rh\\^one-Alpes / LJK Laboratoire\n  Jean Kuntzmann), Zaid Harchaoui (INRIA Grenoble Rh\\^one-Alpes / LJK\n  Laboratoire Jean Kuntzmann)", "title": "Fast and Robust Archetypal Analysis for Representation Learning", "comments": null, "journal-ref": "CVPR 2014 - IEEE Conference on Computer Vision \\& Pattern\n  Recognition (2014)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit a pioneer unsupervised learning technique called archetypal\nanalysis, which is related to successful data analysis methods such as sparse\ncoding and non-negative matrix factorization. Since it was proposed, archetypal\nanalysis did not gain a lot of popularity even though it produces more\ninterpretable models than other alternatives. Because no efficient\nimplementation has ever been made publicly available, its application to\nimportant scientific problems may have been severely limited. Our goal is to\nbring back into favour archetypal analysis. We propose a fast optimization\nscheme using an active-set strategy, and provide an efficient open-source\nimplementation interfaced with Matlab, R, and Python. Then, we demonstrate the\nusefulness of archetypal analysis for computer vision tasks, such as codebook\nlearning, signal classification, and large image collection visualization.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 06:25:18 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Chen", "Yuansi", "", "EECS, INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire Jean\n  Kuntzmann"], ["Mairal", "Julien", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK Laboratoire\n  Jean Kuntzmann"], ["Harchaoui", "Zaid", "", "INRIA Grenoble Rh\u00f4ne-Alpes / LJK\n  Laboratoire Jean Kuntzmann"]]}, {"id": "1405.6563", "submitter": "Radu Horaud P", "authors": "Fabio Cuzzolin, Diana Mateus and Radu Horaud", "title": "Robust Temporally Coherent Laplacian Protrusion Segmentation of 3D\n  Articulated Bodies", "comments": "31 pages, 26 figures", "journal-ref": "International Journal of Computer Vision 112(1), 43-70, 2015", "doi": "10.1007/s11263-014-0754-0", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In motion analysis and understanding it is important to be able to fit a\nsuitable model or structure to the temporal series of observed data, in order\nto describe motion patterns in a compact way, and to discriminate between them.\nIn an unsupervised context, i.e., no prior model of the moving object(s) is\navailable, such a structure has to be learned from the data in a bottom-up\nfashion. In recent times, volumetric approaches in which the motion is captured\nfrom a number of cameras and a voxel-set representation of the body is built\nfrom the camera views, have gained ground due to attractive features such as\ninherent view-invariance and robustness to occlusions. Automatic, unsupervised\nsegmentation of moving bodies along entire sequences, in a temporally-coherent\nand robust way, has the potential to provide a means of constructing a\nbottom-up model of the moving body, and track motion cues that may be later\nexploited for motion classification. Spectral methods such as locally linear\nembedding (LLE) can be useful in this context, as they preserve \"protrusions\",\ni.e., high-curvature regions of the 3D volume, of articulated shapes, while\nimproving their separation in a lower dimensional space, making them in this\nway easier to cluster. In this paper we therefore propose a spectral approach\nto unsupervised and temporally-coherent body-protrusion segmentation along time\nsequences. Volumetric shapes are clustered in an embedding space, clusters are\npropagated in time to ensure coherence, and merged or split to accommodate\nchanges in the body's topology. Experiments on both synthetic and real\nsequences of dense voxel-set data are shown. This supports the ability of the\nproposed method to cluster body-parts consistently over time in a totally\nunsupervised fashion, its robustness to sampling density and shape quality, and\nits potential for bottom-up model construction\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 13:12:05 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Cuzzolin", "Fabio", ""], ["Mateus", "Diana", ""], ["Horaud", "Radu", ""]]}, {"id": "1405.6662", "submitter": "Suma Dawn", "authors": "Suma Dawn, Vikas Saxena, Bhudev Sharma", "title": "Cognitive-mapping and contextual pyramid based Digital Elevation Model\n  Registration and its effective storage using fractal based compression", "comments": "17 pages, 8 tables, and 3 figures; IJCSI International Journal of\n  Computer Science Issues, Vol. 10, Issue 3, No 1, May 2013, ISSN (Print):\n  1694-0814 | ISSN (Online): 1694-0784 (www.IJCSI.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Elevation models (DEM) are images having terrain information embedded\ninto them. Using cognitive mapping concepts for DEM registration, has evolved\nfrom this basic idea of using the mapping between the space to objects and\ndefining their relationships to form the basic landmarks that need to be\nmarked, stored and manipulated in and about the environment or other candidate\nenvironments, namely, in our case, the DEMs. The progressive two-level\nencapsulation of methods of geo-spatial cognition includes landmark knowledge\nand layout knowledge and can be useful for DEM registration. Space-based\napproach, that emphasizes on explicit extent of the environment under\nconsideration, and object-based approach, that emphasizes on the relationships\nbetween objects in the local environment being the two paradigms of cognitive\nmapping can be methodically integrated in this three-architecture for DEM\nregistration. Initially, P-model based segmentation is performed followed by\nlandmark formation for contextual mapping that uses contextual pyramid\nformation. Apart from landmarks being used for registration key-point finding,\nEuclidean distance based deformation calculation has been used for\ntransformation and change detection. Landmarks have been categorized to belong\nto either being flat-plain areas without much variation in the land heights;\npeaks that can be found when there is gradual increase in height as compared to\nthe flat areas; valleys, marked with gradual decrease in the height seen in\nDEM; and finally, ripple areas with very shallow crests and nadirs. Fractal\nbased compression was used for storage of co-registered DEMs. This method may\nfurther be extended for DEM-topographic map and DEM-to-remote sensed image\nregistration. Experimental results further cement the fact that DEM\nregistration may be effectively done using the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 9 May 2014 05:59:01 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Dawn", "Suma", ""], ["Saxena", "Vikas", ""], ["Sharma", "Bhudev", ""]]}, {"id": "1405.6914", "submitter": "Ivan Ivek", "authors": "Ivan Ivek", "title": "Supervised Dictionary Learning by a Variational Bayesian Group Sparse\n  Nonnegative Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) with group sparsity constraints is\nformulated as a probabilistic graphical model and, assuming some observed data\nhave been generated by the model, a feasible variational Bayesian algorithm is\nderived for learning model parameters. When used in a supervised learning\nscenario, NMF is most often utilized as an unsupervised feature extractor\nfollowed by classification in the obtained feature subspace. Having mapped the\nclass labels to a more general concept of groups which underlie sparsity of the\ncoefficients, what the proposed group sparse NMF model allows is incorporating\nclass label information to find low dimensional label-driven dictionaries which\nnot only aim to represent the data faithfully, but are also suitable for class\ndiscrimination. Experiments performed in face recognition and facial expression\nrecognition domains point to advantages of classification in such label-driven\nfeature subspaces over classification in feature subspaces obtained in an\nunsupervised manner.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 14:02:45 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Ivek", "Ivan", ""]]}, {"id": "1405.6922", "submitter": "Omid Aghazadeh", "authors": "Omid Aghazadeh and Stefan Carlsson", "title": "Large Scale, Large Margin Classification using Indefinite Similarity\n  Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of the popular kernelized support vector machines, they\nhave two major limitations: they are restricted to Positive Semi-Definite (PSD)\nkernels, and their training complexity scales at least quadratically with the\nsize of the data. Many natural measures of similarity between pairs of samples\nare not PSD e.g. invariant kernels, and those that are implicitly or explicitly\ndefined by latent variable models. In this paper, we investigate scalable\napproaches for using indefinite similarity measures in large margin frameworks.\nIn particular we show that a normalization of similarity to a subset of the\ndata points constitutes a representation suitable for linear classifiers. The\nresult is a classifier which is competitive to kernelized SVM in terms of\naccuracy, despite having better training and test time complexities.\nExperimental results demonstrate that on CIFAR-10 dataset, the model equipped\nwith similarity measures invariant to rigid and non-rigid deformations, can be\nmade more than 5 times sparser while being more accurate than kernelized SVM\nusing RBF kernels.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 14:18:26 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Aghazadeh", "Omid", ""], ["Carlsson", "Stefan", ""]]}, {"id": "1405.7032", "submitter": "Luo Tao", "authors": "Luo Tao and Shi zaifeng", "title": "An FPGA-based Parallel Architecture for Face Detection using Mixed Color\n  Models", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a reliable method for detecting human faces in color images is\nproposed. This system firstly detects skin color in YCgCr and YIQ color space,\nthen filters binary texture and the result is morphological processed, finally\nconverts skin tone to the preferred skin color configured by users in YIQ color\nspace. The real-time adjusting circuit is implemented and some of simulation\nresults are given out. Experimental results demonstrate that the method has\nachieved high rates and low false positives, another advantage is its\nsimplicity and minor computational costs.\n", "versions": [{"version": "v1", "created": "Tue, 27 May 2014 19:54:35 GMT"}], "update_date": "2014-05-28", "authors_parsed": [["Tao", "Luo", ""], ["zaifeng", "Shi", ""]]}, {"id": "1405.7102", "submitter": "Tim Althoff", "authors": "Tim Althoff, Hyun Oh Song, Trevor Darrell", "title": "Detection Bank: An Object Detection Based Video Representation for\n  Multimedia Event Recognition", "comments": "ACM Multimedia 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While low-level image features have proven to be effective representations\nfor visual recognition tasks such as object recognition and scene\nclassification, they are inadequate to capture complex semantic meaning\nrequired to solve high-level visual tasks such as multimedia event detection\nand recognition. Recognition or retrieval of events and activities can be\nimproved if specific discriminative objects are detected in a video sequence.\nIn this paper, we propose an image representation, called Detection Bank, based\non the detection images from a large number of windowed object detectors where\nan image is represented by different statistics derived from these detections.\nThis representation is extended to video by aggregating the key frame level\nimage representations through mean and max pooling. We empirically show that it\ncaptures complementary information to state-of-the-art representations such as\nSpatial Pyramid Matching and Object Bank. These descriptors combined with our\nDetection Bank representation significantly outperforms any of the\nrepresentations alone on TRECVID MED 2011 data.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 02:07:29 GMT"}, {"version": "v2", "created": "Sat, 14 Jun 2014 20:17:48 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Althoff", "Tim", ""], ["Song", "Hyun Oh", ""], ["Darrell", "Trevor", ""]]}, {"id": "1405.7229", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Felipe Sencion, Daniel Zaldivar, Marco Perez, Humberto\n  Sossa", "title": "A Multi-threshold Segmentation Approach Based on Artificial Bee Colony\n  Optimization", "comments": "16 Pages", "journal-ref": "Applied Intelligence 37 (3), (2012), pp. 321-336", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of the Artificial Bee Colony (ABC) algorithm to\ncompute threshold selection for image segmentation. ABC is a heuristic\nalgorithm motivated by the intelligent behavior of honey-bees which has been\nsuccessfully employed to solve complex optimization problems. In this approach,\nan image 1D histogram is approximated through a Gaussian mixture model whose\nparameters are calculated by the ABC algorithm. For the approximation scheme,\neach Gaussian function represents a pixel class and therefore a threshold.\nUnlike the Expectation Maximization (EM) algorithm, the ABC based method shows\nfast convergence and low sensitivity to initial conditions. Remarkably, it also\nimproves complex time consuming computations commonly required by\ngradient-based methods. Experimental results demonstrate the algorithms ability\nto perform automatic multi threshold selection yet showing interesting\nadvantages by comparison to other well known algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 13:39:20 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Cuevas", "Erik", ""], ["Sencion", "Felipe", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""], ["Sossa", "Humberto", ""]]}, {"id": "1405.7242", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Noe Ortega, Daniel Zaldivar, Marco Perez", "title": "Circle detection by Harmony Search Optimization", "comments": "18 Pages", "journal-ref": "Intelligent and Robotic Systems: Theory and Applications 66 (3),\n  (2013), pp. 359-376", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic circle detection in digital images has received considerable\nattention over the last years in computer vision as several efforts have aimed\nfor an optimal circle detector. This paper presents an algorithm for automatic\ndetection of circular shapes that considers the overall process as an\noptimization problem. The approach is based on the Harmony Search Algorithm\n(HSA), a derivative free meta-heuristic optimization algorithm inspired by\nmusicians while improvising new harmonies. The algorithm uses the encoding of\nthree points as candidate circles (harmonies) over the edge-only image. An\nobjective function evaluates (harmony quality) if such candidate circles are\nactually present in the edge image. Guided by the values of this objective\nfunction, the set of encoded candidate circles are evolved using the HSA so\nthat they can fit to the actual circles on the edge map of the image (optimal\nharmony). Experimental results from several tests on synthetic and natural\nimages with a varying complexity range have been included to validate the\nefficiency of the proposed technique regarding accuracy, speed and robustness.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 13:57:04 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Cuevas", "Erik", ""], ["Ortega", "Noe", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""]]}, {"id": "1405.7361", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Daniel Zaldivar and Marco Perez", "title": "Seeking multi-thresholds for image segmentation with Learning Automata", "comments": "22 Pages. arXiv admin note: text overlap with arXiv:1405.7229", "journal-ref": "Machine Vision and Applications 22 (5), (2011), pp. 805-818", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of the Learning Automata (LA) algorithm to\ncompute threshold selection for image segmentation as it is a critical\npreprocessing step for image analysis, pattern recognition and computer vision.\nLA is a heuristic method which is able to solve complex optimization problems\nwith interesting results in parameter estimation. Despite other techniques\ncommonly seek through the parameter map, LA explores in the probability space\nproviding appropriate convergence properties and robustness. The segmentation\ntask is therefore considered as an optimization problem and the LA is used to\ngenerate the image multi-threshold separation. In this approach, one 1D\nhistogram of a given image is approximated through a Gaussian mixture model\nwhose parameters are calculated using the LA algorithm. Each Gaussian function\napproximating the histogram represents a pixel class and therefore a threshold\npoint. The method shows fast convergence avoiding the typical sensitivity to\ninitial conditions such as the Expectation Maximization (EM) algorithm or the\ncomplex time-consuming computations commonly found in gradient methods.\nExperimental results demonstrate the algorithm ability to perform automatic\nmulti-threshold selection and show interesting advantages as it is compared to\nother algorithms solving the same task.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 14:06:17 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Cuevas", "Erik", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""]]}, {"id": "1405.7362", "submitter": "Erik Cuevas", "authors": "Erik Cuevas, Daniel Zaldivar, Marco Perez and Marte Ramirez", "title": "Circle detection using Discrete Differential Evolution Optimization", "comments": "20 Pages. arXiv admin note: text overlap with arXiv:1405.7242", "journal-ref": "Pattern Analysis and Applications 14 (1), (2011), pp. 93-107", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a circle detection method based on Differential\nEvolution (DE) optimization. Just as circle detection has been lately\nconsidered as a fundamental component for many computer vision algorithms, DE\nhas evolved as a successful heuristic method for solving complex optimization\nproblems, still keeping a simple structure and an easy implementation. It has\nalso shown advantageous convergence properties and remarkable robustness. The\ndetection process is considered similar to a combinational optimization\nproblem. The algorithm uses the combination of three edge points as parameters\nto determine circles candidates in the scene yielding a reduction of the search\nspace. The objective function determines if some circle candidates are actually\npresent in the image. This paper focuses particularly on one DE-based algorithm\nknown as the Discrete Differential Evolution (DDE), which eventually has shown\nbetter results than the original DE in particular for solving combinatorial\nproblems. In the DDE, suitable conversion routines are incorporated into the\nDE, aiming to operate from integer values to real values and then getting\ninteger values back, following the crossover operation. The final algorithm is\na fast circle detector that locates circles with sub-pixel accuracy even\nconsidering complicated conditions and noisy images. Experimental results on\nseveral synthetic and natural images with varying range of complexity validate\nthe efficiency of the proposed technique considering accuracy, speed, and\nrobustness.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 16:46:31 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Cuevas", "Erik", ""], ["Zaldivar", "Daniel", ""], ["Perez", "Marco", ""], ["Ramirez", "Marte", ""]]}, {"id": "1405.7406", "submitter": "Valent\\'in Osuna-Enciso Mr", "authors": "Valent\\'in Osuna-Enciso, Erik Cuevas, Humberto Sossa", "title": "A Comparison of Nature Inspired Algorithms for Multi-threshold Image\n  Segmentation", "comments": "16 pages, this is a draft of the final version of the article sent to\n  the Journal", "journal-ref": "Expert Systems with Applications, Volume 40, Issue 4, March 2013,\n  Pages 1213-1219", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of image analysis, segmentation is one of the most important\npreprocessing steps. One way to achieve segmentation is by mean of threshold\nselection, where each pixel that belongs to a determined class islabeled\naccording to the selected threshold, giving as a result pixel groups that share\nvisual characteristics in the image. Several methods have been proposed in\norder to solve threshold selectionproblems; in this work, it is used the method\nbased on the mixture of Gaussian functions to approximate the 1D histogram of a\ngray level image and whose parameters are calculated using three nature\ninspired algorithms (Particle Swarm Optimization, Artificial Bee Colony\nOptimization and Differential Evolution). Each Gaussian function approximates\nthehistogram, representing a pixel class and therefore a threshold point.\nExperimental results are shown, comparing in quantitative and qualitative\nfashion as well as the main advantages and drawbacks of each algorithm, applied\nto multi-threshold problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 21:40:31 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Osuna-Enciso", "Valent\u00edn", ""], ["Cuevas", "Erik", ""], ["Sossa", "Humberto", ""]]}, {"id": "1405.7545", "submitter": "Michael Sapienza", "authors": "Michael Sapienza and Fabio Cuzzolin and Philip H.S. Torr", "title": "Feature sampling and partitioning for visual vocabulary generation on\n  large action classification datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent trend in action recognition is towards larger datasets, an\nincreasing number of action classes and larger visual vocabularies.\nState-of-the-art human action classification in challenging video data is\ncurrently based on a bag-of-visual-words pipeline in which space-time features\nare aggregated globally to form a histogram. The strategies chosen to sample\nfeatures and construct a visual vocabulary are critical to performance, in fact\noften dominating performance. In this work we provide a critical evaluation of\nvarious approaches to building a vocabulary and show that good practises do\nhave a significant impact. By subsampling and partitioning features\nstrategically, we are able to achieve state-of-the-art results on 5 major\naction recognition datasets using relatively small visual vocabularies.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 13:09:52 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Sapienza", "Michael", ""], ["Cuzzolin", "Fabio", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1405.7626", "submitter": "Rubi Kambo", "authors": "Rubi Kambo, Amit Yerpude", "title": "Classification of Basmati Rice Grain Variety using Image Processing and\n  Principal Component Analysis", "comments": "6 pages from page no:80-85, 8 Figures", "journal-ref": "IJAREEIE, vol. 2, no. 7, pp. 2893-2900, july 2013", "doi": "10.14445/22312803/IJCTT-V11P117", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All important decisions about the variety of rice grain end product are based\non the different features of rice grain.There are various methods available for\nclassification of basmati rice. This paper proposed a new principal component\nanalysis based approach for classification of different variety of basmati\nrice. The experimental result shows the effectiveness of the proposed\nmethodology for various samples of different variety of basmati rice.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 17:41:06 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Kambo", "Rubi", ""], ["Yerpude", "Amit", ""]]}, {"id": "1405.7718", "submitter": "Sajan Goud Lingala", "authors": "Sajan Goud Lingala, Edward DiBella, Mathews Jacob", "title": "Deformation corrected compressed sensing (DC-CS): a novel framework for\n  accelerated dynamic MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deformation corrected compressed sensing (DC-CS) framework\nto recover dynamic magnetic resonance images from undersampled measurements. We\nintroduce a generalized formulation that is capable of handling a wide class of\nsparsity/compactness priors on the deformation corrected dynamic signal. In\nthis work, we consider example compactness priors such as sparsity in temporal\nFourier domain, sparsity in temporal finite difference domain, and nuclear norm\npenalty to exploit low rank structure. Using variable splitting, we decouple\nthe complex optimization problem to simpler and well understood sub problems;\nthe resulting algorithm alternates between simple steps of shrinkage based\ndenoising, deformable registration, and a quadratic optimization step.\nAdditionally, we employ efficient continuation strategies to minimize the risk\nof convergence to local minima. The proposed formulation contrasts with\nexisting DC-CS schemes that are customized for free breathing cardiac cine\napplications, and other schemes that rely on fully sampled reference frames or\nnavigator signals to estimate the deformation parameters. The efficient\ndecoupling enabled by the proposed scheme allows its application to a wide\nrange of applications including contrast enhanced dynamic MRI. Through\nexperiments on numerical phantom and in vivo myocardial perfusion MRI datasets,\nwe demonstrate the utility of the proposed DC-CS scheme in providing robust\nreconstructions with reduced motion artifacts over classical compressed sensing\nschemes that utilize the compact priors on the original deformation\nun-corrected signal.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 20:36:39 GMT"}, {"version": "v2", "created": "Tue, 2 Sep 2014 23:03:52 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Lingala", "Sajan Goud", ""], ["DiBella", "Edward", ""], ["Jacob", "Mathews", ""]]}, {"id": "1405.7771", "submitter": "Suma Dawn", "authors": "Suma Dawn, Vikas Saxena, and Bhu Dev Sharma", "title": "DEM Registration and Error Analysis using ASCII values", "comments": "10 pages, 4 figures, 1 table, Proceeding of International Conference\n  on Signal Processing and Imaging Engineering 2010, San Francisco, USA, 20-22\n  October 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Elevation Model (DEM), while providing a bare earth look, is heavily\nused in many applications including construction modeling, visualization, and\nGIS. Their registration techniques have not been explored much. Methods like\nCoarse-to-fine or pyramid making are common in DEM-to-image or DEM-to-map\nregistration. Self-consistency measure is used to detect any change in terrain\nelevation and hence was used for DEM-to-DEM registration. But these methods\napart from being time and complexity intensive, lack in error matrix\nevaluation. This paper gives a method of registration of DEMs using specified\nheight values as control points by initially converting these DEMs to ASCII\nfiles. These control points may be found by two mannerisms - either by direct\ndetection of appropriate height data in ASCII files or by edge matching along\ncongruous quadrangle of the control point, followed by sub-graph matching.\nError analysis for the same has also been done.\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2014 04:34:10 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Dawn", "Suma", ""], ["Saxena", "Vikas", ""], ["Sharma", "Bhu Dev", ""]]}, {"id": "1405.7903", "submitter": "Carsten Gottschlich", "authors": "Carsten Gottschlich and Dominic Schuhmacher", "title": "The Shortlist Method for Fast Computation of the Earth Mover's Distance\n  and Finding Optimal Solutions to Transportation Problems", "comments": null, "journal-ref": "PLOS ONE 9(10): e110214, Oct. 2014", "doi": "10.1371/journal.pone.0110214", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding solutions to the classical transportation problem is of great\nimportance, since this optimization problem arises in many engineering and\ncomputer science applications. Especially the Earth Mover's Distance is used in\na plethora of applications ranging from content-based image retrieval, shape\nmatching, fingerprint recognition, object tracking and phishing web page\ndetection to computing color differences in linguistics and biology. Our\nstarting point is the well-known revised simplex algorithm, which iteratively\nimproves a feasible solution to optimality. The Shortlist Method that we\npropose substantially reduces the number of candidates inspected for improving\nthe solution, while at the same time balancing the number of pivots required.\nTests on simulated benchmarks demonstrate a considerable reduction in\ncomputation time for the new method as compared to the usual revised simplex\nalgorithm implemented with state-of-the-art initialization and pivot\nstrategies. As a consequence, the Shortlist Method facilitates the computation\nof large scale transportation problems in viable time. In addition we describe\na novel method for finding an initial feasible solution which we coin Modified\nRussell's Method.\n", "versions": [{"version": "v1", "created": "Fri, 30 May 2014 16:07:55 GMT"}], "update_date": "2014-10-15", "authors_parsed": [["Gottschlich", "Carsten", ""], ["Schuhmacher", "Dominic", ""]]}]