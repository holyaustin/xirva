[{"id": "0907.0204", "submitter": "Ghassan Hamarneh", "authors": "Ghassan Hamarneh", "title": "Multi-Label MRF Optimization via Least Squares s-t Cuts", "comments": null, "journal-ref": null, "doi": null, "report-no": "SFU-CMPT-TR 2009-08", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many applications of graph cuts in computer vision, e.g.\nsegmentation. We present a novel method to reformulate the NP-hard, k-way graph\npartitioning problem as an approximate minimal s-t graph cut problem, for which\na globally optimal solution is found in polynomial time. Each non-terminal\nvertex in the original graph is replaced by a set of ceil(log_2(k)) new\nvertices. The original graph edges are replaced by new edges connecting the new\nvertices to each other and to only two, source s and sink t, terminal nodes.\nThe weights of the new edges are obtained using a novel least squares solution\napproximating the constraints of the initial k-way setup. The minimal s-t cut\nlabels each new vertex with a binary (s vs t) \"Gray\" encoding, which is then\ndecoded into a decimal label number that assigns each of the original vertices\nto one of k classes. We analyze the properties of the approximation and present\nquantitative as well as qualitative segmentation results.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2009 17:18:46 GMT"}], "update_date": "2009-07-02", "authors_parsed": [["Hamarneh", "Ghassan", ""]]}, {"id": "0907.0288", "submitter": "Simant Dube", "authors": "Simant Dube", "title": "An Iterative Fingerprint Enhancement Algorithm Based on Accurate\n  Determination of Orientation Flow", "comments": "10 pages, 4 figures. Ongoing work. To be submitted to appropriate\n  conference/journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an algorithm to enhance and binarize a fingerprint image. The\nalgorithm is based on accurate determination of orientation flow of the ridges\nof the fingerprint image by computing variance of the neighborhood pixels\naround a pixel in different directions. We show that an iterative algorithm\nwhich captures the mutual interdependence of orientation flow computation,\nenhancement and binarization gives very good results on poor quality images.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2009 04:57:32 GMT"}], "update_date": "2009-07-03", "authors_parsed": [["Dube", "Simant", ""]]}, {"id": "0907.0418", "submitter": "Gary Huang", "authors": "Andrew Kae, Gary B. Huang, Erik Learned-Miller", "title": "Bounding the Probability of Error for High Precision Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": "UM-CS-2009-031", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider models for which it is important, early in processing, to\nestimate some variables with high precision, but perhaps at relatively low\nrates of recall. If some variables can be identified with near certainty, then\nthey can be conditioned upon, allowing further inference to be done\nefficiently. Specifically, we consider optical character recognition (OCR)\nsystems that can be bootstrapped by identifying a subset of correctly\ntranslated document words with very high precision. This \"clean set\" is\nsubsequently used as document-specific training data. While many current OCR\nsystems produce measures of confidence for the identity of each letter or word,\nthresholding these confidence values, even at very high values, still produces\nsome errors.\n  We introduce a novel technique for identifying a set of correct words with\nvery high precision. Rather than estimating posterior probabilities, we bound\nthe probability that any given word is incorrect under very general\nassumptions, using an approximate worst case analysis. As a result, the\nparameters of the model are nearly irrelevant, and we are able to identify a\nsubset of words, even in noisy documents, of which we are highly confident. On\nour set of 10 documents, we are able to identify about 6% of the words on\naverage without making a single error. This ability to produce word lists with\nvery high precision allows us to use a family of models which depends upon such\nclean word lists.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2009 16:09:47 GMT"}], "update_date": "2009-07-03", "authors_parsed": [["Kae", "Andrew", ""], ["Huang", "Gary B.", ""], ["Learned-Miller", "Erik", ""]]}, {"id": "0907.1545", "submitter": "Se Baek Oh", "authors": "Se Baek Oh, George Barbastathis, and Ramesh Raskar", "title": "Augmenting Light Field to model Wave Optics effects", "comments": "Covering some of the topics presented in CVPR 2009 short course on\n  light field: Present and Future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ray-based 4D light field representation cannot be directly used to\nanalyze diffractive or phase--sensitive optical elements. In this paper, we\nexploit tools from wave optics and extend the light field representation via a\nnovel \"light field transform\". We introduce a key modification to the\nray--based model to support the transform. We insert a \"virtual light source\",\nwith potentially negative valued radiance for certain emitted rays. We create a\nlook-up table of light field transformers of canonical optical elements. The\ntwo key conclusions are that (i) in free space, the 4D light field completely\nrepresents wavefront propagation via rays with real (positive as well as\nnegative) valued radiance and (ii) at occluders, a light field composed of\nlight field transformers plus insertion of (ray--based) virtual light sources\nrepresents resultant phase and amplitude of wavefronts. For free--space\npropagation, we analyze different wavefronts and coherence possibilities. For\noccluders, we show that the light field transform is simply based on a\nconvolution followed by a multiplication operation. This formulation brings\npowerful concepts from wave optics to computer vision and graphics. We show\napplications in cubic-phase plate imaging and holographic displays.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2009 13:43:12 GMT"}], "update_date": "2009-07-10", "authors_parsed": [["Oh", "Se Baek", ""], ["Barbastathis", "George", ""], ["Raskar", "Ramesh", ""]]}, {"id": "0907.2075", "submitter": "Ula\\c{s} Ba\\u{g}ci", "authors": "Ulas Bagci and Li Bai", "title": "Multiresolution Elastic Medical Image Registration in Standard Intensity\n  Scale", "comments": "IEEE Sibgrapi 2007 submission", "journal-ref": "IEEE 20th Brazilian Symposium on Computer Graphics and Image\n  Processing (SIBGRAPI-07), Belo Horizonte-Minas Gerais, Brasil, October 7-10,\n  2007", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image registration is a difficult problem. Not only a registration\nalgorithm needs to capture both large and small scale image deformations, it\nalso has to deal with global and local image intensity variations. In this\npaper we describe a new multiresolution elastic image registration method that\nchallenges these difficulties in image registration. To capture large and small\nscale image deformations, we use both global and local affine transformation\nalgorithms. To address global and local image intensity variations, we apply an\nimage intensity standardization algorithm to correct image intensity\nvariations. This transforms image intensities into a standard intensity scale,\nwhich allows highly accurate registration of medical images.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2009 22:39:34 GMT"}], "update_date": "2009-07-14", "authors_parsed": [["Bagci", "Ulas", ""], ["Bai", "Li", ""]]}, {"id": "0907.3209", "submitter": "Ula\\c{s} Ba\\u{g}ci", "authors": "Ulas Bagci and Li Bai", "title": "Registration of Standardized Histological Images in Feature Space", "comments": "SPIE Medical Imaging 2008 - submission", "journal-ref": "SPIE Medical Imaging 2008: Image Processing. Edited by Reinhardt,\n  Joseph M.; Pluim, Josien P. W. Proceedings of the SPIE, Volume 6914, pp.\n  69142V-69142V-9 (2008)", "doi": "10.1117/12.770219", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose three novel and important methods for the\nregistration of histological images for 3D reconstruction. First, possible\nintensity variations and nonstandardness in images are corrected by an\nintensity standardization process which maps the image scale into a standard\nscale where the similar intensities correspond to similar tissues meaning.\nSecond, 2D histological images are mapped into a feature space where continuous\nvariables are used as high confidence image features for accurate registration.\nThird, we propose an automatic best reference slice selection algorithm that\nimproves reconstruction quality based on both image entropy and mean square\nerror of the registration process. We demonstrate that the choice of reference\nslice has a significant impact on registration error, standardization, feature\nspace and entropy information. After 2D histological slices are registered\nthrough an affine transformation with respect to an automatically chosen\nreference, the 3D volume is reconstructed by co-registering 2D slices\nelastically.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2009 11:28:41 GMT"}], "update_date": "2009-07-21", "authors_parsed": [["Bagci", "Ulas", ""], ["Bai", "Li", ""]]}, {"id": "0907.3215", "submitter": "Ula\\c{s} Ba\\u{g}ci", "authors": "Ulas Bagci and Li Bai", "title": "Fully Automatic 3D Reconstruction of Histological Images", "comments": "IEEE ISBI-08 Submission", "journal-ref": "5th IEEE International Symposium on Biomedical Imaging: From Nano\n  to Macro ISBI-08, pp. 591-594. 2008", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a computational framework for 3D volume\nreconstruction from 2D histological slices using registration algorithms in\nfeature space. To improve the quality of reconstructed 3D volume, first,\nintensity variations in images are corrected by an intensity standardization\nprocess which maps image intensity scale to a standard scale where similar\nintensities correspond to similar tissues. Second, a subvolume approach is\nproposed for 3D reconstruction by dividing standardized slices into groups.\nThird, in order to improve the quality of the reconstruction process, an\nautomatic best reference slice selection algorithm is developed based on an\niterative assessment of image entropy and mean square error of the registration\nprocess. Finally, we demonstrate that the choice of the reference slice has a\nsignificant impact on registration quality and subsequent 3D reconstruction.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2009 12:32:27 GMT"}], "update_date": "2009-07-21", "authors_parsed": [["Bagci", "Ulas", ""], ["Bai", "Li", ""]]}, {"id": "0907.3218", "submitter": "Ula\\c{s} Ba\\u{g}ci", "authors": "Ulas Bagci and Li Bai", "title": "Parallel AdaBoost Algorithm for Gabor Wavelet Selection in Face\n  Recognition", "comments": "IEEE ICIP 2008 Submission", "journal-ref": "IEEE International Conference on Image Processing (ICIP-08), San\n  Diego, CA, U.S.A, 12-15 October, 2008", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of automatic Gabor wavelet selection for face\nrecognition is tackled by introducing an automatic algorithm based on Parallel\nAdaBoosting method. Incorporating mutual information into the algorithm leads\nto the selection procedure not only based on classification accuracy but also\non efficiency. Effective image features are selected by using properly chosen\nGabor wavelets optimised with Parallel AdaBoost method and mutual information\nto get high recognition rates with low computational cost. Experiments are\nconducted using the well-known FERET face database. In proposed framework,\nmemory and computation costs are reduced significantly and high classification\naccuracy is obtained.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2009 13:03:19 GMT"}], "update_date": "2009-07-21", "authors_parsed": [["Bagci", "Ulas", ""], ["Bai", "Li", ""]]}, {"id": "0907.3604", "submitter": "Mark Grundland", "authors": "Mark Grundland, Jiri Patera, Zuzana Masakova and Neil A. Dodgson", "title": "Image Sampling with Quasicrystals", "comments": "For a full resolution version of this paper, along with supplementary\n  materials, please visit at\n  http://www.Eyemaginary.com/Portfolio/Publications.html", "journal-ref": "SIGMA 5 (2009), 075, 23 pages", "doi": "10.3842/SIGMA.2009.075", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We investigate the use of quasicrystals in image sampling. Quasicrystals\nproduce space-filling, non-periodic point sets that are uniformly discrete and\nrelatively dense, thereby ensuring the sample sites are evenly spread out\nthroughout the sampled image. Their self-similar structure can be attractive\nfor creating sampling patterns endowed with a decorative symmetry. We present a\nbrief general overview of the algebraic theory of cut-and-project quasicrystals\nbased on the geometry of the golden ratio. To assess the practical utility of\nquasicrystal sampling, we evaluate the visual effects of a variety of\nnon-adaptive image sampling strategies on photorealistic image reconstruction\nand non-photorealistic image rendering used in multiresolution image\nrepresentations. For computer visualization of point sets used in image\nsampling, we introduce a mosaic rendering technique.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2009 10:08:48 GMT"}], "update_date": "2009-07-22", "authors_parsed": [["Grundland", "Mark", ""], ["Patera", "Jiri", ""], ["Masakova", "Zuzana", ""], ["Dodgson", "Neil A.", ""]]}, {"id": "0907.4354", "submitter": "Damian Eads", "authors": "Damian Eads (1), Edward Rosten (2), David Helmbold (1) ((1) University\n  of California Santa Cruz, (2) University of Cambridge)", "title": "Learning Object Location Predictors with Boosting and Grammar-Guided\n  Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BEAMER: a new spatially exploitative approach to learning object\ndetectors which shows excellent results when applied to the task of detecting\nobjects in greyscale aerial imagery in the presence of ambiguous and noisy\ndata. There are four main contributions used to produce these results. First,\nwe introduce a grammar-guided feature extraction system, enabling the\nexploration of a richer feature space while constraining the features to a\nuseful subset. This is specified with a rule-based generative grammar crafted\nby a human expert. Second, we learn a classifier on this data using a newly\nproposed variant of AdaBoost which takes into account the spatially correlated\nnature of the data. Third, we perform another round of training to optimize the\nmethod of converting the pixel classifications generated by boosting into a\nhigh quality set of (x, y) locations. Lastly, we carefully define three common\nproblems in object detection and define two evaluation criteria that are\ntightly matched to these problems. Major strengths of this approach are: (1) a\nway of randomly searching a broad feature space, (2) its performance when\nevaluated on well-matched evaluation criteria, and (3) its use of the location\nprediction domain to learn object detectors as well as to generate detections\nthat perform well on several tasks: object counting, tracking, and target\ndetection. We demonstrate the efficacy of BEAMER with a comprehensive\nexperimental evaluation on a challenging data set.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2009 18:01:08 GMT"}], "update_date": "2009-07-27", "authors_parsed": [["Eads", "Damian", ""], ["Rosten", "Edward", ""], ["Helmbold", "David", ""]]}, {"id": "0907.4984", "submitter": "R Doomun", "authors": "Yousra Ben Jemaa, Sana Khanfir", "title": "Automatic local Gabor Features extraction for face recognition", "comments": "7 pages, International Journal of Computer Science and Information\n  Security, IJCSIS, Impact Factor 0.423", "journal-ref": "IJCSIS July 2009, Volume 3, ISSN 1947 5500", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a biometric system of face detection and recognition\nin color images. The face detection technique is based on skin color\ninformation and fuzzy classification. A new algorithm is proposed in order to\ndetect automatically face features (eyes, mouth and nose) and extract their\ncorrespondent geometrical points. These fiducial points are described by sets\nof wavelet components which are used for recognition. To achieve the face\nrecognition, we use neural networks and we study its performances for different\ninputs. We compare the two types of features used for recognition: geometric\ndistances and Gabor coefficients which can be used either independently or\njointly. This comparison shows that Gabor coefficients are more powerful than\ngeometric distances. We show with experimental results how the importance\nrecognition ratio makes our system an effective tool for automatic face\ndetection and recognition.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2009 20:02:15 GMT"}], "update_date": "2009-07-30", "authors_parsed": [["Jemaa", "Yousra Ben", ""], ["Khanfir", "Sana", ""]]}, {"id": "0907.5321", "submitter": "Tomoya Sakai", "authors": "Tomoya Sakai", "title": "Multiple pattern classification by sparse subspace decomposition", "comments": "8 pages, 3 figures, 2nd IEEE International Workshop on Subspace\n  Methods, Workshop Proceedings of ICCV 2009", "journal-ref": null, "doi": "10.1109/ICCVW.2009.5457702", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust classification method is developed on the basis of sparse subspace\ndecomposition. This method tries to decompose a mixture of subspaces of\nunlabeled data (queries) into class subspaces as few as possible. Each query is\nclassified into the class whose subspace significantly contributes to the\ndecomposed subspace. Multiple queries from different classes can be\nsimultaneously classified into their respective classes. A practical greedy\nalgorithm of the sparse subspace decomposition is designed for the\nclassification. The present method achieves high recognition rate and robust\nperformance exploiting joint sparsity.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2009 12:23:25 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2009 06:01:53 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Sakai", "Tomoya", ""]]}]