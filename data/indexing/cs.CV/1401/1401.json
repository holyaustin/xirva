[{"id": "1401.0092", "submitter": "Shraddha Shinde", "authors": "Shraddha S. Shinde and Prof. Anagha P. Khedkar", "title": "A Novel Approach For Generating Face Template Using Bda", "comments": "11 pages, ITCSE 2013 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In identity management system, commonly used biometric recognition system\nneeds attention towards issue of biometric template protection as far as more\nreliable solution is concerned. In view of this biometric template protection\nalgorithm should satisfy security, discriminability and cancelability. As no\nsingle template protection method is capable of satisfying the basic\nrequirements, a novel technique for face template generation and protection is\nproposed. The novel approach is proposed to provide security and accuracy in\nnew user enrollment as well as authentication process. This novel technique\ntakes advantage of both the hybrid approach and the binary discriminant\nanalysis algorithm. This algorithm is designed on the basis of random\nprojection, binary discriminant analysis and fuzzy commitment scheme. Three\npublicly available benchmark face databases are used for evaluation. The\nproposed novel technique enhances the discriminability and recognition accuracy\nby 80% in terms of matching score of the face images and provides high\nsecurity.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 04:48:43 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Shinde", "Shraddha S.", ""], ["Khedkar", "Prof. Anagha P.", ""]]}, {"id": "1401.0131", "submitter": "Avinash Bhute", "authors": "Avinash N Bhute and B B Meshram", "title": "System Analysis And Design For Multimedia Retrieval Systems", "comments": "20 pages, 12 Figures. arXiv admin note: substantial text overlap with\n  arXiv:1211.4683", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.5, No.6, December 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the extensive use of information technology and the recent\ndevelopments in multimedia systems, the amount of multimedia data available to\nusers has increased exponentially. Video is an example of multimedia data as it\ncontains several kinds of data such as text, image, meta-data, visual and\naudio. Content based video retrieval is an approach for facilitating the\nsearching and browsing of large multimedia collections over WWW. In order to\ncreate an effective video retrieval system, visual perception must be taken\ninto account. We conjectured that a technique which employs multiple features\nfor indexing and retrieval would be more effective in the discrimination and\nsearch tasks of videos. In order to validate this, content based indexing and\nretrieval systems were implemented using color histogram, Texture feature\n(GLCM), edge density and motion..\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 11:17:42 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Bhute", "Avinash N", ""], ["Meshram", "B B", ""]]}, {"id": "1401.0166", "submitter": "Alex James Dr", "authors": "A.P. James, B. V. Dasarathy", "title": "Medical Image Fusion: A survey of the state of the art", "comments": "Information Fusion, 2014", "journal-ref": null, "doi": "10.1016/j.inffus.2013.12.002", "report-no": null, "categories": "cs.CV cs.AI physics.med-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Medical image fusion is the process of registering and combining multiple\nimages from single or multiple imaging modalities to improve the imaging\nquality and reduce randomness and redundancy in order to increase the clinical\napplicability of medical images for diagnosis and assessment of medical\nproblems. Multi-modal medical image fusion algorithms and devices have shown\nnotable achievements in improving clinical accuracy of decisions based on\nmedical images. This review article provides a factual listing of methods and\nsummarizes the broad scientific challenges faced in the field of medical image\nfusion. We characterize the medical image fusion research based on (1) the\nwidely used image fusion methods, (2) imaging modalities, and (3) imaging of\norgans that are under study. This review concludes that even though there\nexists several open ended technological and scientific challenges, the fusion\nof medical images has proved to be useful for advancing the clinical\nreliability of using medical imaging for medical diagnostics and analysis, and\nis a scientific discipline that has the potential to significantly grow in the\ncoming years.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 16:03:17 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["James", "A. P.", ""], ["Dasarathy", "B. V.", ""]]}, {"id": "1401.0395", "submitter": "Trupti Kodinariya prof", "authors": "Trupti M. Kodinariya", "title": "Hybrid Approach to Face Recognition System using Principle component and\n  Independent component with score based fusion process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid approach has a special status among Face Recognition Systems as they\ncombine different recognition approaches in an either serial or parallel to\novercome the shortcomings of individual methods. This paper explores the area\nof Hybrid Face Recognition using score based strategy as a combiner/fusion\nprocess. In proposed approach, the recognition system operates in two modes:\ntraining and classification. Training mode involves normalization of the face\nimages (training set), extracting appropriate features using Principle\nComponent Analysis (PCA) and Independent Component Analysis (ICA). The\nextracted features are then trained in parallel using Back-propagation neural\nnetworks (BPNNs) to partition the feature space in to different face classes.\nIn classification mode, the trained PCA BPNN and ICA BPNN are fed with new face\nimage(s). The score based strategy which works as a combiner is applied to the\nresults of both PCA BPNN and ICA BPNN to classify given new face image(s)\naccording to face classes obtained during the training mode. The proposed\napproach has been tested on ORL and other face databases; the experimented\nresults show that the proposed system has higher accuracy than face recognition\nsystems using single feature extractor.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 09:21:24 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Kodinariya", "Trupti M.", ""]]}, {"id": "1401.0486", "submitter": "Najiba Tagougui", "authors": "Najiba Tagougui, Houcine Boubaker, Monji Kherallah, Adel M. ALIMI", "title": "A Hybrid NN/HMM Modeling Technique for Online Arabic Handwriting\n  Recognition", "comments": null, "journal-ref": "International Journal of Computational Linguistics Research Volume\n  4 Number 3 September 2013 pp. 107-118", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a hybrid NN/HMM model for online Arabic handwriting\nrecognition. The proposed system is based on Hidden Markov Models (HMMs) and\nMulti Layer Perceptron Neural Networks (MLPNNs). The input signal is segmented\nto continuous strokes called segments based on the Beta-Elliptical strategy by\ninspecting the extremum points of the curvilinear velocity profile. A neural\nnetwork trained with segment level contextual information is used to extract\nclass character probabilities. The output of this network is decoded by HMMs to\nprovide character level recognition. In evaluations on the ADAB database, we\nachieved 96.4% character recognition accuracy that is statistically\nsignificantly important in comparison with character recognition accuracies\nobtained from state-of-the-art online Arabic systems.8\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 17:58:27 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Tagougui", "Najiba", ""], ["Boubaker", "Houcine", ""], ["Kherallah", "Monji", ""], ["ALIMI", "Adel M.", ""]]}, {"id": "1401.0583", "submitter": "Garrett Warnell", "authors": "Garrett Warnell, Sourabh Bhattacharya, Rama Chellappa, Tamer Basar", "title": "Adaptive-Rate Compressive Sensing Using Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two novel adaptive-rate compressive sensing (CS) strategies for\nsparse, time-varying signals using side information. Our first method utilizes\nextra cross-validation measurements, and the second one exploits extra\nlow-resolution measurements. Unlike the majority of current CS techniques, we\ndo not assume that we know an upper bound on the number of significant\ncoefficients that comprise the images in the video sequence. Instead, we use\nthe side information to predict the number of significant coefficients in the\nsignal at the next time instant. For each image in the video sequence, our\ntechniques specify a fixed number of spatially-multiplexed CS measurements to\nacquire, and adjust this quantity from image to image. Our strategies are\ndeveloped in the specific context of background subtraction for surveillance\nvideo, and we experimentally validate the proposed methods on real video\nsequences.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 04:01:29 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Warnell", "Garrett", ""], ["Bhattacharya", "Sourabh", ""], ["Chellappa", "Rama", ""], ["Basar", "Tamer", ""]]}, {"id": "1401.0689", "submitter": "Ankush Roy", "authors": "Ankush Roy, Biswajit Halder, Utpal Garain, David S. Doermann", "title": "Machine Assisted Authentication of Paper Currency: an Experiment on\n  Indian Banknotes", "comments": "There were several errors in the experimental section which we are\n  looking into", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic authentication of paper money has been targeted. Indian bank notes\nare taken as reference to show how a system can be developed for discriminating\nfake notes from genuine ones. Image processing and pattern recognition\ntechniques are used to design the overall approach. The ability of the embedded\nsecurity aspects is thoroughly analysed for detecting fake currencies. Real\nforensic samples are involved in the experiment that shows a high precision\nmachine can be developed for authentication of paper money. The system\nperformance is reported in terms of both accuracy and processing speed.\nComparison with human subjects namely forensic experts and bank staffs clearly\nshows its applicability for mass checking of currency notes in the real world.\nThe analysis of security features to protect counterfeiting highlights some\nfacts that should be taken care of in future designing of currency notes.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 18:12:05 GMT"}, {"version": "v2", "created": "Fri, 7 Nov 2014 23:14:03 GMT"}, {"version": "v3", "created": "Thu, 22 Jan 2015 02:08:03 GMT"}, {"version": "v4", "created": "Wed, 6 May 2015 07:49:16 GMT"}, {"version": "v5", "created": "Fri, 5 Jun 2015 23:14:19 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Roy", "Ankush", ""], ["Halder", "Biswajit", ""], ["Garain", "Utpal", ""], ["Doermann", "David S.", ""]]}, {"id": "1401.0730", "submitter": "Ahmet Iscen", "authors": "Ahmet Iscen, Anil Armagan, Pinar Duygulu", "title": "What is usual in unusual videos? Trajectory snippet histograms for\n  discovering unusualness", "comments": null, "journal-ref": "Computer Vision and Pattern Recognition Workshops (CVPRW), 2014\n  IEEE Conference on", "doi": "10.1109/CVPRW.2014.123", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unusual events are important as being possible indicators of undesired\nconsequences. Moreover, unusualness in everyday life activities may also be\namusing to watch as proven by the popularity of such videos shared in social\nmedia. Discovery of unusual events in videos is generally attacked as a problem\nof finding usual patterns, and then separating the ones that do not resemble to\nthose. In this study, we address the problem from the other side, and try to\nanswer what type of patterns are shared among unusual videos that make them\nresemble to each other regardless of the ongoing event. With this challenging\nproblem at hand, we propose a novel descriptor to encode the rapid motions in\nvideos utilizing densely extracted trajectories. The proposed descriptor, which\nis referred to as trajectory snipped histograms, is used to distinguish unusual\nvideos from usual videos, and further exploited to discover snapshots in which\nunusualness happen. Experiments on domain specific people falling videos and\nunrestricted funny videos show the effectiveness of our method in capturing\nunusualness.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 21:00:33 GMT"}, {"version": "v2", "created": "Sun, 2 Nov 2014 21:52:51 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Iscen", "Ahmet", ""], ["Armagan", "Anil", ""], ["Duygulu", "Pinar", ""]]}, {"id": "1401.0733", "submitter": "Ahmet Iscen", "authors": "Ahmet Iscen, Eren Golge, Ilker Sarac, Pinar Duygulu", "title": "ConceptVision: A Flexible Scene Classification Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ConceptVision, a method that aims for high accuracy in\ncategorizing large number of scenes, while keeping the model relatively simpler\nand efficient for scalability. The proposed method combines the advantages of\nboth low-level representations and high-level semantic categories, and\neliminates the distinctions between different levels through the definition of\nconcepts. The proposed framework encodes the perspectives brought through\ndifferent concepts by considering them in concept groups. Different\nperspectives are ensembled for the final decision. Extensive experiments are\ncarried out on benchmark datasets to test the effects of different concepts,\nand methods used to ensemble. Comparisons with state-of-the-art studies show\nthat we can achieve better results with incorporation of concepts in different\nlevels with different perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 21:15:13 GMT"}, {"version": "v2", "created": "Wed, 29 Oct 2014 20:19:35 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Iscen", "Ahmet", ""], ["Golge", "Eren", ""], ["Sarac", "Ilker", ""], ["Duygulu", "Pinar", ""]]}, {"id": "1401.0764", "submitter": "Chunhua Shen", "authors": "Xi Li, Weiming Hu, Chunhua Shen, Anthony Dick, Zhongfei Zhang", "title": "Context-Aware Hypergraph Construction for Robust Spectral Clustering", "comments": "10 pages. Appearing in IEEE TRANSACTIONS ON KNOWLEDGE AND DATA\n  ENGINEERING: http://doi.ieeecomputersociety.org/10.1109/TKDE.2013.126", "journal-ref": null, "doi": "10.1109/TKDE.2013.126", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a powerful tool for unsupervised data analysis. In\nthis paper, we propose a context-aware hypergraph similarity measure (CAHSM),\nwhich leads to robust spectral clustering in the case of noisy data. We\nconstruct three types of hypergraph---the pairwise hypergraph, the\nk-nearest-neighbor (kNN) hypergraph, and the high-order over-clustering\nhypergraph. The pairwise hypergraph captures the pairwise similarity of data\npoints; the kNN hypergraph captures the neighborhood of each point; and the\nclustering hypergraph encodes high-order contexts within the dataset. By\ncombining the affinity information from these three hypergraphs, the CAHSM\nalgorithm is able to explore the intrinsic topological information of the\ndataset. Therefore, data clustering using CAHSM tends to be more robust.\nConsidering the intra-cluster compactness and the inter-cluster separability of\nvertices, we further design a discriminative hypergraph partitioning criterion\n(DHPC). Using both CAHSM and DHPC, a robust spectral clustering algorithm is\ndeveloped. Theoretical analysis and experimental evaluation demonstrate the\neffectiveness and robustness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 02:05:35 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Li", "Xi", ""], ["Hu", "Weiming", ""], ["Shen", "Chunhua", ""], ["Dick", "Anthony", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1401.0767", "submitter": "Chunhua Shen", "authors": "Chunhua Shen, Fayao Liu", "title": "From Kernel Machines to Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods such as boosting combine multiple learners to obtain better\nprediction than could be obtained from any individual learner. Here we propose\na principled framework for directly constructing ensemble learning methods from\nkernel methods. Unlike previous studies showing the equivalence between\nboosting and support vector machines (SVMs), which needs a translation\nprocedure, we show that it is possible to design boosting-like procedure to\nsolve the SVM optimization problems.\n  In other words, it is possible to design ensemble methods directly from SVM\nwithout any middle procedure.\n  This finding not only enables us to design new ensemble learning methods\ndirectly from kernel methods, but also makes it possible to take advantage of\nthose highly-optimized fast linear SVM solvers for ensemble learning.\n  We exemplify this framework for designing binary ensemble learning as well as\na new multi-class ensemble learning methods.\n  Experimental results demonstrate the flexibility and usefulness of the\nproposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 02:28:48 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Shen", "Chunhua", ""], ["Liu", "Fayao", ""]]}, {"id": "1401.0870", "submitter": "Laurence Aroquiaraj", "authors": "I. Laurence Aroquiaraj and K. Thangavel", "title": "Pectoral Muscles Suppression in Digital Mammograms using Hybridization\n  of Soft Computing Methods", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast region segmentation is an essential prerequisite in computerized\nanalysis of mammograms. It aims at separating the breast tissue from the\nbackground of the mammogram and it includes two independent segmentations. The\nfirst segments the background region which usually contains annotations, labels\nand frames from the whole breast region, while the second removes the pectoral\nmuscle portion (present in Medio Lateral Oblique (MLO) views) from the rest of\nthe breast tissue. In this paper we propose hybridization of Connected\nComponent Labeling (CCL), Fuzzy, and Straight line methods. Our proposed\nmethods worked good for separating pectoral region. After removal pectoral\nmuscle from the mammogram, further processing is confined to the breast region\nalone. To demonstrate the validity of our segmentation algorithm, it is\nextensively tested using over 322 mammographic images from the Mammographic\nImage Analysis Society (MIAS) database. The segmentation results were evaluated\nusing a Mean Absolute Error (MAE), Hausdroff Distance (HD), Probabilistic Rand\nIndex (PRI), Local Consistency Error (LCE) and Tanimoto Coefficient (TC). The\nhybridization of fuzzy with straight line method is given more than 96% of the\ncurve segmentations to be adequate or better. In addition a comparison with\nsimilar approaches from the state of the art has been given, obtaining slightly\nimproved results. Experimental results demonstrate the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 08:14:43 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Aroquiaraj", "I. Laurence", ""], ["Thangavel", "K.", ""]]}, {"id": "1401.0898", "submitter": "Vijendra Singh", "authors": "Vijendra Singh and Shivani Pathak", "title": "Feature Selection Using Classifier in High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is frequently used as a pre-processing step to machine\nlearning. It is a process of choosing a subset of original features so that the\nfeature space is optimally reduced according to a certain evaluation criterion.\nThe central objective of this paper is to reduce the dimension of the data by\nfinding a small set of important features which can give good classification\nperformance. We have applied filter and wrapper approach with different\nclassifiers QDA and LDA respectively. A widely-used filter method is used for\nbioinformatics data i.e. a univariate criterion separately on each feature,\nassuming that there is no interaction between features and then applied\nSequential Feature Selection method. Experimental results show that filter\napproach gives better performance in respect of Misclassification Error Rate.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2014 14:52:27 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Singh", "Vijendra", ""], ["Pathak", "Shivani", ""]]}, {"id": "1401.1190", "submitter": "Purnendu  Banerjee", "authors": "Souvik Bhowmick, Purnendu Banerjee", "title": "Bangla Text Recognition from Video Sequence: A New Focus", "comments": null, "journal-ref": "NATIONAL CONFERENCE ON COMPUTING AND SYSTEMS (NaCCS), pp.\n  62-67,2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 20:25:26 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Bhowmick", "Souvik", ""], ["Banerjee", "Purnendu", ""]]}, {"id": "1401.1489", "submitter": "Romain H\\'erault", "authors": "John Komar and Romain H\\'erault and Ludovic Seifert", "title": "Key point selection and clustering of swimmer coordination through\n  Sparse Fisher-EM", "comments": "Presented at ECML/PKDD 2013 Workshop on Machine Learning and Data\n  Mining for Sports Analytics (MLSA2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To answer the existence of optimal swimmer learning/teaching strategies, this\nwork introduces a two-level clustering in order to analyze temporal dynamics of\nmotor learning in breaststroke swimming. Each level have been performed through\nSparse Fisher-EM, a unsupervised framework which can be applied efficiently on\nlarge and correlated datasets. The induced sparsity selects key points of the\ncoordination phase without any prior knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 20:16:05 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Komar", "John", ""], ["H\u00e9rault", "Romain", ""], ["Seifert", "Ludovic", ""]]}, {"id": "1401.1558", "submitter": "Ming Yan", "authors": "Zhitao Fan and Feng Guan and Chunlin Wu and Ming Yan", "title": "The Continuity of Images by Transmission Imaging Revisited", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DG cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transmission imaging, as an important imaging technique widely used in\nastronomy, medical diagnosis, and biology science, has been shown in [49] quite\ndifferent from reflection imaging used in our everyday life. Understanding the\nstructures of images (the prior information) is important for designing,\ntesting, and choosing image processing methods, and good image processing\nmethods are helpful for further uses of the image data, e.g., increasing the\naccuracy of the object reconstruction methods in transmission imaging\napplications. In reflection imaging, the images are usually modeled as\ndiscontinuous functions and even piecewise constant functions. In transmission\nimaging, it was shown very recently in [49] that almost all images are\ncontinuous functions. However, the author in [49] considered only the case of\nparallel beam geometry and used some too strong assumptions in the proof, which\nexclude some common cases such as cylindrical objects. In this paper, we\nconsider more general beam geometries and simplify the assumptions by using\ntotally different techniques. In particular, we will prove that almost all\nimages in transmission imaging with both parallel and divergent beam geometries\n(two most typical beam geometries) are continuous functions, under much weaker\nassumptions than those in [49], which admit almost all practical cases.\nBesides, taking into accounts our analysis, we compare two image processing\nmethods for Poisson noise (which is the most significant noise in transmission\nimaging) removal. Numerical experiments will be provided to demonstrate our\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 01:50:55 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Fan", "Zhitao", ""], ["Guan", "Feng", ""], ["Wu", "Chunlin", ""], ["Yan", "Ming", ""]]}, {"id": "1401.1605", "submitter": "James Hensman", "authors": "James Hensman and Magnus Rattray and Neil D. Lawrence", "title": "Fast nonparametric clustering of structured time-series", "comments": "Accepted for publication in special edition of TPAMI on Bayesian\n  Nonparametrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this publication, we combine two Bayesian non-parametric models: the\nGaussian Process (GP) and the Dirichlet Process (DP). Our innovation in the GP\nmodel is to introduce a variation on the GP prior which enables us to model\nstructured time-series data, i.e. data containing groups where we wish to model\ninter- and intra-group variability. Our innovation in the DP model is an\nimplementation of a new fast collapsed variational inference procedure which\nenables us to optimize our variationala pproximation significantly faster than\nstandard VB approaches. In a biological time series application we show how our\nmodel better captures salient features of the data, leading to better\nconsistency with existing biological classifications, while the associated\ninference algorithm provides a twofold speed-up over EM-based variational\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 08:47:44 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 08:04:46 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Hensman", "James", ""], ["Rattray", "Magnus", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1401.1742", "submitter": "Avinash Bhute", "authors": "Avinash N Bhute, B. B. Meshram", "title": "Content Based Image Indexing and Retrieval", "comments": "12 pages", "journal-ref": "IJGIP 2013 Vol 3 issue 4", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the efficient content based image retrieval systems\nwhich employ the color, texture and shape information of images to facilitate\nthe retrieval process. For efficient feature extraction, we extract the color,\ntexture and shape feature of images automatically using edge detection which is\nwidely used in signal processing and image compression. For facilitated the\nspeedy retrieval we are implements the antipole-tree algorithm for indexing the\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 16:22:09 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Bhute", "Avinash N", ""], ["Meshram", "B. B.", ""]]}, {"id": "1401.1778", "submitter": "Vignesh Jagadeesh", "authors": "Vignesh Jagadeesh, Robinson Piramuthu, Anurag Bhardwaj, Wei Di, Neel\n  Sundaresan", "title": "Large Scale Visual Recommendations From Street Fashion Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a completely automated large scale visual recommendation system\nfor fashion. Our focus is to efficiently harness the availability of large\nquantities of online fashion images and their rich meta-data. Specifically, we\npropose four data driven models in the form of Complementary Nearest Neighbor\nConsensus, Gaussian Mixture Models, Texture Agnostic Retrieval and Markov Chain\nLDA for solving this problem. We analyze relative merits and pitfalls of these\nalgorithms through extensive experimentation on a large-scale data set and\nbaseline them against existing ideas from color science. We also illustrate key\nfashion insights learned through these experiments and show how they can be\nemployed to design better recommendation systems. Finally, we also outline a\nlarge-scale annotated data set of fashion images (Fashion-136K) that can be\nexploited for future vision research.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 19:10:55 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Jagadeesh", "Vignesh", ""], ["Piramuthu", "Robinson", ""], ["Bhardwaj", "Anurag", ""], ["Di", "Wei", ""], ["Sundaresan", "Neel", ""]]}, {"id": "1401.1882", "submitter": "YuLi Sun", "authors": "Yuli Sun and Jinxu Tao", "title": "Image reconstruction from few views by L0-norm optimization", "comments": "11 pages,5 figures, 1 table", "journal-ref": null, "doi": "10.1088/1674-1056/23/7/078703", "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The L1-norm of the gradient-magnitude images (GMI), which is the well-known\ntotal variation (TV) model, is widely used as regularization in the few views\nCT reconstruction. As the L1-norm TV regularization is tending to uniformly\npenalize the image gradient and the low-contrast structures are sometimes over\nsmoothed, we proposed a new algorithm based on the L0-norm of the GMI to deal\nwith the few views problem. To rise to the challenges introduced by the L0-norm\nDGT, the algorithm uses a pseudo-inverse transform of DGT and adapts an\niterative hard thresholding (IHT) algorithm, whose convergence and effective\nefficiency have been theoretically proven. The simulation indicates that the\nalgorithm proposed in this paper can obviously improve the reconstruction\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 02:08:06 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Sun", "Yuli", ""], ["Tao", "Jinxu", ""]]}, {"id": "1401.1946", "submitter": "Oliver Arold", "authors": "Oliver Arold, Svenja Ettl, Florian Willomitzer, Gerd H\\\"ausler", "title": "Hand-guided 3D surface acquisition by combining simple light sectioning\n  with real-time algorithms", "comments": "19 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise 3D measurements of rigid surfaces are desired in many fields of\napplication like quality control or surgery. Often, views from all around the\nobject have to be acquired for a full 3D description of the object surface. We\npresent a sensor principle called \"Flying Triangulation\" which avoids an\nelaborate \"stop-and-go\" procedure. It combines a low-cost classical\nlight-section sensor with an algorithmic pipeline. A hand-guided sensor\ncaptures a continuous movie of 3D views while being moved around the object.\nThe views are automatically aligned and the acquired 3D model is displayed in\nreal time. In contrast to most existing sensors no bandwidth is wasted for\nspatial or temporal encoding of the projected lines. Nor is an expensive color\ncamera necessary for 3D acquisition. The achievable measurement uncertainty and\nlateral resolution of the generated 3D data is merely limited by physics. An\nalternating projection of vertical and horizontal lines guarantees the\nexistence of corresponding points in successive 3D views. This enables a\nprecise registration without surface interpolation. For registration, a variant\nof the iterative closest point algorithm - adapted to the specific nature of\nour 3D views - is introduced. Furthermore, data reduction and smoothing without\nlosing lateral resolution as well as the acquisition and mapping of a color\ntexture is presented. The precision and applicability of the sensor is\ndemonstrated by simulation and measurement results.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 10:36:49 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Arold", "Oliver", ""], ["Ettl", "Svenja", ""], ["Willomitzer", "Florian", ""], ["H\u00e4usler", "Gerd", ""]]}, {"id": "1401.1990", "submitter": "David Menotti", "authors": "R. F. Prates, G. C\\'amara-Ch\\'avez, William R. Schwartz, and D.\n  Menotti", "title": "Brazilian License Plate Detection Using Histogram of Oriented Gradients\n  and Sliding Windows", "comments": null, "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 5, No 6, pp. 39-52, December 2013", "doi": "10.5121/ijcsit.2013.5603", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasingly need for automatic traffic monitoring, vehicle\nlicense plate detection is of high interest to perform automatic toll\ncollection, traffic law enforcement, parking lot access control, among others.\nIn this paper, a sliding window approach based on Histogram of Oriented\nGradients (HOG) features is used for Brazilian license plate detection. This\napproach consists in scanning the whole image in a multiscale fashion such that\nthe license plate is located precisely. The main contribution of this work\nconsists in a deep study of the best setup for HOG descriptors on the detection\nof Brazilian license plates, in which HOG have never been applied before. We\nalso demonstrate the reliability of this method ensured by a recall higher than\n98% (with a precision higher than 78%) in a publicly available data set.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 13:01:52 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Prates", "R. F.", ""], ["C\u00e1mara-Ch\u00e1vez", "G.", ""], ["Schwartz", "William R.", ""], ["Menotti", "D.", ""]]}, {"id": "1401.2051", "submitter": "Agunbiade Olusanya  yinka", "authors": "Olusanya Y. Agunbiade, Tranos Zuva, Awosejo O. Johnson and Keneilwe\n  Zuva", "title": "Enhancement performance of road recognition system of autonomous robots\n  in shadow scenario", "comments": "Signal & Image Processing : An International Journal (SIPIJ) Vol.4,\n  No.6, December 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Road region recognition is a main feature that is gaining increasing\nattention from intellectuals because it helps autonomous vehicle to achieve a\nsuccessful navigation without accident. However, different techniques based on\ncamera sensor have been used by various researchers and outstanding results\nhave been achieved. Despite their success, environmental noise like shadow\nleads to inaccurate recognition of road region which eventually leads to\naccident for autonomous vehicle. In this research, we conducted an\ninvestigation on shadow and its effects, optimized the road region recognition\nsystem of autonomous vehicle by introducing an algorithm capable of detecting\nand eliminating the effects of shadow. The experimental performance of our\nsystem was tested and compared using the following schemes: Total Positive Rate\n(TPR), False Negative Rate (FNR), Total Negative Rate (TNR), Error Rate (ERR)\nand False Positive Rate (FPR). The performance result of the system improved on\nroad recognition in shadow scenario and this advancement has added tremendously\nto successful navigation approaches for autonomous vehicle.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 16:09:57 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Agunbiade", "Olusanya Y.", ""], ["Zuva", "Tranos", ""], ["Johnson", "Awosejo O.", ""], ["Zuva", "Keneilwe", ""]]}, {"id": "1401.2058", "submitter": "Rachit Puri", "authors": "Rachit Puri", "title": "Gesture recognition based mouse events", "comments": "9 pages, IJCSIT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper presents the maneuver of mouse pointer and performs various mouse\noperations such as left click, right click, double click, drag etc using\ngestures recognition technique. Recognizing gestures is a complex task which\ninvolves many aspects such as motion modeling, motion analysis, pattern\nrecognition and machine learning. Keeping all the essential factors in mind a\nsystem has been created which recognizes the movement of fingers and various\npatterns formed by them. Color caps have been used for fingers to distinguish\nit from the background color such as skin color. Thus recognizing the gestures\nvarious mouse events have been performed. The application has been created on\nMATLAB environment with operating system as windows 7.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 16:26:54 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Puri", "Rachit", ""]]}, {"id": "1401.2416", "submitter": "Odemir Bruno PhD", "authors": "Lucas Assirati, Alexandre Souto Martinez, Odemir Martinez Bruno", "title": "Satellite image classification and segmentation using non-additive\n  entropy", "comments": "4 pages, 5 figures, ICMSquare 2013", "journal-ref": null, "doi": "10.1088/1742-6596/490/1/012086", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we compare the Boltzmann-Gibbs-Shannon (standard) with the Tsallis\nentropy on the pattern recognition and segmentation of coloured images obtained\nby satellites, via \"Google Earth\". By segmentation we mean split an image to\nlocate regions of interest. Here, we discriminate and define an image partition\nclasses according to a training basis. This training basis consists of three\npattern classes: aquatic, urban and vegetation regions. Our numerical\nexperiments demonstrate that the Tsallis entropy, used as a feature vector\ncomposed of distinct entropic indexes $q$ outperforms the standard entropy.\nThere are several applications of our proposed methodology, once satellite\nimages can be used to monitor migration form rural to urban regions,\nagricultural activities, oil spreading on the ocean etc.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 17:57:16 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Assirati", "Lucas", ""], ["Martinez", "Alexandre Souto", ""], ["Bruno", "Odemir Martinez", ""]]}, {"id": "1401.2529", "submitter": "Elif Vural", "authors": "Elif Vural and Pascal Frossard", "title": "A Study of Image Analysis with Tangent Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of the geometric transformation between a reference and a\ntarget image, known as registration or alignment, corresponds to the projection\nof the target image onto the transformation manifold of the reference image\n(the set of images generated by its geometric transformations). It, however,\noften takes a nontrivial form such that the exact computation of projections on\nthe manifold is difficult. The tangent distance method is an effective\nalgorithm to solve this problem by exploiting a linear approximation of the\nmanifold. As theoretical studies about the tangent distance algorithm have been\nlargely overlooked, we present in this work a detailed performance analysis of\nthis useful algorithm, which can eventually help its implementation. We\nconsider a popular image registration setting using a multiscale pyramid of\nlowpass filtered versions of the (possibly noisy) reference and target images,\nwhich is particularly useful for recovering large transformations. We first\nshow that the alignment error has a nonmonotonic variation with the filter\nsize, due to the opposing effects of filtering on both manifold nonlinearity\nand image noise. We then study the convergence of the multiscale tangent\ndistance method to the optimal solution. We finally examine the performance of\nthe tangent distance method in image classification applications. Our\ntheoretical findings are confirmed by experiments on image transformation\nmodels involving translations, rotations and scalings. Our study is the first\ndetailed study of the tangent distance algorithm that leads to a better\nunderstanding of its efficacy and to the proper selection of its design\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 13:31:14 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 16:10:06 GMT"}, {"version": "v3", "created": "Tue, 30 Sep 2014 17:05:41 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Vural", "Elif", ""], ["Frossard", "Pascal", ""]]}, {"id": "1401.2686", "submitter": "Kathryn Heal", "authors": "J\\'er\\^ome Gilles and Kathryn Heal", "title": "A parameterless scale-space approach to find meaningful modes in\n  histograms - Application to image and spectrum segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an algorithm to automatically detect meaningful\nmodes in a histogram. The proposed method is based on the behavior of local\nminima in a scale-space representation. We show that the detection of such\nmeaningful modes is equivalent in a two classes clustering problem on the\nlength of minima scale-space curves. The algorithm is easy to implement, fast,\nand does not require any parameters. We present several results on histogram\nand spectrum segmentation, grayscale image segmentation and color image\nreduction.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 00:19:34 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Gilles", "J\u00e9r\u00f4me", ""], ["Heal", "Kathryn", ""]]}, {"id": "1401.2804", "submitter": "Yunjin Chen", "authors": "Yunjin Chen, Ren\\'e Ranftl and Thomas Pock", "title": "Insights into analysis operator learning: From patch-based sparse models\n  to higher-order MRFs", "comments": "13 pages, 10 figures, accepted to IEEE Image Processing", "journal-ref": null, "doi": "10.1109/TIP.2014.2299065", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a new learning algorithm for the recently introduced\nco-sparse analysis model. First, we give new insights into the co-sparse\nanalysis model by establishing connections to filter-based MRF models, such as\nthe Field of Experts (FoE) model of Roth and Black. For training, we introduce\na technique called bi-level optimization to learn the analysis operators.\nCompared to existing analysis operator learning approaches, our training\nprocedure has the advantage that it is unconstrained with respect to the\nanalysis operator. We investigate the effect of different aspects of the\nco-sparse analysis model and show that the sparsity promoting function (also\ncalled penalty function) is the most important factor in the model. In order to\ndemonstrate the effectiveness of our training approach, we apply our trained\nmodels to various classical image restoration problems. Numerical experiments\nshow that our trained models clearly outperform existing analysis operator\nlearning approaches and are on par with state-of-the-art image denoising\nalgorithms. Our approach develops a framework that is intuitive to understand\nand easy to implement.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 12:10:19 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Chen", "Yunjin", ""], ["Ranftl", "Ren\u00e9", ""], ["Pock", "Thomas", ""]]}, {"id": "1401.2818", "submitter": "Alan Brunton", "authors": "Alan Brunton, Timo Bolkart, Stefanie Wuhrer", "title": "Multilinear Wavelets: A Statistical Shape Space for Human Faces", "comments": "10 pages, 7 figures; accepted to ECCV 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a statistical model for $3$D human faces in varying expression,\nwhich decomposes the surface of the face using a wavelet transform, and learns\nmany localized, decorrelated multilinear models on the resulting coefficients.\nUsing this model we are able to reconstruct faces from noisy and occluded $3$D\nface scans, and facial motion sequences. Accurate reconstruction of face shape\nis important for applications such as tele-presence and gaming. The localized\nand multi-scale nature of our model allows for recovery of fine-scale detail\nwhile retaining robustness to severe noise and occlusion, and is\ncomputationally efficient and scalable. We validate these properties\nexperimentally on challenging data in the form of static scans and motion\nsequences. We show that in comparison to a global multilinear model, our model\nbetter preserves fine detail and is computationally faster, while in comparison\nto a localized PCA model, our model better handles variation in expression, is\nfaster, and allows us to fix identity parameters for a given subject.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 12:48:39 GMT"}, {"version": "v2", "created": "Tue, 1 Jul 2014 09:26:10 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Brunton", "Alan", ""], ["Bolkart", "Timo", ""], ["Wuhrer", "Stefanie", ""]]}, {"id": "1401.2871", "submitter": "Lefei Zhang", "authors": "Lefei Zhang", "title": "Tensor Representation and Manifold Learning Methods for Remote Sensing\n  Images", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  One of the main purposes of earth observation is to extract interested\ninformation and knowledge from remote sensing (RS) images with high efficiency\nand accuracy. However, with the development of RS technologies, RS system\nprovide images with higher spatial and temporal resolution and more spectral\nchannels than before, and it is inefficient and almost impossible to manually\ninterpret these images. Thus, it is of great interests to explore automatic and\nintelligent algorithms to quickly process such massive RS data with high\naccuracy. This thesis targets to develop some efficient information extraction\nalgorithms for RS images, by relying on the advanced technologies in machine\nlearning. More precisely, we adopt the manifold learning algorithms as the\nmainline and unify the regularization theory, tensor-based method, sparse\nlearning and transfer learning into the same framework. The main contributions\nof this thesis are as follows.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 15:33:57 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Zhang", "Lefei", ""]]}, {"id": "1401.2899", "submitter": "Panayiotis Frangos V", "authors": "A. Malamou, C. Pandis, P. Frangos, P. Stefaneas, A. Karakasiliotis and\n  D. Kodokostas", "title": "Application of the Modified Fractal Signature Method for Terrain\n  Classification from Synthetic Aperture Radar Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the Modified Fractal Signature method is applied to real\nSynthetic Aperture Radar images provided to our research group by SET 163\nWorking Group on SAR radar techniques. This method uses the blanket technique\nto provide useful information for SAR image classification. It is based on the\ncalculation of the volume of a blanket, corresponding to the image to be\nclassified, and then on the calculation of the corresponding Fractal Area curve\nand Fractal Dimension curve of the image. The main idea concerning this\nproposed technique is the fact that different terrain types encountered in SAR\nimages yield different values of Fractal Area curves and Fractal Dimension\ncurves, upon which classification of different types of terrain is possible. As\na result, a classification technique for five different terrain types, i.e.\nurban, suburban, rural, mountain and sea, is presented in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 15:17:04 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Malamou", "A.", ""], ["Pandis", "C.", ""], ["Frangos", "P.", ""], ["Stefaneas", "P.", ""], ["Karakasiliotis", "A.", ""], ["Kodokostas", "D.", ""]]}, {"id": "1401.2902", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Sukanta Sinha, Rana Dattagupta, Debajyoti Mukhopadhyay", "title": "An Alternate Approach for Designing a Domain Specific Image Search\n  Prototype Using Histogram", "comments": "10 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Everyone knows that thousand of words are represented by a single image. As a\nresult image search has become a very popular mechanism for the Web searchers.\nImage search means, the search results are produced by the search engine should\nbe a set of images along with their Web page Unified Resource Locator. Now Web\nsearcher can perform two types of image search, they are Text to Image and\nImage to Image search. In Text to Image search, search query should be a text.\nBased on the input text data system will generate a set of images along with\ntheir Web page URL as an output. On the other hand, in Image to Image search,\nsearch query should be an image and based on this image system will generate a\nset of images along with their Web page URL as an output. According to the\ncurrent scenarios, Text to Image search mechanism always not returns perfect\nresult. It matches the text data and then displays the corresponding images as\nan output, which is not always perfect. To resolve this problem, Web\nresearchers have introduced the Image to Image search mechanism. In this paper,\nwe have also proposed an alternate approach of Image to Image search mechanism\nusing Histogram.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 05:10:24 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Sinha", "Sukanta", ""], ["Dattagupta", "Rana", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1401.3385", "submitter": "Val\\'erio Ramos Batista", "authors": "Antonio Elias Fabris and Val\\'erio Ramos Batista", "title": "A programme to determine the exact interior of any connected digital\n  picture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Region filling is one of the most important and fundamental operations in\ncomputer graphics and image processing. Many filling algorithms and their\nimplementations are based on the Euclidean geometry, which are then translated\ninto computational models moving carelessly from the continuous to the finite\ndiscrete space of the computer. The consequences of this approach is that most\nimplementations fail when tested for challenging degenerate and nearly\ndegenerate regions. We present a correct integer-only procedure that works for\nall connected digital pictures. It finds all possible interior points, which\nare then displayed and stored in a locating matrix. Namely, we present a\nfilling and locating procedure that can be used in computer graphics and image\nprocessing applications.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 23:21:58 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Fabris", "Antonio Elias", ""], ["Batista", "Val\u00e9rio Ramos", ""]]}, {"id": "1401.3409", "submitter": "Xiaowei Zhou", "authors": "Xiaowei Zhou, Can Yang, Hongyu Zhao, Weichuan Yu", "title": "Low-Rank Modeling and Its Applications in Image Analysis", "comments": "To appear in ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank modeling generally refers to a class of methods that solve problems\nby representing variables of interest as low-rank matrices. It has achieved\ngreat success in various fields including computer vision, data mining, signal\nprocessing and bioinformatics. Recently, much progress has been made in\ntheories, algorithms and applications of low-rank modeling, such as exact\nlow-rank matrix recovery via convex programming and matrix completion applied\nto collaborative filtering. These advances have brought more and more\nattentions to this topic. In this paper, we review the recent advance of\nlow-rank modeling, the state-of-the-art algorithms, and related applications in\nimage analysis. We first give an overview to the concept of low-rank modeling\nand challenging problems in this area. Then, we summarize the models and\nalgorithms for low-rank matrix recovery and illustrate their advantages and\nlimitations with numerical experiments. Next, we introduce a few applications\nof low-rank modeling in the context of image analysis. Finally, we conclude\nthis paper with some discussions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 02:17:33 GMT"}, {"version": "v2", "created": "Tue, 10 Jun 2014 03:40:29 GMT"}, {"version": "v3", "created": "Thu, 23 Oct 2014 02:05:18 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Zhou", "Xiaowei", ""], ["Yang", "Can", ""], ["Zhao", "Hongyu", ""], ["Yu", "Weichuan", ""]]}, {"id": "1401.3584", "submitter": "Abdul Kadir", "authors": "Abdul Kadir, Lukito Edi Nugroho, Adhi Susanto and Paulus Insap Santosa", "title": "Experiments of Distance Measurements in a Foliage Plant Retrieval System", "comments": "14 pages, International Journal of Signal Processing, Image\n  Processing and Pattern Recognition Vol. 5, No. 2, June, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of important components in an image retrieval system is selecting a\ndistance measure to compute rank between two objects. In this paper, several\ndistance measures were researched to implement a foliage plant retrieval\nsystem. Sixty kinds of foliage plants with various leaf color and shape were\nused to test the performance of 7 different kinds of distance measures: city\nblock distance, Euclidean distance, Canberra distance, Bray-Curtis distance, x2\nstatistics, Jensen Shannon divergence and Kullback Leibler divergence. The\nresults show that city block and Euclidean distance measures gave the best\nperformance among the others.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 07:51:59 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Kadir", "Abdul", ""], ["Nugroho", "Lukito Edi", ""], ["Susanto", "Adhi", ""], ["Santosa", "Paulus Insap", ""]]}, {"id": "1401.3590", "submitter": "Karim Mahmoud", "authors": "Karim M. Mahmoud", "title": "An Enhanced Method For Evaluating Automatic Video Summaries", "comments": "This paper has been withdrawn by the author due to some errors and\n  incomplete study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of automatic video summaries is a challenging problem. In the past\nyears, some evaluation methods are presented that utilize only a single feature\nlike color feature to detect similarity between automatic video summaries and\nground-truth user summaries. One of the drawbacks of using a single feature is\nthat sometimes it gives a false similarity detection which makes the assessment\nof the quality of the generated video summary less perceptual and not accurate.\nIn this paper, a novel method for evaluating automatic video summaries is\npresented. This method is based on comparing automatic video summaries\ngenerated by video summarization techniques with ground-truth user summaries.\nThe objective of this evaluation method is to quantify the quality of video\nsummaries, and allow comparing different video summarization techniques\nutilizing both color and texture features of the video frames and using the\nBhattacharya distance as a dissimilarity measure due to its advantages. Our\nExperiments show that the proposed evaluation method overcomes the drawbacks of\nother methods and gives a more perceptual evaluation of the quality of the\nautomatic video summaries.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 09:30:44 GMT"}, {"version": "v2", "created": "Wed, 30 Apr 2014 23:04:43 GMT"}, {"version": "v3", "created": "Tue, 19 Apr 2016 16:05:08 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Mahmoud", "Karim M.", ""]]}, {"id": "1401.3615", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann, Jan Treibig, Georg Hager, Gerhard Wellein", "title": "Performance Engineering for a Medical Imaging Application on the Intel\n  Xeon Phi Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the Xeon Phi, which is based on Intel's Many Integrated Cores\narchitecture, for its suitability to run the FDK algorithm--the most commonly\nused algorithm to perform the 3D image reconstruction in cone-beam computed\ntomography. We study the challenges of efficiently parallelizing the\napplication and means to enable sensible data sharing between threads despite\nthe lack of a shared last level cache. Apart from parallelization, SIMD\nvectorization is critical for good performance on the Xeon Phi; we perform\nvarious micro-benchmarks to investigate the platform's new set of vector\ninstructions and put a special emphasis on the newly introduced vector gather\ncapability. We refine a previous performance model for the application and\nadapt it for the Xeon Phi to validate the performance of our optimized\nhand-written assembly implementation, as well as the performance of several\ndifferent auto-vectorization approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 14:46:19 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Hofmann", "Johannes", ""], ["Treibig", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1401.3700", "submitter": "Matanya Horowitz", "authors": "Matanya B. Horowitz, Nikolai Matni, Joel W. Burdick", "title": "Convex Relaxations of SE(2) and SE(3) for Visual Pose Estimation", "comments": "ICRA 2014 Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for rigid body pose estimation based on\nspectrahedral representations of the tautological orbitopes of $SE(2)$ and\n$SE(3)$. The approach can use dense point cloud data from stereo vision or an\nRGB-D sensor (such as the Microsoft Kinect), as well as visual appearance data.\nThe method is a convex relaxation of the classical pose estimation problem, and\nis based on explicit linear matrix inequality (LMI) representations for the\nconvex hulls of $SE(2)$ and $SE(3)$. Given these representations, the relaxed\npose estimation problem can be framed as a robust least squares problem with\nthe optimization variable constrained to these convex sets. Although this\nformulation is a relaxation of the original problem, numerical experiments\nindicate that it is indeed exact - i.e. its solution is a member of $SE(2)$ or\n$SE(3)$ - in many interesting settings. We additionally show that this method\nis guaranteed to be exact for a large class of pose estimation problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 18:54:17 GMT"}, {"version": "v2", "created": "Sun, 6 Apr 2014 17:57:31 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Horowitz", "Matanya B.", ""], ["Matni", "Nikolai", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1401.3818", "submitter": "Xiaoxia Sun", "authors": "Xiaoxia Sun, Qing Qu, Nasser M. Nasrabadi, Trac D. Tran", "title": "Structured Priors for Sparse-Representation-Based Hyperspectral Image\n  Classification", "comments": "IEEE Geoscience and Remote Sensing Letter", "journal-ref": null, "doi": "10.1109/LGRS.2013.2290531", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Pixel-wise classification, where each pixel is assigned to a predefined\nclass, is one of the most important procedures in hyperspectral image (HSI)\nanalysis. By representing a test pixel as a linear combination of a small\nsubset of labeled pixels, a sparse representation classifier (SRC) gives rather\nplausible results compared with that of traditional classifiers such as the\nsupport vector machine (SVM). Recently, by incorporating additional structured\nsparsity priors, the second generation SRCs have appeared in the literature and\nare reported to further improve the performance of HSI. These priors are based\non exploiting the spatial dependencies between the neighboring pixels, the\ninherent structure of the dictionary, or both. In this paper, we review and\ncompare several structured priors for sparse-representation-based HSI\nclassification. We also propose a new structured prior called the low rank\ngroup prior, which can be considered as a modification of the low rank prior.\nFurthermore, we will investigate how different structured priors improve the\nresult for the HSI classification.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 03:21:26 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Sun", "Xiaoxia", ""], ["Qu", "Qing", ""], ["Nasrabadi", "Nasser M.", ""], ["Tran", "Trac D.", ""]]}, {"id": "1401.3973", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a and Josep Lluis Arcos", "title": "An Empirical Evaluation of Similarity Measures for Time Series\n  Classification", "comments": "28 pages, 5 figures, 3 tables", "journal-ref": "Knowledge-Based Systems 67: 305-314, 2014", "doi": "10.1016/j.knosys.2014.04.035", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are ubiquitous, and a measure to assess their similarity is a\ncore part of many computational systems. In particular, the similarity measure\nis the most essential ingredient of time series clustering and classification\nsystems. Because of this importance, countless approaches to estimate time\nseries similarity have been proposed. However, there is a lack of comparative\nstudies using empirical, rigorous, quantitative, and large-scale assessment\nstrategies. In this article, we provide an extensive evaluation of similarity\nmeasures for time series classification following the aforementioned\nprinciples. We consider 7 different measures coming from alternative measure\n`families', and 45 publicly-available time series data sets coming from a wide\nvariety of scientific domains. We focus on out-of-sample classification\naccuracy, but in-sample accuracies and parameter choices are also discussed.\nOur work is based on rigorous evaluation methodologies and includes the use of\npowerful statistical significance tests to derive meaningful conclusions. The\nobtained results show the equivalence, in terms of accuracy, of a number of\nmeasures, but with one single candidate outperforming the rest. Such findings,\ntogether with the followed methodology, invite researchers on the field to\nadopt a more consistent evaluation criteria and a more informed decision\nregarding the baseline measures to which new developments should be compared.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 10:21:44 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Arcos", "Josep Lluis", ""]]}, {"id": "1401.4105", "submitter": "Yunjin Chen", "authors": "Yunjin Chen, Thomas Pock and Horst Bischof", "title": "Learning $\\ell_1$-based analysis and synthesis sparsity priors using\n  bi-level optimization", "comments": "5 pages, 1 figure, appear at the Workshop on Analysis Operator\n  Learning vs. Dictionary Learning, NIPS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the analysis operator and synthesis dictionary learning problems\nbased on the the $\\ell_1$ regularized sparse representation model. We reveal\nthe internal relations between the $\\ell_1$-based analysis model and synthesis\nmodel. We then introduce an approach to learn both analysis operator and\nsynthesis dictionary simultaneously by using a unified framework of bi-level\noptimization. Our aim is to learn a meaningful operator (dictionary) such that\nthe minimum energy solution of the analysis (synthesis)-prior based model is as\nclose as possible to the ground-truth. We solve the bi-level optimization\nproblem using the implicit differentiation technique. Moreover, we demonstrate\nthe effectiveness of our leaning approach by applying the learned analysis\noperator (dictionary) to the image denoising task and comparing its performance\nwith state-of-the-art methods. Under this unified framework, we can compare the\nperformance of the two types of priors.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 17:49:45 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Chen", "Yunjin", ""], ["Pock", "Thomas", ""], ["Bischof", "Horst", ""]]}, {"id": "1401.4107", "submitter": "Yunjin Chen", "authors": "Yunjin Chen, Thomas Pock, Ren\\'e Ranftl and Horst Bischof", "title": "Revisiting loss-specific training of filter-based MRFs for image\n  restoration", "comments": "10 pages, 2 figures, appear at 35th German Conference, GCPR 2013,\n  Saarbr\\\"ucken, Germany, September 3-6, 2013. Proceedings", "journal-ref": null, "doi": "10.1007/978-3-642-40602-7_30", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now well known that Markov random fields (MRFs) are particularly\neffective for modeling image priors in low-level vision. Recent years have seen\nthe emergence of two main approaches for learning the parameters in MRFs: (1)\nprobabilistic learning using sampling-based algorithms and (2) loss-specific\ntraining based on MAP estimate. After investigating existing training\napproaches, it turns out that the performance of the loss-specific training has\nbeen significantly underestimated in existing work. In this paper, we revisit\nthis approach and use techniques from bi-level optimization to solve it. We\nshow that we can get a substantial gain in the final performance by solving the\nlower-level problem in the bi-level framework with high accuracy using our\nnewly proposed algorithm. As a result, our trained model is on par with highly\nspecialized image denoising algorithms and clearly outperforms\nprobabilistically trained MRF models. Our findings suggest that for the\nloss-specific training scheme, solving the lower-level problem with higher\naccuracy is beneficial. Our trained model comes along with the additional\nadvantage, that inference is extremely efficient. Our GPU-based implementation\ntakes less than 1s to produce state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 17:58:21 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Chen", "Yunjin", ""], ["Pock", "Thomas", ""], ["Ranftl", "Ren\u00e9", ""], ["Bischof", "Horst", ""]]}, {"id": "1401.4112", "submitter": "Yunjin Chen", "authors": "Yunjin Chen, Ren\\'e Ranftl and Thomas Pock", "title": "A bi-level view of inpainting - based image compression", "comments": "8 pages, 4 figures, best paper award of CVWW 2014, Computer Vision\n  Winter Workshop, K\\v{r}tiny, Czech Republic, 3-5th February 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inpainting based image compression approaches, especially linear and\nnon-linear diffusion models, are an active research topic for lossy image\ncompression. The major challenge in these compression models is to find a small\nset of descriptive supporting points, which allow for an accurate\nreconstruction of the original image. It turns out in practice that this is a\nchallenging problem even for the simplest Laplacian interpolation model. In\nthis paper, we revisit the Laplacian interpolation compression model and\nintroduce two fast algorithms, namely successive preconditioning primal dual\nalgorithm and the recently proposed iPiano algorithm, to solve this problem\nefficiently. Furthermore, we extend the Laplacian interpolation based\ncompression model to a more general form, which is based on principles from\nbi-level optimization. We investigate two different variants of the Laplacian\nmodel, namely biharmonic interpolation and smoothed Total Variation\nregularization. Our numerical results show that significant improvements can be\nobtained from the biharmonic interpolation model, and it can recover an image\nwith very high quality from only 5% pixels.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 18:10:56 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 16:24:26 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Chen", "Yunjin", ""], ["Ranftl", "Ren\u00e9", ""], ["Pock", "Thomas", ""]]}, {"id": "1401.4221", "submitter": "Yuan Xie", "authors": "Yuan Xie and Wensheng Zhang and Dacheng Tao and Wenrui Hu and Yanyun\n  Qu and Hanzi Wang", "title": "Distortion-driven Turbulence Effect Removal using Variational Model", "comments": "28 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  It remains a challenge to simultaneously remove geometric distortion and\nspace-time-varying blur in frames captured through a turbulent atmospheric\nmedium. To solve, or at least reduce these effects, we propose a new scheme to\nrecover a latent image from observed frames by integrating a new variational\nmodel and distortion-driven spatial-temporal kernel regression. The proposed\nscheme first constructs a high-quality reference image from the observed frames\nusing low-rank decomposition. Then, to generate an improved registered\nsequence, the reference image is iteratively optimized using a variational\nmodel containing a new spatial-temporal regularization. The proposed fast\nalgorithm efficiently solves this model without the use of partial differential\nequations (PDEs). Next, to reduce blur variation, distortion-driven\nspatial-temporal kernel regression is carried out to fuse the registered\nsequence into one image by introducing the concept of the near-stationary\npatch. Applying a blind deconvolution algorithm to the fused image produces the\nfinal output. Extensive experimental testing shows, both qualitatively and\nquantitatively, that the proposed method can effectively alleviate distortion\nand blur and recover details of the original scene compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2014 01:40:52 GMT"}], "update_date": "2014-01-20", "authors_parsed": [["Xie", "Yuan", ""], ["Zhang", "Wensheng", ""], ["Tao", "Dacheng", ""], ["Hu", "Wenrui", ""], ["Qu", "Yanyun", ""], ["Wang", "Hanzi", ""]]}, {"id": "1401.4447", "submitter": "Abdul Kadir", "authors": "Abdul Kadir, Lukito Edi Nugroho, Adhi Susanto, Paulus Insap Santosa", "title": "Leaf Classification Using Shape, Color, and Texture Features", "comments": "6 pages, International Journal of Computer Trends and Technology-\n  July to Aug Issue 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several methods to identify plants have been proposed by several researchers.\nCommonly, the methods did not capture color information, because color was not\nrecognized as an important aspect to the identification. In this research,\nshape and vein, color, and texture features were incorporated to classify a\nleaf. In this case, a neural network called Probabilistic Neural network (PNN)\nwas used as a classifier. The experimental result shows that the method for\nclassification gives average accuracy of 93.75% when it was tested on Flavia\ndataset, that contains 32 kinds of plant leaves. It means that the method gives\nbetter performance compared to the original work.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 07:55:40 GMT"}], "update_date": "2014-01-20", "authors_parsed": [["Kadir", "Abdul", ""], ["Nugroho", "Lukito Edi", ""], ["Susanto", "Adhi", ""], ["Santosa", "Paulus Insap", ""]]}, {"id": "1401.4489", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Ifeoma Nwogu, Gaurav Srivastava, Venu Govindaraju", "title": "An Analysis of Random Projections in Cancelable Biometrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing concerns about security, the need for highly secure physical\nbiometrics-based authentication systems utilizing \\emph{cancelable biometric}\ntechnologies is on the rise. Because the problem of cancelable template\ngeneration deals with the trade-off between template security and matching\nperformance, many state-of-the-art algorithms successful in generating high\nquality cancelable biometrics all have random projection as one of their early\nprocessing steps. This paper therefore presents a formal analysis of why random\nprojections is an essential step in cancelable biometrics. By formally defining\nthe notion of an \\textit{Independent Subspace Structure} for datasets, it can\nbe shown that random projection preserves the subspace structure of data\nvectors generated from a union of independent linear subspaces. The bound on\nthe minimum number of random vectors required for this to hold is also derived\nand is shown to depend logarithmically on the number of data samples, not only\nin independent subspaces but in disjoint subspace settings as well. The\ntheoretical analysis presented is supported in detail with empirical results on\nreal-world face recognition datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2014 23:21:56 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 02:57:25 GMT"}, {"version": "v3", "created": "Fri, 14 Nov 2014 02:38:09 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Arpit", "Devansh", ""], ["Nwogu", "Ifeoma", ""], ["Srivastava", "Gaurav", ""], ["Govindaraju", "Venu", ""]]}, {"id": "1401.4612", "submitter": "Javier Velez", "authors": "Javier Velez, Garrett Hemann, Albert S. Huang, Ingmar Posner, Nicholas\n  Roy", "title": "Modelling Observation Correlations for Active Exploration and Robust\n  Object Detection", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 44, pages\n  423-453, 2012", "doi": "10.1613/jair.3516", "report-no": null, "categories": "cs.RO cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, mobile robots are expected to carry out increasingly complex tasks in\nmultifarious, real-world environments. Often, the tasks require a certain\nsemantic understanding of the workspace. Consider, for example, spoken\ninstructions from a human collaborator referring to objects of interest; the\nrobot must be able to accurately detect these objects to correctly understand\nthe instructions. However, existing object detection, while competent, is not\nperfect. In particular, the performance of detection algorithms is commonly\nsensitive to the position of the sensor relative to the objects in the scene.\nThis paper presents an online planning algorithm which learns an explicit model\nof the spatial dependence of object detection and generates plans which\nmaximize the expected performance of the detection, and by extension the\noverall plan performance. Crucially, the learned sensor model incorporates\nspatial correlations between measurements, capturing the fact that successive\nmeasurements taken at the same or nearby locations are not independent. We show\nhow this sensor model can be incorporated into an efficient forward search\nalgorithm in the information space of detected objects, allowing the robot to\ngenerate motion plans efficiently. We investigate the performance of our\napproach by addressing the tasks of door and text detection in indoor\nenvironments and demonstrate significant improvement in detection performance\nduring task execution over alternative methods in simulated and real robot\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2014 21:37:47 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Velez", "Javier", ""], ["Hemann", "Garrett", ""], ["Huang", "Albert S.", ""], ["Posner", "Ingmar", ""], ["Roy", "Nicholas", ""]]}, {"id": "1401.4648", "submitter": "Rafid Siddiqui", "authors": "Rafid Siddiqui, Siamak Khatibi", "title": "Visual Tracking using Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of robust extraction of visual odometry from a sequence of images\nobtained by an eye in hand camera configuration is addressed. A novel approach\ntoward solving planar template based tracking is proposed which performs a\nnon-linear image alignment for successful retrieval of camera transformations.\nIn order to obtain global optimum a bio-metaheuristic is used for optimization\nof similarity among the planar regions. The proposed method is validated on\nimage sequences with real as well as synthetic transformations and found to be\nresilient to intensity variations. A comparative analysis of the various\nsimilarity measures as well as various state-of-art methods reveal that the\nalgorithm succeeds in tracking the planar regions robustly and has good\npotential to be used in real applications.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2014 09:52:19 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Siddiqui", "Rafid", ""], ["Khatibi", "Siamak", ""]]}, {"id": "1401.4788", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "Generalized Bhattacharyya and Chernoff upper bounds on Bayes error using\n  quasi-arithmetic means", "comments": "22 pages, include R code. To appear in Pattern Recognition Letters", "journal-ref": null, "doi": "10.1016/j.patrec.2014.01.002", "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian classification labels observations based on given prior information,\nnamely class-a priori and class-conditional probabilities. Bayes' risk is the\nminimum expected classification cost that is achieved by the Bayes' test, the\noptimal decision rule. When no cost incurs for correct classification and unit\ncost is charged for misclassification, Bayes' test reduces to the maximum a\nposteriori decision rule, and Bayes risk simplifies to Bayes' error, the\nprobability of error. Since calculating this probability of error is often\nintractable, several techniques have been devised to bound it with closed-form\nformula, introducing thereby measures of similarity and divergence between\ndistributions like the Bhattacharyya coefficient and its associated\nBhattacharyya distance. The Bhattacharyya upper bound can further be tightened\nusing the Chernoff information that relies on the notion of best error\nexponent. In this paper, we first express Bayes' risk using the total variation\ndistance on scaled distributions. We then elucidate and extend the\nBhattacharyya and the Chernoff upper bound mechanisms using generalized\nweighted means. We provide as a byproduct novel notions of statistical\ndivergences and affinity coefficients. We illustrate our technique by deriving\nnew upper bounds for the univariate Cauchy and the multivariate\n$t$-distributions, and show experimentally that those bounds are not too\ndistant to the computationally intractable Bayes' error.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 04:05:27 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1401.5098", "submitter": "Mohamed A. El-Sayed", "authors": "Mohamed A. El-Sayed, S. Abdel-Khalek, and Eman Abdel-Aziz", "title": "Study of Efficient Technique Based On 2D Tsallis Entropy For Image\n  Thresholding", "comments": null, "journal-ref": "International Journal on Computer Science and Engineering (IJCSE),\n  Vol. 3 No. 9, pp. 3125-3138, 2011", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thresholding is an important task in image processing. It is a main tool in\npattern recognition, image segmentation, edge detection and scene analysis. In\nthis paper, we present a new thresholding technique based on two-dimensional\nTsallis entropy. The two-dimensional Tsallis entropy was obtained from the\ntwodimensional histogram which was determined by using the gray value of the\npixels and the local average gray value of the pixels, the work it was applied\na generalized entropy formalism that represents a recent development in\nstatistical mechanics. The effectiveness of the proposed method is demonstrated\nby using examples from the real-world and synthetic images. The performance\nevaluation of the proposed technique in terms of the quality of the thresholded\nimages are presented. Experimental results demonstrate that the proposed method\nachieve better result than the Shannon method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 21:36:51 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["El-Sayed", "Mohamed A.", ""], ["Abdel-Khalek", "S.", ""], ["Abdel-Aziz", "Eman", ""]]}, {"id": "1401.5108", "submitter": "Mohamed A. El-Sayed", "authors": "Mohamed A. El-Sayed and Mohamed A. Khafagy", "title": "An Identification System Using Eye Detection Based On Wavelets And\n  Neural Networks", "comments": "Mohamed A. El-Sayed and Mohamed A. Khafagy, An Identification System\n  Using Eye Detection Based On Wavelets And Neural Networks. International\n  Journal Of Computer And Information Technology. Vol. 1, No. 2, pp. 43-48,\n  2012. arXiv admin note: text overlap with arXiv:1205.5097 by other authors\n  without attribution", "journal-ref": "International Journal Of Computer And Information Technology, 2012", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomness and uniqueness of human eye patterns is a major breakthrough\nin the search for quicker, easier and highly reliable forms of automatic human\nidentification. It is being used extensively in security solutions. This\nincludes access control to physical facilities, security systems and\ninformation databases, Suspect tracking, surveillance and intrusion detection\nand by various Intelligence agencies through out the world. We use the\nadvantage of human eye uniqueness to identify people and approve its validity\nas a biometric. . Eye detection involves first extracting the eye from a\ndigital face image, and then encoding the unique patterns of the eye in such a\nway that they can be compared with pre-registered eye patterns. The eye\ndetection system consists of an automatic segmentation system that is based on\nthe wavelet transform, and then the Wavelet analysis is used as a pre-processor\nfor a back propagation neural network with conjugate gradient learning. The\ninputs to the neural network are the wavelet maxima neighborhood coefficients\nof face images at a particular scale. The output of the neural network is the\nclassification of the input into an eye or non-eye region. An accuracy of 90%\nis observed for identifying test images under different conditions included in\ntraining stage.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 22:10:52 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["El-Sayed", "Mohamed A.", ""], ["Khafagy", "Mohamed A.", ""]]}, {"id": "1401.5245", "submitter": "Ayman Bahaa-Eldin", "authors": "Ayman M Bahaa-Eldeen, Abdel-Moneim A. Wahdan, Hani M. K. Mahdi", "title": "Edge detection of binary images using the method of masks", "comments": null, "journal-ref": "Ain Shams University, Faculty of Engineering Scientific Bulletin,\n  Volume 35, Issue 3, pp 349-355, (2000)", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work the method of masks, creating and using of inverted image masks,\ntogether with binary operation of image data are used in edge detection of\nbinary images, monochrome images, which yields about 300 times faster than\nordinary methods. The method is divided into three stages: Mask construction,\nFundamental edge detection, and Edge Construction Comparison with an ordinary\nmethod and a fuzzy based method is carried out.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 09:57:23 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Bahaa-Eldeen", "Ayman M", ""], ["Wahdan", "Abdel-Moneim A.", ""], ["Mahdi", "Hani M. K.", ""]]}, {"id": "1401.5311", "submitter": "Dacheng Tao", "authors": "Changxing Ding, Jonghyun Choi, Dacheng Tao and Larry S. Davis", "title": "Multi-Directional Multi-Level Dual-Cross Patterns for Robust Face\n  Recognition", "comments": "accepted version to IEEE TPAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2015.2462338", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform unconstrained face recognition robust to variations in\nillumination, pose and expression, this paper presents a new scheme to extract\n\"Multi-Directional Multi-Level Dual-Cross Patterns\" (MDML-DCPs) from face\nimages. Specifically, the MDMLDCPs scheme exploits the first derivative of\nGaussian operator to reduce the impact of differences in illumination and then\ncomputes the DCP feature at both the holistic and component levels. DCP is a\nnovel face image descriptor inspired by the unique textural structure of human\nfaces. It is computationally efficient and only doubles the cost of computing\nlocal binary patterns, yet is extremely robust to pose and expression\nvariations. MDML-DCPs comprehensively yet efficiently encodes the invariant\ncharacteristics of a face image from multiple levels into patterns that are\nhighly discriminative of inter-personal differences but robust to\nintra-personal variations. Experimental results on the FERET, CAS-PERL-R1, FRGC\n2.0, and LFW databases indicate that DCP outperforms the state-of-the-art local\ndescriptors (e.g. LBP, LTP, LPQ, POEM, tLBP, and LGXP) for both face\nidentification and face verification tasks. More impressively, the best\nperformance is achieved on the challenging LFW and FRGC 2.0 databases by\ndeploying MDML-DCPs in a simple recognition scheme.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 13:24:16 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2015 02:28:49 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Ding", "Changxing", ""], ["Choi", "Jonghyun", ""], ["Tao", "Dacheng", ""], ["Davis", "Larry S.", ""]]}, {"id": "1401.5535", "submitter": "Shu Kong", "authors": "Shu Kong, Zhuolin Jiang, Qiang Yang", "title": "Learning Mid-Level Features and Modeling Neuron Selectivity for Image\n  Classification", "comments": "19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We now know that mid-level features can greatly enhance the performance of\nimage learning, but how to automatically learn the image features efficiently\nand in an unsupervised manner is still an open question. In this paper, we\npresent a very efficient mid-level feature learning approach (MidFea), which\nonly involves simple operations such as $k$-means clustering, convolution,\npooling, vector quantization and random projection. We explain why this simple\nmethod generates the desired features, and argue that there is no need to spend\nmuch time in learning low-level feature extractors. Furthermore, to boost the\nperformance, we propose to model the neuron selectivity (NS) principle by\nbuilding an additional layer over the mid-level features before feeding the\nfeatures into the classifier. We show that the NS-layer learns\ncategory-specific neurons with both bottom-up inference and top-down analysis,\nand thus supports fast inference for a query image. We run extensive\nexperiments on several public databases to demonstrate that our approach can\nachieve state-of-the-art performances for face recognition, gender\nclassification, age estimation and object categorization. In particular, we\ndemonstrate that our approach is more than an order of magnitude faster than\nsome recently proposed sparse coding based methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 01:35:59 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2014 09:19:10 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Kong", "Shu", ""], ["Jiang", "Zhuolin", ""], ["Yang", "Qiang", ""]]}, {"id": "1401.5559", "submitter": "Norazira A Jalil", "authors": "Nuzulha Khilwani Ibrahim, Emaliana Kasmuri, Norazira A Jalil, Mohd\n  Adili Norasikin, Sazilah Salam, Mohamad Riduwan Md Nawawi", "title": "License Plate Recognition (LPR): A Review with Experiments for Malaysia\n  Case Study", "comments": null, "journal-ref": null, "doi": "10.7321/jscse.v3.n3.15", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most vehicle license plate recognition use neural network techniques to\nenhance its computing capability. The image of the vehicle license plate is\ncaptured and processed to produce a textual output for further processing. This\npaper reviews image processing and neural network techniques applied at\ndifferent stages which are preprocessing, filtering, feature extraction,\nsegmentation and recognition in such way to remove the noise of the image, to\nenhance the image quality and to expedite the computing process by converting\nthe characters in the image into respective text. An exemplar experiment has\nbeen done in MATLAB to show the basic process of the image processing\nespecially for license plate in Malaysia case study. An algorithm is adapted\ninto the solution for parking management system. The solution then is\nimplemented as proof of concept to the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 05:39:41 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Ibrahim", "Nuzulha Khilwani", ""], ["Kasmuri", "Emaliana", ""], ["Jalil", "Norazira A", ""], ["Norasikin", "Mohd Adili", ""], ["Salam", "Sazilah", ""], ["Nawawi", "Mohamad Riduwan Md", ""]]}, {"id": "1401.5589", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo", "title": "The Gabor-Einstein Wavelet: A Model for the Receptive Fields of V1 to MT\n  Neurons", "comments": "40 pages, 13 Figures. We presented a portion of this work in various\n  parts at the National Medical Association's 111th Annual Convention and\n  Scientific Assembly in Toronto Ontario, Canada (Jul. 2013); at the 23rd\n  Annual Washington Retina Symposium in Washington D.C., U.S.A. (Oct. 2013);\n  and at the Society for Neuroscience's 43rd Annual Meeting in San Diego\n  California, U.S.A. (Nov. 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our visual system is astonishingly efficient at detecting moving objects.\nThis process is mediated by the neurons which connect the primary visual cortex\n(V1) to the middle temporal (MT) area. Interestingly, since Kuffler's\npioneering experiments on retinal ganglion cells, mathematical models have been\nvital for advancing our understanding of the receptive fields of visual\nneurons. However, existing models were not designed to describe the most\nsalient attributes of the highly specialized neurons in the V1 to MT motion\nprocessing stream; and they have not been able to do so. Here, we introduce the\nGabor-Einstein wavelet, a new family of functions for representing the\nreceptive fields of V1 to MT neurons. We show that the way space and time are\nmixed in the visual cortex is analogous to the way they are mixed in the\nspecial theory of relativity (STR). Hence we constrained the Gabor-Einstein\nmodel by requiring: (i) relativistic-invariance of the wave carrier, and (ii)\nthe minimum possible number of parameters. From these two constraints, the sinc\nfunction emerged as a natural descriptor of the wave carrier. The particular\ndistribution of lowpass to bandpass temporal frequency filtering properties of\nV1 to MT neurons (Foster et al 1985; DeAngelis et al 1993b; Hawken et al 1996)\nis clearly explained by the Gabor-Einstein basis. Furthermore, it does so in a\nmanner innately representative of the motion-processing stream's neuronal\nhierarchy. Our analysis and computer simulations show that the distribution of\ntemporal frequency filtering properties along the motion processing stream is a\ndirect effect of the way the brain jointly encodes space and time. We uncovered\nthis fundamental link by demonstrating that analogous mathematical structures\nunderlie STR and joint cortical spacetime encoding. This link will provide new\nphysiological insights into how the brain represents visual information.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 08:48:53 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Odaibo", "Stephen G.", ""]]}, {"id": "1401.5632", "submitter": "Manoj Krishnaswamy", "authors": "Manoj Krishnaswamy, G. Hemantha Kumar", "title": "Enhancing Template Security of Face Biometrics by Using Edge Detection\n  and Hashing", "comments": "11 pages, 13 figures, Journal. arXiv admin note: text overlap with\n  arXiv:1307.7474 by other authors", "journal-ref": "International Journal of Information Processing, 7(4), 11-20,\n  2013, ISSN : 0973-8215", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the issues of using edge detection techniques on\nfacial images to produce cancellable biometric templates and a novel method for\ntemplate verification against tampering. With increasing use of biometrics,\nthere is a real threat for the conventional systems using face databases, which\nstore images of users in raw and unaltered form. If compromised not only it is\nirrevocable, but can be misused for cross-matching across different databases.\nSo it is desirable to generate and store revocable templates for the same user\nin different applications to prevent cross-matching and to enhance security,\nwhile maintaining privacy and ethics. By comparing different edge detection\nmethods it has been observed that the edge detection based on the Roberts Cross\noperator performs consistently well across multiple face datasets, in which the\nface images have been taken under a variety of conditions. We have proposed a\nnovel scheme using hashing, for extra verification, in order to harden the\nsecurity of the stored biometric templates.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 11:50:08 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Krishnaswamy", "Manoj", ""], ["Kumar", "G. Hemantha", ""]]}, {"id": "1401.5891", "submitter": "Mikhail Kharinov Vyacheslavovich", "authors": "M. Kharinov", "title": "Hierarchical pixel clustering for image segmentation", "comments": "5 pages, 3 figures, 4 formulas, submitted to the 12 International\n  Conference on Pattern Recognition and Information Processing May 28-30, 2014,\n  Minsk, Belarus", "journal-ref": "Proc. of the 12th International Conference on Pattern Recognition\n  and Information Processing (PRIP'2014), May 28-30, 2014, Minsk, Belarus,\n  pp.103-107", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper a piecewise constant image approximations of sequential number\nof pixel clusters or segments are treated. A majorizing of optimal\napproximation sequence by hierarchical sequence of image approximations is\nstudied. Transition from pixel clustering to image segmentation by reducing of\nsegment numbers in clusters is provided. Algorithms are proved by elementary\nformulas.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 08:33:44 GMT"}], "update_date": "2014-06-03", "authors_parsed": [["Kharinov", "M.", ""]]}, {"id": "1401.5966", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Ali Goli, Neda Barzegar Marvasti, Masoume Azghani\n  and Farokh Marvasti", "title": "Image Block Loss Restoration Using Sparsity Pattern as Side Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method for image block loss restoration based on\nthe notion of sparse representation. We use the sparsity pattern as side\ninformation to efficiently restore block losses by iteratively imposing the\nconstraints of spatial and transform domains on the corrupted image. Two novel\nfeatures, including a pre-interpolation and a criterion for stopping the\niterations, are proposed to improve the performance. Also, to deal with\npractical applications, we develop a technique to transmit the side information\nalong with the image. In this technique, we first compress the side information\nand then embed its LDPC coded version in the least significant bits of the\nimage pixels. This technique ensures the error-free transmission of the side\ninformation, while causing only a small perturbation on the transmitted image.\nMathematical analysis and extensive simulations are performed to validate the\nmethod and investigate the efficiency of the proposed techniques. The results\nverify that the proposed method outperforms its counterparts for image block\nloss restoration.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 13:23:27 GMT"}, {"version": "v2", "created": "Sat, 27 Aug 2016 00:50:13 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Hosseini", "Hossein", ""], ["Goli", "Ali", ""], ["Marvasti", "Neda Barzegar", ""], ["Azghani", "Masoume", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1401.6013", "submitter": "Linhao Li", "authors": "Linhao Li, Ping Wang, Qinghua Hu and Sijia Cai", "title": "Efficient Background Modeling Based on Sparse Representation and Outlier\n  Iterative Removal", "comments": "12pages, 10figures", "journal-ref": null, "doi": "10.1109/TCSVT.2014.2380195", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background modeling is a critical component for various vision-based\napplications. Most traditional methods tend to be inefficient when solving\nlarge-scale problems. In this paper, we introduce sparse representation into\nthe task of large scale stable background modeling, and reduce the video size\nby exploring its 'discriminative' frames. A cyclic iteration process is then\nproposed to extract the background from the discriminative frame set. The two\nparts combine to form our Sparse Outlier Iterative Removal (SOIR) algorithm.\nThe algorithm operates in tensor space to obey the natural data structure of\nvideos. Experimental results show that a few discriminative frames determine\nthe performance of the background extraction. Further, SOIR can achieve high\naccuracy and high speed simultaneously when dealing with real video sequences.\nThus, SOIR has an advantage in solving large-scale tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 15:44:48 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 07:59:54 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Li", "Linhao", ""], ["Wang", "Ping", ""], ["Hu", "Qinghua", ""], ["Cai", "Sijia", ""]]}, {"id": "1401.6108", "submitter": "Karthik Keyan vkk", "authors": "V. Karthikeyan, Manjupriya, C.K. Chithra, M. Divya", "title": "Face Verification Using Kernel Principle Component Analysis", "comments": "7 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the beginning stage, face verification is done using easy method of\ngeometric algorithm models, but the verification route has now developed into a\nscientific progress of complicated geometric representation and matching\nprocess. In modern time the skill have enhanced face detection system into the\nvigorous focal point. Researchers currently undergoing strong research on\nfinding face recognition system for wider area information taken under\nhysterical elucidation dissimilarity. The proposed face recognition system\nconsists of a narrative exposition indiscreet preprocessing method, a hybrid\nFourier-based facial feature extraction and a score fusion scheme. We take in\nconventional the face detection in unlike cheer up circumstances and at unusual\nsetting. Image processing, Image detection, Feature removal and Face detection\nare the methods used for Face Verification System . This paper focuses mainly\non the issue of toughness to lighting variations. The proposed system has\nobtained an average of verification rate on Two-Dimensional images under\ndifferent lightening conditions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 10:37:03 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Karthikeyan", "V.", ""], ["Manjupriya", "", ""], ["Chithra", "C. K.", ""], ["Divya", "M.", ""]]}, {"id": "1401.6112", "submitter": "Karthik Keyan vkk", "authors": "V. Karthikeyan, M. Divya, C.K. Chithra, K. Manju Priya", "title": "Face Verification System based on Integral Normalized Gradient\n  Image(INGI)", "comments": null, "journal-ref": null, "doi": "10.5120/11116-6077", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character identification plays a vital role in the contemporary world of\nImage processing. It can solve many composite problems and makes humans work\neasier. An instance is Handwritten Character detection. Handwritten recognition\nis not a novel expertise, but it has not gained community notice until Now. The\neventual aim of designing Handwritten Character recognition structure with an\naccurateness rate of 100% is pretty illusionary. Tamil Handwritten Character\nrecognition system uses the Neural Networks to distinguish them. Neural Network\nand structural characteristics are used to instruct and recognize written\ncharacters. After training and testing the exactness rate reached 99%. This\ncorrectness rate is extremely high. In this paper we are exploring image\nprocessing through the Hilditch algorithm foundation and structural\ncharacteristics of a character in the image. And we recognized some character\nof the Tamil language, and we are trying to identify all the character of Tamil\nIn our future works.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 09:58:36 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Karthikeyan", "V.", ""], ["Divya", "M.", ""], ["Chithra", "C. K.", ""], ["Priya", "K. Manju", ""]]}, {"id": "1401.6126", "submitter": "Andrew Gleibman Ph.D.", "authors": "Andrew Gleibman", "title": "Delegating Custom Object Detection Tasks to a Universal Classification\n  System", "comments": "3 pages, 2 figures, 6 refs. arXiv admin note: substantial text\n  overlap with arXiv:1310.7170", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a concept of multipurpose object detection system, recently\nintroduced in our previous work, is clarified. The business aspect of this\nmethod is transformation of a classifier into an object detector/locator via an\nimage grid. This is a universal framework for locating objects of interest\nthrough classification. The framework standardizes and simplifies\nimplementation of custom systems by doing only a custom analysis of the\nclassification results on the image grid.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 08:17:24 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Gleibman", "Andrew", ""]]}, {"id": "1401.6127", "submitter": "Vaishali Khairnar mrs", "authors": "Narkhede Sachin G, Vaishali Khairnar", "title": "Brain Tumor Detection Based On Symmetry Information", "comments": "3 Pages, 3 figures, 2 tables", "journal-ref": "Int. Journal of Engineering Research and Application Vol. 3, Issue\n  6, Nov - Dec 2013, pp. 430 -432 (ISSN : 2248 - 9622)", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computing technology have allowed researchers across many fields\nof endeavor to collect and maintain vast amounts of observational statistical\ndata such as clinical data, biological patient data, data regarding access of\nweb sites, financial data, and the like. This paper addresses some of the\nchallenging issues on brain magnetic resonance (MR) image tumor segmentation\ncaused by the weak correlation between magnetic resonance imaging (MRI)\nintensity and anatomical meaning. With the objective of utilizing more\nmeaningful information to improve brain tumor segmentation, an approach which\nemploys bilateral symmetry information as an additional feature for\nsegmentation is proposed. This is motivated by potential performance\nimprovement in the general automatic brain tumor segmentation systems which are\nimportant for many medical and scientific applications\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2013 08:25:08 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["G", "Narkhede Sachin", ""], ["Khairnar", "Vaishali", ""]]}, {"id": "1401.6129", "submitter": "Yogesh Ghodake Mr", "authors": "S.M.Mukane, Y.S.Ghodake and P.S.Khandagle", "title": "Image enhancement using fusion by wavelet transform and laplacian\n  pyramid", "comments": null, "journal-ref": "Published in IJCSI Journal, Volume 10, Issue 4, No 2, July 2013", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of combining multiple image modalities to provide a single, enhanced\nimage is well established different fusion methods have been proposed in\nliterature. This paper is based on image fusion using laplacian pyramid and\nwavelet transform method. Images of same size are used for experimentation.\nImages used for the experimentation are standard images and averaging filter is\nused of equal weights in original images to burl. Performance of image fusion\ntechnique is measured by mean square error, normalized absolute error and peak\nsignal to noise ratio. From the performance analysis it has been observed that\nMSE is decreased in case of both the methods where as PSNR increased, NAE\ndecreased in case of laplacian pyramid where as constant for wavelet transform\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 14:14:18 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Mukane", "S. M.", ""], ["Ghodake", "Y. S.", ""], ["Khandagle", "P. S.", ""]]}, {"id": "1401.6130", "submitter": "Muthu Kalyani k", "authors": "MuthuKalyani.K, VeeraMuthu.A", "title": "smart application for AMS using Face Recognition", "comments": "20 pages,4 figures", "journal-ref": "Computer Science & Engineering: An International Journal (CSEIJ),\n  Vol. 3, No. 5, October 2013", "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attendance Management System (AMS) can be made into smarter way by using face\nrecognition technique, where we use a CCTV camera to be fixed at the entry\npoint of a classroom, which automatically captures the image of the person and\nchecks the observed image with the face database using android enhanced smart\nphone. It is typically used for two purposes. Firstly, marking attendance for\nstudent by comparing the face images produced recently and secondly,\nrecognition of human who are strange to the environment i.e. an unauthorized\nperson For verification of image, a newly emerging trend 3D Face Recognition is\nused which claims to provide more accuracy in matching the image databases and\nhas an ability to recognize a subject at different view angles.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 15:24:15 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["K", "MuthuKalyani.", ""], ["A", "VeeraMuthu.", ""]]}, {"id": "1401.6196", "submitter": "Quan Zhou", "authors": "Q. Zhou, O. Michailovich and Y. Rathi", "title": "Spatially regularized reconstruction of fibre orientation distributions\n  in the presence of isotropic diffusion", "comments": "33 pages, 14 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectivity and structural integrity of the white matter of the brain is\nnowadays known to be implicated into a wide range of brain-related disorders.\nHowever, it was not before the advent of diffusion Magnetic Resonance Imaging\n(dMRI) that researches have been able to examine the properties of white matter\nin vivo. Presently, among a range of various methods of dMRI, high angular\nresolution diffusion imaging (HARDI) is known to excel in its ability to\nprovide reliable information about the local orientations of neural fasciculi\n(aka fibre tracts). Moreover, as opposed to the more traditional diffusion\ntensor imaging (DTI), HARDI is capable of distinguishing the orientations of\nmultiple fibres passing through a given spatial voxel. Unfortunately, the\nability of HARDI to discriminate between neural fibres that cross each other at\nacute angles is always limited, which is the main reason behind the development\nof numerous post-processing tools, aiming at the improvement of the directional\nresolution of HARDI. Among such tools is spherical deconvolution (SD). Due to\nits ill-posed nature, however, SD standardly relies on a number of a priori\nassumptions which are to render its results unique and stable. In this paper,\nwe propose a different approach to the problem of SD in HARDI, which accounts\nfor the spatial continuity of neural fibres as well as the presence of\nisotropic diffusion. Subsequently, we demonstrate how the proposed solution can\nbe used to successfully overcome the effect of partial voluming, while\npreserving the spatial coherency of cerebral diffusion at moderate-to-severe\nnoise levels. In a series of both in silico and in vivo experiments, the\nperformance of the proposed method is compared with that of several available\nalternatives, with the comparative results clearly supporting the viability and\nusefulness of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 21:37:48 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Zhou", "Q.", ""], ["Michailovich", "O.", ""], ["Rathi", "Y.", ""]]}, {"id": "1401.6393", "submitter": "Radu Horaud P", "authors": "Miles Hansard, Radu Horaud, Michel Amat, Georgios Evangelidis", "title": "Automatic Detection of Calibration Grids in Time-of-Flight Images", "comments": "11 pages, 11 figures, 1 table", "journal-ref": "Computer Vision and Image Understanding, 121, 2014", "doi": "10.1016/j.cviu.2014.01.007", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is convenient to calibrate time-of-flight cameras by established methods,\nusing images of a chequerboard pattern. The low resolution of the amplitude\nimage, however, makes it difficult to detect the board reliably. Heuristic\ndetection methods, based on connected image-components, perform very poorly on\nthis data. An alternative, geometrically-principled method is introduced here,\nbased on the Hough transform. The projection of a chequerboard is represented\nby two pencils of lines, which are identified as oriented clusters in the\ngradient-data of the image. A projective Hough transform is applied to each of\nthe two clusters, in axis-aligned coordinates. The range of each transform is\nproperly bounded, because the corresponding gradient vectors are approximately\nparallel. Each of the two transforms contains a series of collinear peaks; one\nfor every line in the given pencil. This pattern is easily detected, by\nsweeping a dual line through the transform. The proposed Hough-based method is\ncompared to the standard OpenCV detection routine, by application to several\nhundred time-of-flight images. It is shown that the new method detects\nsignificantly more calibration boards, over a greater variety of poses, without\nany overall loss of accuracy. This conclusion is based on an analysis of both\ngeometric and photometric error.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 16:25:56 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Hansard", "Miles", ""], ["Horaud", "Radu", ""], ["Amat", "Michel", ""], ["Evangelidis", "Georgios", ""]]}, {"id": "1401.6497", "submitter": "Qibin Zhao Dr", "authors": "Qibin Zhao, Liqing Zhang, and Andrzej Cichocki", "title": "Bayesian CP Factorization of Incomplete Tensors with Automatic Rank\n  Determination", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2015.2392756", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CANDECOMP/PARAFAC (CP) tensor factorization of incomplete data is a powerful\ntechnique for tensor completion through explicitly capturing the multilinear\nlatent factors. The existing CP algorithms require the tensor rank to be\nmanually specified, however, the determination of tensor rank remains a\nchallenging problem especially for CP rank. In addition, existing approaches do\nnot take into account uncertainty information of latent factors, as well as\nmissing entries. To address these issues, we formulate CP factorization using a\nhierarchical probabilistic model and employ a fully Bayesian treatment by\nincorporating a sparsity-inducing prior over multiple latent factors and the\nappropriate hyperpriors over all hyperparameters, resulting in automatic rank\ndetermination. To learn the model, we develop an efficient deterministic\nBayesian inference algorithm, which scales linearly with data size. Our method\nis characterized as a tuning parameter-free approach, which can effectively\ninfer underlying multilinear factors with a low-rank constraint, while also\nproviding predictive distributions over missing entries. Extensive simulations\non synthetic data illustrate the intrinsic capability of our method to recover\nthe ground-truth of CP rank and prevent the overfitting problem, even when a\nlarge amount of entries are missing. Moreover, the results from real-world\napplications, including image inpainting and facial image synthesis,\ndemonstrate that our method outperforms state-of-the-art approaches for both\ntensor factorization and tensor completion in terms of predictive performance.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2014 05:08:33 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2014 09:48:37 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Zhao", "Qibin", ""], ["Zhang", "Liqing", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1401.6606", "submitter": "Giuseppe Lisanti", "authors": "Giuseppe Lisanti and Iacopo Masi and Federico Pernici and Alberto Del\n  Bimbo", "title": "Continuous Localization and Mapping of a Pan Tilt Zoom Camera for Wide\n  Area Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pan-tilt-zoom (PTZ) cameras are powerful to support object identification and\nrecognition in far-field scenes. However, the effective use of PTZ cameras in\nreal contexts is complicated by the fact that a continuous on-line camera\ncalibration is needed and the absolute pan, tilt and zoom positional values\nprovided by the camera actuators cannot be used because are not synchronized\nwith the video stream. So, accurate calibration must be directly extracted from\nthe visual content of the frames. Moreover, the large and abrupt scale changes,\nthe scene background changes due to the camera operation and the need of camera\nmotion compensation make target tracking with these cameras extremely\nchallenging. In this paper, we present a solution that provides continuous\non-line calibration of PTZ cameras which is robust to rapid camera motion,\nchanges of the environment due to illumination or moving objects and scales\nbeyond thousands of landmarks. The method directly derives the relationship\nbetween the position of a target in the 3D world plane and the corresponding\nscale and position in the 2D image, and allows real-time tracking of multiple\ntargets with high and stable degree of accuracy even at far distances and any\nzooming level.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 02:23:56 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2015 18:28:02 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Lisanti", "Giuseppe", ""], ["Masi", "Iacopo", ""], ["Pernici", "Federico", ""], ["Del Bimbo", "Alberto", ""]]}, {"id": "1401.6638", "submitter": "Tong Wu", "authors": "Tong Wu, Gungor Polatkan, David Steel, William Brown, Ingrid\n  Daubechies and Robert Calderbank", "title": "Painting Analysis Using Wavelets and Probabilistic Topic Models", "comments": "5 pages, 4 figures, ICIP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, computer-based techniques for stylistic analysis of paintings\nare applied to the five panels of the 14th century Peruzzi Altarpiece by Giotto\ndi Bondone. Features are extracted by combining a dual-tree complex wavelet\ntransform with a hidden Markov tree (HMT) model. Hierarchical clustering is\nused to identify stylistic keywords in image patches, and keyword frequencies\nare calculated for sub-images that each contains many patches. A generative\nhierarchical Bayesian model learns stylistic patterns of keywords; these\npatterns are then used to characterize the styles of the sub-images; this in\nturn, permits to discriminate between paintings. Results suggest that such\nunsupervised probabilistic topic models can be useful to distill characteristic\nelements of style.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 11:00:46 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Wu", "Tong", ""], ["Polatkan", "Gungor", ""], ["Steel", "David", ""], ["Brown", "William", ""], ["Daubechies", "Ingrid", ""], ["Calderbank", "Robert", ""]]}, {"id": "1401.6929", "submitter": "Wojciech Wislicki", "authors": "W. Wi\\'slicki, T. Bednarski, P. Bia{\\l}as, E. Czerwi\\'nski, {\\L}.\n  Kap{\\l}on, A. Kochanowski, G. Korcyl, J. Kowal, P. Kowalski, T. Kozik, W.\n  Krzemie\\'n, M. Molenda, P. Moskal, S. Nied\\'zwiecki, M. Pa{\\l}ka, M. Pawlik,\n  L. Raczy\\'nski, Z. Rudy, P. Salabura, N.G. Sharma, M. Silarski, A.\n  S{\\l}omski, J. Smyrski, A. Strzelecki, A. Wieczorek, M. Zieli\\'nski, N. Zo\\'n", "title": "Computing support for advanced medical data analysis and imaging", "comments": "9 p, 3 figs, based on talk given at Symposium on Positron Emission\n  Tomography, Sept. 19-22, 2013, Jagiellonian University, Krak\\'ow, Pl", "journal-ref": "Bio-Algorithms and Med-Systems 10(2014)52", "doi": "10.1515/bams-2014-0001", "report-no": null, "categories": "physics.comp-ph cs.CV cs.DC physics.ins-det physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss computing issues for data analysis and image reconstruction of\nPET-TOF medical scanner or other medical scanning devices producing large\nvolumes of data. Service architecture based on the grid and cloud concepts for\ndistributed processing is proposed and critically discussed.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 17:02:37 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Wi\u015blicki", "W.", ""], ["Bednarski", "T.", ""], ["Bia\u0142as", "P.", ""], ["Czerwi\u0144ski", "E.", ""], ["Kap\u0142on", "\u0141.", ""], ["Kochanowski", "A.", ""], ["Korcyl", "G.", ""], ["Kowal", "J.", ""], ["Kowalski", "P.", ""], ["Kozik", "T.", ""], ["Krzemie\u0144", "W.", ""], ["Molenda", "M.", ""], ["Moskal", "P.", ""], ["Nied\u017awiecki", "S.", ""], ["Pa\u0142ka", "M.", ""], ["Pawlik", "M.", ""], ["Raczy\u0144ski", "L.", ""], ["Rudy", "Z.", ""], ["Salabura", "P.", ""], ["Sharma", "N. G.", ""], ["Silarski", "M.", ""], ["S\u0142omski", "A.", ""], ["Smyrski", "J.", ""], ["Strzelecki", "A.", ""], ["Wieczorek", "A.", ""], ["Zieli\u0144ski", "M.", ""], ["Zo\u0144", "N.", ""]]}, {"id": "1401.7413", "submitter": "Canyi Lu", "authors": "Canyi Lu, Zhouchen Lin, Shuicheng Yan", "title": "Smoothed Low Rank and Sparse Matrix Recovery by Iteratively Reweighted\n  Least Squares Minimization", "comments": "IEEE Transactions on Image Processing 2015", "journal-ref": null, "doi": "10.1109/TIP.2014.2380155", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a general framework for solving the low rank and/or sparse\nmatrix minimization problems, which may involve multiple non-smooth terms. The\nIteratively Reweighted Least Squares (IRLS) method is a fast solver, which\nsmooths the objective function and minimizes it by alternately updating the\nvariables and their weights. However, the traditional IRLS can only solve a\nsparse only or low rank only minimization problem with squared loss or an\naffine constraint. This work generalizes IRLS to solve joint/mixed low rank and\nsparse minimization problems, which are essential formulations for many tasks.\nAs a concrete example, we solve the Schatten-$p$ norm and $\\ell_{2,q}$-norm\nregularized Low-Rank Representation (LRR) problem by IRLS, and theoretically\nprove that the derived solution is a stationary point (globally optimal if\n$p,q\\geq1$). Our convergence proof of IRLS is more general than previous one\nwhich depends on the special properties of the Schatten-$p$ norm and\n$\\ell_{2,q}$-norm. Extensive experiments on both synthetic and real data sets\ndemonstrate that our IRLS is much more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 05:16:52 GMT"}, {"version": "v2", "created": "Sat, 6 Dec 2014 14:20:42 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Lu", "Canyi", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1401.7486", "submitter": "Mehdi Gheisari", "authors": "Payam Porkar Rezaeiye, mehrnoosh bazrafkan, ali akbar movassagh,\n  Mojtaba Sedigh Fazli, Gholam hossein bazyari", "title": "Use HMM and KNN for classifying corneal data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  These days to gain classification system with high accuracy that can classify\ncomplicated pattern are so useful in medicine and industry. In this article a\nprocess for getting the best classifier for Lasik data is suggested. However at\nfirst it's been tried to find the best line and curve by this classifier in\norder to gain classifier fitting, and in the end by using the Markov method a\nclassifier for topographies is gained.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 12:27:39 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Rezaeiye", "Payam Porkar", ""], ["bazrafkan", "mehrnoosh", ""], ["movassagh", "ali akbar", ""], ["Fazli", "Mojtaba Sedigh", ""], ["bazyari", "Gholam hossein", ""]]}, {"id": "1401.7517", "submitter": "Mikhail Kharinov Vyacheslavovich", "authors": "M. Kharinov", "title": "Information quantity in a pixel of digital image", "comments": "11 pages, 4 figures, 1 definition, 5 formulas", "journal-ref": "M.V. Kharinov, Information quantity in a pixel of digital image,\n  Bulletin of the Buryat State University. Mathematics and Informatics. 2013.\n  No 2, Ulan-Ude, Russia, pp. 95-104. ISSN 2304-5728 [in Russian]", "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to the problem of integer-valued estimating of\ninformation quantity in a pixel of digital image. The definition of an integer\nestimation of information quantity based on constructing of the certain binary\nhierarchy of pixel clusters is proposed. The methods for constructing\nhierarchies of clusters and generating of hierarchical sequences of image\napproximations that minimally differ from the image by a standard deviation are\ndeveloped. Experimental results on integer-valued estimation of information\nquantity are compared with the results obtained by utilizing of the classical\nformulas.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 14:03:46 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Kharinov", "M.", ""]]}, {"id": "1401.7623", "submitter": "Alex Bronstein", "authors": "Yonathan Aflalo, Alex Bronstein, Ron Kimmel", "title": "Graph matching: relax or not?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of exact and inexact matching of weighted undirected\ngraphs, in which a bijective correspondence is sought to minimize a quadratic\nweight disagreement. This computationally challenging problem is often relaxed\nas a convex quadratic program, in which the space of permutations is replaced\nby the space of doubly-stochastic matrices. However, the applicability of such\na relaxation is poorly understood. We define a broad class of friendly graphs\ncharacterized by an easily verifiable spectral property. We prove that for\nfriendly graphs, the convex relaxation is guaranteed to find the exact\nisomorphism or certify its inexistence. This result is further extended to\napproximately isomorphic graphs, for which we develop an explicit bound on the\namount of weight disagreement under which the relaxation is guaranteed to find\nthe globally optimal approximate isomorphism. We also show that in many cases,\nthe graph matching problem can be further harmlessly relaxed to a convex\nquadratic program with only n separable linear equality constraints, which is\nsubstantially more efficient than the standard relaxation involving 2n equality\nand n^2 inequality constraints. Finally, we show that our results are still\nvalid for unfriendly graphs if additional information in the form of seeds or\nattributes is allowed, with the latter satisfying an easy to verify spectral\ncharacteristic.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 18:59:06 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2014 13:41:56 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2014 21:39:57 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2014 12:51:21 GMT"}, {"version": "v5", "created": "Sun, 12 Oct 2014 22:27:57 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Aflalo", "Yonathan", ""], ["Bronstein", "Alex", ""], ["Kimmel", "Ron", ""]]}, {"id": "1401.7713", "submitter": "Lingqiao Liu", "authors": "Lingqiao Liu, Lei Wang, Chunhua Shen", "title": "A Generalized Probabilistic Framework for Compact Codebook Creation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compact and discriminative visual codebooks are preferred in many visual\nrecognition tasks. In the literature, a number of works have taken the approach\nof hierarchically merging visual words of an initial large-sized codebook, but\nimplemented this approach with different merging criteria. In this work, we\npropose a single probabilistic framework to unify these merging criteria, by\nidentifying two key factors: the function used to model class-conditional\ndistribution and the method used to estimate the distribution parameters. More\nimportantly, by adopting new distribution functions and/or parameter estimation\nmethods, our framework can readily produce a spectrum of novel merging\ncriteria. Three of them are specifically focused in this work. In the first\ncriterion, we adopt the multinomial distribution with Bayesian method; In the\nsecond criterion, we integrate Gaussian distribution with maximum likelihood\nparameter estimation. In the third criterion, which shows the best merging\nperformance, we propose a max-margin-based parameter estimation method and\napply it with multinomial distribution. Extensive experimental study is\nconducted to systematically analyse the performance of the above three criteria\nand compare them with existing ones. As demonstrated, the best criterion\nobtained in our framework achieves the overall best merging performance among\nthe comparable merging criteria developed in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 01:02:50 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Liu", "Lingqiao", ""], ["Wang", "Lei", ""], ["Shen", "Chunhua", ""]]}, {"id": "1401.7715", "submitter": "Jianing Shi", "authors": "Jianing V. Shi, Wotao Yin, Aswin C. Sankaranarayanan, and Richard G.\n  Baraniuk", "title": "Video Compressive Sensing for Dynamic MRI", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a video compressive sensing framework, termed kt-CSLDS, to\naccelerate the image acquisition process of dynamic magnetic resonance imaging\n(MRI). We are inspired by a state-of-the-art model for video compressive\nsensing that utilizes a linear dynamical system (LDS) to model the motion\nmanifold. Given compressive measurements, the state sequence of an LDS can be\nfirst estimated using system identification techniques. We then reconstruct the\nobservation matrix using a joint structured sparsity assumption. In particular,\nwe minimize an objective function with a mixture of wavelet sparsity and joint\nsparsity within the observation matrix. We derive an efficient convex\noptimization algorithm through alternating direction method of multipliers\n(ADMM), and provide a theoretical guarantee for global convergence. We\ndemonstrate the performance of our approach for video compressive sensing, in\nterms of reconstruction accuracy. We also investigate the impact of various\nsampling strategies. We apply this framework to accelerate the acquisition\nprocess of dynamic MRI and show it achieves the best reconstruction accuracy\nwith the least computational time compared with existing algorithms in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 01:18:26 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2014 22:50:51 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Shi", "Jianing V.", ""], ["Yin", "Wotao", ""], ["Sankaranarayanan", "Aswin C.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1401.7743", "submitter": "Balaji T", "authors": "T.Balaji and Dr.M.Sumathi", "title": "Effective Features of Remote Sensing Image Classification Using\n  Interactive Adaptive Thresholding Method", "comments": "5 pages,International Conference on Intelligent Computing\n  Applications - ICICA 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Remote sensing image classification can be performed in many different ways\nto extract meaningful features. One common approach is to perform edge\ndetection. A second approach is to try and detect whole shapes, given the fact\nthat these shapes usually tend to have distinctive properties such as object\nforeground or background. To get optimal results, these two approaches can be\ncombined. This paper adopts a combinatorial optimization method to adaptively\nselect threshold based features to improve remote sensing image. Feature\nselection is an important combinatorial optimization problem in the remote\nsensing image classification. The feature selection method has to achieve three\ncharacteristics: first the performance issues by facilitating data collection\nand reducing storage space and classification time, second to perform semantics\nanalysis helping to understand the problem, and third to improve prediction\naccuracy by avoiding the curse of dimensionality. The goal of this thresholding\nan image is to classify pixels as either dark or light and evaluation of\nclassification results. Interactive adaptive thresholding is a form of\nthresholding that takes into account spatial variations in illumination of\nremote sensing image. We present a technique for remote sensing based adaptive\nthresholding using the interactive satellite image of the input. However, our\nsolution is more robust to illumination changes in the remote sensing image.\nAdditionally, our method is simple and easy to implement but it is effective\nalgorithm to classify the image pixels. This technique is suitable for\npreprocessing the remote sensing image classification, making it a valuable\ntool for interactive remote based applications such as augmented reality of the\nclassification procedure.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 05:33:27 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Balaji", "T.", ""], ["Sumathi", "Dr. M.", ""]]}, {"id": "1401.8053", "submitter": "Ognjen Arandjelovi\\'c PhD", "authors": "Ognjen Arandjelovic", "title": "Hallucinating optimal high-dimensional subspaces", "comments": "Pattern Recognition, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear subspace representations of appearance variation are pervasive in\ncomputer vision. This paper addresses the problem of robustly matching such\nsubspaces (computing the similarity between them) when they are used to\ndescribe the scope of variations within sets of images of different (possibly\ngreatly so) scales. A naive solution of projecting the low-scale subspace into\nthe high-scale image space is described first and subsequently shown to be\ninadequate, especially at large scale discrepancies. A successful approach is\nproposed instead. It consists of (i) an interpolated projection of the\nlow-scale subspace into the high-scale space, which is followed by (ii) a\nrotation of this initial estimate within the bounds of the imposed\n``downsampling constraint''. The optimal rotation is found in the closed-form\nwhich best aligns the high-scale reconstruction of the low-scale subspace with\nthe reference it is compared to. The method is evaluated on the problem of\nmatching sets of (i) face appearances under varying illumination and (ii)\nobject appearances under varying viewpoint, using two large data sets. In\ncomparison to the naive matching, the proposed algorithm is shown to greatly\nincrease the separation of between-class and within-class similarities, as well\nas produce far more meaningful modes of common appearance on which the match\nscore is based.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 03:28:10 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Arandjelovic", "Ognjen", ""]]}, {"id": "1401.8092", "submitter": "Radu Horaud P", "authors": "Miles Hansard, Georgios Evangelidis, Quentin Pelorson, and Radu Horaud", "title": "Cross-calibration of Time-of-flight and Colour Cameras", "comments": "18 pages, 12 figures, 3 tables", "journal-ref": "Computer Vision and Image Understanding, 134, pp.105-115, 2015", "doi": "10.1016/j.cviu.2014.09.001", "report-no": null, "categories": "cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-of-flight cameras provide depth information, which is complementary to\nthe photometric appearance of the scene in ordinary images. It is desirable to\nmerge the depth and colour information, in order to obtain a coherent scene\nrepresentation. However, the individual cameras will have different viewpoints,\nresolutions and fields of view, which means that they must be mutually\ncalibrated. This paper presents a geometric framework for this multi-view and\nmulti-modal calibration problem. It is shown that three-dimensional projective\ntransformations can be used to align depth and parallax-based representations\nof the scene, with or without Euclidean reconstruction. A new evaluation\nprocedure is also developed; this allows the reprojection error to be\ndecomposed into calibration and sensor-dependent components. The complete\napproach is demonstrated on a network of three time-of-flight and six colour\ncameras. The applications of such a system, to a range of automatic\nscene-interpretation problems, are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 09:23:26 GMT"}, {"version": "v2", "created": "Mon, 30 Jun 2014 12:07:18 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Hansard", "Miles", ""], ["Evangelidis", "Georgios", ""], ["Pelorson", "Quentin", ""], ["Horaud", "Radu", ""]]}, {"id": "1401.8126", "submitter": "Chunhua Shen", "authors": "Mehrtash Harandi, Richard Hartley, Chunhua Shen, Brian Lovell, Conrad\n  Sanderson", "title": "Extrinsic Methods for Coding and Dictionary Learning on Grassmann\n  Manifolds", "comments": "Appearing in International Journal of Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-based representations have recently led to notable results in\nvarious visual recognition tasks. In a separate line of research, Riemannian\nmanifolds have been shown useful for dealing with features and models that do\nnot lie in Euclidean spaces. With the aim of building a bridge between the two\nrealms, we address the problem of sparse coding and dictionary learning over\nthe space of linear subspaces, which form Riemannian structures known as\nGrassmann manifolds. To this end, we propose to embed Grassmann manifolds into\nthe space of symmetric matrices by an isometric mapping. This in turn enables\nus to extend two sparse coding schemes to Grassmann manifolds. Furthermore, we\npropose closed-form solutions for learning a Grassmann dictionary, atom by\natom. Lastly, to handle non-linearity in data, we extend the proposed Grassmann\nsparse coding and dictionary learning algorithms through embedding into Hilbert\nspaces.\n  Experiments on several classification tasks (gender recognition, gesture\nclassification, scene analysis, face recognition, action recognition and\ndynamic texture classification) show that the proposed approaches achieve\nconsiderable improvements in discrimination accuracy, in comparison to\nstate-of-the-art methods such as kernelized Affine Hull Method and\ngraph-embedding Grassmann discriminant analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 10:59:38 GMT"}, {"version": "v2", "created": "Wed, 20 May 2015 00:12:44 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Harandi", "Mehrtash", ""], ["Hartley", "Richard", ""], ["Shen", "Chunhua", ""], ["Lovell", "Brian", ""], ["Sanderson", "Conrad", ""]]}, {"id": "1401.8261", "submitter": "Ognjen Arandjelovi\\'c PhD", "authors": "Reza Shoja Ghiass, Ognjen Arandjelovic, Hakim Bendada, Xavier Maldague", "title": "Infrared face recognition: a comprehensive review of methodologies and\n  databases", "comments": "Pattern Recognition, 2014. arXiv admin note: substantial text overlap\n  with arXiv:1306.1603", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic face recognition is an area with immense practical potential which\nincludes a wide range of commercial and law enforcement applications. Hence it\nis unsurprising that it continues to be one of the most active research areas\nof computer vision. Even after over three decades of intense research, the\nstate-of-the-art in face recognition continues to improve, benefitting from\nadvances in a range of different research fields such as image processing,\npattern recognition, computer graphics, and physiology. Systems based on\nvisible spectrum images, the most researched face recognition modality, have\nreached a significant level of maturity with some practical success. However,\nthey continue to face challenges in the presence of illumination, pose and\nexpression changes, as well as facial disguises, all of which can significantly\ndecrease recognition accuracy. Amongst various approaches which have been\nproposed in an attempt to overcome these limitations, the use of infrared (IR)\nimaging has emerged as a particularly promising research direction. This paper\npresents a comprehensive and timely review of the literature on this subject.\nOur key contributions are: (i) a summary of the inherent properties of infrared\nimaging which makes this modality promising in the context of face recognition,\n(ii) a systematic review of the most influential approaches, with a focus on\nemerging common trends as well as key differences between alternative\nmethodologies, (iii) a description of the main databases of infrared facial\nimages available to the researcher, and lastly (iv) a discussion of the most\npromising avenues for future research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 01:04:10 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Ghiass", "Reza Shoja", ""], ["Arandjelovic", "Ognjen", ""], ["Bendada", "Hakim", ""], ["Maldague", "Xavier", ""]]}]