[{"id": "1202.0216", "submitter": "Fernand  Meyer", "authors": "Fernand Meyer", "title": "The watershed concept and its use in segmentation : a brief history", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The watershed is one of the most used tools in image segmentation. We present\nhow its concept is born and developed over time. Its implementation as an\nalgorithm or a hardwired device evolved together with the technology which\nallowed it. We present also how it is used in practice, first together with\nmarkers, and later introduced in a multiscale framework, in order to produce\nnot a unique partition but a complete hierarchy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 17:00:45 GMT"}], "update_date": "2012-02-02", "authors_parsed": [["Meyer", "Fernand", ""]]}, {"id": "1202.0492", "submitter": "Peter Abeles Mr", "authors": "Peter Abeles", "title": "Resolving Implementation Ambiguity and Improving SURF", "comments": "Fixed incorrect contact information contained in previous version and\n  clarified publication information. Additional small changes for grammar and\n  clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speeded Up Robust Features (SURF) has emerged as one of the more popular\nfeature descriptors and detectors in recent years. Performance and algorithmic\ndetails vary widely between implementations due to SURF's complexity and\nambiguities found in its description. To resolve these ambiguities, a set of\ngeneral techniques for feature stability is defined based on the smoothness\nrule. Additional improvements to SURF are proposed for speed and stability. To\nillustrate the importance of these implementation details, a performance study\nof popular SURF implementations is done. By utilizing all the suggested\nimprovements, it is possible to create a SURF implementation that is several\ntimes faster and more stable.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2012 17:10:56 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2012 17:35:50 GMT"}, {"version": "v3", "created": "Sat, 3 Mar 2012 03:15:12 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Abeles", "Peter", ""]]}, {"id": "1202.0549", "submitter": "Gautam Thakur", "authors": "Gautam S. Thakur, Mohsen Ali, Pan Hui and Ahmed Helmy", "title": "Comparing Background Subtraction Algorithms and Method of Car Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare various image background subtraction algorithms\nwith the ground truth of cars counted. We have given a sample of thousand\nimages, which are the snap shots of current traffic as records at various\nintersections and highways. We have also counted an approximate number of cars\nthat are visible in these images. In order to ascertain the accuracy of\nalgorithms to be used for the processing of million images, we compare them on\nmany metrics that includes (i) Scalability (ii) Accuracy (iii) Processing time.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2012 19:19:33 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Thakur", "Gautam S.", ""], ["Ali", "Mohsen", ""], ["Hui", "Pan", ""], ["Helmy", "Ahmed", ""]]}, {"id": "1202.0609", "submitter": "Roberto Herrera", "authors": "Roberto Henry Herrera and Rub\\'en Orozco and Manuel Rodr\\'iguez", "title": "Wavelet-based deconvolution of ultrasonic signals in nondestructive\n  evaluation", "comments": null, "journal-ref": "J Zhejiang Univ SCIENCE A 2006", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the inverse problem of reconstructing reflectivity function of\na medium is examined within a blind deconvolution framework. The ultrasound\npulse is estimated using higher-order statistics, and Wiener filter is used to\nobtain the ultrasonic reflectivity function through wavelet-based models. A new\napproach to the parameter estimation of the inverse filtering step is proposed\nin the nondestructive evaluation field, which is based on the theory of\nFourier-Wavelet regularized deconvolution (ForWaRD). This new approach can be\nviewed as a solution to the open problem of adaptation of the ForWaRD framework\nto perform the convolution kernel estimation and deconvolution\ninterdependently. The results indicate stable solutions of the estimated pulse\nand an improvement in the radio-frequency (RF) signal taking into account its\nsignal-to-noise ratio (SNR) and axial resolution. Simulations and experiments\nshowed that the proposed approach can provide robust and optimal estimates of\nthe reflectivity function.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 05:43:46 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Herrera", "Roberto Henry", ""], ["Orozco", "Rub\u00e9n", ""], ["Rodr\u00edguez", "Manuel", ""]]}, {"id": "1202.0940", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Akshay Maan", "title": "Improving feature selection algorithms using normalised feature\n  histograms", "comments": null, "journal-ref": "Electronics Letters,47, 8, 490-491, 2011", "doi": "10.1049/el.2010.3672", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The proposed feature selection method builds a histogram of the most stable\nfeatures from random subsets of a training set and ranks the features based on\na classifier based cross-validation. This approach reduces the instability of\nfeatures obtained by conventional feature selection methods that occur with\nvariation in training data and selection criteria. Classification results on\nfour microarray and three image datasets using three major feature selection\ncriteria and a naive Bayes classifier show considerable improvement over\nbenchmark results.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2012 04:37:40 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["James", "Alex Pappachen", ""], ["Maan", "Akshay", ""]]}, {"id": "1202.1444", "submitter": "Augusto Salazar Mr.", "authors": "Augusto Salazar, Stefanie Wuhrer, Chang Shu and Flavio Prieto", "title": "Fully Automatic Expression-Invariant Face Correspondence", "comments": null, "journal-ref": "Machine Vision and Applications, 25(4):859-879, 2014", "doi": "10.1007/s00138-013-0579-9", "report-no": null, "categories": "cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing accurate point-to-point correspondences\namong a set of human face scans with varying expressions. Our fully automatic\napproach does not require any manually placed markers on the scan. Instead, the\napproach learns the locations of a set of landmarks present in a database and\nuses this knowledge to automatically predict the locations of these landmarks\non a newly available scan. The predicted landmarks are then used to compute\npoint-to-point correspondences between a template model and the newly available\nscan. To accurately fit the expression of the template to the expression of the\nscan, we use as template a blendshape model. Our algorithm was tested on a\ndatabase of human faces of different ethnic groups with strongly varying\nexpressions. Experimental results show that the obtained point-to-point\ncorrespondence is both highly accurate and consistent for most of the tested 3D\nface models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 15:05:05 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 22:52:30 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Salazar", "Augusto", ""], ["Wuhrer", "Stefanie", ""], ["Shu", "Chang", ""], ["Prieto", "Flavio", ""]]}, {"id": "1202.1585", "submitter": "Karteeka Pavan Kanadam", "authors": "K. Karteeka Pavan, Allam Appa Rao, A.V. Dattatreya Rao, G.R.Sridhar", "title": "Robust seed selection algorithm for k-means type algorithms", "comments": "17 pages, 5 tables, 9figures", "journal-ref": "International Journal of Computer Science and Technology (IJCSIT),\n  Vol 3, No 5, Oct 2011 pp 147-163", "doi": "10.5121/ijcsit.2011.3513", "report-no": null, "categories": "cs.CV cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection of initial seeds greatly affects the quality of the clusters and in\nk-means type algorithms. Most of the seed selection methods result different\nresults in different independent runs. We propose a single, optimal, outlier\ninsensitive seed selection algorithm for k-means type algorithms as extension\nto k-means++. The experimental results on synthetic, real and on microarray\ndata sets demonstrated that effectiveness of the new algorithm in producing the\nclustering results\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 03:07:39 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Pavan", "K. Karteeka", ""], ["Rao", "Allam Appa", ""], ["Rao", "A. V. Dattatreya", ""], ["Sridhar", "G. R.", ""]]}, {"id": "1202.1587", "submitter": "Karteeka Pavan Kanadam", "authors": "K. Karteeka Pavan, Allam Appa Rao, A. V. Dattatreya Rao", "title": "Automatic Clustering with Single Optimal Solution", "comments": "13 pages,4 Tables, 3 figures", "journal-ref": "Computer Engineering and Intelligent Systems, 2011, vol no.2 no.4\n  pp149-161", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining optimal number of clusters in a dataset is a challenging task.\nThough some methods are available, there is no algorithm that produces unique\nclustering solution. The paper proposes an Automatic Merging for Single Optimal\nSolution (AMSOS) which aims to generate unique and nearly optimal clusters for\nthe given datasets automatically. The AMSOS is iteratively merges the closest\nclusters automatically by validating with cluster validity measure to find\nsingle and nearly optimal clusters for the given data set. Experiments on both\nsynthetic and real data have proved that the proposed algorithm finds single\nand nearly optimal clustering structure in terms of number of clusters,\ncompactness and separation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 03:26:01 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Pavan", "K. Karteeka", ""], ["Rao", "Allam Appa", ""], ["Rao", "A. V. Dattatreya", ""]]}, {"id": "1202.1685", "submitter": "Nicolaie Popescu-Bodorin", "authors": "Valentina E. Balas, Iulia M. Motoc, Alina Barbulescu", "title": "Combined Haar-Hilbert and Log-Gabor Based Iris Encoders", "comments": "28 pages, 8 figures, 2 tables, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter shows that combining Haar-Hilbert and Log-Gabor improves iris\nrecognition performance leading to a less ambiguous biometric decision\nlandscape in which the overlap between the experimental intra- and interclass\nscore distributions diminishes or even vanishes. Haar-Hilbert, Log-Gabor and\ncombined Haar-Hilbert and Log-Gabor encoders are tested here both for single\nand dual iris approach. The experimental results confirm that the best\nperformance is obtained for the dual iris approach when the iris code is\ngenerated using the combined Haar-Hilbert and Log-Gabor encoder, and when the\nmatching score fuses the information from both Haar-Hilbert and Log-Gabor\nchannels of the combined encoder.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 13:07:10 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Balas", "Valentina E.", ""], ["Motoc", "Iulia M.", ""], ["Barbulescu", "Alina", ""]]}, {"id": "1202.1808", "submitter": "Surekha Mariam Varghese Dr.", "authors": "Kurien Zacharia, Eldo P. Elias, Surekha Mariam Varghese", "title": "Personalised product design using virtual interactive techniques", "comments": "10 pages; International Journal of Computer Graphics & Animation\n  (IJCGA) Vol.2, No.1, January 2012", "journal-ref": null, "doi": "10.5121/ijcga.2012.2101", "report-no": null, "categories": "cs.MM cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of Virtual Interactive Techniques for personalized product design is\ndescribed in this paper. Usually products are designed and built by considering\ngeneral usage patterns and Prototyping is used to mimic the static or working\nbehaviour of an actual product before manufacturing the product. The user does\nnot have any control on the design of the product. Personalized design\npostpones design to a later stage. It allows for personalized selection of\nindividual components by the user. This is implemented by displaying the\nindividual components over a physical model constructed using Cardboard or\nThermocol in the actual size and shape of the original product. The components\nof the equipment or product such as screen, buttons etc. are then projected\nusing a projector connected to the computer into the physical model. Users can\ninteract with the prototype like the original working equipment and they can\nselect, shape, position the individual components displayed on the interaction\npanel using simple hand gestures. Computer Vision techniques as well as sound\nprocessing techniques are used to detect and recognize the user gestures\ncaptured using a web camera and microphone.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 20:26:26 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Zacharia", "Kurien", ""], ["Elias", "Eldo P.", ""], ["Varghese", "Surekha Mariam", ""]]}, {"id": "1202.1943", "submitter": "Marcus Hutter", "authors": "Srimal Jayawardena and Di Yang and Marcus Hutter", "title": "3D Model Assisted Image Segmentation", "comments": "18 LaTeX pages, 11 figures, 1 algorithm, 1 table", "journal-ref": "Proc. 13th International Conf. on Digital Image Computing:\n  Techniques and Applications (DICTA 2011) pages 51-58", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of segmenting a given image into coherent regions is important in\nComputer Vision and many industrial applications require segmenting a known\nobject into its components. Examples include identifying individual parts of a\ncomponent for process control work in a manufacturing plant and identifying\nparts of a car from a photo for automatic damage detection. Unfortunately most\nof an object's parts of interest in such applications share the same pixel\ncharacteristics, having similar colour and texture. This makes segmenting the\nobject into its components a non-trivial task for conventional image\nsegmentation algorithms. In this paper, we propose a \"Model Assisted\nSegmentation\" method to tackle this problem. A 3D model of the object is\nregistered over the given image by optimising a novel gradient based loss\nfunction. This registration obtains the full 3D pose from an image of the\nobject. The image can have an arbitrary view of the object and is not limited\nto a particular set of views. The segmentation is subsequently performed using\na level-set based method, using the projected contours of the registered 3D\nmodel as initialisation curves. The method is fully automatic and requires no\nuser interaction. Also, the system does not require any prior training. We\npresent our results on photographs of a real car.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 10:53:11 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Jayawardena", "Srimal", ""], ["Yang", "Di", ""], ["Hutter", "Marcus", ""]]}, {"id": "1202.1990", "submitter": "Tapobrata Lahiri", "authors": "Upendra Kumar, Tapobrata Lahiri and Manoj Kumar Pal", "title": "Non-parametric convolution based image-segmentation of ill-posed objects\n  applying context window approach", "comments": "10 pages, 7 figures, 4 tables, not published anywhere", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-dependence in human cognition process is a well-established fact.\nFollowing this, we introduced the image segmentation method that can use\ncontext to classify a pixel on the basis of its membership to a particular\nobject-class of the concerned image. In the broad methodological steps, each\npixel was defined by its context window (CW) surrounding it the size of which\nwas fixed heuristically. CW texture defined by the intensities of its pixels\nwas convoluted with weights optimized through a non-parametric function\nsupported by a backpropagation network. Result of convolution was used to\nclassify them. The training data points (i.e., pixels) were carefully chosen to\ninclude all variety of contexts of types, i) points within the object, ii)\npoints near the edge but inside the objects, iii) points at the border of the\nobjects, iv) points near the edge but outside the objects, v) points near or at\nthe edge of the image frame. Moreover the training data points were selected\nfrom all the images within image-dataset. CW texture information for 1000\npixels from face area and background area of images were captured, out of which\n700 CWs were used as training input data, and remaining 300 for testing. Our\nwork gives the first time foundation of quantitative enumeration of efficiency\nof image-segmentation which is extendable to segment out more than 2 objects\nwithin an image.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 14:02:26 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Kumar", "Upendra", ""], ["Lahiri", "Tapobrata", ""], ["Pal", "Manoj Kumar", ""]]}, {"id": "1202.2160", "submitter": "Laurent Najman", "authors": "Cl\\'ement Farabet and Camille Couprie and Laurent Najman and Yann\n  LeCun", "title": "Scene Parsing with Multiscale Feature Learning, Purity Trees, and\n  Optimal Covers", "comments": "9 pages, 4 figures - Published in 29th International Conference on\n  Machine Learning (ICML 2012), Jun 2012, Edinburgh, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene parsing, or semantic segmentation, consists in labeling each pixel in\nan image with the category of the object it belongs to. It is a challenging\ntask that involves the simultaneous detection, segmentation and recognition of\nall the objects in the image.\n  The scene parsing method proposed here starts by computing a tree of segments\nfrom a graph of pixel dissimilarities. Simultaneously, a set of dense feature\nvectors is computed which encodes regions of multiple sizes centered on each\npixel. The feature extractor is a multiscale convolutional network trained from\nraw pixels. The feature vectors associated with the segments covered by each\nnode in the tree are aggregated and fed to a classifier which produces an\nestimate of the distribution of object categories contained in the segment. A\nsubset of tree nodes that cover the image are then selected so as to maximize\nthe average \"purity\" of the class distributions, hence maximizing the overall\nlikelihood that each segment will contain a single object. The convolutional\nnetwork feature extractor is trained end-to-end from raw pixels, alleviating\nthe need for engineered features. After training, the system is parameter free.\n  The system yields record accuracies on the Stanford Background Dataset (8\nclasses), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170\nclasses) while being an order of magnitude faster than competing approaches,\nproducing a 320 \\times 240 image labeling in less than 1 second.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 00:30:48 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2012 21:32:24 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Farabet", "Cl\u00e9ment", ""], ["Couprie", "Camille", ""], ["Najman", "Laurent", ""], ["LeCun", "Yann", ""]]}, {"id": "1202.2350", "submitter": "Khaled Masmoudi Mr.", "authors": "Khaled Masmoudi and Marc Antonini and Pierre Kornprobst", "title": "Streaming an image through the eye: The retina seen as a dithered\n  scalable image coder", "comments": "arXiv admin note: substantial text overlap with arXiv:1104.1550", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the design of an original scalable image coder/decoder that is\ninspired from the mammalians retina. Our coder accounts for the time-dependent\nand also nondeterministic behavior of the actual retina. The present work\nbrings two main contributions: As a first step, (i) we design a deterministic\nimage coder mimicking most of the retinal processing stages and then (ii) we\nintroduce a retinal noise in the coding process, that we model here as a dither\nsignal, to gain interesting perceptual features. Regarding our first\ncontribution, our main source of inspiration will be the biologically plausible\nmodel of the retina called Virtual Retina. The main novelty of this coder is to\nshow that the time-dependent behavior of the retina cells could ensure, in an\nimplicit way, scalability and bit allocation. Regarding our second\ncontribution, we reconsider the inner layers of the retina. We emit a possible\ninterpretation for the non-determinism observed by neurophysiologists in their\noutput. For this sake, we model the retinal noise that occurs in these layers\nby a dither signal. The dithering process that we propose adds several\ninteresting features to our image coder. The dither noise whitens the\nreconstruction error and decorrelates it from the input stimuli. Furthermore,\nintegrating the dither noise in our coder allows a faster recognition of the\nfine details of the image during the decoding process. Our present paper goal\nis twofold. First, we aim at mimicking as closely as possible the retina for\nthe design of a novel image coder while keeping encouraging performances.\nSecond, we bring a new insight concerning the non-deterministic behavior of the\nretina.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 09:16:43 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Masmoudi", "Khaled", ""], ["Antonini", "Marc", ""], ["Kornprobst", "Pierre", ""]]}, {"id": "1202.2368", "submitter": "Afzal  Godil", "authors": "Sarah Tang and Afzal Godil", "title": "An evaluation of local shape descriptors for 3D shape retrieval", "comments": "IS&T/SPIE Electronic Imaging 2012, Proceedings Vol. 8290\n  Three-Dimensional Image Processing (3DIP) and Applications II, Atilla M.\n  Baskurt; Robert Sitnik, Editors, 82900N Dates: Tuesday-Thursday 24 - 26\n  January 2012, Paper 8290-22", "journal-ref": null, "doi": "10.1117/12.912153", "report-no": "Paper 8290-22, Proceedings Vol. 8290", "categories": "cs.CV cs.CG cs.DL cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the usage of 3D models increases, so does the importance of developing\naccurate 3D shape retrieval algorithms. A common approach is to calculate a\nshape descriptor for each object, which can then be compared to determine two\nobjects' similarity. However, these descriptors are often evaluated\nindependently and on different datasets, making them difficult to compare.\nUsing the SHREC 2011 Shape Retrieval Contest of Non-rigid 3D Watertight Meshes\ndataset, we systematically evaluate a collection of local shape descriptors. We\napply each descriptor to the bag-of-words paradigm and assess the effects of\nvarying the dictionary's size and the number of sample points. In addition,\nseveral salient point detection methods are used to choose sample points; these\nmethods are compared to each other and to random selection. Finally,\ninformation from two local descriptors is combined in two ways and changes in\nperformance are investigated. This paper presents results of these experiment\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 21:02:39 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Tang", "Sarah", ""], ["Godil", "Afzal", ""]]}, {"id": "1202.2449", "submitter": "Salah A. Aly", "authors": "Moataz M. Abdelwahab, Salah A. Aly, Islam Yousry", "title": "Efficient Web-based Facial Recognition System Employing 2DHOG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a system for facial recognition to identify missing and found\npeople in Hajj and Umrah is described as a web portal. Explicitly, we present a\nnovel algorithm for recognition and classifications of facial images based on\napplying 2DPCA to a 2D representation of the Histogram of oriented gradients\n(2D-HOG) which maintains the spatial relation between pixels of the input\nimages. This algorithm allows a compact representation of the images which\nreduces the computational complexity and the storage requirments, while\nmaintaining the highest reported recognition accuracy. This promotes this\nmethod for usage with very large datasets. Large dataset was collected for\npeople in Hajj. Experimental results employing ORL, UMIST, JAFFE, and HAJJ\ndatasets confirm these excellent properties.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2012 15:24:18 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Abdelwahab", "Moataz M.", ""], ["Aly", "Salah A.", ""], ["Yousry", "Islam", ""]]}, {"id": "1202.2528", "submitter": "Kevin Mader", "authors": "Kevin Mader, Gil Reese", "title": "Using Covariance Matrices as Feature Descriptors for Vehicle Detection\n  from a Fixed Camera", "comments": "Written as part of the requirements for the SC/EC520 course in\n  Digital Image Processing at Boston University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is developed to distinguish between cars and trucks present in a\nvideo feed of a highway. The method builds upon previously done work using\ncovariance matrices as an accurate descriptor for regions. Background\nsubtraction and other similar proven image processing techniques are used to\nidentify the regions where the vehicles are most likely to be, and a distance\nmetric comparing the vehicle inside the region to a fixed library of vehicles\nis used to determine the class of vehicle.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 13:40:11 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Mader", "Kevin", ""], ["Reese", "Gil", ""]]}, {"id": "1202.2564", "submitter": "Christoforos Anagnostopoulos Dr", "authors": "David J. Hand, Christoforos Anagnostopoulos", "title": "A better Beta for the H measure of classification performance", "comments": "Preprint. Keywords: supervised classification, classifier\n  performance, AUC, ROC curve, H measure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area under the ROC curve is widely used as a measure of performance of\nclassification rules. However, it has recently been shown that the measure is\nfundamentally incoherent, in the sense that it treats the relative severities\nof misclassifications differently when different classifiers are used. To\novercome this, Hand (2009) proposed the $H$ measure, which allows a given\nresearcher to fix the distribution of relative severities to a\nclassifier-independent setting on a given problem. This note extends the\ndiscussion, and proposes a modified standard distribution for the $H$ measure,\nwhich better matches the requirements of researchers, in particular those faced\nwith heavily unbalanced datasets, the $Beta(\\pi_1+1,\\pi_0+1)$ distribution.\n[Preprint submitted at Pattern Recognition Letters]\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 20:32:15 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2013 11:44:54 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Hand", "David J.", ""], ["Anagnostopoulos", "Christoforos", ""]]}, {"id": "1202.2745", "submitter": "Dan Ciresan", "authors": "Dan Cire\\c{s}an, Ueli Meier, Juergen Schmidhuber", "title": "Multi-column Deep Neural Networks for Image Classification", "comments": "20 pages, 14 figures, 8 tables", "journal-ref": "CVPR 2012, p. 3642-3649", "doi": null, "report-no": "IDSIA-04-12", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods of computer vision and machine learning cannot match\nhuman performance on tasks such as the recognition of handwritten digits or\ntraffic signs. Our biologically plausible deep artificial neural network\narchitectures can. Small (often minimal) receptive fields of convolutional\nwinner-take-all neurons yield large network depth, resulting in roughly as many\nsparsely connected neural layers as found in mammals between retina and visual\ncortex. Only winner neurons are trained. Several deep neural columns become\nexperts on inputs preprocessed in different ways; their predictions are\naveraged. Graphics cards allow for fast training. On the very competitive MNIST\nhandwriting benchmark, our method is the first to achieve near-human\nperformance. On a traffic sign recognition benchmark it outperforms humans by a\nfactor of two. We also improve the state-of-the-art on a plethora of common\nimage classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 14:35:41 GMT"}], "update_date": "2012-11-15", "authors_parsed": [["Cire\u015fan", "Dan", ""], ["Meier", "Ueli", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "1202.3021", "submitter": "Gabriel Cristobal", "authors": "Salvador Gabarda and Gabriel Cristobal", "title": "No-reference image quality assessment through the von Mises distribution", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": "10.1364/JOSAA.29.002058", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An innovative way of calculating the von Mises distribution (VMD) of image\nentropy is introduced in this paper. The VMD's concentration parameter and some\nfitness parameter that will be later defined, have been analyzed in the\nexperimental part for determining their suitability as a image quality\nassessment measure in some particular distortions such as Gaussian blur or\nadditive Gaussian noise. To achieve such measure, the local R\\'{e}nyi entropy\nis calculated in four equally spaced orientations and used to determine the\nparameters of the von Mises distribution of the image entropy. Considering\ncontextual images, experimental results after applying this model show that the\nbest-in-focus noise-free images are associated with the highest values for the\nvon Mises distribution concentration parameter and the highest approximation of\nimage data to the von Mises distribution model. Our defined von Misses fitness\nparameter experimentally appears also as a suitable no-reference image quality\nassessment indicator for no-contextual images.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 12:50:35 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Gabarda", "Salvador", ""], ["Cristobal", "Gabriel", ""]]}, {"id": "1202.3046", "submitter": "Subhadip Basu", "authors": "Subhadip Basu, Chitrita Chaudhuri, Mahantapas Kundu, Mita Nasipuri,\n  Dipak K. Basu", "title": "Segmentation of Offline Handwritten Bengali Script", "comments": "Proceedings of 28th IEEE ACE, pp. 171-174, December 2002, Science\n  City, Kolkata", "journal-ref": "Proceedings of 28th IEEE ACE, pp. 171-174, December 2002, Science\n  City, Kolkata", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character segmentation has long been one of the most critical areas of\noptical character recognition process. Through this operation, an image of a\nsequence of characters, which may be connected in some cases, is decomposed\ninto sub-images of individual alphabetic symbols. In this paper, segmentation\nof cursive handwritten script of world's fourth popular language, Bengali, is\nconsidered. Unlike English script, Bengali handwritten characters and its\ncomponents often encircle the main character, making the conventional\nsegmentation methodologies inapplicable. Experimental results, using the\nproposed segmentation technique, on sample cursive handwritten data containing\n218 ideal segmentation points show a success rate of 97.7%. Further\nfeature-analysis on these segments may lead to actual recognition of\nhandwritten cursive Bengali script.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 14:22:24 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Basu", "Subhadip", ""], ["Chaudhuri", "Chitrita", ""], ["Kundu", "Mahantapas", ""], ["Nasipuri", "Mita", ""], ["Basu", "Dipak K.", ""]]}, {"id": "1202.3684", "submitter": "Marius Leordeanu", "authors": "Marius Leordeanu, Rahul Sukthankar, Cristian Sminchisescu", "title": "Generalized Boundaries from Multiple Image Interpretations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boundary detection is essential for a variety of computer vision tasks such\nas segmentation and recognition. In this paper we propose a unified formulation\nand a novel algorithm that are applicable to the detection of different types\nof boundaries, such as intensity edges, occlusion boundaries or object category\nspecific boundaries. Our formulation leads to a simple method with\nstate-of-the-art performance and significantly lower computational cost than\nexisting methods. We evaluate our algorithm on different types of boundaries,\nfrom low-level boundaries extracted in natural images, to occlusion boundaries\nobtained using motion cues and RGB-D cameras, to boundaries from\nsoft-segmentation. We also propose a novel method for figure/ground\nsoft-segmentation that can be used in conjunction with our boundary detection\nmethod and improve its accuracy at almost no extra computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 20:08:11 GMT"}], "update_date": "2012-02-17", "authors_parsed": [["Leordeanu", "Marius", ""], ["Sukthankar", "Rahul", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "1202.3884", "submitter": "Dinesh Dileep Gaurav", "authors": "Dinesh Dileep Gaurav and Renu Ramesh", "title": "A feature extraction technique based on character geometry for character\n  recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a geometry based technique for feature extraction\napplicable to segmentation-based word recognition systems. The proposed system\nextracts the geometric features of the character contour. This features are\nbased on the basic line types that forms the character skeleton. The system\ngives a feature vector as its output. The feature vectors so generated from a\ntraining set, were then used to train a pattern recognition engine based on\nNeural Networks so that the system can be benchmarked.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 11:41:28 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Gaurav", "Dinesh Dileep", ""], ["Ramesh", "Renu", ""]]}, {"id": "1202.4002", "submitter": "Rene Vidal", "authors": "Rene Vidal, Yi Ma, Shankar Sastry", "title": "Generalized Principal Component Analysis (GPCA)", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol 27, no 12, 2005", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an algebro-geometric solution to the problem of\nsegmenting an unknown number of subspaces of unknown and varying dimensions\nfrom sample data points. We represent the subspaces with a set of homogeneous\npolynomials whose degree is the number of subspaces and whose derivatives at a\ndata point give normal vectors to the subspace passing through the point. When\nthe number of subspaces is known, we show that these polynomials can be\nestimated linearly from data; hence, subspace segmentation is reduced to\nclassifying one point per subspace. We select these points optimally from the\ndata set by minimizing certain distance function, thus dealing automatically\nwith moderate noise in the data. A basis for the complement of each subspace is\nthen recovered by applying standard PCA to the collection of derivatives\n(normal vectors). Extensions of GPCA that deal with data in a high- dimensional\nspace and with an unknown number of subspaces are also presented. Our\nexperiments on low-dimensional data show that GPCA outperforms existing\nalgebraic algorithms based on polynomial factorization and provides a good\ninitialization to iterative techniques such as K-subspaces and Expectation\nMaximization. We also present applications of GPCA to computer vision problems\nsuch as face clustering, temporal video segmentation, and 3D motion\nsegmentation from point correspondences in multiple affine views.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 20:07:25 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Vidal", "Rene", ""], ["Ma", "Yi", ""], ["Sastry", "Shankar", ""]]}, {"id": "1202.4107", "submitter": "Scott A. Hale", "authors": "Scott A. Hale", "title": "Unsupervised Threshold for Automatic Extraction of Dolphin Dorsal Fin\n  Outlines from Digital Photographs in DARWIN (Digital Analysis and Recognition\n  of Whale Images on a Network)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  At least two software packages---DARWIN, Eckerd College, and FinScan, Texas\nA&M---exist to facilitate the identification of cetaceans---whales, dolphins,\nporpoises---based upon the naturally occurring features along the edges of\ntheir dorsal fins. Such identification is useful for biological studies of\npopulation, social interaction, migration, etc. The process whereby fin\noutlines are extracted in current fin-recognition software packages is manually\nintensive and represents a major user input bottleneck: it is both time\nconsuming and visually fatiguing. This research aims to develop automated\nmethods (employing unsupervised thresholding and morphological processing\ntechniques) to extract cetacean dorsal fin outlines from digital photographs\nthereby reducing manual user input. Ideally, automatic outline generation will\nimprove the overall user experience and improve the ability of the software to\ncorrectly identify cetaceans. Various transformations from color to gray space\nwere examined to determine which produced a grayscale image in which a suitable\nthreshold could be easily identified. To assist with unsupervised thresholding,\na new metric was developed to evaluate the jaggedness of figures (\"pixelarity\")\nin an image after thresholding. The metric indicates how cleanly a threshold\nsegments background and foreground elements and hence provides a good measure\nof the quality of a given threshold. This research results in successful\nextractions in roughly 93% of images, and significantly reduces user-input\ntime.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2012 21:42:24 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Hale", "Scott A.", ""]]}, {"id": "1202.4207", "submitter": "Meng Yang", "authors": "Meng Yang, Lei Zhang, Jian Yang and David Zhang", "title": "Regularized Robust Coding for Face Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2012.2235849", "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recently the sparse representation based classification (SRC) has been\nproposed for robust face recognition (FR). In SRC, the testing image is coded\nas a sparse linear combination of the training samples, and the representation\nfidelity is measured by the l2-norm or l1-norm of the coding residual. Such a\nsparse coding model assumes that the coding residual follows Gaussian or\nLaplacian distribution, which may not be effective enough to describe the\ncoding residual in practical FR systems. Meanwhile, the sparsity constraint on\nthe coding coefficients makes SRC's computational cost very high. In this\npaper, we propose a new face coding model, namely regularized robust coding\n(RRC), which could robustly regress a given signal with regularized regression\ncoefficients. By assuming that the coding residual and the coding coefficient\nare respectively independent and identically distributed, the RRC seeks for a\nmaximum a posterior solution of the coding problem. An iteratively reweighted\nregularized robust coding (IR3C) algorithm is proposed to solve the RRC model\nefficiently. Extensive experiments on representative face databases demonstrate\nthat the RRC is much more effective and efficient than state-of-the-art sparse\nrepresentation based methods in dealing with face occlusion, corruption,\nlighting and expression changes, etc.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 02:02:26 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2012 08:42:01 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Yang", "Meng", ""], ["Zhang", "Lei", ""], ["Yang", "Jian", ""], ["Zhang", "David", ""]]}, {"id": "1202.4237", "submitter": "Qiyang Zhao", "authors": "Qiyang Zhao", "title": "A Simple Unsupervised Color Image Segmentation Method based on MRF-MAP", "comments": "Submitted to IEEE SPL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color image segmentation is an important topic in the image processing field.\nMRF-MAP is often adopted in the unsupervised segmentation methods, but their\nperformance are far behind recent interactive segmentation tools supervised by\nuser inputs. Furthermore, the existing related unsupervised methods also suffer\nfrom the low efficiency, and high risk of being trapped in the local optima,\nbecause MRF-MAP is currently solved by iterative frameworks with inaccurate\ninitial color distribution models. To address these problems, the letter\ndesigns an efficient method to calculate the energy functions approximately in\nthe non-iteration style, and proposes a new binary segmentation algorithm based\non the slightly tuned Lanczos eigensolver. The experiments demonstrate that the\nnew algorithm achieves competitive performance compared with two state-of-art\nsegmentation methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 06:56:26 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Zhao", "Qiyang", ""]]}, {"id": "1202.4387", "submitter": "Lori Ziegelmeier", "authors": "Lori Ziegelmeier, Michael Kirby, Chris Peterson", "title": "Locally Linear Embedding Clustering Algorithm for Natural Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to characterize the color content of natural imagery is an\nimportant application of image processing. The pixel by pixel coloring of\nimages may be viewed naturally as points in color space, and the inherent\nstructure and distribution of these points affords a quantization, through\nclustering, of the color information in the image. In this paper, we present a\nnovel topologically driven clustering algorithm that permits segmentation of\nthe color features in a digital image. The algorithm blends Locally Linear\nEmbedding (LLE) and vector quantization by mapping color information to a lower\ndimensional space, identifying distinct color regions, and classifying pixels\ntogether based on both a proximity measure and color content. It is observed\nthat these techniques permit a significant reduction in color resolution while\nmaintaining the visually important features of images.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 17:14:41 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Ziegelmeier", "Lori", ""], ["Kirby", "Michael", ""], ["Peterson", "Chris", ""]]}, {"id": "1202.4495", "submitter": "Josep L. Rossello", "authors": "V. Canals, A. Morro, J.L. Rossell\\'o", "title": "Stochastic-Based Pattern Recognition Analysis", "comments": null, "journal-ref": "Published in Pattern Recognition Letters in 2010", "doi": "10.1016/j.patrec.2010.07.008", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we review the basic principles of stochastic logic and propose\nits application to probabilistic-based pattern-recognition analysis. The\nproposed technique is intrinsically a parallel comparison of input data to\nvarious pre-stored categories using Bayesian techniques. We design smart\npulse-based stochastic-logic blocks to provide an efficient pattern recognition\nanalysis. The proposed rchitecture is applied to a specific navigation problem.\nThe resulting system is orders of magnitude faster than processor-based\nsolutions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 23:48:38 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Canals", "V.", ""], ["Morro", "A.", ""], ["Rossell\u00f3", "J. L.", ""]]}, {"id": "1202.4743", "submitter": "Wonsang You", "authors": "Wonsang You, M. S. Houari Sabirin, Munchurl Kim", "title": "Real-time detection and tracking of multiple objects with partial\n  decoding in H.264/AVC bitstream domain", "comments": "SPIE Real-Time Image and Video Processing Conference 2009", "journal-ref": "Proceedings of SPIE 2009, Volume: 7244, Publisher: SPIE, Pages:\n  72440D-72440D-12", "doi": "10.1117/12.805596", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that we can apply probabilistic spatiotemporal\nmacroblock filtering (PSMF) and partial decoding processes to effectively\ndetect and track multiple objects in real time in H.264|AVC bitstreams with\nstationary background. Our contribution is that our method cannot only show\nfast processing time but also handle multiple moving objects that are\narticulated, changing in size or internally have monotonous color, even though\nthey contain a chaotic set of non-homogeneous motion vectors inside. In\naddition, our partial decoding process for H.264|AVC bitstreams enables to\nimprove the accuracy of object trajectories and overcome long occlusion by\nusing extracted color information.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 20:42:17 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["You", "Wonsang", ""], ["Sabirin", "M. S. Houari", ""], ["Kim", "Munchurl", ""]]}, {"id": "1202.4871", "submitter": "Rakesh S", "authors": "S. Rakesh, Ajitkumar A Kaller, B. C. Shadakshari and B. Annappa", "title": "Multilevel Image Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast evolution of digital data exchange and increased usage of multi\nmedia images, it is essential to protect the confidential image data from\nunauthorized access. In natural images the values and position of the\nneighbouring pixels are strongly correlated. The method proposed in this paper,\nbreaks this correlation increasing entropy of the position and entropy of pixel\nvalues using block shuffling and encryption by chaotic sequence respectively.\nThe plain-image is initially row wise shuffled and first level of encryption is\nperformed using addition modulo operation. The image is divided into blocks and\nthen block based shuffling is performed using Arnold Cat transformation,\nfurther the blocks are uniformly scrambled across the image. Finally the\nshuffled image undergoes second level of encryption by bitwise XOR operation,\nand then the image as a whole is shuffled column wise to produce the ciphered\nimage for transmission. The experimental results show that the proposed\nalgorithm can successfully encrypt or decrypt the image with the secret keys,\nand the analysis of the algorithm also demonstrates that the encrypted image\nhas good information entropy and low correlation coefficients.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 10:36:14 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Rakesh", "S.", ""], ["Kaller", "Ajitkumar A", ""], ["Shadakshari", "B. C.", ""], ["Annappa", "B.", ""]]}, {"id": "1202.4943", "submitter": "Bheshaj Dewangan", "authors": "Bheshaj Kumar, Kavita Thakur and G. R. Sinha", "title": "A new hybrid jpeg image compression scheme using symbol reduction\n  technique", "comments": "11 pages,9 figures, SIP 2012 held on 3-4 January 2012,at\n  Bangalore,India. arXiv admin note: text overlap with standard references on\n  JPEG without attribution", "journal-ref": null, "doi": "10.5121/csit.2012.2101-10.5121-csit.2012.2141", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy JPEG compression is a widely used compression technique. Normally the\nJPEG standard technique uses three process mapping reduces interpixel\nredundancy, quantization, which is lossy process and entropy encoding, which is\nconsidered lossless process. In this paper, a new technique has been proposed\nby combining the JPEG algorithm and Symbol Reduction Huffman technique for\nachieving more compression ratio. The symbols reduction technique reduces the\nnumber of symbols by combining together to form a new symbol. As a result of\nthis technique the number of Huffman code to be generated also reduced. It is\nsimple fast and easy to implement. The result shows that the performance of\nstandard JPEG method can be improved by proposed method. This hybrid approach\nachieves about 20% more compression ratio than the Standard JPEG.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 15:43:56 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Kumar", "Bheshaj", ""], ["Thakur", "Kavita", ""], ["Sinha", "G. R.", ""]]}, {"id": "1202.5414", "submitter": "Marco Reisert", "authors": "Marco Reisert and Henrik Skibbe", "title": "Left-Invariant Diffusion on the Motion Group in terms of the Irreducible\n  Representations of SO(3)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.CV cs.NA math.RT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the formulation of convection/diffusion equations on\nthe 3D motion group SE(3) in terms of the irreducible representations of SO(3).\nTherefore, the left-invariant vector-fields on SE(3) are expressed as linear\noperators, that are differential forms in the translation coordinate and\nalgebraic in the rotation. In the context of 3D image processing this approach\navoids the explicit discretization of SO(3) or $S_2$, respectively. This is\nparticular important for SO(3), where a direct discretization is infeasible due\nto the enormous memory consumption. We show two applications of the framework:\none in the context of diffusion-weighted magnetic resonance imaging and one in\nthe context of object detection.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 10:33:06 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Reisert", "Marco", ""], ["Skibbe", "Henrik", ""]]}, {"id": "1202.5844", "submitter": "Deyu Meng", "authors": "Deyu Meng and Zongben Xu", "title": "Divide-and-Conquer Method for L1 Norm Matrix Factorization in the\n  Presence of Outliers and Missing Data", "comments": "19 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low-rank matrix factorization as a L1 norm minimization problem has\nrecently attracted much attention due to its intrinsic robustness to the\npresence of outliers and missing data. In this paper, we propose a new method,\ncalled the divide-and-conquer method, for solving this problem. The main idea\nis to break the original problem into a series of smallest possible\nsub-problems, each involving only unique scalar parameter. Each of these\nsubproblems is proved to be convex and has closed-form solution. By recursively\noptimizing these small problems in an analytical way, efficient algorithm,\nentirely avoiding the time-consuming numerical optimization as an inner loop,\nfor solving the original problem can naturally be constructed. The\ncomputational complexity of the proposed algorithm is approximately linear in\nboth data size and dimensionality, making it possible to handle large-scale L1\nnorm matrix factorization problems. The algorithm is also theoretically proved\nto be convergent. Based on a series of experiment results, it is substantiated\nthat our method always achieves better results than the current\nstate-of-the-art methods on $L1$ matrix factorization calculation in both\ncomputational time and accuracy, especially on large-scale applications such as\nface recognition and structure from motion.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 07:57:04 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 14:37:56 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2012 11:27:51 GMT"}], "update_date": "2012-04-26", "authors_parsed": [["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}, {"id": "1202.6037", "submitter": "Noam Wagner", "authors": "Noam Wagner, Yonina C. Eldar and Zvi Friedman", "title": "Compressed Beamforming in Ultrasound Imaging", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": "10.1109/TSP.2012.2200891", "report-no": null, "categories": "cs.IT cs.CV math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging sonography techniques often require increasing the number of\ntransducer elements involved in the imaging process. Consequently, larger\namounts of data must be acquired and processed. The significant growth in the\namounts of data affects both machinery size and power consumption. Within the\nclassical sampling framework, state of the art systems reduce processing rates\nby exploiting the bandpass bandwidth of the detected signals. It has been\nrecently shown, that a much more significant sample-rate reduction may be\nobtained, by treating ultrasound signals within the Finite Rate of Innovation\nframework. These ideas follow the spirit of Xampling, which combines classic\nmethods from sampling theory with recent developments in Compressed Sensing.\nApplying such low-rate sampling schemes to individual transducer elements,\nwhich detect energy reflected from biological tissues, is limited by the noisy\nnature of the signals. This often results in erroneous parameter extraction,\nbringing forward the need to enhance the SNR of the low-rate samples. In our\nwork, we achieve SNR enhancement, by beamforming the sub-Nyquist samples\nobtained from multiple elements. We refer to this process as \"compressed\nbeamforming\". Applying it to cardiac ultrasound data, we successfully image\nmacroscopic perturbations, while achieving a nearly eight-fold reduction in\nsample-rate, compared to standard techniques.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 07:12:32 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 07:38:36 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Wagner", "Noam", ""], ["Eldar", "Yonina C.", ""], ["Friedman", "Zvi", ""]]}, {"id": "1202.6384", "submitter": "Arthur Szlam", "authors": "Arthur Szlam, Karol Gregor, Yann LeCun", "title": "Fast approximations to structured sparse coding and applications to\n  object classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for fast approximation of sparse coding. The input space\nis subdivided by a binary decision tree, and we simultaneously learn a\ndictionary and assignment of allowed dictionary elements for each leaf of the\ntree. We store a lookup table with the assignments and the pseudoinverses for\neach node, allowing for very fast inference. We give an algorithm for learning\nthe tree, the dictionary and the dictionary element assignment, and In the\nprocess of describing this algorithm, we discuss the more general problem of\nlearning the groups in group structured sparse modelling. We show that our\nmethod creates good sparse representations by using it in the object\nrecognition framework of \\cite{lazebnik06,yang-cvpr-09}. Implementing our own\nfast version of the SIFT descriptor the whole system runs at 20 frames per\nsecond on $321 \\times 481$ sized images on a laptop with a quad-core cpu, while\nsacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 21:27:14 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Szlam", "Arthur", ""], ["Gregor", "Karol", ""], ["LeCun", "Yann", ""]]}, {"id": "1202.6429", "submitter": "Rachel Ward", "authors": "Deanna Needell, Rachel Ward", "title": "Stable image reconstruction using total variation minimization", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents near-optimal guarantees for accurate and robust image\nrecovery from under-sampled noisy measurements using total variation\nminimization. In particular, we show that from O(slog(N)) nonadaptive linear\nmeasurements, an image can be reconstructed to within the best s-term\napproximation of its gradient up to a logarithmic factor, and this factor can\nbe removed by taking slightly more measurements. Along the way, we prove a\nstrengthened Sobolev inequality for functions lying in the null space of\nsuitably incoherent matrices.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 03:43:01 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2012 01:51:12 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2012 22:32:53 GMT"}, {"version": "v4", "created": "Tue, 13 Mar 2012 22:37:39 GMT"}, {"version": "v5", "created": "Wed, 9 May 2012 19:39:08 GMT"}, {"version": "v6", "created": "Thu, 31 May 2012 22:28:12 GMT"}, {"version": "v7", "created": "Thu, 11 Oct 2012 19:05:15 GMT"}, {"version": "v8", "created": "Tue, 16 Oct 2012 23:23:58 GMT"}, {"version": "v9", "created": "Tue, 12 Mar 2013 17:07:21 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Needell", "Deanna", ""], ["Ward", "Rachel", ""]]}, {"id": "1202.6517", "submitter": "Michal Ciesla", "authors": "Michal Ciesla, Przemyslaw Koziol", "title": "Eye Pupil Location Using Webcam", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three different algorithms used for eye pupil location were described and\ntested. Algorithm efficiency comparison was based on human faces images taken\nfrom the BioID database. Moreover all the eye localisation methods were\nimplemented in a dedicated application supporting eye movement based computer\ncontrol. In this case human face images were acquired by a webcam and processed\nin a real-time.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 11:17:10 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Ciesla", "Michal", ""], ["Koziol", "Przemyslaw", ""]]}, {"id": "1202.6586", "submitter": "Luis Quesada", "authors": "Luis Quesada, Alejandro J. Le\\'on", "title": "Filling-Based Techniques Applied to Object Projection Feature Estimation", "comments": "arXiv admin note: substantial text overlap with arXiv:1111.3969", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D motion tracking is a critical task in many computer vision applications.\nUnsupervised markerless 3D motion tracking systems determine the most relevant\nobject in the screen and then track it by continuously estimating its\nprojection features (center and area) from the edge image and a point inside\nthe relevant object projection (namely, inner point), until the tracking fails.\nExisting object projection feature estimation techniques are based on\nray-casting from the inner point. These techniques present three main\ndrawbacks: when the inner point is surrounded by edges, rays may not reach\nother relevant areas; as a consequence of that issue, the estimated features\nmay greatly vary depending on the position of the inner point relative to the\nobject projection; and finally, increasing the number of rays being casted and\nthe ray-casting iterations (which would make the results more accurate and\nstable) increases the processing time to the point the tracking cannot be\nperformed on the fly. In this paper, we analyze an intuitive filling-based\nobject projection feature estimation technique that solves the aforementioned\nproblems but is too sensitive to edge miscalculations. Then, we propose a less\ncomputing-intensive modification to that technique that would not be affected\nby the existing techniques issues and would be no more sensitive to edge\nmiscalculations than ray-casting-based techniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 16:10:10 GMT"}], "update_date": "2012-03-19", "authors_parsed": [["Quesada", "Luis", ""], ["Le\u00f3n", "Alejandro J.", ""]]}, {"id": "1202.6666", "submitter": "Francois Meyer", "authors": "Francois G. Meyer and Xilin Shen", "title": "Perturbation of the Eigenvectors of the Graph Laplacian: Application to\n  Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The original contributions of this paper are twofold: a new understanding of\nthe influence of noise on the eigenvectors of the graph Laplacian of a set of\nimage patches, and an algorithm to estimate a denoised set of patches from a\nnoisy image. The algorithm relies on the following two observations: (1) the\nlow-index eigenvectors of the diffusion, or graph Laplacian, operators are very\nrobust to random perturbations of the weights and random changes in the\nconnections of the patch-graph; and (2) patches extracted from smooth regions\nof the image are organized along smooth low-dimensional structures in the\npatch-set, and therefore can be reconstructed with few eigenvectors.\nExperiments demonstrate that our denoising algorithm outperforms the denoising\ngold-standards.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 19:59:53 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Meyer", "Francois G.", ""], ["Shen", "Xilin", ""]]}]