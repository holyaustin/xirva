[{"id": "0912.0265", "submitter": "Gabriel Silva", "authors": "Marius Buibas, Diana Yu, Krystal Nizar, Gabriel A. Silva", "title": "Mapping the spatiotemporal dynamics of calcium signaling in cellular\n  neural networks using optical flow", "comments": "23 pages, 5 figures. Peer reviewed accepted version in press in\n  Annals of Biomedical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optical flow gradient algorithm was applied to spontaneously forming net-\nworks of neurons and glia in culture imaged by fluorescence optical microscopy\nin order to map functional calcium signaling with single pixel resolution.\nOptical flow estimates the direction and speed of motion of objects in an image\nbetween subsequent frames in a recorded digital sequence of images (i.e. a\nmovie). Computed vector field outputs by the algorithm were able to track the\nspatiotemporal dynamics of calcium signaling pat- terns. We begin by briefly\nreviewing the mathematics of the optical flow algorithm, and then describe how\nto solve for the displacement vectors and how to measure their reliability. We\nthen compare computed flow vectors with manually estimated vectors for the\nprogression of a calcium signal recorded from representative astrocyte\ncultures. Finally, we applied the algorithm to preparations of primary\nastrocytes and hippocampal neurons and to the rMC-1 Muller glial cell line in\norder to illustrate the capability of the algorithm for capturing different\ntypes of spatiotemporal calcium activity. We discuss the imaging requirements,\nparameter selection and threshold selection for reliable measurements, and\noffer perspectives on uses of the vector data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2009 21:17:53 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2010 17:13:08 GMT"}], "update_date": "2010-01-22", "authors_parsed": [["Buibas", "Marius", ""], ["Yu", "Diana", ""], ["Nizar", "Krystal", ""], ["Silva", "Gabriel A.", ""]]}, {"id": "0912.0572", "submitter": "Mingyu Fan", "authors": "Mingyu Fan, Hong Qiao, and Bo Zhang", "title": "Isometric Multi-Manifolds Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isometric feature mapping (Isomap) is a promising manifold learning method.\nHowever, Isomap fails to work on data which distribute on clusters in a single\nmanifold or manifolds. Many works have been done on extending Isomap to\nmulti-manifolds learning. In this paper, we first proposed a new\nmulti-manifolds learning algorithm (M-Isomap) with help of a general procedure.\nThe new algorithm preserves intra-manifold geodesics and multiple\ninter-manifolds edges precisely. Compared with previous methods, this algorithm\ncan isometrically learn data distributed on several manifolds. Secondly, the\noriginal multi-cluster manifold learning algorithm first proposed in\n\\cite{DCIsomap} and called D-C Isomap has been revised so that the revised D-C\nIsomap can learn multi-manifolds data. Finally, the features and effectiveness\nof the proposed multi-manifolds learning algorithms are demonstrated and\ncompared through experiments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 03:05:59 GMT"}], "update_date": "2009-12-04", "authors_parsed": [["Fan", "Mingyu", ""], ["Qiao", "Hong", ""], ["Zhang", "Bo", ""]]}, {"id": "0912.0600", "submitter": "Rdv Ijcsis", "authors": "Alireza Ghahari, Reza Aghaeizadeh Zoroofi", "title": "Sequential Clustering based Facial Feature Extraction Method for\n  Automatic Creation of Facial Models from Orthogonal Views", "comments": "6 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 042-047, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiview 3D face modeling has attracted increasing attention recently and\nhas become one of the potential avenues in future video systems. We aim to make\nmore reliable and robust automatic feature extraction and natural 3D feature\nconstruction from 2D features detected on a pair of frontal and profile view\nface images. We propose several heuristic algorithms to minimize possible\nerrors introduced by prevalent nonperfect orthogonal condition and noncoherent\nluminance. In our approach, we first extract the 2D features that are visible\nto both cameras in both views. Then, we estimate the coordinates of the\nfeatures in the hidden profile view based on the visible features extracted in\nthe two orthogonal views. Finally, based on the coordinates of the extracted\nfeatures, we deform a 3D generic model to perform the desired 3D clone\nmodeling. Present study proves the scope of resulted facial models for\npractical applications like face recognition and facial animation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 08:54:24 GMT"}], "update_date": "2009-12-04", "authors_parsed": [["Ghahari", "Alireza", ""], ["Zoroofi", "Reza Aghaeizadeh", ""]]}, {"id": "0912.0607", "submitter": "Rdv Ijcsis", "authors": "P. Meenakshi Devi, M.Venkatesan, K.Duraiswamy", "title": "Reversible Image Authentication with Tamper Localization Based on\n  Integer Wavelet Transform", "comments": "8 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 067-074, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new reversible image authentication technique with tamper\nlocalization based on watermarking in integer wavelet transform is proposed. If\nthe image authenticity is verified, then the distortion due to embedding the\nwatermark can be completely removed from the watermarked image. If the image is\ntampered, then the tampering positions can also be localized. Two layers of\nwatermarking are used. The first layer embedded in spatial domain verifies\nauthenticity and the second layer embedded in transform domain provides\nreversibility. This technique utilizes selective LSB embedding and histogram\ncharacteristics of the difference images of the wavelet coefficients and\nmodifies pixel values slightly to embed the watermark. Experimental results\ndemonstrate that the proposed scheme can detect any modifications of the\nwatermarked image.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 09:11:19 GMT"}], "update_date": "2009-12-04", "authors_parsed": [["Devi", "P. Meenakshi", ""], ["Venkatesan", "M.", ""], ["Duraiswamy", "K.", ""]]}, {"id": "0912.0717", "submitter": "Karol Gregor", "authors": "Karol Gregor, Gregory Griffin", "title": "Behavior and performance of the deep belief networks on image\n  classification", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply deep belief networks of restricted Boltzmann machines to bags of\nwords of sift features obtained from databases of 13 Scenes, 15 Scenes and\nCaltech 256 and study experimentally their behavior and performance. We find\nthat the final performance in the supervised phase is reached much faster if\nthe system is pre-trained. Pre-training the system on a larger dataset keeping\nthe supervised dataset fixed improves the performance (for the 13 Scenes case).\nAfter the unsupervised pre-training, neurons arise that form approximate\nexplicit representations for several categories (meaning they are mostly active\nfor this category). The last three facts suggest that unsupervised training\nreally discovers structure in these data. Pre-training can be done on a\ncompletely different dataset (we use Corel dataset) and we find that the\nsupervised phase performs just as good (on the 15 Scenes dataset). This leads\nus to conjecture that one can pre-train the system once (e.g. in a factory) and\nsubsequently apply it to many supervised problems which then learn much faster.\nThe best performance is obtained with single hidden layer system suggesting\nthat the histogram of sift features doesn't have much high level structure. The\noverall performance is almost equal, but slightly worse then that of the\nsupport vector machine and the spatial pyramidal matching.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2009 19:20:14 GMT"}], "update_date": "2009-12-04", "authors_parsed": [["Gregor", "Karol", ""], ["Griffin", "Gregory", ""]]}, {"id": "0912.0950", "submitter": "Rdv Ijcsis", "authors": "B N Lavanya, K B Raja and K R Venugopal", "title": "Fingerprint Verification based on Gabor Filter Enhancement", "comments": "7 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 138-144, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human fingerprints are reliable characteristics for personnel identification\nas it is unique and persistence. A fingerprint pattern consists of ridges,\nvalleys and minutiae. In this paper we propose Fingerprint Verification based\non Gabor Filter Enhancement (FVGFE) algorithm for minutiae feature extraction\nand post processing based on 9 pixel neighborhood. A global feature extraction\nand fingerprints enhancement are based on Hong enhancement method which is\nsimultaneously able to extract local ridge orientation and ridge frequency. It\nis observed that the Sensitivity and Specificity values are better compared to\nthe existing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 21:17:20 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Lavanya", "B N", ""], ["Raja", "K B", ""], ["Venugopal", "K R", ""]]}, {"id": "0912.0955", "submitter": "Rdv Ijcsis", "authors": "Nazmeen Bibi Boodoo, and R. K. Subramanian", "title": "Robust Multi biometric Recognition Using Face and Ear Images", "comments": "6 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 164-169, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the use of ear as a biometric for authentication and\nshows experimental results obtained on a newly created dataset of 420 images.\nImages are passed to a quality module in order to reduce False Rejection Rate.\nThe Principal Component Analysis (eigen ear) approach was used, obtaining 90.7\npercent recognition rate. Improvement in recognition results is obtained when\near biometric is fused with face biometric. The fusion is done at decision\nlevel, achieving a recognition rate of 96 percent.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2009 21:51:03 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Boodoo", "Nazmeen Bibi", ""], ["Subramanian", "R. K.", ""]]}, {"id": "0912.0986", "submitter": "Rdv Ijcsis", "authors": "Mutasem Khalil Sari Alsmadi, Khairuddin Bin Omar, Shahrul Azman Noah\n  and Ibrahim Almarashdah", "title": "Fish recognition based on the combination between robust feature\n  selection, image segmentation and geometrical parameter techniques using\n  Artificial Neural Network and Decision Tree", "comments": "7 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 215-221, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We presents in this paper a novel fish classification methodology based on a\ncombination between robust feature selection, image segmentation and\ngeometrical parameter techniques using Artificial Neural Network and Decision\nTree. Unlike existing works for fish classification, which propose descriptors\nand do not analyze their individual impacts in the whole classification task\nand do not make the combination between the feature selection, image\nsegmentation and geometrical parameter, we propose a general set of features\nextraction using robust feature selection, image segmentation and geometrical\nparameter and their correspondent weights that should be used as a priori\ninformation by the classifier. In this sense, instead of studying techniques\nfor improving the classifiers structure itself, we consider it as a black box\nand focus our research in the determination of which input information must\nbring a robust fish discrimination.The main contribution of this paper is\nenhancement recognize and classify fishes based on digital image and To develop\nand implement a novel fish recognition prototype using global feature\nextraction, image segmentation and geometrical parameters, it have the ability\nto Categorize the given fish into its cluster and Categorize the clustered fish\ninto poison or non-poison fish, and categorizes the non-poison fish into its\nfamily .\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 06:04:03 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Alsmadi", "Mutasem Khalil Sari", ""], ["Omar", "Khairuddin Bin", ""], ["Noah", "Shahrul Azman", ""], ["Almarashdah", "Ibrahim", ""]]}, {"id": "0912.1005", "submitter": "Rdv Ijcsis", "authors": "Dr. G. Padmavathi, Dr. P. Subashini, Mr. M. Muthu Kumar and Suresh\n  Kumar Thakur", "title": "Performance analysis of Non Linear Filtering Algorithms for underwater\n  images", "comments": "7 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 232-238, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.MM cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image filtering algorithms are applied on images to remove the different\ntypes of noise that are either present in the image during capturing or\ninjected in to the image during transmission. Underwater images when captured\nusually have Gaussian noise, speckle noise and salt and pepper noise. In this\nwork, five different image filtering algorithms are compared for the three\ndifferent noise types. The performances of the filters are compared using the\nPeak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE). The modified\nspatial median filter gives desirable results in terms of the above two\nparameters for the three different noise. Forty underwater images are taken for\nstudy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 12:33:09 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Padmavathi", "Dr. G.", ""], ["Subashini", "Dr. P.", ""], ["Kumar", "Mr. M. Muthu", ""], ["Thakur", "Suresh Kumar", ""]]}, {"id": "0912.1009", "submitter": "Rdv Ijcsis", "authors": "V.K.Panchal, Parminder Singh, Navdeep Kaur, Harish Kundra", "title": "Biogeography based Satellite Image Classification", "comments": "6 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 269-274, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biogeography is the study of the geographical distribution of biological\norganisms. The mindset of the engineer is that we can learn from nature.\nBiogeography Based Optimization is a burgeoning nature inspired technique to\nfind the optimal solution of the problem. Satellite image classification is an\nimportant task because it is the only way we can know about the land cover map\nof inaccessible areas. Though satellite images have been classified in past by\nusing various techniques, the researchers are always finding alternative\nstrategies for satellite image classification so that they may be prepared to\nselect the most appropriate technique for the feature extraction task in hand.\nThis paper is focused on classification of the satellite image of a particular\nland cover using the theory of Biogeography based Optimization. The original\nBBO algorithm does not have the inbuilt property of clustering which is\nrequired during image classification. Hence modifications have been proposed to\nthe original algorithm and the modified algorithm is used to classify the\nsatellite image of a given region. The results indicate that highly accurate\nland cover features can be extracted effectively when the proposed algorithm is\nused.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 12:54:24 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Panchal", "V. K.", ""], ["Singh", "Parminder", ""], ["Kaur", "Navdeep", ""], ["Kundra", "Harish", ""]]}, {"id": "0912.1017", "submitter": "Rdv Ijcsis", "authors": "Ismail A. Ismail, Nabawia A. ElRamly, Mohammed A. Abd-ElWahid, Passent\n  M. ElKafrawy and Mohammed M. Nasef", "title": "Genetic Programming Framework for Fingerprint Matching", "comments": "6 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS November 2009, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 2, pp. 316-321, November 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fingerprint matching is a very difficult problem. Minutiae based matching\nis the most popular and widely used technique for fingerprint matching. The\nminutiae points considered in automatic identification systems are based\nnormally on termination and bifurcation points. In this paper we propose a new\ntechnique for fingerprint matching using minutiae points and genetic\nprogramming. The goal of this paper is extracting the mathematical formula that\ndefines the minutiae points.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2009 13:27:10 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Ismail", "Ismail A.", ""], ["ElRamly", "Nabawia A.", ""], ["Abd-ElWahid", "Mohammed A.", ""], ["ElKafrawy", "Passent M.", ""], ["Nasef", "Mohammed M.", ""]]}, {"id": "0912.1310", "submitter": "Edward Rosten", "authors": "Edward Rosten, Rohan Loveland, Mark Hickman", "title": "Automatic creation of urban velocity fields from aerial video", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a system for modelling vehicle motion in an urban\nscene from low frame-rate aerial video. In particular, the scene is modelled as\na probability distribution over velocities at every pixel in the image.\n  We describe the complete system for acquiring this model. The video is\ncaptured from a helicopter and stabilized by warping the images to match an\northorectified image of the area. A pixel classifier is applied to the\nstabilized images, and the response is segmented to determine car locations and\norientations. The results are fed in to a tracking scheme which tracks cars for\nthree frames, creating tracklets. This allows the tracker to use a combination\nof velocity, direction, appearance, and acceleration cues to keep only tracks\nlikely to be correct. Each tracklet provides a measurement of the car velocity\nat every point along the tracklet's length, and these are then aggregated to\ncreate a histogram of vehicle velocities at every pixel in the image.\n  The results demonstrate that the velocity probability distribution prior can\nbe used to infer a variety of information about road lane directions, speed\nlimits, vehicle speeds and common trajectories, and traffic bottlenecks, as\nwell as providing a means of describing environmental knowledge about traffic\nrules that can be used in tracking.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2009 19:04:41 GMT"}], "update_date": "2009-12-08", "authors_parsed": [["Rosten", "Edward", ""], ["Loveland", "Rohan", ""], ["Hickman", "Mark", ""]]}, {"id": "0912.1830", "submitter": "Vishal Goyal", "authors": "Kazumoto Tanaka", "title": "Gesture Recognition with a Focus on Important Actions by Using a Path\n  Searching Method in Weighted Graph", "comments": "International Journal of Computer Science Issues, IJCSI Volume 6,\n  Issue 2, pp14-19, November 2009", "journal-ref": "K. TANAKA, \"Gesture Recognition with a Focus on Important Actions\n  by Using a Path Searching Method in Weighted Graph\", International Journal of\n  Computer Science Issues, IJCSI, Volume 6, Issue 2, pp14-19, November 2009", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method of gesture recognition with a focus on important\nactions for distinguishing similar gestures. The method generates a partial\naction sequence by using optical flow images, expresses the sequence in the\neigenspace, and checks the feature vector sequence by applying an optimum\npath-searching method of weighted graph to focus the important actions. Also\npresented are the results of an experiment on the recognition of similar sign\nlanguage words.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2009 18:41:49 GMT"}], "update_date": "2009-12-10", "authors_parsed": [["Tanaka", "Kazumoto", ""]]}, {"id": "0912.2302", "submitter": "Kadirvelu SivaKumar", "authors": "Ali Douik, Mourad Moussa Jlassi", "title": "Synthesis of supervised classification algorithm using intelligent and\n  statistical tools", "comments": null, "journal-ref": "IJCSE Volume 1 Issue 2 2009 89-97", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental task in detecting foreground objects in both static and dynamic\nscenes is to take the best choice of color system representation and the\nefficient technique for background modeling. We propose in this paper a\nnon-parametric algorithm dedicated to segment and to detect objects in color\nimages issued from a football sports meeting. Indeed segmentation by pixel\nconcern many applications and revealed how the method is robust to detect\nobjects, even in presence of strong shadows and highlights. In the other hand\nto refine their playing strategy such as in football, handball, volley ball,\nRugby..., the coach need to have a maximum of technical-tactics information\nabout the on-going of the game and the players. We propose in this paper a\nrange of algorithms allowing the resolution of many problems appearing in the\nautomated process of team identification, where each player is affected to his\ncorresponding team relying on visual data. The developed system was tested on a\nmatch of the Tunisian national competition. This work is prominent for many\nnext computer vision studies as it's detailed in this study.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2009 18:14:29 GMT"}], "update_date": "2009-12-14", "authors_parsed": [["Douik", "Ali", ""], ["Jlassi", "Mourad Moussa", ""]]}, {"id": "0912.2316", "submitter": "Kadirvelu SivaKumar", "authors": "G. Kheder, A. Kachouri, M. Ben Massoued, M. Samet", "title": "Heart Rate Variability Analysis Using Threshold of Wavelet Package\n  Coefficients", "comments": null, "journal-ref": "IJCSE Volume 1 Issue 3 2009 131-136", "doi": null, "report-no": null, "categories": "cs.CV physics.data-an physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new efficient feature extraction method based on the\nadaptive threshold of wavelet package coefficients is presented. This paper\nespecially deals with the assessment of autonomic nervous system using the\nbackground variation of the signal Heart Rate Variability HRV extracted from\nthe wavelet package coefficients. The application of a wavelet package\ntransform allows us to obtain a time-frequency representation of the signal,\nwhich provides better insight in the frequency distribution of the signal with\ntime. A 6 level decomposition of HRV was achieved with db4 as mother wavelet,\nand the above two bands LF and HF were combined in 12 specialized frequencies\nsub-bands obtained in wavelet package transform. Features extracted from these\ncoefficients can efficiently represent the characteristics of the original\nsignal. ANOVA statistical test is used for the evaluation of proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2009 18:53:44 GMT"}], "update_date": "2009-12-14", "authors_parsed": [["Kheder", "G.", ""], ["Kachouri", "A.", ""], ["Massoued", "M. Ben", ""], ["Samet", "M.", ""]]}, {"id": "0912.2492", "submitter": "Hannes Nickisch", "authors": "Hannes Nickisch, Pushmeet Kohli and Carsten Rother", "title": "Learning an Interactive Segmentation System", "comments": "11 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many successful applications of computer vision to image or video\nmanipulation are interactive by nature. However, parameters of such systems are\noften trained neglecting the user. Traditionally, interactive systems have been\ntreated in the same manner as their fully automatic counterparts. Their\nperformance is evaluated by computing the accuracy of their solutions under\nsome fixed set of user interactions. This paper proposes a new evaluation and\nlearning method which brings the user in the loop. It is based on the use of an\nactive robot user - a simulated model of a human user. We show how this\napproach can be used to evaluate and learn parameters of state-of-the-art\ninteractive segmentation systems. We also show how simulated user models can be\nintegrated into the popular max-margin method for parameter learning and\npropose an algorithm to solve the resulting optimisation problem.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2009 12:27:37 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Nickisch", "Hannes", ""], ["Kohli", "Pushmeet", ""], ["Rother", "Carsten", ""]]}, {"id": "0912.2563", "submitter": "Karthik Narayanaswami", "authors": "Karthik Narayanaswami", "title": "A Model-Based Approach to Predicting Predator-Prey & Friend-Foe\n  Relationships in Ant Colonies", "comments": "Graduate work done in Fall 2005 at the BORG Lab, College of\n  Computing, Georgia Institute of Technology, under the advisement of Professor\n  Tucker Balch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding predator-prey relationships among insects is a challenging task\nin the domain of insect-colony research. This is due to several factors\ninvolved, such as determining whether a particular behavior is the result of a\npredator-prey interaction, a friend-foe interaction or another kind of\ninteraction. In this paper, we analyze a series of predator-prey and friend-foe\ninteractions in two colonies of carpenter ants to better understand and predict\nsuch behavior. Using the data gathered, we have also come up with a preliminary\nmodel for predicting such behavior under the specific conditions the experiment\nwas conducted in. In this paper, we present the results of our data analysis as\nwell as an overview of the processes involved.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2009 01:53:25 GMT"}], "update_date": "2009-12-15", "authors_parsed": [["Narayanaswami", "Karthik", ""]]}, {"id": "0912.3589", "submitter": "Marcus Hutter", "authors": "Marcus Hutter and Nathan Brewer", "title": "Matching 2-D Ellipses to 3-D Circles with Application to Vehicle Pose\n  Estimation", "comments": "16 LaTeX pages, 5 figures", "journal-ref": "Proc. 24th Conf. on Image and Vision Computing New Zealand (IVCNZ\n  2009) pages 153-158", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the three-dimensional representation of all or a part of a scene from\na single two dimensional image is a challenging task. In this paper we propose\na method for identifying the pose and location of objects with circular\nprotrusions in three dimensions from a single image and a 3d representation or\nmodel of the object of interest. To do this, we present a method for\nidentifying ellipses and their properties quickly and reliably with a novel\ntechnique that exploits intensity differences between objects and a geometric\ntechnique for matching an ellipse in 2d to a circle in 3d.\n  We apply these techniques to the specific problem of determining the pose and\nlocation of vehicles, particularly cars, from a single image. We have achieved\nexcellent pose recovery performance on artificially generated car images and\nshow promising results on real vehicle images. We also make use of the ellipse\ndetection method to identify car wheels from images, with a very high\nsuccessful match rate.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2009 05:58:54 GMT"}], "update_date": "2010-10-04", "authors_parsed": [["Hutter", "Marcus", ""], ["Brewer", "Nathan", ""]]}, {"id": "0912.3973", "submitter": "William Jackson", "authors": "Angkoon Phinyomark, Chusak Limsakul, Pornchai Phukpattaranont", "title": "A Novel Feature Extraction for Robust EMG Pattern Recognition", "comments": null, "journal-ref": "Journal of Computing, Volume 1, Issue 1, pp 71-80, December 2009", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Varieties of noises are major problem in recognition of Electromyography\n(EMG) signal. Hence, methods to remove noise become most significant in EMG\nsignal analysis. White Gaussian noise (WGN) is used to represent interference\nin this paper. Generally, WGN is difficult to be removed using typical\nfiltering and solutions to remove WGN are limited. In addition, noise removal\nis an important step before performing feature extraction, which is used in\nEMG-based recognition. This research is aimed to present a novel feature that\ntolerate with WGN. As a result, noise removal algorithm is not needed. Two\nnovel mean and median frequencies (MMNF and MMDF) are presented for robust\nfeature extraction. Sixteen existing features and two novelties are evaluated\nin a noisy environment. WGN with various signal-to-noise ratios (SNRs), i.e.\n20-0 dB, was added to the original EMG signal. The results showed that MMNF\nperformed very well especially in weak EMG signal compared with others. The\nerror of MMNF in weak EMG signal with very high noise, 0 dB SNR, is about 5-10\npercent and closed by MMDF and Histogram, whereas the error of other features\nis more than 20 percent. While in strong EMG signal, the error of MMNF is\nbetter than those from other features. Moreover, the combination of MMNF,\nHistrogram of EMG and Willison amplitude is used as feature vector in\nclassification task. The experimental result shows the better recognition\nresult in noisy environment than other success feature candidates. From the\nabove results demonstrate that MMNF can be used for new robust feature\nextraction.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2009 03:49:21 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2009 15:03:58 GMT"}], "update_date": "2009-12-26", "authors_parsed": [["Phinyomark", "Angkoon", ""], ["Limsakul", "Chusak", ""], ["Phukpattaranont", "Pornchai", ""]]}, {"id": "0912.4571", "submitter": "Shiqian Ma", "authors": "Donald Goldfarb, Shiqian Ma, Katya Scheinberg", "title": "Fast Alternating Linearization Methods for Minimizing the Sum of Two\n  Convex Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper first-order alternating linearization algorithms\nbased on an alternating direction augmented Lagrangian approach for minimizing\nthe sum of two convex functions. Our basic methods require at most\n$O(1/\\epsilon)$ iterations to obtain an $\\epsilon$-optimal solution, while our\naccelerated (i.e., fast) versions of them require at most\n$O(1/\\sqrt{\\epsilon})$ iterations, with little change in the computational\neffort required at each iteration. For both types of methods, we present one\nalgorithm that requires both functions to be smooth with Lipschitz continuous\ngradients and one algorithm that needs only one of the functions to be so.\nAlgorithms in this paper are Gauss-Seidel type methods, in contrast to the ones\nproposed by Goldfarb and Ma in [21] where the algorithms are Jacobi type\nmethods. Numerical results are reported to support our theoretical conclusions\nand demonstrate the practical potential of our algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2009 06:03:27 GMT"}, {"version": "v2", "created": "Wed, 13 Oct 2010 04:58:19 GMT"}], "update_date": "2010-10-14", "authors_parsed": [["Goldfarb", "Donald", ""], ["Ma", "Shiqian", ""], ["Scheinberg", "Katya", ""]]}, {"id": "0912.4936", "submitter": "Li Chen", "authors": "Li Chen", "title": "Genus Computing for 3D digital objects: algorithm and implementation", "comments": "12 pages 7 figures. In Proceedings of the Workshop on Computational\n  Topology in image context 2009, Aug. 26-28, Austria, Edited by W. Kropatsch,\n  H. M. Abril and A. Ion, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper deals with computing topological invariants such as connected\ncomponents, boundary surface genus, and homology groups. For each input data\nset, we have designed or implemented algorithms to calculate connected\ncomponents, boundary surfaces and their genus, and homology groups. Due to the\nfact that genus calculation dominates the entire task for 3D object in 3D\nspace, in this paper, we mainly discuss the calculation of the genus. The new\nalgorithms designed in this paper will perform:\n  (1) pathological cases detection and deletion, (2) raster space to point\nspace (dual space) transformation, (3) the linear time algorithm for boundary\npoint classification, and (4) genus calculation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2009 03:42:17 GMT"}], "update_date": "2009-12-31", "authors_parsed": [["Chen", "Li", ""]]}, {"id": "0912.5502", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Miao Song and Ching Y. Suen", "title": "Writer Identification Using Inexpensive Signal Processing Techniques", "comments": "9 pages; 1 figure; presented at CISSE'09 at\n  http://conference.cisse2009.org/proceedings.aspx ; includes the the\n  application source code; based on MARF described in arXiv:0905.1235", "journal-ref": null, "doi": "10.1007/978-90-481-9112-3_74", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use novel and classical audio and text signal-processing and\notherwise techniques for \"inexpensive\" fast writer identification tasks of\nscanned hand-written documents \"visually\". The \"inexpensive\" refers to the\nefficiency of the identification process in terms of CPU cycles while\npreserving decent accuracy for preliminary identification. This is a\ncomparative study of multiple algorithm combinations in a pattern recognition\npipeline implemented in Java around an open-source Modular Audio Recognition\nFramework (MARF) that can do a lot more beyond audio. We present our\npreliminary experimental findings in such an identification task. We simulate\n\"visual\" identification by \"looking\" at the hand-written document as a whole\nrather than trying to extract fine-grained features out of it prior\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2009 18:19:53 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Mokhov", "Serguei A.", ""], ["Song", "Miao", ""], ["Suen", "Ching Y.", ""]]}]