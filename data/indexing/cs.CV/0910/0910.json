[{"id": "0910.1273", "submitter": "Fabien Moutarde", "authors": "Taoufik Bdiri (CAOR), Fabien Moutarde (CAOR), Nicolas Bourdis (CAOR),\n  Bruno Steux (CAOR)", "title": "Adaboost with \"Keypoint Presence Features\" for Real-Time Vehicle Visual\n  Detection", "comments": null, "journal-ref": "16th World Congress on Intelligent Transport Systems (ITSwc'2009),\n  Su\\`ede (2009)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present promising results for real-time vehicle visual detection, obtained\nwith adaBoost using new original ?keypoints presence features?. These\nweak-classifiers produce a boolean response based on presence or absence in the\ntested image of a ?keypoint? (~ a SURF interest point) with a descriptor\nsufficiently similar (i.e. within a given distance) to a reference descriptor\ncharacterizing the feature. A first experiment was conducted on a public image\ndataset containing lateral-viewed cars, yielding 95% recall with 95% precision\non test set. Moreover, analysis of the positions of adaBoost-selected keypoints\nshow that they correspond to a specific part of the object category (such as\n?wheel? or ?side skirt?) and thus have a ?semantic? meaning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 14:26:01 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Bdiri", "Taoufik", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"], ["Bourdis", "Nicolas", "", "CAOR"], ["Steux", "Bruno", "", "CAOR"]]}, {"id": "0910.1293", "submitter": "Fabien Moutarde", "authors": "Bogdan Stanciulescu (CAOR), Amaury Breheret (CAOR), Fabien Moutarde\n  (CAOR)", "title": "Introducing New AdaBoost Features for Real-Time Vehicle Detection", "comments": null, "journal-ref": "COGIS'07 conference on COGnitive systems with Interactive Sensors,\n  Stanford, Palo Alto : United States (2007)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how to improve the real-time object detection in complex\nrobotics applications, by exploring new visual features as AdaBoost weak\nclassifiers. These new features are symmetric Haar filters (enforcing global\nhorizontal and vertical symmetry) and N-connexity control points. Experimental\nevaluation on a car database show that the latter appear to provide the best\nresults for the vehicle-detection problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 15:42:03 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Stanciulescu", "Bogdan", "", "CAOR"], ["Breheret", "Amaury", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"]]}, {"id": "0910.1294", "submitter": "Fabien Moutarde", "authors": "Taoufik Bdiri (CAOR), Fabien Moutarde (CAOR), Bruno Steux (CAOR)", "title": "Visual object categorization with new keypoint-based adaBoost features", "comments": null, "journal-ref": "IEEE Symposium on Intelligent Vehicles (IV'2009), XiAn : China\n  (2009)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present promising results for visual object categorization, obtained with\nadaBoost using new original ?keypoints-based features?. These weak-classifiers\nproduce a boolean response based on presence or absence in the tested image of\na ?keypoint? (a kind of SURF interest point) with a descriptor sufficiently\nsimilar (i.e. within a given distance) to a reference descriptor characterizing\nthe feature. A first experiment was conducted on a public image dataset\ncontaining lateral-viewed cars, yielding 95% recall with 95% precision on test\nset. Preliminary tests on a small subset of a pedestrians database also gives\npromising 97% recall with 92 % precision, which shows the generality of our new\nfamily of features. Moreover, analysis of the positions of adaBoost-selected\nkeypoints show that they correspond to a specific part of the object category\n(such as ?wheel? or ?side skirt? in the case of lateral-cars) and thus have a\n?semantic? meaning. We also made a first test on video for detecting vehicles\nfrom adaBoostselected keypoints filtered in real-time from all detected\nkeypoints.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 15:42:30 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Bdiri", "Taoufik", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"], ["Steux", "Bruno", "", "CAOR"]]}, {"id": "0910.1295", "submitter": "Fabien Moutarde", "authors": "Fabien Moutarde (CAOR), Alexandre Bargeton (CAOR), Anne Herbin, Lowik\n  Chanussot", "title": "Modular Traffic Sign Recognition applied to on-vehicle real-time visual\n  detection of American and European speed limit signs", "comments": null, "journal-ref": "14th World congress on Intelligent Transportation Systems\n  (ITS'2007), Beijing : China (2007)", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new modular traffic signs recognition system, successfully\napplied to both American and European speed limit signs. Our sign detection\nstep is based only on shape-detection (rectangles or circles). This enables it\nto work on grayscale images, contrary to most European competitors, which eases\nrobustness to illumination conditions (notably night operation). Speed sign\ncandidates are classified (or rejected) by segmenting potential digits inside\nthem (which is rather original and has several advantages), and then applying a\nneural digit recognition. The global detection rate is ~90% for both (standard)\nU.S. and E.U. speed signs, with a misclassification rate <1%, and no validated\nfalse alarm in >150 minutes of video. The system processes in real-time ~20\nframes/s on a standard high-end laptop.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 15:43:01 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Moutarde", "Fabien", "", "CAOR"], ["Bargeton", "Alexandre", "", "CAOR"], ["Herbin", "Anne", ""], ["Chanussot", "Lowik", ""]]}, {"id": "0910.1650", "submitter": "Dingyin Xia", "authors": "Dingyin Xia, Fei Wu, Xuqing Zhang, Yueting Zhuang", "title": "Local and global approaches of affinity propagation clustering for large\n  scale data", "comments": "9 pages", "journal-ref": "J Zhejiang Univ Sci A 2008 9(10):1373-1381", "doi": "10.1631/jzus.A0720058", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a new clustering algorithm called 'affinity propagation' (AP) has\nbeen proposed, which efficiently clustered sparsely related data by passing\nmessages between data points. However, we want to cluster large scale data\nwhere the similarities are not sparse in many cases. This paper presents two\nvariants of AP for grouping large scale data with a dense similarity matrix.\nThe local approach is partition affinity propagation (PAP) and the global\nmethod is landmark affinity propagation (LAP). PAP passes messages in the\nsubsets of data first and then merges them as the number of initial step of\niterations; it can effectively reduce the number of iterations of clustering.\nLAP passes messages between the landmark data points first and then clusters\nnon-landmark data points; it is a large global approximation method to speed up\nclustering. Experiments are conducted on many datasets, such as random data\npoints, manifold subspaces, images of faces and Chinese calligraphy, and the\nresults demonstrate that the two approaches are feasible and practicable.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2009 04:55:41 GMT"}], "update_date": "2009-10-12", "authors_parsed": [["Xia", "Dingyin", ""], ["Wu", "Fei", ""], ["Zhang", "Xuqing", ""], ["Zhuang", "Yueting", ""]]}, {"id": "0910.1844", "submitter": "N Vunka Jungum", "authors": "Pascal Fallavollita", "title": "3D/2D Registration of Mapping Catheter Images for Arrhythmia\n  Interventional Assistance", "comments": "International Journal of Computer Science Issues, IJCSI, Volume 4,\n  Issue 2, pp10-19, September 2009", "journal-ref": "P. Fallavollita, \" 3D/2D Registration of Mapping Catheter Images\n  for Arrhythmia Interventional Assistance\", International Journal of Computer\n  Science Issues, IJCSI, Volume 4, Issue 2, pp10-19, September 2009\"", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiofrequency (RF) catheter ablation has transformed treatment for\ntachyarrhythmias and has become first-line therapy for some tachycardias. The\nprecise localization of the arrhythmogenic site and the positioning of the RF\ncatheter over that site are problematic: they can impair the efficiency of the\nprocedure and are time consuming (several hours). Electroanatomic mapping\ntechnologies are available that enable the display of the cardiac chambers and\nthe relative position of ablation lesions. However, these are expensive and use\ncustom-made catheters. The proposed methodology makes use of standard catheters\nand inexpensive technology in order to create a 3D volume of the heart chamber\naffected by the arrhythmia. Further, we propose a novel method that uses a\npriori 3D information of the mapping catheter in order to estimate the 3D\nlocations of multiple electrodes across single view C-arm images. The monoplane\nalgorithm is tested for feasibility on computer simulations and initial canine\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2009 20:07:11 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Fallavollita", "Pascal", ""]]}, {"id": "0910.1849", "submitter": "N Vunka Jungum", "authors": "Sanjay Silakari, Mahesh Motwani and Manish Maheshwari", "title": "Color Image Clustering using Block Truncation Algorithm", "comments": "\" International Journal of Computer Science Issues, IJCSI, Volume 4,\n  Issue 2, pp31-35, September 2009\"", "journal-ref": "S. Silakari, M. Motwani and M. Maheshwari,\" Color Image Clustering\n  using Block Truncation Algorithm\", International Journal of Computer Science\n  Issues, IJCSI, Volume 4, Issue 2, pp31-35, September 2009", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement in image capturing device, the image data been generated\nat high volume. If images are analyzed properly, they can reveal useful\ninformation to the human users. Content based image retrieval address the\nproblem of retrieving images relevant to the user needs from image databases on\nthe basis of low-level visual features that can be derived from the images.\nGrouping images into meaningful categories to reveal useful information is a\nchallenging and important problem. Clustering is a data mining technique to\ngroup a set of unsupervised data based on the conceptual clustering principal:\nmaximizing the intraclass similarity and minimizing the interclass similarity.\nProposed framework focuses on color as feature. Color Moment and Block\nTruncation Coding (BTC) are used to extract features for image dataset.\nExperimental study using K-Means clustering algorithm is conducted to group the\nimage dataset into various clusters.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2009 20:21:23 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Silakari", "Sanjay", ""], ["Motwani", "Mahesh", ""], ["Maheshwari", "Manish", ""]]}, {"id": "0910.1857", "submitter": "N Vunka Jungum", "authors": "Ahmad Shukri Mohd Noor and Md Yazid Md Saman", "title": "Distributed Object Medical Imaging Model", "comments": "\" International Journal of Computer Science Issues, IJCSI, Volume 4,\n  Issue 2, pp42-48, September 2009\"", "journal-ref": "A.S.M. Noor and Y.Saman, \"Distributed Object Medical Imaging\n  Model\", International Journal of Computer Science Issues, IJCSI, Volume 4,\n  Issue 2, pp42-48, September 2009", "doi": null, "report-no": null, "categories": "cs.SE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital medical informatics and images are commonly used in hospitals today,.\nBecause of the interrelatedness of the radiology department and other\ndepartments, especially the intensive care unit and emergency department, the\ntransmission and sharing of medical images has become a critical issue. Our\nresearch group has developed a Java-based Distributed Object Medical Imaging\nModel(DOMIM) to facilitate the rapid development and deployment of medical\nimaging applications in a distributed environment that can be shared and used\nby related departments and mobile physiciansDOMIM is a unique suite of\nmultimedia telemedicine applications developed for the use by medical related\norganizations. The applications support realtime patients' data, image files,\naudio and video diagnosis annotation exchanges. The DOMIM enables joint\ncollaboration between radiologists and physicians while they are at distant\ngeographical locations. The DOMIM environment consists of heterogeneous,\nautonomous, and legacy resources. The Common Object Request Broker Architecture\n(CORBA), Java Database Connectivity (JDBC), and Java language provide the\ncapability to combine the DOMIM resources into an integrated, interoperable,\nand scalable system. The underneath technology, including IDL ORB, Event\nService, IIOP JDBC/ODBC, legacy system wrapping and Java implementation are\nexplored. This paper explores a distributed collaborative CORBA/JDBC based\nframework that will enhance medical information management requirements and\ndevelopment. It encompasses a new paradigm for the delivery of health services\nthat requires process reengineering, cultural changes, as well as\norganizational changes\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2009 20:42:48 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Noor", "Ahmad Shukri Mohd", ""], ["Saman", "Md Yazid Md", ""]]}, {"id": "0910.1955", "submitter": "Ryszard Piasecki", "authors": "R. Piasecki", "title": "Microstructure reconstruction using entropic descriptors", "comments": "version accepted for publication in Proc. R. Soc. A", "journal-ref": "Proc. R. Soc. A 467 (2011) 806-820", "doi": "10.1098/rspa.2010.0296", "report-no": null, "categories": "cond-mat.stat-mech cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-scale approach to the inverse reconstruction of a pattern's\nmicrostructure is reported. Instead of a correlation function, a pair of\nentropic descriptors (EDs) is proposed for stochastic optimization method. The\nfirst of them measures a spatial inhomogeneity, for a binary pattern, or\ncompositional one, for a greyscale image. The second one quantifies a spatial\nor compositional statistical complexity. The EDs reveal structural information\nthat is dissimilar, at least in part, to that given by correlation functions at\nalmost all of discrete length scales. The method is tested on a few digitized\nbinary and greyscale images. In each of the cases, the persuasive\nreconstruction of the microstructure is found.\n", "versions": [{"version": "v1", "created": "Sat, 10 Oct 2009 22:55:53 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2009 20:53:58 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2009 17:40:29 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2010 10:27:03 GMT"}, {"version": "v5", "created": "Thu, 26 Aug 2010 13:59:23 GMT"}], "update_date": "2011-02-16", "authors_parsed": [["Piasecki", "R.", ""]]}, {"id": "0910.2279", "submitter": "Chunhua Shen", "authors": "Chunhua Shen, Junae Kim, Lei Wang, Anton van den Hengel", "title": "Positive Semidefinite Metric Learning with Boosting", "comments": "11 pages, Twenty-Third Annual Conference on Neural Information\n  Processing Systems (NIPS 2009), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of appropriate distance metrics is a critical problem in image\nclassification and retrieval. In this work, we propose a boosting-based\ntechnique, termed \\BoostMetric, for learning a Mahalanobis distance metric. One\nof the primary difficulties in learning such a metric is to ensure that the\nMahalanobis matrix remains positive semidefinite. Semidefinite programming is\nsometimes used to enforce this constraint, but does not scale well.\n\\BoostMetric is instead based on a key observation that any positive\nsemidefinite matrix can be decomposed into a linear positive combination of\ntrace-one rank-one matrices. \\BoostMetric thus uses rank-one positive\nsemidefinite matrices as weak learners within an efficient and scalable\nboosting-based learning process. The resulting method is easy to implement,\ndoes not require tuning, and can accommodate various types of constraints.\nExperiments on various datasets show that the proposed algorithm compares\nfavorably to those state-of-the-art methods in terms of classification accuracy\nand running time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 00:54:31 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Shen", "Chunhua", ""], ["Kim", "Junae", ""], ["Wang", "Lei", ""], ["Hengel", "Anton van den", ""]]}, {"id": "0910.2381", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "Fractional differentiation based image processing", "comments": "Keywords: Fractional calculation, image processing, astronomy,\n  Misprints revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many resources useful for processing images, most of them freely\navailable and quite friendly to use. In spite of this abundance of tools, a\nstudy of the processing methods is still worthy of efforts. Here, we want to\ndiscuss the possibilities arising from the use of fractional differential\ncalculus. This calculus evolved in the research field of pure mathematics until\n1920, when applied science started to use it. Only recently, fractional\ncalculus was involved in image processing methods. As we shall see, the\nfractional calculation is able to enhance the quality of images, with\ninteresting possibilities in edge detection and image restoration. We suggest\nalso the fractional differentiation as a tool to reveal faint objects in\nastronomical images.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 12:37:32 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2009 10:49:09 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2010 09:19:21 GMT"}, {"version": "v4", "created": "Tue, 7 Apr 2015 07:08:06 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "0910.2917", "submitter": "Venkatesh Saligrama", "authors": "P. M. Jodoin, V. Saligrama, J. Konrad", "title": "Behavior Subtraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background subtraction has been a driving engine for many computer vision and\nvideo analytics tasks. Although its many variants exist, they all share the\nunderlying assumption that photometric scene properties are either static or\nexhibit temporal stationarity. While this works in some applications, the model\nfails when one is interested in discovering {\\it changes in scene dynamics}\nrather than those in a static background; detection of unusual pedestrian and\nmotor traffic patterns is but one example. We propose a new model and\ncomputational framework that address this failure by considering stationary\nscene dynamics as a ``background'' with which observed scene dynamics are\ncompared. Central to our approach is the concept of an {\\it event}, that we\ndefine as short-term scene dynamics captured over a time window at a specific\nspatial location in the camera field of view. We compute events by\ntime-aggregating motion labels, obtained by background subtraction, as well as\nobject descriptors (e.g., object size). Subsequently, we characterize events\nprobabilistically, but use a low-memory, low-complexity surrogates in practical\nimplementation. Using these surrogates amounts to {\\it behavior subtraction}, a\nnew algorithm with some surprising properties. As demonstrated here, behavior\nsubtraction is an effective tool in anomaly detection and localization. It is\nresilient to spurious background motion, such as one due to camera jitter, and\nis content-blind, i.e., it works equally well on humans, cars, animals, and\nother objects in both uncluttered and highly-cluttered scenes. Clearly,\ntreating video as a collection of events rather than colored pixels opens new\npossibilities for video analytics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2009 16:09:18 GMT"}], "update_date": "2009-10-16", "authors_parsed": [["Jodoin", "P. M.", ""], ["Saligrama", "V.", ""], ["Konrad", "J.", ""]]}, {"id": "0910.3348", "submitter": "Harris Georgiou", "authors": "Harris Georgiou", "title": "Algorithms for Image Analysis and Combination of Pattern Classifiers\n  with Application to Medical Diagnosis", "comments": "PhD thesis summary, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GT cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Medical Informatics and the application of modern signal processing in the\nassistance of the diagnostic process in medical imaging is one of the more\nrecent and active research areas today. This thesis addresses a variety of\nissues related to the general problem of medical image analysis, specifically\nin mammography, and presents a series of algorithms and design approaches for\nall the intermediate levels of a modern system for computer-aided diagnosis\n(CAD). The diagnostic problem is analyzed with a systematic approach, first\ndefining the imaging characteristics and features that are relevant to probable\npathology in mammo-grams. Next, these features are quantified and fused into\nnew, integrated radio-logical systems that exhibit embedded digital signal\nprocessing, in order to improve the final result and minimize the radiological\ndose for the patient. In a higher level, special algorithms are designed for\ndetecting and encoding these clinically interest-ing imaging features, in order\nto be used as input to advanced pattern classifiers and machine learning\nmodels. Finally, these approaches are extended in multi-classifier models under\nthe scope of Game Theory and optimum collective deci-sion, in order to produce\nefficient solutions for combining classifiers with minimum computational costs\nfor advanced diagnostic systems. The material covered in this thesis is related\nto a total of 18 published papers, 6 in scientific journals and 12 in\ninternational conferences.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2009 03:31:33 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Georgiou", "Harris", ""]]}, {"id": "0910.4711", "submitter": "Shrisha Rao", "authors": "Rajashekar Annaji, Shrisha Rao", "title": "Parallelization of the LBG Vector Quantization Algorithm for Shared\n  Memory Systems", "comments": "14 pages", "journal-ref": "International Journal of Image Processing, vol. 3, no. 4,\n  July/August 2009, pp. 170-183", "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a parallel approach for the Vector Quantization (VQ)\nproblem in image processing. VQ deals with codebook generation from the input\ntraining data set and replacement of any arbitrary data with the nearest\ncodevector. Most of the efforts in VQ have been directed towards designing\nparallel search algorithms for the codebook, and little has hitherto been done\nin evolving a parallelized procedure to obtain an optimum codebook. This\nparallel algorithm addresses the problem of designing an optimum codebook using\nthe traditional LBG type of vector quantization algorithm for shared memory\nsystems and for the efficient usage of parallel processors. Using the codebook\nformed from a training set, any arbitrary input data is replaced with the\nnearest codevector from the codebook. The effectiveness of the proposed\nalgorithm is indicated.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2009 04:46:56 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Annaji", "Rajashekar", ""], ["Rao", "Shrisha", ""]]}, {"id": "0910.4839", "submitter": "Patrick Erik Bradley", "authors": "Patrick Erik Bradley", "title": "A $p$-adic RanSaC algorithm for stereo vision using Hensel lifting", "comments": "15 pages; typos removed, abstract changed, computation error removed", "journal-ref": "p-Adic Numbers, Ultrametric Analysis, and Applications, Vol. 2,\n  No. 1 (2010), 55-67", "doi": "10.1134/S2070046610010048", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $p$-adic variation of the Ran(dom) Sa(mple) C(onsensus) method for solving\nthe relative pose problem in stereo vision is developped. From two 2-adically\nencoded images a random sample of five pairs of corresponding points is taken,\nand the equations for the essential matrix are solved by lifting solutions\nmodulo 2 to the 2-adic integers. A recently devised $p$-adic hierarchical\nclassification algorithm imitating the known LBG quantisation method classifies\nthe solutions for all the samples after having determined the number of\nclusters using the known intra-inter validity of clusterings. In the successful\ncase, a cluster ranking will determine the cluster containing a 2-adic\napproximation to the \"true\" solution of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2009 09:34:29 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2009 17:24:27 GMT"}], "update_date": "2010-02-15", "authors_parsed": [["Bradley", "Patrick Erik", ""]]}, {"id": "0910.5002", "submitter": "Oleg Michailovich", "authors": "Oleg Michailovich", "title": "An Iterative Shrinkage Approach to Total-Variation Image Restoration", "comments": "The paper was submitted to the IEEE Transactions on Image Processing\n  on October 22nd, 2009", "journal-ref": null, "doi": "10.1109/TIP.2010.2090532", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of restoration of digital images from their degraded measurements\nplays a central role in a multitude of practically important applications. A\nparticularly challenging instance of this problem occurs in the case when the\ndegradation phenomenon is modeled by an ill-conditioned operator. In such a\ncase, the presence of noise makes it impossible to recover a valuable\napproximation of the image of interest without using some a priori information\nabout its properties. Such a priori information is essential for image\nrestoration, rendering it stable and robust to noise. Particularly, if the\noriginal image is known to be a piecewise smooth function, one of the standard\npriors used in this case is defined by the Rudin-Osher-Fatemi model, which\nresults in total variation (TV) based image restoration. The current arsenal of\nalgorithms for TV-based image restoration is vast. In the present paper, a\ndifferent approach to the solution of the problem is proposed based on the\nmethod of iterative shrinkage (aka iterated thresholding). In the proposed\nmethod, the TV-based image restoration is performed through a recursive\napplication of two simple procedures, viz. linear filtering and soft\nthresholding. Therefore, the method can be identified as belonging to the group\nof first-order algorithms which are efficient in dealing with images of\nrelatively large sizes. Another valuable feature of the proposed method\nconsists in its working directly with the TV functional, rather then with its\nsmoothed versions. Moreover, the method provides a single solution for both\nisotropic and anisotropic definitions of the TV functional, thereby\nestablishing a useful connection between the two formulae.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2009 22:50:18 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Michailovich", "Oleg", ""]]}, {"id": "0910.5454", "submitter": "Patrick C. McGuire", "authors": "P.C. McGuire, C. Gross, L. Wendt, A. Bonnici, V. Souza-Egipsy, J.\n  Ormo, E. Diaz-Martinez, B.H. Foing, R. Bose, S. Walter, M. Oesker, J. Ontrup,\n  R. Haschke, H. Ritter", "title": "The Cyborg Astrobiologist: Testing a Novelty-Detection Algorithm on Two\n  Mobile Exploration Systems at Rivas Vaciamadrid in Spain and at the Mars\n  Desert Research Station in Utah", "comments": "28 pages, 12 figures, accepted for publication in the International\n  Journal of Astrobiology", "journal-ref": "International Journal of Astrobiology, Vol. 9, pp. 11-27 (2010).", "doi": "10.1017/S1473550409990358", "report-no": null, "categories": "cs.CV astro-ph.EP astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (ABRIDGED) In previous work, two platforms have been developed for testing\ncomputer-vision algorithms for robotic planetary exploration (McGuire et al.\n2004b,2005; Bartolo et al. 2007). The wearable-computer platform has been\ntested at geological and astrobiological field sites in Spain (Rivas\nVaciamadrid and Riba de Santiuste), and the phone-camera has been tested at a\ngeological field site in Malta. In this work, we (i) apply a Hopfield\nneural-network algorithm for novelty detection based upon color, (ii) integrate\na field-capable digital microscope on the wearable computer platform, (iii)\ntest this novelty detection with the digital microscope at Rivas Vaciamadrid,\n(iv) develop a Bluetooth communication mode for the phone-camera platform, in\norder to allow access to a mobile processing computer at the field sites, and\n(v) test the novelty detection on the Bluetooth-enabled phone-camera connected\nto a netbook computer at the Mars Desert Research Station in Utah. This systems\nengineering and field testing have together allowed us to develop a real-time\ncomputer-vision system that is capable, for example, of identifying lichens as\nnovel within a series of images acquired in semi-arid desert environments. We\nacquired sequences of images of geologic outcrops in Utah and Spain consisting\nof various rock types and colors to test this algorithm. The algorithm robustly\nrecognized previously-observed units by their color, while requiring only a\nsingle image or a few images to learn colors as familiar, demonstrating its\nfast learning capability.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 18:26:39 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["McGuire", "P. C.", ""], ["Gross", "C.", ""], ["Wendt", "L.", ""], ["Bonnici", "A.", ""], ["Souza-Egipsy", "V.", ""], ["Ormo", "J.", ""], ["Diaz-Martinez", "E.", ""], ["Foing", "B. H.", ""], ["Bose", "R.", ""], ["Walter", "S.", ""], ["Oesker", "M.", ""], ["Ontrup", "J.", ""], ["Haschke", "R.", ""], ["Ritter", "H.", ""]]}, {"id": "0910.5932", "submitter": "Prateek Jain", "authors": "Prateek Jain, Brian Kulis, Jason V. Davis, Inderjit S. Dhillon", "title": "Metric and Kernel Learning using a Linear Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric and kernel learning are important in several machine learning\napplications. However, most existing metric learning algorithms are limited to\nlearning metrics over low-dimensional data, while existing kernel learning\nalgorithms are often limited to the transductive setting and do not generalize\nto new data points. In this paper, we study metric learning as a problem of\nlearning a linear transformation of the input data. We show that for\nhigh-dimensional data, a particular framework for learning a linear\ntransformation of the data based on the LogDet divergence can be efficiently\nkernelized to learn a metric (or equivalently, a kernel function) over an\narbitrarily high dimensional space. We further demonstrate that a wide class of\nconvex loss functions for learning linear transformations can similarly be\nkernelized, thereby considerably expanding the potential applications of metric\nlearning. We demonstrate our learning approach by applying it to large-scale\nreal world problems in computer vision and text mining.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2009 18:19:03 GMT"}], "update_date": "2009-11-02", "authors_parsed": [["Jain", "Prateek", ""], ["Kulis", "Brian", ""], ["Davis", "Jason V.", ""], ["Dhillon", "Inderjit S.", ""]]}]