[{"id": "1009.0051", "submitter": "Keyvan Yahya", "authors": "Keyvan Yahya, Jafar Biazar, Hossein Azari, Pouyan Rafiei Fard", "title": "Variational Iteration Method for Image Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous Perona-Malik (P-M) equation which was at first introduced for\nimage restoration has been solved via various numerical methods. In this paper\nwe will solve it for the first time via applying a new numerical method called\nthe Variational Iteration Method (VIM) and the correspondent approximated\nsolutions will be obtained for the P-M equation with regards to relevant error\nanalysis. Through implementation of our algorithm we will access some effective\nresults which are deserved to be considered as worthy as the other solutions\nissued by the other methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Aug 2010 23:15:26 GMT"}, {"version": "v2", "created": "Thu, 2 Sep 2010 05:56:26 GMT"}], "update_date": "2010-09-03", "authors_parsed": [["Yahya", "Keyvan", ""], ["Biazar", "Jafar", ""], ["Azari", "Hossein", ""], ["Fard", "Pouyan Rafiei", ""]]}, {"id": "1009.0623", "submitter": "Sakthivel Subramaniam S", "authors": "S. Sakthivel, R. Lakshmipathi", "title": "Weighted Attribute Fusion Model for Face Recognition", "comments": "Keywords - Face Recognition, Feature Fusion Method, Parallel Method,\n  PCA, DCT, Histogram Matching", "journal-ref": "International Journal of Computer Science and Information\n  Security,Vol. 8, No. 3, 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing a face based on its attributes is an easy task for a human to\nperform as it is a cognitive process. In recent years, Face Recognition is\nachieved with different kinds of facial features which were used separately or\nin a combined manner. Currently, Feature fusion methods and parallel methods\nare the facial features used and performed by integrating multiple feature sets\nat different levels. However, this integration and the combinational methods do\nnot guarantee better result. Hence to achieve better results, the feature\nfusion model with multiple weighted facial attribute set is selected. For this\nfeature model, face images from predefined data set has been taken from\nOlivetti Research Laboratory (ORL) and applied on different methods like\nPrincipal Component Analysis (PCA) based Eigen feature extraction technique,\nDiscrete Cosine Transformation (DCT) based feature extraction technique,\nHistogram Based Feature Extraction technique and Simple Intensity based\nfeatures. The extracted feature set obtained from these methods were compared\nand tested for accuracy. In this work we have developed a model which will use\nthe above set of feature extraction techniques with different levels of weights\nto attain better accuracy. The results show that the selection of optimum\nweight for a particular feature will lead to improvement in recognition rate.\n", "versions": [{"version": "v1", "created": "Fri, 3 Sep 2010 10:05:20 GMT"}, {"version": "v2", "created": "Tue, 28 Sep 2010 15:57:24 GMT"}], "update_date": "2010-11-10", "authors_parsed": [["Sakthivel", "S.", ""], ["Lakshmipathi", "R.", ""]]}, {"id": "1009.0854", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hassan Kingravi, Fatih Celiker", "title": "Fast Color Space Transformations Using Minimax Approximations", "comments": null, "journal-ref": "IET Image Processing 4 (2010) 70-80", "doi": "10.1049/iet-ipr.2008.0172", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color space transformations are frequently used in image processing,\ngraphics, and visualization applications. In many cases, these transformations\nare complex nonlinear functions, which prohibits their use in time-critical\napplications. In this paper, we present a new approach called Minimax\nApproximations for Color-space Transformations (MACT).We demonstrate MACT on\nthree commonly used color space transformations. Extensive experiments on a\nlarge and diverse image set and comparisons with well-known multidimensional\nlookup table interpolation methods show that MACT achieves an excellent balance\namong four criteria: ease of implementation, memory usage, accuracy, and\ncomputational speed.\n", "versions": [{"version": "v1", "created": "Sat, 4 Sep 2010 17:44:06 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""], ["Kingravi", "Hassan", ""], ["Celiker", "Fatih", ""]]}, {"id": "1009.0892", "submitter": "Chunhua Shen", "authors": "Yongbin Zheng, Chunhua Shen, Richard Hartley, Xinsheng Huang", "title": "Effective Pedestrian Detection Using Center-symmetric Local\n  Binary/Trinary Patterns", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately detecting pedestrians in images plays a critically important role\nin many computer vision applications. Extraction of effective features is the\nkey to this task. Promising features should be discriminative, robust to\nvarious variations and easy to compute. In this work, we present novel\nfeatures, termed dense center-symmetric local binary patterns (CS-LBP) and\npyramid center-symmetric local binary/ternary patterns (CS-LBP/LTP), for\npedestrian detection. The standard LBP proposed by Ojala et al. \\cite{c4}\nmainly captures the texture information. The proposed CS-LBP feature, in\ncontrast, captures the gradient information and some texture information.\nMoreover, the proposed dense CS-LBP and the pyramid CS-LBP/LTP are easy to\nimplement and computationally efficient, which is desirable for real-time\napplications. Experiments on the INRIA pedestrian dataset show that the dense\nCS-LBP feature with linear supporct vector machines (SVMs) is comparable with\nthe histograms of oriented gradients (HOG) feature with linear SVMs, and the\npyramid CS-LBP/LTP features outperform both HOG features with linear SVMs and\nthe start-of-the-art pyramid HOG (PHOG) feature with the histogram intersection\nkernel SVMs. We also demonstrate that the combination of our pyramid CS-LBP\nfeature and the PHOG feature could significantly improve the detection\nperformance-producing state-of-the-art accuracy on the INRIA pedestrian\ndataset.\n", "versions": [{"version": "v1", "created": "Sun, 5 Sep 2010 05:16:11 GMT"}, {"version": "v2", "created": "Fri, 17 Sep 2010 01:58:29 GMT"}], "update_date": "2010-09-20", "authors_parsed": [["Zheng", "Yongbin", ""], ["Shen", "Chunhua", ""], ["Hartley", "Richard", ""], ["Huang", "Xinsheng", ""]]}, {"id": "1009.0957", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi", "title": "Distance Measures for Reduced Ordering Based Vector Filters", "comments": null, "journal-ref": "IET Image Processing 3 (2009) 249-260", "doi": "10.1049/iet-ipr.2009.0056", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced ordering based vector filters have proved successful in removing\nlong-tailed noise from color images while preserving edges and fine image\ndetails. These filters commonly utilize variants of the Minkowski distance to\norder the color vectors with the aim of distinguishing between noisy and\nnoise-free vectors. In this paper, we review various alternative distance\nmeasures and evaluate their performance on a large and diverse set of images\nusing several effectiveness and efficiency criteria. The results demonstrate\nthat there are in fact strong alternatives to the popular Minkowski metrics.\n", "versions": [{"version": "v1", "created": "Sun, 5 Sep 2010 23:49:38 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""]]}, {"id": "1009.0958", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi", "title": "Real-Time Implementation of Order-Statistics Based Directional Filters", "comments": null, "journal-ref": "IET Image Processing 3 (2009) 1-9", "doi": "10.1049/iet-ipr:20080080", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector filters based on order-statistics have proved successful in removing\nimpulsive noise from color images while preserving edges and fine image\ndetails. Among these filters, the ones that involve the cosine distance\nfunction (directional filters) have particularly high computational\nrequirements, which limits their use in time critical applications. In this\npaper, we introduce two methods to speed up these filters. Experiments on a\ndiverse set of color images show that the proposed methods provide substantial\ncomputational gains without significant loss of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 5 Sep 2010 23:53:27 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""]]}, {"id": "1009.0959", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hassan A. Kingravi, Rastislav Lukac, Fatih Celiker", "title": "Cost-Effective Implementation of Order-Statistics Based Vector Filters\n  Using Minimax Approximations", "comments": null, "journal-ref": "Journal of the Optical Society of America A 26 (2009) 1518-1524", "doi": "10.1364/JOSAA.26.001518", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector operators based on robust order statistics have proved successful in\ndigital multichannel imaging applications, particularly color image filtering\nand enhancement, in dealing with impulsive noise while preserving edges and\nfine image details. These operators often have very high computational\nrequirements which limits their use in time-critical applications. This paper\nintroduces techniques to speed up vector filters using the minimax\napproximation theory. Extensive experiments on a large and diverse set of color\nimages show that proposed approximations achieve an excellent balance among\nease of implementation, accuracy, and computational speed.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 00:02:35 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""], ["Kingravi", "Hassan A.", ""], ["Lukac", "Rastislav", ""], ["Celiker", "Fatih", ""]]}, {"id": "1009.0961", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hassan A. Kingravi, Bakhtiyar Uddin, Y. Alp Aslandogan", "title": "A Fast Switching Filter for Impulsive Noise Removal from Color Images", "comments": null, "journal-ref": "Journal of Imaging Science and Technology 51 (2007) 155-165", "doi": "10.2352/J.ImagingSci.Technol.(2007)51:2(155)", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a fast switching filter for impulsive noise removal\nfrom color images. The filter exploits the HSL color space, and is based on the\npeer group concept, which allows for the fast detection of noise in a\nneighborhood without resorting to pairwise distance computations between each\npixel. Experiments on large set of diverse images demonstrate that the proposed\napproach is not only extremely fast, but also gives excellent results in\ncomparison to various state-of-the-art filters.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 00:13:25 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""], ["Kingravi", "Hassan A.", ""], ["Uddin", "Bakhtiyar", ""], ["Aslandogan", "Y. Alp", ""]]}, {"id": "1009.0962", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hassan A. Kingravi, Y. Alp Aslandogan", "title": "Nonlinear Vector Filtering for Impulsive Noise Removal from Color Images", "comments": null, "journal-ref": "Journal of Electronic Imaging 16 (2007) 033008", "doi": "10.1117/1.2772639", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a comprehensive survey of 48 filters for impulsive noise\nremoval from color images is presented. The filters are formulated using a\nuniform notation and categorized into 8 families. The performance of these\nfilters is compared on a large set of images that cover a variety of domains\nusing three effectiveness and one efficiency criteria. In order to ensure a\nfair efficiency comparison, a fast and accurate approximation for the inverse\ncosine function is introduced. In addition, commonly used distance measures\n(Minkowski, angular, and directional-distance) are analyzed and evaluated.\nFinally, suggestions are provided on how to choose a filter given certain\nrequirements.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 00:22:58 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""], ["Kingravi", "Hassan A.", ""], ["Aslandogan", "Y. Alp", ""]]}, {"id": "1009.1013", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hitoshi Iyatomi, William V. Stoecker, Randy H. Moss,\n  Harold S. Rabinovitz, Giuseppe Argenziano, H. Peter Soyer", "title": "Automatic Detection of Blue-White Veil and Related Structures in\n  Dermoscopy Images", "comments": null, "journal-ref": "Computerized Medical Imaging and Graphics 32 (2008) 670-677", "doi": "10.1016/j.compmedimag.2008.08.003", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dermoscopy is a non-invasive skin imaging technique, which permits\nvisualization of features of pigmented melanocytic neoplasms that are not\ndiscernable by examination with the naked eye. One of the most important\nfeatures for the diagnosis of melanoma in dermoscopy images is the blue-white\nveil (irregular, structureless areas of confluent blue pigmentation with an\noverlying white \"ground-glass\" film). In this article, we present a machine\nlearning approach to the detection of blue-white veil and related structures in\ndermoscopy images. The method involves contextual pixel classification using a\ndecision tree classifier. The percentage of blue-white areas detected in a\nlesion combined with a simple shape descriptor yielded a sensitivity of 69.35%\nand a specificity of 89.97% on a set of 545 dermoscopy images. The sensitivity\nrises to 78.20% for detection of blue veil in those cases where it is a primary\nfeature for melanoma recognition.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 10:29:18 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Celebi", "M. Emre", ""], ["Iyatomi", "Hitoshi", ""], ["Stoecker", "William V.", ""], ["Moss", "Randy H.", ""], ["Rabinovitz", "Harold S.", ""], ["Argenziano", "Giuseppe", ""], ["Soyer", "H. Peter", ""]]}, {"id": "1009.1020", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Gerald Schaefer, Hitoshi Iyatomi, William V. Stoecker,\n  Joseph M. Malters, James M. Grichnik", "title": "An Improved Objective Evaluation Measure for Border Detection in\n  Dermoscopy Images", "comments": null, "journal-ref": "Skin Research and Technology 15 (2009) 444-450", "doi": "10.1111/j.1600-0846.2009.00387.x", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, dermoscopy image analysis has become\nan important research area. One of the most important steps in dermoscopy image\nanalysis is the automated detection of lesion borders. Although numerous\nmethods have been developed for the detection of lesion borders, very few\nstudies were comprehensive in the evaluation of their results. Methods: In this\npaper, we evaluate five recent border detection methods on a set of 90\ndermoscopy images using three sets of dermatologist-drawn borders as the\nground-truth. In contrast to previous work, we utilize an objective measure,\nthe Normalized Probabilistic Rand Index, which takes into account the\nvariations in the ground-truth images. Conclusion: The results demonstrate that\nthe differences between four of the evaluated border detection methods are in\nfact smaller than those predicted by the commonly used XOR measure.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 10:53:21 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Celebi", "M. Emre", ""], ["Schaefer", "Gerald", ""], ["Iyatomi", "Hitoshi", ""], ["Stoecker", "William V.", ""], ["Malters", "Joseph M.", ""], ["Grichnik", "James M.", ""]]}, {"id": "1009.1362", "submitter": "M. Emre Celebi", "authors": "M. Emre Celebi, Hitoshi Iyatomi, Gerald Schaefer, William V. Stoecker", "title": "Approximate Lesion Localization in Dermoscopy Images", "comments": null, "journal-ref": "Skin Research and Technology 15 (2009) 314-322", "doi": "10.1111/j.1600-0846.2009.00357.x", "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Dermoscopy is one of the major imaging modalities used in the\ndiagnosis of melanoma and other pigmented skin lesions. Due to the difficulty\nand subjectivity of human interpretation, automated analysis of dermoscopy\nimages has become an important research area. Border detection is often the\nfirst step in this analysis. Methods: In this article, we present an\napproximate lesion localization method that serves as a preprocessing step for\ndetecting borders in dermoscopy images. In this method, first the black frame\naround the image is removed using an iterative algorithm. The approximate\nlocation of the lesion is then determined using an ensemble of thresholding\nalgorithms. Results: The method is tested on a set of 428 dermoscopy images.\nThe localization error is quantified by a metric that uses dermatologist\ndetermined borders as the ground truth. Conclusion: The results demonstrate\nthat the method presented here achieves both fast and accurate localization of\nlesions in dermoscopy images.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 11:01:53 GMT"}], "update_date": "2010-09-08", "authors_parsed": [["Celebi", "M. Emre", ""], ["Iyatomi", "Hitoshi", ""], ["Schaefer", "Gerald", ""], ["Stoecker", "William V.", ""]]}, {"id": "1009.1983", "submitter": "Jenny Blight", "authors": "P. Geetha and Vasumathi Narayanan", "title": "Evolutionary Computational Method of Facial Expression Analysis for\n  Content-based Video Retrieval using 2-Dimensional Cellular Automata", "comments": "Submitted to Journal of Computer Science and Engineering, see\n  http://sites.google.com/site/jcseuk/volume-2-issue-2-August-2010", "journal-ref": "Journal of Computer Science and Engineering, Volume 2, Issue 2,\n  p30-39, August 2010", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, Deterministic Cellular Automata (DCA) based video shot\nclassification and retrieval is proposed. The deterministic 2D Cellular\nautomata model captures the human facial expressions, both spontaneous and\nposed. The determinism stems from the fact that the facial muscle actions are\nstandardized by the encodings of Facial Action Coding System (FACS) and Action\nUnits (AUs). Based on these encodings, we generate the set of evolutionary\nupdate rules of the DCA for each facial expression. We consider a\nPerson-Independent Facial Expression Space (PIFES) to analyze the facial\nexpressions based on Partitioned 2D-Cellular Automata which capture the\ndynamics of facial expressions and classify the shots based on it. Target video\nshot is retrieved by comparing the similar expression is obtained for the query\nframe's face with respect to the key faces expressions in the database video.\nConsecutive key face expressions in the database that are highly similar to the\nquery frame's face, then the key faces are used to generate the set of\nretrieved video shots from the database. A concrete example of its application\nwhich realizes an affective interaction between the computer and the user is\nproposed. In the affective interaction, the computer can recognize the facial\nexpression of any given video shot. This interaction endows the computer with\ncertain ability to adapt to the user's feedback.\n", "versions": [{"version": "v1", "created": "Fri, 10 Sep 2010 11:25:17 GMT"}], "update_date": "2010-09-13", "authors_parsed": [["Geetha", "P.", ""], ["Narayanan", "Vasumathi", ""]]}, {"id": "1009.3029", "submitter": "Laurent Jacques", "authors": "Maxime Taquet, Laurent Jacques, Christophe De Vleeschouwer and Benoit\n  Macq", "title": "Invariant Spectral Hashing of Image Saliency Graph", "comments": "Keywords: Invariant Hashing, Geometrical Invariant, Spectral Graph,\n  Salient Points. Content: 8 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": "TR-LJ-2010.01", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image hashing is the process of associating a short vector of bits to an\nimage. The resulting summaries are useful in many applications including image\nindexing, image authentication and pattern recognition. These hashes need to be\ninvariant under transformations of the image that result in similar visual\ncontent, but should drastically differ for conceptually distinct contents. This\npaper proposes an image hashing method that is invariant under rotation,\nscaling and translation of the image. The gist of our approach relies on the\ngeometric characterization of salient point distribution in the image. This is\nachieved by the definition of a \"saliency graph\" connecting these points\njointly with an image intensity function on the graph nodes. An invariant hash\nis then obtained by considering the spectrum of this function in the\neigenvector basis of the Laplacian graph, that is, its graph Fourier transform.\nInterestingly, this spectrum is invariant under any relabeling of the graph\nnodes. The graph reveals geometric information of the image, making the hash\nrobust to image transformation, yet distinct for different visual content. The\nefficiency of the proposed method is assessed on a set of MRI 2-D slices and on\na database of faces.\n", "versions": [{"version": "v1", "created": "Wed, 15 Sep 2010 20:11:11 GMT"}], "update_date": "2010-09-17", "authors_parsed": [["Taquet", "Maxime", ""], ["Jacques", "Laurent", ""], ["De Vleeschouwer", "Christophe", ""], ["Macq", "Benoit", ""]]}, {"id": "1009.3078", "submitter": "Chunhua Shen", "authors": "Peng Wang, Chunhua Shen, Nick Barnes, Hong Zheng, Zhang Ren", "title": "Asymmetric Totally-corrective Boosting for Real-time Object Detection", "comments": "14 pages, published in Asian Conf. Computer Vision 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time object detection is one of the core problems in computer vision.\nThe cascade boosting framework proposed by Viola and Jones has become the\nstandard for this problem. In this framework, the learning goal for each node\nis asymmetric, which is required to achieve a high detection rate and a\nmoderate false positive rate. We develop new boosting algorithms to address\nthis asymmetric learning problem. We show that our methods explicitly optimize\nasymmetric loss objectives in a totally corrective fashion. The methods are\ntotally corrective in the sense that the coefficients of all selected weak\nclassifiers are updated at each iteration. In contract, conventional boosting\nlike AdaBoost is stage-wise in that only the current weak classifier's\ncoefficient is updated. At the heart of the totally corrective boosting is the\ncolumn generation technique. Experiments on face detection show that our\nmethods outperform the state-of-the-art asymmetric boosting methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 02:45:59 GMT"}], "update_date": "2010-09-17", "authors_parsed": [["Wang", "Peng", ""], ["Shen", "Chunhua", ""], ["Barnes", "Nick", ""], ["Zheng", "Hong", ""], ["Ren", "Zhang", ""]]}, {"id": "1009.3589", "submitter": "Yoshua Bengio", "authors": "Fr\\'ed\\'eric Bastien and Yoshua Bengio and Arnaud Bergeron and Nicolas\n  Boulanger-Lewandowski and Thomas Breuel and Youssouf Chherawala and Moustapha\n  Cisse and Myriam C\\^ot\\'e and Dumitru Erhan and Jeremy Eustache and Xavier\n  Glorot and Xavier Muller and Sylvain Pannetier Lebeuf and Razvan Pascanu and\n  Salah Rifai and Francois Savard and Guillaume Sicard", "title": "Deep Self-Taught Learning for Handwritten Character Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": "1353, Dept. IRO, U. Montreal", "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical and empirical work in statistical machine learning has\ndemonstrated the importance of learning algorithms for deep architectures,\ni.e., function classes obtained by composing multiple non-linear\ntransformations. Self-taught learning (exploiting unlabeled examples or\nexamples from other distributions) has already been applied to deep learners,\nbut mostly to show the advantage of unlabeled examples. Here we explore the\nadvantage brought by {\\em out-of-distribution examples}. For this purpose we\ndeveloped a powerful generator of stochastic variations and noise processes for\ncharacter images, including not only affine transformations but also slant,\nlocal elastic deformations, changes in thickness, background images, grey level\nchanges, contrast, occlusion, and various types of noise. The\nout-of-distribution examples are obtained from these highly distorted images or\nby including examples of object classes different from those in the target test\nset. We show that {\\em deep learners benefit more from out-of-distribution\nexamples than a corresponding shallow learner}, at least in the area of\nhandwritten character recognition. In fact, we show that they beat previously\npublished results and reach human-level performance on both handwritten digit\nclassification and 62-class handwritten character recognition.\n", "versions": [{"version": "v1", "created": "Sat, 18 Sep 2010 22:11:05 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Bastien", "Fr\u00e9d\u00e9ric", ""], ["Bengio", "Yoshua", ""], ["Bergeron", "Arnaud", ""], ["Boulanger-Lewandowski", "Nicolas", ""], ["Breuel", "Thomas", ""], ["Chherawala", "Youssouf", ""], ["Cisse", "Moustapha", ""], ["C\u00f4t\u00e9", "Myriam", ""], ["Erhan", "Dumitru", ""], ["Eustache", "Jeremy", ""], ["Glorot", "Xavier", ""], ["Muller", "Xavier", ""], ["Lebeuf", "Sylvain Pannetier", ""], ["Pascanu", "Razvan", ""], ["Rifai", "Salah", ""], ["Savard", "Francois", ""], ["Sicard", "Guillaume", ""]]}, {"id": "1009.3802", "submitter": "Ju Sun", "authors": "Yuzhao Ni, Ju Sun, Xiaotong Yuan, Shuicheng Yan, Loong-Fah Cheong", "title": "Robust Low-Rank Subspace Segmentation with Semidefinite Guarantees", "comments": "10 pages, 4 figures. Accepted by ICDM Workshop on Optimization Based\n  Methods for Emerging Data Mining Problems (OEDM), 2010. Main proof simplified\n  and typos corrected. Experimental data slightly added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there is a line of research work proposing to employ Spectral\nClustering (SC) to segment (group){Throughout the paper, we use segmentation,\nclustering, and grouping, and their verb forms, interchangeably.}\nhigh-dimensional structural data such as those (approximately) lying on\nsubspaces {We follow {liu2010robust} and use the term \"subspace\" to denote both\nlinear subspaces and affine subspaces. There is a trivial conversion between\nlinear subspaces and affine subspaces as mentioned therein.} or low-dimensional\nmanifolds. By learning the affinity matrix in the form of sparse\nreconstruction, techniques proposed in this vein often considerably boost the\nperformance in subspace settings where traditional SC can fail. Despite the\nsuccess, there are fundamental problems that have been left unsolved: the\nspectrum property of the learned affinity matrix cannot be gauged in advance,\nand there is often one ugly symmetrization step that post-processes the\naffinity for SC input. Hence we advocate to enforce the symmetric positive\nsemidefinite constraint explicitly during learning (Low-Rank Representation\nwith Positive SemiDefinite constraint, or LRR-PSD), and show that factually it\ncan be solved in an exquisite scheme efficiently instead of general-purpose SDP\nsolvers that usually scale up poorly. We provide rigorous mathematical\nderivations to show that, in its canonical form, LRR-PSD is equivalent to the\nrecently proposed Low-Rank Representation (LRR) scheme {liu2010robust}, and\nhence offer theoretic and practical insights to both LRR-PSD and LRR, inviting\nfuture research. As per the computational cost, our proposal is at most\ncomparable to that of LRR, if not less. We validate our theoretic analysis and\noptimization scheme by experiments on both synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Sep 2010 12:54:12 GMT"}, {"version": "v2", "created": "Sun, 26 Sep 2010 16:07:15 GMT"}, {"version": "v3", "created": "Fri, 8 Oct 2010 16:53:06 GMT"}], "update_date": "2010-10-11", "authors_parsed": [["Ni", "Yuzhao", ""], ["Sun", "Ju", ""], ["Yuan", "Xiaotong", ""], ["Yan", "Shuicheng", ""], ["Cheong", "Loong-Fah", ""]]}, {"id": "1009.4004", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "A family of statistical symmetric divergences based on Jensen's\n  inequality", "comments": "15 pages, 2 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel parametric family of symmetric information-theoretic\ndistances based on Jensen's inequality for a convex functional generator. In\nparticular, this family unifies the celebrated Jeffreys divergence with the\nJensen-Shannon divergence when the Shannon entropy generator is chosen. We then\ndesign a generic algorithm to compute the unique centroid defined as the\nminimum average divergence. This yields a smooth family of centroids linking\nthe Jeffreys to the Jensen-Shannon centroid. Finally, we report on our\nexperimental results.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 06:32:52 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2011 02:31:16 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1009.4581", "submitter": "Mohammed El Hassouni", "authors": "Mohammed EL Hassouni and Driss Aboutajdine", "title": "3D-Mesh denoising using an improved vertex based anisotropic diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with an improvement of vertex based nonlinear diffusion for\nmesh denoising. This method directly filters the position of the vertices using\nLaplace, reduced centered Gaussian and Rayleigh probability density functions\nas diffusivities. The use of these PDFs improves the performance of a\nvertex-based diffusion method which are adapted to the underlying mesh\nstructure. We also compare the proposed method to other mesh denoising methods\nsuch as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To\nevaluate these methods of filtering, we use two error metrics. The first is\nbased on the vertices and the second is based on the normals. Experimental\nresults demonstrate the effectiveness of our proposed method in comparison with\nthe existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 11:26:37 GMT"}], "update_date": "2010-09-24", "authors_parsed": [["Hassouni", "Mohammed EL", ""], ["Aboutajdine", "Driss", ""]]}, {"id": "1009.4739", "submitter": "Romain Tavenard", "authors": "Romain Tavenard (INRIA - IRISA), Laurent Amsaleg (INRIA - IRISA),\n  Herv\\'e J\\'egou (INRIA - IRISA)", "title": "Balancing clusters to reduce response time variability in large scale\n  image search", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7387", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many algorithms for approximate nearest neighbor search in high-dimensional\nspaces partition the data into clusters. At query time, in order to avoid\nexhaustive search, an index selects the few (or a single) clusters nearest to\nthe query point. Clusters are often produced by the well-known $k$-means\napproach since it has several desirable properties. On the downside, it tends\nto produce clusters having quite different cardinalities. Imbalanced clusters\nnegatively impact both the variance and the expectation of query response\ntimes. This paper proposes to modify $k$-means centroids to produce clusters\nwith more comparable sizes without sacrificing the desirable properties.\nExperiments with a large scale collection of image descriptors show that our\nalgorithm significantly reduces the variance of response times without\nseriously impacting the search quality.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 11:31:02 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Tavenard", "Romain", "", "INRIA - IRISA"], ["Amsaleg", "Laurent", "", "INRIA - IRISA"], ["J\u00e9gou", "Herv\u00e9", "", "INRIA - IRISA"]]}, {"id": "1009.4757", "submitter": "Vikram Dhillon", "authors": "Vikram Dhillon", "title": "Modeling Instantaneous Changes In Natural Scenes", "comments": "20 pages double spaced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This project aims to create 3d model of the natural world and model changes\nin it instantaneously. A framework for modeling instantaneous changes natural\nscenes in real time using Lagrangian Particle Framework and a fluid-particle\ngrid approach is presented. This project is presented in the form of a\nproof-based system where we show that the design is very much possible but\ncurrently we only have selective scripts that accomplish the given job, a\ncomplete software however is still under work. This research can be divided\ninto 3 distinct sections: the first one discusses a multi-camera rig that can\nmeasure ego-motion accurately up to 88%, how this device becomes the backbone\nof our framework, and some improvements devised to optimize a know framework\nfor depth maps and 3d structure estimation from a single still image called\nmake3d. The second part discusses the fluid-particle framework to model natural\nscenes, presents some algorithms that we are using to accomplish this task and\nwe show how an application of our framework can extend make3d to model natural\nscenes in real time. This part of the research constructs a bridge between\ncomputer vision and computer graphics so that now ideas, answers and intuitions\nthat arose in the domain of computer graphics can now be applied to computer\nvision and natural modeling. The final part of this research improves upon what\nmight become the first general purpose vision system using deep belief\narchitectures and provides another framework to improve the lower bound on\ntraining images for boosting by using a variation of Restricted Boltzmann\nmachines (RBM). We also discuss other applications that might arise from our\nwork in these areas.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 03:32:28 GMT"}, {"version": "v2", "created": "Mon, 4 Oct 2010 00:19:00 GMT"}, {"version": "v3", "created": "Thu, 25 Nov 2010 05:34:24 GMT"}], "update_date": "2010-11-29", "authors_parsed": [["Dhillon", "Vikram", ""]]}, {"id": "1009.4823", "submitter": "Adrian Ion", "authors": "Joao Carreira, Adrian Ion, and Cristian Sminchisescu", "title": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "TR-06-2010", "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mid-level image segmentation framework that combines multiple\nfigure-ground hypothesis (FG) constrained at different locations and scales,\ninto interpretations that tile the entire image. The problem is cast as\noptimization over sets of maximal cliques sampled from the graph connecting\nnon-overlapping, putative figure-ground segment hypotheses. Potential functions\nover cliques combine unary Gestalt-based figure quality scores and pairwise\ncompatibilities among spatially neighboring segments, constrained by\nT-junctions and the boundary interface statistics resulting from projections of\nreal 3d scenes. Learning the model parameters is formulated as rank\noptimization, alternating between sampling image tilings and optimizing their\npotential function parameters. State of the art results are reported on both\nthe Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was\nachieved.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 12:32:02 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Carreira", "Joao", ""], ["Ion", "Adrian", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "1009.4974", "submitter": "S. M. Kamruzzaman", "authors": "S. M. Kamruzzaman, Firoz Ahmed Siddiqi, Md. Saiful Islam, Md. Emdadul\n  Haque, and Mohammad Shamsul Alam", "title": "Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis\n  Function Networks", "comments": "5 Pages, International Conference", "journal-ref": "12th International Conference on Human Computer Interaction,\n  Beijing, China, Vol. 18, Jul. 2007", "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method for human face detection with its\norientation by using wavelet, principle component analysis (PCA) and redial\nbasis networks. The input image is analyzed by two-dimensional wavelet and a\ntwo-dimensional stationary wavelet. The common goals concern are the image\nclearance and simplification, which are parts of de-noising or compression. We\napplied an effective procedure to reduce the dimension of the input vectors\nusing PCA. Radial Basis Function (RBF) neural network is then used as a\nfunction approximation network to detect where either the input image is\ncontained a face or not and if there is a face exists then tell about its\norientation. We will show how RBF can perform well then back-propagation\nalgorithm and give some solution for better regularization of the RBF (GRNN)\nnetwork. Compared with traditional RBF networks, the proposed network\ndemonstrates better capability of approximation to underlying functions, faster\nlearning speed, better size of network, and high robustness to outliers.\n", "versions": [{"version": "v1", "created": "Sat, 25 Sep 2010 05:46:31 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Kamruzzaman", "S. M.", ""], ["Siddiqi", "Firoz Ahmed", ""], ["Islam", "Md. Saiful", ""], ["Haque", "Md. Emdadul", ""], ["Alam", "Mohammad Shamsul", ""]]}, {"id": "1009.5249", "submitter": "Bin Jiang", "authors": "Xintao Liu and Bin Jiang", "title": "Defining and Generating Axial Lines from Street Center Lines for better\n  Understanding of Urban Morphologies", "comments": "10 pages, 7 figures, and 2 tables, one figure added + minor revision", "journal-ref": "International Journal of Geographical Information Science, 26(8),\n  2012, 1521-1532", "doi": null, "report-no": null, "categories": "cs.CV physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axial lines are defined as the longest visibility lines for representing\nindividual linear spaces in urban environments. The least number of axial lines\nthat cover the free space of an urban environment or the space between\nbuildings constitute what is often called an axial map. This is a fundamental\ntool in space syntax, a theory developed by Bill Hillier and his colleagues for\ncharacterizing the underlying urban morphologies. For a long time, generating\naxial lines with help of some graphic software has been a tedious manual\nprocess that is criticized for being time consuming, subjective, or even\narbitrary. In this paper, we redefine axial lines as the least number of\nindividual straight line segments mutually intersected along natural streets\nthat are generated from street center lines using the Gestalt principle of good\ncontinuity. Based on this new definition, we develop an automatic solution to\ngenerating the newly defined axial lines from street center lines. We apply\nthis solution to six typical street networks (three from North America and\nthree from Europe), and generate a new set of axial lines for analyzing the\nurban morphologies. Through a comparison study between the new axial lines and\nthe conventional or old axial lines, and between the new axial lines and\nnatural streets, we demonstrate with empirical evidence that the newly defined\naxial lines are a better alternative in capturing the underlying urban\nstructure.\n  Keywords: Space syntax, street networks, topological analysis, traffic,\nhead/tail division rule\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 13:17:40 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2011 04:03:29 GMT"}], "update_date": "2013-07-17", "authors_parsed": [["Liu", "Xintao", ""], ["Jiang", "Bin", ""]]}, {"id": "1009.5750", "submitter": "Raymond J. Carroll", "authors": "Josue G. Martinez, Jianhua Z. Huang, Robert C. Burghardt, Rola\n  Barhoumi, Raymond J. Carroll", "title": "Use of multiple singular value decompositions to analyze complex\n  intracellular calcium ion signals", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS253 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2009, Vol. 3, No. 4, 1467-1492", "doi": "10.1214/09-AOAS253", "report-no": "IMS-AOAS-AOAS253", "categories": "stat.AP cs.CV physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare calcium ion signaling ($\\mathrm {Ca}^{2+}$) between two exposures;\nthe data are present as movies, or, more prosaically, time series of images.\nThis paper describes novel uses of singular value decompositions (SVD) and\nweighted versions of them (WSVD) to extract the signals from such movies, in a\nway that is semi-automatic and tuned closely to the actual data and their many\ncomplexities. These complexities include the following. First, the images\nthemselves are of no interest: all interest focuses on the behavior of\nindividual cells across time, and thus, the cells need to be segmented in an\nautomated manner. Second, the cells themselves have 100$+$ pixels, so that they\nform 100$+$ curves measured over time, so that data compression is required to\nextract the features of these curves. Third, some of the pixels in some of the\ncells are subject to image saturation due to bit depth limits, and this\nsaturation needs to be accounted for if one is to normalize the images in a\nreasonably unbiased manner. Finally, the $\\mathrm {Ca}^{2+}$ signals have\noscillations or waves that vary with time and these signals need to be\nextracted. Thus, our aim is to show how to use multiple weighted and standard\nsingular value decompositions to detect, extract and clarify the $\\mathrm\n{Ca}^{2+}$ signals. Our signal extraction methods then lead to simple although\nfinely focused statistical methods to compare $\\mathrm {Ca}^{2+}$ signals\nacross experimental conditions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Sep 2010 09:16:19 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Martinez", "Josue G.", ""], ["Huang", "Jianhua Z.", ""], ["Burghardt", "Robert C.", ""], ["Barhoumi", "Rola", ""], ["Carroll", "Raymond J.", ""]]}, {"id": "1009.5758", "submitter": "Chunhua Shen", "authors": "Sakrapee Paisitkriangkrai, Chunhua Shen, Jian Zhang", "title": "Face Detection with Effective Feature Extraction", "comments": "7 pages. Conference version published in Asian Conf. Comp. Vision\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an abundant literature on face detection due to its important role\nin many vision applications. Since Viola and Jones proposed the first real-time\nAdaBoost based face detector, Haar-like features have been adopted as the\nmethod of choice for frontal face detection. In this work, we show that simple\nfeatures other than Haar-like features can also be applied for training an\neffective face detector. Since, single feature is not discriminative enough to\nseparate faces from difficult non-faces, we further improve the generalization\nperformance of our simple features by introducing feature co-occurrences. We\ndemonstrate that our proposed features yield a performance improvement compared\nto Haar-like features. In addition, our findings indicate that features play a\ncrucial role in the ability of the system to generalize.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 03:13:09 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Paisitkriangkrai", "Sakrapee", ""], ["Shen", "Chunhua", ""], ["Zhang", "Jian", ""]]}, {"id": "1009.6215", "submitter": "Bjoern Andres", "authors": "Bjoern Andres, Ullrich Koethe, Thorben Kroeger, Fred A. Hamprecht", "title": "How to Extract the Geometry and Topology from Very Large 3D\n  Segmentations", "comments": "C++ source code, free command line tools and MATLAB mex files are\n  avilable from http://hci.iwr.uni-heidelberg.de/software.php", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation is often an essential intermediate step in image analysis. A\nvolume segmentation characterizes the underlying volume image in terms of\ngeometric information--segments, faces between segments, curves in which\nseveral faces meet--as well as a topology on these objects. Existing algorithms\nencode this information in designated data structures, but require that these\ndata structures fit entirely in Random Access Memory (RAM). Today, 3D images\nwith several billion voxels are acquired, e.g. in structural neurobiology.\nSince these large volumes can no longer be processed with existing methods, we\npresent a new algorithm which performs geometry and topology extraction with a\nruntime linear in the number of voxels and log-linear in the number of faces\nand curves. The parallelizable algorithm proceeds in a block-wise fashion and\nconstructs a consistent representation of the entire volume image on the hard\ndrive, making the structure of very large volume segmentations accessible to\nimage analysis. The parallelized C++ source code, free command line tools and\nMATLAB mex files are avilable from\nhttp://hci.iwr.uni-heidelberg.de/software.php\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 18:24:09 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Andres", "Bjoern", ""], ["Koethe", "Ullrich", ""], ["Kroeger", "Thorben", ""], ["Hamprecht", "Fred A.", ""]]}]