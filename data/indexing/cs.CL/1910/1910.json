[{"id": "1910.00051", "submitter": "Federico Fancellu Dr.", "authors": "Federico Fancellu, Sorcha Gilroy, Adam Lopez, Mirella Lapata", "title": "Semantic Graph Parsing with Recurrent Neural Network DAG Grammars", "comments": "9 pages, to appear in EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parses are directed acyclic graphs (DAGs), so semantic parsing\nshould be modeled as graph prediction. But predicting graphs presents difficult\ntechnical challenges, so it is simpler and more common to predict the\nlinearized graphs found in semantic parsing datasets using well-understood\nsequence models. The cost of this simplicity is that the predicted strings may\nnot be well-formed graphs. We present recurrent neural network DAG grammars, a\ngraph-aware sequence model that ensures only well-formed graphs while\nsidestepping many difficulties in graph prediction. We test our model on the\nParallel Meaning Bank---a multilingual semantic graphbank. Our approach yields\ncompetitive results in English and establishes the first results for German,\nItalian and Dutch.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:39:08 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 14:20:59 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Fancellu", "Federico", ""], ["Gilroy", "Sorcha", ""], ["Lopez", "Adam", ""], ["Lapata", "Mirella", ""]]}, {"id": "1910.00054", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Daniel Hsu, Luis Gravano", "title": "Weakly Supervised Attention Networks for Fine-Grained Opinion Mining and\n  Public Health", "comments": "Accepted for the 5th Workshop on Noisy User-generated Text (W-NUT\n  2019), held in conjunction with EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many review classification applications, a fine-grained analysis of the\nreviews is desirable, because different segments (e.g., sentences) of a review\nmay focus on different aspects of the entity in question. However, training\nsupervised models for segment-level classification requires segment labels,\nwhich may be more difficult or expensive to obtain than review labels. In this\npaper, we employ Multiple Instance Learning (MIL) and use only weak supervision\nin the form of a single label per review. First, we show that when\ninappropriate MIL aggregation functions are used, then MIL-based networks are\noutperformed by simpler baselines. Second, we propose a new aggregation\nfunction based on the sigmoid attention mechanism and show that our proposed\nmodel outperforms the state-of-the-art models for segment-level sentiment\nclassification (by up to 9.8% in F1). Finally, we highlight the importance of\nfine-grained predictions in an important public-health application: finding\nactionable reports of foodborne illness. We show that our model achieves 48.6%\nhigher recall compared to previous models, thus increasing the chance of\nidentifying previously unknown foodborne outbreaks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:40:59 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Hsu", "Daniel", ""], ["Gravano", "Luis", ""]]}, {"id": "1910.00058", "submitter": "Po-Yao Huang", "authors": "Po-Yao Huang, Xiaojun Chang, Alexander Hauptmann", "title": "Multi-Head Attention with Diversity for Learning Grounded Multilingual\n  Multimodal Representations", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of promoting and understanding the multilingual version of image\nsearch, we leverage visual object detection and propose a model with diverse\nmulti-head attention to learn grounded multilingual multimodal representations.\nSpecifically, our model attends to different types of textual semantics in two\nlanguages and visual objects for fine-grained alignments between sentences and\nimages. We introduce a new objective function which explicitly encourages\nattention diversity to learn an improved visual-semantic embedding space. We\nevaluate our model in the German-Image and English-Image matching tasks on the\nMulti30K dataset, and in the Semantic Textual Similarity task with the English\ndescriptions of visual content. Results show that our model yields a\nsignificant performance gain over other methods in all of the three tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 18:58:03 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Huang", "Po-Yao", ""], ["Chang", "Xiaojun", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1910.00065", "submitter": "Jekaterina Novikova Dr.", "authors": "Jekaterina Novikova, Aparna Balagopalan, Ksenia Shkaruta, Frank\n  Rudzicz", "title": "Lexical Features Are More Vulnerable, Syntactic Features Have More\n  Predictive Power", "comments": "EMNLP Workshop on Noisy User-generated Text (W-NUT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the vulnerability of linguistic features extracted from noisy\ntext is important for both developing better health text classification models\nand for interpreting vulnerabilities of natural language models. In this paper,\nwe investigate how generic language characteristics, such as syntax or the\nlexicon, are impacted by artificial text alterations. The vulnerability of\nfeatures is analysed from two perspectives: (1) the level of feature value\nchange, and (2) the level of change of feature predictive power as a result of\ntext modifications. We show that lexical features are more sensitive to text\nmodifications than syntactic ones. However, we also demonstrate that these\nsmaller changes of syntactic features have a stronger influence on\nclassification performance downstream, compared to the impact of changes to\nlexical features. Results are validated across three datasets representing\ndifferent text-classification tasks, with different levels of lexical and\nsyntactic complexity of both conversational and written language.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:34:45 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Novikova", "Jekaterina", ""], ["Balagopalan", "Aparna", ""], ["Shkaruta", "Ksenia", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1910.00084", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, Ni Lao", "title": "Contextual Graph Attention for Answering Logical Queries over Incomplete\n  Knowledge Graphs", "comments": "8 pages, 3 figures, camera ready version of article accepted to K-CAP\n  2019, Marina del Rey, California, United States", "journal-ref": "K-CAP 2019, Nov. 19 - 21, 2019, Marina del Rey, CA, USA", "doi": "10.1145/3360901.3364432", "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies have explored methods for using KG embedding to\nanswer logical queries. These approaches either treat embedding learning and\nquery answering as two separated learning tasks, or fail to deal with the\nvariability of contributions from different query paths. We proposed to\nleverage a graph attention mechanism to handle the unequal contribution of\ndifferent query paths. However, commonly used graph attention assumes that the\ncenter node embedding is provided, which is unavailable in this task since the\ncenter node is to be predicted. To solve this problem we propose a multi-head\nattention-based end-to-end logical query answering model, called Contextual\nGraph Attention model(CGA), which uses an initial neighborhood aggregation\nlayer to generate the center embedding, and the whole model is trained jointly\non the original KG structure as well as the sampled query-answer pairs. We also\nintroduce two new datasets, DB18 and WikiGeo19, which are rather large in size\ncompared to the existing datasets and contain many more relation types, and use\nthem to evaluate the performance of the proposed model. Our result shows that\nthe proposed CGA with fewer learnable parameters consistently outperforms the\nbaseline models on both datasets as well as Bio dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 20:20:48 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Yan", "Bo", ""], ["Zhu", "Rui", ""], ["Cai", "Ling", ""], ["Lao", "Ni", ""]]}, {"id": "1910.00139", "submitter": "Pooya Moradi", "authors": "Pooya Moradi, Nishant Kambhatla, and Anoop Sarkar", "title": "Interrogating the Explanatory Power of Attention in Neural Machine\n  Translation", "comments": "Accepted at the 3rd Workshop on Neural Generation and Translation\n  (WNGT 2019) held at EMNLP-IJCNLP 2019 (Camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention models have become a crucial component in neural machine\ntranslation (NMT). They are often implicitly or explicitly used to justify the\nmodel's decision in generating a specific token but it has not yet been\nrigorously established to what extent attention is a reliable source of\ninformation in NMT. To evaluate the explanatory power of attention for NMT, we\nexamine the possibility of yielding the same prediction but with counterfactual\nattention models that modify crucial aspects of the trained attention model.\nUsing these counterfactual attention mechanisms we assess the extent to which\nthey still preserve the generation of function and content words in the\ntranslation process. Compared to a state of the art attention model, our\ncounterfactual attention models produce 68% of function words and 21% of\ncontent words in our German-English dataset. Our experiments demonstrate that\nattention models by themselves cannot reliably explain the decisions made by a\nNMT model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 22:30:56 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Moradi", "Pooya", ""], ["Kambhatla", "Nishant", ""], ["Sarkar", "Anoop", ""]]}, {"id": "1910.00163", "submitter": "Xiang Lisa Li", "authors": "Xiang Lisa Li and Jason Eisner", "title": "Specializing Word Embeddings (for Parsing) by Information Bottleneck", "comments": "Accepted for publication at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word embeddings like ELMo and BERT contain rich syntactic and\nsemantic information, resulting in state-of-the-art performance on various\ntasks. We propose a very fast variational information bottleneck (VIB) method\nto nonlinearly compress these embeddings, keeping only the information that\nhelps a discriminative parser. We compress each word embedding to either a\ndiscrete tag or a continuous vector. In the discrete version, our automatically\ncompressed tags form an alternative tag set: we show experimentally that our\ntags capture most of the information in traditional POS tag annotations, but\nour tag sequences can be parsed more accurately at the same level of tag\ngranularity. In the continuous version, we show experimentally that moderately\ncompressing the word embeddings by our method yields a more accurate parser in\n8 of 9 languages, unlike simple dimensionality reduction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 00:47:31 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Xiang Lisa", ""], ["Eisner", "Jason", ""]]}, {"id": "1910.00192", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis and Eric Fosler-Lussier", "title": "Writing habits and telltale neighbors: analyzing clinical concept usage\n  patterns with sublanguage embeddings", "comments": "LOUHI 2019 (co-located with EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing techniques are being applied to increasingly\ndiverse types of electronic health records, and can benefit from in-depth\nunderstanding of the distinguishing characteristics of medical document types.\nWe present a method for characterizing the usage patterns of clinical concepts\namong different document types, in order to capture semantic differences beyond\nthe lexical level. By training concept embeddings on clinical documents of\ndifferent types and measuring the differences in their nearest neighborhood\nstructures, we are able to measure divergences in concept usage while\ncorrecting for noise in embedding learning. Experiments on the MIMIC-III corpus\ndemonstrate that our approach captures clinically-relevant differences in\nconcept usage and provides an intuitive way to explore semantic characteristics\nof clinical document collections.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:07:15 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1910.00194", "submitter": "Christian Hadiwinoto", "authors": "Christian Hadiwinoto, Hwee Tou Ng, and Wee Chung Gan", "title": "Improved Word Sense Disambiguation Using Pre-Trained Contextualized Word\n  Representations", "comments": "10 pages, 2 figures, EMNLP 2019, added URL to the source code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized word representations are able to give different\nrepresentations for the same word in different contexts, and they have been\nshown to be effective in downstream natural language processing tasks, such as\nquestion answering, named entity recognition, and sentiment analysis. However,\nevaluation on word sense disambiguation (WSD) in prior work shows that using\ncontextualized word representations does not outperform the state-of-the-art\napproach that makes use of non-contextualized word embeddings. In this paper,\nwe explore different strategies of integrating pre-trained contextualized word\nrepresentations and our best strategy achieves accuracies exceeding the best\nprior published accuracies by significant margins on multiple benchmark WSD\ndatasets. We make the source code available at\nhttps://github.com/nusnlp/contextemb-wsd.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 04:11:33 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 15:00:39 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hadiwinoto", "Christian", ""], ["Ng", "Hwee Tou", ""], ["Gan", "Wee Chung", ""]]}, {"id": "1910.00203", "submitter": "Logan Lebanoff", "authors": "Logan Lebanoff, John Muchovej, Franck Dernoncourt, Doo Soon Kim,\n  Seokhwan Kim, Walter Chang and Fei Liu", "title": "Analyzing Sentence Fusion in Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent work in abstractive summarization has resulted in higher scores\nin automatic metrics, there is little understanding on how these systems\ncombine information taken from multiple document sentences. In this paper, we\nanalyze the outputs of five state-of-the-art abstractive summarizers, focusing\non summary sentences that are formed by sentence fusion. We ask assessors to\njudge the grammaticality, faithfulness, and method of fusion for summary\nsentences. Our analysis reveals that system sentences are mostly grammatical,\nbut often fail to remain faithful to the original article.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 05:22:19 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Lebanoff", "Logan", ""], ["Muchovej", "John", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Kim", "Seokhwan", ""], ["Chang", "Walter", ""], ["Liu", "Fei", ""]]}, {"id": "1910.00254", "submitter": "Hirofumi Inaguma", "authors": "Hirofumi Inaguma, Kevin Duh, Tatsuya Kawahara, Shinji Watanabe", "title": "Multilingual End-to-End Speech Translation", "comments": "Accepted to ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple yet effective framework for multilingual\nend-to-end speech translation (ST), in which speech utterances in source\nlanguages are directly translated to the desired target languages with a\nuniversal sequence-to-sequence architecture. While multilingual models have\nshown to be useful for automatic speech recognition (ASR) and machine\ntranslation (MT), this is the first time they are applied to the end-to-end ST\nproblem. We show the effectiveness of multilingual end-to-end ST in two\nscenarios: one-to-many and many-to-many translations with publicly available\ndata. We experimentally confirm that multilingual end-to-end ST models\nsignificantly outperform bilingual ones in both scenarios. The generalization\nof multilingual training is also evaluated in a transfer learning scenario to a\nvery low-resource language pair. All of our codes and the database are publicly\navailable to encourage further research in this emergent multilingual ST topic.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 08:38:26 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 14:56:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Inaguma", "Hirofumi", ""], ["Duh", "Kevin", ""], ["Kawahara", "Tatsuya", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1910.00275", "submitter": "Jeroen Van Hautte", "authors": "Jeroen Van Hautte, Guy Emerson, Marek Rei", "title": "Bad Form: Comparing Context-Based and Form-Based Few-Shot Learning in\n  Distributional Semantic Models", "comments": "Accepted to the Proceedings of the Second Workshop on Deep Learning\n  for Low-Resource NLP (DeepLo 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are an essential component in a wide range of natural\nlanguage processing applications. However, distributional semantic models are\nknown to struggle when only a small number of context sentences are available.\nSeveral methods have been proposed to obtain higher-quality vectors for these\nwords, leveraging both this context information and sometimes the word forms\nthemselves through a hybrid approach. We show that the current tasks do not\nsuffice to evaluate models that use word-form information, as such models can\neasily leverage word forms in the training data that are related to word forms\nin the test data. We introduce 3 new tasks, allowing for a more balanced\ncomparison between models. Furthermore, we show that hyperparameters that have\nlargely been ignored in previous work can consistently improve the performance\nof both baseline and advanced models, achieving a new state of the art on 4 out\nof 6 tasks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 09:39:07 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Van Hautte", "Jeroen", ""], ["Emerson", "Guy", ""], ["Rei", "Marek", ""]]}, {"id": "1910.00290", "submitter": "Marco Valentino", "authors": "Mokanarangan Thayaparan, Marco Valentino, Viktor Schlegel, Andre\n  Freitas", "title": "Identifying Supporting Facts for Multi-hop Question Answering with\n  Document Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reading comprehension have resulted in models that surpass\nhuman performance when the answer is contained in a single, continuous passage\nof text. However, complex Question Answering (QA) typically requires multi-hop\nreasoning - i.e. the integration of supporting facts from different sources, to\ninfer the correct answer. This paper proposes Document Graph Network (DGN), a\nmessage passing architecture for the identification of supporting facts over a\ngraph-structured representation of text. The evaluation on HotpotQA shows that\nDGN obtains competitive results when compared to a reading comprehension\nbaseline operating on raw text, confirming the relevance of structured\nrepresentations for supporting multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:26:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Schlegel", "Viktor", ""], ["Freitas", "Andre", ""]]}, {"id": "1910.00292", "submitter": "Florian Schmidt", "authors": "Florian Schmidt", "title": "Generalization in Generation: A closer look at Exposure Bias", "comments": "wngt2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exposure bias refers to the train-test discrepancy that seemingly arises when\nan autoregressive generative model uses only ground-truth contexts at training\ntime but generated ones at test time. We separate the contributions of the\nmodel and the learning framework to clarify the debate on consequences and\nreview proposed counter-measures. In this light, we argue that generalization\nis the underlying property to address and propose unconditional generation as\nits fundamental benchmark. Finally, we combine latent variable modeling with a\nrecent formulation of exploration in reinforcement learning to obtain a\nrigorous handling of true and generated contexts. Results on language modeling\nand variational sentence auto-encoding confirm the model's generalization\ncapability.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:28:32 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 06:55:36 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Schmidt", "Florian", ""]]}, {"id": "1910.00294", "submitter": "Yunsu Kim", "authors": "Yunsu Kim, Duc Thanh Tran, Hermann Ney", "title": "When and Why is Document-level Context Useful in Neural Machine\n  Translation?", "comments": "DiscoMT 2019 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level context has received lots of attention for compensating neural\nmachine translation (NMT) of isolated sentences. However, recent advances in\ndocument-level NMT focus on sophisticated integration of the context,\nexplaining its improvement with only a few selected examples or targeted test\nsets. We extensively quantify the causes of improvements by a document-level\nmodel in general test sets, clarifying the limit of the usefulness of\ndocument-level context in NMT. We show that most of the improvements are not\ninterpretable as utilizing the context. We also show that a minimal encoding is\nsufficient for the context modeling and very long context is not helpful for\nNMT.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 10:40:26 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kim", "Yunsu", ""], ["Tran", "Duc Thanh", ""], ["Ney", "Hermann", ""]]}, {"id": "1910.00314", "submitter": "Yatin Chaudhary", "authors": "Yatin Chaudhary, Pankaj Gupta, Hinrich Sch\\\"utze", "title": "BioNLP-OST 2019 RDoC Tasks: Multi-grain Neural Relevance Ranking Using\n  Topics and Attention Based Query-Document-Sentence Interactions", "comments": "EMNLP2019, 10 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our system details and results of participation in the\nRDoC Tasks of BioNLP-OST 2019. Research Domain Criteria (RDoC) construct is a\nmulti-dimensional and broad framework to describe mental health disorders by\ncombining knowledge from genomics to behaviour. Non-availability of RDoC\nlabelled dataset and tedious labelling process hinders the use of RDoC\nframework to reach its full potential in Biomedical research community and\nHealthcare industry. Therefore, Task-1 aims at retrieval and ranking of PubMed\nabstracts relevant to a given RDoC construct and Task-2 aims at extraction of\nthe most relevant sentence from a given PubMed abstract. We investigate (1)\nattention based supervised neural topic model and SVM for retrieval and ranking\nof PubMed abstracts and, further utilize BM25 and other relevance measures for\nre-ranking, (2) supervised and unsupervised sentence ranking models utilizing\nmulti-view representations comprising of query-aware attention-based sentence\nrepresentation (QAR), bag-of-words (BoW) and TF-IDF. Our best systems achieved\n1st rank and scored 0.86 mean average precision (mAP) and 0.58 macro average\naccuracy (MAA) in Task-1 and Task-2 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 11:47:36 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 08:06:02 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Chaudhary", "Yatin", ""], ["Gupta", "Pankaj", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1910.00330", "submitter": "Sayed Soroush Haj Zargarbashi", "authors": "S. Soroush Haj Zargarbashi, Bagher Babaali", "title": "A Multi-Modal Feature Embedding Approach to Diagnose Alzheimer Disease\n  from Spoken Language", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction: Alzheimer's disease is a type of dementia in which early\ndiagnosis plays a major rule in the quality of treatment. Among new works in\nthe diagnosis of Alzheimer's disease, there are many of them analyzing the\nvoice stream acoustically, syntactically or both. The mostly used tools to\nperform these analysis usually include machine learning techniques. Objective:\nDesigning an automatic machine learning based diagnosis system will help in the\nprocedure of early detection. Also, systems, using noninvasive data are\npreferable. Methods: We used are classification system based on spoken\nlanguage. We use three (statistical and neural) approaches to classify audio\nsignals from spoken language into two classes of dementia and control. Result:\nThis work designs a multi-modal feature embedding on the spoken language audio\nsignal using three approaches; N-gram, i-vector, and x-vector. The evaluation\nof the system is done on the cookie picture description task from Pitt Corpus\ndementia bank with the accuracy of 83:6\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:03:24 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zargarbashi", "S. Soroush Haj", ""], ["Babaali", "Bagher", ""]]}, {"id": "1910.00334", "submitter": "Ana Roxin", "authors": "Nicolas Bus (CSTB), Ana Roxin (Le2i), Guillaume Picinbono (CSTB),\n  Muhammad Fahad (CSTB)", "title": "Towards French Smart Building Code: Compliance Checking Based on\n  Semantic Rules", "comments": null, "journal-ref": "Linked Data for Architecture and Construction (LDAC'2018), Jun\n  2018, Londres, United Kingdom", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually checking models for compliance against building regulation is a\ntime-consuming task for architects and construction engineers. There is thus a\nneed for algorithms that process information from construction projects and\nreport non-compliant elements. Still automated code-compliance checking raises\nseveral obstacles. Building regulations are usually published as human readable\ntexts and their content is often ambiguous or incomplete. Also, the vocabulary\nused for expressing such regulations is very different from the vocabularies\nused to express Building Information Models (BIM). Furthermore, the high level\nof details associated to BIM-contained geometries induces complex calculations.\nFinally, the level of complexity of the IFC standard also hinders the\nautomation of IFC processing tasks. Model chart, formal rules and\npre-processors approach allows translating construction regulations into\nsemantic queries. We further demonstrate the usefulness of this approach\nthrough several use cases. We argue our approach is a step forward in bridging\nthe gap between regulation texts and automated checking algorithms. Finally\nwith the recent building ontology BOT recommended by the W3C Linked Building\nData Community Group, we identify perspectives for standardizing and extending\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:18:42 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Bus", "Nicolas", "", "CSTB"], ["Roxin", "Ana", "", "Le2i"], ["Picinbono", "Guillaume", "", "CSTB"], ["Fahad", "Muhammad", "", "CSTB"]]}, {"id": "1910.00337", "submitter": "Piotr Niewinski", "authors": "Piotr Niewinski, Maria Pszona, Maria Janicka", "title": "TMLab: Generative Enhanced Model (GEM) for adversarial attacks", "comments": "7 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our Generative Enhanced Model (GEM) that we used to create samples\nawarded the first prize on the FEVER 2.0 Breakers Task. GEM is the extended\nlanguage model developed upon GPT-2 architecture. The addition of novel target\nvocabulary input to the already existing context input enabled controlled text\ngeneration. The training procedure resulted in creating a model that inherited\nthe knowledge of pretrained GPT-2, and therefore was ready to generate\nnatural-like English sentences in the task domain with some additional control.\nAs a result, GEM generated malicious claims that mixed facts from various\narticles, so it became difficult to classify their truthfulness.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:25:44 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Niewinski", "Piotr", ""], ["Pszona", "Maria", ""], ["Janicka", "Maria", ""]]}, {"id": "1910.00340", "submitter": "Bernd Kiefer", "authors": "Bernd Kiefer and Anna Welker and Christophe Biwer", "title": "VOnDA: A Framework for Ontology-Based Dialogue Management", "comments": "Presented at the Tenth International Workshop on Spoken Dialogue\n  Systems Technology (IWSDS), April 24-26, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VOnDA, a framework to implement the dialogue management\nfunctionality in dialogue systems. Although domain-independent, VOnDA is\ntailored towards dialogue systems with a focus on social communication, which\nimplies the need of long-term memory and high user adaptivity. For these\nsystems, which are used in health environments or elderly care, margin of error\nis very low and control over the dialogue process is of topmost importance. The\nsame holds for commercial applications, where customer trust is at risk.\nVOnDA's specification and memory layer relies upon (extended) RDF/OWL, which\nprovides a universal and uniform representation, and facilitates\ninteroperability with external data sources, e.g., from physical sensors.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:33:16 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kiefer", "Bernd", ""], ["Welker", "Anna", ""], ["Biwer", "Christophe", ""]]}, {"id": "1910.00353", "submitter": "Milan Straka", "authors": "Jakub N\\'aplava, Milan Straka", "title": "Grammatical Error Correction in Low-Resource Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error correction in English is a long studied problem with many\nexisting systems and datasets. However, there has been only a limited research\non error correction of other languages. In this paper, we present a new dataset\nAKCES-GEC on grammatical error correction for Czech. We then make experiments\non Czech, German and Russian and show that when utilizing synthetic parallel\ncorpus, Transformer neural machine translation model can reach new\nstate-of-the-art results on these datasets. AKCES-GEC is published under CC\nBY-NC-SA 4.0 license at https://hdl.handle.net/11234/1-3057 and the source code\nof the GEC model is available at\nhttps://github.com/ufal/low-resource-gec-wnut2019.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 12:58:44 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 08:08:57 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 12:03:49 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["N\u00e1plava", "Jakub", ""], ["Straka", "Milan", ""]]}, {"id": "1910.00368", "submitter": "Albina Khusainova", "authors": "Aidar Valeev, Ilshat Gibadullin, Albina Khusainova and Adil Khan", "title": "Application of Low-resource Machine Translation Techniques to\n  Russian-Tatar Language Pair", "comments": "Presented on ICATHS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation is the current state-of-the-art in machine\ntranslation. Although it is successful in a resource-rich setting, its\napplicability for low-resource language pairs is still debatable. In this\npaper, we explore the effect of different techniques to improve machine\ntranslation quality when a parallel corpus is as small as 324 000 sentences,\ntaking as an example previously unexplored Russian-Tatar language pair. We\napply such techniques as transfer learning and semi-supervised learning to the\nbase Transformer model, and empirically show that the resulting models improve\nRussian to Tatar and Tatar to Russian translation quality by +2.57 and +3.66\nBLEU, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:24:56 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Valeev", "Aidar", ""], ["Gibadullin", "Ilshat", ""], ["Khusainova", "Albina", ""], ["Khan", "Adil", ""]]}, {"id": "1910.00373", "submitter": "Albina Khusainova", "authors": "Ilshat Gibadullin, Aidar Valeev, Albina Khusainova and Adil Khan", "title": "A Survey of Methods to Leverage Monolingual Data in Low-resource Neural\n  Machine Translation", "comments": "Presented in ICATHS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation has become the state-of-the-art for language pairs\nwith large parallel corpora. However, the quality of machine translation for\nlow-resource languages leaves much to be desired. There are several approaches\nto mitigate this problem, such as transfer learning, semi-supervised and\nunsupervised learning techniques. In this paper, we review the existing\nmethods, where the main idea is to exploit the power of monolingual data,\nwhich, compared to parallel, is usually easier to obtain and significantly\ngreater in amount.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:29:53 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Gibadullin", "Ilshat", ""], ["Valeev", "Aidar", ""], ["Khusainova", "Albina", ""], ["Khan", "Adil", ""]]}, {"id": "1910.00382", "submitter": "Xiaoan Ding", "authors": "Xiaoan Ding, Kevin Gimpel", "title": "Latent-Variable Generative Models for Data-Efficient Text Classification", "comments": "11 pages, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative classifiers offer potential advantages over their discriminative\ncounterparts, namely in the areas of data efficiency, robustness to data shift\nand adversarial examples, and zero-shot learning (Ng and Jordan,2002; Yogatama\net al., 2017; Lewis and Fan,2019). In this paper, we improve generative text\nclassifiers by introducing discrete latent variables into the generative story,\nand explore several graphical model configurations. We parameterize the\ndistributions using standard neural architectures used in conditional language\nmodeling and perform learning by directly maximizing the log marginal\nlikelihood via gradient-based optimization, which avoids the need to do\nexpectation-maximization. We empirically characterize the performance of our\nmodels on six text classification datasets. The choice of where to include the\nlatent variable has a significant impact on performance, with the strongest\nresults obtained when using the latent variable as an auxiliary conditioning\nvariable in the generation of the textual input. This model consistently\noutperforms both the generative and discriminative classifiers in small-data\nsettings. We analyze our model by using it for controlled generation, finding\nthat the latent variable captures interpretable properties of the data, even\nwith very small training sets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:45:56 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ding", "Xiaoan", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1910.00421", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen and Hal Daum\\'e III", "title": "Global Voices: Crossing Borders in Automatic News Summarization", "comments": "NewSum workshop at EMNLP 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct Global Voices, a multilingual dataset for evaluating\ncross-lingual summarization methods. We extract social-network descriptions of\nGlobal Voices news articles to cheaply collect evaluation data for into-English\nand from-English summarization in 15 languages. Especially, for the\ninto-English summarization task, we crowd-source a high-quality evaluation\ndataset based on guidelines that emphasize accuracy, coverage, and\nunderstandability. To ensure the quality of this dataset, we collect human\nratings to filter out bad summaries, and conduct a survey on humans, which\nshows that the remaining summaries are preferred over the social-network\nsummaries. We study the effect of translation quality in cross-lingual\nsummarization, comparing a translate-then-summarize approach with several\nbaselines. Our results highlight the limitations of the ROUGE metric that are\noverlooked in monolingual summarization. Our dataset is available for download\nat https://forms.gle/gpkJDT6RJWHM1Ztz9 .\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:19:40 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 02:13:40 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 15:19:30 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 16:00:33 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Nguyen", "Khanh", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1910.00458", "submitter": "Di Jin", "authors": "Di Jin, Shuyang Gao, Jiun-Yu Kao, Tagyoung Chung, Dilek Hakkani-tur", "title": "MMM: Multi-stage Multi-task Learning for Multi-choice Reading\n  Comprehension", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) for question answering (QA), which aims\nto answer a question given the relevant context passages, is an important way\nto test the ability of intelligence systems to understand human language.\nMultiple-Choice QA (MCQA) is one of the most difficult tasks in MRC because it\noften requires more advanced reading comprehension skills such as logical\nreasoning, summarization, and arithmetic operations, compared to the extractive\ncounterpart where answers are usually spans of text within given passages.\nMoreover, most existing MCQA datasets are small in size, making the learning\ntask even harder. We introduce MMM, a Multi-stage Multi-task learning framework\nfor Multi-choice reading comprehension. Our method involves two sequential\nstages: coarse-tuning stage using out-of-domain datasets and multi-task\nlearning stage using a larger in-domain dataset to help model generalize better\nwith limited data. Furthermore, we propose a novel multi-step attention network\n(MAN) as the top-level classifier for this task. We demonstrate MMM\nsignificantly advances the state-of-the-art on four representative MCQA\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 14:43:37 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 01:01:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Jin", "Di", ""], ["Gao", "Shuyang", ""], ["Kao", "Jiun-Yu", ""], ["Chung", "Tagyoung", ""], ["Hakkani-tur", "Dilek", ""]]}, {"id": "1910.00478", "submitter": "Amirhossein Tebbifakhr", "authors": "Amirhossein Tebbifakhr, Luisa Bentivogli, Matteo Negri, Marco Turchi", "title": "Machine Translation for Machines: the Sentiment Classification Use Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural machine translation (NMT) approach that, instead of\npursuing adequacy and fluency (\"human-oriented\" quality criteria), aims to\ngenerate translations that are best suited as input to a natural language\nprocessing component designed for a specific downstream task (a\n\"machine-oriented\" criterion). Towards this objective, we present a\nreinforcement learning technique based on a new candidate sampling strategy,\nwhich exploits the results obtained on the downstream task as weak feedback.\nExperiments in sentiment classification of Twitter data in German and Italian\nshow that feeding an English classifier with machine-oriented translations\nsignificantly improves its performance. Classification results outperform those\nobtained with translations produced by general-purpose NMT models as well as by\nan approach based on reinforcement learning. Moreover, our results on both\nlanguages approximate the classification accuracy computed on gold standard\nEnglish tweets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:24:57 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Tebbifakhr", "Amirhossein", ""], ["Bentivogli", "Luisa", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1910.00486", "submitter": "Alan Nichol", "authors": "Vladimir Vlasov, Johannes E. M. Mosig, Alan Nichol", "title": "Dialogue Transformers", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dialogue policy based on a transformer architecture, where the\nself-attention mechanism operates over the sequence of dialogue turns. Recent\nwork has used hierarchical recurrent neural networks to encode multiple\nutterances in a dialogue context, but we argue that a pure self-attention\nmechanism is more suitable. By default, an RNN assumes that every item in a\nsequence is relevant for producing an encoding of the full sequence, but a\nsingle conversation can consist of multiple overlapping discourse segments as\nspeakers interleave multiple topics. A transformer picks which turns to include\nin its encoding of the current dialogue state, and is naturally suited to\nselectively ignoring or attending to dialogue history. We compare the\nperformance of the Transformer Embedding Dialogue (TED) policy to an LSTM and\nto the REDP, which was specifically designed to overcome this limitation of\nRNNs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 15:36:27 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 13:46:38 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 07:43:00 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Vlasov", "Vladimir", ""], ["Mosig", "Johannes E. M.", ""], ["Nichol", "Alan", ""]]}, {"id": "1910.00515", "submitter": "Bahman Mirheidari", "authors": "Bahman Mirheidari and Yilin Pan and Traci Walker and Markus Reuber and\n  Annalena Venneri and Daniel Blackburn and Heidi Christensen", "title": "Detecting Alzheimer's Disease by estimating attention and elicitation\n  path through the alignment of spoken picture descriptions with the picture\n  prompt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive decline is a sign of Alzheimer's disease (AD), and there is\nevidence that tracking a person's eye movement, using eye tracking devices, can\nbe used for the automatic identification of early signs of cognitive decline.\nHowever, such devices are expensive and may not be easy-to-use for people with\ncognitive problems. In this paper, we present a new way of capturing similar\nvisual features, by using the speech of people describing the Cookie Theft\npicture - a common cognitive testing task - to identify regions in the picture\nprompt that will have caught the speaker's attention and elicited their speech.\nAfter aligning the automatically recognised words with different regions of the\npicture prompt, we extract information inspired by eye tracking metrics such as\ncoordinates of the area of interests (AOI)s, time spent in AOI, time to reach\nthe AOI, and the number of AOI visits. Using the DementiaBank dataset we train\na binary classifier (AD vs. healthy control) using 10-fold cross-validation and\nachieve an 80% F1-score using the timing information from the forced alignments\nof the automatic speech recogniser (ASR); this achieved around 72% using the\ntiming information from the ASR outputs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:06:44 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mirheidari", "Bahman", ""], ["Pan", "Yilin", ""], ["Walker", "Traci", ""], ["Reuber", "Markus", ""], ["Venneri", "Annalena", ""], ["Blackburn", "Daniel", ""], ["Christensen", "Heidi", ""]]}, {"id": "1910.00523", "submitter": "Anastassia Kornilova", "authors": "Anastassia Kornilova and Vlad Eidelman", "title": "BillSum: A Corpus for Automatic Summarization of US Legislation", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-5406", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarization methods have been studied on a variety of domains,\nincluding news and scientific articles. Yet, legislation has not previously\nbeen considered for this task, despite US Congress and state governments\nreleasing tens of thousands of bills every year. In this paper, we introduce\nBillSum, the first dataset for summarization of US Congressional and California\nstate bills (https://github.com/FiscalNote/BillSum). We explain the properties\nof the dataset that make it more challenging to process than other domains.\nThen, we benchmark extractive methods that consider neural sentence\nrepresentations and traditional contextual features. Finally, we demonstrate\nthat models built on Congressional bills can be used to summarize California\nbills, thus, showing that methods developed on this dataset can transfer to\nstates without human-written summaries.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:25:12 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 02:50:00 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kornilova", "Anastassia", ""], ["Eidelman", "Vlad", ""]]}, {"id": "1910.00546", "submitter": "Heike Adel", "authors": "Heike Adel and Hinrich Sch\\\"utze", "title": "Type-aware Convolutional Neural Networks for Slot Filling", "comments": "Journal of Artificial Intelligence Research (JAIR), volume 66", "journal-ref": null, "doi": "10.1613/jair.1.11725", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The slot filling task aims at extracting answers for queries about entities\nfrom text, such as \"Who founded Apple\". In this paper, we focus on the relation\nclassification component of a slot filling system. We propose type-aware\nconvolutional neural networks to benefit from the mutual dependencies between\nentity and relation classification. In particular, we explore different ways of\nintegrating the named entity types of the relation arguments into a neural\nnetwork for relation classification, including a joint training and a\nstructured prediction approach. To the best of our knowledge, this is the first\nstudy on type-aware neural networks for slot filling. The type-aware models\nlead to the best results of our slot filling pipeline. Joint training performs\ncomparable to structured prediction. To understand the impact of the different\ncomponents of the slot filling pipeline, we perform a recall analysis, a manual\nerror analysis and several ablation studies. Such analyses are of particular\nimportance to other slot filling researchers since the official slot filling\nevaluations only assess pipeline outputs. The analyses show that especially\ncoreference resolution and our convolutional neural networks have a large\npositive impact on the final performance of the slot filling pipeline. The\npresented models, the source code of our system as well as our coreference\nresource is publicy available.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:09:29 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Adel", "Heike", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1910.00553", "submitter": "Lei Yu", "authors": "Lei Yu, Laurent Sartran, Wojciech Stokowiec, Wang Ling, Lingpeng Kong,\n  Phil Blunsom, Chris Dyer", "title": "Better Document-Level Machine Translation with Bayes' Rule", "comments": "Accepted by TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that Bayes' rule provides an effective mechanism for creating\ndocument translation models that can be learned from only parallel sentences\nand monolingual documents---a compelling benefit as parallel documents are not\nalways available. In our formulation, the posterior probability of a candidate\ntranslation is the product of the unconditional (prior) probability of the\ncandidate output document and the \"reverse translation probability\" of\ntranslating the candidate output back into the source language. Our proposed\nmodel uses a powerful autoregressive language model as the prior on target\nlanguage documents, but it assumes that each sentence is translated\nindependently from the target to the source language. Crucially, at test time,\nwhen a source document is observed, the document language model prior induces\ndependencies between the translations of the source sentences in the posterior.\nThe model's independence assumption not only enables efficient use of available\ndata, but it additionally admits a practical left-to-right beam-search\nalgorithm for carrying out inference. Experiments show that our model benefits\nfrom using cross-sentence context in the language model, and it outperforms\nexisting document translation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:30:56 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 10:47:17 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Yu", "Lei", ""], ["Sartran", "Laurent", ""], ["Stokowiec", "Wojciech", ""], ["Ling", "Wang", ""], ["Kong", "Lingpeng", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""]]}, {"id": "1910.00565", "submitter": "Shahram Ghorbani", "authors": "Shahram Ghorbani, Soheil Khorram, John H.L. Hansen", "title": "Domain Expansion in DNN-based Acoustic Models for Robust Speech\n  Recognition", "comments": "Accepted at ASRU, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training acoustic models with sequentially incoming data -- while both\nleveraging new data and avoiding the forgetting effect-- is an essential\nobstacle to achieving human intelligence level in speech recognition. An\nobvious approach to leverage data from a new domain (e.g., new accented speech)\nis to first generate a comprehensive dataset of all domains, by combining all\navailable data, and then use this dataset to retrain the acoustic models.\nHowever, as the amount of training data grows, storing and retraining on such a\nlarge-scale dataset becomes practically impossible. To deal with this problem,\nin this study, we study several domain expansion techniques which exploit only\nthe data of the new domain to build a stronger model for all domains. These\ntechniques are aimed at learning the new domain with a minimal forgetting\neffect (i.e., they maintain original model performance). These techniques\nmodify the adaptation procedure by imposing new constraints including (1)\nweight constraint adaptation (WCA): keeping the model parameters close to the\noriginal model parameters; (2) elastic weight consolidation (EWC): slowing down\ntraining for parameters that are important for previously established domains;\n(3) soft KL-divergence (SKLD): restricting the KL-divergence between the\noriginal and the adapted model output distributions; and (4) hybrid SKLD-EWC:\nincorporating both SKLD and EWC constraints. We evaluate these techniques in an\naccent adaptation task in which we adapt a deep neural network (DNN) acoustic\nmodel trained with native English to three different English accents:\nAustralian, Hispanic, and Indian. The experimental results show that SKLD\nsignificantly outperforms EWC, and EWC works better than WCA. The hybrid\nSKLD-EWC technique results in the best overall performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 17:40:49 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ghorbani", "Shahram", ""], ["Khorram", "Soheil", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1910.00610", "submitter": "Yi-Lin Tuan", "authors": "Yi-Lin Tuan, Yun-Nung Chen, Hung-yi Lee", "title": "DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic\n  Knowledge Graphs", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven, knowledge-grounded neural conversation models are capable of\ngenerating more informative responses. However, these models have not yet\ndemonstrated that they can zero-shot adapt to updated, unseen knowledge graphs.\nThis paper proposes a new task about how to apply dynamic knowledge graphs in\nneural conversation model and presents a novel TV series conversation corpus\n(DyKgChat) for the task. Our new task and corpus aids in understanding the\ninfluence of dynamic knowledge graphs on responses generation. Also, we propose\na preliminary model that selects an output from two networks at each time step:\na sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in\norder to support dynamic knowledge graphs. To benchmark this new task and\nevaluate the capability of adaptation, we introduce several evaluation metrics\nand the experiments show that our proposed approach outperforms previous\nknowledge-grounded conversation models. The proposed corpus and model can\nmotivate the future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 18:29:08 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Tuan", "Yi-Lin", ""], ["Chen", "Yun-Nung", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1910.00637", "submitter": "Danni Ma", "authors": "Danni Ma, Chen Chen, Behzad Golshan, Wang-Chiew Tan", "title": "Essentia: Mining Domain-Specific Paraphrases with Word-Alignment Graphs", "comments": "accepted at the 13th Workshop on Graph-Based Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrases are important linguistic resources for a wide variety of NLP\napplications. Many techniques for automatic paraphrase mining from general\ncorpora have been proposed. While these techniques are successful at\ndiscovering generic paraphrases, they often fail to identify domain-specific\nparaphrases (e.g., {staff, concierge} in the hospitality domain). This is\nbecause current techniques are often based on statistical methods, while\ndomain-specific corpora are too small to fit statistical methods. In this\npaper, we present an unsupervised graph-based technique to mine paraphrases\nfrom a small set of sentences that roughly share the same topic or intent. Our\nsystem, Essentia, relies on word-alignment techniques to create a\nword-alignment graph that merges and organizes tokens from input sentences. The\nresulting graph is then used to generate candidate paraphrases. We demonstrate\nthat our system obtains high-quality paraphrases, as evaluated by crowd\nworkers. We further show that the majority of the identified paraphrases are\ndomain-specific and thus complement existing paraphrase databases.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 19:51:57 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 19:04:53 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ma", "Danni", ""], ["Chen", "Chen", ""], ["Golshan", "Behzad", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "1910.00673", "submitter": "Li Yao", "authors": "Tobi Olatunji, Li Yao", "title": "Learning to estimate label uncertainty for automatic radiology report\n  parsing", "comments": "Med-NeurIPS-2019 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrapping labels from radiology reports has become the scalable\nalternative to provide inexpensive ground truth for medical imaging. Because of\nthe domain specific nature, state-of-the-art report labeling tools are\npredominantly rule-based. These tools, however, typically yield a binary 0 or 1\nprediction that indicates the presence or absence of abnormalities. These hard\ntargets are then used as ground truth to train image models in the downstream,\nforcing models to express high degree of certainty even on cases where\nspecificity is low. This could negatively impact the statistical efficiency of\nimage models. We address such an issue by training a Bidirectional Long-Short\nTerm Memory Network to augment heuristic-based discrete labels of X-ray reports\nfrom all body regions and achieve performance comparable or better than\ndomain-specific NLP, but with additional uncertainty estimates which enable\nfiner downstream image model training.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 21:20:33 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Olatunji", "Tobi", ""], ["Yao", "Li", ""]]}, {"id": "1910.00702", "submitter": "Ling Cai", "authors": "Ling Cai, Bo Yan, Gengchen Mai, Krzysztof Janowicz, Rui Zhu", "title": "TransGCN:Coupling Transformation Assumptions with Graph Convolutional\n  Networks for Link Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3360901.3364441", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is an important and frequently studied task that contributes\nto an understanding of the structure of knowledge graphs (KGs) in statistical\nrelational learning. Inspired by the success of graph convolutional networks\n(GCN) in modeling graph data, we propose a unified GCN framework, named\nTransGCN, to address this task, in which relation and entity embeddings are\nlearned simultaneously. To handle heterogeneous relations in KGs, we introduce\na novel way of representing heterogeneous neighborhood by introducing\ntransformation assumptions on the relationship between the subject, the\nrelation, and the object of a triple. Specifically, a relation is treated as a\ntransformation operator transforming a head entity to a tail entity. Both\ntranslation assumption in TransE and rotation assumption in RotatE are explored\nin our framework. Additionally, instead of only learning entity embeddings in\nthe convolution-based encoder while learning relation embeddings in the decoder\nas done by the state-of-art models, e.g., R-GCN, the TransGCN framework trains\nrelation embeddings and entity embeddings simultaneously during the graph\nconvolution operation, thus having fewer parameters compared with R-GCN.\nExperiments show that our models outperform the-state-of-arts methods on both\nFB15K-237 and WN18RR.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 22:34:40 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Cai", "Ling", ""], ["Yan", "Bo", ""], ["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Zhu", "Rui", ""]]}, {"id": "1910.00716", "submitter": "Kyu Han", "authors": "Kyu J. Han, Ramon Prieto, Kaixing Wu, Tao Ma", "title": "State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention\n  With Dilated 1D Convolutions", "comments": "Accepted to ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention has been a huge success for many downstream tasks in NLP,\nwhich led to exploration of applying self-attention to speech problems as well.\nThe efficacy of self-attention in speech applications, however, seems not fully\nblown yet since it is challenging to handle highly correlated speech frames in\nthe context of self-attention. In this paper we propose a new neural network\nmodel architecture, namely multi-stream self-attention, to address the issue\nthus make the self-attention mechanism more effective for speech recognition.\nThe proposed model architecture consists of parallel streams of self-attention\nencoders, and each stream has layers of 1D convolutions with dilated kernels\nwhose dilation rates are unique given stream, followed by a self-attention\nlayer. The self-attention mechanism in each stream pays attention to only one\nresolution of input speech frames and the attentive computation can be more\nefficient. In a later stage, outputs from all the streams are concatenated then\nlinearly projected to the final embedding. By stacking the proposed\nmulti-stream self-attention encoder blocks and rescoring the resultant lattices\nwith neural network language models, we achieve the word error rate of 2.2% on\nthe test-clean dataset of the LibriSpeech corpus, the best number reported thus\nfar on the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 23:41:28 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Han", "Kyu J.", ""], ["Prieto", "Ramon", ""], ["Wu", "Kaixing", ""], ["Ma", "Tao", ""]]}, {"id": "1910.00741", "submitter": "Shresth Verma", "authors": "Shresth Verma, Joydip Dhar", "title": "Emergence of Writing Systems Through Multi-Agent Cooperation", "comments": "Under Review as Student Abstract at AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to communicate is considered an essential task to develop a general\nAI. While recent literature in language evolution has studied emergent language\nthrough discrete or continuous message symbols, there has been little work in\nthe emergence of writing systems in artificial agents. In this paper, we\npresent a referential game setup with two agents, where the mode of\ncommunication is a written language system that emerges during the play. We\nshow that the agents can learn to coordinate successfully using this mode of\ncommunication. Further, we study how the game rules affect the writing system\ntaxonomy by proposing a consistency metric.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 01:35:14 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Verma", "Shresth", ""], ["Dhar", "Joydip", ""]]}, {"id": "1910.00748", "submitter": "Nikita Srivatsan", "authors": "Nikita Srivatsan, Jonathan T. Barron, Dan Klein, Taylor\n  Berg-Kirkpatrick", "title": "A Deep Factorization of Style and Structure in Fonts", "comments": "EMNLP 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep factorization model for typographic analysis that\ndisentangles content from style. Specifically, a variational inference\nprocedure factors each training glyph into the combination of a\ncharacter-specific content embedding and a latent font-specific style variable.\nThe underlying generative model combines these factors through an asymmetric\ntranspose convolutional process to generate the image of the glyph itself. When\ntrained on corpora of fonts, our model learns a manifold over font styles that\ncan be used to analyze or reconstruct new, unseen fonts. On the task of\nreconstructing missing glyphs from an unknown font given only a small number of\nobservations, our model outperforms both a strong nearest neighbors baseline\nand a state-of-the-art discriminative model from prior work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 02:24:12 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 01:43:18 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Srivatsan", "Nikita", ""], ["Barron", "Jonathan T.", ""], ["Klein", "Dan", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1910.00795", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Speech-to-speech Translation between Untranscribed Unknown Languages", "comments": "Accepted in IEEE ASRU 2019. Web-page for more samples & details:\n  https://sp2code-translation-v1.netlify.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore a method for training speech-to-speech translation\ntasks without any transcription or linguistic supervision. Our proposed method\nconsists of two steps: First, we train and generate discrete representation\nwith unsupervised term discovery with a discrete quantized autoencoder. Second,\nwe train a sequence-to-sequence model that directly maps the source language\nspeech to the target language's discrete representation. Our proposed method\ncan directly generate target speech without any auxiliary or pre-training steps\nwith a source or target transcription. To the best of our knowledge, this is\nthe first work that performed pure speech-to-speech translation between\nuntranscribed unknown languages.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 06:42:57 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 08:03:25 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1910.00825", "submitter": "Lin Yuan", "authors": "Lin Yuan, Zhou Yu", "title": "Abstractive Dialog Summarization with Semantic Scaffolds", "comments": "unpublished preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for abstractive dialog summary is growing in real-world\napplications. For example, customer service center or hospitals would like to\nsummarize customer service interaction and doctor-patient interaction. However,\nfew researchers explored abstractive summarization on dialogs due to the lack\nof suitable datasets. We propose an abstractive dialog summarization dataset\nbased on MultiWOZ. If we directly apply previous state-of-the-art document\nsummarization methods on dialogs, there are two significant drawbacks: the\ninformative entities such as restaurant names are difficult to preserve, and\nthe contents from different dialog domains are sometimes mismatched. To address\nthese two drawbacks, we propose Scaffold Pointer Network (SPNet)to utilize the\nexisting annotation on speaker role, semantic slot and dialog domain. SPNet\nincorporates these semantic scaffolds for dialog summarization. Since ROUGE\ncannot capture the two drawbacks mentioned, we also propose a new evaluation\nmetric that considers critical informative entities in the text. On MultiWOZ,\nour proposed SPNet outperforms state-of-the-art abstractive summarization\nmethods on all the automatic and human evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 08:22:03 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Yuan", "Lin", ""], ["Yu", "Zhou", ""]]}, {"id": "1910.00856", "submitter": "Stefanos Angelidis", "authors": "Stefanos Angelidis, Lea Frermann, Diego Marcheggiani, Roi Blanco,\n  Llu\\'is M\\`arquez", "title": "BookQA: Stories of Challenges and Opportunities", "comments": "Accepted at 2nd Workshop on Machine Reading for Question Answering\n  (MRQA), EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for answering questions based on the full text of books\n(BookQA), which first selects book passages given a question at hand, and then\nuses a memory network to reason and predict an answer. To improve\ngeneralization, we pretrain our memory network using artificial questions\ngenerated from book sentences. We experiment with the recently published\nNarrativeQA corpus, on the subset of Who questions, which expect book\ncharacters as answers. We experimentally show that BERT-based retrieval and\npretraining improve over baseline results significantly. At the same time, we\nconfirm that NarrativeQA is a highly challenging data set, and that there is\nneed for novel research in order to achieve high-precision BookQA results. We\nanalyze some of the bottlenecks of the current approach, and we argue that more\nresearch is needed on text representation, retrieval of relevant passages, and\nreasoning, including commonsense knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 10:05:44 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Angelidis", "Stefanos", ""], ["Frermann", "Lea", ""], ["Marcheggiani", "Diego", ""], ["Blanco", "Roi", ""], ["M\u00e0rquez", "Llu\u00eds", ""]]}, {"id": "1910.00861", "submitter": "Wangjin Lee", "authors": "Wangjin Lee, Hyeryun Park, Jooyoung Yoon, Kyeongmo Kim, and Jinwook\n  Choi", "title": "Clinical Text Generation through Leveraging Medical Concept and\n  Relations", "comments": "This is a revised version of one uploaded in openreview.net\n  (https://openreview.net/forum?id=Skg6L9ZTpV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a neural sequence generation model, this study aims to develop a method\nof writing the patient clinical texts given a brief medical history. As a\nproof-of-a-concept, we have demonstrated that it can be workable to use medical\nconcept embedding in clinical text generation. Our model was based on the\nSequence-to-Sequence architecture and trained with a large set of de-identified\nclinical text data. The quantitative result shows that our concept embedding\nmethod decreased the perplexity of the baseline architecture. Also, we discuss\nthe analyzed results from a human evaluation performed by medical doctors.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 10:17:28 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Lee", "Wangjin", ""], ["Park", "Hyeryun", ""], ["Yoon", "Jooyoung", ""], ["Kim", "Kyeongmo", ""], ["Choi", "Jinwook", ""]]}, {"id": "1910.00883", "submitter": "Xin Li", "authors": "Xin Li, Lidong Bing, Wenxuan Zhang, Wai Lam", "title": "Exploiting BERT for End-to-End Aspect-based Sentiment Analysis", "comments": "NUT workshop@EMNLP-IJCNLP-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the modeling power of contextualized embeddings\nfrom pre-trained language models, e.g. BERT, on the E2E-ABSA task.\nSpecifically, we build a series of simple yet insightful neural baselines to\ndeal with E2E-ABSA. The experimental results show that even with a simple\nlinear classification layer, our BERT-based architecture can outperform\nstate-of-the-art works. Besides, we also standardize the comparative study by\nconsistently utilizing a hold-out validation dataset for model selection, which\nis largely ignored by previous works. Therefore, our work can serve as a\nBERT-based benchmark for E2E-ABSA.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:34:58 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 04:05:46 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Li", "Xin", ""], ["Bing", "Lidong", ""], ["Zhang", "Wenxuan", ""], ["Lam", "Wai", ""]]}, {"id": "1910.00896", "submitter": "Suzan Verberne", "authors": "Benjamin van der Burgh and Suzan Verberne", "title": "The merits of Universal Language Model Fine-tuning for Small Datasets --\n  a case with Dutch book reviews", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluated the effectiveness of using language models, that were\npre-trained in one domain, as the basis for a classification model in another\ndomain: Dutch book reviews. Pre-trained language models have opened up new\npossibilities for classification tasks with limited labelled data, because\nrepresentation can be learned in an unsupervised fashion. In our experiments we\nhave studied the effects of training set size (100-1600 items) on the\nprediction accuracy of a ULMFiT classifier, based on a language models that we\npre-trained on the Dutch Wikipedia. We also compared ULMFiT to Support Vector\nMachines, which is traditionally considered suitable for small collections. We\nfound that ULMFiT outperforms SVM for all training set sizes and that\nsatisfactory results (~90%) can be achieved using training sets that can be\nmanually annotated within a few hours. We deliver both our new benchmark\ncollection of Dutch book reviews for sentiment classification as well as the\npre-trained Dutch language model to the community.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 12:02:46 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["van der Burgh", "Benjamin", ""], ["Verberne", "Suzan", ""]]}, {"id": "1910.00912", "submitter": "Andrea Vanzo", "authors": "Andrea Vanzo, Emanuele Bastianelli, Oliver Lemon", "title": "Hierarchical Multi-Task Natural Language Understanding for Cross-domain\n  Conversational AI: HERMIT NLU", "comments": "10 pages", "journal-ref": "SIGDial 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new neural architecture for wide-coverage Natural Language\nUnderstanding in Spoken Dialogue Systems. We develop a hierarchical multi-task\narchitecture, which delivers a multi-layer representation of sentence meaning\n(i.e., Dialogue Acts and Frame-like structures). The architecture is a\nhierarchy of self-attention mechanisms and BiLSTM encoders followed by CRF\ntagging layers. We describe a variety of experiments, showing that our approach\nobtains promising results on a dataset annotated with Dialogue Acts and Frame\nSemantics. Moreover, we demonstrate its applicability to a different, publicly\navailable NLU dataset annotated with domain-specific intents and corresponding\nsemantic roles, providing overall performance higher than state-of-the-art\ntools such as RASA, Dialogflow, LUIS, and Watson. For example, we show an\naverage 4.45% improvement in entity tagging F-score over Rasa, Dialogflow and\nLUIS.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 12:39:53 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Vanzo", "Andrea", ""], ["Bastianelli", "Emanuele", ""], ["Lemon", "Oliver", ""]]}, {"id": "1910.00930", "submitter": "Izumi Haruta", "authors": "Izumi Haruta, Koji Mineshima, Daisuke Bekki", "title": "A CCG-based Compositional Semantics and Inference System for\n  Comparatives", "comments": "10 pages, to appear in the Proceedings of PACLIC33", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparative constructions play an important role in natural language\ninference. However, attempts to study semantic representations and logical\ninferences for comparatives from the computational perspective are not well\ndeveloped, due to the complexity of their syntactic structures and inference\npatterns. In this study, using a framework based on Combinatory Categorial\nGrammar (CCG), we present a compositional semantics that maps various\ncomparative constructions in English to semantic representations and introduces\nan inference system that effectively handles logical inference with\ncomparatives, including those involving numeral adjectives, antonyms, and\nquantification. We evaluate the performance of our system on the FraCaS test\nsuite and show that the system can handle a variety of complex logical\ninferences with comparatives.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:05:48 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Haruta", "Izumi", ""], ["Mineshima", "Koji", ""], ["Bekki", "Daisuke", ""]]}, {"id": "1910.00998", "submitter": "Peter J Liu", "authors": "Peter J. Liu, Yu-An Chung, Jie Ren", "title": "SummAE: Zero-Shot Abstractive Text Summarization using Length-Agnostic\n  Auto-Encoders", "comments": "first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end neural model for zero-shot abstractive text\nsummarization of paragraphs, and introduce a benchmark task, ROCSumm, based on\nROCStories, a subset for which we collected human summaries. In this task,\nfive-sentence stories (paragraphs) are summarized with one sentence, using\nhuman summaries only for evaluation. We show results for extractive and human\nbaselines to demonstrate a large abstractive gap in performance. Our model,\nSummAE, consists of a denoising auto-encoder that embeds sentences and\nparagraphs in a common space, from which either can be decoded. Summaries for\nparagraphs are generated by decoding a sentence from the paragraph\nrepresentations. We find that traditional sequence-to-sequence auto-encoders\nfail to produce good summaries and describe how specific architectural choices\nand pre-training techniques can significantly improve performance,\noutperforming extractive baselines. The data, training, evaluation code, and\nbest model weights are open-sourced.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:57:55 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Liu", "Peter J.", ""], ["Chung", "Yu-An", ""], ["Ren", "Jie", ""]]}, {"id": "1910.01043", "submitter": "Sravan Babu Bodapati", "authors": "Sravan Babu Bodapati, Spandana Gella, Kasturi Bhattacharjee, Yaser\n  Al-Onaizan", "title": "Neural Word Decomposition Models for Abusive Language Detection", "comments": "Accepted at ALW Workshop at ACL2019, Florence; BERT has a WordPiece\n  model and it enhances performance of word based models in noisy settings", "journal-ref": "https://www.aclweb.org/anthology/events/acl-2019/", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User generated text on social media often suffers from a lot of undesired\ncharacteristics including hatespeech, abusive language, insults etc. that are\ntargeted to attack or abuse a specific group of people. Often such text is\nwritten differently compared to traditional text such as news involving either\nexplicit mention of abusive words, obfuscated words and typological errors or\nimplicit abuse i.e., indicating or targeting negative stereotypes. Thus,\nprocessing this text poses several robustness challenges when we apply natural\nlanguage processing techniques developed for traditional text. For example,\nusing word or token based models to process such text can treat two spelling\nvariants of a word as two different words. Following recent work, we analyze\nhow character, subword and byte pair encoding (BPE) models can be aid some of\nthe challenges posed by user generated text. In our work, we analyze the\neffectiveness of each of the above techniques, compare and contrast various\nword decomposition techniques when used in combination with others. We\nexperiment with finetuning large pretrained language models, and demonstrate\ntheir robustness to domain shift by studying Wikipedia attack, toxicity and\nTwitter hatespeech datasets\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:00:42 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Bodapati", "Sravan Babu", ""], ["Gella", "Spandana", ""], ["Bhattacharjee", "Kasturi", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1910.01108", "submitter": "Victor Sanh", "authors": "Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf", "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and\n  lighter", "comments": "February 2020 - Revision: fix bug in evaluation metrics, updated\n  metrics, argumentation unchanged. 5 pages, 1 figure, 4 tables. Accepted at\n  the 5th Workshop on Energy Efficient Machine Learning and Cognitive Computing\n  - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Transfer Learning from large-scale pre-trained models becomes more\nprevalent in Natural Language Processing (NLP), operating these large models in\non-the-edge and/or under constrained computational training or inference\nbudgets remains challenging. In this work, we propose a method to pre-train a\nsmaller general-purpose language representation model, called DistilBERT, which\ncan then be fine-tuned with good performances on a wide range of tasks like its\nlarger counterparts. While most prior work investigated the use of distillation\nfor building task-specific models, we leverage knowledge distillation during\nthe pre-training phase and show that it is possible to reduce the size of a\nBERT model by 40%, while retaining 97% of its language understanding\ncapabilities and being 60% faster. To leverage the inductive biases learned by\nlarger models during pre-training, we introduce a triple loss combining\nlanguage modeling, distillation and cosine-distance losses. Our smaller, faster\nand lighter model is cheaper to pre-train and we demonstrate its capabilities\nfor on-device computations in a proof-of-concept experiment and a comparative\non-device study.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 17:56:28 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 14:52:02 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 16:58:52 GMT"}, {"version": "v4", "created": "Sun, 1 Mar 2020 02:57:50 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sanh", "Victor", ""], ["Debut", "Lysandre", ""], ["Chaumond", "Julien", ""], ["Wolf", "Thomas", ""]]}, {"id": "1910.01157", "submitter": "Jeff Da", "authors": "Jeff Da and Jungo Kasai", "title": "Cracking the Contextual Commonsense Code: Understanding Commonsense\n  Reasoning Aptitude of Deep Contextual Representations", "comments": "Accepted to EMNLP Commonsense (COIN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained deep contextual representations have advanced the state-of-the-art\non various commonsense NLP tasks, but we lack a concrete understanding of the\ncapability of these models. Thus, we investigate and challenge several aspects\nof BERT's commonsense representation abilities. First, we probe BERT's ability\nto classify various object attributes, demonstrating that BERT shows a strong\nability in encoding various commonsense features in its embedding space, but is\nstill deficient in many areas. Next, we show that, by augmenting BERT's\npretraining data with additional data related to the deficient attributes, we\nare able to improve performance on a downstream commonsense reasoning task\nwhile using a minimal amount of data. Finally, we develop a method of\nfine-tuning knowledge graphs embeddings alongside BERT and show the continued\nimportance of explicit knowledge graphs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 18:35:40 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 02:47:07 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Da", "Jeff", ""], ["Kasai", "Jungo", ""]]}, {"id": "1910.01160", "submitter": "Pedram Hosseini", "authors": "Or Levi, Pedram Hosseini, Mona Diab, David A. Broniatowski", "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "comments": "Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-5004", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 18:47:17 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 20:45:25 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Levi", "Or", ""], ["Hosseini", "Pedram", ""], ["Diab", "Mona", ""], ["Broniatowski", "David A.", ""]]}, {"id": "1910.01244", "submitter": "Jon Gauthier", "authors": "Jon Gauthier and Roger Levy", "title": "Linking artificial and human neural representations of language", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What information from an act of sentence understanding is robustly\nrepresented in the human brain? We investigate this question by comparing\nsentence encoding models on a brain decoding task, where the sentence that an\nexperimental participant has seen must be predicted from the fMRI signal evoked\nby the sentence. We take a pre-trained BERT architecture as a baseline sentence\nencoding model and fine-tune it on a variety of natural language understanding\n(NLU) tasks, asking which lead to improvements in brain-decoding performance.\n  We find that none of the sentence encoding tasks tested yield significant\nincreases in brain decoding performance. Through further task ablations and\nrepresentational analyses, we find that tasks which produce syntax-light\nrepresentations yield significant improvements in brain decoding performance.\nOur results constrain the space of NLU models that could best account for human\nneural representations of language, but also suggest limits on the possibility\nof decoding fine-grained syntactic information from fMRI human neuroimaging.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 22:36:51 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Gauthier", "Jon", ""], ["Levy", "Roger", ""]]}, {"id": "1910.01274", "submitter": "Isar Nejadgholi", "authors": "Kathleen C. Fraser, Isar Nejadgholi, Berry De Bruijn, Muqun Li, Astha\n  LaPlante, Khaldoun Zine El Abidine", "title": "Extracting UMLS Concepts from Medical Text Using General and\n  Domain-Specific Deep Learning Models", "comments": "11 pages, accepted at LOUHI2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity recognition is a critical first step to a number of clinical NLP\napplications, such as entity linking and relation extraction. We present the\nfirst attempt to apply state-of-the-art entity recognition approaches on a\nnewly released dataset, MedMentions. This dataset contains over 4000 biomedical\nabstracts, annotated for UMLS semantic types. In comparison to existing\ndatasets, MedMentions contains a far greater number of entity types, and thus\nrepresents a more challenging but realistic scenario in a real-world setting.\nWe explore a number of relevant dimensions, including the use of contextual\nversus non-contextual word embeddings, general versus domain-specific\nunsupervised pre-training, and different deep learning architectures. We\ncontrast our results against the well-known i2b2 2010 entity recognition\ndataset, and propose a new method to combine general and domain-specific\ninformation. While producing a state-of-the-art result for the i2b2 2010 task\n(F1 = 0.90), our results on MedMentions are significantly lower (F1 = 0.63),\nsuggesting there is still plenty of opportunity for improvement on this new\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 01:51:17 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Fraser", "Kathleen C.", ""], ["Nejadgholi", "Isar", ""], ["De Bruijn", "Berry", ""], ["Li", "Muqun", ""], ["LaPlante", "Astha", ""], ["Abidine", "Khaldoun Zine El", ""]]}, {"id": "1910.01289", "submitter": "Kai Fan Dr", "authors": "Kai Fan, Jiayi Wang, Bo Li, Shiliang Zhang, Boxing Chen, Niyu Ge,\n  Zhijie Yan", "title": "Neural Zero-Inflated Quality Estimation Model For Automatic Speech\n  Recognition System", "comments": "InterSpeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performances of automatic speech recognition (ASR) systems are usually\nevaluated by the metric word error rate (WER) when the manually transcribed\ndata are provided, which are, however, expensively available in the real\nscenario. In addition, the empirical distribution of WER for most ASR systems\nusually tends to put a significant mass near zero, making it difficult to\nsimulate with a single continuous distribution. In order to address the two\nissues of ASR quality estimation (QE), we propose a novel neural zero-inflated\nmodel to predict the WER of the ASR result without transcripts. We design a\nneural zero-inflated beta regression on top of a bidirectional transformer\nlanguage model conditional on speech features (speech-BERT). We adopt the\npre-training strategy of token level mask language modeling for speech-BERT as\nwell, and further fine-tune with our zero-inflated layer for the mixture of\ndiscrete and continuous outputs. The experimental results show that our\napproach achieves better performance on WER prediction in the metrics of\nPearson and MAE, compared with most existed quality estimation algorithms for\nASR or machine translation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 03:19:55 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 19:03:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Fan", "Kai", ""], ["Wang", "Jiayi", ""], ["Li", "Bo", ""], ["Zhang", "Shiliang", ""], ["Chen", "Boxing", ""], ["Ge", "Niyu", ""], ["Yan", "Zhijie", ""]]}, {"id": "1910.01299", "submitter": "Yuta Koreeda", "authors": "Yuta Koreeda, Gaku Morio, Terufumi Morishita, Hiroaki Ozaki, Kohsuke\n  Yanai", "title": "Hitachi at MRP 2019: Unified Encoder-to-Biaffine Network for\n  Cross-Framework Meaning Representation Parsing", "comments": "13 pages, 3 figures", "journal-ref": "in Proceedings of the Shared Task on Cross-Framework Meaning\n  Representation Parsing at the 2019 Conference on Natural Language Learning", "doi": "10.18653/v1/K19-2011", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the proposed system of the Hitachi team for the\nCross-Framework Meaning Representation Parsing (MRP 2019) shared task. In this\nshared task, the participating systems were asked to predict nodes, edges and\ntheir attributes for five frameworks, each with different order of\n\"abstraction\" from input tokens. We proposed a unified encoder-to-biaffine\nnetwork for all five frameworks, which effectively incorporates a shared\nencoder to extract rich input features, decoder networks to generate anchorless\nnodes in UCCA and AMR, and biaffine networks to predict edges. Our system was\nranked fifth with the macro-averaged MRP F1 score of 0.7604, and outperformed\nthe baseline unified transition-based MRP. Furthermore, post-evaluation\nexperiments showed that we can boost the performance of the proposed system by\nincorporating multi-task learning, whereas the baseline could not. These imply\nefficacy of incorporating the biaffine network to the shared architecture for\nMRP and that learning heterogeneous meaning representations at once can boost\nthe system performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 04:27:49 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 14:56:26 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 05:17:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Koreeda", "Yuta", ""], ["Morio", "Gaku", ""], ["Morishita", "Terufumi", ""], ["Ozaki", "Hiroaki", ""], ["Yanai", "Kohsuke", ""]]}, {"id": "1910.01302", "submitter": "Igor Shalyminov", "authors": "Igor Shalyminov, Sungjin Lee, Arash Eshghi, and Oliver Lemon", "title": "Data-Efficient Goal-Oriented Conversation with Dialogue Knowledge\n  Transfer Networks", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialogue systems are now being widely adopted in industry where\nit is of key importance to maintain a rapid prototyping cycle for new products\nand domains. Data-driven dialogue system development has to be adapted to meet\nthis requirement --- therefore, reducing the amount of data and annotations\nnecessary for training such systems is a central research problem.\n  In this paper, we present the Dialogue Knowledge Transfer Network (DiKTNet),\na state-of-the-art approach to goal-oriented dialogue generation which only\nuses a few example dialogues (i.e. few-shot learning), none of which has to be\nannotated. We achieve this by performing a 2-stage training. Firstly, we\nperform unsupervised dialogue representation pre-training on a large source of\ngoal-oriented dialogues in multiple domains, the MetaLWOz corpus. Secondly, at\nthe transfer stage, we train DiKTNet using this representation together with 2\nother textual knowledge sources with different levels of generality: ELMo\nencoder and the main dataset's source domains.\n  Our main dataset is the Stanford Multi-Domain dialogue corpus. We evaluate\nour model on it in terms of BLEU and Entity F1 scores, and show that our\napproach significantly and consistently improves upon a series of baseline\nmodels as well as over the previous state-of-the-art dialogue generation model,\nZSDG. The improvement upon the latter --- up to 10% in Entity F1 and the\naverage of 3% in BLEU score --- is achieved using only the equivalent of 10% of\nZSDG's in-domain training data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 05:08:15 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Shalyminov", "Igor", ""], ["Lee", "Sungjin", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1910.01335", "submitter": "Zhengyuan Liu", "authors": "Zhengyuan Liu, Angela Ng, Sheldon Lee, Ai Ti Aw, Nancy F. Chen", "title": "Topic-aware Pointer-Generator Networks for Summarizing Spoken\n  Conversations", "comments": "To appear in ASRU2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the lack of publicly available resources, conversation summarization\nhas received far less attention than text summarization. As the purpose of\nconversations is to exchange information between at least two interlocutors,\nkey information about a certain topic is often scattered and spanned across\nmultiple utterances and turns from different speakers. This phenomenon is more\npronounced during spoken conversations, where speech characteristics such as\nbackchanneling and false-starts might interrupt the topical flow. Moreover,\ntopic diffusion and (intra-utterance) topic drift are also more common in\nhuman-to-human conversations. Such linguistic characteristics of dialogue\ntopics make sentence-level extractive summarization approaches used in spoken\ndocuments ill-suited for summarizing conversations. Pointer-generator networks\nhave effectively demonstrated its strength at integrating extractive and\nabstractive capabilities through neural modeling in text summarization. To the\nbest of our knowledge, to date no one has adopted it for summarizing\nconversations. In this work, we propose a topic-aware architecture to exploit\nthe inherent hierarchical structure in conversations to further adapt the\npointer-generator model. Our approach significantly outperforms competitive\nbaselines, achieves more efficient learning outcomes, and attains more robust\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:48:32 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Liu", "Zhengyuan", ""], ["Ng", "Angela", ""], ["Lee", "Sheldon", ""], ["Aw", "Ai Ti", ""], ["Chen", "Nancy F.", ""]]}, {"id": "1910.01340", "submitter": "Bilal Ghanem", "authors": "Bilal Ghanem, Davide Buscaldi, Paolo Rosso", "title": "TexTrolls: Identifying Russian Trolls on Twitter from a Textual\n  Perspective", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online new emerging suspicious users, that usually are called trolls, are\none of the main sources of hate, fake, and deceptive online messages. Some\nagendas are utilizing these harmful users to spread incitement tweets, and as a\nconsequence, the audience get deceived. The challenge in detecting such\naccounts is that they conceal their identities which make them disguised in\nsocial media, adding more difficulty to identify them using just their social\nnetwork information. Therefore, in this paper, we propose a text-based approach\nto detect the online trolls such as those that were discovered during the US\n2016 presidential elections. Our approach is mainly based on textual features\nwhich utilize thematic information, and profiling features to identify the\naccounts from their way of writing tweets. We deduced the thematic information\nin a unsupervised way and we show that coupling them with the textual features\nenhanced the performance of the proposed model. In addition, we find that the\nproposed profiling features perform the best comparing to the textual features.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:56:52 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ghanem", "Bilal", ""], ["Buscaldi", "Davide", ""], ["Rosso", "Paolo", ""]]}, {"id": "1910.01363", "submitter": "Mareike Hartmann", "authors": "Mareike Hartmann and Yevgeniy Golovchenko and Isabelle Augenstein", "title": "Mapping (Dis-)Information Flow about the MH17 Plane Crash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital media enables not only fast sharing of information, but also\ndisinformation. One prominent case of an event leading to circulation of\ndisinformation on social media is the MH17 plane crash. Studies analysing the\nspread of information about this event on Twitter have focused on small,\nmanually annotated datasets, or used proxys for data annotation. In this work,\nwe examine to what extent text classifiers can be used to label data for\nsubsequent content analysis, in particular we focus on predicting pro-Russian\nand pro-Ukrainian Twitter content related to the MH17 plane crash. Even though\nwe find that a neural classifier improves over a hashtag based baseline,\nlabeling pro-Russian and pro-Ukrainian content with high precision remains a\nchallenging problem. We provide an error analysis underlining the difficulty of\nthe task and identify factors that might help improve classification in future\nwork. Finally, we show how the classifier can facilitate the annotation task\nfor human annotators.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 09:00:58 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Hartmann", "Mareike", ""], ["Golovchenko", "Yevgeniy", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1910.01441", "submitter": "Jon Chun", "authors": "Katherine Elkins, Jon Chun", "title": "Can Sentiment Analysis Reveal Structure in a Plotless Novel?", "comments": "Digital Humanities, Sentiment Analysis, Novel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modernist novels are thought to break with traditional plot structure. In\nthis paper, we test this theory by applying Sentiment Analysis to one of the\nmost famous modernist novels, To the Lighthouse by Virginia Woolf. We first\nassess Sentiment Analysis in light of the critique that it cannot adequately\naccount for literary language: we use a unique statistical comparison to\ndemonstrate that even simple lexical approaches to Sentiment Analysis are\nsurprisingly effective. We then use the Syuzhet.R package to explore\nsimilarities and differences across modeling methods. This comparative\napproach, when paired with literary close reading, can offer interpretive\nclues. To our knowledge, we are the first to undertake a hybrid model that\nfully leverages the strengths of both computational analysis and close reading.\nThis hybrid model raises new questions for the literary critic, such as how to\ninterpret relative versus absolute emotional valence and how to take into\naccount subjective identification. Our finding is that while To the Lighthouse\ndoes not replicate a plot centered around a traditional hero, it does reveal an\nunderlying emotional structure distributed between characters - what we term a\ndistributed heroine model. This finding is innovative in the field of modernist\nand narrative studies and demonstrates that a hybrid method can yield\nsignificant discoveries.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2019 17:25:00 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Elkins", "Katherine", ""], ["Chun", "Jon", ""]]}, {"id": "1910.01442", "submitter": "Chuang Gan", "authors": "Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio\n  Torralba, Joshua B. Tenenbaum", "title": "CLEVRER: CoLlision Events for Video REpresentation and Reasoning", "comments": "The first two authors contributed equally to this work. Accepted as\n  Oral Spotlight as ICLR 2020. Project page: http://clevrer.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to reason about temporal and causal events from videos lies at\nthe core of human intelligence. Most video reasoning benchmarks, however, focus\non pattern recognition from complex visual and language input, instead of on\ncausal structure. We study the complementary problem, exploring the temporal\nand causal structures behind videos of objects with simple visual appearance.\nTo this end, we introduce the CoLlision Events for Video REpresentation and\nReasoning (CLEVRER), a diagnostic video dataset for systematic evaluation of\ncomputational models on a wide range of reasoning tasks. Motivated by the\ntheory of human casual judgment, CLEVRER includes four types of questions:\ndescriptive (e.g., \"what color\"), explanatory (\"what is responsible for\"),\npredictive (\"what will happen next\"), and counterfactual (\"what if\"). We\nevaluate various state-of-the-art models for visual reasoning on our benchmark.\nWhile these models thrive on the perception-based task (descriptive), they\nperform poorly on the causal tasks (explanatory, predictive and\ncounterfactual), suggesting that a principled approach for causal reasoning\nshould incorporate the capability of both perceiving complex visual and\nlanguage inputs, and understanding the underlying dynamics and causal\nrelations. We also study an oracle model that explicitly combines these\ncomponents via symbolic representations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:16:36 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 00:09:07 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Yi", "Kexin", ""], ["Gan", "Chuang", ""], ["Li", "Yunzhu", ""], ["Kohli", "Pushmeet", ""], ["Wu", "Jiajun", ""], ["Torralba", "Antonio", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1910.01462", "submitter": "Yung-Sung Chuang", "authors": "Alexander Te-Wei Shieh, Yung-Sung Chuang, Shang-Yu Su, Yun-Nung Chen", "title": "Towards Understanding of Medical Randomized Controlled Trials by\n  Conclusion Generation", "comments": "In Proceedings of the 10th International Workshop on Health Text\n  Mining and Information Analysis at EMNLP (LOUHI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized controlled trials (RCTs) represent the paramount evidence of\nclinical medicine. Using machines to interpret the massive amount of RCTs has\nthe potential of aiding clinical decision-making. We propose a RCT conclusion\ngeneration task from the PubMed 200k RCT sentence classification dataset to\nexamine the effectiveness of sequence-to-sequence models on understanding RCTs.\nWe first build a pointer-generator baseline model for conclusion generation.\nThen we fine-tune the state-of-the-art GPT-2 language model, which is\npre-trained with general domain data, for this new medical domain task. Both\nautomatic and human evaluation show that our GPT-2 fine-tuned models achieve\nimproved quality and correctness in the generated conclusions compared to the\nbaseline pointer-generator model. Further inspection points out the limitations\nof this current approach and future directions to explore.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:35:00 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Shieh", "Alexander Te-Wei", ""], ["Chuang", "Yung-Sung", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1910.01489", "submitter": "Nicolas Dugu\\'e", "authors": "Nicolas Dugu\\'e and Victor Connes", "title": "Complex networks based word embeddings", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the time, the first step to learn word embeddings is to build a word\nco-occurrence matrix. As such matrices are equivalent to graphs, complex\nnetworks theory can naturally be used to deal with such data. In this paper, we\nconsider applying community detection, a main tool of this field, to the\nco-occurrence matrix corresponding to a huge corpus. Community structure is\nused as a way to reduce the dimensionality of the initial space. Using this\ncommunity structure, we propose a method to extract word embeddings that are\ncomparable to the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:12:38 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Dugu\u00e9", "Nicolas", ""], ["Connes", "Victor", ""]]}, {"id": "1910.01531", "submitter": "Aaron Mueller", "authors": "Arya D. McCarthy, Winston Wu, Aaron Mueller, Bill Watson, David\n  Yarowsky", "title": "Modeling Color Terminology Across Thousands of Languages", "comments": "Accepted for presentation at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an extensive history of scholarship into what constitutes a \"basic\"\ncolor term, as well as a broadly attested acquisition sequence of basic color\nterms across many languages, as articulated in the seminal work of Berlin and\nKay (1969). This paper employs a set of diverse measures on massively\ncross-linguistic data to operationalize and critique the Berlin and Kay color\nterm hypotheses. Collectively, the 14 empirically-grounded computational\nlinguistic metrics we design---as well as their aggregation---correlate\nstrongly with both the Berlin and Kay basic/secondary color term partition\n(gamma=0.96) and their hypothesized universal acquisition sequence. The\nmeasures and result provide further empirical evidence from computational\nlinguistics in support of their claims, as well as additional nuance: they\nsuggest treating the partition as a spectrum instead of a dichotomy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 14:46:22 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["McCarthy", "Arya D.", ""], ["Wu", "Winston", ""], ["Mueller", "Aaron", ""], ["Watson", "Bill", ""], ["Yarowsky", "David", ""]]}, {"id": "1910.01709", "submitter": "Soroosh Mariooryad", "authors": "Raza Habib, Soroosh Mariooryad, Matt Shannon, Eric Battenberg, RJ\n  Skerry-Ryan, Daisy Stanton, David Kao, Tom Bagby", "title": "Semi-Supervised Generative Modeling for Controllable Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel generative model that combines state-of-the-art neural\ntext-to-speech (TTS) with semi-supervised probabilistic latent variable models.\nBy providing partial supervision to some of the latent variables, we are able\nto force them to take on consistent and interpretable purposes, which\npreviously hasn't been possible with purely unsupervised TTS models. We\ndemonstrate that our model is able to reliably discover and control important\nbut rarely labelled attributes of speech, such as affect and speaking rate,\nwith as little as 1% (30 minutes) supervision. Even at such low supervision\nlevels we do not observe a degradation of synthesis quality compared to a\nstate-of-the-art baseline. Audio samples are available on the web.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 20:18:45 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Habib", "Raza", ""], ["Mariooryad", "Soroosh", ""], ["Shannon", "Matt", ""], ["Battenberg", "Eric", ""], ["Skerry-Ryan", "RJ", ""], ["Stanton", "Daisy", ""], ["Kao", "David", ""], ["Bagby", "Tom", ""]]}, {"id": "1910.01761", "submitter": "Mike Tian-Jian Jiang", "authors": "Mike Tian-Jian Jiang", "title": "Character Feature Engineering for Japanese Word Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  On word segmentation problems, machine learning architecture engineering\noften draws attention. The problem representation itself, however, has remained\nalmost static as either word lattice ranking or character sequence tagging, for\nat least two decades. The latter of-ten shows stronger predictive power than\nthe former for out-of-vocabulary (OOV) issue. When the issue escalating to\nrapid adaptation, which is a common scenario for industrial applications,\nactive learning of partial annotations or re-training with additional lexical\nre-sources is usually applied, however, from a somewhat word-based perspective.\nNot only it is uneasy for end-users to comply with linguistically consistent\nword boundary decisions, but also the risk/cost of forking models permanently\nwith estimated weights is seldom affordable. To overcome the obstacle, this\nwork provides an alternative, which uses linguistic intuition about character\ncompositions, such that a sophisticated feature set and its derived scheme can\nenable dynamic lexicon expansion with the model remaining intact. Experiment\nresults suggest that the proposed solution, with or without external lexemes,\nperforms competitively in terms of F1 score and OOV recall across various\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 23:39:31 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Jiang", "Mike Tian-Jian", ""]]}, {"id": "1910.01769", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee and Ahmed Hassan Awadallah", "title": "Distilling BERT into Simple Neural Networks with Unlabeled Transfer Data", "comments": "Multilingual version of this work, namely XtremeDistil\n  (https://aka.ms/XtremeDistil) appears at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in pre-training huge models on large amounts of text through\nself supervision have obtained state-of-the-art results in various natural\nlanguage processing tasks. However, these huge and expensive models are\ndifficult to use in practise for downstream tasks. Some recent efforts use\nknowledge distillation to compress these models. However, we see a gap between\nthe performance of the smaller student models as compared to that of the large\nteacher. In this work, we leverage large amounts of in-domain unlabeled\ntransfer data in addition to a limited amount of labeled training instances to\nbridge this gap for distilling BERT. We show that simple RNN based student\nmodels even with hard distillation can perform at par with the huge teachers\ngiven the transfer set. The student performance can be further improved with\nsoft distillation and leveraging teacher intermediate representations. We show\nthat our student models can compress the huge teacher by up to 26x while still\nmatching or even marginally exceeding the teacher performance in low-resource\nsettings with small amount of labeled data. Additionally, for the multilingual\nextension of this work with XtremeDistil (Mukherjee and Hassan Awadallah,\n2020), we demonstrate massive distillation of multilingual BERT-like teacher\nmodels by upto 35x in terms of parameter compression and 51x in terms of\nlatency speedup for batch inference while retaining 95% of its F1-score for NER\nover 41 languages.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 01:01:26 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 01:44:14 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "1910.01818", "submitter": "Hang Jiang", "authors": "Hang Jiang, Haoshen Hong, Yuxing Chen, Vivek Kulkarni", "title": "DialectGram: Detecting Dialectal Variation at Multiple Geographic\n  Resolutions", "comments": "Hang Jiang, Haoshen Hong, and Yuxing Chen are equal contributors", "journal-ref": "Proceedings of the Society for Computation in Linguistics, 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several computational models have been developed to detect and analyze\ndialect variation in recent years. Most of these models assume a predefined set\nof geographical regions over which they detect and analyze dialectal variation.\nHowever, dialect variation occurs at multiple levels of geographic resolution\nranging from cities within a state, states within a country, and between\ncountries across continents. In this work, we propose a model that enables\ndetection of dialectal variation at multiple levels of geographic resolution\nobviating the need for a-priori definition of the resolution level. Our method\nDialectGram, learns dialect-sensitive word embeddings while being agnostic of\nthe geographic resolution. Specifically it only requires one-time training and\nenables analysis of dialectal variation at a chosen resolution post-hoc -- a\nsignificant departure from prior models which need to be re-trained whenever\nthe pre-defined set of regions changes. Furthermore, DialectGram explicitly\nmodels senses thus enabling one to estimate the proportion of each sense usage\nin any given region. Finally, we quantitatively evaluate our model against\nother baselines on a new evaluation dataset DialectSim (in English) and show\nthat DialectGram can effectively model linguistic variation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 07:22:25 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 00:33:11 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Jiang", "Hang", ""], ["Hong", "Haoshen", ""], ["Chen", "Yuxing", ""], ["Kulkarni", "Vivek", ""]]}, {"id": "1910.01822", "submitter": "Wei Li", "authors": "Wei Li and Yunfang Wu", "title": "Multi-level Gated Recurrent Neural Network for Dialog Act Classification", "comments": "COLING 2016 published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we focus on the problem of dialog act (DA) labelling. This\nproblem has recently attracted a lot of attention as it is an important\nsub-part of an automatic question answering system, which is currently in great\ndemand. Traditional methods tend to see this problem as a sequence labelling\ntask and deals with it by applying classifiers with rich features. Most of the\ncurrent neural network models still omit the sequential information in the\nconversation. Henceforth, we apply a novel multi-level gated recurrent neural\nnetwork (GRNN) with non-textual information to predict the DA tag. Our model\nnot only utilizes textual information, but also makes use of non-textual and\ncontextual information. In comparison, our model has shown significant\nimprovement over previous works on Switchboard Dialog Act (SWDA) task by over\n6%.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 07:27:23 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Li", "Wei", ""], ["Wu", "Yunfang", ""]]}, {"id": "1910.01859", "submitter": "Jan Niehues", "authors": "Jan Niehues and Ngoc-Quan Pham", "title": "Modeling Confidence in Sequence-to-Sequence Models", "comments": "8 pages; INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant improvements have been achieved in various natural\nlanguage processing tasks using neural sequence-to-sequence models. While\naiming for the best generation quality is important, ultimately it is also\nnecessary to develop models that can assess the quality of their output.\n  In this work, we propose to use the similarity between training and test\nconditions as a measure for models' confidence. We investigate methods solely\nusing the similarity as well as methods combining it with the posterior\nprobability. While traditionally only target tokens are annotated with\nconfidence measures, we also investigate methods to annotate source tokens with\nconfidence. By learning an internal alignment model, we can significantly\nimprove confidence projection over using state-of-the-art external alignment\ntools. We evaluate the proposed methods on downstream confidence estimation for\nmachine translation (MT). We show improvements on segment-level confidence\nestimation as well as on confidence estimation for source tokens. In addition,\nwe show that the same methods can also be applied to other tasks using\nsequence-to-sequence models. On the automatic speech recognition (ASR) task, we\nare able to find 60% of the errors by looking at 20% of the data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:30:36 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Niehues", "Jan", ""], ["Pham", "Ngoc-Quan", ""]]}, {"id": "1910.01863", "submitter": "Jenna Kanerva", "authors": "Jenna Kanerva and Samuel R\\\"onnqvist and Riina Kekki and Tapio\n  Salakoski and Filip Ginter", "title": "Template-free Data-to-Text Generation of Finnish Sports News", "comments": "NoDaLiDa 2019 (https://www.aclweb.org/anthology/W19-6125/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News articles such as sports game reports are often thought to closely follow\nthe underlying game statistics, but in practice they contain a notable amount\nof background knowledge, interpretation, insight into the game, and quotes that\nare not present in the official statistics. This poses a challenge for\nautomated data-to-text news generation with real-world news corpora as training\ndata. We report on the development of a corpus of Finnish ice hockey news,\nedited to be suitable for training of end-to-end news generation methods, as\nwell as demonstrate generation of text, which was judged by journalists to be\nrelatively close to a viable product. The new dataset and system source code\nare available for research purposes at\nhttps://github.com/scoopmatic/finnish-hockey-news-generation-paper.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:40:44 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kanerva", "Jenna", ""], ["R\u00f6nnqvist", "Samuel", ""], ["Kekki", "Riina", ""], ["Salakoski", "Tapio", ""], ["Ginter", "Filip", ""]]}, {"id": "1910.01990", "submitter": "Preslav Nakov", "authors": "Daniel Kopev, Ahmed Ali, Ivan Koychev, Preslav Nakov", "title": "Detecting Deception in Political Debates Using Acoustic and Textual\n  Features", "comments": null, "journal-ref": "ASRU-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present work on deception detection, where, given a spoken claim, we aim\nto predict its factuality. While previous work in the speech community has\nrelied on recordings from staged setups where people were asked to tell the\ntruth or to lie and their statements were recorded, here we use real-world\npolitical debates. Thanks to the efforts of fact-checking organizations, it is\npossible to obtain annotations for statements in the context of a political\ndiscourse as true, half-true, or false. Starting with such data from the\nCLEF-2018 CheckThat! Lab, which was limited to text, we performed alignment to\nthe corresponding videos, thus producing a multimodal dataset. We further\ndeveloped a multimodal deep-learning architecture for the task of deception\ndetection, which yielded sizable improvements over the state of the art for the\nCLEF-2018 Lab task 2. Our experiments show that the use of the acoustic signal\nconsistently helped to improve the performance compared to using textual and\nmetadata features only, based on several different evaluation measures. We\nrelease the new dataset to the research community, hoping to help advance the\noverall field of multimodal deception detection.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:28:01 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Kopev", "Daniel", ""], ["Ali", "Ahmed", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.01992", "submitter": "Zhen Huang", "authors": "Zhen Huang, Tim Ng, Leo Liu, Henry Mason, Xiaodan Zhuang, Daben Liu", "title": "SNDCNN: Self-normalizing deep CNNs with scaled exponential linear units\n  for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very deep CNNs achieve state-of-the-art results in both computer vision and\nspeech recognition, but are difficult to train. The most popular way to train\nvery deep CNNs is to use shortcut connections (SC) together with batch\nnormalization (BN). Inspired by Self- Normalizing Neural Networks, we propose\nthe self-normalizing deep CNN (SNDCNN) based acoustic model topology, by\nremoving the SC/BN and replacing the typical RELU activations with scaled\nexponential linear unit (SELU) in ResNet-50. SELU activations make the network\nself-normalizing and remove the need for both shortcut connections and batch\nnormalization. Compared to ResNet- 50, we can achieve the same or lower (up to\n4.5% relative) word error rate (WER) while boosting both training and inference\nspeed by 60%-80%. We also explore other model inference optimization schemes to\nfurther reduce latency for production use.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:31:48 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 14:39:52 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 20:39:17 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Huang", "Zhen", ""], ["Ng", "Tim", ""], ["Liu", "Leo", ""], ["Mason", "Henry", ""], ["Zhuang", "Xiaodan", ""], ["Liu", "Daben", ""]]}, {"id": "1910.02001", "submitter": "Preslav Nakov", "authors": "Atanas Atanasov, Gianmarco De Francisci Morales, Preslav Nakov", "title": "Predicting the Role of Political Trolls in Social Media", "comments": null, "journal-ref": "CoNLL-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the political roles of \"Internet trolls\" in social media.\nPolitical trolls, such as the ones linked to the Russian Internet Research\nAgency (IRA), have recently gained enormous attention for their ability to sway\npublic opinion and even influence elections. Analysis of the online traces of\ntrolls has shown different behavioral patterns, which target different slices\nof the population. However, this analysis is manual and labor-intensive, thus\nmaking it impractical as a first-response tool for newly-discovered troll\nfarms. In this paper, we show how to automate this analysis by using machine\nlearning in a realistic setting. In particular, we show how to classify trolls\naccording to their political role ---left, news feed, right--- by using\nfeatures extracted from social media, i.e., Twitter, in two scenarios: (i) in a\ntraditional supervised learning scenario, where labels for trolls are\navailable, and (ii) in a distant supervision scenario, where labels for trolls\nare not available, and we rely on more-commonly-available labels for news\noutlets mentioned by the trolls. Technically, we leverage the community\nstructure and the text of the messages in the online social network of trolls\nrepresented as a graph, from which we extract several types of learned\nrepresentations, i.e.,~embeddings, for the trolls. Experiments on the \"IRA\nRussian Troll\" dataset show that our methodology improves over the\nstate-of-the-art in the first scenario, while providing a compelling case for\nthe second scenario, which has not been explored in the literature thus far.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 15:50:30 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Atanasov", "Atanas", ""], ["Morales", "Gianmarco De Francisci", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02028", "submitter": "Preslav Nakov", "authors": "Yifan Zhang, Giovanni Da San Martino, Alberto Barr\\'on-Cede\\~no,\n  Salvatore Romeo, Jisun An, Haewoon Kwak, Todor Staykovski, Israa Jaradat,\n  Georgi Karadzhov, Ramy Baly, Kareem Darwish, James Glass, Preslav Nakov", "title": "Tanbih: Get To Know What You Are Reading", "comments": null, "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Tanbih, a news aggregator with intelligent analysis tools to\nhelp readers understanding what's behind a news story. Our system displays news\ngrouped into events and generates media profiles that show the general\nfactuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics of a news outlet. In addition,\nwe automatically analyse each article to detect whether it is propagandistic\nand to determine its stance with respect to a number of controversial topics.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:43:49 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zhang", "Yifan", ""], ["Martino", "Giovanni Da San", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Romeo", "Salvatore", ""], ["An", "Jisun", ""], ["Kwak", "Haewoon", ""], ["Staykovski", "Todor", ""], ["Jaradat", "Israa", ""], ["Karadzhov", "Georgi", ""], ["Baly", "Ramy", ""], ["Darwish", "Kareem", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02029", "submitter": "Arun Balajee Vasudevan", "authors": "Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool", "title": "Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention\n  and Spatial Memory", "comments": "Accepted to IJCV 2020, 20 pages, 10 Figures, Demo Video:\n  https://people.ee.ethz.ch/~arunv/resources/talk2nav.mp4", "journal-ref": null, "doi": "10.1007/s11263-020-01374-3", "report-no": null, "categories": "cs.CV cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of robots in society keeps expanding, bringing with it the necessity\nof interacting and communicating with humans. In order to keep such interaction\nintuitive, we provide automatic wayfinding based on verbal navigational\ninstructions. Our first contribution is the creation of a large-scale dataset\nwith verbal navigation instructions. To this end, we have developed an\ninteractive visual navigation environment based on Google Street View; we\nfurther design an annotation method to highlight mined anchor landmarks and\nlocal directions between them in order to help annotators formulate typical,\nhuman references to those. The annotation task was crowdsourced on the AMT\nplatform, to construct a new Talk2Nav dataset with $10,714$ routes. Our second\ncontribution is a new learning method. Inspired by spatial cognition research\non the mental conceptualization of navigational instructions, we introduce a\nsoft dual attention mechanism defined over the segmented language instructions\nto jointly extract two partial instructions -- one for matching the next\nupcoming visual landmark and the other for matching the local directions to the\nnext landmark. On the similar lines, we also introduce spatial memory scheme to\nencode the local directional transitions. Our work takes advantage of the\nadvance in two lines of research: mental formalization of verbal navigational\ninstructions and training neural network agents for automatic way finding.\nExtensive experiments show that our method significantly outperforms previous\nnavigation methods. For demo video, dataset and code, please refer to our\nproject page: https://www.trace.ethz.ch/publications/2019/talk2nav/index.html\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:44:59 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 11:25:09 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 12:03:18 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Vasudevan", "Arun Balajee", ""], ["Dai", "Dengxin", ""], ["Van Gool", "Luc", ""]]}, {"id": "1910.02065", "submitter": "Oana-Maria Camburu", "authors": "Oana-Maria Camburu, Eleonora Giunchiglia, Jakob Foerster, Thomas\n  Lukasiewicz, Phil Blunsom", "title": "Can I Trust the Explainer? Verifying Post-hoc Explanatory Methods", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Safety and Robustness in Decision Making,\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For AI systems to garner widespread public acceptance, we must develop\nmethods capable of explaining the decisions of black-box models such as neural\nnetworks. In this work, we identify two issues of current explanatory methods.\nFirst, we show that two prevalent perspectives on explanations ---\nfeature-additivity and feature-selection --- lead to fundamentally different\ninstance-wise explanations. In the literature, explainers from different\nperspectives are currently being directly compared, despite their distinct\nexplanation goals. The second issue is that current post-hoc explainers are\neither validated under simplistic scenarios (on simple models such as linear\nregression, or on models trained on syntactic datasets), or, when applied to\nreal-world neural networks, explainers are commonly validated under the\nassumption that the learned models behave reasonably. However, neural networks\noften rely on unreasonable correlations, even when producing correct decisions.\nWe introduce a verification framework for explanatory methods under the\nfeature-selection perspective. Our framework is based on a non-trivial neural\nnetwork architecture trained on a real-world task, and for which we are able to\nprovide guarantees on its inner workings. We validate the efficacy of our\nevaluation by showing the failure modes of current explainers. We aim for this\nframework to provide a publicly available, off-the-shelf evaluation when the\nfeature-selection perspective on explanations is needed.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:44:36 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 14:58:47 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 13:41:46 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Camburu", "Oana-Maria", ""], ["Giunchiglia", "Eleonora", ""], ["Foerster", "Jakob", ""], ["Lukasiewicz", "Thomas", ""], ["Blunsom", "Phil", ""]]}, {"id": "1910.02076", "submitter": "Preslav Nakov", "authors": "Mitra Mohtarami, James Glass, Preslav Nakov", "title": "Contrastive Language Adaptation for Cross-Lingual Stance Detection", "comments": null, "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study cross-lingual stance detection, which aims to leverage labeled data\nin one language to identify the relative perspective (or stance) of a given\ndocument with respect to a claim in a different target language. In particular,\nwe introduce a novel contrastive language adaptation approach applied to memory\nnetworks, which ensures accurate alignment of stances in the source and target\nlanguages, and can effectively deal with the challenge of limited labeled data\nin the target language. The evaluation results on public benchmark datasets and\ncomparison against current state-of-the-art approaches demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:01:23 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Mohtarami", "Mitra", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02145", "submitter": "Alexis Ghyselen", "authors": "Patrick Baillot and Alexis Ghyselen", "title": "Types for Parallel Complexity in the Pi-calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type systems as a way to control or analyze programs have been largely\nstudied in the context of functional programming languages. Some of those work\nallow to extract from a typing derivation for a program a complexity bound on\nthis program. We present how to adapt this result for parallel complexity in\nthe pi-calculus, as a model of concurrency and parallel communication. We study\ntwo notions of time complexity: the total computation time without parallelism\n(the work) and the computation time under maximal parallelism (the span). We\ndefine reduction relations in the pi-calculus to capture those two notions, and\nwe present two type systems from which one can extract a complexity bound on a\nprocess. The type systems are inspired by input/output types and size types,\nwith temporal information about communications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 10:43:43 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Baillot", "Patrick", ""], ["Ghyselen", "Alexis", ""]]}, {"id": "1910.02187", "submitter": "Pengyu Cheng", "authors": "Pengyu Cheng, Yitong Li, Xinyuan Zhang, Liqun Cheng, David Carlson,\n  Lawrence Carin", "title": "Dynamic Embedding on Textual Networks via a Gaussian Process", "comments": "Accepted for presentation at the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual network embedding aims to learn low-dimensional representations of\ntext-annotated nodes in a graph. Prior work in this area has typically focused\non fixed graph structures; however, real-world networks are often dynamic. We\naddress this challenge with a novel end-to-end node-embedding model, called\nDynamic Embedding for Textual Networks with a Gaussian Process (DetGP). After\ntraining, DetGP can be applied efficiently to dynamic graphs without\nre-training or backpropagation. The learned representation of each node is a\ncombination of textual and structural embeddings. Because the structure is\nallowed to be dynamic, our method uses the Gaussian process to take advantage\nof its non-parametric properties. To use both local and global graph\nstructures, diffusion is used to model multiple hops between neighbors. The\nrelative importance of global versus local structure for the embeddings is\nlearned automatically. With the non-parametric nature of the Gaussian process,\nupdating the embeddings for a changed graph structure requires only a forward\npass through the learned model. Considering link prediction and node\nclassification, experiments demonstrate the empirical effectiveness of our\nmethod compared to baseline approaches. We further show that DetGP can be\nstraightforwardly and efficiently applied to dynamic textual networks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 01:16:33 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 20:44:42 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 20:52:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cheng", "Pengyu", ""], ["Li", "Yitong", ""], ["Zhang", "Xinyuan", ""], ["Cheng", "Liqun", ""], ["Carlson", "David", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.02202", "submitter": "Nguyen Vo", "authors": "Nguyen Vo, Kyumin Lee", "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "comments": "SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 03:23:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Vo", "Nguyen", ""], ["Lee", "Kyumin", ""]]}, {"id": "1910.02211", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Vaibhav Kumar, Vivek Gupta, Florian Metze", "title": "On Dimensional Linguistic Properties of the Word Embedding Space", "comments": "Published at ACL RepL4NLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have become a staple of several natural language processing\ntasks, yet much remains to be understood about their properties. In this work,\nwe analyze word embeddings in terms of their principal components and arrive at\na number of novel and counterintuitive observations. In particular, we\ncharacterize the utility of variance explained by the principal components as a\nproxy for downstream performance. Furthermore, through syntactic probing of the\nprincipal embedding space, we show that the syntactic information captured by a\nprincipal component does not correlate with the amount of variance it explains.\nConsequently, we investigate the limitations of variance based embedding\npost-processing and demonstrate that such post-processing is counter-productive\nin sentence classification and machine translation tasks. Finally, we offer a\nfew precautionary guidelines on applying variance based embedding\npost-processing and explain why non-isotropic geometry might be integral to\nword embedding performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 05:03:30 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:56:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Raunak", "Vikas", ""], ["Kumar", "Vaibhav", ""], ["Gupta", "Vivek", ""], ["Metze", "Florian", ""]]}, {"id": "1910.02216", "submitter": "Rajas Agashe", "authors": "Rajas Agashe, Srinivasan Iyer and Luke Zettlemoyer", "title": "JuICe: A Large Scale Distantly Supervised Dataset for Open Domain\n  Context-based Code Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive programming with interleaved code snippet cells and natural\nlanguage markdown is recently gaining popularity in the form of Jupyter\nnotebooks, which accelerate prototyping and collaboration. To study code\ngeneration conditioned on a long context history, we present JuICe, a corpus of\n1.5 million examples with a curated test set of 3.7K instances based on online\nprogramming assignments. Compared with existing contextual code generation\ndatasets, JuICe provides refined human-curated data, open-domain code, and an\norder of magnitude more training data. Using JuICe, we train models for two\ntasks: (1) generation of the API call sequence in a code cell, and (2) full\ncode cell generation, both conditioned on the NL-Code history up to a\nparticular code cell. Experiments using current baseline code generation models\nshow that both context and distant supervision aid in generation, and that the\ndataset is challenging for current systems.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 05:51:45 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 02:56:46 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Agashe", "Rajas", ""], ["Iyer", "Srinivasan", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1910.02223", "submitter": "Qi Jia Sun", "authors": "Qi Jia Sun", "title": "A Machine Learning Analysis of the Features in Deceptive and Credible\n  News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 06:48:23 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Sun", "Qi Jia", ""]]}, {"id": "1910.02228", "submitter": "Omri Koshorek", "authors": "Omri Koshorek, Gabriel Stanovsky, Yichu Zhou, Vivek Srikumar, Jonathan\n  Berant", "title": "On the Limits of Learning to Actively Learn Semantic Representations", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the goals of natural language understanding is to develop models that\nmap sentences into meaning representations. However, training such models\nrequires expensive annotation of complex structures, which hinders their\nadoption. Learning to actively-learn (LTAL) is a recent paradigm for reducing\nthe amount of labeled data by learning a policy that selects which samples\nshould be labeled. In this work, we examine LTAL for learning semantic\nrepresentations, such as QA-SRL. We show that even an oracle policy that is\nallowed to pick examples that maximize performance on the test set (and\nconstitutes an upper bound on the potential of LTAL), does not substantially\nimprove performance compared to a random policy. We investigate factors that\ncould explain this finding and show that a distinguishing characteristic of\nsuccessful applications of LTAL is the interaction between optimization and the\noracle policy selection process. In successful applications of LTAL, the\nexamples selected by the oracle policy do not substantially depend on the\noptimization procedure, while in our setup the stochastic nature of\noptimization strongly affects the examples selected by the oracle. We conclude\nthat the current applicability of LTAL for improving data efficiency in\nlearning semantic meaning representations is limited.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 07:49:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Koshorek", "Omri", ""], ["Stanovsky", "Gabriel", ""], ["Zhou", "Yichu", ""], ["Srikumar", "Vivek", ""], ["Berant", "Jonathan", ""]]}, {"id": "1910.02238", "submitter": "Ngo Thi-Vinh", "authors": "Thi-Vinh Ngo, Thanh-Le Ha, Phuong-Thai Nguyen, Le-Minh Nguyen", "title": "How Transformer Revitalizes Character-based Neural Machine Translation:\n  An Investigation on Japanese-Vietnamese Translation Systems", "comments": null, "journal-ref": "16th International Workshop on Spoken Language Translation 2019", "doi": "10.5281/zenodo.3525490", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While translating between East Asian languages, many works have discovered\nclear advantages of using characters as the translation unit. Unfortunately,\ntraditional recurrent neural machine translation systems hinder the practical\nusage of those character-based systems due to their architectural limitations.\nThey are unfavorable in handling extremely long sequences as well as highly\nrestricted in parallelizing the computations. In this paper, we demonstrate\nthat the new transformer architecture can perform character-based translation\nbetter than the recurrent one. We conduct experiments on a low-resource\nlanguage pair: Japanese-Vietnamese. Our models considerably outperform the\nstate-of-the-art systems which employ word-based recurrent architectures.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 09:16:44 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:19:22 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ngo", "Thi-Vinh", ""], ["Ha", "Thanh-Le", ""], ["Nguyen", "Phuong-Thai", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1910.02267", "submitter": "Nasser Zalmout", "authors": "Nasser Zalmout and Nizar Habash", "title": "Joint Diacritization, Lemmatization, Normalization, and Fine-Grained\n  Morphological Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semitic languages can be highly ambiguous, having several interpretations of\nthe same surface forms, and morphologically rich, having many morphemes that\nrealize several morphological features. This is further exacerbated for\ndialectal content, which is more prone to noise and lacks a standard\northography. The morphological features can be lexicalized, like lemmas and\ndiacritized forms, or non-lexicalized, like gender, number, and part-of-speech\ntags, among others. Joint modeling of the lexicalized and non-lexicalized\nfeatures can identify more intricate morphological patterns, which provide\nbetter context modeling, and further disambiguate ambiguous lexical choices.\nHowever, the different modeling granularity can make joint modeling more\ndifficult. Our approach models the different features jointly, whether\nlexicalized (on the character-level), where we also model surface form\nnormalization, or non-lexicalized (on the word-level). We use Arabic as a test\ncase, and achieve state-of-the-art results for Modern Standard Arabic, with 20%\nrelative error reduction, and Egyptian Arabic (a dialectal variant of Arabic),\nwith 11% reduction.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 13:31:39 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zalmout", "Nasser", ""], ["Habash", "Nizar", ""]]}, {"id": "1910.02290", "submitter": "Anna Kruspe", "authors": "Anna Kruspe", "title": "Few-shot tweet detection in emerging disaster events", "comments": "Accepted to AI+HADR workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media sources can provide crucial information in crisis situations,\nbut discovering relevant messages is not trivial. Methods have so far focused\non universal detection models for all kinds of crises or for certain crisis\ntypes (e.g. floods). Event-specific models could implement a more focused\nsearch area, but collecting data and training new models for a crisis that is\nalready in progress is costly and may take too much time for a prompt response.\nAs a compromise, manually collecting a small amount of example messages is\nfeasible. Few-shot models can generalize to unseen classes with such a small\nhandful of examples, and do not need be trained anew for each event. We compare\nhow few-shot approaches (matching networks and prototypical networks) perform\nfor this task. Since this is essentially a one-class problem, we also\ndemonstrate how a modified one-class version of prototypical models can be used\nfor this application.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 16:25:56 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kruspe", "Anna", ""]]}, {"id": "1910.02292", "submitter": "Joyce Nakatumba-Nabende Dr.", "authors": "Benjamin Akera, Joyce Nakatumba-Nabende, Jonathan Mukiibi, Ali\n  Hussein, Nathan Baleeta, Daniel Ssendiwala, Samiiha Nalwooga", "title": "Keyword Spotter Model for Crop Pest and Disease Monitoring from\n  Community Radio Data", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In societies with well developed internet infrastructure, social media is the\nleading medium of communication for various social issues especially for\nbreaking news situations. In rural Uganda however, public community radio is\nstill a dominant means for news dissemination. Community radio gives audience\nto the general public especially to individuals living in rural areas, and thus\nplays an important role in giving a voice to those living in the broadcast\narea. It is an avenue for participatory communication and a tool relevant in\nboth economic and social development.This is supported by the rise to ubiquity\nof mobile phones providing access to phone-in or text-in talk shows. In this\npaper, we describe an approach to analysing the readily available community\nradio data with machine learning-based speech keyword spotting techniques. We\nidentify the keywords of interest related to agriculture and build models to\nautomatically identify these keywords from audio streams. Our contribution\nthrough these techniques is a cost-efficient and effective way to monitor food\nsecurity concerns particularly in rural areas. Through keyword spotting and\nradio talk show analysis, issues such as crop diseases, pests, drought and\nfamine can be captured and fed into an early warning system for stakeholders\nand policy makers.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 16:30:49 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Akera", "Benjamin", ""], ["Nakatumba-Nabende", "Joyce", ""], ["Mukiibi", "Jonathan", ""], ["Hussein", "Ali", ""], ["Baleeta", "Nathan", ""], ["Ssendiwala", "Daniel", ""], ["Nalwooga", "Samiiha", ""]]}, {"id": "1910.02334", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Benet Oriol Sabat, Cristian Canton Ferrer, Xavier Giro-i-Nieto", "title": "Hate Speech in Pixels: Detection of Offensive Memes towards Automatic\n  Moderation", "comments": "AI for Social Good Workshop at NeurIPS 2019 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the challenge of hate speech detection in Internet memes,\nand attempts using visual information to automatically detect hate speech,\nunlike any previous work of our knowledge. Memes are pixel-based multimedia\ndocuments that contain photos or illustrations together with phrases which,\nwhen combined, usually adopt a funny meaning. However, hate memes are also used\nto spread hate through social networks, so their automatic detection would help\nreduce their harmful societal impact. Our results indicate that the model can\nlearn to detect some of the memes, but that the task is far from being solved\nwith this simple architecture. While previous work focuses on linguistic hate\nspeech, our experiments indicate how the visual modality can be much more\ninformative for hate speech detection than the linguistic one in memes. In our\nexperiments, we built a dataset of 5,020 memes to train and evaluate a\nmulti-layer perceptron over the visual and language representations, whether\nindependently or fused. The source code and mode and models are available\nhttps://github.com/imatge-upc/hate-speech-detection .\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 22:05:43 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Sabat", "Benet Oriol", ""], ["Ferrer", "Cristian Canton", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "1910.02339", "submitter": "Kezhen Chen", "authors": "Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Kenneth D.\n  Forbus and Jianfeng Gao", "title": "Mapping Natural-language Problems to Formal-language Solutions Using\n  Structured Neural Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating formal-language programs represented by relational tuples, such as\nLisp programs or mathematical operations, to solve problems stated in natural\nlanguage is a challenging task because it requires explicitly capturing\ndiscrete symbolic structural information implicit in the input. However, most\ngeneral neural sequence models do not explicitly capture such structural\ninformation, limiting their performance on these tasks. In this paper, we\npropose a new encoder-decoder model based on a structured neural\nrepresentation, Tensor Product Representations (TPRs), for mapping\nNatural-language problems to Formal-language solutions, called TP-N2F. The\nencoder of TP-N2F employs TPR `binding' to encode natural-language symbolic\nstructure in vector space and the decoder uses TPR `unbinding' to generate, in\nsymbolic space, a sequential program represented by relational tuples, each\nconsisting of a relation (or operation) and a number of arguments. TP-N2F\nconsiderably outperforms LSTM-based seq2seq models on two benchmarks and\ncreates new state-of-the-art results. Ablation studies show that improvements\ncan be attributed to the use of structured TPRs explicitly in both the encoder\nand decoder. Analysis of the learned structures shows how TPRs enhance the\ninterpretability of TP-N2F.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 22:57:04 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 04:20:45 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 03:18:59 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Chen", "Kezhen", ""], ["Huang", "Qiuyuan", ""], ["Palangi", "Hamid", ""], ["Smolensky", "Paul", ""], ["Forbus", "Kenneth D.", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1910.02356", "submitter": "Lianzhe Huang", "authors": "Lianzhe Huang, Dehong Ma, Sujian Li, Xiaodong Zhang and Houfeng WANG", "title": "Text Level Graph Neural Network for Text Classification", "comments": "Accepted by EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researches have explored the graph neural network (GNN) techniques\non text classification, since GNN does well in handling complex structures and\npreserving global information. However, previous methods based on GNN are\nmainly faced with the practical problems of fixed corpus level graph structure\nwhich do not support online testing and high memory consumption. To tackle the\nproblems, we propose a new GNN based model that builds graphs for each input\ntext with global parameters sharing instead of a single graph for the whole\ncorpus. This method removes the burden of dependence between an individual text\nand entire corpus which support online testing, but still preserve global\ninformation. Besides, we build graphs by much smaller windows in the text,\nwhich not only extract more local features but also significantly reduce the\nedge numbers as well as memory consumption. Experiments show that our model\noutperforms existing models on several text classification datasets even with\nconsuming less memory.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 02:38:25 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 08:33:05 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Huang", "Lianzhe", ""], ["Ma", "Dehong", ""], ["Li", "Sujian", ""], ["Zhang", "Xiaodong", ""], ["WANG", "Houfeng", ""]]}, {"id": "1910.02365", "submitter": "Chen Chen", "authors": "Chen Chen, Lisong Qiu, Zhenxin Fu, Dongyan Zhao, Junfei Liu, Rui Yan", "title": "Multilingual Dialogue Generation with Shared-Private Memory", "comments": "Accepted by NLPCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing dialog systems are all monolingual, where features shared among\ndifferent languages are rarely explored. In this paper, we introduce a novel\nmultilingual dialogue system. Specifically, we augment the sequence to sequence\nframework with improved shared-private memory. The shared memory learns common\nfeatures among different languages and facilitates a cross-lingual transfer to\nboost dialogue systems, while the private memory is owned by each separate\nlanguage to capture its unique feature. Experiments conducted on Chinese and\nEnglish conversation corpora of different scales show that our proposed\narchitecture outperforms the individually learned model with the help of the\nother language, where the improvement is particularly distinct when the\ntraining data is limited.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 04:02:55 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chen", "Chen", ""], ["Qiu", "Lisong", ""], ["Fu", "Zhenxin", ""], ["Zhao", "Dongyan", ""], ["Liu", "Junfei", ""], ["Yan", "Rui", ""]]}, {"id": "1910.02375", "submitter": "Michael Kruse", "authors": "Michael Kruse, Hal Finkel", "title": "Design and Use of Loop-Transformation Pragmas", "comments": "IWOMP 2019, September 11-13, Auckland, preprint", "journal-ref": null, "doi": "10.1007/978-3-030-28596-8_9", "report-no": null, "categories": "cs.PL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding a pragma directive into the source code is arguably easier than\nrewriting it, for instance for loop unrolling. Moreover, if the application is\nmaintained for multiple platforms, their difference in performance\ncharacteristics may require different code transformations. Code transformation\ndirectives allow replacing the directives depending on the platform, i.e.\nseparation of code semantics and its performance optimization.\n  In this paper, we explore the design space (syntax and semantics) of adding\nsuch directive into a future OpenMP specification. Using a prototype\nimplementation in Clang, we demonstrate the usefulness of such directives on a\nfew benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 05:06:38 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Kruse", "Michael", ""], ["Finkel", "Hal", ""]]}, {"id": "1910.02403", "submitter": "Tomasz Stanis{\\l}awek", "authors": "Tomasz Stanislawek, Anna Wr\\'oblewska, Alicja W\\'ojcicka, Daniel\n  Ziembicki, Przemyslaw Biecek", "title": "Named Entity Recognition -- Is there a glass ceiling?", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Named Entity Recognition (NER) have resulted in better\nand better models. However, is there a glass ceiling? Do we know which types of\nerrors are still hard or even impossible to correct? In this paper, we present\na detailed analysis of the types of errors in state-of-the-art machine learning\n(ML) methods. Our study reveals the weak and strong points of the Stanford,\nCMU, FLAIR, ELMO and BERT models, as well as their shared limitations. We also\nintroduce new techniques for improving annotation, for training processes and\nfor checking a model's quality and stability. Presented results are based on\nthe CoNLL 2003 data set for the English language. A new enriched semantic\nannotation of errors for this data set and new diagnostic data sets are\nattached in the supplementary materials.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 09:35:52 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 18:00:41 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Stanislawek", "Tomasz", ""], ["Wr\u00f3blewska", "Anna", ""], ["W\u00f3jcicka", "Alicja", ""], ["Ziembicki", "Daniel", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1910.02517", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Seunghak Yu, Alberto Barr\\'on-Cede\\~no,\n  Rostislav Petrov, Preslav Nakov", "title": "Fine-Grained Analysis of Propaganda in News Articles", "comments": null, "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propaganda aims at influencing people's mindset with the purpose of advancing\na specific agenda. Previous work has addressed propaganda detection at the\ndocument level, typically labelling all articles from a propagandistic news\noutlet as propaganda. Such noisy gold labels inevitably affect the quality of\nany learning system trained on them. A further issue with most existing systems\nis the lack of explainability. To overcome these limitations, we propose a\nnovel task: performing fine-grained analysis of texts by detecting all\nfragments that contain propaganda techniques as well as their type. In\nparticular, we create a corpus of news articles manually annotated at the\nfragment level with eighteen propaganda techniques and we propose a suitable\nevaluation measure. We further design a novel multi-granularity neural network,\nand we show that it outperforms several strong BERT-based baselines.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 20:26:12 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Yu", "Seunghak", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Petrov", "Rostislav", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.02545", "submitter": "Yikuan Li", "authors": "Zhiheng Li, Xinyue Xing, Bingzhang Lu and Zhixiang Li", "title": "Early Prediction of 30-day ICU Re-admissions Using Natural Language\n  Processing and Machine Learning", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICU readmission is associated with longer hospitalization, mortality and\nadverse outcomes. An early recognition of ICU re-admission can help prevent\npatients from worse situation and lower treatment cost. As the abundance of\nElectronics Health Records (EHR), it is popular to design clinical decision\ntools with machine learning technique manipulating on healthcare large scale\ndata. We designed data-driven predictive models to estimate the risk of ICU\nreadmission. The discharge summary of each hospital admission was carefully\nrepresented by natural language processing techniques. Unified Medical Language\nSystem (UMLS) was further used to standardize inconsistency of discharge\nsummaries. 5 machine learning classifiers were adopted to construct predictive\nmodels. The best configuration yielded a competitive AUC of 0.748. Our work\nsuggests that natural language processing of discharge summaries is capable to\nsend clinicians warning of unplanned 30-day readmission upon discharge.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 22:54:00 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Li", "Zhiheng", ""], ["Xing", "Xinyue", ""], ["Lu", "Bingzhang", ""], ["Li", "Zhixiang", ""]]}, {"id": "1910.02555", "submitter": "Zi-Yi Dou", "authors": "Zi-Yi Dou, Xinyi Wang, Junjie Hu, Graham Neubig", "title": "Domain Differential Adaptation for Neural Machine Translation", "comments": "Workshop on Neural Generation and Translation (WNGT) at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be data hungry and domain sensitive, but it is\nnearly impossible to obtain large quantities of labeled data for every domain\nwe are interested in. This necessitates the use of domain adaptation\nstrategies. One common strategy encourages generalization by aligning the\nglobal distribution statistics between source and target domains, but one\ndrawback is that the statistics of different domains or tasks are inherently\ndivergent, and smoothing over these differences can lead to sub-optimal\nperformance. In this paper, we propose the framework of {\\it Domain\nDifferential Adaptation (DDA)}, where instead of smoothing over these\ndifferences we embrace them, directly modeling the difference between domains\nusing models in a related task. We then use these learned domain differentials\nto adapt models for the target task accordingly. Experimental results on domain\nadaptation for neural machine translation demonstrate the effectiveness of this\nstrategy, achieving consistent improvements over other alternative adaptation\nstrategies in multiple experimental settings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 00:15:11 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Wang", "Xinyi", ""], ["Hu", "Junjie", ""], ["Neubig", "Graham", ""]]}, {"id": "1910.02586", "submitter": "Peng-Hsuan Li", "authors": "Peng-Hsuan Li, Tsu-Jui Fu, Wei-Yun Ma", "title": "Why Attention? Analyzing and Remedying BiLSTM Deficiency in Modeling\n  Cross-Context for NER", "comments": "This short article is obsolete, as its content is contained in the\n  full paper arXiv:1908.11046, which will also be published by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art approaches of NER have used sequence-labeling BiLSTM as a\ncore module. This paper formally shows the limitation of BiLSTM in modeling\ncross-context patterns. Two types of simple cross-structures -- self-attention\nand Cross-BiLSTM -- are shown to effectively remedy the problem. On both\nOntoNotes 5.0 and WNUT 2017, clear and consistent improvements are achieved\nover bare-bone models, up to 8.7% on some of the multi-token mentions. In-depth\nanalyses across several aspects of the improvements, especially the\nidentification of multi-token mentions, are further given.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 03:03:08 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 12:13:21 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Li", "Peng-Hsuan", ""], ["Fu", "Tsu-Jui", ""], ["Ma", "Wei-Yun", ""]]}, {"id": "1910.02610", "submitter": "Jifan Chen", "authors": "Jifan Chen, Shih-ting Lin, Greg Durrett", "title": "Multi-hop Question Answering via Reasoning Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering requires models to gather information from\ndifferent parts of a text to answer a question. Most current approaches learn\nto address this task in an end-to-end way with neural networks, without\nmaintaining an explicit representation of the reasoning process. We propose a\nmethod to extract a discrete reasoning chain over the text, which consists of a\nseries of sentences leading to the answer. We then feed the extracted chains to\na BERT-based QA model to do final answer prediction. Critically, we do not rely\non gold annotated chains or \"supporting facts:\" at training time, we derive\npseudogold reasoning chains using heuristics based on named entity recognition\nand coreference resolution. Nor do we rely on these annotations at test time,\nas our model learns to extract chains from raw text alone. We test our approach\non two recently proposed large multi-hop question answering datasets: WikiHop\nand HotpotQA, and achieve state-of-art performance on WikiHop and strong\nperformance on HotpotQA. Our analysis shows the properties of chains that are\ncrucial for high performance: in particular, modeling extraction sequentially\nis important, as is dealing with each candidate sentence in a context-aware\nway. Furthermore, human evaluation shows that our extracted chains allow humans\nto give answers with high confidence, indicating that these are a strong\nintermediate abstraction for this task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 04:58:43 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 04:29:57 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Jifan", ""], ["Lin", "Shih-ting", ""], ["Durrett", "Greg", ""]]}, {"id": "1910.02612", "submitter": "Yuanpeng Li", "authors": "Yuanpeng Li, Liang Zhao, Jianyu Wang, Joel Hestness", "title": "Compositional Generalization for Primitive Substitutions", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional generalization is a basic mechanism in human language learning,\nbut current neural networks lack such ability. In this paper, we conduct\nfundamental research for encoding compositionality in neural networks.\nConventional methods use a single representation for the input sentence, making\nit hard to apply prior knowledge of compositionality. In contrast, our approach\nleverages such knowledge with two representations, one generating attention\nmaps, and the other mapping attended input words to output symbols. We reduce\nthe entropy in each representation to improve generalization. Our experiments\ndemonstrate significant improvements over the conventional methods in five NLP\ntasks including instruction learning and machine translation. In the SCAN\ndomain, it boosts accuracies from 14.0% to 98.8% in Jump task, and from 92.0%\nto 99.7% in TurnLeft task. It also beats human performance on a few-shot\nlearning task. We hope the proposed approach can help ease future research\ntowards human-level compositional language learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 05:27:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Li", "Yuanpeng", ""], ["Zhao", "Liang", ""], ["Wang", "Jianyu", ""], ["Hestness", "Joel", ""]]}, {"id": "1910.02655", "submitter": "Amir Soleimani", "authors": "Amir Soleimani, Christof Monz, Marcel Worring", "title": "BERT for Evidence Retrieval and Claim Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the promising performance of pre-trained language models, we\ninvestigate BERT in an evidence retrieval and claim verification pipeline for\nthe FEVER fact extraction and verification challenge. To this end, we propose\nto use two BERT models, one for retrieving potential evidence sentences\nsupporting or rejecting claims, and another for verifying claims based on the\npredicted evidence sets. To train the BERT retrieval system, we use pointwise\nand pairwise loss functions, and examine the effect of hard negative mining. A\nsecond BERT model is trained to classify the samples as supported, refuted, and\nnot enough information. Our system achieves a new state of the art recall of\n87.1 for retrieving top five sentences out of the FEVER documents consisting of\n50K Wikipedia pages, and scores second in the official leaderboard with the\nFEVER score of 69.7.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 07:58:26 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Soleimani", "Amir", ""], ["Monz", "Christof", ""], ["Worring", "Marcel", ""]]}, {"id": "1910.02677", "submitter": "Louis Martin", "authors": "Louis Martin, Beno\\^it Sagot, \\'Eric de la Clergerie and Antoine\n  Bordes", "title": "Controllable Sentence Simplification", "comments": "Code and models: https://github.com/facebookresearch/access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text simplification aims at making a text easier to read and understand by\nsimplifying grammar and structure while keeping the underlying information\nidentical. It is often considered an all-purpose generic task where the same\nsimplification is suitable for all; however multiple audiences can benefit from\nsimplified text in different ways. We adapt a discrete parametrization\nmechanism that provides explicit control on simplification systems based on\nSequence-to-Sequence models. As a result, users can condition the\nsimplifications returned by a model on attributes such as length, amount of\nparaphrasing, lexical complexity and syntactic complexity. We also show that\ncarefully chosen values of these attributes allow out-of-the-box\nSequence-to-Sequence models to outperform their standard counterparts on\nsimplification benchmarks. Our model, which we call ACCESS (as shorthand for\nAudienCe-CEntric Sentence Simplification), establishes the state of the art at\n41.87 SARI on the WikiLarge test set, a +1.42 improvement over the best\npreviously reported score.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 09:00:26 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:06:00 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 10:01:39 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Martin", "Louis", ""], ["Sagot", "Beno\u00eet", ""], ["de la Clergerie", "\u00c9ric", ""], ["Bordes", "Antoine", ""]]}, {"id": "1910.02724", "submitter": "Pengfei Li", "authors": "Pengfei Li, Kezhi Mao, Xuefeng Yang, and Qi Li", "title": "Improving Relation Extraction with Knowledge-attention", "comments": "Paper presented at 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "journal-ref": null, "doi": "10.18653/v1/D19-1022", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While attention mechanisms have been proven to be effective in many NLP\ntasks, majority of them are data-driven. We propose a novel knowledge-attention\nencoder which incorporates prior knowledge from external lexical resources into\ndeep neural networks for relation extraction task. Furthermore, we present\nthree effective ways of integrating knowledge-attention with self-attention to\nmaximize the utilization of both knowledge and data. The proposed relation\nextraction system is end-to-end and fully attention-based. Experiment results\nshow that the proposed knowledge-attention mechanism has complementary\nstrengths with self-attention, and our integrated models outperform existing\nCNN, RNN, and self-attention based models. State-of-the-art performance is\nachieved on TACRED, a complex and large-scale relation extraction dataset.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 11:08:24 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 11:55:18 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Li", "Pengfei", ""], ["Mao", "Kezhi", ""], ["Yang", "Xuefeng", ""], ["Li", "Qi", ""]]}, {"id": "1910.02733", "submitter": "Gabriel Marzinotto", "authors": "Gabriel Marzinotto (TALEP), Johannes Heinecke (FT R&D), Geraldine\n  Damnati", "title": "MaskParse@Deskin at SemEval-2019 Task 1: Cross-lingual UCCA Semantic\n  Parsing using Recursive Masked Sequence Tagging", "comments": null, "journal-ref": "Proceedings of the Thirteenth International Workshop on Semantic\n  Evaluation, Jun 2019, Minneapolis, United States", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our recursive system for SemEval-2019 \\textit{ Task 1:\nCross-lingual Semantic Parsing with UCCA}. Each recursive step consists of two\nparts. We first perform semantic parsing using a sequence tagger to estimate\nthe probabilities of the UCCA categories in the sentence. Then, we apply a\ndecoding policy which interprets these probabilities and builds the graph\nnodes. Parsing is done recursively, we perform a first inference on the\nsentence to extract the main scenes and links and then we recursively apply our\nmodel on the sentence using a masking feature that reflects the decisions made\nin previous steps. Process continues until the terminal nodes are reached. We\nchoose a standard neural tagger and we focused on our recursive parsing\nstrategy and on the cross lingual transfer problem to develop a robust model\nfor the French language, using only few training samples.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 11:38:28 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Marzinotto", "Gabriel", "", "TALEP"], ["Heinecke", "Johannes", "", "FT R&D"], ["Damnati", "Geraldine", ""]]}, {"id": "1910.02734", "submitter": "Gabriel Marzinotto", "authors": "Gabriel Marzinotto (TALEP), Geraldine Damnati, Fr\\'ed\\'eric B\\'echet\n  (TALEP)", "title": "Adapting a FrameNet Semantic Parser for Spoken Language Understanding\n  Using Adversarial Learning", "comments": null, "journal-ref": "Interspeech 2019, Sep 2019, Graz, Austria. pp.799-803", "doi": "10.21437/Interspeech.2019-2732", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new semantic frame parsing model, based on Berkeley\nFrameNet, adapted to process spoken documents in order to perform information\nextraction from broadcast contents. Building upon previous work that had shown\nthe effectiveness of adversarial learning for domain generalization in the\ncontext of semantic parsing of encyclopedic written documents, we propose to\nextend this approach to elocutionary style generalization. The underlying\nquestion throughout this study is whether adversarial learning can be used to\ncombine data from different sources and train models on a higher level of\nabstraction in order to increase their robustness to lexical and stylistic\nvariations as well as automatic speech recognition errors. The proposed\nstrategy is evaluated on a French corpus of encyclopedic written documents and\na smaller corpus of radio podcast transcriptions, both annotated with a\nFrameNet paradigm. We show that adversarial learning increases all models\ngeneralization capabilities both on manual and automatic speech transcription\nas well as on encyclopedic data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 11:41:14 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Marzinotto", "Gabriel", "", "TALEP"], ["Damnati", "Geraldine", "", "TALEP"], ["B\u00e9chet", "Fr\u00e9d\u00e9ric", "", "TALEP"]]}, {"id": "1910.02754", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Sang Keun Choe, Quanyang Lu, Yi Xu, Florian Metze", "title": "On Leveraging the Visual Modality for Neural Machine Translation", "comments": "Accepted to INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the visual modality effectively for Neural Machine Translation\n(NMT) remains an open problem in computational linguistics. Recently, Caglayan\net al. posit that the observed gains are limited mainly due to the very simple,\nshort, repetitive sentences of the Multi30k dataset (the only multimodal MT\ndataset available at the time), which renders the source text sufficient for\ncontext. In this work, we further investigate this hypothesis on a new large\nscale multimodal Machine Translation (MMT) dataset, How2, which has 1.57 times\nlonger mean sentence length than Multi30k and no repetition. We propose and\nevaluate three novel fusion techniques, each of which is designed to ensure the\nutilization of visual context at different stages of the Sequence-to-Sequence\ntransduction pipeline, even under full linguistic context. However, we still\nobtain only marginal gains under full linguistic context and posit that visual\nembeddings extracted from deep vision models (ResNet for Multi30k, ResNext for\nHow2) do not lend themselves to increasing the discriminativeness between the\nvocabulary elements at token level prediction in NMT. We demonstrate this\nqualitatively by analyzing attention distribution and quantitatively through\nPrincipal Component Analysis, arriving at the conclusion that it is the quality\nof the visual embeddings rather than the length of sentences, which need to be\nimproved in existing MMT datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:42:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Raunak", "Vikas", ""], ["Choe", "Sang Keun", ""], ["Lu", "Quanyang", ""], ["Xu", "Yi", ""], ["Metze", "Florian", ""]]}, {"id": "1910.02766", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and St\\'ephane Dupont", "title": "Adversarial reconstruction for Multi-modal Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even with the growing interest in problems at the intersection of Computer\nVision and Natural Language, grounding (i.e. identifying) the components of a\nstructured description in an image still remains a challenging task. This\ncontribution aims to propose a model which learns grounding by reconstructing\nthe visual features for the Multi-modal translation task. Previous works have\npartially investigated standard approaches such as regression methods to\napproximate the reconstruction of a visual input. In this paper, we propose a\ndifferent and novel approach which learns grounding by adversarial feedback. To\ndo so, we modulate our network following the recent promising adversarial\narchitectures and evaluate how the adversarial response from a visual\nreconstruction as an auxiliary task helps the model in its learning. We report\nthe highest scores in term of BLEU and METEOR metrics on the different\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 13:08:07 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1910.02789", "submitter": "Guy Tennenholtz", "authors": "Erez Schwartz, Guy Tennenholtz, Chen Tessler, Shie Mannor", "title": "Language is Power: Representing States Using Natural Language in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have shown its potential to tackle\ncomplex real-life tasks. However, as the dimensionality of the task increases,\nreinforcement learning methods tend to struggle. To overcome this, we explore\nmethods for representing the semantic information embedded in the state. While\nprevious methods focused on information in its raw form (e.g., raw visual\ninput), we propose to represent the state using natural language. Language can\nrepresent complex scenarios and concepts, making it a favorable candidate for\nrepresentation. Empirical evidence, within the domain of ViZDoom, suggests that\nnatural language based agents are more robust, converge faster and perform\nbetter than vision based agents, showing the benefit of using natural language\nrepresentations for reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 11:06:17 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 07:16:02 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Schwartz", "Erez", ""], ["Tennenholtz", "Guy", ""], ["Tessler", "Chen", ""], ["Mannor", "Shie", ""]]}, {"id": "1910.02893", "submitter": "Abhijeet Awasthi", "authors": "Abhijeet Awasthi, Sunita Sarawagi, Rasna Goyal, Sabyasachi Ghosh,\n  Vihari Piratla", "title": "Parallel Iterative Edit Models for Local Sequence Transduction", "comments": "Accepted at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Parallel Iterative Edit (PIE) model for the problem of local\nsequence transduction arising in tasks like Grammatical error correction (GEC).\nRecent approaches are based on the popular encoder-decoder (ED) model for\nsequence to sequence learning. The ED model auto-regressively captures full\ndependency among output tokens but is slow due to sequential decoding. The PIE\nmodel does parallel decoding, giving up the advantage of modelling full\ndependency in the output, yet it achieves accuracy competitive with the ED\nmodel for four reasons: 1.~predicting edits instead of tokens, 2.~labeling\nsequences instead of generating sequences, 3.~iteratively refining predictions\nto capture dependencies, and 4.~factorizing logits over edits and their token\nargument to harness pre-trained language models like BERT. Experiments on tasks\nspanning GEC, OCR correction and spell correction demonstrate that the PIE\nmodel is an accurate and significantly faster alternative for local sequence\ntransduction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 16:37:31 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 16:04:00 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Awasthi", "Abhijeet", ""], ["Sarawagi", "Sunita", ""], ["Goyal", "Rasna", ""], ["Ghosh", "Sabyasachi", ""], ["Piratla", "Vihari", ""]]}, {"id": "1910.02902", "submitter": "Vitalii Zhelezniak", "authors": "Vitalii Zhelezniak, April Shen, Daniel Busbridge, Aleksandar Savkov,\n  Nils Hammerla", "title": "Correlations between Word Vector Sets", "comments": "Accepted as a long paper at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity measures based purely on word embeddings are comfortably competing\nwith much more sophisticated deep learning and expert-engineered systems on\nunsupervised semantic textual similarity (STS) tasks. In contrast to commonly\nused geometric approaches, we treat a single word embedding as e.g. 300\nobservations from a scalar random variable. Using this paradigm, we first\nillustrate that similarities derived from elementary pooling operations and\nclassic correlation coefficients yield excellent results on standard STS\nbenchmarks, outperforming many recently proposed methods while being much\nfaster and trivial to implement. Next, we demonstrate how to avoid pooling\noperations altogether and compare sets of word embeddings directly via\ncorrelation operators between reproducing kernel Hilbert spaces. Just like\ncosine similarity is used to compare individual word vectors, we introduce a\nnovel application of the centered kernel alignment (CKA) as a natural\ngeneralisation of squared cosine similarity for sets of word vectors. Likewise,\nCKA is very easy to implement and enjoys very strong empirical results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 16:44:32 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Shen", "April", ""], ["Busbridge", "Daniel", ""], ["Savkov", "Aleksandar", ""], ["Hammerla", "Nils", ""]]}, {"id": "1910.02915", "submitter": "Chaitanya Malaviya", "authors": "Chaitanya Malaviya, Chandra Bhagavatula, Antoine Bosselut, Yejin Choi", "title": "Commonsense Knowledge Base Completion with Structural and Semantic\n  Context", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic KB completion for commonsense knowledge graphs (e.g., ATOMIC and\nConceptNet) poses unique challenges compared to the much studied conventional\nknowledge bases (e.g., Freebase). Commonsense knowledge graphs use free-form\ntext to represent nodes, resulting in orders of magnitude more nodes compared\nto conventional KBs (18x more nodes in ATOMIC compared to Freebase\n(FB15K-237)). Importantly, this implies significantly sparser graph structures\n- a major challenge for existing KB completion methods that assume densely\nconnected graphs over a relatively smaller set of nodes. In this paper, we\npresent novel KB completion models that can address these challenges by\nexploiting the structural and semantic context of nodes. Specifically, we\ninvestigate two key ideas: (1) learning from local graph structure, using graph\nconvolutional networks and automatic graph densification and (2) transfer\nlearning from pre-trained language models to knowledge graphs for enhanced\ncontextual representation of knowledge. We describe our method to incorporate\ninformation from both these sources in a joint model and provide the first\nempirical results for KB completion on ATOMIC and evaluation with ranking\nmetrics on ConceptNet. Our results demonstrate the effectiveness of language\nmodel representations in boosting link prediction performance and the\nadvantages of learning from local graph structure (+1.5 points in MRR for\nConceptNet) when training on subgraphs for computational efficiency. Further\nanalysis on model predictions shines light on the types of commonsense\nknowledge that language models capture well.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:16:04 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 20:02:50 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Malaviya", "Chaitanya", ""], ["Bhagavatula", "Chandra", ""], ["Bosselut", "Antoine", ""], ["Choi", "Yejin", ""]]}, {"id": "1910.02930", "submitter": "Jack Hessel", "authors": "Jack Hessel, Bo Pang, Zhenhai Zhu, Radu Soricut", "title": "A Case Study on Combining ASR and Visual Features for Generating\n  Instructional Video Captions", "comments": null, "journal-ref": "Published in The SIGNLL Conference on Computational Natural\n  Language Learning (CoNLL) 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instructional videos get high-traffic on video sharing platforms, and prior\nwork suggests that providing time-stamped, subtask annotations (e.g., \"heat the\noil in the pan\") improves user experiences. However, current automatic\nannotation methods based on visual features alone perform only slightly better\nthan constant prediction. Taking cues from prior work, we show that we can\nimprove performance significantly by considering automatic speech recognition\n(ASR) tokens as input. Furthermore, jointly modeling ASR tokens and visual\nfeatures results in higher performance compared to training individually on\neither modality. We find that unstated background information is better\nexplained by visual features, whereas fine-grained distinctions (e.g., \"add\noil\" vs. \"add olive oil\") are disambiguated more easily via ASR tokens.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 17:39:39 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hessel", "Jack", ""], ["Pang", "Bo", ""], ["Zhu", "Zhenhai", ""], ["Soricut", "Radu", ""]]}, {"id": "1910.02974", "submitter": "Marcella Cornia", "authors": "Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara", "title": "SMArT: Training Shallow Memory-aware Transformers for Robotic\n  Explainability", "comments": "ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to generate natural language explanations conditioned on the\nvisual perception is a crucial step towards autonomous agents which can explain\nthemselves and communicate with humans. While the research efforts in image and\nvideo captioning are giving promising results, this is often done at the\nexpense of the computational requirements of the approaches, limiting their\napplicability to real contexts. In this paper, we propose a fully-attentive\ncaptioning algorithm which can provide state-of-the-art performances on\nlanguage generation while restricting its computational demands. Our model is\ninspired by the Transformer model and employs only two Transformer layers in\nthe encoding and decoding stages. Further, it incorporates a novel memory-aware\nencoding of image regions. Experiments demonstrate that our approach achieves\ncompetitive results in terms of caption quality while featuring reduced\ncomputational demands. Further, to evaluate its applicability on autonomous\nagents, we conduct experiments on simulated scenes taken from the perspective\nof domestic robots.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:03:14 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 18:15:50 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 14:35:47 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Cornia", "Marcella", ""], ["Baraldi", "Lorenzo", ""], ["Cucchiara", "Rita", ""]]}, {"id": "1910.02993", "submitter": "Daniel Y. Fu", "authors": "Daniel Y. Fu, Will Crichton, James Hong, Xinwei Yao, Haotian Zhang,\n  Anh Truong, Avanika Narayan, Maneesh Agrawala, Christopher R\\'e, Kayvon\n  Fatahalian", "title": "Rekall: Specifying Video Events using Compositions of Spatiotemporal\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world video analysis applications require the ability to identify\ndomain-specific events in video, such as interviews and commercials in TV news\nbroadcasts, or action sequences in film. Unfortunately, pre-trained models to\ndetect all the events of interest in video may not exist, and training new\nmodels from scratch can be costly and labor-intensive. In this paper, we\nexplore the utility of specifying new events in video in a more traditional\nmanner: by writing queries that compose outputs of existing, pre-trained\nmodels. To write these queries, we have developed Rekall, a library that\nexposes a data model and programming model for compositional video event\nspecification. Rekall represents video annotations from different sources\n(object detectors, transcripts, etc.) as spatiotemporal labels associated with\ncontinuous volumes of spacetime in a video, and provides operators for\ncomposing labels into queries that model new video events. We demonstrate the\nuse of Rekall in analyzing video from cable TV news broadcasts, films,\nstatic-camera vehicular video streams, and commercial autonomous vehicle logs.\nIn these efforts, domain experts were able to quickly (in a few hours to a day)\nauthor queries that enabled the accurate detection of new events (on par with,\nand in some cases much more accurate than, learned approaches) and to rapidly\nretrieve video clips for human-in-the-loop tasks such as video content curation\nand training data curation. Finally, in a user study, novice users of Rekall\nwere able to author queries to retrieve new events in video given just one hour\nof query development time.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:18:37 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Fu", "Daniel Y.", ""], ["Crichton", "Will", ""], ["Hong", "James", ""], ["Yao", "Xinwei", ""], ["Zhang", "Haotian", ""], ["Truong", "Anh", ""], ["Narayan", "Avanika", ""], ["Agrawala", "Maneesh", ""], ["R\u00e9", "Christopher", ""], ["Fatahalian", "Kayvon", ""]]}, {"id": "1910.03009", "submitter": "Zhenhao Li", "authors": "Zhenhao Li and Lucia Specia", "title": "Improving Neural Machine Translation Robustness via Data Augmentation:\n  Beyond Back Translation", "comments": "add missing content & references, fix url line break in footnotes", "journal-ref": null, "doi": "10.18653/v1/D19-5543", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models have been proved strong when\ntranslating clean texts, but they are very sensitive to noise in the input.\nImproving NMT models robustness can be seen as a form of \"domain\" adaption to\nnoise. The recently created Machine Translation on Noisy Text task corpus\nprovides noisy-clean parallel data for a few language pairs, but this data is\nvery limited in size and diversity. The state-of-the-art approaches are heavily\ndependent on large volumes of back-translated data. This paper has two main\ncontributions: Firstly, we propose new data augmentation methods to extend\nlimited noisy data and further improve NMT robustness to noise while keeping\nthe models small. Secondly, we explore the effect of utilizing noise from\nexternal data in the form of speech transcripts and show that it could help\nrobustness.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 18:55:32 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 13:13:37 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 23:03:29 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Zhenhao", ""], ["Specia", "Lucia", ""]]}, {"id": "1910.03042", "submitter": "Dian Yu", "authors": "Dian Yu, Michelle Cohn, Yi Mang Yang, Chun-Yen Chen, Weiming Wen,\n  Jiaping Zhang, Mingyang Zhou, Kevin Jesse, Austin Chau, Antara Bhowmick,\n  Shreenath Iyer, Giritheja Sreenivasulu, Sam Davidson, Ashwin Bhandare, Zhou\n  Yu", "title": "Gunrock: A Social Bot for Complex and Engaging Long Conversations", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gunrock is the winner of the 2018 Amazon Alexa Prize, as evaluated by\ncoherence and engagement from both real users and Amazon-selected expert\nconversationalists. We focus on understanding complex sentences and having\nin-depth conversations in open domains. In this paper, we introduce some\ninnovative system designs and related validation analysis. Overall, we found\nthat users produce longer sentences to Gunrock, which are directly related to\nusers' engagement (e.g., ratings, number of turns). Additionally, users'\nbackstory queries about Gunrock are positively correlated to user satisfaction.\nFinally, we found dialog flows that interleave facts and personal opinions and\nstories lead to better user satisfaction.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 19:24:36 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Yu", "Dian", ""], ["Cohn", "Michelle", ""], ["Yang", "Yi Mang", ""], ["Chen", "Chun-Yen", ""], ["Wen", "Weiming", ""], ["Zhang", "Jiaping", ""], ["Zhou", "Mingyang", ""], ["Jesse", "Kevin", ""], ["Chau", "Austin", ""], ["Bhowmick", "Antara", ""], ["Iyer", "Shreenath", ""], ["Sreenivasulu", "Giritheja", ""], ["Davidson", "Sam", ""], ["Bhandare", "Ashwin", ""], ["Yu", "Zhou", ""]]}, {"id": "1910.03065", "submitter": "Oana-Maria Camburu", "authors": "Oana-Maria Camburu, Brendan Shillingford, Pasquale Minervini, Thomas\n  Lukasiewicz, Phil Blunsom", "title": "Make Up Your Mind! Adversarial Generation of Inconsistent Natural\n  Language Explanations", "comments": null, "journal-ref": "Short Paper at ACL, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To increase trust in artificial intelligence systems, a promising research\ndirection consists of designing neural models capable of generating natural\nlanguage explanations for their predictions. In this work, we show that such\nmodels are nonetheless prone to generating mutually inconsistent explanations,\nsuch as \"Because there is a dog in the image\" and \"Because there is no dog in\nthe [same] image\", exposing flaws in either the decision-making process of the\nmodel or in the generation of the explanations. We introduce a simple yet\neffective adversarial framework for sanity checking models against the\ngeneration of inconsistent natural language explanations. Moreover, as part of\nthe framework, we address the problem of adversarial attacks with full target\nsequences, a scenario that was not previously addressed in sequence-to-sequence\nattacks. Finally, we apply our framework on a state-of-the-art neural natural\nlanguage inference model that provides natural language explanations for its\npredictions. Our framework shows that this model is capable of generating a\nsignificant number of inconsistent explanations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 20:14:23 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 14:56:58 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 10:37:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Camburu", "Oana-Maria", ""], ["Shillingford", "Brendan", ""], ["Minervini", "Pasquale", ""], ["Lukasiewicz", "Thomas", ""], ["Blunsom", "Phil", ""]]}, {"id": "1910.03118", "submitter": "Mohamed Nadjib Mami", "authors": "Mohamed Nadjib Mami, Damien Graux, Harsh Thakkar, Simon Scerri,\n  S\\\"oren Auer, Jens Lehmann", "title": "The Query Translation Landscape: a Survey", "comments": "25 pages, 5 tables, 92 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Whereas the availability of data has seen a manyfold increase in past years,\nits value can be only shown if the data variety is effectively tackled ---one\nof the prominent Big Data challenges. The lack of data interoperability limits\nthe potential of its collective use for novel applications. Achieving\ninteroperability through the full transformation and integration of diverse\ndata structures remains an ideal that is hard, if not impossible, to achieve.\nInstead, methods that can simultaneously interpret different types of data\navailable in different data structures and formats have been explored. On the\nother hand, many query languages have been designed to enable users to interact\nwith the data, from relational, to object-oriented, to hierarchical, to the\nmultitude emerging NoSQL languages. Therefore, the interoperability issue could\nbe solved not by enforcing physical data transformation, but by looking at\ntechniques that are able to query heterogeneous sources using one uniform\nlanguage. Both industry and research communities have been keen to develop such\ntechniques, which require the translation of a chosen 'universal' query\nlanguage to the various data model specific query languages that make the\nunderlying data accessible. In this article, we survey more than forty query\ntranslation methods and tools for popular query languages, and classify them\naccording to eight criteria. In particular, we study which query language is a\nmost suitable candidate for that 'universal' query language. Further, the\nresults enable us to discover the weakly addressed and unexplored translation\npaths, to discover gaps and to learn lessons that can benefit future research\nin the area.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 22:37:33 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Mami", "Mohamed Nadjib", ""], ["Graux", "Damien", ""], ["Thakkar", "Harsh", ""], ["Scerri", "Simon", ""], ["Auer", "S\u00f6ren", ""], ["Lehmann", "Jens", ""]]}, {"id": "1910.03136", "submitter": "Xinchi Chen", "authors": "Xinchi Chen, Chunchuan Lyu, Ivan Titov", "title": "Capturing Argument Interaction in Semantic Role Labeling with Capsule\n  Networks", "comments": "11 pages, 6 figures, accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) involves extracting propositions (i.e.\npredicates and their typed arguments) from natural language sentences.\nState-of-the-art SRL models rely on powerful encoders (e.g., LSTMs) and do not\nmodel non-local interaction between arguments. We propose a new approach to\nmodeling these interactions while maintaining efficient inference.\nSpecifically, we use Capsule Networks: each proposition is encoded as a tuple\nof \\textit{capsules}, one capsule per argument type (i.e. role). These tuples\nserve as embeddings of entire propositions. In every network layer, the\ncapsules interact with each other and with representations of words in the\nsentence. Each iteration results in updated proposition embeddings and updated\npredictions about the SRL structure. Our model substantially outperforms the\nnon-refinement baseline model on all 7 CoNLL-2019 languages and achieves\nstate-of-the-art results on 5 languages (including English) for dependency SRL.\nWe analyze the types of mistakes corrected by the refinement procedure. For\nexample, each role is typically (but not always) filled with at most one\nargument. Whereas enforcing this approximate constraint is not useful with the\nmodern SRL system, iterative procedure corrects the mistakes by capturing this\nintuition in a flexible and context-sensitive way.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 23:46:49 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chen", "Xinchi", ""], ["Lyu", "Chunchuan", ""], ["Titov", "Ivan", ""]]}, {"id": "1910.03176", "submitter": "Ta-Chun Su", "authors": "Ta-Chun Su, Hsiang-Chih Cheng", "title": "SesameBERT: Attention for Anywhere", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning with pre-trained models has achieved exceptional results for many\nlanguage tasks. In this study, we focused on one such self-attention network\nmodel, namely BERT, which has performed well in terms of stacking layers across\ndiverse language-understanding benchmarks. However, in many downstream tasks,\ninformation between layers is ignored by BERT for fine-tuning. In addition,\nalthough self-attention networks are well-known for their ability to capture\nglobal dependencies, room for improvement remains in terms of emphasizing the\nimportance of local contexts. In light of these advantages and disadvantages,\nthis paper proposes SesameBERT, a generalized fine-tuning method that (1)\nenables the extraction of global information among all layers through Squeeze\nand Excitation and (2) enriches local information by capturing neighboring\ncontexts via Gaussian blurring. Furthermore, we demonstrated the effectiveness\nof our approach in the HANS dataset, which is used to determine whether models\nhave adopted shallow heuristics instead of learning underlying generalizations.\nThe experiments revealed that SesameBERT outperformed BERT with respect to GLUE\nbenchmark and the HANS evaluation set.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 02:31:35 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Su", "Ta-Chun", ""], ["Cheng", "Hsiang-Chih", ""]]}, {"id": "1910.03177", "submitter": "Rajeev Bhatt Ambati", "authors": "Rajeev Bhatt Ambati, Saptarashmi Bandyopadhyay and Prasenjit Mitra", "title": "Read, Highlight and Summarize: A Hierarchical Neural Semantic\n  Encoder-based Approach", "comments": "Submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional sequence-to-sequence (seq2seq) models and other variations of the\nattention-mechanism such as hierarchical attention have been applied to the\ntext summarization problem. Though there is a hierarchy in the way humans use\nlanguage by forming paragraphs from sentences and sentences from words,\nhierarchical models have usually not worked that much better than their\ntraditional seq2seq counterparts. This effect is mainly because either the\nhierarchical attention mechanisms are too sparse using hard attention or noisy\nusing soft attention. In this paper, we propose a method based on extracting\nthe highlights of a document; a key concept that is conveyed in a few\nsentences. In a typical text summarization dataset consisting of documents that\nare 800 tokens in length (average), capturing long-term dependencies is very\nimportant, e.g., the last sentence can be grouped with the first sentence of a\ndocument to form a summary. LSTMs (Long Short-Term Memory) proved useful for\nmachine translation. However, they often fail to capture long-term dependencies\nwhile modeling long sequences. To address these issues, we have adapted Neural\nSemantic Encoders (NSE) to text summarization, a class of memory-augmented\nneural networks by improving its functionalities and proposed a novel\nhierarchical NSE that outperforms similar previous models significantly. The\nquality of summarization was improved by augmenting linguistic factors, namely\nlemma, and Part-of-Speech (PoS) tags, to each word in the dataset for improved\nvocabulary coverage and generalization. The hierarchical NSE model on factored\ndataset outperformed the state-of-the-art by nearly 4 ROUGE points. We further\ndesigned and used the first GPU-based self-critical Reinforcement Learning\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 02:36:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 04:54:54 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ambati", "Rajeev Bhatt", ""], ["Bandyopadhyay", "Saptarashmi", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "1910.03206", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Shriphani Palakodety, Ashiqur R. KhudaBukhsh, Jaime G. Carbonell", "title": "Voice for the Voiceless: Active Sampling to Detect Comments Supporting\n  the Rohingyas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rohingya refugee crisis is one of the biggest humanitarian crises of\nmodern times with more than 600,000 Rohingyas rendered homeless according to\nthe United Nations High Commissioner for Refugees. While it has received\nsustained press attention globally, no comprehensive research has been\nperformed on social media pertaining to this large evolving crisis. In this\nwork, we construct a substantial corpus of YouTube video comments (263,482\ncomments from 113,250 users in 5,153 relevant videos) with an aim to analyze\nthe possible role of AI in helping a marginalized community. Using a novel\ncombination of multiple Active Learning strategies and a novel active sampling\nstrategy based on nearest-neighbors in the comment-embedding space, we\nconstruct a classifier that can detect comments defending the Rohingyas among\nlarger numbers of disparaging and neutral ones. We advocate that beyond the\nburgeoning field of hate-speech detection, automatic detection of\n\\emph{help-speech} can lend voice to the voiceless people and make the internet\nsafer for marginalized communities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 04:17:33 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 19:33:00 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Palakodety", "Shriphani", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1910.03246", "submitter": "Paul Reisert", "authors": "Paul Reisert, Benjamin Heinzerling, Naoya Inoue, Shun Kiyono and\n  Kentaro Inui", "title": "Riposte! A Large Corpus of Counter-Arguments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructive feedback is an effective method for improving critical thinking\nskills. Counter-arguments (CAs), one form of constructive feedback, have been\nproven to be useful for critical thinking skills. However, little work has been\ndone for constructing a large-scale corpus of them which can drive research on\nautomatic generation of CAs for fallacious micro-level arguments (i.e. a single\nclaim and premise pair). In this work, we cast providing constructive feedback\nas a natural language processing task and create Riposte!, a corpus of CAs,\ntowards this goal. Produced by crowdworkers, Riposte! contains over 18k CAs. We\ninstruct workers to first identify common fallacy types and produce a CA which\nidentifies the fallacy. We analyze how workers create CAs and construct a\nbaseline model based on our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 07:18:58 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Reisert", "Paul", ""], ["Heinzerling", "Benjamin", ""], ["Inoue", "Naoya", ""], ["Kiyono", "Shun", ""], ["Inui", "Kentaro", ""]]}, {"id": "1910.03262", "submitter": "Rishiraj Saha Roy", "authors": "Philipp Christmann, Rishiraj Saha Roy, Abdalghani Abujabal, Jyotsna\n  Singh, Gerhard Weikum", "title": "Look before you Hop: Conversational Question Answering over Knowledge\n  Graphs Using Judicious Context Expansion", "comments": "CIKM 2019 Long Paper, 10 pages", "journal-ref": "CIKM 2019", "doi": "10.1145/3357384.3358016", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact-centric information needs are rarely one-shot; users typically ask\nfollow-up questions to explore a topic. In such a conversational setting, the\nuser's inputs are often incomplete, with entities or predicates left out, and\nungrammatical phrases. This poses a huge challenge to question answering (QA)\nsystems that typically rely on cues in full-fledged interrogative sentences. As\na solution, we develop CONVEX: an unsupervised method that can answer\nincomplete questions over a knowledge graph (KG) by maintaining conversation\ncontext using entities and predicates seen so far and automatically inferring\nmissing or ambiguous pieces for follow-up questions. The core of our method is\na graph exploration algorithm that judiciously expands a frontier to find\ncandidate answers for the current question. To evaluate CONVEX, we release\nConvQuestions, a crowdsourced benchmark with 11,200 distinct conversations from\nfive different domains. We show that CONVEX: (i) adds conversational support to\nany stand-alone QA system, and (ii) outperforms state-of-the-art baselines and\nquestion completion strategies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 07:57:48 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 13:03:19 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 15:42:33 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Christmann", "Philipp", ""], ["Roy", "Rishiraj Saha", ""], ["Abujabal", "Abdalghani", ""], ["Singh", "Jyotsna", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1910.03270", "submitter": "Marco Guerini", "authors": "Y.L. Chung, E. Kuzmenko, S.S. Tekiroglu, M. Guerini", "title": "CONAN -- COunter NArratives through Nichesourcing: a Multilingual\n  Dataset of Responses to Fight Online Hate Speech", "comments": "Published as a long paper at ACL 2019", "journal-ref": "In Proceedings of ACL 2019 (pp. 2819-2829)", "doi": "10.18653/v1/P19-1271", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is an unprecedented effort to provide adequate responses in\nterms of laws and policies to hate content on social media platforms, dealing\nwith hatred online is still a tough problem. Tackling hate speech in the\nstandard way of content deletion or user suspension may be charged with\ncensorship and overblocking. One alternate strategy, that has received little\nattention so far by the research community, is to actually oppose hate content\nwith counter-narratives (i.e. informed textual responses). In this paper, we\ndescribe the creation of the first large-scale, multilingual, expert-based\ndataset of hate speech/counter-narrative pairs. This dataset has been built\nwith the effort of more than 100 operators from three different NGOs that\napplied their training and expertise to the task. Together with the collected\ndata we also provide additional annotations about expert demographics, hate and\nresponse type, and data augmentation through translation and paraphrasing.\nFinally, we provide initial experiments to assess the quality of our data.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:33:56 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chung", "Y. L.", ""], ["Kuzmenko", "E.", ""], ["Tekiroglu", "S. S.", ""], ["Guerini", "M.", ""]]}, {"id": "1910.03291", "submitter": "Alireza Mohammadshahi", "authors": "Alireza Mohammadshahi, Remi Lebret, Karl Aberer", "title": "Aligning Multilingual Word Embeddings for Cross-Modal Retrieval Task", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-6605", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new approach to learn multimodal multilingual\nembeddings for matching images and their relevant captions in two languages. We\ncombine two existing objective functions to make images and captions close in a\njoint embedding space while adapting the alignment of word embeddings between\nexisting languages in our model. We show that our approach enables better\ngeneralization, achieving state-of-the-art performance in text-to-image and\nimage-to-text retrieval task, and caption-caption similarity task. Two\nmultimodal multilingual datasets are used for evaluation: Multi30k with German\nand English captions and Microsoft-COCO with English and Japanese captions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 09:13:39 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Mohammadshahi", "Alireza", ""], ["Lebret", "Remi", ""], ["Aberer", "Karl", ""]]}, {"id": "1910.03320", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi and Matteo Negri and Marco Turchi", "title": "One-To-Many Multilingual End-to-end Speech Translation", "comments": "8 pages, one figure, version accepted at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, training end-to-end neural models for spoken language translation\n(SLT) still has to confront with extreme data scarcity conditions. The existing\nSLT parallel corpora are indeed orders of magnitude smaller than those\navailable for the closely related tasks of automatic speech recognition (ASR)\nand machine translation (MT), which usually comprise tens of millions of\ninstances. To cope with data paucity, in this paper we explore the\neffectiveness of transfer learning in end-to-end SLT by presenting a\nmultilingual approach to the task. Multilingual solutions are widely studied in\nMT and usually rely on ``\\textit{target forcing}'', in which multilingual\nparallel data are combined to train a single model by prepending to the input\nsequences a language token that specifies the target language. However, when\ntested in speech translation, our experiments show that MT-like \\textit{target\nforcing}, used as is, is not effective in discriminating among the target\nlanguages. Thus, we propose a variant that uses target-language embeddings to\nshift the input representations in different portions of the space according to\nthe language, so to better support the production of output in the desired\ntarget language. Our experiments on end-to-end SLT from English into six\nlanguages show important improvements when translating into similar languages,\nespecially when these are supported by scarce data. Further improvements are\nobtained when using English ASR data as an additional language (up to $+2.5$\nBLEU points).\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 10:29:09 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1910.03343", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and Antoine Maiorca and Nathan Hubens and\n  St\\'ephane Dupont", "title": "Modulated Self-attention Convolutional Network for VQA", "comments": "Accepted at NeurIPS 2019 workshop: ViGIL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As new data-sets for real-world visual reasoning and compositional question\nanswering are emerging, it might be needed to use the visual feature extraction\nas a end-to-end process during training. This small contribution aims to\nsuggest new ideas to improve the visual processing of traditional convolutional\nnetwork for visual question answering (VQA). In this paper, we propose to\nmodulate by a linguistic input a CNN augmented with self-attention. We show\nencouraging relative improvements for future research in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 11:28:38 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 16:59:23 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Maiorca", "Antoine", ""], ["Hubens", "Nathan", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1910.03355", "submitter": "Miguel Domingo", "authors": "Miguel Domingo and Francisco Casacuberta", "title": "An Interactive Machine Translation Framework for Modernizing Historical\n  Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the nature of human language, historical documents are hard to\ncomprehend by contemporary people. This limits their accessibility to scholars\nspecialized in the time period in which the documents were written.\nModernization aims at breaking this language barrier by generating a new\nversion of a historical document, written in the modern version of the\ndocument's original language. However, while it is able to increase the\ndocument's comprehension, modernization is still far from producing an\nerror-free version. In this work, we propose a collaborative framework in which\na scholar can work together with the machine to generate the new version. We\ntested our approach on a simulated environment, achieving significant\nreductions of the human effort needed to produce the modernized version of the\ndocument.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 12:15:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Domingo", "Miguel", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1910.03375", "submitter": "Petra Baran\\v{c}\\'ikov\\'a", "authors": "Petra Baran\\v{c}\\'ikov\\'a and Ond\\v{r}ej Bojar", "title": "In Search for Linear Relations in Sentence Embedding Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an introductory investigation into continuous-space vector\nrepresentations of sentences. We acquire pairs of very similar sentences\ndiffering only by a small alterations (such as change of a noun, adding an\nadjective, noun or punctuation) from datasets for natural language inference\nusing a simple pattern method. We look into how such a small change within the\nsentence text affects its representation in the continuous space and how such\nalterations are reflected by some of the popular sentence embedding models. We\nfound that vector differences of some embeddings actually reflect small changes\nwithin a sentence.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:06:01 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Baran\u010d\u00edkov\u00e1", "Petra", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1910.03385", "submitter": "Usama Yaseen", "authors": "Usama Yaseen, Pankaj Gupta, Hinrich Sch\\\"utze", "title": "Linguistically Informed Relation Extraction and Neural Architectures for\n  Nested Named Entity Recognition in BioNLP-OST 2019", "comments": "EMNLP 2019, 11 pages, 4 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) and Relation Extraction (RE) are essential\ntools in distilling knowledge from biomedical literature. This paper presents\nour findings from participating in BioNLP Shared Tasks 2019. We addressed Named\nEntity Recognition including nested entities extraction, Entity Normalization\nand Relation Extraction. Our proposed approach of Named Entities can be\ngeneralized to different languages and we have shown it's effectiveness for\nEnglish and Spanish text. We investigated linguistic features, hybrid loss\nincluding ranking and Conditional Random Fields (CRF), multi-task objective and\ntoken-level ensembling strategy to improve NER. We employed dictionary based\nfuzzy and semantic search to perform Entity Normalization. Finally, our RE\nsystem employed Support Vector Machine (SVM) with linguistic features.\n  Our NER submission (team:MIC-CIS) ranked first in BB-2019 norm+NER task with\nstandard error rate (SER) of 0.7159 and showed competitive performance on\nPharmaCo NER task with F1-score of 0.8662. Our RE system ranked first in the\nSeeDev-binary Relation Extraction Task with F1-score of 0.3738.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:33:48 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Yaseen", "Usama", ""], ["Gupta", "Pankaj", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1910.03387", "submitter": "Manuel Stoeckel", "authors": "Manuel Stoeckel, Wahed Hemati, Alexander Mehler", "title": "When Specialization Helps: Using Pooled Contextualized Embeddings to\n  Detect Chemical and Biomedical Entities in Spanish", "comments": "EMNLP-IJCNLP 2019: International Workshop on BioNLP Open Shared Tasks\n  2019, 5, pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of pharmacological substances, compounds and proteins is an\nessential preliminary work for the recognition of relations between chemicals\nand other biomedically relevant units. In this paper, we describe an approach\nto Task 1 of the PharmaCoNER Challenge, which involves the recognition of\nmentions of chemicals and drugs in Spanish medical texts. We train a\nstate-of-the-art BiLSTM-CRF sequence tagger with stacked Pooled Contextualized\nEmbeddings, word and sub-word embeddings using the open-source framework FLAIR.\nWe present a new corpus composed of articles and papers from Spanish health\nscience journals, termed the Spanish Health Corpus, and use it to train\ndomain-specific embeddings which we incorporate in our model training. We\nachieve a result of 89.76% F1-score using pre-trained embeddings and are able\nto improve these results to 90.52% F1-score using specialized embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:38:39 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Stoeckel", "Manuel", ""], ["Hemati", "Wahed", ""], ["Mehler", "Alexander", ""]]}, {"id": "1910.03401", "submitter": "Jiazuo Qiu", "authors": "Jiazuo Qiu and Deyi Xiong", "title": "Generating Highly Relevant Questions", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural seq2seq based question generation (QG) is prone to generating\ngeneric and undiversified questions that are poorly relevant to the given\npassage and target answer. In this paper, we propose two methods to address the\nissue. (1) By a partial copy mechanism, we prioritize words that are\nmorphologically close to words in the input passage when generating questions;\n(2) By a QA-based reranker, from the n-best list of question candidates, we\nselect questions that are preferred by both the QA and QG model. Experiments\nand analyses demonstrate that the proposed two methods substantially improve\nthe relevance of generated questions to passages and answers.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 13:57:02 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Qiu", "Jiazuo", ""], ["Xiong", "Deyi", ""]]}, {"id": "1910.03432", "submitter": "Ananda Theertha Suresh", "authors": "Mingqing Chen, Ananda Theertha Suresh, Rajiv Mathews, Adeline Wong,\n  Cyril Allauzen, Fran\\c{c}oise Beaufays, Michael Riley", "title": "Federated Learning of N-gram Language Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose algorithms to train production-quality n-gram language models\nusing federated learning. Federated learning is a distributed computation\nplatform that can be used to train global models for portable devices such as\nsmart phones. Federated learning is especially relevant for applications\nhandling privacy-sensitive data, such as virtual keyboards, because training is\nperformed without the users' data ever leaving their devices. While the\nprinciples of federated learning are fairly generic, its methodology assumes\nthat the underlying models are neural networks. However, virtual keyboards are\ntypically powered by n-gram language models for latency reasons.\n  We propose to train a recurrent neural network language model using the\ndecentralized FederatedAveraging algorithm and to approximate this federated\nmodel server-side with an n-gram model that can be deployed to devices for fast\ninference. Our technical contributions include ways of handling large\nvocabularies, algorithms to correct capitalization errors in user data, and\nefficient finite state transducer algorithms to convert word language models to\nword-piece language models and vice versa. The n-gram language models trained\nwith federated learning are compared to n-grams trained with traditional\nserver-based algorithms using A/B tests on tens of millions of users of virtual\nkeyboard. Results are presented for two languages, American English and\nBrazilian Portuguese. This work demonstrates that high-quality n-gram language\nmodels can be trained directly on client mobile devices without sensitive\ntraining data ever leaving the devices.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 14:48:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chen", "Mingqing", ""], ["Suresh", "Ananda Theertha", ""], ["Mathews", "Rajiv", ""], ["Wong", "Adeline", ""], ["Allauzen", "Cyril", ""], ["Beaufays", "Fran\u00e7oise", ""], ["Riley", "Michael", ""]]}, {"id": "1910.03467", "submitter": "Ngo Thi-Vinh", "authors": "Thi-Vinh Ngo, Thanh-Le Ha, Phuong-Thai Nguyen, Le-Minh Nguyen", "title": "Overcoming the Rare Word Problem for Low-Resource Language Pairs in\n  Neural Machine Translation", "comments": null, "journal-ref": "Proceedings of the 6th Workshop on Asian Translation, WAT 2019", "doi": "10.18653/v1/D19-5228", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Among the six challenges of neural machine translation (NMT) coined by (Koehn\nand Knowles, 2017), rare-word problem is considered the most severe one,\nespecially in translation of low-resource languages. In this paper, we propose\nthree solutions to address the rare words in neural machine translation\nsystems. First, we enhance source context to predict the target words by\nconnecting directly the source embeddings to the output of the attention\ncomponent in NMT. Second, we propose an algorithm to learn morphology of\nunknown words for English in supervised way in order to minimize the adverse\neffect of rare-word problem. Finally, we exploit synonymous relation from the\nWordNet to overcome out-of-vocabulary (OOV) problem of NMT. We evaluate our\napproaches on two low-resource language pairs: English-Vietnamese and\nJapanese-Vietnamese. In our experiments, we have achieved significant\nimprovements of up to roughly +1.0 BLEU points in both language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 03:11:13 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:02:55 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ngo", "Thi-Vinh", ""], ["Ha", "Thanh-Le", ""], ["Nguyen", "Phuong-Thai", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1910.03474", "submitter": "Manish Munikar", "authors": "Manish Munikar, Sushil Shakya, Aakash Shrestha", "title": "Fine-grained Sentiment Classification using BERT", "comments": "Submitted to IEEE International Conference on Artificial Intelligence\n  for Transforming Business and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment classification is an important process in understanding people's\nperception towards a product, service, or topic. Many natural language\nprocessing models have been proposed to solve the sentiment classification\nproblem. However, most of them have focused on binary sentiment classification.\nIn this paper, we use a promising deep learning model called BERT to solve the\nfine-grained sentiment classification task. Experiments show that our model\noutperforms other popular models for this task without sophisticated\narchitecture. We also demonstrate the effectiveness of transfer learning in\nnatural language processing in the process.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 09:20:48 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Munikar", "Manish", ""], ["Shakya", "Sushil", ""], ["Shrestha", "Aakash", ""]]}, {"id": "1910.03475", "submitter": "Awais Jumani Khan", "authors": "Awais Khan Jumani, Mashooque Ahmed Memon, Fida Hussain Khoso, Anwar\n  Ali Sanjrani, Safeeullah Soomro", "title": "Named Entity Recognition System for Sindhi Language", "comments": "10 Pages, 3 figures", "journal-ref": null, "doi": "10.1007/978-3-319-95450-9_20", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) System aims to extract the existing\ninformation into the following categories such as: Persons Name, Organization,\nLocation, Date and Time, Term, Designation and Short forms. Now, it is\nconsidered to be important aspect for many natural languages processing (NLP)\ntasks such as: information retrieval system, machine translation system,\ninformation extraction system and question answering. Even at a surface level,\nthe understanding of the named entities involved in a document gives richer\nanalytical framework and cross referencing. It has been used for different\nArabic Script-Based languages like, Arabic, Persian and Urdu but, Sindhi could\nnot come into being yet. This paper explains the problem of NER in the\nframework of Sindhi Language and provides relevant solution. The system is\ndeveloped to tag ten different Named Entities. We have used Ruled based\napproach for NER system of Sindhi Language. For the training and testing, 936\nwords were used and calculated performance accuracy of 98.71%.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 07:45:55 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Jumani", "Awais Khan", ""], ["Memon", "Mashooque Ahmed", ""], ["Khoso", "Fida Hussain", ""], ["Sanjrani", "Anwar Ali", ""], ["Soomro", "Safeeullah", ""]]}, {"id": "1910.03476", "submitter": "Sam Shleifer", "authors": "Sam Shleifer, Manish Chablani, Namit Katariya, Anitha Kannan, Xavier\n  Amatriain", "title": "Classification As Decoder: Trading Flexibility For Control In Neural\n  Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative seq2seq dialogue systems are trained to predict the next word in\ndialogues that have already occurred. They can learn from large unlabeled\nconversation datasets, build a deep understanding of conversational context,\nand generate a wide variety of responses. This flexibility comes at the cost of\ncontrol. Undesirable responses in the training data will be reproduced by the\nmodel at inference time, and longer generations often don't make sense. Instead\nof generating responses one word at a time, we train a classifier to choose\nfrom a predefined list of full responses. The classifier is trained on\n(conversation context, response class) pairs, where each response class is a\nnoisily labeled group of interchangeable responses. At inference, we generate\nthe exemplar response associated with the predicted response class. Experts can\nedit and improve these exemplar responses over time without retraining the\nclassifier or invalidating old training data. Human evaluation of 775 unseen\ndoctor/patient conversations shows that this tradeoff improves responses. Only\n12% of our discriminative approach's responses are worse than the doctor's\nresponse in the same conversational context, compared to 18% for the generative\nmodel. A discriminative model trained without any manual labeling of response\nclasses achieves equal performance to the generative model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 21:04:20 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 23:56:03 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 23:09:14 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shleifer", "Sam", ""], ["Chablani", "Manish", ""], ["Katariya", "Namit", ""], ["Kannan", "Anitha", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1910.03484", "submitter": "Raheel Qader", "authors": "Raheel Qader, Fran\\c{c}ois Portet, Cyril Labb\\'e", "title": "Semi-Supervised Neural Text Generation by Joint Learning of Natural\n  Language Generation and Natural Language Understanding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Generation (NLG), End-to-End (E2E) systems trained\nthrough deep learning have recently gained a strong interest. Such deep models\nneed a large amount of carefully annotated data to reach satisfactory\nperformance. However, acquiring such datasets for every new NLG application is\na tedious and time-consuming task. In this paper, we propose a semi-supervised\ndeep learning scheme that can learn from non-annotated data and annotated data\nwhen available. It uses an NLG and a Natural Language Understanding (NLU)\nsequence-to-sequence models which are learned jointly to compensate for the\nlack of annotation. Experiments on two benchmark datasets show that, with\nlimited amount of annotated data, the method can achieve very competitive\nresults while not using any pre-processing or re-scoring tricks. These findings\nopen the way to the exploitation of non-annotated datasets which is the current\nbottleneck for the E2E NLG system development to new applications.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 11:37:18 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Qader", "Raheel", ""], ["Portet", "Fran\u00e7ois", ""], ["Labb\u00e9", "Cyril", ""]]}, {"id": "1910.03487", "submitter": "Minmin Shen", "authors": "Nikolaos Malandrakis, Minmin Shen, Anuj Goyal, Shuyang Gao, Abhishek\n  Sethi, Angeliki Metallinou", "title": "Controlled Text Generation for Data Augmentation in Intelligent\n  Artificial Agents", "comments": "EMNLP WNGT workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data availability is a bottleneck during early stages of development of new\ncapabilities for intelligent artificial agents. We investigate the use of text\ngeneration techniques to augment the training data of a popular commercial\nartificial agent across categories of functionality, with the goal of faster\ndevelopment of new functionality. We explore a variety of encoder-decoder\ngenerative models for synthetic training data generation and propose using\nconditional variational auto-encoders. Our approach requires only direct\noptimization, works well with limited data and significantly outperforms the\nprevious controlled text generation techniques. Further, the generated data are\nused as additional training samples in an extrinsic intent classification task,\nleading to improved performance by up to 5\\% absolute f-score in low-resource\ncases, validating the usefulness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 20:44:21 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Malandrakis", "Nikolaos", ""], ["Shen", "Minmin", ""], ["Goyal", "Anuj", ""], ["Gao", "Shuyang", ""], ["Sethi", "Abhishek", ""], ["Metallinou", "Angeliki", ""]]}, {"id": "1910.03492", "submitter": "Dan Busbridge", "authors": "Joseph Enguehard, Dan Busbridge, Vitalii Zhelezniak, Nils Hammerla", "title": "Neural Language Priors", "comments": "4 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of sentence encoder architecture reflects assumptions about how a\nsentence's meaning is composed from its constituent words. We examine the\ncontribution of these architectures by holding them randomly initialised and\nfixed, effectively treating them as as hand-crafted language priors, and\nevaluating the resulting sentence encoders on downstream language tasks. We\nfind that even when encoders are presented with additional information that can\nbe used to solve tasks, the corresponding priors do not leverage this\ninformation, except in an isolated case. We also find that apparently\nuninformative priors are just as good as seemingly informative priors on almost\nall tasks, indicating that learning is a necessary component to leverage\ninformation provided by architecture choice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:44:33 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Enguehard", "Joseph", ""], ["Busbridge", "Dan", ""], ["Zhelezniak", "Vitalii", ""], ["Hammerla", "Nils", ""]]}, {"id": "1910.03496", "submitter": "\\'Alvaro Ibrain", "authors": "\\'Alvaro Ibrain Rodr\\'iguez and Lara Lloret Iglesias", "title": "Fake news detection using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n\"fake news\" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 17:45:48 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 05:36:23 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Rodr\u00edguez", "\u00c1lvaro Ibrain", ""], ["Iglesias", "Lara Lloret", ""]]}, {"id": "1910.03498", "submitter": "Dominique Mercier", "authors": "Dominique Mercier, Akansha Bhardwaj, Andreas Dengel, Sheraz Ahmed", "title": "SentiCite: An Approach for Publication Sentiment Analysis", "comments": "Preprint, 8 pages, 2 figures, 10th International Conference on Agents\n  and Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth in the number of scientific publications, year after\nyear, it is becoming increasingly difficult to identify quality authoritative\nwork on a single topic. Though there is an availability of scientometric\nmeasures which promise to offer a solution to this problem, these measures are\nmostly quantitative and rely, for instance, only on the number of times an\narticle is cited. With this approach, it becomes irrelevant if an article is\ncited 10 times in a positive, negative or neutral way. In this context, it is\nquite important to study the qualitative aspect of a citation to understand its\nsignificance. This paper presents a novel system for sentiment analysis of\ncitations in scientific documents (SentiCite) and is also capable of detecting\nnature of citations by targeting the motivation behind a citation, e.g.,\nreference to a dataset, reading reference. Furthermore, the paper also presents\ntwo datasets (SentiCiteDB and IntentCiteDB) containing about 2,600 citations\nwith their ground truth for sentiment and nature of citation. SentiCite along\nwith other state-of-the-art methods for sentiment analysis are evaluated on the\npresented datasets. Evaluation results reveal that SentiCite outperforms\nstate-of-the-art methods for sentiment analysis in scientific publications by\nachieving a F1-measure of 0.71.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 06:49:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Mercier", "Dominique", ""], ["Bhardwaj", "Akansha", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1910.03505", "submitter": "Jinghui Lu", "authors": "Jinghui Lu, Maeve Henchion, Brian Mac Namee", "title": "Investigating the Effectiveness of Representations Based on\n  Word-Embeddings in Active Learning for Labelling Text Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually labelling large collections of text data is a time-consuming,\nexpensive, and laborious task, but one that is necessary to support machine\nlearning based on text datasets. Active learning has been shown to be an\neffective way to alleviate some of the effort required in utilising large\ncollections of unlabelled data for machine learning tasks without needing to\nfully label them. The representation mechanism used to represent text documents\nwhen performing active learning, however, has a significant influence on how\neffective the process will be. While simple vector representations such as bag\nof words have been shown to be an effective way to represent documents during\nactive learning, the emergence of representation mechanisms based on the word\nembeddings prevalent in neural network research (e.g. word2vec and\ntransformer-based models like BERT) offer a promising, and as yet not fully\nexplored, alternative. This paper describes a large-scale evaluation of the\neffectiveness of different text representation mechanisms for active learning\nacross 8 datasets from varied domains. This evaluation shows that using\nrepresentations based on modern word embeddings---especially BERT---, which\nhave not yet been widely used in active learning, achieves a significant\nimprovement over more commonly used vector-based methods like bag of words.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 11:00:36 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 11:15:27 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Lu", "Jinghui", ""], ["Henchion", "Maeve", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1910.03506", "submitter": "Pan Li", "authors": "Pan Li, Alexander Tuzhilin", "title": "Towards Controllable and Personalized Review Generation", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel model RevGAN that automatically generates\ncontrollable and personalized user reviews based on the arbitrarily given\nsentimental and stylistic information. RevGAN utilizes the combination of three\nnovel components, including self-attentive recursive autoencoders, conditional\ndiscriminators, and personalized decoders. We test its performance on the\nseveral real-world datasets, where our model significantly outperforms\nstate-of-the-art generation models in terms of sentence quality, coherence,\npersonalization and human evaluations. We also empirically show that the\ngenerated reviews could not be easily distinguished from the organically\nproduced reviews and that they follow the same statistical linguistics laws.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 19:12:10 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 15:05:45 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Li", "Pan", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "1910.03544", "submitter": "Jianguo Zhang", "authors": "Jian-Guo Zhang, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S.\n  Yu, Richard Socher, Caiming Xiong", "title": "Find or Classify? Dual Strategy for Slot-Value Predictions on\n  Multi-Domain Dialog State Tracking", "comments": "14 pages, accepted at the 9th Joint Conference on Lexical and\n  Computational Semantics (*SEM 2020). This version fixes small errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog state tracking (DST) is a core component in task-oriented dialog\nsystems. Existing approaches for DST mainly fall into one of two categories,\nnamely, ontology-based and ontology-free methods. An ontology-based method\nselects a value from a candidate-value list for each target slot, while an\nontology-free method extracts spans from dialog contexts. Recent work\nintroduced a BERT-based model to strike a balance between the two methods by\npre-defining categorical and non-categorical slots. However, it is not clear\nenough which slots are better handled by either of the two slot types, and the\nway to use the pre-trained model has not been well investigated. In this paper,\nwe propose a simple yet effective dual-strategy model for DST, by adapting a\nsingle BERT-style reading comprehension model to jointly handle both the\ncategorical and non-categorical slots. Our experiments on the MultiWOZ datasets\nshow that our method significantly outperforms the BERT-based counterpart,\nfinding that the key is a deep interaction between the domain-slot and context\ninformation. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1)\nsettings, our method performs competitively and robustly across the two\ndifferent settings. Our method sets the new state of the art in the noisy\nsetting, while performing more robustly than the best model in the cleaner\nsetting. We also conduct a comprehensive error analysis on the dataset,\nincluding the effects of the dual strategy for each slot, to facilitate future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:08:39 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 08:04:12 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 08:37:44 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 10:07:01 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Zhang", "Jian-Guo", ""], ["Hashimoto", "Kazuma", ""], ["Wu", "Chien-Sheng", ""], ["Wan", "Yao", ""], ["Yu", "Philip S.", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1910.03634", "submitter": "Prerna Kashyap", "authors": "Prerna Kashyap, Samrat Phatale, Iddo Drori", "title": "Prose for a Painting", "comments": null, "journal-ref": "ICCV Workshop on Closing the Loop Between Vision and Language,\n  2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Painting captions are often dry and simplistic which motivates us to describe\na painting creatively in the style of Shakespearean prose. This is a difficult\nproblem, since there does not exist a large supervised dataset from paintings\nto Shakespearean prose. Our solution is to use an intermediate English poem\ndescription of the painting and then apply language style transfer which\nresults in Shakespearean prose describing the painting. We rate our results by\nhuman evaluation on a Likert scale, and evaluate the quality of language style\ntransfer using BLEU score as a function of prose length. We demonstrate the\napplicability and limitations of our approach by generating Shakespearean prose\nfor famous paintings. We make our models and code publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:39:49 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kashyap", "Prerna", ""], ["Phatale", "Samrat", ""], ["Drori", "Iddo", ""]]}, {"id": "1910.03641", "submitter": "Haoqi Li", "authors": "Haoqi Li, Brian Baucom and Panayiotis Georgiou", "title": "Linking emotions to behaviors through deep transfer learning", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.HC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human behavior refers to the way humans act and interact. Understanding human\nbehavior is a cornerstone of observational practice, especially in\npsychotherapy. An important cue of behavior analysis is the dynamical changes\nof emotions during the conversation. Domain experts integrate emotional\ninformation in a highly nonlinear manner, thus, it is challenging to explicitly\nquantify the relationship between emotions and behaviors. In this work, we\nemploy deep transfer learning to analyze their inferential capacity and\ncontextual importance. We first train a network to quantify emotions from\nacoustic signals and then use information from the emotion recognition network\nas features for behavior recognition. We treat this emotion-related information\nas behavioral primitives and further train higher level layers towards behavior\nquantification. Through our analysis, we find that emotion-related information\nis an important cue for behavior recognition. Further, we investigate the\nimportance of emotional-context in the expression of behavior by constraining\n(or not) the neural networks' contextual view of the data. This demonstrates\nthat the sequence of emotions is critical in behavior expression. To achieve\nthese frameworks we employ hybrid architectures of convolutional networks and\nrecurrent networks to extract emotion-related behavior primitives and\nfacilitate automatic behavior recognition from speech.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 18:55:08 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Li", "Haoqi", ""], ["Baucom", "Brian", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1910.03655", "submitter": "Alane Suhr", "authors": "Alane Suhr, Claudia Yan, Jacob Schluger, Stanley Yu, Hadi Khader,\n  Marwa Mouallem, Iris Zhang, Yoav Artzi", "title": "Executing Instructions in Situated Collaborative Interactions", "comments": "EMNLP 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a collaborative scenario where a user not only instructs a system to\ncomplete tasks, but also acts alongside it. This allows the user to adapt to\nthe system abilities by changing their language or deciding to simply\naccomplish some tasks themselves, and requires the system to effectively\nrecover from errors as the user strategically assigns it new goals. We build a\ngame environment to study this scenario, and learn to map user instructions to\nsystem actions. We introduce a learning approach focused on recovery from\ncascading errors between instructions, and modeling methods to explicitly\nreason about instructions with multiple goals. We evaluate with a new\nevaluation protocol using recorded interactions and online games with human\nusers, and observe how users adapt to the system abilities.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:22:58 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 14:25:12 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 15:27:46 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Suhr", "Alane", ""], ["Yan", "Claudia", ""], ["Schluger", "Jacob", ""], ["Yu", "Stanley", ""], ["Khader", "Hadi", ""], ["Mouallem", "Marwa", ""], ["Zhang", "Iris", ""], ["Artzi", "Yoav", ""]]}, {"id": "1910.03678", "submitter": "Muhammad Mahbubur Rahman", "authors": "Muhammad Mahbubur Rahman, Tim Finin", "title": "Unfolding the Structure of a Document using Deep Learning", "comments": "16 pages, 16 figures and 10 tables. arXiv admin note: text overlap\n  with arXiv:1709.00770", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and extracting of information from large documents, such as\nbusiness opportunities, academic articles, medical documents and technical\nreports, poses challenges not present in short documents. Such large documents\nmay be multi-themed, complex, noisy and cover diverse topics. We describe a\nframework that can analyze large documents and help people and computer systems\nlocate desired information in them. We aim to automatically identify and\nclassify different sections of documents and understand their purpose within\nthe document. A key contribution of our research is modeling and extracting the\nlogical and semantic structure of electronic documents using deep learning\ntechniques. We evaluate the effectiveness and robustness of our framework\nthrough extensive experiments on two collections: more than one million\nscholarly articles from arXiv and a collection of requests for proposal\ndocuments from government sources.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 21:33:46 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Finin", "Tim", ""]]}, {"id": "1910.03698", "submitter": "Iddo Drori", "authors": "Iddo Drori, Lu Liu, Yi Nian, Sharath C. Koorathota, Jie S. Li, Antonio\n  Khalil Moretti, Juliana Freire, Madeleine Udell", "title": "AutoML using Metadata Language Embeddings", "comments": null, "journal-ref": "NeurIPS Workshop on Meta-Learning, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a human choosing a supervised learning algorithm, it is natural to begin\nby reading a text description of the dataset and documentation for the\nalgorithms you might use. We demonstrate that the same idea improves the\nperformance of automated machine learning methods. We use language embeddings\nfrom modern NLP to improve state-of-the-art AutoML systems by augmenting their\nrecommendations with vector embeddings of datasets and of algorithms. We use\nthese embeddings in a neural architecture to learn the distance between\nbest-performing pipelines. The resulting (meta-)AutoML framework improves on\nthe performance of existing AutoML frameworks. Our zero-shot AutoML system\nusing dataset metadata embeddings provides good solutions instantaneously,\nrunning in under one second of computation. Performance is competitive with\nAutoML systems OBOE, AutoSklearn, AlphaD3M, and TPOT when each framework is\nallocated a minute of computation. We make our data, models, and code publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 21:28:47 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Drori", "Iddo", ""], ["Liu", "Lu", ""], ["Nian", "Yi", ""], ["Koorathota", "Sharath C.", ""], ["Li", "Jie S.", ""], ["Moretti", "Antonio Khalil", ""], ["Freire", "Juliana", ""], ["Udell", "Madeleine", ""]]}, {"id": "1910.03704", "submitter": "Casey Casalnuovo", "authors": "Casey Casalnuovo, Kevin Lee, Hulin Wang, Prem Devanbu, Emily Morgan", "title": "Do People Prefer \"Natural\" code?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IT cs.PL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural code is known to be very repetitive (much more so than natural\nlanguage corpora); furthermore, this repetitiveness persists, even after\naccounting for the simpler syntax of code. However, programming languages are\nvery expressive, allowing a great many different ways (all clear and\nunambiguous) to express even very simple computations. So why is natural code\nrepetitive? We hypothesize that the reasons for this lie in fact that code is\nbimodal: it is executed by machines, but also read by humans. This bimodality,\nwe argue, leads developers to write code in certain preferred ways that would\nbe familiar to code readers. To test this theory, we 1) model familiarity using\na language model estimated over a large training corpus and 2) run an\nexperiment applying several meaning preserving transformations to Java and\nPython expressions in a distinct test corpus to see if forms more familiar to\nreaders (as predicted by the language models) are in fact the ones actually\nwritten. We find that these transformations generally produce program\nstructures that are less common in practice, supporting the theory that the\nhigh repetitiveness in code is a matter of deliberate preference. Finally, 3)\nwe use a human subject study to show alignment between language model score and\nhuman preference for the first time in code, providing support for using this\nmeasure to improve code.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 22:11:55 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Casalnuovo", "Casey", ""], ["Lee", "Kevin", ""], ["Wang", "Hulin", ""], ["Devanbu", "Prem", ""], ["Morgan", "Emily", ""]]}, {"id": "1910.03723", "submitter": "Gustavo Aguilar", "authors": "Gustavo Aguilar, Yuan Ling, Yu Zhang, Benjamin Yao, Xing Fan, Chenlei\n  Guo", "title": "Knowledge Distillation from Internal Representations", "comments": "To appear in AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is typically conducted by training a small model (the\nstudent) to mimic a large and cumbersome model (the teacher). The idea is to\ncompress the knowledge from the teacher by using its output probabilities as\nsoft-labels to optimize the student. However, when the teacher is considerably\nlarge, there is no guarantee that the internal knowledge of the teacher will be\ntransferred into the student; even if the student closely matches the\nsoft-labels, its internal representations may be considerably different. This\ninternal mismatch can undermine the generalization capabilities originally\nintended to be transferred from the teacher to the student. In this paper, we\npropose to distill the internal representations of a large model such as BERT\ninto a simplified version of it. We formulate two ways to distill such\nrepresentations and various algorithms to conduct the distillation. We\nexperiment with datasets from the GLUE benchmark and consistently show that\nadding knowledge distillation from internal representations is a more powerful\nmethod than only using soft-label distillation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 23:56:27 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 14:39:11 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Aguilar", "Gustavo", ""], ["Ling", "Yuan", ""], ["Zhang", "Yu", ""], ["Yao", "Benjamin", ""], ["Fan", "Xing", ""], ["Guo", "Chenlei", ""]]}, {"id": "1910.03739", "submitter": "Diego Garat", "authors": "Diego Garat and Dina Wonsever", "title": "Towards De-identification of Legal Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many countries, personal information that can be published or shared\nbetween organizations is regulated and, therefore, documents must undergo a\nprocess of de-identification to eliminate or obfuscate confidential data. Our\nwork focuses on the de-identification of legal texts, where the goal is to hide\nthe names of the actors involved in a lawsuit without losing the sense of the\nstory. We present a first evaluation on our corpus of NLP tools in tasks such\nas segmentation, tokenization and recognition of named entities, and we analyze\nseveral evaluation measures for our de-identification task. Results are meager:\n84% of the documents have at least one name not covered by NER tools, something\nthat might lead to the re-identification of involved names. We conclude that\ntools must be strongly adapted for processing texts of this particular domain.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:33:29 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Garat", "Diego", ""], ["Wonsever", "Dina", ""]]}, {"id": "1910.03747", "submitter": "Richard Yuanzhe Pang", "authors": "Richard Yuanzhe Pang", "title": "The Daunting Task of Real-World Textual Style Transfer Auto-Evaluation", "comments": "Extended abstract in EMNLP Workshop on Neural Generation and\n  Translation (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of textual style transfer lies in the lack of parallel\ncorpora. Numerous advances have been proposed for the unsupervised generation.\nHowever, significant problems remain with the auto-evaluation of style transfer\ntasks. Based on the summary of Pang and Gimpel (2018) and Mir et al. (2019),\nstyle transfer evaluations rely on three criteria: style accuracy of\ntransferred sentences, content similarity between original and transferred\nsentences, and fluency of transferred sentences. We elucidate the problematic\ncurrent state of style transfer research. Given that current tasks do not\nrepresent real use cases of style transfer, current auto-evaluation approach is\nflawed. This discussion aims to bring researchers to think about the future of\nstyle transfer and style transfer evaluation research.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 01:54:47 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 00:33:34 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Pang", "Richard Yuanzhe", ""]]}, {"id": "1910.03756", "submitter": "Qingyang Wu", "authors": "Qingyang Wu, Yichi Zhang, Yu Li, Zhou Yu", "title": "Alternating Recurrent Dialog Model with Large-scale Pre-trained Language\n  Models", "comments": "EACL 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing dialog system models require extensive human annotations and are\ndifficult to generalize to different tasks. The recent success of large\npre-trained language models such as BERT and GPT-2 (Devlin et al., 2019;\nRadford et al., 2019) have suggested the effectiveness of incorporating\nlanguage priors in down-stream NLP tasks. However, how much pre-trained\nlanguage models can help dialog response generation is still under exploration.\nIn this paper, we propose a simple, general, and effective framework:\nAlternating Roles Dialog Model (ARDM). ARDM models each speaker separately and\ntakes advantage of the large pre-trained language model. It requires no\nsupervision from human annotations such as belief states or dialog acts to\nachieve effective conversations. ARDM outperforms or is on par with\nstate-of-the-art methods on two popular task-oriented dialog datasets:\nCamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging,\nnon-collaborative tasks such as persuasion. In persuasion tasks, ARDM is\ncapable of generating human-like responses to persuade people to donate to a\ncharity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 02:31:37 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 02:01:13 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 19:48:38 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wu", "Qingyang", ""], ["Zhang", "Yichi", ""], ["Li", "Yu", ""], ["Yu", "Zhou", ""]]}, {"id": "1910.03771", "submitter": "Victor Sanh", "authors": "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and\n  Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R\\'emi\n  Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von\n  Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven\n  Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander\n  M. Rush", "title": "HuggingFace's Transformers: State-of-the-art Natural Language Processing", "comments": "8 pages, 4 figures, more details at\n  https://github.com/huggingface/transformers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in natural language processing has been driven by advances in\nboth model architecture and model pretraining. Transformer architectures have\nfacilitated building higher-capacity models and pretraining has made it\npossible to effectively utilize this capacity for a wide variety of tasks.\n\\textit{Transformers} is an open-source library with the goal of opening up\nthese advances to the wider machine learning community. The library consists of\ncarefully engineered state-of-the art Transformer architectures under a unified\nAPI. Backing this library is a curated collection of pretrained models made by\nand available for the community. \\textit{Transformers} is designed to be\nextensible by researchers, simple for practitioners, and fast and robust in\nindustrial deployments. The library is available at\n\\url{https://github.com/huggingface/transformers}.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 03:23:22 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 15:33:45 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 15:36:45 GMT"}, {"version": "v4", "created": "Tue, 11 Feb 2020 14:42:10 GMT"}, {"version": "v5", "created": "Tue, 14 Jul 2020 03:42:34 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Wolf", "Thomas", ""], ["Debut", "Lysandre", ""], ["Sanh", "Victor", ""], ["Chaumond", "Julien", ""], ["Delangue", "Clement", ""], ["Moi", "Anthony", ""], ["Cistac", "Pierric", ""], ["Rault", "Tim", ""], ["Louf", "R\u00e9mi", ""], ["Funtowicz", "Morgan", ""], ["Davison", "Joe", ""], ["Shleifer", "Sam", ""], ["von Platen", "Patrick", ""], ["Ma", "Clara", ""], ["Jernite", "Yacine", ""], ["Plu", "Julien", ""], ["Xu", "Canwen", ""], ["Scao", "Teven Le", ""], ["Gugger", "Sylvain", ""], ["Drame", "Mariama", ""], ["Lhoest", "Quentin", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1910.03806", "submitter": "Samuel R\\\"onnqvist", "authors": "Samuel R\\\"onnqvist, Jenna Kanerva, Tapio Salakoski, Filip Ginter", "title": "Is Multilingual BERT Fluent in Language Generation?", "comments": null, "journal-ref": "In proceedings of the First NLPL Workshop on Deep Learning for\n  Natural Language Processing (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multilingual BERT model is trained on 104 languages and meant to serve as\na universal language model and tool for encoding sentences. We explore how well\nthe model performs on several languages across several tasks: a diagnostic\nclassification probing the embeddings for a particular syntactic property, a\ncloze task testing the language modelling ability to fill in gaps in a\nsentence, and a natural language generation task testing for the ability to\nproduce coherent text fitting a given context. We find that the currently\navailable multilingual BERT model is clearly inferior to the monolingual\ncounterparts, and cannot in many cases serve as a substitute for a well-trained\nmonolingual model. We find that the English and German models perform well at\ngeneration, whereas the multilingual model is lacking, in particular, for\nNordic languages.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:35:59 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["R\u00f6nnqvist", "Samuel", ""], ["Kanerva", "Jenna", ""], ["Salakoski", "Tapio", ""], ["Ginter", "Filip", ""]]}, {"id": "1910.03814", "submitter": "Raul Gomez", "authors": "Raul Gomez, Jaume Gibert, Lluis Gomez, Dimosthenis Karatzas", "title": "Exploring Hate Speech Detection in Multimodal Publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we target the problem of hate speech detection in multimodal\npublications formed by a text and an image. We gather and annotate a large\nscale dataset from Twitter, MMHS150K, and propose different models that jointly\nanalyze textual and visual information for hate speech detection, comparing\nthem with unimodal detection. We provide quantitative and qualitative results\nand analyze the challenges of the proposed task. We find that, even though\nimages are useful for the hate speech detection task, current multimodal models\ncannot outperform models analyzing only text. We discuss why and open the field\nand the dataset for further research.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:53:39 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Gomez", "Raul", ""], ["Gibert", "Jaume", ""], ["Gomez", "Lluis", ""], ["Karatzas", "Dimosthenis", ""]]}, {"id": "1910.03833", "submitter": "Yubei Chen", "authors": "Juexiao Zhang, Yubei Chen, Brian Cheung, Bruno A Olshausen", "title": "Word Embedding Visualization Via Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-occurrence statistics based word embedding techniques have proved to be\nvery useful in extracting the semantic and syntactic representation of words as\nlow dimensional continuous vectors. In this work, we discovered that dictionary\nlearning can open up these word vectors as a linear combination of more\nelementary word factors. We demonstrate many of the learned factors have\nsurprisingly strong semantic or syntactic meaning corresponding to the factors\npreviously identified manually by human inspection. Thus dictionary learning\nprovides a powerful visualization tool for understanding word embedding\nrepresentations. Furthermore, we show that the word factors can help in\nidentifying key semantic and syntactic differences in word analogy tasks and\nimprove upon the state-of-the-art word embedding techniques in these tasks by a\nlarge margin.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 08:14:48 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 09:57:44 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhang", "Juexiao", ""], ["Chen", "Yubei", ""], ["Cheung", "Brian", ""], ["Olshausen", "Bruno A", ""]]}, {"id": "1910.03891", "submitter": "Wenqiang Liu", "authors": "Wenqiang Liu, Hongyun Cai, Xu Cheng, Sifa Xie, Yipeng Yu, Hanyu Zhang", "title": "Learning High-order Structural and Attribute information by Knowledge\n  Graph Attention Networks for Enhancing Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of representation learning of knowledge graph is to encode both\nentities and relations into a low-dimensional embedding spaces. Many recent\nworks have demonstrated the benefits of knowledge graph embedding on knowledge\ngraph completion task, such as relation extraction. However, we observe that:\n1) existing method just take direct relations between entities into\nconsideration and fails to express high-order structural relationship between\nentities; 2) these methods just leverage relation triples of KGs while ignoring\na large number of attribute triples that encoding rich semantic information. To\novercome these limitations, this paper propose a novel knowledge graph\nembedding method, named KANE, which is inspired by the recent developments of\ngraph convolutional networks (GCN). KANE can capture both high-order structural\nand attribute information of KGs in an efficient, explicit and unified manner\nunder the graph convolutional networks framework. Empirical results on three\ndatasets show that KANE significantly outperforms seven state-of-arts methods.\nFurther analysis verify the efficiency of our method and the benefits brought\nby the attention mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:33:59 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 02:58:00 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Liu", "Wenqiang", ""], ["Cai", "Hongyun", ""], ["Cheng", "Xu", ""], ["Xie", "Sifa", ""], ["Yu", "Yipeng", ""], ["Zhang", "Hanyu", ""]]}, {"id": "1910.03912", "submitter": "Evgeny Matusov", "authors": "Patrick Wilken and Evgeny Matusov", "title": "Novel Applications of Factored Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore the usefulness of target factors in neural machine\ntranslation (NMT) beyond their original purpose of predicting word lemmas and\ntheir inflections, as proposed by Garc\\`ia-Mart\\`inez et al., 2016. For this,\nwe introduce three novel applications of the factored output architecture: In\nthe first one, we use a factor to explicitly predict the word case separately\nfrom the target word itself. This allows for information to be shared between\ndifferent casing variants of a word. In a second task, we use a factor to\npredict when two consecutive subwords have to be joined, eliminating the need\nfor target subword joining markers. The third task is the prediction of special\ntokens of the operation sequence NMT model (OSNMT) of Stahlberg et al., 2018.\nAutomatic evaluation on English-to-German and English-to-Turkish tasks showed\nthat integration of such auxiliary prediction tasks into NMT is at least as\ngood as the standard NMT approach. For the OSNMT, we observed a significant\nimprovement in BLEU over the baseline OSNMT implementation due to a reduced\noutput sequence length that resulted from the introduction of the target\nfactors.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 11:45:07 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wilken", "Patrick", ""], ["Matusov", "Evgeny", ""]]}, {"id": "1910.03940", "submitter": "Mamdouh Farouk", "authors": "Mamdouh Farouk", "title": "Measuring Sentences Similarity: A Survey", "comments": "11 pages, 2 figures, journal", "journal-ref": "Indian Journal of Science and Technology, Vol 12(25), July 2019", "doi": "10.17485/ijst/2019/v12i25/143977", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study is to review the approaches used for measuring sentences\nsimilarity. Measuring similarity between natural language sentences is a\ncrucial task for many Natural Language Processing applications such as text\nclassification, information retrieval, question answering, and plagiarism\ndetection. This survey classifies approaches of calculating sentences\nsimilarity based on the adopted methodology into three categories. Word-to-word\nbased, structure based, and vector-based are the most widely used approaches to\nfind sentences similarity. Each approach measures relatedness between short\ntexts based on a specific perspective. In addition, datasets that are mostly\nused as benchmarks for evaluating techniques in this field are introduced to\nprovide a complete view on this issue. The approaches that combine more than\none perspective give better results. Moreover, structure based similarity that\nmeasures similarity between sentences structures needs more investigation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 09:21:21 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Farouk", "Mamdouh", ""]]}, {"id": "1910.03943", "submitter": "Ali Sadeghian", "authors": "Ali Sadeghian, Shervin Minaee, Ioannis Partalas, Xinxin Li, Daisy Zhe\n  Wang, Brooke Cowan", "title": "Hotel2vec: Learning Attribute-Aware Hotel Embeddings with\n  Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network architecture for learning vector representations\nof hotels. Unlike previous works, which typically only use user click\ninformation for learning item embeddings, we propose a framework that combines\nseveral sources of data, including user clicks, hotel attributes (e.g.,\nproperty type, star rating, average user rating), amenity information (e.g.,\nthe hotel has free Wi-Fi or free breakfast), and geographic information. During\nmodel training, a joint embedding is learned from all of the above information.\nWe show that including structured attributes about hotels enables us to make\nbetter predictions in a downstream task than when we rely exclusively on click\ndata. We train our embedding model on more than 40 million user click sessions\nfrom a leading online travel platform and learn embeddings for more than one\nmillion hotels. Our final learned embeddings integrate distinct sub-embeddings\nfor user clicks, hotel attributes, and geographic information, providing an\ninterpretable representation that can be used flexibly depending on the\napplication. We show empirically that our model generates high-quality\nrepresentations that boost the performance of a hotel recommendation system in\naddition to other applications. An important advantage of the proposed neural\nmodel is that it addresses the cold-start problem for hotels with insufficient\nhistorical click information by incorporating additional hotel attributes which\nare available for all hotels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 23:47:55 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Sadeghian", "Ali", ""], ["Minaee", "Shervin", ""], ["Partalas", "Ioannis", ""], ["Li", "Xinxin", ""], ["Wang", "Daisy Zhe", ""], ["Cowan", "Brooke", ""]]}, {"id": "1910.04006", "submitter": "Eben Holderness", "authors": "Elena Alvarez-Mellado, Eben Holderness, Nicholas Miller, Fyonn Dhang,\n  Philip Cawkwell, Kirsten Bolton, James Pustejovsky, Mei-Hua Hall", "title": "Assessing the Efficacy of Clinical Sentiment Analysis and Topic\n  Extraction in Psychiatric Readmission Risk Prediction", "comments": "LOUHI @ EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting which patients are more likely to be readmitted to a hospital\nwithin 30 days after discharge is a valuable piece of information in clinical\ndecision-making. Building a successful readmission risk classifier based on the\ncontent of Electronic Health Records (EHRs) has proved, however, to be a\nchallenging task. Previously explored features include mainly structured\ninformation, such as sociodemographic data, comorbidity codes and physiological\nvariables. In this paper we assess incorporating additional clinically\ninterpretable NLP-based features such as topic extraction and clinical\nsentiment analysis to predict early readmission risk in psychiatry patients.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:10:47 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Alvarez-Mellado", "Elena", ""], ["Holderness", "Eben", ""], ["Miller", "Nicholas", ""], ["Dhang", "Fyonn", ""], ["Cawkwell", "Philip", ""], ["Bolton", "Kirsten", ""], ["Pustejovsky", "James", ""], ["Hall", "Mei-Hua", ""]]}, {"id": "1910.04023", "submitter": "Ignacio Arroyo-Fern\\'andez", "authors": "Ignacio Arroyo-Fern\\'andez and Mauricio Carrasco-Ru\\'iz and J. Anibal\n  Arias-Aguilar", "title": "On the Possibility of Rewarding Structure Learning Agents: Mutual\n  Information on Linguistic Random Sets", "comments": "Paper accepted to the Workshop on Sets & Partitions (NeurIPS 2019,\n  Vancouver, Canada)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a first attempt to elucidate a theoretical and empirical approach\nto design the reward provided by a natural language environment to some\nstructure learning agent. To this end, we revisit the Information Theory of\nunsupervised induction of phrase-structure grammars to characterize the\nbehavior of simulated actions modeled as set-valued random variables (random\nsets of linguistic samples) constituting semantic structures. Our results\nshowed empirical evidence of that simulated semantic structures (Open\nInformation Extraction triplets) can be distinguished from randomly constructed\nones by observing the Mutual Information among their constituents. This\nsuggests the possibility of rewarding structure learning agents without using\npretrained structural analyzers (oracle actors/experts).\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 14:33:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 01:34:52 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 01:48:19 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 16:56:56 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Arroyo-Fern\u00e1ndez", "Ignacio", ""], ["Carrasco-Ru\u00edz", "Mauricio", ""], ["Arias-Aguilar", "J. Anibal", ""]]}, {"id": "1910.04056", "submitter": "Saida Mahmoud", "authors": "Marco Menardi, Alex Falcon, Saida S.Mohamed, Lorenzo Seidenari,\n  Giuseppe Serra, Alberto Del Bimbo and Carlo Tasso", "title": "Text-to-Image Synthesis Based on Machine Generated Captions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text to Image Synthesis refers to the process of automatic generation of a\nphoto-realistic image starting from a given text and is revolutionizing many\nreal-world applications. In order to perform such process it is necessary to\nexploit datasets containing captioned images, meaning that each image is\nassociated with one (or more) captions describing it. Despite the abundance of\nuncaptioned images datasets, the number of captioned datasets is limited. To\naddress this issue, in this paper we propose an approach capable of generating\nimages starting from a given text using conditional GANs trained on uncaptioned\nimages dataset. In particular, uncaptioned images are fed to an Image\nCaptioning Module to generate the descriptions. Then, the GAN Module is trained\non both the input image and the machine-generated caption. To evaluate the\nresults, the performance of our solution is compared with the results obtained\nby the unconditional GAN. For the experiments, we chose to use the uncaptioned\ndataset LSUN bedroom. The results obtained in our study are preliminary but\nstill promising.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:14:09 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Menardi", "Marco", ""], ["Falcon", "Alex", ""], ["Mohamed", "Saida S.", ""], ["Seidenari", "Lorenzo", ""], ["Serra", "Giuseppe", ""], ["Del Bimbo", "Alberto", ""], ["Tasso", "Carlo", ""]]}, {"id": "1910.04073", "submitter": "Rajat Maheshwari", "authors": "Yaman Kumar, Debanjan Mahata, Sagar Aggarwal, Anmol Chugh, Rajat\n  Maheshwari, Rajiv Ratn Shah", "title": "BHAAV- A Text Corpus for Emotion Analysis from Hindi Stories", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.3457467", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the first and largest Hindi text corpus, named\nBHAAV, which means emotions in Hindi, for analyzing emotions that a writer\nexpresses through his characters in a story, as perceived by a narrator/reader.\nThe corpus consists of 20,304 sentences collected from 230 different short\nstories spanning across 18 genres such as Inspirational and Mystery. Each\nsentence has been annotated into one of the five emotion categories - anger,\njoy, suspense, sad, and neutral, by three native Hindi speakers with at least\nten years of formal education in Hindi. We also discuss challenges in the\nannotation of low resource languages such as Hindi, and discuss the scope of\nthe proposed corpus along with its possible uses. We also provide a detailed\nanalysis of the dataset and train strong baseline classifiers reporting their\nperformances.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:42:25 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kumar", "Yaman", ""], ["Mahata", "Debanjan", ""], ["Aggarwal", "Sagar", ""], ["Chugh", "Anmol", ""], ["Maheshwari", "Rajat", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1910.04176", "submitter": "Varun Kumar", "authors": "Varun Kumar, Hadrien Glaude, Cyprien de Lichy, William Campbell", "title": "A Closer Look At Feature Space Data Augmentation For Few-Shot Intent\n  Classification", "comments": "Accepted at Deep Learning for low-resource NLP workshop @ EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  New conversation topics and functionalities are constantly being added to\nconversational AI agents like Amazon Alexa and Apple Siri. As data collection\nand annotation is not scalable and is often costly, only a handful of examples\nfor the new functionalities are available, which results in poor generalization\nperformance. We formulate it as a Few-Shot Integration (FSI) problem where a\nfew examples are used to introduce a new intent. In this paper, we study six\nfeature space data augmentation methods to improve classification performance\nin FSI setting in combination with both supervised and unsupervised\nrepresentation learning methods such as BERT. Through realistic experiments on\ntwo public conversational datasets, SNIPS, and the Facebook Dialog corpus, we\nshow that data augmentation in feature space provides an effective way to\nimprove intent classification performance in few-shot setting beyond\ntraditional transfer learning approaches. In particular, we show that (a)\nupsampling in latent space is a competitive baseline for feature space\naugmentation (b) adding the difference between two examples to a new example is\na simple yet effective data augmentation method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:00:04 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Kumar", "Varun", ""], ["Glaude", "Hadrien", ""], ["de Lichy", "Cyprien", ""], ["Campbell", "William", ""]]}, {"id": "1910.04192", "submitter": "Clara McCreery", "authors": "Clara McCreery, Namit Katariya, Anitha Kannan, Manish Chablani, Xavier\n  Amatriain", "title": "Domain-Relevant Embeddings for Medical Question Similarity", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rate at which medical questions are asked online far exceeds the capacity\nof qualified people to answer them, and many of these questions are not unique.\nIdentifying same-question pairs could enable questions to be answered more\neffectively. While many research efforts have focused on the problem of general\nquestion similarity for non-medical applications, these approaches do not\ngeneralize well to the medical domain, where medical expertise is often\nrequired to determine semantic similarity. In this paper, we show how a\nsemi-supervised approach of pre-training a neural network on medical\nquestion-answer pairs is a particularly useful intermediate task for the\nultimate goal of determining medical question similarity. While other\npre-training tasks yield an accuracy below 78.7% on this task, our model\nachieves an accuracy of 82.6% with the same number of training examples, and an\naccuracy of 80.0% with a much smaller training set.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:19:48 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:06:47 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["McCreery", "Clara", ""], ["Katariya", "Namit", ""], ["Kannan", "Anitha", ""], ["Chablani", "Manish", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1910.04196", "submitter": "Eunah Cho", "authors": "Eunah Cho, He Xie, John P. Lalor, Varun Kumar, William M. Campbell", "title": "Efficient Semi-Supervised Learning for Natural Language Understanding by\n  Optimizing Diversity", "comments": "IEEE Copyright. To appear at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding new functionalities efficiently is an ongoing challenge for\nsingle-turn task-oriented dialogue systems. In this work, we explore\nfunctionality-specific semi-supervised learning via self-training. We consider\nmethods that augment training data automatically from unlabeled data sets in a\nfunctionality-targeted manner. In addition, we examine multiple techniques for\nefficient selection of augmented utterances to reduce training time and\nincrease diversity. First, we consider paraphrase detection methods that\nattempt to find utterance variants of labeled training data with good coverage.\nSecond, we explore sub-modular optimization based on n-grams features for\nutterance selection. Experiments show that functionality-specific self-training\nis very effective for improving system performance. In addition, methods\noptimizing diversity can reduce training data in many cases to 50% with little\nimpact on performance.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 18:34:17 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Cho", "Eunah", ""], ["Xie", "He", ""], ["Lalor", "John P.", ""], ["Kumar", "Varun", ""], ["Campbell", "William M.", ""]]}, {"id": "1910.04210", "submitter": "Vinodkumar Prabhakaran", "authors": "Vinodkumar Prabhakaran, Ben Hutchinson, Margaret Mitchell", "title": "Perturbation Sensitivity Analysis to Detect Unintended Model Biases", "comments": "EMNLP 2019 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data-driven statistical Natural Language Processing (NLP) techniques leverage\nlarge amounts of language data to build models that can understand language.\nHowever, most language data reflect the public discourse at the time the data\nwas produced, and hence NLP models are susceptible to learning incidental\nassociations around named referents at a particular point in time, in addition\nto general linguistic meaning. An NLP system designed to model notions such as\nsentiment and toxicity should ideally produce scores that are independent of\nthe identity of such entities mentioned in text and their social associations.\nFor example, in a general purpose sentiment analysis system, a phrase such as I\nhate Katy Perry should be interpreted as having the same sentiment as I hate\nTaylor Swift. Based on this idea, we propose a generic evaluation framework,\nPerturbation Sensitivity Analysis, which detects unintended model biases\nrelated to named entities, and requires no new annotations or corpora. We\ndemonstrate the utility of this analysis by employing it on two different NLP\nmodels --- a sentiment model and a toxicity model --- applied on online\ncomments in English language from four different genres.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:25:21 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Prabhakaran", "Vinodkumar", ""], ["Hutchinson", "Ben", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1910.04269", "submitter": "Govind Mittal", "authors": "Sarthak, Shikhar Shukla, Govind Mittal", "title": "Spoken Language Identification using ConvNets", "comments": "2019 European Conference on Ambient Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language Identification (LI) is an important first step in several speech\nprocessing systems. With a growing number of voice-based assistants, speech LI\nhas emerged as a widely researched field. To approach the problem of\nidentifying languages, we can either adopt an implicit approach where only the\nspeech for a language is present or an explicit one where text is available\nwith its corresponding transcript. This paper focuses on an implicit approach\ndue to the absence of transcriptive data. This paper benchmarks existing models\nand proposes a new attention based model for language identification which uses\nlog-Mel spectrogram images as input. We also present the effectiveness of raw\nwaveforms as features to neural network models for LI tasks. For training and\nevaluation of models, we classified six languages (English, French, German,\nSpanish, Russian and Italian) with an accuracy of 95.4% and four languages\n(English, French, German, Spanish) with an accuracy of 96.3% obtained from the\nVoxForge dataset. This approach can further be scaled to incorporate more\nlanguages.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 21:43:36 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Sarthak", "", ""], ["Shukla", "Shikhar", ""], ["Mittal", "Govind", ""]]}, {"id": "1910.04289", "submitter": "Bill Yuchen Lin", "authors": "Ouyu Lan, Xiao Huang, Bill Yuchen Lin, He Jiang, Liyuan Liu, Xiang Ren", "title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence\n  Labeling", "comments": "Accepted to the ACL 2020, code: https://github.com/INK-USC/ConNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling is a fundamental framework for various natural language\nprocessing problems. Its performance is largely influenced by the annotation\nquality and quantity in supervised learning scenarios, and obtaining ground\ntruth labels is often costly. In many cases, ground truth labels do not exist,\nbut noisy annotations or annotations from different domains are accessible. In\nthis paper, we propose a novel framework Consensus Network (ConNet) that can be\ntrained on annotations from multiple sources (e.g., crowd annotation,\ncross-domain data...). It learns individual representation for every source and\ndynamically aggregates source-specific knowledge by a context-aware attention\nmodule. Finally, it leads to a model reflecting the agreement (consensus) among\nmultiple sources. We evaluate the proposed framework in two practical settings\nof multi-source learning: learning with crowd annotations and unsupervised\ncross-domain model adaptation. Extensive experimental results show that our\nmodel achieves significant improvements over existing methods in both settings.\nWe also demonstrate that the method can apply to various tasks and cope with\ndifferent encoders.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 22:54:43 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 07:21:02 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lan", "Ouyu", ""], ["Huang", "Xiao", ""], ["Lin", "Bill Yuchen", ""], ["Jiang", "He", ""], ["Liu", "Liyuan", ""], ["Ren", "Xiang", ""]]}, {"id": "1910.04345", "submitter": "Wanzheng Zhu", "authors": "Wanzheng Zhu, Hongyu Gong, Jiaming Shen, Chao Zhang, Jingbo Shang,\n  Suma Bhat, Jiawei Han", "title": "FUSE: Multi-Faceted Set Expansion by Coherent Clustering of Skip-grams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set expansion aims to expand a small set of seed entities into a complete set\nof relevant entities. Most existing approaches assume the input seed set is\nunambiguous and completely ignore the multi-faceted semantics of seed entities.\nAs a result, given the seed set {\"Canon\", \"Sony\", \"Nikon\"}, previous models\nreturn one mixed set of entities that are either Camera Brands or Japanese\nCompanies. In this paper, we study the task of multi-faceted set expansion,\nwhich aims to capture all semantic facets in the seed set and return multiple\nsets of entities, one for each semantic facet. We propose an unsupervised\nframework, FUSE, which consists of three major components: (1) facet discovery\nmodule: identifies all semantic facets of each seed entity by extracting and\nclustering its skip-grams, and (2) facet fusion module: discovers shared\nsemantic facets of the entire seed set by an optimization formulation, and (3)\nentity expansion module: expands each semantic facet by utilizing a masked\nlanguage model with pre-trained BERT models. Extensive experiments demonstrate\nthat FUSE can accurately identify multiple semantic facets of the seed set and\ngenerate quality entities for each facet.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 03:06:46 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 22:12:29 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:30:06 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Zhu", "Wanzheng", ""], ["Gong", "Hongyu", ""], ["Shen", "Jiaming", ""], ["Zhang", "Chao", ""], ["Shang", "Jingbo", ""], ["Bhat", "Suma", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.04385", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee, Jongyeong Lee, Yiping Jin, Dittaya Wanvarie,\n  Masashi Sugiyama", "title": "Learning Only from Relevant Keywords and Unlabeled Documents", "comments": "EMNLP-IJCNLP2019, fix typos in Theorem 1: change $\\pi$ and $\\pi'$ to\n  $\\theta$ and $\\theta'$", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a document classification problem where document labels are\nabsent but only relevant keywords of a target class and unlabeled documents are\ngiven. Although heuristic methods based on pseudo-labeling have been\nconsidered, theoretical understanding of this problem has still been limited.\nMoreover, previous methods cannot easily incorporate well-developed techniques\nin supervised text classification. In this paper, we propose a theoretically\nguaranteed learning framework that is simple to implement and has flexible\nchoices of models, e.g., linear models or neural networks. We demonstrate how\nto optimize the area under the receiver operating characteristic curve (AUC)\neffectively and also discuss how to adjust it to optimize other well-known\nevaluation metrics such as the accuracy and F1-measure. Finally, we show the\neffectiveness of our framework using benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:29:22 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 03:40:51 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Lee", "Jongyeong", ""], ["Jin", "Yiping", ""], ["Wanvarie", "Dittaya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.04387", "submitter": "Jonathan Mallinson", "authors": "Jonathan Mallinson and Mirella Lapata", "title": "Controllable Sentence Simplification: Employing Syntactic and Lexical\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification aims to make sentences easier to read and understand.\nRecent approaches have shown promising results with sequence-to-sequence models\nwhich have been developed assuming homogeneous target audiences. In this paper\nwe argue that different users have different simplification needs (e.g.\ndyslexics vs. non-native speakers), and propose CROSS, ContROllable Sentence\nSimplification model, which allows to control both the level of simplicity and\nthe type of the simplification. We achieve this by enriching a\nTransformer-based architecture with syntactic and lexical constraints (which\ncan be set or learned from data). Empirical results on two benchmark datasets\nshow that constraints are key to successful simplification, offering flexible\ngeneration output.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 06:37:36 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Mallinson", "Jonathan", ""], ["Lapata", "Mirella", ""]]}, {"id": "1910.04424", "submitter": "Boris Ruf", "authors": "Boris Ruf, Matteo Sammarco, Marcin Detyniecki", "title": "Contract Statements Knowledge Service for Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards conversational agents that are capable of handling more complex\nquestions on contractual conditions, formalizing contract statements in a\nmachine readable way is crucial. However, constructing a formal model which\ncaptures the full scope of a contract proves difficult due to the overall\ncomplexity its set of rules represent. Instead, this paper presents a top-down\napproach to the problem. After identifying the most relevant contract\nstatements, we model their underlying rules in a novel knowledge engineering\nmethod. A user-friendly tool we developed for this purpose allows to do so\neasily and at scale. Then, we expose the statements as service so they can get\nsmoothly integrated in any chatbot framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 08:25:42 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Ruf", "Boris", ""], ["Sammarco", "Matteo", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1910.04519", "submitter": "Patrick Schrempf", "authors": "Mattias Appelgren, Patrick Schrempf, Mat\\'u\\v{s} Falis, Satoshi Ikeda,\n  Alison Q O'Neil", "title": "Language Transfer for Early Warning of Epidemics from Social Media", "comments": "Artificial Intelligence for Humanitarian Assistance and Disaster\n  Response Workshop (AI+HADR) at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statements on social media can be analysed to identify individuals who are\nexperiencing red flag medical symptoms, allowing early detection of the spread\nof disease such as influenza. Since disease does not respect cultural borders\nand may spread between populations speaking different languages, we would like\nto build multilingual models. However, the data required to train models for\nevery language may be difficult, expensive and time-consuming to obtain,\nparticularly for low-resource languages. Taking Japanese as our target\nlanguage, we explore methods by which data in one language might be used to\nbuild models for a different language. We evaluate strategies of training on\nmachine translated data and of zero-shot transfer through the use of\nmultilingual models. We find that the choice of source language impacts the\nperformance, with Chinese-Japanese being a better language pair than\nEnglish-Japanese. Training on machine translated data shows promise, especially\nwhen used in conjunction with a small amount of target language data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 12:42:19 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Appelgren", "Mattias", ""], ["Schrempf", "Patrick", ""], ["Falis", "Mat\u00fa\u0161", ""], ["Ikeda", "Satoshi", ""], ["O'Neil", "Alison Q", ""]]}, {"id": "1910.04601", "submitter": "Naoya Inoue", "authors": "Naoya Inoue, Pontus Stenetorp, Kentaro Inui", "title": "R4C: A Benchmark for Evaluating RC Systems to Get the Right Answer for\n  the Right Reason", "comments": "Accepted by ACL2020. See https://naoya-i.github.io/r4c/ for more\n  information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have revealed that reading comprehension (RC) systems learn to\nexploit annotation artifacts and other biases in current datasets. This\nprevents the community from reliably measuring the progress of RC systems. To\naddress this issue, we introduce R4C, a new task for evaluating RC systems'\ninternal reasoning. R4C requires giving not only answers but also derivations:\nexplanations that justify predicted answers. We present a reliable,\ncrowdsourced framework for scalably annotating RC datasets with derivations. We\ncreate and publicly release the R4C dataset, the first, quality-assured dataset\nconsisting of 4.6k questions, each of which is annotated with 3 reference\nderivations (i.e. 13.8k derivations). Experiments show that our automatic\nevaluation metrics using multiple reference derivations are reliable, and that\nR4C assesses different skills from an existing benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:28:56 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 03:21:29 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Inoue", "Naoya", ""], ["Stenetorp", "Pontus", ""], ["Inui", "Kentaro", ""]]}, {"id": "1910.04602", "submitter": "Pulkit Parikh", "authors": "Pulkit Parikh, Harika Abburi, Pinkesh Badjatiya, Radhika Krishnan,\n  Niyati Chhaya, Manish Gupta and Vasudeva Varma", "title": "Multi-label Categorization of Accounts of Sexism using a Neural\n  Framework", "comments": "Accepted at 2019 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP - 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexism, an injustice that subjects women and girls to enormous suffering,\nmanifests in blatant as well as subtle ways. In the wake of growing\ndocumentation of experiences of sexism on the web, the automatic categorization\nof accounts of sexism has the potential to assist social scientists and policy\nmakers in studying and countering sexism better. The existing work on sexism\nclassification, which is different from sexism detection, has certain\nlimitations in terms of the categories of sexism used and/or whether they can\nco-occur. To the best of our knowledge, this is the first work on the\nmulti-label classification of sexism of any kind(s), and we contribute the\nlargest dataset for sexism categorization. We develop a neural solution for\nthis multi-label classification that can combine sentence representations\nobtained using models such as BERT with distributional and linguistic word\nembeddings using a flexible, hierarchical architecture involving recurrent\ncomponents and optional convolutional ones. Further, we leverage unlabeled\naccounts of sexism to infuse domain-specific elements into our framework. The\nbest proposed method outperforms several deep learning as well as traditional\nmachine learning baselines by an appreciable margin.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:28:57 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 17:44:30 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 17:05:38 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 12:24:13 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Parikh", "Pulkit", ""], ["Abburi", "Harika", ""], ["Badjatiya", "Pinkesh", ""], ["Krishnan", "Radhika", ""], ["Chhaya", "Niyati", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1910.04618", "submitter": "Hang Gao", "authors": "Hang Gao and Tim Oates", "title": "Universal Adversarial Perturbation for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a state-of-the-art deep neural network text classifier, we show the\nexistence of a universal and very small perturbation vector (in the embedding\nspace) that causes natural text to be misclassified with high probability.\nUnlike images on which a single fixed-size adversarial perturbation can be\nfound, text is of variable length, so we define the \"universality\" as\n\"token-agnostic\", where a single perturbation is applied to each token,\nresulting in different perturbations of flexible sizes at the sequence level.\nWe propose an algorithm to compute universal adversarial perturbations, and\nshow that the state-of-the-art deep neural networks are highly vulnerable to\nthem, even though they keep the neighborhood of tokens mostly preserved. We\nalso show how to use these adversarial perturbations to generate adversarial\ntext samples. The surprising existence of universal \"token-agnostic\"\nadversarial perturbations may reveal important properties of a text classifier.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:48:22 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Gao", "Hang", ""], ["Oates", "Tim", ""]]}, {"id": "1910.04659", "submitter": "Wissam Siblini", "authors": "Wissam Siblini, Charlotte Pasqual, Axel Lavielle, Mohamed Challal,\n  Cyril Cauchois", "title": "Multilingual Question Answering from Formatted Text applied to\n  Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances with language models (e.g. BERT, XLNet, ...), have allowed\nsurpassing human performance on complex NLP tasks such as Reading\nComprehension. However, labeled datasets for training are available mostly in\nEnglish which makes it difficult to acknowledge progress in other languages.\nFortunately, models are now pre-trained on unlabeled data from hundreds of\nlanguages and exhibit interesting transfer abilities from one language to\nanother. In this paper, we show that multilingual BERT is naturally capable of\nzero-shot transfer for an extractive Question Answering task (eQA) from English\nto other languages. More specifically, it outperforms the best previously known\nbaseline for transfer to Japanese and French. Moreover, using a recently\npublished large eQA French dataset, we are able to further show that (1)\nzero-shot transfer provides results really close to a direct training on the\ntarget language and (2) combination of transfer and training on target is the\nbest option overall. We finally present a practical application: a multilingual\nconversational agent called Kate which answers to HR-related questions in\nseveral languages directly from the content of intranet pages.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:44:29 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 10:35:04 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Siblini", "Wissam", ""], ["Pasqual", "Charlotte", ""], ["Lavielle", "Axel", ""], ["Challal", "Mohamed", ""], ["Cauchois", "Cyril", ""]]}, {"id": "1910.04708", "submitter": "Zirui Wang", "authors": "Zirui Wang, Jiateng Xie, Ruochen Xu, Yiming Yang, Graham Neubig, Jaime\n  Carbonell", "title": "Cross-lingual Alignment vs Joint Training: A Comparative Study and A\n  Simple Unified Framework", "comments": "Published as a conference paper at ICLR 2020. First two authors\n  contributed equally. Source code is available at\n  https://github.com/thespectrewithin/joint-align", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning multilingual representations of text has proven a successful method\nfor many cross-lingual transfer learning tasks. There are two main paradigms\nfor learning such representations: (1) alignment, which maps different\nindependently trained monolingual representations into a shared space, and (2)\njoint training, which directly learns unified multilingual representations\nusing monolingual and cross-lingual objectives jointly. In this paper, we first\nconduct direct comparisons of representations learned using both of these\nmethods across diverse cross-lingual tasks. Our empirical results reveal a set\nof pros and cons for both methods, and show that the relative performance of\nalignment versus joint training is task-dependent. Stemming from this analysis,\nwe propose a simple and novel framework that combines these two previously\nmutually-exclusive approaches. Extensive experiments demonstrate that our\nproposed framework alleviates limitations of both approaches, and outperforms\nexisting methods on the MUSE bilingual lexicon induction (BLI) benchmark. We\nfurther show that this framework can generalize to contextualized\nrepresentations such as Multilingual BERT, and produces state-of-the-art\nresults on the CoNLL cross-lingual NER benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:04:30 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 16:34:25 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 20:48:45 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 00:59:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wang", "Zirui", ""], ["Xie", "Jiateng", ""], ["Xu", "Ruochen", ""], ["Yang", "Yiming", ""], ["Neubig", "Graham", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1910.04731", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek, Karin Sevegnani, Ioannis Konstas and Verena\n  Rieser", "title": "Automatic Quality Estimation for Natural Language Generation: Ranting\n  (Jointly Rating and Ranking)", "comments": "Accepted as a short paper at INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recurrent neural network based system for automatic quality\nestimation of natural language generation (NLG) outputs, which jointly learns\nto assign numerical ratings to individual outputs and to provide pairwise\nrankings of two different outputs. The latter is trained using pairwise hinge\nloss over scores from two copies of the rating network.\n  We use learning to rank and synthetic data to improve the quality of ratings\nassigned by our system: we synthesise training pairs of distorted system\noutputs and train the system to rank the less distorted one higher. This leads\nto a 12% increase in correlation with human ratings over the previous\nbenchmark. We also establish the state of the art on the dataset of relative\nrankings from the E2E NLG Challenge (Du\\v{s}ek et al., 2019), where synthetic\ndata lead to a 4% accuracy increase over the base model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:43:31 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Sevegnani", "Karin", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "1910.04732", "submitter": "Jeremy Wohlwend", "authors": "Ziheng Wang, Jeremy Wohlwend, Tao Lei", "title": "Structured Pruning of Large Language Models", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.496", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large language models have recently achieved state of the art performance\nacross a wide variety of natural language tasks. Meanwhile, the size of these\nmodels and their latency have significantly increased, which makes their usage\ncostly, and raises an interesting question: do language models need to be\nlarge? We study this question through the lens of model compression. We present\na generic, structured pruning approach by parameterizing each weight matrix\nusing its low-rank factorization, and adaptively removing rank-1 components\nduring training. On language modeling tasks, our structured approach\noutperforms other unstructured and block-structured pruning baselines at\nvarious compression levels, while achieving significant speedups during both\ntraining and inference. We also demonstrate that our method can be applied to\npruning adaptive word embeddings in large language models, and to pruning the\nBERT model on several downstream fine-tuning classification benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 17:44:18 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 19:04:25 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wang", "Ziheng", ""], ["Wohlwend", "Jeremy", ""], ["Lei", "Tao", ""]]}, {"id": "1910.04887", "submitter": "Samuel Sharpe", "authors": "Samuel Sharpe, Jin Yan, Fan Wu, Iddo Drori", "title": "Visual Natural Language Query Auto-Completion for Estimating Instance\n  Probabilities", "comments": null, "journal-ref": "CVPR Language and Vision Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new task of query auto-completion for estimating instance\nprobabilities. We complete a user query prefix conditioned upon an image. Given\nthe complete query, we fine tune a BERT embedding for estimating probabilities\nof a broad set of instances. The resulting instance probabilities are used for\nselection while being agnostic to the segmentation or attention mechanism. Our\nresults demonstrate that auto-completion using both language and vision\nperforms better than using only language, and that fine tuning a BERT embedding\nallows to efficiently rank instances in the image. In the spirit of\nreproducible research we make our data, models, and code available.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:46:26 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Sharpe", "Samuel", ""], ["Yan", "Jin", ""], ["Wu", "Fan", ""], ["Drori", "Iddo", ""]]}, {"id": "1910.04979", "submitter": "Nicholas Andrews", "authors": "Nicholas Andrews and Marcus Bishop", "title": "Learning Invariant Representations of Social Media Users", "comments": "12 pages, 3 figures; to be published in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of social media users' behavior over time complicates\nuser-level comparison tasks such as verification, classification, clustering,\nand ranking. As a result, na\\\"ive approaches may fail to generalize to new\nusers or even to future observations of previously known users. In this paper,\nwe propose a novel procedure to learn a mapping from short episodes of user\nactivity on social media to a vector space in which the distance between points\ncaptures the similarity of the corresponding users' invariant features. We fit\nthe model by optimizing a surrogate metric learning objective over a large\ncorpus of unlabeled social media content. Once learned, the mapping may be\napplied to users not seen at training time and enables efficient comparisons of\nusers in the resulting vector space. We present a comprehensive evaluation to\nvalidate the benefits of the proposed approach using data from Reddit, Twitter,\nand Wikipedia.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 05:37:11 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Andrews", "Nicholas", ""], ["Bishop", "Marcus", ""]]}, {"id": "1910.04980", "submitter": "Soujanya Poria", "authors": "Devamanyu Hazarika, Soujanya Poria, Roger Zimmermann, Rada Mihalcea", "title": "Conversational Transfer Learning for Emotion Recognition", "comments": "Information Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing emotions in conversations is a challenging task due to the\npresence of contextual dependencies governed by self- and inter-personal\ninfluences. Recent approaches have focused on modeling these dependencies\nprimarily via supervised learning. However, purely supervised strategies demand\nlarge amounts of annotated data, which is lacking in most of the available\ncorpora in this task. To tackle this challenge, we look at transfer learning\napproaches as a viable alternative. Given the large amount of available\nconversational data, we investigate whether generative conversational models\ncan be leveraged to transfer affective knowledge for detecting emotions in\ncontext. We propose an approach, TL-ERC, where we pre-train a hierarchical\ndialogue model on multi-turn conversations (source) and then transfer its\nparameters to a conversational emotion classifier (target). In addition to the\npopular practice of using pre-trained sentence encoders, our approach also\nincorporates recurrent parameters that model inter-sentential context across\nthe whole conversation. Based on this idea, we perform several experiments\nacross multiple datasets and find improvement in performance and robustness\nagainst limited training data. TL-ERC also achieves better validation\nperformances in significantly fewer epochs. Overall, we infer that knowledge\nacquired from dialogue generators can indeed help recognize emotions in\nconversations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 05:39:08 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 00:03:12 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 00:58:18 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Hazarika", "Devamanyu", ""], ["Poria", "Soujanya", ""], ["Zimmermann", "Roger", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1910.05014", "submitter": "Jean-Claude Houbart M.", "authors": "Jean-Claude Houbart, Solen Quiniou, Marion Berthaut, B\\'eatrice\n  Daille, Claire Salom\\'e", "title": "Automatic segmentation of texts into units of meaning for reading\n  assistance", "comments": "7 pages, 7 figures. Work Presented at International Joint Conferences\n  on Artificial Intelligence (IJCAI ) workshop on AI and the United Nations\n  Sustainable Development Goals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of the digital book is a major step forward in providing access\nto reading, and therefore often to the common culture and the labour market. By\nallowing the enrichment of texts with cognitive crutches, EPub 3 compatible\naccessibility formats such as FROG have proven their effectiveness in\nalleviating but also reducing dyslexic disorders. In this paper, we show how\nArtificial Intelligence and particularly Transfer Learning with Google BERT can\nautomate the division into units of meaning, and thus facilitate the creation\nof enriched digital books at a moderate cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 07:54:38 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Houbart", "Jean-Claude", ""], ["Quiniou", "Solen", ""], ["Berthaut", "Marion", ""], ["Daille", "B\u00e9atrice", ""], ["Salom\u00e9", "Claire", ""]]}, {"id": "1910.05032", "submitter": "Deli Chen", "authors": "Deli Chen, Shuming ma, Keiko Harimoto, Ruihan Bao, Qi Su, Xu Sun", "title": "Group, Extract and Aggregate: Summarizing a Large Amount of Finance News\n  for Forex Movement Prediction", "comments": "Accepted by 2th ECONLP workshop in EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating related text information has proven successful in stock market\nprediction. However, it is a huge challenge to utilize texts in the enormous\nforex (foreign currency exchange) market because the associated texts are too\nredundant. In this work, we propose a BERT-based Hierarchical Aggregation Model\nto summarize a large amount of finance news to predict forex movement. We\nfirstly group news from different aspects: time, topic and category. Then we\nextract the most crucial news in each group by the SOTA extractive\nsummarization method. Finally, we conduct interaction between the news and the\ntrade data with attention to predict the forex movement. The experimental\nresults show that the category based method performs best among three grouping\nmethods and outperforms all the baselines. Besides, we study the influence of\nessential news attributes (category and region) by statistical analysis and\nsummarize the influence patterns for different currency pairs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 08:56:52 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Chen", "Deli", ""], ["ma", "Shuming", ""], ["Harimoto", "Keiko", ""], ["Bao", "Ruihan", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1910.05040", "submitter": "Yimin Jing", "authors": "Yimin Jing, Deyi Xiong, Yan Zhen", "title": "BiPaR: A Bilingual Parallel Dataset for Multilingual and Cross-lingual\n  Reading Comprehension on Novels", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents BiPaR, a bilingual parallel novel-style machine reading\ncomprehension (MRC) dataset, developed to support multilingual and\ncross-lingual reading comprehension. The biggest difference between BiPaR and\nexisting reading comprehension datasets is that each triple (Passage, Question,\nAnswer) in BiPaR is written parallelly in two languages. We collect 3,667\nbilingual parallel paragraphs from Chinese and English novels, from which we\nconstruct 14,668 parallel question-answer pairs via crowdsourced workers\nfollowing a strict quality control procedure. We analyze BiPaR in depth and\nfind that BiPaR offers good diversification in prefixes of questions, answer\ntypes and relationships between questions and passages. We also observe that\nanswering questions of novels requires reading comprehension skills of\ncoreference resolution, multi-sentence reasoning, and understanding of implicit\ncausality, etc. With BiPaR, we build monolingual, multilingual, and\ncross-lingual MRC baseline models. Even for the relatively simple monolingual\nMRC on this dataset, experiments show that a strong BERT baseline is over 30\npoints behind human in terms of both EM and F1 score, indicating that BiPaR\nprovides a challenging testbed for monolingual, multilingual and cross-lingual\nMRC on novels. The dataset is available at https://multinlp.github.io/BiPaR/.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 09:16:29 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Jing", "Yimin", ""], ["Xiong", "Deyi", ""], ["Zhen", "Yan", ""]]}, {"id": "1910.05059", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Ond\\v{r}ej Bojar", "title": "Keyphrase Generation: A Multi-Aspect Survey", "comments": "10 pages, 5 tables. Published in proceedings of FRUCT 2019, the 25th\n  Conference of the Open Innovations Association FRUCT, Helsinki, Finland", "journal-ref": null, "doi": "10.23919/FRUCT48121.2019.8981519", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive keyphrase generation research has been around since the nineties,\nbut the more advanced abstractive approach based on the encoder-decoder\nframework and sequence-to-sequence learning has been explored only recently. In\nfact, more than a dozen of abstractive methods have been proposed in the last\nthree years, producing meaningful keyphrases and achieving state-of-the-art\nscores. In this survey, we examine various aspects of the extractive keyphrase\ngeneration methods and focus mostly on the more recent abstractive methods that\nare based on neural networks. We pay particular attention to the mechanisms\nthat have driven the perfection of the later. A huge collection of scientific\narticle metadata and the corresponding keyphrases is created and released for\nthe research community. We also present various keyphrase generation and text\nsummarization research patterns and trends of the last two decades.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 10:03:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1910.05069", "submitter": "Tao Shen", "authors": "Tao Shen, Xiubo Geng, Tao Qin, Daya Guo, Duyu Tang, Nan Duan, Guodong\n  Long and Daxin Jiang", "title": "Multi-Task Learning for Conversational Question Answering over a\n  Large-Scale Knowledge Base", "comments": "Accepted to appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of conversational question answering over a\nlarge-scale knowledge base. To handle huge entity vocabulary of a large-scale\nknowledge base, recent neural semantic parsing based approaches usually\ndecompose the task into several subtasks and then solve them sequentially,\nwhich leads to following issues: 1) errors in earlier subtasks will be\npropagated and negatively affect downstream ones; and 2) each subtask cannot\nnaturally share supervision signals with others. To tackle these issues, we\npropose an innovative multi-task learning framework where a pointer-equipped\nsemantic parsing model is designed to resolve coreference in conversations, and\nnaturally empower joint learning with a novel type-aware entity detection\nmodel. The proposed framework thus enables shared supervisions and alleviates\nthe effect of error propagation. Experiments on a large-scale conversational\nquestion answering dataset containing 1.6M question answering pairs over 12.8M\nentities show that the proposed framework improves overall F1 score from 67% to\n79% compared with previous state-of-the-art work.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 10:40:42 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Shen", "Tao", ""], ["Geng", "Xiubo", ""], ["Qin", "Tao", ""], ["Guo", "Daya", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Long", "Guodong", ""], ["Jiang", "Daxin", ""]]}, {"id": "1910.05154", "submitter": "Marcely Zanon Boito", "authors": "Marcely Zanon Boito, Aline Villavicencio, Laurent Besacier", "title": "How Does Language Influence Documentation Workflow? Unsupervised Word\n  Discovery Using Translations in Multiple Languages", "comments": "4 pages, workshop LIFT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For language documentation initiatives, transcription is an expensive\nresource: one minute of audio is estimated to take one hour and a half on\naverage of a linguist's work (Austin and Sallabank, 2013). Recently, collecting\naligned translations in well-resourced languages became a popular solution for\nensuring posterior interpretability of the recordings (Adda et al. 2016). In\nthis paper we investigate language-related impact in automatic approaches for\ncomputational language documentation. We translate the bilingual Mboshi-French\nparallel corpus (Godard et al. 2017) into four other languages, and we perform\nbilingual-rooted unsupervised word discovery. Our results hint towards an\nimpact of the well-resourced language in the quality of the output. However, by\ncombining the information learned by different bilingual models, we are only\nable to marginally increase the quality of the segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:04:31 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Boito", "Marcely Zanon", ""], ["Villavicencio", "Aline", ""], ["Besacier", "Laurent", ""]]}, {"id": "1910.05171", "submitter": "Byeonggeun Kim", "authors": "Byeonggeun Kim, Mingu Lee, Jinkyu Lee, Yeonseok Kim, and Kyuwoong\n  Hwang", "title": "Query-by-example on-device keyword spotting", "comments": "IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A keyword spotting (KWS) system determines the existence of, usually\npredefined, keyword in a continuous speech stream. This paper presents a\nquery-by-example on-device KWS system which is user-specific. The proposed\nsystem consists of two main steps: query enrollment and testing. In query\nenrollment step, phonetic posteriors are output by a small-footprint automatic\nspeech recognition model based on connectionist temporal classification. Using\nthe phonetic-level posteriorgram, hypothesis graph of finite-state transducer\n(FST) is built, thus can enroll any keywords thus avoiding an out-of-vocabulary\nproblem. In testing, a log-likelihood is scored for input audio using the FST.\nWe propose a threshold prediction method while using the user-specific keyword\nhypothesis only. The system generates query-specific negatives by rearranging\neach query utterance in waveform. The threshold is decided based on the\nenrollment queries and generated negatives. We tested two keywords in English,\nand the proposed work shows promising performance while preserving simplicity.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 13:28:03 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 03:37:05 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 01:55:51 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Kim", "Byeonggeun", ""], ["Lee", "Mingu", ""], ["Lee", "Jinkyu", ""], ["Kim", "Yeonseok", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1910.05276", "submitter": "Sebastian Gehrmann", "authors": "Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann", "title": "exBERT: A Visual Analysis Tool to Explore Learned Representations in\n  Transformers Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large language models can produce powerful contextual representations that\nlead to improvements across many NLP tasks. Since these models are typically\nguided by a sequence of learned self attention mechanisms and may comprise\nundesired inductive biases, it is paramount to be able to explore what the\nattention has learned. While static analyses of these models lead to targeted\ninsights, interactive tools are more dynamic and can help humans better gain an\nintuition for the model-internal reasoning process. We present exBERT, an\ninteractive tool named after the popular BERT language model, that provides\ninsights into the meaning of the contextual representations by matching a\nhuman-specified input to similar contexts in a large annotated dataset. By\naggregating the annotations of the matching similar contexts, exBERT helps\nintuitively explain what each attention-head has learned.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:10:55 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Hoover", "Benjamin", ""], ["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""]]}, {"id": "1910.05291", "submitter": "Serhii Havrylov", "authors": "Shangmin Guo, Yi Ren, Serhii Havrylov, Stella Frank, Ivan Titov, Kenny\n  Smith", "title": "The Emergence of Compositional Languages for Numeric Concepts Through\n  Iterated Learning in Neural Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since first introduced, computer simulation has been an increasingly\nimportant tool in evolutionary linguistics. Recently, with the development of\ndeep learning techniques, research in grounded language learning has also\nstarted to focus on facilitating the emergence of compositional languages\nwithout pre-defined elementary linguistic knowledge. In this work, we explore\nthe emergence of compositional languages for numeric concepts in multi-agent\ncommunication systems. We demonstrate that compositional language for encoding\nnumeric concepts can emerge through iterated learning in populations of deep\nneural network agents. However, language properties greatly depend on the input\nrepresentations given to agents. We found that compositional languages only\nemerge if they require less iterations to be fully learnt than other\nnon-degenerate languages for agents on a given input representation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:34:01 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Guo", "Shangmin", ""], ["Ren", "Yi", ""], ["Havrylov", "Serhii", ""], ["Frank", "Stella", ""], ["Titov", "Ivan", ""], ["Smith", "Kenny", ""]]}, {"id": "1910.05298", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek and Filip Jur\\v{c}\\'i\\v{c}ek", "title": "Neural Generation for Czech: Data and Baselines", "comments": "Accepted as a long paper at INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first dataset targeted at end-to-end NLG in Czech in the\nrestaurant domain, along with several strong baseline models using the\nsequence-to-sequence approach. While non-English NLG is under-explored in\ngeneral, Czech, as a morphologically rich language, makes the task even harder:\nSince Czech requires inflecting named entities, delexicalization or copy\nmechanisms do not work out-of-the-box and lexicalizing the generated outputs is\nnon-trivial.\n  In our experiments, we present two different approaches to this this problem:\n(1) using a neural language model to select the correct inflected form while\nlexicalizing, (2) a two-step generation setup: our sequence-to-sequence model\ngenerates an interleaved sequence of lemmas and morphological tags, which are\nthen inflected by a morphological generator.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:43:05 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Jur\u010d\u00ed\u010dek", "Filip", ""]]}, {"id": "1910.05315", "submitter": "Aissatou Diallo", "authors": "Aissatou Diallo, Markus Zopf, Johannes F\\\"urnkranz", "title": "Learning Analogy-Preserving Sentence Embeddings for Answer Selection", "comments": "To appear in CoNLL19", "journal-ref": "Proc. CoNLL 2019: 910-919", "doi": "10.18653/v1/K19-1085", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer selection aims at identifying the correct answer for a given question\nfrom a set of potentially correct answers. Contrary to previous works, which\ntypically focus on the semantic similarity between a question and its answer,\nour hypothesis is that question-answer pairs are often in analogical relation\nto each other. Using analogical inference as our use case, we propose a\nframework and a neural network architecture for learning dedicated sentence\nembeddings that preserve analogical properties in the semantic space. We\nevaluate the proposed method on benchmark datasets for answer selection and\ndemonstrate that our sentence embeddings indeed capture analogical properties\nbetter than conventional embeddings, and that analogy-based question answering\noutperforms a comparable similarity-based technique.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 17:22:19 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Diallo", "Aissatou", ""], ["Zopf", "Markus", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1910.05389", "submitter": "Ziyu Yao", "authors": "Ziyu Yao, Yu Su, Huan Sun, Wen-tau Yih", "title": "Model-based Interactive Semantic Parsing: A Unified Framework and A\n  Text-to-SQL Case Study", "comments": "14 pages, 4 figures, accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising paradigm, interactive semantic parsing has shown to improve\nboth semantic parsing accuracy and user confidence in the results. In this\npaper, we propose a new, unified formulation of the interactive semantic\nparsing problem, where the goal is to design a model-based intelligent agent.\nThe agent maintains its own state as the current predicted semantic parse,\ndecides whether and where human intervention is needed, and generates a\nclarification question in natural language. A key part of the agent is a world\nmodel: it takes a percept (either an initial question or subsequent feedback\nfrom the user) and transitions to a new state. We then propose a simple yet\nremarkably effective instantiation of our framework, demonstrated on two\ntext-to-SQL datasets (WikiSQL and Spider) with different state-of-the-art base\nsemantic parsers. Compared to an existing interactive semantic parsing approach\nthat treats the base parser as a black box, our approach solicits less user\nfeedback but yields higher run-time accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:56:47 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Yao", "Ziyu", ""], ["Su", "Yu", ""], ["Sun", "Huan", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1910.05453", "submitter": "Alexei Baevski", "authors": "Alexei Baevski, Steffen Schneider, Michael Auli", "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose vq-wav2vec to learn discrete representations of audio segments\nthrough a wav2vec-style self-supervised context prediction task. The algorithm\nuses either a gumbel softmax or online k-means clustering to quantize the dense\nrepresentations. Discretization enables the direct application of algorithms\nfrom the NLP community which require discrete inputs. Experiments show that\nBERT pre-training achieves a new state of the art on TIMIT phoneme\nclassification and WSJ speech recognition.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 00:55:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 21:28:15 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 18:35:27 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Baevski", "Alexei", ""], ["Schneider", "Steffen", ""], ["Auli", "Michael", ""]]}, {"id": "1910.05456", "submitter": "Katharina Kann", "authors": "Katharina Kann", "title": "Acquisition of Inflectional Morphology in Artificial Neural Networks\n  With Prior Knowledge", "comments": "SCiL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does knowledge of one language's morphology influence learning of\ninflection rules in a second one? In order to investigate this question in\nartificial neural network models, we perform experiments with a\nsequence-to-sequence architecture, which we train on different combinations of\neight source and three target languages. A detailed analysis of the model\noutputs suggests the following conclusions: (i) if source and target language\nare closely related, acquisition of the target language's inflectional\nmorphology constitutes an easier task for the model; (ii) knowledge of a\nprefixing (resp. suffixing) language makes acquisition of a suffixing (resp.\nprefixing) language's morphology more challenging; and (iii) surprisingly, a\nsource language which exhibits an agglutinative morphology simplifies learning\nof a second language's inflectional morphology, independent of their\nrelatedness.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 01:10:24 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Kann", "Katharina", ""]]}, {"id": "1910.05479", "submitter": "Ke Tran", "authors": "Ke Tran, Arianna Bisazza", "title": "Zero-shot Dependency Parsing with Pre-trained Multilingual Sentence\n  Representations", "comments": "DeepLo workshop, EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether off-the-shelf deep bidirectional sentence\nrepresentations trained on a massively multilingual corpus (multilingual BERT)\nenable the development of an unsupervised universal dependency parser. This\napproach only leverages a mix of monolingual corpora in many languages and does\nnot require any translation data making it applicable to low-resource\nlanguages. In our experiments we outperform the best CoNLL 2018\nlanguage-specific systems in all of the shared task's six truly low-resource\nlanguages while using a single system. However, we also find that (i) parsing\naccuracy still varies dramatically when changing the training languages and\n(ii) in some target languages zero-shot transfer fails under all tested\nconditions, raising concerns on the 'universality' of the whole approach.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 03:44:56 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Tran", "Ke", ""], ["Bisazza", "Arianna", ""]]}, {"id": "1910.05495", "submitter": "Jason Ren", "authors": "Jason Ren, Russell Kunes, Finale Doshi-Velez", "title": "Prediction Focused Topic Models via Feature Selection", "comments": "AISTATS 2020. arXiv admin note: substantial text overlap with\n  arXiv:1911.08551", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised topic models are often sought to balance prediction quality and\ninterpretability. However, when models are (inevitably) misspecified, standard\napproaches rarely deliver on both. We introduce a novel approach, the\nprediction-focused topic model, that uses the supervisory signal to retain only\nvocabulary terms that improve, or at least do not hinder, prediction\nperformance. By removing terms with irrelevant signal, the topic model is able\nto learn task-relevant, coherent topics. We demonstrate on several data sets\nthat compared to existing approaches, prediction-focused topic models learn\nmuch more coherent topics while maintaining competitive predictions.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 05:08:43 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 06:20:26 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ren", "Jason", ""], ["Kunes", "Russell", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1910.05535", "submitter": "Mika H\\\"am\\\"al\\\"ainen", "authors": "Mika H\\\"am\\\"al\\\"ainen and Simon Hengchen", "title": "From the Paft to the Fiiture: a Fully Automatic NMT and Word Embeddings\n  Method for OCR Post-Correction", "comments": null, "journal-ref": "Proceedings of Recent Advances in Natural Language Processing.\n  Angelova, G., Mitkov, R., Nikolova, I. & Temnikova, I. (eds.). Shoumen:\n  INCOMA, p. 432-437 6 p (2019)", "doi": "10.26615/978-954-452-056-4_051", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great deal of historical corpora suffer from errors introduced by the OCR\n(optical character recognition) methods used in the digitization process.\nCorrecting these errors manually is a time-consuming process and a great part\nof the automatic approaches have been relying on rules or supervised machine\nlearning. We present a fully automatic unsupervised way of extracting parallel\ndata for training a character-based sequence-to-sequence NMT (neural machine\ntranslation) model to conduct OCR error correction.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 09:23:11 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Hengchen", "Simon", ""]]}, {"id": "1910.05577", "submitter": "Xudong Lin", "authors": "Xudong Lin, Lin Ma, Wei Liu, Shih-Fu Chang", "title": "Context-Gated Convolution", "comments": "ECCV 2020 camera ready version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the basic building block of Convolutional Neural Networks (CNNs), the\nconvolutional layer is designed to extract local patterns and lacks the ability\nto model global context in its nature. Many efforts have been recently devoted\nto complementing CNNs with the global modeling ability, especially by a family\nof works on global feature interaction. In these works, the global context\ninformation is incorporated into local features before they are fed into\nconvolutional layers. However, research on neuroscience reveals that the\nneurons' ability of modifying their functions dynamically according to context\nis essential for the perceptual tasks, which has been overlooked in most of\nCNNs. Motivated by this, we propose one novel Context-Gated Convolution (CGC)\nto explicitly modify the weights of convolutional layers adaptively under the\nguidance of global context. As such, being aware of the global context, the\nmodulated convolution kernel of our proposed CGC can better extract\nrepresentative local patterns and compose discriminative features. Moreover,\nour proposed CGC is lightweight and applicable with modern CNN architectures,\nand consistently improves the performance of CNNs according to extensive\nexperiments on image classification, action recognition, and machine\ntranslation. Our code of this paper is available at\nhttps://github.com/XudongLinthu/context-gated-convolution.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 15:30:18 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 03:08:24 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 19:19:28 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 16:59:19 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Lin", "Xudong", ""], ["Ma", "Lin", ""], ["Liu", "Wei", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1910.05598", "submitter": "Kartikey Pant", "authors": "Kartikey Pant, Venkata Himakar Yanamandra, Alok Debnath and Radhika\n  Mamidi", "title": "SmokEng: Towards Fine-grained Classification of Tobacco-related Social\n  Media Text", "comments": "Accepted at the Workshop on Noisy User-generated Text (W-NUT) at\n  EMNLP-IJCNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-5524", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary datasets on tobacco consumption focus on one of two topics,\neither public health mentions and disease surveillance, or sentiment analysis\non topical tobacco products and services. However, two primary considerations\nare not accounted for, the language of the demographic affected and a\ncombination of the topics mentioned above in a fine-grained classification\nmechanism. In this paper, we create a dataset of 3144 tweets, which are\nselected based on the presence of colloquial slang related to smoking and\nanalyze it based on the semantics of the tweet. Each class is created and\nannotated based on the content of the tweets such that further hierarchical\nmethods can be easily applied.\n  Further, we prove the efficacy of standard text classification methods on\nthis dataset, by designing experiments which do both binary as well as\nmulti-class classification. Our experiments tackle the identification of either\na specific topic (such as tobacco product promotion), a general mention\n(cigarettes and related products) or a more fine-grained classification. This\nmethodology paves the way for further analysis, such as understanding sentiment\nor style, which makes this dataset a vital contribution to both disease\nsurveillance and tobacco use research.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 17:06:07 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Pant", "Kartikey", ""], ["Yanamandra", "Venkata Himakar", ""], ["Debnath", "Alok", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1910.05603", "submitter": "Binh Nguyen", "authors": "Quang Minh Nguyen, Thai Binh Nguyen, Ngoc Phuong Pham, The Loc Nguyen", "title": "VAIS ASR: Building a conversational speech recognition system using\n  language model combination", "comments": "3 pages, 1 figures, Vietnamese Language and Speech Processing\n  conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Speech Recognition (ASR) systems have been evolving quickly and\nreaching human parity in certain cases. The systems usually perform pretty well\non reading style and clean speech, however, most of the available systems\nsuffer from situation where the speaking style is conversation and in noisy\nenvironments. It is not straight-forward to tackle such problems due to\ndifficulties in data collection for both speech and text. In this paper, we\nattempt to mitigate the problems using language models combination techniques\nthat allows us to utilize both large amount of writing style text and small\nnumber of conversation text data. Evaluation on the VLSP 2019 ASR challenges\nshowed that our system achieved 4.85% WER on the VLSP 2018 and 15.09% WER on\nthe VLSP 2019 data sets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 17:37:52 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nguyen", "Quang Minh", ""], ["Nguyen", "Thai Binh", ""], ["Pham", "Ngoc Phuong", ""], ["Nguyen", "The Loc", ""]]}, {"id": "1910.05608", "submitter": "Binh Nguyen", "authors": "Thai Binh Nguyen, Quang Minh Nguyen, Thu Hien Nguyen, Ngoc Phuong\n  Pham, The Loc Nguyen, Quoc Truong Do", "title": "VAIS Hate Speech Detection System: A Deep Learning based Approach for\n  System Combination", "comments": "5 pages, 6 figures, Vietnamese Language and Speech Processing\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Social network sites (SNSs) such as Facebook, Twitter are common\nplaces where people show their opinions, sentiments and share information with\nothers. However, some people use SNSs to post abuse and harassment threats in\norder to prevent other SNSs users from expressing themselves as well as seeking\ndifferent opinions. To deal with this problem, SNSs have to use a lot of\nresources including people to clean the aforementioned content. In this paper,\nwe propose a supervised learning model based on the ensemble method to solve\nthe problem of detecting hate content on SNSs in order to make conversations on\nSNSs more effective. Our proposed model got the first place for public\ndashboard with 0.730 F1 macro-score and the third place with 0.584 F1\nmacro-score for private dashboard at the sixth international workshop on\nVietnamese Language and Speech Processing 2019.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 17:46:16 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nguyen", "Thai Binh", ""], ["Nguyen", "Quang Minh", ""], ["Nguyen", "Thu Hien", ""], ["Pham", "Ngoc Phuong", ""], ["Nguyen", "The Loc", ""], ["Do", "Quoc Truong", ""]]}, {"id": "1910.05624", "submitter": "Matthew Marge", "authors": "Matthew Marge, Stephen Nogar, Cory J. Hayes, Stephanie M. Lukin, Jesse\n  Bloecker, Eric Holder, Clare Voss", "title": "A Research Platform for Multi-Robot Dialogue with Humans", "comments": "Accepted for publication at NAACL 2019; also presented at AI-HRI 2019\n  (arXiv:1909.04812)", "journal-ref": null, "doi": null, "report-no": "AI-HRI/2019/05", "categories": "cs.RO cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a research platform that supports spoken dialogue\ninteraction with multiple robots. The demonstration showcases our crafted\nMultiBot testing scenario in which users can verbally issue search, navigate,\nand follow instructions to two robotic teammates: a simulated ground robot and\nan aerial robot. This flexible language and robotic platform takes advantage of\nexisting tools for speech recognition and dialogue management that are\ncompatible with new domains, and implements an inter-agent communication\nprotocol (tactical behavior specification), where verbal instructions are\nencoded for tasks assigned to the appropriate robot.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 18:59:50 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Marge", "Matthew", ""], ["Nogar", "Stephen", ""], ["Hayes", "Cory J.", ""], ["Lukin", "Stephanie M.", ""], ["Bloecker", "Jesse", ""], ["Holder", "Eric", ""], ["Voss", "Clare", ""]]}, {"id": "1910.05728", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Shivansh Patel and Vinay P. Namboodiri", "title": "Granular Multimodal Attention Networks for Visual Dialog", "comments": "ICCV Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision and language tasks have benefited from attention. There have been a\nnumber of different attention models proposed. However, the scale at which\nattention needs to be applied has not been well examined. Particularly, in this\nwork, we propose a new method Granular Multi-modal Attention, where we aim to\nparticularly address the question of the right granularity at which one needs\nto attend while solving the Visual Dialog task. The proposed method shows\nimprovement in both image and text attention networks. We then propose a\ngranular Multi-modal Attention network that jointly attends on the image and\ntext granules and shows the best performance. With this work, we observe that\nobtaining granular attention and doing exhaustive Multi-modal Attention appears\nto be the best way to attend while solving visual dialog.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 10:49:41 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Patro", "Badri N.", ""], ["Patel", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1910.05752", "submitter": "Ziqi Zhang", "authors": "Ziqi Zhang, Yaya Shi, Jiutong Wei, Chunfeng Yuan, Bing Li, Weiming Hu", "title": "VATEX Captioning Challenge 2019: Multi-modal Information Fusion and\n  Multi-stage Training Strategy for Video Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal information is essential to describe what has happened in a\nvideo. In this work, we represent videos by various appearance, motion and\naudio information guided with video topic. By following multi-stage training\nstrategy, our experiments show steady and significant improvement on the VATEX\nbenchmark. This report presents an overview and comparative analysis of our\nsystem designed for both Chinese and English tracks on VATEX Captioning\nChallenge 2019.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 13:54:31 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zhang", "Ziqi", ""], ["Shi", "Yaya", ""], ["Wei", "Jiutong", ""], ["Yuan", "Chunfeng", ""], ["Li", "Bing", ""], ["Hu", "Weiming", ""]]}, {"id": "1910.05786", "submitter": "Xiao Luo", "authors": "Matthew Tang and Priyanka Gandhi and Md Ahsanul Kabir and Christopher\n  Zou and Jordyn Blakey and Xiao Luo", "title": "Progress Notes Classification and Keyword Extraction using\n  Attention-based Deep Learning Models with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various deep learning algorithms have been developed to analyze different\ntypes of clinical data including clinical text classification and extracting\ninformation from 'free text' and so on. However, automate the keyword\nextraction from the clinical notes is still challenging. The challenges include\ndealing with noisy clinical notes which contain various abbreviations, possible\ntypos, and unstructured sentences. The objective of this research is to\ninvestigate the attention-based deep learning models to classify the\nde-identified clinical progress notes extracted from a real-world EHR system.\nThe attention-based deep learning models can be used to interpret the models\nand understand the critical words that drive the correct or incorrect\nclassification of the clinical progress notes. The attention-based models in\nthis research are capable of presenting the human interpretable text\nclassification models. The results show that the fine-tuned BERT with the\nattention layer can achieve a high classification accuracy of 97.6%, which is\nhigher than the baseline fine-tuned BERT classification model. In this\nresearch, we also demonstrate that the attention-based models can identify\nrelevant keywords that are strongly related to the clinical progress note\ncategories.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 16:54:21 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 16:20:06 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Tang", "Matthew", ""], ["Gandhi", "Priyanka", ""], ["Kabir", "Md Ahsanul", ""], ["Zou", "Christopher", ""], ["Blakey", "Jordyn", ""], ["Luo", "Xiao", ""]]}, {"id": "1910.05895", "submitter": "Julian Salazar", "authors": "Toan Q. Nguyen and Julian Salazar", "title": "Transformers without Tears: Improving the Normalization of\n  Self-Attention", "comments": "Accepted to IWSLT 2019 (oral); code is available at\n  https://github.com/tnq177/transformers_without_tears", "journal-ref": null, "doi": "10.5281/zenodo.3525484", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate three simple, normalization-centric changes to improve\nTransformer training. First, we show that pre-norm residual connections\n(PreNorm) and smaller initializations enable warmup-free, validation-based\ntraining with large learning rates. Second, we propose $\\ell_2$ normalization\nwith a single scale parameter (ScaleNorm) for faster training and better\nperformance. Finally, we reaffirm the effectiveness of normalizing word\nembeddings to a fixed length (FixNorm). On five low-resource translation pairs\nfrom TED Talks-based corpora, these changes always converge, giving an average\n+1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on\nIWSLT'15 English-Vietnamese. We observe sharper performance curves, more\nconsistent gradient norms, and a linear relationship between activation scaling\nand decoder depth. Surprisingly, in the high-resource setting (WMT'14\nEnglish-German), ScaleNorm and FixNorm remain competitive but PreNorm degrades\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 02:23:43 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 03:53:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Nguyen", "Toan Q.", ""], ["Salazar", "Julian", ""]]}, {"id": "1910.05915", "submitter": "Shengluan Hou", "authors": "Shengluan Hou and Ruqian Lu", "title": "Knowledge-guided Unsupervised Rhetorical Parsing for Text Summarization", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization (ATS) has recently achieved impressive\nperformance thanks to recent advances in deep learning and the availability of\nlarge-scale corpora. To make the summarization results more faithful, this\npaper presents an unsupervised approach that combines rhetorical structure\ntheory, deep neural model and domain knowledge concern for ATS. This\narchitecture mainly contains three components: domain knowledge base\nconstruction based on representation learning, attentional encoder-decoder\nmodel for rhetorical parsing and subroutine-based model for text summarization.\nDomain knowledge can be effectively used for unsupervised rhetorical parsing\nthus rhetorical structure trees for each document can be derived. In the\nunsupervised rhetorical parsing module, the idea of translation was adopted to\nalleviate the problem of data scarcity. The subroutine-based summarization\nmodel purely depends on the derived rhetorical structure trees and can generate\ncontent-balanced results. To evaluate the summary results without golden\nstandard, we proposed an unsupervised evaluation metric, whose hyper-parameters\nwere tuned by supervised learning. Experimental results show that, on a\nlarge-scale Chinese dataset, our proposed approach can obtain comparable\nperformances compared with existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 04:48:16 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Hou", "Shengluan", ""], ["Lu", "Ruqian", ""]]}, {"id": "1910.06036", "submitter": "Yifan Gao", "authors": "Jingjing Li, Yifan Gao, Lidong Bing, Irwin King, Michael R. Lyu", "title": "Improving Question Generation With to the Point Context", "comments": "EMNLP19, fix wordings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question generation (QG) is the task of generating a question from a\nreference sentence and a specified answer within the sentence. A major\nchallenge in QG is to identify answer-relevant context words to finish the\ndeclarative-to-interrogative sentence transformation. Existing\nsequence-to-sequence neural models achieve this goal by proximity-based answer\nposition encoding under the intuition that neighboring words of answers are of\nhigh possibility to be answer-relevant. However, such intuition may not apply\nto all cases especially for sentences with complex answer-relevant relations.\nConsequently, the performance of these models drops sharply when the relative\ndistance between the answer fragment and other non-stop sentence words that\nalso appear in the ground truth question increases. To address this issue, we\npropose a method to jointly model the unstructured sentence and the structured\nanswer-relevant relation (extracted from the sentence in advance) for question\ngeneration. Specifically, the structured answer-relevant relation acts as the\nto the point context and it thus naturally helps keep the generated question to\nthe point, while the unstructured sentence provides the full information.\nExtensive experiments show that to the point context helps our question\ngeneration model achieve significant improvements on several automatic\nevaluation metrics. Furthermore, our model is capable of generating diverse\nquestions for a sentence which conveys multiple relations of its answer\nfragment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:03:55 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 09:51:33 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Li", "Jingjing", ""], ["Gao", "Yifan", ""], ["Bing", "Lidong", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1910.06048", "submitter": "Kashyap Popat", "authors": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum", "title": "STANCY: Stance Classification Based on Consistency Cues", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controversial claims are abundant in online media and discussion forums. A\nbetter understanding of such claims requires analyzing them from different\nperspectives. Stance classification is a necessary step for inferring these\nperspectives in terms of supporting or opposing the claim. In this work, we\npresent a neural network model for stance classification leveraging BERT\nrepresentations and augmenting them with a novel consistency constraint.\nExperiments on the Perspectrum dataset, consisting of claims and users'\nperspectives from various debate websites, demonstrate the effectiveness of our\napproach over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:39:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Popat", "Kashyap", ""], ["Mukherjee", "Subhabrata", ""], ["Yates", "Andrew", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1910.06061", "submitter": "Lukas Lange", "authors": "Lukas Lange, Michael A. Hedderich, Dietrich Klakow", "title": "Feature-Dependent Confusion Matrices for Low-Resource NER Labeling with\n  Noisy Labels", "comments": "Published at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-resource settings, the performance of supervised labeling models can\nbe improved with automatically annotated or distantly supervised data, which is\ncheap to create but often noisy. Previous works have shown that significant\nimprovements can be reached by injecting information about the confusion\nbetween clean and noisy labels in this additional training data into the\nclassifier training. However, for noise estimation, these approaches either do\nnot take the input features (in our case word embeddings) into account, or they\nneed to learn the noise modeling from scratch which can be difficult in a\nlow-resource setting. We propose to cluster the training data using the input\nfeatures and then compute different confusion matrices for each cluster. To the\nbest of our knowledge, our approach is the first to leverage feature-dependent\nnoise modeling with pre-initialized confusion matrices. We evaluate on\nlow-resource named entity recognition settings in several languages, showing\nthat our methods improve upon other confusion-matrix based methods by up to 9%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 12:03:07 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 23:20:44 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lange", "Lukas", ""], ["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1910.06188", "submitter": "Ofir Zafrir", "authors": "Ofir Zafrir, Guy Boudoukh, Peter Izsak, Moshe Wasserblat", "title": "Q8BERT: Quantized 8Bit BERT", "comments": "5 Pages, Accepted at the 5th Workshop on Energy Efficient Machine\n  Learning and Cognitive Computing - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained Transformer based language models such as BERT and GPT,\nhave shown great improvement in many Natural Language Processing (NLP) tasks.\nHowever, these models contain a large amount of parameters. The emergence of\neven larger and more accurate models such as GPT2 and Megatron, suggest a trend\nof large pre-trained Transformer models. However, using these large models in\nproduction environments is a complex task requiring a large amount of compute,\nmemory and power resources. In this work we show how to perform\nquantization-aware training during the fine-tuning phase of BERT in order to\ncompress BERT by $4\\times$ with minimal accuracy loss. Furthermore, the\nproduced quantized model can accelerate inference speed if it is optimized for\n8bit Integer supporting hardware.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 14:55:19 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 17:15:24 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Zafrir", "Ofir", ""], ["Boudoukh", "Guy", ""], ["Izsak", "Peter", ""], ["Wasserblat", "Moshe", ""]]}, {"id": "1910.06204", "submitter": "Mikel Forcada Dr.", "authors": "Carolina Scarton and Mikel L. Forcada and Miquel Espl\\`a-Gomis and\n  Lucia Specia", "title": "Estimating post-editing effort: a study on human judgements, task-based\n  and reference-based metrics of MT quality", "comments": "IWSLT 2019, Hong Kong, November 2 and 3, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devising metrics to assess translation quality has always been at the core of\nmachine translation (MT) research. Traditional automatic reference-based\nmetrics, such as BLEU, have shown correlations with human judgements of\nadequacy and fluency and have been paramount for the advancement of MT system\ndevelopment. Crowd-sourcing has popularised and enabled the scalability of\nmetrics based on human judgements, such as subjective direct assessments (DA)\nof adequacy, that are believed to be more reliable than reference-based\nautomatic metrics. Finally, task-based measurements, such as post-editing time,\nare expected to provide a more detailed evaluation of the usefulness of\ntranslations for a specific task. Therefore, while DA averages adequacy\njudgements to obtain an appraisal of (perceived) quality independently of the\ntask, and reference-based automatic metrics try to objectively estimate quality\nalso in a task-independent way, task-based metrics are measurements obtained\neither during or after performing a specific task. In this paper we argue that,\nalthough expensive, task-based measurements are the most reliable when\nestimating MT quality in a specific task; in our case, this task is\npost-editing. To that end, we report experiments on a dataset with\nnewly-collected post-editing indicators and show their usefulness when\nestimating post-editing effort. Our results show that task-based metrics\ncomparing machine-translated and post-edited versions are the best at tracking\npost-editing effort, as expected. These metrics are followed by DA, and then by\nmetrics comparing the machine-translated version and independent references. We\nsuggest that MT practitioners should be aware of these differences and\nacknowledge their implications when deciding how to evaluate MT for\npost-editing purposes.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 15:20:30 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Scarton", "Carolina", ""], ["Forcada", "Mikel L.", ""], ["Espl\u00e0-Gomis", "Miquel", ""], ["Specia", "Lucia", ""]]}, {"id": "1910.06241", "submitter": "Piotr Bojanowski", "authors": "Piotr Bojanowski, Onur Celebi, Tomas Mikolov, Edouard Grave, Armand\n  Joulin", "title": "Updating Pre-trained Word Vectors and Text Classifiers using Monolingual\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the problem of adapting word vector-based models\nto new textual data. Given a model pre-trained on large reference data, how can\nwe adapt it to a smaller piece of data with a slightly different language\ndistribution? We frame the adaptation problem as a monolingual word vector\nalignment problem, and simply average models after alignment. We align vectors\nusing the RCSLS criterion. Our formulation results in a simple and efficient\nalgorithm that allows adapting general-purpose models to changing word\ndistributions. In our evaluation, we consider applications to word embedding\nand text classification models. We show that the proposed approach yields good\nperformance in all setups and outperforms a baseline consisting in fine-tuning\nthe model on new data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:19:20 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 08:12:03 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Bojanowski", "Piotr", ""], ["Celebi", "Onur", ""], ["Mikolov", "Tomas", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""]]}, {"id": "1910.06262", "submitter": "Yannis Assael", "authors": "Yannis Assael, Thea Sommerschield, Jonathan Prag", "title": "Restoring ancient text using deep learning: a case study on Greek\n  epigraphy", "comments": null, "journal-ref": "Empirical Methods in Natural Language Processing (EMNLP) 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancient history relies on disciplines such as epigraphy, the study of ancient\ninscribed texts, for evidence of the recorded past. However, these texts,\n\"inscriptions\", are often damaged over the centuries, and illegible parts of\nthe text must be restored by specialists, known as epigraphists. This work\npresents Pythia, the first ancient text restoration model that recovers missing\ncharacters from a damaged text input using deep neural networks. Its\narchitecture is carefully designed to handle long-term context information, and\ndeal efficiently with missing or corrupted character and word representations.\nTo train it, we wrote a non-trivial pipeline to convert PHI, the largest\ndigital corpus of ancient Greek inscriptions, to machine actionable text, which\nwe call PHI-ML. On PHI-ML, Pythia's predictions achieve a 30.1% character error\nrate, compared to the 57.3% of human epigraphists. Moreover, in 73.5% of cases\nthe ground-truth sequence was among the Top-20 hypotheses of Pythia, which\neffectively demonstrates the impact of this assistive method on the field of\ndigital epigraphy, and sets the state-of-the-art in ancient text restoration.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 16:43:00 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Assael", "Yannis", ""], ["Sommerschield", "Thea", ""], ["Prag", "Jonathan", ""]]}, {"id": "1910.06294", "submitter": "Peter Izsak", "authors": "Peter Izsak, Shira Guskin, Moshe Wasserblat", "title": "Training Compact Models for Low Resource Entity Tagging using\n  Pre-trained Language Models", "comments": "Accepted to the 5th Workshop on Energy Efficient Machine Learning and\n  Cognitive Computing - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training models on low-resource named entity recognition tasks has been shown\nto be a challenge, especially in industrial applications where deploying\nupdated models is a continuous effort and crucial for business operations. In\nsuch cases there is often an abundance of unlabeled data, while labeled data is\nscarce or unavailable. Pre-trained language models trained to extract\ncontextual features from text were shown to improve many natural language\nprocessing (NLP) tasks, including scarcely labeled tasks, by leveraging\ntransfer learning. However, such models impose a heavy memory and computational\nburden, making it a challenge to train and deploy such models for inference\nuse. In this work-in-progress we combined the effectiveness of transfer\nlearning provided by pre-trained masked language models with a semi-supervised\napproach to train a fast and compact model using labeled and unlabeled\nexamples. Preliminary evaluations show that the compact models can achieve\ncompetitive accuracy with 36x compression rate when compared with a\nstate-of-the-art pre-trained language model, and run significantly faster in\ninference, allowing deployment of such models in production environments or on\nedge devices.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:22:37 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 08:07:19 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Izsak", "Peter", ""], ["Guskin", "Shira", ""], ["Wasserblat", "Moshe", ""]]}, {"id": "1910.06315", "submitter": "Badri Narayana Patro", "authors": "Soumik Dasgupta, Badri N. Patro, and Vinay P. Namboodiri", "title": "Dynamic Attention Networks for Task Oriented Grounding", "comments": "Accepted ICCV 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to successfully perform tasks specified by natural language\ninstructions, an artificial agent operating in a visual world needs to map\nwords, concepts, and actions from the instruction to visual elements in its\nenvironment. This association is termed as Task-Oriented Grounding. In this\nwork, we propose a novel Dynamic Attention Network architecture for the\nefficient multi-modal fusion of text and visual representations which can\ngenerate a robust definition of state for the policy learner. Our model assumes\nno prior knowledge from visual and textual domains and is an end to end\ntrainable. For a 3D visual world where the observation changes continuously,\nthe attention on the visual elements tends to be highly co-related from a\none-time step to the next. We term this as \"Dynamic Attention\". In this work,\nwe show that Dynamic Attention helps in achieving grounding and also aids in\nthe policy learning objective. Since most practical robotic applications take\nplace in the real world where the observation space is continuous, our\nframework can be used as a generalized multi-modal fusion unit for robotic\ncontrol through natural language. We show the effectiveness of using 1D\nconvolution over Gated Attention Hadamard product on the rate of convergence of\nthe network. We demonstrate that the cell-state of a Long Short Term Memory\n(LSTM) is a natural choice for modeling Dynamic Attention and shows through\nvisualization that the generated attention is very close to how humans tend to\nfocus on the environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 17:57:21 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Dasgupta", "Soumik", ""], ["Patro", "Badri N.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1910.06360", "submitter": "Jeffrey McCarley", "authors": "J.S. McCarley, Rishav Chakravarti, and Avirup Sil", "title": "Structured Pruning of a BERT-based Question Answering Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent trend in industry-setting Natural Language Processing (NLP)\nresearch has been to operate large %scale pretrained language models like BERT\nunder strict computational limits. While most model compression work has\nfocused on \"distilling\" a general-purpose language representation using\nexpensive pretraining distillation, less attention has been paid to creating\nsmaller task-specific language representations which, arguably, are more useful\nin an industry setting. In this paper, we investigate compressing BERT- and\nRoBERTa-based question answering systems by structured pruning of parameters\nfrom the underlying transformer model. We find that an inexpensive combination\nof task-specific structured pruning and task-specific distillation, without the\nexpense of pretraining distillation, yields highly-performing models across a\nrange of speed/accuracy tradeoff operating points. We start from existing\nfull-size models trained for SQuAD 2.0 or Natural Questions and introduce gates\nthat allow selected parts of transformers to be individually eliminated.\nSpecifically, we investigate (1) structured pruning to reduce the number of\nparameters in each transformer layer, (2) applicability to both BERT- and\nRoBERTa-based models, (3) applicability to both SQuAD 2.0 and Natural\nQuestions, and (4) combining structured pruning with distillation. We achieve a\nnear-doubling of inference speed with less than a 0.5 F1-point loss in short\nanswer accuracy on Natural Questions.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 18:12:30 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:23:14 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 18:53:43 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["McCarley", "J. S.", ""], ["Chakravarti", "Rishav", ""], ["Sil", "Avirup", ""]]}, {"id": "1910.06393", "submitter": "Zachary Kaden", "authors": "Zachary Kaden, Teven Le Scao, Raphael Olivier", "title": "In-training Matrix Factorization for Parameter-frugal Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the use of in-training matrix factorization to\nreduce the model size for neural machine translation. Using in-training matrix\nfactorization, parameter matrices may be decomposed into the products of\nsmaller matrices, which can compress large machine translation architectures by\nvastly reducing the number of learnable parameters. We apply in-training matrix\nfactorization to different layers of standard neural architectures and show\nthat in-training factorization is capable of reducing nearly 50% of learnable\nparameters without any associated loss in BLEU score. Further, we find that\nin-training matrix factorization is especially powerful on embedding layers,\nproviding a simple and effective method to curtail the number of parameters\nwith minimal impact on model performance, and, at times, an increase in\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 08:58:55 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 18:17:20 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Kaden", "Zachary", ""], ["Scao", "Teven Le", ""], ["Olivier", "Raphael", ""]]}, {"id": "1910.06411", "submitter": "Sourav Dutta", "authors": "Sourav Dutta (1) ((1) Saarland University)", "title": "Mapping Supervised Bilingual Word Embeddings from English to\n  low-resource languages", "comments": "7 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is very challenging to work with low-resource languages due to the\ninadequate availability of data. Using a dictionary to map independently\ntrained word embeddings into a shared vector space has proved to be very useful\nin learning bilingual embeddings in the past. Here we have tried to map\nindividual embeddings of words in English and their corresponding translated\nwords in low-resource languages like Estonian, Slovenian, Slovakian, and\nHungarian. We have used a supervised learning approach. We report accuracy\nscores through various retrieval strategies which show that it is possible to\napproach challenging tasks in Natural Language Processing like machine\ntranslation for such languages, provided that we have at least some amount of\nproper bilingual data. We also conclude that we can follow an unsupervised\nlearning path on monolingual text data as that is more suitable for\nlow-resource languages.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 20:32:41 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Dutta", "Sourav", "", "Saarland University"]]}, {"id": "1910.06426", "submitter": "Feng Xu", "authors": "Shuangjie Xu, Feng Xu, Yu Cheng, Pan Zhou", "title": "Tell-the-difference: Fine-grained Visual Descriptor via a Discriminating\n  Referee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate a novel problem of telling the difference\nbetween image pairs in natural language. Compared to previous approaches for\nsingle image captioning, it is challenging to fetch linguistic representation\nfrom two independent visual information. To this end, we have proposed an\neffective encoder-decoder caption framework based on Hyper Convolution Net. In\naddition, a series of novel feature fusing techniques for pairwise visual\ninformation fusing are introduced and a discriminating referee is proposed to\nevaluate the pipeline. Because of the lack of appropriate datasets to support\nthis task, we have collected and annotated a large new dataset with Amazon\nMechanical Turk (AMT) for generating captions in a pairwise manner (with 14764\nimages and 26710 image pairs in total). The dataset is the first one on the\nrelative difference caption task that provides descriptions in free language.\nWe evaluate the effectiveness of our model on two datasets in the field and it\noutperforms the state-of-the-art approach by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 21:21:03 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Xu", "Shuangjie", ""], ["Xu", "Feng", ""], ["Cheng", "Yu", ""], ["Zhou", "Pan", ""]]}, {"id": "1910.06431", "submitter": "Sourav Dutta", "authors": "Ekaterina Arkhangelskaia (1), Sourav Dutta (1) ((1) Saarland\n  University)", "title": "Whatcha lookin' at? DeepLIFTing BERT's Attention in Question Answering", "comments": "6 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been great success recently in tackling challenging NLP tasks by\nneural networks which have been pre-trained and fine-tuned on large amounts of\ntask data. In this paper, we investigate one such model, BERT for\nquestion-answering, with the aim to analyze why it is able to achieve\nsignificantly better results than other models. We run DeepLIFT on the model\npredictions and test the outcomes to monitor shift in the attention values for\ninput. We also cluster the results to analyze any possible patterns similar to\nhuman reasoning depending on the kind of input paragraph and question the model\nis trying to answer.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 21:32:38 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Arkhangelskaia", "Ekaterina", ""], ["Dutta", "Sourav", ""]]}, {"id": "1910.06492", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang, Philip S.Yu and Yuan Luo", "title": "Hierarchical Semantic Correspondence Learning for Post-Discharge Patient\n  Mortality Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting patient mortality is an important and challenging problem in the\nhealthcare domain, especially for intensive care unit (ICU) patients.\nElectronic health notes serve as a rich source for learning patient\nrepresentations, that can facilitate effective risk assessment. However, a\nlarge portion of clinical notes are unstructured and also contain domain\nspecific terminologies, from which we need to extract structured information.\nIn this paper, we introduce an embedding framework to learn\nsemantically-plausible distributed representations of clinical notes that\nexploits the semantic correspondence between the unstructured texts and their\ncorresponding structured knowledge, known as semantic frame, in a hierarchical\nfashion. Our approach integrates text modeling and semantic correspondence\nlearning into a single model that comprises 1) an unstructured embedding module\nthat makes use of self-similarity matrix representations in order to inject\nstructural regularities of different segments inherent in clinical texts to\npromote local coherence, 2) a structured embedding module to embed the semantic\nframes (e.g., UMLS semantic types) with deep ConvNet and 3) a hierarchical\nsemantic correspondence module that embeds by enhancing the interactions\nbetween text-semantic frame embedding pairs at multiple levels (i.e., words,\nsentence, note). Evaluations on multiple embedding benchmarks on post discharge\nintensive care patient mortality prediction tasks demonstrate its effectiveness\ncompared to approaches that do not exploit the semantic interactions between\nstructured and unstructured information present in clinical notes.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:40:29 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""], ["Luo", "Yuan", ""]]}, {"id": "1910.06522", "submitter": "Xuankai Chang", "authors": "Xuankai Chang, Wangyou Zhang, Yanmin Qian, Jonathan Le Roux, Shinji\n  Watanabe", "title": "MIMO-SPEECH: End-to-End Multi-Channel Multi-Speaker Speech Recognition", "comments": "Accepted at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the end-to-end approach has proven its efficacy in monaural\nmulti-speaker speech recognition. However, high word error rates (WERs) still\nprevent these systems from being used in practical applications. On the other\nhand, the spatial information in multi-channel signals has proven helpful in\nfar-field speech recognition tasks. In this work, we propose a novel neural\nsequence-to-sequence (seq2seq) architecture, MIMO-Speech, which extends the\noriginal seq2seq to deal with multi-channel input and multi-channel output so\nthat it can fully model multi-channel multi-speaker speech separation and\nrecognition. MIMO-Speech is a fully neural end-to-end framework, which is\noptimized only via an ASR criterion. It is comprised of: 1) a monaural masking\nnetwork, 2) a multi-source neural beamformer, and 3) a multi-output speech\nrecognition model. With this processing, the input overlapped speech is\ndirectly mapped to text sequences. We further adopted a curriculum learning\nstrategy, making the best use of the training set to improve the performance.\nThe experiments on the spatialized wsj1-2mix corpus show that our model can\nachieve more than 60% WER reduction compared to the single-channel system with\nhigh quality enhanced signals (SI-SDR = 23.1 dB) obtained by the above\nseparation function.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 04:45:34 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 02:18:14 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Chang", "Xuankai", ""], ["Zhang", "Wangyou", ""], ["Qian", "Yanmin", ""], ["Roux", "Jonathan Le", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1910.06558", "submitter": "Hoang-Quoc Nguyen-Son", "authors": "Hoang-Quoc Nguyen-Son, Tran Phuong Thao, Seira Hidano, Shinsaku\n  Kiyomoto", "title": "Detecting Machine-Translated Text using Back Translation", "comments": "INLG 2019, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-translated text plays a crucial role in the communication of people\nusing different languages. However, adversaries can use such text for malicious\npurposes such as plagiarism and fake review. The existing methods detected a\nmachine-translated text only using the text's intrinsic content, but they are\nunsuitable for classifying the machine-translated and human-written texts with\nthe same meanings. We have proposed a method to extract features used to\ndistinguish machine/human text based on the similarity between the intrinsic\ntext and its back-translation. The evaluation of detecting translated sentences\nwith French shows that our method achieves 75.0% of both accuracy and F-score.\nIt outperforms the existing methods whose the best accuracy is 62.8% and the\nF-score is 62.7%. The proposed method even detects more efficiently the\nback-translated text with 83.4% of accuracy, which is higher than 66.7% of the\nbest previous accuracy. We also achieve similar results not only with F-score\nbut also with similar experiments related to Japanese. Moreover, we prove that\nour detector can recognize both machine-translated and machine-back-translated\ntexts without the language information which is used to generate these machine\ntexts. It demonstrates the persistence of our method in various applications in\nboth low- and rich-resource languages.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 06:54:28 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Nguyen-Son", "Hoang-Quoc", ""], ["Thao", "Tran Phuong", ""], ["Hidano", "Seira", ""], ["Kiyomoto", "Shinsaku", ""]]}, {"id": "1910.06571", "submitter": "Yanyan Zou", "authors": "Yanyan Zou and Wei Lu", "title": "Text2Math: End-to-end Parsing Text into Math Expressions", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose Text2Math, a model for semantically parsing text into math\nexpressions. The model can be used to solve different math related problems\nincluding arithmetic word problems and equation parsing problems. Unlike\nprevious approaches, we tackle the problem from an end-to-end structured\nprediction perspective where our algorithm aims to predict the complete math\nexpression at once as a tree structure, where minimal manual efforts are\ninvolved in the process. Empirical results on benchmark datasets demonstrate\nthe efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 07:44:54 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zou", "Yanyan", ""], ["Lu", "Wei", ""]]}, {"id": "1910.06575", "submitter": "Yanyan Zou", "authors": "Hsiu-Wei Yang, Yanyan Zou, Peng Shi, Wei Lu, Jimmy Lin, and Xu Sun", "title": "Aligning Cross-Lingual Entities with Multi-Aspect Information", "comments": "Accepted by EMNLP19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multilingual knowledge graphs (KGs), such as YAGO and DBpedia, represent\nentities in different languages. The task of cross-lingual entity alignment is\nto match entities in a source language with their counterparts in target\nlanguages. In this work, we investigate embedding-based approaches to encode\nentities from multilingual KGs into the same vector space, where equivalent\nentities are close to each other. Specifically, we apply graph convolutional\nnetworks (GCNs) to combine multi-aspect information of entities, including\ntopological connections, relations, and attributes of entities, to learn entity\nembeddings. To exploit the literal descriptions of entities expressed in\ndifferent languages, we propose two uses of a pretrained multilingual BERT\nmodel to bridge cross-lingual gaps. We further propose two strategies to\nintegrate GCN-based and BERT-based modules to boost performance. Extensive\nexperiments on two benchmark datasets demonstrate that our method significantly\noutperforms existing systems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 07:54:12 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Yang", "Hsiu-Wei", ""], ["Zou", "Yanyan", ""], ["Shi", "Peng", ""], ["Lu", "Wei", ""], ["Lin", "Jimmy", ""], ["Sun", "Xu", ""]]}, {"id": "1910.06592", "submitter": "Bilal Ghanem", "authors": "Bilal Ghanem, Simone Paolo Ponzetto, Paolo Rosso", "title": "FacTweet: Profiling Fake News Twitter Accounts", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to detect fake news in Twitter at the account level\nusing a neural recurrent model and a variety of different semantic and\nstylistic features. Our method extracts a set of features from the timelines of\nnews Twitter accounts by reading their posts as chunks, rather than dealing\nwith each tweet independently. We show the experimental benefits of modeling\nlatent stylistic signatures of mixed fake and real news with a sequential model\nover a wide range of strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 08:43:47 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ghanem", "Bilal", ""], ["Ponzetto", "Simone Paolo", ""], ["Rosso", "Paolo", ""]]}, {"id": "1910.06700", "submitter": "Gabriel Marzinotto", "authors": "Gabriel Marzinotto (TALEP), Geraldine Damnati, Fr\\'ed\\'eric B\\'echet\n  (TALEP), Benoit Favre (LIF)", "title": "Robust Semantic Parsing with Adversarial Learning for Domain\n  Generalization", "comments": null, "journal-ref": "Proceedings of the 2019 Conference of the North, Jun 2019,\n  Minneapolis - Minnesota, France. pp.166-173", "doi": "10.18653/v1/N19-2021", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the issue of generalization for Semantic Parsing in an\nadversarial framework. Building models that are more robust to inter-document\nvariability is crucial for the integration of Semantic Parsing technologies in\nreal applications. The underlying question throughout this study is whether\nadversarial learning can be used to train models on a higher level of\nabstraction in order to increase their robustness to lexical and stylistic\nvariations.We propose to perform Semantic Parsing with a domain classification\nadversarial task without explicit knowledge of the domain. The strategy is\nfirst evaluated on a French corpus of encyclopedic documents, annotated with\nFrameNet, in an information retrieval perspective, then on PropBank Semantic\nRole Labeling task on the CoNLL-2005 benchmark. We show that adversarial\nlearning increases all models generalization capabilities both on in and\nout-of-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 09:23:35 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Marzinotto", "Gabriel", "", "TALEP"], ["Damnati", "Geraldine", "", "TALEP"], ["B\u00e9chet", "Fr\u00e9d\u00e9ric", "", "TALEP"], ["Favre", "Benoit", "", "LIF"]]}, {"id": "1910.06701", "submitter": "Peng Li", "authors": "Qiu Ran, Yankai Lin, Peng Li, Jie Zhou, Zhiyuan Liu", "title": "NumNet: Machine Reading Comprehension with Numerical Reasoning", "comments": "Accepted to EMNLP2019; 11 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical reasoning, such as addition, subtraction, sorting and counting is a\ncritical skill in human's reading comprehension, which has not been well\nconsidered in existing machine reading comprehension (MRC) systems. To address\nthis issue, we propose a numerical MRC model named as NumNet, which utilizes a\nnumerically-aware graph neural network to consider the comparing information\nand performs numerical reasoning over numbers in the question and passage. Our\nsystem achieves an EM-score of 64.56% on the DROP dataset, outperforming all\nexisting machine reading comprehension models by considering the numerical\nrelations among numbers.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:09:06 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Ran", "Qiu", ""], ["Lin", "Yankai", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1910.06707", "submitter": "Junjie Yin", "authors": "Junjie Yin, Zixun Chen, Kelai Zhou, Chongyuan Yu", "title": "A Deep Learning Based Chatbot for Campus Psychological Therapy", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Evebot, an innovative, sequence to sequence\n(Seq2seq) based, fully generative conversational system for the diagnosis of\nnegative emotions and prevention of depression through positively suggestive\nresponses. The system consists of an assembly of deep-learning based models,\nincluding Bi-LSTM based model for detecting negative emotions of users and\nobtaining psychological counselling related corpus for training the chatbot,\nanti-language sequence to sequence neural network, and maximum mutual\ninformation (MMI) model. As adolescents are reluctant to show their negative\nemotions in physical interaction, traditional methods of emotion analysis and\ncomforting methods may not work. Therefore, this system puts emphasis on using\nvirtual platform to detect signs of depression or anxiety, channel adolescents'\nstress and mood, and thus prevent the emergence of mental illness. We launched\nthe integrated chatbot system onto an online platform for real-world campus\napplications. Through a one-month user study, we observe better results in the\nincrease in positivity than other public chatbots in the control group.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 15:34:28 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Yin", "Junjie", ""], ["Chen", "Zixun", ""], ["Zhou", "Kelai", ""], ["Yu", "Chongyuan", ""]]}, {"id": "1910.06710", "submitter": "Tiffany Callahan", "authors": "Tiffany J. Callahan (1), Harrison Pielke-Lombardo (1), Ignacio J.\n  Tripodi (1 and 2), and Lawrence E. Hunter (1) ((1) Computational Bioscience\n  Program, Department of Pharmacology, University of Colorado Denver Anschutz\n  Medical Campus, (2) Computer Science, University of Colorado Boulder)", "title": "Knowledge-based Biomedical Data Science 2019", "comments": "Manuscript 43 pages with 3 tables; Supplemental material 43 pages\n  with 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge-based biomedical data science (KBDS) involves the design and\nimplementation of computer systems that act as if they knew about biomedicine.\nSuch systems depend on formally represented knowledge in computer systems,\noften in the form of knowledge graphs. Here we survey the progress in the last\nyear in systems that use formally represented knowledge to address data science\nproblems in both clinical and biological domains, as well as on approaches for\ncreating knowledge graphs. Major themes include the relationships between\nknowledge graphs and machine learning, the use of natural language processing,\nand the expansion of knowledge-based approaches to novel domains, such as\nChinese Traditional Medicine and biodiversity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 17:28:16 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Callahan", "Tiffany J.", "", "1 and 2"], ["Pielke-Lombardo", "Harrison", "", "1 and 2"], ["Tripodi", "Ignacio J.", "", "1 and 2"], ["Hunter", "Lawrence E.", ""]]}, {"id": "1910.06711", "submitter": "Rithesh Kumar", "authors": "Kundan Kumar, Rithesh Kumar, Thibault de Boissiere, Lucas Gestin, Wei\n  Zhen Teoh, Jose Sotelo, Alexandre de Brebisson, Yoshua Bengio, Aaron\n  Courville", "title": "MelGAN: Generative Adversarial Networks for Conditional Waveform\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works (Donahue et al., 2018a; Engel et al., 2019a) have found that\ngenerating coherent raw audio waveforms with GANs is challenging. In this\npaper, we show that it is possible to train GANs reliably to generate high\nquality coherent waveforms by introducing a set of architectural changes and\nsimple training techniques. Subjective evaluation metric (Mean Opinion Score,\nor MOS) shows the effectiveness of the proposed approach for high quality\nmel-spectrogram inversion. To establish the generality of the proposed\ntechniques, we show qualitative results of our model in speech synthesis, music\ndomain translation and unconditional music synthesis. We evaluate the various\ncomponents of the model through ablation studies and suggest a set of\nguidelines to design general purpose discriminators and generators for\nconditional sequence synthesis tasks. Our model is non-autoregressive, fully\nconvolutional, with significantly fewer parameters than competing models and\ngeneralizes to unseen speakers for mel-spectrogram inversion. Our pytorch\nimplementation runs at more than 100x faster than realtime on GTX 1080Ti GPU\nand more than 2x faster than real-time on CPU, without any hardware specific\noptimization tricks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 15:03:08 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 12:00:53 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 01:17:32 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Kumar", "Kundan", ""], ["Kumar", "Rithesh", ""], ["de Boissiere", "Thibault", ""], ["Gestin", "Lucas", ""], ["Teoh", "Wei Zhen", ""], ["Sotelo", "Jose", ""], ["de Brebisson", "Alexandre", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1910.06717", "submitter": "Kenton Murray", "authors": "Kenton Murray, Jeffery Kinnison, Toan Q. Nguyen, Walter Scheirer,\n  David Chiang", "title": "Auto-Sizing the Transformer Network: Improving Speed, Efficiency, and\n  Performance for Low-Resource Machine Translation", "comments": "The 3rd Workshop on Neural Generation and Translation (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence models, particularly the Transformer, are the\nstate of the art in machine translation. Yet these neural networks are very\nsensitive to architecture and hyperparameter settings. Optimizing these\nsettings by grid or random search is computationally expensive because it\nrequires many training runs. In this paper, we incorporate architecture search\ninto a single training run through auto-sizing, which uses regularization to\ndelete neurons in a network over the course of training. On very low-resource\nlanguage pairs, we show that auto-sizing can improve BLEU scores by up to 3.9\npoints while removing one-third of the parameters from the model.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 19:21:26 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Murray", "Kenton", ""], ["Kinnison", "Jeffery", ""], ["Nguyen", "Toan Q.", ""], ["Scheirer", "Walter", ""], ["Chiang", "David", ""]]}, {"id": "1910.06719", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Pawe{\\l} Budzianowski, Yen-Chen Wu, Milica\n  Ga\\v{s}i\\'c", "title": "Tree-Structured Semantic Encoder with Knowledge Sharing for Domain\n  Adaptation in Natural Language Generation", "comments": "Published in SIGDIAL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation in natural language generation (NLG) remains challenging\nbecause of the high complexity of input semantics across domains and limited\ndata of a target domain. This is particularly the case for dialogue systems,\nwhere we want to be able to seamlessly include new domains into the\nconversation. Therefore, it is crucial for generation models to share knowledge\nacross domains for the effective adaptation from one domain to another. In this\nstudy, we exploit a tree-structured semantic encoder to capture the internal\nstructure of complex semantic representations required for multi-domain\ndialogues in order to facilitate knowledge sharing across domains. In addition,\na layer-wise attention mechanism between the tree encoder and the decoder is\nadopted to further improve the model's capability. The automatic evaluation\nresults show that our model outperforms previous methods in terms of the BLEU\nscore and the slot error rate, in particular when the adaptation data is\nlimited. In subjective evaluation, human judges tend to prefer the sentences\ngenerated by our model, rating them more highly on informativeness and\nnaturalness than other systems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:27:11 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Budzianowski", "Pawe\u0142", ""], ["Wu", "Yen-Chen", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1910.06720", "submitter": "Ahmad Rashid", "authors": "Vasileios Lioutas, Ahmad Rashid, Krtin Kumar, Md Akmal Haidar and\n  Mehdi Rezagholizadeh", "title": "Improving Word Embedding Factorization for Compression Using Distilled\n  Nonlinear Neural Decomposition", "comments": "Accepted at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word-embeddings are vital components of Natural Language Processing (NLP)\nmodels and have been extensively explored. However, they consume a lot of\nmemory which poses a challenge for edge deployment. Embedding matrices,\ntypically, contain most of the parameters for language models and about a third\nfor machine translation systems. In this paper, we propose Distilled Embedding,\nan (input/output) embedding compression method based on low-rank matrix\ndecomposition and knowledge distillation. First, we initialize the weights of\nour decomposed matrices by learning to reconstruct the full pre-trained\nword-embedding and then fine-tune end-to-end, employing knowledge distillation\non the factorized embedding. We conduct extensive experiments with various\ncompression rates on machine translation and language modeling, using different\ndata-sets with a shared word-embedding matrix for both embedding and vocabulary\nprojection matrices. We show that the proposed technique is simple to\nreplicate, with one fixed parameter controlling compression size, has higher\nBLEU score on translation and lower perplexity on language modeling compared to\ncomplex, difficult to tune state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:40:03 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 22:59:44 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Rashid", "Ahmad", ""], ["Kumar", "Krtin", ""], ["Haidar", "Md Akmal", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1910.06748", "submitter": "Richard Khoury", "authors": "Duy Tin Vo, Richard Khoury", "title": "Language Identification on Massive Datasets of Short Message using an\n  Attention Mechanism CNN", "comments": "9 pages, 5 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language Identification (LID) is a challenging task, especially when the\ninput texts are short and noisy such as posts and statuses on social media or\nchat logs on gaming forums. The task has been tackled by either designing a\nfeature set for a traditional classifier (e.g. Naive Bayes) or applying a deep\nneural network classifier (e.g. Bi-directional Gated Recurrent Unit,\nEncoder-Decoder). These methods are usually trained and tested on a huge amount\nof private data, then used and evaluated as off-the-shelf packages by other\nresearchers using their own datasets, and consequently the various results\npublished are not directly comparable. In this paper, we first create a new\nmassive labelled dataset based on one year of Twitter data. We use this dataset\nto test several existing language identification systems, in order to obtain a\nset of coherent benchmarks, and we make our dataset publicly available so that\nothers can add to this set of benchmarks. Finally, we propose a shallow but\nefficient neural LID system, which is a ngram-regional convolution neural\nnetwork enhanced with an attention mechanism. Experimental results show that\nour architecture is able to predict tens of thousands of samples per second and\nsurpasses all state-of-the-art systems with an improvement of 5%.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:51:24 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Vo", "Duy Tin", ""], ["Khoury", "Richard", ""]]}, {"id": "1910.06753", "submitter": "Duygu Ataman", "authors": "Duygu Ataman, Orhan Firat, Mattia A. Di Gangi, Marcello Federico and\n  Alexandra Birch", "title": "On the Importance of Word Boundaries in Character-level Neural Machine\n  Translation", "comments": "To appear at the 3rd Workshop on Neural Generation and Translation\n  (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models generally perform translation using a\nfixed-size lexical vocabulary, which is an important bottleneck on their\ngeneralization capability and overall translation quality. The standard\napproach to overcome this limitation is to segment words into subword units,\ntypically using some external tools with arbitrary heuristics, resulting in\nvocabulary units not optimized for the translation task. Recent studies have\nshown that the same approach can be extended to perform NMT directly at the\nlevel of characters, which can deliver translation accuracy on-par with\nsubword-based models, on the other hand, this requires relatively deeper\nnetworks. In this paper, we propose a more computationally-efficient solution\nfor character-level NMT which implements a hierarchical decoding architecture\nwhere translations are subsequently generated at the level of words and\ncharacters. We evaluate different methods for open-vocabulary NMT in the\nmachine translation task from English into five languages with distinct\nmorphological typology, and show that the hierarchical decoding model can reach\nhigher translation accuracy than the subword-level NMT model using\nsignificantly fewer parameters, while demonstrating better capacity in learning\nlonger-distance contextual and grammatical dependencies than the standard\ncharacter-level NMT model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 13:54:44 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 08:52:02 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ataman", "Duygu", ""], ["Firat", "Orhan", ""], ["Di Gangi", "Mattia A.", ""], ["Federico", "Marcello", ""], ["Birch", "Alexandra", ""]]}, {"id": "1910.06826", "submitter": "Ib\\'eria Medeiros", "authors": "Ib\\'eria Medeiros (1), Nuno Neves (1), Miguel Correia (2) ((1) LASIGE,\n  Faculdade de Ci\\^encias, Universidade de Lisboa, Portugal, (2) INESC-ID,\n  Instituto Superior T\\'ecnico, Universidade de Lisboa, Portugal)", "title": "Statically Detecting Vulnerabilities by Processing Programming Languages\n  as Natural Languages", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web applications continue to be a favorite target for hackers due to a\ncombination of wide adoption and rapid deployment cycles, which often lead to\nthe introduction of high impact vulnerabilities. Static analysis tools are\nimportant to search for bugs automatically in the program source code,\nsupporting developers on their removal. However, building these tools requires\nprogramming the knowledge on how to discover the vulnerabilities. This paper\npresents an alternative approach in which tools learn to detect flaws\nautomatically by resorting to artificial intelligence concepts, more concretely\nto natural language processing. The approach employs a sequence model to learn\nto characterize vulnerabilities based on an annotated corpus. Afterwards, the\nmodel is utilized to discover and identify vulnerabilities in the source code.\nIt was implemented in the DEKANT tool and evaluated experimentally with a large\nset of PHP applications and WordPress plugins. Overall, we found several\nhundred vulnerabilities belonging to 12 classes of input validation\nvulnerabilities, where 62 of them were zero-day.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 18:23:42 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Medeiros", "Ib\u00e9ria", ""], ["Neves", "Nuno", ""], ["Correia", "Miguel", ""]]}, {"id": "1910.06848", "submitter": "Peng-Jen Chen", "authors": "Peng-Jen Chen, Jiajun Shen, Matt Le, Vishrav Chaudhary, Ahmed\n  El-Kishky, Guillaume Wenzek, Myle Ott, Marc'Aurelio Ranzato", "title": "Facebook AI's WAT19 Myanmar-English Translation Task Submission", "comments": "The 6th Workshop on Asian Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Facebook AI's submission to the WAT 2019 Myanmar-English\ntranslation task. Our baseline systems are BPE-based transformer models. We\nexplore methods to leverage monolingual data to improve generalization,\nincluding self-training, back-translation and their combination. We further\nimprove results by using noisy channel re-ranking and ensembling. We\ndemonstrate that these techniques can significantly improve not only a system\ntrained with additional monolingual data, but even the baseline system trained\nexclusively on the provided small parallel dataset. Our system ranks first in\nboth directions according to human evaluation and BLEU, with a gain of over 8\nBLEU points above the second best system.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:10:16 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Chen", "Peng-Jen", ""], ["Shen", "Jiajun", ""], ["Le", "Matt", ""], ["Chaudhary", "Vishrav", ""], ["El-Kishky", "Ahmed", ""], ["Wenzek", "Guillaume", ""], ["Ott", "Myle", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1910.06954", "submitter": "Marius C\\u{a}t\\u{a}lin Iordan", "authors": "Marius C\\u{a}t\\u{a}lin Iordan, Tyler Giallanza, Cameron T. Ellis,\n  Nicole M. Beckage, Jonathan D. Cohen", "title": "Context Matters: Recovering Human Semantic Structure from Machine\n  Learning Analysis of Large-Scale Text Corpora", "comments": "Main Text: 35 pages, 5 figures; Supplemental: 21 pages, 11 figures, 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning algorithms to large-scale, text-based corpora\n(embeddings) presents a unique opportunity to investigate at scale how human\nsemantic knowledge is organized and how people use it to judge fundamental\nrelationships, such as similarity between concepts. However, efforts to date\nhave shown a substantial discrepancy between algorithm predictions and\nempirical judgments. Here, we introduce a novel approach of generating\nembeddings motivated by the psychological theory that semantic context plays a\ncritical role in human judgments. Specifically, we train state-of-the-art\nmachine learning algorithms using contextually-constrained text corpora and\nshow that this greatly improves predictions of similarity judgments and feature\nratings. By improving the correspondence between representations derived using\nembeddings generated by machine learning methods and empirical measurements of\nhuman judgments, the approach we describe helps advance the use of large-scale\ntext corpora to understand the structure of human semantic representations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:51:01 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 23:49:12 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 20:41:41 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Iordan", "Marius C\u0103t\u0103lin", ""], ["Giallanza", "Tyler", ""], ["Ellis", "Cameron T.", ""], ["Beckage", "Nicole M.", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "1910.07000", "submitter": "Peng Qi", "authors": "Peng Qi and Xiaowen Lin and Leo Mehr and Zijian Wang and Christopher\n  D. Manning", "title": "Answering Complex Open-domain Questions Through Iterative Query\n  Generation", "comments": "EMNLP-IJCNLP 2019. Xiaowen Lin, Leo Mehr, and Zijian Wang contributed\n  equally. GitHub: https://github.com/qipeng/golden-retriever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging for current one-step retrieve-and-read question answering\n(QA) systems to answer questions like \"Which novel by the author of 'Armada'\nwill be adapted as a feature film by Steven Spielberg?\" because the question\nseldom contains retrievable clues about the missing entity (here, the author).\nAnswering such a question requires multi-hop reasoning where one must gather\ninformation about the missing entity (or facts) to proceed with further\nreasoning. We present GoldEn (Gold Entity) Retriever, which iterates between\nreading context and retrieving more supporting documents to answer open-domain\nmulti-hop questions. Instead of using opaque and computationally expensive\nneural retrieval models, GoldEn Retriever generates natural language search\nqueries given the question and available context, and leverages off-the-shelf\ninformation retrieval systems to query for missing entities. This allows GoldEn\nRetriever to scale up efficiently for open-domain multi-hop reasoning while\nmaintaining interpretability. We evaluate GoldEn Retriever on the recently\nproposed open-domain multi-hop QA dataset, HotpotQA, and demonstrate that it\noutperforms the best previously published model despite not using pretrained\nlanguage models such as BERT.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 18:44:47 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Qi", "Peng", ""], ["Lin", "Xiaowen", ""], ["Mehr", "Leo", ""], ["Wang", "Zijian", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1910.07060", "submitter": "Avik Ray", "authors": "Avik Ray, Yilin Shen, Hongxia Jin", "title": "Iterative Delexicalization for Improved Spoken Language Understanding", "comments": "Published at INTERSPEECH 2019, Graz, Austria", "journal-ref": "Proc. Interspeech 2019 (2019): 1183-1187", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network (RNN) based joint intent classification and slot\ntagging models have achieved tremendous success in recent years for building\nspoken language understanding and dialog systems. However, these models suffer\nfrom poor performance for slots which often encounter large semantic\nvariability in slot values after deployment (e.g. message texts, partial\nmovie/artist names). While greedy delexicalization of slots in the input\nutterance via substring matching can partly improve performance, it often\nproduces incorrect input. Moreover, such techniques cannot delexicalize slots\nwith out-of-vocabulary slot values not seen at training. In this paper, we\npropose a novel iterative delexicalization algorithm, which can accurately\ndelexicalize the input, even with out-of-vocabulary slot values. Based on model\nconfidence of the current delexicalized input, our algorithm improves\ndelexicalization in every iteration to converge to the best input having the\nhighest confidence. We show on benchmark and in-house datasets that our\nalgorithm can greatly improve parsing performance for RNN based models,\nespecially for out-of-distribution slot values.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 21:28:13 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Ray", "Avik", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""]]}, {"id": "1910.07117", "submitter": "Tianxing He", "authors": "Tianxing He and Jun Liu and Kyunghyun Cho and Myle Ott and Bing Liu\n  and James Glass and Fuchun Peng", "title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue\n  Response Models", "comments": null, "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study how the finetuning stage in the pretrain-finetune\nframework changes the behavior of a pretrained neural language generator. We\nfocus on the transformer encoder-decoder model for the open-domain dialogue\nresponse generation task. Our major finding is that after standard finetuning,\nthe model forgets some of the important language generation skills acquired\nduring large-scale pretraining. We demonstrate the forgetting phenomenon\nthrough a set of detailed behavior analysis from the perspectives of knowledge\ntransfer, context sensitivity, and function space projection. As a preliminary\nattempt to alleviate the forgetting problem, we propose an intuitive finetuning\nstrategy named \"mix-review\". We find that mix-review effectively regularizes\nthe finetuning process, and the forgetting problem is alleviated to some\nextent. Finally, we discuss interesting behavior of the resulting dialogue\nmodel and its implications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:10:10 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 23:38:37 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 19:43:05 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 17:56:28 GMT"}, {"version": "v5", "created": "Sat, 16 Jan 2021 19:14:41 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["He", "Tianxing", ""], ["Liu", "Jun", ""], ["Cho", "Kyunghyun", ""], ["Ott", "Myle", ""], ["Liu", "Bing", ""], ["Glass", "James", ""], ["Peng", "Fuchun", ""]]}, {"id": "1910.07124", "submitter": "Tianyu Gao", "authors": "Tianyu Gao, Xu Han, Hao Zhu, Zhiyuan Liu, Peng Li, Maosong Sun, Jie\n  Zhou", "title": "FewRel 2.0: Towards More Challenging Few-Shot Relation Classification", "comments": "Accepted to EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FewRel 2.0, a more challenging task to investigate two aspects of\nfew-shot relation classification models: (1) Can they adapt to a new domain\nwith only a handful of instances? (2) Can they detect none-of-the-above (NOTA)\nrelations? To construct FewRel 2.0, we build upon the FewRel dataset (Han et\nal., 2018) by adding a new test set in a quite different domain, and a NOTA\nrelation choice. With the new dataset and extensive experimental analysis, we\nfound (1) that the state-of-the-art few-shot relation classification models\nstruggle on these two aspects, and (2) that the commonly-used techniques for\ndomain adaptation and NOTA detection still cannot handle the two challenges\nwell. Our research calls for more attention and further efforts to these two\nreal-world issues. All details and resources about the dataset and baselines\nare released at https: //github.com/thunlp/fewrel.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 01:27:40 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Gao", "Tianyu", ""], ["Han", "Xu", ""], ["Zhu", "Hao", ""], ["Liu", "Zhiyuan", ""], ["Li", "Peng", ""], ["Sun", "Maosong", ""], ["Zhou", "Jie", ""]]}, {"id": "1910.07134", "submitter": "Kenton Murray", "authors": "Kenton Murray and Brian DuSell and David Chiang", "title": "Efficiency through Auto-Sizing: Notre Dame NLP's Submission to the WNGT\n  2019 Efficiency Task", "comments": "The 3rd Workshop on Neural Generation and Translation (WNGT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Notre Dame Natural Language Processing Group's\n(NDNLP) submission to the WNGT 2019 shared task (Hayashi et al., 2019). We\ninvestigated the impact of auto-sizing (Murray and Chiang, 2015; Murray et al.,\n2019) to the Transformer network (Vaswani et al., 2017) with the goal of\nsubstantially reducing the number of parameters in the model. Our method was\nable to eliminate more than 25% of the model's parameters while suffering a\ndecrease of only 1.1 BLEU.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 02:22:07 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Murray", "Kenton", ""], ["DuSell", "Brian", ""], ["Chiang", "David", ""]]}, {"id": "1910.07150", "submitter": "Jiewen Wu", "authors": "Jiewen Wu, Luis Fernando D'Haro, Nancy F. Chen, Pavitra Krishnaswamy,\n  Rafael E. Banchs", "title": "Joint Learning of Word and Label Embeddings for Sequence Labelling in\n  Spoken Language Understanding", "comments": "Accepted for publication at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an architecture to jointly learn word and label embeddings for\nslot filling in spoken language understanding. The proposed approach encodes\nlabels using a combination of word embeddings and straightforward word-label\nassociation from the training data. Compared to the state-of-the-art methods,\nour approach does not require label embeddings as part of the input and\ntherefore lends itself nicely to a wide range of model architectures. In\naddition, our architecture computes contextual distances between words and\nlabels to avoid adding contextual windows, thus reducing memory footprint. We\nvalidate the approach on established spoken dialogue datasets and show that it\ncan achieve state-of-the-art performance with much fewer trainable parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:28:14 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Wu", "Jiewen", ""], ["D'Haro", "Luis Fernando", ""], ["Chen", "Nancy F.", ""], ["Krishnaswamy", "Pavitra", ""], ["Banchs", "Rafael E.", ""]]}, {"id": "1910.07154", "submitter": "Mayank Jobanputra", "authors": "Mayank Jobanputra", "title": "Unsupervised Question Answering for Fact-Checking", "comments": "FEVER - 19 (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Deep Learning (DL) models have succeeded in achieving human-level\naccuracy on various natural language tasks such as question-answering, natural\nlanguage inference (NLI), and textual entailment. These tasks not only require\nthe contextual knowledge but also the reasoning abilities to be solved\nefficiently. In this paper, we propose an unsupervised question-answering based\napproach for a similar task, fact-checking. We transform the FEVER dataset into\na Cloze-task by masking named entities provided in the claims. To predict the\nanswer token, we utilize pre-trained Bidirectional Encoder Representations from\nTransformers (BERT). The classifier computes label based on the correctly\nanswered questions and a threshold. Currently, the classifier is able to\nclassify the claims as \"SUPPORTS\" and \"MANUAL_REVIEW\". This approach achieves a\nlabel accuracy of 80.2% on the development set and 80.25% on the test set of\nthe transformed dataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:34:34 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Jobanputra", "Mayank", ""]]}, {"id": "1910.07179", "submitter": "Huilin Gao", "authors": "Tong Guo, Huilin Gao", "title": "Content Enhanced BERT-based Text-to-SQL Generation", "comments": "working in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple methods to leverage the table content for the BERT-based\nmodel to solve the text-to-SQL problem. Based on the observation that some of\nthe table content match some words in question string and some of the table\nheader also match some words in question string, we encode two addition feature\nvector for the deep model. Our methods also benefit the model inference in\ntesting time as the tables are almost the same in training and testing time. We\ntest our model on the WikiSQL dataset and outperform the BERT-based baseline by\n3.7% in logic form and 3.7% in execution accuracy and achieve state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 05:50:35 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 09:50:01 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 04:46:38 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 03:11:36 GMT"}, {"version": "v5", "created": "Wed, 22 Apr 2020 01:37:07 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Guo", "Tong", ""], ["Gao", "Huilin", ""]]}, {"id": "1910.07181", "submitter": "Timo Schick", "authors": "Timo Schick and Hinrich Sch\\\"utze", "title": "BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized\n  Model Performance", "comments": "Accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining deep language models has led to large performance gains in NLP.\nDespite this success, Schick and Sch\\\"utze (2020) recently showed that these\nmodels struggle to understand rare words. For static word embeddings, this\nproblem has been addressed by separately learning representations for rare\nwords. In this work, we transfer this idea to pretrained language models: We\nintroduce BERTRAM, a powerful architecture based on BERT that is capable of\ninferring high-quality embeddings for rare words that are suitable as input\nrepresentations for deep language models. This is achieved by enabling the\nsurface form and contexts of a word to interact with each other in a deep\narchitecture. Integrating BERTRAM into BERT leads to large performance\nincreases due to improved representations of rare and medium frequency words on\nboth a rare word probing task and three downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 06:14:42 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 13:48:50 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 13:29:52 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1910.07204", "submitter": "Emiru Tsunoo", "authors": "Emiru Tsunoo, Yosuke Kashiwagi, Toshiyuki Kumakura, Shinji Watanabe", "title": "Transformer ASR with Contextual Block Processing", "comments": "Accepted for ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer self-attention network has recently shown promising\nperformance as an alternative to recurrent neural networks (RNNs) in end-to-end\n(E2E) automatic speech recognition (ASR) systems. However, the Transformer has\na drawback in that the entire input sequence is required to compute\nself-attention. In this paper, we propose a new block processing method for the\nTransformer encoder by introducing a context-aware inheritance mechanism. An\nadditional context embedding vector handed over from the previously processed\nblock helps to encode not only local acoustic information but also global\nlinguistic, channel, and speaker attributes. We introduce a novel mask\ntechnique to implement the context inheritance to train the model efficiently.\nEvaluations of the Wall Street Journal (WSJ), Librispeech, VoxForge Italian,\nand AISHELL-1 Mandarin speech recognition datasets show that our proposed\ncontextual block processing method outperforms naive block processing\nconsistently. Furthermore, the attention weight tendency of each layer is\nanalyzed to clarify how the added contextual inheritance mechanism models the\nglobal information.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:04:07 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Tsunoo", "Emiru", ""], ["Kashiwagi", "Yosuke", ""], ["Kumakura", "Toshiyuki", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1910.07221", "submitter": "Yerai Doval", "authors": "Yerai Doval, Jose Camacho-Collados, Luis Espinosa-Anke, Steven\n  Schockaert", "title": "Meemi: A Simple Method for Post-processing and Integrating Cross-lingual\n  Word Embeddings", "comments": "22 pages, 2 figures, 9 tables. Preprint submitted to Natural Language\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have become a standard resource in the toolset of any Natural\nLanguage Processing practitioner. While monolingual word embeddings encode\ninformation about words in the context of a particular language, cross-lingual\nembeddings define a multilingual space where word embeddings from two or more\nlanguages are integrated together. Current state-of-the-art approaches learn\nthese embeddings by aligning two disjoint monolingual vector spaces through an\northogonal transformation which preserves the structure of the monolingual\ncounterparts. In this work, we propose to apply an additional transformation\nafter this initial alignment step, which aims to bring the vector\nrepresentations of a given word and its translations closer to their average.\nSince this additional transformation is non-orthogonal, it also affects the\nstructure of the monolingual spaces. We show that our approach both improves\nthe integration of the monolingual spaces as well as the quality of the\nmonolingual spaces themselves. Furthermore, because our transformation can be\napplied to an arbitrary number of languages, we are able to effectively obtain\na truly multilingual space. The resulting (monolingual and multilingual) spaces\nshow consistent gains over the current state-of-the-art in standard intrinsic\ntasks, namely dictionary induction and word similarity, as well as in extrinsic\ntasks such as cross-lingual hypernym discovery and cross-lingual natural\nlanguage inference.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 08:59:31 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 17:16:26 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 08:06:37 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 10:07:30 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Doval", "Yerai", ""], ["Camacho-Collados", "Jose", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "1910.07323", "submitter": "Adrien Dufraux", "authors": "Adrien Dufraux, Emmanuel Vincent, Awni Hannun, Armelle Brun, Matthijs\n  Douze", "title": "Lead2Gold: Towards exploiting the full potential of noisy transcriptions\n  for speech recognition", "comments": "8 pages, 4 tables, Accepted for publication in ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transcriptions used to train an Automatic Speech Recognition (ASR) system\nmay contain errors. Usually, either a quality control stage discards\ntranscriptions with too many errors, or the noisy transcriptions are used as\nis. We introduce Lead2Gold, a method to train an ASR system that exploits the\nfull potential of noisy transcriptions. Based on a noise model of transcription\nerrors, Lead2Gold searches for better transcriptions of the training data with\na beam search that takes this noise model into account. The beam search is\ndifferentiable and does not require a forced alignment step, thus the whole\nsystem is trained end-to-end. Lead2Gold can be viewed as a new loss function\nthat can be used on top of any sequence-to-sequence deep neural network. We\nconduct proof-of-concept experiments on noisy transcriptions generated from\nletter corruptions with different noise levels. We show that Lead2Gold obtains\na better ASR accuracy than a competitive baseline which does not account for\nthe (artificially-introduced) transcription noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 12:55:34 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Dufraux", "Adrien", ""], ["Vincent", "Emmanuel", ""], ["Hannun", "Awni", ""], ["Brun", "Armelle", ""], ["Douze", "Matthijs", ""]]}, {"id": "1910.07333", "submitter": "Lahari Poddar", "authors": "Lahari Poddar, Gyorgy Szarvas, Lea Frermann", "title": "A Probabilistic Framework for Learning Domain Specific Hierarchical Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meaning of a word often varies depending on its usage in different\ndomains. The standard word embedding models struggle to represent this\nvariation, as they learn a single global representation for a word. We propose\na method to learn domain-specific word embeddings, from text organized into\nhierarchical domains, such as reviews in an e-commerce website, where products\nfollow a taxonomy. Our structured probabilistic model allows vector\nrepresentations for the same word to drift away from each other for distant\ndomains in the taxonomy, to accommodate its domain-specific meanings. By\nlearning sets of domain-specific word representations jointly, our model can\nleverage domain relationships, and it scales well with the number of domains.\nUsing large real-world review datasets, we demonstrate the effectiveness of our\nmodel compared to state-of-the-art approaches, in learning domain-specific word\nembeddings that are both intuitive to humans and benefit downstream NLP tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 13:24:54 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 17:11:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Poddar", "Lahari", ""], ["Szarvas", "Gyorgy", ""], ["Frermann", "Lea", ""]]}, {"id": "1910.07350", "submitter": "Simon \\v{S}uster", "authors": "Simon \\v{S}uster, Madhumita Sushil, Walter Daelemans", "title": "Why can't memory networks read effectively?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory networks have been a popular choice among neural architectures for\nmachine reading comprehension and question answering. While recent work\nrevealed that memory networks can't truly perform multi-hop reasoning, we show\nin the present paper that vanilla memory networks are ineffective even in\nsingle-hop reading comprehension. We analyze the reasons for this on two\ncloze-style datasets, one from the medical domain and another including\nchildren's fiction. We find that the output classification layer with\nentity-specific weights, and the aggregation of passage information with\nrelatively flat attention distributions are the most important contributors to\npoor results. We propose network adaptations that can serve as simple remedies.\nWe also find that the presence of unseen answers at test time can dramatically\naffect the reported results, so we suggest controlling for this factor during\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 13:56:27 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["\u0160uster", "Simon", ""], ["Sushil", "Madhumita", ""], ["Daelemans", "Walter", ""]]}, {"id": "1910.07357", "submitter": "Marco Guerini", "authors": "Sourabh Majumdar, Serra Sinem Tekiroglu, Marco Guerini", "title": "Generating Challenge Datasets for Task-Oriented Conversational Agents\n  through Self-Play", "comments": "Proceedings of Recent Advances in Natural Language Processing (RANLP)\n  Conference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end neural approaches are becoming increasingly common in\nconversational scenarios due to their promising performances when provided with\nsufficient amount of data. In this paper, we present a novel methodology to\naddress the interpretability of neural approaches in such scenarios by creating\nchallenge datasets using dialogue self-play over multiple tasks/intents.\nDialogue self-play allows generating large amount of synthetic data; by taking\nadvantage of the complete control over the generation process, we show how\nneural approaches can be evaluated in terms of unseen dialogue patterns. We\npropose several out-of-pattern test cases each of which introduces a natural\nand unexpected user utterance phenomenon. As a proof of concept, we built a\nsingle and a multiple memory network, and show that these two architectures\nhave diverse performances depending on the peculiar dialogue patterns.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:07:42 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Majumdar", "Sourabh", ""], ["Tekiroglu", "Serra Sinem", ""], ["Guerini", "Marco", ""]]}, {"id": "1910.07370", "submitter": "Pratik Ratadiya", "authors": "Aditya Malte, Pratik Ratadiya", "title": "Evolution of transfer learning in natural language processing", "comments": "Pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a study of the recent advancements which have\nhelped bring Transfer Learning to NLP through the use of semi-supervised\ntraining. We discuss cutting-edge methods and architectures such as BERT, GPT,\nELMo, ULMFit among others. Classically, tasks in natural language processing\nhave been performed through rule-based and statistical methodologies. However,\nowing to the vast nature of natural languages these methods do not generalise\nwell and failed to learn the nuances of language. Thus machine learning\nalgorithms such as Naive Bayes and decision trees coupled with traditional\nmodels such as Bag-of-Words and N-grams were used to usurp this problem.\nEventually, with the advent of advanced recurrent neural network architectures\nsuch as the LSTM, we were able to achieve state-of-the-art performance in\nseveral natural language processing tasks such as text classification and\nmachine translation. We talk about how Transfer Learning has brought about the\nwell-known ImageNet moment for NLP. Several advanced architectures such as the\nTransformer and its variants have allowed practitioners to leverage knowledge\ngained from unrelated task to drastically fasten convergence and provide better\nperformance on the target task. This survey represents an effort at providing a\nsuccinct yet complete understanding of the recent advances in natural language\nprocessing using deep learning in with a special focus on detailing transfer\nlearning and its potential advantages.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:24:37 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Malte", "Aditya", ""], ["Ratadiya", "Pratik", ""]]}, {"id": "1910.07419", "submitter": "Mohammed Khalilia", "authors": "Parminder Bhatia, Busra Celikkaya, Mohammed Khalilia, Selvan Senthivel", "title": "Comprehend Medical: a Named Entity Recognition and Relationship\n  Extraction Web Service", "comments": "ICMLA 2019. $\\copyright$ 2019 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses in any\n  current or future media including reprinting/republishing this material for\n  advertising, promotional purposes, creating new collective works, for resale\n  or redistribution to servers or lists, reuse of any copyrighted component of\n  this work in other works. arXiv admin note: text overlap with\n  arXiv:1812.05270", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehend Medical is a stateless and Health Insurance Portability and\nAccountability Act (HIPAA) eligible Named Entity Recognition (NER) and\nRelationship Extraction (RE) service launched under Amazon Web Services (AWS)\ntrained using state-of-the-art deep learning models. Contrary to many existing\nopen source tools, Comprehend Medical is scalable and does not require steep\nlearning curve, dependencies, pipeline configurations, or installations.\nCurrently, Comprehend Medical performs NER in five medical categories: Anatomy,\nMedical Condition, Medications, Protected Health Information (PHI) and\nTreatment, Test and Procedure (TTP). Additionally, the service provides\nrelationship extraction for the detected entities as well as contextual\ninformation such as negation and temporality in the form of traits. Comprehend\nMedical provides two Application Programming Interfaces (API): 1) the NERe API\nwhich returns all the extracted named entities, their traits and the\nrelationships between them and 2) the PHId API which returns just the protected\nhealth information contained in the text. Furthermore, Comprehend Medical is\naccessible through AWS Console, Java and Python Software Development Kit (SDK),\nmaking it easier for non-developers and developers to use.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:38:55 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Bhatia", "Parminder", ""], ["Celikkaya", "Busra", ""], ["Khalilia", "Mohammed", ""], ["Senthivel", "Selvan", ""]]}, {"id": "1910.07429", "submitter": "Travis Goodwin", "authors": "Travis R. Goodwin and Dina Demner-Fushman", "title": "Bridging the Knowledge Gap: Enhancing Question Answering with World and\n  Domain Knowledge", "comments": "6 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present OSCAR (Ontology-based Semantic Composition Augmented\nRegularization), a method for injecting task-agnostic knowledge from an\nOntology or knowledge graph into a neural network during pretraining. We\nevaluated the impact of including OSCAR when pretraining BERT with Wikipedia\narticles by measuring the performance when fine-tuning on two question\nanswering tasks involving world knowledge and causal reasoning and one\nrequiring domain (healthcare) knowledge and obtained 33:3%, 18:6%, and 4%\nimproved accuracy compared to pretraining BERT without OSCAR and obtaining new\nstate-of-the-art results on two of the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:44:09 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Goodwin", "Travis R.", ""], ["Demner-Fushman", "Dina", ""]]}, {"id": "1910.07457", "submitter": "Eleftherios Avramidis", "authors": "Eleftherios Avramidis, Vivien Macketanz, Ursula Strohriegel, Hans\n  Uszkoreit", "title": "Linguistic evaluation of German-English Machine Translation using a Test\n  Suite", "comments": null, "journal-ref": "Proceedings of the Fourth Conference on Machine Translation.\n  Conference on Machine Translation (WMT-2019)", "doi": "10.18653/v1/W19-5351", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the results of the application of a grammatical test suite for\nGerman$\\rightarrow$English MT on the systems submitted at WMT19, with a\ndetailed analysis for 107 phenomena organized in 14 categories. The systems\nstill translate wrong one out of four test items in average. Low performance is\nindicated for idioms, modals, pseudo-clefts, multi-word expressions and verb\nvalency. When compared to last year, there has been a improvement of function\nwords, non-verbal agreement and punctuation. More detailed conclusions about\nparticular systems and phenomena are also presented.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:27:26 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Avramidis", "Eleftherios", ""], ["Macketanz", "Vivien", ""], ["Strohriegel", "Ursula", ""], ["Uszkoreit", "Hans", ""]]}, {"id": "1910.07460", "submitter": "Eleftherios Avramidis", "authors": "Vivien Macketanz, Eleftherios Avramidis, Aljoscha Burchardt, Hans\n  Uszkoreit", "title": "Fine-grained evaluation of German-English Machine Translation based on a\n  Test Suite", "comments": null, "journal-ref": "Proceedings of the Third Conference on Machine Translation\n  (WMT-2018)", "doi": "10.18653/v1/W18-6436", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an analysis of 16 state-of-the-art MT systems on German-English\nbased on a linguistically-motivated test suite. The test suite has been devised\nmanually by a team of language professionals in order to cover a broad variety\nof linguistic phenomena that MT often fails to translate properly. It contains\n5,000 test sentences covering 106 linguistic phenomena in 14 categories, with\nan increased focus on verb tenses, aspects and moods. The MT outputs are\nevaluated in a semi-automatic way through regular expressions that focus only\non the part of the sentence that is relevant to each phenomenon. Through our\nanalysis, we are able to compare systems based on their performance on these\ncategories. Additionally, we reveal strengths and weaknesses of particular\nsystems and we identify grammatical phenomena where the overall performance of\nMT is relatively low.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:36:07 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Macketanz", "Vivien", ""], ["Avramidis", "Eleftherios", ""], ["Burchardt", "Aljoscha", ""], ["Uszkoreit", "Hans", ""]]}, {"id": "1910.07467", "submitter": "Biao Zhang", "authors": "Biao Zhang, Rico Sennrich", "title": "Root Mean Square Layer Normalization", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer normalization (LayerNorm) has been successfully applied to various deep\nneural networks to help stabilize training and boost model convergence because\nof its capability in handling re-centering and re-scaling of both inputs and\nweight matrix. However, the computational overhead introduced by LayerNorm\nmakes these improvements expensive and significantly slows the underlying\nnetwork, e.g. RNN in particular. In this paper, we hypothesize that\nre-centering invariance in LayerNorm is dispensable and propose root mean\nsquare layer normalization, or RMSNorm. RMSNorm regularizes the summed inputs\nto a neuron in one layer according to root mean square (RMS), giving the model\nre-scaling invariance property and implicit learning rate adaptation ability.\nRMSNorm is computationally simpler and thus more efficient than LayerNorm. We\nalso present partial RMSNorm, or pRMSNorm where the RMS is estimated from p% of\nthe summed inputs without breaking the above properties. Extensive experiments\non several tasks using diverse network architectures show that RMSNorm achieves\ncomparable performance against LayerNorm but reduces the running time by 7%~64%\non different models. Source code is available at\nhttps://github.com/bzhangGo/rmsnorm.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:44:22 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Zhang", "Biao", ""], ["Sennrich", "Rico", ""]]}, {"id": "1910.07468", "submitter": "Eleftherios Avramidis", "authors": "Avramidis Eleftherios, Vivien Macketanz, Arle Lommel, Hans Uszkoreit", "title": "Fine-grained evaluation of Quality Estimation for Machine translation\n  based on a linguistically-motivated Test Suite", "comments": null, "journal-ref": "Proceedings of the First Workshop on Translation Quality\n  Estimation and Automatic Post-Editing (QEAPE-2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an alternative method of evaluating Quality Estimation systems,\nwhich is based on a linguistically-motivated Test Suite. We create a test-set\nconsisting of 14 linguistic error categories and we gather for each of them a\nset of samples with both correct and erroneous translations. Then, we measure\nthe performance of 5 Quality Estimation systems by checking their ability to\ndistinguish between the correct and the erroneous translations. The detailed\nresults are much more informative about the ability of each system. The fact\nthat different Quality Estimation systems perform differently at various\nphenomena confirms the usefulness of the Test Suite.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:49:28 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Eleftherios", "Avramidis", ""], ["Macketanz", "Vivien", ""], ["Lommel", "Arle", ""], ["Uszkoreit", "Hans", ""]]}, {"id": "1910.07475", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Barlas O\\u{g}uz, Ruty Rinott, Sebastian Riedel, Holger\n  Schwenk", "title": "MLQA: Evaluating Cross-lingual Extractive Question Answering", "comments": "To appear in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) models have shown rapid progress enabled by the\navailability of large, high-quality benchmark datasets. Such annotated datasets\nare difficult and costly to collect, and rarely exist in languages other than\nEnglish, making training QA systems in other languages challenging. An\nalternative to building large monolingual training datasets is to develop\ncross-lingual systems which can transfer to a target language without requiring\ntraining data in that language. In order to develop such systems, it is crucial\nto invest in high quality multilingual evaluation benchmarks to measure\nprogress. We present MLQA, a multi-way aligned extractive QA evaluation\nbenchmark intended to spur research in this area. MLQA contains QA instances in\n7 languages, namely English, Arabic, German, Spanish, Hindi, Vietnamese and\nSimplified Chinese. It consists of over 12K QA instances in English and 5K in\neach other language, with each QA instance being parallel between 4 languages\non average. MLQA is built using a novel alignment context strategy on Wikipedia\narticles, and serves as a cross-lingual extension to existing extractive QA\ndatasets. We evaluate current state-of-the-art cross-lingual representations on\nMLQA, and also provide machine-translation-based baselines. In all cases,\ntransfer results are shown to be significantly behind training-language\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:05:21 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 05:46:56 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 10:13:02 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lewis", "Patrick", ""], ["O\u011fuz", "Barlas", ""], ["Rinott", "Ruty", ""], ["Riedel", "Sebastian", ""], ["Schwenk", "Holger", ""]]}, {"id": "1910.07481", "submitter": "Christophe Servan", "authors": "Valentin Mac\\'e, Christophe Servan", "title": "Using Whole Document Context in Neural Machine Translation", "comments": "Accepted paper to IWSLT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Translation, considering the document as a whole can help to\nresolve ambiguities and inconsistencies. In this paper, we propose a simple yet\npromising approach to add contextual information in Neural Machine Translation.\nWe present a method to add source context that capture the whole document with\naccurate boundaries, taking every word into account. We provide this additional\ninformation to a Transformer model and study the impact of our method on three\nlanguage pairs. The proposed approach obtains promising results in the\nEnglish-German, English-French and French-English document-level translation\ntasks. We observe interesting cross-sentential behaviors where the model learns\nto use document-level information to improve translation coherence.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:15:35 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Mac\u00e9", "Valentin", ""], ["Servan", "Christophe", ""]]}, {"id": "1910.07482", "submitter": "Ozan Caglayan", "authors": "Ozan Caglayan, Zixiu Wu, Pranava Madhyastha, Josiah Wang, Lucia Specia", "title": "Imperial College London Submission to VATEX Video Captioning Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Imperial College London team's submission to the\n2019' VATEX video captioning challenge, where we first explore two\nsequence-to-sequence models, namely a recurrent (GRU) model and a transformer\nmodel, which generate captions from the I3D action features. We then\ninvestigate the effect of dropping the encoder and the attention mechanism and\ninstead conditioning the GRU decoder over two different vectorial\nrepresentations: (i) a max-pooled action feature vector and (ii) the output of\na multi-label classifier trained to predict visual entities from the action\nfeatures. Our baselines achieved scores comparable to the official baseline.\nConditioning over entity predictions performed substantially better than\nconditioning on the max-pooled feature vector, and only marginally worse than\nthe GRU-based sequence-to-sequence baseline.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:22:25 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Caglayan", "Ozan", ""], ["Wu", "Zixiu", ""], ["Madhyastha", "Pranava", ""], ["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1910.07514", "submitter": "Deepali Aneja", "authors": "Deepali Aneja, Rens Hoegen, Daniel McDuff, and Mary Czerwinski", "title": "Designing Style Matching Conversational Agents", "comments": "Conversational Agents: Acting on the Wave of Research and\n  Development, CHI 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine intelligence have enabled conversational interfaces that\nhave the potential to radically change the way humans interact with machines.\nHowever, even with the progress in the abilities of these agents, there remain\ncritical gaps in their capacity for natural interactions. One limitation is\nthat the agents are often monotonic in behavior and do not adapt to their\npartner. We built two end-to-end conversational agents: a voice-based agent\nthat can engage in naturalistic, multi-turn dialogue and align with the\ninterlocutor's conversational style, and a 2nd, expressive, embodied\nconversational agent (ECA) that can recognize human behavior during open-ended\nconversations and automatically align its responses to the visual and\nconversational style of the other party. The embodied conversational agent\nleverages multimodal inputs to produce rich and perceptually valid vocal and\nfacial responses (e.g., lip syncing and expressions) during the conversation.\nBased on empirical results from a set of user studies, we highlight several\nsignificant challenges in building such systems and provide design guidelines\nfor multi-turn dialogue interactions using style adaptation for future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:58:36 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Aneja", "Deepali", ""], ["Hoegen", "Rens", ""], ["McDuff", "Daniel", ""], ["Czerwinski", "Mary", ""]]}, {"id": "1910.07518", "submitter": "Tom De Smedt", "authors": "Sylvia Jaki, Tom De Smedt", "title": "Right-wing German Hate Speech on Twitter: Analysis and Automatic\n  Detection", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion about the social network Twitter often concerns its role in\npolitical discourse, involving the question of when an expression of opinion\nbecomes offensive, immoral, and/or illegal, and how to deal with it. Given the\ngrowing amount of offensive communication on the internet, there is a demand\nfor new technology that can automatically detect hate speech, to assist content\nmoderation by humans. This comes with new challenges, such as defining exactly\nwhat is free speech and what is illegal in a specific country, and knowing\nexactly what the linguistic characteristics of hate speech are. To shed light\non the German situation, we analyzed over 50,000 right-wing German hate tweets\nposted between August 2017 and April 2018, at the time of the 2017 German\nfederal elections, using both quantitative and qualitative methods. In this\npaper, we discuss the results of the analysis and demonstrate how the insights\ncan be employed for the development of automatic detection systems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 00:54:17 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Jaki", "Sylvia", ""], ["De Smedt", "Tom", ""]]}, {"id": "1910.07601", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Thomas Hain", "title": "Contextual Joint Factor Acoustic Embeddings", "comments": "Published at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding acoustic information into fixed length representations is of\ninterest for a whole range of applications in speech and audio technology. Two\nnovel unsupervised approaches to generate acoustic embeddings by modelling of\nacoustic context are proposed. The first approach is a contextual joint factor\nsynthesis encoder, where the encoder in an encoder/decoder framework is trained\nto extract joint factors from surrounding audio frames to best generate the\ntarget output. The second approach is a contextual joint factor analysis\nencoder, where the encoder is trained to analyse joint factors from the source\nsignal that correlates best with the neighbouring audio. To evaluate the\neffectiveness of our approaches compared to prior work, two tasks are conducted\n-- phone classification and speaker recognition -- and test on different TIMIT\ndata sets. Experimental results show that one of the proposed approaches\noutperforms phone classification baselines, yielding a classification accuracy\nof 74.1%. When using additional out-of-domain data for training, an additional\n3% improvements can be obtained, for both for phone classification and speaker\nrecognition tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 20:36:41 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:40:15 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shi", "Yanpei", ""], ["Hain", "Thomas", ""]]}, {"id": "1910.07659", "submitter": "Fei Liu", "authors": "Kristjan Arumae and Parminder Bhatia and Fei Liu", "title": "Towards Annotating and Creating Sub-Sentence Summary Highlights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highlighting is a powerful tool to pick out important content and emphasize.\nCreating summary highlights at the sub-sentence level is particularly\ndesirable, because sub-sentences are more concise than whole sentences. They\nare also better suited than individual words and phrases that can potentially\nlead to disfluent, fragmented summaries. In this paper we seek to generate\nsummary highlights by annotating summary-worthy sub-sentences and teaching\nclassifiers to do the same. We frame the task as jointly selecting important\nsentences and identifying a single most informative textual unit from each\nsentence. This formulation dramatically reduces the task complexity involved in\nsentence compression. Our study provides new benchmarks and baselines for\ngenerating highlights at the sub-sentence level.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 00:20:11 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Arumae", "Kristjan", ""], ["Bhatia", "Parminder", ""], ["Liu", "Fei", ""]]}, {"id": "1910.07713", "submitter": "Jeff Da", "authors": "Jeff Da", "title": "BIG MOOD: Relating Transformers to Explicit Commonsense Knowledge", "comments": "Accepted to EMNLP Commonsense (COIN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple yet effective method of integrating contextual\nembeddings with commonsense graph embeddings, dubbed BERT Infused Graphs:\nMatching Over Other embeDdings. First, we introduce a preprocessing method to\nimprove the speed of querying knowledge bases. Then, we develop a method of\ncreating knowledge embeddings from each knowledge base. We introduce a method\nof aligning tokens between two misaligned tokenization methods. Finally, we\ncontribute a method of contextualizing BERT after combining with knowledge base\nembeddings. We also show BERTs tendency to correct lower accuracy question\ntypes. Our model achieves a higher accuracy than BERT, and we score fifth on\nthe official leaderboard of the shared task and score the highest without any\nadditional language model pretraining.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 05:19:29 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Da", "Jeff", ""]]}, {"id": "1910.07834", "submitter": "Md Rashad Al Hasan Rony", "authors": "Debanjan Chaudhuri, Md Rashad Al Hasan Rony, Simon Jordan and Jens\n  Lehmann", "title": "Using a KG-Copy Network for Non-Goal Oriented Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-goal oriented, generative dialogue systems lack the ability to generate\nanswers with grounded facts. A knowledge graph can be considered an abstraction\nof the real world consisting of well-grounded facts. This paper addresses the\nproblem of generating well grounded responses by integrating knowledge graphs\ninto the dialogue systems response generation process, in an end-to-end manner.\nA dataset for nongoal oriented dialogues is proposed in this paper in the\ndomain of soccer, conversing on different clubs and national teams along with a\nknowledge graph for each of these teams. A novel neural network architecture is\nalso proposed as a baseline on this dataset, which can integrate knowledge\ngraphs into the response generation process, producing well articulated,\nknowledge grounded responses. Empirical evidence suggests that the proposed\nmodel performs better than other state-of-the-art models for knowledge graph\nintegrated dialogue systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 11:42:58 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Chaudhuri", "Debanjan", ""], ["Rony", "Md Rashad Al Hasan", ""], ["Jordan", "Simon", ""], ["Lehmann", "Jens", ""]]}, {"id": "1910.07848", "submitter": "Yoo Yeon Sung", "authors": "Yoo yeon Sung and Seoung Bum Kim", "title": "Topical Keyphrase Extraction with Hierarchical Semantic Networks", "comments": "Accepted at Decision Support Systems 2019 on 16 Sep 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topical keyphrase extraction is used to summarize large collections of text\ndocuments. However, traditional methods cannot properly reflect the intrinsic\nsemantics and relationships of keyphrases because they rely on a simple\nterm-frequency-based process. Consequently, these methods are not effective in\nobtaining significant contextual knowledge. To resolve this, we propose a\ntopical keyphrase extraction method based on a hierarchical semantic network\nand multiple centrality network measures that together reflect the hierarchical\nsemantics of keyphrases. We conduct experiments on real data to examine the\npracticality of the proposed method and to compare its performance with that of\nexisting topical keyphrase extraction methods. The results confirm that the\nproposed method outperforms state-of-the-art topical keyphrase extraction\nmethods in terms of the representativeness of the selected keyphrases for each\ntopic. The proposed method can effectively reflect intrinsic keyphrase\nsemantics and interrelationships.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 12:09:11 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Sung", "Yoo yeon", ""], ["Kim", "Seoung Bum", ""]]}, {"id": "1910.07897", "submitter": "Jishnu Ray Chowdhury", "authors": "Jishnu Ray Chowdhury, Cornelia Caragea, Doina Caragea", "title": "Keyphrase Extraction from Disaster-related Tweets", "comments": "12 pages, 7 figures", "journal-ref": "In The World Wide Web Conference (WWW '19), Ling Liu and Ryen\n  White (Eds.). ACM, New York, NY, USA, 1555-1566 (2019)", "doi": "10.1145/3308558.3313696", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While keyphrase extraction has received considerable attention in recent\nyears, relatively few studies exist on extracting keyphrases from social media\nplatforms such as Twitter, and even fewer for extracting disaster-related\nkeyphrases from such sources. During a disaster, keyphrases can be extremely\nuseful for filtering relevant tweets that can enhance situational awareness.\nPreviously, joint training of two different layers of a stacked Recurrent\nNeural Network for keyword discovery and keyphrase extraction had been shown to\nbe effective in extracting keyphrases from general Twitter data. We improve the\nmodel's performance on both general Twitter data and disaster-related Twitter\ndata by incorporating contextual word embeddings, POS-tags, phonetics, and\nphonological features. Moreover, we discuss the shortcomings of the often used\nF1-measure for evaluating the quality of predicted keyphrases with respect to\nthe ground truth annotations. Instead of the F1-measure, we propose the use of\nembedding-based metrics to better capture the correctness of the predicted\nkeyphrases. In addition, we also present a novel extension of an\nembedding-based metric. The extension allows one to better control the penalty\nfor the difference in the number of ground-truth and predicted keyphrases\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:31:45 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Chowdhury", "Jishnu Ray", ""], ["Caragea", "Cornelia", ""], ["Caragea", "Doina", ""]]}, {"id": "1910.07900", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Qiang Huang, Thomas Hain", "title": "H-VECTORS: Utterance-level Speaker Embedding Using A Hierarchical\n  Attention Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a hierarchical attention network to generate utterance-level\nembeddings (H-vectors) for speaker identification is proposed. Since different\nparts of an utterance may have different contributions to speaker identities,\nthe use of hierarchical structure aims to learn speaker related information\nlocally and globally. In the proposed approach, frame-level encoder and\nattention are applied on segments of an input utterance and generate individual\nsegment vectors. Then, segment level attention is applied on the segment\nvectors to construct an utterance representation. To evaluate the effectiveness\nof the proposed approach, NIST SRE 2008 Part1 dataset is used for training, and\ntwo datasets, Switchboard Cellular part1 and CallHome American English Speech,\nare used to evaluate the quality of extracted utterance embeddings on speaker\nidentification and verification tasks. In comparison with two baselines,\nX-vector, X-vector+Attention, the obtained results show that H-vectors can\nachieve a significantly better performance. Furthermore, the extracted\nutterance-level embeddings are more discriminative than the two baselines when\nmapped into a 2D space using t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 13:33:41 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:21:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shi", "Yanpei", ""], ["Huang", "Qiang", ""], ["Hain", "Thomas", ""]]}, {"id": "1910.07924", "submitter": "Benjamin Beilharz", "authors": "Benjamin Beilharz, Xin Sun, Sariya Karimova, Stefan Riezler", "title": "LibriVoxDeEn: A Corpus for German-to-English Speech Translation and\n  German Speech Recognition", "comments": "Corpus can be downloaded from:\n  https://www.cl.uni-heidelberg.de/statnlpgroup/librivoxdeen/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a corpus of sentence-aligned triples of German audio, German text,\nand English translation, based on German audiobooks. The speech translation\ndata consist of 110 hours of audio material aligned to over 50k parallel\nsentences. An even larger dataset comprising 547 hours of German speech aligned\nto German text is available for speech recognition. The audio data is read\nspeech and thus low in disfluencies. The quality of audio and sentence\nalignments has been checked by a manual evaluation, showing that speech\nalignment quality is in general very high. The sentence alignment quality is\ncomparable to well-used parallel translation data and can be adjusted by\ncutoffs on the automatic alignment score. To our knowledge, this corpus is to\ndate the largest resource for German speech recognition and for end-to-end\nGerman-to-English speech translation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 14:01:57 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 10:27:27 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:50:48 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Beilharz", "Benjamin", ""], ["Sun", "Xin", ""], ["Karimova", "Sariya", ""], ["Riezler", "Stefan", ""]]}, {"id": "1910.07931", "submitter": "Siqi Bao", "authors": "Siqi Bao, Huang He, Fan Wang, Hua Wu and Haifeng Wang", "title": "PLATO: Pre-trained Dialogue Generation Model with Discrete Latent\n  Variable", "comments": "Accepted for publication at ACL2020. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training models have been proved effective for a wide range of natural\nlanguage processing tasks. Inspired by this, we propose a novel dialogue\ngeneration pre-training framework to support various kinds of conversations,\nincluding chit-chat, knowledge grounded dialogues, and conversational question\nanswering. In this framework, we adopt flexible attention mechanisms to fully\nleverage the bi-directional context and the uni-directional characteristic of\nlanguage generation. We also introduce discrete latent variables to tackle the\ninherent one-to-many mapping problem in response generation. Two reciprocal\ntasks of response generation and latent act recognition are designed and\ncarried out simultaneously within a shared network. Comprehensive experiments\non three publicly available datasets verify the effectiveness and superiority\nof the proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 14:09:42 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 13:37:16 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 16:06:37 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Bao", "Siqi", ""], ["He", "Huang", ""], ["Wang", "Fan", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "1910.07938", "submitter": "James Barry", "authors": "James Barry, Joachim Wagner, Jennifer Foster", "title": "Cross-lingual Parsing with Polyglot Training and Multi-treebank\n  Learning: A Faroese Case Study", "comments": "Submitted to the DeepLo workshop at EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual dependency parsing involves transferring syntactic knowledge\nfrom one language to another. It is a crucial component for inducing dependency\nparsers in low-resource scenarios where no training data for a language exists.\nUsing Faroese as the target language, we compare two approaches using\nannotation projection: first, projecting from multiple monolingual source\nmodels; second, projecting from a single polyglot model which is trained on the\ncombination of all source languages. Furthermore, we reproduce multi-source\nprojection (Tyers et al., 2018), in which dependency trees of multiple sources\nare combined. Finally, we apply multi-treebank modelling to the projected\ntreebanks, in addition to or alternatively to polyglot modelling on the source\nside. We find that polyglot training on the source languages produces an\noverall trend of better results on the target language but the single best\nresult for the target language is obtained by projecting from monolingual\nsource parsing models and then training multi-treebank POS tagging and parsing\nmodels on the target side.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 14:28:35 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Barry", "James", ""], ["Wagner", "Joachim", ""], ["Foster", "Jennifer", ""]]}, {"id": "1910.07973", "submitter": "Xiaofei Ma", "authors": "Xiaofei Ma, Zhiguo Wang, Patrick Ng, Ramesh Nallapati, Bing Xiang", "title": "Universal Text Representation from BERT: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic investigation of layer-wise BERT activations for\ngeneral-purpose text representations to understand what linguistic information\nthey capture and how transferable they are across different tasks.\nSentence-level embeddings are evaluated against two state-of-the-art models on\ndownstream and probing tasks from SentEval, while passage-level embeddings are\nevaluated on four question-answering (QA) datasets under a learning-to-rank\nproblem setting. Embeddings from the pre-trained BERT model perform poorly in\nsemantic similarity and sentence surface information probing tasks. Fine-tuning\nBERT on natural language inference data greatly improves the quality of the\nembeddings. Combining embeddings from different BERT layers can further boost\nperformance. BERT embeddings outperform BM25 baseline significantly on factoid\nQA datasets at the passage level, but fail to perform better than BM25 on\nnon-factoid datasets. For all QA datasets, there is a gap between\nembedding-based method and in-domain fine-tuned BERT (we report new\nstate-of-the-art results on two datasets), which suggests deep interactions\nbetween question and answer pairs are critical for those hard tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:33:26 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 23:56:32 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Ma", "Xiaofei", ""], ["Wang", "Zhiguo", ""], ["Ng", "Patrick", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1910.08129", "submitter": "Jeffrey Kegler", "authors": "Jeffrey Kegler", "title": "Marpa, A practical general parser: the recognizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Marpa recognizer is described. Marpa is a practical and fully implemented\nalgorithm for the recognition, parsing and evaluation of context-free grammars.\nThe Marpa recognizer is the first to unite the improvements to Earley's\nalgorithm found in Joop Leo's 1991 paper to those in Aycock and Horspool's 2002\npaper. Marpa tracks the full state of the parse, at it proceeds, in a form\nconvenient for the application. This greatly improves error detection and\nenables event-driven parsing. One such technique is \"Ruby Slippers\" parsing, in\nwhich the input is altered in response to the parser's expectations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 19:45:18 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kegler", "Jeffrey", ""]]}, {"id": "1910.08144", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff, Steffen Hessler, Dorothea Kolossa, Robert M.\n  Nickel", "title": "Explainable Authorship Verification in Social Media via Attention-based\n  Similarity Learning", "comments": "Accepted for 2019 IEEE International Conference on Big Data (IEEE Big\n  Data 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification is the task of analyzing the linguistic patterns of\ntwo or more texts to determine whether they were written by the same author or\nnot. The analysis is traditionally performed by experts who consider linguistic\nfeatures, which include spelling mistakes, grammatical inconsistencies, and\nstylistics for example. Machine learning algorithms, on the other hand, can be\ntrained to accomplish the same, but have traditionally relied on so-called\nstylometric features. The disadvantage of such features is that their\nreliability is greatly diminished for short and topically varied social media\ntexts. In this interdisciplinary work, we propose a substantial extension of a\nrecently published hierarchical Siamese neural network approach, with which it\nis feasible to learn neural features and to visualize the decision-making\nprocess. For this purpose, a new large-scale corpus of short Amazon reviews for\ntext comparison research is compiled and we show that the Siamese network\ntopologies outperform state-of-the-art approaches that were built up on\nstylometric features. Our linguistic analysis of the internal attention weights\nof the network shows that the proposed method is indeed able to latch on to\nsome traditional linguistic categories.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:18:23 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 21:57:57 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Hessler", "Steffen", ""], ["Kolossa", "Dorothea", ""], ["Nickel", "Robert M.", ""]]}, {"id": "1910.08192", "submitter": "Jiaming Shen", "authors": "Jiaming Shen, Zeqiu Wu, Dongming Lei, Jingbo Shang, Xiang Ren, Jiawei\n  Han", "title": "SetExpan: Corpus-Based Set Expansion via Context Feature Selection and\n  Rank Ensemble", "comments": "ECMLPKDD 2017 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corpus-based set expansion (i.e., finding the \"complete\" set of entities\nbelonging to the same semantic class, based on a given corpus and a tiny set of\nseeds) is a critical task in knowledge discovery. It may facilitate numerous\ndownstream applications, such as information extraction, taxonomy induction,\nquestion answering, and web search. To discover new entities in an expanded\nset, previous approaches either make one-time entity ranking based on\ndistributional similarity, or resort to iterative pattern-based bootstrapping.\nThe core challenge for these methods is how to deal with noisy context features\nderived from free-text corpora, which may lead to entity intrusion and semantic\ndrifting. In this study, we propose a novel framework, SetExpan, which tackles\nthis problem, with two techniques: (1) a context feature selection method that\nselects clean context features for calculating entity-entity distributional\nsimilarity, and (2) a ranking-based unsupervised ensemble method for expanding\nentity set based on denoised context features. Experiments on three datasets\nshow that SetExpan is robust and outperforms previous state-of-the-art methods\nin terms of mean average precision.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 22:55:29 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shen", "Jiaming", ""], ["Wu", "Zeqiu", ""], ["Lei", "Dongming", ""], ["Shang", "Jingbo", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.08194", "submitter": "Jiaming Shen", "authors": "Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle\n  T. Vanni, Brian M. Sadler, Jiawei Han", "title": "HiExpan: Task-Guided Taxonomy Construction by Hierarchical Tree\n  Expansion", "comments": "KDD 2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies are of great value to many knowledge-rich applications. As the\nmanual taxonomy curation costs enormous human effects, automatic taxonomy\nconstruction is in great demand. However, most existing automatic taxonomy\nconstruction methods can only build hypernymy taxonomies wherein each edge is\nlimited to expressing the \"is-a\" relation. Such a restriction limits their\napplicability to more diverse real-world tasks where the parent-child may carry\ndifferent relations. In this paper, we aim to construct a task-guided taxonomy\nfrom a domain-specific corpus and allow users to input a \"seed\" taxonomy,\nserving as the task guidance. We propose an expansion-based taxonomy\nconstruction framework, namely HiExpan, which automatically generates key term\nlist from the corpus and iteratively grows the seed taxonomy. Specifically,\nHiExpan views all children under each taxonomy node forming a coherent set and\nbuilds the taxonomy by recursively expanding all these sets. Furthermore,\nHiExpan incorporates a weakly-supervised relation extraction module to extract\nthe initial children of a newly-expanded node and adjusts the taxonomy tree by\noptimizing its global structure. Our experiments on three real datasets from\ndifferent domains demonstrate the effectiveness of HiExpan for building\ntask-guided taxonomies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 23:02:34 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Shen", "Jiaming", ""], ["Wu", "Zeqiu", ""], ["Lei", "Dongming", ""], ["Zhang", "Chao", ""], ["Ren", "Xiang", ""], ["Vanni", "Michelle T.", ""], ["Sadler", "Brian M.", ""], ["Han", "Jiawei", ""]]}, {"id": "1910.08210", "submitter": "Victor Zhong", "authors": "Victor Zhong, Tim Rockt\\\"aschel, Edward Grefenstette", "title": "RTFM: Generalising to Novel Environment Dynamics via Reading", "comments": "ICLR 2020; 17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining policies that can generalise to new environments in reinforcement\nlearning is challenging. In this work, we demonstrate that language\nunderstanding via a reading policy learner is a promising vehicle for\ngeneralisation to new environments. We propose a grounded policy learning\nproblem, Read to Fight Monsters (RTFM), in which the agent must jointly reason\nover a language goal, relevant dynamics described in a document, and\nenvironment observations. We procedurally generate environment dynamics and\ncorresponding language descriptions of the dynamics, such that agents must read\nto understand new environment dynamics instead of memorising any particular\ninformation. In addition, we propose txt2$\\pi$, a model that captures three-way\ninteractions between the goal, document, and observations. On RTFM, txt2$\\pi$\ngeneralises to new environments with dynamics not seen during training via\nreading. Furthermore, our model outperforms baselines such as FiLM and\nlanguage-conditioned CNNs on RTFM. Through curriculum learning, txt2$\\pi$\nproduces policies that excel on complex RTFM tasks requiring several reasoning\nand coreference steps.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 00:49:15 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 21:26:05 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 21:49:27 GMT"}, {"version": "v4", "created": "Tue, 28 Jan 2020 18:37:02 GMT"}, {"version": "v5", "created": "Wed, 12 Feb 2020 20:22:15 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 20:46:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhong", "Victor", ""], ["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1910.08249", "submitter": "Kaveh Hassani", "authors": "Salvatore Vivona and Kaveh Hassani", "title": "Relational Graph Representation Learning for Open-Domain Question\n  Answering", "comments": "NeurIPS 2019 Workshop on Graph Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a relational graph neural network with bi-directional attention\nmechanism and hierarchical representation learning for open-domain question\nanswering task. Our model can learn contextual representation by jointly\nlearning and updating the query, knowledge graph, and document representations.\nThe experiments suggest that our model achieves state-of-the-art on the\nWebQuestionsSP benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 03:54:58 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Vivona", "Salvatore", ""], ["Hassani", "Kaveh", ""]]}, {"id": "1910.08252", "submitter": "Gong Cheng", "authors": "Qingxia Liu, Gong Cheng, Kalpa Gunaratna, Yuzhong Qu", "title": "Entity Summarization: State of the Art and Future Challenges", "comments": "25 pages, accepted by Journal of Web Semantics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing availability of semantic data has substantially enhanced Web\napplications. Semantic data such as RDF data is commonly represented as\nentity-property-value triples. The magnitude of semantic data, in particular\nthe large number of triples describing an entity, could overload users with\nexcessive amounts of information. This has motivated fruitful research on\nautomated generation of summaries for entity descriptions to satisfy users'\ninformation needs efficiently and effectively. We focus on this prominent topic\nof entity summarization, and our research objective is to present the first\ncomprehensive survey of entity summarization research. Rather than separately\nreviewing each method, our contributions include (1) identifying and\nclassifying technical features of existing methods to form a high-level\noverview, (2) identifying and classifying frameworks for combining multiple\ntechnical features adopted by existing methods, (3) collecting known benchmarks\nfor intrinsic evaluation and efforts for extrinsic evaluation, and (4)\nsuggesting research directions for future work. By investigating the\nliterature, we synthesized two hierarchies of techniques. The first hierarchy\ncategories generic technical features into several perspectives: frequency and\ncentrality, informativeness, and diversity and coverage. In the second\nhierarchy we present domain-specific and task-specific technical features,\nincluding the use of domain knowledge, context awareness, and personalization.\nOur review demonstrated that existing methods are mainly unsupervised and they\ncombine multiple technical features using various frameworks: random surfer\nmodels, similarity-based grouping, MMR-like re-ranking, or combinatorial\noptimization. We also found a few deep learning based methods in recent\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 04:02:33 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 02:22:59 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Liu", "Qingxia", ""], ["Cheng", "Gong", ""], ["Gunaratna", "Kalpa", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1910.08270", "submitter": "Manirupa Das", "authors": "Manirupa Das, Zhen Wang, Evan Jaffe, Madhuja Chattopadhyay, Eric\n  Fosler-Lussier and Rajiv Ramnath", "title": "Learning to Answer Subjective, Specific Product-Related Queries using\n  Customer Reviews by Adversarial Domain Adaptation", "comments": "8 pages, 1 figure, 6 tables, added additional references to end of\n  section 2.1, removed graphics from referenced works, added to argument in\n  section 2.3 corrected typos, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online customer reviews on large-scale e-commerce websites, represent a rich\nand varied source of opinion data, often providing subjective qualitative\nassessments of product usage that can help potential customers to discover\nfeatures that meet their personal needs and preferences. Thus they have the\npotential to automatically answer specific queries about products, and to\naddress the problems of answer starvation and answer augmentation on associated\nconsumer Q & A forums, by providing good answer alternatives. In this work, we\nexplore several recently successful neural approaches to modeling sentence\npairs, that could better learn the relationship between questions and ground\ntruth answers, and thus help infer reviews that can best answer a question or\naugment a given answer. In particular, we hypothesize that our adversarial\ndomain adaptation-based approach, due to its ability to additionally learn\ndomain-invariant features from a large number of unlabeled, unpaired\nquestion-review samples, would perform better than our proposed baselines, at\nanswering specific, subjective product-related queries using reviews. We\nvalidate this hypothesis using a small gold standard dataset of question-review\npairs evaluated by human experts, significantly surpassing our chosen\nbaselines. Moreover, our approach, using no labeled question-review sentence\npair data for training, gives performance at par with another method utilizing\nlabeled question-review samples for the same task.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 05:28:46 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 07:12:45 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Das", "Manirupa", ""], ["Wang", "Zhen", ""], ["Jaffe", "Evan", ""], ["Chattopadhyay", "Madhuja", ""], ["Fosler-Lussier", "Eric", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1910.08282", "submitter": "Kun Zhou", "authors": "Kun Zhou, Kai Zhang, Yu Wu, Shujie Liu, Jingsong Yu", "title": "Unsupervised Context Rewriting for Open Domain Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context modeling has a pivotal role in open domain conversation. Existing\nworks either use heuristic methods or jointly learn context modeling and\nresponse generation with an encoder-decoder framework. This paper proposes an\nexplicit context rewriting method, which rewrites the last utterance by\nconsidering context history. We leverage pseudo-parallel data and elaborate a\ncontext rewriting network, which is built upon the CopyNet with the\nreinforcement learning method. The rewritten utterance is beneficial to\ncandidate retrieval, explainable context modeling, as well as enabling to\nemploy a single-turn framework to the multi-turn scenario. The empirical\nresults show that our model outperforms baselines in terms of the rewriting\nquality, the multi-turn response generation, and the end-to-end retrieval-based\nchatbots.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:49:55 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:41:45 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zhou", "Kun", ""], ["Zhang", "Kai", ""], ["Wu", "Yu", ""], ["Liu", "Shujie", ""], ["Yu", "Jingsong", ""]]}, {"id": "1910.08293", "submitter": "Steven Y. Feng", "authors": "Aaron W. Li, Veronica Jiang, Steven Y. Feng, Julia Sprague, Wei Zhou,\n  Jesse Hoey", "title": "ALOHA: Artificial Learning of Human Attributes for Dialogue Agents", "comments": "AAAI 2020; Code available at https://github.com/newpro/aloha-chatbot", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6328", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For conversational AI and virtual assistants to communicate with humans in a\nrealistic way, they must exhibit human characteristics such as expression of\nemotion and personality. Current attempts toward constructing human-like\ndialogue agents have presented significant difficulties. We propose Human Level\nAttributes (HLAs) based on tropes as the basis of a method for learning\ndialogue agents that can imitate the personalities of fictional characters.\nTropes are characteristics of fictional personalities that are observed\nrecurrently and determined by viewers' impressions. By combining detailed HLA\ndata with dialogue data for specific characters, we present a dataset,\nHLA-Chat, that models character profiles and gives dialogue agents the ability\nto learn characters' language styles through their HLAs. We then introduce a\nthree-component system, ALOHA (which stands for Artificial Learning of Human\nAttributes), that combines character space mapping, character community\ndetection, and language style retrieval to build a character (or personality)\nspecific language model. Our preliminary experiments demonstrate that two\nvariations of ALOHA, combined with our proposed dataset, can outperform\nbaseline models at identifying the correct dialogue responses of chosen target\ncharacters, and are stable regardless of the character's identity, the genre of\nthe show, and the context of the dialogue.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:52:01 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 19:18:03 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 07:52:11 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Aaron W.", ""], ["Jiang", "Veronica", ""], ["Feng", "Steven Y.", ""], ["Sprague", "Julia", ""], ["Zhou", "Wei", ""], ["Hoey", "Jesse", ""]]}, {"id": "1910.08294", "submitter": "Elizabeth Jasmi George", "authors": "Elizabeth Jasmi George and Radhika Mamidi", "title": "Towards Computing Inferences from English News Headlines", "comments": "PACLING 2019 Long paper, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newspapers are a popular form of written discourse, read by many people,\nthanks to the novelty of the information provided by the news content in it. A\nheadline is the most widely read part of any newspaper due to its appearance in\na bigger font and sometimes in colour print. In this paper, we suggest and\nimplement a method for computing inferences from English news headlines,\nexcluding the information from the context in which the headlines appear. This\nmethod attempts to generate the possible assumptions a reader formulates in\nmind upon reading a fresh headline. The generated inferences could be useful\nfor assessing the impact of the news headline on readers including children.\nThe understandability of the current state of social affairs depends greatly on\nthe assimilation of the headlines. As the inferences that are independent of\nthe context depend mainly on the syntax of the headline, dependency trees of\nheadlines are used in this approach, to find the syntactical structure of the\nheadlines and to compute inferences out of them.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 07:56:08 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["George", "Elizabeth Jasmi", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1910.08350", "submitter": "Dani Yogatama", "authors": "Lingpeng Kong, Cyprien de Masson d'Autume, Wang Ling, Lei Yu, Zihang\n  Dai, Dani Yogatama", "title": "A Mutual Information Maximization Perspective of Language Representation\n  Learning", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show state-of-the-art word representation learning methods maximize an\nobjective function that is a lower bound on the mutual information between\ndifferent parts of a word sequence (i.e., a sentence). Our formulation provides\nan alternative perspective that unifies classical word embedding models (e.g.,\nSkip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to\nenhancing our theoretical understanding of these methods, our derivation leads\nto a principled framework that can be used to construct new self-supervised\ntasks. We provide an example by drawing inspirations from related methods based\non mutual information maximization that have been successful in computer\nvision, and introduce a simple self-supervised objective that maximizes the\nmutual information between a global sentence representation and n-grams in the\nsentence. Our analysis offers a holistic view of representation learning\nmethods to transfer knowledge and translate progress across multiple domains\n(e.g., natural language processing, computer vision, audio processing).\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 11:47:24 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 17:59:43 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Kong", "Lingpeng", ""], ["d'Autume", "Cyprien de Masson", ""], ["Ling", "Wang", ""], ["Yu", "Lei", ""], ["Dai", "Zihang", ""], ["Yogatama", "Dani", ""]]}, {"id": "1910.08381", "submitter": "Ming Gong", "authors": "Ze Yang, Linjun Shou, Ming Gong, Wutao Lin, Daxin Jiang", "title": "Model Compression with Two-stage Multi-teacher Knowledge Distillation\n  for Web Question Answering System", "comments": "Accepted by WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep pre-training and fine-tuning models (such as BERT and OpenAI GPT) have\ndemonstrated excellent results in question answering areas. However, due to the\nsheer amount of model parameters, the inference speed of these models is very\nslow. How to apply these complex models to real business scenarios becomes a\nchallenging but practical problem. Previous model compression methods usually\nsuffer from information loss during the model compression procedure, leading to\ninferior models compared with the original one. To tackle this challenge, we\npropose a Two-stage Multi-teacher Knowledge Distillation (TMKD for short)\nmethod for web Question Answering system. We first develop a general Q\\&A\ndistillation task for student model pre-training, and further fine-tune this\npre-trained student model with multi-teacher knowledge distillation on\ndownstream tasks (like Web Q\\&A task, MNLI, SNLI, RTE tasks from GLUE), which\neffectively reduces the overfitting bias in individual teacher models, and\ntransfers more general knowledge to the student model. The experiment results\nshow that our method can significantly outperform the baseline methods and even\nachieve comparable results with the original teacher models, along with\nsubstantial speedup of model inference.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 12:36:52 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Yang", "Ze", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Lin", "Wutao", ""], ["Jiang", "Daxin", ""]]}, {"id": "1910.08418", "submitter": "Laurent Besacier", "authors": "Pierre Godard, Laurent Besacier, Francois Yvon", "title": "Controlling Utterance Length in NMT-based Word Segmentation with\n  Attention", "comments": "Accepted to IWSLT 2019 (Hong-Kong)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the basic tasks of computational language documentation (CLD) is to\nidentify word boundaries in an unsegmented phonemic stream. While several\nunsupervised monolingual word segmentation algorithms exist in the literature,\nthey are challenged in real-world CLD settings by the small amount of available\ndata. A possible remedy is to take advantage of glosses or translation in a\nforeign, well-resourced, language, which often exist for such data. In this\npaper, we explore and compare ways to exploit neural machine translation models\nto perform unsupervised boundary detection with bilingual information, notably\nintroducing a new loss function for jointly learning alignment and\nsegmentation. We experiment with an actual under-resourced language, Mboshi,\nand show that these techniques can effectively control the output segmentation\nlength.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:44:16 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Godard", "Pierre", ""], ["Besacier", "Laurent", ""], ["Yvon", "Francois", ""]]}, {"id": "1910.08435", "submitter": "Angela Fan", "authors": "Angela Fan, Claire Gardent, Chloe Braud, Antoine Bordes", "title": "Using Local Knowledge Graph Construction to Scale Seq2Seq Models to\n  Multi-Document Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query-based open-domain NLP tasks require information synthesis from long and\ndiverse web results. Current approaches extractively select portions of web\ntext as input to Sequence-to-Sequence models using methods such as TF-IDF\nranking. We propose constructing a local graph structured knowledge base for\neach query, which compresses the web search information and reduces redundancy.\nWe show that by linearizing the graph into a structured input sequence, models\ncan encode the graph representations within a standard Sequence-to-Sequence\nsetting. For two generative tasks with very long text input, long-form question\nanswering and multi-document summarization, feeding graph representations as\ninput can achieve better performance than using retrieved text portions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 14:23:03 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Fan", "Angela", ""], ["Gardent", "Claire", ""], ["Braud", "Chloe", ""], ["Bordes", "Antoine", ""]]}, {"id": "1910.08486", "submitter": "Yang Gao", "authors": "Wang Wenbo, Gao Yang, Huang Heyan, Zhou Yuxiang", "title": "Concept Pointer Network for Abstractive Summarization", "comments": "Accepted by EMNLP'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quality abstractive summary should not only copy salient source texts as\nsummaries but should also tend to generate new conceptual words to express\nconcrete details. Inspired by the popular pointer generator\nsequence-to-sequence model, this paper presents a concept pointer network for\nimproving these aspects of abstractive summarization. The network leverages\nknowledge-based, context-aware conceptualizations to derive an extended set of\ncandidate concepts. The model then points to the most appropriate choice using\nboth the concept set and original source text. This joint approach generates\nabstractive summaries with higher-level semantic concepts. The training model\nis also optimized in a way that adapts to different data, which is based on a\nnovel method of distantly-supervised learning guided by reference summaries and\ntesting set. Overall, the proposed approach provides statistically significant\nimprovements over several state-of-the-art models on both the DUC-2004 and\nGigaword datasets. A human evaluation of the model's abstractive abilities also\nsupports the quality of the summaries produced within this framework.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 16:11:31 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Wenbo", "Wang", ""], ["Yang", "Gao", ""], ["Heyan", "Huang", ""], ["Yuxiang", "Zhou", ""]]}, {"id": "1910.08502", "submitter": "Florian Boyer Md", "authors": "Florian Boyer and Jean-Luc Rouas", "title": "End-to-End Speech Recognition: A review for the French Language", "comments": "10 pages, 2 column-style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, end-to-end ASR based either on sequence-to-sequence networks or on\nthe CTC objective function gained a lot of interest from the community,\nachieving competitive results over traditional systems using robust but complex\npipelines. One of the main features of end-to-end systems, in addition to the\nability to free themselves from extra linguistic resources such as dictionaries\nor language models, is the capacity to model acoustic units such as characters,\nsubwords or directly words; opening up the capacity to directly translate\nspeech with different representations or levels of knowledge depending on the\ntarget language. In this paper we propose a review of the existing end-to-end\nASR approaches for the French language. We compare results to conventional\nstate-of-the-art ASR systems and discuss which units are more suited to model\nthe French language.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 16:52:01 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:22:11 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Boyer", "Florian", ""], ["Rouas", "Jean-Luc", ""]]}, {"id": "1910.08534", "submitter": "Vivian Lai", "authors": "Vivian Lai, Jon Z. Cai, Chenhao Tan", "title": "Many Faces of Feature Importance: Comparing Built-in and Post-hoc\n  Feature Importance in Text Classification", "comments": "17 pages, 18 figures, EMNLP 2019, the code is available at\n  https://vivlai.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature importance is commonly used to explain machine predictions. While\nfeature importance can be derived from a machine learning model with a variety\nof methods, the consistency of feature importance via different methods remains\nunderstudied. In this work, we systematically compare feature importance from\nbuilt-in mechanisms in a model such as attention values and post-hoc methods\nthat approximate model behavior such as LIME. Using text classification as a\ntestbed, we find that 1) no matter which method we use, important features from\ntraditional models such as SVM and XGBoost are more similar with each other,\nthan with deep learning models; 2) post-hoc methods tend to generate more\nsimilar important features for two models than built-in methods. We further\ndemonstrate how such similarity varies across instances. Notably, important\nfeatures do not always resemble each other better when two models agree on the\npredicted label than when they disagree.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 17:59:59 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Lai", "Vivian", ""], ["Cai", "Jon Z.", ""], ["Tan", "Chenhao", ""]]}, {"id": "1910.08549", "submitter": "Achim Rettinger", "authors": "Achim Rettinger, Viktoria Bogdanova, Philipp Niemann", "title": "Towards Learning Cross-Modal Perception-Trace Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a key element of state-of-the-art deep learning\napproaches. It enables to transform raw data into structured vector space\nembeddings. Such embeddings are able to capture the distributional semantics of\ntheir context, e.g. by word windows on natural language sentences, graph walks\non knowledge graphs or convolutions on images. So far, this context is manually\ndefined, resulting in heuristics which are solely optimized for computational\nperformance on certain tasks like link-prediction. However, such heuristic\nmodels of context are fundamentally different to how humans capture\ninformation. For instance, when reading a multi-modal webpage (i) humans do not\nperceive all parts of a document equally: Some words and parts of images are\nskipped, others are revisited several times which makes the perception trace\nhighly non-sequential; (ii) humans construct meaning from a document's content\nby shifting their attention between text and image, among other things, guided\nby layout and design elements. In this paper we empirically investigate the\ndifference between human perception and context heuristics of basic embedding\nmodels. We conduct eye tracking experiments to capture the underlying\ncharacteristics of human perception of media documents containing a mixture of\ntext and images. Based on that, we devise a prototypical computational\nperception-trace model, called CMPM. We evaluate empirically how CMPM can\nimprove a basic skip-gram embedding approach. Our results suggest, that even\nwith a basic human-inspired computational perception model, there is a huge\npotential for improving embeddings since such a model does inherently capture\nmultiple modalities, as well as layout and design elements.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:20:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Rettinger", "Achim", ""], ["Bogdanova", "Viktoria", ""], ["Niemann", "Philipp", ""]]}, {"id": "1910.08592", "submitter": "Rajen Chatterjee", "authors": "Rajen Chatterjee", "title": "Automatic Post-Editing for Machine Translation", "comments": "PhD dissertation on Automatic Post-Editing for Machine Translation\n  (this work has been done between 2014 and 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Post-Editing (APE) aims to correct systematic errors in a machine\ntranslated text. This is primarily useful when the machine translation (MT)\nsystem is not accessible for improvement, leaving APE as a viable option to\nimprove translation quality as a downstream task - which is the focus of this\nthesis. This field has received less attention compared to MT due to several\nreasons, which include: the limited availability of data to perform a sound\nresearch, contrasting views reported by different researchers about the\neffectiveness of APE, and limited attention from the industry to use APE in\ncurrent production pipelines. In this thesis, we perform a thorough\ninvestigation of APE as a downstream task in order to: i) understand its\npotential to improve translation quality; ii) advance the core technology -\nstarting from classical methods to recent deep-learning based solutions; iii)\ncope with limited and sparse data; iv) better leverage multiple input sources;\nv) mitigate the task-specific problem of over-correction; vi) enhance neural\ndecoding to leverage external knowledge; and vii) establish an online learning\nframework to handle data diversity in real-time. All the above contributions\nare discussed across several chapters, and most of them are evaluated in the\nAPE shared task organized each year at the Conference on Machine Translation.\nOur efforts in improving the technology resulted in the best system at the 2017\nAPE shared task, and our work on online learning received a distinguished paper\naward at the Italian Conference on Computational Linguistics. Overall, outcomes\nand findings of our work have boost interest among researchers and attracted\nindustries to examine this technology to solve real-word problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 19:14:17 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Chatterjee", "Rajen", ""]]}, {"id": "1910.08684", "submitter": "Ran Tian", "authors": "Ran Tian, Shashi Narayan, Thibault Sellam, Ankur P. Parikh", "title": "Sticking to the Facts: Confident Decoding for Faithful Data-to-Text\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of hallucination in data-to-text generation, i.e.,\nreducing the generation of text that is unsupported by the source. We\nconjecture that hallucination can be caused by an encoder-decoder model\ngenerating content phrases without attending to the source; so we propose a\nconfidence score to ensure that the model attends to the source whenever\nnecessary, as well as a variational Bayes training framework that can learn the\nscore from data. Experiments on the WikiBio (Lebretet al., 2016) dataset show\nthat our approach is more faithful to the source than existing state-of-the-art\napproaches, according to both PARENT score (Dhingra et al., 2019) and human\nevaluation. We also report strong results on the WebNLG (Gardent et al., 2017)\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 03:00:46 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 01:20:58 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 13:25:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tian", "Ran", ""], ["Narayan", "Shashi", ""], ["Sellam", "Thibault", ""], ["Parikh", "Ankur P.", ""]]}, {"id": "1910.08692", "submitter": "Xiaofei Xu", "authors": "Xiaofei Xu, Ke Deng, Fei Hu, Li Li", "title": "An Improved Historical Embedding without Alignment", "comments": "9 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many words have evolved in meaning as a result of cultural and social change.\nUnderstanding such changes is crucial for modelling language and cultural\nevolution. Low-dimensional embedding methods have shown promise in detecting\nwords' meaning change by encoding them into dense vectors. However, when\nexploring semantic change of words over time, these methods require the\nalignment of word embeddings across different time periods. This process is\ncomputationally expensive, prohibitively time consuming and suffering from\ncontextual variability. In this paper, we propose a new and scalable method for\nencoding words from different time periods into one dense vector space. This\ncan greatly improve performance when it comes to identifying words that have\nchanged in meaning over time. We evaluated our method on dataset from Google\nBooks N-gram. Our method outperformed three other popular methods in terms of\nthe number of words correctly identified to have changed in meaning.\nAdditionally, we provide an intuitive visualization of the semantic evolution\nof some words extracted by our method\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 03:32:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Xu", "Xiaofei", ""], ["Deng", "Ke", ""], ["Hu", "Fei", ""], ["Li", "Li", ""]]}, {"id": "1910.08716", "submitter": "Songxiang Liu", "authors": "Songxiang Liu, Haibin Wu, Hung-yi Lee, Helen Meng", "title": "Adversarial Attacks on Spoofing Countermeasures of automatic speaker\n  verification", "comments": "Accepted for ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance spoofing countermeasure systems for automatic speaker\nverification (ASV) have been proposed in the ASVspoof 2019 challenge. However,\nthe robustness of such systems under adversarial attacks has not been studied\nyet. In this paper, we investigate the vulnerability of spoofing\ncountermeasures for ASV under both white-box and black-box adversarial attacks\nwith the fast gradient sign method (FGSM) and the projected gradient descent\n(PGD) method. We implement high-performing countermeasure models in the\nASVspoof 2019 challenge and conduct adversarial attacks on them. We compare\nperformance of black-box attacks across spoofing countermeasure models with\ndifferent network architectures and different amount of model parameters. The\nexperimental results show that all implemented countermeasure models are\nvulnerable to FGSM and PGD attacks under the scenario of white-box attack. The\nmore dangerous black-box attacks also prove to be effective by the experimental\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 07:28:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Liu", "Songxiang", ""], ["Wu", "Haibin", ""], ["Lee", "Hung-yi", ""], ["Meng", "Helen", ""]]}, {"id": "1910.08772", "submitter": "Hai Hu", "authors": "Hai Hu, Qi Chen, Kyle Richardson, Atreyee Mukherjee, Lawrence S. Moss,\n  Sandra Kuebler", "title": "MonaLog: a Lightweight System for Natural Language Inference Based on\n  Monotonicity", "comments": "accepted to SCIL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new logic-based inference engine for natural language inference\n(NLI) called MonaLog, which is based on natural logic and the monotonicity\ncalculus. In contrast to existing logic-based approaches, our system is\nintentionally designed to be as lightweight as possible, and operates using a\nsmall set of well-known (surface-level) monotonicity facts about quantifiers,\nlexical items and tokenlevel polarity information. Despite its simplicity, we\nfind our approach to be competitive with other logic-based NLI models on the\nSICK benchmark. We also use MonaLog in combination with the current\nstate-of-the-art model BERT in a variety of settings, including for\ncompositional data augmentation. We show that MonaLog is capable of generating\nlarge amounts of high-quality training data for BERT, improving its accuracy on\nSICK.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 13:45:30 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hu", "Hai", ""], ["Chen", "Qi", ""], ["Richardson", "Kyle", ""], ["Mukherjee", "Atreyee", ""], ["Moss", "Lawrence S.", ""], ["Kuebler", "Sandra", ""]]}, {"id": "1910.08832", "submitter": "Yu Chen", "authors": "Yu Chen, Lingfei Wu and Mohammed J. Zaki", "title": "Natural Question Generation with Reinforcement Learning Based\n  Graph-to-Sequence Model", "comments": "4 pages. Accepted at the NeurIPS 2019 Workshop on Graph\n  Representation Learning (NeurIPS GRL 2019). Final Version. arXiv admin note:\n  substantial text overlap with arXiv:1908.04942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural question generation (QG) aims to generate questions from a passage\nand an answer. In this paper, we propose a novel reinforcement learning (RL)\nbased graph-to-sequence (Graph2Seq) model for QG. Our model consists of a\nGraph2Seq generator where a novel Bidirectional Gated Graph Neural Network is\nproposed to embed the passage, and a hybrid evaluator with a mixed objective\ncombining both cross-entropy and RL losses to ensure the generation of\nsyntactically and semantically valid text. The proposed model outperforms\nprevious state-of-the-art methods by a large margin on the SQuAD dataset.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 20:05:44 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Chen", "Yu", ""], ["Wu", "Lingfei", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "1910.08840", "submitter": "Debanjan Mahata", "authors": "Dhruva Sahrawat, Debanjan Mahata, Mayank Kulkarni, Haimin Zhang,\n  Rakesh Gosangi, Amanda Stent, Agniv Sharma, Yaman Kumar, Rajiv Ratn Shah,\n  Roger Zimmermann", "title": "Keyphrase Extraction from Scholarly Articles as Sequence Labeling using\n  Contextualized Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate keyphrase extraction from scholarly articles as a\nsequence labeling task solved using a BiLSTM-CRF, where the words in the input\ntext are represented using deep contextualized embeddings. We evaluate the\nproposed architecture using both contextualized and fixed word embedding models\non three different benchmark datasets (Inspec, SemEval 2010, SemEval 2017) and\ncompare with existing popular unsupervised and supervised techniques. Our\nresults quantify the benefits of (a) using contextualized embeddings (e.g.\nBERT) over fixed word embeddings (e.g. Glove); (b) using a BiLSTM-CRF\narchitecture with contextualized word embeddings over fine-tuning the\ncontextualized word embedding model directly, and (c) using genre-specific\ncontextualized embeddings (SciBERT). Through error analysis, we also provide\nsome insights into why particular models work better than others. Lastly, we\npresent a case study where we analyze different self-attention layers of the\ntwo best models (BERT and SciBERT) to better understand the predictions made by\neach for the task of keyphrase extraction.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 20:42:59 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Sahrawat", "Dhruva", ""], ["Mahata", "Debanjan", ""], ["Kulkarni", "Mayank", ""], ["Zhang", "Haimin", ""], ["Gosangi", "Rakesh", ""], ["Stent", "Amanda", ""], ["Sharma", "Agniv", ""], ["Kumar", "Yaman", ""], ["Shah", "Rajiv Ratn", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1910.08902", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan and Borja Balle and Thomas Drake and Tom Diethe", "title": "Privacy- and Utility-Preserving Textual Analysis via Calibrated\n  Multivariate Perturbations", "comments": "Accepted at WSDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately learning from user data while providing quantifiable privacy\nguarantees provides an opportunity to build better ML models while maintaining\nuser trust. This paper presents a formal approach to carrying out privacy\npreserving text perturbation using the notion of dx-privacy designed to achieve\ngeo-indistinguishability in location data. Our approach applies carefully\ncalibrated noise to vector representation of words in a high dimension space as\ndefined by word embedding models. We present a privacy proof that satisfies\ndx-privacy where the privacy parameter epsilon provides guarantees with respect\nto a distance metric defined by the word embedding space. We demonstrate how\nepsilon can be selected by analyzing plausible deniability statistics backed up\nby large scale analysis on GloVe and fastText embeddings. We conduct privacy\naudit experiments against 2 baseline models and utility experiments on 3\ndatasets to demonstrate the tradeoff between privacy and utility for varying\nvalues of epsilon on different task types. Our results demonstrate practical\nutility (< 2% utility loss for training binary classifiers) while providing\nbetter privacy guarantees than baseline models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 05:12:23 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Balle", "Borja", ""], ["Drake", "Thomas", ""], ["Diethe", "Tom", ""]]}, {"id": "1910.08910", "submitter": "Fanchao Qi", "authors": "Yujia Qin, Fanchao Qi, Sicong Ouyang, Zhiyuan Liu, Cheng Yang, Yasheng\n  Wang, Qun Liu, Maosong Sun", "title": "Improving Sequence Modeling Ability of Recurrent Neural Networks via\n  Sememes", "comments": "Published in IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing (TASLP). 10 pages, 2 figures", "journal-ref": null, "doi": "10.1109/TASLP.2020.3012060", "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sememes, the minimum semantic units of human languages, have been\nsuccessfully utilized in various natural language processing applications.\nHowever, most existing studies exploit sememes in specific tasks and few\nefforts are made to utilize sememes more fundamentally. In this paper, we\npropose to incorporate sememes into recurrent neural networks (RNNs) to improve\ntheir sequence modeling ability, which is beneficial to all kinds of downstream\ntasks. We design three different sememe incorporation methods and employ them\nin typical RNNs including LSTM, GRU and their bidirectional variants. In\nevaluation, we use several benchmark datasets involving PTB and WikiText-2 for\nlanguage modeling, SNLI for natural language inference and another two datasets\nfor sentiment analysis and paraphrase detection. Experimental results show\nevident and consistent improvement of our sememe-incorporated models compared\nwith vanilla RNNs, which proves the effectiveness of our sememe incorporation\nmethods. Moreover, we find the sememe-incorporated models have higher\nrobustness and outperform adversarial training in defending adversarial attack.\nAll the code and data of this work can be obtained at\nhttps://github.com/thunlp/SememeRNN.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 06:43:21 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 09:17:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Qin", "Yujia", ""], ["Qi", "Fanchao", ""], ["Ouyang", "Sicong", ""], ["Liu", "Zhiyuan", ""], ["Yang", "Cheng", ""], ["Wang", "Yasheng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "1910.08916", "submitter": "Wenxiang Jiao", "authors": "Wenxiang Jiao, Michael R. Lyu, and Irwin King", "title": "PT-CoDE: Pre-trained Context-Dependent Encoder for Utterance-level\n  Emotion Recognition", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utterance-level emotion recognition (ULER) is a significant research topic\nfor understanding human behaviors and developing empathetic chatting machines\nin the artificial intelligence area. Unlike traditional text classification\nproblem, this task is supported by a limited number of datasets, among which\nmost contain inadequate conversations or speeches. Such a data scarcity issue\nlimits the possibility of training larger and more powerful models for this\ntask. Witnessing the success of transfer learning in natural language process\n(NLP), we propose to pre-train a context-dependent encoder (CoDE) for ULER by\nlearning from unlabeled conversation data. Essentially, CoDE is a hierarchical\narchitecture that contains an utterance encoder and a conversation encoder,\nmaking it different from those works that aim to pre-train a universal sentence\nencoder. Also, we propose a new pre-training task named \"conversation\ncompletion\" (CoCo), which attempts to select the correct answer from candidate\nanswers to fill a masked utterance in a question conversation. The CoCo task is\ncarried out on pure movie subtitles so that our CoDE can be pre-trained in an\nunsupervised fashion. Finally, the pre-trained CoDE (PT-CoDE) is fine-tuned for\nULER and boosts the model performance significantly on five datasets.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 07:12:04 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jiao", "Wenxiang", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1910.08917", "submitter": "Oluwaseyi Feyisetan", "authors": "Oluwaseyi Feyisetan and Tom Diethe and Thomas Drake", "title": "Leveraging Hierarchical Representations for Preserving Privacy and\n  Utility in Text", "comments": "Accepted at ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guaranteeing a certain level of user privacy in an arbitrary piece of text is\na challenging issue. However, with this challenge comes the potential of\nunlocking access to vast data stores for training machine learning models and\nsupporting data driven decisions. We address this problem through the lens of\ndx-privacy, a generalization of Differential Privacy to non Hamming distance\nmetrics. In this work, we explore word representations in Hyperbolic space as a\nmeans of preserving privacy in text. We provide a proof satisfying dx-privacy,\nthen we define a probability distribution in Hyperbolic space and describe a\nway to sample from it in high dimensions. Privacy is provided by perturbing\nvector representations of words in high dimensional Hyperbolic space to obtain\na semantic generalization. We conduct a series of experiments to demonstrate\nthe tradeoff between privacy and utility. Our privacy experiments illustrate\nprotections against an authorship attribution algorithm while our utility\nexperiments highlight the minimal impact of our perturbations on several\ndownstream machine learning models. Compared to the Euclidean baseline, we\nobserve > 20x greater guarantees on expected privacy against comparable worst\ncase statistics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 07:16:29 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Diethe", "Tom", ""], ["Drake", "Thomas", ""]]}, {"id": "1910.08948", "submitter": "Preslav Nakov", "authors": "Yoan Dinkov, Ahmed Ali, Ivan Koychev, Preslav Nakov", "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "comments": "media bias, political ideology, Youtube channels, propaganda,\n  disinformation, fake news", "journal-ref": "INTERSPEECH-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 11:05:05 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Dinkov", "Yoan", ""], ["Ali", "Ahmed", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.08955", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and David Fuenmayor", "title": "Computer-supported Analysis of Positive Properties, Ultrafilters and\n  Modal Collapse in Variants of G\\\"odel's Ontological Argument", "comments": "21 pages, 6 figures; to appear in the Bulletin of the Section of\n  Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three variants of Kurt G\\\"odel's ontological argument, proposed by Dana\nScott, C. Anthony Anderson and Melvin Fitting, are encoded and rigorously\nassessed on the computer. In contrast to Scott's version of G\\\"odel's argument\nthe two variants contributed by Anderson and Fitting avoid modal collapse.\nAlthough they appear quite different on a cursory reading they are in fact\nclosely related. This has been revealed in the computer-supported formal\nanalysis presented in this article. Key to our formal analysis is the\nutilization of suitably adapted notions of (modal) ultrafilters, and a careful\ndistinction between extensions and intensions of positive properties.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 11:54:05 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 12:32:15 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Fuenmayor", "David", ""]]}, {"id": "1910.08962", "submitter": "Samuel M\\\"uller", "authors": "Samuel M\\\"uller and Andreas Vlachos", "title": "Byte-Pair Encoding for Text-to-SQL Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence models provide a competitive approach to the task\nof mapping a question in natural language to an SQL query, also referred to as\ntext-to-SQL generation. The Byte-Pair Encoding algorithm (BPE) has previously\nbeen used to improve machine translation (MT) between natural languages. In\nthis work, we adapt BPE for text-to-SQL generation. As the datasets for this\ntask are rather small compared to MT, we present a novel stopping criterion\nthat prevents overfitting the BPE encoding to the training set. Additionally,\nwe present AST BPE, which is a version of BPE that uses the Abstract Syntax\nTree (AST) of the SQL statement to guide BPE merges and therefore produce BPE\nencodings that generalize better. We improved the accuracy of a strong\nattentive seq2seq baseline on five out of six English text-to-SQL tasks while\nreducing training time by more than 50% on four of them due to the shortened\ntargets. Finally, on two of these tasks we exceeded previously reported\naccuracies.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 12:32:20 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 12:02:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["M\u00fcller", "Samuel", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1910.08987", "submitter": "Bai Li", "authors": "Bai Li, Jing Yi Xie, Frank Rudzicz", "title": "Representation Learning for Discovering Phonemic Tone Contours", "comments": "Accepted by SIGMORPHON 2020: 17th SIGMORPHON Workshop on\n  Computational Research in Phonetics, Phonology, and Morphology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tone is a prosodic feature used to distinguish words in many languages, some\nof which are endangered and scarcely documented. In this work, we use\nunsupervised representation learning to identify probable clusters of syllables\nthat share the same phonemic tone. Our method extracts the pitch for each\nsyllable, then trains a convolutional autoencoder to learn a low dimensional\nrepresentation for each contour. We then apply the mean shift algorithm to\ncluster tones in high-density regions of the latent space. Furthermore, by\nfeeding the centers of each cluster into the decoder, we produce a prototypical\ncontour that represents each cluster. We apply this method to spoken\nmulti-syllable words in Mandarin Chinese and Cantonese and evaluate how closely\nour clusters match the ground truth tone categories. Finally, we discuss some\ndifficulties with our approach, including contextual tone variation and\nallophony effects.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 14:18:51 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 22:23:28 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Li", "Bai", ""], ["Xie", "Jing Yi", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1910.09058", "submitter": "Mikolaj Kegler", "authors": "Mikolaj Kegler, Pierre Beckmann, Milos Cernak", "title": "Deep speech inpainting of time-frequency masks", "comments": "Accepted to InterSpeech2020", "journal-ref": "Proc. Interspeech 2020, 3276-3280", "doi": "10.21437/Interspeech.2020-1532", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient loud intrusions, often occurring in noisy environments, can\ncompletely overpower speech signal and lead to an inevitable loss of\ninformation. While existing algorithms for noise suppression can yield\nimpressive results, their efficacy remains limited for very low signal-to-noise\nratios or when parts of the signal are missing. To address these limitations,\nhere we propose an end-to-end framework for speech inpainting, the\ncontext-based retrieval of missing or severely distorted parts of\ntime-frequency representation of speech. The framework is based on a\nconvolutional U-Net trained via deep feature losses, obtained using speechVGG,\na deep speech feature extractor pre-trained on an auxiliary word classification\ntask. Our evaluation results demonstrate that the proposed framework can\nrecover large portions of missing or distorted time-frequency representation of\nspeech, up to 400 ms and 3.2 kHz in bandwidth. In particular, our approach\nprovided a substantial increase in STOI & PESQ objective metrics of the\ninitially corrupted speech samples. Notably, using deep feature losses to train\nthe framework led to the best results, as compared to conventional approaches.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 20:24:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 11:53:55 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 15:11:06 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 14:28:23 GMT"}, {"version": "v5", "created": "Sat, 29 Aug 2020 18:13:04 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kegler", "Mikolaj", ""], ["Beckmann", "Pierre", ""], ["Cernak", "Milos", ""]]}, {"id": "1910.09113", "submitter": "Paul Soulos", "authors": "Paul Soulos, Tom McCoy, Tal Linzen, Paul Smolensky", "title": "Discovering the Compositional Structure of Vector Representations with\n  Role Learning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can neural networks perform so well on compositional tasks even though\nthey lack explicit compositional representations? We use a novel analysis\ntechnique called ROLE to show that recurrent neural networks perform well on\nsuch tasks by converging to solutions which implicitly represent symbolic\nstructure. This method uncovers a symbolic structure which, when properly\nembedded in vector space, closely approximates the encodings of a standard\nseq2seq network trained to perform the compositional SCAN task. We verify the\ncausal importance of the discovered symbolic structure by showing that, when we\nsystematically manipulate hidden embeddings based on this symbolic structure,\nthe model's output is changed in the way predicted by our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:12:51 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 16:38:33 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 20:23:51 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Soulos", "Paul", ""], ["McCoy", "Tom", ""], ["Linzen", "Tal", ""], ["Smolensky", "Paul", ""]]}, {"id": "1910.09129", "submitter": "Pinky Sitikhu", "authors": "Pinky Sitikhu, Kritish Pahi, Pujan Thapa, Subarna Shakya", "title": "A Comparison of Semantic Similarity Methods for Maximum Human\n  Interpretability", "comments": "Accepted in IEEE International Conference on Artificial Intelligence\n  for Transforming Business and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inclusion of semantic information in any similarity measures improves the\nefficiency of the similarity measure and provides human interpretable results\nfor further analysis. The similarity calculation method that focuses on\nfeatures related to the text's words only, will give less accurate results.\nThis paper presents three different methods that not only focus on the text's\nwords but also incorporates semantic information of texts in their feature\nvector and computes semantic similarities. These methods are based on\ncorpus-based and knowledge-based methods, which are: cosine similarity using\ntf-idf vectors, cosine similarity using word embedding and soft cosine\nsimilarity using word embedding. Among these three, cosine similarity using\ntf-idf vectors performed best in finding similarities between short news texts.\nThe similar texts given by the method are easy to interpret and can be used\ndirectly in other information retrieval applications.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 03:09:02 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 02:10:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Sitikhu", "Pinky", ""], ["Pahi", "Kritish", ""], ["Thapa", "Pujan", ""], ["Shakya", "Subarna", ""]]}, {"id": "1910.09134", "submitter": "Jiaying Lu", "authors": "Jiaying Lu, Xin Ye, Yi Ren, Yezhou Yang", "title": "Good, Better, Best: Textual Distractors Generation for Multi-Choice VQA\n  via Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of studies have investigated the decision-making process\nof VQA models. Many of these studies focus on the reason behind the correct\nanswer chosen by a model. Yet, the reason why the distracting answer chose by a\nmodel has rarely been studied. To this end, we introduce a novel task called\n\\textit{textual Distractors Generation for VQA} (DG-VQA) that explaining the\ndecision boundaries of existing VQA models. The goal of DG-VQA is to generate\nthe most confusing set of textual distractors in multi-choice VQA tasks which\nexpose the vulnerability of existing models (i.e. to generate distractors that\nlure existing models to fail). We show that DG-VQA can be formulated as a\nMarkov Decision Process, and present a reinforcement learning solution to come\nup with distractors in an unsupervised manner. The solution addresses the lack\nof large annotated corpus issues in previous distractor generation methods. Our\nproposed model receives reward signals from fully-trained multi-choice VQA\nmodels and updates its parameters via policy gradient. The empirical results\nshow that the generated textual distractors can successfully attack several\npopular VQA models with an average $20\\%$ accuracy drop from $64\\%$.\nFurthermore, we conduct adversarial training to improve the robustness of VQA\nmodels by incorporating the generated distractors. Empirical results validate\nthe effectiveness of adversarial training by showing a performance improvement\nof $27\\%$ for the multi-choice VQA task.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 03:32:17 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 21:01:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Lu", "Jiaying", ""], ["Ye", "Xin", ""], ["Ren", "Yi", ""], ["Yang", "Yezhou", ""]]}, {"id": "1910.09180", "submitter": "Takumi Ito", "authors": "Takumi Ito, Tatsuki Kuribayashi, Hayato Kobayashi, Ana Brassard,\n  Masato Hagiwara, Jun Suzuki, Kentaro Inui", "title": "Diamonds in the Rough: Generating Fluent Sentences from Early-Stage\n  Drafts for Academic Writing Assistance", "comments": "Proceedings of the 12th International Conference on Natural Language\n  Generation (INLG 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The writing process consists of several stages such as drafting, revising,\nediting, and proofreading. Studies on writing assistance, such as grammatical\nerror correction (GEC), have mainly focused on sentence editing and\nproofreading, where surface-level issues such as typographical, spelling, or\ngrammatical errors should be corrected. We broaden this focus to include the\nearlier revising stage, where sentences require adjustment to the information\nincluded or major rewriting and propose Sentence-level Revision (SentRev) as a\nnew writing assistance task. Well-performing systems in this task can help\ninexperienced authors by producing fluent, complete sentences given their\nrough, incomplete drafts. We build a new freely available crowdsourced\nevaluation dataset consisting of incomplete sentences authored by non-native\nwriters paired with their final versions extracted from published academic\npapers for developing and evaluating SentRev models. We also establish baseline\nperformance on SentRev using our newly built evaluation dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 07:26:07 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ito", "Takumi", ""], ["Kuribayashi", "Tatsuki", ""], ["Kobayashi", "Hayato", ""], ["Brassard", "Ana", ""], ["Hagiwara", "Masato", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "1910.09183", "submitter": "Yingxue Zhang", "authors": "Yingxue Zhang, Ping Jian, Fandong Meng, Ruiying Geng, Wei Cheng, Jie\n  Zhou", "title": "Semantic Graph Convolutional Network for Implicit Discourse Relation\n  Classification", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation classification is of great importance for\ndiscourse parsing, but remains a challenging problem due to the absence of\nexplicit discourse connectives communicating these relations. Modeling the\nsemantic interactions between the two arguments of a relation has proven useful\nfor detecting implicit discourse relations. However, most previous approaches\nmodel such semantic interactions from a shallow interactive level, which is\ninadequate on capturing enough semantic information. In this paper, we propose\na novel and effective Semantic Graph Convolutional Network (SGCN) to enhance\nthe modeling of inter-argument semantics on a deeper interaction level for\nimplicit discourse relation classification. We first build an interaction graph\nover representations of the two arguments, and then automatically extract\nin-depth semantic interactive information through graph convolution.\nExperimental results on the English corpus PDTB and the Chinese corpus CDTB\nboth demonstrate the superiority of our model to previous state-of-the-art\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 07:35:46 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zhang", "Yingxue", ""], ["Jian", "Ping", ""], ["Meng", "Fandong", ""], ["Geng", "Ruiying", ""], ["Cheng", "Wei", ""], ["Zhou", "Jie", ""]]}, {"id": "1910.09255", "submitter": "Gaurav Singh", "authors": "Gaurav Singh, Zahra Sabet, John Shawe-Taylor, James Thomas", "title": "Constructing Artificial Data for Fine-tuning for Low-Resource Biomedical\n  Text Tagging with Applications in PICO Annotation", "comments": "International Workshop on Health Intelligence (W3PHIAI-20); AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical text tagging systems are plagued by the dearth of labeled training\ndata. There have been recent attempts at using pre-trained encoders to deal\nwith this issue. Pre-trained encoder provides representation of the input text\nwhich is then fed to task-specific layers for classification. The entire\nnetwork is fine-tuned on the labeled data from the target task. Unfortunately,\na low-resource biomedical task often has too few labeled instances for\nsatisfactory fine-tuning. Also, if the label space is large, it contains few or\nno labeled instances for majority of the labels. Most biomedical tagging\nsystems treat labels as indexes, ignoring the fact that these labels are often\nconcepts expressed in natural language e.g. `Appearance of lesion on brain\nimaging'. To address these issues, we propose constructing extra labeled\ninstances using label-text (i.e. label's name) as input for the corresponding\nlabel-index (i.e. label's index). In fact, we propose a number of strategies\nfor manufacturing multiple artificial labeled instances from a single label.\nThe network is then fine-tuned on a combination of real and these newly\nconstructed artificial labeled instances. We evaluate the proposed approach on\nan important low-resource biomedical task called \\textit{PICO annotation},\nwhich requires tagging raw text describing clinical trials with labels\ncorresponding to different aspects of the trial i.e. PICO (Population,\nIntervention/Control, Outcome) characteristics of the trial. Our empirical\nresults show that the proposed method achieves a new state-of-the-art\nperformance for PICO annotation with very significant improvements over\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 10:19:53 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 15:10:16 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 22:29:49 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Singh", "Gaurav", ""], ["Sabet", "Zahra", ""], ["Shawe-Taylor", "John", ""], ["Thomas", "James", ""]]}, {"id": "1910.09260", "submitter": "Jingjing Wang", "authors": "Jingjing Wang, Changlong Sun, Shoushan Li, Jiancheng Wang, Luo Si, Min\n  Zhang, Xiaozhong Liu, Guodong Zhou", "title": "Human-Like Decision Making: Document-level Aspect Sentiment\n  Classification via Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have shown promising results on Document-level\nAspect Sentiment Classification (DASC). However, these approaches often offer\nlittle transparency w.r.t. their inner working mechanisms and lack\ninterpretability. In this paper, to simulating the steps of analyzing aspect\nsentiment in a document by human beings, we propose a new Hierarchical\nReinforcement Learning (HRL) approach to DASC. This approach incorporates\nclause selection and word selection strategies to tackle the data noise problem\nin the task of DASC. First, a high-level policy is proposed to select\naspect-relevant clauses and discard noisy clauses. Then, a low-level policy is\nproposed to select sentiment-relevant words and discard noisy words inside the\nselected clauses. Finally, a sentiment rating predictor is designed to provide\nreward signals to guide both clause and word selection. Experimental results\ndemonstrate the impressive effectiveness of the proposed approach to DASC over\nthe state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 10:55:46 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Wang", "Jingjing", ""], ["Sun", "Changlong", ""], ["Li", "Shoushan", ""], ["Wang", "Jiancheng", ""], ["Si", "Luo", ""], ["Zhang", "Min", ""], ["Liu", "Xiaozhong", ""], ["Zhou", "Guodong", ""]]}, {"id": "1910.09275", "submitter": "Won Ik Cho", "authors": "Won Ik Cho, Jeonghwa Cho, Woo Hyun Kang, Nam Soo Kim", "title": "Text Matters but Speech Influences: A Computational Analysis of\n  Syntactic Ambiguity Resolution", "comments": "CogSci 2020 Camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing how human beings resolve syntactic ambiguity has long been an issue\nof interest in the field of linguistics. It is, at the same time, one of the\nmost challenging issues for spoken language understanding (SLU) systems as\nwell. As syntactic ambiguity is intertwined with issues regarding prosody and\nsemantics, the computational approach toward speech intention identification is\nexpected to benefit from the observations of the human language processing\nmechanism. In this regard, we address the task with attentive recurrent neural\nnetworks that exploit acoustic and textual features simultaneously and reveal\nhow the modalities interact with each other to derive sentence meaning.\nUtilizing a speech corpus recorded on Korean scripts of syntactically ambiguous\nutterances, we revealed that co-attention frameworks, namely multi-hop\nattention and cross-attention, show significantly superior performance in\ndisambiguating speech intention. With further analysis, we demonstrate that the\ncomputational models reflect the internal relationship between auditory and\nlinguistic processes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 11:53:07 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 01:44:58 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 07:57:20 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Cho", "Won Ik", ""], ["Cho", "Jeonghwa", ""], ["Kang", "Woo Hyun", ""], ["Kim", "Nam Soo", ""]]}, {"id": "1910.09292", "submitter": "Shengluan Hou", "authors": "Ruqian Lu and Shengluan Hou", "title": "On Semi-Supervised Multiple Representation Behavior Learning", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel paradigm of semi-supervised learning (SSL)--the\nsemi-supervised multiple representation behavior learning (SSMRBL). SSMRBL aims\nto tackle the difficulty of learning a grammar for natural language parsing\nwhere the data are natural language texts and the 'labels' for marking data are\nparsing trees and/or grammar rule pieces. We call such 'labels' as compound\nstructured labels which require a hard work for training. SSMRBL is an\nincremental learning process that can learn more than one representation, which\nis an appropriate solution for dealing with the scarce of labeled training data\nin the age of big data and with the heavy workload of learning compound\nstructured labels. We also present a typical example of SSMRBL, regarding\nbehavior learning in form of a grammatical approach towards domain-based\nmultiple text summarization (DBMTS). DBMTS works under the framework of\nrhetorical structure theory (RST). SSMRBL includes two representations: text\nembedding (for representing information contained in the texts) and grammar\nmodel (for representing parsing as a behavior). The first representation was\nlearned as embedded digital vectors called impacts in a low dimensional space.\nThe grammar model was learned in an iterative way. Then an automatic\ndomain-oriented multi-text summarization approach was proposed based on the two\nrepresentations discussed above. Experimental results on large-scale Chinese\ndataset SogouCA indicate that the proposed method brings a good performance\neven if only few labeled texts are used for training with respect to our\ndefined automated metrics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:23:48 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Lu", "Ruqian", ""], ["Hou", "Shengluan", ""]]}, {"id": "1910.09295", "submitter": "Jan Christian Blaise Cruz", "authors": "Jan Christian Blaise Cruz, Julianne Agatha Tan and Charibeth Cheng", "title": "Localization of Fake News Detection via Multitask Transfer Learning", "comments": "Published in the LREC 2020 Proceedings. Models and data available at\n  https://github.com/jcblaisecruz02/Tagalog-fake-news", "journal-ref": "In Proceedings of The 12th Language Resources and Evaluation\n  Conference, pp.2589-2597 (2020)", "doi": "10.13140/RG.2.2.23028.40322", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of the internet as a fast medium of spreading fake news reinforces\nthe need for computational tools that combat it. Techniques that train fake\nnews classifiers exist, but they all assume an abundance of resources including\nlarge labeled datasets and expert-curated corpora, which low-resource languages\nmay not have. In this work, we make two main contributions: First, we alleviate\nresource scarcity by constructing the first expertly-curated benchmark dataset\nfor fake news detection in Filipino, which we call \"Fake News Filipino.\"\nSecond, we benchmark Transfer Learning (TL) techniques and show that they can\nbe used to train robust fake news classifiers from little data, achieving 91%\naccuracy on our fake news dataset, reducing the error by 14% compared to\nestablished few-shot baselines. Furthermore, lifting ideas from multitask\nlearning, we show that augmenting transformer-based transfer techniques with\nauxiliary language modeling losses improves their performance by adapting to\nwriting style. Using this, we improve TL performance by 4-6%, achieving an\naccuracy of 96% on our best model. Lastly, we show that our method generalizes\nwell to different types of news articles, including political news,\nentertainment news, and opinion articles.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:28:00 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 04:57:39 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 17:54:09 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Cruz", "Jan Christian Blaise", ""], ["Tan", "Julianne Agatha", ""], ["Cheng", "Charibeth", ""]]}, {"id": "1910.09302", "submitter": "Ohad Rozen", "authors": "Ohad Rozen, Vered Shwartz, Roee Aharoni, and Ido Dagan", "title": "Diversify Your Datasets: Analyzing Generalization via Controlled\n  Variance in Adversarial Datasets", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phenomenon-specific \"adversarial\" datasets have been recently designed to\nperform targeted stress-tests for particular inference types. Recent work (Liu\net al., 2019a) proposed that such datasets can be utilized for training NLI and\nother types of models, often allowing to learn the phenomenon in focus and\nimprove on the challenge dataset, indicating a \"blind spot\" in the original\ntraining data. Yet, although a model can improve in such a training process, it\nmight still be vulnerable to other challenge datasets targeting the same\nphenomenon but drawn from a different distribution, such as having a different\nsyntactic complexity level. In this work, we extend this method to drive\nconclusions about a model's ability to learn and generalize a target phenomenon\nrather than to \"learn\" a dataset, by controlling additional aspects in the\nadversarial datasets. We demonstrate our approach on two inference phenomena -\ndative alternation and numerical reasoning, elaborating, and in some cases\ncontradicting, the results of Liu et al.. Our methodology enables building\nbetter challenge datasets for creating more robust models, and may yield better\nmodel understanding and subsequent overarching improvements.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:34:53 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Rozen", "Ohad", ""], ["Shwartz", "Vered", ""], ["Aharoni", "Roee", ""], ["Dagan", "Ido", ""]]}, {"id": "1910.09329", "submitter": "Nikolaos Stylianou", "authors": "Nikolaos Stylianou, Ioannis Vlahavas", "title": "A Neural Entity Coreference Resolution Review", "comments": "52 pages, 8 figures, 4 tables, Published in Expert Systems with\n  Applications", "journal-ref": "Expert Systems with Applications, Volume 168, 15 April 2021,\n  114466", "doi": "10.1016/j.eswa.2020.114466", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Coreference Resolution is the task of resolving all mentions in a\ndocument that refer to the same real world entity and is considered as one of\nthe most difficult tasks in natural language understanding. It is of great\nimportance for downstream natural language processing tasks such as entity\nlinking, machine translation, summarization, chatbots, etc. This work aims to\ngive a detailed review of current progress on solving Coreference Resolution\nusing neural-based approaches. It also provides a detailed appraisal of the\ndatasets and evaluation metrics in the field, as well as the subtask of Pronoun\nResolution that has seen various improvements in the recent years. We highlight\nthe advantages and disadvantages of the approaches, the challenges of the task,\nthe lack of agreed-upon standards in the task and propose a way to further\nexpand the boundaries of the field.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:59:32 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 12:24:28 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Stylianou", "Nikolaos", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "1910.09342", "submitter": "Seanie Lee", "authors": "Seanie Lee, Donggyu Kim, Jangwon Park", "title": "Domain-agnostic Question-Answering with Adversarial Training", "comments": "EMNLP-IJCNLP 2019 MRQA Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adapting models to new domain without finetuning is a challenging problem in\ndeep learning. In this paper, we utilize an adversarial training framework for\ndomain generalization in Question Answering (QA) task. Our model consists of a\nconventional QA model and a discriminator. The training is performed in the\nadversarial manner, where the two models constantly compete, so that QA model\ncan learn domain-invariant features. We apply this approach in MRQA Shared Task\n2019 and show better performance compared to the baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:11:21 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 05:07:22 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Lee", "Seanie", ""], ["Kim", "Donggyu", ""], ["Park", "Jangwon", ""]]}, {"id": "1910.09362", "submitter": "Wenxiang Jiao", "authors": "Wenxiang Jiao, Irwin King, and Michael R. Lyu", "title": "Improving Word Representations: A Sub-sampled Unigram Distribution for\n  Negative Sampling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2Vec is the most popular model for word representation and has been\nwidely investigated in literature. However, its noise distribution for negative\nsampling is decided by empirical trials and the optimality has always been\nignored. We suggest that the distribution is a sub-optimal choice, and propose\nto use a sub-sampled unigram distribution for better negative sampling. Our\ncontributions include: (1) proposing the concept of semantics quantification\nand deriving a suitable sub-sampling rate for the proposed distribution\nadaptive to different training corpora; (2) demonstrating the advantages of our\napproach in both negative sampling and noise contrastive estimation by\nextensive evaluation tasks; and (3) proposing a semantics weighted model for\nthe MSR sentence completion task, resulting in considerable improvements. Our\nwork not only improves the quality of word vectors but also benefits current\nunderstanding of Word2Vec.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:34:12 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jiao", "Wenxiang", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1910.09387", "submitter": "Konstantinos Drossos", "authors": "Konstantinos Drossos and Samuel Lipping and Tuomas Virtanen", "title": "Clotho: An Audio Captioning Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio captioning is the novel task of general audio content description using\nfree text. It is an intermodal translation task (not speech-to-text), where a\nsystem accepts as an input an audio signal and outputs the textual description\n(i.e. the caption) of that signal. In this paper we present Clotho, a dataset\nfor audio captioning consisting of 4981 audio samples of 15 to 30 seconds\nduration and 24 905 captions of eight to 20 words length, and a baseline method\nto provide initial results. Clotho is built with focus on audio content and\ncaption diversity, and the splits of the data are not hampering the training or\nevaluation of methods. All sounds are from the Freesound platform, and captions\nare crowdsourced using Amazon Mechanical Turk and annotators from English\nspeaking countries. Unique words, named entities, and speech transcription are\nremoved with post-processing. Clotho is freely available online\n(https://zenodo.org/record/3490684).\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:06:01 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Drossos", "Konstantinos", ""], ["Lipping", "Samuel", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1910.09399", "submitter": "Haicheng Tao", "authors": "Jorge Agnese, Jonathan Herrera, Haicheng Tao, Xingquan Zhu", "title": "A Survey and Taxonomy of Adversarial Neural Networks for Text-to-Image\n  Synthesis", "comments": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery.\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-image synthesis refers to computational methods which translate human\nwritten textual descriptions, in the form of keywords or sentences, into images\nwith similar semantic meaning to the text. In earlier research, image synthesis\nrelied mainly on word to image correlation analysis combined with supervised\nmethods to find best alignment of the visual content matching to the text.\nRecent progress in deep learning (DL) has brought a new set of unsupervised\ndeep learning methods, particularly deep generative models which are able to\ngenerate realistic visual images using suitably trained neural network models.\nIn this paper, we review the most recent development in the text-to-image\nsynthesis research domain. Our survey first introduces image synthesis and its\nchallenges, and then reviews key concepts such as generative adversarial\nnetworks (GANs) and deep convolutional encoder-decoder neural networks (DCNN).\nAfter that, we propose a taxonomy to summarize GAN based text-to-image\nsynthesis into four major categories: Semantic Enhancement GANs, Resolution\nEnhancement GANs, Diversity Enhancement GANS, and Motion Enhancement GANs. We\nelaborate the main objective of each group, and further review typical GAN\narchitectures in each group. The taxonomy and the review outline the techniques\nand the evolution of different approaches, and eventually provide a clear\nroadmap to summarize the list of contemporaneous solutions that utilize GANs\nand DCNNs to generate enthralling results in categories such as human faces,\nbirds, flowers, room interiors, object reconstruction from edge maps (games)\netc. The survey will conclude with a comparison of the proposed solutions,\nchallenges that remain unresolved, and future developments in the text-to-image\nsynthesis domain.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 14:23:14 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Agnese", "Jorge", ""], ["Herrera", "Jonathan", ""], ["Tao", "Haicheng", ""], ["Zhu", "Xingquan", ""]]}, {"id": "1910.09451", "submitter": "Mathieu Seurin", "authors": "Geoffrey Cideron, Mathieu Seurin, Florian Strub, and Olivier Pietquin", "title": "HIGhER : Improving instruction following with Hindsight Generation for\n  Experience Replay", "comments": "Accepted at ADPRL'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language creates a compact representation of the world and allows the\ndescription of unlimited situations and objectives through compositionality.\nWhile these characterizations may foster instructing, conditioning or\nstructuring interactive agent behavior, it remains an open-problem to correctly\nrelate language understanding and reinforcement learning in even simple\ninstruction following scenarios. This joint learning problem is alleviated\nthrough expert demonstrations, auxiliary losses, or neural inductive biases. In\nthis paper, we propose an orthogonal approach called Hindsight Generation for\nExperience Replay (HIGhER) that extends the Hindsight Experience Replay (HER)\napproach to the language-conditioned policy setting. Whenever the agent does\nnot fulfill its instruction, HIGhER learns to output a new directive that\nmatches the agent trajectory, and it relabels the episode with a positive\nreward. To do so, HIGhER learns to map a state into an instruction by using\npast successful trajectories, which removes the need to have external expert\ninterventions to relabel episodes as in vanilla HER. We show the efficiency of\nour approach in the BabyAI environment, and demonstrate how it complements\nother instruction following methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 15:31:29 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 15:36:42 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 16:01:45 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cideron", "Geoffrey", ""], ["Seurin", "Mathieu", ""], ["Strub", "Florian", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1910.09513", "submitter": "Jakub Hara\\v{s}ta Ph.D", "authors": "Tereza Novotn\\'a and Jakub Hara\\v{s}ta", "title": "The Czech Court Decisions Corpus (CzCDC): Availability as the First Step", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the Czech Court Decision Corpus (CzCDC). CzCDC is\na dataset of 237,723 decisions published by the Czech apex (or top-tier)\ncourts, namely the Supreme Court, the Supreme Administrative Court and the\nConstitutional Court. All the decisions were published between 1st January 1993\nand 30th September 2018.\n  Court decisions are available on the webpages of the respective courts or via\ncommercial databases of legal information. This often leads researchers\ninterested in these decisions to reach either to respective court or to\ncommercial provider. This leads to delays and additional costs. These are\nfurther exacerbated by a lack of inter-court standard in the terms of the data\nformat in which courts provide their decisions. Additionally, courts' databases\noften lack proper documentation.\n  Our goal is to make the dataset of court decisions freely available online in\nconsistent (plain) format to lower the cost associated with obtaining data for\nfuture research. We believe that simplified access to court decisions through\nthe CzCDC could benefit other researchers.\n  In this paper, we describe the processing of decisions before their inclusion\ninto CzCDC and basic statistics of the dataset. This dataset contains plain\ntexts of court decisions and these texts are not annotated for any grammatical\nor syntactical features.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 17:06:38 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Novotn\u00e1", "Tereza", ""], ["Hara\u0161ta", "Jakub", ""]]}, {"id": "1910.09532", "submitter": "Mikul\\'a\\v{s} Zelinka", "authors": "Mikul\\'a\\v{s} Zelinka, Xingdi Yuan, Marc-Alexandre C\\^ot\\'e, Romain\n  Laroche, Adam Trischler", "title": "Building Dynamic Knowledge Graphs from Text-based Games", "comments": "NeurIPS 2019, Graph Representation Learning (GRL) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in learning how to update Knowledge Graphs (KG) from text.\nIn this preliminary work, we propose a novel Sequence-to-Sequence (Seq2Seq)\narchitecture to generate elementary KG operations. Furthermore, we introduce a\nnew dataset for KG extraction built upon text-based game transitions (over 300k\ndata points). We conduct experiments and discuss the results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 17:55:25 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 01:20:36 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 22:53:16 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zelinka", "Mikul\u00e1\u0161", ""], ["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Laroche", "Romain", ""], ["Trischler", "Adam", ""]]}, {"id": "1910.09563", "submitter": "Chenhao Tan", "authors": "Kumar Bhargav Srinivasan, Cristian Danescu-Niculescu-Mizil, Lillian\n  Lee, Chenhao Tan", "title": "Content Removal as a Moderation Strategy: Compliance and Other Outcomes\n  in the ChangeMyView Community", "comments": "21 pages, 8 figures, accepted at CSCW 2019, the dataset is available\n  at https://chenhaot.com/papers/content-removal.html", "journal-ref": null, "doi": "10.1145/3359265", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moderators of online communities often employ comment deletion as a tool. We\nask here whether, beyond the positive effects of shielding a community from\nundesirable content, does comment removal actually cause the behavior of the\ncomment's author to improve? We examine this question in a particularly\nwell-moderated community, the ChangeMyView subreddit.\n  The standard analytic approach of interrupted time-series analysis\nunfortunately cannot answer this question of causality because it fails to\ndistinguish the effect of having made a non-compliant comment from the effect\nof being subjected to moderator removal of that comment. We therefore leverage\na \"delayed feedback\" approach based on the observation that some users may\nremain active between the time when they posted the non-compliant comment and\nthe time when that comment is deleted. Applying this approach to such users, we\nreveal the causal role of comment deletion in reducing immediate noncompliance\nrates, although we do not find evidence of it having a causal role in inducing\nother behavior improvements. Our work thus empirically demonstrates both the\npromise and some potential limits of content removal as a positive moderation\nstrategy, and points to future directions for identifying causal effects from\nobservational data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:00:04 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Srinivasan", "Kumar Bhargav", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""], ["Lee", "Lillian", ""], ["Tan", "Chenhao", ""]]}, {"id": "1910.09621", "submitter": "Ting-Hao Huang", "authors": "Ting-Hao 'Kenneth' Huang", "title": "On Automating Conversations", "comments": "An invited position paper at the \"Artificial Intelligence and Work:\n  AAAI 2019 Fall Symposium\" (AAAI-FSS 2019), Washington, DC, November 7-9, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From 2016 to 2018, we developed and deployed Chorus, a system that blends\nreal-time human computation with artificial intelligence (AI) and has\nreal-world, open conversations with users. We took a top-down approach that\nstarted with a working crowd-powered system, Chorus, and then created a\nframework, Evorus, that enables Chorus to automate itself over time. Over our\ntwo-year deployment, more than 420 users talked with Chorus, having over 2,200\nconversation sessions. This line of work demonstrated how a crowd-powered\nconversational assistant can be automated over time, and more importantly, how\nsuch a system can be deployed to talk with real users to help them with their\neveryday tasks. This position paper discusses two sets of challenges that we\nexplored during the development and deployment of Chorus and Evorus: the\nchallenges that come from being an \"agent\" and those that arise from the subset\nof conversations that are more difficult to automate.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 19:29:06 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 17:59:09 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 20:51:33 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Huang", "Ting-Hao 'Kenneth'", ""]]}, {"id": "1910.09664", "submitter": "Valts Blukis", "authors": "Valts Blukis, Yannick Terme, Eyvind Niklasson, Ross A. Knepper, Yoav\n  Artzi", "title": "Learning to Map Natural Language Instructions to Physical Quadcopter\n  Control using Simulated Flight", "comments": "Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a joint simulation and real-world learning framework for mapping\nnavigation instructions and raw first-person observations to continuous\ncontrol. Our model estimates the need for environment exploration, predicts the\nlikelihood of visiting environment positions during execution, and controls the\nagent to both explore and visit high-likelihood positions. We introduce\nSupervised Reinforcement Asynchronous Learning (SuReAL). Learning uses both\nsimulation and real environments without requiring autonomous flight in the\nphysical environment during training, and combines supervised learning for\npredicting positions to visit and reinforcement learning for continuous\ncontrol. We evaluate our approach on a natural language instruction-following\ntask with a physical quadcopter, and demonstrate effective execution and\nexploration behavior.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 21:19:33 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Blukis", "Valts", ""], ["Terme", "Yannick", ""], ["Niklasson", "Eyvind", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "1910.09702", "submitter": "Tariq Alhindi", "authors": "Tariq Alhindi, Jonas Pfeiffer and Smaranda Muresan", "title": "Fine-Tuned Neural Models for Propaganda Detection at the Sentence and\n  Fragment levels", "comments": "Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda", "journal-ref": null, "doi": "10.18653/v1/D19-5013", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the CUNLP submission for the NLP4IF 2019 shared-task on\nFineGrained Propaganda Detection. Our system finished 5th out of 26 teams on\nthe sentence-level classification task and 5th out of 11 teams on the\nfragment-level classification task based on our scores on the blind test set.\nWe present our models, a discussion of our ablation studies and experiments,\nand an analysis of our performance on all eighteen propaganda techniques\npresent in the corpus of the shared task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:06:52 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Alhindi", "Tariq", ""], ["Pfeiffer", "Jonas", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1910.09703", "submitter": "Qiujia Li", "authors": "Qiujia Li, Florian L. Kreyssig, Chao Zhang, and Philip C. Woodland", "title": "Discriminative Neural Clustering for Speaker Diarisation", "comments": "Accepted as a conference paper at the 8th IEEE Spoken Language\n  Technology Workshop (SLT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Discriminative Neural Clustering (DNC) that\nformulates data clustering with a maximum number of clusters as a supervised\nsequence-to-sequence learning problem. Compared to traditional unsupervised\nclustering algorithms, DNC learns clustering patterns from training data\nwithout requiring an explicit definition of a similarity measure. An\nimplementation of DNC based on the Transformer architecture is shown to be\neffective on a speaker diarisation task using the challenging AMI dataset.\nSince AMI contains only 147 complete meetings as individual input sequences,\ndata scarcity is a significant issue for training a Transformer model for DNC.\nAccordingly, this paper proposes three data augmentation schemes: sub-sequence\nrandomisation, input vector randomisation, and Diaconis augmentation, which\ngenerates new data samples by rotating the entire input sequence of\nL2-normalised speaker embeddings. Experimental results on AMI show that DNC\nachieves a reduction in speaker error rate (SER) of 29.4% relative to spectral\nclustering.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 00:09:22 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 15:32:03 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Qiujia", ""], ["Kreyssig", "Florian L.", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1910.09729", "submitter": "Katharina Kann", "authors": "Katharina Kann", "title": "Grammatical Gender, Neo-Whorfianism, and Word Embeddings: A Data-Driven\n  Approach to Linguistic Relativity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relation between language and thought has occupied linguists for at least\na century. Neo-Whorfianism, a weak version of the controversial Sapir-Whorf\nhypothesis, holds that our thoughts are subtly influenced by the grammatical\nstructures of our native language. One area of investigation in this vein\nfocuses on how the grammatical gender of nouns affects the way we perceive the\ncorresponding objects. For instance, does the fact that key is masculine in\nGerman (der Schl\\\"ussel), but feminine in Spanish (la llave) change the\nspeakers' views of those objects? Psycholinguistic evidence presented by\nBoroditsky et al. (2003, {\\S}4) suggested the answer might be yes: When asked\nto produce adjectives that best described a key, German and Spanish speakers\nnamed more stereotypically masculine and feminine ones, respectively. However,\nrecent attempts to replicate those experiments have failed (Mickan et al.,\n2014). In this work, we offer a computational analogue of Boroditsky et al.\n(2003, {\\S}4)'s experimental design on 9 languages, finding evidence against\nneo-Whorfianism.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 02:16:47 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kann", "Katharina", ""]]}, {"id": "1910.09753", "submitter": "Adam Fisch", "authors": "Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo, Eunsol Choi, Danqi\n  Chen", "title": "MRQA 2019 Shared Task: Evaluating Generalization in Reading\n  Comprehension", "comments": "EMNLP 2019 Workshop on Machine Reading for Question Answering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results of the Machine Reading for Question Answering (MRQA)\n2019 shared task on evaluating the generalization capabilities of reading\ncomprehension systems. In this task, we adapted and unified 18 distinct\nquestion answering datasets into the same format. Among them, six datasets were\nmade available for training, six datasets were made available for development,\nand the final six were hidden for final evaluation. Ten teams submitted\nsystems, which explored various ideas including data sampling, multi-task\nlearning, adversarial training and ensembling. The best system achieved an\naverage F1 score of 72.5 on the 12 held-out datasets, 10.7 absolute points\nhigher than our initial baseline based on BERT.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 03:41:33 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 19:04:01 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Fisch", "Adam", ""], ["Talmor", "Alon", ""], ["Jia", "Robin", ""], ["Seo", "Minjoon", ""], ["Choi", "Eunsol", ""], ["Chen", "Danqi", ""]]}, {"id": "1910.09760", "submitter": "Weiguo Zheng", "authors": "Weiguo Zheng and Mei Zhang", "title": "Question Answering over Knowledge Graphs via Structural Query Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language question answering over knowledge graphs is an important and\ninteresting task as it enables common users to gain accurate answers in an easy\nand intuitive manner. However, it remains a challenge to bridge the gap between\nunstructured questions and structured knowledge graphs. To address the problem,\na natural discipline is building a structured query to represent the input\nquestion. Searching the structured query over the knowledge graph can produce\nanswers to the question. Distinct from the existing methods that are based on\nsemantic parsing or templates, we propose an effective approach powered by a\nnovel notion, structural query pattern, in this paper. Given an input question,\nwe first generate its query sketch that is compatible with the underlying\nstructure of the knowledge graph. Then, we complete the query graph by labeling\nthe nodes and edges under the guidance of the structural query pattern.\nFinally, answers can be retrieved by executing the constructed query graph over\nthe knowledge graph. Evaluations on three question answering benchmarks show\nthat our proposed approach outperforms state-of-the-art methods significantly.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 04:21:06 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 10:33:13 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zheng", "Weiguo", ""], ["Zhang", "Mei", ""]]}, {"id": "1910.09796", "submitter": "Zhenghao Liu PhD.", "authors": "Zhenghao Liu, Chenyan Xiong, Maosong Sun, Zhiyuan Liu", "title": "Fine-grained Fact Verification with Kernel Graph Attention Network", "comments": "Accepted to ACL 2020, 10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact Verification requires fine-grained natural language inference capability\nthat finds subtle clues to identify the syntactical and semantically correct\nbut not well-supported claims. This paper presents Kernel Graph Attention\nNetwork (KGAT), which conducts more fine-grained fact verification with\nkernel-based attentions. Given a claim and a set of potential evidence\nsentences that form an evidence graph, KGAT introduces node kernels, which\nbetter measure the importance of the evidence node, and edge kernels, which\nconduct fine-grained evidence propagation in the graph, into Graph Attention\nNetworks for more accurate fact verification. KGAT achieves a 70.38% FEVER\nscore and significantly outperforms existing fact verification models on FEVER,\na large-scale benchmark for fact verification. Our analyses illustrate that,\ncompared to dot-product attentions, the kernel-based attention concentrates\nmore on relevant evidence sentences and meaningful clues in the evidence graph,\nwhich is the main source of KGAT's effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 07:06:45 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 04:17:55 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 01:50:32 GMT"}, {"version": "v4", "created": "Sun, 20 Jun 2021 09:54:54 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Sun", "Maosong", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1910.09799", "submitter": "Yongqiang Wang", "authors": "Yongqiang Wang, Abdelrahman Mohamed, Duc Le, Chunxi Liu, Alex Xiao,\n  Jay Mahadeokar, Hongzhao Huang, Andros Tjandra, Xiaohui Zhang, Frank Zhang,\n  Christian Fuegen, Geoffrey Zweig, Michael L. Seltzer", "title": "Transformer-based Acoustic Modeling for Hybrid Speech Recognition", "comments": "to appear in ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054345", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate transformer-based acoustic models (AMs) for hybrid\nspeech recognition. Several modeling choices are discussed in this work,\nincluding various positional embedding methods and an iterated loss to enable\ntraining deep transformers. We also present a preliminary study of using\nlimited right context in transformer models, which makes it possible for\nstreaming applications. We demonstrate that on the widely used Librispeech\nbenchmark, our transformer-based AM outperforms the best published hybrid\nresult by 19% to 26% relative when the standard n-gram language model (LM) is\nused. Combined with neural network LM for rescoring, our proposed approach\nachieves state-of-the-art results on Librispeech. Our findings are also\nconfirmed on a much larger internal dataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 07:20:02 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 00:01:15 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Wang", "Yongqiang", ""], ["Mohamed", "Abdelrahman", ""], ["Le", "Duc", ""], ["Liu", "Chunxi", ""], ["Xiao", "Alex", ""], ["Mahadeokar", "Jay", ""], ["Huang", "Hongzhao", ""], ["Tjandra", "Andros", ""], ["Zhang", "Xiaohui", ""], ["Zhang", "Frank", ""], ["Fuegen", "Christian", ""], ["Zweig", "Geoffrey", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1910.09804", "submitter": "Efthymios Tzinis", "authors": "Efthymios Tzinis, Shrikant Venkataramani, Zhepei Wang, Cem Subakan and\n  Paris Smaragdis", "title": "Two-Step Sound Source Separation: Training on Learned Latent Targets", "comments": "Submitted to ICASSP 2020", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9054172", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a two-step training procedure for source separation\nvia a deep neural network. In the first step we learn a transform (and it's\ninverse) to a latent space where masking-based separation performance using\noracles is optimal. For the second step, we train a separation module that\noperates on the previously learned space. In order to do so, we also make use\nof a scale-invariant signal to distortion ratio (SI-SDR) loss function that\nworks in the latent space, and we prove that it lower-bounds the SI-SDR in the\ntime domain. We run various sound separation experiments that show how this\napproach can obtain better performance as compared to systems that learn the\ntransform and the separation module jointly. The proposed methodology is\ngeneral enough to be applicable to a large class of neural network end-to-end\nseparation systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 07:49:21 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 18:45:42 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Venkataramani", "Shrikant", ""], ["Wang", "Zhepei", ""], ["Subakan", "Cem", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1910.09879", "submitter": "Weiguo Zheng", "authors": "Weiguo Zheng and Mei Zhang", "title": "Towards Combinational Relation Linking over Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a natural language phrase, relation linking aims to find a relation\n(predicate or property) from the underlying knowledge graph to match the\nphrase. It is very useful in many applications, such as natural language\nquestion answering, personalized recommendation and text summarization.\nHowever, the previous relation linking algorithms usually produce a single\nrelation for the input phrase and pay little attention to a more general and\nchallenging problem, i.e., combinational relation linking that extracts a\nsubgraph pattern to match the compound phrase (e.g. mother-in-law). In this\npaper, we focus on the task of combinational relation linking over knowledge\ngraphs. To resolve the problem, we design a systematic method based on the\ndata-driven relation assembly technique, which is performed under the guidance\nof meta patterns. We also introduce external knowledge to enhance the system\nunderstanding ability. Finally, we conduct extensive experiments over the real\nknowledge graph to study the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 10:35:41 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 10:31:25 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zheng", "Weiguo", ""], ["Zhang", "Mei", ""]]}, {"id": "1910.09909", "submitter": "Mikolaj Kegler", "authors": "Pierre Beckmann, Mikolaj Kegler, Hugues Saltini, Milos Cernak", "title": "Speech-VGG: A deep feature extractor for speech processing", "comments": "Submitted to InterSpeech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in deep learning often rely on representation learning\nand knowledge transfer. In particular, readily available models pre-trained on\nlarge datasets are key for the efficient transfer of knowledge. They can be\napplied as feature extractors for data preprocessing, fine-tuned to perform a\nvariety of tasks, or used for computing feature losses in the training of deep\nlearning systems. While applications of transfer learning are common in the\nfields of computer vision and natural language processing, audio- and speech\nprocessing are surprisingly lacking readily available and transferable models.\nHere, we introduce speechVGG, a flexible, transferable feature extractor\ntailored for integration with deep learning frameworks for speech processing.\nOur transferable model adopts the classic VGG-16 architecture and is trained on\na spoken word classification task. We demonstrate the application of the\npre-trained model in four speech processing tasks, including speech\nenhancement, language identification, speech, noise and music classification,\nand speaker identification. Each time, we compare the performance of our\napproach to existing baselines. Our results confirm that the representation of\nnatural speech captured using speechVGG is transferable and generalizable\nacross various speech processing problems and datasets. Notably, relatively\nsimple applications of our pre-trained model are capable of achieving\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:58:59 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 15:09:22 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 10:59:48 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 14:43:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Beckmann", "Pierre", ""], ["Kegler", "Mikolaj", ""], ["Saltini", "Hugues", ""], ["Cernak", "Milos", ""]]}, {"id": "1910.09916", "submitter": "Johan Fernquist", "authors": "Nazar Akrami, Johan Fernquist, Tim Isbister, Lisa Kaati, and Bj\\\"orn\n  Pelzer", "title": "Automatic Extraction of Personality from Text: Challenges and\n  Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we examined the possibility to extract personality traits from\na text. We created an extensive dataset by having experts annotate personality\ntraits in a large number of texts from multiple online sources. From these\nannotated texts, we selected a sample and made further annotations ending up in\na large low-reliability dataset and a small high-reliability dataset. We then\nused the two datasets to train and test several machine learning models to\nextract personality from text, including a language model. Finally, we\nevaluated our best models in the wild, on datasets from different domains. Our\nresults show that the models based on the small high-reliability dataset\nperformed better (in terms of $\\textrm{R}^2$) than models based on large\nlow-reliability dataset. Also, language model based on small high-reliability\ndataset performed better than the random baseline. Finally, and more\nimportantly, the results showed our best model did not perform better than the\nrandom baseline when tested in the wild. Taken together, our results show that\ndetermining personality traits from a text remains a challenge and that no firm\nconclusions can be made on model performance before testing in the wild.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:16:00 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Akrami", "Nazar", ""], ["Fernquist", "Johan", ""], ["Isbister", "Tim", ""], ["Kaati", "Lisa", ""], ["Pelzer", "Bj\u00f6rn", ""]]}, {"id": "1910.09932", "submitter": "Wei Zou", "authors": "Dongwei Jiang, Xiaoning Lei, Wubo Li, Ne Luo, Yuxuan Hu, Wei Zou,\n  Xiangang Li", "title": "Improving Transformer-based Speech Recognition Using Unsupervised\n  Pre-training", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition technologies are gaining enormous popularity in various\nindustrial applications. However, building a good speech recognition system\nusually requires large amounts of transcribed data, which is expensive to\ncollect. To tackle this problem, an unsupervised pre-training method called\nMasked Predictive Coding is proposed, which can be applied for unsupervised\npre-training with Transformer based model. Experiments on HKUST show that using\nthe same training data, we can achieve CER 23.3%, exceeding the best end-to-end\nmodel by over 0.2% absolute CER. With more pre-training data, we can further\nreduce the CER to 21.0%, or a 11.8% relative CER reduction over baseline.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 12:47:29 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 16:02:44 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 13:54:23 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Dongwei", ""], ["Lei", "Xiaoning", ""], ["Li", "Wubo", ""], ["Luo", "Ne", ""], ["Hu", "Yuxuan", ""], ["Zou", "Wei", ""], ["Li", "Xiangang", ""]]}, {"id": "1910.09942", "submitter": "Vevake Balaraman", "authors": "Vevake Balaraman and Bernardo Magnini", "title": "Scalable Neural Dialogue State Tracking", "comments": "8 pages, 3 figures, Accepted at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dialogue State Tracker (DST) is a key component in a dialogue system aiming\nat estimating the beliefs of possible user goals at each dialogue turn. Most of\nthe current DST trackers make use of recurrent neural networks and are based on\ncomplex architectures that manage several aspects of a dialogue, including the\nuser utterance, the system actions, and the slot-value pairs defined in a\ndomain ontology. However, the complexity of such neural architectures incurs\ninto a considerable latency in the dialogue state prediction, which limits the\ndeployments of the models in real-world applications, particularly when task\nscalability (i.e. amount of slots) is a crucial factor. In this paper, we\npropose an innovative neural model for dialogue state tracking, named Global\nencoder and Slot-Attentive decoders (G-SAT), which can predict the dialogue\nstate with a very low latency time, while maintaining high-level performance.\nWe report experiments on three different languages (English, Italian, and\nGerman) of the WoZ2.0 dataset, and show that the proposed approach provides\ncompetitive advantages over state-of-art DST systems, both in terms of accuracy\nand in terms of time complexity for predictions, being over 15 times faster\nthan the other systems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:01:00 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Balaraman", "Vevake", ""], ["Magnini", "Bernardo", ""]]}, {"id": "1910.09982", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Alberto Barr\\'on-Cede\\~no, Preslav Nakov", "title": "Findings of the NLP4IF-2019 Shared Task on Fine-Grained Propaganda\n  Detection", "comments": "propaganda, disinformation, fake news. arXiv admin note: text overlap\n  with arXiv:1910.02517", "journal-ref": "NLP4IF@EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the shared task on Fine-Grained Propaganda Detection, which was\norganized as part of the NLP4IF workshop at EMNLP-IJCNLP 2019. There were two\nsubtasks. FLC is a fragment-level task that asks for the identification of\npropagandist text fragments in a news article and also for the prediction of\nthe specific propaganda technique used in each such fragment (18-way\nclassification task). SLC is a sentence-level binary classification task asking\nto detect the sentences that contain propaganda. A total of 12 teams submitted\nsystems for the FLC task, 25 teams did so for the SLC task, and 14 teams\neventually submitted a system description paper. For both subtasks, most\nsystems managed to beat the baseline by a sizable margin. The leaderboard and\nthe data from the competition are available at\nhttp://propaganda.qcri.org/nlp4if-shared-task/.\n", "versions": [{"version": "v1", "created": "Sun, 20 Oct 2019 10:53:18 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "1910.09991", "submitter": "Fabrizio De Fausti", "authors": "Fabrizio De Fausti, Francesco Pugliese and Diego Zardetto", "title": "Towards Automated Website Classification by Deep Learning", "comments": null, "journal-ref": "Rivista di Statistica Ufficiale, n. 3/2020, Istat, pag. 9-50, ISSN\n  1828-1982", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the interest in Big Data sources has been steadily growing\nwithin the Official Statistic community. The Italian National Institute of\nStatistics (Istat) is currently carrying out several Big Data pilot studies.\nOne of these studies, the ICT Big Data pilot, aims at exploiting massive\namounts of textual data automatically scraped from the websites of Italian\nenterprises in order to predict a set of target variables (e.g. e-commerce)\nthat are routinely observed by the traditional ICT Survey. In this paper, we\nshow that Deep Learning techniques can successfully address this problem.\nEssentially, we tackle a text classification task: an algorithm must learn to\ninfer whether an Italian enterprise performs e-commerce from the textual\ncontent of its website. To reach this goal, we developed a sophisticated\nprocessing pipeline and evaluated its performance through extensive\nexperiments. Our pipeline uses Convolutional Neural Networks and relies on Word\nEmbeddings to encode raw texts into grayscale images (i.e. normalized numeric\nmatrices). Web-scraped texts are huge and have very low signal to noise ratio:\nto overcome these issues, we adopted a framework known as False Positive\nReduction, which has seldom (if ever) been applied before to text\nclassification tasks. Several original contributions enable our processing\npipeline to reach good classification results. Empirical evidence shows that\nour proposal outperforms all the alternative Machine Learning solutions already\ntested in Istat for the same task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:07:17 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 23:07:25 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["De Fausti", "Fabrizio", ""], ["Pugliese", "Francesco", ""], ["Zardetto", "Diego", ""]]}, {"id": "1910.10032", "submitter": "Ryan Leary", "authors": "Hugo Braun, Justin Luitjens, Ryan Leary, Tim Kaldewey, Daniel Povey", "title": "GPU-Accelerated Viterbi Exact Lattice Decoder for Batched Online and\n  Offline Speech Recognition", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimized weighted finite-state transducer (WFST) decoder\ncapable of online streaming and offline batch processing of audio using\nGraphics Processing Units (GPUs). The decoder is efficient in memory\nutilization, input/output (I/O) bandwidth, and uses a novel Viterbi\nimplementation designed to maximize parallelism. The reduced memory footprint\nallows the decoder to process significantly larger graphs than previously\npossible, while optimizing I/O increases the number of simultaneous streams\nsupported. GPU preprocessing of lattice segments enables intermediate lattice\nresults to be returned to the requestor during streaming inference.\nCollectively, the proposed algorithm yields up to a 240x speedup over single\ncore CPU decoding, and up to 40x faster decoding than the current\nstate-of-the-art GPU decoder, while returning equivalent results. This decoder\ndesign enables deployment of production-grade ASR models on a large spectrum of\nsystems, ranging from large data center servers to low-power edge devices.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:08:49 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 04:55:02 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Braun", "Hugo", ""], ["Luitjens", "Justin", ""], ["Leary", "Ryan", ""], ["Kaldewey", "Tim", ""], ["Povey", "Daniel", ""]]}, {"id": "1910.10034", "submitter": "Matthew Walter", "authors": "Siddharth Patki, Ethan Fahnestock, Thomas M. Howard, Matthew R. Walter", "title": "Language-guided Semantic Mapping and Mobile Manipulation in Partially\n  Observable Environments", "comments": "To appear at 2019 Conference on Robot Learning (CoRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in data-driven models for grounded language understanding\nhave enabled robots to interpret increasingly complex instructions. Two\nfundamental limitations of these methods are that most require a full model of\nthe environment to be known a priori, and they attempt to reason over a world\nrepresentation that is flat and unnecessarily detailed, which limits\nscalability. Recent semantic mapping methods address partial observability by\nexploiting language as a sensor to infer a distribution over topological,\nmetric and semantic properties of the environment. However, maintaining a\ndistribution over highly detailed maps that can support grounding of diverse\ninstructions is computationally expensive and hinders real-time human-robot\ncollaboration. We propose a novel framework that learns to adapt perception\naccording to the task in order to maintain compact distributions over semantic\nmaps. Experiments with a mobile manipulator demonstrate more efficient\ninstruction following in a priori unknown environments.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:09:02 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Patki", "Siddharth", ""], ["Fahnestock", "Ethan", ""], ["Howard", "Thomas M.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1910.10037", "submitter": "Manish Munikar", "authors": "Pranjal Dhakal, Manish Munikar, Bikram Dahal", "title": "One-Shot Template Matching for Automatic Document Data Capture", "comments": "Accepted in International Conference on AI for Transforming Business\n  (AITB2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel one-shot template-matching algorithm to\nautomatically capture data from business documents with an aim to minimize\nmanual data entry. Given one annotated document, our algorithm can\nautomatically extract similar data from other documents having the same format.\nBased on a set of engineered visual and textual features, our method is\ninvariant to changes in position and value. Experiments on a dataset of 595\nreal invoices demonstrate 86.4% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:15:27 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Dhakal", "Pranjal", ""], ["Munikar", "Manish", ""], ["Dahal", "Bikram", ""]]}, {"id": "1910.10073", "submitter": "Maha Elbayad", "authors": "Maha Elbayad and Jiatao Gu and Edouard Grave and Michael Auli", "title": "Depth-Adaptive Transformer", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art sequence-to-sequence models for large scale tasks perform a\nfixed number of computations for each input sequence regardless of whether it\nis easy or hard to process. In this paper, we train Transformer models which\ncan make output predictions at different stages of the network and we\ninvestigate different ways to predict how much computation is required for a\nparticular sequence. Unlike dynamic computation in Universal Transformers,\nwhich applies the same set of layers iteratively, we apply different layers at\nevery step to adjust both the amount of computation as well as the model\ncapacity. On IWSLT German-English translation our approach matches the accuracy\nof a well tuned baseline Transformer while using less than a quarter of the\ndecoder layers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:15:58 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 18:32:39 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 17:26:49 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 20:49:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Elbayad", "Maha", ""], ["Gu", "Jiatao", ""], ["Grave", "Edouard", ""], ["Auli", "Michael", ""]]}, {"id": "1910.10082", "submitter": "Samuel Kim", "authors": "Samuel Kim, Namhee Kwon, Henry O'Connell", "title": "Toward estimating personal well-being using voice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating personal well-being draws increasing attention particularly from\nhealthcare and pharmaceutical industries. We propose an approach to estimate\npersonal well-being in terms of various measurements such as anxiety, sleep\nquality and mood using voice. With clinically validated questionnaires to score\nthose measurements in a self-assessed way, we extract salient features from\nvoice and train regression models with deep neural networks. Experiments with\nthe collected database of 219 subjects show promising results in predicting the\nwell-being related measurements; concordance correlation coefficients (CCC)\nbetween self-assessed scores and predicted scores are 0.41 for anxiety, 0.44\nfor sleep quality and 0.38 for mood.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 16:20:35 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Kim", "Samuel", ""], ["Kwon", "Namhee", ""], ["O'Connell", "Henry", ""]]}, {"id": "1910.10138", "submitter": "Elias Stengel-Eskin", "authors": "Elias Stengel-Eskin, Aaron Steven White, Sheng Zhang, Benjamin Van\n  Durme", "title": "Universal Decompositional Semantic Parsing", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a transductive model for parsing into Universal Decompositional\nSemantics (UDS) representations, which jointly learns to map natural language\nutterances into UDS graph structures and annotate the graph with\ndecompositional semantic attribute scores. We also introduce a strong pipeline\nmodel for parsing into the UDS graph structure, and show that our transductive\nparser performs comparably while additionally performing attribute prediction.\nBy analyzing the attribute prediction errors, we find the model captures\nnatural relationships between attribute groups.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 17:41:48 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 21:04:28 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 14:03:14 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Stengel-Eskin", "Elias", ""], ["White", "Aaron Steven", ""], ["Zhang", "Sheng", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1910.10238", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi and Robert Enyedi and Alessandra Brusadin and\n  Marcello Federico", "title": "Robust Neural Machine Translation for Clean and Noisy Speech Transcripts", "comments": "6 pages, accepted at IWSLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation models have shown to achieve high quality when\ntrained and fed with well structured and punctuated input texts. Unfortunately,\nthe latter condition is not met in spoken language translation, where the input\nis generated by an automatic speech recognition (ASR) system. In this paper, we\nstudy how to adapt a strong NMT system to make it robust to typical ASR errors.\nAs in our application scenarios transcripts might be post-edited by human\nexperts, we propose adaptation strategies to train a single system that can\ntranslate either clean or noisy input with no supervision on the input type.\nOur experimental results on a public speech translation data set show that\nadapting a model on a significant amount of parallel data including ASR\ntranscripts is beneficial with test data of the same type, but produces a small\ndegradation when translating clean text. Adapting on both clean and noisy\nvariants of the same data leads to the best results on both input types.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:24:24 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Enyedi", "Robert", ""], ["Brusadin", "Alessandra", ""], ["Federico", "Marcello", ""]]}, {"id": "1910.10274", "submitter": "Darsh Shah", "authors": "Luu Anh Tuan, Darsh J Shah, Regina Barzilay", "title": "Capturing Greater Context for Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation can benefit many applications ranging from\ndialogue systems to reading comprehension. While questions are often asked with\nrespect to long documents, there are many challenges with modeling such long\ndocuments. Many existing techniques generate questions by effectively looking\nat one sentence at a time, leading to questions that are easy and not\nreflective of the human process of question generation. Our goal is to\nincorporate interactions across multiple sentences to generate realistic\nquestions for long documents. In order to link a broad document context to the\ntarget answer, we represent the relevant context via a multi-stage attention\nmechanism, which forms the foundation of a sequence to sequence model. We\noutperform state-of-the-art methods on question generation on three\nquestion-answering datasets -- SQuAD, MS MARCO and NewsQA.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 23:19:04 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Tuan", "Luu Anh", ""], ["Shah", "Darsh J", ""], ["Barzilay", "Regina", ""]]}, {"id": "1910.10281", "submitter": "Kurt Espinosa", "authors": "Kurt Espinosa, Makoto Miwa, Sophia Ananiadou", "title": "A Search-based Neural Model for Biomedical Nested and Overlapping Event\n  Detection", "comments": "Accepted at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We tackle the nested and overlapping event detection task and propose a novel\nsearch-based neural network (SBNN) structured prediction model that treats the\ntask as a search problem on a relation graph of trigger-argument structures.\nUnlike existing structured prediction tasks such as dependency parsing, the\ntask targets to detect DAG structures, which constitute events, from the\nrelation graph. We define actions to construct events and use all the beams in\na beam search to detect all event structures that may be overlapping and\nnested. The search process constructs events in a bottom-up manner while\nmodelling the global properties for nested and overlapping structures\nsimultaneously using neural networks. We show that the model achieves\nperformance comparable to the state-of-the-art model Turku Event Extraction\nSystem (TEES) on the BioNLP Cancer Genetics (CG) Shared Task 2013 without the\nuse of any syntactic and hand-engineered features. Further analyses on the\ndevelopment set show that our model is more computationally efficient while\nyielding higher F1-score performance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 23:41:53 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 00:51:29 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Espinosa", "Kurt", ""], ["Miwa", "Makoto", ""], ["Ananiadou", "Sophia", ""]]}, {"id": "1910.10287", "submitter": "Panayiotis Georgiou", "authors": "Prashanth Gurunath Shivakumar, Naveen Kumar, Panayiotis Georgiou,\n  Shrikanth Narayanan", "title": "RNN based Incremental Online Spoken Language Understanding", "comments": "Accepted for publication at IEEE Spoken Language Technology Workshop\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) typically comprises of an automatic\nspeech recognition (ASR) followed by a natural language understanding (NLU)\nmodule. The two modules process signals in a blocking sequential fashion, i.e.,\nthe NLU often has to wait for the ASR to finish processing on an utterance\nbasis, potentially leading to high latencies that render the spoken interaction\nless natural. In this paper, we propose recurrent neural network (RNN) based\nincremental processing towards the SLU task of intent detection. The proposed\nmethodology offers lower latencies than a typical SLU system, without any\nsignificant reduction in system accuracy. We introduce and analyze different\nrecurrent neural network architectures for incremental and online processing of\nthe ASR transcripts and compare it to the existing offline systems. A lexical\nEnd-of-Sentence (EOS) detector is proposed for segmenting the stream of\ntranscript into sentences for intent classification. Intent detection\nexperiments are conducted on benchmark ATIS, Snips and Facebook's multilingual\ntask oriented dialog datasets modified to emulate a continuous incremental\nstream of words with no utterance demarcation. We also analyze the prospects of\nearly intent detection, before EOS, with our proposed system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 00:17:26 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 18:27:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shivakumar", "Prashanth Gurunath", ""], ["Kumar", "Naveen", ""], ["Georgiou", "Panayiotis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1910.10288", "submitter": "Eric Battenberg", "authors": "Eric Battenberg, RJ Skerry-Ryan, Soroosh Mariooryad, Daisy Stanton,\n  David Kao, Matt Shannon, Tom Bagby", "title": "Location-Relative Attention Mechanisms For Robust Long-Form Speech\n  Synthesis", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ability to produce human-level speech for in-domain text,\nattention-based end-to-end text-to-speech (TTS) systems suffer from text\nalignment failures that increase in frequency for out-of-domain text. We show\nthat these failures can be addressed using simple location-relative attention\nmechanisms that do away with content-based query/key comparisons. We compare\ntwo families of attention mechanisms: location-relative GMM-based mechanisms\nand additive energy-based mechanisms. We suggest simple modifications to\nGMM-based attention that allow it to align quickly and consistently during\ntraining, and introduce a new location-relative attention mechanism to the\nadditive energy-based family, called Dynamic Convolution Attention (DCA). We\ncompare the various mechanisms in terms of alignment speed and consistency\nduring training, naturalness, and ability to generalize to long utterances, and\nconclude that GMM attention and DCA can generalize to very long utterances,\nwhile preserving naturalness for shorter, in-domain utterances.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 00:21:33 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 23:08:58 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Battenberg", "Eric", ""], ["Skerry-Ryan", "RJ", ""], ["Mariooryad", "Soroosh", ""], ["Stanton", "Daisy", ""], ["Kao", "David", ""], ["Shannon", "Matt", ""], ["Bagby", "Tom", ""]]}, {"id": "1910.10294", "submitter": "Mohit Rajpal", "authors": "Mohit Rajpal and Bryan Kian Hsiang Low", "title": "A Unifying Framework of Bilinear LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel unifying framework of bilinear LSTMs that can\nrepresent and utilize the nonlinear interaction of the input features present\nin sequence datasets for achieving superior performance over a linear LSTM and\nyet not incur more parameters to be learned. To realize this, our unifying\nframework allows the expressivity of the linear vs. bilinear terms to be\nbalanced by correspondingly trading off between the hidden state vector size\nvs. approximation quality of the weight matrix in the bilinear term so as to\noptimize the performance of our bilinear LSTM, while not incurring more\nparameters to be learned. We empirically evaluate the performance of our\nbilinear LSTM in several language-based sequence learning tasks to demonstrate\nits general applicability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 00:50:29 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Rajpal", "Mohit", ""], ["Low", "Bryan Kian Hsiang", ""]]}, {"id": "1910.10324", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Chunxi Liu, Frank Zhang, Xiaohui Zhang, Yongqiang\n  Wang, Gabriel Synnaeve, Satoshi Nakamura, Geoffrey Zweig", "title": "Deja-vu: Double Feature Presentation and Iterated Loss in Deep\n  Transformer Networks", "comments": "Accepted in IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep acoustic models typically receive features in the first layer of the\nnetwork, and process increasingly abstract representations in the subsequent\nlayers. Here, we propose to feed the input features at multiple depths in the\nacoustic model. As our motivation is to allow acoustic models to re-examine\ntheir input features in light of partial hypotheses we introduce intermediate\nmodel heads and loss function. We study this architecture in the context of\ndeep Transformer networks, and we use an attention mechanism over both the\nprevious layer activations and the input features. To train this model's\nintermediate output hypothesis, we apply the objective function at each layer\nright before feature re-use. We find that the use of such iterated loss\nsignificantly improves performance by itself, as well as enabling input feature\nre-use. We present results on both Librispeech, and a large scale video\ndataset, with relative improvements of 10 - 20% for Librispeech and 3.2 - 13%\nfor videos.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:48:30 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 06:07:18 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tjandra", "Andros", ""], ["Liu", "Chunxi", ""], ["Zhang", "Frank", ""], ["Zhang", "Xiaohui", ""], ["Wang", "Yongqiang", ""], ["Synnaeve", "Gabriel", ""], ["Nakamura", "Satoshi", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "1910.10352", "submitter": "Liang Lu", "authors": "Liang Lu", "title": "A Transformer with Interleaved Self-attention and Convolution for Hybrid\n  Acoustic Models", "comments": "5 pages, submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer with self-attention has achieved great success in the area of\nnature language processing. Recently, there have been a few studies on\ntransformer for end-to-end speech recognition, while its application for hybrid\nacoustic model is still very limited. In this paper, we revisit the\ntransformer-based hybrid acoustic model, and propose a model structure with\ninterleaved self-attention and 1D convolution, which is proven to have faster\nconvergence and higher recognition accuracy. We also study several aspects of\nthe transformer model, including the impact of the positional encoding feature,\ndropout regularization, as well as training with and without time restriction.\nWe show competitive recognition results on the public Librispeech dataset when\ncompared to the Kaldi baseline at both cross entropy training and sequence\ntraining stages. For reproducible research, we release our source code and\nrecipe within the PyKaldi2 toolbox.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 04:57:51 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Lu", "Liang", ""]]}, {"id": "1910.10363", "submitter": "Yan Gao", "authors": "Yan Gao, Jian-Guang Lou, Dongmei Zhang", "title": "A Hybrid Semantic Parsing Approach for Tabular Data Analysis", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to translating natural language\nquestions to SQL queries for given tables, which meets three requirements as a\nreal-world data analysis application: cross-domain, multilingualism and\nenabling quick-start. Our proposed approach consists of: (1) a novel data\nabstraction step before the parser to make parsing table-agnosticism; (2) a set\nof semantic rules for parsing abstracted data-analysis questions to\nintermediate logic forms as tree derivations to reduce the search space; (3) a\nneural-based model as a local scoring function on a span-based semantic parser\nfor structured optimization and efficient inference. Experiments show that our\napproach outperforms state-of-the-art algorithms on a large open benchmark\ndataset WikiSQL. We also achieve promising results on a small dataset for more\ncomplex queries in both English and Chinese, which demonstrates our language\nexpansion and quick-start ability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:41:39 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 05:05:39 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Gao", "Yan", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Dongmei", ""]]}, {"id": "1910.10387", "submitter": "Guangsen Wang", "authors": "Xingchen Song, Guangsen Wang, Zhiyong Wu, Yiheng Huang, Dan Su, Dong\n  Yu, Helen Meng", "title": "Speech-XLNet: Unsupervised Acoustic Model Pretraining For Self-Attention\n  Networks", "comments": "\\c{opyright} 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention network (SAN) can benefit significantly from the\nbi-directional representation learning through unsupervised pretraining\nparadigms such as BERT and XLNet. In this paper, we present an XLNet-like\npretraining scheme \"Speech-XLNet\" for unsupervised acoustic model pretraining\nto learn speech representations with SAN. The pretrained SAN is finetuned under\nthe hybrid SAN/HMM framework. We conjecture that by shuffling the speech frame\norders, the permutation in Speech-XLNet serves as a strong regularizer to\nencourage the SAN to make inferences by focusing on global structures through\nits attention weights. In addition, Speech-XLNet also allows the model to\nexplore the bi-directional contexts for effective speech representation\nlearning. Experiments on TIMIT and WSJ demonstrate that Speech-XLNet greatly\nimproves the SAN/HMM performance in terms of both convergence speed and\nrecognition accuracy compared to the one trained from randomly initialized\nweights. Our best systems achieve a relative improvement of 11.9% and 8.3% on\nthe TIMIT and WSJ tasks respectively. In particular, the best system achieves a\nphone error rate (PER) of 13.3% on the TIMIT test set, which to our best\nknowledge, is the lowest PER obtained from a single system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 07:08:03 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 10:09:50 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Song", "Xingchen", ""], ["Wang", "Guangsen", ""], ["Wu", "Zhiyong", ""], ["Huang", "Yiheng", ""], ["Su", "Dan", ""], ["Yu", "Dong", ""], ["Meng", "Helen", ""]]}, {"id": "1910.10408", "submitter": "Surafel Melaku Lakew Mr.", "authors": "Surafel Melaku Lakew, Mattia Di Gangi, Marcello Federico", "title": "Controlling the Output Length of Neural Machine Translation", "comments": "To appear at the 16th International Workshop on Spoken Language\n  Translation (IWSLT), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent advances introduced by neural machine translation (NMT) are\nrapidly expanding the application fields of machine translation, as well as\nreshaping the quality level to be targeted. In particular, if translations have\nto fit some given layout, quality should not only be measured in terms of\nadequacy and fluency, but also length. Exemplary cases are the translation of\ndocument files, subtitles, and scripts for dubbing, where the output length\nshould ideally be as close as possible to the length of the input text. This\npaper addresses for the first time, to the best of our knowledge, the problem\nof controlling the output length in NMT. We investigate two methods for biasing\nthe output length with a transformer architecture: i) conditioning the output\nto a given target-source length-ratio class and ii) enriching the transformer\npositional embedding with length information. Our experiments show that both\nmethods can induce the network to generate shorter translations, as well as\nacquiring interpretable linguistic skills.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 08:25:43 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:01:42 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lakew", "Surafel Melaku", ""], ["Di Gangi", "Mattia", ""], ["Federico", "Marcello", ""]]}, {"id": "1910.10479", "submitter": "Yong-Siang Shih", "authors": "Yong-Siang Shih, Wei-Cheng Chang, Yiming Yang", "title": "XL-Editor: Post-editing Sentences with XLNet", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural sequence generation models achieve initial success for many NLP\napplications, the canonical decoding procedure with left-to-right generation\norder (i.e., autoregressive) in one-pass can not reflect the true nature of\nhuman revising a sentence to obtain a refined result. In this work, we propose\nXL-Editor, a novel training framework that enables state-of-the-art generalized\nautoregressive pretraining methods, XLNet specifically, to revise a given\nsentence by the variable-length insertion probability. Concretely, XL-Editor\ncan (1) estimate the probability of inserting a variable-length sequence into a\nspecific position of a given sentence; (2) execute post-editing operations such\nas insertion, deletion, and replacement based on the estimated variable-length\ninsertion probability; (3) complement existing sequence-to-sequence models to\nrefine the generated sequences. Empirically, we first demonstrate better\npost-editing capabilities of XL-Editor over XLNet on the text insertion and\ndeletion tasks, which validates the effectiveness of our proposed framework.\nFurthermore, we extend XL-Editor to the unpaired text style transfer task,\nwhere transferring the target style onto a given sentence can be naturally\nviewed as post-editing the sentence into the target style. XL-Editor achieves\nsignificant improvement in style transfer accuracy and also maintains coherent\nsemantic of the original sentence, showing the broad applicability of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 21:39:03 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Shih", "Yong-Siang", ""], ["Chang", "Wei-Cheng", ""], ["Yang", "Yiming", ""]]}, {"id": "1910.10485", "submitter": "Gabriele Prato", "authors": "Gabriele Prato, Ella Charlaix, Mehdi Rezagholizadeh", "title": "Fully Quantized Transformer for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural machine translation methods employ massive amounts of\nparameters. Drastically reducing computational costs of such methods without\naffecting performance has been up to this point unsuccessful. To this end, we\npropose FullyQT: an all-inclusive quantization strategy for the Transformer. To\nthe best of our knowledge, we are the first to show that it is possible to\navoid any loss in translation quality with a fully quantized Transformer.\nIndeed, compared to full-precision, our 8-bit models score greater or equal\nBLEU on most tasks. Comparing ourselves to all previously proposed methods, we\nachieve state-of-the-art quantization results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 01:29:12 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 22:44:17 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 19:06:55 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Prato", "Gabriele", ""], ["Charlaix", "Ella", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1910.10486", "submitter": "Haochen Liu", "authors": "Haochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao Liu and Jiliang\n  Tang", "title": "Does Gender Matter? Towards Fairness in Dialogue Systems", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there are increasing concerns about the fairness of Artificial\nIntelligence (AI) in real-world applications such as computer vision and\nrecommendations. For example, recognition algorithms in computer vision are\nunfair to black people such as poorly detecting their faces and inappropriately\nidentifying them as \"gorillas\". As one crucial application of AI, dialogue\nsystems have been extensively applied in our society. They are usually built\nwith real human conversational data; thus they could inherit some fairness\nissues which are held in the real world. However, the fairness of dialogue\nsystems has not been well investigated. In this paper, we perform a pioneering\nstudy about the fairness issues in dialogue systems. In particular, we\nconstruct a benchmark dataset and propose quantitative measures to understand\nfairness in dialogue models. Our studies demonstrate that popular dialogue\nmodels show significant prejudice towards different genders and races. Besides,\nto mitigate the bias in dialogue systems, we propose two simple but effective\ndebiasing methods. Experiments show that our methods can reduce the bias in\ndialogue systems significantly. The dataset and the implementation are released\nto foster fairness research in dialogue systems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 22:17:02 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:12:39 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 19:04:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Haochen", ""], ["Dacon", "Jamell", ""], ["Fan", "Wenqi", ""], ["Liu", "Hui", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1910.10487", "submitter": "David Donahue", "authors": "David Donahue, Yuanliang Meng, Anna Rumshisky", "title": "Memory-Augmented Recurrent Networks for Dialogue Coherence", "comments": "Honors project, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent dialogue approaches operate by reading each word in a conversation\nhistory, and aggregating accrued dialogue information into a single state. This\nfixed-size vector is not expandable and must maintain a consistent format over\ntime. Other recent approaches exploit an attention mechanism to extract useful\ninformation from past conversational utterances, but this introduces an\nincreased computational complexity. In this work, we explore the use of the\nNeural Turing Machine (NTM) to provide a more permanent and flexible storage\nmechanism for maintaining dialogue coherence. Specifically, we introduce two\nseparate dialogue architectures based on this NTM design. The first design\nfeatures a sequence-to-sequence architecture with two separate NTM modules, one\nfor each participant in the conversation. The second memory architecture\nincorporates a single NTM module, which stores parallel context information for\nboth speakers. This second design also replaces the sequence-to-sequence\narchitecture with a neural language model, to allow for longer context of the\nNTM and greater understanding of the dialogue history. We report perplexity\nperformance for both models, and compare them to existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:59:33 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Donahue", "David", ""], ["Meng", "Yuanliang", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1910.10488", "submitter": "David Donahue", "authors": "David Donahue, Vladislav Lialin, Anna Rumshisky", "title": "Injecting Hierarchy with U-Net Transformers", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer architecture has become increasingly popular over the past\ntwo years, owing to its impressive performance on a number of natural language\nprocessing (NLP) tasks. However, all Transformer computations occur at the\nlevel of word representations and therefore, it may be argued that Transformer\nmodels do not explicitly attempt to learn hierarchical structure which is\nwidely assumed to be integral to language. In the present work, we introduce\nhierarchical processing into the Transformer model, taking inspiration from the\nU-Net architecture, popular in computer vision for its hierarchical view of\nnatural images. We empirically demonstrate that the proposed architecture\noutperforms both the vanilla Transformer and some strong baselines in the\ndomain of chit-chat dialogue.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:48:46 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 19:41:09 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Donahue", "David", ""], ["Lialin", "Vladislav", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1910.10490", "submitter": "Janyl Jumadinova", "authors": "Xingbang Liu and Janyl Jumadinova", "title": "Automated Text Summarization for the Enhancement of Public Services", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural language processing and machine learning algorithms have been shown\nto be effective in a variety of applications. In this work, we contribute to\nthe area of AI adoption in the public sector. We present an automated system\nthat was used to process textual information, generate important keywords, and\nautomatically summarize key elements of the Meadville community statements. We\nalso describe the process of collaboration with My Meadville administrators\nduring the development of our system. My Meadville, a community initiative,\nsupported by the city of Meadville conducted a large number of interviews with\nthe residents of Meadville during the community events and transcribed these\ninterviews into textual data files. Their goal was to uncover the issues of\nimportance to the Meadville residents in an attempt to enhance public services.\nOur AI system cleans and pre-processes the interview data, then using machine\nlearning algorithms it finds important keywords and key excerpts from each\ninterview. It also provides searching functionality to find excerpts from\nrelevant interviews based on specific keywords. Our automated system allowed\nthe city to save over 300 hours of human labor that would have taken to read\nall interviews and highlight important points. Our findings are being used by\nMy Meadville initiative to locate important information from the collected data\nset for ongoing community enhancement projects, to highlight relevant community\nassets, and to assist in identifying the steps to be taken based on the\nconcerns and areas of improvement identified by the community members.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 13:55:02 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Liu", "Xingbang", ""], ["Jumadinova", "Janyl", ""]]}, {"id": "1910.10491", "submitter": "Rajhersh Patel", "authors": "Raj Patel, Carlotta Domeniconi", "title": "Estimator Vectors: OOV Word Embeddings based on Subword and Context Clue\n  Estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic representations of words have been successfully extracted from\nunlabeled corpuses using neural network models like word2vec. These\nrepresentations are generally high quality and are computationally inexpensive\nto train, making them popular. However, these approaches generally fail to\napproximate out of vocabulary (OOV) words, a task humans can do quite easily,\nusing word roots and context clues. This paper proposes a neural network model\nthat learns high quality word representations, subword representations, and\ncontext clue representations jointly. Learning all three types of\nrepresentations together enhances the learning of each, leading to enriched\nword vectors, along with strong estimates for OOV words, via the combination of\nthe corresponding context clue and subword embeddings. Our model, called\nEstimator Vectors (EV), learns strong word embeddings and is competitive with\nstate of the art methods for OOV estimation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 06:17:07 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Patel", "Raj", ""], ["Domeniconi", "Carlotta", ""]]}, {"id": "1910.10492", "submitter": "Haozheng Luo", "authors": "Haozheng Luo, Ningwei Liu, Charles Feng", "title": "Question Classification with Deep Contextualized Transformer", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-73103-8_32", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest work for Question and Answer problems is to use the Stanford Parse\nTree. We build on prior work and develop a new method to handle the Question\nand Answer problem with the Deep Contextualized Transformer to manage some\naberrant expressions. We also conduct extensive evaluations of the SQuAD and\nSwDA dataset and show significant improvement over QA problem classification of\nindustry needs. We also investigate the impact of different models for the\naccuracy and efficiency of the problem answers. It shows that our new method is\nmore effective for solving QA problems with higher accuracy\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 23:00:22 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 17:15:23 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Luo", "Haozheng", ""], ["Liu", "Ningwei", ""], ["Feng", "Charles", ""]]}, {"id": "1910.10495", "submitter": "Junhua Liu", "authors": "Junhua Liu, Yung Chuen Ng, Kristin L. Wood, Kwan Hui Lim", "title": "IPOD: An Industrial and Professional Occupations Dataset and its\n  Applications to Occupational Data Mining and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Occupational data mining and analysis is an important task in understanding\ntoday's industry and job market. Various machine learning techniques are\nproposed and gradually deployed to improve companies' operations for upstream\ntasks, such as employee churn prediction, career trajectory modelling and\nautomated interview. Job titles analysis and embedding, as the fundamental\nbuilding blocks, are crucial upstream tasks to address these occupational data\nmining and analysis problems. In this work, we present the Industrial and\nProfessional Occupations Dataset (IPOD), which consists of over 190,000 job\ntitles crawled from over 56,000 profiles from Linkedin. We also illustrate the\nusefulness of IPOD by addressing two challenging upstream tasks, including: (i)\nproposing Title2vec, a contextual job title vector representation using a\nbidirectional Language Model (biLM) approach; and (ii) addressing the important\noccupational Named Entity Recognition problem using Conditional Random Fields\n(CRF) and bidirectional Long Short-Term Memory with CRF (LSTM-CRF). Both CRF\nand LSTM-CRF outperform human and baselines in both exact-match accuracy and F1\nscores. The dataset and pre-trained embeddings are available at\nhttps://www.github.com/junhua/ipod.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 08:30:26 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 16:50:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Junhua", ""], ["Ng", "Yung Chuen", ""], ["Wood", "Kristin L.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "1910.10502", "submitter": "Maaike De Boer", "authors": "Hella Haanstra and Maaike H. T. de Boer", "title": "Opinion aspect extraction in Dutch childrens diary entries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect extraction can be used in dialogue systems to understand the topic of\nopinionated text. Expressing an empathetic reaction to an opinion can\nstrengthen the bond between a human and, for example, a robot. The aim of this\nstudy is three-fold: 1. create a new annotated dataset for both aspect\nextraction and opinion words for Dutch childrens language, 2. acquire aspect\nextraction results for this task and 3. improve current results for aspect\nextraction in Dutch reviews. This was done by training a deep learning Gated\nRecurrent Unit (GRU) model, originally developed for an English review dataset,\non Dutch restaurant review data to classify both opinion words and their\nrespective aspects. We obtained state-of-the-art performance on the Dutch\nrestaurant review dataset. Additionally, we acquired aspect extraction results\nfor the Dutch childrens dataset. Since the model was trained on standardised\nlanguage, these results are quite promising.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 09:33:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Haanstra", "Hella", ""], ["de Boer", "Maaike H. T.", ""]]}, {"id": "1910.10605", "submitter": "Ondrej Klejch", "authors": "Ond\\v{r}ej Klejch, Joachim Fainberg, Peter Bell, Steve Renals", "title": "Speaker Adaptive Training using Model Agnostic Meta-Learning", "comments": "Accepted to IEEE ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker adaptive training (SAT) of neural network acoustic models learns\nmodels in a way that makes them more suitable for adaptation to test\nconditions. Conventionally, model-based speaker adaptive training is performed\nby having a set of speaker dependent parameters that are jointly optimised with\nspeaker independent parameters in order to remove speaker variation. However,\nthis does not scale well if all neural network weights are to be adapted to the\nspeaker. In this paper we formulate speaker adaptive training as a\nmeta-learning task, in which an adaptation process using gradient descent is\nencoded directly into the training of the model. We compare our approach with\ntest-only adaptation of a standard baseline model and a SAT-LHUC model with a\nlearned speaker adaptation schedule and demonstrate that the meta-learning\napproach achieves comparable results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:22:22 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Klejch", "Ond\u0159ej", ""], ["Fainberg", "Joachim", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1910.10663", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi and Viet-Nhat Nguyen and Matteo Negri and\n  Marco Turchi", "title": "Instance-Based Model Adaptation For Direct Speech Translation", "comments": "6 pages, under review at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent technology advancements, the effectiveness of neural\napproaches to end-to-end speech-to-text translation is still limited by the\npaucity of publicly available training corpora. We tackle this limitation with\na method to improve data exploitation and boost the system's performance at\ninference time. Our approach allows us to customize \"on the fly\" an existing\nmodel to each incoming translation request. At its core, it exploits an\ninstance selection procedure to retrieve, from a given pool of data, a small\nset of samples similar to the input query in terms of latent properties of its\naudio signal. The retrieved samples are then used for an instance-specific\nfine-tuning of the model. We evaluate our approach in three different\nscenarios. In all data conditions (different languages, in/out-of-domain\nadaptation), our instance-based adaptation yields coherent performance gains\nover static models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 16:39:21 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Nguyen", "Viet-Nhat", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1910.10670", "submitter": "Jun Liu", "authors": "Jun Liu, Jiedan Zhu, Vishal Kathuria, Fuchun Peng", "title": "Efficient Dynamic WFST Decoding for Personalized Language Models", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-layer cache mechanism to speed up dynamic WFST decoding with\npersonalized language models. The first layer is a public cache that stores\nmost of the static part of the graph. This is shared globally among all users.\nA second layer is a private cache that caches the graph that represents the\npersonalized language model, which is only shared by the utterances from a\nparticular user. We also propose two simple yet effective pre-initialization\nmethods, one based on breadth-first search, and another based on a data-driven\nexploration of decoder states using previous utterances. Experiments with a\ncalling speech recognition task using a personalized contact list demonstrate\nthat the proposed public cache reduces decoding time by factor of three\ncompared to decoding without pre-initialization. Using the private cache\nprovides additional efficiency gains, reducing the decoding time by a factor of\nfive.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:10:26 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Liu", "Jun", ""], ["Zhu", "Jiedan", ""], ["Kathuria", "Vishal", ""], ["Peng", "Fuchun", ""]]}, {"id": "1910.10671", "submitter": "Ruizhi Li", "authors": "Ruizhi Li, Gregory Sell, Xiaofei Wang, Shinji Watanabe, Hynek\n  Hermansky", "title": "A practical two-stage training strategy for multi-stream end-to-end\n  speech recognition", "comments": "submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-stream paradigm of audio processing, in which several sources are\nsimultaneously considered, has been an active research area for information\nfusion. Our previous study offered a promising direction within end-to-end\nautomatic speech recognition, where parallel encoders aim to capture diverse\ninformation followed by a stream-level fusion based on attention mechanisms to\ncombine the different views. However, with an increasing number of streams\nresulting in an increasing number of encoders, the previous approach could\nrequire substantial memory and massive amounts of parallel data for joint\ntraining. In this work, we propose a practical two-stage training scheme.\nStage-1 is to train a Universal Feature Extractor (UFE), where encoder outputs\nare produced from a single-stream model trained with all data. Stage-2\nformulates a multi-stream scheme intending to solely train the attention fusion\nmodule using the UFE features and pretrained components from Stage-1.\nExperiments have been conducted on two datasets, DIRHA and AMI, as a\nmulti-stream scenario. Compared with our previous method, this strategy\nachieves relative word error rate reductions of 8.2--32.4%, while consistently\noutperforming several conventional combination methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:12:48 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Li", "Ruizhi", ""], ["Sell", "Gregory", ""], ["Wang", "Xiaofei", ""], ["Watanabe", "Shinji", ""], ["Hermansky", "Hynek", ""]]}, {"id": "1910.10683", "submitter": "Colin Raffel", "authors": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\n  Narang, Michael Matena, Yanqi Zhou, Wei Li and Peter J. Liu", "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text\n  Transformer", "comments": "Final version as published in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning, where a model is first pre-trained on a data-rich task\nbefore being fine-tuned on a downstream task, has emerged as a powerful\ntechnique in natural language processing (NLP). The effectiveness of transfer\nlearning has given rise to a diversity of approaches, methodology, and\npractice. In this paper, we explore the landscape of transfer learning\ntechniques for NLP by introducing a unified framework that converts all\ntext-based language problems into a text-to-text format. Our systematic study\ncompares pre-training objectives, architectures, unlabeled data sets, transfer\napproaches, and other factors on dozens of language understanding tasks. By\ncombining the insights from our exploration with scale and our new ``Colossal\nClean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks\ncovering summarization, question answering, text classification, and more. To\nfacilitate future work on transfer learning for NLP, we release our data set,\npre-trained models, and code.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:37:36 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 15:13:50 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 13:10:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Raffel", "Colin", ""], ["Shazeer", "Noam", ""], ["Roberts", "Adam", ""], ["Lee", "Katherine", ""], ["Narang", "Sharan", ""], ["Matena", "Michael", ""], ["Zhou", "Yanqi", ""], ["Li", "Wei", ""], ["Liu", "Peter J.", ""]]}, {"id": "1910.10697", "submitter": "Oleksii Hrinchuk", "authors": "Oleksii Hrinchuk, Mariya Popova, Boris Ginsburg", "title": "Correction of Automatic Speech Recognition with Transformer\n  Sequence-to-sequence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a simple yet efficient post-processing model for\nautomatic speech recognition (ASR). Our model has Transformer-based\nencoder-decoder architecture which \"translates\" ASR model output into\ngrammatically and semantically correct text. We investigate different\nstrategies for regularizing and optimizing the model and show that extensive\ndata augmentation and the initialization with pre-trained weights are required\nto achieve good performance. On the LibriSpeech benchmark, our method\ndemonstrates significant improvement in word error rate over the baseline\nacoustic model with greedy decoding, especially on much noisier dev-other and\ntest-other portions of the evaluation dataset. Our model also outperforms\nbaseline with 6-gram language model re-scoring and approaches the performance\nof re-scoring with Transformer-XL neural language model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 17:57:11 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Hrinchuk", "Oleksii", ""], ["Popova", "Mariya", ""], ["Ginsburg", "Boris", ""]]}, {"id": "1910.10706", "submitter": "Noa Garcia", "authors": "Noa Garcia, Mayu Otani, Chenhui Chu, Yuta Nakashima", "title": "KnowIT VQA: Answering Knowledge-Based Questions about Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel video understanding task by fusing knowledge-based and\nvideo question answering. First, we introduce KnowIT VQA, a video dataset with\n24,282 human-generated question-answer pairs about a popular sitcom. The\ndataset combines visual, textual and temporal coherence reasoning together with\nknowledge-based questions, which need of the experience obtained from the\nviewing of the series to be answered. Second, we propose a video understanding\nmodel by combining the visual and textual video content with specific knowledge\nabout the show. Our main findings are: (i) the incorporation of knowledge\nproduces outstanding improvements for VQA in video, and (ii) the performance on\nKnowIT VQA still lags well behind human accuracy, indicating its usefulness for\nstudying current video modelling limitations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 01:44:12 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:37:24 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 04:13:21 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Garcia", "Noa", ""], ["Otani", "Mayu", ""], ["Chu", "Chenhui", ""], ["Nakashima", "Yuta", ""]]}, {"id": "1910.10762", "submitter": "Mihaela Catalina Stoian", "authors": "Mihaela C. Stoian, Sameer Bansal, Sharon Goldwater", "title": "Analyzing ASR pretraining for low-resource speech-to-text translation", "comments": "Accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that for low-resource source languages, automatic\nspeech-to-text translation (AST) can be improved by pretraining an end-to-end\nmodel on automatic speech recognition (ASR) data from a high-resource language.\nHowever, it is not clear what factors --e.g., language relatedness or size of\nthe pretraining data-- yield the biggest improvements, or whether pretraining\ncan be effectively combined with other methods such as data augmentation. Here,\nwe experiment with pretraining on datasets of varying sizes, including\nlanguages related and unrelated to the AST source language. We find that the\nbest predictor of final AST performance is the word error rate of the\npretrained ASR model, and that differences in ASR/AST performance correlate\nwith how phonetic information is encoded in the later RNN layers of our model.\nWe also show that pretraining and data augmentation yield complementary\nbenefits for AST.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:37:56 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 15:57:42 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Stoian", "Mihaela C.", ""], ["Bansal", "Sameer", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1910.10781", "submitter": "Raghavendra Reddy Pappagari", "authors": "Raghavendra Pappagari, Piotr \\.Zelasko, Jes\\'us Villalba, Yishay\n  Carmiel and Najim Dehak", "title": "Hierarchical Transformers for Long Document Classification", "comments": "4 figures, 7 pages", "journal-ref": "Automatic Speech Recognition and Understanding Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  BERT, which stands for Bidirectional Encoder Representations from\nTransformers, is a recently introduced language representation model based upon\nthe transfer learning paradigm. We extend its fine-tuning procedure to address\none of its major limitations - applicability to inputs longer than a few\nhundred words, such as transcripts of human call conversations. Our method is\nconceptually simple. We segment the input into smaller chunks and feed each of\nthem into the base model. Then, we propagate each output through a single\nrecurrent layer, or another transformer, followed by a softmax activation. We\nobtain the final classification decision after the last segment has been\nconsumed. We show that both BERT extensions are quick to fine-tune and converge\nafter as little as 1 epoch of training on a small, domain-specific data set. We\nsuccessfully apply them in three different tasks involving customer call\nsatisfaction prediction and topic classification, and obtain a significant\nimprovement over the baseline models in two of them.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 19:51:50 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Pappagari", "Raghavendra", ""], ["\u017belasko", "Piotr", ""], ["Villalba", "Jes\u00fas", ""], ["Carmiel", "Yishay", ""], ["Dehak", "Najim", ""]]}, {"id": "1910.10832", "submitter": "Luke de Oliveira", "authors": "Alexandre Matton and Luke de Oliveira", "title": "Emergent Properties of Finetuned Language Representation Models", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, self-supervised transformer-based language representation models have\nrecently received significant amounts of attention, and have produced\nstate-of-the-art results across a variety of tasks simply by scaling up\npre-training on larger and larger corpora. Such models usually produce high\ndimensional vectors, on top of which additional task-specific layers and\narchitectural modifications are added to adapt them to specific downstream\ntasks. Though there exists ample evidence that such models work well, we aim to\nunderstand what happens when they work well. We analyze the redundancy and\nlocation of information contained in output vectors for one such language\nrepresentation model -- BERT. We show empirical evidence that the [CLS]\nembedding in BERT contains highly redundant information, and can be compressed\nwith minimal loss of accuracy, especially for finetuned models, dovetailing\ninto open threads in the field about the role of over-parameterization in\nlearning. We also shed light on the existence of specific output dimensions\nwhich alone give very competitive results when compared to using all dimensions\nof output vectors.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:01:10 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Matton", "Alexandre", ""], ["de Oliveira", "Luke", ""]]}, {"id": "1910.10843", "submitter": "Kevin Huang", "authors": "Kevin Huang, Yun Tang, Jing Huang, Xiaodong He, and Bowen Zhou", "title": "Relation Module for Non-answerable Prediction on Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension(MRC) has attracted significant amounts of\nresearch attention recently, due to an increase of challenging reading\ncomprehension datasets. In this paper, we aim to improve a MRC model's ability\nto determine whether a question has an answer in a given context (e.g. the\nrecently proposed SQuAD 2.0 task). Our solution is a relation module that is\nadaptable to any MRC model. The relation module consists of both semantic\nextraction and relational information. We first extract high level semantics as\nobjects from both question and context with multi-head self-attentive pooling.\nThese semantic objects are then passed to a relation network, which generates\nrelationship scores for each object pair in a sentence. These scores are used\nto determine whether a question is non-answerable. We test the relation module\non the SQuAD 2.0 dataset using both BiDAF and BERT models as baseline readers.\nWe obtain 1.8% gain of F1 on top of the BiDAF reader, and 1.0% on top of the\nBERT base model. These results show the effectiveness of our relation module on\nMRC\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 23:55:23 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Huang", "Kevin", ""], ["Tang", "Yun", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1910.10849", "submitter": "EPTCS", "authors": "Michael Kohlhase (Computer Science, FAU Erlangen-N\\\"urnberg), Jan\n  Frederik Schaefer (Computer Science, FAU Erlangen-N\\\"urnberg)", "title": "GF + MMT = GLF -- From Language to Semantics through LF", "comments": "In Proceedings LFMTP 2019, arXiv:1910.08712", "journal-ref": "EPTCS 307, 2019, pp. 24-39", "doi": "10.4204/EPTCS.307.4", "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These days, vast amounts of knowledge are available online, most of it in\nwritten form. Search engines help us access this knowledge, but aggregating,\nrelating and reasoning with it is still a predominantly human effort. One of\nthe key challenges for automated reasoning based on natural-language texts is\nthe need to extract meaning (semantics) from texts. Natural language\nunderstanding (NLU) systems describe the conversion from a set of natural\nlanguage utterances to terms in a particular logic. Tools for the\nco-development of grammar and target logic are currently largely missing.\n  We will describe the Grammatical Logical Framework (GLF), a combination of\ntwo existing frameworks, in which large parts of a symbolic, rule-based NLU\nsystem can be developed and implemented: the Grammatical Framework (GF) and\nMMT. GF is a tool for syntactic analysis, generation, and translation with\ncomplex natural language grammars and MMT can be used to specify logical\nsystems and to represent knowledge in them. Combining these tools is possible,\nbecause they are based on compatible logical frameworks: Martin-L\\\"of type\ntheory and LF. The flexibility of logical frameworks is needed, as NLU research\nhas not settled on a particular target logic for meaning representation.\nInstead, new logics are developed all the time to handle various language\nphenomena. GLF allows users to develop the logic and the language parsing\ncomponents in parallel, and to connect them for experimentation with the entire\npipeline.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:22:43 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Kohlhase", "Michael", "", "Computer Science, FAU Erlangen-N\u00fcrnberg"], ["Schaefer", "Jan Frederik", "", "Computer Science, FAU Erlangen-N\u00fcrnberg"]]}, {"id": "1910.10857", "submitter": "Xiaochen Hou", "authors": "Xiaochen Hou, Jing Huang, Guangtao Wang, Xiaodong He, Bowen Zhou", "title": "Selective Attention Based Graph Convolutional Networks for Aspect-Level\n  Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification aims to identify the sentiment polarity\ntowards a specific aspect term in a sentence. Most current approaches mainly\nconsider the semantic information by utilizing attention mechanisms to capture\nthe interactions between the context and the aspect term. In this paper, we\npropose to employ graph convolutional networks (GCNs) on the dependency tree to\nlearn syntax-aware representations of aspect terms. GCNs often show the best\nperformance with two layers, and deeper GCNs do not bring additional gain due\nto over-smoothing problem. However, in some cases, important context words\ncannot be reached within two hops on the dependency tree. Therefore we design a\nselective attention based GCN block (SA-GCN) to find the most important context\nwords, and directly aggregate these information into the aspect-term\nrepresentation. We conduct experiments on the SemEval 2014 Task 4 datasets. Our\nexperimental results show that our model outperforms the current\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 00:33:39 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 04:05:51 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 04:33:13 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 02:19:25 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hou", "Xiaochen", ""], ["Huang", "Jing", ""], ["Wang", "Guangtao", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1910.10869", "submitter": "Andreas Stolcke", "authors": "Dave Makhervaks and William Hinthorn and Dimitrios Dimitriadis and\n  Andreas Stolcke", "title": "Combining Acoustics, Content and Interaction Features to Find Hot Spots\n  in Meetings", "comments": "Revised for publication", "journal-ref": "Proc. IEEE ICASSP, May 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Involvement hot spots have been proposed as a useful concept for meeting\nanalysis and studied off and on for over 15 years. These are regions of\nmeetings that are marked by high participant involvement, as judged by human\nannotators. However, prior work was either not conducted in a formal machine\nlearning setting, or focused on only a subset of possible meeting features or\ndownstream applications (such as summarization). In this paper we investigate\nto what extent various acoustic, linguistic and pragmatic aspects of the\nmeetings, both in isolation and jointly, can help detect hot spots. In this\ncontext, the openSMILE toolkit is to used to extract features based on\nacoustic-prosodic cues, BERT word embeddings are used for encoding the lexical\ncontent, and a variety of statistics based on speech activity are used to\ndescribe the verbal interaction among participants. In experiments on the\nannotated ICSI meeting corpus, we find that the lexical model is the most\ninformative, with incremental contributions from interaction and\nacoustic-prosodic model components.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:18:24 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:57:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Makhervaks", "Dave", ""], ["Hinthorn", "William", ""], ["Dimitriadis", "Dimitrios", ""], ["Stolcke", "Andreas", ""]]}, {"id": "1910.10872", "submitter": "Ninareh Mehrabi", "authors": "Ninareh Mehrabi, Thamme Gowda, Fred Morstatter, Nanyun Peng, Aram\n  Galstyan", "title": "Man is to Person as Woman is to Location: Measuring Gender Bias in Named\n  Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the bias in several state-of-the-art named entity recognition (NER)\nmodels---specifically, a difference in the ability to recognize male and female\nnames as PERSON entity types. We evaluate NER models on a dataset containing\n139 years of U.S. census baby names and find that relatively more female names,\nas opposed to male names, are not recognized as PERSON entities. We study the\nextent of this bias in several NER systems that are used prominently in\nindustry and academia. In addition, we also report a bias in the datasets on\nwhich these models were trained. The result of this analysis yields a new\nbenchmark for gender bias evaluation in named entity recognition systems. The\ndata and code for the application of this benchmark will be publicly available\nfor researchers to use.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:32:24 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Mehrabi", "Ninareh", ""], ["Gowda", "Thamme", ""], ["Morstatter", "Fred", ""], ["Peng", "Nanyun", ""], ["Galstyan", "Aram", ""]]}, {"id": "1910.10893", "submitter": "Chen Li", "authors": "Zuyi Bao, Rui Huang, Chen Li and Kenny Q. Zhu", "title": "Low-Resource Sequence Labeling via Unsupervised Multilingual\n  Contextualized Representations", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work on cross-lingual sequence labeling tasks either requires\nparallel data or bridges the two languages through word-byword matching. Such\nrequirements and assumptions are infeasible for most languages, especially for\nlanguages with large linguistic distances, e.g., English and Chinese. In this\nwork, we propose a Multilingual Language Model with deep semantic Alignment\n(MLMA) to generate language-independent representations for cross-lingual\nsequence labeling. Our methods require only monolingual corpora with no\nbilingual resources at all and take advantage of deep contextualized\nrepresentations. Experimental results show that our approach achieves new\nstate-of-the-art NER and POS performance across European languages, and is also\neffective on distant language pairs such as English and Chinese.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 03:00:53 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Bao", "Zuyi", ""], ["Huang", "Rui", ""], ["Li", "Chen", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1910.10909", "submitter": "Tomoki Hayashi", "authors": "Tomoki Hayashi and Ryuichi Yamamoto and Katsuki Inoue and Takenori\n  Yoshimura and Shinji Watanabe and Tomoki Toda and Kazuya Takeda and Yu Zhang\n  and Xu Tan", "title": "ESPnet-TTS: Unified, Reproducible, and Integratable Open Source\n  End-to-End Text-to-Speech Toolkit", "comments": "Accepted to ICASSP2020. Demo HP:\n  https://espnet.github.io/icassp2020-tts/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new end-to-end text-to-speech (E2E-TTS) toolkit named\nESPnet-TTS, which is an extension of the open-source speech processing toolkit\nESPnet. The toolkit supports state-of-the-art E2E-TTS models, including\nTacotron~2, Transformer TTS, and FastSpeech, and also provides recipes inspired\nby the Kaldi automatic speech recognition (ASR) toolkit. The recipes are based\non the design unified with the ESPnet ASR recipe, providing high\nreproducibility. The toolkit also provides pre-trained models and samples of\nall of the recipes so that users can use it as a baseline. Furthermore, the\nunified design enables the integration of ASR functions with TTS, e.g.,\nASR-based objective evaluation and semi-supervised learning with both ASR and\nTTS models. This paper describes the design of the toolkit and experimental\nevaluation in comparison with other toolkits. The experimental results show\nthat our models can achieve state-of-the-art performance comparable to the\nother latest toolkits, resulting in a mean opinion score (MOS) of 4.25 on the\nLJSpeech dataset. The toolkit is publicly available at\nhttps://github.com/espnet/espnet.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 04:24:27 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 01:13:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hayashi", "Tomoki", ""], ["Yamamoto", "Ryuichi", ""], ["Inoue", "Katsuki", ""], ["Yoshimura", "Takenori", ""], ["Watanabe", "Shinji", ""], ["Toda", "Tomoki", ""], ["Takeda", "Kazuya", ""], ["Zhang", "Yu", ""], ["Tan", "Xu", ""]]}, {"id": "1910.10950", "submitter": "Fuli Luo", "authors": "Fuli Luo, Shunyao Li, Pengcheng Yang, Lei li, Baobao Chang, Zhifang\n  Sui, Xu Sun", "title": "Pun-GAN: Generative Adversarial Network for Pun Generation", "comments": "EMNLP 2019 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the task of generating a pun sentence given a pair\nof word senses. A major challenge for pun generation is the lack of large-scale\npun corpus to guide the supervised learning. To remedy this, we propose an\nadversarial generative network for pun generation (Pun-GAN), which does not\nrequire any pun corpus. It consists of a generator to produce pun sentences,\nand a discriminator to distinguish between the generated pun sentences and the\nreal sentences with specific word senses. The output of the discriminator is\nthen used as a reward to train the generator via reinforcement learning,\nencouraging it to produce pun sentences that can support two word senses\nsimultaneously. Experiments show that the proposed Pun-GAN can generate\nsentences that are more ambiguous and diverse in both automatic and human\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:26:36 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Luo", "Fuli", ""], ["Li", "Shunyao", ""], ["Yang", "Pengcheng", ""], ["li", "Lei", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""], ["Sun", "Xu", ""]]}, {"id": "1910.11005", "submitter": "Ioannis Partalas", "authors": "Georgios Balikas and Ioannis Partalas", "title": "Wasserstein distances for evaluating cross-lingual embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are high dimensional vector representations of words that\ncapture their semantic similarity in the vector space. There exist several\nalgorithms for learning such embeddings both for a single language as well as\nfor several languages jointly. In this work we propose to evaluate collections\nof embeddings by adapting downstream natural language tasks to the optimal\ntransport framework. We show how the family of Wasserstein distances can be\nused to solve cross-lingual document retrieval and the cross-lingual document\nclassification problems. We argue on the advantages of this approach compared\nto more traditional evaluation methods of embeddings like bilingual lexical\ninduction. Our experimental results suggest that using Wasserstein distances on\nthese problems out-performs several strong baselines and performs on par with\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:04:12 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 08:03:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Balikas", "Georgios", ""], ["Partalas", "Ioannis", ""]]}, {"id": "1910.11119", "submitter": "Jianri Li", "authors": "Jianri Li, Jae-whan Lee, Woo-sang Song, Ki-young Shin, Byung-hyun Go", "title": "Designovel's system description for Fashion-IQ challenge 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Designovel's systems which are submitted to the Fashion\nIQ Challenge 2019. Goal of the challenge is building an image retrieval system\nwhere input query is a candidate image plus two text phrases describe user's\nfeedback about visual differences between the candidate image and the search\ntarget. We built the systems by combining methods from recent work on deep\nmetric learning, multi-modal retrieval and natual language processing. First,\nwe encode both candidate and target images with CNNs into high-level\nrepresentations, and encode text descriptions to a single text vector using\nTransformer-based encoder. Then we compose candidate image vector and text\nrepresentation into a single vector which is exptected to be biased toward\ntarget image vector. Finally, we compute cosine similarities between composed\nvector and encoded vectors of whole dataset, and rank them in desceding order\nto get ranked list. We experimented with Fashion IQ 2019 dataset in various\nsettings of hyperparameters, achieved 39.12% average recall by a single model\nand 43.67% average recall by an ensemble of 16 models on test dataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:06:26 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Li", "Jianri", ""], ["Lee", "Jae-whan", ""], ["Song", "Woo-sang", ""], ["Shin", "Ki-young", ""], ["Go", "Byung-hyun", ""]]}, {"id": "1910.11124", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi, Md. Mehrab Tanjim and David J. Kriegman", "title": "Enforcing Reasoning in Visual Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of Visual Commonsense Reasoning is extremely challenging in the\nsense that the model has to not only be able to answer a question given an\nimage, but also be able to learn to reason. The baselines introduced in this\ntask are quite limiting because two networks are trained for predicting answers\nand rationales separately. Question and image is used as input to train answer\nprediction network while question, image and correct answer are used as input\nin the rationale prediction network. As rationale is conditioned on the correct\nanswer, it is based on the assumption that we can solve Visual Question\nAnswering task without any error - which is over ambitious. Moreover, such an\napproach makes both answer and rationale prediction two completely independent\nVQA tasks rendering cognition task meaningless. In this paper, we seek to\naddress these issues by proposing an end-to-end trainable model which considers\nboth answers and their reasons jointly. Specifically, we first predict the\nanswer for the question and then use the chosen answer to predict the\nrationale. However, a trivial design of such a model becomes non-differentiable\nwhich makes it difficult to train. We solve this issue by proposing four\napproaches - softmax, gumbel-softmax, reinforcement learning based sampling and\ndirect cross entropy against all pairs of answers and rationales. We\ndemonstrate through experiments that our model performs competitively against\ncurrent state-of-the-art. We conclude with an analysis of presented approaches\nand discuss avenues for further work.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:33:18 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 10:09:58 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ayyubi", "Hammad A.", ""], ["Tanjim", "Md. Mehrab", ""], ["Kriegman", "David J.", ""]]}, {"id": "1910.11161", "submitter": "Fei Hu", "authors": "Fei Hu, Wei Liu, Ajmal Saeed Mian, and Li Li", "title": "Diversifying Topic-Coherent Response Generation for Natural Multi-turn\n  Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although response generation (RG) diversification for single-turn dialogs has\nbeen well developed, it is less investigated for natural multi-turn\nconversations. Besides, past work focused on diversifying responses without\nconsidering topic coherence to the context, producing uninformative replies. In\nthis paper, we propose the Topic-coherent Hierarchical Recurrent\nEncoder-Decoder model (THRED) to diversify the generated responses without\ndeviating the contextual topics for multi-turn conversations. In overall, we\nbuild a sequence-to-sequence net (Seq2Seq) to model multi-turn conversations.\nAnd then we resort to the latent Variable Hierarchical Recurrent\nEncoder-Decoder model (VHRED) to learn global contextual distribution of\ndialogs. Besides, we construct a dense topic matrix which implies word-level\ncorrelations of the conversation corpora. The topic matrix is used to learn\nlocal topic distribution of the contextual utterances. By incorporating both\nthe global contextual distribution and the local topic distribution, THRED\nproduces both diversified and topic-coherent replies. In addition, we propose\nan explicit metric (\\emph{TopicDiv}) to measure the topic divergence between\nthe post and generated response, and we also propose an overall metric\ncombining the diversification metric (\\emph{Distinct}) and \\emph{TopicDiv}. We\nevaluate our model comparing with three baselines (Seq2Seq, HRED and VHRED) on\ntwo real-world corpora, respectively, and demonstrate its outstanding\nperformance in both diversification and topic coherence.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:18:55 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Hu", "Fei", ""], ["Liu", "Wei", ""], ["Mian", "Ajmal Saeed", ""], ["Li", "Li", ""]]}, {"id": "1910.11204", "submitter": "Yue Zhang", "authors": "Yue Zhang, Rui Wang, Luo Si", "title": "Syntax-Enhanced Self-Attention-Based Semantic Role Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a fundamental NLP task, semantic role labeling (SRL) aims to discover the\nsemantic roles for each predicate within one sentence. This paper investigates\nhow to incorporate syntactic knowledge into the SRL task effectively. We\npresent different approaches of encoding the syntactic information derived from\ndependency trees of different quality and representations; we propose a\nsyntax-enhanced self-attention model and compare it with other two strong\nbaseline methods; and we conduct experiments with newly published deep\ncontextualized word representations as well. The experiment results demonstrate\nthat with proper incorporation of the high quality syntactic information, our\nmodel achieves a new state-of-the-art performance for the Chinese SRL task on\nthe CoNLL-2009 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:05:01 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zhang", "Yue", ""], ["Wang", "Rui", ""], ["Si", "Luo", ""]]}, {"id": "1910.11218", "submitter": "Dominik Mach\\'a\\v{c}ek", "authors": "Thuong-Hai Pham, Dominik Mach\\'a\\v{c}ek, Ond\\v{r}ej Bojar", "title": "Promoting the Knowledge of Source Syntax in Transformer NMT Is Not\n  Needed", "comments": "CICLING 2019", "journal-ref": "Computac\\'ion y Sistemas, Vol. 23, No. 3, 2019, pp. 923-934", "doi": "10.13053/CyS-23-3-3265", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utility of linguistic annotation in neural machine translation seemed to\nhad been established in past papers. The experiments were however limited to\nrecurrent sequence-to-sequence architectures and relatively small data\nsettings. We focus on the state-of-the-art Transformer model and use comparably\nlarger corpora. Specifically, we try to promote the knowledge of source-side\nsyntax using multi-task learning either through simple data manipulation\ntechniques or through a dedicated model component. In particular, we train one\nof Transformer attention heads to produce source-side dependency tree. Overall,\nour results cast some doubt on the utility of multi-task setups with linguistic\ninformation. The data manipulation techniques, recommended in previous works,\nprove ineffective in large data settings. The treatment of self-attention as\ndependencies seems much more promising: it helps in translation and reveals\nthat Transformer model can very easily grasp the syntactic structure. An\nimportant but curious result is, however, that identical gains are obtained by\nusing trivial \"linear trees\" instead of true dependencies. The reason for the\ngain thus may not be coming from the added linguistic knowledge but from some\nsimpler regularizing effect we induced on self-attention matrices.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 15:23:08 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Pham", "Thuong-Hai", ""], ["Mach\u00e1\u010dek", "Dominik", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1910.11235", "submitter": "Yifan Xu", "authors": "Yifan Xu, Kening Zhang, Haoyu Dong, Yuezhou Sun, Wenlong Zhao, Zhuowen\n  Tu", "title": "Rethinking Exposure Bias In Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exposure bias describes the phenomenon that a language model trained under\nthe teacher forcing schema may perform poorly at the inference stage when its\npredictions are conditioned on its previous predictions unseen from the\ntraining corpus. Recently, several generative adversarial networks (GANs) and\nreinforcement learning (RL) methods have been introduced to alleviate this\nproblem. Nonetheless, a common issue in RL and GANs training is the sparsity of\nreward signals. In this paper, we adopt two simple strategies, multi-range\nreinforcing, and multi-entropy sampling, to amplify and denoise the reward\nsignal. Our model produces an improvement over competing models with regards to\nBLEU scores and road exam, a new metric we designed to measure the robustness\nagainst exposure bias in language models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 23:34:04 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 22:46:12 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xu", "Yifan", ""], ["Zhang", "Kening", ""], ["Dong", "Haoyu", ""], ["Sun", "Yuezhou", ""], ["Zhao", "Wenlong", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1910.11236", "submitter": "Yucheng Lin", "authors": "Hao Cheng, Xiaoqing Yang, Zang Li, Yanghua Xiao, Yucheng Lin", "title": "Interpretable Text Classification Using CNN and Max-pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been widely used in text classification. However,\nit is hard to interpret the neural models due to the complicate mechanisms. In\nthis work, we study the interpretability of a variant of the typical text\nclassification model which is based on convolutional operation and max-pooling\nlayer. Two mechanisms: convolution attribution and n-gram feature analysis are\nproposed to analyse the process procedure for the CNN model. The\ninterpretability of the model is reflected by providing posterior\ninterpretation for neural network predictions. Besides, a multi-sentence\nstrategy is proposed to enable the model to beused in multi-sentence situation\nwithout loss of performance and interpret ability. We evaluate the performance\nof the model on several classification tasks and justify the interpretable\nperformance with some case studies.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 11:52:03 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Cheng", "Hao", ""], ["Yang", "Xiaoqing", ""], ["Li", "Zang", ""], ["Xiao", "Yanghua", ""], ["Lin", "Yucheng", ""]]}, {"id": "1910.11241", "submitter": "Dattaraj Rao", "authors": "Amogh Kamat Tarcar, Aashis Tiwari, Vineet Naique Dhaimodker, Penjo\n  Rebelo, Rahul Desai, Dattaraj Rao", "title": "Healthcare NER Models Using Language Model Pretraining", "comments": "This work was presented at the first Health Search and Data Mining\n  Workshop (HSDM 2020) as part of WSDM 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approach to extracting structured information\nfrom unstructured Electronic Health Records (EHR) [2] which can be used to, for\nexample, study adverse drug reactions in patients due to chemicals in their\nproducts. Our solution uses a combination of Natural Language Processing (NLP)\ntechniques and a web-based annotation tool to optimize the performance of a\ncustom Named Entity Recognition (NER) [1] model trained on a limited amount of\nEHR training data. This work was presented at the first Health Search and Data\nMining Workshop (HSDM 2020) [26]. We showcase a combination of tools and\ntechniques leveraging the recent advancements in NLP aimed at targeting domain\nshifts by applying transfer learning and language model pre-training techniques\n[3]. We present a comparison of our technique to the current popular approaches\nand show the effective increase in performance of the NER model and the\nreduction in time to annotate data.A key observation of the results presented\nis that the F1 score of model (0.734) trained with our approach with just 50%\nof available training data outperforms the F1 score of the blank spaCy model\nwithout language model component (0.704) trained with 100% of the available\ntraining data. We also demonstrate an annotation tool to minimize domain expert\ntime and the manual effort required to generate such a training dataset.\nFurther, we plan to release the annotated dataset as well as the pre-trained\nmodel to the community to further research in medical health records.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 07:37:14 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 07:12:58 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Tarcar", "Amogh Kamat", ""], ["Tiwari", "Aashis", ""], ["Dhaimodker", "Vineet Naique", ""], ["Rebelo", "Penjo", ""], ["Desai", "Rahul", ""], ["Rao", "Dattaraj", ""]]}, {"id": "1910.11242", "submitter": "Prabhakar Gupta", "authors": "Prabhakar Gupta", "title": "A context sensitive real-time Spell Checker with language adaptability", "comments": "7 pages, 6 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel language adaptable spell checking system which detects\nspelling errors and suggests context sensitive corrections in real-time. We\nshow that our system can be extended to new languages with minimal\nlanguage-specific processing. Available literature majorly discusses spell\ncheckers for English but there are no publicly available systems which can be\nextended to work for other languages out of the box. Most of the systems do not\nwork in real-time. We explain the process of generating a language's word\ndictionary and n-gram probability dictionaries using Wikipedia-articles data\nand manually curated video subtitles. We present the results of generating a\nlist of suggestions for a misspelled word. We also propose three approaches to\ncreate noisy channel datasets of real-world typographic errors. We compare our\nsystem with industry-accepted spell checker tools for 11 languages. Finally, we\nshow the performance of our system on synthetic datasets for 24 languages.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:00:39 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Gupta", "Prabhakar", ""]]}, {"id": "1910.11263", "submitter": "Zheng Lian", "authors": "Zheng Lian, Jianhua Tao, Bin Liu, Jian Huang", "title": "Conversational Emotion Analysis via Attention Mechanisms", "comments": null, "journal-ref": "Proc. Interspeech 2019, 1936-1940", "doi": "10.21437/Interspeech.2019-1577", "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the emotion recognition in individual utterances, we propose a\nmultimodal learning framework using relation and dependencies among the\nutterances for conversational emotion analysis. The attention mechanism is\napplied to the fusion of the acoustic and lexical features. Then these fusion\nrepresentations are fed into the self-attention based bi-directional gated\nrecurrent unit (GRU) layer to capture long-term contextual information. To\nimitate real interaction patterns of different speakers, speaker embeddings are\nalso utilized as additional inputs to distinguish the speaker identities during\nconversational dialogs. To verify the effectiveness of the proposed method, we\nconduct experiments on the IEMOCAP database. Experimental results demonstrate\nthat our method shows absolute 2.42% performance improvement over the\nstate-of-the-art strategies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 16:16:45 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Lian", "Zheng", ""], ["Tao", "Jianhua", ""], ["Liu", "Bin", ""], ["Huang", "Jian", ""]]}, {"id": "1910.11292", "submitter": "Nadav Oved", "authors": "Nadav Oved, Amir Feder, Roi Reichart", "title": "Predicting In-game Actions from Interviews of NBA Players", "comments": "First two authors contributed equally. To be published in the\n  Computational Linguistics journal. Code is available at:\n  https://github.com/nadavo/mood", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sports competitions are widely researched in computer and social science,\nwith the goal of understanding how players act under uncertainty. While there\nis an abundance of computational work on player metrics prediction based on\npast performance, very few attempts to incorporate out-of-game signals have\nbeen made. Specifically, it was previously unclear whether linguistic signals\ngathered from players' interviews can add information which does not appear in\nperformance metrics. To bridge that gap, we define text classification tasks of\npredicting deviations from mean in NBA players' in-game actions, which are\nassociated with strategic choices, player behavior and risk, using their choice\nof language prior to the game. We collected a dataset of transcripts from key\nNBA players' pre-game interviews and their in-game performance metrics,\ntotalling in 5,226 interview-metric pairs. We design neural models for players'\naction prediction based on increasingly more complex aspects of the language\nsignals in their open-ended interviews. Our models can make their predictions\nbased on the textual signal alone, or on a combination with signals from\npast-performance metrics. Our text-based models outperform strong baselines\ntrained on performance metrics only, demonstrating the importance of language\nusage for action prediction. Moreover, the models that employ both textual\ninput and past-performance metrics produced the best results. Finally, as\nneural networks are notoriously difficult to interpret, we propose a method for\ngaining further insight into what our models have learned. Particularly, we\npresent an LDA-based analysis, where we interpret model predictions in terms of\ncorrelated topics. We find that our best performing textual model is most\nassociated with topics that are intuitively related to each prediction task and\nthat better models yield higher correlation with more informative topics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:10:34 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 01:29:32 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 17:46:33 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Oved", "Nadav", ""], ["Feder", "Amir", ""], ["Reichart", "Roi", ""]]}, {"id": "1910.11295", "submitter": "Milan Straka", "authors": "Milan Straka, Jana Strakov\\'a", "title": "\\'UFAL MRPipe at MRP 2019: UDPipe Goes Semantic in the Meaning\n  Representation Parsing Shared Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system description of our contribution to the CoNLL 2019 shared\ntask, Cross-Framework Meaning Representation Parsing (MRP 2019). The proposed\narchitecture is our first attempt towards a semantic parsing extension of the\nUDPipe 2.0, a lemmatization, POS tagging and dependency parsing pipeline.\n  For the MRP 2019, which features five formally and linguistically different\napproaches to meaning representation (DM, PSD, EDS, UCCA and AMR), we propose a\nuniform, language and framework agnostic graph-to-graph neural network\narchitecture. Without any knowledge about the graph structure, and specifically\nwithout any linguistically or framework motivated features, our system\nimplicitly models the meaning representation graphs.\n  After fixing a human error (we used earlier incorrect version of provided\ntest set analyses), our submission would score third in the competition\nevaluation. The source code of our system is available at\nhttps://github.com/ufal/mrpipe-conll2019.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:17:10 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Straka", "Milan", ""], ["Strakov\u00e1", "Jana", ""]]}, {"id": "1910.11301", "submitter": "An Yan", "authors": "An Yan, Xin Eric Wang, Jiangtao Feng, Lei Li, William Yang Wang", "title": "Cross-Lingual Vision-Language Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commanding a robot to navigate with natural language instructions is a\nlong-term goal for grounded language understanding and robotics. But the\ndominant language is English, according to previous studies on vision-language\nnavigation (VLN). To go beyond English and serve people speaking different\nlanguages, we collect a bilingual Room-to-Room (BL-R2R) dataset, extending the\noriginal benchmark with new Chinese instructions. Based on this newly\nintroduced dataset, we study how an agent can be trained on existing English\ninstructions but navigate effectively with another language under a zero-shot\nlearning scenario. Without any training data of the target language, our model\nshows competitive results even compared to a model with full access to the\ntarget language training data. Moreover, we investigate the transferring\nability of our model when given a certain amount of target language training\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:32:38 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 05:48:48 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 02:48:07 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yan", "An", ""], ["Wang", "Xin Eric", ""], ["Feng", "Jiangtao", ""], ["Li", "Lei", ""], ["Wang", "William Yang", ""]]}, {"id": "1910.11368", "submitter": "Viet Lai", "authors": "Viet Dac Lai and Thien Huu Nguyen", "title": "Extending Event Detection to New Types with Learning from Keywords", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional event detection classifies a word or a phrase in a given sentence\nfor a set of predefined event types. The limitation of such predefined set is\nthat it prevents the adaptation of the event detection models to new event\ntypes. We study a novel formulation of event detection that describes types via\nseveral keywords to match the contexts in documents. This facilitates the\noperation of the models to new types. We introduce a novel feature-based\nattention mechanism for convolutional neural networks for event detection in\nthe new formulation. Our extensive experiments demonstrate the benefits of the\nnew formulation for new type extension for event detection as well as the\nproposed attention mechanism for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:20:48 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lai", "Viet Dac", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1910.11377", "submitter": "Sunyang Fu", "authors": "Sunyang Fu, David Chen, Huan He, Sijia Liu, Sungrim Moon, Kevin J\n  Peterson, Feichen Shen, Liwei Wang, Yanshan Wang, Andrew Wen, Yiqing Zhao,\n  Sunghwan Sohn, Hongfang Liu", "title": "Clinical Concept Extraction: a Methodology Review", "comments": null, "journal-ref": "Journal of Biomedical Informatics (2020): 103526", "doi": "10.1016/j.jbi.2020.103526", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Concept extraction, a subdomain of natural language processing\n(NLP) with a focus on extracting concepts of interest, has been adopted to\ncomputationally extract clinical information from text for a wide range of\napplications ranging from clinical decision support to care quality\nimprovement.\n  Objectives In this literature review, we provide a methodology review of\nclinical concept extraction, aiming to catalog development processes, available\nmethods and tools, and specific considerations when developing clinical concept\nextraction applications.\n  Methods Based on the Preferred Reporting Items for Systematic Reviews and\nMeta-Analyses (PRISMA) guidelines, a literature search was conducted for\nretrieving EHR-based information extraction articles written in English and\npublished from January 2009 through June 2019 from Ovid MEDLINE In-Process &\nOther Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science,\nand the ACM Digital Library.\n  Results A total of 6,686 publications were retrieved. After title and\nabstract screening, 228 publications were selected. The methods used for\ndeveloping clinical concept extraction applications were discussed in this\nreview.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 18:54:25 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 19:17:01 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 19:17:25 GMT"}, {"version": "v4", "created": "Mon, 10 Aug 2020 21:09:35 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Fu", "Sunyang", ""], ["Chen", "David", ""], ["He", "Huan", ""], ["Liu", "Sijia", ""], ["Moon", "Sungrim", ""], ["Peterson", "Kevin J", ""], ["Shen", "Feichen", ""], ["Wang", "Liwei", ""], ["Wang", "Yanshan", ""], ["Wen", "Andrew", ""], ["Zhao", "Yiqing", ""], ["Sohn", "Sunghwan", ""], ["Liu", "Hongfang", ""]]}, {"id": "1910.11386", "submitter": "Shahan Ali Memon", "authors": "Shahan Ali Memon, Hira Dhamyal, Oren Wright, Daniel Justice,\n  Vijaykumar Palat, William Boler, Bhiksha Raj, Rita Singh", "title": "Detecting gender differences in perception of emotion in crowdsourced\n  data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do men and women perceive emotions differently? Popular convictions place\nwomen as more emotionally perceptive than men. Empirical findings, however,\nremain inconclusive. Most prior studies focus on visual modalities. In\naddition, almost all of the studies are limited to experiments within\ncontrolled environments. Generalizability and scalability of these studies has\nnot been sufficiently established. In this paper, we study the differences in\nperception of emotion between genders from speech data in the wild, annotated\nthrough crowdsourcing. While we limit ourselves to a single modality (i.e.\nspeech), our framework is applicable to studies of emotion perception from all\nsuch loosely annotated data in general. Our paper addresses multiple serious\nchallenges related to making statistically viable conclusions from crowdsourced\ndata. Overall, the contributions of this paper are two fold: a reliable novel\nframework for perceptual studies from crowdsourced data; and the demonstration\nof statistically significant differences in speech-based emotion perception\nbetween genders.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 19:13:21 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 18:23:50 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 13:28:06 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 14:33:39 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Memon", "Shahan Ali", ""], ["Dhamyal", "Hira", ""], ["Wright", "Oren", ""], ["Justice", "Daniel", ""], ["Palat", "Vijaykumar", ""], ["Boler", "William", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1910.11399", "submitter": "Manirupa Das", "authors": "Manirupa Das and Renhao Cui", "title": "Comparison of Quality Indicators in User-generated Content Using Social\n  Media and Scholarly Text", "comments": "8 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the quality of a text document is a critical task when presented\nwith the problem of measuring the performance of a document before its release.\nIn this work, we evaluate various features including those extracted from the\ntext content (textual) and those describing higher-level characteristics of the\ntext (meta) features that are not directly available from the text, and show\nhow these features inform prediction of document quality in different ways.\nMoreover, we also compare our methods on both social user-generated data such\nas tweets, and scholarly user-generated data such as academic articles, showing\nhow the same features differently influence prediction of quality across these\ndisparate domains.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 19:54:32 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Das", "Manirupa", ""], ["Cui", "Renhao", ""]]}, {"id": "1910.11411", "submitter": "Fei Liu", "authors": "Sangwoo Cho and Chen Li and Dong Yu and Hassan Foroosh and Fei Liu", "title": "Multi-Document Summarization with Determinantal Point Processes and\n  Contextualized Representations", "comments": "EMNLP 2019 Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerged as one of the best performing techniques for extractive\nsummarization, determinantal point processes select the most probable set of\nsentences to form a summary according to a probability measure defined by\nmodeling sentence prominence and pairwise repulsion. Traditionally, these\naspects are modelled using shallow and linguistically informed features, but\nthe rise of deep contextualized representations raises an interesting question\nof whether, and to what extent, contextualized representations can be used to\nimprove DPP modeling. Our findings suggest that, despite the success of deep\nrepresentations, it remains necessary to combine them with surface indicators\nfor effective identification of summary sentences.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 20:14:12 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Cho", "Sangwoo", ""], ["Li", "Chen", ""], ["Yu", "Dong", ""], ["Foroosh", "Hassan", ""], ["Liu", "Fei", ""]]}, {"id": "1910.11424", "submitter": "Abhinav Gupta", "authors": "Cinjon Resnick, Abhinav Gupta, Jakob Foerster, Andrew M. Dai,\n  Kyunghyun Cho", "title": "Capacity, Bandwidth, and Compositionality in Emergent Language Learning", "comments": "The first two authors contributed equally. Accepted at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works have discussed the propensity, or lack thereof, for\nemergent languages to exhibit properties of natural languages. A favorite in\nthe literature is learning compositionality. We note that most of those works\nhave focused on communicative bandwidth as being of primary importance. While\nimportant, it is not the only contributing factor. In this paper, we\ninvestigate the learning biases that affect the efficacy and compositionality\nof emergent languages. Our foremost contribution is to explore how capacity of\na neural network impacts its ability to learn a compositional language. We\nadditionally introduce a set of evaluation metrics with which we analyze the\nlearned languages. Our hypothesis is that there should be a specific range of\nmodel capacity and channel bandwidth that induces compositional structure in\nthe resulting language and consequently encourages systematic generalization.\nWhile we empirically see evidence for the bottom of this range, we curiously do\nnot find evidence for the top part of the range and believe that this is an\nopen question for the community.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 21:06:38 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 22:36:24 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 07:54:53 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Resnick", "Cinjon", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Dai", "Andrew M.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1910.11450", "submitter": "Hongzhao Huang", "authors": "Hongzhao Huang and Fuchun Peng", "title": "An Empirical Study of Efficient ASR Rescoring with Transformers", "comments": "5 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) have been proved to significantly outperform\nclassical n-gram LMs for language modeling due to their superior abilities to\nmodel long-range dependencies in text and handle data sparsity problems. And\nrecently, well configured deep Transformers have exhibited superior performance\nover shallow stack of recurrent neural network layers for language modeling.\nHowever, these state-of-the-art deep Transformer models were mostly engineered\nto be deep with high model capacity, which makes it computationally inefficient\nand challenging to be deployed into large-scale real-world applications.\nTherefore, it is important to develop Transformer LMs that have relatively\nsmall model sizes, while still retaining good performance of those much larger\nmodels. In this paper, we aim to conduct empirical study on training\nTransformers with small parameter sizes in the context of ASR rescoring. By\ncombining techniques including subword units, adaptive softmax, large-scale\nmodel pre-training, and knowledge distillation, we show that we are able to\nsuccessfully train small Transformer LMs with significant relative word error\nrate reductions (WERR) through n-best rescoring. In particular, our experiments\non a video speech recognition dataset show that we are able to achieve WERRs\nranging from 6.46% to 7.17% while only with 5.5% to 11.9% parameter sizes of\nthe well-known large GPT model [1], whose WERR with rescoring on the same\ndataset is 7.58%.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 23:00:12 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Huang", "Hongzhao", ""], ["Peng", "Fuchun", ""]]}, {"id": "1910.11455", "submitter": "Arun Narayanan", "authors": "Arun Narayanan, Rohit Prabhavalkar, Chung-Cheng Chiu, David Rybach,\n  Tara N. Sainath, Trevor Strohman", "title": "Recognizing long-form speech using streaming end-to-end models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All-neural end-to-end (E2E) automatic speech recognition (ASR) systems that\nuse a single neural network to transduce audio to word sequences have been\nshown to achieve state-of-the-art results on several tasks. In this work, we\nexamine the ability of E2E models to generalize to unseen domains, where we\nfind that models trained on short utterances fail to generalize to long-form\nspeech. We propose two complementary solutions to address this: training on\ndiverse acoustic data, and LSTM state manipulation to simulate long-form audio\nwhen training using short utterances. On a synthesized long-form test set,\nadding data diversity improves word error rate (WER) by 90% relative, while\nsimulating long-form training improves it by 67% relative, though the\ncombination doesn't improve over data diversity alone. On a real long-form\ncall-center test set, adding data diversity improves WER by 40% relative.\nSimulating long-form training on top of data diversity improves performance by\nan additional 27% relative.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 23:18:07 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Narayanan", "Arun", ""], ["Prabhavalkar", "Rohit", ""], ["Chiu", "Chung-Cheng", ""], ["Rybach", "David", ""], ["Sainath", "Tara N.", ""], ["Strohman", "Trevor", ""]]}, {"id": "1910.11470", "submitter": "Vikas Yadav", "authors": "Vikas Yadav and Steven Bethard", "title": "A Survey on Recent Advances in Named Entity Recognition from Deep\n  Learning models", "comments": "Published at COLING 2018", "journal-ref": null, "doi": null, "report-no": "C18-1182", "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) is a key component in NLP systems for question\nanswering, information retrieval, relation extraction, etc. NER systems have\nbeen studied and developed widely for decades, but accurate systems using deep\nneural networks (NN) have only been introduced in the last few years. We\npresent a comprehensive survey of deep neural network architectures for NER,\nand contrast them with previous approaches to NER based on feature engineering\nand other supervised or semi-supervised learning algorithms. Our results\nhighlight the improvements achieved by neural networks, and show how\nincorporating some of the lessons learned from past work on feature-based NER\nsystems can yield further improvements.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 00:45:48 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Yadav", "Vikas", ""], ["Bethard", "Steven", ""]]}, {"id": "1910.11471", "submitter": "K.M. Tahsin Hassan Rahit", "authors": "K.M. Tahsin Hassan Rahit, Rashidul Hasan Nabil and Md Hasibul Huq", "title": "Machine Translation from Natural Language to Code using Long-Short Term\n  Memory", "comments": "8 pages, 3 figures, conference", "journal-ref": "Proceedings of the Future Technologies Conference (FTC) 2019.\n  Advances in Intelligent Systems and Computing, vol 1069. Springer, Cham", "doi": "10.1007/978-3-030-32520-6_6", "report-no": null, "categories": "cs.CL cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making computer programming language more understandable and easy for the\nhuman is a longstanding problem. From assembly language to present day's\nobject-oriented programming, concepts came to make programming easier so that a\nprogrammer can focus on the logic and the architecture rather than the code and\nlanguage itself. To go a step further in this journey of removing\nhuman-computer language barrier, this paper proposes machine learning approach\nusing Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) to\nconvert human language into programming language code. The programmer will\nwrite expressions for codes in layman's language, and the machine learning\nmodel will translate it to the targeted programming language. The proposed\napproach yields result with 74.40% accuracy. This can be further improved by\nincorporating additional techniques, which are also discussed in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 00:46:07 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Rahit", "K. M. Tahsin Hassan", ""], ["Nabil", "Rashidul Hasan", ""], ["Huq", "Md Hasibul", ""]]}, {"id": "1910.11473", "submitter": "Tushar Khot", "authors": "Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, and Ashish\n  Sabharwal", "title": "QASC: A Dataset for Question Answering via Sentence Composition", "comments": "AAAI-20 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composing knowledge from multiple pieces of texts is a key challenge in\nmulti-hop question answering. We present a multi-hop reasoning dataset,\nQuestion Answering via Sentence Composition(QASC), that requires retrieving\nfacts from a large corpus and composing them to answer a multiple-choice\nquestion. QASC is the first dataset to offer two desirable properties: (a) the\nfacts to be composed are annotated in a large corpus, and (b) the decomposition\ninto these facts is not evident from the question itself. The latter makes\nretrieval challenging as the system must introduce new concepts or relations in\norder to discover potential decompositions. Further, the reasoning model must\nthen learn to identify valid compositions of these retrieved facts using\ncommon-sense reasoning. To help address these challenges, we provide annotation\nfor supporting facts as well as their composition. Guided by these annotations,\nwe present a two-step approach to mitigate the retrieval challenges. We use\nother multiple-choice datasets as additional training data to strengthen the\nreasoning model. Our proposed approach improves over current state-of-the-art\nlanguage models by 11% (absolute). The reasoning and retrieval problems,\nhowever, remain unsolved as this model still lags by 20% behind human\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:02:18 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 23:43:26 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Khot", "Tushar", ""], ["Clark", "Peter", ""], ["Guerquin", "Michal", ""], ["Jansen", "Peter", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "1910.11476", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Jingrong Feng, Yuxian Meng, Qinghong Han, Fei Wu and Jiwei\n  Li", "title": "A Unified MRC Framework for Named Entity Recognition", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of named entity recognition (NER) is normally divided into nested\nNER and flat NER depending on whether named entities are nested or not. Models\nare usually separately developed for the two tasks, since sequence labeling\nmodels, the most widely used backbone for flat NER, are only able to assign a\nsingle label to a particular token, which is unsuitable for nested NER where a\ntoken may be assigned several labels.\n  In this paper, we propose a unified framework that is capable of handling\nboth flat and nested NER tasks. Instead of treating the task of NER as a\nsequence labeling problem, we propose to formulate it as a machine reading\ncomprehension (MRC) task. For example, extracting entities with the\n\\textsc{per} label is formalized as extracting answer spans to the question\n\"{\\it which person is mentioned in the text?}\". This formulation naturally\ntackles the entity overlapping issue in nested NER: the extraction of two\noverlapping entities for different categories requires answering two\nindependent questions. Additionally, since the query encodes informative prior\nknowledge, this strategy facilitates the process of entity extraction, leading\nto better performances for not only nested NER, but flat NER.\n  We conduct experiments on both {\\em nested} and {\\em flat} NER datasets.\nExperimental results demonstrate the effectiveness of the proposed formulation.\nWe are able to achieve vast amount of performance boost over current SOTA\nmodels on nested NER datasets, i.e., +1.28, +2.55, +5.44, +6.37, respectively\non ACE04, ACE05, GENIA and KBP17, along with SOTA results on flat NER datasets,\ni.e.,+0.24, +1.95, +0.21, +1.49 respectively on English CoNLL 2003, English\nOntoNotes 5.0, Chinese MSRA, Chinese OntoNotes 4.0.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:06:07 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 01:26:30 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 10:30:04 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 07:24:34 GMT"}, {"version": "v5", "created": "Thu, 21 May 2020 09:01:21 GMT"}, {"version": "v6", "created": "Sat, 23 May 2020 11:03:34 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Xiaoya", ""], ["Feng", "Jingrong", ""], ["Meng", "Yuxian", ""], ["Han", "Qinghong", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "1910.11483", "submitter": "Woon Sang Cho", "authors": "Woon Sang Cho, Yizhe Zhang, Sudha Rao, Chris Brockett, Sungjin Lee", "title": "Generating a Common Question from Multiple Documents using Multi-source\n  Encoder-Decoder Models", "comments": "Accepted at EMNLP-IJCNLP 2019 - The 3rd Workshop on Neural Generation\n  and Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambiguous user queries in search engines result in the retrieval of documents\nthat often span multiple topics. One potential solution is for the search\nengine to generate multiple refined queries, each of which relates to a subset\nof the documents spanning the same topic. A preliminary step towards this goal\nis to generate a question that captures common concepts of multiple documents.\nWe propose a new task of generating common question from multiple documents and\npresent simple variant of an existing multi-source encoder-decoder framework,\ncalled the Multi-Source Question Generator (MSQG). We first train an RNN-based\nsingle encoder-decoder generator from (single document, question) pairs. At\ntest time, given multiple documents, the 'Distribute' step of our MSQG model\npredicts target word distributions for each document using the trained model.\nThe 'Aggregate' step aggregates these distributions to generate a common\nquestion. This simple yet effective strategy significantly outperforms several\nexisting baseline models applied to the new task when evaluated using automated\nmetrics and human judgments on the MS-MARCO-QA dataset.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:35:14 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Cho", "Woon Sang", ""], ["Zhang", "Yizhe", ""], ["Rao", "Sudha", ""], ["Brockett", "Chris", ""], ["Lee", "Sungjin", ""]]}, {"id": "1910.11491", "submitter": "Gui Min", "authors": "Min Gui, Junfeng Tian, Rui Wang, Zhenglu Yang", "title": "Attention Optimization for Abstractive Document Summarization", "comments": null, "journal-ref": "Proceedings of the 2019 Conference on Empirical Methods in Natural\n  Language Processing and the 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP),", "doi": "10.18653/v1/D19-1117", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention plays a key role in the improvement of sequence-to-sequence-based\ndocument summarization models. To obtain a powerful attention helping with\nreproducing the most salient information and avoiding repetitions, we augment\nthe vanilla attention model from both local and global aspects. We propose an\nattention refinement unit paired with local variance loss to impose supervision\non the attention model at each decoding step, and a global variance loss to\noptimize the attention distributions of all decoding steps from the global\nperspective. The performances on the CNN/Daily Mail dataset verify the\neffectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:14:17 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Gui", "Min", ""], ["Tian", "Junfeng", ""], ["Wang", "Rui", ""], ["Yang", "Zhenglu", ""]]}, {"id": "1910.11493", "submitter": "Sabrina Mielke", "authors": "Arya D. McCarthy, Ekaterina Vylomova, Shijie Wu, Chaitanya Malaviya,\n  Lawrence Wolf-Sonkin, Garrett Nicolai, Christo Kirov, Miikka Silfverberg,\n  Sabrina J. Mielke, Jeffrey Heinz, Ryan Cotterell, Mans Hulden", "title": "The SIGMORPHON 2019 Shared Task: Morphological Analysis in Context and\n  Cross-Lingual Transfer for Inflection", "comments": "Presented at SIGMORPHON 2019", "journal-ref": "Proceedings of the 16th Workshop on Computational Research in\n  Phonetics, Phonology, and Morphology (2019) 229-244", "doi": "10.18653/v1/W19-4226", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SIGMORPHON 2019 shared task on cross-lingual transfer and contextual\nanalysis in morphology examined transfer learning of inflection between 100\nlanguage pairs, as well as contextual lemmatization and morphosyntactic\ndescription in 66 languages. The first task evolves past years' inflection\ntasks by examining transfer of morphological inflection knowledge from a\nhigh-resource language to a low-resource language. This year also presents a\nnew second challenge on lemmatization and morphological feature analysis in\ncontext. All submissions featured a neural component and built on either this\nyear's strong baselines or highly ranked systems from previous years' shared\ntasks. Every participating team improved in accuracy over the baselines for the\ninflection task (though not Levenshtein distance), and every team in the\ncontextual analysis task improved on both state-of-the-art neural and\nnon-neural baselines.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:20:06 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:41:48 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["McCarthy", "Arya D.", ""], ["Vylomova", "Ekaterina", ""], ["Wu", "Shijie", ""], ["Malaviya", "Chaitanya", ""], ["Wolf-Sonkin", "Lawrence", ""], ["Nicolai", "Garrett", ""], ["Kirov", "Christo", ""], ["Silfverberg", "Miikka", ""], ["Mielke", "Sabrina J.", ""], ["Heinz", "Jeffrey", ""], ["Cotterell", "Ryan", ""], ["Hulden", "Mans", ""]]}, {"id": "1910.11494", "submitter": "Jianxun Lian", "authors": "Danyang Liu, Jianxun Lian, Shiyin Wang, Ying Qiao, Jiun-Hung Chen,\n  Guangzhong Sun, Xing Xie", "title": "KRED: Knowledge-Aware Document Representation for News Recommendations", "comments": "RecSys'20", "journal-ref": null, "doi": "10.1145/3383313.3412237", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News articles usually contain knowledge entities such as celebrities or\norganizations. Important entities in articles carry key messages and help to\nunderstand the content in a more direct way. An industrial news recommender\nsystem contains various key applications, such as personalized recommendation,\nitem-to-item recommendation, news category classification, news popularity\nprediction and local news detection. We find that incorporating knowledge\nentities for better document understanding benefits these applications\nconsistently. However, existing document understanding models either represent\nnews articles without considering knowledge entities (e.g., BERT) or rely on a\nspecific type of text encoding model (e.g., DKN) so that the generalization\nability and efficiency is compromised. In this paper, we propose KRED, which is\na fast and effective model to enhance arbitrary document representation with a\nknowledge graph. KRED first enriches entities' embeddings by attentively\naggregating information from their neighborhood in the knowledge graph. Then a\ncontext embedding layer is applied to annotate the dynamic context of different\nentities such as frequency, category and position. Finally, an information\ndistillation layer aggregates the entity embeddings under the guidance of the\noriginal document representation and transforms the document vector into a new\none. We advocate to optimize the model with a multi-task framework, so that\ndifferent news recommendation applications can be united and useful information\ncan be shared across different tasks. Experiments on a real-world Microsoft\nNews dataset demonstrate that KRED greatly benefits a variety of news\nrecommendation applications.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:21:33 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 12:03:47 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 11:25:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Liu", "Danyang", ""], ["Lian", "Jianxun", ""], ["Wang", "Shiyin", ""], ["Qiao", "Ying", ""], ["Chen", "Jiun-Hung", ""], ["Sun", "Guangzhong", ""], ["Xie", "Xing", ""]]}, {"id": "1910.11496", "submitter": "Yuanfeng Song", "authors": "Yuanfeng Song, Di Jiang, Xuefang Zhao, Qian Xu, Raymond Chi-Wing Wong,\n  Lixin Fan, Qiang Yang", "title": "L2RS: A Learning-to-Rescore Mechanism for Automatic Speech Recognition", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Automatic Speech Recognition (ASR) systems primarily rely on scores\nfrom an Acoustic Model (AM) and a Language Model (LM) to rescore the N-best\nlists. With the abundance of recent natural language processing advances, the\ninformation utilized by current ASR for evaluating the linguistic and semantic\nlegitimacy of the N-best hypotheses is rather limited. In this paper, we\npropose a novel Learning-to-Rescore (L2RS) mechanism, which is specialized for\nutilizing a wide range of textual information from the state-of-the-art NLP\nmodels and automatically deciding their weights to rescore the N-best lists for\nASR systems. Specifically, we incorporate features including BERT sentence\nembedding, topic vector, and perplexity scores produced by n-gram LM, topic\nmodeling LM, BERT LM and RNNLM to train a rescoring model. We conduct extensive\nexperiments based on a public dataset, and experimental results show that L2RS\noutperforms not only traditional rescoring methods but also its deep neural\nnetwork counterparts by a substantial improvement of 20.67% in terms of\nNDCG@10. L2RS paves the way for developing more effective rescoring models for\nASR.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 02:25:34 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Song", "Yuanfeng", ""], ["Jiang", "Di", ""], ["Zhao", "Xuefang", ""], ["Xu", "Qian", ""], ["Wong", "Raymond Chi-Wing", ""], ["Fan", "Lixin", ""], ["Yang", "Qiang", ""]]}, {"id": "1910.11536", "submitter": "Yash Shah", "authors": "Yash Shah, Ishan Tarunesh, Harsh Deshpande, Preethi Jyothi", "title": "Stem-driven Language Models for Morphologically Rich Languages", "comments": "5 pages, 3 figures, under review at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) have shown to benefit significantly from\nenhancing word vectors with subword-level information, especially for\nmorphologically rich languages. This has been mainly tackled by providing\nsubword-level information as an input; using subword units in the output layer\nhas been far less explored. In this work, we propose LMs that are cognizant of\nthe underlying stems in each word. We derive stems for words using a simple\nunsupervised technique for stem identification. We experiment with different\narchitectures involving multi-task learning and mixture models over words and\nstems. We focus on four morphologically complex languages -- Hindi, Tamil,\nKannada and Finnish -- and observe significant perplexity gains with using our\nstem-driven LMs when compared with other competitive baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 05:35:36 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Shah", "Yash", ""], ["Tarunesh", "Ishan", ""], ["Deshpande", "Harsh", ""], ["Jyothi", "Preethi", ""]]}, {"id": "1910.11555", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Zhuohan Li, Haoqing Wang, Zi Lin, Di He, Zhi-Hong Deng", "title": "Fast Structured Decoding for Sequence Models", "comments": "Accepted to NeurIPS 2019 (Previous title: Structured Decoding for\n  Non-Autoregressive Machine Translation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive sequence models achieve state-of-the-art performance in\ndomains like machine translation. However, due to the autoregressive\nfactorization nature, these models suffer from heavy latency during inference.\nRecently, non-autoregressive sequence models were proposed to reduce the\ninference time. However, these models assume that the decoding process of each\ntoken is conditionally independent of others. Such a generation process\nsometimes makes the output sentence inconsistent, and thus the learned\nnon-autoregressive models could only achieve inferior accuracy compared to\ntheir autoregressive counterparts. To improve then decoding consistency and\nreduce the inference cost at the same time, we propose to incorporate a\nstructured inference module into the non-autoregressive models. Specifically,\nwe design an efficient approximation for Conditional Random Fields (CRF) for\nnon-autoregressive sequence models, and further propose a dynamic transition\ntechnique to model positional contexts in the CRF. Experiments in machine\ntranslation show that while increasing little latency (8~14ms), our model could\nachieve significantly better translation performance than previous\nnon-autoregressive models on different translation datasets. In particular, for\nthe WMT14 En-De dataset, our model obtains a BLEU score of 26.80, which largely\noutperforms the previous non-autoregressive baselines and is only 0.61 lower in\nBLEU than purely autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:32:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 08:25:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Sun", "Zhiqing", ""], ["Li", "Zhuohan", ""], ["Wang", "Haoqing", ""], ["Lin", "Zi", ""], ["He", "Di", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1910.11559", "submitter": "Yung-Sung Chuang", "authors": "Yung-Sung Chuang, Chi-Liang Liu, Hung-Yi Lee, Lin-shan Lee", "title": "SpeechBERT: An Audio-and-text Jointly Learned Language Model for\n  End-to-end Spoken Question Answering", "comments": "Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While various end-to-end models for spoken language understanding tasks have\nbeen explored recently, this paper is probably the first known attempt to\nchallenge the very difficult task of end-to-end spoken question answering\n(SQA). Learning from the very successful BERT model for various text processing\ntasks, here we proposed an audio-and-text jointly learned SpeechBERT model.\nThis model outperformed the conventional approach of cascading ASR with the\nfollowing text question answering (TQA) model on datasets including ASR errors\nin answer spans, because the end-to-end model was shown to be able to extract\ninformation out of audio data before ASR produced errors. When ensembling the\nproposed end-to-end model with the cascade architecture, even better\nperformance was achieved. In addition to the potential of end-to-end SQA, the\nSpeechBERT can also be considered for many other spoken language understanding\ntasks just as BERT for many text processing tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:46:39 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 13:35:40 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 06:03:29 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 05:48:36 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Chuang", "Yung-Sung", ""], ["Liu", "Chi-Liang", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1910.11621", "submitter": "Shumin Deng", "authors": "Shumin Deng, Ningyu Zhang, Jiaojian Kang, Yichi Zhang, Wei Zhang,\n  Huajun Chen", "title": "Meta-Learning with Dynamic-Memory-Based Prototypical Network for\n  Few-Shot Event Detection", "comments": "Accepted by WSDM 2020", "journal-ref": null, "doi": "10.1145/3336191.3371796", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection (ED), a sub-task of event extraction, involves identifying\ntriggers and categorizing event mentions. Existing methods primarily rely upon\nsupervised learning and require large-scale labeled event datasets which are\nunfortunately not readily available in many real-life applications. In this\npaper, we consider and reformulate the ED task with limited labeled data as a\nFew-Shot Learning problem. We propose a Dynamic-Memory-Based Prototypical\nNetwork (DMB-PN), which exploits Dynamic Memory Network (DMN) to not only learn\nbetter prototypes for event types, but also produce more robust sentence\nencodings for event mentions. Differing from vanilla prototypical networks\nsimply computing event prototypes by averaging, which only consume event\nmentions once, our model is more robust and is capable of distilling contextual\ninformation from event mentions for multiple times due to the multi-hop\nmechanism of DMNs. The experiments show that DMB-PN not only deals with sample\nscarcity better than a series of baseline models but also performs more\nrobustly when the variety of event types is relatively large and the instance\nquantity is extremely small.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 11:14:33 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 15:27:52 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Deng", "Shumin", ""], ["Zhang", "Ningyu", ""], ["Kang", "Jiaojian", ""], ["Zhang", "Yichi", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "1910.11691", "submitter": "Andreas Stolcke", "authors": "Andreas Stolcke", "title": "Improving Diarization Robustness using Diversification, Randomization\n  and the DOVER Algorithm", "comments": "Revised and expanded. To appear in Proc. Odyssey Speaker and Language\n  Recognition Workshop. arXiv admin note: text overlap with arXiv:1909.08090", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization based on bottom-up clustering of speech segments by\nacoustic similarity is often highly sensitive to the choice of hyperparameters,\nsuch as the initial number of clusters and feature weighting. Optimizing these\nhyperparameters is difficult and often not robust across different data sets.\nWe recently proposed the DOVER algorithm for combining multiple diarization\nhypotheses by voting. Here we propose to mitigate the robustness problem in\ndiarization by using DOVER to average across different parameter choices. We\nalso investigate the combination of diverse outputs obtained by following\ndifferent merge choices pseudo-randomly in the course of clustering, thereby\nmitigating the greediness of best-first clustering. We show on two conference\nmeeting data sets drawn from NIST evaluations that the proposed methods indeed\nyield more robust, and in several cases overall improved, results.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 01:57:34 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 05:03:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Stolcke", "Andreas", ""]]}, {"id": "1910.11768", "submitter": "Muhammad Osama", "authors": "Chen Liu, Anderson de Andrade, Muhammad Osama", "title": "Exploring Multilingual Syntactic Sentence Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for learning sentence embeddings with syntactic structure.\nWe focus on methods of learning syntactic sentence-embeddings by using a\nmultilingual parallel-corpus augmented by Universal Parts-of-Speech tags. We\nevaluate the quality of the learned embeddings by examining sentence-level\nnearest neighbours and functional dissimilarity in the embedding space. We also\nevaluate the ability of the method to learn syntactic sentence-embeddings for\nlow-resource languages and demonstrate strong evidence for transfer learning.\nOur results show that syntactic sentence-embeddings can be learned while using\nless training data, fewer model parameters, and resulting in better evaluation\nmetrics than state-of-the-art language models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:38:18 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Liu", "Chen", ""], ["de Andrade", "Anderson", ""], ["Osama", "Muhammad", ""]]}, {"id": "1910.11769", "submitter": "Muhammad Osama", "authors": "Chen Liu, Muhammad Osama, Anderson de Andrade", "title": "DENS: A Dataset for Multi-class Emotion Analysis", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new dataset for multi-class emotion analysis from long-form\nnarratives in English. The Dataset for Emotions of Narrative Sequences (DENS)\nwas collected from both classic literature available on Project Gutenberg and\nmodern online narratives available on Wattpad, annotated using Amazon\nMechanical Turk. A number of statistics and baseline benchmarks are provided\nfor the dataset. Of the tested techniques, we find that the fine-tuning of a\npre-trained BERT model achieves the best results, with an average micro-F1\nscore of 60.4%. Our results show that the dataset provides a novel opportunity\nin emotion analysis that requires moving beyond existing sentence-level\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 14:40:14 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Liu", "Chen", ""], ["Osama", "Muhammad", ""], ["de Andrade", "Anderson", ""]]}, {"id": "1910.11790", "submitter": "Michael Sigamani", "authors": "Keith Vella, Massimo Poesio, Michael Sigamani, Cihan Dogan, Aimore\n  Dutra, Dimitrios Dimakopoulos, Alfredo Gemma, Ella Walters", "title": "Measuring Conversational Fluidity in Automated Dialogue Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an automated evaluation method to measure fluidity in\nconversational dialogue systems. The method combines various state of the art\nNatural Language tools into a classifier, and human ratings on these dialogues\nto train an automated judgment model. Our experiments show that the results are\nan improvement on existing metrics for measuring fluidity.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 15:15:44 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Vella", "Keith", ""], ["Poesio", "Massimo", ""], ["Sigamani", "Michael", ""], ["Dogan", "Cihan", ""], ["Dutra", "Aimore", ""], ["Dimakopoulos", "Dimitrios", ""], ["Gemma", "Alfredo", ""], ["Walters", "Ella", ""]]}, {"id": "1910.11834", "submitter": "S{\\l}awomir Dadas", "authors": "S{\\l}awomir Dadas, Micha{\\l} Pere{\\l}kiewicz, Rafa{\\l} Po\\'swiata", "title": "Evaluation of Sentence Representations in Polish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for learning sentence representations have been actively developed in\nrecent years. However, the lack of pre-trained models and datasets annotated at\nthe sentence level has been a problem for low-resource languages such as Polish\nwhich led to less interest in applying these methods to language-specific\ntasks. In this study, we introduce two new Polish datasets for evaluating\nsentence embeddings and provide a comprehensive evaluation of eight sentence\nrepresentation methods including Polish and multilingual models. We consider\nclassic word embedding models, recently developed contextual embeddings and\nmultilingual sentence encoders, showing strengths and weaknesses of specific\napproaches. We also examine different methods of aggregating word vectors into\na single sentence vector.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 16:35:47 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 11:20:27 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Dadas", "S\u0142awomir", ""], ["Pere\u0142kiewicz", "Micha\u0142", ""], ["Po\u015bwiata", "Rafa\u0142", ""]]}, {"id": "1910.11856", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama", "title": "On the Cross-lingual Transferability of Monolingual Representations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art unsupervised multilingual models (e.g., multilingual BERT)\nhave been shown to generalize in a zero-shot cross-lingual setting. This\ngeneralization ability has been attributed to the use of a shared subword\nvocabulary and joint training across multiple languages giving rise to deep\nmultilingual abstractions. We evaluate this hypothesis by designing an\nalternative approach that transfers a monolingual model to new languages at the\nlexical level. More concretely, we first train a transformer-based masked\nlanguage model on one language, and transfer it to a new language by learning a\nnew embedding matrix with the same masked language modeling objective, freezing\nparameters of all other layers. This approach does not rely on a shared\nvocabulary or joint training. However, we show that it is competitive with\nmultilingual BERT on standard cross-lingual classification benchmarks and on a\nnew Cross-lingual Question Answering Dataset (XQuAD). Our results contradict\ncommon beliefs of the basis of the generalization ability of multilingual\nmodels and suggest that deep monolingual models learn some abstractions that\ngeneralize across languages. We also release XQuAD as a more comprehensive\ncross-lingual benchmark, which comprises 240 paragraphs and 1190\nquestion-answer pairs from SQuAD v1.1 translated into ten languages by\nprofessional translators.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:30:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:55:33 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 22:45:22 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Artetxe", "Mikel", ""], ["Ruder", "Sebastian", ""], ["Yogatama", "Dani", ""]]}, {"id": "1910.11871", "submitter": "Emiru Tsunoo", "authors": "Emiru Tsunoo, Yosuke Kashiwagi, Toshiyuki Kumakura, Shinji Watanabe", "title": "Towards Online End-to-end Transformer Automatic Speech Recognition", "comments": "arXiv admin note: text overlap with arXiv:1910.07204", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer self-attention network has recently shown promising\nperformance as an alternative to recurrent neural networks in end-to-end (E2E)\nautomatic speech recognition (ASR) systems. However, Transformer has a drawback\nin that the entire input sequence is required to compute self-attention. We\nhave proposed a block processing method for the Transformer encoder by\nintroducing a context-aware inheritance mechanism. An additional context\nembedding vector handed over from the previously processed block helps to\nencode not only local acoustic information but also global linguistic, channel,\nand speaker attributes. In this paper, we extend it towards an entire online\nE2E ASR system by introducing an online decoding process inspired by monotonic\nchunkwise attention (MoChA) into the Transformer decoder. Our novel MoChA\ntraining and inference algorithms exploit the unique properties of Transformer,\nwhose attentions are not always monotonic or peaky, and have multiple heads and\nresidual connections of the decoder layers. Evaluations of the Wall Street\nJournal (WSJ) and AISHELL-1 show that our proposed online Transformer decoder\noutperforms conventional chunkwise approaches.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 05:28:17 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tsunoo", "Emiru", ""], ["Kashiwagi", "Yosuke", ""], ["Kumakura", "Toshiyuki", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1910.11922", "submitter": "Chris Emmery", "authors": "Chris Emmery, Ben Verhoeven, Guy De Pauw, Gilles Jacobs, Cynthia Van\n  Hee, Els Lefever, Bart Desmet, V\\'eronique Hoste, Walter Daelemans", "title": "Current Limitations in Cyberbullying Detection: on Evaluation Criteria,\n  Reproducibility, and Data Scarcity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The detection of online cyberbullying has seen an increase in societal\nimportance, popularity in research, and available open data. Nevertheless,\nwhile computational power and affordability of resources continue to increase,\nthe access restrictions on high-quality data limit the applicability of\nstate-of-the-art techniques. Consequently, much of the recent research uses\nsmall, heterogeneous datasets, without a thorough evaluation of applicability.\nIn this paper, we further illustrate these issues, as we (i) evaluate many\npublicly available resources for this task and demonstrate difficulties with\ndata collection. These predominantly yield small datasets that fail to capture\nthe required complex social dynamics and impede direct comparison of progress.\nWe (ii) conduct an extensive set of experiments that indicate a general lack of\ncross-domain generalization of classifiers trained on these sources, and openly\nprovide this framework to replicate and extend our evaluation criteria.\nFinally, we (iii) present an effective crowdsourcing method: simulating\nreal-life bullying scenarios in a lab setting generates plausible data that can\nbe effectively used to enrich real data. This largely circumvents the\nrestrictions on data that can be collected, and increases classifier\nperformance. We believe these contributions can aid in improving the empirical\npractices of future research in the field.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 20:15:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Emmery", "Chris", ""], ["Verhoeven", "Ben", ""], ["De Pauw", "Guy", ""], ["Jacobs", "Gilles", ""], ["Van Hee", "Cynthia", ""], ["Lefever", "Els", ""], ["Desmet", "Bart", ""], ["Hoste", "V\u00e9ronique", ""], ["Daelemans", "Walter", ""]]}, {"id": "1910.11932", "submitter": "Silviu Oprea", "authors": "Silviu Oprea and Walid Magdy", "title": "Exploring Author Context for Detecting Intended vs Perceived Sarcasm", "comments": "6 pages, 1 figure, ACL 2020", "journal-ref": "Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics, 2019, pages 2854-2859", "doi": "10.18653/v1/P19-1275", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the impact of using author context on textual sarcasm\ndetection. We define author context as the embedded representation of their\nhistorical posts on Twitter and suggest neural models that extract these\nrepresentations. We experiment with two tweet datasets, one labelled manually\nfor sarcasm, and the other via tag-based distant supervision. We achieve\nstate-of-the-art performance on the second dataset, but not on the one labelled\nmanually, indicating a difference between intended sarcasm, captured by distant\nsupervision, and perceived sarcasm, captured by manual labelling.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 20:59:09 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Oprea", "Silviu", ""], ["Magdy", "Walid", ""]]}, {"id": "1910.11949", "submitter": "Mariona Car\\'os Roca", "authors": "Mariona Caros, Maite Garolera, Petia Radeva and Xavier Giro-i-Nieto", "title": "Automatic Reminiscence Therapy for Dementia", "comments": "MSc thesis at TelecomBCN, Universitat Politecnica de Catalunya 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With people living longer than ever, the number of cases with dementia such\nas Alzheimer's disease increases steadily. It affects more than 46 million\npeople worldwide, and it is estimated that in 2050 more than 100 million will\nbe affected. While there are not effective treatments for these terminal\ndiseases, therapies such as reminiscence, that stimulate memories from the past\nare recommended. Currently, reminiscence therapy takes place in care homes and\nis guided by a therapist or a carer. In this work, we present an AI-based\nsolution to automatize the reminiscence therapy, which consists in a dialogue\nsystem that uses photos as input to generate questions. We run a usability case\nstudy with patients diagnosed of mild cognitive impairment that shows they\nfound the system very entertaining and challenging. Overall, this paper\npresents how reminiscence therapy can be automatized by using machine learning,\nand deployed to smartphones and laptops, making the therapy more accessible to\nevery person affected by dementia.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 21:47:52 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 12:26:15 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Caros", "Mariona", ""], ["Garolera", "Maite", ""], ["Radeva", "Petia", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "1910.11959", "submitter": "Yunzhe Tao", "authors": "Yunzhe Tao, Saurabh Gupta, Satyapriya Krishna, Xiong Zhou, Orchid\n  Majumder, Vineet Khare", "title": "FineText: Text Classification via Attention-based Language Model\n  Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks from scratch on natural language processing\n(NLP) tasks requires significant amount of manually labeled text corpus and\nsubstantial time to converge, which usually cannot be satisfied by the\ncustomers. In this paper, we aim to develop an effective transfer learning\nalgorithm by fine-tuning a pre-trained language model. The goal is to provide\nexpressive and convenient-to-use feature extractors for downstream NLP tasks,\nand achieve improvement in terms of accuracy, data efficiency, and\ngeneralization to new domains. Therefore, we propose an attention-based\nfine-tuning algorithm that automatically selects relevant contextualized\nfeatures from the pre-trained language model and uses those features on\ndownstream text classification tasks. We test our methods on six widely-used\nbenchmarking datasets, and achieve new state-of-the-art performance on all of\nthem. Moreover, we then introduce an alternative multi-task learning approach,\nwhich is an end-to-end algorithm given the pre-trained model. By doing\nmulti-task learning, one can largely reduce the total training time by trading\noff some classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 23:13:15 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tao", "Yunzhe", ""], ["Gupta", "Saurabh", ""], ["Krishna", "Satyapriya", ""], ["Zhou", "Xiong", ""], ["Majumder", "Orchid", ""], ["Khare", "Vineet", ""]]}, {"id": "1910.11966", "submitter": "Gabriel Stanovsky", "authors": "Gabriel Stanovsky, Ronen Tamari", "title": "Yall should read this! Identifying Plurality in Second-Person Personal\n  Pronouns in English Texts", "comments": "Accepted to the 5th Workshop on Noisy User-generated Text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing between singular and plural \"you\" in English is a challenging\ntask which has potential for downstream applications, such as machine\ntranslation or coreference resolution. While formal written English does not\ndistinguish between these cases, other languages (such as Spanish), as well as\nother dialects of English (via phrases such as \"yall\"), do make this\ndistinction. We make use of this to obtain distantly-supervised labels for the\ntask on a large-scale in two domains. Following, we train a model to\ndistinguish between the single/plural you, finding that although in-domain\ntraining achieves reasonable accuracy (over 77%), there is still a lot of room\nfor improvement, especially in the domain-transfer scenario, which proves\nextremely challenging. Our code and data are publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 00:21:18 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Stanovsky", "Gabriel", ""], ["Tamari", "Ronen", ""]]}, {"id": "1910.12038", "submitter": "Lei Cao", "authors": "Lei Cao, Huijun Zhang, Ling Feng, Zihan Wei, Xin Wang, Ningyun Li,\n  Xiaohao He", "title": "Latent Suicide Risk Detection on Microblog via Suicide-Oriented Word\n  Embeddings and Layered Attention", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite detection of suicidal ideation on social media has made great\nprogress in recent years, people's implicitly and anti-real contrarily\nexpressed posts still remain as an obstacle, constraining the detectors to\nacquire higher satisfactory performance. Enlightened by the hidden \"tree holes\"\nphenomenon on microblog, where people at suicide risk tend to disclose their\ninner real feelings and thoughts to the microblog space whose authors have\ncommitted suicide, we explore the use of tree holes to enhance microblog-based\nsuicide risk detection from the following two perspectives. (1) We build\nsuicide-oriented word embeddings based on tree hole contents to strength the\nsensibility of suicide-related lexicons and context based on tree hole\ncontents. (2) A two-layered attention mechanism is deployed to grasp\nintermittently changing points from individual's open blog streams, revealing\none's inner emotional world more or less. Our experimental results show that\nwith suicide-oriented word embeddings and attention, microblog-based suicide\nrisk detection can achieve over 91\\% accuracy. A large-scale well-labelled\nsuicide data set is also reported in the paper.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 09:40:26 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cao", "Lei", ""], ["Zhang", "Huijun", ""], ["Feng", "Ling", ""], ["Wei", "Zihan", ""], ["Wang", "Xin", ""], ["Li", "Ningyun", ""], ["He", "Xiaohao", ""]]}, {"id": "1910.12073", "submitter": "Jillian Tompkins", "authors": "Jillian Tompkins", "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 14:29:37 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tompkins", "Jillian", ""]]}, {"id": "1910.12094", "submitter": "Jui-Yang Hsu", "authors": "Jui-Yang Hsu, Yuan-Jui Chen, Hung-yi Lee", "title": "Meta Learning for End-to-End Low-Resource Speech Recognition", "comments": "5 pages, submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we proposed to apply meta learning approach for low-resource\nautomatic speech recognition (ASR). We formulated ASR for different languages\nas different tasks, and meta-learned the initialization parameters from many\npretraining languages to achieve fast adaptation on unseen target language, via\nrecently proposed model-agnostic meta learning algorithm (MAML). We evaluated\nthe proposed approach using six languages as pretraining tasks and four\nlanguages as target tasks. Preliminary results showed that the proposed method,\nMetaASR, significantly outperforms the state-of-the-art multitask pretraining\napproach on all target languages with different combinations of pretraining\nlanguages. In addition, since MAML's model-agnostic property, this paper also\nopens new research direction of applying meta learning to more speech-related\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 16:00:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hsu", "Jui-Yang", ""], ["Chen", "Yuan-Jui", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1910.12129", "submitter": "Juraj Juraska", "authors": "Juraj Juraska, Kevin K. Bowden, Marilyn Walker", "title": "ViGGO: A Video Game Corpus for Data-To-Text Generation in Open-Domain\n  Conversation", "comments": "Accepted to INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uptake of deep learning in natural language generation (NLG) led to the\nrelease of both small and relatively large parallel corpora for training neural\nmodels. The existing data-to-text datasets are, however, aimed at task-oriented\ndialogue systems, and often thus limited in diversity and versatility. They are\ntypically crowdsourced, with much of the noise left in them. Moreover, current\nneural NLG models do not take full advantage of large training data, and due to\ntheir strong generalizing properties produce sentences that look template-like\nregardless. We therefore present a new corpus of 7K samples, which (1) is clean\ndespite being crowdsourced, (2) has utterances of 9 generalizable and\nconversational dialogue act types, making it more suitable for open-domain\ndialogue systems, and (3) explores the domain of video games, which is new to\ndialogue systems despite having excellent potential for supporting rich\nconversations.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 20:18:59 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Juraska", "Juraj", ""], ["Bowden", "Kevin K.", ""], ["Walker", "Marilyn", ""]]}, {"id": "1910.12180", "submitter": "Saeid Hosseini", "authors": "Saeed Najafipour, Saeid Hosseini, Wen Hua, Mohammad Reza Kangavari,\n  Xiaofang Zhou", "title": "SoulMate: Short-text author linking through Multi-aspect\n  temporal-textual embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking authors of short-text contents has important usages in many\napplications, including Named Entity Recognition (NER) and human community\ndetection. However, certain challenges lie ahead. Firstly, the input short-text\ncontents are noisy, ambiguous, and do not follow the grammatical rules.\nSecondly, traditional text mining methods fail to effectively extract concepts\nthrough words and phrases. Thirdly, the textual contents are temporally skewed,\nwhich can affect the semantic understanding by multiple time facets. Finally,\nusing the complementary knowledge-bases makes the results biased to the content\nof the external database and deviates the understanding and interpretation away\nfrom the real nature of the given short text corpus. To overcome these\nchallenges, we devise a neural network-based temporal-textual framework that\ngenerates the tightly connected author subgraphs from microblog short-text\ncontents. Our approach, on the one hand, computes the relevance score (edge\nweight) between the authors through considering a portmanteau of contents and\nconcepts, and on the other hand, employs a stack-wise graph cutting algorithm\nto extract the communities of the related authors. Experimental results show\nthat compared to other knowledge-centered competitors, our multi-aspect vector\nspace model can achieve a higher performance in linking short-text authors.\nAdditionally, given the author linking task, the more comprehensive the dataset\nis, the higher the significance of the extracted concepts will be.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 04:53:35 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Najafipour", "Saeed", ""], ["Hosseini", "Saeid", ""], ["Hua", "Wen", ""], ["Kangavari", "Mohammad Reza", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "1910.12196", "submitter": "Fanchao Qi", "authors": "Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun\n  Liu, Maosong Sun", "title": "Word-level Textual Adversarial Attacking as Combinatorial Optimization", "comments": "Accepted at ACL 2020 as a long paper (a typo is corrected as compared\n  with the official conference camera-ready version). 16 pages, 3 figures", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.540", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks are carried out to reveal the vulnerability of deep\nneural networks. Textual adversarial attacking is challenging because text is\ndiscrete and a small perturbation can bring significant change to the original\ninput. Word-level attacking, which can be regarded as a combinatorial\noptimization problem, is a well-studied class of textual attack methods.\nHowever, existing word-level attack models are far from perfect, largely\nbecause unsuitable search space reduction methods and inefficient optimization\nalgorithms are employed. In this paper, we propose a novel attack model, which\nincorporates the sememe-based word substitution method and particle swarm\noptimization-based search algorithm to solve the two problems separately. We\nconduct exhaustive experiments to evaluate our attack model by attacking BiLSTM\nand BERT on three benchmark datasets. Experimental results demonstrate that our\nmodel consistently achieves much higher attack success rates and crafts more\nhigh-quality adversarial examples as compared to baseline methods. Also,\nfurther experiments show our model has higher transferability and can bring\nmore robustness enhancement to victim models by adversarial training. All the\ncode and data of this paper can be obtained on\nhttps://github.com/thunlp/SememePSO-Attack.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:54:27 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 11:20:10 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 09:54:31 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 09:38:21 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Zang", "Yuan", ""], ["Qi", "Fanchao", ""], ["Yang", "Chenghao", ""], ["Liu", "Zhiyuan", ""], ["Zhang", "Meng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "1910.12197", "submitter": "Forough Arabshahi", "authors": "Zhichu Lu, Forough Arabshahi, Igor Labutov, Tom Mitchell", "title": "Look-up and Adapt: A One-shot Semantic Parser", "comments": "2019 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing devices have recently become capable of interacting with their end\nusers via natural language. However, they can only operate within a limited\n\"supported\" domain of discourse and fail drastically when faced with an\nout-of-domain utterance, mainly due to the limitations of their semantic\nparser. In this paper, we propose a semantic parser that generalizes to\nout-of-domain examples by learning a general strategy for parsing an unseen\nutterance through adapting the logical forms of seen utterances, instead of\nlearning to generate a logical form from scratch. Our parser maintains a memory\nconsisting of a representative subset of the seen utterances paired with their\nlogical forms. Given an unseen utterance, our parser works by looking up a\nsimilar utterance from the memory and adapting its logical form until it fits\nthe unseen utterance. Moreover, we present a data generation strategy for\nconstructing utterance-logical form pairs from different domains. Our results\nshow an improvement of up to 68.8% on one-shot parsing under two different\nevaluation settings compared to the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 06:56:43 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Lu", "Zhichu", ""], ["Arabshahi", "Forough", ""], ["Labutov", "Igor", ""], ["Mitchell", "Tom", ""]]}, {"id": "1910.12203", "submitter": "Vaibhav Vaibhav", "authors": "Vaibhav Vaibhav, Raghuram Mandyam Annasamy, Eduard Hovy", "title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "comments": "Accepted at TextGraphs - EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 07:44:33 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Vaibhav", "Vaibhav", ""], ["Annasamy", "Raghuram Mandyam", ""], ["Hovy", "Eduard", ""]]}, {"id": "1910.12274", "submitter": "Elad Yom-Tov", "authors": "Brit Youngmann, Ran Gilad-Bachrach, Danny Karmon, Elad Yom-Tov", "title": "Algorithmic Copywriting: Automated Generation of Health-Related\n  Advertisements to Improve their Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search advertising, a popular method for online marketing, has been employed\nto improve health by eliciting positive behavioral change. However, writing\neffective advertisements requires expertise and experimentation, which may not\nbe available to health authorities wishing to elicit such changes, especially\nwhen dealing with public health crises such as epidemic outbreaks.\n  Here we develop a framework, comprised of two neural networks models, that\nautomatically generate ads. First, it employs a generator model, which create\nads from web pages. It then employs a translation model, which transcribes ads\nto improve performance.\n  We trained the networks using 114K health-related ads shown on Microsoft\nAdvertising. We measure ads performance using the click-through rates (CTR).\n  Our experiments show that the generated advertisements received approximately\nthe same CTR as human-authored ads. The marginal contribution of the generator\nmodel was, on average, 28\\% lower than that of human-authored ads, while the\ntranslator model received, on average, 32\\% more clicks than human-authored\nads. Our analysis shows that the translator model produces ads reflecting\nhigher values of psychological attributes associated with a user action,\nincluding higher valance and arousal, and more calls-to-actions. In contrast,\nlevels of these attributes in ads produced by the generator model are similar\nto those of human-authored ads.\n  Our results demonstrate the ability to automatically generate useful\nadvertisements for the health domain. We believe that our work offers health\nauthorities an improved ability to nudge people towards healthier behaviors\nwhile saving the time and cost needed to build effective advertising campaigns.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 14:51:53 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 18:00:36 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 07:22:00 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Youngmann", "Brit", ""], ["Gilad-Bachrach", "Ran", ""], ["Karmon", "Danny", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1910.12279", "submitter": "Suryatej Vyalla", "authors": "Suryatej Reddy Vyalla, Vishaal Udandarao, Tanmoy Chakraborty", "title": "Memeify: A Large-Scale Meme Generation System", "comments": "Accepted at ACM India Joint International Conference on Data Science\n  & Management of Data (CoDS-CoMAD) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in the research areas related to meme propagation and generation has\nbeen increasing rapidly in the last couple of years. Meme datasets available\nonline are either specific to a context or contain no class information. Here,\nwe prepare a large-scale dataset of memes with captions and class labels. The\ndataset consists of 1.1 million meme captions from 128 classes. We also provide\nreasoning for the existence of broad categories, called \"themes\" across the\nmeme dataset; each theme consists of multiple meme classes. Our generation\nsystem uses a trained state-of-the-art transformer-based model for caption\ngeneration by employing an encoder-decoder architecture. We develop a web\ninterface, called Memeify for users to generate memes of their choice, and\nexplain in detail, the working of individual components of the system. We also\nperform a qualitative evaluation of the generated memes by conducting a user\nstudy. A link to the demonstration of the Memeify system is\nhttps://youtu.be/P_Tfs0X-czs.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 15:13:26 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 19:04:19 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Vyalla", "Suryatej Reddy", ""], ["Udandarao", "Vishaal", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1910.12299", "submitter": "Oliver Adams", "authors": "Oliver Adams, Matthew Wiesner, Jan Trmal, Garrett Nicolai and David\n  Yarowsky", "title": "Induced Inflection-Set Keyword Search in Speech", "comments": "To appear in SIGMORPHON 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of searching for a lexeme-set in speech by\nsearching for its inflectional variants. Experimental results indicate how\nlexeme-set search performance changes with the number of hypothesized\ninflections, while ablation experiments highlight the relative importance of\ndifferent components in the lexeme-set search pipeline and the value of using\ncurated inflectional paradigms. We provide a recipe and evaluation set for the\ncommunity to use as an extrinsic measure of the performance of inflection\ngeneration approaches.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 16:54:26 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 02:29:06 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Adams", "Oliver", ""], ["Wiesner", "Matthew", ""], ["Trmal", "Jan", ""], ["Nicolai", "Garrett", ""], ["Yarowsky", "David", ""]]}, {"id": "1910.12354", "submitter": "Vladislav Kurenkov", "authors": "Vladislav Kurenkov, Bulat Maksudov, Adil Khan", "title": "Task-Oriented Language Grounding for Language Input with Multiple\n  Sub-Goals of Non-Linear Order", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the performance of general deep reinforcement\nlearning algorithms for a task-oriented language grounding problem, where\nlanguage input contains multiple sub-goals and their order of execution is\nnon-linear.\n  We generate a simple instructional language for the GridWorld environment,\nthat is built around three language elements (order connectors) defining the\norder of execution: one linear - \"comma\" and two non-linear - \"but first\", \"but\nbefore\". We apply one of the deep reinforcement learning baselines - Double DQN\nwith frame stacking and ablate several extensions such as Prioritized\nExperience Replay and Gated-Attention architecture.\n  Our results show that the introduction of non-linear order connectors\nimproves the success rate on instructions with a higher number of sub-goals in\n2-3 times, but it still does not exceed 20%. Also, we observe that the usage of\nGated-Attention provides no competitive advantage against concatenation in this\nsetting. Source code and experiments' results are available at\nhttps://github.com/vkurenkov/language-grounding-multigoal\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 21:11:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kurenkov", "Vladislav", ""], ["Maksudov", "Bulat", ""], ["Khan", "Adil", ""]]}, {"id": "1910.12366", "submitter": "Kalpesh Krishna", "authors": "Kalpesh Krishna, Gaurav Singh Tomar, Ankur P. Parikh, Nicolas\n  Papernot, Mohit Iyyer", "title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs", "comments": "ICLR 2020 Camera Ready (19 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of model extraction in natural language processing, in\nwhich an adversary with only query access to a victim model attempts to\nreconstruct a local copy of that model. Assuming that both the adversary and\nvictim model fine-tune a large pretrained language model such as BERT (Devlin\net al. 2019), we show that the adversary does not need any real training data\nto successfully mount the attack. In fact, the attacker need not even use\ngrammatical or semantically meaningful queries: we show that random sequences\nof words coupled with task-specific heuristics form effective queries for model\nextraction on a diverse set of NLP tasks, including natural language inference\nand question answering. Our work thus highlights an exploit only made feasible\nby the shift towards transfer learning methods within the NLP community: for a\nquery budget of a few hundred dollars, an attacker can extract a model that\nperforms only slightly worse than the victim model. Finally, we study two\ndefense strategies against model extraction---membership classification and API\nwatermarking---which while successful against naive adversaries, are\nineffective against more sophisticated ones.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:09:13 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 03:20:52 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 12:14:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Krishna", "Kalpesh", ""], ["Tomar", "Gaurav Singh", ""], ["Parikh", "Ankur P.", ""], ["Papernot", "Nicolas", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1910.12367", "submitter": "Abdelrahman Mohamed", "authors": "Kritika Singh, Dmytro Okhonko, Jun Liu, Yongqiang Wang, Frank Zhang,\n  Ross Girshick, Sergey Edunov, Fuchun Peng, Yatharth Saraf, Geoffrey Zweig,\n  Abdelrahman Mohamed", "title": "Training ASR models by Generation of Contextual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised ASR models have reached unprecedented levels of accuracy, thanks\nin part to ever-increasing amounts of labelled training data. However, in many\napplications and locales, only moderate amounts of data are available, which\nhas led to a surge in semi- and weakly-supervised learning research. In this\npaper, we conduct a large-scale study evaluating the effectiveness of\nweakly-supervised learning for speech recognition by using loosely related\ncontextual information as a surrogate for ground-truth labels. For weakly\nsupervised training, we use 50k hours of public English social media videos\nalong with their respective titles and post text to train an encoder-decoder\ntransformer model. Our best encoder-decoder models achieve an average of 20.8%\nWER reduction over a 1000 hours supervised baseline, and an average of 13.4%\nWER reduction when using only the weakly supervised encoder for CTC\nfine-tuning. Our results show that our setup for weak supervision improved both\nthe encoder acoustic representations as well as the decoder language generation\nabilities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:13:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 21:59:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Singh", "Kritika", ""], ["Okhonko", "Dmytro", ""], ["Liu", "Jun", ""], ["Wang", "Yongqiang", ""], ["Zhang", "Frank", ""], ["Girshick", "Ross", ""], ["Edunov", "Sergey", ""], ["Peng", "Fuchun", ""], ["Saraf", "Yatharth", ""], ["Zweig", "Geoffrey", ""], ["Mohamed", "Abdelrahman", ""]]}, {"id": "1910.12368", "submitter": "Tejas Srinivasan", "authors": "Tejas Srinivasan, Ramon Sanabria, Florian Metze", "title": "Multitask Learning For Different Subword Segmentations In Neural Machine\n  Translation", "comments": "Accepted to 16th International Workshop on Spoken Language\n  Translation (IWSLT) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Neural Machine Translation (NMT) the usage of subwords and characters as\nsource and target units offers a simple and flexible solution for translation\nof rare and unseen words. However, selecting the optimal subword segmentation\ninvolves a trade-off between expressiveness and flexibility, and is language\nand dataset-dependent. We present Block Multitask Learning (BMTL), a novel NMT\narchitecture that predicts multiple targets of different granularities\nsimultaneously, removing the need to search for the optimal segmentation\nstrategy. Our multi-task model exhibits improvements of up to 1.7 BLEU points\non each decoder over single-task baseline models with the same number of\nparameters on datasets from two language pairs of IWSLT15 and one from IWSLT19.\nThe multiple hypotheses generated at different granularities can be combined as\na post-processing step to give better translations, which improves over\nhypothesis combination from baseline models while using substantially fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:14:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Srinivasan", "Tejas", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""]]}, {"id": "1910.12383", "submitter": "Junichi Yamagishi", "authors": "Yusuke Yasuda, Xin Wang, Junichi Yamagishi", "title": "Effect of choice of probability distribution, randomness, and search\n  methods for alignment modeling in sequence-to-sequence text-to-speech\n  synthesis using hard alignment", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence text-to-speech (TTS) is dominated by\nsoft-attention-based methods. Recently, hard-attention-based methods have been\nproposed to prevent fatal alignment errors, but their sampling method of\ndiscrete alignment is poorly investigated. This research investigates various\ncombinations of sampling methods and probability distributions for alignment\ntransition modeling in a hard-alignment-based sequence-to-sequence TTS method\ncalled SSNT-TTS. We clarify the common sampling methods of discrete variables\nincluding greedy search, beam search, and random sampling from a Bernoulli\ndistribution in a more general way. Furthermore, we introduce the binary\nConcrete distribution to model discrete variables more properly. The results of\na listening test shows that deterministic search is more preferable than\nstochastic search, and the binary Concrete distribution is robust with\nstochastic search for natural alignment transition.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 00:01:12 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yasuda", "Yusuke", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1910.12391", "submitter": "Chenglei Si", "authors": "Chenglei Si, Shuohang Wang, Min-Yen Kan, Jing Jiang", "title": "What does BERT Learn from Multiple-Choice Reading Comprehension\n  Datasets?", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-Choice Reading Comprehension (MCRC) requires the model to read the\npassage and question, and select the correct answer among the given options.\nRecent state-of-the-art models have achieved impressive performance on multiple\nMCRC datasets. However, such performance may not reflect the model's true\nability of language understanding and reasoning. In this work, we adopt two\napproaches to investigate what BERT learns from MCRC datasets: 1) an\nun-readable data attack, in which we add keywords to confuse BERT, leading to a\nsignificant performance drop; and 2) an un-answerable data training, in which\nwe train BERT on partial or shuffled input. Under un-answerable data training,\nBERT achieves unexpectedly high performance. Based on our experiments on the 5\nkey MCRC datasets - RACE, MCTest, MCScript, MCScript2.0, DREAM - we observe\nthat 1) fine-tuned BERT mainly learns how keywords lead to correct prediction,\ninstead of learning semantic understanding and reasoning; and 2) BERT does not\nneed correct syntactic information to solve the task; 3) there exists artifacts\nin these datasets such that they can be solved even without the full context.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 00:50:55 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Si", "Chenglei", ""], ["Wang", "Shuohang", ""], ["Kan", "Min-Yen", ""], ["Jiang", "Jing", ""]]}, {"id": "1910.12418", "submitter": "Zhiyun Fan", "authors": "Zhiyun Fan and Shiyu Zhou and Bo Xu", "title": "Unsupervised pre-training for sequence to sequence speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach to pre-train encoder-decoder\nsequence-to-sequence (seq2seq) model with unpaired speech and transcripts\nrespectively. Our pre-training method is divided into two stages, named\nacoustic pre-trianing and linguistic pre-training. In the acoustic pre-training\nstage, we use a large amount of speech to pre-train the encoder by predicting\nmasked speech feature chunks with its context. In the linguistic pre-training\nstage, we generate synthesized speech from a large number of transcripts using\na single-speaker text to speech (TTS) system, and use the synthesized paired\ndata to pre-train decoder. This two-stage pre-training method integrates rich\nacoustic and linguistic knowledge into seq2seq model, which will benefit\ndownstream automatic speech recognition (ASR) tasks. The unsupervised\npre-training is finished on AISHELL-2 dataset and we apply the pre-trained\nmodel to multiple paired data ratios of AISHELL-1 and HKUST. We obtain relative\ncharacter error rate reduction (CERR) from 38.24% to 7.88% on AISHELL-1 and\nfrom 12.00% to 1.20% on HKUST. Besides, we apply our pretrained model to a\ncross-lingual case with CALLHOME dataset. For all six languages in CALLHOME\ndataset, our pre-training method makes model outperform baseline consistently.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:17:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 01:45:28 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Fan", "Zhiyun", ""], ["Zhou", "Shiyu", ""], ["Xu", "Bo", ""]]}, {"id": "1910.12419", "submitter": "Tung Tran", "authors": "Tung Tran, Ramakanth Kavuluru, Halil Kilicoglu", "title": "Attention-Gated Graph Convolutions for Extracting Drug Interaction\n  Information from Drug Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventable adverse events as a result of medical errors present a growing\nconcern in the healthcare system. As drug-drug interactions (DDIs) may lead to\npreventable adverse events, being able to extract DDIs from drug labels into a\nmachine-processable form is an important step toward effective dissemination of\ndrug safety information. In this study, we tackle the problem of jointly\nextracting drugs and their interactions, including interaction outcome, from\ndrug labels. Our deep learning approach entails composing various intermediate\nrepresentations including sequence and graph based context, where the latter is\nderived using graph convolutions (GC) with a novel attention-based gating\nmechanism (holistically called GCA). These representations are then composed in\nmeaningful ways to handle all subtasks jointly. To overcome scarcity in\ntraining data, we additionally propose transfer learning by pre-training on\nrelated DDI data. Our model is trained and evaluated on the 2018 TAC DDI\ncorpus. Our GCA model in conjunction with transfer learning performs at 39.20%\nF1 and 26.09% F1 on entity recognition (ER) and relation extraction (RE)\nrespectively on the first official test set and at 45.30% F1 and 27.87% F1 on\nER and RE respectively on the second official test set corresponding to an\nimprovement over our prior best results by up to 6 absolute F1 points. After\ncontrolling for available training data, our model exhibits state-of-the-art\nperformance by improving over the next comparable best outcome by roughly three\nF1 points in ER and 1.5 F1 points in RE evaluation across two official test\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 03:18:25 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 19:11:22 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tran", "Tung", ""], ["Kavuluru", "Ramakanth", ""], ["Kilicoglu", "Halil", ""]]}, {"id": "1910.12441", "submitter": "Samaneh Karimi", "authors": "Samaneh Karimi, Azadeh Shakery, Rakesh Verma", "title": "Online News Media Website Ranking Using User Generated Content", "comments": "35 pages, 4 Figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News media websites are important online resources that have drawn great\nattention of text mining researchers. The main aim of this study is to propose\na framework for ranking online news websites from different viewpoints. The\nranking of news websites is useful information, which can benefit many\nnews-related tasks such as news retrieval and news recommendation. In the\nproposed framework, the ranking of news websites is obtained by calculating\nthree measures introduced in the paper and based on user-generated content.\nEach proposed measure is concerned with the performance of news websites from a\nparticular viewpoint including the completeness of news reports, the diversity\nof events being covered by the website and its speed. The use of user-generated\ncontent in this framework, as a partly-unbiased, real-time and low cost content\non the web distinguishes the proposed news website ranking framework from the\nliterature. The results obtained for three prominent news websites, BBC, CNN,\nNYTimes, show that BBC has the best performance in terms of news completeness\nand speed, and NYTimes has the best diversity in comparison with the other two\nwebsites.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 04:50:22 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Karimi", "Samaneh", ""], ["Shakery", "Azadeh", ""], ["Verma", "Rakesh", ""]]}, {"id": "1910.12446", "submitter": "Renhao Cui", "authors": "Renhao Cui, Gagan Agrawal, Rajiv Ramnath", "title": "Towards Successful Social Media Advertising: Predicting the Influence of\n  Commercial Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Businesses communicate using Twitter for a variety of reasons -- to raise\nawareness of their brands, to market new products, to respond to community\ncomments, and to connect with their customers and potential customers in a\ntargeted manner. For businesses to do this effectively, they need to understand\nwhich content and structural elements about a tweet make it influential, that\nis, widely liked, followed, and retweeted. This paper presents a systematic\nmethodology for analyzing commercial tweets, and predicting the influence on\ntheir readers. Our model, which use a combination of decoration and meta\nfeatures, outperforms the prediction ability of the baseline model as well as\nthe tweet embedding model. Further, in order to demonstrate a practical use of\nthis work, we show how an unsuccessful tweet may be engineered (for example,\nreworded) to increase its potential for success.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 05:14:41 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Cui", "Renhao", ""], ["Agrawal", "Gagan", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1910.12477", "submitter": "Yiying Yang", "authors": "Yiying Yang, Xiahui He, Kaijie Zhou, Zhongyu Wei", "title": "Multi-Module System for Open Domain Chinese Question Answering over\n  Knowledge Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the task of open domain Knowledge Based Question Answering in CCKS2019,\nwe propose a method combining information retrieval and semantic parsing. This\nmulti-module system extracts the topic entity and the most related relation\npredicate from a question and transforms it into a Sparql query statement. Our\nmethod obtained the F1 score of 70.45% on the test data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 07:28:57 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Yang", "Yiying", ""], ["He", "Xiahui", ""], ["Zhou", "Kaijie", ""], ["Wei", "Zhongyu", ""]]}, {"id": "1910.12507", "submitter": "Genet Asefa Gesese", "authors": "Genet Asefa Gesese, Russa Biswas, Mehwish Alam, Harald Sack", "title": "A Survey on Knowledge Graph Embeddings with Literals: Which model links\n  better Literal-ly?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) are composed of structured information about a\nparticular domain in the form of entities and relations. In addition to the\nstructured information KGs help in facilitating interconnectivity and\ninteroperability between different resources represented in the Linked Data\nCloud. KGs have been used in a variety of applications such as entity linking,\nquestion answering, recommender systems, etc. However, KG applications suffer\nfrom high computational and storage costs. Hence, there arises the necessity\nfor a representation able to map the high dimensional KGs into low dimensional\nspaces, i.e., embedding space, preserving structural as well as relational\ninformation. This paper conducts a survey of KG embedding models which not only\nconsider the structured information contained in the form of entities and\nrelations in a KG but also the unstructured information represented as literals\nsuch as text, numerical values, images, etc. Along with a theoretical analysis\nand comparison of the methods proposed so far for generating KG embeddings with\nliterals, an empirical evaluation of the different methods under identical\nsettings has been performed for the general task of link prediction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 09:06:00 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 07:14:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Gesese", "Genet Asefa", ""], ["Biswas", "Russa", ""], ["Alam", "Mehwish", ""], ["Sack", "Harald", ""]]}, {"id": "1910.12527", "submitter": "Xiuying Chen", "authors": "Xiuying Chen, Daorui Xiao, Shen Gao, Guojun Liu, Wei Lin, Bo Zheng,\n  Dongyan Zhao, Rui Yan", "title": "RPM-Oriented Query Rewriting Framework for E-commerce Keyword-Based\n  Sponsored Search", "comments": "2 pages, 2 figures", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search optimizes revenue and relevance, which is estimated by\nRevenue Per Mille (RPM). Existing sponsored search models are all based on\ntraditional statistical models, which have poor RPM performance when queries\nfollow a heavy-tailed distribution. Here, we propose an RPM-oriented Query\nRewriting Framework (RQRF) which outputs related bid keywords that can yield\nhigh RPM. RQRF embeds both queries and bid keywords to vectors in the same\nimplicit space, converting the rewriting probability between each query and\nkeyword to the distance between the two vectors. For label construction, we\npropose an RPM-oriented sample construction method, labeling keywords based on\nwhether or not they can lead to high RPM. Extensive experiments are conducted\nto evaluate performance of RQRF. In a one month large-scale real-world traffic\nof e-commerce sponsored search system, the proposed model significantly\noutperforms traditional baseline.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 10:03:24 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 08:45:18 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chen", "Xiuying", ""], ["Xiao", "Daorui", ""], ["Gao", "Shen", ""], ["Liu", "Guojun", ""], ["Lin", "Wei", ""], ["Zheng", "Bo", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1910.12531", "submitter": "Jonggu Kim", "authors": "Jonggu Kim and Jong-Hyeok Lee", "title": "Modeling Inter-Speaker Relationship in XLNet for Contextual Spoken\n  Language Understanding", "comments": "submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two methods to capture relevant history information in a\nmulti-turn dialogue by modeling inter-speaker relationship for spoken language\nunderstanding (SLU). Our methods are tailored for and therefore compatible with\nXLNet, which is a state-of-the-art pretrained model, so we verified our models\nbuilt on the top of XLNet. In our experiments, all models achieved higher\naccuracy than state-of-the-art contextual SLU models on two benchmark datasets.\nAnalysis on the results demonstrated that the proposed methods are effective to\nimprove SLU accuracy of XLNet. These methods to identify important dialogue\nhistory will be useful to alleviate ambiguity in SLU of the current utterance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 10:23:03 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kim", "Jonggu", ""], ["Lee", "Jong-Hyeok", ""]]}, {"id": "1910.12554", "submitter": "Yingbo Gao", "authors": "Yingbo Gao, Christian Herold, Weiyue Wang, Hermann Ney", "title": "Exploring Kernel Functions in the Softmax Layer for Contextual Word\n  Classification", "comments": "IWSLT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prominently used in support vector machines and logistic regressions, kernel\nfunctions (kernels) can implicitly map data points into high dimensional spaces\nand make it easier to learn complex decision boundaries. In this work, by\nreplacing the inner product function in the softmax layer, we explore the use\nof kernels for contextual word classification. In order to compare the\nindividual kernels, experiments are conducted on standard language modeling and\nmachine translation tasks. We observe a wide range of performances across\ndifferent kernel settings. Extending the results, we look at the gradient\nproperties, investigate various mixture strategies and examine the\ndisambiguation abilities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 11:06:21 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Gao", "Yingbo", ""], ["Herold", "Christian", ""], ["Wang", "Weiyue", ""], ["Ney", "Hermann", ""]]}, {"id": "1910.12574", "submitter": "Marzieh Mozafari", "authors": "Marzieh Mozafari, Reza Farahbakhsh, Noel Crespi", "title": "A BERT-Based Transfer Learning Approach for Hate Speech Detection in\n  Online Social Media", "comments": "This paper has been accepted in The 8th International Conference on\n  Complex Networks and their Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generated hateful and toxic content by a portion of users in social media is\na rising phenomenon that motivated researchers to dedicate substantial efforts\nto the challenging direction of hateful content identification. We not only\nneed an efficient automatic hate speech detection model based on advanced\nmachine learning and natural language processing, but also a sufficiently large\namount of annotated data to train a model. The lack of a sufficient amount of\nlabelled hate speech data, along with the existing biases, has been the main\nissue in this domain of research. To address these needs, in this study we\nintroduce a novel transfer learning approach based on an existing pre-trained\nlanguage model called BERT (Bidirectional Encoder Representations from\nTransformers). More specifically, we investigate the ability of BERT at\ncapturing hateful context within social media content by using new fine-tuning\nmethods based on transfer learning. To evaluate our proposed approach, we use\ntwo publicly available datasets that have been annotated for racism, sexism,\nhate, or offensive content on Twitter. The results show that our solution\nobtains considerable performance on these datasets in terms of precision and\nrecall in comparison to existing approaches. Consequently, our model can\ncapture some biases in data annotation and collection process and can\npotentially lead us to a more accurate model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 12:13:38 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Mozafari", "Marzieh", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "1910.12592", "submitter": "Hossein Zeinali", "authors": "Hossein Zeinali, Shuai Wang, Anna Silnova, Pavel Mat\\v{e}jka,\n  Old\\v{r}ich Plchot", "title": "BUT System Description to VoxCeleb Speaker Recognition Challenge 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we describe the submission of Brno University of Technology\n(BUT) team to the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2019. We also\nprovide a brief analysis of different systems on VoxCeleb-1 test sets.\nSubmitted systems for both Fixed and Open conditions are a fusion of 4\nConvolutional Neural Network (CNN) topologies. The first and second networks\nhave ResNet34 topology and use two-dimensional CNNs. The last two networks are\none-dimensional CNN and are based on the x-vector extraction topology. Some of\nthe networks are fine-tuned using additive margin angular softmax. Kaldi FBanks\nand Kaldi PLPs were used as features. The difference between Fixed and Open\nsystems lies in the used training data and fusion strategy. The best systems\nfor Fixed and Open conditions achieved 1.42% and 1.26% ERR on the challenge\nevaluation set respectively.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 11:27:27 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zeinali", "Hossein", ""], ["Wang", "Shuai", ""], ["Silnova", "Anna", ""], ["Mat\u011bjka", "Pavel", ""], ["Plchot", "Old\u0159ich", ""]]}, {"id": "1910.12607", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, James Glass", "title": "Generative Pre-Training for Speech with Autoregressive Predictive Coding", "comments": "Accepted to ICASSP 2020. Code and pre-trained models are available at\n  https://github.com/iamyuanchung/Autoregressive-Predictive-Coding", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful and general representations from unannotated speech that\nare applicable to a wide range of tasks remains challenging. In this paper we\npropose to use autoregressive predictive coding (APC), a recently proposed\nself-supervised objective, as a generative pre-training approach for learning\nmeaningful, non-specific, and transferable speech representations. We pre-train\nAPC on large-scale unlabeled data and conduct transfer learning experiments on\nthree speech applications that require different information about speech\ncharacteristics to perform well: speech recognition, speech translation, and\nspeaker identification. Extensive experiments show that APC not only\noutperforms surface features (e.g., log Mel spectrograms) and other popular\nrepresentation learning methods on all three tasks, but is also effective at\nreducing downstream labeled data size and model parameters. We also investigate\nthe use of Transformers for modeling APC and find it superior to RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 15:28:51 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 09:36:23 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "1910.12611", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Shirui Pan and Xue Li and Erik Cambria and Guodong\n  Long and Zi Huang", "title": "Suicidal Ideation Detection: A Review of Machine Learning Methods and\n  Applications", "comments": "IEEE Transactions on Computational Social Systems", "journal-ref": "IEEE Transactions on Computational Social Systems, 8(1), 2021, pp.\n  214-226", "doi": "10.1109/TCSS.2020.3021467", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suicide is a critical issue in modern society. Early detection and prevention\nof suicide attempts should be addressed to save people's life. Current suicidal\nideation detection methods include clinical methods based on the interaction\nbetween social workers or experts and the targeted individuals and machine\nlearning techniques with feature engineering or deep learning for automatic\ndetection based on online social contents. This paper is the first survey that\ncomprehensively introduces and discusses the methods from these categories.\nDomain-specific applications of suicidal ideation detection are reviewed\naccording to their data sources, i.e., questionnaires, electronic health\nrecords, suicide notes, and online user content. Several specific tasks and\ndatasets are introduced and summarized to facilitate further research. Finally,\nwe summarize the limitations of current work and provide an outlook of further\nresearch directions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 02:10:42 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 11:04:42 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 09:49:48 GMT"}, {"version": "v4", "created": "Sun, 6 Sep 2020 06:12:03 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Pan", "Shirui", ""], ["Li", "Xue", ""], ["Cambria", "Erik", ""], ["Long", "Guodong", ""], ["Huang", "Zi", ""]]}, {"id": "1910.12618", "submitter": "David Obst", "authors": "David Obst and Badih Ghattas and Sandra Claudel and Jairo Cugliari and\n  Yannig Goude and Georges Oppenheim", "title": "Textual Data for Time Series Forecasting", "comments": "-Added e-mail addresses of authors. -Added author who didn't appear\n  on the paper's arXiv page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While ubiquitous, textual sources of information such as company reports,\nsocial media posts, etc. are hardly included in prediction algorithms for time\nseries, despite the relevant information they may contain. In this work, openly\naccessible daily weather reports from France and the United-Kingdom are\nleveraged to predict time series of national electricity consumption, average\ntemperature and wind-speed with a single pipeline. Two methods of numerical\nrepresentation of text are considered, namely traditional Term Frequency -\nInverse Document Frequency (TF-IDF) as well as our own neural word embedding.\nUsing exclusively text, we are able to predict the aforementioned time series\nwith sufficient accuracy to be used to replace missing data. Furthermore the\nproposed word embeddings display geometric properties relating to the behavior\nof the time series and context similarity between words.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 07:47:56 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 09:39:06 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Obst", "David", ""], ["Ghattas", "Badih", ""], ["Claudel", "Sandra", ""], ["Cugliari", "Jairo", ""], ["Goude", "Yannig", ""], ["Oppenheim", "Georges", ""]]}, {"id": "1910.12619", "submitter": "Laura Hollink", "authors": "Laura Hollink, Aysenur Bilgin, Jacco van Ossenbruggen", "title": "Is it a Fruit, an Apple or a Granny Smith? Predicting the Basic Level in\n  a Concept Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The \"basic level\", according to experiments in cognitive psychology, is the\nlevel of abstraction in a hierarchy of concepts at which humans perform tasks\nquicker and with greater accuracy than at other levels. We argue that\napplications that use concept hierarchies - such as knowledge graphs,\nontologies or taxonomies - could significantly improve their user interfaces if\nthey `knew' which concepts are the basic level concepts. This paper examines to\nwhat extent the basic level can be learned from data. We test the utility of\nthree types of concept features, that were inspired by the basic level theory:\nlexical features, structural features and frequency features. We evaluate our\napproach on WordNet, and create a training set of manually labelled examples\nthat includes concepts from different domains. Our findings include that the\nbasic level concepts can be accurately identified within one domain. Concepts\nthat are difficult to label for humans are also harder to classify\nautomatically. Our experiments provide insight into how classification\nperformance across domains could be improved, which is necessary for\nidentification of basic level concepts on a larger scale.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 12:26:32 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hollink", "Laura", ""], ["Bilgin", "Aysenur", ""], ["van Ossenbruggen", "Jacco", ""]]}, {"id": "1910.12622", "submitter": "Jacob Danovitch", "authors": "Jacob Danovitch", "title": "Trouble with the Curve: Predicting Future MLB Players Using Scouting\n  Reports", "comments": "Carnegie Mellon Sports Analytics Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In baseball, a scouting report profiles a player's characteristics and\ntraits, usually intended for use in player valuation. This work presents a\nfirst-of-its-kind dataset of almost 10,000 scouting reports for minor league,\ninternational, and draft prospects. Compiled from articles posted to MLB.com\nand Fangraphs.com, each report consists of a written description of the player,\nnumerical grades for several skills, and unique IDs to reference their profiles\non popular resources like MLB.com, FanGraphs, and Baseball-Reference. With this\ndataset, we employ several deep neural networks to predict if minor league\nplayers will make the MLB given their scouting report. We open-source this data\nto share with the community, and present a web application demonstrating\nlanguage variations in the reports of successful and unsuccessful prospects.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 02:02:59 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Danovitch", "Jacob", ""]]}, {"id": "1910.12638", "submitter": "Andy T. Liu", "authors": "Andy T. Liu, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, Hung-yi Lee", "title": "Mockingjay: Unsupervised Speech Representation Learning with Deep\n  Bidirectional Transformer Encoders", "comments": "Accepted by ICASSP 2020, Lecture Session", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9054458", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Mockingjay as a new speech representation learning approach, where\nbidirectional Transformer encoders are pre-trained on a large amount of\nunlabeled speech. Previous speech representation methods learn through\nconditioning on past frames and predicting information about future frames.\nWhereas Mockingjay is designed to predict the current frame through jointly\nconditioning on both past and future contexts. The Mockingjay representation\nimproves performance for a wide range of downstream tasks, including phoneme\nclassification, speaker recognition, and sentiment classification on spoken\ncontent, while outperforming other approaches. Mockingjay is empirically\npowerful and can be fine-tuned with downstream models, with only 2 epochs we\nfurther improve performance dramatically. In a low resource setting with only\n0.1% of labeled data, we outperform the result of Mel-features that uses all\n100% labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 01:55:12 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 15:08:39 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Liu", "Andy T.", ""], ["Yang", "Shu-wen", ""], ["Chi", "Po-Han", ""], ["Hsu", "Po-chun", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1910.12647", "submitter": "Mehrad Moradshahi", "authors": "Mehrad Moradshahi, Hamid Palangi, Monica S. Lam, Paul Smolensky,\n  Jianfeng Gao", "title": "HUBERT Untangles BERT to Improve Transfer across NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce HUBERT which combines the structured-representational power of\nTensor-Product Representations (TPRs) and BERT, a pre-trained bidirectional\nTransformer language model. We show that there is shared structure between\ndifferent NLP datasets that HUBERT, but not BERT, is able to learn and\nleverage. We validate the effectiveness of our model on the GLUE benchmark and\nHANS dataset. Our experiment results show that untangling data-specific\nsemantics from general language structure is key for better transfer among NLP\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 06:25:25 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 23:42:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Moradshahi", "Mehrad", ""], ["Palangi", "Hamid", ""], ["Lam", "Monica S.", ""], ["Smolensky", "Paul", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1910.12674", "submitter": "Anderson De Andrade", "authors": "Anderson de Andrade", "title": "A Comparison of Neural Network Training Methods for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of neural networks in text classification. Our focus is\non training deep neural networks with proper weight initialization and greedy\nlayer-wise pretraining. Results are compared with 1-layer neural networks and\nSupport Vector Machines. We work with a dataset of labeled messages from the\nTwitter microblogging service and aim to predict weather conditions. A feature\nextraction procedure specific for the task is proposed, which applies\ndimensionality reduction using Latent Semantic Analysis. Our results show that\nneural networks outperform Support Vector Machines with Gaussian kernels,\nnoticing performance gains from introducing additional hidden layers with\nnonlinearities. The impact of using Nesterov's Accelerated Gradient in\nbackpropagation is also studied. We conclude that deep neural networks are a\nreasonable approach for text classification and propose further ideas to\nimprove performance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 13:46:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["de Andrade", "Anderson", ""]]}, {"id": "1910.12698", "submitter": "Shrey Desai", "authors": "Shrey Desai, Barea Sinno, Alex Rosenfeld, Junyi Jessy Li", "title": "Adaptive Ensembling: Unsupervised Domain Adaptation for Political\n  Document Analysis", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insightful findings in political science often require researchers to analyze\ndocuments of a certain subject or type, yet these documents are usually\ncontained in large corpora that do not distinguish between pertinent and\nnon-pertinent documents. In contrast, we can find corpora that label relevant\ndocuments but have limitations (e.g., from a single source or era), preventing\ntheir use for political science research. To bridge this gap, we present\n\\textit{adaptive ensembling}, an unsupervised domain adaptation framework,\nequipped with a novel text classification model and time-aware training to\nensure our methods work well with diachronic corpora. Experiments on an\nexpert-annotated dataset show that our framework outperforms strong benchmarks.\nFurther analysis indicates that our methods are more stable, learn better\nrepresentations, and extract cleaner corpora for fine-grained analysis.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:17:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Desai", "Shrey", ""], ["Sinno", "Barea", ""], ["Rosenfeld", "Alex", ""], ["Li", "Junyi Jessy", ""]]}, {"id": "1910.12702", "submitter": "Nasser Zalmout", "authors": "Nasser Zalmout and Nizar Habash", "title": "Adversarial Multitask Learning for Joint Multi-Feature and Multi-Dialect\n  Morphological Modeling", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological tagging is challenging for morphologically rich languages due\nto the large target space and the need for more training data to minimize model\nsparsity. Dialectal variants of morphologically rich languages suffer more as\nthey tend to be more noisy and have less resources. In this paper we explore\nthe use of multitask learning and adversarial training to address morphological\nrichness and dialectal variations in the context of full morphological tagging.\nWe use multitask learning for joint morphological modeling for the features\nwithin two dialects, and as a knowledge-transfer scheme for cross-dialectal\nmodeling. We use adversarial training to learn dialect invariant features that\ncan help the knowledge-transfer scheme from the high to low-resource variants.\nWe work with two dialectal variants: Modern Standard Arabic (high-resource\n\"dialect\") and Egyptian Arabic (low-resource dialect) as a case study. Our\nmodels achieve state-of-the-art results for both. Furthermore, adversarial\ntraining provides more significant improvement when using smaller training\ndatasets in particular.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:22:56 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zalmout", "Nasser", ""], ["Habash", "Nizar", ""]]}, {"id": "1910.12708", "submitter": "Shrey Desai", "authors": "Shrey Desai, Hongyuan Zhan, Ahmed Aly", "title": "Evaluating Lottery Tickets Under Distributional Shifts", "comments": "Accepted to EMNLP 2019 Workshop on Deep Learning for Low-Resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lottery Ticket Hypothesis suggests large, over-parameterized neural\nnetworks consist of small, sparse subnetworks that can be trained in isolation\nto reach a similar (or better) test accuracy. However, the initialization and\ngeneralizability of the obtained sparse subnetworks have been recently called\ninto question. Our work focuses on evaluating the initialization of sparse\nsubnetworks under distributional shifts. Specifically, we investigate the\nextent to which a sparse subnetwork obtained in a source domain can be\nre-trained in isolation in a dissimilar, target domain. In addition, we examine\nthe effects of different initialization strategies at transfer-time. Our\nexperiments show that sparse subnetworks obtained through lottery ticket\ntraining do not simply overfit to particular domains, but rather reflect an\ninductive bias of deep neural networks that can be exploited in multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:29:28 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Desai", "Shrey", ""], ["Zhan", "Hongyuan", ""], ["Aly", "Ahmed", ""]]}, {"id": "1910.12729", "submitter": "Alexander H. Liu", "authors": "Alexander H. Liu and Tao Tu and Hung-yi Lee and Lin-shan Lee", "title": "Towards Unsupervised Speech Recognition and Synthesis with Quantized\n  Speech Representation Learning", "comments": "ICASSP 2020, equal contribution from first two authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a Sequential Representation Quantization AutoEncoder\n(SeqRQ-AE) to learn from primarily unpaired audio data and produce sequences of\nrepresentations very close to phoneme sequences of speech utterances. This is\nachieved by proper temporal segmentation to make the representations\nphoneme-synchronized, and proper phonetic clustering to have total number of\ndistinct representations close to the number of phonemes. Mapping between the\ndistinct representations and phonemes is learned from a small amount of\nannotated paired data. Preliminary experiments on LJSpeech demonstrated the\nlearned representations for vowels have relative locations in latent space in\ngood parallel to that shown in the IPA vowel chart defined by linguistics\nexperts. With less than 20 minutes of annotated speech, our method outperformed\nexisting methods on phoneme recognition and is able to synthesize intelligible\nspeech that beats our baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:50:03 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 12:28:55 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Liu", "Alexander H.", ""], ["Tu", "Tao", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1910.12740", "submitter": "Alexander H. Liu", "authors": "Alexander H. Liu and Tzu-Wei Sung and Shun-Po Chuang and Hung-yi Lee\n  and Lin-shan Lee", "title": "Sequence-to-sequence Automatic Speech Recognition with Word Embedding\n  Regularization and Fused Decoding", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the benefit that off-the-shelf word embedding\ncan bring to the sequence-to-sequence (seq-to-seq) automatic speech recognition\n(ASR). We first introduced the word embedding regularization by maximizing the\ncosine similarity between a transformed decoder feature and the target word\nembedding. Based on the regularized decoder, we further proposed the fused\ndecoding mechanism. This allows the decoder to consider the semantic\nconsistency during decoding by absorbing the information carried by the\ntransformed decoder feature, which is learned to be close to the target word\nembedding. Initial results on LibriSpeech demonstrated that pre-trained word\nembedding can significantly lower ASR recognition error with a negligible cost,\nand the choice of word embedding algorithms among Skip-gram, CBOW and BERT is\nimportant.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 15:09:01 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 11:47:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Liu", "Alexander H.", ""], ["Sung", "Tzu-Wei", ""], ["Chuang", "Shun-Po", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1910.12795", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Bowen Tan, Ruslan Salakhutdinov, Tom Mitchell, Eric P.\n  Xing", "title": "Learning Data Manipulation for Augmentation and Weighting", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating data, such as weighting data examples or augmenting with new\ninstances, has been increasingly used to improve model training. Previous work\nhas studied various rule- or learning-based approaches designed for specific\ntypes of data manipulation. In this work, we propose a new method that supports\nlearning different manipulation schemes with the same gradient-based algorithm.\nOur approach builds upon a recent connection of supervised learning and\nreinforcement learning (RL), and adapts an off-the-shelf reward learning\nalgorithm from RL for joint data manipulation learning and model training.\nDifferent parameterization of the \"data reward\" function instantiates different\nmanipulation schemes. We showcase data augmentation that learns a text\ntransformation network, and data weighting that dynamically adapts the data\nsample importance. Experiments show the resulting algorithms significantly\nimprove the image and text classification performance in low data regime and\nclass-imbalance problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:46:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Hu", "Zhiting", ""], ["Tan", "Bowen", ""], ["Salakhutdinov", "Ruslan", ""], ["Mitchell", "Tom", ""], ["Xing", "Eric P.", ""]]}, {"id": "1910.12840", "submitter": "Wojciech Kry\\'sci\\'nski", "authors": "Wojciech Kry\\'sci\\'nski, Bryan McCann, Caiming Xiong, Richard Socher", "title": "Evaluating the Factual Consistency of Abstractive Text Summarization", "comments": "11 pages, 7 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently used metrics for assessing summarization algorithms do not account\nfor whether summaries are factually consistent with source documents. We\npropose a weakly-supervised, model-based approach for verifying factual\nconsistency and identifying conflicts between source documents and a generated\nsummary. Training data is generated by applying a series of rule-based\ntransformations to the sentences of source documents. The factual consistency\nmodel is then trained jointly for three tasks: 1) identify whether sentences\nremain factually consistent after transformation, 2) extract a span in the\nsource documents to support the consistency prediction, 3) extract a span in\nthe summary sentence that is inconsistent if one exists. Transferring this\nmodel to summaries generated by several state-of-the art models reveals that\nthis highly scalable approach substantially outperforms previous models,\nincluding those trained with strong supervision using standard datasets for\nnatural language inference and fact checking. Additionally, human evaluation\nshows that the auxiliary span extraction tasks provide useful assistance in the\nprocess of verifying factual consistency.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:51:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kry\u015bci\u0144ski", "Wojciech", ""], ["McCann", "Bryan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1910.12853", "submitter": "Shiyu Chang", "authors": "Shiyu Chang, Yang Zhang, Mo Yu, Tommi S. Jaakkola", "title": "A Game Theoretic Approach to Class-wise Selective Rationalization", "comments": "Accepted by Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection of input features such as relevant pieces of text has become a\ncommon technique of highlighting how complex neural predictors operate. The\nselection can be optimized post-hoc for trained models or incorporated directly\ninto the method itself (self-explaining). However, an overall selection does\nnot properly capture the multi-faceted nature of useful rationales such as pros\nand cons for decisions. To this end, we propose a new game theoretic approach\nto class-dependent rationalization, where the method is specifically trained to\nhighlight evidence supporting alternative conclusions. Each class involves\nthree players set up competitively to find evidence for factual and\ncounterfactual scenarios. We show theoretically in a simplified scenario how\nthe game drives the solution towards meaningful class-dependent rationales. We\nevaluate the method in single- and multi-aspect sentiment classification tasks\nand demonstrate that the proposed method is able to identify both factual\n(justifying the ground truth label) and counterfactual (countering the ground\ntruth label) rationales consistent with human rationalization. The code for our\nmethod is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:59:02 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Yu", "Mo", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1910.12941", "submitter": "Binxuan Huang", "authors": "Binxuan Huang and Kathleen M. Carley", "title": "A Hierarchical Location Prediction Neural Network for Twitter User\n  Geolocation", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of user location is important for many online services.\nPrevious neural network based methods largely ignore the hierarchical structure\namong locations. In this paper, we propose a hierarchical location prediction\nneural network for Twitter user geolocation. Our model first predicts the home\ncountry for a user, then uses the country result to guide the city-level\nprediction. In addition, we employ a character-aware word embedding layer to\novercome the noisy information in tweets. With the feature fusion layer, our\nmodel can accommodate various feature combinations and achieves\nstate-of-the-art results over three commonly used benchmarks under different\nfeature settings. It not only improves the prediction accuracy but also greatly\nreduces the mean error distance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 19:57:02 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Huang", "Binxuan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1910.12944", "submitter": "Justin Leo", "authors": "Justin Leo, Jugal Kalita", "title": "Moving Towards Open Set Incremental Learning: Readily Discovering New\n  Authors", "comments": "Accepted to Future of Information and Communication Conference (FICC)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of textual data often yields important information. Most\nclassifiers work in a closed world setting where the classifier is trained on a\nknown corpus, and then it is tested on unseen examples that belong to one of\nthe classes seen during training. Despite the usefulness of this design, often\nthere is a need to classify unseen examples that do not belong to any of the\nclasses on which the classifier was trained. This paper describes the open set\nscenario where unseen examples from previously unseen classes are handled while\ntesting. This further examines a process of enhanced open set classification\nwith a deep neural network that discovers new classes by clustering the\nexamples identified as belonging to unknown classes, followed by a process of\nretraining the classifier with newly recognized classes. Through this process\nthe model moves to an incremental learning model where it continuously finds\nand learns from novel classes of data that have been identified automatically.\nThis paper also develops a new metric that measures multiple attributes of\nclustering open set data. Multiple experiments across two author attribution\ndata sets demonstrate the creation an incremental model that produces excellent\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:01:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Leo", "Justin", ""], ["Kalita", "Jugal", ""]]}, {"id": "1910.12956", "submitter": "Vaibhav Jain", "authors": "Vaibhav Jain, Ruchika Malhotra, Sanskar Jain and Nishant Tanwar", "title": "Cross-Domain Ambiguity Detection using Linear Transformation of Word\n  Embedding Spaces", "comments": "Published as part of the proceedings of the 3rd Workshop on Natural\n  Language Processing for Requirements Engineering in CEUR-WS Vol-2584", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirements engineering process is a crucial stage of the software\ndevelopment life cycle. It involves various stakeholders from different\nprofessional backgrounds, particularly in the requirements elicitation phase.\nEach stakeholder carries distinct domain knowledge, causing them to differently\ninterpret certain words, leading to cross-domain ambiguity. This can result in\nmisunderstanding amongst them and jeopardize the entire project. This paper\nproposes a natural language processing approach to find potentially ambiguous\nwords for a given set of domains. The idea is to apply linear transformations\non word embedding models trained on different domain corpora, to bring them\ninto a unified embedding space. The approach then finds words with divergent\nembeddings as they signify a variation in the meaning across the domains. It\ncan help a requirements analyst in preventing misunderstandings during\nelicitation interviews and meetings by defining a set of potentially ambiguous\nterms in advance. The paper also discusses certain problems with the existing\napproaches and discusses how the proposed approach resolves them.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 20:32:56 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 05:51:41 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 19:10:42 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jain", "Vaibhav", ""], ["Malhotra", "Ruchika", ""], ["Jain", "Sanskar", ""], ["Tanwar", "Nishant", ""]]}, {"id": "1910.12977", "submitter": "Ching-Feng Yeh", "authors": "Ching-Feng Yeh, Jay Mahadeokar, Kaustubh Kalgaonkar, Yongqiang Wang,\n  Duc Le, Mahaveer Jain, Kjell Schubert, Christian Fuegen, Michael L. Seltzer", "title": "Transformer-Transducer: End-to-End Speech Recognition with\n  Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore options to use Transformer networks in neural transducer for\nend-to-end speech recognition. Transformer networks use self-attention for\nsequence modeling and comes with advantages in parallel computation and\ncapturing contexts. We propose 1) using VGGNet with causal convolution to\nincorporate positional information and reduce frame rate for efficient\ninference 2) using truncated self-attention to enable streaming for Transformer\nand reduce computational complexity. All experiments are conducted on the\npublic LibriSpeech corpus. The proposed Transformer-Transducer outperforms\nneural transducer with LSTM/BLSTM networks and achieved word error rates of\n6.37 % on the test-clean set and 15.30 % on the test-other set, while remaining\nstreamable, compact with 45.7M parameters for the entire system, and\ncomputationally efficient with complexity of O(T), where T is input sequence\nlength.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 21:29:21 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Yeh", "Ching-Feng", ""], ["Mahadeokar", "Jay", ""], ["Kalgaonkar", "Kaustubh", ""], ["Wang", "Yongqiang", ""], ["Le", "Duc", ""], ["Jain", "Mahaveer", ""], ["Schubert", "Kjell", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1910.12995", "submitter": "Tuan Manh Lai", "authors": "Tuan Manh Lai, Quan Hung Tran, Trung Bui, Daisuke Kihara", "title": "A Simple but Effective BERT Model for Dialog State Tracking on\n  Resource-Limited Systems", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a task-oriented dialog system, the goal of dialog state tracking (DST) is\nto monitor the state of the conversation from the dialog history. Recently,\nmany deep learning based methods have been proposed for the task. Despite their\nimpressive performance, current neural architectures for DST are typically\nheavily-engineered and conceptually complex, making it difficult to implement,\ndebug, and maintain them in a production setting. In this work, we propose a\nsimple but effective DST model based on BERT. In addition to its simplicity,\nour approach also has a number of other advantages: (a) the number of\nparameters does not grow with the ontology size (b) the model can operate in\nsituations where the domain ontology may change dynamically. Experimental\nresults demonstrate that our BERT-based model outperforms previous methods by a\nlarge margin, achieving new state-of-the-art results on the standard WoZ 2.0\ndataset. Finally, to make the model small and fast enough for\nresource-restricted systems, we apply the knowledge distillation method to\ncompress our model. The final compressed model achieves comparable results with\nthe original model while being 8x smaller and 7x faster.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 22:41:55 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 18:02:09 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 04:35:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lai", "Tuan Manh", ""], ["Tran", "Quan Hung", ""], ["Bui", "Trung", ""], ["Kihara", "Daisuke", ""]]}, {"id": "1910.13008", "submitter": "Wojciech Kry\\'sci\\'nski", "authors": "Michael Shum, Stephan Zheng, Wojciech Kry\\'sci\\'nski, Caiming Xiong,\n  Richard Socher", "title": "Sketch-Fill-A-R: A Persona-Grounded Chit-Chat Generation Framework", "comments": "10 pages, 9 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-like chit-chat conversation requires agents to generate responses that\nare fluent, engaging and consistent. We propose Sketch-Fill-A-R, a framework\nthat uses a persona-memory to generate chit-chat responses in three phases.\nFirst, it generates dynamic sketch responses with open slots. Second, it\ngenerates candidate responses by filling slots with parts of its stored persona\ntraits. Lastly, it ranks and selects the final response via a language model\nscore. Sketch-Fill-A-R outperforms a state-of-the-art baseline both\nquantitatively (10-point lower perplexity) and qualitatively (preferred by 55%\nheads-up in single-turn and 20% higher in consistency in multi-turn user\nstudies) on the Persona-Chat dataset. Finally, we extensively analyze\nSketch-Fill-A-R's responses and human feedback, and show it is more consistent\nand engaging by using more relevant responses and questions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 23:49:26 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Shum", "Michael", ""], ["Zheng", "Stephan", ""], ["Kry\u015bci\u0144ski", "Wojciech", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1910.13034", "submitter": "Lala Li", "authors": "Lala Li, William Chan", "title": "Big Bidirectional Insertion Representations for Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Insertion Transformer is well suited for long form text generation due to\nits parallel generation capabilities, requiring $O(\\log_2 n)$ generation steps\nto generate $n$ tokens. However, modeling long sequences is difficult, as there\nis more ambiguity captured in the attention mechanism. This work proposes the\nBig Bidirectional Insertion Representations for Documents (Big BIRD), an\ninsertion-based model for document-level translation tasks. We scale up the\ninsertion-based models to long form documents. Our key contribution is\nintroducing sentence alignment via sentence-positional embeddings between the\nsource and target document. We show an improvement of +4.3 BLEU on the WMT'19\nEnglish$\\rightarrow$German document-level translation task compared with the\nInsertion Transformer baseline.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:38:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Li", "Lala", ""], ["Chan", "William", ""]]}, {"id": "1910.13105", "submitter": "Bo Chen", "authors": "Bo Chen, Jing Zhang, Xiaobin Tang, Hong Chen, Cuiping Li", "title": "JarKA: Modeling Attribute Interactions for Cross-lingual Knowledge\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract. Cross-lingual knowledge alignment is the cornerstone in building a\ncomprehensive knowledge graph (KG), which can benefit various knowledge-driven\napplications. As the structures of KGs are usually sparse, attributes of\nentities may play an important role in aligning the entities. However, the\nheterogeneity of the attributes across KGs prevents from accurately embedding\nand comparing entities. To deal with the issue, we propose to model the\ninteractions between attributes, instead of globally embedding an entity with\nall the attributes. We further propose a joint framework to merge the\nalignments inferred from the attributes and the structures. Experimental\nresults show that the proposed model outperforms the state-of-art baselines by\nup to 38.48% HitRatio@1. The results also demonstrate that our model can infer\nthe alignments between attributes, relationships and values, in addition to\nentities.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:41:30 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 08:15:00 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Bo", ""], ["Zhang", "Jing", ""], ["Tang", "Xiaobin", ""], ["Chen", "Hong", ""], ["Li", "Cuiping", ""]]}, {"id": "1910.13106", "submitter": "Cao Liu", "authors": "Cao Liu, Kang Liu, Shizhu He, Zaiqing Nie and Jun Zhao", "title": "Incorporating Interlocutor-Aware Context into Response Generation on\n  Multi-Party Chatbots", "comments": "Accepted to CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional chatbots focus on two-party response generation, which\nsimplifies the real dialogue scene. In this paper, we strive toward a novel\ntask of Response Generation on Multi-Party Chatbot (RGMPC), where the generated\nresponses heavily rely on the interlocutors' roles (e.g., speaker and\naddressee) and their utterances. Unfortunately, complex interactions among the\ninterlocutors' roles make it challenging to precisely capture conversational\ncontexts and interlocutors' information. Facing this challenge, we present a\nresponse generation model which incorporates Interlocutor-aware Contexts into\nRecurrent Encoder-Decoder frameworks (ICRED) for RGMPC. Specifically, we employ\ninteractive representations to capture dialogue contexts for different\ninterlocutors. Moreover, we leverage an addressee memory to enhance contextual\ninterlocutor information for the target addressee. Finally, we construct a\ncorpus for RGMPC based on an existing open-access dataset. Automatic and manual\nevaluations demonstrate that the ICRED remarkably outperforms strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:43:51 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Liu", "Cao", ""], ["Liu", "Kang", ""], ["He", "Shizhu", ""], ["Nie", "Zaiqing", ""], ["Zhao", "Jun", ""]]}, {"id": "1910.13108", "submitter": "Cao Liu", "authors": "Cao Liu, Kang Liu, Shizhu He, Zaiqing Nie and Jun Zhao", "title": "Generating Questions for Knowledge Bases via Incorporating Diversified\n  Contexts and Answer-Aware Loss", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the task of question generation over knowledge bases. Conventional\nmethods for this task neglect two crucial research issues: 1) the given\npredicate needs to be expressed; 2) the answer to the generated question needs\nto be definitive. In this paper, we strive toward the above two issues via\nincorporating diversified contexts and answer-aware loss. Specifically, we\npropose a neural encoder-decoder model with multi-level copy mechanisms to\ngenerate such questions. Furthermore, the answer aware loss is introduced to\nmake generated questions corresponding to more definitive answers. Experiments\ndemonstrate that our model achieves state-of-the-art performance. Meanwhile,\nsuch generated question can express the given predicate and correspond to a\ndefinitive answer.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:45:24 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Liu", "Cao", ""], ["Liu", "Kang", ""], ["He", "Shizhu", ""], ["Nie", "Zaiqing", ""], ["Zhao", "Jun", ""]]}, {"id": "1910.13114", "submitter": "Hongfei Yu", "authors": "Xiangyu Duan, Hoongfei Yu, Mingming Yin, Min Zhang, Weihua Luo, Yue\n  Zhang", "title": "Contrastive Attention Mechanism for Abstractive Sentence Summarization", "comments": "accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a contrastive attention mechanism to extend the\nsequence-to-sequence framework for abstractive sentence summarization task,\nwhich aims to generate a brief summary of a given source sentence. The proposed\ncontrastive attention mechanism accommodates two categories of attention: one\nis the conventional attention that attends to relevant parts of the source\nsentence, the other is the opponent attention that attends to irrelevant or\nless relevant parts of the source sentence. Both attentions are trained in an\nopposite way so that the contribution from the conventional attention is\nencouraged and the contribution from the opponent attention is discouraged\nthrough a novel softmax and softmin functionality. Experiments on benchmark\ndatasets show that, the proposed contrastive attention mechanism is more\nfocused on the relevant parts for the summary than the conventional attention\nmechanism, and greatly advances the state-of-the-art performance on the\nabstractive sentence summarization task. We release the code at\nhttps://github.com/travel-go/Abstractive-Text-Summarization\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 06:56:46 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 05:33:27 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Duan", "Xiangyu", ""], ["Yu", "Hoongfei", ""], ["Yin", "Mingming", ""], ["Zhang", "Min", ""], ["Luo", "Weihua", ""], ["Zhang", "Yue", ""]]}, {"id": "1910.13162", "submitter": "Hoang Nhat Suong", "authors": "Suong N. Hoang, Linh V. Nguyen, Tai Huynh and Vuong T. Pham", "title": "An Efficient Model for Sentiment Analysis of Electronic Product Reviews\n  in Vietnamese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the past few years, the growth of e-commerce and digital marketing in\nVietnam has generated a huge volume of opinionated data. Analyzing those data\nwould provide enterprises with insight for better business decisions. In this\nwork, as part of the Advosights project, we study sentiment analysis of product\nreviews in Vietnamese. The final solution is based on Self-attention neural\nnetworks, a flexible architecture for text classification task with about\n90.16% of accuracy in 0.0124 second, a very fast inference time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 10:06:56 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Hoang", "Suong N.", ""], ["Nguyen", "Linh V.", ""], ["Huynh", "Tai", ""], ["Pham", "Vuong T.", ""]]}, {"id": "1910.13212", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Emily Mower Provost", "title": "Privacy Enhanced Multimodal Neural Representations for Emotion\n  Recognition", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mobile applications and virtual conversational agents now aim to\nrecognize and adapt to emotions. To enable this, data are transmitted from\nusers' devices and stored on central servers. Yet, these data contain sensitive\ninformation that could be used by mobile applications without user's consent\nor, maliciously, by an eavesdropping adversary. In this work, we show how\nmultimodal representations trained for a primary task, here emotion\nrecognition, can unintentionally leak demographic information, which could\noverride a selected opt-out option by the user. We analyze how this leakage\ndiffers in representations obtained from textual, acoustic, and multimodal\ndata. We use an adversarial learning paradigm to unlearn the private\ninformation present in a representation and investigate the effect of varying\nthe strength of the adversarial component on the primary task and on the\nprivacy metric, defined here as the inability of an attacker to predict\nspecific demographic information. We evaluate this paradigm on multiple\ndatasets and show that we can improve the privacy metric while not\nsignificantly impacting the performance on the primary task. To the best of our\nknowledge, this is the first work to analyze how the privacy metric differs\nacross modalities and how multiple privacy concerns can be tackled while still\nmaintaining performance on emotion recognition.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:49:30 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1910.13215", "submitter": "Zixiu Wu", "authors": "Zixiu Wu, Ozan Caglayan, Julia Ive, Josiah Wang, Lucia Specia", "title": "Transformer-based Cascaded Multimodal Speech Translation", "comments": "Accepted to IWSLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the cascaded multimodal speech translation systems\ndeveloped by Imperial College London for the IWSLT 2019 evaluation campaign.\nThe architecture consists of an automatic speech recognition (ASR) system\nfollowed by a Transformer-based multimodal machine translation (MMT) system.\nWhile the ASR component is identical across the experiments, the MMT model\nvaries in terms of the way of integrating the visual context (simple\nconditioning vs. attention), the type of visual features exploited (pooled,\nconvolutional, action categories) and the underlying architecture. For the\nlatter, we explore both the canonical transformer and its deliberation version\nwith additive and cascade variants which differ in how they integrate the\ntextual attention. Upon conducting extensive experiments, we found that (i) the\nexplored visual integration schemes often harm the translation performance for\nthe transformer and additive deliberation, but considerably improve the cascade\ndeliberation; (ii) the transformer and cascade deliberation integrate the\nvisual modality better than the additive deliberation, as shown by the\nincongruence analysis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:56:12 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:17:04 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 20:04:10 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Wu", "Zixiu", ""], ["Caglayan", "Ozan", ""], ["Ive", "Julia", ""], ["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1910.13267", "submitter": "Elena Voita", "authors": "Ivan Provilkov, Dmitrii Emelianenko, Elena Voita", "title": "BPE-Dropout: Simple and Effective Subword Regularization", "comments": "ACL 2020 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subword segmentation is widely used to address the open vocabulary problem in\nmachine translation. The dominant approach to subword segmentation is Byte Pair\nEncoding (BPE), which keeps the most frequent words intact while splitting the\nrare ones into multiple tokens. While multiple segmentations are possible even\nwith the same vocabulary, BPE splits words into unique sequences; this may\nprevent a model from better learning the compositionality of words and being\nrobust to segmentation errors. So far, the only way to overcome this BPE\nimperfection, its deterministic nature, was to create another subword\nsegmentation algorithm (Kudo, 2018). In contrast, we show that BPE itself\nincorporates the ability to produce multiple segmentations of the same word. We\nintroduce BPE-dropout - simple and effective subword regularization method\nbased on and compatible with conventional BPE. It stochastically corrupts the\nsegmentation procedure of BPE, which leads to producing multiple segmentations\nwithin the same fixed BPE framework. Using BPE-dropout during training and the\nstandard BPE during inference improves translation quality up to 3 BLEU\ncompared to BPE and up to 0.9 BLEU compared to the previous subword\nregularization.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 13:42:56 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 18:54:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Provilkov", "Ivan", ""], ["Emelianenko", "Dmitrii", ""], ["Voita", "Elena", ""]]}, {"id": "1910.13276", "submitter": "Xinyong Zhou", "authors": "Xinyong Zhou, Hao Che, Xiaorui Wang, Lei Xie", "title": "a novel cross-lingual voice cloning approach with a few text-free\n  samples", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a cross-lingual voice cloning approach. BN features\nobtained by SI-ASR model are used as a bridge across speakers and language\nboundaries. The relationships between text and BN features are modeled by the\nlatent prosody model. The acoustic model learns the translation from BN\nfeatures to acoustic features. The acoustic model is fine-tuned with a few\nsamples of the target speaker to realize voice cloning. This system can\ngenerate speech of arbitrary utterance of target language in cross-lingual\nspeakers' voice. We verify that with small amount of audio data, our proposed\napproach can well handle cross-lingual tasks. And in intra-lingual tasks, our\nproposed approach also performs better than baseline approach in naturalness\nand similarity.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:06:49 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 06:13:33 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Zhou", "Xinyong", ""], ["Che", "Hao", ""], ["Wang", "Xiaorui", ""], ["Xie", "Lei", ""]]}, {"id": "1910.13291", "submitter": "Ekaterina Artemova", "authors": "Dmitry Popov and Alexander Pugachev and Polina Svyatokum and Elizaveta\n  Svitanko and Ekaterina Artemova", "title": "Sentence Embeddings for Russian NLU", "comments": "to appear in AIST2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the performance of sentence embeddings models on several tasks\nfor the Russian language. In our comparison, we include such tasks as multiple\nchoice question answering, next sentence prediction, and paraphrase\nidentification. We employ FastText embeddings as a baseline and compare it to\nELMo and BERT embeddings. We conduct two series of experiments, using both\nunsupervised (i.e., based on similarity measure only) and supervised approaches\nfor the tasks. Finally, we present datasets for multiple choice question\nanswering and next sentence prediction in Russian.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:28:34 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Popov", "Dmitry", ""], ["Pugachev", "Alexander", ""], ["Svyatokum", "Polina", ""], ["Svitanko", "Elizaveta", ""], ["Artemova", "Ekaterina", ""]]}, {"id": "1910.13294", "submitter": "Mo Yu", "authors": "Mo Yu, Shiyu Chang, Yang Zhang, Tommi S. Jaakkola", "title": "Rethinking Cooperative Rationalization: Introspective Extraction and\n  Complement Control", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective rationalization has become a common mechanism to ensure that\npredictive models reveal how they use any available features. The selection may\nbe soft or hard, and identifies a subset of input features relevant for\nprediction. The setup can be viewed as a co-operate game between the selector\n(aka rationale generator) and the predictor making use of only the selected\nfeatures. The co-operative setting may, however, be compromised for two\nreasons. First, the generator typically has no direct access to the outcome it\naims to justify, resulting in poor performance. Second, there's typically no\ncontrol exerted on the information left outside the selection. We revise the\noverall co-operative framework to address these challenges. We introduce an\nintrospective model which explicitly predicts and incorporates the outcome into\nthe selection process. Moreover, we explicitly control the rationale complement\nvia an adversary so as not to leave any useful information out of the\nselection. We show that the two complementary mechanisms maintain both high\npredictive accuracy and lead to comprehensive rationales.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:32:54 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 21:21:15 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1910.13299", "submitter": "Hiroaki Hayashi", "authors": "Hiroaki Hayashi, Yusuke Oda, Alexandra Birch, Ioannis Konstas, Andrew\n  Finch, Minh-Thang Luong, Graham Neubig, Katsuhito Sudoh", "title": "Findings of the Third Workshop on Neural Generation and Translation", "comments": "Fixed the metadata (author list)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the findings of the Third Workshop on Neural\nGeneration and Translation, held in concert with the annual conference of the\nEmpirical Methods in Natural Language Processing (EMNLP 2019). First, we\nsummarize the research trends of papers presented in the proceedings. Second,\nwe describe the results of the two shared tasks 1) efficient neural machine\ntranslation (NMT) where participants were tasked with creating NMT systems that\nare both accurate and efficient, and 2) document-level generation and\ntranslation (DGT) where participants were tasked with developing systems that\ngenerate summaries from structured data, potentially with assistance from text\nin another language.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 14:41:19 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 01:17:20 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Hayashi", "Hiroaki", ""], ["Oda", "Yusuke", ""], ["Birch", "Alexandra", ""], ["Konstas", "Ioannis", ""], ["Finch", "Andrew", ""], ["Luong", "Minh-Thang", ""], ["Neubig", "Graham", ""], ["Sudoh", "Katsuhito", ""]]}, {"id": "1910.13339", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Gang Niu, Yoav Goldberg, Masashi Sugiyama", "title": "Scalable Evaluation and Improvement of Document Set Expansion via Neural\n  Positive-Unlabeled Learning", "comments": "Accepted as a long paper to EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the situation in which a user has collected a small set of\ndocuments on a cohesive topic, and they want to retrieve additional documents\non this topic from a large collection. Information Retrieval (IR) solutions\ntreat the document set as a query, and look for similar documents in the\ncollection. We propose to extend the IR approach by treating the problem as an\ninstance of positive-unlabeled (PU) learning -- i.e., learning binary\nclassifiers from only positive and unlabeled data, where the positive data\ncorresponds to the query documents, and the unlabeled data is the results\nreturned by the IR engine. Utilizing PU learning for text with big neural\nnetworks is a largely unexplored field. We discuss various challenges in\napplying PU learning to the setting, including an unknown class prior,\nextremely imbalanced data and large-scale accurate evaluation of models, and we\npropose solutions and empirically validate them. We demonstrate the\neffectiveness of the method using a series of experiments of retrieving PubMed\nabstracts adhering to fine-grained topics. We demonstrate improvements over the\nbase IR solution and other baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:56:33 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 20:48:36 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Jacovi", "Alon", ""], ["Niu", "Gang", ""], ["Goldberg", "Yoav", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1910.13425", "submitter": "Pratik Kayal", "authors": "Pratik Kayal, Mayank Singh, Pawan Goyal", "title": "Weakly-Supervised Deep Learning for Domain Invariant Sentiment\n  Classification", "comments": "5 Pages, 3 tables", "journal-ref": null, "doi": "10.1145/3371158.3371194", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of learning a sentiment classification model that adapts well to any\ntarget domain, different from the source domain, is a challenging problem.\nMajority of the existing approaches focus on learning a common representation\nby leveraging both source and target data during training. In this paper, we\nintroduce a two-stage training procedure that leverages weakly supervised\ndatasets for developing simple lift-and-shift-based predictive models without\nbeing exposed to the target domain during the training phase. Experimental\nresults show that transfer with weak supervision from a source domain to\nvarious target domains provides performance very close to that obtained via\nsupervised training on the target domain itself.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:43:37 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 06:59:48 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kayal", "Pratik", ""], ["Singh", "Mayank", ""], ["Goyal", "Pawan", ""]]}, {"id": "1910.13437", "submitter": "William Chan", "authors": "William Chan, Mitchell Stern, Jamie Kiros, Jakob Uszkoreit", "title": "An Empirical Study of Generation Order for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an empirical study of generation order for machine\ntranslation. Building on recent advances in insertion-based modeling, we first\nintroduce a soft order-reward framework that enables us to train models to\nfollow arbitrary oracle generation policies. We then make use of this framework\nto explore a large variety of generation orders, including uninformed orders,\nlocation-based orders, frequency-based orders, content-based orders, and\nmodel-based orders. Curiously, we find that for the WMT'14 English $\\to$ German\ntranslation task, order does not have a substantial impact on output quality,\nwith unintuitive orderings such as alphabetical and shortest-first matching the\nperformance of a standard Transformer. This demonstrates that traditional\nleft-to-right generation is not strictly necessary to achieve high performance.\nOn the other hand, results on the WMT'18 English $\\to$ Chinese task tend to\nvary more widely, suggesting that translation for less well-aligned language\npairs may be more sensitive to generation order.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 17:54:36 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Chan", "William", ""], ["Stern", "Mitchell", ""], ["Kiros", "Jamie", ""], ["Uszkoreit", "Jakob", ""]]}, {"id": "1910.13461", "submitter": "Marjan Ghazvininejad", "authors": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman\n  Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer", "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language\n  Generation, Translation, and Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BART, a denoising autoencoder for pretraining sequence-to-sequence\nmodels. BART is trained by (1) corrupting text with an arbitrary noising\nfunction, and (2) learning a model to reconstruct the original text. It uses a\nstandard Tranformer-based neural machine translation architecture which,\ndespite its simplicity, can be seen as generalizing BERT (due to the\nbidirectional encoder), GPT (with the left-to-right decoder), and many other\nmore recent pretraining schemes. We evaluate a number of noising approaches,\nfinding the best performance by both randomly shuffling the order of the\noriginal sentences and using a novel in-filling scheme, where spans of text are\nreplaced with a single mask token. BART is particularly effective when fine\ntuned for text generation but also works well for comprehension tasks. It\nmatches the performance of RoBERTa with comparable training resources on GLUE\nand SQuAD, achieves new state-of-the-art results on a range of abstractive\ndialogue, question answering, and summarization tasks, with gains of up to 6\nROUGE. BART also provides a 1.1 BLEU increase over a back-translation system\nfor machine translation, with only target language pretraining. We also report\nablation experiments that replicate other pretraining schemes within the BART\nframework, to better measure which factors most influence end-task performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 18:01:00 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lewis", "Mike", ""], ["Liu", "Yinhan", ""], ["Goyal", "Naman", ""], ["Ghazvininejad", "Marjan", ""], ["Mohamed", "Abdelrahman", ""], ["Levy", "Omer", ""], ["Stoyanov", "Ves", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1910.13466", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Arian Hosseini, Zhouhan Lin, Alessandro\n  Sordoni, Aaron Courville", "title": "Ordered Memory", "comments": "Published in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stack-augmented recurrent neural networks (RNNs) have been of interest to the\ndeep learning community for some time. However, the difficulty of training\nmemory models remains a problem obstructing the widespread use of such models.\nIn this paper, we propose the Ordered Memory architecture. Inspired by Ordered\nNeurons (Shen et al., 2018), we introduce a new attention-based mechanism and\nuse its cumulative probability to control the writing and erasing operation of\nthe memory. We also introduce a new Gated Recursive Cell to compose lower-level\nrepresentations into higher-level representation. We demonstrate that our model\nachieves strong performance on the logical inference task (Bowman et al.,\n2015)and the ListOps (Nangia and Bowman, 2018) task. We can also interpret the\nmodel to retrieve the induced tree structure, and find that these induced\nstructures align with the ground truth. Finally, we evaluate our model on the\nStanford SentimentTreebank tasks (Socher et al., 2013), and find that it\nperforms comparatively with the state-of-the-art methods in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 18:14:14 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 18:10:34 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Hosseini", "Arian", ""], ["Lin", "Zhouhan", ""], ["Sordoni", "Alessandro", ""], ["Courville", "Aaron", ""]]}, {"id": "1910.13488", "submitter": "Bhavya Ghai", "authors": "Bhavya Ghai, Buvana Ramanan, Klaus Mueller", "title": "Does Speech enhancement of publicly available data help build robust\n  Speech Recognition Systems?", "comments": "Accepted to AAAI conference of Artificial Intelligence 2020\n  (abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems play a key role in many commercial\nproducts including voice assistants. Typically, they require large amounts of\nclean speech data for training which gives an undue advantage to large\norganizations which have tons of private data. In this paper, we have first\ncurated a fairly big dataset using publicly available data sources. Thereafter,\nwe tried to investigate if we can use publicly available noisy data to train\nrobust ASR systems. We have used speech enhancement to clean the noisy data\nfirst and then used it together with its cleaned version to train ASR systems.\nWe have found that using speech enhancement gives 9.5\\% better word error rate\nthan training on just noisy data and 9\\% better than training on just clean\ndata. It's performance is also comparable to the ideal case scenario when\ntrained on noisy and its clean version.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:23:16 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 05:53:39 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ghai", "Bhavya", ""], ["Ramanan", "Buvana", ""], ["Mueller", "Klaus", ""]]}, {"id": "1910.13497", "submitter": "Adina Williams", "authors": "Adina Williams and Ryan Cotterell and Lawrence Wolf-Sonkin and\n  Dami\\'an Blasi and Hanna Wallach", "title": "Quantifying the Semantic Core of Gender Systems", "comments": "6 pages, 2 figures, accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the world's languages employ grammatical gender on the lexeme. For\nexample, in Spanish, the word for 'house' (casa) is feminine, whereas the word\nfor 'paper' (papel) is masculine. To a speaker of a genderless language, this\nassignment seems to exist with neither rhyme nor reason. But is the assignment\nof inanimate nouns to grammatical genders truly arbitrary? We present the first\nlarge-scale investigation of the arbitrariness of noun-gender assignments. To\nthat end, we use canonical correlation analysis to correlate the grammatical\ngender of inanimate nouns with an externally grounded definition of their\nlexical semantics. We find that 18 languages exhibit a significant correlation\nbetween grammatical gender and lexical semantics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 19:44:17 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Williams", "Adina", ""], ["Cotterell", "Ryan", ""], ["Wolf-Sonkin", "Lawrence", ""], ["Blasi", "Dami\u00e1n", ""], ["Wallach", "Hanna", ""]]}, {"id": "1910.13573", "submitter": "Neil Deshmukh", "authors": "Neil Deshmukh, Selin Gumustop, Romane Gauriau, Varun Buch, Bradley\n  Wright, Christopher Bridge, Ram Naidu, Katherine Andriole, and Bernardo Bizzo", "title": "Semi-Supervised Natural Language Approach for Fine-Grained\n  Classification of Medical Reports", "comments": "Accepted for IEEE publication & presented at MIT URTC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although machine learning has become a powerful tool to augment doctors in\nclinical analysis, the immense amount of labeled data that is necessary to\ntrain supervised learning approaches burdens each development task as time and\nresource intensive. The vast majority of dense clinical information is stored\nin written reports, detailing pertinent patient information. The challenge with\nutilizing natural language data for standard model development is due to the\ncomplex nature of the modality. In this research, a model pipeline was\ndeveloped to utilize an unsupervised approach to train an encoder-language\nmodel, a recurrent network, to generate document encodings; which then can be\nused as features passed into a decoder-classifier model that requires\nmagnitudes less labeled data than previous approaches to differentiate between\nfine-grained disease classes accurately. The language model was trained on\nunlabeled radiology reports from the Massachusetts General Hospital Radiology\nDepartment (n=218,159) and terminated with a loss of 1.62. The classification\nmodels were trained on three labeled datasets of head CT studies of reported\npatients, presenting large vessel occlusion (n=1403), acute ischemic strokes\n(n=331), and intracranial hemorrhage (n=4350), to identify a variety of\ndifferent findings directly from the radiology report data; resulting in AUCs\nof 0.98, 0.95, and 0.99, respectively, for the large vessel occlusion, acute\nischemic stroke, and intracranial hemorrhage datasets. The output encodings are\nable to be used in conjunction with imaging data, to create models that can\nprocess a multitude of different modalities. The ability to automatically\nextract relevant features from textual data allows for faster model development\nand integration of textual modality, overall, allowing clinical reports to\nbecome a more viable input for more encompassing and accurate deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 23:25:59 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 03:18:19 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Deshmukh", "Neil", ""], ["Gumustop", "Selin", ""], ["Gauriau", "Romane", ""], ["Buch", "Varun", ""], ["Wright", "Bradley", ""], ["Bridge", "Christopher", ""], ["Naidu", "Ram", ""], ["Andriole", "Katherine", ""], ["Bizzo", "Bernardo", ""]]}, {"id": "1910.13634", "submitter": "HaiLiang Li", "authors": "Hailiang Li, Adele Y.C. Wang, Yang Liu, Du Tang, Zhibin Lei, Wenye Li", "title": "An Augmented Transformer Architecture for Natural Language Generation\n  Tasks", "comments": "This paper will be appeared in the conference workshop ICDM MLCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Transformer based neural networks have been showing significant\nadvantages on most evaluations of various natural language processing and other\nsequence-to-sequence tasks due to its inherent architecture based\nsuperiorities. Although the main architecture of the Transformer has been\ncontinuously being explored, little attention was paid to the positional\nencoding module. In this paper, we enhance the sinusoidal positional encoding\nalgorithm by maximizing the variances between encoded consecutive positions to\nobtain additional promotion. Furthermore, we propose an augmented Transformer\narchitecture encoded with additional linguistic knowledge, such as the\nPart-of-Speech (POS) tagging, to boost the performance on some natural language\ngeneration tasks, e.g., the automatic translation and summarization tasks.\nExperiments show that the proposed architecture attains constantly superior\nresults compared to the vanilla Transformer.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 02:46:04 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Li", "Hailiang", ""], ["Wang", "Adele Y. C.", ""], ["Liu", "Yang", ""], ["Tang", "Du", ""], ["Lei", "Zhibin", ""], ["Li", "Wenye", ""]]}, {"id": "1910.13664", "submitter": "Andriy Mulyar", "authors": "Andriy Mulyar, Elliot Schumacher, Masoud Rouhizadeh and Mark Dredze", "title": "Phenotyping of Clinical Notes with Improved Document Classification\n  Models Using Contextualized Neural Language Models", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract The original paper was published in December 2019. After\n  publication, we identified a bug in our code that resulted in an error in our\n  reported results. This version of the paper corrects that error and clarifies\n  some of our descriptions of the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes contain an extensive record of a patient's health status, such\nas smoking status or the presence of heart conditions. However, this detail is\nnot replicated within the structured data of electronic health systems.\nPhenotyping, the extraction of patient conditions from free clinical text, is a\ncritical task which supports avariety of downstream applications such as\ndecision support and secondary use of medical records. Previous work has\nresulted in systems which are high performing but require hand engineering,\noften of rules. Recent work in pretrained contextualized language models have\nenabled advances in representing text for a variety of tasks. We therefore\nexplore several architectures for modeling pheno-typing that rely solely on\nBERT representations of the clinical note, removing the need for manual\nengineering. We find these architectures are competitive with or outperform\nexisting state of the art methods on two phenotyping tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 04:47:17 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 02:12:24 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mulyar", "Andriy", ""], ["Schumacher", "Elliot", ""], ["Rouhizadeh", "Masoud", ""], ["Dredze", "Mark", ""]]}, {"id": "1910.13689", "submitter": "Laurent Besacier", "authors": "Ha Nguyen and Natalia Tomashenko and Marcely Zanon Boito and Antoine\n  Caubriere and Fethi Bougares and Mickael Rouvier and Laurent Besacier and\n  Yannick Esteve", "title": "ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT\n  2019 Shared Task", "comments": "IWSLT 2019 - First two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the ON-TRAC Consortium translation systems developed for\nthe end-to-end model task of IWSLT Evaluation 2019 for the\nEnglish-to-Portuguese language pair. ON-TRAC Consortium is composed of\nresearchers from three French academic laboratories: LIA (Avignon\nUniversit\\'e), LIG (Universit\\'e Grenoble Alpes), and LIUM (Le Mans\nUniversit\\'e). A single end-to-end model built as a neural encoder-decoder\narchitecture with attention mechanism was used for two primary submissions\ncorresponding to the two EN-PT evaluations sets: (1) TED (MuST-C) and (2) How2.\nIn this paper, we notably investigate impact of pooling heterogeneous corpora\nfor training, impact of target tokenization (characters or BPEs), impact of\nspeech input segmentation and we also compare our best end-to-end model (BLEU\nof 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT)\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 06:11:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Nguyen", "Ha", ""], ["Tomashenko", "Natalia", ""], ["Boito", "Marcely Zanon", ""], ["Caubriere", "Antoine", ""], ["Bougares", "Fethi", ""], ["Rouvier", "Mickael", ""], ["Besacier", "Laurent", ""], ["Esteve", "Yannick", ""]]}, {"id": "1910.13707", "submitter": "Christoph Boeddeker", "authors": "Christoph Boeddeker, Tomohiro Nakatani, Keisuke Kinoshita, Reinhold\n  Haeb-Umbach", "title": "Jointly optimal dereverberation and beamforming", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We previously proposed an optimal (in the maximum likelihood sense)\nconvolutional beamformer that can perform simultaneous denoising and\ndereverberation, and showed its superiority over the widely used cascade of a\nWPE dereverberation filter and a conventional MPDR beamformer. However, it has\nnot been fully investigated which components in the convolutional beamformer\nyield such superiority. To this end, this paper presents a new derivation of\nthe convolutional beamformer that allows us to factorize it into a WPE\ndereverberation filter, and a special type of a (non-convolutional) beamformer,\nreferred to as a wMPDR beamformer, without loss of optimality. With\nexperiments, we show that the superiority of the convolutional beamformer in\nfact comes from its wMPDR part.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 08:11:05 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Boeddeker", "Christoph", ""], ["Nakatani", "Tomohiro", ""], ["Kinoshita", "Keisuke", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1910.13732", "submitter": "Binh Nguyen Duc", "authors": "Binh Duc Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "LSTM Easy-first Dependency Parsing with Pre-trained Word Embeddings and\n  Character-level Word Embeddings in Vietnamese", "comments": null, "journal-ref": "10th International Conference on Knowledge and Systems Engineering\n  (KSE). IEEE, 2018. p. 187-192", "doi": "10.1109/KSE.2018.8573397", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Vietnamese dependency parsing, several methods have been proposed.\nDependency parser which uses deep neural network model has been reported that\nachieved state-of-the-art results. In this paper, we proposed a new method\nwhich applies LSTM easy-first dependency parsing with pre-trained word\nembeddings and character-level word embeddings. Our method achieves an accuracy\nof 80.91% of unlabeled attachment score and 72.98% of labeled attachment score\non the Vietnamese Dependency Treebank (VnDT).\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 09:28:49 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Nguyen", "Binh Duc", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1910.13793", "submitter": "Pieter Delobelle", "authors": "Pieter Delobelle and Bettina Berendt", "title": "Time to Take Emoji Seriously: They Vastly Improve Casual Conversational\n  Models", "comments": "Accepted at Benelearn 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphical emoji are ubiquitous in modern-day online conversations. So is a\nsingle thumbs-up emoji able to signify an agreement, without any words. We\nargue that the current state-of-the-art systems are ill-equipped to correctly\ninterpret these emoji, especially in a conversational context. However, in a\ncasual context, the benefits might be high: a better understanding of users'\nutterances and more natural, emoji-rich responses.\n  With this in mind, we modify BERT to fully support emoji, both from the\nUnicode Standard and custom emoji. This modified BERT is then trained on a\ncorpus of question-answer (QA) tuples with a high number of emoji, where we're\nable to increase the 1-of-100 accuracy from 12.7% for the current\nstate-of-the-art to 17.8% for our model with emoji support.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:11:36 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Delobelle", "Pieter", ""], ["Berendt", "Bettina", ""]]}, {"id": "1910.13794", "submitter": "Junmo Kang", "authors": "Junmo Kang, Haritz Puerto San Roman, Sung-Hyon Myaeng", "title": "Let Me Know What to Ask: Interrogative-Word-Aware Question Generation", "comments": "Accepted at 2nd Workshop on Machine Reading for Question Answering\n  (MRQA), EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Generation (QG) is a Natural Language Processing (NLP) task that\naids advances in Question Answering (QA) and conversational assistants.\nExisting models focus on generating a question based on a text and possibly the\nanswer to the generated question. They need to determine the type of\ninterrogative word to be generated while having to pay attention to the grammar\nand vocabulary of the question. In this work, we propose\nInterrogative-Word-Aware Question Generation (IWAQG), a pipelined system\ncomposed of two modules: an interrogative word classifier and a QG model. The\nfirst module predicts the interrogative word that is provided to the second\nmodule to create the question. Owing to an increased recall of deciding the\ninterrogative words to be used for the generated questions, the proposed model\nachieves new state-of-the-art results on the task of QG in SQuAD, improving\nfrom 46.58 to 47.69 in BLEU-1, 17.55 to 18.53 in BLEU-4, 21.24 to 22.33 in\nMETEOR, and from 44.53 to 46.94 in ROUGE-L.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:14:11 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kang", "Junmo", ""], ["Roman", "Haritz Puerto San", ""], ["Myaeng", "Sung-Hyon", ""]]}, {"id": "1910.13826", "submitter": "Kazunori Komatani", "authors": "Mikio Nakano and Kazunori Komatani", "title": "A Framework for Building Closed-Domain Chat Dialogue Systems", "comments": "24 pages", "journal-ref": "Knowledge-Based Systems, Volume 204, 2020", "doi": "10.1016/j.knosys.2020.106212", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents HRIChat, a framework for developing closed-domain chat\ndialogue systems. Being able to engage in chat dialogues has been found\neffective for improving communication between humans and dialogue systems. This\npaper focuses on closed-domain systems because they would be useful when\ncombined with task-oriented dialogue systems in the same domain. HRIChat\nenables domain-dependent language understanding so that it can deal well with\ndomain-specific utterances. In addition, HRIChat makes it possible to integrate\nstate transition network-based dialogue management and reaction-based dialogue\nmanagement. FoodChatbot, which is an application in the food and restaurant\ndomain, has been developed and evaluated through a user study. Its results\nsuggest that reasonably good systems can be developed with HRIChat. This paper\nalso reports lessons learned from the development and evaluation of\nFoodChatbot.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 13:06:23 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 08:44:36 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 02:22:23 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 00:30:01 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Nakano", "Mikio", ""], ["Komatani", "Kazunori", ""]]}, {"id": "1910.13890", "submitter": "Duygu Ataman", "authors": "Duygu Ataman, Wilker Aziz, Alexandra Birch", "title": "A Latent Morphology Model for Open-Vocabulary Neural Machine Translation", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translation into morphologically-rich languages challenges neural machine\ntranslation (NMT) models with extremely sparse vocabularies where atomic\ntreatment of surface forms is unrealistic. This problem is typically addressed\nby either pre-processing words into subword units or performing translation\ndirectly at the level of characters. The former is based on word segmentation\nalgorithms optimized using corpus-level statistics with no regard to the\ntranslation task. The latter learns directly from translation data but requires\nrather deep architectures. In this paper, we propose to translate words by\nmodeling word formation through a hierarchical latent variable model which\nmimics the process of morphological inflection. Our model generates words one\ncharacter at a time by composing two latent representations: a continuous one,\naimed at capturing the lexical semantics, and a set of (approximately) discrete\nfeatures, aimed at capturing the morphosyntactic function, which are shared\namong different surface forms. Our model achieves better accuracy in\ntranslation into three morphologically-rich languages than conventional\nopen-vocabulary NMT methods, while also demonstrating a better generalization\ncapacity under low to mid-resource settings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:29:47 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:34:30 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 20:47:17 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Ataman", "Duygu", ""], ["Aziz", "Wilker", ""], ["Birch", "Alexandra", ""]]}, {"id": "1910.13913", "submitter": "Yang (Trista) Cao", "authors": "Yang Trista Cao, Hal Daum\\'e III", "title": "Toward Gender-Inclusive Coreference Resolution", "comments": "28 pages; ACL version", "journal-ref": "Association for Computational Linguistics. Proceedings of the 58th\n  Annual Meeting of the Association for Computational Linguistics (2020)\n  4568-4595", "doi": "10.18653/v1/2020.acl-main.418", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly resolving textual mentions of people fundamentally entails making\ninferences about those people. Such inferences raise the risk of systemic\nbiases in coreference resolution systems, including biases that can harm binary\nand non-binary trans and cis stakeholders. To better understand such biases, we\nforeground nuanced conceptualizations of gender from sociology and\nsociolinguistics, and develop two new datasets for interrogating bias in crowd\nannotations and in existing coreference resolution systems. Through these\nstudies, conducted on English text, we confirm that without acknowledging and\nbuilding systems that recognize the complexity of gender, we build systems that\nlead to many potential harms.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 14:59:56 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:09:06 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 17:03:47 GMT"}, {"version": "v4", "created": "Wed, 2 Dec 2020 16:41:16 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Cao", "Yang Trista", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1910.13923", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Samuel Cahyawijaya, Zhaojiang Lin, Zihan Liu,\n  Pascale Fung", "title": "Lightweight and Efficient End-to-End Speech Recognition Using Low-Rank\n  Transformer", "comments": "The first two authors contributed equally to this work. Accepted as\n  an oral presentation in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly performing deep neural networks come at the cost of computational\ncomplexity that limits their practicality for deployment on portable devices.\nWe propose the low-rank transformer (LRT), a memory-efficient and fast neural\narchitecture that significantly reduces the parameters and boosts the speed of\ntraining and inference for end-to-end speech recognition. Our approach reduces\nthe number of parameters of the network by more than 50% and speeds up the\ninference time by around 1.35x compared to the baseline transformer model. The\nexperiments show that our LRT model generalizes better and yields lower error\nrates on both validation and test sets compared to an uncompressed transformer\nmodel. The LRT model outperforms those from existing works on several datasets\nin an end-to-end setting without using an external language model or acoustic\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:20:07 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:09:09 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 08:06:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Winata", "Genta Indra", ""], ["Cahyawijaya", "Samuel", ""], ["Lin", "Zhaojiang", ""], ["Liu", "Zihan", ""], ["Fung", "Pascale", ""]]}, {"id": "1910.13934", "submitter": "Christoph Boeddeker", "authors": "Lukas Drude, Jens Heitkaemper, Christoph Boeddeker, Reinhold\n  Haeb-Umbach", "title": "SMS-WSJ: Database, performance measures, and baseline recipe for\n  multi-channel source separation and recognition", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-channel database of overlapping speech for training,\nevaluation, and detailed analysis of source separation and extraction\nalgorithms: SMS-WSJ -- Spatialized Multi-Speaker Wall Street Journal. It\nconsists of artificially mixed speech taken from the WSJ database, but unlike\nearlier databases we consider all WSJ0+1 utterances and take care of strictly\nseparating the speaker sets present in the training, validation and test sets.\nWhen spatializing the data we ensure a high degree of randomness w.r.t. room\nsize, array center and rotation, as well as speaker position. Furthermore, this\npaper offers a critical assessment of recently proposed measures of source\nseparation performance. Alongside the code to generate the database we provide\na source separation baseline and a Kaldi recipe with competitive word error\nrates to provide common ground for evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:39:31 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Drude", "Lukas", ""], ["Heitkaemper", "Jens", ""], ["Boeddeker", "Christoph", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1910.13946", "submitter": "Mika H\\\"am\\\"al\\\"ainen", "authors": "Mika H\\\"am\\\"al\\\"ainen and Khalid Alnajjar", "title": "Let's FACE it. Finnish Poetry Generation with Aesthetics and Framing", "comments": null, "journal-ref": "Proceedings of the 12th International Conference on Natural\n  Language Generation (INLG 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a creative poem generator for the morphologically rich Finnish\nlanguage. Our method falls into the master-apprentice paradigm, where a\ncomputationally creative genetic algorithm teaches a BRNN model to generate\npoetry. We model several parts of poetic aesthetics in the fitness function of\nthe genetic algorithm, such as sonic features, semantic coherence, imagery and\nmetaphor. Furthermore, we justify the creativity of our method based on the\nFACE theory on computational creativity and take additional care in evaluating\nour system by automatic metrics for concepts together with human evaluation for\naesthetics, framing and expressions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 16:00:54 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Alnajjar", "Khalid", ""]]}, {"id": "1910.13998", "submitter": "Surafel Melaku Lakew Mr.", "authors": "Surafel M. Lakew, Alina Karakanta, Marcello Federico, Matteo Negri,\n  Marco Turchi", "title": "Adapting Multilingual Neural Machine Translation to Unseen Languages", "comments": "Accepted at the 16th International Workshop on Spoken Language\n  Translation (IWSLT), November, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multilingual Neural Machine Translation (MNMT) for low-resource languages\n(LRL) can be enhanced by the presence of related high-resource languages (HRL),\nbut the relatedness of HRL usually relies on predefined linguistic assumptions\nabout language similarity. Recently, adapting MNMT to a LRL has shown to\ngreatly improve performance. In this work, we explore the problem of adapting\nan MNMT model to an unseen LRL using data selection and model adaptation. In\norder to improve NMT for LRL, we employ perplexity to select HRL data that are\nmost similar to the LRL on the basis of language distance. We extensively\nexplore data selection in popular multilingual NMT settings, namely in\n(zero-shot) translation, and in adaptation from a multilingual pre-trained\nmodel, for both directions (LRL-en). We further show that dynamic adaptation of\nthe model's vocabulary results in a more favourable segmentation for the LRL in\ncomparison with direct adaptation. Experiments show reductions in training time\nand significant performance gains over LRL baselines, even with zero LRL data\n(+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic\nadaptation with related data selection. Our method outperforms current\napproaches, such as massively multilingual models and data augmentation, on\nfour LRL.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 17:34:46 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lakew", "Surafel M.", ""], ["Karakanta", "Alina", ""], ["Federico", "Marcello", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1910.14025", "submitter": "Chen Li", "authors": "Linmei Hu, Chen Li, Chuan Shi, Cheng Yang, Chao Shao", "title": "Graph Neural News Recommendation with Long-term and Short-term Interest\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the information explosion of news articles, personalized news\nrecommendation has become important for users to quickly find news that they\nare interested in. Existing methods on news recommendation mainly include\ncollaborative filtering methods which rely on direct user-item interactions and\ncontent based methods which characterize the content of user reading history.\nAlthough these methods have achieved good performances, they still suffer from\ndata sparse problem, since most of them fail to extensively exploit high-order\nstructure information (similar users tend to read similar news articles) in\nnews recommendation systems. In this paper, we propose to build a heterogeneous\ngraph to explicitly model the interactions among users, news and latent topics.\nThe incorporated topic information would help indicate a user's interest and\nalleviate the sparsity of user-item interactions. Then we take advantage of\ngraph neural networks to learn user and news representations that encode\nhigh-order structure information by propagating embeddings over the graph. The\nlearned user embeddings with complete historic user clicks capture the users'\nlong-term interests. We also consider a user's short-term interest using the\nrecent reading history with an attention based LSTM model. Experimental results\non real-world datasets show that our proposed model significantly outperforms\nstate-of-the-art methods on news recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 08:04:43 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 02:20:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hu", "Linmei", ""], ["Li", "Chen", ""], ["Shi", "Chuan", ""], ["Yang", "Cheng", ""], ["Shao", "Chao", ""]]}, {"id": "1910.14075", "submitter": "Sebastien Jean", "authors": "S\\'ebastien Jean, Ankur Bapna, Orhan Firat", "title": "Fill in the Blanks: Imputing Missing Sentences for Larger-Context Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural machine translation systems still translate sentences in\nisolation. To make further progress, a promising line of research additionally\nconsiders the surrounding context in order to provide the model potentially\nmissing source-side information, as well as to maintain a coherent output. One\ndifficulty in training such larger-context (i.e. document-level) machine\ntranslation systems is that context may be missing from many parallel examples.\nTo circumvent this issue, two-stage approaches, in which sentence-level\ntranslations are post-edited in context, have recently been proposed. In this\npaper, we instead consider the viability of filling in the missing context. In\nparticular, we consider three distinct approaches to generate the missing\ncontext: using random contexts, applying a copy heuristic or generating it with\na language model. In particular, the copy heuristic significantly helps with\nlexical coherence, while using completely random contexts hurts performance on\nmany long-distance linguistic phenomena. We also validate the usefulness of\ntagged back-translation. In addition to improving BLEU scores as expected,\nusing back-translated data helps larger-context machine translation systems to\nbetter capture long-range phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:38:17 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jean", "S\u00e9bastien", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""]]}, {"id": "1910.14076", "submitter": "Irene Li", "authors": "Irene Li, Michihiro Yasunaga, Muhammed Yavuz Nuzumlal{\\i}, Cesar\n  Caraballo, Shiwani Mahajan, Harlan Krumholz and Dragomir Radev", "title": "A Neural Topic-Attention Model for Medical Term Abbreviation\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated analysis of clinical notes is attracting increasing attention.\nHowever, there has not been much work on medical term abbreviation\ndisambiguation. Such abbreviations are abundant, and highly ambiguous, in\nclinical documents. One of the main obstacles is the lack of large scale,\nbalance labeled data sets. To address the issue, we propose a few-shot learning\napproach to take advantage of limited labeled data. Specifically, a neural\ntopic-attention model is applied to learn improved contextualized sentence\nrepresentations for medical term abbreviation disambiguation. Another vital\nissue is that the existing scarce annotations are noisy and missing. We\nre-examine and correct an existing dataset for training and collect a test set\nto evaluate the models fairly especially for rare senses. We train our model on\nthe training set which contains 30 abbreviation terms as categories (on\naverage, 479 samples and 3.24 classes in each term) selected from a public\nabbreviation disambiguation dataset, and then test on a manually-created\nbalanced dataset (each class in each term has 15 samples). We show that\nenhancing the sentence representation with topic information improves the\nperformance on small-scale unbalanced training datasets by a large margin,\ncompared to a number of baseline models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:39:46 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Li", "Irene", ""], ["Yasunaga", "Michihiro", ""], ["Nuzumlal\u0131", "Muhammed Yavuz", ""], ["Caraballo", "Cesar", ""], ["Mahajan", "Shiwani", ""], ["Krumholz", "Harlan", ""], ["Radev", "Dragomir", ""]]}, {"id": "1910.14080", "submitter": "Yifu Sun", "authors": "Yifu Sun, Haoming Jiang", "title": "Contextual Text Denoising with Masked Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the help of deep learning models, significant advances have\nbeen made in different Natural Language Processing (NLP) tasks. Unfortunately,\nstate-of-the-art models are vulnerable to noisy texts. We propose a new\ncontextual text denoising algorithm based on the ready-to-use masked language\nmodel. The proposed algorithm does not require retraining of the model and can\nbe integrated into any NLP system without additional training on paired\ncleaning training data. We evaluate our method under synthetic noise and\nnatural noise and show that the proposed algorithm can use context information\nto correct noise text and improve the performance of noisy inputs in several\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:47:37 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Sun", "Yifu", ""], ["Jiang", "Haoming", ""]]}, {"id": "1910.14084", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Bing Liu, Shuai Wang, Sepideh Esmaeilpour", "title": "Building an Application Independent Natural Language Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to building natural language (NL) interfaces typically\nuse a semantic parser to parse the user command and convert it to a logical\nform, which is then translated to an executable action in an application.\nHowever, it is still challenging for a semantic parser to correctly parse\nnatural language. For a different domain, the parser may need to be retrained\nor tuned, and a new translator also needs to be written to convert the logical\nforms to executable actions. In this work, we propose a novel and application\nindependent approach to building NL interfaces that does not need a semantic\nparser or a translator. It is based on natural language to natural language\nmatching and learning, where the representation of each action and each user\ncommand are both in natural language. To perform a user intended action, the\nsystem only needs to match the user command with the correct action\nrepresentation, and then execute the corresponding action. The system also\ninteractively learns new (paraphrased) commands for actions to expand the\naction representations over time. Our experimental results show the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 18:57:28 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""], ["Wang", "Shuai", ""], ["Esmaeilpour", "Sepideh", ""]]}, {"id": "1910.14087", "submitter": "Kaixin Ma", "authors": "Kaixin Ma, Jonathan Francis, Quanyang Lu, Eric Nyberg, Alessandro\n  Oltramari", "title": "Towards Generalizable Neuro-Symbolic Systems for Commonsense Question\n  Answering", "comments": "EMNLP-COIN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-extractive commonsense QA remains a challenging AI task, as it requires\nsystems to reason about, synthesize, and gather disparate pieces of\ninformation, in order to generate responses to queries. Recent approaches on\nsuch tasks show increased performance, only when models are either pre-trained\nwith additional information or when domain-specific heuristics are used,\nwithout any special consideration regarding the knowledge resource type. In\nthis paper, we perform a survey of recent commonsense QA methods and we provide\na systematic analysis of popular knowledge resources and knowledge-integration\nmethods, across benchmarks from multiple commonsense datasets. Our results and\nanalysis show that attention-based injection seems to be a preferable choice\nfor knowledge integration and that the degree of domain overlap, between\nknowledge bases and datasets, plays a crucial role in determining model\nsuccess.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:07:31 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ma", "Kaixin", ""], ["Francis", "Jonathan", ""], ["Lu", "Quanyang", ""], ["Nyberg", "Eric", ""], ["Oltramari", "Alessandro", ""]]}, {"id": "1910.14142", "submitter": "Jiacheng Xu", "authors": "Jiacheng Xu, Zhe Gan, Yu Cheng, Jingjing Liu", "title": "Discourse-Aware Neural Extractive Text Summarization", "comments": "To appear at ACL 2020; Code available at\n  https://github.com/jiacheng-xu/DiscoBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently BERT has been adopted for document encoding in state-of-the-art text\nsummarization models. However, sentence-based extractive models often result in\nredundant or uninformative phrases in the extracted summaries. Also, long-range\ndependencies throughout a document are not well captured by BERT, which is\npre-trained on sentence pairs instead of documents. To address these issues, we\npresent a discourse-aware neural summarization model - DiscoBert. DiscoBert\nextracts sub-sentential discourse units (instead of sentences) as candidates\nfor extractive selection on a finer granularity. To capture the long-range\ndependencies among discourse units, structural discourse graphs are constructed\nbased on RST trees and coreference mentions, encoded with Graph Convolutional\nNetworks. Experiments show that the proposed model outperforms state-of-the-art\nmethods by a significant margin on popular summarization benchmarks compared to\nother BERT-base models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 21:17:26 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 03:36:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xu", "Jiacheng", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Liu", "Jingjing", ""]]}, {"id": "1910.14161", "submitter": "Hila Gonen", "authors": "Hila Gonen, Yova Kementchedjhieva, Yoav Goldberg", "title": "How does Grammatical Gender Affect Noun Representations in\n  Gender-Marking Languages?", "comments": "CONLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many natural languages assign grammatical gender also to inanimate nouns in\nthe language. In such languages, words that relate to the gender-marked nouns\nare inflected to agree with the noun's gender. We show that this affects the\nword representations of inanimate nouns, resulting in nouns with the same\ngender being closer to each other than nouns with different gender. While\n\"embedding debiasing\" methods fail to remove the effect, we demonstrate that a\ncareful application of methods that neutralize grammatical gender signals from\nthe words' context when training word embeddings is effective in removing it.\nFixing the grammatical gender bias yields a positive effect on the quality of\nthe resulting word embeddings, both in monolingual and cross-lingual settings.\nWe note that successfully removing gender signals, while achievable, is not\ntrivial to do and that a language-specific morphological analyzer, together\nwith careful usage of it, are essential for achieving good results.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:28:14 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Gonen", "Hila", ""], ["Kementchedjhieva", "Yova", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1910.14176", "submitter": "Patrick Huber", "authors": "Patrick Huber and Giuseppe Carenini", "title": "Predicting Discourse Structure using Distant Supervision from Sentiment", "comments": "Accepted to EMNLP 2019, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse parsing could not yet take full advantage of the neural NLP\nrevolution, mostly due to the lack of annotated datasets. We propose a novel\napproach that uses distant supervision on an auxiliary task (sentiment\nclassification), to generate abundant data for RST-style discourse structure\nprediction. Our approach combines a neural variant of multiple-instance\nlearning, using document-level supervision, with an optimal CKY-style tree\ngeneration algorithm. In a series of experiments, we train a discourse parser\n(for only structure prediction) on our automatically generated dataset and\ncompare it with parsers trained on human-annotated corpora (news domain RST-DT\nand Instructional domain). Results indicate that while our parser does not yet\nmatch the performance of a parser trained and tested on the same dataset\n(intra-domain), it does perform remarkably well on the much more difficult and\narguably more useful task of inter-domain discourse structure prediction, where\nthe parser is trained on one domain and tested/applied on another one.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:15:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "1910.14192", "submitter": "Zheng Li", "authors": "Zheng Li, Xin Li, Ying Wei, Lidong Bing, Yu Zhang, Qiang Yang", "title": "Transferable End-to-End Aspect-based Sentiment Analysis with Selective\n  Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint extraction of aspects and sentiments can be effectively formulated as a\nsequence labeling problem. However, such formulation hinders the effectiveness\nof supervised methods due to the lack of annotated sequence data in many\ndomains. To address this issue, we firstly explore an unsupervised domain\nadaptation setting for this task. Prior work can only use common syntactic\nrelations between aspect and opinion words to bridge the domain gaps, which\nhighly relies on external linguistic resources. To resolve it, we propose a\nnovel Selective Adversarial Learning (SAL) method to align the inferred\ncorrelation vectors that automatically capture their latent relations. The SAL\nmethod can dynamically learn an alignment weight for each word such that more\nimportant words can possess higher alignment weights to achieve fine-grained\n(word-level) adaptation. Empirically, extensive experiments demonstrate the\neffectiveness of the proposed SAL method.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 00:22:27 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Li", "Zheng", ""], ["Li", "Xin", ""], ["Wei", "Ying", ""], ["Bing", "Lidong", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1910.14208", "submitter": "Jialin Wu", "authors": "Jialin Wu and Raymond J. Mooney", "title": "Hidden State Guidance: Improving Image Captioning using An Image\n  Conditioned Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most RNN-based image captioning models receive supervision on the output\nwords to mimic human captions. Therefore, the hidden states can only receive\nnoisy gradient signals via layers of back-propagation through time, leading to\nless accurate generated captions. Consequently, we propose a novel framework,\nHidden State Guidance (HSG), that matches the hidden states in the caption\ndecoder to those in a teacher decoder trained on an easier task of autoencoding\nthe captions conditioned on the image. During training with the REINFORCE\nalgorithm, the conventional rewards are sentence-based evaluation metrics\nequally distributed to each generated word, no matter their relevance. HSG\nprovides a word-level reward that helps the model learn better hidden\nrepresentations. Experimental results demonstrate that HSG clearly outperforms\nvarious state-of-the-art caption decoders using either raw images or detected\nobjects as inputs.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 01:56:33 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 19:21:02 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wu", "Jialin", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1910.14229", "submitter": "Yue Ma", "authors": "Yue Ma, Xiaojie Wang, Zhenjiang Dong, Hong Chen", "title": "Cascaded LSTMs based Deep Reinforcement Learning for Goal-driven\n  Dialogue", "comments": "12 pages, 3 figures, appear in NLPCC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a deep neural network model for joint modeling Natural\nLanguage Understanding (NLU) and Dialogue Management (DM) in goal-driven\ndialogue systems. There are three parts in this model. A Long Short-Term Memory\n(LSTM) at the bottom of the network encodes utterances in each dialogue turn\ninto a turn embedding. Dialogue embeddings are learned by a LSTM at the middle\nof the network, and updated by the feeding of all turn embeddings. The top part\nis a forward Deep Neural Network which converts dialogue embeddings into the\nQ-values of different dialogue actions. The cascaded LSTMs based reinforcement\nlearning network is jointly optimized by making use of the rewards received at\neach dialogue turn as the only supervision information. There is no explicit\nNLU and dialogue states in the network. Experimental results show that our\nmodel outperforms both traditional Markov Decision Process (MDP) model and\nsingle LSTM with Deep Q-Network on meeting room booking tasks. Visualization of\ndialogue embeddings illustrates that the model can learn the representation of\ndialogue states.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 03:08:10 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Ma", "Yue", ""], ["Wang", "Xiaojie", ""], ["Dong", "Zhenjiang", ""], ["Chen", "Hong", ""]]}, {"id": "1910.14243", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed, Chiyu Zhang, AbdelRahim Elmadany, Arun\n  Rajendran and Lyle Ungar", "title": "DiaNet: BERT and Hierarchical Attention Multi-Task Learning of\n  Fine-Grained Dialect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of language varieties and dialects is an important language\nprocessing task, with a wide range of applications. For Arabic, the native\ntongue of ~ 300 million people, most varieties remain unsupported. To ease this\nbottleneck, we present a very large scale dataset covering 319 cities from all\n21 Arab countries. We introduce a hierarchical attention multi-task learning\n(HA-MTL) approach for dialect identification exploiting our data at the city,\nstate, and country levels. We also evaluate use of BERT on the three tasks,\ncomparing it to the MTL approach. We benchmark and release our data and models.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 03:56:32 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Elmadany", "AbdelRahim", ""], ["Rajendran", "Arun", ""], ["Ungar", "Lyle", ""]]}, {"id": "1910.14254", "submitter": "Sebastian Schuster", "authors": "Sebastian Schuster, Yuxing Chen, Judith Degen", "title": "Harnessing the linguistic signal to predict scalar inferences", "comments": "ACL 2020; 16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pragmatic inferences often subtly depend on the presence or absence of\nlinguistic features. For example, the presence of a partitive construction (of\nthe) increases the strength of a so-called scalar inference: listeners perceive\nthe inference that Chris did not eat all of the cookies to be stronger after\nhearing \"Chris ate some of the cookies\" than after hearing the same utterance\nwithout a partitive, \"Chris ate some cookies.\" In this work, we explore to what\nextent neural network sentence encoders can learn to predict the strength of\nscalar inferences. We first show that an LSTM-based sentence encoder trained on\nan English dataset of human inference strength ratings is able to predict\nratings with high accuracy (r=0.78). We then probe the model's behavior using\nmanually constructed minimal sentence pairs and corpus data. We find that the\nmodel inferred previously established associations between linguistic features\nand inference strength, suggesting that the model learns to use linguistic\nfeatures to predict pragmatic inferences.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 04:35:17 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 21:04:21 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Schuster", "Sebastian", ""], ["Chen", "Yuxing", ""], ["Degen", "Judith", ""]]}, {"id": "1910.14270", "submitter": "Xu Zhao", "authors": "Xu Zhao", "title": "Parameter Sharing Decoder Pair for Auto Composing", "comments": "The author information of the old version of this paper is wrong.\n  Removed it. Please use this version if need to cite", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto Composing is an active and appealing research area in the past few\nyears, and lots of efforts have been put into inventing more robust models to\nsolve this problem. With the fast evolution of deep learning techniques, some\ndeep neural network-based language models are becoming dominant. Notably, the\ntransformer structure has been proven to be very efficient and promising in\nmodeling texts. However, the transformer-based language models usually contain\nhuge number of parameters and the size of the model is usually too large to put\nin production for some storage limited applications. In this paper, we propose\na parameter sharing decoder pair (PSDP), which reduces the number of parameters\ndramatically and at the same time maintains the capability of generating\nunderstandable and reasonable compositions. Works created by the proposed model\nare presented to demonstrate the effectiveness of the model.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 06:06:56 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 00:25:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhao", "Xu", ""]]}, {"id": "1910.14286", "submitter": "Kuan-Yu Chen", "authors": "Li-Phen Yen, Zhen-Yu Wu, Kuan-Yu Chen", "title": "A neural document language modeling framework for spoken document\n  retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in deep learning have led to a significant innovation in\nvarious classic and practical subjects, including speech recognition, computer\nvision, question answering, information retrieval and so on. In the context of\nnatural language processing (NLP), language representations have shown giant\nsuccesses in many downstream tasks, so the school of studies have become a\nmajor stream of research recently. Because the immenseness of multimedia data\nalong with speech have spread around the world in our daily life, spoken\ndocument retrieval (SDR) has become an important research subject in the past\ndecades. Targeting on enhancing the SDR performance, the paper concentrates on\nproposing a neural retrieval framework, which assembles the merits of using\nlanguage modeling (LM) mechanism in SDR and leveraging the abstractive\ninformation learned by the language representation models. Consequently, to our\nknowledge, this is a pioneer study on supervised training of a neural LM-based\nSDR framework, especially combined with the pretrained language representation\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 07:50:41 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Yen", "Li-Phen", ""], ["Wu", "Zhen-Yu", ""], ["Chen", "Kuan-Yu", ""]]}, {"id": "1910.14296", "submitter": "Junru Zhou", "authors": "Junru Zhou, Zhuosheng Zhang, Hai Zhao, Shuailiang Zhang", "title": "LIMIT-BERT : Linguistic Informed Multi-Task BERT", "comments": "EMNLP 2020, ACL Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Linguistic Informed Multi-Task BERT (LIMIT-BERT)\nfor learning language representations across multiple linguistic tasks by\nMulti-Task Learning (MTL). LIMIT-BERT includes five key linguistic syntax and\nsemantics tasks: Part-Of-Speech (POS) tags, constituent and dependency\nsyntactic parsing, span and dependency semantic role labeling (SRL). Besides,\nLIMIT-BERT adopts linguistics mask strategy: Syntactic and Semantic Phrase\nMasking which mask all of the tokens corresponding to a syntactic/semantic\nphrase. Different from recent Multi-Task Deep Neural Networks (MT-DNN) (Liu et\nal., 2019), our LIMIT-BERT is linguistically motivated and learning in a\nsemi-supervised method which provides large amounts of linguistic-task data as\nsame as BERT learning corpus. As a result, LIMIT-BERT not only improves\nlinguistic tasks performance but also benefits from a regularization effect and\nlinguistic information that leads to more general representations to help adapt\nto new tasks and domains. LIMIT-BERT obtains new state-of-the-art or\ncompetitive results on both span and dependency semantic parsing on Propbank\nbenchmarks and both dependency and constituent syntactic parsing on Penn\nTreebank.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 08:14:51 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 03:11:55 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhou", "Junru", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhang", "Shuailiang", ""]]}, {"id": "1910.14326", "submitter": "Yiping Song", "authors": "Yiping Song, Zequn Liu, Wei Bi, Rui Yan, Ming Zhang", "title": "Learning to Customize Model Structures for Few-shot Dialogue Generation\n  Tasks", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training the generative models with minimal corpus is one of the critical\nchallenges for building open-domain dialogue systems. Existing methods tend to\nuse the meta-learning framework which pre-trains the parameters on all\nnon-target tasks then fine-tunes on the target task. However, fine-tuning\ndistinguishes tasks from the parameter perspective but ignores the\nmodel-structure perspective, resulting in similar dialogue models for different\ntasks. In this paper, we propose an algorithm that can customize a unique\ndialogue model for each task in the few-shot setting. In our approach, each\ndialogue model consists of a shared module, a gating module, and a private\nmodule. The first two modules are shared among all the tasks, while the third\none will differentiate into different network structures to better capture the\ncharacteristics of the corresponding task. The extensive experiments on two\ndatasets show that our method outperforms all the baselines in terms of task\nconsistency, response quality, and diversity.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 09:25:34 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 03:28:57 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Song", "Yiping", ""], ["Liu", "Zequn", ""], ["Bi", "Wei", ""], ["Yan", "Rui", ""], ["Zhang", "Ming", ""]]}, {"id": "1910.14353", "submitter": "Valeriya Slovikovskaya", "authors": "Valeriya Slovikovskaya", "title": "Transfer Learning from Transformers to Fake News Challenge Stance\n  Detection (FNC-1) Task", "comments": "12 pages, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report improved results of the Fake News Challenge Stage 1\n(FNC-1) stance detection task. This gain in performance is due to the\ngeneralization power of large language models based on Transformer\narchitecture, invented, trained and publicly released over the last two years.\nSpecifically (1) we improved the FNC-1 best performing model adding BERT\nsentence embedding of input sequences as a model feature, (2) we fine-tuned\nBERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained\nstate-of-the-art results on FNC-1 task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:32:43 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Slovikovskaya", "Valeriya", ""]]}, {"id": "1910.14395", "submitter": "Selena Savic", "authors": "Selena Savic", "title": "Great New Design: How Do We Talk about Media Architecture in Social\n  Media", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In social media, we communicate through pictures, videos, short codes, links,\npartial phrases. It is a rich, and digitally documented communication channel\nthat relies on a multitude of media and forms. These channels are sorted by\nalgorithms as organizers of discourse, mostly with the goal of channeling\nattention. In this research, we used Twitter to study the way Media\nArchitecture is discussed within the community of architects, designers,\nresearchers and policy makers. We look at the way they spontaneously share\nopinions on their engagement with digital infrastructures, networked places and\nhybrid public spaces. What can we do with all those opinions? We propose here\nthe use of text-mining and machine learning techniques to identify important\nconcepts and patterns in this prolific communication stream. We discuss how\nsuch techniques could inform the practice and emergence of future trends.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 11:49:32 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Savic", "Selena", ""]]}, {"id": "1910.14443", "submitter": "Joanna Rownicka", "authors": "Joanna Rownicka, Peter Bell, Steve Renals", "title": "Multi-scale Octave Convolutions for Robust Speech Recognition", "comments": "submitted to ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-scale octave convolution layer to learn robust speech\nrepresentations efficiently. Octave convolutions were introduced by Chen et al\n[1] in the computer vision field to reduce the spatial redundancy of the\nfeature maps by decomposing the output of a convolutional layer into feature\nmaps at two different spatial resolutions, one octave apart. This approach\nimproved the efficiency as well as the accuracy of the CNN models. The accuracy\ngain was attributed to the enlargement of the receptive field in the original\ninput space. We argue that octave convolutions likewise improve the robustness\nof learned representations due to the use of average pooling in the lower\nresolution group, acting as a low-pass filter. We test this hypothesis by\nevaluating on two noisy speech corpora - Aurora-4 and AMI. We extend the octave\nconvolution concept to multiple resolution groups and multiple octaves. To\nevaluate the robustness of the inferred representations, we report the\nsimilarity between clean and noisy encodings using an affine projection loss as\na proxy robustness measure. The results show that proposed method reduces the\nWER by up to 6.6% relative for Aurora-4 and 3.6% for AMI, while improving the\ncomputational efficiency of the CNN acoustic models.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:15:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Rownicka", "Joanna", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "1910.14464", "submitter": "Jordan Boyd-Graber", "authors": "Jordan Boyd-Graber, Benjamin B\\\"orschinger", "title": "What Question Answering can Learn from Trivia Nerds", "comments": null, "journal-ref": "ACL 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to the traditional task of getting machines to answer questions,\na major research question in question answering is to create interesting,\nchallenging questions that can help systems learn how to answer questions and\nalso reveal which systems are the best at answering questions. We argue that\ncreating a question answering dataset -- and the ubiquitous leaderboard that\ngoes with it -- closely resembles running a trivia tournament: you write\nquestions, have agents (either humans or machines) answer the questions, and\ndeclare a winner. However, the research community has ignored the decades of\nhard-learned lessons from decades of the trivia community creating vibrant,\nfair, and effective question answering competitions. After detailing problems\nwith existing QA datasets, we outline the key lessons -- removing ambiguity,\ndiscriminating skill, and adjudicating disputes -- that can transfer to QA\nresearch and how they might be implemented for the QA community.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 13:38:01 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:27:05 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 12:41:05 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Boyd-Graber", "Jordan", ""], ["B\u00f6rschinger", "Benjamin", ""]]}, {"id": "1910.14497", "submitter": "Hailey James", "authors": "Hailey James and David Alvarez-Melis", "title": "Probabilistic Bias Mitigation in Word Embeddings", "comments": "4 pages, 4 figures, Workshop on Human-Centric Machine Learning at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that word embeddings derived from large corpora tend to\nincorporate biases present in their training data. Various methods for\nmitigating these biases have been proposed, but recent work has demonstrated\nthat these methods hide but fail to truly remove the biases, which can still be\nobserved in word nearest-neighbor statistics. In this work we propose a\nprobabilistic view of word embedding bias. We leverage this framework to\npresent a novel method for mitigating bias which relies on probabilistic\nobservations to yield a more robust bias mitigation algorithm. We demonstrate\nthat this method effectively reduces bias according to three separate measures\nof bias while maintaining embedding quality across various popular benchmark\nsemantic tasks\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 14:34:14 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 23:17:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["James", "Hailey", ""], ["Alvarez-Melis", "David", ""]]}, {"id": "1910.14520", "submitter": "Mo Yu", "authors": "Haoyu Wang, Mo Yu, Xiaoxiao Guo, Rajarshi Das, Wenhan Xiong, Tian Gao", "title": "Do Multi-hop Readers Dream of Reasoning Chains?", "comments": "Accepted by MRQA Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General Question Answering (QA) systems over texts require the multi-hop\nreasoning capability, i.e. the ability to reason with information collected\nfrom multiple passages to derive the answer. In this paper we conduct a\nsystematic analysis to assess such an ability of various existing models\nproposed for multi-hop QA tasks. Specifically, our analysis investigates that\nwhether providing the full reasoning chain of multiple passages, instead of\njust one final passage where the answer appears, could improve the performance\nof the existing QA models. Surprisingly, when using the additional evidence\npassages, the improvements of all the existing multi-hop reading approaches are\nrather limited, with the highest error reduction of 5.8% on F1 (corresponding\nto 1.3% absolute improvement) from the BERT model.\n  To better understand whether the reasoning chains could indeed help find\ncorrect answers, we further develop a co-matching-based method that leads to\n13.1% error reduction with passage chains when applied to two of our base\nreaders (including BERT). Our results demonstrate the existence of the\npotential improvement using explicit multi-hop reasoning and the necessity to\ndevelop models with better reasoning abilities.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:02:49 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Wang", "Haoyu", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Das", "Rajarshi", ""], ["Xiong", "Wenhan", ""], ["Gao", "Tian", ""]]}, {"id": "1910.14528", "submitter": "Shu Jiang", "authors": "Shu Jiang, Rui Wang, Zuchao Li, Masao Utiyama, Kehai Chen, Eiichiro\n  Sumita, Hai Zhao, Bao-liang Lu", "title": "Document-level Neural Machine Translation with Inter-Sentence Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Standard neural machine translation (NMT) is on the assumption of\ndocument-level context independent. Most existing document-level NMT methods\nonly focus on briefly introducing document-level information but fail to\nconcern about selecting the most related part inside document context. The\ncapacity of memory network for detecting the most relevant part of the current\nsentence from the memory provides a natural solution for the requirement of\nmodeling document-level context by document-level NMT. In this work, we propose\na Transformer NMT system with associated memory network (AMN) to both capture\nthe document-level context and select the most salient part related to the\nconcerned translation from the memory. Experiments on several tasks show that\nthe proposed method significantly improves the NMT performance over strong\nTransformer baselines and other related studies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:14:54 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Jiang", "Shu", ""], ["Wang", "Rui", ""], ["Li", "Zuchao", ""], ["Utiyama", "Masao", ""], ["Chen", "Kehai", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Hai", ""], ["Lu", "Bao-liang", ""]]}, {"id": "1910.14537", "submitter": "Sufeng Duan", "authors": "Sufeng Duan, Hai Zhao", "title": "Attention Is All You Need for Chinese Word Segmentation", "comments": "11 pages, to appear in EMNLP 2020 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking greedy decoding algorithm as it should be, this work focuses on\nfurther strengthening the model itself for Chinese word segmentation (CWS),\nwhich results in an even more fast and more accurate CWS model. Our model\nconsists of an attention only stacked encoder and a light enough decoder for\nthe greedy segmentation plus two highway connections for smoother training, in\nwhich the encoder is composed of a newly proposed Transformer variant,\nGaussian-masked Directional (GD) Transformer, and a biaffine attention scorer.\nWith the effective encoder design, our model only needs to take unigram\nfeatures for scoring. Our model is evaluated on SIGHAN Bakeoff benchmark\ndatasets. The experimental results show that with the highest segmentation\nspeed, the proposed model achieves new state-of-the-art or comparable\nperformance against strong baselines in terms of strict closed test setting.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:32:19 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 13:17:01 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 06:38:42 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Duan", "Sufeng", ""], ["Zhao", "Hai", ""]]}, {"id": "1910.14539", "submitter": "Alexandre B\\'erard", "authors": "Fahimeh Saleh, Alexandre B\\'erard, Ioan Calapodescu, Laurent Besacier", "title": "Naver Labs Europe's Systems for the Document-Level Generation and\n  Translation Task at WNGT 2019", "comments": "WNGT 2019 - System Description Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural models led to significant improvements in both machine\ntranslation (MT) and natural language generation tasks (NLG). However,\ngeneration of long descriptive summaries conditioned on structured data remains\nan open challenge. Likewise, MT that goes beyond sentence-level context is\nstill an open issue (e.g., document-level MT or MT with metadata). To address\nthese challenges, we propose to leverage data from both tasks and do transfer\nlearning between MT, NLG, and MT with source-side metadata (MT+NLG). First, we\ntrain document-based MT systems with large amounts of parallel data. Then, we\nadapt these models to pure NLG and MT+NLG tasks by fine-tuning with smaller\namounts of domain-specific data. This end-to-end NLG approach, without data\nselection and planning, outperforms the previous state of the art on the\nRotowire NLG task. We participated to the \"Document Generation and Translation\"\ntask at WNGT 2019, and ranked first in all tracks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:34:48 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Saleh", "Fahimeh", ""], ["B\u00e9rard", "Alexandre", ""], ["Calapodescu", "Ioan", ""], ["Besacier", "Laurent", ""]]}, {"id": "1910.14549", "submitter": "Sang Sang Tan", "authors": "Sang-Sang Tan (1), Jin-Cheon Na (1) ((1) Nanyang Technological\n  University, Singapore)", "title": "Positional Attention-based Frame Identification with BERT: A Deep\n  Learning Approach to Target Disambiguation and Semantic Frame Selection", "comments": "19 pages, 7 figures, uses basic.sty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of transforming sentences from natural language\ninto formal representations of predicate-argument structures. Under this\nresearch area, frame-semantic parsing has attracted much interest. This parsing\napproach leverages the lexical information defined in FrameNet to associate\nmarked predicates or targets with semantic frames, thereby assigning semantic\nroles to sentence components based on pre-specified frame elements in FrameNet.\nIn this paper, a deep neural network architecture known as Positional\nAttention-based Frame Identification with BERT (PAFIBERT) is presented as a\nsolution to the frame identification subtask in frame-semantic parsing.\nAlthough the importance of this subtask is well-established, prior research has\nyet to find a robust solution that works satisfactorily for both in-domain and\nout-of-domain data. This study thus set out to improve frame identification in\nlight of recent advancements of language modeling and transfer learning in\nnatural language processing. The proposed method is partially empowered by\nBERT, a pre-trained language model that excels at capturing contextual\ninformation in texts. By combining the language representation power of BERT\nwith a position-based attention mechanism, PAFIBERT is able to attend to\ntarget-specific contexts in sentences for disambiguating targets and\nassociating them with the most suitable semantic frames. Under various\nexperimental settings, PAFIBERT outperformed existing solutions by a\nsignificant margin, achieving new state-of-the-art results for both in-domain\nand out-of-domain benchmark test sets.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 15:51:04 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Tan", "Sang-Sang", ""], ["Na", "Jin-Cheon", ""]]}, {"id": "1910.14589", "submitter": "Alexandre B\\'erard", "authors": "Alexandre B\\'erard, Ioan Calapodescu, Marc Dymetman, Claude Roux,\n  Jean-Luc Meunier, Vassilina Nikoulina", "title": "Machine Translation of Restaurant Reviews: New Corpus for Domain\n  Adaptation and Robustness", "comments": "WNGT 2019 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We share a French-English parallel corpus of Foursquare restaurant reviews\n(https://europe.naverlabs.com/research/natural-language-processing/machine-translation-of-restaurant-reviews),\nand define a new task to encourage research on Neural Machine Translation\nrobustness and domain adaptation, in a real-world scenario where better-quality\nMT would be greatly beneficial. We discuss the challenges of such\nuser-generated content, and train good baseline models that build upon the\nlatest techniques for MT robustness. We also perform an extensive evaluation\n(automatic and human) that shows significant improvements over existing online\nsystems. Finally, we propose task-specific metrics based on sentiment analysis\nor translation accuracy of domain-specific polysemous words.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:42:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["B\u00e9rard", "Alexandre", ""], ["Calapodescu", "Ioan", ""], ["Dymetman", "Marc", ""], ["Roux", "Claude", ""], ["Meunier", "Jean-Luc", ""], ["Nikoulina", "Vassilina", ""]]}, {"id": "1910.14599", "submitter": "Douwe Kiela", "authors": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston,\n  Douwe Kiela", "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new large-scale NLI benchmark dataset, collected via an\niterative, adversarial human-and-model-in-the-loop procedure. We show that\ntraining models on this new dataset leads to state-of-the-art performance on a\nvariety of popular NLI benchmarks, while posing a more difficult challenge with\nits new test set. Our analysis sheds light on the shortcomings of current\nstate-of-the-art models, and shows that non-expert annotators are successful at\nfinding their weaknesses. The data collection method can be applied in a\nnever-ending learning scenario, becoming a moving target for NLU, rather than a\nstatic benchmark that will quickly saturate.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:50:43 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:01:56 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Nie", "Yixin", ""], ["Williams", "Adina", ""], ["Dinan", "Emily", ""], ["Bansal", "Mohit", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""]]}, {"id": "1910.14609", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and Bastien Vanderplaetse and St\\'ephane Dupont", "title": "Can adversarial training learn image captioning ?", "comments": "Accepted to NeurIPS 2019 ViGiL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, generative adversarial networks (GAN) have gathered a lot of\ninterest. Their efficiency in generating unseen samples of high quality,\nespecially images, has improved over the years. In the field of Natural\nLanguage Generation (NLG), the use of the adversarial setting to generate\nmeaningful sentences has shown to be difficult for two reasons: the lack of\nexisting architectures to produce realistic sentences and the lack of\nevaluation tools. In this paper, we propose an adversarial architecture related\nto the conditional GAN (cGAN) that generates sentences according to a given\nimage (also called image captioning). This attempt is the first that uses no\npre-training or reinforcement methods. We also explain why our experiment\nsettings can be safely evaluated and interpreted for further works.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:59:14 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Vanderplaetse", "Bastien", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1910.14613", "submitter": "Sharan Narang", "authors": "Arvind Neelakantan, Semih Yavuz, Sharan Narang, Vishaal Prasad, Ben\n  Goodrich, Daniel Duckworth, Chinnadhurai Sankar, Xifeng Yan", "title": "Neural Assistant: Joint Action Prediction, Response Generation, and\n  Latent Knowledge Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog presents a difficult challenge encompassing multiple\nproblems including multi-turn language understanding and generation, knowledge\nretrieval and reasoning, and action prediction. Modern dialog systems typically\nbegin by converting conversation history to a symbolic object referred to as\nbelief state by using supervised learning. The belief state is then used to\nreason on an external knowledge source whose result along with the conversation\nhistory is used in action prediction and response generation tasks\nindependently. Such a pipeline of individually optimized components not only\nmakes the development process cumbersome but also makes it non-trivial to\nleverage session-level user reinforcement signals. In this paper, we develop\nNeural Assistant: a single neural network model that takes conversation history\nand an external knowledge source as input and jointly produces both text\nresponse and action to be taken by the system as output. The model learns to\nreason on the provided knowledge source with weak supervision signal coming\nfrom the text generation and the action prediction tasks, hence removing the\nneed for belief state annotations. In the MultiWOZ dataset, we study the effect\nof distant supervision, and the size of knowledge base on model performance. We\nfind that the Neural Assistant without belief states is able to incorporate\nexternal knowledge information achieving higher factual accuracy scores\ncompared to Transformer. In settings comparable to reported baseline systems,\nNeural Assistant when provided with oracle belief state significantly improves\nlanguage generation performance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:01:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Neelakantan", "Arvind", ""], ["Yavuz", "Semih", ""], ["Narang", "Sharan", ""], ["Prasad", "Vishaal", ""], ["Goodrich", "Ben", ""], ["Duckworth", "Daniel", ""], ["Sankar", "Chinnadhurai", ""], ["Yan", "Xifeng", ""]]}, {"id": "1910.14659", "submitter": "Julian Salazar", "authors": "Julian Salazar, Davis Liang, Toan Q. Nguyen, Katrin Kirchhoff", "title": "Masked Language Model Scoring", "comments": "ACL 2020 camera-ready (presented July 2020)", "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics (2020), 2699-2712", "doi": "10.18653/v1/2020.acl-main.240", "report-no": null, "categories": "cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained masked language models (MLMs) require finetuning for most NLP\ntasks. Instead, we evaluate MLMs out of the box via their pseudo-log-likelihood\nscores (PLLs), which are computed by masking tokens one by one. We show that\nPLLs outperform scores from autoregressive language models like GPT-2 in a\nvariety of tasks. By rescoring ASR and NMT hypotheses, RoBERTa reduces an\nend-to-end LibriSpeech model's WER by 30% relative and adds up to +1.7 BLEU on\nstate-of-the-art baselines for low-resource translation pairs, with further\ngains from domain adaptation. We attribute this success to PLL's unsupervised\nexpression of linguistic acceptability without a left-to-right bias, greatly\nimproving on scores from GPT-2 (+10 points on island effects, NPI licensing in\nBLiMP). One can finetune MLMs to give scores without masking, enabling\ncomputation in a single inference pass. In all, PLLs and their associated\npseudo-perplexities (PPPLs) enable plug-and-play use of the growing number of\npretrained MLMs; e.g., we use a single cross-lingual model to rescore\ntranslations in multiple languages. We release our library for language model\nscoring at https://github.com/awslabs/mlm-scoring.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:51:21 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 17:55:10 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 00:00:14 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Salazar", "Julian", ""], ["Liang", "Davis", ""], ["Nguyen", "Toan Q.", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1910.14671", "submitter": "Jingxiang Lin", "authors": "Jingxiang Lin, Unnat Jain, Alexander G. Schwing", "title": "TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning\n  Baselines", "comments": "Accepted to NeurIPS 2019. Project page:\n  https://deanplayerljx.github.io/tabvcr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reasoning is an important ability that we learn from a very early age. Yet,\nreasoning is extremely hard for algorithms. Despite impressive recent progress\nthat has been reported on tasks that necessitate reasoning, such as visual\nquestion answering and visual dialog, models often exploit biases in datasets.\nTo develop models with better reasoning abilities, recently, the new visual\ncommonsense reasoning (VCR) task has been introduced. Not only do models have\nto answer questions, but also do they have to provide a reason for the given\nanswer. The proposed baseline achieved compelling results, leveraging a\nmeticulously designed model composed of LSTM modules and attention nets. Here\nwe show that a much simpler model obtained by ablating and pruning the existing\nintricate baseline can perform better with half the number of trainable\nparameters. By associating visual features with attribute information and\nbetter text to image grounding, we obtain further improvements for our simpler\n& effective baseline, TAB-VCR. We show that this approach results in a 5.3%,\n4.4% and 6.5% absolute improvement over the previous state-of-the-art on\nquestion answering, answer justification and holistic VCR.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:59:57 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:55:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Lin", "Jingxiang", ""], ["Jain", "Unnat", ""], ["Schwing", "Alexander G.", ""]]}]