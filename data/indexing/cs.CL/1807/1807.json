[{"id": "1807.00072", "submitter": "Joo-Kyung Kim", "authors": "Joo-Kyung Kim and Young-Bum Kim", "title": "Joint Learning of Domain Classification and Out-of-Domain Detection with\n  Dynamic Class Weighting for Satisficing False Acceptance Rates", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domain classification for spoken dialog systems, correct detection of\nout-of-domain (OOD) utterances is crucial because it reduces confusion and\nunnecessary interaction costs between users and the systems. Previous work\nusually utilizes OOD detectors that are trained separately from in-domain (IND)\nclassifiers, and confidence thresholding for OOD detection given target\nevaluation scores. In this paper, we introduce a neural joint learning model\nfor domain classification and OOD detection, where dynamic class weighting is\nused during the model training to satisfice a given OOD false acceptance rate\n(FAR) while maximizing the domain classification accuracy. Evaluating on two\ndomain classification tasks for the utterances from a large spoken dialogue\nsystem, we show that our approach significantly improves the domain\nclassification performance with satisficing given target FARs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 21:27:05 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kim", "Joo-Kyung", ""], ["Kim", "Young-Bum", ""]]}, {"id": "1807.00099", "submitter": "Braden Hancock", "authors": "Braden Hancock, Hongrae Lee, Cong Yu", "title": "Generating Titles for Web Tables", "comments": "WWW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descriptive titles provide crucial context for interpreting tables that are\nextracted from web pages and are a key component of table-based web\napplications. Prior approaches have attempted to produce titles by selecting\nexisting text snippets associated with the table. These approaches, however,\nare limited by their dependence on suitable titles existing a priori. In our\nuser study, we observe that the relevant information for the title tends to be\nscattered across the page, and often--more than 80% of the time--does not\nappear verbatim anywhere in the page. We propose instead the application of a\nsequence-to-sequence neural network model as a more generalizable means of\ngenerating high-quality titles. This is accomplished by extracting many text\nsnippets that have potentially relevant information to the table, encoding them\ninto an input sequence, and using both copy and generation mechanisms in the\ndecoder to balance relevance and readability of the generated title. We\nvalidate this approach with human evaluation on sample web tables and report\nthat while sequence models with only a copy mechanism or only a generation\nmechanism are easily outperformed by simple selection-based baselines, the\nmodel with both capabilities outperforms them all, approaching the quality of\ncrowdsourced titles while training on fewer than ten thousand examples. To the\nbest of our knowledge, the proposed technique is the first to consider text\ngeneration methods for table titles and establishes a new state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 00:57:15 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 03:29:05 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hancock", "Braden", ""], ["Lee", "Hongrae", ""], ["Yu", "Cong", ""]]}, {"id": "1807.00122", "submitter": "Sanaz Bahargam", "authors": "Sanaz Bahargam, Evangelos E. Papalexakis", "title": "A Constrained Coupled Matrix-Tensor Factorization for Learning\n  Time-evolving and Emerging Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic discovery has witnessed a significant growth as a field of data mining\nat large. In particular, time-evolving topic discovery, where the evolution of\na topic is taken into account has been instrumental in understanding the\nhistorical context of an emerging topic in a dynamic corpus. Traditionally,\ntime-evolving topic discovery has focused on this notion of time. However,\nespecially in settings where content is contributed by a community or a crowd,\nan orthogonal notion of time is the one that pertains to the level of expertise\nof the content creator: the more experienced the creator, the more advanced the\ntopic. In this paper, we propose a novel time-evolving topic discovery method\nwhich, in addition to the extracted topics, is able to identify the evolution\nof that topic over time, as well as the level of difficulty of that topic, as\nit is inferred by the level of expertise of its main contributors. Our method\nis based on a novel formulation of Constrained Coupled Matrix-Tensor\nFactorization, which adopts constraints well-motivated for, and, as we\ndemonstrate, are essential for high-quality topic discovery. We qualitatively\nevaluate our approach using real data from the Physics and also Programming\nStack Exchange forum, and we were able to identify topics of varying levels of\ndifficulty which can be linked to external events, such as the announcement of\ngravitational waves by the LIGO lab in Physics forum. We provide a quantitative\nevaluation of our method by conducting a user study where experts were asked to\njudge the coherence and quality of the extracted topics. Finally, our proposed\nmethod has implications for automatic curriculum design using the extracted\ntopics, where the notion of the level of difficulty is necessary for the proper\nmodeling of prerequisites and advanced concepts.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 04:07:00 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Bahargam", "Sanaz", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1807.00181", "submitter": "Ted Underwood", "authors": "Ted Underwood", "title": "The Historical Significance of Textual Distances", "comments": "Preprint of a paper for the 2nd Joint SIGHUM Workshop on\n  Computational Linguistics for Cultural Heritage, Social Sciences, Humanities\n  and Literature (LaTeCH-CLfL 2018). Code is available at\n  https://github.com/tedunderwood/genredistance or, archivally, at\n  https://zenodo.org/record/1300934", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring similarity is a basic task in information retrieval, and now often\na building-block for more complex arguments about cultural change. But do\nmeasures of textual similarity and distance really correspond to evidence about\ncultural proximity and differentiation? To explore that question empirically,\nthis paper compares textual and social measures of the similarities between\ngenres of English-language fiction. Existing measures of textual similarity\n(cosine similarity on tf-idf vectors or topic vectors) are also compared to new\nstrategies that use supervised learning to anchor textual measurement in a\nsocial context.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 14:06:54 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Underwood", "Ted", ""]]}, {"id": "1807.00248", "submitter": "Massimo Piccardi", "authors": "Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Massimo Piccardi", "title": "A Shared Attention Mechanism for Interpretation of Neural Automatic\n  Post-Editing Systems", "comments": "2nd Workshop on Neural Machine Translation and Generation (WNMT\n  2018), held in conjunction with ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic post-editing (APE) systems aim to correct the systematic errors\nmade by machine translators. In this paper, we propose a neural APE system that\nencodes the source (src) and machine translated (mt) sentences with two\nseparate encoders, but leverages a shared attention mechanism to better\nunderstand how the two inputs contribute to the generation of the post-edited\n(pe) sentences. Our empirical observations have showed that when the mt is\nincorrect, the attention shifts weight toward tokens in the src sentence to\nproperly edit the incorrect translation. The model has been trained and\nevaluated on the official data from the WMT16 and WMT17 APE IT domain\nEnglish-German shared tasks. Additionally, we have used the extra 500K\nartificial data provided by the shared task. Our system has been able to\nreproduce the accuracies of systems trained with the same data, while at the\nsame time providing better interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 00:31:27 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Unanue", "Inigo Jauregi", ""], ["Borzeshi", "Ehsan Zare", ""], ["Piccardi", "Massimo", ""]]}, {"id": "1807.00267", "submitter": "Raghav Gupta", "authors": "Raghav Gupta, Abhinav Rastogi and Dilek Hakkani-Tur", "title": "An Efficient Approach to Encoding Context for Spoken Language\n  Understanding", "comments": "Submitted to INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In task-oriented dialogue systems, spoken language understanding, or SLU,\nrefers to the task of parsing natural language user utterances into semantic\nframes. Making use of context from prior dialogue history holds the key to more\neffective SLU. State of the art approaches to SLU use memory networks to encode\ncontext by processing multiple utterances from the dialogue at each turn,\nresulting in significant trade-offs between accuracy and computational\nefficiency. On the other hand, downstream components like the dialogue state\ntracker (DST) already keep track of the dialogue state, which can serve as a\nsummary of the dialogue history. In this work, we propose an efficient approach\nto encoding context from prior utterances for SLU. More specifically, our\narchitecture includes a separate recurrent neural network (RNN) based encoding\nmodule that accumulates dialogue context to guide the frame parsing sub-tasks\nand can be shared between SLU and DST. In our experiments, we demonstrate the\neffectiveness of our approach on dialogues from two domains.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 04:11:18 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Gupta", "Raghav", ""], ["Rastogi", "Abhinav", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1807.00286", "submitter": "Manuel Mager", "authors": "Manuel Mager and Elisabeth Mager and Alfonso Medina-Urrea and Ivan\n  Meza and Katharina Kann", "title": "Lost in Translation: Analysis of Information Loss During Machine\n  Translation Between Polysynthetic and Fusional Languages", "comments": "To appear in \"All Together Now? Computational Modeling of\n  Polysynthetic Languages\" Workshop, at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine translation from polysynthetic to fusional languages is a challenging\ntask, which gets further complicated by the limited amount of parallel text\navailable. Thus, translation performance is far from the state of the art for\nhigh-resource and more intensively studied language pairs. To shed light on the\nphenomena which hamper automatic translation to and from polysynthetic\nlanguages, we study translations from three low-resource, polysynthetic\nlanguages (Nahuatl, Wixarika and Yorem Nokki) into Spanish and vice versa.\nDoing so, we find that in a morpheme-to-morpheme alignment an important amount\nof information contained in polysynthetic morphemes has no Spanish counterpart,\nand its translation is often omitted. We further conduct a qualitative analysis\nand, thus, identify morpheme types that are commonly hard to align or ignored\nin the translation process.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 07:17:36 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Mager", "Manuel", ""], ["Mager", "Elisabeth", ""], ["Medina-Urrea", "Alfonso", ""], ["Meza", "Ivan", ""], ["Kann", "Katharina", ""]]}, {"id": "1807.00303", "submitter": "Vinicius Woloszyn", "authors": "Vinicius Woloszyn, Guilherme Medeiros Machado, Leandro Krug Wives,\n  Jos\\'e Palazzo Moreira de Oliveira", "title": "Modeling, comprehending and summarizing textual content by graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic Text Summarization strategies have been successfully employed to\ndigest text collections and extract its essential content. Usually, summaries\nare generated using textual corpora that belongs to the same domain area where\nthe summary will be used. Nonetheless, there are special cases where it is not\nfound enough textual sources, and one possible alternative is to generate a\nsummary from a different domain. One manner to summarize texts consists of\nusing a graph model. This model allows giving more importance to words\ncorresponding to the main concepts from the target domain found in the\nsummarized text. This gives the reader an overview of the main text concepts as\nwell as their relationships. However, this kind of summarization presents a\nsignificant number of repeated terms when compared to human-generated\nsummaries. In this paper, we present an approach to produce graph-model\nextractive summaries of texts, meeting the target domain exigences and treating\nthe terms repetition problem. To evaluate the proposition, we performed a\nseries of experiments showing that the proposed approach statistically improves\nthe performance of a model based on Graph Centrality, achieving better\ncoverage, accuracy, and recall.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 09:42:10 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Woloszyn", "Vinicius", ""], ["Machado", "Guilherme Medeiros", ""], ["Wives", "Leandro Krug", ""], ["de Oliveira", "Jos\u00e9 Palazzo Moreira", ""]]}, {"id": "1807.00488", "submitter": "Kaili Zhu", "authors": "Zhu Kaili, Chuan Wang, Ruobing Li, Yang Liu, Tianlei Hu and Hui Lin", "title": "A Simple but Effective Classification Model for Grammatical Error\n  Correction", "comments": "short paper with 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat grammatical error correction (GEC) as a classification problem in\nthis study, where for different types of errors, a target word is identified,\nand the classifier predicts the correct word form from a set of possible\nchoices. We propose a novel neural network based feature representation and\nclassification model, trained using large text corpora without human\nannotations. Specifically we use RNNs with attention to represent both the left\nand right context of a target word. All feature embeddings are learned jointly\nin an end-to-end fashion. Experimental results show that our novel approach\noutperforms other classifier methods on the CoNLL-2014 test set (F0.5 45.05%).\nOur model is simple but effective, and is suitable for industrial production.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:48:46 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kaili", "Zhu", ""], ["Wang", "Chuan", ""], ["Li", "Ruobing", ""], ["Liu", "Yang", ""], ["Hu", "Tianlei", ""], ["Lin", "Hui", ""]]}, {"id": "1807.00543", "submitter": "Piotr \\.Zelasko", "authors": "Piotr \\.Zelasko, Piotr Szyma\\'nski, Jan Mizgajski, Adrian Szymczak,\n  Yishay Carmiel, Najim Dehak", "title": "Punctuation Prediction Model for Conversational Speech", "comments": "Accepted for Interspeech 2018 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ASR system usually does not predict any punctuation or capitalization.\nLack of punctuation causes problems in result presentation and confuses both\nthe human reader andoff-the-shelf natural language processing algorithms. To\novercome these limitations, we train two variants of Deep Neural Network (DNN)\nsequence labelling models - a Bidirectional Long Short-Term Memory (BLSTM) and\na Convolutional Neural Network (CNN), to predict the punctuation. The models\nare trained on the Fisher corpus which includes punctuation annotation. In our\nexperiments, we combine time-aligned and punctuated Fisher corpus transcripts\nusing a sequence alignment algorithm. The neural networks are trained on Common\nWeb Crawl GloVe embedding of the words in Fisher transcripts aligned with\nconversation side indicators and word time infomation. The CNNs yield a better\nprecision and BLSTMs tend to have better recall. While BLSTMs make fewer\nmistakes overall, the punctuation predicted by the CNN is more accurate -\nespecially in the case of question marks. Our results constitute significant\nevidence that the distribution of words in time, as well as pre-trained\nembeddings, can be useful in the punctuation prediction task.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:06:27 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["\u017belasko", "Piotr", ""], ["Szyma\u0144ski", "Piotr", ""], ["Mizgajski", "Jan", ""], ["Szymczak", "Adrian", ""], ["Carmiel", "Yishay", ""], ["Dehak", "Najim", ""]]}, {"id": "1807.00560", "submitter": "Sihao Xue", "authors": "Sihao Xue, Zhenyi Ying, Fan Mo, Min Wang, Jue Sun", "title": "Weight-importance sparse training in keyword spotting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large size models are implemented in recently ASR system to deal with complex\nspeech recognition problems. The num- ber of parameters in these models makes\nthem hard to deploy, especially on some resource-short devices such as car\ntablet. Besides this, at most of time, ASR system is used to deal with\nreal-time problem such as keyword spotting (KWS). It is contradictory to the\nfact that large model requires long com- putation time. To deal with this\nproblem, we apply some sparse algo- rithms to reduces number of parameters in\nsome widely used models, Deep Neural Network (DNN) KWS, which requires real\nshort computation time. We can prune more than 90 % even 95% of parameters in\nthe model with tiny effect decline. And the sparse model performs better than\nbaseline models which has same order number of parameters. Besides this, sparse\nalgorithm can lead us to find rational model size au- tomatically for certain\nproblem without concerning choosing an original model size.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:34:34 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 11:33:33 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 01:35:50 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Xue", "Sihao", ""], ["Ying", "Zhenyi", ""], ["Mo", "Fan", ""], ["Wang", "Min", ""], ["Sun", "Jue", ""]]}, {"id": "1807.00571", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados and Luis Espinosa-Anke and Mohammad Taher\n  Pilehvar", "title": "The Interplay between Lexical Resources and Natural Language Processing", "comments": "NAACL 2018 Tutorial", "journal-ref": "Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Tutorial Abstracts", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating linguistic, world and common sense knowledge into AI/NLP\nsystems is currently an important research area, with several open problems and\nchallenges. At the same time, processing and storing this knowledge in lexical\nresources is not a straightforward task. This tutorial proposes to address\nthese complementary goals from two methodological perspectives: the use of NLP\nmethods to help the process of constructing and enriching lexical resources and\nthe use of lexical resources for improving NLP applications. Two main types of\naudience can benefit from this tutorial: those working on language resources\nwho are interested in becoming acquainted with automatic NLP techniques, with\nthe end goal of speeding and/or easing up the process of resource curation; and\non the other hand, researchers in NLP who would like to benefit from the\nknowledge of lexical resources to improve their systems and models. The slides\nof the tutorial are available at https://bitbucket.org/luisespinosa/lr-nlp/\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:53:50 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Camacho-Collados", "Jose", ""], ["Espinosa-Anke", "Luis", ""], ["Pilehvar", "Mohammad Taher", ""]]}, {"id": "1807.00651", "submitter": "Marcos Zampieri", "authors": "Marta R. Costa-juss\\`a, Marcos Zampieri, Santanu Pal", "title": "A Neural Approach to Language Variety Translation", "comments": "Proceedings of the Fifth Workshop on NLP for Similar Languages,\n  Varieties and Dialects (VarDial)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the first neural-based machine translation system\ntrained to translate between standard national varieties of the same language.\nWe take the pair Brazilian - European Portuguese as an example and compare the\nperformance of this method to a phrase-based statistical machine translation\nsystem. We report a performance improvement of 0.9 BLEU points in translating\nfrom European to Brazilian Portuguese and 0.2 BLEU points when translating in\nthe opposite direction. We also carried out a human evaluation experiment with\nnative speakers of Brazilian Portuguese which indicates that humans prefer the\noutput produced by the neural-based system in comparison to the statistical\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:29:46 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Costa-juss\u00e0", "Marta R.", ""], ["Zampieri", "Marcos", ""], ["Pal", "Santanu", ""]]}, {"id": "1807.00717", "submitter": "Mark-Christoph M\\\"uller", "authors": "Mark-Christoph M\\\"uller and Michael Strube", "title": "Transparent, Efficient, and Robust Word Embedding Access with WOMBAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present WOMBAT, a Python tool which supports NLP practitioners in\naccessing word embeddings from code. WOMBAT addresses common research problems,\nincluding unified access, scaling, and robust and reproducible preprocessing.\nCode that uses WOMBAT for accessing word embeddings is not only cleaner, more\nreadable, and easier to reuse, but also much more efficient than code using\nstandard in-memory methods: a Python script using WOMBAT for evaluating seven\nlarge word embedding collections (8.7M embedding vectors in total) on a simple\nSemEval sentence similarity task involving 250 raw sentence pairs completes in\nunder ten seconds end-to-end on a standard notebook computer.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 14:47:30 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["M\u00fcller", "Mark-Christoph", ""], ["Strube", "Michael", ""]]}, {"id": "1807.00735", "submitter": "Yang-Hui He", "authors": "Yang-Hui He, Vishnu Jejjala, Brent D. Nelson", "title": "hep-th", "comments": "50 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply techniques in natural language processing, computational\nlinguistics, and machine-learning to investigate papers in hep-th and four\nrelated sections of the arXiv: hep-ph, hep-lat, gr-qc, and math-ph. All of the\ntitles of papers in each of these sections, from the inception of the arXiv\nuntil the end of 2017, are extracted and treated as a corpus which we use to\ntrain the neural network Word2Vec. A comparative study of common n-grams,\nlinear syntactical identities, word cloud and word similarities is carried out.\nWe find notable scientific and sociological differences between the fields. In\nconjunction with support vector machines, we also show that the syntactic\nstructure of the titles in different sub-fields of high energy and mathematical\nphysics are sufficiently different that a neural network can perform a binary\nclassification of formal versus phenomenological sections with 87.1% accuracy,\nand can perform a finer five-fold classification across all sections with 65.1%\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 11:44:35 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["He", "Yang-Hui", ""], ["Jejjala", "Vishnu", ""], ["Nelson", "Brent D.", ""]]}, {"id": "1807.00745", "submitter": "Michael A. Hedderich", "authors": "Michael A. Hedderich and Dietrich Klakow", "title": "Training a Neural Network in a Low-Resource Setting on Automatically\n  Annotated Noisy Data", "comments": "In Proceedings of the Workshop on Deep Learning Approaches for\n  Low-Resource NLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually labeled corpora are expensive to create and often not available for\nlow-resource languages or domains. Automatic labeling approaches are an\nalternative way to obtain labeled data in a quicker and cheaper way. However,\nthese labels often contain more errors which can deteriorate a classifier's\nperformance when trained on this data. We propose a noise layer that is added\nto a neural network architecture. This allows modeling the noise and train on a\ncombination of clean and noisy data. We show that in a low-resource NER task we\ncan improve performance by up to 35% by using additional, noisy data and\nhandling the noise.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:35:02 GMT"}, {"version": "v2", "created": "Sun, 22 Jul 2018 06:01:14 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Hedderich", "Michael A.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1807.00752", "submitter": "Akihiro Kato", "authors": "Akihiro Kato and Tomi Kinnunen", "title": "Waveform to Single Sinusoid Regression to Estimate the F0 Contour from\n  Noisy Speech Using Recurrent Deep Neural Networks", "comments": "Accepted by peer reviewing for Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental frequency (F0) represents pitch in speech that determines\nprosodic characteristics of speech and is needed in various tasks for speech\nanalysis and synthesis. Despite decades of research on this topic, F0\nestimation at low signal-to-noise ratios (SNRs) in unexpected noise conditions\nremains difficult. This work proposes a new approach to noise robust F0\nestimation using a recurrent neural network (RNN) trained in a supervised\nmanner. Recent studies employ deep neural networks (DNNs) for F0 tracking as a\nframe-by-frame classification task into quantised frequency states but we\npropose waveform-to-sinusoid regression instead to achieve both noise\nrobustness and accurate estimation with increased frequency resolution.\n  Experimental results with PTDB-TUG corpus contaminated by additive noise\n(NOISEX-92) demonstrate that the proposed method improves gross pitch error\n(GPE) rate and fine pitch error (FPE) by more than 35 % at SNRs between -10 dB\nand +10 dB compared with well-known noise robust F0 tracker, PEFAC.\nFurthermore, the proposed method also outperforms state-of-the-art DNN-based\napproaches by more than 15 % in terms of both FPE and GPE rate over the\npreceding SNR range.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:42:00 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kato", "Akihiro", ""], ["Kinnunen", "Tomi", ""]]}, {"id": "1807.00775", "submitter": "Sven Buechel", "authors": "Sven Buechel and Udo Hahn", "title": "Representation Mapping: A Novel Approach to Generate High-Quality\n  Multi-Lingual Emotion Lexicons", "comments": "Published in LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, sentiment analysis has increasingly shifted attention to\nrepresentational frameworks more expressive than semantic polarity (being\npositive, negative or neutral). However, these richer formats (like Basic\nEmotions or Valence-Arousal-Dominance, and variants therefrom), rooted in\npsychological research, tend to proliferate the number of representation\nschemes for emotion encoding. Thus, a large amount of representationally\nincompatible emotion lexicons has been developed by various research groups\nadopting one or the other emotion representation format. As a consequence, the\nreusability of these resources decreases as does the comparability of systems\nusing them. In this paper, we propose to solve this dilemma by methods and\ntools which map different representation formats onto each other for the sake\nof mutual compatibility and interoperability of language resources. We present\nthe first large-scale investigation of such representation mappings for four\ntypologically diverse languages and find evidence that our approach produces\n(near-)gold quality emotion lexicons, even in cross-lingual settings. Finally,\nwe use our models to create new lexicons for eight typologically diverse\nlanguages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 16:29:34 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Buechel", "Sven", ""], ["Hahn", "Udo", ""]]}, {"id": "1807.00791", "submitter": "Michael Rumiancau", "authors": "Aliaksei Vertsel, Mikhail Rumiantsau", "title": "Pragmatic approach to structured data querying via natural language\n  interface", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of technology increases and data analysis becomes integral in many\nbusinesses, the ability to quickly access and interpret data has become more\nimportant than ever. Information retrieval technologies are being utilized by\norganizations and companies to manage their information systems and processes.\nDespite information retrieval of a large amount of data being efficient\norganized in relational databases, a user still needs to master the DB\nlanguage/schema to completely formulate the queries. This puts a burden on\norganizations and companies to hire employees that are proficient in DB\nlanguages/schemas to formulate queries. To reduce some of the burden on already\noverstretched data teams, many organizations are looking for tools that allow\nnon-developers to query their databases. Unfortunately, writing a valid SQL\nquery that answers the question a user is trying to ask isn't always easy. Even\nseemingly simple questions, like \"Which start-up companies received more than\n$200M in funding?\" can actually be very hard to answer, let alone convert into\na SQL query. How do you define start-up companies? By size, location, duration\nof time they have been incorporated? This may be fine if a user is working with\na database they're already familiar with, but what if users are not familiar\nwith the database. What is needed is a centralized system that can effectively\ntranslate natural language queries into specific database queries for different\ncustomer database types. There is a number of factors that can dramatically\naffect the system architecture and the set of algorithms used to translate NL\nqueries into a structured query representation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 17:24:22 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Vertsel", "Aliaksei", ""], ["Rumiantsau", "Mikhail", ""]]}, {"id": "1807.00818", "submitter": "Ilya Gusev", "authors": "Daniil Anastasyev, Ilya Gusev, Eugene Indenbom", "title": "Improving part-of-speech tagging via multi-task learning and\n  character-level word representations", "comments": null, "journal-ref": "Computational Linguistics and Intellectual Technologies, Papers\n  from the Annual International Conference \"Dialogue\" (2018) Issue 17, 14-27", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the ways to improve POS-tagging using various types\nof auxiliary losses and different word representations. As a baseline, we\nutilized a BiLSTM tagger, which is able to achieve state-of-the-art results on\nthe sequence labelling tasks. We developed a new method for character-level\nword representation using feedforward neural network. Such representation gave\nus better results in terms of speed and performance of the model. We also\napplied a novel technique of pretraining such word representations with\nexisting word vectors. Finally, we designed a new variant of auxiliary loss for\nsequence labelling tasks: an additional prediction of the neighbour labels.\nSuch loss forces a model to learn the dependencies in-side a sequence of labels\nand accelerates the process of training. We test these methods on English and\nRussian languages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:04:52 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Anastasyev", "Daniil", ""], ["Gusev", "Ilya", ""], ["Indenbom", "Eugene", ""]]}, {"id": "1807.00868", "submitter": "Vladimir Bataev", "authors": "Vladimir Bataev, Maxim Korenevsky, Ivan Medennikov, Alexander\n  Zatvornitskiy", "title": "Exploring End-to-End Techniques for Low-Resource Speech Recognition", "comments": "Accepted for Specom 2018, 20th International Conference on Speech and\n  Computer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present simple grapheme-based system for low-resource speech\nrecognition using Babel data for Turkish spontaneous speech (80 hours). We have\ninvestigated different neural network architectures performance, including\nfully-convolutional, recurrent and ResNet with GRU. Different features and\nnormalization techniques are compared as well. We also proposed CTC-loss\nmodification using segmentation during training, which leads to improvement\nwhile decoding with small beam size. Our best model achieved word error rate of\n45.8%, which is the best reported result for end-to-end systems using in-domain\ndata for this task, according to our knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 19:47:22 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Bataev", "Vladimir", ""], ["Korenevsky", "Maxim", ""], ["Medennikov", "Ivan", ""], ["Zatvornitskiy", "Alexander", ""]]}, {"id": "1807.00914", "submitter": "Edoardo Maria Ponti", "authors": "Edoardo Maria Ponti, Helen O'Horan, Yevgeni Berzak, Ivan Vuli\\'c, Roi\n  Reichart, Thierry Poibeau, Ekaterina Shutova, Anna Korhonen", "title": "Modeling Language Variation and Universals: A Survey on Typological\n  Linguistics for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic typology aims to capture structural and semantic variation across\nthe world's languages. A large-scale typology could provide excellent guidance\nfor multilingual Natural Language Processing (NLP), particularly for languages\nthat suffer from the lack of human labeled resources. We present an extensive\nliterature survey on the use of typological information in the development of\nNLP techniques. Our survey demonstrates that to date, the use of information in\nexisting typological databases has resulted in consistent but modest\nimprovements in system performance. We show that this is due to both intrinsic\nlimitations of databases (in terms of coverage and feature granularity) and\nunder-employment of the typological features included in them. We advocate for\na new approach that adapts the broad and discrete nature of typological\ncategories to the contextual and continuous nature of machine learning\nalgorithms used in contemporary NLP. In particular, we suggest that such\napproach could be facilitated by recent developments in data-driven induction\nof typological knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 22:09:59 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 19:55:28 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 23:23:45 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ponti", "Edoardo Maria", ""], ["O'Horan", "Helen", ""], ["Berzak", "Yevgeni", ""], ["Vuli\u0107", "Ivan", ""], ["Reichart", "Roi", ""], ["Poibeau", "Thierry", ""], ["Shutova", "Ekaterina", ""], ["Korhonen", "Anna", ""]]}, {"id": "1807.00930", "submitter": "Davide Nunes", "authors": "Davide Nunes, Luis Antunes", "title": "Neural Random Projections for Language Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based language models deal with data sparsity problems by\nmapping the large discrete space of words into a smaller continuous space of\nreal-valued vectors. By learning distributed vector representations for words,\neach training sample informs the neural network model about a combinatorial\nnumber of other patterns. In this paper, we exploit the sparsity in natural\nlanguage even further by encoding each unique input word using a fixed sparse\nrandom representation. These sparse codes are then projected onto a smaller\nembedding space which allows for the encoding of word occurrences from a\npossibly unknown vocabulary, along with the creation of more compact language\nmodels using a reduced number of parameters. We investigate the properties of\nour encoding mechanism empirically, by evaluating its performance on the widely\nused Penn Treebank corpus. We show that guaranteeing approximately equidistant\n(nearly orthogonal) vector representations for unique discrete inputs is enough\nto provide the neural network model with enough information to learn --and make\nuse-- of distributed representations for these inputs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 23:54:48 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 09:56:55 GMT"}, {"version": "v3", "created": "Wed, 15 Aug 2018 19:15:05 GMT"}, {"version": "v4", "created": "Wed, 26 Sep 2018 16:55:04 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Nunes", "Davide", ""], ["Antunes", "Luis", ""]]}, {"id": "1807.00938", "submitter": "Gibran Fuentes-Pineda", "authors": "Gibran Fuentes-Pineda and Ivan Vladimir Meza-Ruiz", "title": "Topic Discovery in Massive Text Corpora Based on Min-Hashing", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2019.06.024", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of discovering topics in text corpora has been dominated by Latent\nDirichlet Allocation and other Topic Models for over a decade. In order to\napply these approaches to massive text corpora, the vocabulary needs to be\nreduced considerably and large computer clusters and/or GPUs are typically\nrequired. Moreover, the number of topics must be provided beforehand but this\ndepends on the corpus characteristics and it is often difficult to estimate,\nespecially for massive text corpora. Unfortunately, both topic quality and time\ncomplexity are sensitive to this choice. This paper describes an alternative\napproach to discover topics based on Min-Hashing, which can handle massive text\ncorpora and large vocabularies using modest computer hardware and does not\nrequire to fix the number of topics in advance. The basic idea is to generate\nmultiple random partitions of the corpus vocabulary to find sets of highly\nco-occurring words, which are then clustered to produce the final topics. In\ncontrast to probabilistic topic models where topics are distributions over the\ncomplete vocabulary, the topics discovered by the proposed approach are sets of\nhighly co-occurring words. Interestingly, these topics underlie various\nthematics with different levels of granularity. An extensive qualitative and\nquantitative evaluation using the 20 Newsgroups (18K), Reuters (800K), Spanish\nWikipedia (1M), and English Wikipedia (5M) corpora shows that the proposed\napproach is able to consistently discover meaningful and coherent topics.\nRemarkably, the time complexity of the proposed approach is linear with respect\nto corpus and vocabulary size; a non-parallel implementation was able to\ndiscover topics from the entire English edition of Wikipedia with over 5\nmillion documents and 1 million words in less than 7 hours.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 00:52:50 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 06:41:03 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Fuentes-Pineda", "Gibran", ""], ["Meza-Ruiz", "Ivan Vladimir", ""]]}, {"id": "1807.00993", "submitter": "Bin Wang", "authors": "Bin Wang, Zhijian Ou", "title": "Improved training of neural trans-dimensional random field language\n  models with dynamic noise-contrastive estimation", "comments": "6 pages. Has been submitted to SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new whole-sentence language model - neural trans-dimensional random field\nlanguage model (neural TRF LM), where sentences are modeled as a collection of\nrandom fields, and the potential function is defined by a neural network, has\nbeen introduced and successfully trained by noise-contrastive estimation (NCE).\nIn this paper, we extend NCE and propose dynamic noise-contrastive estimation\n(DNCE) to solve the two problems observed in NCE training. First, a dynamic\nnoise distribution is introduced and trained simultaneously to converge to the\ndata distribution. This helps to significantly cut down the noise sample number\nused in NCE and reduce the training cost. Second, DNCE discriminates between\nsentences generated from the noise distribution and sentences generated from\nthe interpolation of the data distribution and the noise distribution. This\nalleviates the overfitting problem caused by the sparseness of the training\nset. With DNCE, we can successfully and efficiently train neural TRF LMs on\nlarge corpus (about 0.8 billion words) with large vocabulary (about 568 K\nwords). Neural TRF LMs perform as good as LSTM LMs with less parameters and\nbeing 5x~114x faster in rescoring sentences. Interpolating neural TRF LMs with\nLSTM LMs and n-gram LMs can further reduce the error rates.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 06:36:48 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Wang", "Bin", ""], ["Ou", "Zhijian", ""]]}, {"id": "1807.01122", "submitter": "Nathaniel Blanchard", "authors": "Nathaniel Blanchard, Daniel Moreira, Aparna Bharati, Walter J.\n  Scheirer", "title": "Getting the subtext without the text: Scalable multimodal sentiment\n  classification from visual and acoustic modalities", "comments": "Published in the First Workshop on Computational Modeling of Human\n  Multimodal Language - ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, video blogs (vlogs) have become an extremely popular\nmethod through which people express sentiment. The ubiquitousness of these\nvideos has increased the importance of multimodal fusion models, which\nincorporate video and audio features with traditional text features for\nautomatic sentiment detection. Multimodal fusion offers a unique opportunity to\nbuild models that learn from the full depth of expression available to human\nviewers. In the detection of sentiment in these videos, acoustic and video\nfeatures provide clarity to otherwise ambiguous transcripts. In this paper, we\npresent a multimodal fusion model that exclusively uses high-level video and\naudio features to analyze spoken sentences for sentiment. We discard\ntraditional transcription features in order to minimize human intervention and\nto maximize the deployability of our model on at-scale real-world data. We\nselect high-level features for our model that have been successful in nonaffect\ndomains in order to test their generalizability in the sentiment detection\ndomain. We train and test our model on the newly released CMU Multimodal\nOpinion Sentiment and Emotion Intensity (CMUMOSEI) dataset, obtaining an F1\nscore of 0.8049 on the validation set and an F1 score of 0.6325 on the held-out\nchallenge test set.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 12:38:11 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Blanchard", "Nathaniel", ""], ["Moreira", "Daniel", ""], ["Bharati", "Aparna", ""], ["Scheirer", "Walter J.", ""]]}, {"id": "1807.01270", "submitter": "Tao Ge", "authors": "Tao Ge, Furu Wei, Ming Zhou", "title": "Reaching Human-level Performance in Automatic Grammatical Error\n  Correction: An Empirical Study", "comments": "Substantial text overlap with \"Fluency Boost Learning and Inference\n  for Neural Grammatical Error Correction\" (accepted by ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence (seq2seq) approaches have proven to be successful\nin grammatical error correction (GEC). Based on the seq2seq framework, we\npropose a novel fluency boost learning and inference mechanism. Fluency\nboosting learning generates diverse error-corrected sentence pairs during\ntraining, enabling the error correction model to learn how to improve a\nsentence's fluency from more instances, while fluency boosting inference allows\nthe model to correct a sentence incrementally with multiple inference steps.\nCombining fluency boost learning and inference with convolutional seq2seq\nmodels, our approach achieves the state-of-the-art performance: 75.72 (F_{0.5})\non CoNLL-2014 10 annotation dataset and 62.42 (GLEU) on JFLEG test set\nrespectively, becoming the first GEC system that reaches human-level\nperformance (72.58 for CoNLL and 62.37 for JFLEG) on both of the benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:37:05 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 05:15:00 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 06:01:45 GMT"}, {"version": "v4", "created": "Tue, 10 Jul 2018 14:20:14 GMT"}, {"version": "v5", "created": "Wed, 11 Jul 2018 05:20:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ge", "Tao", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1807.01292", "submitter": "Umutcan \\c{S}im\\c{s}ek", "authors": "Umutcan \\c{S}im\\c{s}ek and Dieter Fensel", "title": "Intent Generation for Goal-Oriented Dialogue Systems based on Schema.org\n  Annotations", "comments": "Presented in the First International Workshop on Chatbots co-located\n  with ICWSM 2018 in Stanford, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialogue systems typically communicate with a backend (e.g.\ndatabase, Web API) to complete certain tasks to reach a goal. The intents that\na dialogue system can recognize are mostly included to the system by the\ndeveloper statically. For an open dialogue system that can work on more than a\nsmall set of well curated data and APIs, this manual intent creation will not\nscalable. In this paper, we introduce a straightforward methodology for intent\ncreation based on semantic annotation of data and services on the web. With\nthis method, the Natural Language Understanding (NLU) module of a goal-oriented\ndialogue system can adapt to newly introduced APIs without requiring heavy\ndeveloper involvement. We were able to extract intents and necessary slots to\nbe filled from schema.org annotations. We were also able to create a set of\ninitial training sentences for classifying user utterances into the generated\nintents. We demonstrate our approach on the NLU module of a state-of-the art\ndialogue system development framework.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 17:15:49 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["\u015eim\u015fek", "Umutcan", ""], ["Fensel", "Dieter", ""]]}, {"id": "1807.01337", "submitter": "Piero Molino", "authors": "Piero Molino, Huaixiu Zheng, Yi-Chia Wang", "title": "COTA: Improving the Speed and Accuracy of Customer Support through\n  Ranking and Deep Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3219819.3219851", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a company looking to provide delightful user experiences, it is of\nparamount importance to take care of any customer issues. This paper proposes\nCOTA, a system to improve speed and reliability of customer support for end\nusers through automated ticket classification and answers selection for support\nrepresentatives. Two machine learning and natural language processing\ntechniques are demonstrated: one relying on feature engineering (COTA v1) and\nthe other exploiting raw signals through deep learning architectures (COTA v2).\nCOTA v1 employs a new approach that converts the multi-classification task into\na ranking problem, demonstrating significantly better performance in the case\nof thousands of classes. For COTA v2, we propose an Encoder-Combiner-Decoder, a\nnovel deep learning architecture that allows for heterogeneous input and output\nfeature types and injection of prior knowledge through network architecture\nchoices. This paper compares these models and their variants on the task of\nticket classification and answer selection, showing model COTA v2 outperforms\nCOTA v1, and analyzes their inner workings and shortcomings. Finally, an A/B\ntest is conducted in a production setting validating the real-world impact of\nCOTA in reducing issue resolution time by 10 percent without reducing customer\nsatisfaction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 18:25:44 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Molino", "Piero", ""], ["Zheng", "Huaixiu", ""], ["Wang", "Yi-Chia", ""]]}, {"id": "1807.01395", "submitter": "Madhumita Sushil", "authors": "Madhumita Sushil and Simon \\v{S}uster and Kim Luyckx and Walter\n  Daelemans", "title": "Patient representation learning and interpretable evaluation using\n  clinical notes", "comments": "Accepted manuscript at Journal of Biomedical Informatics", "journal-ref": "Journal of Biomedical Informatics Volume 84C (2018) pp. 103-113", "doi": "10.1016/j.jbi.2018.06.016", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have three contributions in this work: 1. We explore the utility of a\nstacked denoising autoencoder and a paragraph vector model to learn\ntask-independent dense patient representations directly from clinical notes. To\nanalyze if these representations are transferable across tasks, we evaluate\nthem in multiple supervised setups to predict patient mortality, primary\ndiagnostic and procedural category, and gender. We compare their performance\nwith sparse representations obtained from a bag-of-words model. We observe that\nthe learned generalized representations significantly outperform the sparse\nrepresentations when we have few positive instances to learn from, and there is\nan absence of strong lexical features. 2. We compare the model performance of\nthe feature set constructed from a bag of words to that obtained from medical\nconcepts. In the latter case, concepts represent problems, treatments, and\ntests. We find that concept identification does not improve the classification\nperformance. 3. We propose novel techniques to facilitate model\ninterpretability. To understand and interpret the representations, we explore\nthe best encoded features within the patient representations obtained from the\nautoencoder model. Further, we calculate feature sensitivity across two\nnetworks to identify the most significant input features for different\nclassification tasks when we use these pretrained representations as the\nsupervised input. We successfully extract the most influential features for the\npipeline using this technique.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 23:20:49 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Sushil", "Madhumita", ""], ["\u0160uster", "Simon", ""], ["Luyckx", "Kim", ""], ["Daelemans", "Walter", ""]]}, {"id": "1807.01396", "submitter": "Timothy Dozat", "authors": "Timothy Dozat and Christopher D. Manning", "title": "Simpler but More Accurate Semantic Dependency Parsing", "comments": "ACL 2018 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While syntactic dependency annotations concentrate on the surface or\nfunctional structure of a sentence, semantic dependency annotations aim to\ncapture between-word relationships that are more closely related to the meaning\nof a sentence, using graph-structured representations. We extend the LSTM-based\nsyntactic parser of Dozat and Manning (2017) to train on and generate these\ngraph structures. The resulting system on its own achieves state-of-the-art\nperformance, beating the previous, substantially more complex state-of-the-art\nsystem by 0.6% labeled F1. Adding linguistically richer input representations\npushes the margin even higher, allowing us to beat it by 1.9% labeled F1.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 23:29:49 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Dozat", "Timothy", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1807.01466", "submitter": "Leimin Tian", "authors": "Leimin Tian, Catherine Lai, Johanna D. Moore", "title": "Polarity and Intensity: the Two Aspects of Sentiment Analysis", "comments": "Published at the First Grand Challenge and Workshop on Human\n  Multimodal Language (Challenge-HML) of ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current multimodal sentiment analysis frames sentiment score prediction as a\ngeneral Machine Learning task. However, what the sentiment score actually\nrepresents has often been overlooked. As a measurement of opinions and\naffective states, a sentiment score generally consists of two aspects: polarity\nand intensity. We decompose sentiment scores into these two aspects and study\nhow they are conveyed through individual modalities and combined multimodal\nmodels in a naturalistic monologue setting. In particular, we build unimodal\nand multimodal multi-task learning models with sentiment score prediction as\nthe main task and polarity and/or intensity classification as the auxiliary\ntasks. Our experiments show that sentiment analysis benefits from multi-task\nlearning, and individual modalities differ when conveying the polarity and\nintensity aspects of sentiment.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 07:18:36 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Tian", "Leimin", ""], ["Lai", "Catherine", ""], ["Moore", "Johanna D.", ""]]}, {"id": "1807.01554", "submitter": "Yutai Hou", "authors": "Yutai Hou, Yijia Liu, Wanxiang Che, Ting Liu", "title": "Sequence-to-Sequence Data Augmentation for Dialogue Language\n  Understanding", "comments": "Accepted By COLING2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of data augmentation for language\nunderstanding in task-oriented dialogue system. In contrast to previous work\nwhich augments an utterance without considering its relation with other\nutterances, we propose a sequence-to-sequence generation based data\naugmentation framework that leverages one utterance's same semantic\nalternatives in the training data. A novel diversity rank is incorporated into\nthe utterance representation to make the model produce diverse utterances and\nthese diversely augmented utterances help to improve the language understanding\nmodule. Experimental results on the Airline Travel Information System dataset\nand a newly created semantic frame annotation on Stanford Multi-turn,\nMultidomain Dialogue Dataset show that our framework achieves significant\nimprovements of 6.38 and 10.04 F-scores respectively when only a training set\nof hundreds utterances is represented. Case studies also confirm that our\nmethod generates diverse utterances.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 13:07:53 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Hou", "Yutai", ""], ["Liu", "Yijia", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "1807.01670", "submitter": "Karl Moritz Hermann", "authors": "Tiago Ramalho, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Frederic Besse, S. M. Ali\n  Eslami, G\\'abor Melis, Fabio Viola, Phil Blunsom, Karl Moritz Hermann", "title": "Encoding Spatial Relations from Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing has made significant inroads into learning the\nsemantics of words through distributional approaches, however representations\nlearnt via these methods fail to capture certain kinds of information implicit\nin the real world. In particular, spatial relations are encoded in a way that\nis inconsistent with human spatial reasoning and lacking invariance to\nviewpoint changes. We present a system capable of capturing the semantics of\nspatial relations such as behind, left of, etc from natural language. Our key\ncontributions are a novel multi-modal objective based on generating images of\nscenes from their textual descriptions, and a new dataset on which to train it.\nWe demonstrate that internal representations are robust to meaning preserving\ntransformations of descriptions (paraphrase invariance), while viewpoint\ninvariance is an emergent property of the system.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:38:49 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 10:03:23 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ramalho", "Tiago", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Besse", "Frederic", ""], ["Eslami", "S. M. Ali", ""], ["Melis", "G\u00e1bor", ""], ["Viola", "Fabio", ""], ["Blunsom", "Phil", ""], ["Hermann", "Karl Moritz", ""]]}, {"id": "1807.01677", "submitter": "Sreekavitha Parupalli", "authors": "Sreekavitha Parupalli, Vijjini Anvesh Rao and Radhika Mamidi", "title": "Towards Automation of Sense-type Identification of Verbs in\n  OntoSenseNet(Telugu)", "comments": "Accepted Long Oral Paper at 6th International Workshop on Natural\n  Language Processing for Social Media (SocialNLP) at 56th Annual Meeting of\n  the Association for Computational Linguistics, ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the enrichment of a manually developed resource of\nTelugu lexicon, OntoSenseNet. OntoSenseNet is a ontological sense annotated\nlexicon that marks each verb of Telugu with a primary and a secondary sense.\nThe area of research is relatively recent but has a large scope of development.\nWe provide an introductory work to enrich the OntoSenseNet to promote further\nresearch in Telugu. Classifiers are adopted to learn the sense relevant\nfeatures of the words in the resource and also to automate the tagging of\nsense-types for verbs. We perform a comparative analysis of different\nclassifiers applied on OntoSenseNet. The results of the experiment prove that\nautomated enrichment of the resource is effective using SVM classifiers and\nAdaboost ensemble.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:54:05 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Parupalli", "Sreekavitha", ""], ["Rao", "Vijjini Anvesh", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1807.01679", "submitter": "Sreekavitha Parupalli", "authors": "Sreekavitha Parupalli, Vijjini Anvesh Rao and Radhika Mamidi", "title": "BCSAT : A Benchmark Corpus for Sentiment Analysis in Telugu Using\n  Word-level Annotations", "comments": "Accepted as Long Paper at Student Research Workshop in 56th Annual\n  Meeting of the Association for Computational Linguistics, ACL-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presented work aims at generating a systematically annotated corpus that\ncan support the enhancement of sentiment analysis tasks in Telugu using\nword-level sentiment annotations. From OntoSenseNet, we extracted 11,000\nadjectives, 253 adverbs, 8483 verbs and sentiment annotation is being done by\nlanguage experts. We discuss the methodology followed for the polarity\nannotations and validate the developed resource. This work aims at developing a\nbenchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a\nmodel where lexeme annotations are applied for sentiment predictions. The\nfundamental aim of this paper is to validate and study the possibility of\nutilizing machine learning algorithms, word-level sentiment annotations in the\ntask of automated sentiment identification. Furthermore, accuracy is improved\nby annotating the bi-grams extracted from the target corpus.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:56:50 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Parupalli", "Sreekavitha", ""], ["Rao", "Vijjini Anvesh", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1807.01682", "submitter": "Weidong Yuan", "authors": "Weidong Yuan, Alan W Black", "title": "Generating Mandarin and Cantonese F0 Contours with Decision Trees and\n  BLSTMs", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper models the fundamental frequency contours on both Mandarin and\nCantonese speech with decision trees and DNNs (deep neural networks). Different\nkinds of f0 representations and model architectures are tested for decision\ntrees and DNNs. A new model called Additive-BLSTM (additive bidirectional long\nshort term memory) that predicts a base f0 contour and a residual f0 contour\nwith two BLSTMs is proposed. With respect to objective measures of RMSE and\ncorrelation, applying tone-dependent trees together with sample normalization\nand delta feature regularization within decision tree framework performs best.\nWhile the new Additive-BLSTM model with delta feature regularization performs\neven better. Subjective listening tests on both Mandarin and Cantonese\ncomparing Random Forest model (multiple decision trees) and the Additive-BLSTM\nmodel were also held and confirmed the advantage of the new model according to\nthe listeners' preference.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 17:04:14 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Yuan", "Weidong", ""], ["Black", "Alan W", ""]]}, {"id": "1807.01704", "submitter": "Yingping Xing", "authors": "Yongping Xing and Chuangbai Xiao and Yifei Wu and Ziming Ding", "title": "A Convolutional Neural Network for Aspect Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of the Internet, natural language processing (NLP), in\nwhich sentiment analysis is an important task, became vital in information\nprocessing.Sentiment analysis includes aspect sentiment classification. Aspect\nsentiment can provide complete and in-depth results with increased attention on\naspect-level. Different context words in a sentence influence the sentiment\npolarity of a sentence variably, and polarity varies based on the different\naspects in a sentence. Take the sentence, 'I bought a new camera. The picture\nquality is amazing but the battery life is too short.'as an example. If the\naspect is picture quality, then the expected sentiment polarity is 'positive',\nif the battery life aspect is considered, then the sentiment polarity should be\n'negative'; therefore, aspect is important to consider when we explore aspect\nsentiment in the sentence. Recurrent neural network (RNN) is regarded as a good\nmodel to deal with natural language processing, and RNNs has get good\nperformance on aspect sentiment classification including Target-Dependent LSTM\n(TD-LSTM) ,Target-Connection LSTM (TC-LSTM) (Tang, 2015a, b), AE-LSTM, AT-LSTM,\nAEAT-LSTM (Wang et al., 2016).There are also extensive literatures on sentiment\nclassification utilizing convolutional neural network, but there is little\nliterature on aspect sentiment classification using convolutional neural\nnetwork. In our paper, we develop attention-based input layers in which aspect\ninformation is considered by input layer. We then incorporate attention-based\ninput layers into convolutional neural network (CNN) to introduce context words\ninformation. In our experiment, incorporating aspect information into CNN\nimproves the latter's aspect sentiment classification performance without using\nsyntactic parser or external sentiment lexicons in a benchmark dataset from\nTwitter but get better performance compared with other models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 09:07:34 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Xing", "Yongping", ""], ["Xiao", "Chuangbai", ""], ["Wu", "Yifei", ""], ["Ding", "Ziming", ""]]}, {"id": "1807.01745", "submitter": "Tianze Shi", "authors": "Carlos G\\'omez-Rodr\\'iguez and Tianze Shi and Lillian Lee", "title": "Global Transition-based Non-projective Dependency Parsing", "comments": "Proceedings of ACL 2018. 13 pages", "journal-ref": "Proceedings of ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shi, Huang, and Lee (2017) obtained state-of-the-art results for English and\nChinese dependency parsing by combining dynamic-programming implementations of\ntransition-based dependency parsers with a minimal set of bidirectional LSTM\nfeatures. However, their results were limited to projective parsing. In this\npaper, we extend their approach to support non-projectivity by providing the\nfirst practical implementation of the MH_4 algorithm, an $O(n^4)$ mildly\nnonprojective dynamic-programming parser with very high coverage on\nnon-projective treebanks. To make MH_4 compatible with minimal transition-based\nfeature sets, we introduce a transition-based interpretation of it in which\nparser items are mapped to sequences of transitions. We thus obtain the first\nimplementation of global decoding for non-projective transition-based parsing,\nand demonstrate empirically that it is more effective than its projective\ncounterpart in parsing a number of highly non-projective languages\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 19:09:40 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Shi", "Tianze", ""], ["Lee", "Lillian", ""]]}, {"id": "1807.01763", "submitter": "Yue Liu", "authors": "Yue Liu, Tongtao Zhang, Zhicheng Liang, Heng Ji, Deborah L. McGuinness", "title": "Seq2RDF: An end-to-end application for deriving Triples from Natural\n  Language Text", "comments": "Proceedings of the 17th International Semantic Web Conference P&D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end approach that takes unstructured textual input and\ngenerates structured output compliant with a given vocabulary. Inspired by\nrecent successes in neural machine translation, we treat the triples within a\ngiven knowledge graph as an independent graph language and propose an\nencoder-decoder framework with an attention mechanism that leverages knowledge\ngraph embeddings. Our model learns the mapping from natural language text to\ntriple representation in the form of subject-predicate-object using the\nselected knowledge graph vocabulary. Experiments on three different data sets\nshow that we achieve competitive F1-Measures over the baselines using our\nsimple yet effective approach. A demo video is included.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 20:13:31 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 06:27:30 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 20:49:30 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Liu", "Yue", ""], ["Zhang", "Tongtao", ""], ["Liang", "Zhicheng", ""], ["Ji", "Heng", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1807.01836", "submitter": "Vikas Yadav", "authors": "Vikas Yadav and Rebecca Sharp and Mihai Surdeanu", "title": "Sanity Check: A Strong Alignment and Information Retrieval Baseline for\n  Question Answering", "comments": "SIGIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While increasingly complex approaches to question answering (QA) have been\nproposed, the true gain of these systems, particularly with respect to their\nexpensive training requirements, can be inflated when they are not compared to\nadequate baselines. Here we propose an unsupervised, simple, and fast alignment\nand information retrieval baseline that incorporates two novel contributions: a\n\\textit{one-to-many alignment} between query and document terms and\n\\textit{negative alignment} as a proxy for discriminative information. Our\napproach not only outperforms all conventional baselines as well as many\nsupervised recurrent neural networks, but also approaches the state of the art\nfor supervised systems on three QA datasets. With only three hyperparameters,\nwe achieve 47\\% P@1 on an 8th grade Science QA dataset, 32.9\\% P@1 on a Yahoo!\nanswers QA dataset and 64\\% MAP on WikiQA. We also achieve 26.56\\% and 58.36\\%\non ARC challenge and easy dataset respectively. In addition to including the\nadditional ARC results in this version of the paper, for the ARC easy set only\nwe also experimented with one additional parameter -- number of justifications\nretrieved.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 03:33:53 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Yadav", "Vikas", ""], ["Sharp", "Rebecca", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1807.01855", "submitter": "Haitao Liu", "authors": "Shuiyuan Yu, Chunshan Xu, Haitao Liu", "title": "Zipf's law in 50 languages: its structural pattern, linguistic\n  interpretation, and cognitive motivation", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zipf's law has been found in many human-related fields, including language,\nwhere the frequency of a word is persistently found as a power law function of\nits frequency rank, known as Zipf's law. However, there is much dispute whether\nit is a universal law or a statistical artifact, and little is known about what\nmechanisms may have shaped it. To answer these questions, this study conducted\na large scale cross language investigation into Zipf's law. The statistical\nresults show that Zipf's laws in 50 languages all share a 3-segment structural\npattern, with each segment demonstrating distinctive linguistic properties and\nthe lower segment invariably bending downwards to deviate from theoretical\nexpectation. This finding indicates that this deviation is a fundamental and\nuniversal feature of word frequency distributions in natural languages, not the\nstatistical error of low frequency words. A computer simulation based on the\ndual-process theory yields Zipf's law with the same structural pattern,\nsuggesting that Zipf's law of natural languages are motivated by common\ncognitive mechanisms. These results show that Zipf's law in languages is\nmotivated by cognitive mechanisms like dual-processing that govern human verbal\nbehaviors.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 06:03:39 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Yu", "Shuiyuan", ""], ["Xu", "Chunshan", ""], ["Liu", "Haitao", ""]]}, {"id": "1807.01882", "submitter": "Shuqi Sun", "authors": "Zhenyu Jiao, Shuqi Sun, Ke Sun", "title": "Chinese Lexical Analysis with Deep Bi-GRU-CRF Network", "comments": "10 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical analysis is believed to be a crucial step towards natural language\nunderstanding and has been widely studied. Recent years, end-to-end lexical\nanalysis models with recurrent neural networks have gained increasing\nattention. In this report, we introduce a deep Bi-GRU-CRF network that jointly\nmodels word segmentation, part-of-speech tagging and named entity recognition\ntasks. We trained the model using several massive corpus pre-tagged by our best\nChinese lexical analysis tool, together with a small, yet high-quality human\nannotated corpus. We conducted balanced sampling between different corpora to\nguarantee the influence of human annotations, and fine-tune the CRF decoding\nlayer regularly during the training progress. As evaluated by linguistic\nexperts, the model achieved a 95.5% accuracy on the test set, roughly 13%\nrelative error reduction over our (previously) best Chinese lexical analysis\ntool. The model is computationally efficient, achieving the speed of 2.3K\ncharacters per second with one thread.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 07:45:25 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Jiao", "Zhenyu", ""], ["Sun", "Shuqi", ""], ["Sun", "Ke", ""]]}, {"id": "1807.01956", "submitter": "Markus M\\\"uller", "authors": "Markus M\\\"uller, Sebastian St\\\"uker, and Alex Waibel", "title": "Neural Language Codes for Multilingual Acoustic Models", "comments": "5 pages, 3 figures, accepted at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Speech Recognition is one of the most costly AI problems,\nbecause each language (7,000+) and even different accents require their own\nacoustic models to obtain best recognition performance. Even though they all\nuse the same phoneme symbols, each language and accent imposes its own coloring\nor \"twang\". Many adaptive approaches have been proposed, but they require\nfurther training, additional data and generally are inferior to monolingually\ntrained models. In this paper, we propose a different approach that uses a\nlarge multilingual model that is \\emph{modulated} by the codes generated by an\nancillary network that learns to code useful differences between the \"twangs\"\nor human language.\n  We use Meta-Pi networks to have one network (the language code net) gate the\nactivity of neurons in another (the acoustic model nets). Our results show that\nduring recognition multilingual Meta-Pi networks quickly adapt to the proper\nlanguage coloring without retraining or new data, and perform better than\nmonolingually trained networks. The model was evaluated by training acoustic\nmodeling nets and modulating language code nets jointly and optimize them for\nbest recognition performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:15:34 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["M\u00fcller", "Markus", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1807.01996", "submitter": "Sreekavitha Parupalli", "authors": "Sreekavitha Parupalli and Navjyoti Singh", "title": "A Formal Ontology-Based Classification of Lexemes and its Applications", "comments": "Accepted as Oral Presentation at Second Edition of Widening Natural\n  Language Processing (WiNLP) workshop in 16th Annual Conference of the North\n  American Association for Computational Linguistics, NAACL HLT-2018. arXiv\n  admin note: substantial text overlap with arXiv:1804.02186", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the enrichment of OntoSenseNet - a verb-centric lexical\nresource for Indian Languages. A major contribution of this work is\npreservation of an authentic Telugu dictionary by developing a computational\nversion of the same. It is important because native speakers can better\nannotate the sense-types when both the word and its meaning are in Telugu.\nHence efforts are made to develop the aforementioned Telugu dictionary and\nannotations are done manually. The manually annotated gold standard corpus\nconsists 8483 verbs, 253 adverbs and 1673 adjectives. Annotations are done by\nnative speakers according to defined annotation guidelines. In this paper, we\nprovide an overview of the annotation procedure and present the validation of\nthe developed resource through inter-annotator agreement. Additional words from\nTelugu WordNet are added to our resource and are crowd-sourced for annotation.\nThe statistics are compared with the sense-annotated lexicon, our resource for\nmore insights.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 17:05:09 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Parupalli", "Sreekavitha", ""], ["Singh", "Navjyoti", ""]]}, {"id": "1807.02162", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Ankit Kumar, Asif Ekbal, Sriparna Saha and Pushpak\n  Bhattacharyya", "title": "Feature Assisted bi-directional LSTM Model for Protein-Protein\n  Interaction Identification from Biomedical Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge about protein-protein interactions is essential in understanding\nthe biological processes such as metabolic pathways, DNA replication, and\ntranscription etc. However, a majority of the existing Protein-Protein\nInteraction (PPI) systems are dependent primarily on the scientific literature,\nwhich is yet not accessible as a structured database. Thus, efficient\ninformation extraction systems are required for identifying PPI information\nfrom the large collection of biomedical texts. Most of the existing systems\nmodel the PPI extraction task as a classification problem and are tailored to\nthe handcrafted feature set including domain dependent features. In this paper,\nwe present a novel method based on deep bidirectional long short-term memory\n(B-LSTM) technique that exploits word sequences and dependency path related\ninformation to identify PPI information from text. This model leverages joint\nmodeling of proteins and relations in a single unified framework, which we name\nas Shortest Dependency Path B-LSTM (sdpLSTM) model. We perform experiments on\ntwo popular benchmark PPI datasets, namely AiMed & BioInfer. The evaluation\nshows the F1-score values of 86.45% and 77.35% on AiMed and BioInfer,\nrespectively. Comparisons with the existing systems show that our proposed\napproach attains state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 19:37:29 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yadav", "Shweta", ""], ["Kumar", "Ankit", ""], ["Ekbal", "Asif", ""], ["Saha", "Sriparna", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1807.02200", "submitter": "Sergio Oramas", "authors": "Sergio Oramas, Luis Espinosa-Anke, Francisco G\\'omez, Xavier Serra", "title": "Natural Language Processing for Music Knowledge Discovery", "comments": null, "journal-ref": "Journal of New Music Research (2018)", "doi": "10.1080/09298215.2018.1488878", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, a massive amount of musical knowledge is stored in written form, with\ntestimonies dated as far back as several centuries ago. In this work, we\npresent different Natural Language Processing (NLP) approaches to harness the\npotential of these text collections for automatic music knowledge discovery,\ncovering different phases in a prototypical NLP pipeline, namely corpus\ncompilation, text-mining, information extraction, knowledge graph generation\nand sentiment analysis. Each of these approaches is presented alongside\ndifferent use cases (i.e., flamenco, Renaissance and popular music) where large\ncollections of documents are processed, and conclusions stemming from\ndata-driven analyses are presented and discussed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 00:07:27 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Oramas", "Sergio", ""], ["Espinosa-Anke", "Luis", ""], ["G\u00f3mez", "Francisco", ""], ["Serra", "Xavier", ""]]}, {"id": "1807.02202", "submitter": "Arun Tejasvi Chaganty", "authors": "Arun Tejasvi Chaganty, Stephen Mussman, Percy Liang", "title": "The price of debiasing automatic metrics in natural language evaluation", "comments": "To appear ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For evaluating generation systems, automatic metrics such as BLEU cost\nnothing to run but have been shown to correlate poorly with human judgment,\nleading to systematic bias against certain model improvements. On the other\nhand, averaging human judgments, the unbiased gold standard, is often too\nexpensive. In this paper, we use control variates to combine automatic metrics\nwith human evaluation to obtain an unbiased estimator with lower cost than\nhuman evaluation alone. In practice, however, we obtain only a 7-13% cost\nreduction on evaluating summarization and open-response question answering\nsystems. We then prove that our estimator is optimal: there is no unbiased\nestimator with lower cost. Our theory further highlights the two fundamental\nbottlenecks---the automatic metric and the prompt shown to human\nevaluators---both of which need to be improved to obtain greater cost savings.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 00:11:27 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Chaganty", "Arun Tejasvi", ""], ["Mussman", "Stephen", ""], ["Liang", "Percy", ""]]}, {"id": "1807.02221", "submitter": "Ganna Pogrebna Dr", "authors": "Marco Del Vecchio, Alexander Kharlamov, Glenn Parry, Ganna Pogrebna", "title": "The Data Science of Hollywood: Using Emotional Arcs of Movies to Drive\n  Business Model Innovation in Entertainment Industries", "comments": null, "journal-ref": "Journal of the Operational Research Society, 2020", "doi": "10.1080/01605682.2019.1705194", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of business literature addresses the issues of consumer-centric design:\nhow can businesses design customized services and products which accurately\nreflect consumer preferences? This paper uses data science natural language\nprocessing methodology to explore whether and to what extent emotions shape\nconsumer preferences for media and entertainment content. Using a unique\nfiltered dataset of 6,174 movie scripts, we generate a mapping of screen\ncontent to capture the emotional trajectory of each motion picture. We then\ncombine the obtained mappings into clusters which represent groupings of\nconsumer emotional journeys. These clusters are used to predict overall success\nparameters of the movies including box office revenues, viewer satisfaction\nlevels (captured by IMDb ratings), awards, as well as the number of viewers'\nand critics' reviews. We find that like books all movie stories are dominated\nby 6 basic shapes. The highest box offices are associated with the Man in a\nHole shape which is characterized by an emotional fall followed by an emotional\nrise. This shape results in financially successful movies irrespective of genre\nand production budget. Yet, Man in a Hole succeeds not because it produces most\n\"liked\" movies but because it generates most \"talked about\" movies.\nInterestingly, a carefully chosen combination of production budget and genre\nmay produce a financially successful movie with any emotional shape.\nImplications of this analysis for generating on-demand content and for driving\nbusiness model innovation in entertainment industries are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 01:59:42 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 22:39:44 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Del Vecchio", "Marco", ""], ["Kharlamov", "Alexander", ""], ["Parry", "Glenn", ""], ["Pogrebna", "Ganna", ""]]}, {"id": "1807.02226", "submitter": "Patrick Connor", "authors": "Patrick Connor", "title": "A Concept Specification and Abstraction-based Semantic Representation:\n  Addressing the Barriers to Rule-based Machine Translation", "comments": "23 pages, 3 figures, 1 table. Not yet submitted to any conference or\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based machine translation is more data efficient than the big data-based\nmachine translation approaches, making it appropriate for languages with low\nbilingual corpus resources -- i.e., minority languages. However, the rule-based\napproach has declined in popularity relative to its big data cousins primarily\nbecause of the extensive training and labour required to define the language\nrules. To address this, we present a semantic representation that 1) treats all\nbits of meaning as individual concepts that 2) modify or further specify one\nanother to build a network that relates entities in space and time. Also, the\nrepresentation can 3) encapsulate propositions and thereby define concepts in\nterms of other concepts, supporting the abstraction of underlying linguistic\nand ontological details. These features afford an exact, yet intuitive semantic\nrepresentation aimed at handling the great variety in language and reducing\nlabour and training time. The proposed natural language generation, parsing,\nand translation strategies are also amenable to probabilistic modeling and thus\nto learning the necessary rules from example data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 02:53:32 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 01:35:35 GMT"}, {"version": "v3", "created": "Fri, 26 Apr 2019 01:02:38 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Connor", "Patrick", ""]]}, {"id": "1807.02291", "submitter": "Zeping Yu", "authors": "Zeping Yu and Gongshen Liu", "title": "Sliced Recurrent Neural Networks", "comments": "12 pages (including references), 2 figures, 3 tables, conference: The\n  27th International Conference on Computational Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent neural networks have achieved great success in many NLP tasks.\nHowever, they have difficulty in parallelization because of the recurrent\nstructure, so it takes much time to train RNNs. In this paper, we introduce\nsliced recurrent neural networks (SRNNs), which could be parallelized by\nslicing the sequences into many subsequences. SRNNs have the ability to obtain\nhigh-level information through multiple layers with few extra parameters. We\nprove that the standard RNN is a special case of the SRNN when we use linear\nactivation functions. Without changing the recurrent units, SRNNs are 136 times\nas fast as standard RNNs and could be even faster when we train longer\nsequences. Experiments on six largescale sentiment analysis datasets show that\nSRNNs achieve better performance than standard RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 07:31:13 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yu", "Zeping", ""], ["Liu", "Gongshen", ""]]}, {"id": "1807.02301", "submitter": "Qingyu Zhou", "authors": "Qingyu Zhou, Nan Yang, Furu Wei, Ming Zhou", "title": "Sequential Copying Networks", "comments": "In AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copying mechanism shows effectiveness in sequence-to-sequence based neural\nnetwork models for text generation tasks, such as abstractive sentence\nsummarization and question generation. However, existing works on modeling\ncopying or pointing mechanism only considers single word copying from the\nsource sentences. In this paper, we propose a novel copying framework, named\nSequential Copying Networks (SeqCopyNet), which not only learns to copy single\nwords, but also copies sequences from the input sentence. It leverages the\npointer networks to explicitly select a sub-span from the source side to target\nside, and integrates this sequential copying mechanism to the generation\nprocess in the encoder-decoder paradigm. Experiments on abstractive sentence\nsummarization and question generation tasks show that the proposed SeqCopyNet\ncan copy meaningful spans and outperforms the baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:09:37 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Zhou", "Qingyu", ""], ["Yang", "Nan", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1807.02305", "submitter": "Qingyu Zhou", "authors": "Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang, Ming Zhou, Tiejun Zhao", "title": "Neural Document Summarization by Jointly Learning to Score and Select\n  Sentences", "comments": "In ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence scoring and sentence selection are two main steps in extractive\ndocument summarization systems. However, previous works treat them as two\nseparated subtasks. In this paper, we present a novel end-to-end neural network\nframework for extractive document summarization by jointly learning to score\nand select sentences. It first reads the document sentences with a hierarchical\nencoder to obtain the representation of sentences. Then it builds the output\nsummary by extracting sentences one by one. Different from previous methods,\nour approach integrates the selection strategy into the scoring model, which\ndirectly predicts the relative importance given previously selected sentences.\nExperiments on the CNN/Daily Mail dataset show that the proposed framework\nsignificantly outperforms the state-of-the-art extractive summarization models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:15:15 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Zhou", "Qingyu", ""], ["Yang", "Nan", ""], ["Wei", "Furu", ""], ["Huang", "Shaohan", ""], ["Zhou", "Ming", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1807.02314", "submitter": "Xianggen Liu", "authors": "Xianggen Liu, Lili Mou, Haotian Cui, Zhengdong Lu, Sen Song", "title": "JUMPER: Learning When to Make Classification Decisions in Reading", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In early years, text classification is typically accomplished by\nfeature-based machine learning models; recently, deep neural networks, as a\npowerful learning machine, make it possible to work with raw input as the text\nstands. However, exiting end-to-end neural networks lack explicit\ninterpretation of the prediction. In this paper, we propose a novel framework,\nJUMPER, inspired by the cognitive process of text reading, that models text\nclassification as a sequential decision process. Basically, JUMPER is a neural\nsystem that scans a piece of text sequentially and makes classification\ndecisions at the time it wishes. Both the classification result and when to\nmake the classification are part of the decision process, which is controlled\nby a policy network and trained with reinforcement learning. Experimental\nresults show that a properly trained JUMPER has the following properties: (1)\nIt can make decisions whenever the evidence is enough, therefore reducing total\ntext reading by 30-40% and often finding the key rationale of prediction. (2)\nIt achieves classification accuracy better than or comparable to\nstate-of-the-art models in several benchmark and industrial datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:49:56 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Liu", "Xianggen", ""], ["Mou", "Lili", ""], ["Cui", "Haotian", ""], ["Lu", "Zhengdong", ""], ["Song", "Sen", ""]]}, {"id": "1807.02322", "submitter": "Chen Liang", "authors": "Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc Le, Ni Lao", "title": "Memory Augmented Policy Optimization for Program Synthesis and Semantic\n  Parsing", "comments": "17 Pages, 4 figures, 7 tables, accepted as a spotlight paper for\n  NeurIPS 2018, camera ready version, fixed a typo in table 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Memory Augmented Policy Optimization (MAPO), a simple and novel\nway to leverage a memory buffer of promising trajectories to reduce the\nvariance of policy gradient estimate. MAPO is applicable to deterministic\nenvironments with discrete actions, such as structured prediction and\ncombinatorial optimization tasks. We express the expected return objective as a\nweighted sum of two terms: an expectation over the high-reward trajectories\ninside the memory buffer, and a separate expectation over trajectories outside\nthe buffer. To make an efficient algorithm of MAPO, we propose: (1) memory\nweight clipping to accelerate and stabilize training; (2) systematic\nexploration to discover high-reward trajectories; (3) distributed sampling from\ninside and outside of the memory buffer to scale up training. MAPO improves the\nsample efficiency and robustness of policy gradient, especially on tasks with\nsparse rewards. We evaluate MAPO on weakly supervised program synthesis from\nnatural language (semantic parsing). On the WikiTableQuestions benchmark, we\nimprove the state-of-the-art by 2.6%, achieving an accuracy of 46.3%. On the\nWikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak\nsupervision, outperforming several strong baselines with full supervision. Our\nsource code is available at\nhttps://github.com/crazydonkey200/neural-symbolic-machines\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 09:15:05 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 00:53:35 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 07:51:12 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 17:58:45 GMT"}, {"version": "v5", "created": "Sun, 13 Jan 2019 02:03:10 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Liang", "Chen", ""], ["Norouzi", "Mohammad", ""], ["Berant", "Jonathan", ""], ["Le", "Quoc", ""], ["Lao", "Ni", ""]]}, {"id": "1807.02340", "submitter": "Wenyu Wang", "authors": "Wujie Zheng, Wenyu Wang, Dian Liu, Changrong Zhang, Qinsong Zeng,\n  Yuetang Deng, Wei Yang, Pinjia He, Tao Xie", "title": "Testing Untestable Neural Machine Translation: An Industrial Case", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has been widely adopted recently due to its\nadvantages compared with the traditional Statistical Machine Translation (SMT).\nHowever, an NMT system still often produces translation failures due to the\ncomplexity of natural language and sophistication in designing neural networks.\nWhile in-house black-box system testing based on reference translations (i.e.,\nexamples of valid translations) has been a common practice for NMT quality\nassurance, an increasingly critical industrial practice, named in-vivo testing,\nexposes unseen types or instances of translation failures when real users are\nusing a deployed industrial NMT system. To fill the gap of lacking test oracle\nfor in-vivo testing of an NMT system, in this paper, we propose a new approach\nfor automatically identifying translation failures, without requiring reference\ntranslations for a translation task; our approach can directly serve as a test\noracle for in-vivo testing. Our approach focuses on properties of natural\nlanguage translation that can be checked systematically and uses information\nfrom both the test inputs (i.e., the texts to be translated) and the test\noutputs (i.e., the translations under inspection) of the NMT system. Our\nevaluation conducted on real-world datasets shows that our approach can\neffectively detect targeted property violations as translation failures. Our\nexperiences on deploying our approach in both production and development\nenvironments of WeChat (a messenger app with over one billion monthly active\nusers) demonstrate high effectiveness of our approach along with high industry\nimpact.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 10:17:44 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:42:51 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Zheng", "Wujie", ""], ["Wang", "Wenyu", ""], ["Liu", "Dian", ""], ["Zhang", "Changrong", ""], ["Zeng", "Qinsong", ""], ["Deng", "Yuetang", ""], ["Yang", "Wei", ""], ["He", "Pinjia", ""], ["Xie", "Tao", ""]]}, {"id": "1807.02383", "submitter": "Sonit Singh", "authors": "Sonit Singh", "title": "Natural Language Processing for Information Extraction", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With rise of digital age, there is an explosion of information in the form of\nnews, articles, social media, and so on. Much of this data lies in unstructured\nform and manually managing and effectively making use of it is tedious, boring\nand labor intensive. This explosion of information and need for more\nsophisticated and efficient information handling tools gives rise to\nInformation Extraction(IE) and Information Retrieval(IR) technology.\nInformation Extraction systems takes natural language text as input and\nproduces structured information specified by certain criteria, that is relevant\nto a particular application. Various sub-tasks of IE such as Named Entity\nRecognition, Coreference Resolution, Named Entity Linking, Relation Extraction,\nKnowledge Base reasoning forms the building blocks of various high end Natural\nLanguage Processing (NLP) tasks such as Machine Translation, Question-Answering\nSystem, Natural Language Understanding, Text Summarization and Digital\nAssistants like Siri, Cortana and Google Now. This paper introduces Information\nExtraction technology, its various sub-tasks, highlights state-of-the-art\nresearch in various IE subtasks, current challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 12:44:31 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Singh", "Sonit", ""]]}, {"id": "1807.02391", "submitter": "Sudha Subramani", "authors": "Sudha Subramani, Manjula O'Connor", "title": "Extracting Actionable Knowledge from Domestic Violence Discourses on\n  Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic Violence (DV) is considered as big social issue and there exists a\nstrong relationship between DV and health impacts of the public. Existing\nresearch studies have focused on social media to track and analyse real world\nevents like emerging trends, natural disasters, user sentiment analysis,\npolitical opinions, and health care. However there is less attention given on\nsocial welfare issues like DV and its impact on public health. Recently, the\nvictims of DV turned to social media platforms to express their feelings in the\nform of posts and seek the social and emotional support, for sympathetic\nencouragement, to show compassion and empathy among public. But, it is\ndifficult to mine the actionable knowledge from large conversational datasets\nfrom social media due to the characteristics of high dimensions, short, noisy,\nhuge volume, high velocity, and so on. Hence, this paper will propose a novel\nframework to model and discover the various themes related to DV from the\npublic domain. The proposed framework would possibly provide unprecedentedly\nvaluable information to the public health researchers, national family health\norganizations, government and public with data enrichment and consolidation to\nimprove the social welfare of the community. Thus provides actionable knowledge\nby monitoring and analysing continuous and rich user generated content.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 03:34:22 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Subramani", "Sudha", ""], ["O'Connor", "Manjula", ""]]}, {"id": "1807.02471", "submitter": "Debadri Dutta", "authors": "Debadri Dutta", "title": "A Review of Different Word Embeddings for Sentiment Classification using\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web is loaded with textual content, and Natural Language Processing is a\nstandout amongst the most vital fields in Machine Learning. But when data is\nhuge simple Machine Learning algorithms are not able to handle it and that is\nwhen Deep Learning comes into play which based on Neural Networks. However\nsince neural networks cannot process raw text, we have to change over them\nthrough some diverse strategies of word embedding. This paper demonstrates\nthose distinctive word embedding strategies implemented on an Amazon Review\nDataset, which has two sentiments to be classified: Happy and Unhappy based on\nnumerous customer reviews. Moreover we demonstrate the distinction in accuracy\nwith a discourse about which word embedding to apply when.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 07:17:21 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Dutta", "Debadri", ""]]}, {"id": "1807.02478", "submitter": "Cunchao Tu", "authors": "Chaojun Xiao and Haoxi Zhong and Zhipeng Guo and Cunchao Tu and\n  Zhiyuan Liu and Maosong Sun and Yansong Feng and Xianpei Han and Zhen Hu and\n  Heng Wang and Jianfeng Xu", "title": "CAIL2018: A Large-Scale Legal Dataset for Judgment Prediction", "comments": "4 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the \\textbf{C}hinese \\textbf{AI} and \\textbf{L}aw\nchallenge dataset (CAIL2018), the first large-scale Chinese legal dataset for\njudgment prediction. \\dataset contains more than $2.6$ million criminal cases\npublished by the Supreme People's Court of China, which are several times\nlarger than other datasets in existing works on judgment prediction. Moreover,\nthe annotations of judgment results are more detailed and rich. It consists of\napplicable law articles, charges, and prison terms, which are expected to be\ninferred according to the fact descriptions of cases. For comparison, we\nimplement several conventional text classification baselines for judgment\nprediction and experimental results show that it is still a challenge for\ncurrent models to predict the judgment results of legal cases, especially on\nprison terms. To help the researchers make improvements on legal judgment\nprediction, both \\dataset and baselines will be released after the CAIL\ncompetition\\footnote{http://cail.cipsc.org.cn/}.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 02:09:06 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Xiao", "Chaojun", ""], ["Zhong", "Haoxi", ""], ["Guo", "Zhipeng", ""], ["Tu", "Cunchao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""], ["Feng", "Yansong", ""], ["Han", "Xianpei", ""], ["Hu", "Zhen", ""], ["Wang", "Heng", ""], ["Xu", "Jianfeng", ""]]}, {"id": "1807.02599", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Erik Mayer, Sophia N. Yaliraki, Mauricio Barahona", "title": "From Text to Topics in Healthcare Records: An Unsupervised Graph\n  Partitioning Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Healthcare Records contain large volumes of unstructured data,\nincluding extensive free text. Yet this source of detailed information often\nremains under-used because of a lack of methodologies to extract interpretable\ncontent in a timely manner. Here we apply network-theoretical tools to analyse\nfree text in Hospital Patient Incident reports from the National Health\nService, to find clusters of documents with similar content in an unsupervised\nmanner at different levels of resolution. We combine deep neural network\nparagraph vector text-embedding with multiscale Markov Stability community\ndetection applied to a sparsified similarity graph of document vectors, and\nshowcase the approach on incident reports from Imperial College Healthcare NHS\nTrust, London. The multiscale community structure reveals different levels of\nmeaning in the topics of the dataset, as shown by descriptive terms extracted\nfrom the clusters of records. We also compare a posteriori against hand-coded\ncategories assigned by healthcare personnel, and show that our approach\noutperforms LDA-based models. Our content clusters exhibit good correspondence\nwith two levels of hand-coded categories, yet they also provide further medical\ndetail in certain areas and reveal complementary descriptors of incidents\nbeyond the external classification taxonomy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 01:14:10 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1807.02658", "submitter": "J\\\"org Franke", "authors": "J\\\"org Franke, Jan Niehues, Alex Waibel", "title": "Robust and Scalable Differentiable Neural Computer for Question\n  Answering", "comments": "Accepted at Workshop on Machine Reading for Question Answering\n  (MRQA), ACL 2018. 14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are often not easily adaptable to new tasks and require\ntask-specific adjustments. The differentiable neural computer (DNC), a\nmemory-augmented neural network, is designed as a general problem solver which\ncan be used in a wide range of tasks. But in reality, it is hard to apply this\nmodel to new tasks. We analyze the DNC and identify possible improvements\nwithin the application of question answering. This motivates a more robust and\nscalable DNC (rsDNC). The objective precondition is to keep the general\ncharacter of this model intact while making its application more reliable and\nspeeding up its required training time. The rsDNC is distinguished by a more\nrobust training, a slim memory unit and a bidirectional architecture. We not\nonly achieve new state-of-the-art performance on the bAbI task, but also\nminimize the performance variance between different initializations.\nFurthermore, we demonstrate the simplified applicability of the rsDNC to new\ntasks with passable results on the CNN RC task without adaptions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 12:44:32 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Franke", "J\u00f6rg", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1807.02745", "submitter": "Ryan Cotterell Ryan D Cotterell", "authors": "Ryan Cotterell and Jason Eisner", "title": "A Deep Generative Model of Vowel Formant Typology", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes some types of languages more probable than others? For instance,\nwe know that almost all spoken languages contain the vowel phoneme /i/; why\nshould that be? The field of linguistic typology seeks to answer these\nquestions and, thereby, divine the mechanisms that underlie human language. In\nour work, we tackle the problem of vowel system typology, i.e., we propose a\ngenerative probability model of which vowels a language contains. In contrast\nto previous work, we work directly with the acoustic information -- the first\ntwo formant values -- rather than modeling discrete sets of phonemic symbols\n(IPA). We develop a novel generative probability model and report results based\non a corpus of 233 languages.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 03:26:01 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Cotterell", "Ryan", ""], ["Eisner", "Jason", ""]]}, {"id": "1807.02747", "submitter": "Ryan Cotterell Ryan D Cotterell", "authors": "Ryan Cotterell and Christo Kirov and Mans Hulden and Jason Eisner", "title": "On the Complexity and Typology of Inflectional Morphological Systems", "comments": "TACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We quantify the linguistic complexity of different languages' morphological\nsystems. We verify that there is an empirical trade-off between paradigm size\nand irregularity: a language's inflectional paradigms may be either large in\nsize or highly irregular, but never both. Our methodology measures paradigm\nirregularity as the entropy of the surface realization of a paradigm -- how\nhard it is to jointly predict all the surface forms of a paradigm. We estimate\nthis by a variational approximation. Our measurements are taken on large\nmorphological paradigms from 31 typologically diverse languages.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 03:32:45 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kirov", "Christo", ""], ["Hulden", "Mans", ""], ["Eisner", "Jason", ""]]}, {"id": "1807.02748", "submitter": "Kamal Al-Sabahi Ph.D.", "authors": "Kamal Al-Sabahi, Zhang Zuping, Yang Kang", "title": "Latent Semantic Analysis Approach for Document Summarization Based on\n  Word Embeddings", "comments": "20 pages, One-column, 4 figures", "journal-ref": "KSII Transactions on Internet and Information Systems, 2019, Vol.\n  13, No.1", "doi": "10.3837/tiis.2019.01.015", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the amount of information on the internet is growing rapidly, it is not\neasy for a user to find relevant information for his/her query. To tackle this\nissue, much attention has been paid to Automatic Document Summarization. The\nkey point in any successful document summarizer is a good document\nrepresentation. The traditional approaches based on word overlapping mostly\nfail to produce that kind of representation. Word embedding, distributed\nrepresentation of words, has shown an excellent performance that allows words\nto match on semantic level. Naively concatenating word embeddings makes the\ncommon word dominant which in turn diminish the representation quality. In this\npaper, we employ word embeddings to improve the weighting schemes for\ncalculating the input matrix of Latent Semantic Analysis method. Two\nembedding-based weighting schemes are proposed and then combined to calculate\nthe values of this matrix. The new weighting schemes are modified versions of\nthe augment weight and the entropy frequency. The new schemes combine the\nstrength of the traditional weighting schemes and word embedding. The proposed\napproach is experimentally evaluated on three well-known English datasets, DUC\n2002, DUC 2004 and Multilingual 2015 Single-document Summarization for English.\nThe proposed model performs comprehensively better compared to the\nstate-of-the-art methods, by at least 1% ROUGE points, leading to a conclusion\nthat it provides a better document representation and a better document summary\nas a result.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 03:39:37 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 02:11:53 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Al-Sabahi", "Kamal", ""], ["Zuping", "Zhang", ""], ["Kang", "Yang", ""]]}, {"id": "1807.02854", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Bernt Andrassy and Hinrich Sch\\\"utze", "title": "Replicated Siamese LSTM in Ticketing System for Similarity Learning and\n  Retrieval in Asymmetric Texts", "comments": "In the 27th International Conference on Computational Linguistics\n  (COLING 2018) workshop on Semantic Deep Learning (SemDeep-3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of our industrial ticketing system is to retrieve a relevant\nsolution for an input query, by matching with historical tickets stored in\nknowledge base. A query is comprised of subject and description, while a\nhistorical ticket consists of subject, description and solution. To retrieve a\nrelevant solution, we use textual similarity paradigm to learn similarity in\nthe query and historical tickets. The task is challenging due to significant\nterm mismatch in the query and ticket pairs of asymmetric lengths, where\nsubject is a short text but description and solution are multi-sentence texts.\nWe present a novel Replicated Siamese LSTM model to learn similarity in\nasymmetric text pairs, that gives 22% and 7% gain (Accuracy@10) for retrieval\ntask, respectively over unsupervised and supervised baselines. We also show\nthat the topic and distributed semantic features for short and long texts\nimproved both similarity learning and retrieval.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 17:33:43 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Andrassy", "Bernt", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1807.02903", "submitter": "Nikola Ljube\\v{s}i\\'c", "authors": "Nikola Ljube\\v{s}i\\'c, Darja Fi\\v{s}er, Anita Peti-Stanti\\'c", "title": "Predicting Concreteness and Imageability of Words Within and Across\n  Languages via Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of concreteness and imageability, traditionally important in\npsycholinguistics, are gaining significance in semantic-oriented natural\nlanguage processing tasks. In this paper we investigate the predictability of\nthese two concepts via supervised learning, using word embeddings as\nexplanatory variables. We perform predictions both within and across languages\nby exploiting collections of cross-lingual embeddings aligned to a single\nvector space. We show that the notions of concreteness and imageability are\nhighly predictable both within and across languages, with a moderate loss of up\nto 20% in correlation when predicting across languages. We further show that\nthe cross-lingual transfer via word embeddings is more efficient than the\nsimple transfer via bilingual dictionaries.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 00:44:47 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Ljube\u0161i\u0107", "Nikola", ""], ["Fi\u0161er", "Darja", ""], ["Peti-Stanti\u0107", "Anita", ""]]}, {"id": "1807.02911", "submitter": "Abdulaziz Alayba", "authors": "Abdulaziz M. Alayba, Vasile Palade, Matthew England, and Rahat Iqbal", "title": "A Combined CNN and LSTM Model for Arabic Sentiment Analysis", "comments": "Authors accepted version of submission for CD-MAKE 2018", "journal-ref": "Proc. International Cross-Domain Conference for Machine Learning\n  and Knowledge Extraction. CD-MAKE 2018. Lecture Notes in Computer Science,\n  vol 11015, pp. 179-191. Springer, Cham", "doi": "10.1007/978-3-319-99740-7_12", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown good data modelling capabilities when dealing\nwith challenging and large datasets from a wide range of application areas.\nConvolutional Neural Networks (CNNs) offer advantages in selecting good\nfeatures and Long Short-Term Memory (LSTM) networks have proven good abilities\nof learning sequential data. Both approaches have been reported to provide\nimproved results in areas such image processing, voice recognition, language\ntranslation and other Natural Language Processing (NLP) tasks. Sentiment\nclassification for short text messages from Twitter is a challenging task, and\nthe complexity increases for Arabic language sentiment classification tasks\nbecause Arabic is a rich language in morphology. In addition, the availability\nof accurate pre-processing tools for Arabic is another current limitation,\nalong with limited research available in this area. In this paper, we\ninvestigate the benefits of integrating CNNs and LSTMs and report obtained\nimproved accuracy for Arabic sentiment analysis on different datasets.\nAdditionally, we seek to consider the morphological diversity of particular\nArabic words by using different sentiment classification levels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 01:41:20 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 22:08:59 GMT"}, {"version": "v3", "created": "Sun, 22 Jul 2018 02:02:30 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Alayba", "Abdulaziz M.", ""], ["Palade", "Vasile", ""], ["England", "Matthew", ""], ["Iqbal", "Rahat", ""]]}, {"id": "1807.02974", "submitter": "Yan Shao", "authors": "Yan Shao, Christian Hardmeier, Joakim Nivre", "title": "Universal Word Segmentation: Implementation and Interpretation", "comments": null, "journal-ref": "Transactions of the Association for Computational Linguistics,\n  vol. 6, pp. 421--435, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word segmentation is a low-level NLP task that is non-trivial for a\nconsiderable number of languages. In this paper, we present a sequence tagging\nframework and apply it to word segmentation for a wide range of languages with\ndifferent writing systems and typological characteristics. Additionally, we\ninvestigate the correlations between various typological factors and word\nsegmentation accuracy. The experimental results indicate that segmentation\naccuracy is positively related to word boundary markers and negatively to the\nnumber of unique non-segmental terms. Based on the analysis, we design a small\nset of language-specific settings and extensively evaluate the segmentation\nsystem on the Universal Dependencies datasets. Our model obtains\nstate-of-the-art accuracies on all the UD languages. It performs substantially\nbetter on languages that are non-trivial to segment, such as Chinese, Japanese,\nArabic and Hebrew, when compared to previous work.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 07:51:51 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Shao", "Yan", ""], ["Hardmeier", "Christian", ""], ["Nivre", "Joakim", ""]]}, {"id": "1807.03004", "submitter": "Sreekavitha Parupalli", "authors": "Sreekavitha Parupalli, Vijjini Anvesh Rao and Radhika Mamidi", "title": "Towards Enhancing Lexical Resource and Using Sense-annotations of\n  OntoSenseNet for Sentiment Analysis", "comments": "Accepted at 3rd Workshop on Semantic Deep Learning (SemDeep-3) at The\n  27th International Conference on Computational Linguistics, COLING (August\n  2018) in Santa Fe, New Mexico, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper illustrates the interface of the tool we developed for crowd\nsourcing and we explain the annotation procedure in detail. Our tool is named\nas 'Parupalli Padajaalam' which means web of words by Parupalli. The aim of\nthis tool is to populate the OntoSenseNet, sentiment polarity annotated Telugu\nresource. Recent works have shown the importance of word-level annotations on\nsentiment analysis. With this as basis, we aim to analyze the importance of\nsense-annotations obtained from OntoSenseNet in performing the task of\nsentiment analysis. We explain the fea- tures extracted from OntoSenseNet\n(Telugu). Furthermore we compute and explain the adverbial class distribution\nof verbs in OntoSenseNet. This task is known to aid in disambiguating\nword-senses which helps in enhancing the performance of word-sense\ndisambiguation (WSD) task(s).\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:27:25 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 19:30:43 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Parupalli", "Sreekavitha", ""], ["Rao", "Vijjini Anvesh", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1807.03006", "submitter": "Angel Daza", "authors": "Angel Daza and Anette Frank", "title": "A Sequence-to-Sequence Model for Semantic Role Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore a novel approach for Semantic Role Labeling (SRL) by casting it as\na sequence-to-sequence process. We employ an attention-based model enriched\nwith a copying mechanism to ensure faithful regeneration of the input sequence,\nwhile enabling interleaved generation of argument role labels. Here, we apply\nthis model in a monolingual setting, performing PropBank SRL on English\nlanguage data. The constrained sequence generation set-up enforced with the\ncopying mechanism allows us to analyze the performance and special properties\nof the model on manually labeled data and benchmarking against state-of-the-art\nsequence labeling models. We show that our model is able to solve the SRL\nargument labeling task on English data, yet further structural decoding\nconstraints will need to be added to make the model truly competitive. Our work\nrepresents a first step towards more advanced, generative SRL labeling setups.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:37:43 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Daza", "Angel", ""], ["Frank", "Anette", ""]]}, {"id": "1807.03012", "submitter": "Miguel Feria", "authors": "Miguel Feria, Juan Paolo Balbin, Francis Michael Bautista", "title": "Constructing a Word Similarity Graph from Vector based Word\n  Representation for Named Entity Recognition", "comments": "Preprint for 14th International Conference On Web Information Systems\n  and Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss a method for identifying a seed word that would\nbest represent a class of named entities in a graphical representation of words\nand their similarities. Word networks, or word graphs, are representations of\nvectorized text where nodes are the words encountered in a corpus, and the\nweighted edges incident on the nodes represent how similar the words are to\neach other. We intend to build a bilingual word graph and identify seed words\nthrough community analysis that would be best used to segment a graph according\nto its named entities, therefore providing an unsupervised way of tagging named\nentities for a bilingual language base.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:43:23 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Feria", "Miguel", ""], ["Balbin", "Juan Paolo", ""], ["Bautista", "Francis Michael", ""]]}, {"id": "1807.03052", "submitter": "Benjamin Roth", "authors": "Ivan Bilan and Benjamin Roth", "title": "Position-aware Self-attention with Relative Positional Encodings for\n  Slot Filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how to apply self-attention with relative positional\nencodings to the task of relation extraction. We propose to use the\nself-attention encoder layer together with an additional position-aware\nattention layer that takes into account positions of the query and the object\nin the sentence. The self-attention encoder also uses a custom implementation\nof relative positional encodings which allow each word in the sentence to take\ninto account its left and right context. The evaluation of the model is done on\nthe TACRED dataset. The proposed model relies only on attention (no recurrent\nor convolutional layers are used), while improving performance w.r.t. the\nprevious state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 11:34:13 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Bilan", "Ivan", ""], ["Roth", "Benjamin", ""]]}, {"id": "1807.03053", "submitter": "Pedro Henrique Alves Martins", "authors": "Pedro Henrique Martins and Lu\\'is Cust\\'odio and Rodrigo Ventura", "title": "A deep learning approach for understanding natural language commands for\n  mobile service robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using natural language to give instructions to robots is challenging, since\nnatural language understanding is still largely an open problem. In this paper\nwe address this problem by restricting our attention to commands modeled as one\naction, plus arguments (also known as slots). For action detection (also called\nintent detection) and slot filling various architectures of Recurrent Neural\nNetworks and Long Short Term Memory (LSTM) networks were evaluated, having\nLSTMs achieved a superior accuracy. As the action requested may not fall within\nthe robots capabilities, a Support Vector Machine(SVM) is used to determine\nwhether it is or not. For the input of the neural networks, several word\nembedding algorithms were compared. Finally, to implement the system in a\nrobot, a ROS package is created using a SMACH state machine. The proposed\nsystem is then evaluated both using well-known datasets and benchmarks in the\ncontext of domestic service robots.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 11:34:21 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Martins", "Pedro Henrique", ""], ["Cust\u00f3dio", "Lu\u00eds", ""], ["Ventura", "Rodrigo", ""]]}, {"id": "1807.03096", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris and Francisco Casacuberta", "title": "NMT-Keras: a Very Flexible Toolkit with a Focus on Interactive NMT and\n  Online Learning", "comments": "To appear at The Prague Bulletin of Mathematical Linguistics 111", "journal-ref": null, "doi": "10.2478/pralin-2018-0010", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present NMT-Keras, a flexible toolkit for training deep learning models,\nwhich puts a particular emphasis on the development of advanced applications of\nneural machine translation systems, such as interactive-predictive translation\nprotocols and long-term adaptation of the translation system via continuous\nlearning. NMT-Keras is based on an extended version of the popular Keras\nlibrary, and it runs on Theano and Tensorflow. State-of-the-art neural machine\ntranslation models are deployed and used following the high-level framework\nprovided by Keras. Given its high modularity and flexibility, it also has been\nextended to tackle different problems, such as image and video captioning,\nsentence classification and visual question answering.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:14:00 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 10:32:01 GMT"}, {"version": "v3", "created": "Thu, 16 Aug 2018 07:57:45 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1807.03100", "submitter": "Oleksandr Polozov", "authors": "Chenglong Wang, Kedar Tatwawadi, Marc Brockschmidt, Po-Sen Huang, Yi\n  Mao, Oleksandr Polozov, Rishabh Singh", "title": "Robust Text-to-SQL Generation with Execution-Guided Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of neural semantic parsing, which translates natural\nlanguage questions into executable SQL queries. We introduce a new mechanism,\nexecution guidance, to leverage the semantics of SQL. It detects and excludes\nfaulty programs during the decoding procedure by conditioning on the execution\nof partially generated program. The mechanism can be used with any\nautoregressive generative model, which we demonstrate on four state-of-the-art\nrecurrent or template-based semantic parsing models. We demonstrate that\nexecution guidance universally improves model performance on various\ntext-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS,\nand GeoQuery. As a result, we achieve new state-of-the-art execution accuracy\nof 83.8% on WikiSQL.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:20:28 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 21:55:52 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 00:29:17 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Wang", "Chenglong", ""], ["Tatwawadi", "Kedar", ""], ["Brockschmidt", "Marc", ""], ["Huang", "Po-Sen", ""], ["Mao", "Yi", ""], ["Polozov", "Oleksandr", ""], ["Singh", "Rishabh", ""]]}, {"id": "1807.03108", "submitter": "Marcos Zampieri", "authors": "Alina Maria Ciobanu, Marcos Zampieri, Shervin Malmasi, Santanu Pal,\n  Liviu P. Dinu", "title": "Discriminating between Indo-Aryan Languages Using SVM Ensembles", "comments": "Proceedings of the Fifth Workshop on NLP for Similar Languages,\n  Varieties and Dialects", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a system based on SVM ensembles trained on\ncharacters and words to discriminate between five similar languages of the\nIndo-Aryan family: Hindi, Braj Bhasha, Awadhi, Bhojpuri, and Magahi. We\ninvestigate the performance of individual features and combine the output of\nsingle classifiers to maximize performance. The system competed in the\nIndo-Aryan Language Identification (ILI) shared task organized within the\nVarDial Evaluation Campaign 2018. Our best entry in the competition, named\nILIdentification, scored 88:95% F1 score and it was ranked 3rd out of 8 teams.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:26:44 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Ciobanu", "Alina Maria", ""], ["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""], ["Pal", "Santanu", ""], ["Dinu", "Liviu P.", ""]]}, {"id": "1807.03121", "submitter": "Yijia Liu", "authors": "Wanxiang Che, Yijia Liu, Yuxuan Wang, Bo Zheng, Ting Liu", "title": "Towards Better UD Parsing: Deep Contextualized Word Embeddings,\n  Ensemble, and Treebank Concatenation", "comments": "System description paper of our system (HIT-SCIR) for the CoNLL 2018\n  shared task on Universal Dependency parsing, which was ranked first in the\n  LAS evaluation. Fix typos and grammar errors. Add the results of parser\n  without ensemble", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared\ntask on Multilingual Parsing from Raw Text to Universal Dependencies. We base\nour submission on Stanford's winning system for the CoNLL 2017 shared task and\nmake two effective extensions: 1) incorporating deep contextualized word\nembeddings into both the part of speech tagger and parser; 2) ensembling\nparsers trained with different initialization. We also explore different ways\nof concatenating treebanks for further improvements. Experimental results on\nthe development data show the effectiveness of our methods. In the final\nevaluation, our system was ranked first according to LAS (75.84%) and\noutperformed the other systems by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:34:16 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 16:37:22 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 06:44:34 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Che", "Wanxiang", ""], ["Liu", "Yijia", ""], ["Wang", "Yuxuan", ""], ["Zheng", "Bo", ""], ["Liu", "Ting", ""]]}, {"id": "1807.03367", "submitter": "Harm de Vries", "authors": "Harm de Vries, Kurt Shuster, Dhruv Batra, Devi Parikh, Jason Weston,\n  Douwe Kiela", "title": "Talk the Walk: Navigating New York City through Grounded Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"Talk The Walk\", the first large-scale dialogue dataset grounded\nin action and perception. The task involves two agents (a \"guide\" and a\n\"tourist\") that communicate via natural language in order to achieve a common\ngoal: having the tourist navigate to a given target location. The task and\ndataset, which are described in detail, are challenging and their full solution\nis an open problem that we pose to the community. We (i) focus on the task of\ntourist localization and develop the novel Masked Attention for Spatial\nConvolutions (MASC) mechanism that allows for grounding tourist utterances into\nthe guide's map, (ii) show it yields significant improvements for both emergent\nand natural language communication, and (iii) using this method, we establish\nnon-trivial baselines on the full task.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:05:24 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 16:07:08 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 22:42:59 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["de Vries", "Harm", ""], ["Shuster", "Kurt", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""]]}, {"id": "1807.03396", "submitter": "Hao Tang", "authors": "Hao Tang and James Glass", "title": "On Training Recurrent Networks with Truncated Backpropagation Through\n  Time in Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have been the dominant models for many speech and\nlanguage processing tasks. However, we understand little about the behavior and\nthe class of functions recurrent networks can realize. Moreover, the heuristics\nused during training complicate the analyses. In this paper, we study recurrent\nnetworks' ability to learn long-term dependency in the context of speech\nrecognition. We consider two decoding approaches, online and batch decoding,\nand show the classes of functions to which the decoding approaches correspond.\nWe then draw a connection between batch decoding and a popular training\napproach for recurrent networks, truncated backpropagation through time.\nChanging the decoding approach restricts the amount of past history recurrent\nnetworks can use for prediction, allowing us to analyze their ability to\nremember. Empirically, we utilize long-term dependency in subphonetic states,\nphonemes, and words, and show how the design decisions, such as the decoding\napproach, lookahead, context frames, and consecutive prediction, characterize\nthe behavior of recurrent networks. Finally, we draw a connection between\nMarkov processes and vanishing gradients. These results have implications for\nstudying the long-term dependency in speech data and how these properties are\nlearned by recurrent networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:31:49 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 15:41:08 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 17:17:30 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1807.03397", "submitter": "Ashwath Kumar Channabasaya Salimath", "authors": "Ashwath Kumar Salimath, Robin K Thomas, Sethuram Ramalinga Reddy,\n  Yuhao Qiao", "title": "Detecting Levels of Depression in Text Based on Metrics", "comments": "7 pages, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is one of the most common and a major concern for society. Proper\nmonitoring using devices that can aid in its detection could be helpful to\nprevent it all together. The Distress Analysis Interview Corpus (DAIC) is used\nto build a metric-based depression detection. We have designed a metric to\ndescribe the level of depression using negative sentences and classify the\nparticipant accordingly. The score generated from the algorithm is then\nlevelled up to denote the intensity of depression. The results show that\nmeasuring depression is very complex to using text alone as other factors are\nnot taken into consideration. Further, In the paper, the limitations of\nmeasuring depression using text are described, and future suggestions are made.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:32:47 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Salimath", "Ashwath Kumar", ""], ["Thomas", "Robin K", ""], ["Reddy", "Sethuram Ramalinga", ""], ["Qiao", "Yuhao", ""]]}, {"id": "1807.03399", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Albert M. Lai, Eric Fosler-Lussier", "title": "Jointly Embedding Entities and Text with Distant Supervision", "comments": "12 pages; Accepted to 3rd Workshop on Representation Learning for NLP\n  (Repl4NLP 2018). Code at https://github.com/OSU-slatelab/JET", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for knowledge base entities and concepts is becoming\nincreasingly important for NLP applications. However, recent entity embedding\nmethods have relied on structured resources that are expensive to create for\nnew domains and corpora. We present a distantly-supervised method for jointly\nlearning embeddings of entities and text from an unnanotated corpus, using only\na list of mappings between entities and surface forms. We learn embeddings from\nopen-domain and biomedical corpora, and compare against prior methods that rely\non human-annotated text or large knowledge graph structure. Our embeddings\ncapture entity similarity and relatedness better than prior work, both in\nexisting biomedical datasets and a new Wikipedia-based dataset that we release\nto the community. Results on analogy completion and entity sense disambiguation\nindicate that entities and words capture complementary information that can be\neffectively combined for downstream use.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:40:53 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Lai", "Albert M.", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1807.03409", "submitter": "Minh Nguyen", "authors": "Minh Nguyen and Thien Huu Nguyen", "title": "Who is Killed by Police: Introducing Supervised Attention for\n  Hierarchical LSTMs", "comments": "11 pages (including references), 3 figures, 2 tables, conference: The\n  27th International Conference on Computational Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding names of people killed by police has become increasingly important as\npolice shootings get more and more public attention (police killing detection).\nUnfortunately, there has been not much work in the literature addressing this\nproblem. The early work in this field \\cite{keith2017identifying} proposed a\ndistant supervision framework based on Expectation Maximization (EM) to deal\nwith the multiple appearances of the names in documents. However, such EM-based\nframework cannot take full advantages of deep learning models, necessitating\nthe use of hand-designed features to improve the detection performance. In this\nwork, we present a novel deep learning method to solve the problem of police\nkilling recognition. The proposed method relies on hierarchical LSTMs to model\nthe multiple sentences that contain the person names of interests, and\nintroduce supervised attention mechanisms based on semantical word lists and\ndependency trees to upweight the important contextual words. Our experiments\ndemonstrate the benefits of the proposed model and yield the state-of-the-art\nperformance for police killing detection.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 22:28:09 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Nguyen", "Minh", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1807.03491", "submitter": "Jey Han Lau", "authors": "Jey Han Lau and Trevor Cohn and Timothy Baldwin and Julian Brooke and\n  Adam Hammond", "title": "Deep-speare: A Joint Neural Model of Poetic Language, Meter and Rhyme", "comments": "11 pages; ACL2018", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a joint architecture that captures language, rhyme\nand meter for sonnet modelling. We assess the quality of generated poems using\ncrowd and expert judgements. The stress and rhyme models perform very well, as\ngenerated poems are largely indistinguishable from human-written poems. Expert\nevaluation, however, reveals that a vanilla language model captures meter\nimplicitly, and that machine-generated poems still underperform in terms of\nreadability and emotion. Our research shows the importance expert evaluation\nfor poetry generation, and that future research should look beyond rhyme/meter\nand focus on poetic language.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:26:24 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Lau", "Jey Han", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""], ["Brooke", "Julian", ""], ["Hammond", "Adam", ""]]}, {"id": "1807.03583", "submitter": "Andr\\'as Dob\\'o", "authors": "Andr\\'as Dob\\'o", "title": "Multi-D Kneser-Ney Smoothing Preserving the Original Marginal\n  Distributions", "comments": null, "journal-ref": "Research in Computing Science, 147 (6), 11-25", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothing is an essential tool in many NLP tasks, therefore numerous\ntechniques have been developed for this purpose in the past. One of the most\nwidely used smoothing methods are the Kneser-Ney smoothing (KNS) and its\nvariants, including the Modified Kneser-Ney smoothing (MKNS), which are widely\nconsidered to be among the best smoothing methods available. Although when\ncreating the original KNS the intention of the authors was to develop such a\nsmoothing method that preserves the marginal distributions of the original\nmodel, this property was not maintained when developing the MKNS.\n  In this article I would like to overcome this and propose such a refined\nversion of the MKNS that preserves these marginal distributions while keeping\nthe advantages of both previous versions. Beside its advantageous properties,\nthis novel smoothing method is shown to achieve about the same results as the\nMKNS in a standard language modelling task.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 12:04:54 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Dob\u00f3", "Andr\u00e1s", ""]]}, {"id": "1807.03586", "submitter": "Yifan Gao", "authors": "Yifan Gao, Lidong Bing, Wang Chen, Michael R. Lyu, Irwin King", "title": "Difficulty Controllable Generation of Reading Comprehension Questions", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the difficulty levels of questions in reading comprehension\ndatasets such as SQuAD, and propose a new question generation setting, named\nDifficulty-controllable Question Generation (DQG). Taking as input a sentence\nin the reading comprehension paragraph and some of its text fragments (i.e.,\nanswers) that we want to ask questions about, a DQG method needs to generate\nquestions each of which has a given text fragment as its answer, and meanwhile\nthe generation is under the control of specified difficulty labels---the output\nquestions should satisfy the specified difficulty as much as possible. To solve\nthis task, we propose an end-to-end framework to generate questions of\ndesignated difficulty levels by exploring a few important intuitions. For\nevaluation, we prepared the first dataset of reading comprehension questions\nwith difficulty labels. The results show that the question generated by our\nframework not only have better quality under the metrics like BLEU, but also\ncomply with the specified difficulty labels.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 12:10:16 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 12:06:29 GMT"}, {"version": "v3", "created": "Sat, 8 Sep 2018 07:01:52 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2019 06:34:25 GMT"}, {"version": "v5", "created": "Thu, 30 May 2019 09:41:11 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gao", "Yifan", ""], ["Bing", "Lidong", ""], ["Chen", "Wang", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1807.03591", "submitter": "Christoph Dalitz", "authors": "Christoph Dalitz, Jens Wilberg, Katrin E. Bednarek", "title": "Paired Comparison Sentiment Scores", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": "Technical Report No. 2017-03, Hochschule Niederrhein, Fachbereich\n  Elektrotechnik & Informatik (2017)", "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The method of paired comparisons is an established method in psychology. In\nthis article, it is applied to obtain continuous sentiment scores for words\nfrom comparisons made by test persons. We created an initial lexicon with\n$n=199$ German words from a two-fold all-pair comparison experiment with ten\ndifferent test persons. From the probabilistic models taken into account, the\nlogistic model showed the best agreement with the results of the comparison\nexperiment. The initial lexicon can then be used in different ways. One is to\ncreate special purpose sentiment lexica through the addition of arbitrary words\nthat are compared with some of the initial words by test persons. A\ncross-validation experiment suggests that only about 18 two-fold comparisons\nare necessary to estimate the score of a new, yet unknown word, provided these\nwords are selected by a modification of a method by Silverstein & Farrell.\nAnother application of the initial lexicon is the evaluation of automatically\ncreated corpus-based lexica. By such an evaluation, we compared the\ncorpus-based lexica SentiWS, SenticNet, and SentiWordNet, of which SenticNet 4\nperformed best. This technical report is a corrected and extended version of a\npresentation made at the ICDM Sentire workshop in 2016.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 12:25:59 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Dalitz", "Christoph", ""], ["Wilberg", "Jens", ""], ["Bednarek", "Katrin E.", ""]]}, {"id": "1807.03595", "submitter": "\\'Akos K\\'ad\\'ar", "authors": "\\'Akos K\\'ad\\'ar, Marc-Alexandre C\\^ot\\'e, Grzegorz Chrupa{\\l}a, Afra\n  Alishahi", "title": "Revisiting the Hierarchical Multiscale LSTM", "comments": "To appear in COLING 2018 (reproduction track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hierarchical Multiscale LSTM (Chung et al., 2016a) is a state-of-the-art\nlanguage model that learns interpretable structure from character-level input.\nSuch models can provide fertile ground for (cognitive) computational\nlinguistics studies. However, the high complexity of the architecture, training\nprocedure and implementations might hinder its applicability. We provide a\ndetailed reproduction and ablation study of the architecture, shedding light on\nsome of the potential caveats of re-purposing complex deep-learning\narchitectures. We further show that simplifying certain aspects of the\narchitecture can in fact improve its performance. We also investigate the\nlinguistic units (segments) learned by various levels of the model, and argue\nthat their quality does not correlate with the overall performance of the model\non language modeling.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 12:46:30 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["K\u00e1d\u00e1r", "\u00c1kos", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Chrupa\u0142a", "Grzegorz", ""], ["Alishahi", "Afra", ""]]}, {"id": "1807.03654", "submitter": "Anna Feldman", "authors": "Kei Yin Ng, Anna Feldman, Jing Peng, Chris Leberknight", "title": "Linguistic Characteristics of Censorable Language on SinaWeibo", "comments": null, "journal-ref": "1st Workshop on NLP for Internet Freedom (NLP4IF-2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates censorship from a linguistic perspective. We collect\na corpus of censored and uncensored posts on a number of topics, build a\nclassifier that predicts censorship decisions independent of discussion topics.\nOur investigation reveals that the strongest linguistic indicator of censored\ncontent of our corpus is its readability.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:02:35 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Ng", "Kei Yin", ""], ["Feldman", "Anna", ""], ["Peng", "Jing", ""], ["Leberknight", "Chris", ""]]}, {"id": "1807.03656", "submitter": "Paramita Mirza", "authors": "Paramita Mirza and Simon Razniewski and Fariz Darari and Gerhard\n  Weikum", "title": "Enriching Knowledge Bases with Counting Quantifiers", "comments": "16 pages, The 17th International Semantic Web Conference (ISWC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction traditionally focuses on extracting relations between\nidentifiable entities, such as <Monterey, locatedIn, California>. Yet, texts\noften also contain Counting information, stating that a subject is in a\nspecific relation with a number of objects, without mentioning the objects\nthemselves, for example, \"California is divided into 58 counties\". Such\ncounting quantifiers can help in a variety of tasks such as query answering or\nknowledge base curation, but are neglected by prior work. This paper develops\nthe first full-fledged system for extracting counting information from text,\ncalled CINEX. We employ distant supervision using fact counts from a knowledge\nbase as training seeds, and develop novel techniques for dealing with several\nchallenges: (i) non-maximal training seeds due to the incompleteness of\nknowledge bases, (ii) sparse and skewed observations in text sources, and (iii)\nhigh diversity of linguistic patterns. Experiments with five human-evaluated\nrelations show that CINEX can achieve 60% average precision for extracting\ncounting information. In a large-scale experiment, we demonstrate the potential\nfor knowledge base enrichment by applying CINEX to 2,474 frequent relations in\nWikidata. CINEX can assert the existence of 2.5M facts for 110 distinct\nrelations, which is 28% more than the existing Wikidata facts for these\nrelations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:03:23 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Mirza", "Paramita", ""], ["Razniewski", "Simon", ""], ["Darari", "Fariz", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1807.03658", "submitter": "Xiangxi Shi", "authors": "Xiangxi Shi, Jianfei Cai, Jiuxiang Gu, Shafiq Joty", "title": "Video Captioning with Boundary-aware Hierarchical Language Decoding and\n  Joint Video Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of video data on the internet requires effective and efficient\ntechnology to generate captions automatically for people who are not able to\nwatch the videos. Despite the great progress of video captioning research,\nparticularly on video feature encoding, the language decoder is still largely\nbased on the prevailing RNN decoder such as LSTM, which tends to prefer the\nfrequent word that aligns with the video. In this paper, we propose a\nboundary-aware hierarchical language decoder for video captioning, which\nconsists of a high-level GRU based language decoder, working as a global\n(caption-level) language model, and a low-level GRU based language decoder,\nworking as a local (phrase-level) language model. Most importantly, we\nintroduce a binary gate into the low-level GRU language decoder to detect the\nlanguage boundaries. Together with other advanced components including joint\nvideo prediction, shared soft attention, and boundary-aware video encoding, our\nintegrated video captioning framework can discover hierarchical language\ninformation and distinguish the subject and the object in a sentence, which are\nusually confusing during the language generation. Extensive experiments on two\nwidely-used video captioning datasets, MSR-Video-to-Text (MSR-VTT)\n\\cite{xu2016msr} and YouTube-to-Text (MSVD) \\cite{chen2011collecting} show that\nour method is highly competitive, compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 08:49:34 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Shi", "Xiangxi", ""], ["Cai", "Jianfei", ""], ["Gu", "Jiuxiang", ""], ["Joty", "Shafiq", ""]]}, {"id": "1807.03674", "submitter": "Sebastien Cossin", "authors": "S\\'ebastien Cossin, Vianney Jouhet, Fleur Mougin, Gayo Diallo, Frantz\n  Thiessard", "title": "IAM at CLEF eHealth 2018: Concept Annotation and Coding in French Death\n  Certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe the approach and results for our participation in\nthe task 1 (multilingual information extraction) of the CLEF eHealth 2018\nchallenge. We addressed the task of automatically assigning ICD-10 codes to\nFrench death certificates. We used a dictionary-based approach using materials\nprovided by the task organizers. The terms of the ICD-10 terminology were\nnormalized, tokenized and stored in a tree data structure. The Levenshtein\ndistance was used to detect typos. Frequent abbreviations were detected by\nmanually creating a small set of them. Our system achieved an F-score of 0.786\n(precision: 0.794, recall: 0.779). These scores were substantially higher than\nthe average score of the systems that participated in the challenge.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:31:25 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Cossin", "S\u00e9bastien", ""], ["Jouhet", "Vianney", ""], ["Mougin", "Fleur", ""], ["Diallo", "Gayo", ""], ["Thiessard", "Frantz", ""]]}, {"id": "1807.03756", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Yoon Kim, Justin Chiu, Demi Guo, Alexander M. Rush", "title": "Latent Alignment and Variational Attention", "comments": "accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural attention has become central to many state-of-the-art models in\nnatural language processing and related domains. Attention networks are an\neasy-to-train and effective method for softly simulating alignment; however,\nthe approach does not marginalize over latent alignments in a probabilistic\nsense. This property makes it difficult to compare attention to other alignment\napproaches, to compose it with probabilistic models, and to perform posterior\ninference conditioned on observed data. A related latent approach, hard\nattention, fixes these issues, but is generally harder to train and less\naccurate. This work considers variational attention networks, alternatives to\nsoft and hard attention for learning latent variable alignment models, with\ntighter approximation bounds based on amortized variational inference. We\nfurther propose methods for reducing the variance of gradients to make these\napproaches computationally feasible. Experiments show that for machine\ntranslation and visual question answering, inefficient exact latent variable\nmodels outperform standard neural attention, but these gains go away when using\nhard attention based training. On the other hand, variational attention retains\nmost of the performance gain but with training speed comparable to neural\nattention.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 16:59:12 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 23:03:21 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Deng", "Yuntian", ""], ["Kim", "Yoon", ""], ["Chiu", "Justin", ""], ["Guo", "Demi", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1807.03819", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit,\n  {\\L}ukasz Kaiser", "title": "Universal Transformers", "comments": "Published at ICLR2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) sequentially process data by updating their\nstate with each new data point, and have long been the de facto choice for\nsequence modeling tasks. However, their inherently sequential computation makes\nthem slow to train. Feed-forward and convolutional architectures have recently\nbeen shown to achieve superior results on some sequence modeling tasks such as\nmachine translation, with the added advantage that they concurrently process\nall inputs in the sequence, leading to easy parallelization and faster training\ntimes. Despite these successes, however, popular feed-forward sequence models\nlike the Transformer fail to generalize in many simple tasks that recurrent\nmodels handle with ease, e.g. copying strings or even simple logical inference\nwhen the string or formula lengths exceed those observed at training time. We\npropose the Universal Transformer (UT), a parallel-in-time self-attentive\nrecurrent sequence model which can be cast as a generalization of the\nTransformer model and which addresses these issues. UTs combine the\nparallelizability and global receptive field of feed-forward sequence models\nlike the Transformer with the recurrent inductive bias of RNNs. We also add a\ndynamic per-position halting mechanism and find that it improves accuracy on\nseveral tasks. In contrast to the standard Transformer, under certain\nassumptions, UTs can be shown to be Turing-complete. Our experiments show that\nUTs outperform standard Transformers on a wide range of algorithmic and\nlanguage understanding tasks, including the challenging LAMBADA language\nmodeling task where UTs achieve a new state of the art, and machine translation\nwhere UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 18:39:15 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2019 15:17:22 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 16:46:19 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Gouws", "Stephan", ""], ["Vinyals", "Oriol", ""], ["Uszkoreit", "Jakob", ""], ["Kaiser", "\u0141ukasz", ""]]}, {"id": "1807.03915", "submitter": "Thomas Manzini", "authors": "Hai Pham, Thomas Manzini, Paul Pu Liang, Barnabas Poczos", "title": "Seq2Seq2Sentiment: Multimodal Sequence to Sequence Models for Sentiment\n  Analysis", "comments": "8 pages of content, 11 pages total, 2 figures. Published as a\n  workshop paper at ACL 2018, Proceedings of Grand Challenge and Workshop on\n  Human Multimodal Language (Challenge-HML). 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine learning is a core research area spanning the language,\nvisual and acoustic modalities. The central challenge in multimodal learning\ninvolves learning representations that can process and relate information from\nmultiple modalities. In this paper, we propose two methods for unsupervised\nlearning of joint multimodal representations using sequence to sequence\n(Seq2Seq) methods: a \\textit{Seq2Seq Modality Translation Model} and a\n\\textit{Hierarchical Seq2Seq Modality Translation Model}. We also explore\nmultiple different variations on the multimodal inputs and outputs of these\nseq2seq models. Our experiments on multimodal sentiment analysis using the\nCMU-MOSI dataset indicate that our methods learn informative multimodal\nrepresentations that outperform the baselines and achieve improved performance\non multimodal sentiment analysis, specifically in the Bimodal case where our\nmodel is able to improve F1 Score by twelve points. We also discuss future\ndirections for multimodal Seq2Seq methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 01:13:13 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 11:14:31 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Pham", "Hai", ""], ["Manzini", "Thomas", ""], ["Liang", "Paul Pu", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1807.03948", "submitter": "Ramesh Manuvinakurike", "authors": "Ramesh Manuvinakurike, Sumanth Bharadwaj, Kallirroi Georgila", "title": "A Dialogue Annotation Scheme for Weight Management Chat using the\n  Trans-Theoretical Model of Health Behavior Change", "comments": "to appear in Fourteenth Joint ACL - ISO Workshop on Interoperable\n  Semantic Annotation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we collect and annotate human-human role-play dialogues in the\ndomain of weight management. There are two roles in the conversation: the\n\"seeker\" who is looking for ways to lose weight and the \"helper\" who provides\nsuggestions to help the \"seeker\" in their weight loss journey. The chat\ndialogues collected are then annotated with a novel annotation scheme inspired\nby a popular health behavior change theory called \"trans-theoretical model of\nhealth behavior change\". We also build classifiers to automatically predict the\nannotation labels used in our corpus. We find that classification accuracy\nimproves when oracle segmentations of the interlocutors' sentences are provided\ncompared to directly classifying unsegmented sentences.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 04:45:59 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Manuvinakurike", "Ramesh", ""], ["Bharadwaj", "Sumanth", ""], ["Georgila", "Kallirroi", ""]]}, {"id": "1807.03950", "submitter": "Ramesh Manuvinakurike", "authors": "Deepthi Karkada, Ramesh Manuvinakurike, Kallirroi Georgila", "title": "Towards Understanding End-of-trip Instructions in a Taxi Ride Scenario", "comments": "to appear in Fourteenth Joint ACL - ISO Workshop on Interoperable\n  Semantic Annotation, Corresponding author: Ramesh Manuvinakurike", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a dataset containing human-authored descriptions of target\nlocations in an \"end-of-trip in a taxi ride\" scenario. We describe our data\ncollection method and a novel annotation scheme that supports understanding of\nsuch descriptions of target locations. Our dataset contains target location\ndescriptions for both synthetic and real-world images as well as visual\nannotations (ground truth labels, dimensions of vehicles and objects,\ncoordinates of the target location,distance and direction of the target\nlocation from vehicles and objects) that can be used in various visual and\nlanguage tasks. We also perform a pilot experiment on how the corpus could be\napplied to visual reference resolution in this domain.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 05:06:53 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Karkada", "Deepthi", ""], ["Manuvinakurike", "Ramesh", ""], ["Georgila", "Kallirroi", ""]]}, {"id": "1807.03955", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen and Karin Verspoor", "title": "An improved neural network model for joint POS tagging and dependency\n  parsing", "comments": "11 pages; In Proceedings of the CoNLL 2018 Shared Task: Multilingual\n  Parsing from Raw Text to Universal Dependencies, to appear", "journal-ref": null, "doi": "10.18653/v1/K18-2008", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network model for joint part-of-speech (POS)\ntagging and dependency parsing. Our model extends the well-known BIST\ngraph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating\na BiLSTM-based tagging component to produce automatically predicted POS tags\nfor the parser. On the benchmark English Penn treebank, our model obtains\nstrong UAS and LAS scores at 94.51% and 92.87%, respectively, producing 1.5+%\nabsolute improvements to the BIST graph-based parser, and also obtaining a\nstate-of-the-art POS tagging accuracy at 97.97%. Furthermore, experimental\nresults on parsing 61 \"big\" Universal Dependencies treebanks from raw texts\nshow that our model outperforms the baseline UDPipe (Straka and Strakov\\'a,\n2017) with 0.8% higher average POS tagging score and 3.6% higher average LAS\nscore. In addition, with our model, we also obtain state-of-the-art downstream\ntask scores for biomedical event extraction and opinion analysis applications.\nOur code is available together with all pre-trained models at:\nhttps://github.com/datquocnguyen/jPTDP\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 05:47:33 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 13:37:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Verspoor", "Karin", ""]]}, {"id": "1807.04053", "submitter": "Natalie Schluter", "authors": "Daniel Varab and Natalie Schluter", "title": "UniParse: A universal graph-based parsing toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and use of the graph-based parsing framework\nand toolkit UniParse, released as an open-source python software package.\nUniParse as a framework novelly streamlines research prototyping, development\nand evaluation of graph-based dependency parsing architectures. UniParse does\nthis by enabling highly efficient, sufficiently independent, easily readable,\nand easily extensible implementations for all dependency parser components. We\ndistribute the toolkit with ready-made configurations as re-implementations of\nall current state-of-the-art first-order graph-based parsers, including even\nmore efficient Cython implementations of both encoders and decoders, as well as\nthe required specialised loss functions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 10:14:48 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Varab", "Daniel", ""], ["Schluter", "Natalie", ""]]}, {"id": "1807.04148", "submitter": "Sven Buechel", "authors": "Johannes Hellrich, Sven Buechel, and Udo Hahn", "title": "JeSemE: A Website for Exploring Diachronic Changes in Word Meaning and\n  Emotion", "comments": "COLING 2018 System Demonstrations (camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We here introduce a substantially extended version of JeSemE, an interactive\nwebsite for visually exploring computationally derived time-variant information\non word meanings and lexical emotions assembled from five large diachronic text\ncorpora. JeSemE is designed for scholars in the (digital) humanities as an\nalternative to consulting manually compiled, printed dictionaries for such\ninformation (if available at all). This tool uniquely combines state-of-the-art\ndistributional semantics with a nuanced model of human emotions, two\ninformation streams we deem beneficial for a data-driven interpretation of\ntexts in the humanities.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:12:58 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 11:17:15 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Hellrich", "Johannes", ""], ["Buechel", "Sven", ""], ["Hahn", "Udo", ""]]}, {"id": "1807.04172", "submitter": "Tomas Brychcin", "authors": "Tom\\'a\\v{s} Brychc\\'in", "title": "Linear Transformations for Cross-lingual Semantic Textual Similarity", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual semantic textual similarity systems estimate the degree of the\nmeaning similarity between two sentences, each in a different language.\nState-of-the-art algorithms usually employ machine translation and combine vast\namount of features, making the approach strongly supervised, resource rich, and\ndifficult to use for poorly-resourced languages.\n  In this paper, we study linear transformations, which project monolingual\nsemantic spaces into a shared space using bilingual dictionaries. We propose a\nnovel transformation, which builds on the best ideas from prior works. We\nexperiment with unsupervised techniques for sentence similarity based only on\nsemantic spaces and we show they can be significantly improved by the word\nweighting. Our transformation outperforms other methods and together with word\nweighting leads to very promising results on several datasets in different\nlanguages.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:48:02 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Brychc\u00edn", "Tom\u00e1\u0161", ""]]}, {"id": "1807.04175", "submitter": "Tomas Brychcin", "authors": "Tom\\'a\\v{s} Brychc\\'in, Stephen Eugene Taylor, Luk\\'a\\v{s} Svoboda", "title": "Cross-lingual Word Analogies using Linear Transformations between\n  Semantic Spaces", "comments": "11 pages. arXiv admin note: text overlap with arXiv:1807.04172", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the word analogy task across languages, to provide a new\nintrinsic evaluation method for cross-lingual semantic spaces. We experiment\nwith six languages within different language families, including English,\nGerman, Spanish, Italian, Czech, and Croatian. State-of-the-art monolingual\nsemantic spaces are transformed into a shared space using dictionaries of word\ntranslations. We compare several linear transformations and rank them for\nexperiments with monolingual (no transformation), bilingual (one semantic space\nis transformed to another), and multilingual (all semantic spaces are\ntransformed onto English space) versions of semantic spaces. We show that\ntested linear transformations preserve relationships between words (word\nanalogies) and lead to impressive results. We achieve average accuracy of\n51.1%, 43.1%, and 38.2% for monolingual, bilingual, and multilingual semantic\nspaces, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:51:35 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Brychc\u00edn", "Tom\u00e1\u0161", ""], ["Taylor", "Stephen Eugene", ""], ["Svoboda", "Luk\u00e1\u0161", ""]]}, {"id": "1807.04441", "submitter": "Roberto Camacho Barranco", "authors": "Roberto Camacho Barranco, Raimundo F. Dos Santos, M. Shahriar Hossain", "title": "Tracking the Evolution of Words with Time-reflective Text\n  Representations", "comments": "10 pages, 8 figures, presented at the 4th Special Session on\n  Intelligent Data Mining special session of the 2018 IEEE International\n  Conference on Big Data 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 80% of today's data is unstructured in nature, and these\nunstructured datasets evolve over time. A large part of these datasets are text\ndocuments generated by media outlets, scholarly articles in digital libraries,\nfindings from scientific and professional communities, and social media. Vector\nspace models were developed to analyze text data using data mining and machine\nlearning algorithms. While ample vector space models exist for text data, the\nevolutionary aspect of ever-changing text corpora is still missing in\nvector-based representations. The advent of word embeddings has enabled us to\ncreate a contextual vector space, but the embeddings fail to consider the\ntemporal aspects of the feature space successfully. This paper presents an\napproach to include temporal aspects in feature spaces. The inclusion of the\ntime aspect in the feature space provides vectors for every natural language\nelement, such as words or entities, at every timestamp. Such temporal word\nvectors allow us to track how the meaning of a word changes over time, by\nstudying the changes in its neighborhood. Moreover, a time-reflective text\nrepresentation will pave the way to a new set of text analytic abilities\ninvolving time series for text collections. In this paper, we present a\ntime-reflective vector space model for temporal text data that is able to\ncapture short and long-term changes in the meaning of words. We compare our\napproach with the limited literature on dynamic embeddings. We present\nqualitative and quantitative evaluations using the tracking of semantic\nevolution as the target application.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 06:47:15 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 02:20:04 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Barranco", "Roberto Camacho", ""], ["Santos", "Raimundo F. Dos", ""], ["Hossain", "M. Shahriar", ""]]}, {"id": "1807.04687", "submitter": "Linara Adilova", "authors": "Linara Adilova, Sven Giesselbach, Stefan R\\\"uping", "title": "Making Efficient Use of a Domain Expert's Time in Relation Extraction", "comments": "DMNLP Workshop paper, ECML-PKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of labeled data is one of the most frequent problems faced in\nmachine learning. This is particularly true in relation extraction in text\nmining, where large corpora of texts exists in many application domains, while\nlabeling of text data requires an expert to invest much time to read the\ndocuments. Overall, state-of-the art models, like the convolutional neural\nnetwork used in this paper, achieve great results when trained on large enough\namounts of labeled data. However, from a practical point of view the question\narises whether this is the most efficient approach when one takes the manual\neffort of the expert into account. In this paper, we report on an alternative\napproach where we first construct a relation extraction model using distant\nsupervision, and only later make use of a domain expert to refine the results.\nDistant supervision provides a mean of labeling data given known relations in a\nknowledge base, but it suffers from noisy labeling. We introduce an active\nlearning based extension, that allows our neural network to incorporate expert\nfeedback and report on first results on a complex data set.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:53:29 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Adilova", "Linara", ""], ["Giesselbach", "Sven", ""], ["R\u00fcping", "Stefan", ""]]}, {"id": "1807.04715", "submitter": "Konstantinos Skianis", "authors": "Konstantinos Skianis, Nikolaos Tziortziotis, Michalis Vazirgiannis", "title": "Orthogonal Matching Pursuit for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text classification, the problem of overfitting arises due to the high\ndimensionality, making regularization essential. Although classic regularizers\nprovide sparsity, they fail to return highly accurate models. On the contrary,\nstate-of-the-art group-lasso regularizers provide better results at the expense\nof low sparsity. In this paper, we apply a greedy variable selection algorithm,\ncalled Orthogonal Matching Pursuit, for the text classification task. We also\nextend standard group OMP by introducing overlapping Group OMP to handle\noverlapping groups of features. Empirical analysis verifies that both OMP and\noverlapping GOMP constitute powerful regularizers, able to produce effective\nand very sparse models. Code and data are available online:\nhttps://github.com/y3nk0/OMP-for-Text-Classification .\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:43:32 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 11:54:10 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Skianis", "Konstantinos", ""], ["Tziortziotis", "Nikolaos", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1807.04723", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Chinnadhurai Sankar, Michael Pieper, Joelle\n  Pineau, Yoshua Bengio", "title": "The Bottleneck Simulator: A Model-based Deep Reinforcement Learning\n  Approach", "comments": "26 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently shown many impressive successes.\nHowever, one major obstacle towards applying such methods to real-world\nproblems is their lack of data-efficiency. To this end, we propose the\nBottleneck Simulator: a model-based reinforcement learning method which\ncombines a learned, factorized transition model of the environment with rollout\nsimulations to learn an effective policy from few examples. The learned\ntransition model employs an abstract, discrete (bottleneck) state, which\nincreases sample efficiency by reducing the number of model parameters and by\nexploiting structural properties of the environment. We provide a mathematical\nanalysis of the Bottleneck Simulator in terms of fixed points of the learned\npolicy, which reveals how performance is affected by four distinct sources of\nerror: an error related to the abstract space structure, an error related to\nthe transition model estimation variance, an error related to the transition\nmodel estimation bias, and an error related to the transition model class bias.\nFinally, we evaluate the Bottleneck Simulator on two natural language\nprocessing tasks: a text adventure game and a real-world, complex dialogue\nresponse selection task. On both tasks, the Bottleneck Simulator yields\nexcellent performance beating competing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:59:28 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Sankar", "Chinnadhurai", ""], ["Pieper", "Michael", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1807.04783", "submitter": "Christo Kirov", "authors": "Christo Kirov and Ryan Cotterell", "title": "Recurrent Neural Networks in Linguistic Theory: Revisiting Pinker and\n  Prince (1988) and the Past Tense Debate", "comments": "TACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can advances in NLP help advance cognitive modeling? We examine the role of\nartificial neural networks, the current state of the art in many common NLP\ntasks, by returning to a classic case study. In 1986, Rumelhart and McClelland\nfamously introduced a neural architecture that learned to transduce English\nverb stems to their past tense forms. Shortly thereafter, Pinker & Prince\n(1988) presented a comprehensive rebuttal of many of Rumelhart and McClelland's\nclaims. Much of the force of their attack centered on the empirical inadequacy\nof the Rumelhart and McClelland (1986) model. Today, however, that model is\nseverely outmoded. We show that the Encoder-Decoder network architectures used\nin modern NLP systems obviate most of Pinker and Prince's criticisms without\nrequiring any simplication of the past tense mapping problem. We suggest that\nthe empirical performance of modern networks warrants a re-examination of their\nutility in linguistic and cognitive modeling.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 18:44:34 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 18:54:24 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Kirov", "Christo", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1807.04863", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Yoon Kim, Alexander M. Rush, David M. Blei", "title": "Avoiding Latent Variable Collapse With Generative Skip Models", "comments": "In the Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2019), Naha, Okinawa, Japan. PMLR:\n  Volume 89. An earlier version of this paper was presented at the Workshop on\n  Theoretical Foundations and Applications of Deep Generative Models, ICML,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders learn distributions of high-dimensional data. They\nmodel data with a deep latent-variable model and then fit the model by\nmaximizing a lower bound of the log marginal likelihood. VAEs can capture\ncomplex distributions, but they can also suffer from an issue known as \"latent\nvariable collapse,\" especially if the likelihood model is powerful.\nSpecifically, the lower bound involves an approximate posterior of the latent\nvariables; this posterior \"collapses\" when it is set equal to the prior, i.e.,\nwhen the approximate posterior is independent of the data. While VAEs learn\ngood generative models, latent variable collapse prevents them from learning\nuseful representations. In this paper, we propose a simple new way to avoid\nlatent variable collapse by including skip connections in our generative model;\nthese connections enforce strong links between the latent variables and the\nlikelihood function. We study generative skip models both theoretically and\nempirically. Theoretically, we prove that skip models increase the mutual\ninformation between the observations and the inferred latent variables.\nEmpirically, we study images (MNIST and Omniglot) and text (Yahoo). Compared to\nexisting VAE architectures, we show that generative skip models maintain\nsimilar predictive performance but lead to less collapse and provide more\nmeaningful representations of the data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 23:37:27 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 19:33:29 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Dieng", "Adji B.", ""], ["Kim", "Yoon", ""], ["Rush", "Alexander M.", ""], ["Blei", "David M.", ""]]}, {"id": "1807.04905", "submitter": "Eunsol Choi", "authors": "Eunsol Choi, Omer Levy, Yejin Choi, Luke Zettlemoyer", "title": "Ultra-Fine Entity Typing", "comments": "ACL 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new entity typing task: given a sentence with an entity\nmention, the goal is to predict a set of free-form phrases (e.g. skyscraper,\nsongwriter, or criminal) that describe appropriate types for the target entity.\nThis formulation allows us to use a new type of distant supervision at large\nscale: head words, which indicate the type of the noun phrases they appear in.\nWe show that these ultra-fine types can be crowd-sourced, and introduce new\nevaluation sets that are much more diverse and fine-grained than existing\nbenchmarks. We present a model that can predict open types, and is trained\nusing a multitask objective that pools our new head-word supervision with prior\nsupervision from entity linking. Experimental results demonstrate that our\nmodel is effective in predicting entity types at varying granularity; it\nachieves state of the art performance on an existing fine-grained entity typing\nbenchmark, and sets baselines for our newly-introduced datasets. Our data and\nmodel can be downloaded from: http://nlp.cs.washington.edu/entity_type\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 04:19:03 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Choi", "Eunsol", ""], ["Levy", "Omer", ""], ["Choi", "Yejin", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1807.04978", "submitter": "Zhangyu Xiao", "authors": "Zhangyu Xiao, Zhijian Ou, Wei Chu, Hui Lin", "title": "Hybrid CTC-Attention based End-to-End Speech Recognition using Subword\n  Units", "comments": "accepted by ISCSLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an end-to-end automatic speech recognition system,\nwhich successfully employs subword units in a hybrid CTC-Attention based\nsystem. The subword units are obtained by the byte-pair encoding (BPE)\ncompression algorithm. Compared to using words as modeling units, using\ncharacters or subword units does not suffer from the out-of-vocabulary (OOV)\nproblem. Furthermore, using subword units further offers a capability in\nmodeling longer context than using characters. We evaluate different systems\nover the LibriSpeech 1000h dataset. The subword-based hybrid CTC-Attention\nsystem obtains 6.8% word error rate (WER) on the test_clean subset without any\ndictionary or external language model. This represents a significant\nimprovement (a 12.8% WER relative reduction) over the character-based hybrid\nCTC-Attention system.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 09:06:07 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 02:21:41 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Xiao", "Zhangyu", ""], ["Ou", "Zhijian", ""], ["Chu", "Wei", ""], ["Lin", "Hui", ""]]}, {"id": "1807.04990", "submitter": "Zeyang Lei", "authors": "Zeyang Lei, Yujiu Yang, Min Yang, Yi Liu", "title": "A Multi-sentiment-resource Enhanced Attention Network for Sentiment\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches for sentiment classification do not fully exploit\nsentiment linguistic knowledge. In this paper, we propose a\nMulti-sentiment-resource Enhanced Attention Network (MEAN) to alleviate the\nproblem by integrating three kinds of sentiment linguistic knowledge (e.g.,\nsentiment lexicon, negation words, intensity words) into the deep neural\nnetwork via attention mechanisms. By using various types of sentiment\nresources, MEAN utilizes sentiment-relevant information from different\nrepresentation subspaces, which makes it more effective to capture the overall\nsemantics of the sentiment, negation and intensity words for sentiment\nprediction. The experimental results demonstrate that MEAN has robust\nsuperiority over strong competitors.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 10:01:19 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Lei", "Zeyang", ""], ["Yang", "Yujiu", ""], ["Yang", "Min", ""], ["Liu", "Yi", ""]]}, {"id": "1807.05013", "submitter": "Christophe Cerisara", "authors": "Christophe Cerisara (SYNALP), Somayeh Jafaritazehjani, Adedayo\n  Oluokun, Hoa Le (SYNALP)", "title": "Multi-task dialog act and sentiment recognition on Mastodon", "comments": null, "journal-ref": "COLING, Aug 2018, Santa Fe, United States", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of license restrictions, it often becomes impossible to strictly\nreproduce most research results on Twitter data already a few months after the\ncreation of the corpus. This situation worsened gradually as time passes and\ntweets become inaccessible. This is a critical issue for reproducible and\naccountable research on social media. We partly solve this challenge by\nannotating a new Twitter-like corpus from an alternative large social medium\nwith licenses that are compatible with reproducible experiments: Mastodon. We\nmanually annotate both dialogues and sentiments on this corpus, and train a\nmulti-task hierarchical recurrent network on joint sentiment and dialog act\nrecognition. We experimentally demonstrate that transfer learning may be\nefficiently achieved between both tasks, and further analyze some specific\ncorrelations between sentiments and dialogues on social media. Both the\nannotated corpus and deep network are released with an open-source license.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 11:26:42 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Cerisara", "Christophe", "", "SYNALP"], ["Jafaritazehjani", "Somayeh", "", "SYNALP"], ["Oluokun", "Adedayo", "", "SYNALP"], ["Le", "Hoa", "", "SYNALP"]]}, {"id": "1807.05127", "submitter": "Patrick Verga", "authors": "Shikhar Murty*, Patrick Verga*, Luke Vilnis, Irena Radovanovic, Andrew\n  McCallum", "title": "Hierarchical Losses and New Resources for Fine-grained Entity Typing and\n  Linking", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extraction from raw text to a knowledge base of entities and fine-grained\ntypes is often cast as prediction into a flat set of entity and type labels,\nneglecting the rich hierarchies over types and entities contained in curated\nontologies. Previous attempts to incorporate hierarchical structure have\nyielded little benefit and are restricted to shallow ontologies. This paper\npresents new methods using real and complex bilinear mappings for integrating\nhierarchical information, yielding substantial improvement over flat\npredictions in entity linking and fine-grained entity typing, and achieving new\nstate-of-the-art results for end-to-end models on the benchmark FIGER dataset.\nWe also present two new human-annotated datasets containing wide and deep\nhierarchies which we will release to the community to encourage further\nresearch in this direction: MedMentions, a collection of PubMed abstracts in\nwhich 246k mentions have been mapped to the massive UMLS ontology; and TypeNet,\nwhich aligns Freebase types with the WordNet hierarchy to obtain nearly 2k\nentity types. In experiments on all three datasets we show substantial gains\nfrom hierarchy-aware training.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:15:41 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Murty*", "Shikhar", ""], ["Verga*", "Patrick", ""], ["Vilnis", "Luke", ""], ["Radovanovic", "Irena", ""], ["McCallum", "Andrew", ""]]}, {"id": "1807.05151", "submitter": "Seid Muhie Yimam", "authors": "Gregor Wiedemann and Seid Muhie Yimam and Chris Biemann", "title": "New/s/leak 2.0 - Multilingual Information Extraction and Visualization\n  for Investigative Journalism", "comments": "Social Informatics 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Investigative journalism in recent years is confronted with two major\nchallenges: 1) vast amounts of unstructured data originating from large text\ncollections such as leaks or answers to Freedom of Information requests, and 2)\nmulti-lingual data due to intensified global cooperation and communication in\npolitics, business and civil society. Faced with these challenges, journalists\nare increasingly cooperating in international networks. To support such\ncollaborations, we present the new version of new/s/leak 2.0, our open-source\nsoftware for content-based searching of leaks. It includes three novel main\nfeatures: 1) automatic language detection and language-dependent information\nextraction for 40 languages, 2) entity and keyword visualization for efficient\nexploration, and 3) decentral deployment for analysis of confidential data from\nvarious formats. We illustrate the new analysis capabilities with an exemplary\ncase study.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:51:31 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Wiedemann", "Gregor", ""], ["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""]]}, {"id": "1807.05154", "submitter": "Hongxiao Bai", "authors": "Hongxiao Bai, Hai Zhao", "title": "Deep Enhanced Representation for Implicit Discourse Relation Recognition", "comments": "13(10) pages, accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation recognition is a challenging task as the relation\nprediction without explicit connectives in discourse parsing needs\nunderstanding of text spans and cannot be easily derived from surface features\nfrom the input sentence pairs. Thus, properly representing the text is very\ncrucial to this task. In this paper, we propose a model augmented with\ndifferent grained text representations, including character, subword, word,\nsentence, and sentence pair levels. The proposed deeper model is evaluated on\nthe benchmark treebank and achieves state-of-the-art accuracy with greater than\n48% in 11-way and $F_1$ score greater than 50% in 4-way classifications for the\nfirst time according to our best knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:57:39 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bai", "Hongxiao", ""], ["Zhao", "Hai", ""]]}, {"id": "1807.05195", "submitter": "Daniel Grie{\\ss}haber", "authors": "Daniel Grie{\\ss}haber, Ngoc Thang Vu, and Johannes Maucher", "title": "Low-Resource Text Classification using Domain-Adversarial Learning", "comments": null, "journal-ref": "Computer Speech & Language Volume 62, July 2020, 101056 Computer\n  Speech & Language Volume 62, July 2020, 101056", "doi": "10.1016/j.csl.2019.101056", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have recently shown to be successful in many natural\nlanguage processing tasks forming state-of-the-art systems. They require,\nhowever, a large amount of annotated data which is often missing. This paper\nexplores the use of domain-adversarial learning as a regularizer to avoid\noverfitting when training domain invariant features for deep, complex neural\nnetworks in low-resource and zero-resource settings in new target domains or\nlanguages. In case of new languages, we show that monolingual word vectors can\nbe directly used for training without prealignment. Their projection into a\ncommon space can be learnt ad-hoc at training time reaching the final\nperformance of pretrained multilingual word vectors.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:30:32 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 07:19:47 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Grie\u00dfhaber", "Daniel", ""], ["Vu", "Ngoc Thang", ""], ["Maucher", "Johannes", ""]]}, {"id": "1807.05206", "submitter": "Abdulkareem Alsudais", "authors": "Abdulkareem Alsudais", "title": "Image Classification for Arabic: Assessing the Accuracy of Direct\n  English to Arabic Translations", "comments": null, "journal-ref": "IEEE Access 2019", "doi": "10.1109/ACCESS.2019.2926924", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification is an ongoing research challenge. Most of the available\nresearch focuses on image classification for the English language, however\nthere is very little research on image classification for the Arabic language.\nExpanding image classification to Arabic has several applications. The present\nstudy investigated a method for generating Arabic labels for images of objects.\nThe method used in this study involved a direct English to Arabic translation\nof the labels that are currently available on ImageNet, a database commonly\nused in image classification research. The purpose of this study was to test\nthe accuracy of this method. In this study, 2,887 labeled images were randomly\nselected from ImageNet. All of the labels were translated from English to\nArabic using Google Translate. The accuracy of the translations was evaluated.\nResults indicated that that 65.6% of the Arabic labels were accurate. This\nstudy makes three important contributions to the image classification\nliterature: (1) it determined the baseline level of accuracy for algorithms\nthat provide Arabic labels for images, (2) it provided 1,895 images that are\ntagged with accurate Arabic labels, and (3) provided the accuracy of\ntranslations of image labels from English to Arabic.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:44:20 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 11:38:21 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Alsudais", "Abdulkareem", ""]]}, {"id": "1807.05324", "submitter": "Heng Ding", "authors": "Heng Ding, Krisztian Balog", "title": "Generating Synthetic Data for Neural Keyword-to-Question Models", "comments": "Extended version of ICTIR'18 full paper, 11 pages", "journal-ref": null, "doi": "10.1145/3234944.3234964", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search typically relies on keyword queries, but these are often semantically\nambiguous. We propose to overcome this by offering users natural language\nquestions, based on their keyword queries, to disambiguate their intent. This\nkeyword-to-question task may be addressed using neural machine translation\ntechniques. Neural translation models, however, require massive amounts of\ntraining data (keyword-question pairs), which is unavailable for this task. The\nmain idea of this paper is to generate large amounts of synthetic training data\nfrom a small seed set of hand-labeled keyword-question pairs. Since natural\nlanguage questions are available in large quantities, we develop models to\nautomatically generate the corresponding keyword queries. Further, we introduce\nvarious filtering mechanisms to ensure that synthetic training data is of high\nquality. We demonstrate the feasibility of our approach using both automatic\nand manual evaluation. This is an extended version of the article published\nwith the same title in the Proceedings of ICTIR'18.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 03:24:31 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ding", "Heng", ""], ["Balog", "Krisztian", ""]]}, {"id": "1807.05353", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre, Atsushi Fujita", "title": "Recurrent Stacking of Layers for Compact Neural Machine Translation\n  Models", "comments": "Version 2 (Current): Fixed Typos. Additional Results for models using\n  back-translated data. Resized the figure. Better explanations of some parts.\n  Version 1: Initial version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural machine translation (NMT), the most common practice is to stack a\nnumber of recurrent or feed-forward layers in the encoder and the decoder. As a\nresult, the addition of each new layer improves the translation quality\nsignificantly. However, this also leads to a significant increase in the number\nof parameters. In this paper, we propose to share parameters across all the\nlayers thereby leading to a recurrently stacked NMT model. We empirically show\nthat the translation quality of a model that recurrently stacks a single layer\n6 times is comparable to the translation quality of a model that stacks 6\nseparate layers. We also show that using pseudo-parallel corpora by\nback-translation leads to further significant improvements in translation\nquality.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 08:18:45 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 09:34:46 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""]]}, {"id": "1807.05518", "submitter": "Jacob Krantz", "authors": "Jacob Krantz, Maxwell Dulin, Paul De Palma, Mark VanDam", "title": "Syllabification by Phone Categorization", "comments": null, "journal-ref": "Jacob Krantz, Maxwell Dulin, Paul De Palma, and Mark VanDam. 2018.\n  Syllabification by Phone Categorization. In Proceedings of the Genetic and\n  Evolutionary Computation Conference Companion (GECCO '18) 47-48", "doi": "10.1145/3205651.3208781", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syllables play an important role in speech synthesis, speech recognition, and\nspoken document retrieval. A novel, low cost, and language agnostic approach to\ndividing words into their corresponding syllables is presented. A hybrid\ngenetic algorithm constructs a categorization of phones optimized for\nsyllabification. This categorization is used on top of a hidden Markov model\nsequence classifier to find syllable boundaries. The technique shows promising\npreliminary results when trained and tested on English words.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 09:23:49 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Krantz", "Jacob", ""], ["Dulin", "Maxwell", ""], ["De Palma", "Paul", ""], ["VanDam", "Mark", ""]]}, {"id": "1807.05519", "submitter": "Erik Cambria", "authors": "Yukun Ma and Erik Cambria", "title": "Concept-Based Embeddings for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on effectively leveraging and integrating information\nfrom concept-level as well as word-level via projecting concepts and words into\na lower dimensional space while retaining most critical semantics. In a broad\ncontext of opinion understanding system, we investigate the use of the fused\nembedding for several core NLP tasks: named entity detection and\nclassification, automatic speech recognition reranking, and targeted sentiment\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 09:36:39 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ma", "Yukun", ""], ["Cambria", "Erik", ""]]}, {"id": "1807.05574", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo, Tru H. Cao and Tuan M. V. Le", "title": "WordNet-Based Information Retrieval Using Common Hypernyms and Combined\n  Features", "comments": "6pages, Will be in proceedings of the 5th International Conference on\n  Intelligent Computing and Information Systems (ICICIS-2011), in cooperation\n  with ACM. 30 June to 3 July, 2011, Cairo, Egypt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text search based on lexical matching of keywords is not satisfactory due to\npolysemous and synonymous words. Semantic search that exploits word meanings,\nin general, improves search performance. In this paper, we survey WordNet-based\ninformation retrieval systems, which employ a word sense disambiguation method\nto process queries and documents. The problem is that in many cases a word has\nmore than one possible direct sense, and picking only one of them may give a\nwrong sense for the word. Moreover, the previous systems use only word forms to\nrepresent word senses and their hypernyms. We propose a novel approach that\nuses the most specific common hypernym of the remaining undisambiguated\nmulti-senses of a word, as well as combined WordNet features to represent word\nmeanings. Experiments on a benchmark dataset show that, in terms of the MAP\nmeasure, our search engine is 17.7% better than the lexical search, and at\nleast 9.4% better than all surveyed search systems using WordNet.\n  Keywords Ontology, word sense disambiguation, semantic annotation, semantic\nsearch.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 16:49:06 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""], ["Le", "Tuan M. V.", ""]]}, {"id": "1807.05642", "submitter": "John Feser", "authors": "Peter Ahrens, John Feser, Robin Hui", "title": "LATE Ain'T Earley: A Faster Parallel Earley Parser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the LATE algorithm, an asynchronous variant of the Earley\nalgorithm for parsing context-free grammars. The Earley algorithm is naturally\ntask-based, but is difficult to parallelize because of dependencies between the\ntasks. We present the LATE algorithm, which uses additional data structures to\nmaintain information about the state of the parse so that work items may be\nprocessed in any order. This property allows the LATE algorithm to be sped up\nusing task parallelism. We show that the LATE algorithm can achieve a 120x\nspeedup over the Earley algorithm on a natural language task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 00:50:00 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ahrens", "Peter", ""], ["Feser", "John", ""], ["Hui", "Robin", ""]]}, {"id": "1807.05797", "submitter": "Antonio San Mart\\'in", "authors": "Pilar Leon-Arauz, Antonio San Martin and Arianne Reimerink", "title": "The EcoLexicon English Corpus as an open corpus in Sketch Engine", "comments": "Proceedings of the 18th EURALEX International Congress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EcoLexicon English Corpus (EEC) is a 23.1-million-word corpus of\ncontemporary environmental texts. It was compiled by the LexiCon research group\nfor the development of EcoLexicon (Faber, Leon-Arauz & Reimerink 2016; San\nMartin et al. 2017), a terminological knowledge base on the environment. It is\navailable as an open corpus in the well-known corpus query system Sketch Engine\n(Kilgarriff et al. 2014), which means that any user, even without a\nsubscription, can freely access and query the corpus. In this paper, the EEC is\nintroduced by de- scribing how it was built and compiled and how it can be\nqueried and exploited, based both on the functionalities provided by Sketch\nEngine and on the parameters in which the texts in the EEC are classified.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:32:40 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Leon-Arauz", "Pilar", ""], ["Martin", "Antonio San", ""], ["Reimerink", "Arianne", ""]]}, {"id": "1807.05849", "submitter": "Junxin Liu", "authors": "Junxin Liu, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, Xing Xie", "title": "Neural Chinese Word Segmentation with Dictionary Knowledge", "comments": "This paper has been accepted by The Seventh CCF International\n  Conference on Natural Language Processing and Chinese Computing (NLPCC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is an important task for Chinese NLP.\nRecently, many neural network based methods have been proposed for CWS.\nHowever, these methods require a large number of labeled sentences for model\ntraining, and usually cannot utilize the useful information in Chinese\ndictionary. In this paper, we propose two methods to exploit the dictionary\ninformation for CWS. The first one is based on pseudo labeled data generation,\nand the second one is based on multi-task learning. The experimental results on\ntwo benchmark datasets validate that our approach can effectively improve the\nperformance of Chinese word segmentation, especially when training data is\ninsufficient.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 04:51:41 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Liu", "Junxin", ""], ["Wu", "Fangzhao", ""], ["Wu", "Chuhan", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1807.05855", "submitter": "Hosung Park", "authors": "Hosung Park, Donghyun Lee, Minkyu Lim, Yoseb Kang, Juneseok Oh and\n  Ji-Hwan Kim", "title": "A Fast-Converged Acoustic Modeling for Korean Speech Recognition: A\n  Preliminary Study on Time Delay Neural Network", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a time delay neural network (TDNN) based acoustic model is\nproposed to implement a fast-converged acoustic modeling for Korean speech\nrecognition. The TDNN has an advantage in fast-convergence where the amount of\ntraining data is limited, due to subsampling which excludes duplicated weights.\nThe TDNN showed an absolute improvement of 2.12% in terms of character error\nrate compared to feed forward neural network (FFNN) based modelling for Korean\nspeech corpora. The proposed model converged 1.67 times faster than a\nFFNN-based model did.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 05:34:09 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Park", "Hosung", ""], ["Lee", "Donghyun", ""], ["Lim", "Minkyu", ""], ["Kang", "Yoseb", ""], ["Oh", "Juneseok", ""], ["Kim", "Ji-Hwan", ""]]}, {"id": "1807.05962", "submitter": "Debanjan Mahata", "authors": "Debanjan Mahata, John Kuriakose, Rajiv Ratn Shah, Roger Zimmermann,\n  John R. Talburt", "title": "Theme-weighted Ranking of Keywords from Text Documents using Phrase\n  Embeddings", "comments": "preprint for paper accepted in Proceedings of 1st IEEE International\n  Conference on Multimedia Information Processing and Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword extraction is a fundamental task in natural language processing that\nfacilitates mapping of documents to a concise set of representative single and\nmulti-word phrases. Keywords from text documents are primarily extracted using\nsupervised and unsupervised approaches. In this paper, we present an\nunsupervised technique that uses a combination of theme-weighted personalized\nPageRank algorithm and neural phrase embeddings for extracting and ranking\nkeywords. We also introduce an efficient way of processing text documents and\ntraining phrase embeddings using existing techniques. We share an evaluation\ndataset derived from an existing dataset that is used for choosing the\nunderlying embedding model. The evaluations for ranked keyword extraction are\nperformed on two benchmark datasets comprising of short abstracts (Inspec), and\nlong scientific papers (SemEval 2010), and is shown to produce results better\nthan the state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 16:39:11 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Mahata", "Debanjan", ""], ["Kuriakose", "John", ""], ["Shah", "Rajiv Ratn", ""], ["Zimmermann", "Roger", ""], ["Talburt", "John R.", ""]]}, {"id": "1807.06008", "submitter": "Kittipitch Kuptavanich", "authors": "Kittipitch Kuptavanich", "title": "Using Textual Summaries to Describe a Set of Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When customers are faced with the task of making a purchase in an unfamiliar\nproduct domain, it might be useful to provide them with an overview of the\nproduct set to help them understand what they can expect. In this paper we\npresent and evaluate a method to summarise sets of products in natural\nlanguage, focusing on the price range, common product features across the set,\nand product features that impact on price. In our study, participants reported\nthat they found our summaries useful, but we found no evidence that the\nsummaries influenced the selections made by participants.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 19:40:23 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Kuptavanich", "Kittipitch", ""]]}, {"id": "1807.06107", "submitter": "Amita Misra", "authors": "Mansurul Bhuiyan, Amita Misra, Saurabh Tripathy, Jalal Mahmud, Rama\n  Akkiraju", "title": "Don't get Lost in Negation: An Effective Negation Handled Dialogue Acts\n  Prediction Algorithm for Twitter Customer Service Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last several years, Twitter is being adopted by the companies as an\nalternative platform to interact with the customers to address their concerns.\nWith the abundance of such unconventional conversation resources, push for\ndeveloping effective virtual agents is more than ever. To address this\nchallenge, a better understanding of such customer service conversations is\nrequired. Lately, there have been several works proposing a novel taxonomy for\nfine-grained dialogue acts as well as develop algorithms for automatic\ndetection of these acts. The outcomes of these works are providing stepping\nstones for the ultimate goal of building efficient and effective virtual\nagents. But none of these works consider handling the notion of negation into\nthe proposed algorithms. In this work, we developed an SVM-based dialogue acts\nprediction algorithm for Twitter customer service conversations where negation\nhandling is an integral part of the end-to-end solution. For negation handling,\nwe propose several efficient heuristics as well as adopt recent state-of- art\nthird party machine learning based solutions. Empirically we show model's\nperformance gain while handling negation compared to when we don't. Our\nexperiments show that for the informal text such as tweets, the heuristic-based\napproach is more effective.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 21:01:52 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bhuiyan", "Mansurul", ""], ["Misra", "Amita", ""], ["Tripathy", "Saurabh", ""], ["Mahmud", "Jalal", ""], ["Akkiraju", "Rama", ""]]}, {"id": "1807.06151", "submitter": "Nishant Nikhil", "authors": "Nishant Nikhil, Ramit Pahwa, Mehul Kumar Nirala and Rohan Khilnani", "title": "LSTMs with Attention for Aggression Detection", "comments": "Accepted in First Workshop on Trolling, Aggression and Cyberbullying\n  at 27th International Conference of Computational Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe the system submitted for the shared task on\nAggression Identification in Facebook posts and comments by the team Nishnik.\nPrevious works demonstrate that LSTMs have achieved remarkable performance in\nnatural language processing tasks. We deploy an LSTM model with an attention\nunit over it. Our system ranks 6th and 4th in the Hindi subtask for Facebook\ncomments and subtask for generalized social media data respectively. And it\nranks 17th and 10th in the corresponding English subtasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 23:35:57 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Nikhil", "Nishant", ""], ["Pahwa", "Ramit", ""], ["Nirala", "Mehul Kumar", ""], ["Khilnani", "Rohan", ""]]}, {"id": "1807.06204", "submitter": "Chunxi Liu", "authors": "Chunxi Liu, Matthew Wiesner, Shinji Watanabe, Craig Harman, Jan Trmal,\n  Najim Dehak, Sanjeev Khudanpur", "title": "Low-Resource Contextual Topic Identification on Speech", "comments": "Accepted for publication at 2018 IEEE Workshop on Spoken Language\n  Technology (SLT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In topic identification (topic ID) on real-world unstructured audio, an audio\ninstance of variable topic shifts is first broken into sequential segments, and\neach segment is independently classified. We first present a general purpose\nmethod for topic ID on spoken segments in low-resource languages, using a\ncascade of universal acoustic modeling, translation lexicons to English, and\nEnglish-language topic classification. Next, instead of classifying each\nsegment independently, we demonstrate that exploring the contextual\ndependencies across sequential segments can provide large improvements. In\nparticular, we propose an attention-based contextual model which is able to\nleverage the contexts in a selective manner. We test both our contextual and\nnon-contextual models on four LORELEI languages, and on all but one our\nattention-based contextual model significantly outperforms the\ncontext-independent models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 04:01:06 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 21:58:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Liu", "Chunxi", ""], ["Wiesner", "Matthew", ""], ["Watanabe", "Shinji", ""], ["Harman", "Craig", ""], ["Trmal", "Jan", ""], ["Dehak", "Najim", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1807.06234", "submitter": "Kalpesh Krishna", "authors": "Kalpesh Krishna, Shubham Toshniwal, Karen Livescu", "title": "Hierarchical Multitask Learning for CTC-based Speech Recognition", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that neural encoder-decoder speech recognition can be\nimproved with hierarchical multitask learning, where auxiliary tasks are added\nat intermediate layers of a deep encoder. We explore the effect of hierarchical\nmultitask learning in the context of connectionist temporal classification\n(CTC)-based speech recognition, and investigate several aspects of this\napproach. Consistent with previous work, we observe performance improvements on\ntelephone conversational speech recognition (specifically the Eval2000 test\nsets) when training a subword-level CTC model with an auxiliary phone loss at\nan intermediate layer. We analyze the effects of a number of experimental\nvariables (like interpolation constant and position of the auxiliary loss\nfunction), performance in lower-resource settings, and the relationship between\npretraining and multitask learning. We observe that the hierarchical multitask\napproach improves over standard multitask training in our higher-data\nexperiments, while in the low-resource settings standard multitask training\nworks well. The best results are obtained by combining hierarchical multitask\nlearning and pretraining, which improves word error rates by 3.4% absolute on\nthe Eval2000 test sets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 06:05:00 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 03:46:17 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Krishna", "Kalpesh", ""], ["Toshniwal", "Shubham", ""], ["Livescu", "Karen", ""]]}, {"id": "1807.06270", "submitter": "Animesh Prasad", "authors": "Animesh Prasad, Herv\\'e D\\'ejean, Jean-Luc Meunier, Max Weidemann,\n  Johannes Michael, Gundram Leifert", "title": "Bench-Marking Information Extraction in Semi-Structured Historical\n  Handwritten Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we present our findings from benchmarking experiments for\ninformation extraction on historical handwritten marriage records Esposalles\nfrom IEHHR - ICDAR 2017 robust reading competition. The information extraction\nis modeled as semantic labeling of the sequence across 2 set of labels. This\ncan be achieved by sequentially or jointly applying handwritten text\nrecognition (HTR) and named entity recognition (NER). We deploy a pipeline\napproach where first we use state-of-the-art HTR and use its output as input\nfor NER. We show that given low resource setup and simple structure of the\nrecords, high performance of HTR ensures overall high performance. We explore\nthe various configurations of conditional random fields and neural networks to\nbenchmark NER on given certain noisy input. The best model on 10-fold\ncross-validation as well as blind test data uses n-gram features with\nbidirectional long short-term memory.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 08:13:19 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Prasad", "Animesh", ""], ["D\u00e9jean", "Herv\u00e9", ""], ["Meunier", "Jean-Luc", ""], ["Weidemann", "Max", ""], ["Michael", "Johannes", ""], ["Leifert", "Gundram", ""]]}, {"id": "1807.06414", "submitter": "Mehdi Ben Lazreg", "authors": "Mehdi Ben Lazreg, Morten Goodwin", "title": "Combining a Context Aware Neural Network with a Denoising Autoencoder\n  for Measuring String Similarities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarities between strings is central for many established and\nfast growing research areas including information retrieval, biology, and\nnatural language processing. The traditional approach for string similarity\nmeasurements is to define a metric over a word space that quantifies and sums\nup the differences between characters in two strings. The state-of-the-art in\nthe area has, surprisingly, not evolved much during the last few decades. The\nmajority of the metrics are based on a simple comparison between character and\ncharacter distributions without consideration for the context of the words.\nThis paper proposes a string metric that encompasses similarities between\nstrings based on (1) the character similarities between the words including.\nNon-Standard and standard spellings of the same words, and (2) the context of\nthe words. Our proposal is a neural network composed of a denoising autoencoder\nand what we call a context encoder specifically designed to find similarities\nbetween the words based on their context. The experimental results show that\nthe resulting metrics succeeds in 85.4\\% of the cases in finding the correct\nversion of a non-standard spelling among the closest words, compared to 63.2\\%\nwith the established Normalised-Levenshtein distance. Besides, we show that\nwords used in similar context are with our approach calculated to be similar\nthan words with different contexts, which is a desirable property missing in\nestablished string metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 12:29:23 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Lazreg", "Mehdi Ben", ""], ["Goodwin", "Morten", ""]]}, {"id": "1807.06441", "submitter": "Jan Vanek", "authors": "Jan Vanek, Josef Michalek, Jan Zelinka, Josef Psutka", "title": "A Comparison of Adaptation Techniques and Recurrent Neural Network\n  Architectures", "comments": "submitted and accepted to SLSP 2018 conference. arXiv admin note:\n  text overlap with arXiv:1806.07186, arXiv:1806.07974", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, recurrent neural networks have become state-of-the-art in acoustic\nmodeling for automatic speech recognition. The long short-term memory (LSTM)\nunits are the most popular ones. However, alternative units like gated\nrecurrent unit (GRU) and its modifications outperformed LSTM in some\npublications. In this paper, we compared five neural network (NN) architectures\nwith various adaptation and feature normalization techniques. We have evaluated\nfeature-space maximum likelihood linear regression, five variants of i-vector\nadaptation and two variants of cepstral mean normalization. The most adaptation\nand normalization techniques were developed for feed-forward NNs and, according\nto results in this paper, not all of them worked also with RNNs. For\nexperiments, we have chosen a well known and available TIMIT phone recognition\ntask. The phone recognition is much more sensitive to the quality of AM than\nlarge vocabulary task with a complex language model. Also, we published the\nopen-source scripts to easily replicate the results and to help continue the\ndevelopment.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 09:40:21 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Vanek", "Jan", ""], ["Michalek", "Josef", ""], ["Zelinka", "Jan", ""], ["Psutka", "Josef", ""]]}, {"id": "1807.06500", "submitter": "Jiyuan Zhang", "authors": "Jiyuan Zhang, Dong Wang", "title": "Chinese Poetry Generation with Flexible Styles", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that sequence-to-sequence neural models, particularly\nthose with the attention mechanism, can successfully generate classical Chinese\npoems. However, neural models are not capable of generating poems that match\nspecific styles, such as the impulsive style of Li Bai, a famous poet in the\nTang Dynasty. This work proposes a memory-augmented neural model to enable the\ngeneration of style-specific poetry. The key idea is a memory structure that\nstores how poems with a desired style were generated by humans, and uses\nsimilar fragments to adjust the generation. We demonstrate that the proposed\nalgorithm generates poems with flexible styles, including styles of a\nparticular era and an individual poet.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:26:04 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 03:17:15 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Zhang", "Jiyuan", ""], ["Wang", "Dong", ""]]}, {"id": "1807.06517", "submitter": "Osman Ramadan", "authors": "Osman Ramadan, Pawe{\\l} Budzianowski, Milica Ga\\v{s}i\\'c", "title": "Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing", "comments": "10 pages, 1 figure and 2 tables. In Proceedings of the 56th Annual\n  Meeting of the Association for Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust dialogue belief tracking is a key component in maintaining good\nquality dialogue systems. The tasks that dialogue systems are trying to solve\nare becoming increasingly complex, requiring scalability to multi domain,\nsemantically rich dialogues. However, most current approaches have difficulty\nscaling up with domains because of the dependency of the model parameters on\nthe dialogue ontology. In this paper, a novel approach is introduced that fully\nutilizes semantic similarity between dialogue utterances and the ontology\nterms, allowing the information to be shared across domains. The evaluation is\nperformed on a recently collected multi-domain dialogues dataset, one order of\nmagnitude larger than currently available corpora. Our model demonstrates great\ncapability in handling multi-domain dialogues, simultaneously outperforming\nexisting state-of-the-art models in single-domain dialogue tracking tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:00:35 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ramadan", "Osman", ""], ["Budzianowski", "Pawe\u0142", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1807.06538", "submitter": "Konno Tomohiko", "authors": "Tomohiko Konno and Michiaki Iwazume", "title": "Cavity Filling: Pseudo-Feature Generation for Multi-Class Imbalanced\n  Data Problems in Deep Learning", "comments": "The slides are available at https://goo.gl/SPsSDh in English and at\n  https://goo.gl/RFHYAa in Japanese. 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we generate pseudo-features based on the multivariate probability\ndistributions obtained from the feature maps in layers of trained deep neural\nnetworks. Further, we augment the minor-class data based on these generated\npseudo-features to overcome the imbalanced data problems. The proposed method,\ni.e., cavity filling, improves the deep learning capabilities in several\nproblems because all the real-world data are observed to be imbalanced.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:34:47 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 02:37:09 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 01:22:27 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 02:45:11 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 08:50:34 GMT"}, {"version": "v6", "created": "Sun, 13 Oct 2019 14:47:42 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Konno", "Tomohiko", ""], ["Iwazume", "Michiaki", ""]]}, {"id": "1807.06557", "submitter": "Catherina Xu", "authors": "Michelle Lam, Catherina Xu, Angela Kong, Vinodkumar Prabhakaran", "title": "Power Networks: A Novel Neural Architecture to Predict Power Relations", "comments": "Accepted by SIGHUM, an ACL Special Interest Group on Language\n  Technologies for the Socio-Economic Sciences and Humanities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can language analysis reveal the underlying social power relations that exist\nbetween participants of an interaction? Prior work within NLP has shown promise\nin this area, but the performance of automatically predicting power relations\nusing NLP analysis of social interactions remains wanting. In this paper, we\npresent a novel neural architecture that captures manifestations of power\nwithin individual emails which are then aggregated in an order-preserving way\nin order to infer the direction of power between pairs of participants in an\nemail thread. We obtain an accuracy of 80.4%, a 10.1% improvement over\nstate-of-the-art methods, in this task. We further apply our model to the task\nof predicting power relations between individuals based on the entire set of\nmessages exchanged between them; here also, our model significantly outperforms\nthe70.0% accuracy using prior state-of-the-art techniques, obtaining an\naccuracy of 83.0%.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:04:52 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Lam", "Michelle", ""], ["Xu", "Catherina", ""], ["Kong", "Angela", ""], ["Prabhakaran", "Vinodkumar", ""]]}, {"id": "1807.06588", "submitter": "Jason R.C. Nurse Dr", "authors": "Charlie Kingston and Jason R. C. Nurse and Ioannis Agrafiotis and\n  Andrew Milich", "title": "Using semantic clustering to support situation awareness on Twitter: The\n  case of World Views", "comments": null, "journal-ref": "Human-centric Computing and Information Sciences (HCIS) 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, situation awareness has been recognised as a critical part\nof effective decision making, in particular for crisis management. One way to\nextract value and allow for better situation awareness is to develop a system\ncapable of analysing a dataset of multiple posts, and clustering consistent\nposts into different views or stories (or, world views). However, this can be\nchallenging as it requires an understanding of the data, including determining\nwhat is consistent data, and what data corroborates other data. Attempting to\naddress these problems, this article proposes Subject-Verb-Object Semantic\nSuffix Tree Clustering (SVOSSTC) and a system to support it, with a special\nfocus on Twitter content. The novelty and value of SVOSSTC is its emphasis on\nutilising the Subject-Verb-Object (SVO) typology in order to construct\nsemantically consistent world views, in which individuals---particularly those\ninvolved in crisis response---might achieve an enhanced picture of a situation\nfrom social media data. To evaluate our system and its ability to provide\nenhanced situation awareness, we tested it against existing approaches,\nincluding human data analysis, using a variety of real-world scenarios. The\nresults indicated a noteworthy degree of evidence (e.g., in cluster granularity\nand meaningfulness) to affirm the suitability and rigour of our approach.\nMoreover, these results highlight this article's proposals as innovative and\npractical system contributions to the research field.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 17:59:39 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Kingston", "Charlie", ""], ["Nurse", "Jason R. C.", ""], ["Agrafiotis", "Ioannis", ""], ["Milich", "Andrew", ""]]}, {"id": "1807.06610", "submitter": "Davis Liang", "authors": "Davis Liang, Zhiheng Huang, Zachary C. Lipton", "title": "Learning Noise-Invariant Representations for Robust Speech Recognition", "comments": "Under Review at IEEE SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite rapid advances in speech recognition, current models remain brittle\nto superficial perturbations to their inputs. Small amounts of noise can\ndestroy the performance of an otherwise state-of-the-art model. To harden\nmodels against background noise, practitioners often perform data augmentation,\nadding artificially-noised examples to the training set, carrying over the\noriginal label. In this paper, we hypothesize that a clean example and its\nsuperficially perturbed counterparts shouldn't merely map to the same class ---\nthey should map to the same representation. We propose\ninvariant-representation-learning (IRL): At each training iteration, for each\ntraining example,we sample a noisy counterpart. We then apply a penalty term to\ncoerce matched representations at each layer (above some chosen layer). Our key\nresults, demonstrated on the Librispeech dataset are the following: (i) IRL\nsignificantly reduces character error rates (CER) on both 'clean' (3.3% vs\n6.5%) and 'other' (11.0% vs 18.1%) test sets; (ii) on several out-of-domain\nnoise settings (different from those seen during training), IRL's benefits are\neven more pronounced. Careful ablations confirm that our results are not simply\ndue to shrinking activations at the chosen layers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 18:15:14 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Liang", "Davis", ""], ["Huang", "Zhiheng", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1807.06638", "submitter": "Chengsheng Mao", "authors": "Himanshu Sharma, Chengsheng Mao, Yizhen Zhang, Haleh Vatani, Liang\n  Yao, Yizhen Zhong, Luke Rasmussen, Guoqian Jiang, Jyotishman Pathak and Yuan\n  Luo", "title": "Developing a Portable Natural Language Processing Based Phenotyping\n  System", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a portable phenotyping system that is capable of\nintegrating both rule-based and statistical machine learning based approaches.\nOur system utilizes UMLS to extract clinically relevant features from the\nunstructured text and then facilitates portability across different\ninstitutions and data systems by incorporating OHDSI's OMOP Common Data Model\n(CDM) to standardize necessary data elements. Our system can also store the key\ncomponents of rule-based systems (e.g., regular expression matches) in the\nformat of OMOP CDM, thus enabling the reuse, adaptation and extension of many\nexisting rule-based clinical NLP systems. We experimented with our system on\nthe corpus from i2b2's Obesity Challenge as a pilot study. Our system\nfacilitates portable phenotyping of obesity and its 15 comorbidities based on\nthe unstructured patient discharge summaries, while achieving a performance\nthat often ranked among the top 10 of the challenge participants. This\nstandardization enables a consistent application of numerous rule-based and\nmachine learning based classification techniques downstream.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 19:40:28 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Sharma", "Himanshu", ""], ["Mao", "Chengsheng", ""], ["Zhang", "Yizhen", ""], ["Vatani", "Haleh", ""], ["Yao", "Liang", ""], ["Zhong", "Yizhen", ""], ["Rasmussen", "Luke", ""], ["Jiang", "Guoqian", ""], ["Pathak", "Jyotishman", ""], ["Luo", "Yuan", ""]]}, {"id": "1807.06683", "submitter": "Onur G\\\"ung\\\"or", "authors": "Onur G\\\"ung\\\"or, Suzan \\\"Usk\\\"udarl{\\i}, Tunga G\\\"ung\\\"or", "title": "Improving Named Entity Recognition by Jointly Learning to Disambiguate\n  Morphological Tags", "comments": "COLING 2018 (accepted)", "journal-ref": "Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018). pp. 2082-2092", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous studies have shown that linguistic features of a word such as\npossession, genitive or other grammatical cases can be employed in word\nrepresentations of a named entity recognition (NER) tagger to improve the\nperformance for morphologically rich languages. However, these taggers require\nexternal morphological disambiguation (MD) tools to function which are hard to\nobtain or non-existent for many languages. In this work, we propose a model\nwhich alleviates the need for such disambiguators by jointly learning NER and\nMD taggers in languages for which one can provide a list of candidate\nmorphological analyses. We show that this can be done independent of the\nmorphological annotation schemes, which differ among languages. Our experiments\nemploying three different model architectures that join these two tasks show\nthat joint learning improves NER performance. Furthermore, the morphological\ndisambiguator's performance is shown to be competitive.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 21:46:02 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["G\u00fcng\u00f6r", "Onur", ""], ["\u00dcsk\u00fcdarl\u0131", "Suzan", ""], ["G\u00fcng\u00f6r", "Tunga", ""]]}, {"id": "1807.06718", "submitter": "Yangming Zhou", "authors": "Qi Wang, Jiahui Qiu, Yangming Zhou, Tong Ruan, Daqi Gao and Ju Gao", "title": "Automatic Severity Classification of Coronary Artery Disease via\n  Recurrent Capsule Network", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronary artery disease (CAD) is one of the leading causes of cardiovascular\ndisease deaths. CAD condition progresses rapidly, if not diagnosed and treated\nat an early stage may eventually lead to an irreversible state of the heart\nmuscle death. Invasive coronary arteriography is the gold standard technique\nfor CAD diagnosis. Coronary arteriography texts describe which part has\nstenosis and how much stenosis is in details. It is crucial to conduct the\nseverity classification of CAD. In this paper, we employ a recurrent capsule\nnetwork (RCN) to extract semantic relations between clinical named entities in\nChinese coronary arteriography texts, through which we can automatically find\nout the maximal stenosis for each lumen to inference how severe CAD is\naccording to the improved method of Gensini. Experimental results on the corpus\ncollected from Shanghai Shuguang Hospital show that our proposed method\nachieves an accuracy of 97.0\\% in the severity classification of CAD.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 00:38:47 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 13:45:48 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wang", "Qi", ""], ["Qiu", "Jiahui", ""], ["Zhou", "Yangming", ""], ["Ruan", "Tong", ""], ["Gao", "Daqi", ""], ["Gao", "Ju", ""]]}, {"id": "1807.06736", "submitter": "Jingxuan Zhang", "authors": "Jing-Xuan Zhang, Zhen-Hua Ling, Li-Rong Dai", "title": "Forward Attention in Sequence-to-sequence Acoustic Modelling for Speech\n  Synthesis", "comments": "5 pages, 3 figures, 2 tables. Published in IEEE International\n  Conference on Acoustics, Speech and Signal Processing 2018 (ICASSP2018)", "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (2018) 4789-4793", "doi": "10.1109/ICASSP.2018.8462020", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a forward attention method for the sequenceto- sequence\nacoustic modeling of speech synthesis. This method is motivated by the nature\nof the monotonic alignment from phone sequences to acoustic sequences. Only the\nalignment paths that satisfy the monotonic condition are taken into\nconsideration at each decoder timestep. The modified attention probabilities at\neach timestep are computed recursively using a forward algorithm. A transition\nagent for forward attention is further proposed, which helps the attention\nmechanism to make decisions whether to move forward or stay at each decoder\ntimestep. Experimental results show that the proposed forward attention method\nachieves faster convergence speed and higher stability than the baseline\nattention method. Besides, the method of forward attention with transition\nagent can also help improve the naturalness of synthetic speech and control the\nspeed of synthetic speech effectively.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 01:59:26 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhang", "Jing-Xuan", ""], ["Ling", "Zhen-Hua", ""], ["Dai", "Li-Rong", ""]]}, {"id": "1807.06792", "submitter": "Panayiotis Georgiou", "authors": "Shao-Yen Tseng and Brian Baucom and Panayiotis Georgiou", "title": "Unsupervised Online Multitask Learning of Behavioral Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning has been an attractive method for easily deriving\nmeaningful data representations from vast amounts of unlabeled data. These\nrepresentations, or embeddings, often yield superior results in many tasks,\nwhether used directly or as features in subsequent training stages. However,\nthe quality of the embeddings is highly dependent on the assumed knowledge in\nthe unlabeled data and how the system extracts information without supervision.\nDomain portability is also very limited in unsupervised learning, often\nrequiring re-training on other in-domain corpora to achieve robustness. In this\nwork we present a multitask paradigm for unsupervised contextual learning of\nbehavioral interactions which addresses unsupervised domain adaption. We\nintroduce an online multitask objective into unsupervised learning and show\nthat sentence embeddings generated through this process increases performance\nof affective tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 06:39:07 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 05:47:39 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tseng", "Shao-Yen", ""], ["Baucom", "Brian", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1807.06882", "submitter": "Tal Linzen", "authors": "Tal Linzen and Brian Leonard", "title": "Distinct patterns of syntactic agreement errors in recurrent networks\n  and humans", "comments": "Proceedings of the 40th Annual Conference of the Cognitive Science\n  Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the correct form of a verb in context requires an understanding\nof the syntactic structure of the sentence. Recurrent neural networks have been\nshown to perform this task with an error rate comparable to humans, despite the\nfact that they are not designed with explicit syntactic representations. To\nexamine the extent to which the syntactic representations of these networks are\nsimilar to those used by humans when processing sentences, we compare the\ndetailed pattern of errors that RNNs and humans make on this task. Despite\nsignificant similarities (attraction errors, asymmetry between singular and\nplural subjects), the error patterns differed in important ways. In particular,\nin complex sentences with relative clauses error rates increased in RNNs but\ndecreased in humans. Furthermore, RNNs showed a cumulative effect of attractors\nbut humans did not. We conclude that at least in some respects the syntactic\nrepresentations acquired by RNNs are fundamentally different from those used by\nhumans.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 11:58:59 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Linzen", "Tal", ""], ["Leonard", "Brian", ""]]}, {"id": "1807.06926", "submitter": "Josemar Caetano", "authors": "Evandro Cunha, Gabriel Magno, Josemar Caetano, Douglas Teixeira,\n  Virgilio Almeida", "title": "Fake news as we feel it: perception and conceptualization of the term\n  \"fake news\" in the media", "comments": "Accepted as a full paper at the 10th International Conference on\n  Social Informatics (SocInfo 2018). Please cite the SocInfo version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we quantitatively analyze how the term \"fake news\" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression \"fake news\", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term \"fake news\",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term \"fake news\", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:41:57 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Cunha", "Evandro", ""], ["Magno", "Gabriel", ""], ["Caetano", "Josemar", ""], ["Teixeira", "Douglas", ""], ["Almeida", "Virgilio", ""]]}, {"id": "1807.06978", "submitter": "Sixun Ouyang", "authors": "Sixun Ouyang and Aonghus Lawlor and Felipe Costa and Peter Dolog", "title": "Improving Explainable Recommendations with Synthetic Reviews", "comments": "Recsys DLRS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task for a recommender system to provide interpretable\nexplanations for the user. This is important for the credibility of the system.\nCurrent interpretable recommender systems tend to focus on certain features\nknown to be important to the user and offer their explanations in a structured\nform. It is well known that user generated reviews and feedback from reviewers\nhave strong leverage over the users' decisions. On the other hand, recent text\ngeneration works have been shown to generate text of similar quality to human\nwritten text, and we aim to show that generated text can be successfully used\nto explain recommendations.\n  In this paper, we propose a framework consisting of popular review-oriented\ngeneration models aiming to create personalised explanations for\nrecommendations. The interpretations are generated at both character and word\nlevels. We build a dataset containing reviewers' feedback from the Amazon books\nreview dataset. Our cross-domain experiments are designed to bridge from\nnatural language processing to the recommender system domain. Besides language\nmodel evaluation methods, we employ DeepCoNN, a novel review-oriented\nrecommender system using a deep neural network, to evaluate the recommendation\nperformance of generated reviews by root mean square error (RMSE). We\ndemonstrate that the synthetic personalised reviews have better recommendation\nperformance than human written reviews. To our knowledge, this presents the\nfirst machine-generated natural language explanations for rating prediction.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:42:35 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Ouyang", "Sixun", ""], ["Lawlor", "Aonghus", ""], ["Costa", "Felipe", ""], ["Dolog", "Peter", ""]]}, {"id": "1807.06998", "submitter": "Filip Klubi\\v{c}ka", "authors": "Filip Klubi\\v{c}ka, Giancarlo D. Salton, John D. Kelleher", "title": "Is it worth it? Budget-related evaluation metrics for model selection", "comments": "7 pages, 1 figure, 5 tables, In proceedings of the Eleventh\n  International Conference on Language Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating a linguistic resource is often done by using a machine learning\nmodel that filters the content that goes through to a human annotator, before\ngoing into the final resource. However, budgets are often limited, and the\namount of available data exceeds the amount of affordable annotation. In order\nto optimize the benefit from the invested human work, we argue that deciding on\nwhich model one should employ depends not only on generalized evaluation\nmetrics such as F-score, but also on the gain metric. Because the model with\nthe highest F-score may not necessarily have the best sequencing of predicted\nclasses, this may lead to wasting funds on annotating false positives, yielding\nzero improvement of the linguistic resource. We exemplify our point with a case\nstudy, using real data from a task of building a verb-noun idiom dictionary. We\nshow that, given the choice of three systems with varying F-scores, the system\nwith the highest F-score does not yield the highest profits. In other words, in\nour case the cost-benefit trade off is more favorable for a system with a lower\nF-score.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 15:37:58 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Klubi\u010dka", "Filip", ""], ["Salton", "Giancarlo D.", ""], ["Kelleher", "John D.", ""]]}, {"id": "1807.07104", "submitter": "Ramon Sanabria", "authors": "Ramon Sanabria and Florian Metze", "title": "Hierarchical Multi Task Learning With CTC", "comments": "In Proceedings at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Automatic Speech Recognition it is still challenging to learn useful\nintermediate representations when using high-level (or abstract) target units\nsuch as words. For that reason, character or phoneme based systems tend to\noutperform word-based systems when just few hundreds of hours of training data\nare being used. In this paper, we first show how hierarchical multi-task\ntraining can encourage the formation of useful intermediate representations. We\nachieve this by performing Connectionist Temporal Classification at different\nlevels of the network with targets of different granularity. Our model thus\nperforms predictions in multiple scales for the same input. On the standard\n300h Switchboard training setup, our hierarchical multi-task architecture\nexhibits improvements over single-task architectures with the same number of\nparameters. Our model obtains 14.0% Word Error Rate on the Eval2000 Switchboard\nsubset without any decoder or language model, outperforming the current\nstate-of-the-art on acoustic-to-word models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 18:57:37 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 03:57:25 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 06:53:25 GMT"}, {"version": "v4", "created": "Mon, 14 Jan 2019 02:52:26 GMT"}, {"version": "v5", "created": "Mon, 14 Jan 2019 02:54:19 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Sanabria", "Ramon", ""], ["Metze", "Florian", ""]]}, {"id": "1807.07108", "submitter": "Fabiano Ferreira Luz", "authors": "Fabiano Ferreira Luz and Marcelo Finger", "title": "Semantic Parsing: Syntactic assurance to target sentence using LSTM\n  Encoder CFG-Decoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing can be defined as the process of mapping natural language\nsentences into a machine interpretable, formal representation of its meaning.\nSemantic parsing using LSTM encoder-decoder neural networks have become\npromising approach. However, human automated translation of natural language\ndoes not provide grammaticality guarantees for the sentences generate such a\nguarantee is particularly important for practical cases where a data base query\ncan cause critical errors if the sentence is ungrammatical. In this work, we\npropose an neural architecture called Encoder CFG-Decoder, whose output\nconforms to a given context-free grammar. Results are show for any\nimplementation of such architecture display its correctness and providing\nbenchmark accuracy levels better than the literature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 19:10:45 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Luz", "Fabiano Ferreira", ""], ["Finger", "Marcelo", ""]]}, {"id": "1807.07147", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov and Ivan P. Yamshchikov", "title": "Guess who? Multilingual approach for the automated generation of\n  author-stylized poetry", "comments": null, "journal-ref": null, "doi": "10.1109/SLT.2018.8639573", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of stylized text generation in a\nmultilingual setup. A version of a language model based on a long short-term\nmemory (LSTM) artificial neural network with extended phonetic and semantic\nembeddings is used for stylized poetry generation. The quality of the resulting\npoems generated by the network is estimated through bilingual evaluation\nunderstudy (BLEU), a survey and a new cross-entropy based metric that is\nsuggested for the problems of such type. The experiments show that the proposed\nmodel consistently outperforms random sample and vanilla-LSTM baselines, humans\nalso tend to associate machine generated texts with the target author.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:13:20 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 21:08:53 GMT"}, {"version": "v3", "created": "Mon, 17 Sep 2018 16:27:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1807.07149", "submitter": "Mireille Boutin", "authors": "Albert Parra and Andrew W. Haddad and Mireille Boutin and Edward J.\n  Delp", "title": "A Hand-Held Multimedia Translation and Interpretation System with\n  Application to Diet Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a network independent, hand-held system to translate and\ndisambiguate foreign restaurant menu items in real-time. The system is based on\nthe use of a portable multimedia device, such as a smartphones or a PDA. An\naccurate and fast translation is obtained using a Machine Translation engine\nand a context-specific corpora to which we apply two pre-processing steps,\ncalled translation standardization and $n$-gram consolidation. The phrase-table\ngenerated is orders of magnitude lighter than the ones commonly used in market\napplications, thus making translations computationally less expensive, and\ndecreasing the battery usage. Translation ambiguities are mitigated using\nmultimedia information including images of dishes and ingredients, along with\ningredient lists. We implemented a prototype of our system on an iPod Touch\nSecond Generation for English speakers traveling in Spain. Our tests indicate\nthat our translation method yields higher accuracy than translation engines\nsuch as Google Translate, and does so almost instantaneously. The memory\nrequirements of the application, including the database of images, are also\nwell within the limits of the device. By combining it with a database of\nnutritional information, our proposed system can be used to help individuals\nwho follow a medical diet maintain this diet while traveling.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 03:52:26 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Parra", "Albert", ""], ["Haddad", "Andrew W.", ""], ["Boutin", "Mireille", ""], ["Delp", "Edward J.", ""]]}, {"id": "1807.07186", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Katharina Kann and Hinrich Sch\\\"utze", "title": "Evaluating Word Embeddings in Multi-label Classification Using\n  Fine-grained Name Typing", "comments": "6 pages, The 3rd Workshop on Representation Learning for NLP\n  (RepL4NLP @ ACL2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models typically associate each word with a single real-valued\nvector, representing its different properties. Evaluation methods, therefore,\nneed to analyze the accuracy and completeness of these properties in\nembeddings. This requires fine-grained analysis of embedding subspaces.\nMulti-label classification is an appropriate way to do so. We propose a new\nevaluation method for word embeddings based on multi-label classification given\na word embedding. The task we use is fine-grained name typing: given a large\ncorpus, find all types that a name can refer to based on the name embedding.\nGiven the scale of entities in knowledge bases, we can build datasets for this\ntask that are complementary to the current embedding evaluation datasets in:\nthey are very large, contain fine-grained classes, and allow the direct\nevaluation of embeddings without confounding factors like sentence context\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 23:38:08 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Kann", "Katharina", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1807.07187", "submitter": "Walid Krichene", "authors": "Walid Krichene, Nicolas Mayoraz, Steffen Rendle, Li Zhang, Xinyang Yi,\n  Lichan Hong, Ed Chi, John Anderson", "title": "Efficient Training on Very Large Corpora via Gramian Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning similarity functions over very large corpora\nusing neural network embedding models. These models are typically trained using\nSGD with sampling of random observed and unobserved pairs, with a number of\nsamples that grows quadratically with the corpus size, making it expensive to\nscale to very large corpora. We propose new efficient methods to train these\nmodels without having to sample unobserved pairs. Inspired by matrix\nfactorization, our approach relies on adding a global quadratic penalty to all\npairs of examples and expressing this term as the matrix-inner-product of two\ngeneralized Gramians. We show that the gradient of this term can be efficiently\ncomputed by maintaining estimates of the Gramians, and develop variance\nreduction schemes to improve the quality of the estimates. We conduct\nlarge-scale experiments that show a significant improvement in training time\nand generalization quality compared to traditional sampling methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 23:45:33 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Krichene", "Walid", ""], ["Mayoraz", "Nicolas", ""], ["Rendle", "Steffen", ""], ["Zhang", "Li", ""], ["Yi", "Xinyang", ""], ["Hong", "Lichan", ""], ["Chi", "Ed", ""], ["Anderson", "John", ""]]}, {"id": "1807.07255", "submitter": "Wei Wu", "authors": "Can Xu, Wei Wu, Yu Wu", "title": "Towards Explainable and Controllable Open Domain Dialogue Generation\n  with Dialogue Acts", "comments": "The paper is also available on OpenReview of ICLR 2018\n  (https://openreview.net/forum?id=Bym0cU1CZ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study open domain dialogue generation with dialogue acts designed to\nexplain how people engage in social chat. To imitate human behavior, we propose\nmanaging the flow of human-machine interactions with the dialogue acts as\npolicies. The policies and response generation are jointly learned from\nhuman-human conversations, and the former is further optimized with a\nreinforcement learning approach. With the dialogue acts, we achieve significant\nimprovement over state-of-the-art methods on response quality for given\ncontexts and dialogue length in both machine-machine simulation and\nhuman-machine conversation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 06:41:05 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 01:45:32 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Xu", "Can", ""], ["Wu", "Wei", ""], ["Wu", "Yu", ""]]}, {"id": "1807.07279", "submitter": "Aykut Koc", "authors": "Lutfi Kerem Senel, Ihsan Utlu, Furkan \\c{S}ahinu\\c{c}, Haldun M.\n  Ozaktas, Aykut Ko\\c{c}", "title": "Imparting Interpretability to Word Embeddings while Preserving Semantic\n  Structure", "comments": "14 pages, 5 figures", "journal-ref": "Natural Language Engineering, 1-26, 2020", "doi": "10.1017/S1351324920000315", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an ubiquitous method in natural language processing, word embeddings are\nextensively employed to map semantic properties of words into a dense vector\nrepresentation. They capture semantic and syntactic relations among words but\nthe vectors corresponding to the words are only meaningful relative to each\nother. Neither the vector nor its dimensions have any absolute, interpretable\nmeaning. We introduce an additive modification to the objective function of the\nembedding learning algorithm that encourages the embedding vectors of words\nthat are semantically related to a predefined concept to take larger values\nalong a specified dimension, while leaving the original semantic learning\nmechanism mostly unaffected. In other words, we align words that are already\ndetermined to be related, along predefined concepts. Therefore, we impart\ninterpretability to the word embedding by assigning meaning to its vector\ndimensions. The predefined concepts are derived from an external lexical\nresource, which in this paper is chosen as Roget's Thesaurus. We observe that\nalignment along the chosen concepts is not limited to words in the Thesaurus\nand extends to other related words as well. We quantify the extent of\ninterpretability and assignment of meaning from our experimental results.\nManual human evaluation results have also been presented to further verify that\nthe proposed method increases interpretability. We also demonstrate the\npreservation of semantic coherence of the resulting vector space by using\nword-analogy and word-similarity tests. These tests show that the\ninterpretability-imparted word embeddings that are obtained by the proposed\nframework do not sacrifice performances in common benchmark tests.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:14:59 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 13:27:55 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 11:41:00 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 11:31:59 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Senel", "Lutfi Kerem", ""], ["Utlu", "Ihsan", ""], ["\u015eahinu\u00e7", "Furkan", ""], ["Ozaktas", "Haldun M.", ""], ["Ko\u00e7", "Aykut", ""]]}, {"id": "1807.07281", "submitter": "Wei Ping", "authors": "Wei Ping, Kainan Peng, Jitong Chen", "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "comments": "Published at ICLR 2019. (v3: add important details & discussion in\n  Appendix A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new solution for parallel wave generation by\nWaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we\ndistill a Gaussian inverse autoregressive flow from the autoregressive WaveNet\nby minimizing a regularized KL divergence between their highly-peaked output\ndistributions. Our method computes the KL divergence in closed-form, which\nsimplifies the training algorithm and provides very efficient distillation. In\naddition, we introduce the first text-to-wave neural architecture for speech\nsynthesis, which is fully convolutional and enables fast end-to-end training\nfrom scratch. It significantly outperforms the previous pipeline that connects\na text-to-spectrogram model to a separately trained WaveNet (Ping et al.,\n2018). We also successfully distill a parallel waveform synthesizer conditioned\non the hidden representation in this end-to-end model.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:15:41 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 07:34:16 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 00:22:40 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Ping", "Wei", ""], ["Peng", "Kainan", ""], ["Chen", "Jitong", ""]]}, {"id": "1807.07351", "submitter": "Adam Tsakalidis", "authors": "Adam Tsakalidis, Maria Liakata, Theo Damoulas, Alexandra I. Cristea", "title": "Can We Assess Mental Health through Social Media and Smart Devices?\n  Addressing Bias in Methodology and Evaluation", "comments": "Preprint accepted for publication in the European Conference on\n  Machine Learning and Principles and Practice of Knowledge Discovery in\n  Databases (ECML-PKDD 2018 Applied Data Science Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting mental health from smartphone and social media data on a\nlongitudinal basis has recently attracted great interest, with very promising\nresults being reported across many studies. Such approaches have the potential\nto revolutionise mental health assessment, if their development and evaluation\nfollows a real world deployment setting. In this work we take a closer look at\nstate-of-the-art approaches, using different mental health datasets and\nindicators, different feature sources and multiple simulations, in order to\nassess their ability to generalise. We demonstrate that under a pragmatic\nevaluation framework, none of the approaches deliver or even approach the\nreported performances. In fact, we show that current state-of-the-art\napproaches can barely outperform the most na\\\"ive baselines in the real-world\nsetting, posing serious questions not only about their deployment ability, but\nalso about the contribution of the derived features for the mental health\nassessment task and how to make better use of such data in the future.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 11:44:10 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Tsakalidis", "Adam", ""], ["Liakata", "Maria", ""], ["Damoulas", "Theo", ""], ["Cristea", "Alexandra I.", ""]]}, {"id": "1807.07425", "submitter": "Liang Yao Dr.", "authors": "Liang Yao, Chengsheng Mao, Yuan Luo", "title": "Clinical Text Classification with Rule-based Features and\n  Knowledge-guided Convolutional Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1806.04820 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical text classification is an important problem in medical natural\nlanguage processing. Existing studies have conventionally focused on rules or\nknowledge sources-based feature engineering, but only a few have exploited\neffective feature learning capability of deep learning methods. In this study,\nwe propose a novel approach which combines rule-based features and\nknowledge-guided deep learning techniques for effective disease classification.\nCritical Steps of our method include identifying trigger phrases, predicting\nclasses with very few examples using trigger phrases and training a\nconvolutional neural network with word embeddings and Unified Medical Language\nSystem (UMLS) entity embeddings. We evaluated our method on the 2008\nIntegrating Informatics with Biology and the Bedside (i2b2) obesity challenge.\nThe results show that our method outperforms the state of the art methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:00:41 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 04:27:30 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Yao", "Liang", ""], ["Mao", "Chengsheng", ""], ["Luo", "Yuan", ""]]}, {"id": "1807.07517", "submitter": "Sudip Mittal", "authors": "Priyanka Ranade, Sudip Mittal, Anupam Joshi, Karuna Joshi", "title": "Using Deep Neural Networks to Translate Multi-lingual Threat\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multilingual nature of the Internet increases complications in the\ncybersecurity community's ongoing efforts to strategically mine threat\nintelligence from OSINT data on the web. OSINT sources such as social media,\nblogs, and dark web vulnerability markets exist in diverse languages and hinder\nsecurity analysts, who are unable to draw conclusions from intelligence in\nlanguages they don't understand. Although third party translation engines are\ngrowing stronger, they are unsuited for private security environments. First,\nsensitive intelligence is not a permitted input to third party engines due to\nprivacy and confidentiality policies. In addition, third party engines produce\ngeneralized translations that tend to lack exclusive cybersecurity terminology.\nIn this paper, we address these issues and describe our system that enables\nthreat intelligence understanding across unfamiliar languages. We create a\nneural network based system that takes in cybersecurity data in a different\nlanguage and outputs the respective English translation. The English\ntranslation can then be understood by an analyst, and can also serve as input\nto an AI based cyber-defense system that can take mitigative action. As a proof\nof concept, we have created a pipeline which takes Russian threats and\ngenerates its corresponding English, RDF, and vectorized representations. Our\nnetwork optimizes translations on specifically, cybersecurity data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 16:14:08 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Ranade", "Priyanka", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Joshi", "Karuna", ""]]}, {"id": "1807.07520", "submitter": "Grant Strimel", "authors": "Grant P. Strimel, Kanthashree Mysore Sathyendra, Stanislav Peshterliev", "title": "Statistical Model Compression for Small-Footprint Natural Language\n  Understanding", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate statistical model compression applied to natural\nlanguage understanding (NLU) models. Small-footprint NLU models are important\nfor enabling offline systems on hardware restricted devices, and for decreasing\non-demand model loading latency in cloud-based systems. To compress NLU models,\nwe present two main techniques, parameter quantization and perfect feature\nhashing. These techniques are complementary to existing model pruning\nstrategies such as L1 regularization. We performed experiments on a large scale\nNLU system. The results show that our approach achieves 14-fold reduction in\nmemory usage compared to the original models with minimal predictive\nperformance impact.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 16:23:35 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Strimel", "Grant P.", ""], ["Sathyendra", "Kanthashree Mysore", ""], ["Peshterliev", "Stanislav", ""]]}, {"id": "1807.07545", "submitter": "Jo\\~ao Loula", "authors": "Jo\\~ao Loula, Marco Baroni, Brenden M. Lake", "title": "Rearranging the Familiar: Testing Compositional Generalization in\n  Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic compositionality is the ability to recombine meaningful units with\nregular and predictable outcomes, and it's seen as key to humans' capacity for\ngeneralization in language. Recent work has studied systematic compositionality\nin modern seq2seq models using generalization to novel navigation instructions\nin a grounded environment as a probing tool, requiring models to quickly\nbootstrap the meaning of new words. We extend this framework here to settings\nwhere the model needs only to recombine well-trained functional words (such as\n\"around\" and \"right\") in novel contexts. Our findings confirm and strengthen\nthe earlier ones: seq2seq models can be impressively good at generalizing to\nnovel combinations of previously-seen input, but only when they receive\nextensive training on the specific pattern to be generalized (e.g.,\ngeneralizing from many examples of \"X around right\" to \"jump around right\"),\nwhile failing when generalization requires novel application of compositional\nrules (e.g., inferring the meaning of \"around right\" from those of \"right\" and\n\"around\").\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:23:13 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Loula", "Jo\u00e3o", ""], ["Baroni", "Marco", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1807.07741", "submitter": "Luiza Sayfullina", "authors": "Luiza Sayfullina, Eric Malmi and Juho Kannala", "title": "Learning Representations for Soft Skill Matching", "comments": "Accepted by 7th International Conference - Analysis of Images, Social\n  networks and Texts, http://aistconf.org/ (Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Employers actively look for talents having not only specific hard skills but\nalso various soft skills. To analyze the soft skill demands on the job market,\nit is important to be able to detect soft skill phrases from job advertisements\nautomatically. However, a naive matching of soft skill phrases can lead to\nfalse positive matches when a soft skill phrase, such as friendly, is used to\ndescribe a company, a team, or another entity, rather than a desired candidate.\n  In this paper, we propose a phrase-matching-based approach which\ndifferentiates between soft skill phrases referring to a candidate vs.\nsomething else. The disambiguation is formulated as a binary text\nclassification problem where the prediction is made for the potential soft\nskill based on the context where it occurs. To inform the model about the soft\nskill for which the prediction is made, we develop several approaches,\nincluding soft skill masking and soft skill tagging.\n  We compare several neural network based approaches, including CNN, LSTM and\nHierarchical Attention Model. The proposed tagging-based input representation\nusing LSTM achieved the highest recall of 83.92% on the job dataset when fixing\na precision to 95%.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 08:40:10 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Sayfullina", "Luiza", ""], ["Malmi", "Eric", ""], ["Kannala", "Juho", ""]]}, {"id": "1807.07752", "submitter": "Shaunak Joshi", "authors": "Shaunak Joshi and Deepali Deshpande", "title": "Twitter Sentiment Analysis System", "comments": "5 pages", "journal-ref": "International Journal of Computer Applications (2018)", "doi": "10.5120/ijca2018917319", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is increasingly used by humans to express their feelings and\nopinions in the form of short text messages. Detecting sentiments in the text\nhas a wide range of applications including identifying anxiety or depression of\nindividuals and measuring well-being or mood of a community. Sentiments can be\nexpressed in many ways that can be seen such as facial expression and gestures,\nspeech and by written text. Sentiment Analysis in text documents is essentially\na content-based classification problem involving concepts from the domains of\nNatural Language Processing as well as Machine Learning. In this paper,\nsentiment recognition based on textual data and the techniques used in\nsentiment analysis are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 09:19:08 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Joshi", "Shaunak", ""], ["Deshpande", "Deepali", ""]]}, {"id": "1807.07779", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Tru H. Cao", "title": "A Generalized Vector Space Model for Ontology-Based Information\n  Retrieval", "comments": "5 pages, in Vietnamese. information retrieval, vector space model,\n  ontology, named entity, keyword. Accepted by Vietnamese Journal on\n  Information Technologies and Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entities (NE) are objects that are referred to by names such as people,\norganizations and locations. Named entities and keywords are important to the\nmeaning of a document. We propose a generalized vector space model that\ncombines named entities and keywords. In the model, we take into account\ndifferent ontological features of named entities, namely, aliases, classes and\nidentifiers. Moreover, we use entity classes to represent the latent\ninformation of interrogative words in Wh-queries, which are ignored in\ntraditional keyword-based searching. We have implemented and tested the\nproposed model on a TREC dataset, as presented and discussed in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:37:31 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""]]}, {"id": "1807.07828", "submitter": "EPTCS", "authors": "Jules Hedges (University of Oxford), Martha Lewis (ILLC, University of\n  Amsterdam)", "title": "Towards Functorial Language-Games", "comments": "In Proceedings CAPNS 2018, arXiv:1811.02701", "journal-ref": "EPTCS 283, 2018, pp. 89-102", "doi": "10.4204/EPTCS.283.7", "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In categorical compositional semantics of natural language one studies\nfunctors from a category of grammatical derivations (such as a Lambek pregroup)\nto a semantic category (such as real vector spaces). We compositionally build\ngame-theoretic semantics of sentences by taking the semantic category to be the\ncategory whose morphisms are open games. This requires some modifications to\nthe grammar category to compensate for the failure of open games to form a\ncompact closed category. We illustrate the theory using simple examples of\nWittgenstein's language-games.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 13:18:15 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 05:12:27 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Hedges", "Jules", "", "University of Oxford"], ["Lewis", "Martha", "", "ILLC, University of\n  Amsterdam"]]}, {"id": "1807.07961", "submitter": "Jianbo Yuan", "authors": "Yuxiao Chen, Jianbo Yuan, Quanzeng You, Jiebo Luo", "title": "Twitter Sentiment Analysis via Bi-sense Emoji Embedding and\n  Attention-based LSTM", "comments": null, "journal-ref": null, "doi": "10.1145/3240508.3240533", "report-no": null, "categories": "cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis on large-scale social media data is important to bridge\nthe gaps between social media contents and real world activities including\npolitical election prediction, individual and public emotional status\nmonitoring and analysis, and so on. Although textual sentiment analysis has\nbeen well studied based on platforms such as Twitter and Instagram, analysis of\nthe role of extensive emoji uses in sentiment analysis remains light. In this\npaper, we propose a novel scheme for Twitter sentiment analysis with extra\nattention on emojis. We first learn bi-sense emoji embeddings under positive\nand negative sentimental tweets individually, and then train a sentiment\nclassifier by attending on these bi-sense emoji embeddings with an\nattention-based long short-term memory network (LSTM). Our experiments show\nthat the bi-sense embedding is effective for extracting sentiment-aware\nembeddings of emojis and outperforms the state-of-the-art models. We also\nvisualize the attentions to show that the bi-sense emoji embedding provides\nbetter guidance on the attention mechanism to obtain a more robust\nunderstanding of the semantics and sentiments.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 04:09:08 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 01:25:05 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Chen", "Yuxiao", ""], ["Yuan", "Jianbo", ""], ["You", "Quanzeng", ""], ["Luo", "Jiebo", ""]]}, {"id": "1807.07964", "submitter": "Minjeong Kim", "authors": "Minjeong Kim, David Keetae Park, Hyungjong Noh, Yeonsoo Lee and Jaegul\n  Choo", "title": "Question-Aware Sentence Gating Networks for Question and Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine comprehension question answering, which finds an answer to the\nquestion given a passage, involves high-level reasoning processes of\nunderstanding and tracking the relevant contents across various semantic units\nsuch as words, phrases, and sentences in a document. This paper proposes the\nnovel question-aware sentence gating networks that directly incorporate the\nsentence-level information into word-level encoding processes. To this end, our\nmodel first learns question-aware sentence representations and then dynamically\ncombines them with word-level representations, resulting in semantically\nmeaningful word representations for QA tasks. Experimental results demonstrate\nthat our approach consistently improves the accuracy over existing baseline\napproaches on various QA datasets and bears the wide applicability to other\nneural network-based QA models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 07:35:43 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kim", "Minjeong", ""], ["Park", "David Keetae", ""], ["Noh", "Hyungjong", ""], ["Lee", "Yeonsoo", ""], ["Choo", "Jaegul", ""]]}, {"id": "1807.07965", "submitter": "Arindam Chowdhury", "authors": "Arindam Chowdhury and Lovekesh Vig", "title": "An Efficient End-to-End Neural Model for Handwritten Text Recognition", "comments": "Accepted at British Machine Vision Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline handwritten text recognition from images is an important problem for\nenterprises attempting to digitize large volumes of handmarked scanned\ndocuments/reports. Deep recurrent models such as Multi-dimensional LSTMs have\nbeen shown to yield superior performance over traditional Hidden Markov Model\nbased approaches that suffer from the Markov assumption and therefore lack the\nrepresentational power of RNNs. In this paper we introduce a novel approach\nthat combines a deep convolutional network with a recurrent Encoder-Decoder\nnetwork to map an image to a sequence of characters corresponding to the text\npresent in the image. The entire model is trained end-to-end using Focal Loss,\nan improvement over the standard Cross-Entropy loss that addresses the class\nimbalance problem, inherent to text recognition. To enhance the decoding\ncapacity of the model, Beam Search algorithm is employed which searches for the\nbest sequence out of a set of hypotheses based on a joint distribution of\nindividual characters. Our model takes as input a downsampled version of the\noriginal image thereby making it both computationally and memory efficient. The\nexperimental results were benchmarked against two publicly available datasets,\nIAM and RIMES. We surpass the state-of-the-art word level accuracy on the\nevaluation set of both datasets by 3.5% & 1.1%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 09:55:09 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 13:31:24 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Chowdhury", "Arindam", ""], ["Vig", "Lovekesh", ""]]}, {"id": "1807.07982", "submitter": "Aaron Schwartz", "authors": "Aaron J. Schwartz, Peter Sheridan Dodds, Jarlath P.M. O'Neil-Dunne,\n  Christopher M. Danforth, Taylor H. Ricketts", "title": "Visitors to urban greenspace have higher sentiment and lower negativity\n  on Twitter", "comments": "18 pages, 5 figures", "journal-ref": "People Nat. 2019; 00: 1- 10", "doi": "10.1002/pan3.10045", "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more people living in cities, we are witnessing a decline in exposure to\nnature. A growing body of research has demonstrated an association between\nnature contact and improved mood. Here, we used Twitter and the Hedonometer, a\nworld analysis tool, to investigate how sentiment, or the estimated happiness\nof the words people write, varied before, during, and after visits to San\nFrancisco's urban park system. We found that sentiment was substantially higher\nduring park visits and remained elevated for several hours following the visit.\nLeveraging differences in vegetative cover across park types, we explored how\ndifferent types of outdoor public spaces may contribute to subjective\nwell-being. Tweets during visits to Regional Parks, which are greener and have\ngreater vegetative cover, exhibited larger increases in sentiment than tweets\nduring visits to Civic Plazas and Squares. Finally, we analyzed word\nfrequencies to explore several mechanisms theorized to link nature exposure\nwith mental and cognitive benefits. Negation words such as 'no', 'not', and\n'don't' decreased in frequency during visits to urban parks. These results can\nbe used by urban planners and public health officials to better target nature\ncontact recommendations for growing urban populations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:09:44 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 19:15:05 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Schwartz", "Aaron J.", ""], ["Dodds", "Peter Sheridan", ""], ["O'Neil-Dunne", "Jarlath P. M.", ""], ["Danforth", "Christopher M.", ""], ["Ricketts", "Taylor H.", ""]]}, {"id": "1807.08000", "submitter": "Chandra Khatri", "authors": "Chandra Khatri, Gyanit Singh, Nish Parikh", "title": "Abstractive and Extractive Text Summarization using Document Context\n  Vector and Recurrent Neural Networks", "comments": "ACM KDD 2018 Deep Learning Day", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence (Seq2Seq) learning has recently been used for\nabstractive and extractive summarization. In current study, Seq2Seq models have\nbeen used for eBay product description summarization. We propose a novel\nDocument-Context based Seq2Seq models using RNNs for abstractive and extractive\nsummarizations. Intuitively, this is similar to humans reading the title,\nabstract or any other contextual information before reading the document. This\ngives humans a high-level idea of what the document is about. We use this idea\nand propose that Seq2Seq models should be started with contextual information\nat the first time-step of the input to obtain better summaries. In this manner,\nthe output summaries are more document centric, than being generic, overcoming\none of the major hurdles of using generative models. We generate\ndocument-context from user-behavior and seller provided information. We train\nand evaluate our models on human-extracted-golden-summaries. The\ndocument-contextual Seq2Seq models outperform standard Seq2Seq models.\nMoreover, generating human extracted summaries is prohibitively expensive to\nscale, we therefore propose a semi-supervised technique for extracting\napproximate summaries and using it for training Seq2Seq models at scale.\nSemi-supervised models are evaluated against human extracted summaries and are\nfound to be of similar efficacy. We provide side by side comparison for\nabstractive and extractive summarizers (contextual and non-contextual) on same\nevaluation dataset. Overall, we provide methodologies to use and evaluate the\nproposed techniques for large document summarization. Furthermore, we found\nthese techniques to be highly effective, which is not the case with existing\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:56:32 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 09:59:43 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Khatri", "Chandra", ""], ["Singh", "Gyanit", ""], ["Parikh", "Nish", ""]]}, {"id": "1807.08074", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, Felix Gervits, Cory J. Hayes, Anton Leuski, Pooja\n  Moolchandani, John G. Rogers III, Carlos Sanchez Amaro, Matthew Marge, Clare\n  R. Voss, David Traum", "title": "ScoutBot: A Dialogue System for Collaborative Navigation", "comments": "Originally published in the Proceedings of the Association for\n  Computational Linguistics (ACL) 2018, System Demonstrations, 93-98", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ScoutBot is a dialogue interface to physical and simulated robots that\nsupports collaborative exploration of environments. The demonstration will\nallow users to issue unconstrained spoken language commands to ScoutBot.\nScoutBot will prompt for clarification if the user's instruction needs\nadditional input. It is trained on human-robot dialogue collected from\nWizard-of-Oz experiments, where robot responses were initiated by a human\nwizard in previous interactions. The demonstration will show a simulated ground\nrobot (Clearpath Jackal) in a simulated environment supported by ROS (Robot\nOperating System).\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 03:12:36 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Gervits", "Felix", ""], ["Hayes", "Cory J.", ""], ["Leuski", "Anton", ""], ["Moolchandani", "Pooja", ""], ["Rogers", "John G.", "III"], ["Amaro", "Carlos Sanchez", ""], ["Marge", "Matthew", ""], ["Voss", "Clare R.", ""], ["Traum", "David", ""]]}, {"id": "1807.08076", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, Kimberly A. Pollard, Claire Bonial, Matthew Marge,\n  Cassidy Henry, Ron Arstein, David Traum, Clare R. Voss", "title": "Consequences and Factors of Stylistic Differences in Human-Robot\n  Dialogue", "comments": "Originally published in the Proceedings of the 19th Annual Meeting of\n  the Special Interest Group on Discourse and Dialogue (SIGDIAL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper identifies stylistic differences in instruction-giving observed in\na corpus of human-robot dialogue. Differences in verbosity and structure (i.e.,\nsingle-intent vs. multi-intent instructions) arose naturally without\nrestrictions or prior guidance on how users should speak with the robot.\nDifferent styles were found to produce different rates of miscommunication, and\ncorrelations were found between style differences and individual user\nvariation, trust, and interaction experience with the robot. Understanding\npotential consequences and factors that influence style can inform design of\ndialogue systems that are robust to natural variation from human users.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 03:21:56 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Pollard", "Kimberly A.", ""], ["Bonial", "Claire", ""], ["Marge", "Matthew", ""], ["Henry", "Cassidy", ""], ["Arstein", "Ron", ""], ["Traum", "David", ""], ["Voss", "Clare R.", ""]]}, {"id": "1807.08077", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, Reginald Hobbs, Clare R. Voss", "title": "A Pipeline for Creative Visual Storytelling", "comments": "Originally published in the Proceedings of the First Workshop on\n  Storytelling (StoryNLP), 2018, at the North American Association for\n  Computational Linguistics (NAACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational visual storytelling produces a textual description of events\nand interpretations depicted in a sequence of images. These texts are made\npossible by advances and cross-disciplinary approaches in natural language\nprocessing, generation, and computer vision. We define a computational creative\nvisual storytelling as one with the ability to alter the telling of a story\nalong three aspects: to speak about different environments, to produce\nvariations based on narrative goals, and to adapt the narrative to the\naudience. These aspects of creative storytelling and their effect on the\nnarrative have yet to be explored in visual storytelling. This paper presents a\npipeline of task-modules, Object Identification, Single-Image Inferencing, and\nMulti-Image Narration, that serve as a preliminary design for building a\ncreative visual storyteller. We have piloted this design for a sequence of\nimages in an annotation task. We present and analyze the collected corpus and\ndescribe plans towards automation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 03:33:50 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Hobbs", "Reginald", ""], ["Voss", "Clare R.", ""]]}, {"id": "1807.08089", "submitter": "Yi-Chen Chen", "authors": "Yi-Chen Chen, Sung-Feng Huang, Chia-Hao Shen, Hung-yi Lee, Lin-shan\n  Lee", "title": "Phonetic-and-Semantic Embedding of Spoken Words with Applications in\n  Spoken Content Retrieval", "comments": "Accepted at SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding or Word2Vec has been successful in offering semantics for text\nwords learned from the context of words. Audio Word2Vec was shown to offer\nphonetic structures for spoken words (signal segments for words) learned from\nsignals within spoken words. This paper proposes a two-stage framework to\nperform phonetic-and-semantic embedding on spoken words considering the context\nof the spoken words. Stage 1 performs phonetic embedding with speaker\ncharacteristics disentangled. Stage 2 then performs semantic embedding in\naddition. We further propose to evaluate the phonetic-and-semantic nature of\nthe audio embeddings obtained in Stage 2 by parallelizing with text embeddings.\nIn general, phonetic structure and semantics inevitably disturb each other. For\nexample the words \"brother\" and \"sister\" are close in semantics but very\ndifferent in phonetic structure, while the words \"brother\" and \"bother\" are in\nthe other way around. But phonetic-and-semantic embedding is attractive, as\nshown in the initial experiments on spoken document retrieval. Not only spoken\ndocuments including the spoken query can be retrieved based on the phonetic\nstructures, but spoken documents semantically related to the query but not\nincluding the query can also be retrieved based on the semantics.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 06:07:46 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 06:32:06 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2018 17:24:57 GMT"}, {"version": "v4", "created": "Sat, 19 Jan 2019 06:27:32 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Chen", "Yi-Chen", ""], ["Huang", "Sung-Feng", ""], ["Shen", "Chia-Hao", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1807.08133", "submitter": "John Kelleher", "authors": "John D. Kelleher and Simon Dobnik", "title": "What is not where: the challenge of integrating spatial representations\n  into deep learning architectures", "comments": "15 pages, 10 figures, Appears in CLASP Papers in Computational\n  Linguistics Vol 1: Proceedings of the Conference on Logic and Machine\n  Learning in Natural Language (LaML 2017), pp. 41-52", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines to what degree current deep learning architectures for\nimage caption generation capture spatial language. On the basis of the\nevaluation of examples of generated captions from the literature we argue that\nsystems capture what objects are in the image data but not where these objects\nare located: the captions generated by these systems are the output of a\nlanguage model conditioned on the output of an object detector that cannot\ncapture fine-grained location information. Although language models provide\nuseful knowledge for image captions, we argue that deep learning image\ncaptioning architectures should also model geometric relations between objects.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:55:17 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kelleher", "John D.", ""], ["Dobnik", "Simon", ""]]}, {"id": "1807.08204", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Matko Bosnjak, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "Towards Neural Theorem Proving at Scale", "comments": "Federated Artificial Intelligence Meeting (FAIM) Workshop on Neural\n  Abstract Machines & Program Induction v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models combining representation learning and reasoning in an\nend-to-end trainable manner are receiving increasing interest. However, their\nuse is severely limited by their computational complexity, which renders them\nunusable on real world datasets. We focus on the Neural Theorem Prover (NTP)\nmodel proposed by Rockt{\\\"{a}}schel and Riedel (2017), a continuous relaxation\nof the Prolog backward chaining algorithm where unification between terms is\nreplaced by the similarity between their embedding representations. For\nanswering a given query, this model needs to consider all possible proof paths,\nand then aggregate results - this quickly becomes infeasible even for small\nKnowledge Bases (KBs). We observe that we can accurately approximate the\ninference process in this model by considering only proof paths associated with\nthe highest proof scores. This enables inference and learning on previously\nimpracticable KBs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 20:48:53 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Minervini", "Pasquale", ""], ["Bosnjak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1807.08228", "submitter": "Yuanhang Su", "authors": "Yuanhang Su, Ruiyuan Lin, C.-C. Jay Kuo", "title": "Tree-structured multi-stage principal component analysis (TMPCA): theory\n  and applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2018.10.020", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A PCA based sequence-to-vector (seq2vec) dimension reduction method for the\ntext classification problem, called the tree-structured multi-stage principal\ncomponent analysis (TMPCA) is presented in this paper. Theoretical analysis and\napplicability of TMPCA are demonstrated as an extension to our previous work\n(Su, Huang & Kuo). Unlike conventional word-to-vector embedding methods, the\nTMPCA method conducts dimension reduction at the sequence level without labeled\ntraining data. Furthermore, it can preserve the sequential structure of input\nsequences. We show that TMPCA is computationally efficient and able to\nfacilitate sequence-based text classification tasks by preserving strong mutual\ninformation between its input and output mathematically. It is also\ndemonstrated by experimental results that a dense (fully connected) network\ntrained on the TMPCA preprocessed data achieves better performance than\nstate-of-the-art fastText and other neural-network-based solutions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 03:15:44 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 04:26:25 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Su", "Yuanhang", ""], ["Lin", "Ruiyuan", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1807.08230", "submitter": "Shervin Malmasi", "authors": "Alina Maria Ciobanu, Shervin Malmasi, Liviu P. Dinu", "title": "German Dialect Identification Using Classifier Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the GDI_classification entry to the second German\nDialect Identification (GDI) shared task organized within the scope of the\nVarDial Evaluation Campaign 2018. We present a system based on SVM classifier\nensembles trained on characters and words. The system was trained on a\ncollection of speech transcripts of five Swiss-German dialects provided by the\norganizers. The transcripts included in the dataset contained speakers from\nBasel, Bern, Lucerne, and Zurich. Our entry in the challenge reached 62.03%\nF1-score and was ranked third out of eight teams.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 03:20:19 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ciobanu", "Alina Maria", ""], ["Malmasi", "Shervin", ""], ["Dinu", "Liviu P.", ""]]}, {"id": "1807.08280", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Multi-scale Alignment and Contextual History for Attention Mechanism in\n  Sequence-to-sequence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequence-to-sequence model is a neural network module for mapping two\nsequences of different lengths. The sequence-to-sequence model has three core\nmodules: encoder, decoder, and attention. Attention is the bridge that connects\nthe encoder and decoder modules and improves model performance in many tasks.\nIn this paper, we propose two ideas to improve sequence-to-sequence model\nperformance by enhancing the attention module. First, we maintain the history\nof the location and the expected context from several previous time-steps.\nSecond, we apply multiscale convolution from several previous attention vectors\nto the current decoder state. We utilized our proposed framework for\nsequence-to-sequence speech recognition and text-to-speech systems. The results\nreveal that our proposed extension could improve performance significantly\ncompared to a standard attention baseline.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 13:10:30 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1807.08374", "submitter": "Chao Lu", "authors": "Chao Lu, Yi Bu, Jie Wang, Ying Ding, Vetle Torvik, Matthew Schnaars,\n  Chengzhi Zhang", "title": "Examining Scientific Writing Styles from the Perspective of Linguistic\n  Complexity", "comments": "6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Publishing articles in high-impact English journals is difficult for scholars\naround the world, especially for non-native English-speaking scholars (NNESs),\nmost of whom struggle with proficiency in English. In order to uncover the\ndifferences in English scientific writing between native English-speaking\nscholars (NESs) and NNESs, we collected a large-scale data set containing more\nthan 150,000 full-text articles published in PLoS between 2006 and 2015. We\ndivided these articles into three groups according to the ethnic backgrounds of\nthe first and corresponding authors, obtained by Ethnea, and examined the\nscientific writing styles in English from a two-fold perspective of linguistic\ncomplexity: (1) syntactic complexity, including measurements of sentence length\nand sentence complexity; and (2) lexical complexity, including measurements of\nlexical diversity, lexical density, and lexical sophistication. The\nobservations suggest marginal differences between groups in syntactical and\nlexical complexity.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 21:35:01 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 02:36:57 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Lu", "Chao", ""], ["Bu", "Yi", ""], ["Wang", "Jie", ""], ["Ding", "Ying", ""], ["Torvik", "Vetle", ""], ["Schnaars", "Matthew", ""], ["Zhang", "Chengzhi", ""]]}, {"id": "1807.08435", "submitter": "Linghao Zhang", "authors": "Prakruthi Prabhakar, Nitish Kulkarni, Linghao Zhang", "title": "Question Relevance in Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Free-form and open-ended Visual Question Answering systems solve the problem\nof providing an accurate natural language answer to a question pertaining to an\nimage. Current VQA systems do not evaluate if the posed question is relevant to\nthe input image and hence provide nonsensical answers when posed with\nirrelevant questions to an image. In this paper, we solve the problem of\nidentifying the relevance of the posed question to an image. We address the\nproblem as two sub-problems. We first identify if the question is visual or\nnot. If the question is visual, we then determine if it's relevant to the image\nor not. For the second problem, we generate a large dataset from existing\nvisual question answering datasets in order to enable the training of complex\narchitectures and model the relevance of a visual question to an image. We also\ncompare the results of our Long Short-Term Memory Recurrent Neural Network\nbased models to Logistic Regression, XGBoost and multi-layer perceptron based\napproaches to the problem.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:01:44 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Prabhakar", "Prakruthi", ""], ["Kulkarni", "Nitish", ""], ["Zhang", "Linghao", ""]]}, {"id": "1807.08447", "submitter": "Rakshit Trivedi", "authors": "Rakshit Trivedi and Bunyamin Sisman and Jun Ma and Christos Faloutsos\n  and Hongyuan Zha and Xin Luna Dong", "title": "LinkNBed: Multi-Graph Representation Learning with Entity Linkage", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs have emerged as an important model for studying complex\nmulti-relational data. This has given rise to the construction of numerous\nlarge scale but incomplete knowledge graphs encoding information extracted from\nvarious resources. An effective and scalable approach to jointly learn over\nmultiple graphs and eventually construct a unified graph is a crucial next step\nfor the success of knowledge-based inference for many downstream applications.\nTo this end, we propose LinkNBed, a deep relational learning framework that\nlearns entity and relationship representations across multiple graphs. We\nidentify entity linkage across graphs as a vital component to achieve our goal.\nWe design a novel objective that leverage entity linkage and build an efficient\nmulti-task training procedure. Experiments on link prediction and entity\nlinkage demonstrate substantial improvements over the state-of-the-art\nrelational learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:47:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Trivedi", "Rakshit", ""], ["Sisman", "Bunyamin", ""], ["Ma", "Jun", ""], ["Faloutsos", "Christos", ""], ["Zha", "Hongyuan", ""], ["Dong", "Xin Luna", ""]]}, {"id": "1807.08465", "submitter": "Philipp Blandfort", "authors": "Philipp Blandfort, Desmond Patton, William R. Frey, Svebor Karaman,\n  Surabhi Bhargava, Fei-Tzin Lee, Siddharth Varia, Chris Kedzie, Michael B.\n  Gaskell, Rossano Schifanella, Kathleen McKeown, Shih-Fu Chang", "title": "Multimodal Social Media Analysis for Gang Violence Prevention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gang violence is a severe issue in major cities across the U.S. and recent\nstudies [Patton et al. 2017] have found evidence of social media communications\nthat can be linked to such violence in communities with high rates of exposure\nto gang activity. In this paper we partnered computer scientists with social\nwork researchers, who have domain expertise in gang violence, to analyze how\npublic tweets with images posted by youth who mention gang associations on\nTwitter can be leveraged to automatically detect psychosocial factors and\nconditions that could potentially assist social workers and violence outreach\nworkers in prevention and early intervention programs. To this end, we\ndeveloped a rigorous methodology for collecting and annotating tweets. We\ngathered 1,851 tweets and accompanying annotations related to visual concepts\nand the psychosocial codes: aggression, loss, and substance use. These codes\nare relevant to social work interventions, as they represent possible pathways\nto violence on social media. We compare various methods for classifying tweets\ninto these three classes, using only the text of the tweet, only the image of\nthe tweet, or both modalities as input to the classifier. In particular, we\nanalyze the usefulness of mid-level visual concepts and the role of different\nmodalities for this tweet classification task. Our experiments show that\nindividually, text information dominates classification performance of the loss\nclass, while image information dominates the aggression and substance use\nclasses. Our multimodal approach provides a very promising improvement (18%\nrelative in mean average precision) over the best single modality approach.\nFinally, we also illustrate the complexity of understanding social media data\nand elaborate on open challenges.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 07:52:52 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Blandfort", "Philipp", ""], ["Patton", "Desmond", ""], ["Frey", "William R.", ""], ["Karaman", "Svebor", ""], ["Bhargava", "Surabhi", ""], ["Lee", "Fei-Tzin", ""], ["Varia", "Siddharth", ""], ["Kedzie", "Chris", ""], ["Gaskell", "Michael B.", ""], ["Schifanella", "Rossano", ""], ["McKeown", "Kathleen", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1807.08484", "submitter": "Wang Ruijie", "authors": "Ruijie Wang, Yuchen Yan, Jialu Wang, Yuting Jia, Ye Zhang, Weinan\n  Zhang, Xinbing Wang", "title": "AceKG: A Large-scale Knowledge Graph for Academic Data Mining", "comments": "CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing knowledge graphs (KGs) in academic domains suffer from problems\nof insufficient multi-relational information, name ambiguity and improper data\nformat for large-scale machine processing. In this paper, we present AceKG, a\nnew large-scale KG in academic domain. AceKG not only provides clean academic\ninformation, but also offers a large-scale benchmark dataset for researchers to\nconduct challenging data mining projects including link prediction, community\ndetection and scholar classification. Specifically, AceKG describes 3.13\nbillion triples of academic facts based on a consistent ontology, including\nnecessary properties of papers, authors, fields of study, venues and\ninstitutes, as well as the relations among them. To enrich the proposed\nknowledge graph, we also perform entity alignment with existing databases and\nrule-based inference. Based on AceKG, we conduct experiments of three typical\nacademic data mining tasks and evaluate several state-of- the-art knowledge\nembedding and network representation learning approaches on the benchmark\ndatasets built from AceKG. Finally, we discuss several promising research\ndirections that benefit from AceKG.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 08:57:44 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 07:46:48 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wang", "Ruijie", ""], ["Yan", "Yuchen", ""], ["Wang", "Jialu", ""], ["Jia", "Yuting", ""], ["Zhang", "Ye", ""], ["Zhang", "Weinan", ""], ["Wang", "Xinbing", ""]]}, {"id": "1807.08587", "submitter": "Eug\\'enio Ribeiro", "authors": "Eug\\'enio Ribeiro, Ricardo Ribeiro, and David Martins de Matos", "title": "Deep Dialog Act Recognition using Multiple Token, Segment, and Context\n  Information Representations", "comments": "38 pages, 7 figures, 9 tables, submitted to JAIR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog act (DA) recognition is a task that has been widely explored over the\nyears. Recently, most approaches to the task explored different DNN\narchitectures to combine the representations of the words in a segment and\ngenerate a segment representation that provides cues for intention. In this\nstudy, we explore means to generate more informative segment representations,\nnot only by exploring different network architectures, but also by considering\ndifferent token representations, not only at the word level, but also at the\ncharacter and functional levels. At the word level, in addition to the commonly\nused uncontextualized embeddings, we explore the use of contextualized\nrepresentations, which provide information concerning word sense and segment\nstructure. Character-level tokenization is important to capture\nintention-related morphological aspects that cannot be captured at the word\nlevel. Finally, the functional level provides an abstraction from words, which\nshifts the focus to the structure of the segment. We also explore approaches to\nenrich the segment representation with context information from the history of\nthe dialog, both in terms of the classifications of the surrounding segments\nand the turn-taking history. This kind of information has already been proved\nimportant for the disambiguation of DAs in previous studies. Nevertheless, we\nare able to capture additional information by considering a summary of the\ndialog history and a wider turn-taking context. By combining the best\napproaches at each step, we achieve results that surpass the previous\nstate-of-the-art on generic DA recognition on both SwDA and MRDA, two of the\nmost widely explored corpora for the task. Furthermore, by considering both\npast and future context, simulating annotation scenario, our approach achieves\na performance similar to that of a human annotator on SwDA and surpasses it on\nMRDA.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:12:28 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 21:36:28 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ribeiro", "Eug\u00e9nio", ""], ["Ribeiro", "Ricardo", ""], ["de Matos", "David Martins", ""]]}, {"id": "1807.08666", "submitter": "Raghav Menon", "authors": "Raghav Menon, Herman Kamper, Emre Yilmaz, John Quinn, Thomas Niesler", "title": "ASR-free CNN-DTW keyword spotting using multilingual bottleneck features\n  for almost zero-resource languages", "comments": "5 pages, 3 figures, 3 tables, 1 equation accepted at SLTU 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multilingual bottleneck features (BNFs) for nearly zero-resource\nkeyword spotting. This forms part of a United Nations effort using keyword\nspotting to support humanitarian relief programmes in parts of Africa where\nlanguages are severely under-resourced. We use 1920 isolated keywords (40\ntypes, 34 minutes) as exemplars for dynamic time warping (DTW) template\nmatching, which is performed on a much larger body of untranscribed speech.\nThese DTW costs are used as targets for a convolutional neural network (CNN)\nkeyword spotter, giving a much faster system than direct DTW. Here we consider\nhow available data from well-resourced languages can improve this CNN-DTW\napproach. We show that multilingual BNFs trained on ten languages improve the\narea under the ROC curve of a CNN-DTW system by 10.9% absolute relative to the\nMFCC baseline. By combining low-resource DTW-based supervision with information\nfrom well-resourced languages, CNN-DTW is a competitive option for low-resource\nkeyword spotting.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 15:14:32 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Menon", "Raghav", ""], ["Kamper", "Herman", ""], ["Yilmaz", "Emre", ""], ["Quinn", "John", ""], ["Niesler", "Thomas", ""]]}, {"id": "1807.08669", "submitter": "Raghav Menon", "authors": "Raghav Menon, Astik Biswas, Armin Saeb, John Quinn and Thomas Niesler", "title": "Automatic Speech Recognition for Humanitarian Applications in Somali", "comments": "5 pages, 3 figures, 5 tables accepted at SLTU 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our first efforts in building an automatic speech recognition\nsystem for Somali, an under-resourced language, using 1.57 hrs of annotated\nspeech for acoustic model training. The system is part of an ongoing effort by\nthe United Nations (UN) to implement keyword spotting systems supporting\nhumanitarian relief programmes in parts of Africa where languages are severely\nunder-resourced. We evaluate several types of acoustic model, including recent\nneural architectures. Language model data augmentation using a combination of\nrecurrent neural networks (RNN) and long short-term memory neural networks\n(LSTMs) as well as the perturbation of acoustic data are also considered. We\nfind that both types of data augmentation are beneficial to performance, with\nour best system using a combination of convolutional neural networks (CNNs),\ntime-delay neural networks (TDNNs) and bi-directional long short term memory\n(BLSTMs) to achieve a word error rate of 53.75%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 15:17:04 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Menon", "Raghav", ""], ["Biswas", "Astik", ""], ["Saeb", "Armin", ""], ["Quinn", "John", ""], ["Niesler", "Thomas", ""]]}, {"id": "1807.08945", "submitter": "Biao Zhang", "authors": "Jing Yang, Biao Zhang, Yue Qin, Xiangwen Zhang, Qian Lin and Jinsong\n  Su", "title": "Otem&Utem: Over- and Under-Translation Evaluation Metric for NMT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation(NMT) yields promising translation\nperformance, it unfortunately suffers from over- and under-translation is- sues\n[Tu et al., 2016], of which studies have become research hotspots in NMT. At\npresent, these studies mainly apply the dominant automatic evaluation metrics,\nsuch as BLEU, to evaluate the overall translation quality with respect to both\nadequacy and uency. However, they are unable to accurately measure the ability\nof NMT systems in dealing with the above-mentioned issues. In this paper, we\npropose two quantitative metrics, the Otem and Utem, to automatically evaluate\nthe system perfor- mance in terms of over- and under-translation respectively.\nBoth metrics are based on the proportion of mismatched n-grams between gold\nref- erence and system translation. We evaluate both metrics by comparing their\nscores with human evaluations, where the values of Pearson Cor- relation\nCoefficient reveal their strong correlation. Moreover, in-depth analyses on\nvarious translation systems indicate some inconsistency be- tween BLEU and our\nproposed metrics, highlighting the necessity and significance of our metrics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 08:09:22 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Yang", "Jing", ""], ["Zhang", "Biao", ""], ["Qin", "Yue", ""], ["Zhang", "Xiangwen", ""], ["Lin", "Qian", ""], ["Su", "Jinsong", ""]]}, {"id": "1807.08998", "submitter": "Steffen Eger", "authors": "Steffen Eger and Johannes Daxenberger and Christian Stab and Iryna\n  Gurevych", "title": "Cross-lingual Argumentation Mining: Machine Translation (and a bit of\n  Projection) is All You Need!", "comments": "Accepted at Coling 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation mining (AM) requires the identification of complex discourse\nstructures and has lately been applied with success monolingually. In this\nwork, we show that the existing resources are, however, not adequate for\nassessing cross-lingual AM, due to their heterogeneity or lack of complexity.\nWe therefore create suitable parallel corpora by (human and machine)\ntranslating a popular AM dataset consisting of persuasive student essays into\nGerman, French, Spanish, and Chinese. We then compare (i) annotation projection\nand (ii) bilingual word embeddings based direct transfer strategies for\ncross-lingual AM, finding that the former performs considerably better and\nalmost eliminates the loss from cross-lingual transfer. Moreover, we find that\nannotation projection works equally well when using either costly human or\ncheap machine translations. Our code and data are available at\n\\url{http://github.com/UKPLab/coling2018-xling_argument_mining}.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:48:43 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Eger", "Steffen", ""], ["Daxenberger", "Johannes", ""], ["Stab", "Christian", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1807.09000", "submitter": "Robert Hawkins", "authors": "Robert D. Hawkins, Hyowon Gweon, Noah D. Goodman", "title": "The division of labor in communication: Speakers help listeners account\n  for asymmetries in visual perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent debates over adults' theory of mind use have been fueled by surprising\nfailures of perspective-taking in communication, suggesting that\nperspective-taking can be relatively effortful. How, then, should speakers and\nlisteners allocate their resources to achieve successful communication? We\nbegin with the observation that this shared goal induces a natural division of\nlabor: the resources one agent chooses to allocate toward perspective-taking\nshould depend on their expectations about the other's allocation. We formalize\nthis idea in a resource-rational model augmenting recent probabilistic\nweighting accounts with a mechanism for (costly) control over the degree of\nperspective-taking. In a series of simulations, we first derive an intermediate\ndegree of perspective weighting as an optimal tradeoff between expected costs\nand benefits of perspective-taking. We then present two behavioral experiments\ntesting novel predictions of our model. In Experiment 1, we manipulated the\npresence or absence of occlusions in a director-matcher task and found that\nspeakers spontaneously produced more informative descriptions to account for\n\"known unknowns\" in their partner's private view. In Experiment 2, we compared\nthe scripted utterances used by confederates in prior work with those produced\nin interactions with unscripted directors. We found that confederates were\nsystematically less informative than listeners would initially expect given the\npresence of occlusions, but listeners used violations to adaptively make fewer\nerrors over time. Taken together, our work suggests that people are not simply\n\"mindblind\"; they use contextually appropriate expectations to navigate the\ndivision of labor with their partner. We discuss how a resource rational\nframework may provide a more deeply explanatory foundation for understanding\nflexible perspective-taking under processing constraints.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:56:53 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 07:44:51 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 20:07:38 GMT"}, {"version": "v4", "created": "Mon, 11 May 2020 23:48:15 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Hawkins", "Robert D.", ""], ["Gweon", "Hyowon", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1807.09433", "submitter": "Kai Fan Dr", "authors": "Kai Fan, Jiayi Wang, Bo Li, Fengming Zhou, Boxing Chen, Luo Si", "title": "\"Bilingual Expert\" Can Find Translation Errors", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in statistical machine translation via the adoption of neural\nsequence-to-sequence models empower the end-to-end system to achieve\nstate-of-the-art in many WMT benchmarks. The performance of such machine\ntranslation (MT) system is usually evaluated by automatic metric BLEU when the\ngolden references are provided for validation. However, for model inference or\nproduction deployment, the golden references are prohibitively available or\nrequire expensive human annotation with bilingual expertise. In order to\naddress the issue of quality evaluation (QE) without reference, we propose a\ngeneral framework for automatic evaluation of translation output for most WMT\nquality evaluation tasks. We first build a conditional target language model\nwith a novel bidirectional transformer, named neural bilingual expert model,\nwhich is pre-trained on large parallel corpora for feature extraction. For QE\ninference, the bilingual expert model can simultaneously produce the joint\nlatent representation between the source and the translation, and real-valued\nmeasurements of possible erroneous tokens based on the prior knowledge learned\nfrom parallel data. Subsequently, the features will further be fed into a\nsimple Bi-LSTM predictive model for quality evaluation. The experimental\nresults show that our approach achieves the state-of-the-art performance in the\nquality estimation track of WMT 2017/2018.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 04:31:21 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 18:11:33 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 23:57:52 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Fan", "Kai", ""], ["Wang", "Jiayi", ""], ["Li", "Bo", ""], ["Zhou", "Fengming", ""], ["Chen", "Boxing", ""], ["Si", "Luo", ""]]}, {"id": "1807.09434", "submitter": "Boeun Kim", "authors": "Boeun Kim, Young Han Lee, Hyedong Jung and Choongsang Cho", "title": "Distinctive-attribute Extraction for Image Captioning", "comments": "14 main pages, 4 supplementary pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning, an open research issue, has been evolved with the progress\nof deep neural networks. Convolutional neural networks (CNNs) and recurrent\nneural networks (RNNs) are employed to compute image features and generate\nnatural language descriptions in the research. In previous works, a caption\ninvolving semantic description can be generated by applying additional\ninformation into the RNNs. In this approach, we propose a distinctive-attribute\nextraction (DaE) which explicitly encourages significant meanings to generate\nan accurate caption describing the overall meaning of the image with their\nunique situation. Specifically, the captions of training images are analyzed by\nterm frequency-inverse document frequency (TF-IDF), and the analyzed semantic\ninformation is trained to extract distinctive-attributes for inferring\ncaptions. The proposed scheme is evaluated on a challenge data, and it improves\nan objective performance while describing images in more detail.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 04:34:17 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Kim", "Boeun", ""], ["Lee", "Young Han", ""], ["Jung", "Hyedong", ""], ["Cho", "Choongsang", ""]]}, {"id": "1807.09561", "submitter": "Lewis Mitchell", "authors": "Ahmad Hany Hossny, Terry Moschou, Grant Osborne, Lewis Mitchell, Nick\n  Lothian", "title": "Enhancing keyword correlation for event detection in social networks\n  using SVD and k-means: Twitter case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting textual features from tweets is a challenging process due to the\nnoisy nature of the content and the weak signal of most of the words used. In\nthis paper, we propose using singular value decomposition (SVD) with clustering\nto enhance the signals of the textual features in the tweets to improve the\ncorrelation with events. The proposed technique applies SVD to the time series\nvector for each feature to factorize the matrix of feature/day counts, in order\nto ensure the independence of the feature vectors. Afterwards, the k-means\nclustering is applied to build a look-up table that maps members of each\ncluster to the cluster-centroid. The lookup table is used to map each feature\nin the original data to the centroid of its cluster, then we calculate the sum\nof the term frequency vectors of all features in each cluster to the\nterm-frequency-vector of the cluster centroid. To test the technique we\ncalculated the correlations of the cluster centroids with the golden standard\nrecord (GSR) vector before and after summing the vectors of the cluster members\nto the centroid-vector. The proposed method is applied to multiple correlation\ntechniques including the Pearson, Spearman, distance correlation and Kendal\nTao. The experiments have also considered the different word forms and lengths\nof the features including keywords, n-grams, skip-grams and bags-of-words. The\ncorrelation results are enhanced significantly as the highest correlation\nscores have increased from 0.3 to 0.6, and the average correlation scores have\nincreased from 0.3 to 0.4.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 12:56:25 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Hossny", "Ahmad Hany", ""], ["Moschou", "Terry", ""], ["Osborne", "Grant", ""], ["Mitchell", "Lewis", ""], ["Lothian", "Nick", ""]]}, {"id": "1807.09597", "submitter": "Shruti Palaskar", "authors": "Shruti Palaskar and Florian Metze", "title": "Acoustic-to-Word Recognition with Sequence-to-Sequence Models", "comments": "9 pages, 3 figures, Under Review at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic-to-Word recognition provides a straightforward solution to\nend-to-end speech recognition without needing external decoding, language model\nre-scoring or lexicon. While character-based models offer a natural solution to\nthe out-of-vocabulary problem, word models can be simpler to decode and may\nalso be able to directly recognize semantically meaningful units. We present\neffective methods to train Sequence-to-Sequence models for direct word-level\nrecognition (and character-level recognition) and show an absolute improvement\nof 4.4-5.0\\% in Word Error Rate on the Switchboard corpus compared to prior\nwork. In addition to these promising results, word-based models are more\ninterpretable than character models, which have to be composed into words using\na separate decoding step. We analyze the encoder hidden states and the\nattention behavior, and show that location-aware attention naturally represents\nwords as a single speech-word-vector, despite spanning multiple frames in the\ninput. We finally show that the Acoustic-to-Word model also learns to segment\nspeech into words with a mean standard deviation of 3 frames as compared with\nhuman annotated forced-alignments for the Switchboard corpus.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:29:43 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 11:28:14 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Palaskar", "Shruti", ""], ["Metze", "Florian", ""]]}, {"id": "1807.09602", "submitter": "Seyed Mahdi Rezaeinia", "authors": "Seyed Mahdi Rezaeinia, Ali Ghodsi, Rouhollah Rahmani", "title": "Text Classification based on Multiple Block Convolutional Highways", "comments": "arXiv admin note: text overlap with arXiv:1711.08609", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Text Classification areas of Sentiment Analysis,\nSubjectivity/Objectivity Analysis, and Opinion Polarity, Convolutional Neural\nNetworks have gained special attention because of their performance and\naccuracy. In this work, we applied recent advances in CNNs and propose a novel\narchitecture, Multiple Block Convolutional Highways (MBCH), which achieves\nimproved accuracy on multiple popular benchmark datasets, compared to previous\narchitectures. The MBCH is based on new techniques and architectures including\nhighway networks, DenseNet, batch normalization and bottleneck layers. In\naddition, to cope with the limitations of existing pre-trained word vectors\nwhich are used as inputs for the CNN, we propose a novel method, Improved Word\nVectors (IWV). The IWV improves the accuracy of CNNs which are used for text\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:58:38 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Rezaeinia", "Seyed Mahdi", ""], ["Ghodsi", "Ali", ""], ["Rahmani", "Rouhollah", ""]]}, {"id": "1807.09623", "submitter": "Alon Talmor", "authors": "Alon Talmor and Jonathan Berant", "title": "Repartitioning of the ComplexWebQuestions Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Talmor and Berant (2018) introduced ComplexWebQuestions - a dataset\nfocused on answering complex questions by decomposing them into a sequence of\nsimpler questions and extracting the answer from retrieved web snippets. In\ntheir work the authors used a pre-trained reading comprehension (RC) model\n(Salant and Berant, 2018) to extract the answer from the web snippets. In this\nshort note we show that training a RC model directly on the training data of\nComplexWebQuestions reveals a leakage from the training set to the test set\nthat allows to obtain unreasonably high performance. As a solution, we\nconstruct a new partitioning of ComplexWebQuestions that does not suffer from\nthis leakage and publicly release it. We also perform an empirical evaluation\non these two datasets and show that training a RC model on the training data\nsubstantially improves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:15:40 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1807.09639", "submitter": "Yingting Wu", "authors": "Yingting Wu and Hai Zhao", "title": "Finding Better Subword Segmentation for Neural Machine Translation", "comments": "12 pages, accepted by CCL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For different language pairs, word-level neural machine translation (NMT)\nmodels with a fixed-size vocabulary suffer from the same problem of\nrepresenting out-of-vocabulary (OOV) words. The common practice usually\nreplaces all these rare or unknown words with a <UNK> token, which limits the\ntranslation performance to some extent. Most of recent work handled such a\nproblem by splitting words into characters or other specially extracted subword\nunits to enable open-vocabulary translation. Byte pair encoding (BPE) is one of\nthe successful attempts that has been shown extremely competitive by providing\neffective subword segmentation for NMT systems. In this paper, we extend the\nBPE style segmentation to a general unsupervised framework with three\nstatistical measures: frequency (FRQ), accessor variety (AV) and description\nlength gain (DLG). We test our approach on two translation tasks: German to\nEnglish and Chinese to English. The experimental results show that AV and DLG\nenhanced systems outperform the FRQ baseline in the frequency weighted schemes\nat different significant levels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:43:46 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Wu", "Yingting", ""], ["Zhao", "Hai", ""]]}, {"id": "1807.09671", "submitter": "Wencan Luo", "authors": "Wencan Luo, Fei Liu, Zitao Liu, and Diane Litman", "title": "A Novel ILP Framework for Summarizing Content with High Lexical Variety", "comments": "Accepted for publication in the journal of Natural Language\n  Engineering, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing content contributed by individuals can be challenging, because\npeople make different lexical choices even when describing the same events.\nHowever, there remains a significant need to summarize such content. Examples\ninclude the student responses to post-class reflective questions, product\nreviews, and news articles published by different news agencies related to the\nsame events. High lexical diversity of these documents hinders the system's\nability to effectively identify salient content and reduce summary redundancy.\nIn this paper, we overcome this issue by introducing an integer linear\nprogramming-based summarization framework. It incorporates a low-rank\napproximation to the sentence-word co-occurrence matrix to intrinsically group\nsemantically-similar lexical items. We conduct extensive experiments on\ndatasets of student responses, product reviews, and news documents. Our\napproach compares favorably to a number of extractive baselines as well as a\nneural abstractive summarization system. The paper finally sheds light on when\nand why the proposed framework is effective at summarizing content with high\nlexical variety.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 15:42:01 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Luo", "Wencan", ""], ["Liu", "Fei", ""], ["Liu", "Zitao", ""], ["Litman", "Diane", ""]]}, {"id": "1807.09842", "submitter": "Muhammad Mahbubur Rahman", "authors": "Muhammad Mahbubur Rahman, Tim Finin", "title": "Understanding and representing the semantics of large structured\n  documents", "comments": "10 pages, 6 figures, 28 references and 2 tables", "journal-ref": "Semantic Deep Learning at ISWC 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding large, structured documents like scholarly articles, requests\nfor proposals or business reports is a complex and difficult task. It involves\ndiscovering a document's overall purpose and subject(s), understanding the\nfunction and meaning of its sections and subsections, and extracting low level\nentities and facts about them. In this research, we present a deep learning\nbased document ontology to capture the general purpose semantic structure and\ndomain specific semantic concepts from a large number of academic articles and\nbusiness documents. The ontology is able to describe different functional parts\nof a document, which can be used to enhance semantic indexing for a better\nunderstanding by human beings and machines. We evaluate our models through\nextensive experiments on datasets of scholarly articles from arXiv and Request\nfor Proposal documents.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 04:14:51 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Finin", "Tim", ""]]}, {"id": "1807.09844", "submitter": "John Kelleher", "authors": "Simon Dobnik and John D. Kelleher", "title": "Modular Mechanistic Networks: On Bridging Mechanistic and\n  Phenomenological Models with Deep Neural Networks in Natural Language\n  Processing", "comments": "18 pages, 1 figure, Appears in CLASP Papers in Computational\n  Linguistics Vol. 1: Proceedings of the Conference on Logic and Machine\n  Learning in Natural Language (LaML 2017)", "journal-ref": "CLASP Papers in Computational Linguistics Vol. 1: Proceedings of\n  the Conference on Logic and Machine Learning in Natural Language (LaML 2017).\n  ISSN: 2002-9764. URI: http://hdl.handle.net/2077/54911", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) can be done using either top-down (theory\ndriven) and bottom-up (data driven) approaches, which we call mechanistic and\nphenomenological respectively. The approaches are frequently considered to\nstand in opposition to each other. Examining some recent approaches in deep\nlearning we argue that deep neural networks incorporate both perspectives and,\nfurthermore, that leveraging this aspect of deep learning may help in solving\ncomplex problems within language technology, such as modelling language and\nperception in the domain of spatial cognition.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:37:15 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 15:45:24 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Dobnik", "Simon", ""], ["Kelleher", "John D.", ""]]}, {"id": "1807.09875", "submitter": "Caio Corro", "authors": "Caio Corro, Ivan Titov", "title": "Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a\n  Structured Variational Autoencoder", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human annotation for syntactic parsing is expensive, and large resources are\navailable only for a fraction of languages. A question we ask is whether one\ncan leverage abundant unlabeled texts to improve syntactic parsers, beyond just\nusing the texts to obtain more generalisable lexical features (i.e. beyond word\nembeddings). To this end, we propose a novel latent-variable generative model\nfor semi-supervised syntactic dependency parsing. As exact inference is\nintractable, we introduce a differentiable relaxation to obtain approximate\nsamples and compute gradients with respect to the parser parameters. Our method\n(Differentiable Perturb-and-Parse) relies on differentiable dynamic programming\nover stochastically perturbed edge scores. We demonstrate effectiveness of our\napproach with experiments on English, French and Swedish.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 21:42:55 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 19:45:49 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Corro", "Caio", ""], ["Titov", "Ivan", ""]]}, {"id": "1807.09950", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran, Thin Nguyen and Svetha Venkatesh", "title": "Variational Memory Encoder-Decoder", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing variability while maintaining coherence is a core task in\nlearning to generate utterances in conversation. Standard neural\nencoder-decoder models and their extensions using conditional variational\nautoencoder often result in either trivial or digressive responses. To overcome\nthis, we explore a novel approach that injects variability into neural\nencoder-decoder via the use of external memory as a mixture model, namely\nVariational Memory Encoder-Decoder (VMED). By associating each memory read with\na mode in the latent mixture distribution at each timestep, our model can\ncapture the variability observed in sequential data such as natural\nconversations. We empirically compare the proposed model against other recent\napproaches on various conversational datasets. The results show that VMED\nconsistently achieves significant improvement over others in both metric-based\nand qualitative evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 04:41:30 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 06:18:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Nguyen", "Thin", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1807.10076", "submitter": "Georgios Balikas", "authors": "Georgios Balikas, Ga\\\"el Dias, Rumen Moraliyski, Massih-Reza Amini", "title": "Concurrent Learning of Semantic Relations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering whether words are semantically related and identifying the\nspecific semantic relation that holds between them is of crucial importance for\nNLP as it is essential for tasks like query expansion in IR. Within this\ncontext, different methodologies have been proposed that either exclusively\nfocus on a single lexical relation (e.g. hypernymy vs. random) or learn\nspecific classifiers capable of identifying multiple semantic relations (e.g.\nhypernymy vs. synonymy vs. random). In this paper, we propose another way to\nlook at the problem that relies on the multi-task learning paradigm. In\nparticular, we want to study whether the learning process of a given semantic\nrelation (e.g. hypernymy) can be improved by the concurrent learning of another\nsemantic relation (e.g. co-hyponymy). Within this context, we particularly\nexamine the benefits of semi-supervised learning where the training of a\nprediction function is performed over few labeled data jointly with many\nunlabeled ones. Preliminary results based on simple learning strategies and\nstate-of-the-art distributional feature representations show that concurrent\nlearning can lead to improvements in a vast majority of tested situations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 11:44:19 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 11:41:55 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 08:33:13 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Balikas", "Georgios", ""], ["Dias", "Ga\u00ebl", ""], ["Moraliyski", "Rumen", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1807.10104", "submitter": "Jonathan Mamou", "authors": "Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Ido Dagan, Yoav\n  Goldberg, Alon Eirew, Yael Green, Shira Guskin, Peter Izsak, Daniel Korat", "title": "Term Set Expansion based on Multi-Context Term Embeddings: an End-to-end\n  Workflow", "comments": "COLING 2018 System Demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present SetExpander, a corpus-based system for expanding a seed set of\nterms into a more complete set of terms that belong to the same semantic class.\nSetExpander implements an iterative end-to end workflow for term set expansion.\nIt enables users to easily select a seed set of terms, expand it, view the\nexpanded set, validate it, re-expand the validated set and store it, thus\nsimplifying the extraction of domain-specific fine-grained semantic classes.\nSetExpander has been used for solving real-life use cases including integration\nin an automated recruitment system and an issues and defects resolution system.\nA video demo of SetExpander is available at\nhttps://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images\nwere blurred for privacy reasons).\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:11:51 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Mamou", "Jonathan", ""], ["Pereg", "Oren", ""], ["Wasserblat", "Moshe", ""], ["Dagan", "Ido", ""], ["Goldberg", "Yoav", ""], ["Eirew", "Alon", ""], ["Green", "Yael", ""], ["Guskin", "Shira", ""], ["Izsak", "Peter", ""], ["Korat", "Daniel", ""]]}, {"id": "1807.10311", "submitter": "Arne K\\\"ohn", "authors": "Benjamin Milde and Arne K\\\"ohn", "title": "Open Source Automatic Speech Recognition for German", "comments": "Accepted at ITG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High quality Automatic Speech Recognition (ASR) is a prerequisite for\nspeech-based applications and research. While state-of-the-art ASR software is\nfreely available, the language dependent acoustic models are lacking for\nlanguages other than English, due to the limited amount of freely available\ntraining data. We train acoustic models for German with Kaldi on two datasets,\nwhich are both distributed under a Creative Commons license. The resulting\nmodel is freely redistributable, lowering the cost of entry for German ASR. The\nmodels are trained on a total of 412 hours of German read speech data and we\nachieve a relative word error reduction of 26% by adding data from the Spoken\nWikipedia Corpus to the previously best freely available German acoustic model\nrecipe and dataset. Our best model achieves a word error rate of 14.38 on the\nTuda-De test set. Due to the large amount of speakers and the diversity of\ntopics included in the training data, our model is robust against speaker\nvariation and topic shift.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 18:31:08 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Milde", "Benjamin", ""], ["K\u00f6hn", "Arne", ""]]}, {"id": "1807.10543", "submitter": "Neslihan Suzen", "authors": "Neslihan Suzen, Alexander Gorban, Jeremy Levesley and Evgeny Mirkes", "title": "Automatic Short Answer Grading and Feedback Using Text Mining Methods", "comments": "27 pages; added questions for section 6; correction of typos", "journal-ref": "Procedia Computer Science 169 (2020), 726-743", "doi": "10.1016/j.procs.2020.02.171", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic grading is not a new approach but the need to adapt the latest\ntechnology to automatic grading has become very important. As the technology\nhas rapidly became more powerful on scoring exams and essays, especially from\nthe 1990s onwards, partially or wholly automated grading systems using\ncomputational methods have evolved and have become a major area of research. In\nparticular, the demand of scoring of natural language responses has created a\nneed for tools that can be applied to automatically grade these responses. In\nthis paper, we focus on the concept of automatic grading of short answer\nquestions such as are typical in the UK GCSE system, and providing useful\nfeedback on their answers to students. We present experimental results on a\ndataset provided from the introductory computer science class in the University\nof North Texas. We first apply standard data mining techniques to the corpus of\nstudent answers for the purpose of measuring similarity between the student\nanswers and the model answer. This is based on the number of common words. We\nthen evaluate the relation between these similarities and marks awarded by\nscorers. We then consider an approach that groups student answers into\nclusters. Each cluster would be awarded the same mark, and the same feedback\ngiven to each answer in a cluster. In this manner, we demonstrate that clusters\nindicate the groups of students who are awarded the same or the similar scores.\nWords in each cluster are compared to show that clusters are constructed based\non how many and which words of the model answer have been used. The main\nnovelty in this paper is that we design a model to predict marks based on the\nsimilarities between the student answers and the model answer.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 12:00:21 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 17:21:46 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 20:48:35 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Suzen", "Neslihan", ""], ["Gorban", "Alexander", ""], ["Levesley", "Jeremy", ""], ["Mirkes", "Evgeny", ""]]}, {"id": "1807.10564", "submitter": "Bryan Eikema", "authors": "Bryan Eikema and Wilker Aziz", "title": "Auto-Encoding Variational Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep generative model of bilingual sentence pairs for machine\ntranslation. The model generates source and target sentences jointly from a\nshared latent representation and is parameterised by neural networks. We\nperform efficient training using amortised variational inference and\nreparameterised gradients. Additionally, we discuss the statistical\nimplications of joint modelling and propose an efficient approximation to\nmaximum a posteriori decoding for fast test-time predictions. We demonstrate\nthe effectiveness of our model in three machine translation scenarios:\nin-domain training, mixed-domain training, and learning from a mix of\ngold-standard and synthetic data. Our experiments show consistently that our\njoint formulation outperforms conditional modelling (i.e. standard neural\nmachine translation) in all such scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 13:03:06 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 07:50:23 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 09:20:21 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 14:00:00 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Eikema", "Bryan", ""], ["Aziz", "Wilker", ""]]}, {"id": "1807.10615", "submitter": "Nishtha Madaan", "authors": "Nishtha Madaan, Sameep Mehta, Shravika Mittal, Ashima Suvarna", "title": "Judging a Book by its Description : Analyzing Gender Stereotypes in the\n  Man Bookers Prize Winning Fiction", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.04117", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of gender stereotypes in many aspects of society is a well-known\nphenomenon. In this paper, we focus on studying and quantifying such\nstereotypes and bias in the Man Bookers Prize winning fiction. We consider 275\nbooks shortlisted for Man Bookers Prize between 1969 and 2017. The gender bias\nis analyzed by semantic modeling of book descriptions on Goodreads. This\nreveals the pervasiveness of gender bias and stereotype in the books on\ndifferent features like occupation, introductions and actions associated to the\ncharacters in the book.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 08:36:02 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Madaan", "Nishtha", ""], ["Mehta", "Sameep", ""], ["Mittal", "Shravika", ""], ["Suvarna", "Ashima", ""]]}, {"id": "1807.10661", "submitter": "Giuseppe Riccardi", "authors": "Jacopo Gobbi and Evgeny Stepanov and Giuseppe Riccardi", "title": "Concept Tagging for Natural Language Understanding: Two Decadelong\n  Algorithm Development", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept tagging is a type of structured learning needed for natural language\nunderstanding (NLU) systems. In this task, meaning labels from a domain\nontology are assigned to word sequences. In this paper, we review the\nalgorithms developed over the last twenty five years. We perform a comparative\nevaluation of generative, discriminative and deep learning methods on two\npublic datasets. We report on the statistical variability performance\nmeasurements. The third contribution is the release of a repository of the\nalgorithms, datasets and recipes for NLU evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 14:40:32 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Gobbi", "Jacopo", ""], ["Stepanov", "Evgeny", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1807.10675", "submitter": "Sajawel Ahmed", "authors": "Sajawel Ahmed, Alexander Mehler", "title": "Resource-Size matters: Improving Neural Named Entity Recognition with\n  Optimized Large Corpora", "comments": "ICMLA 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study improves the performance of neural named entity recognition by a\nmargin of up to 11% in F-score on the example of a low-resource language like\nGerman, thereby outperforming existing baselines and establishing a new\nstate-of-the-art on each single open-source dataset. Rather than designing\ndeeper and wider hybrid neural architectures, we gather all available resources\nand perform a detailed optimization and grammar-dependent morphological\nprocessing consisting of lemmatization and part-of-speech tagging prior to\nexposing the raw data to any training process. We test our approach in a\nthreefold monolingual experimental setup of a) single, b) joint, and c)\noptimized training and shed light on the dependency of downstream-tasks on the\nsize of corpora used to compute word embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:05:20 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Ahmed", "Sajawel", ""], ["Mehler", "Alexander", ""]]}, {"id": "1807.10740", "submitter": "Marcely Zanon Boito", "authors": "Marcely Zanon Boito, Antonios Anastasopoulos, Marika Lekakou, Aline\n  Villavicencio, Laurent Besacier", "title": "A small Griko-Italian speech translation corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension to a very low-resource parallel corpus\ncollected in an endangered language, Griko, making it useful for computational\nresearch. The corpus consists of 330 utterances (about 20 minutes of speech)\nwhich have been transcribed and translated in Italian, with annotations for\nword-level speech-to-transcription and speech-to-translation alignments. The\ncorpus also includes morphosyntactic tags and word-level glosses. Applying an\nautomatic unit discovery method, pseudo-phones were also generated. We detail\nhow the corpus was collected, cleaned and processed, and we illustrate its use\non zero-resource tasks by presenting some baseline results for the task of\nspeech-to-translation alignment and unsupervised word discovery. The dataset is\navailable online, aiming to encourage replicability and diversity in\ncomputational language documentation experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 17:29:20 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Boito", "Marcely Zanon", ""], ["Anastasopoulos", "Antonios", ""], ["Lekakou", "Marika", ""], ["Villavicencio", "Aline", ""], ["Besacier", "Laurent", ""]]}, {"id": "1807.10800", "submitter": "Abdulkareem Alsudais", "authors": "Abdulkareem Alsudais, Hovig Tchalian", "title": "Clustering Prominent People and Organizations in Topic-Specific Text\n  Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Named entities in text documents are the names of people, organization,\nlocation or other types of objects in the documents that exist in the real\nworld. A persisting research challenge is to use computational techniques to\nidentify such entities in text documents. Once identified, several text mining\ntools and algorithms can be utilized to leverage these discovered named\nentities and improve NLP applications. In this paper, a method that clusters\nprominent names of people and organizations based on their semantic similarity\nin a text corpus is proposed. The method relies on common named entity\nrecognition techniques and on recent word embeddings models. The semantic\nsimilarity scores generated using the word embeddings models for the named\nentities are used to cluster similar entities of the people and organizations\ntypes. Two human judges evaluated ten variations of the method after it was run\non a corpus that consists of 4,821 articles on a specific topic. The\nperformance of the method was measured using three quantitative measures. The\nresults of these three metrics demonstrate that the method is effective in\nclustering semantically similar named entities.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 19:00:01 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 11:43:55 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Alsudais", "Abdulkareem", ""], ["Tchalian", "Hovig", ""]]}, {"id": "1807.10805", "submitter": "Mahtab Ahmed", "authors": "Mahtab Ahmed, Muhammad Rifayat Samee, Robert E. Mercer", "title": "Improving Neural Sequence Labelling using Additional Linguistic\n  Information", "comments": "9 pages, 1 figure, Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sequence labelling is the task of assigning categorical labels to a data\nsequence. In Natural Language Processing, sequence labelling can be applied to\nvarious fundamental problems, such as Part of Speech (POS) tagging, Named\nEntity Recognition (NER), and Chunking. In this study, we propose a method to\nadd various linguistic features to the neural sequence framework to improve\nsequence labelling. Besides word level knowledge, sense embeddings are added to\nprovide semantic information. Additionally, selective readings of character\nembeddings are added to capture contextual as well as morphological features\nfor each word in a sentence. Compared to previous methods, these added\nlinguistic features allow us to design a more concise model and perform more\nefficient training. Our proposed architecture achieves state of the art results\non the benchmark datasets of POS, NER, and chunking. Moreover, the convergence\nrate of our model is significantly better than the previous state of the art\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 19:07:33 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Ahmed", "Mahtab", ""], ["Samee", "Muhammad Rifayat", ""], ["Mercer", "Robert E.", ""]]}, {"id": "1807.10854", "submitter": "Jugal Kalita", "authors": "Daniel W. Otter, Julian R. Medina, Jugal K. Kalita", "title": "A Survey of the Usages of Deep Learning in Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last several years, the field of natural language processing has\nbeen propelled forward by an explosion in the use of deep learning models. This\nsurvey provides a brief introduction to the field and a quick overview of deep\nlearning architectures and methods. It then sifts through the plethora of\nrecent studies and summarizes a large assortment of relevant contributions.\nAnalyzed research areas include several core linguistic processing issues in\naddition to a number of applications of computational linguistics. A discussion\nof the current state of the art is then provided along with recommendations for\nfuture research in the field.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 23:11:39 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:23:05 GMT"}, {"version": "v3", "created": "Sat, 21 Dec 2019 20:34:43 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Otter", "Daniel W.", ""], ["Medina", "Julian R.", ""], ["Kalita", "Jugal K.", ""]]}, {"id": "1807.10857", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Anjuli Kannan, Chung-Cheng Chiu, Yonghui Wu, Tara N\n  Sainath, Karen Livescu", "title": "A Comparison of Techniques for Language Model Integration in\n  Encoder-Decoder Speech Recognition", "comments": "Accepted in SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based recurrent neural encoder-decoder models present an elegant\nsolution to the automatic speech recognition problem. This approach folds the\nacoustic model, pronunciation model, and language model into a single network\nand requires only a parallel corpus of speech and text for training. However,\nunlike in conventional approaches that combine separate acoustic and language\nmodels, it is not clear how to use additional (unpaired) text. While there has\nbeen previous work on methods addressing this problem, a thorough comparison\namong methods is still lacking. In this paper, we compare a suite of past\nmethods and some of our own proposed methods for using unpaired text data to\nimprove encoder-decoder models. For evaluation, we use the medium-sized\nSwitchboard data set and the large-scale Google voice search and dictation data\nsets. Our results confirm the benefits of using unpaired text across a range of\nmethods and data sets. Surprisingly, for first-pass decoding, the rather simple\napproach of shallow fusion performs best across data sets. However, for Google\ndata sets we find that cold fusion has a lower oracle error rate and\noutperforms other approaches after second-pass rescoring on the Google voice\nsearch data set.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 23:33:33 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 23:21:14 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Kannan", "Anjuli", ""], ["Chiu", "Chung-Cheng", ""], ["Wu", "Yonghui", ""], ["Sainath", "Tara N", ""], ["Livescu", "Karen", ""]]}, {"id": "1807.10893", "submitter": "Tomoki Hayashi", "authors": "Tomoki Hayashi, Shinji Watanabe, Yu Zhang, Tomoki Toda, Takaaki Hori,\n  Ramon Astudillo, Kazuya Takeda", "title": "Back-Translation-Style Data Augmentation for End-to-End ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel data augmentation method for attention-based\nend-to-end automatic speech recognition (E2E-ASR), utilizing a large amount of\ntext which is not paired with speech signals. Inspired by the back-translation\ntechnique proposed in the field of machine translation, we build a neural\ntext-to-encoder model which predicts a sequence of hidden states extracted by a\npre-trained E2E-ASR encoder from a sequence of characters. By using hidden\nstates as a target instead of acoustic features, it is possible to achieve\nfaster attention learning and reduce computational cost, thanks to sub-sampling\nin E2E-ASR encoder, also the use of the hidden states can avoid to model\nspeaker dependencies unlike acoustic features. After training, the\ntext-to-encoder model generates the hidden states from a large amount of\nunpaired text, then E2E-ASR decoder is retrained using the generated hidden\nstates as additional training data. Experimental evaluation using LibriSpeech\ndataset demonstrates that our proposed method achieves improvement of ASR\nperformance and reduces the number of unknown words without the need for paired\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 05:32:11 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Hayashi", "Tomoki", ""], ["Watanabe", "Shinji", ""], ["Zhang", "Yu", ""], ["Toda", "Tomoki", ""], ["Hori", "Takaaki", ""], ["Astudillo", "Ramon", ""], ["Takeda", "Kazuya", ""]]}, {"id": "1807.10945", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Henk van den Heuvel and David A. van Leeuwen", "title": "Acoustic and Textual Data Augmentation for Improved ASR of\n  Code-Switching Speech", "comments": "Accepted for publication at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe several techniques for improving the acoustic and\nlanguage model of an automatic speech recognition (ASR) system operating on\ncode-switching (CS) speech. We focus on the recognition of Frisian-Dutch radio\nbroadcasts where one of the mixed languages, namely Frisian, is an\nunder-resourced language. In previous work, we have proposed several automatic\ntranscription strategies for CS speech to increase the amount of available\ntraining speech data. In this work, we explore how the acoustic modeling (AM)\ncan benefit from monolingual speech data belonging to the high-resourced mixed\nlanguage. For this purpose, we train state-of-the-art AMs, which were\nineffective due to lack of training data, on a significantly increased amount\nof CS speech and monolingual Dutch speech. Moreover, we improve the language\nmodel (LM) by creating code-switching text, which is in practice almost\nnon-existent, by (1) generating text using recurrent LMs trained on the\ntranscriptions of the training CS speech data, (2) adding the transcriptions of\nthe automatically transcribed CS speech data and (3) translating Dutch text\nextracted from the transcriptions of a large Dutch speech corpora. We report\nsignificantly improved CS ASR performance due to the increase in the acoustic\nand textual training data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 14:59:52 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Heuvel", "Henk van den", ""], ["van Leeuwen", "David A.", ""]]}, {"id": "1807.10948", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Vikramjit Mitra, Chris Bartels and Horacio Franco", "title": "Articulatory Features for ASR of Pathological Speech", "comments": "Accepted for publication at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the joint use of articulatory and acoustic\nfeatures for automatic speech recognition (ASR) of pathological speech. Despite\nlong-lasting efforts to build speaker- and text-independent ASR systems for\npeople with dysarthria, the performance of state-of-the-art systems is still\nconsiderably lower on this type of speech than on normal speech. The most\nprominent reason for the inferior performance is the high variability in\npathological speech that is characterized by the spectrotemporal deviations\ncaused by articulatory impairments due to various etiologies. To cope with this\nhigh variation, we propose to use speech representations which utilize\narticulatory information together with the acoustic properties. A designated\nacoustic model, namely a fused-feature-map convolutional neural network (fCNN),\nwhich performs frequency convolution on acoustic features and time convolution\non articulatory features is trained and tested on a Dutch and a Flemish\npathological speech corpus. The ASR performance of fCNN-based ASR system using\njoint features is compared to other neural network architectures such\nconventional CNNs and time-frequency convolutional networks (TFCNNs) in several\ntraining scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 15:04:53 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Mitra", "Vikramjit", ""], ["Bartels", "Chris", ""], ["Franco", "Horacio", ""]]}, {"id": "1807.10949", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Astik Biswas, Ewald van der Westhuizen, Febe de Wet\n  and Thomas Niesler", "title": "Building a Unified Code-Switching ASR System for South African Languages", "comments": "Acccepted for publication at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our first efforts towards building a single multilingual automatic\nspeech recognition (ASR) system that can process code-switching (CS) speech in\nfive languages spoken within the same population. This contrasts with related\nprior work which focuses on the recognition of CS speech in bilingual\nscenarios. Recently, we have compiled a small five-language corpus of South\nAfrican soap opera speech which contains examples of CS between 5 languages\noccurring in various contexts such as using English as the matrix language and\nswitching to other indigenous languages. The ASR system presented in this work\nis trained on 4 corpora containing English-isiZulu, English-isiXhosa,\nEnglish-Setswana and English-Sesotho CS speech. The interpolation of multiple\nlanguage models trained on these language pairs enables the ASR system to\nhypothesize mixed word sequences from these 5 languages. We evaluate various\nstate-of-the-art acoustic models trained on this 5-lingual training data and\nreport ASR accuracy and language recognition performance on the development and\ntest sets of the South African multilingual soap opera corpus.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 15:09:55 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Biswas", "Astik", ""], ["van der Westhuizen", "Ewald", ""], ["de Wet", "Febe", ""], ["Niesler", "Thomas", ""]]}, {"id": "1807.10965", "submitter": "Tim Finin", "authors": "Jennifer Sleeman, Tim Finin, Milton Halem", "title": "Ontology-Grounded Topic Modeling for Climate Science Research", "comments": "To appear in Proc. of Semantic Web for Social Good Workshop of the\n  Int. Semantic Web Conf., Oct 2018 and published as part of the book \"Emerging\n  Topics in Semantic Technologies. ISWC 2018 Satellite Events\", E. Demidova,\n  A.J. Zaveri, E. Simperl (Eds.), ISBN: 978-3-89838-736-1, 2018, AKA Verlag\n  Berlin, (edited authors)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In scientific disciplines where research findings have a strong impact on\nsociety, reducing the amount of time it takes to understand, synthesize and\nexploit the research is invaluable. Topic modeling is an effective technique\nfor summarizing a collection of documents to find the main themes among them\nand to classify other documents that have a similar mixture of co-occurring\nwords. We show how grounding a topic model with an ontology, extracted from a\nglossary of important domain phrases, improves the topics generated and makes\nthem easier to understand. We apply and evaluate this method to the climate\nscience domain. The result improves the topics generated and supports faster\nresearch understanding, discovery of social networks among researchers, and\nautomatic ontology generation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 18:26:28 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 01:08:37 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Sleeman", "Jennifer", ""], ["Finin", "Tim", ""], ["Halem", "Milton", ""]]}, {"id": "1807.10984", "submitter": "Siddharth Dalmia", "authors": "Siddharth Dalmia, Xinjian Li, Florian Metze and Alan W. Black", "title": "Domain Robust Feature Extraction for Rapid Low Resource ASR Development", "comments": "To appear in SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing a practical speech recognizer for a low resource language is\nchallenging, not only because of the (potentially unknown) properties of the\nlanguage, but also because test data may not be from the same domain as the\navailable training data. In this paper, we focus on the latter challenge, i.e.\ndomain mismatch, for systems trained using a sequence-based criterion. We\ndemonstrate the effectiveness of using a pre-trained English recognizer, which\nis robust to such mismatched conditions, as a domain normalizing feature\nextractor on a low resource language. In our example, we use Turkish\nConversational Speech and Broadcast News data. This enables rapid development\nof speech recognizers for new languages which can easily adapt to any domain.\nTesting in various cross-domain scenarios, we achieve relative improvements of\naround 25% in phoneme error rate, with improvements being around 50% for some\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 23:54:59 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 21:16:18 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Dalmia", "Siddharth", ""], ["Li", "Xinjian", ""], ["Metze", "Florian", ""], ["Black", "Alan W.", ""]]}, {"id": "1807.11024", "submitter": "Vuong M. Ngo", "authors": "L.H. Nguyen, N.T.H. Pham, V.M. Ngo", "title": "Opinion Spam Recognition Method for Online Reviews using Ontological\n  Features", "comments": "15 pages, In Journal of Science, Special Issue: Natural Science and\n  Technology, Ho Chi Minh City University of Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there are a lot of people using social media opinions to make their\ndecision on buying products or services. Opinion spam detection is a hard\nproblem because fake reviews can be made by organizations as well as\nindividuals for different purposes. They write fake reviews to mislead readers\nor automated detection system by promoting or demoting target products to\npromote them or to damage their reputations. In this paper, we pro-pose a new\napproach using knowledge-based Ontology to detect opinion spam with high\naccuracy (higher than 75%). Keywords: Opinion spam, Fake review, E-commercial,\nOntology.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:05:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Nguyen", "L. H.", ""], ["Pham", "N. T. H.", ""], ["Ngo", "V. M.", ""]]}, {"id": "1807.11057", "submitter": "Wei Li", "authors": "Wei Li, Brian Mak", "title": "NMT-based Cross-lingual Document Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a cross-lingual document embedding method that\nimproves the current Neural machine Translation framework based Document Vector\n(NTDV or simply NV). NV is developed with a self-attention mechanism under the\nneural machine translation (NMT) framework. In NV, each pair of parallel\ndocuments in different languages are projected to the same shared layer in the\nmodel. However, the pair of NV embeddings are not guaranteed to be similar.\nThis paper further adds a distance constraint to the training objective\nfunction of NV so that the two embeddings of a parallel document are required\nto be as close as possible. The new method will be called constrained NV (cNV).\nIn a cross-lingual document classification task, the new cNV performs as well\nas NV and outperforms other published studies that require forward-pass\ndecoding. Compared with the previous NV, cNV does not need a translator during\ntesting, and so the method is lighter and more flexible.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 13:49:00 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 14:59:10 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 17:58:06 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Li", "Wei", ""], ["Mak", "Brian", ""]]}, {"id": "1807.11082", "submitter": "Bin He", "authors": "Bin He, Yi Guan, Rui Dai", "title": "Convolutional Gated Recurrent Units for Medical Relation Classification", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) and recurrent neural network (RNN) models\nhave become the mainstream methods for relation classification. We propose a\nunified architecture, which exploits the advantages of CNN and RNN\nsimultaneously, to identify medical relations in clinical records, with only\nword embedding features. Our model learns phrase-level features through a CNN\nlayer, and these feature representations are directly fed into a bidirectional\ngated recurrent unit (GRU) layer to capture long-term feature dependencies. We\nevaluate our model on two clinical datasets, and experiments demonstrate that\nour model performs significantly better than previous single-model methods on\nboth datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 16:43:06 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["He", "Bin", ""], ["Guan", "Yi", ""], ["Dai", "Rui", ""]]}, {"id": "1807.11089", "submitter": "Pramit Saha", "authors": "Pramit Saha, Praneeth Srungarapu and Sidney Fels", "title": "Towards Automatic Speech Identification from Vocal Tract Shape Dynamics\n  in Real-time MRI", "comments": "To appear in the INTERSPEECH 2018 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vocal tract configurations play a vital role in generating distinguishable\nspeech sounds, by modulating the airflow and creating different resonant\ncavities in speech production. They contain abundant information that can be\nutilized to better understand the underlying speech production mechanism. As a\nstep towards automatic mapping of vocal tract shape geometry to acoustics, this\npaper employs effective video action recognition techniques, like Long-term\nRecurrent Convolutional Networks (LRCN) models, to identify different\nvowel-consonant-vowel (VCV) sequences from dynamic shaping of the vocal tract.\nSuch a model typically combines a CNN based deep hierarchical visual feature\nextractor with Recurrent Networks, that ideally makes the network\nspatio-temporally deep enough to learn the sequential dynamics of a short video\nclip for video classification tasks. We use a database consisting of 2D\nreal-time MRI of vocal tract shaping during VCV utterances by 17 speakers. The\ncomparative performances of this class of algorithms under various parameter\nsettings and for various classification tasks are discussed. Interestingly, the\nresults show a marked difference in the model performance in the context of\nspeech classification with respect to generic sequence or video classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 17:36:08 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Saha", "Pramit", ""], ["Srungarapu", "Praneeth", ""], ["Fels", "Sidney", ""]]}, {"id": "1807.11125", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yu Wang and Siqi Sun and Sarah Panda and Jingjing Liu\n  and Jianfeng Gao", "title": "Microsoft Dialogue Challenge: Building End-to-End Task-Completion\n  Dialogue Systems", "comments": "SLT 2018 Special Session: http://www.slt2018.org/news/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This proposal introduces a Dialogue Challenge for building end-to-end\ntask-completion dialogue systems, with the goal of encouraging the dialogue\nresearch community to collaborate and benchmark on standard datasets and\nunified experimental environment. In this special session, we will release\nhuman-annotated conversational data in three domains (movie-ticket booking,\nrestaurant reservation, and taxi booking), as well as an experiment platform\nwith built-in simulators in each domain, for training and evaluation purposes.\nThe final submitted systems will be evaluated both in simulated setting and by\nhuman judges.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 23:51:08 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 23:47:59 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Li", "Xiujun", ""], ["Wang", "Yu", ""], ["Sun", "Siqi", ""], ["Panda", "Sarah", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1807.11172", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Joy Sain, Amit Sheth, Asif Ekbal, Sriparna Saha, Pushpak\n  Bhattacharyya", "title": "Leveraging Medical Sentiment to Understand Patients Health on Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The unprecedented growth of Internet users in recent years has resulted in an\nabundance of unstructured information in the form of social media text. A large\npercentage of this population is actively engaged in health social networks to\nshare health-related information. In this paper, we address an important and\ntimely topic by analyzing the users' sentiments and emotions w.r.t their\nmedical conditions. Towards this, we examine users on popular medical forums\n(Patient.info,dailystrength.org), where they post on important topics such as\nasthma, allergy, depression, and anxiety. First, we provide a benchmark setup\nfor the task by crawling the data, and further define the sentiment specific\nfine-grained medical conditions (Recovered, Exist, Deteriorate, and Other). We\npropose an effective architecture that uses a Convolutional Neural Network\n(CNN) as a data-driven feature extractor and a Support Vector Machine (SVM) as\na classifier. We further develop a sentiment feature which is sensitive to the\nmedical context. Here, we show that the use of medical sentiment feature along\nwith extracted features from CNN improves the model performance. In addition to\nour dataset, we also evaluate our approach on the benchmark \"CLEF eHealth 2014\"\ncorpora and show that our model outperforms the state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 04:59:43 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Yadav", "Shweta", ""], ["Sain", "Joy", ""], ["Sheth", "Amit", ""], ["Ekbal", "Asif", ""], ["Saha", "Sriparna", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1807.11219", "submitter": "Katsuki Chousa", "authors": "Katsuki Chousa, Katsuhito Sudoh, Satoshi Nakamura", "title": "Training Neural Machine Translation using Word Embedding-based Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural machine translation (NMT), the computational cost at the output\nlayer increases with the size of the target-side vocabulary. Using a\nlimited-size vocabulary instead may cause a significant decrease in translation\nquality. This trade-off is derived from a softmax-based loss function that\nhandles in-dictionary words independently, in which word similarity is not\nconsidered. In this paper, we propose a novel NMT loss function that includes\nword similarity in forms of distances in a word embedding space. The proposed\nloss function encourages an NMT decoder to generate words close to their\nreferences in the embedding space; this helps the decoder to choose similar\nacceptable words when the actual best candidates are not included in the\nvocabulary due to its size limitation. In experiments using ASPEC\nJapanese-to-English and IWSLT17 English-to-French data sets, the proposed\nmethod showed improvements against a standard NMT baseline in both datasets;\nespecially with IWSLT17 En-Fr, it achieved up to +1.72 in BLEU and +1.99 in\nMETEOR. When the target-side vocabulary was very limited to 1,000 words, the\nproposed method demonstrated a substantial gain, +1.72 in METEOR with ASPEC\nJa-En.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:11:52 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chousa", "Katsuki", ""], ["Sudoh", "Katsuhito", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1807.11227", "submitter": "Tao Li", "authors": "Tao Li, Lei Lin, Minsoo Choi, Kaiming Fu, Siyuan Gong, Jian Wang", "title": "YouTube AV 50K: An Annotated Corpus for Comments in Autonomous Vehicles", "comments": "in Proceedings of the Thirteenth International Joint Symposium on\n  Artificial Intelligence and Natural Language Processing (iSAI-NLP 2018)", "journal-ref": null, "doi": "10.1109/iSAI-NLP.2018.8692799", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With one billion monthly viewers, and millions of users discussing and\nsharing opinions, comments below YouTube videos are rich sources of data for\nopinion mining and sentiment analysis. We introduce the YouTube AV 50K dataset,\na freely-available collections of more than 50,000 YouTube comments and\nmetadata below autonomous vehicle (AV)-related videos. We describe its creation\nprocess, its content and data format, and discuss its possible usages.\nEspecially, we do a case study of the first self-driving car fatality to\nevaluate the dataset, and show how we can use this dataset to better understand\npublic attitudes toward self-driving cars and public reactions to the accident.\nFuture developments of the dataset are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:28:44 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 05:12:09 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 03:07:22 GMT"}, {"version": "v4", "created": "Mon, 15 Oct 2018 06:56:48 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Li", "Tao", ""], ["Lin", "Lei", ""], ["Choi", "Minsoo", ""], ["Fu", "Kaiming", ""], ["Gong", "Siyuan", ""], ["Wang", "Jian", ""]]}, {"id": "1807.11243", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris and Francisco Casacuberta", "title": "Active Learning for Interactive Neural Machine Translation of Data\n  Streams", "comments": "Accepted at The SIGNLL Conference on Computational Natural Language\n  Learning (CoNLL'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the application of active learning techniques to the translation of\nunbounded data streams via interactive neural machine translation. The main\nidea is to select, from an unbounded stream of source sentences, those worth to\nbe supervised by a human agent. The user will interactively translate those\nsamples. Once validated, these data is useful for adapting the neural machine\ntranslation model.\n  We propose two novel methods for selecting the samples to be validated. We\nexploit the information from the attention mechanism of a neural machine\ntranslation system. Our experiments show that the inclusion of active learning\ntechniques into this pipeline allows to reduce the effort required during the\nprocess, while increasing the quality of the translation system. Moreover, it\nenables to balance the human effort required for achieving a certain\ntranslation quality. Moreover, our neural system outperforms classical\napproaches by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 09:11:26 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 08:54:52 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1807.11276", "submitter": "Christina Niklaus", "authors": "Matthias Cetto, Christina Niklaus, Andr\\'e Freitas and Siegfried\n  Handschuh", "title": "Graphene: Semantically-Linked Propositions in Open Information\n  Extraction", "comments": "27th International Conference on Computational Linguistics (COLING\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an Open Information Extraction (IE) approach that uses a\ntwo-layered transformation stage consisting of a clausal disembedding layer and\na phrasal disembedding layer, together with rhetorical relation identification.\nIn that way, we convert sentences that present a complex linguistic structure\ninto simplified, syntactically sound sentences, from which we can extract\npropositions that are represented in a two-layered hierarchy in the form of\ncore relational tuples and accompanying contextual information which are\nsemantically linked via rhetorical relations. In a comparative evaluation, we\ndemonstrate that our reference implementation Graphene outperforms\nstate-of-the-art Open IE systems in the construction of correct n-ary\npredicate-argument structures. Moreover, we show that existing Open IE\napproaches can benefit from the transformation process of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 10:31:52 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Cetto", "Matthias", ""], ["Niklaus", "Christina", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1807.11284", "submitter": "Pavel Denisov", "authors": "Pavel Denisov, Ngoc Thang Vu, Marc Ferras Font", "title": "Unsupervised Domain Adaptation by Adversarial Learning for Robust Speech\n  Recognition", "comments": "5 pages, 2 figures, the 13th ITG conference on Speech Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the use of adversarial learning for\nunsupervised adaptation to unseen recording conditions, more specifically,\nsingle microphone far-field speech. We adapt neural networks based acoustic\nmodels trained with close-talk clean speech to the new recording conditions\nusing untranscribed adaptation data. Our experimental results on Italian\nSPEECON data set show that our proposed method achieves 19.8% relative word\nerror rate (WER) reduction compared to the unadapted models. Furthermore, this\nadaptation method is beneficial even when performed on data from another\nlanguage (i.e. French) giving 12.6% relative WER reduction.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 11:00:59 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""], ["Font", "Marc Ferras", ""]]}, {"id": "1807.11535", "submitter": "Sanjeev Kumar Karn", "authors": "Sanjeev Kumar Karn, Mark Buckley, Ulli Waltinger and Hinrich Sch\\\"utze", "title": "News Article Teaser Tweets and How to Generate Them", "comments": null, "journal-ref": "2019 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we define the task of teaser generation and provide an\nevaluation benchmark and baseline systems for the process of generating\nteasers. A teaser is a short reading suggestion for an article that is\nillustrative and includes curiosity-arousing elements to entice potential\nreaders to read particular news items. Teasers are one of the main vehicles for\ntransmitting news to social media users. We compile a novel dataset of teasers\nby systematically accumulating tweets and selecting those that conform to the\nteaser definition. We have compared a number of neural abstractive\narchitectures on the task of teaser generation and the overall best performing\nsystem is See et al.(2017)'s seq2seq with pointer network.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 19:16:09 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 14:52:57 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Karn", "Sanjeev Kumar", ""], ["Buckley", "Mark", ""], ["Waltinger", "Ulli", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1807.11567", "submitter": "Seonghan Ryu", "authors": "Seonghan Ryu, Seokhwan Kim, Junhwi Choi, Hwanjo Yu, Gary Geunbae Lee", "title": "Neural Sentence Embedding using Only In-domain Sentences for\n  Out-of-domain Sentence Detection in Dialog Systems", "comments": "Published in Pattern Recognition Letters, 88:26-32, 2017", "journal-ref": null, "doi": "10.1016/j.patrec.2017.01.008", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure satisfactory user experience, dialog systems must be able to\ndetermine whether an input sentence is in-domain (ID) or out-of-domain (OOD).\nWe assume that only ID sentences are available as training data because\ncollecting enough OOD sentences in an unbiased way is a laborious and\ntime-consuming job. This paper proposes a novel neural sentence embedding\nmethod that represents sentences in a low-dimensional continuous vector space\nthat emphasizes aspects that distinguish ID cases from OOD cases. We first used\na large set of unlabeled text to pre-train word representations that are used\nto initialize neural sentence embedding. Then we used domain-category analysis\nas an auxiliary task to train neural sentence embedding for OOD sentence\ndetection. After the sentence representations were learned, we used them to\ntrain an autoencoder aimed at OOD sentence detection. We evaluated our method\nby experimentally comparing it to the state-of-the-art methods in an\neight-domain dialog system; our proposed method achieved the highest accuracy\nin all tests.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:31:15 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Ryu", "Seonghan", ""], ["Kim", "Seokhwan", ""], ["Choi", "Junhwi", ""], ["Yu", "Hwanjo", ""], ["Lee", "Gary Geunbae", ""]]}, {"id": "1807.11582", "submitter": "Patrick Huber", "authors": "Patrick Huber and Jan Niehues and Alex Waibel", "title": "A Hierarchical Approach to Neural Context-Aware Modeling", "comments": "8 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new recurrent neural network topology to enhance\nstate-of-the-art machine learning systems by incorporating a broader context.\nOur approach overcomes recent limitations with extended narratives through a\nmulti-layered computational approach to generate an abstract context\nrepresentation. Therefore, the developed system captures the narrative on\nword-level, sentence-level, and context-level. Through the hierarchical set-up,\nour proposed model summarizes the most salient information on each level and\ncreates an abstract representation of the extended context. We subsequently use\nthis representation to enhance neural language processing systems on the task\nof semantic error detection. To show the potential of the newly introduced\ntopology, we compare the approach against a context-agnostic set-up including a\nstandard neural language model and a supervised binary classification network.\nThe performance measures on the error detection task show the advantage of the\nhierarchical context-aware topologies, improving the baseline by 12.75%\nrelative for unsupervised models and 20.37% relative for supervised models.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 11:10:03 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 10:17:55 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Huber", "Patrick", ""], ["Niehues", "Jan", ""], ["Waibel", "Alex", ""]]}, {"id": "1807.11584", "submitter": "Sudipta Kar", "authors": "Marc Franco-Salvador, Sudipta Kar, Thamar Solorio, and Paolo Rosso", "title": "UH-PRHLT at SemEval-2016 Task 3: Combining Lexical and Semantic-based\n  Features for Community Question Answering", "comments": "Top system for question-question similarity in SemEval 2016 Task 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we describe the system built for the three English subtasks of\nthe SemEval 2016 Task 3 by the Department of Computer Science of the University\nof Houston (UH) and the Pattern Recognition and Human Language Technology\n(PRHLT) research center - Universitat Polit`ecnica de Val`encia: UH-PRHLT. Our\nsystem represents instances by using both lexical and semantic-based similarity\nmeasures between text pairs. Our semantic features include the use of\ndistributed representations of words, knowledge graphs generated with the\nBabelNet multilingual semantic network, and the FrameNet lexical database.\nExperimental results outperform the random and Google search engine baselines\nin the three English subtasks. Our approach obtained the highest results of\nsubtask B compared to the other task participants.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 21:14:25 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Franco-Salvador", "Marc", ""], ["Kar", "Sudipta", ""], ["Solorio", "Thamar", ""], ["Rosso", "Paolo", ""]]}, {"id": "1807.11605", "submitter": "Hasan Sait Arslan", "authors": "Hasan Sait Arslan, Mark Fishel, Gholamreza Anbarjafari", "title": "Doubly Attentive Transformer Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a doubly attentive transformer machine translation model\n(DATNMT) is presented in which a doubly-attentive transformer decoder normally\njoins spatial visual features obtained via pretrained convolutional neural\nnetworks, conquering any gap between image captioning and translation. In this\nframework, the transformer decoder figures out how to take care of\nsource-language words and parts of an image freely by methods for two separate\nattention components in an Enhanced Multi-Head Attention Layer of doubly\nattentive transformer, as it generates words in the target language. We find\nthat the proposed model can effectively exploit not just the scarce multimodal\nmachine translation data, but also large general-domain text-only machine\ntranslation corpora, or image-text image captioning corpora. The experimental\nresults show that the proposed doubly-attentive transformer-decoder performs\nbetter than a single-decoder transformer model, and gives the state-of-the-art\nresults in the English-German multimodal machine translation task.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 23:13:55 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Arslan", "Hasan Sait", ""], ["Fishel", "Mark", ""], ["Anbarjafari", "Gholamreza", ""]]}, {"id": "1807.11618", "submitter": "Kamal Al-Sabahi Ph.D.", "authors": "Kamal Al-Sabahi, Zuping Zhang, Jun Long, Khaled Alwesabi", "title": "An Enhanced Latent Semantic Analysis Approach for Arabic Document\n  Summarization", "comments": "This is a pre-print of an article published in Arabian Journal for\n  Science and Engineering. The final authenticated version is available online\n  at: https://doi.org/10.1007/s13369-018-3286-z", "journal-ref": "K. Al-Sabahi, Z. Zhang, J. Long, and K. Alwesabi, \"An Enhanced\n  Latent Semantic Analysis Approach for Arabic Document Summarization,\" Arabian\n  Journal for Science and Engineering, journal article May 05 2018", "doi": "10.1007/s13369-018-3286-z", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast-growing amount of information on the Internet makes the research in\nautomatic document summarization very urgent. It is an effective solution for\ninformation overload. Many approaches have been proposed based on different\nstrategies, such as latent semantic analysis (LSA). However, LSA, when applied\nto document summarization, has some limitations which diminish its performance.\nIn this work, we try to overcome these limitations by applying statistic and\nlinear algebraic approaches combined with syntactic and semantic processing of\ntext. First, the part of speech tagger is utilized to reduce the dimension of\nLSA. Then, the weight of the term in four adjacent sentences is added to the\nweighting schemes while calculating the input matrix to take into account the\nword order and the syntactic relations. In addition, a new LSA-based sentence\nselection algorithm is proposed, in which the term description is combined with\nsentence description for each topic which in turn makes the generated summary\nmore informative and diverse. To ensure the effectiveness of the proposed\nLSA-based sentence selection algorithm, extensive experiment on Arabic and\nEnglish are done. Four datasets are used to evaluate the new model, Linguistic\nData Consortium (LDC) Arabic Newswire-a corpus, Essex Arabic Summaries Corpus\n(EASC), DUC2002, and Multilingual MSS 2015 dataset. Experimental results on the\nfour datasets show the effectiveness of the proposed model on Arabic and\nEnglish datasets. It performs comprehensively better compared to the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 00:50:15 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Al-Sabahi", "Kamal", ""], ["Zhang", "Zuping", ""], ["Long", "Jun", ""], ["Alwesabi", "Khaled", ""]]}, {"id": "1807.11679", "submitter": "Junichi Yamagishi", "authors": "Yi Zhao, Shinji Takaki, Hieu-Thi Luong, Junichi Yamagishi, Daisuke\n  Saito, Nobuaki Minematsu", "title": "Wasserstein GAN and Waveform Loss-based Acoustic Model Training for\n  Multi-speaker Text-to-Speech Synthesis Systems Using a WaveNet Vocoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural networks such as WaveNet and sampleRNN that learn directly from\nspeech waveform samples have achieved very high-quality synthetic speech in\nterms of both naturalness and speaker similarity even in multi-speaker\ntext-to-speech synthesis systems. Such neural networks are being used as an\nalternative to vocoders and hence they are often called neural vocoders. The\nneural vocoder uses acoustic features as local condition parameters, and these\nparameters need to be accurately predicted by another acoustic model. However,\nit is not yet clear how to train this acoustic model, which is problematic\nbecause the final quality of synthetic speech is significantly affected by the\nperformance of the acoustic model. Significant degradation happens, especially\nwhen predicted acoustic features have mismatched characteristics compared to\nnatural ones. In order to reduce the mismatched characteristics between natural\nand generated acoustic features, we propose frameworks that incorporate either\na conditional generative adversarial network (GAN) or its variant, Wasserstein\nGAN with gradient penalty (WGAN-GP), into multi-speaker speech synthesis that\nuses the WaveNet vocoder. We also extend the GAN frameworks and use the\ndiscretized mixture logistic loss of a well-trained WaveNet in addition to mean\nsquared error and adversarial losses as parts of objective functions.\nExperimental results show that acoustic models trained using the WGAN-GP\nframework using back-propagated discretized-mixture-of-logistics (DML) loss\nachieves the highest subjective evaluation scores in terms of both quality and\nspeaker similarity.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 06:38:54 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Zhao", "Yi", ""], ["Takaki", "Shinji", ""], ["Luong", "Hieu-Thi", ""], ["Yamagishi", "Junichi", ""], ["Saito", "Daisuke", ""], ["Minematsu", "Nobuaki", ""]]}, {"id": "1807.11689", "submitter": "Muhao Chen", "authors": "Muhao Chen, Changping Meng, Gang Huang and Carlo Zaniolo", "title": "Neural Article Pair Modeling for Wikipedia Sub-article Matching", "comments": "ECML-PKDD 2018. 16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, editors tend to separate different subtopics of a long Wiki-pedia\narticle into multiple sub-articles. This separation seeks to improve human\nreadability. However, it also has a deleterious effect on many Wikipedia-based\ntasks that rely on the article-as-concept assumption, which requires each\nentity (or concept) to be described solely by one article. This underlying\nassumption significantly simplifies knowledge representation and extraction,\nand it is vital to many existing technologies such as automated knowledge base\nconstruction, cross-lingual knowledge alignment, semantic search and data\nlineage of Wikipedia entities. In this paper we provide an approach to match\nthe scattered sub-articles back to their corresponding main-articles, with the\nintent of facilitating automated Wikipedia curation and processing. The\nproposed model adopts a hierarchical learning structure that combines multiple\nvariants of neural document pair encoders with a comprehensive set of explicit\nfeatures. A large crowdsourced dataset is created to support the evaluation and\nfeature extraction for the task. Based on the large dataset, the proposed model\nachieves promising results of cross-validation and significantly outperforms\nprevious approaches. Large-scale serving on the entire English Wikipedia also\nproves the practicability and scalability of the proposed model by effectively\nextracting a vast collection of newly paired main and sub-articles.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 07:19:36 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 21:30:17 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Chen", "Muhao", ""], ["Meng", "Changping", ""], ["Huang", "Gang", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1807.11712", "submitter": "Sudipta Kar", "authors": "Niloofar Safi Samghabadi and Deepthi Mave and Sudipta Kar and Thamar\n  Solorio", "title": "RiTUAL-UH at TRAC 2018 Shared Task: Aggression Identification", "comments": "TRAC I Shared Task' 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our system for \"TRAC 2018 Shared Task on Aggression\nIdentification\". Our best systems for the English dataset use a combination of\nlexical and semantic features. However, for Hindi data using only lexical\nfeatures gave us the best results. We obtained weighted F1- measures of 0.5921\nfor the English Facebook task (ranked 12th), 0.5663 for the English Social\nMedia task (ranked 6th), 0.6292 for the Hindi Facebook task (ranked 1st), and\n0.4853 for the Hindi Social Media task (ranked 2nd).\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 09:21:22 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Samghabadi", "Niloofar Safi", ""], ["Mave", "Deepthi", ""], ["Kar", "Sudipta", ""], ["Solorio", "Thamar", ""]]}, {"id": "1807.11714", "submitter": "Kaiji Lu", "authors": "Kaiji Lu, Piotr Mardziel, Fangjing Wu, Preetam Amancharla, Anupam\n  Datta", "title": "Gender Bias in Neural Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine whether neural natural language processing (NLP) systems reflect\nhistorical biases in training data. We define a general benchmark to quantify\ngender bias in a variety of neural NLP tasks. Our empirical evaluation with\nstate-of-the-art neural coreference resolution and textbook RNN-based language\nmodels trained on benchmark datasets finds significant gender bias in how\nmodels view occupations. We then mitigate bias with CDA: a generic methodology\nfor corpus augmentation via causal interventions that breaks associations\nbetween gendered and gender-neutral words. We empirically show that CDA\neffectively decreases gender bias while preserving accuracy. We also explore\nthe space of mitigation strategies with CDA, a prior approach to word embedding\ndebiasing (WED), and their compositions. We show that CDA outperforms WED,\ndrastically so when word embeddings are trained. For pre-trained embeddings,\nthe two methods can be effectively composed. We also find that as training\nproceeds on the original data set with gradient descent the gender bias grows\nas the loss reduces, indicating that the optimization encourages bias; CDA\nmitigates this behavior.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 09:27:27 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 23:34:50 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Lu", "Kaiji", ""], ["Mardziel", "Piotr", ""], ["Wu", "Fangjing", ""], ["Amancharla", "Preetam", ""], ["Datta", "Anupam", ""]]}, {"id": "1807.11761", "submitter": "Michael Cochez", "authors": "Michael Cochez and Martina Garofalo and J\\'er\\^ome Len{\\ss}en and\n  Maria Angela Pellegrino", "title": "A First Experiment on Including Text Literals in KGloVe", "comments": "Presented at the 4th Workshop on Semantic Deep Learning (SemDeep-4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding models produce embedding vectors for entities and relations\nin Knowledge Graphs, often without taking literal properties into account. We\nshow an initial idea based on the combination of global graph structure with\nadditional information provided by textual information in properties. Our\ninitial experiment shows that this approach might be useful, but does not\nclearly outperform earlier approaches when evaluated on machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 11:18:18 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Cochez", "Michael", ""], ["Garofalo", "Martina", ""], ["Len\u00dfen", "J\u00e9r\u00f4me", ""], ["Pellegrino", "Maria Angela", ""]]}, {"id": "1807.11838", "submitter": "Jonathan Connell", "authors": "Jonathan Connell", "title": "Extensible Grounding of Speech for Robot Instruction", "comments": null, "journal-ref": null, "doi": null, "report-no": "draft of chapter for \"Robots That Talk and Listen\", J. Markowitz\n  (ed.), De Grutyer 2014", "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language is a convenient interface for commanding a mobile robot. Yet\nfor this to work a number of base terms must be grounded in perceptual and\nmotor skills. We detail the language processing used on our robot ELI and\nexplain how this grounding is performed, how it interacts with user gestures,\nand how it handles phenomena such as anaphora. More importantly, however, there\nare certain concepts which the robot cannot be preprogrammed with, such as the\nnames of various objects in a household or the nature of specific tasks it may\nbe requested to perform. In these cases it is vital that there exist a method\nfor extending the grounding, essentially \"learning by being told\". We describe\nhow this was successfully implemented for learning new nouns and verbs in a\ntabletop setting. Creating this language learning kernel may be the last\nexplicit programming the robot ever needs - the core mechanism could eventually\nbe used for imparting a vast amount of knowledge, much as a child learns from\nits parents and teachers.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 14:31:17 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Connell", "Jonathan", ""]]}, {"id": "1807.11906", "submitter": "Yinfei Yang", "authors": "Mandy Guo, Qinlan Shen, Yinfei Yang, Heming Ge, Daniel Cer, Gustavo\n  Hernandez Abrego, Keith Stevens, Noah Constant, Yun-Hsuan Sung, Brian Strope,\n  Ray Kurzweil", "title": "Effective Parallel Corpus Mining using Bilingual Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an effective approach for parallel corpus mining using\nbilingual sentence embeddings. Our embedding models are trained to produce\nsimilar representations exclusively for bilingual sentence pairs that are\ntranslations of each other. This is achieved using a novel training method that\nintroduces hard negatives consisting of sentences that are not translations but\nthat have some degree of semantic similarity. The quality of the resulting\nembeddings are evaluated on parallel corpus reconstruction and by assessing\nmachine translation systems trained on gold vs. mined sentence pairs. We find\nthat the sentence embeddings can be used to reconstruct the United Nations\nParallel Corpus at the sentence level with a precision of 48.9% for en-fr and\n54.9% for en-es. When adapted to document level matching, we achieve a parallel\ndocument matching accuracy that is comparable to the significantly more\ncomputationally intensive approach of [Jakob 2010]. Using reconstructed\nparallel data, we are able to train NMT models that perform nearly as well as\nmodels trained on the original data (within 1-2 BLEU).\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 16:32:50 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 17:48:13 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Guo", "Mandy", ""], ["Shen", "Qinlan", ""], ["Yang", "Yinfei", ""], ["Ge", "Heming", ""], ["Cer", "Daniel", ""], ["Abrego", "Gustavo Hernandez", ""], ["Stevens", "Keith", ""], ["Constant", "Noah", ""], ["Sung", "Yun-Hsuan", ""], ["Strope", "Brian", ""], ["Kurzweil", "Ray", ""]]}]