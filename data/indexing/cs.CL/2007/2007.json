[{"id": "2007.00049", "submitter": "Sunipa Dev", "authors": "Sunipa Dev, Tao Li, Jeff M Phillips, Vivek Srikumar", "title": "OSCaR: Orthogonal Subspace Correction and Rectification of Biases in\n  Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language representations are known to carry stereotypical biases and, as a\nresult, lead to biased predictions in downstream tasks. While existing methods\nare effective at mitigating biases by linear projection, such methods are too\naggressive: they not only remove bias, but also erase valuable information from\nword embeddings. We develop new measures for evaluating specific information\nretention that demonstrate the tradeoff between bias removal and information\nretention. To address this challenge, we propose OSCaR (Orthogonal Subspace\nCorrection and Rectification), a bias-mitigating method that focuses on\ndisentangling biased associations between concepts instead of removing concepts\nwholesale. Our experiments on gender biases show that OSCaR is a well-balanced\napproach that ensures that semantic information is retained in the embeddings\nand bias is also effectively mitigated.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:18:13 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dev", "Sunipa", ""], ["Li", "Tao", ""], ["Phillips", "Jeff M", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2007.00067", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Kaizhao Liang, Bhavya Kailkhura, Zhongming\n  Jin, Xian-Sheng Hua, Deng Cai, Bo Li", "title": "Adversarial Mutual Information for Text Generation", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in maximizing mutual information (MI) between the source and\ntarget have demonstrated its effectiveness in text generation. However,\nprevious works paid little attention to modeling the backward network of MI\n(i.e., dependency from the target to the source), which is crucial to the\ntightness of the variational information maximization lower bound. In this\npaper, we propose Adversarial Mutual Information (AMI): a text generation\nframework which is formed as a novel saddle point (min-max) optimization aiming\nto identify joint interactions between the source and target. Within this\nframework, the forward and backward networks are able to iteratively promote or\ndemote each other's generated instances by comparing the real and synthetic\ndata distributions. We also develop a latent noise sampling strategy that\nleverages random variations at the high-level semantic space to enhance the\nlong term dependency in the generation process. Extensive experiments based on\ndifferent text generation tasks demonstrate that the proposed AMI framework can\nsignificantly outperform several strong baselines, and we also show that AMI\nhas potential to lead to a tighter lower bound of maximum mutual information\nfor the variational information maximization problem.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 19:11:51 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Liang", "Kaizhao", ""], ["Kailkhura", "Bhavya", ""], ["Jin", "Zhongming", ""], ["Hua", "Xian-Sheng", ""], ["Cai", "Deng", ""], ["Li", "Bo", ""]]}, {"id": "2007.00131", "submitter": "Maarten Van Segbroeck", "authors": "Maarten Van Segbroeck, Harish Mallidih, Brian King, I-Fan Chen,\n  Gurpreet Chadha, Roland Maas", "title": "Multi-view Frequency LSTM: An Efficient Frontend for Automatic Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic models in real-time speech recognition systems typically stack\nmultiple unidirectional LSTM layers to process the acoustic frames over time.\nPerformance improvements over vanilla LSTM architectures have been reported by\nprepending a stack of frequency-LSTM (FLSTM) layers to the time LSTM. These\nFLSTM layers can learn a more robust input feature to the time LSTM layers by\nmodeling time-frequency correlations in the acoustic input signals. A drawback\nof FLSTM based architectures however is that they operate at a predefined, and\ntuned, window size and stride, referred to as 'view' in this paper. We present\na simple and efficient modification by combining the outputs of multiple FLSTM\nstacks with different views, into a dimensionality reduced feature\nrepresentation. The proposed multi-view FLSTM architecture allows to model a\nwider range of time-frequency correlations compared to an FLSTM model with\nsingle view. When trained on 50K hours of English far-field speech data with\nCTC loss followed by sMBR sequence training, we show that the multi-view FLSTM\nacoustic model provides relative Word Error Rate (WER) improvements of 3-7% for\ndifferent speaker and acoustic environment scenarios over an optimized single\nFLSTM model, while retaining a similar computational footprint.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 22:19:53 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Van Segbroeck", "Maarten", ""], ["Mallidih", "Harish", ""], ["King", "Brian", ""], ["Chen", "I-Fan", ""], ["Chadha", "Gurpreet", ""], ["Maas", "Roland", ""]]}, {"id": "2007.00145", "submitter": "Eric Dodds", "authors": "Eric Dodds, Jack Culpepper, Simao Herdade, Yang Zhang, Kofi Boakye", "title": "Modality-Agnostic Attention Fusion for visual search with text feedback", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image retrieval with natural language feedback offers the promise of catalog\nsearch based on fine-grained visual features that go beyond objects and binary\nattributes, facilitating real-world applications such as e-commerce. Our\nModality-Agnostic Attention Fusion (MAAF) model combines image and text\nfeatures and outperforms existing approaches on two visual search with\nmodifying phrase datasets, Fashion IQ and CSS, and performs competitively on a\ndataset with only single-word modifications, Fashion200k. We also introduce two\nnew challenging benchmarks adapted from Birds-to-Words and Spot-the-Diff, which\nprovide new settings with rich language inputs, and we show that our approach\nwithout modification outperforms strong baselines. To better understand our\nmodel, we conduct detailed ablations on Fashion IQ and provide visualizations\nof the surprising phenomenon of words avoiding \"attending\" to the image region\nthey refer to.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 22:55:02 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dodds", "Eric", ""], ["Culpepper", "Jack", ""], ["Herdade", "Simao", ""], ["Zhang", "Yang", ""], ["Boakye", "Kofi", ""]]}, {"id": "2007.00183", "submitter": "Bowen Shi", "authors": "Bowen Shi, Shane Settle, Karen Livescu", "title": "Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings", "comments": "SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmental models are sequence prediction models in which scores of hypotheses\nare based on entire variable-length segments of frames. We consider segmental\nmodels for whole-word (\"acoustic-to-word\") speech recognition, with the feature\nvectors defined using vector embeddings of segments. Such models are\ncomputationally challenging as the number of paths is proportional to the\nvocabulary size, which can be orders of magnitude larger than when using\nsubword units like phones. We describe an efficient approach for end-to-end\nwhole-word segmental models, with forward-backward and Viterbi decoding\nperformed on a GPU and a simple segment scoring function that reduces space\ncomplexity. In addition, we investigate the use of pre-training via jointly\ntrained acoustic word embeddings (AWEs) and acoustically grounded word\nembeddings (AGWEs) of written word labels. We find that word error rate can be\nreduced by a large margin by pre-training the acoustic segment representation\nwith AWEs, and additional (smaller) gains can be obtained by pre-training the\nword prediction layer with AGWEs. Our final models improve over prior A2W\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 02:22:09 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:03:52 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Shi", "Bowen", ""], ["Settle", "Shane", ""], ["Livescu", "Karen", ""]]}, {"id": "2007.00217", "submitter": "Minbyul Jeong", "authors": "Minbyul Jeong, Mujeen Sung, Gangwoo Kim, Donghyeon Kim, Wonjin Yoon,\n  Jaehyo Yoo, Jaewoo Kang", "title": "Transferability of Natural Language Inference to Biomedical Question\n  Answering", "comments": "submit for the 8th BioASQ workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical question answering (QA) is a challenging task due to the scarcity\nof data and the requirement of domain expertise. Pre-trained language models\nhave been used to address these issues. Recently, learning relationships\nbetween sentence pairs has been proved to improve performance in general QA. In\nthis paper, we focus on applying BioBERT to transfer the knowledge of natural\nlanguage inference (NLI) to biomedical QA. We observe that BioBERT trained on\nthe NLI dataset obtains better performance on Yes/No (+5.59%), Factoid\n(+0.53%), List type (+13.58%) questions compared to performance obtained in a\nprevious challenge (BioASQ 7B Phase B). We present a sequential transfer\nlearning method that significantly performed well in the 8th BioASQ Challenge\n(Phase B). In sequential transfer learning, the order in which tasks are\nfine-tuned is important. We measure an unanswerable rate of the extractive QA\nsetting when the formats of factoid and list type questions are converted to\nthe format of the Stanford Question Answering Dataset (SQuAD).\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 04:05:48 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 08:21:55 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 07:08:36 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2021 06:40:48 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Jeong", "Minbyul", ""], ["Sung", "Mujeen", ""], ["Kim", "Gangwoo", ""], ["Kim", "Donghyeon", ""], ["Yoon", "Wonjin", ""], ["Yoo", "Jaehyo", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2007.00229", "submitter": "Xin Eric Wang", "authors": "Wanrong Zhu, Xin Eric Wang, Tsu-Jui Fu, An Yan, Pradyumna Narayana,\n  Kazoo Sone, Sugato Basu, William Yang Wang", "title": "Multimodal Text Style Transfer for Outdoor Vision-and-Language\n  Navigation", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging topics in Natural Language Processing (NLP) is\nvisually-grounded language understanding and reasoning. Outdoor\nvision-and-language navigation (VLN) is such a task where an agent follows\nnatural language instructions and navigates a real-life urban environment. Due\nto the lack of human-annotated instructions that illustrate intricate urban\nscenes, outdoor VLN remains a challenging task to solve. This paper introduces\na Multimodal Text Style Transfer (MTST) learning approach and leverages\nexternal multimodal resources to mitigate data scarcity in outdoor navigation\ntasks. We first enrich the navigation data by transferring the style of the\ninstructions generated by Google Maps API, then pre-train the navigator with\nthe augmented external outdoor navigation dataset. Experimental results show\nthat our MTST learning approach is model-agnostic, and our MTST approach\nsignificantly outperforms the baseline models on the outdoor VLN task,\nimproving task completion rate by 8.7% relatively on the test set.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 04:29:07 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 09:43:58 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 04:48:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhu", "Wanrong", ""], ["Wang", "Xin Eric", ""], ["Fu", "Tsu-Jui", ""], ["Yan", "An", ""], ["Narayana", "Pradyumna", ""], ["Sone", "Kazoo", ""], ["Basu", "Sugato", ""], ["Wang", "William Yang", ""]]}, {"id": "2007.00236", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Shuailong Liang, Yili Jin, Yilong Wang, Xiaodan Zhu and\n  Yue Zhang", "title": "SemEval-2020 Task 4: Commonsense Validation and Explanation", "comments": "Task description paper of SemEval-2020 Task 4: Commonsense Validation\n  and Explanation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present SemEval-2020 Task 4, Commonsense Validation and\nExplanation (ComVE), which includes three subtasks, aiming to evaluate whether\na system can distinguish a natural language statement that makes sense to\nhumans from one that does not, and provide the reasons. Specifically, in our\nfirst subtask, the participating systems are required to choose from two\nnatural language statements of similar wording the one that makes sense and the\none does not. The second subtask additionally asks a system to select the key\nreason from three options why a given statement does not make sense. In the\nthird subtask, a participating system needs to generate the reason. We finally\nattracted 39 teams participating at least one of the three subtasks. For\nSubtask A and Subtask B, the performances of top-ranked systems are close to\nthat of humans. However, for Subtask C, there is still a relatively large gap\nbetween systems and human performance. The dataset used in our task can be\nfound at https://github.com/wangcunxiang/SemEval2020-\nTask4-Commonsense-Validation-and-Explanation; The leaderboard can be found at\nhttps://competitions.codalab.org/competitions/21080#results.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 04:41:05 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 15:13:40 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Cunxiang", ""], ["Liang", "Shuailong", ""], ["Jin", "Yili", ""], ["Wang", "Yilong", ""], ["Zhu", "Xiaodan", ""], ["Zhang", "Yue", ""]]}, {"id": "2007.00257", "submitter": "Tatiana Batura", "authors": "Ekaterina Artemova, Tatiana Batura, Anna Golenkovskaya, Vitaly Ivanin,\n  Vladimir Ivanov, Veronika Sarkisyan, Ivan Smurov, Elena Tutubalina", "title": "So What's the Plan? Mining Strategic Planning Documents", "comments": "15 pages, 3 figures, 5 tables. The paper has been accepted for the\n  Fifth International Conference on Digital Transformation and Global Society\n  (DTGS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a corpus of Russian strategic planning documents,\nRuREBus. This project is grounded both from language technology and\ne-government perspectives. Not only new language sources and tools are being\ndeveloped, but also their applications to e-goverment research. We demonstrate\nthe pipeline for creating a text corpus from scratch. First, the annotation\nschema is designed. Next texts are marked up using human-in-the-loop strategy,\nso that preliminary annotations are derived from a machine learning model and\nare manually corrected. The amount of annotated texts is large enough to\nshowcase what insights can be gained from RuREBus.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 05:40:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 16:02:37 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Artemova", "Ekaterina", ""], ["Batura", "Tatiana", ""], ["Golenkovskaya", "Anna", ""], ["Ivanin", "Vitaly", ""], ["Ivanov", "Vladimir", ""], ["Sarkisyan", "Veronika", ""], ["Smurov", "Ivan", ""], ["Tutubalina", "Elena", ""]]}, {"id": "2007.00266", "submitter": "Ben Bogin", "authors": "Ben Bogin, Sanjay Subramanian, Matt Gardner, Jonathan Berant", "title": "Latent Compositional Representations Improve Systematic Generalization\n  in Grounded Question Answering", "comments": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2020. Author's final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions that involve multi-step reasoning requires decomposing\nthem and using the answers of intermediate steps to reach the final answer.\nHowever, state-of-the-art models in grounded question answering often do not\nexplicitly perform decomposition, leading to difficulties in generalization to\nout-of-distribution examples. In this work, we propose a model that computes a\nrepresentation and denotation for all question spans in a bottom-up,\ncompositional manner using a CKY-style parser. Our model induces latent trees,\ndriven by end-to-end (the answer) supervision only. We show that this inductive\nbias towards tree structures dramatically improves systematic generalization to\nout-of-distribution examples, compared to strong baselines on an arithmetic\nexpressions benchmark as well as on CLOSURE, a dataset that focuses on\nsystematic generalization for grounded question answering. On this challenging\ndataset, our model reaches an accuracy of 96.1%, significantly higher than\nprior models that almost perfectly solve the task on a random, in-distribution\nsplit.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 06:22:51 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 14:35:21 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 06:22:21 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Bogin", "Ben", ""], ["Subramanian", "Sanjay", ""], ["Gardner", "Matt", ""], ["Berant", "Jonathan", ""]]}, {"id": "2007.00320", "submitter": "Ryan Culkin", "authors": "Ryan Culkin, J. Edward Hu, Elias Stengel-Eskin, Guanghui Qin, Benjamin\n  Van Durme", "title": "Iterative Paraphrastic Augmentation with Discriminative Span Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel paraphrastic augmentation strategy based on\nsentence-level lexically constrained paraphrasing and discriminative span\nalignment. Our approach allows for the large-scale expansion of existing\nresources, or the rapid creation of new resources from a small,\nmanually-produced seed corpus. We illustrate our framework on the Berkeley\nFrameNet Project, a large-scale language understanding effort spanning more\nthan two decades of human labor. Based on roughly four days of collecting\ntraining data for the alignment model and approximately one day of parallel\ncompute, we automatically generate 495,300 unique (Frame, Trigger) combinations\nannotated in context, a roughly 50x expansion atop FrameNet v1.7.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 08:33:44 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Culkin", "Ryan", ""], ["Hu", "J. Edward", ""], ["Stengel-Eskin", "Elias", ""], ["Qin", "Guanghui", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "2007.00380", "submitter": "Casper Hansen", "authors": "Casper Hansen and Christian Hansen and Jakob Grue Simonsen and Stephen\n  Alstrup and Christina Lioma", "title": "Unsupervised Semantic Hashing with Pairwise Reconstruction", "comments": "Accepted at SIGIR'20", "journal-ref": null, "doi": "10.1145/3397271.3401220", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Hashing is a popular family of methods for efficient similarity\nsearch in large-scale datasets. In Semantic Hashing, documents are encoded as\nshort binary vectors (i.e., hash codes), such that semantic similarity can be\nefficiently computed using the Hamming distance. Recent state-of-the-art\napproaches have utilized weak supervision to train better performing hashing\nmodels. Inspired by this, we present Semantic Hashing with Pairwise\nReconstruction (PairRec), which is a discrete variational autoencoder based\nhashing model. PairRec first encodes weakly supervised training pairs (a query\ndocument and a semantically similar document) into two hash codes, and then\nlearns to reconstruct the same query document from both of these hash codes\n(i.e., pairwise reconstruction). This pairwise reconstruction enables our model\nto encode local neighbourhood structures within the hash code directly through\nthe decoder. We experimentally compare PairRec to traditional and\nstate-of-the-art approaches, and obtain significant performance improvements in\nthe task of document similarity search.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 10:54:27 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Simonsen", "Jakob Grue", ""], ["Alstrup", "Stephen", ""], ["Lioma", "Christina", ""]]}, {"id": "2007.00492", "submitter": "Shaoqing Yuan", "authors": "Shaoqing Yuan, Parminder Bhatia, Busra Celikkaya, Haiyang Liu,\n  Kyunghwan Choi", "title": "Towards User Friendly Medication Mapping Using Entity-Boosted Two-Tower\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in medical entity linking have been applied in the area\nof scientific literature and social media data. However, with the adoption of\ntelemedicine and conversational agents such as Alexa in healthcare settings,\nmedical name inference has become an important task. Medication name inference\nis the task of mapping user friendly medication names from a free-form text to\na concept in a normalized medication list. This is challenging due to the\ndifferences in the use of medical terminology from health care professionals\nand user conversations coming from the lay public. We begin with mapping\ndescriptive medication phrases (DMP) to standard medication names (SMN). Given\nthe prescriptions of each patient, we want to provide them with the flexibility\nof referring to the medication in their preferred ways. We approach this as a\nranking problem which maps SMN to DMP by ordering the list of medications in\nthe patient's prescription list obtained from pharmacies. Furthermore, we\nleveraged the output of intermediate layers and performed medication\nclustering. We present the Medication Inference Model (MIM) achieving\nstate-of-the-art results. By incorporating medical entities based attention, we\nhave obtained further improvement for ranking models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:56:44 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 18:44:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yuan", "Shaoqing", ""], ["Bhatia", "Parminder", ""], ["Celikkaya", "Busra", ""], ["Liu", "Haiyang", ""], ["Choi", "Kyunghwan", ""]]}, {"id": "2007.00576", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Manling Li, Xuan Wang, Nikolaus Parulian, Guangxing Han,\n  Jiawei Ma, Jingxuan Tu, Ying Lin, Haoran Zhang, Weili Liu, Aabhas Chauhan,\n  Yingjun Guan, Bangzheng Li, Ruisong Li, Xiangchen Song, Yi R. Fung, Heng Ji,\n  Jiawei Han, Shih-Fu Chang, James Pustejovsky, Jasmine Rah, David Liem, Ahmed\n  Elsayed, Martha Palmer, Clare Voss, Cynthia Schneider, Boyan Onyshkevych", "title": "COVID-19 Literature Knowledge Graph Construction and Drug Repurposing\n  Report Generation", "comments": "12 pages, Accepted by Proceedings of 2021 Annual Conference of the\n  North American Chapter of the Association for Computational Linguistics\n  System Demonstrations, for resources see\n  http://blender.cs.illinois.edu/covid19/, for video see\n  http://159.89.180.81/demo/covid/Covid-KG_DemoVideo.mp4, for slides see\n  https://eaglew.github.io/files/Covid-KG_DemoVideo_with_ethics.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To combat COVID-19, both clinicians and scientists need to digest vast\namounts of relevant biomedical knowledge in scientific literature to understand\nthe disease mechanism and related biological functions. We have developed a\nnovel and comprehensive knowledge discovery framework, COVID-KG to extract\nfine-grained multimedia knowledge elements (entities and their visual chemical\nstructures, relations, and events) from scientific literature. We then exploit\nthe constructed multimedia knowledge graphs (KGs) for question answering and\nreport generation, using drug repurposing as a case study. Our framework also\nprovides detailed contextual sentences, subfigures, and knowledge subgraphs as\nevidence.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 16:03:20 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 22:50:14 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 23:53:39 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 20:38:41 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 02:47:58 GMT"}, {"version": "v6", "created": "Wed, 12 May 2021 03:30:44 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Wang", "Qingyun", ""], ["Li", "Manling", ""], ["Wang", "Xuan", ""], ["Parulian", "Nikolaus", ""], ["Han", "Guangxing", ""], ["Ma", "Jiawei", ""], ["Tu", "Jingxuan", ""], ["Lin", "Ying", ""], ["Zhang", "Haoran", ""], ["Liu", "Weili", ""], ["Chauhan", "Aabhas", ""], ["Guan", "Yingjun", ""], ["Li", "Bangzheng", ""], ["Li", "Ruisong", ""], ["Song", "Xiangchen", ""], ["Fung", "Yi R.", ""], ["Ji", "Heng", ""], ["Han", "Jiawei", ""], ["Chang", "Shih-Fu", ""], ["Pustejovsky", "James", ""], ["Rah", "Jasmine", ""], ["Liem", "David", ""], ["Elsayed", "Ahmed", ""], ["Palmer", "Martha", ""], ["Voss", "Clare", ""], ["Schneider", "Cynthia", ""], ["Onyshkevych", "Boyan", ""]]}, {"id": "2007.00655", "submitter": "Corbin Rosset", "authors": "Corby Rosset, Chenyan Xiong, Minh Phan, Xia Song, Paul Bennett,\n  Saurabh Tiwary", "title": "Knowledge-Aware Language Model Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much knowledge do pretrained language models hold? Recent research\nobserved that pretrained transformers are adept at modeling semantics but it is\nunclear to what degree they grasp human knowledge, or how to ensure they do so.\nIn this paper we incorporate knowledge-awareness in language model pretraining\nwithout changing the transformer architecture, inserting explicit knowledge\nlayers, or adding external storage of semantic information. Rather, we simply\nsignal the existence of entities to the input of the transformer in\npretraining, with an entity-extended tokenizer; and at the output, with an\nadditional entity prediction task. Our experiments show that solely by adding\nthese entity signals in pretraining, significantly more knowledge is packed\ninto the transformer parameters: we observe improved language modeling\naccuracy, factual correctness in LAMA knowledge probing tasks, and semantics in\nthe hidden representations through edge probing.We also show that our\nknowledge-aware language model (KALM) can serve as a drop-in replacement for\nGPT-2 models, significantly improving downstream tasks like zero-shot\nquestion-answering with no task-related training.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 06:09:59 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 06:54:39 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Rosset", "Corby", ""], ["Xiong", "Chenyan", ""], ["Phan", "Minh", ""], ["Song", "Xia", ""], ["Bennett", "Paul", ""], ["Tiwary", "Saurabh", ""]]}, {"id": "2007.00709", "submitter": "Seethalakshmi Gopalakrishnan", "authors": "Hossein Hematialam, Luciana Garbayo, Seethalakshmi Gopalakrishnan,\n  Wlodek Zadrozny", "title": "Computing Conceptual Distances between Breast Cancer Screening\n  Guidelines: An Implementation of a Near-Peer Epistemic Model of Medical\n  Disagreement", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "3285697", "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using natural language processing tools, we investigate the differences of\nrecommendations in medical guidelines for the same decision problem -- breast\ncancer screening. We show that these differences arise from knowledge brought\nto the problem by different medical societies, as reflected in the conceptual\nvocabularies used by the different groups of authors.The computational models\nwe build and analyze agree with the near-peer epistemic model of expert\ndisagreement proposed by Garbayo. Even though the article is a case study\nfocused on one set of guidelines, the proposed methodology is broadly\napplicable. In addition to proposing a novel graph-based similarity model for\ncomparing collections of documents, we perform an extensive analysis of the\nmodel performance. In a series of a few dozen experiments, in three broad\ncategories, we show, at a very high statistical significance level of 3-4\nstandard deviations for our best models, that the high similarity between\nexpert annotated model and our concept based, automatically created,\ncomputational models is not accidental. Our best model achieves roughly 70%\nsimilarity. We also describe possible extensions of this work.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 19:21:10 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 02:01:05 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Hematialam", "Hossein", ""], ["Garbayo", "Luciana", ""], ["Gopalakrishnan", "Seethalakshmi", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "2007.00750", "submitter": "Caitrin Armstrong", "authors": "Caitrin Armstrong and Derek Ruths", "title": "Legends: Folklore on Reddit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Reddit legends, a collection of venerated old\nposts that have become famous on Reddit. To establish the utility of Reddit\nlegends for both computational science/HCI and folkloristics, we investigate\ntwo main questions: (1) whether they can be considered folklore, i.e. if they\nhave consistent form, cultural significance, and undergo spontaneous\ntransmission, and (2) whether they can be studied in a systematic manner.\nThrough several subtasks, including the creation of a typology, an analysis of\nreferences to Reddit legends, and an examination of some of the textual\ncharacteristics of referencing behaviour, we show that Reddit legends can\nindeed be considered as folklore and that they are amendable to systematic\ntext-based approaches. We discuss how these results will enable future analyses\nof folklore on Reddit, including tracking subreddit-wide and individual-user\nbehaviour, and the relationship of this behaviour to other cultural markers.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:55:41 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Armstrong", "Caitrin", ""], ["Ruths", "Derek", ""]]}, {"id": "2007.00808", "submitter": "Li Xiong", "authors": "Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul\n  Bennett, Junaid Ahmed, Arnold Overwijk", "title": "Approximate Nearest Neighbor Negative Contrastive Learning for Dense\n  Text Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conducting text retrieval in a dense learned representation space has many\nintriguing advantages over sparse retrieval. Yet the effectiveness of dense\nretrieval (DR) often requires combination with sparse retrieval. In this paper,\nwe identify that the main bottleneck is in the training mechanisms, where the\nnegative instances used in training are not representative of the irrelevant\ndocuments in testing. This paper presents Approximate nearest neighbor Negative\nContrastive Estimation (ANCE), a training mechanism that constructs negatives\nfrom an Approximate Nearest Neighbor (ANN) index of the corpus, which is\nparallelly updated with the learning process to select more realistic negative\ntraining instances. This fundamentally resolves the discrepancy between the\ndata distribution used in the training and testing of DR. In our experiments,\nANCE boosts the BERT-Siamese DR model to outperform all competitive dense and\nsparse retrieval baselines. It nearly matches the accuracy of\nsparse-retrieval-and-BERT-reranking using dot-product in the ANCE-learned\nrepresentation space and provides almost 100x speed-up.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 23:15:56 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 22:17:19 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Xiong", "Lee", ""], ["Xiong", "Chenyan", ""], ["Li", "Ye", ""], ["Tang", "Kwok-Fung", ""], ["Liu", "Jialin", ""], ["Bennett", "Paul", ""], ["Ahmed", "Junaid", ""], ["Overwijk", "Arnold", ""]]}, {"id": "2007.00814", "submitter": "Omar Khattab", "authors": "Omar Khattab, Christopher Potts, Matei Zaharia", "title": "Relevance-guided Supervision for OpenQA with ColBERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems for Open-Domain Question Answering (OpenQA) generally depend on a\nretriever for finding candidate passages in a large corpus and a reader for\nextracting answers from those passages. In much recent work, the retriever is a\nlearned component that uses coarse-grained vector representations of questions\nand passages. We argue that this modeling choice is insufficiently expressive\nfor dealing with the complexity of natural language questions. To address this,\nwe define ColBERT-QA, which adapts the scalable neural retrieval model ColBERT\nto OpenQA. ColBERT creates fine-grained interactions between questions and\npassages. We propose a weak supervision strategy that iteratively uses ColBERT\nto create its own training data. This greatly improves OpenQA retrieval on both\nNatural Questions and TriviaQA, and the resulting end-to-end OpenQA system\nattains state-of-the-art performance on both of those datasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 23:50:58 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Khattab", "Omar", ""], ["Potts", "Christopher", ""], ["Zaharia", "Matei", ""]]}, {"id": "2007.00824", "submitter": "Gabriela Ferraro", "authors": "Gabriela Ferraro and Brendan Loo Gee and Shenjia Ji and Luis\n  Salvador-Carulla", "title": "Lightme: Analysing Language in Internet Support Groups for Mental Health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: Assisting moderators to triage harmful posts in Internet Support\nGroups is relevant to ensure its safe use. Automated text classification\nmethods analysing the language expressed in posts of online forums is a\npromising solution. Methods: Natural Language Processing and Machine Learning\ntechnologies were used to build a triage post classifier using a dataset from\nReachout mental health forum for young people. Results: When comparing with the\nstate-of-the-art, a solution mainly based on features from lexical resources,\nreceived the best classification performance for the crisis posts (52%), which\nis the most severe class. Six salient linguistic characteristics were found\nwhen analysing the crisis post; 1) posts expressing hopelessness, 2) short\nposts expressing concise negative emotional responses, 3) long posts expressing\nvariations of emotions, 4) posts expressing dissatisfaction with available\nhealth services, 5) posts utilising storytelling, and 6) posts expressing users\nseeking advice from peers during a crisis. Conclusion: It is possible to build\na competitive triage classifier using features derived only from the textual\ncontent of the post. Further research needs to be done in order to translate\nour quantitative and qualitative findings into features, as it may improve\noverall performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 01:25:22 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 00:45:15 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Ferraro", "Gabriela", ""], ["Gee", "Brendan Loo", ""], ["Ji", "Shenjia", ""], ["Salvador-Carulla", "Luis", ""]]}, {"id": "2007.00849", "submitter": "Haitian Sun", "authors": "Pat Verga, Haitian Sun, Livio Baldini Soares, William W. Cohen", "title": "Facts as Experts: Adaptable and Interpretable Neural Memory over\n  Symbolic Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive language models are the core of modern NLP modeling and have been\nshown to encode impressive amounts of commonsense and factual information.\nHowever, that knowledge exists only within the latent parameters of the model,\ninaccessible to inspection and interpretation, and even worse, factual\ninformation memorized from the training corpora is likely to become stale as\nthe world changes. Knowledge stored as parameters will also inevitably exhibit\nall of the biases inherent in the source materials. To address these problems,\nwe develop a neural language model that includes an explicit interface between\nsymbolically interpretable factual information and subsymbolic neural\nknowledge. We show that this model dramatically improves performance on two\nknowledge-intensive question-answering tasks. More interestingly, the model can\nbe updated without re-training by manipulating its symbolic representations. In\nparticular this model allows us to add new facts and overwrite existing ones in\nways that are not possible for earlier models.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 03:05:41 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Verga", "Pat", ""], ["Sun", "Haitian", ""], ["Soares", "Livio Baldini", ""], ["Cohen", "William W.", ""]]}, {"id": "2007.00875", "submitter": "Nikka Mofid", "authors": "Chetanya Rastogi, Nikka Mofid, Fang-I Hsiao", "title": "Can We Achieve More with Less? Exploring Data Augmentation for Toxic\n  Comment Classification", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles one of the greatest limitations in Machine Learning: Data\nScarcity. Specifically, we explore whether high accuracy classifiers can be\nbuilt from small datasets, utilizing a combination of data augmentation\ntechniques and machine learning algorithms. In this paper, we experiment with\nEasy Data Augmentation (EDA) and Backtranslation, as well as with three popular\nlearning algorithms, Logistic Regression, Support Vector Machine (SVM), and\nBidirectional Long Short-Term Memory Network (Bi-LSTM). For our\nexperimentation, we utilize the Wikipedia Toxic Comments dataset so that in the\nprocess of exploring the benefits of data augmentation, we can develop a model\nto detect and classify toxic speech in comments to help fight back against\ncyberbullying and online harassment. Ultimately, we found that data\naugmentation techniques can be used to significantly boost the performance of\nclassifiers and are an excellent strategy to combat lack of data in NLP\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 04:43:31 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Rastogi", "Chetanya", ""], ["Mofid", "Nikka", ""], ["Hsiao", "Fang-I", ""]]}, {"id": "2007.00916", "submitter": "Hayate Iso", "authors": "Hayate Iso, Chao Qiao, Hang Li", "title": "Fact-based Text Editing", "comments": "ACL 2020", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.17", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel text editing task, referred to as \\textit{fact-based text\nediting}, in which the goal is to revise a given document to better describe\nthe facts in a knowledge base (e.g., several triples). The task is important in\npractice because reflecting the truth is a common requirement in text editing.\nFirst, we propose a method for automatically generating a dataset for research\non fact-based text editing, where each instance consists of a draft text, a\nrevised text, and several facts represented in triples. We apply the method\ninto two public table-to-text datasets, obtaining two new datasets consisting\nof 233k and 37k instances, respectively. Next, we propose a new neural network\narchitecture for fact-based text editing, called \\textsc{FactEditor}, which\nedits a draft text by referring to given facts using a buffer, a stream, and a\nmemory. A straightforward approach to address the problem would be to employ an\nencoder-decoder model. Our experimental results on the two datasets show that\n\\textsc{FactEditor} outperforms the encoder-decoder approach in terms of\nfidelity and fluency. The results also show that \\textsc{FactEditor} conducts\ninference faster than the encoder-decoder approach.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:50:30 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Iso", "Hayate", ""], ["Qiao", "Chao", ""], ["Li", "Hang", ""]]}, {"id": "2007.00924", "submitter": "Luxi Xing", "authors": "Luxi Xing, Yuqiang Xie, Yue Hu, Wei Peng", "title": "IIE-NLP-NUT at SemEval-2020 Task 4: Guiding PLM with Prompt Template\n  Reconstruction Strategy for ComVE", "comments": "8 pages, 1 figure, 5 tables, SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces our systems for the first two subtasks of SemEval\nTask4: Commonsense Validation and Explanation. To clarify the intention for\njudgment and inject contrastive information for selection, we propose the input\nreconstruction strategy with prompt templates. Specifically, we formalize the\nsubtasks into the multiple-choice question answering format and construct the\ninput with the prompt templates, then, the final prediction of question\nanswering is considered as the result of subtasks. Experimental results show\nthat our approaches achieve significant performance compared with the baseline\nsystems. Our approaches secure the third rank on both official test sets of the\nfirst two subtasks with an accuracy of 96.4 and an accuracy of 94.3\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:59:53 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Xing", "Luxi", ""], ["Xie", "Yuqiang", ""], ["Hu", "Yue", ""], ["Peng", "Wei", ""]]}, {"id": "2007.00968", "submitter": "Jacopo Staiano", "authors": "Rachel Keraron, Guillaume Lancrenon, Mathilde Bras, Fr\\'ed\\'eric\n  Allary, Gilles Moyse, Thomas Scialom, Edmundo-Pavel Soriano-Morales, Jacopo\n  Staiano", "title": "Project PIAF: Building a Native French Question-Answering Dataset", "comments": "LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the lack of data for non-English languages, in particular for\nthe evaluation of downstream tasks such as Question Answering, we present a\nparticipatory effort to collect a native French Question Answering Dataset.\nFurthermore, we describe and publicly release the annotation tool developed for\nour collection effort, along with the data obtained and preliminary baselines.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 08:59:15 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Keraron", "Rachel", ""], ["Lancrenon", "Guillaume", ""], ["Bras", "Mathilde", ""], ["Allary", "Fr\u00e9d\u00e9ric", ""], ["Moyse", "Gilles", ""], ["Scialom", "Thomas", ""], ["Soriano-Morales", "Edmundo-Pavel", ""], ["Staiano", "Jacopo", ""]]}, {"id": "2007.00991", "submitter": "Eugene Kharitonov", "authors": "Eugene Kharitonov and Morgane Rivi\\`ere and Gabriel Synnaeve and Lior\n  Wolf and Pierre-Emmanuel Mazar\\'e and Matthijs Douze and Emmanuel Dupoux", "title": "Data Augmenting Contrastive Learning of Speech Representations in the\n  Time Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive Predictive Coding (CPC), based on predicting future segments of\nspeech based on past segments is emerging as a powerful algorithm for\nrepresentation learning of speech signal. However, it still under-performs\nother methods on unsupervised evaluation benchmarks. Here, we introduce\nWavAugment, a time-domain data augmentation library and find that applying\naugmentation in the past is generally more efficient and yields better\nperformances than other methods. We find that a combination of pitch\nmodification, additive noise and reverberation substantially increase the\nperformance of CPC (relative improvement of 18-22%), beating the reference\nLibri-light results with 600 times less data. Using an out-of-domain dataset,\ntime-domain data augmentation can push CPC to be on par with the state of the\nart on the Zero Speech Benchmark 2017. We also show that time-domain data\naugmentation consistently improves downstream limited-supervision phoneme\nclassification tasks by a factor of 12-15% relative.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 09:59:51 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Rivi\u00e8re", "Morgane", ""], ["Synnaeve", "Gabriel", ""], ["Wolf", "Lior", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Douze", "Matthijs", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2007.01022", "submitter": "Lukas Lange", "authors": "Lukas Lange, Heike Adel, Jannik Str\\\"otgen", "title": "NLNDE: Enhancing Neural Sequence Taggers with Attention and Noisy\n  Channel for Robust Pharmacological Entity Detection", "comments": "Published at BioNLP-OST@EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-5705", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition has been extensively studied on English news texts.\nHowever, the transfer to other domains and languages is still a challenging\nproblem. In this paper, we describe the system with which we participated in\nthe first subtrack of the PharmaCoNER competition of the BioNLP Open Shared\nTasks 2019. Aiming at pharmacological entity detection in Spanish texts, the\ntask provides a non-standard domain and language setting. However, we propose\nan architecture that requires neither language nor domain expertise. We treat\nthe task as a sequence labeling task and experiment with attention-based\nembedding selection and the training on automatically annotated data to further\nimprove our system's performance. Our system achieves promising results,\nespecially by combining the different techniques, and reaches up to 88.6% F1 in\nthe competition.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:17:16 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Lange", "Lukas", ""], ["Adel", "Heike", ""], ["Str\u00f6tgen", "Jannik", ""]]}, {"id": "2007.01030", "submitter": "Lukas Lange", "authors": "Lukas Lange, Heike Adel, Jannik Str\\\"otgen", "title": "NLNDE: The Neither-Language-Nor-Domain-Experts' Way of Spanish Medical\n  Document De-Identification", "comments": "Published at IberLEF 2019. Winning System of the MEDDOCAN shared task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing has huge potential in the medical domain which\nrecently led to a lot of research in this field. However, a prerequisite of\nsecure processing of medical documents, e.g., patient notes and clinical\ntrials, is the proper de-identification of privacy-sensitive information. In\nthis paper, we describe our NLNDE system, with which we participated in the\nMEDDOCAN competition, the medical document anonymization task of IberLEF 2019.\nWe address the task of detecting and classifying protected health information\nfrom Spanish data as a sequence-labeling problem and investigate different\nembedding methods for our neural network. Despite dealing in a non-standard\nlanguage and domain setting, the NLNDE system achieves promising results in the\ncompetition.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 11:30:32 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Lange", "Lukas", ""], ["Adel", "Heike", ""], ["Str\u00f6tgen", "Jannik", ""]]}, {"id": "2007.01127", "submitter": "Manit Mishra", "authors": "Shivaji Alaparthi (Data Scientist, CenturyLink, Bengaluru, India) and\n  Manit Mishra (Associate Professor, International Management Institute\n  Bhubaneswar, India)", "title": "Bidirectional Encoder Representations from Transformers (BERT): A\n  sentiment analysis odyssey", "comments": "15 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the study is to investigate the relative effectiveness of four\ndifferent sentiment analysis techniques: (1) unsupervised lexicon-based model\nusing Sent WordNet; (2) traditional supervised machine learning model using\nlogistic regression; (3) supervised deep learning model using Long Short-Term\nMemory (LSTM); and, (4) advanced supervised deep learning models using\nBidirectional Encoder Representations from Transformers (BERT). We use publicly\navailable labeled corpora of 50,000 movie reviews originally posted on internet\nmovie database (IMDB) for analysis using Sent WordNet lexicon, logistic\nregression, LSTM, and BERT. The first three models were run on CPU based system\nwhereas BERT was run on GPU based system. The sentiment classification\nperformance was evaluated based on accuracy, precision, recall, and F1 score.\nThe study puts forth two key insights: (1) relative efficacy of four highly\nadvanced and widely used sentiment analysis techniques; (2) undisputed\nsuperiority of pre-trained advanced supervised deep learning BERT model in\nsentiment analysis from text data. This study provides professionals in\nanalytics industry and academicians working on text analysis key insight\nregarding comparative classification performance evaluation of key sentiment\nanalysis techniques, including the recently developed BERT. This is the first\nresearch endeavor to compare the advanced pre-trained supervised deep learning\nmodel of BERT vis-\\`a-vis other sentiment analysis models of LSTM, logistic\nregression, and Sent WordNet.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 14:23:57 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Alaparthi", "Shivaji", "", "Data Scientist, CenturyLink, Bengaluru, India"], ["Mishra", "Manit", "", "Associate Professor, International Management Institute\n  Bhubaneswar, India"]]}, {"id": "2007.01176", "submitter": "Sabrina Mielke", "authors": "Brian Roark, Lawrence Wolf-Sonkin, Christo Kirov, Sabrina J. Mielke,\n  Cibu Johny, Isin Demirsahin, Keith Hall", "title": "Processing South Asian Languages Written in the Latin Script: the\n  Dakshina Dataset", "comments": "Published at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Dakshina dataset, a new resource consisting of text\nin both the Latin and native scripts for 12 South Asian languages. The dataset\nincludes, for each language: 1) native script Wikipedia text; 2) a romanization\nlexicon; and 3) full sentence parallel data in both a native script of the\nlanguage and the basic Latin alphabet. We document the methods used for\npreparation and selection of the Wikipedia text in each language; collection of\nattested romanizations for sampled lexicons; and manual romanization of\nheld-out sentences from the native script collections. We additionally provide\nbaseline results on several tasks made possible by the dataset, including\nsingle word transliteration, full sentence transliteration, and language\nmodeling of native script and romanized text. Keywords: romanization,\ntransliteration, South Asian languages\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 14:57:28 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Roark", "Brian", ""], ["Wolf-Sonkin", "Lawrence", ""], ["Kirov", "Christo", ""], ["Mielke", "Sabrina J.", ""], ["Johny", "Cibu", ""], ["Demirsahin", "Isin", ""], ["Hall", "Keith", ""]]}, {"id": "2007.01189", "submitter": "Avinash Madasu", "authors": "Avinash Madasu and Vijjini Anvesh Rao", "title": "Sequential Domain Adaptation through Elastic Weight Consolidation for\n  Sentiment Analysis", "comments": "Accepted at 25th International Conference on Pattern Recognition,\n  January 2021, Milan, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elastic Weight Consolidation (EWC) is a technique used in overcoming\ncatastrophic forgetting between successive tasks trained on a neural network.\nWe use this phenomenon of information sharing between tasks for domain\nadaptation. Training data for tasks such as sentiment analysis (SA) may not be\nfairly represented across multiple domains. Domain Adaptation (DA) aims to\nbuild algorithms that leverage information from source domains to facilitate\nperformance on an unseen target domain. We propose a model-independent\nframework - Sequential Domain Adaptation (SDA). SDA draws on EWC for training\non successive source domains to move towards a general domain solution, thereby\nsolving the problem of domain adaptation. We test SDA on convolutional,\nrecurrent, and attention-based architectures. Our experiments show that the\nproposed framework enables simple architectures such as CNNs to outperform\ncomplex state-of-the-art models in domain adaptation of SA. In addition, we\nobserve that the effectiveness of a harder first Anti-Curriculum ordering of\nsource domains leads to maximum performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 15:21:56 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 11:06:07 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 08:50:19 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Madasu", "Avinash", ""], ["Rao", "Vijjini Anvesh", ""]]}, {"id": "2007.01282", "submitter": "Gautier Izacard", "authors": "Gautier Izacard and Edouard Grave", "title": "Leveraging Passage Retrieval with Generative Models for Open Domain\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for open domain question answering have proven to be\ncompetitive, without resorting to external knowledge. While promising, this\napproach requires to use models with billions of parameters, which are\nexpensive to train and query. In this paper, we investigate how much these\nmodels can benefit from retrieving text passages, potentially containing\nevidence. We obtain state-of-the-art results on the Natural Questions and\nTriviaQA open benchmarks. Interestingly, we observe that the performance of\nthis method significantly improves when increasing the number of retrieved\npassages. This is evidence that generative models are good at aggregating and\ncombining evidence from multiple passages.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 17:44:57 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 09:18:34 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Izacard", "Gautier", ""], ["Grave", "Edouard", ""]]}, {"id": "2007.01359", "submitter": "Santosh Kesiraju", "authors": "Santosh Kesiraju, Sangeet Sagar, Ond\\v{r}ej Glembek, Luk\\'a\\v{s}\n  Burget, Suryakanth V Gangashetty", "title": "Bayesian multilingual topic model for zero-shot cross-lingual topic\n  identification", "comments": "Requires a major revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Bayesian multilingual topic model for learning\nlanguage-independent document embeddings. Our model learns to represent the\ndocuments in the form of Gaussian distributions, thereby encoding the\nuncertainty in its covariance. We propagate the learned uncertainties through\nlinear classifiers for zero-shot cross-lingual topic identification. Our\nexperiments on 5 language Europarl and Reuters (MLDoc) corpora show that the\nproposed model outperforms multi-lingual word embedding and BiLSTM sentence\nencoder based systems with significant margins in the majority of the transfer\ndirections. Moreover, our system trained under a single day on a single GPU\nwith much lower amounts of data performs competitively as compared to the\nstate-of-the-art universal BiLSTM sentence encoder trained on 93 languages. Our\nexperimental analysis shows that the amount of parallel data improves the\noverall performance of embeddings. Nonetheless, exploiting the uncertainties is\nalways beneficial.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 19:55:08 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 12:46:45 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kesiraju", "Santosh", ""], ["Sagar", "Sangeet", ""], ["Glembek", "Ond\u0159ej", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Gangashetty", "Suryakanth V", ""]]}, {"id": "2007.01379", "submitter": "Mariano Maisonnave", "authors": "Mariano Maisonnave, Fernando Delbianco, Fernando Tohm\\'e, Ana\n  Maguitman, Evangelos Milios", "title": "Detecting Ongoing Events Using Contextual Word and Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Ongoing Event Detection (OED) task, which is a\nspecific Event Detection task where the goal is to detect ongoing event\nmentions only, as opposed to historical, future, hypothetical, or other forms\nor events that are neither fresh nor current. Any application that needs to\nextract structured information about ongoing events from unstructured texts can\ntake advantage of an OED system. The main contribution of this paper are the\nfollowing: (1) it introduces the OED task along with a dataset manually labeled\nfor the task; (2) it presents the design and implementation of an RNN model for\nthe task that uses BERT embeddings to define contextual word and contextual\nsentence embeddings as attributes, which to the best of our knowledge were\nnever used before for detecting ongoing events in news; (3) it presents an\nextensive empirical evaluation that includes (i) the exploration of different\narchitectures and hyperparameters, (ii) an ablation test to study the impact of\neach attribute, and (iii) a comparison with a replication of a state-of-the-art\nmodel. The results offer several insights into the importance of contextual\nembeddings and indicate that the proposed approach is effective in the OED\ntask, outperforming the baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 20:44:05 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 19:51:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Maisonnave", "Mariano", ""], ["Delbianco", "Fernando", ""], ["Tohm\u00e9", "Fernando", ""], ["Maguitman", "Ana", ""], ["Milios", "Evangelos", ""]]}, {"id": "2007.01488", "submitter": "Jianing Li", "authors": "Jianing Li, Yanyan Lan, Jiafeng Guo, Xueqi Cheng", "title": "On the Relation between Quality-Diversity Evaluation and\n  Distribution-Fitting Goal in Text Generation", "comments": "16 pages, 7 figures. ICML2020 Final Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of text generation models is to fit the underlying real probability\ndistribution of text. For performance evaluation, quality and diversity metrics\nare usually applied. However, it is still not clear to what extend can the\nquality-diversity evaluation reflect the distribution-fitting goal. In this\npaper, we try to reveal such relation in a theoretical approach. We prove that\nunder certain conditions, a linear combination of quality and diversity\nconstitutes a divergence metric between the generated distribution and the real\ndistribution. We also show that the commonly used BLEU/Self-BLEU metric pair\nfails to match any divergence metric, thus propose CR/NRR as a substitute for\nquality/diversity metric pair.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 04:06:59 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 03:37:59 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Li", "Jianing", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2007.01510", "submitter": "Yusi Zhang", "authors": "Yusi Zhang, Chuanjie Liu, Angen Luo, Hui Xue, Xuan Shan, Yuxiang Luo,\n  Yiqian Xia, Yuanchi Yan, Haidong Wang", "title": "MIRA: Leveraging Multi-Intention Co-click Information in Web-scale\n  Document Retrieval using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of deep recall model in industrial web search, which is,\ngiven a user query, retrieve hundreds of most relevance documents from billions\nof candidates. The common framework is to train two encoding models based on\nneural embedding which learn the distributed representations of queries and\ndocuments separately and match them in the latent semantic space. However, all\nthe exiting encoding models only leverage the information of the document\nitself, which is often not sufficient in practice when matching with query\nterms, especially for the hard tail queries. In this work we aim to leverage\nthe additional information for each document from its co-click neighbour to\nhelp document retrieval. The challenges include how to effectively extract\ninformation and eliminate noise when involving co-click information in deep\nmodel while meet the demands of billion-scale data size for real time online\ninference.\n  To handle the noise in co-click relations, we firstly propose a web-scale\nMulti-Intention Co-click document Graph(MICG) which builds the co-click\nconnections between documents on click intention level but not on document\nlevel. Then we present an encoding framework MIRA based on Bert and graph\nattention networks which leverages a two-factor attention mechanism to\naggregate neighbours. To meet the online latency requirements, we only involve\nneighbour information in document side, which can save the time-consuming query\nneighbor search in real time serving. We conduct extensive offline experiments\non both public dataset and private web-scale dataset from two major commercial\nsearch engines demonstrating the effectiveness and scalability of the proposed\nmethod compared with several baselines. And a further case study reveals that\nco-click relations mainly help improve web search quality from two aspects: key\nconcept enhancing and query term complementary.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 06:32:48 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Zhang", "Yusi", ""], ["Liu", "Chuanjie", ""], ["Luo", "Angen", ""], ["Xue", "Hui", ""], ["Shan", "Xuan", ""], ["Luo", "Yuxiang", ""], ["Xia", "Yiqian", ""], ["Yan", "Yuanchi", ""], ["Wang", "Haidong", ""]]}, {"id": "2007.01528", "submitter": "Hai Wang", "authors": "Hai Wang, David McAllester", "title": "On-The-Fly Information Retrieval Augmentation for Language Models", "comments": "ACL 2020 NUSE Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we experiment with the use of information retrieval as an augmentation\nfor pre-trained language models. The text corpus used in information retrieval\ncan be viewed as form of episodic memory which grows over time. By augmenting\nGPT 2.0 with information retrieval we achieve a zero shot 15% relative\nreduction in perplexity on Gigaword corpus without any re-training. We also\nvalidate our IR augmentation on an event co-reference task.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 07:31:14 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wang", "Hai", ""], ["McAllester", "David", ""]]}, {"id": "2007.01652", "submitter": "Heng-Da Xu", "authors": "Heng-Da Xu, Xian-Ling Mao, Zewen Chi, Jing-Jing Zhu, Fanshu Sun, Heyan\n  Huang", "title": "Generating Informative Dialogue Responses with Keywords-Guided Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, open-domain dialogue systems have attracted growing attention. Most\nof them use the sequence-to-sequence (Seq2Seq) architecture to generate\nresponses. However, traditional Seq2Seq-based open-domain dialogue models tend\nto generate generic and safe responses, which are less informative, unlike\nhuman responses. In this paper, we propose a simple but effective\nkeywords-guided Sequence-to-Sequence model (KW-Seq2Seq) which uses keywords\ninformation as guidance to generate open-domain dialogue responses.\nSpecifically, KW-Seq2Seq first uses a keywords decoder to predict some topic\nkeywords, and then generates the final response under the guidance of them.\nExtensive experiments demonstrate that the KW-Seq2Seq model produces more\ninformative, coherent and fluent responses, yielding substantive gain in both\nautomatic and human evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 12:47:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Xu", "Heng-Da", ""], ["Mao", "Xian-Ling", ""], ["Chi", "Zewen", ""], ["Zhu", "Jing-Jing", ""], ["Sun", "Fanshu", ""], ["Huang", "Heyan", ""]]}, {"id": "2007.01658", "submitter": "Martin Malmsten", "authors": "Martin Malmsten, Love B\\\"orjeson and Chris Haffenden", "title": "Playing with Words at the National Library of Sweden -- Making a Swedish\n  BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces the Swedish BERT (\"KB-BERT\") developed by the KBLab for\ndata-driven research at the National Library of Sweden (KB). Building on recent\nefforts to create transformer-based BERT models for languages other than\nEnglish, we explain how we used KB's collections to create and train a new\nlanguage-specific BERT model for Swedish. We also present the results of our\nmodel in comparison with existing models - chiefly that produced by the Swedish\nPublic Employment Service, Arbetsf\\\"ormedlingen, and Google's multilingual\nM-BERT - where we demonstrate that KB-BERT outperforms these in a range of NLP\ntasks from named entity recognition (NER) to part-of-speech tagging (POS). Our\ndiscussion highlights the difficulties that continue to exist given the lack of\ntraining data and testbeds for smaller languages like Swedish. We release our\nmodel for further exploration and research here:\nhttps://github.com/Kungbib/swedish-bert-models .\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 12:53:39 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Malmsten", "Martin", ""], ["B\u00f6rjeson", "Love", ""], ["Haffenden", "Chris", ""]]}, {"id": "2007.01667", "submitter": "Milan Straka", "authors": "Kate\\v{r}ina Mackov\\'a, Milan Straka", "title": "Reading Comprehension in Czech via Machine Translation and Cross-lingual\n  Transfer", "comments": "Accepted at TSD 2020, 23rd International Conference on Text, Speech\n  and Dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension is a well studied task, with huge training datasets in\nEnglish. This work focuses on building reading comprehension systems for Czech,\nwithout requiring any manually annotated Czech training data. First of all, we\nautomatically translated SQuAD 1.1 and SQuAD 2.0 datasets to Czech to create\ntraining and development data, which we release at\nhttp://hdl.handle.net/11234/1-3249. We then trained and evaluated several BERT\nand XLM-RoBERTa baseline models. However, our main focus lies in cross-lingual\ntransfer models. We report that a XLM-RoBERTa model trained on English data and\nevaluated on Czech achieves very competitive performance, only approximately 2\npercent points worse than a~model trained on the translated Czech data. This\nresult is extremely good, considering the fact that the model has not seen any\nCzech data during training. The cross-lingual transfer approach is very\nflexible and provides a reading comprehension in any language, for which we\nhave enough monolingual raw texts.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 13:09:37 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Mackov\u00e1", "Kate\u0159ina", ""], ["Straka", "Milan", ""]]}, {"id": "2007.01777", "submitter": "Dat Hong", "authors": "Dat Hong, Stephen S. Baek, Tong Wang", "title": "Interpretable Sequence Classification Via Prototype Trajectory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel interpretable recurrent neural network (RNN) model, called\nProtoryNet, in which we introduce a new concept of prototype trajectories.\nMotivated by the prototype theory in modern linguistics, ProtoryNet makes a\nprediction by finding the most similar prototype for each sentence in a text\nsequence and feeding an RNN backbone with the proximity of each of the\nsentences to the prototypes. The RNN backbone then captures the temporal\npattern of the prototypes, to which we refer as prototype trajectories. The\nprototype trajectories enable intuitive, fine-grained interpretation of how the\nmodel reached to the final prediction, resembling the process of how humans\nanalyze paragraphs. Experiments conducted on multiple public data sets reveal\nthat the proposed method not only is more interpretable but also is more\naccurate than the current state-of-the-art prototype-based method. Furthermore,\nwe report a survey result indicating that human users find ProtoryNet more\nintuitive and easier to understand, compared to the other prototype-based\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:00:26 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Hong", "Dat", ""], ["Baek", "Stephen S.", ""], ["Wang", "Tong", ""]]}, {"id": "2007.01780", "submitter": "Amelia Pollard", "authors": "Amelia Elizabeth Pollard and Jonathan L. Shapiro", "title": "Visual Question Answering as a Multi-Task Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering(VQA) is a highly complex problem set, relying on\nmany sub-problems to produce reasonable answers. In this paper, we present the\nhypothesis that Visual Question Answering should be viewed as a multi-task\nproblem, and provide evidence to support this hypothesis. We demonstrate this\nby reformatting two commonly used Visual Question Answering datasets, COCO-QA\nand DAQUAR, into a multi-task format and train these reformatted datasets on\ntwo baseline networks, with one designed specifically to eliminate other\npossible causes for performance changes as a result of the reformatting. Though\nthe networks demonstrated in this paper do not achieve strongly competitive\nresults, we find that the multi-task approach to Visual Question Answering\nresults in increases in performance of 5-9% against the single-task formatting,\nand that the networks reach convergence much faster than in the single-task\ncase. Finally we discuss possible reasons for the observed difference in\nperformance, and perform additional experiments which rule out causes not\nassociated with the learning of the dataset as a multi-task problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:07:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Pollard", "Amelia Elizabeth", ""], ["Shapiro", "Jonathan L.", ""]]}, {"id": "2007.01788", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos, Alessandro Cattelan, Zi-Yi Dou, Marcello\n  Federico, Christian Federman, Dmitriy Genzel, Francisco Guzm\\'an, Junjie Hu,\n  Macduff Hughes, Philipp Koehn, Rosie Lazar, Will Lewis, Graham Neubig,\n  Mengmeng Niu, Alp \\\"Oktem, Eric Paquin, Grace Tang, and Sylwia Tur", "title": "TICO-19: the Translation Initiative for Covid-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic is the worst pandemic to strike the world in over a\ncentury. Crucial to stemming the tide of the SARS-CoV-2 virus is communicating\nto vulnerable populations the means by which they can protect themselves. To\nthis end, the collaborators forming the Translation Initiative for COvid-19\n(TICO-19) have made test and development data available to AI and MT\nresearchers in 35 different languages in order to foster the development of\ntools and resources for improving access to information about COVID-19 in these\nlanguages. In addition to 9 high-resourced, \"pivot\" languages, the team is\ntargeting 26 lesser resourced languages, in particular languages of Africa,\nSouth Asia and South-East Asia, whose populations may be the most vulnerable to\nthe spread of the virus. The same data is translated into all of the languages\nrepresented, meaning that testing or development can be done for any pairing of\nlanguages in the set. Further, the team is converting the test and development\ndata into translation memories (TMXs) that can be used by localizers from and\nto any of the languages.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:26:17 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 14:13:51 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Cattelan", "Alessandro", ""], ["Dou", "Zi-Yi", ""], ["Federico", "Marcello", ""], ["Federman", "Christian", ""], ["Genzel", "Dmitriy", ""], ["Guzm\u00e1n", "Francisco", ""], ["Hu", "Junjie", ""], ["Hughes", "Macduff", ""], ["Koehn", "Philipp", ""], ["Lazar", "Rosie", ""], ["Lewis", "Will", ""], ["Neubig", "Graham", ""], ["Niu", "Mengmeng", ""], ["\u00d6ktem", "Alp", ""], ["Paquin", "Eric", ""], ["Tang", "Grace", ""], ["Tur", "Sylwia", ""]]}, {"id": "2007.01800", "submitter": "Jingxuan Tu", "authors": "Jingxuan Tu, Marc Verhagen, Brent Cochran, James Pustejovsky", "title": "Exploration and Discovery of the COVID-19 Literature through Semantic\n  Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are developing semantic visualization techniques in order to enhance\nexploration and enable discovery over large datasets of complex networks of\nrelations. Semantic visualization is a method of enabling exploration and\ndiscovery over large datasets of complex networks by exploiting the semantics\nof the relations in them. This involves (i) NLP to extract named entities,\nrelations and knowledge graphs from the original data; (ii) indexing the output\nand creating representations for all relevant entities and relations that can\nbe visualized in many different ways, e.g., as tag clouds, heat maps, graphs,\netc.; (iii) applying parameter reduction operations to the extracted relations,\ncreating \"relation containers\", or functional entities that can also be\nvisualized using the same methods, allowing the visualization of multiple\nrelations, partial pathways, and exploration across multiple dimensions. Our\nhope is that this will enable the discovery of novel inferences over relations\nin complex data that otherwise would go unnoticed. We have applied this to\nanalysis of the recently released CORD-19 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:40:37 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Tu", "Jingxuan", ""], ["Verhagen", "Marc", ""], ["Cochran", "Brent", ""], ["Pustejovsky", "James", ""]]}, {"id": "2007.01836", "submitter": "Pavel Denisov", "authors": "Pavel Denisov, Ngoc Thang Vu", "title": "Pretrained Semantic Speech Embeddings for End-to-End Spoken Language\n  Understanding via Cross-Modal Teacher-Student Learning", "comments": "Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Spoken language understanding is typically based on pipeline architectures\nincluding speech recognition and natural language understanding steps. These\ncomponents are optimized independently to allow usage of available data, but\nthe overall system suffers from error propagation. In this paper, we propose a\nnovel training method that enables pretrained contextual embeddings to process\nacoustic features. In particular, we extend it with an encoder of pretrained\nspeech recognition systems in order to construct end-to-end spoken language\nunderstanding systems. Our proposed method is based on the teacher-student\nframework across speech and text modalities that aligns the acoustic and the\nsemantic latent spaces. Experimental results in three benchmarks show that our\nsystem reaches the performance comparable to the pipeline architecture without\nusing any training data and outperforms it after fine-tuning with ten examples\nper class on two out of three benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 17:43:12 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 23:32:56 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "2007.01852", "submitter": "Yinfei Yang", "authors": "Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, Wei Wang", "title": "Language-agnostic BERT Sentence Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt multilingual BERT to produce language-agnostic sentence embeddings\nfor 109 languages. %The state-of-the-art for numerous monolingual and\nmultilingual NLP tasks is masked language model (MLM) pretraining followed by\ntask specific fine-tuning. While English sentence embeddings have been obtained\nby fine-tuning a pretrained BERT model, such models have not been applied to\nmultilingual sentence embeddings. Our model combines masked language model\n(MLM) and translation language model (TLM) pretraining with a translation\nranking task using bi-directional dual encoders. The resulting multilingual\nsentence embeddings improve average bi-text retrieval accuracy over 112\nlanguages to 83.7%, well above the 65.5% achieved by the prior state-of-the-art\non Tatoeba. Our sentence embeddings also establish new state-of-the-art results\non BUCC and UN bi-text retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 17:58:42 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Feng", "Fangxiaoyu", ""], ["Yang", "Yinfei", ""], ["Cer", "Daniel", ""], ["Arivazhagan", "Naveen", ""], ["Wang", "Wei", ""]]}, {"id": "2007.01918", "submitter": "Roger Barrull", "authors": "Roger Barrull, Jugal Kalita", "title": "Abstractive and mixed summarization for long-single documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of diversity in the datasets available for automatic summarization\nof documents has meant that the vast majority of neural models for automatic\nsummarization have been trained with news articles. These datasets are\nrelatively small, with an average size of about 600 words, and the models\ntrained with such data sets see their performance limited to short documents.\nIn order to surmount this problem, this paper uses scientific papers as the\ndataset on which different models are trained. These models have been chosen\nbased on their performance on the CNN/Daily Mail data set, so that the highest\nranked model of each architectural variant is selected. In this work, six\ndifferent models are compared, two with an RNN architecture, one with a CNN\narchitecture, two with a Transformer architecture and one with a Transformer\narchitecture combined with reinforcement learning. The results from this work\nshow that those models that use a hierarchical encoder to model the structure\nof the document has a better performance than the rest.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 19:30:28 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Barrull", "Roger", ""], ["Kalita", "Jugal", ""]]}, {"id": "2007.01955", "submitter": "Mikhail Galkin", "authors": "Maria Khvalchik and Mikhail Galkin", "title": "El Departamento de Nosotros: How Machine Translated Corpora Affects\n  Language Models in MRC Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training large-scale language models (LMs) requires huge amounts of text\ncorpora. LMs for English enjoy ever growing corpora of diverse language\nresources. However, less resourced languages and their mono- and multilingual\nLMs often struggle to obtain bigger datasets. A typical approach in this case\nimplies using machine translation of English corpora to a target language. In\nthis work, we study the caveats of applying directly translated corpora for\nfine-tuning LMs for downstream natural language processing tasks and\ndemonstrate that careful curation along with post-processing lead to improved\nperformance and overall LMs robustness. In the empirical evaluation, we perform\na comparison of directly translated against curated Spanish SQuAD datasets on\nboth user and system levels. Further experimental results on XQuAD and MLQA\ntransfer-learning evaluation question answering tasks show that presumably\nmultilingual LMs exhibit more resilience to machine translation artifacts in\nterms of the exact match score.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 22:22:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Khvalchik", "Maria", ""], ["Galkin", "Mikhail", ""]]}, {"id": "2007.02025", "submitter": "Monica Sunkara", "authors": "Monica Sunkara, Srikanth Ronanki, Kalpit Dixit, Sravan Bodapati,\n  Katrin Kirchhoff", "title": "Robust Prediction of Punctuation and Truecasing for Medical ASR", "comments": "Accepted for ACL NLPMC workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems in the medical domain that focus\non transcribing clinical dictations and doctor-patient conversations often pose\nmany challenges due to the complexity of the domain. ASR output typically\nundergoes automatic punctuation to enable users to speak naturally, without\nhaving to vocalise awkward and explicit punctuation commands, such as \"period\",\n\"add comma\" or \"exclamation point\", while truecasing enhances user readability\nand improves the performance of downstream NLP tasks. This paper proposes a\nconditional joint modeling framework for prediction of punctuation and\ntruecasing using pretrained masked language models such as BERT, BioBERT and\nRoBERTa. We also present techniques for domain and task specific adaptation by\nfine-tuning masked language models with medical domain data. Finally, we\nimprove the robustness of the model against common errors made in ASR by\nperforming data augmentation. Experiments performed on dictation and\nconversational style corpora show that our proposed model achieves ~5% absolute\nimprovement on ground truth text and ~10% improvement on ASR outputs over\nbaseline models under F1 metric.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 07:15:13 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 17:53:01 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Sunkara", "Monica", ""], ["Ronanki", "Srikanth", ""], ["Dixit", "Kalpit", ""], ["Bodapati", "Sravan", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "2007.02033", "submitter": "Maxime Meyer", "authors": "Mehdi Regina and Maxime Meyer and S\\'ebastien Goutal", "title": "Text Data Augmentation: Towards better detection of spear-phishing\n  emails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text data augmentation, i.e., the creation of new textual data from an\nexisting text, is challenging. Indeed, augmentation transformations should take\ninto account language complexity while being relevant to the target Natural\nLanguage Processing (NLP) task (e.g., Machine Translation, Text\nClassification). Initially motivated by an application of Business Email\nCompromise (BEC) detection, we propose a corpus and task agnostic augmentation\nframework used as a service to augment English texts within our company. Our\nproposal combines different methods, utilizing BERT language model, multi-step\nback-translation and heuristics. We show that our augmentation framework\nimproves performances on several text classification tasks using publicly\navailable models and corpora as well as on a BEC detection task. We also\nprovide a comprehensive argumentation about the limitations of our augmentation\nframework.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 07:45:04 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 14:54:10 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Regina", "Mehdi", ""], ["Meyer", "Maxime", ""], ["Goutal", "S\u00e9bastien", ""]]}, {"id": "2007.02038", "submitter": "Saurav Sahay", "authors": "Saurav Sahay, Eda Okur, Shachi H Kumar, Lama Nachman", "title": "Low Rank Fusion based Transformers for Multimodal Sequences", "comments": "ACL 2020 workshop on Second Grand Challenge and Workshop on\n  Multimodal Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our senses individually work in a coordinated fashion to express our\nemotional intentions. In this work, we experiment with modeling\nmodality-specific sensory signals to attend to our latent multimodal emotional\nintentions and vice versa expressed via low-rank multimodal fusion and\nmultimodal transformers. The low-rank factorization of multimodal fusion\namongst the modalities helps represent approximate multiplicative latent signal\ninteractions. Motivated by the work of~\\cite{tsai2019MULT} and~\\cite{Liu_2018},\nwe present our transformer-based cross-fusion architecture without any\nover-parameterization of the model. The low-rank fusion helps represent the\nlatent signal interactions while the modality-specific attention helps focus on\nrelevant parts of the signal. We present two methods for the Multimodal\nSentiment and Emotion Recognition results on CMU-MOSEI, CMU-MOSI, and IEMOCAP\ndatasets and show that our models have lesser parameters, train faster and\nperform comparably to many larger fusion-based architectures.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 08:05:40 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Sahay", "Saurav", ""], ["Okur", "Eda", ""], ["Kumar", "Shachi H", ""], ["Nachman", "Lama", ""]]}, {"id": "2007.02100", "submitter": "Alberto Cetoli", "authors": "Alberto Cetoli", "title": "Pynsett: A programmable relation extractor", "comments": "Accepted for publication in SEMAPRO2020", "journal-ref": "The Fourteenth International Conference on Advances in Semantic\n  Processing (2020), Pages 45-48", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a programmable relation extraction method for the English\nlanguage by parsing texts into semantic graphs. A person can define rules in\nplain English that act as matching patterns onto the graph representation.\nThese rules are designed to capture the semantic content of the documents,\nallowing for flexibility and ad-hoc entities. Relation extraction is a complex\ntask that typically requires sizable training corpora. The method proposed here\nis ideal for extracting specialized ontologies in a limited collection of\ndocuments.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 14:03:48 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 22:52:29 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Cetoli", "Alberto", ""]]}, {"id": "2007.02144", "submitter": "Antony Samuels", "authors": "Antony Samuels, John Mcgonical", "title": "Sentiment Analysis on Social Media Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Nowadays, people from all around the world use social media sites to share\ninformation. Twitter for example is a platform in which users send, read posts\nknown as tweets and interact with different communities. Users share their\ndaily lives, post their opinions on everything such as brands and places.\nCompanies can benefit from this massive platform by collecting data related to\nopinions on them. The aim of this paper is to present a model that can perform\nsentiment analysis of real data collected from Twitter. Data in Twitter is\nhighly unstructured which makes it difficult to analyze. However, our proposed\nmodel is different from prior work in this field because it combined the use of\nsupervised and unsupervised machine learning algorithms. The process of\nperforming sentiment analysis as follows: Tweet extracted directly from Twitter\nAPI, then cleaning and discovery of data performed. After that the data were\nfed into several models for the purpose of training. Each tweet extracted\nclassified based on its sentiment whether it is a positive, negative or\nneutral. Data were collected on two subjects McDonalds and KFC to show which\nrestaurant has more popularity. Different machine learning algorithms were\nused. The result from these models were tested using various testing metrics\nlike cross validation and f-score. Moreover, our model demonstrates strong\nperformance on mining texts extracted directly from Twitter.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 17:03:30 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 02:42:14 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Samuels", "Antony", ""], ["Mcgonical", "John", ""]]}, {"id": "2007.02164", "submitter": "Yigeng Zhang", "authors": "Yigeng Zhang, Fan Yang, Yifan Zhang, Eduard Dragut and Arjun Mukherjee", "title": "Birds of a Feather Flock Together: Satirical News Detection via Language\n  Model Differentiation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satirical news is regularly shared in modern social media because it is\nentertaining with smartly embedded humor. However, it can be harmful to society\nbecause it can sometimes be mistaken as factual news, due to its deceptive\ncharacter. We found that in satirical news, the lexical and pragmatical\nattributes of the context are the key factors in amusing the readers. In this\nwork, we propose a method that differentiates the satirical news and true news.\nIt takes advantage of satirical writing evidence by leveraging the difference\nbetween the prediction loss of two language models, one trained on true news\nand the other on satirical news, when given a new news article. We compute\nseveral statistical metrics of language model prediction loss as features,\nwhich are then used to conduct downstream classification. The proposed method\nis computationally effective because the language models capture the language\nusage differences between satirical news documents and traditional news\ndocuments, and are sensitive when applied to documents outside their domains.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 18:46:36 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhang", "Yigeng", ""], ["Yang", "Fan", ""], ["Zhang", "Yifan", ""], ["Dragut", "Eduard", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "2007.02220", "submitter": "Roei Schuster", "authors": "Roei Schuster, Congzheng Song, Eran Tromer, Vitaly Shmatikov", "title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion", "comments": "Accepted at USENIX Security '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code autocompletion is an integral feature of modern code editors and IDEs.\nThe latest generation of autocompleters uses neural language models, trained on\npublic open-source code repositories, to suggest likely (not just statically\nfeasible) completions given the current context.\n  We demonstrate that neural code autocompleters are vulnerable to poisoning\nattacks. By adding a few specially-crafted files to the autocompleter's\ntraining corpus (data poisoning), or else by directly fine-tuning the\nautocompleter on these files (model poisoning), the attacker can influence its\nsuggestions for attacker-chosen contexts. For example, the attacker can \"teach\"\nthe autocompleter to suggest the insecure ECB mode for AES encryption, SSLv3\nfor the SSL/TLS protocol version, or a low iteration count for password-based\nencryption. Moreover, we show that these attacks can be targeted: an\nautocompleter poisoned by a targeted attack is much more likely to suggest the\ninsecure completion for files from a specific repo or specific developer.\n  We quantify the efficacy of targeted and untargeted data- and model-poisoning\nattacks against state-of-the-art autocompleters based on Pythia and GPT-2. We\nthen evaluate existing defenses against poisoning attacks and show that they\nare largely ineffective.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 01:13:36 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 21:34:38 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 23:12:25 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Schuster", "Roei", ""], ["Song", "Congzheng", ""], ["Tromer", "Eran", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2007.02237", "submitter": "Antony Samuels", "authors": "Antony Samuels, John Mcgonical", "title": "Sentiment Analysis on Customer Responses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sentiment analysis is one of the fastest spreading research areas in computer\nscience, making it challenging to keep track of all the activities in the area.\nWe present a customer feedback reviews on product, where we utilize opinion\nmining, text mining and sentiments, which has affected the surrounded world by\nchanging their opinion on a specific product. Data used in this study are\nonline product reviews collected from Amazon.com. We performed a comparative\nsentiment analysis of retrieved reviews. This research paper provides you with\nsentimental analysis of various smart phone opinions on smart phones dividing\nthem Positive, Negative and Neutral Behaviour.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 04:50:40 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Samuels", "Antony", ""], ["Mcgonical", "John", ""]]}, {"id": "2007.02238", "submitter": "Antony Samuels", "authors": "Antony Samuels, John Mcgonical", "title": "News Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern technological era has reshaped traditional lifestyle in several\ndomains. The medium of publishing news and events has become faster with the\nadvancement of Information Technology. IT has also been flooded with immense\namounts of data, which is being published every minute of every day, by\nmillions of users, in the shape of comments, blogs, news sharing through blogs,\nsocial media micro-blogging websites and many more. Manual traversal of such\nhuge data is a challenging job, thus, sophisticated methods are acquired to\nperform this task automatically and efficiently. News reports events that\ncomprise of emotions - good, bad, neutral. Sentiment analysis is utilized to\ninvestigate human emotions present in textual information. This paper presents\na lexicon-based approach for sentiment analysis of news articles. The\nexperiments have been performed on BBC news data set, which expresses the\napplicability and validation of the adopted approach.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 05:15:35 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Samuels", "Antony", ""], ["Mcgonical", "John", ""]]}, {"id": "2007.02244", "submitter": "A.B. Siddique", "authors": "A. B. Siddique, Samet Oymak, Vagelis Hristidis", "title": "Unsupervised Paraphrasing via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403231", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrasing is expressing the meaning of an input sentence in different\nwording while maintaining fluency (i.e., grammatical and syntactical\ncorrectness). Most existing work on paraphrasing use supervised models that are\nlimited to specific domains (e.g., image captions). Such models can neither be\nstraightforwardly transferred to other domains nor generalize well, and\ncreating labeled training data for new domains is expensive and laborious. The\nneed for paraphrasing across different domains and the scarcity of labeled\ntraining data in many such domains call for exploring unsupervised paraphrase\ngeneration methods. We propose Progressive Unsupervised Paraphrasing (PUP): a\nnovel unsupervised paraphrase generation method based on deep reinforcement\nlearning (DRL). PUP uses a variational autoencoder (trained using a\nnon-parallel corpus) to generate a seed paraphrase that warm-starts the DRL\nmodel. Then, PUP progressively tunes the seed paraphrase guided by our novel\nreward function which combines semantic adequacy, language fluency, and\nexpression diversity measures to quantify the quality of the generated\nparaphrases in each iteration without needing parallel sentences. Our extensive\nexperimental evaluation shows that PUP outperforms unsupervised\nstate-of-the-art paraphrasing techniques in terms of both automatic metrics and\nuser studies on four real datasets. We also show that PUP outperforms\ndomain-adapted supervised algorithms on several datasets. Our evaluation also\nshows that PUP achieves a great trade-off between semantic similarity and\ndiversity of expression.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 05:54:02 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Siddique", "A. B.", ""], ["Oymak", "Samet", ""], ["Hristidis", "Vagelis", ""]]}, {"id": "2007.02259", "submitter": "Wei-Yao Wang", "authors": "Wei-Yao Wang, Kai-Shiang Chang, Yu-Chien Tang", "title": "EmotionGIF-Yankee: A Sentiment Classifier with Robust Model Based\n  Ensemble Methods", "comments": "EmotionGIF 2020, the shared task of SocialNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a method to classify sentiment with robust model based\nensemble methods. We preprocess tweet data to enhance coverage of tokenizer. To\nreduce domain bias, we first train tweet dataset for pre-trained language\nmodel. Besides, each classifier has its strengths and weakness, we leverage\ndifferent types of models with ensemble methods: average and power weighted\nsum. From the experiments, we show that our approach has achieved positive\neffect for sentiment classification. Our system reached third place among 26\nteams from the evaluation in SocialNLP 2020 EmotionGIF competition.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 07:48:51 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wang", "Wei-Yao", ""], ["Chang", "Kai-Shiang", ""], ["Tang", "Yu-Chien", ""]]}, {"id": "2007.02282", "submitter": "Yong Li", "authors": "Yong Li, Andrea Turrini, Xuechao Sun, Lijun Zhang", "title": "Proving Non-Inclusion of B\\\"uchi Automata based on Monte Carlo Sampling", "comments": "Accepted to ATVA 2020; typos corrected; authors corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for a proof of correctness and the search for counterexamples\n(bugs) are complementary aspects of verification. In order to maximize the\npractical use of verification tools it is better to pursue them at the same\ntime. While this is well-understood in the termination analysis of programs,\nthis is not the case for the language inclusion analysis of B\\\"uchi automata,\nwhere research mainly focused on improving algorithms for proving language\ninclusion, with the search for counterexamples left to the expensive\ncomplementation operation.\n  In this paper, we present $\\mathsf{IMC}^2$, a specific algorithm for proving\nB\\\"uchi automata non-inclusion $\\mathcal{L}(\\mathcal{A}) \\not\\subseteq\n\\mathcal{L}(\\mathcal{B})$, based on Grosu and Smolka's algorithm\n$\\mathsf{MC}^2$ developed for Monte Carlo model checking against LTL formulas.\nThe algorithm we propose takes $M = \\lceil \\ln \\delta / \\ln (1-\\epsilon)\n\\rceil$ random lasso-shaped samples from $\\mathcal{A}$ to decide whether to\nreject the hypothesis $\\mathcal{L}(\\mathcal{A}) \\not\\subseteq\n\\mathcal{L}(\\mathcal{B})$, for given error probability $\\epsilon$ and\nconfidence level $1 - \\delta$. With such a number of samples, $\\mathsf{IMC}^2$\nensures that the probability of witnessing $\\mathcal{L}(\\mathcal{A})\n\\not\\subseteq \\mathcal{L}(\\mathcal{B})$ via further sampling is less than\n$\\delta$, under the assumption that the probability of finding a lasso\ncounterexample is larger than $\\epsilon$. Extensive experimental evaluation\nshows that $\\mathsf{IMC}^2$ is a fast and reliable way to find counterexamples\nto B\\\"uchi automata inclusion.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 10:17:02 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 01:26:19 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Li", "Yong", ""], ["Turrini", "Andrea", ""], ["Sun", "Xuechao", ""], ["Zhang", "Lijun", ""]]}, {"id": "2007.02342", "submitter": "Zhang Yifan", "authors": "Yifan Zhang, Maohua Wang, Yongjian Huang, Qianrong Gu", "title": "Improving Chinese Segmentation-free Word Embedding With Unsupervised\n  Association Measure", "comments": "9pages, 4figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on segmentation-free word embedding(sembei) developed a new\npipeline of word embedding for unsegmentated language while avoiding\nsegmentation as a preprocessing step. However, too many noisy n-grams existing\nin the embedding vocabulary that do not have strong association strength\nbetween characters would limit the quality of learned word embedding. To deal\nwith this problem, a new version of segmentation-free word embedding model is\nproposed by collecting n-grams vocabulary via a novel unsupervised association\nmeasure called pointwise association with times information(PATI). Comparing\nwith the commonly used n-gram filtering method like frequency used in sembei\nand pointwise mutual information(PMI), the proposed method leverages more\nlatent information from the corpus and thus is able to collect more valid\nn-grams that have stronger cohesion as embedding targets in unsegmented\nlanguage data, such as Chinese texts. Further experiments on Chinese SNS data\nshow that the proposed model improves performance of word embedding in\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 13:55:19 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Zhang", "Yifan", ""], ["Wang", "Maohua", ""], ["Huang", "Yongjian", ""], ["Gu", "Qianrong", ""]]}, {"id": "2007.02366", "submitter": "Vlado Keselj", "authors": "Vlado Keselj", "title": "Starfish: A Prototype for Universal Preprocessing and Text-Embedded\n  Programming", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel concept of universal text preprocessing and text-embedded\nprogramming (PTEP). Preprocessing and text-embedded programming has been widely\nused in programming languages and frameworks in a fragmented and mutually\nisolated way. The PTEP ideas can be found in the implementation of the \\TeX\\\ntypesetting system; they are prominent in PHP and similar web languages, and\nfinally they are used in the Jupyter data science framework. This paper\npresents this area of research and related work in a more unified framework,\nand we describe the implemented system Starfish that satisfies the following\nnovel principles of PTEP: universality, update and replace modes, flexiblity,\nconfigurability, and transparency. We describe the operating model and design\nof Starfish, which is an open-source system implementing universal\npreprocessing and text-embedded programming in Perl. The system is transparent\nand its design allows direct implementation in other programming languages as\nwell.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 15:37:44 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Keselj", "Vlado", ""]]}, {"id": "2007.02375", "submitter": "Ting Yao", "authors": "Yingwei Pan and Yehao Li and Jianjie Luo and Jun Xu and Ting Yao and\n  Tao Mei", "title": "Auto-captions on GIF: A Large-scale Video-sentence Dataset for\n  Vision-language Pre-training", "comments": "The Auto-captions on GIF dataset is available at\n  \\url{http://www.auto-video-captions.top/2020/dataset}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present Auto-captions on GIF, which is a new large-scale\npre-training dataset for generic video understanding. All video-sentence pairs\nare created by automatically extracting and filtering video caption annotations\nfrom billions of web pages. Auto-captions on GIF dataset can be utilized to\npre-train the generic feature representation or encoder-decoder structure for\nvideo captioning, and other downstream tasks (e.g., sentence localization in\nvideos, video question answering, etc.) as well. We present a detailed analysis\nof Auto-captions on GIF dataset in comparison to existing video-sentence\ndatasets. We also provide an evaluation of a Transformer-based encoder-decoder\nstructure for vision-language pre-training, which is further adapted to video\ncaptioning downstream task and yields the compelling generalizability on\nMSR-VTT. The dataset is available at\n\\url{http://www.auto-video-captions.top/2020/dataset}.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 16:11:57 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Pan", "Yingwei", ""], ["Li", "Yehao", ""], ["Luo", "Jianjie", ""], ["Xu", "Jun", ""], ["Yao", "Ting", ""], ["Mei", "Tao", ""]]}, {"id": "2007.02452", "submitter": "Hyeju Jang", "authors": "Hyeju Jang, Emily Rempel, Giuseppe Carenini, Naveed Janjua", "title": "Exploratory Analysis of COVID-19 Related Tweets in North America to\n  Inform Public Health Institutes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social media is a rich source where we can learn about people's reactions to\nsocial issues. As COVID-19 has significantly impacted on people's lives, it is\nessential to capture how people react to public health interventions and\nunderstand their concerns. In this paper, we aim to investigate people's\nreactions and concerns about COVID-19 in North America, especially focusing on\nCanada. We analyze COVID-19 related tweets using topic modeling and\naspect-based sentiment analysis, and interpret the results with public health\nexperts. We compare timeline of topics discussed with timing of implementation\nof public health interventions for COVID-19. We also examine people's sentiment\nabout COVID-19 related issues. We discuss how the results can be helpful for\npublic health agencies when designing a policy for new interventions. Our work\nshows how Natural Language Processing (NLP) techniques could be applied to\npublic health questions with domain expert involvement.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 21:38:28 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Jang", "Hyeju", ""], ["Rempel", "Emily", ""], ["Carenini", "Giuseppe", ""], ["Janjua", "Naveed", ""]]}, {"id": "2007.02461", "submitter": "Hengameh Mirzaalian", "authors": "Xiao Guo and Hengameh Mirzaalian and Ekraam Sabir and Ayush Jaiswal\n  and Wael Abd-Almageed", "title": "CORD19STS: COVID-19 Semantic Textual Similarity Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to combat the COVID-19 pandemic, society can benefit from various\nnatural language processing applications, such as dialog medical diagnosis\nsystems and information retrieval engines calibrated specifically for COVID-19.\nThese applications rely on the ability to measure semantic textual similarity\n(STS), making STS a fundamental task that can benefit several downstream\napplications. However, existing STS datasets and models fail to translate their\nperformance to a domain-specific environment such as COVID-19. To overcome this\ngap, we introduce CORD19STS dataset which includes 13,710 annotated sentence\npairs collected from COVID-19 open research dataset (CORD-19) challenge. To be\nspecific, we generated one million sentence pairs using different sampling\nstrategies. We then used a finetuned BERT-like language model, which we call\nSen-SCI-CORD19-BERT, to calculate the similarity scores between sentence pairs\nto provide a balanced dataset with respect to the different semantic similarity\nlevels, which gives us a total of 32K sentence pairs. Each sentence pair was\nannotated by five Amazon Mechanical Turk (AMT) crowd workers, where the labels\nrepresent different semantic similarity levels between the sentence pairs (i.e.\nrelated, somewhat-related, and not-related). After employing a rigorous\nqualification tasks to verify collected annotations, our final CORD19STS\ndataset includes 13,710 sentence pairs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 22:23:37 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 19:28:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Guo", "Xiao", ""], ["Mirzaalian", "Hengameh", ""], ["Sabir", "Ekraam", ""], ["Jaiswal", "Ayush", ""], ["Abd-Almageed", "Wael", ""]]}, {"id": "2007.02540", "submitter": "Shilei Liu", "authors": "Shilei Liu, Yu Guo, Bochao Li and Feiliang Ren", "title": "LMVE at SemEval-2020 Task 4: Commonsense Validation and Explanation\n  using Pretraining Language Model", "comments": "Accepted in SemEval2020. 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our submission to subtask a and b of SemEval-2020 Task\n4. For subtask a, we use a ALBERT based model with improved input form to pick\nout the common sense statement from two statement candidates. For subtask b, we\nuse a multiple choice model enhanced by hint sentence mechanism to select the\nreason from given options about why a statement is against common sense.\nBesides, we propose a novel transfer learning strategy between subtasks which\nhelp improve the performance. The accuracy scores of our system are 95.6 / 94.9\non official test set and rank 7$^{th}$ / 2$^{nd}$ on Post-Evaluation\nleaderboard.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 05:51:10 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Shilei", ""], ["Guo", "Yu", ""], ["Li", "Bochao", ""], ["Ren", "Feiliang", ""]]}, {"id": "2007.02598", "submitter": "Yoichi Ishibashi", "authors": "Yoichi Ishibashi, Katsuhito Sudoh, Koichiro Yoshino, Satoshi Nakamura", "title": "Reflection-based Word Attribute Transfer", "comments": "Accepted at ACL 2020 Student Research Workshop (SRW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings, which often represent such analogic relations as king - man\n+ woman = queen, can be used to change a word's attribute, including its\ngender. For transferring king into queen in this analogy-based manner, we\nsubtract a difference vector man - woman based on the knowledge that king is\nmale. However, developing such knowledge is very costly for words and\nattributes. In this work, we propose a novel method for word attribute transfer\nbased on reflection mappings without such an analogy operation. Experimental\nresults show that our proposed method can transfer the word attributes of the\ngiven words without changing the words that do not have the target attributes.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 09:17:14 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 04:28:48 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Ishibashi", "Yoichi", ""], ["Sudoh", "Katsuhito", ""], ["Yoshino", "Koichiro", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2007.02609", "submitter": "Carlos Gemmell", "authors": "Carlos Gemmell, Federico Rossetto, Jeffrey Dalton", "title": "Relevance Transformer: Generating Concise Code Snippets with Relevance\n  Feedback", "comments": null, "journal-ref": null, "doi": "10.1145/3397271.3401215", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tools capable of automatic code generation have the potential to augment\nprogrammer's capabilities. While straightforward code retrieval is incorporated\ninto many IDEs, an emerging area is explicit code generation. Code generation\nis currently approached as a Machine Translation task, with Recurrent Neural\nNetwork (RNN) based encoder-decoder architectures trained on code-description\npairs. In this work we introduce and study modern Transformer architectures for\nthis task. We further propose a new model called the Relevance Transformer that\nincorporates external knowledge using pseudo-relevance feedback. The Relevance\nTransformer biases the decoding process to be similar to existing retrieved\ncode while enforcing diversity. We perform experiments on multiple standard\nbenchmark datasets for code generation including Django, Hearthstone, and\nCoNaLa. The results show improvements over state-of-the-art methods based on\nBLEU evaluation. The Relevance Transformer model shows the potential of\nTransformer-based architectures for code generation and introduces a method of\nincorporating pseudo-relevance feedback during inference.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 09:54:17 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:33:43 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Gemmell", "Carlos", ""], ["Rossetto", "Federico", ""], ["Dalton", "Jeffrey", ""]]}, {"id": "2007.02629", "submitter": "Chao-Wei Huang", "authors": "Chao-Wei Huang and Yun-Nung Chen", "title": "Learning Spoken Language Representations with Neural Lattice Language\n  Modeling", "comments": "Published in ACL 2020 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models have achieved huge improvement on many NLP tasks.\nHowever, these methods are usually designed for written text, so they do not\nconsider the properties of spoken language. Therefore, this paper aims at\ngeneralizing the idea of language model pre-training to lattices generated by\nrecognition systems. We propose a framework that trains neural lattice language\nmodels to provide contextualized representations for spoken language\nunderstanding tasks. The proposed two-stage pre-training approach reduces the\ndemands of speech data and has better efficiency. Experiments on intent\ndetection and dialogue act recognition datasets demonstrate that our proposed\nmethod consistently outperforms strong baselines when evaluated on spoken\ninputs. The code is available at https://github.com/MiuLab/Lattice-ELMo.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 10:38:03 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 06:53:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Chao-Wei", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2007.02670", "submitter": "Ritwik Bose", "authors": "James Allen, Hannah An, Ritwik Bose, Will de Beaumont and Choh Man\n  Teng", "title": "A Broad-Coverage Deep Semantic Lexicon for Verbs", "comments": "Draft of LREC-2020 paper. Proceedings of The 12th Language Resources\n  and Evaluation Conference. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress on deep language understanding is inhibited by the lack of a broad\ncoverage lexicon that connects linguistic behavior to ontological concepts and\naxioms. We have developed COLLIE-V, a deep lexical resource for verbs, with the\ncoverage of WordNet and syntactic and semantic details that meet or exceed\nexisting resources. Bootstrapping from a hand-built lexicon and ontology, new\nontological concepts and lexical entries, together with semantic role\npreferences and entailment axioms, are automatically derived by combining\nmultiple constraints from parsing dictionary definitions and examples. We\nevaluated the accuracy of the technique along a number of different dimensions\nand were able to obtain high accuracy in deriving new concepts and lexical\nentries. COLLIE-V is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 12:03:14 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Allen", "James", ""], ["An", "Hannah", ""], ["Bose", "Ritwik", ""], ["de Beaumont", "Will", ""], ["Teng", "Choh Man", ""]]}, {"id": "2007.02671", "submitter": "Hao Jia", "authors": "Xiangyu Duan, Baijun Ji, Hao Jia, Min Tan, Min Zhang, Boxing Chen,\n  Weihua Luo and Yue Zhang", "title": "Bilingual Dictionary Based Neural Machine Translation without Using\n  Parallel Sentences", "comments": "Accepted by ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new task of machine translation (MT), which is\nbased on no parallel sentences but can refer to a ground-truth bilingual\ndictionary. Motivated by the ability of a monolingual speaker learning to\ntranslate via looking up the bilingual dictionary, we propose the task to see\nhow much potential an MT system can attain using the bilingual dictionary and\nlarge scale monolingual corpora, while is independent on parallel sentences. We\npropose anchored training (AT) to tackle the task. AT uses the bilingual\ndictionary to establish anchoring points for closing the gap between source\nlanguage and target language. Experiments on various language pairs show that\nour approaches are significantly better than various baselines, including\ndictionary-based word-by-word translation, dictionary-supervised cross-lingual\nword embedding transformation, and unsupervised MT. On distant language pairs\nthat are hard for unsupervised MT to perform well, AT performs remarkably\nbetter, achieving performances comparable to supervised SMT trained on more\nthan 4M parallel sentences.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 12:05:27 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Duan", "Xiangyu", ""], ["Ji", "Baijun", ""], ["Jia", "Hao", ""], ["Tan", "Min", ""], ["Zhang", "Min", ""], ["Chen", "Boxing", ""], ["Luo", "Weihua", ""], ["Zhang", "Yue", ""]]}, {"id": "2007.02699", "submitter": "K. R. Chowdhary", "authors": "K. R. Chowdhary", "title": "On the Evolution of Programming Languages", "comments": "UGC National Conference on \"New Advances in Programming languages and\n  their implementation\", March 15-16, 2013 (APL-2013), Dept. of Computer\n  Science and Engineering, MBM Engineering College, JNV Univ. jodhpur, India.\n  (6 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to connects the evolution of computer languages with the\nevolution of life, where the later has been dictated by \\emph{theory of\nevolution of species}, and tries to give supportive evidence that the new\nlanguages are more robust than the previous, carry-over the mixed features of\nolder languages, such that strong features gets added into them and weak\nfeatures of older languages gets removed. In addition, an analysis of most\nprominent programming languages is presented, emphasizing on how the features\nof existing languages have influenced the development of new programming\nlanguages. At the end, it suggests a set of experimental languages, which may\nrule the world of programming languages in the time of new multi-core\narchitectures.\n  Index terms- Programming languages' evolution, classifications of languages,\nfuture languages, scripting-languages.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 10:18:14 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Chowdhary", "K. R.", ""]]}, {"id": "2007.02758", "submitter": "Omar Sharif", "authors": "Eftekhar Hossain, Omar Sharif and Mohammed Moshiul Hoque", "title": "Sentiment Polarity Detection on Bengali Book Reviews Using Multinomial\n  Naive Bayes", "comments": "12 pages, ICACIE 2020, Will be published by Advances in Intelligent\n  Systems and Computing (AISC) series of Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, sentiment polarity detection has increased attention to NLP\nresearchers due to the massive availability of customer's opinions or reviews\nin the online platform. Due to the continued expansion of e-commerce sites, the\nrate of purchase of various products, including books, are growing enormously\namong the people. Reader's opinions/reviews affect the buying decision of a\ncustomer in most cases. This work introduces a machine learning-based technique\nto determine sentiment polarities (either positive or negative category) from\nBengali book reviews. To assess the effectiveness of the proposed technique, a\ncorpus with 2000 reviews on Bengali books is developed. A comparative analysis\nwith various approaches (such as logistic regression, naive Bayes, SVM, and\nSGD) also performed by taking into consideration of the unigram, bigram, and\ntrigram features, respectively. Experimental result reveals that the\nmultinomial Naive Bayes with unigram feature outperforms the other techniques\nwith 84% accuracy on the test set.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:58:51 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Hossain", "Eftekhar", ""], ["Sharif", "Omar", ""], ["Hoque", "Mohammed Moshiul", ""]]}, {"id": "2007.02871", "submitter": "Rui Zhang", "authors": "Linyong Nan, Dragomir Radev, Rui Zhang, Amrit Rau, Abhinand\n  Sivaprasad, Chiachun Hsieh, Xiangru Tang, Aadit Vyas, Neha Verma, Pranav\n  Krishna, Yangxiaokang Liu, Nadia Irwanto, Jessica Pan, Faiaz Rahman, Ahmad\n  Zaidi, Mutethia Mutuma, Yasin Tarabar, Ankit Gupta, Tao Yu, Yi Chern Tan, Xi\n  Victoria Lin, Caiming Xiong, Richard Socher, Nazneen Fatema Rajani", "title": "DART: Open-Domain Structured Data Record to Text Generation", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present DART, an open domain structured DAta Record to Text generation\ndataset with over 82k instances (DARTs). Data-to-Text annotations can be a\ncostly process, especially when dealing with tables which are the major source\nof structured data and contain nontrivial structures. To this end, we propose a\nprocedure of extracting semantic triples from tables that encodes their\nstructures by exploiting the semantic dependencies among table headers and the\ntable title. Our dataset construction framework effectively merged\nheterogeneous sources from open domain semantic parsing and dialogue-act-based\nmeaning representation tasks by utilizing techniques such as: tree ontology\nannotation, question-answer pair to declarative sentence conversion, and\npredicate unification, all with minimum post-editing. We present systematic\nevaluation on DART as well as new state-of-the-art results on WebNLG 2017 to\nshow that DART (1) poses new challenges to existing data-to-text datasets and\n(2) facilitates out-of-domain generalization. Our data and code can be found at\nhttps://github.com/Yale-LILY/dart.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:35:30 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 14:18:06 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Nan", "Linyong", ""], ["Radev", "Dragomir", ""], ["Zhang", "Rui", ""], ["Rau", "Amrit", ""], ["Sivaprasad", "Abhinand", ""], ["Hsieh", "Chiachun", ""], ["Tang", "Xiangru", ""], ["Vyas", "Aadit", ""], ["Verma", "Neha", ""], ["Krishna", "Pranav", ""], ["Liu", "Yangxiaokang", ""], ["Irwanto", "Nadia", ""], ["Pan", "Jessica", ""], ["Rahman", "Faiaz", ""], ["Zaidi", "Ahmad", ""], ["Mutuma", "Mutethia", ""], ["Tarabar", "Yasin", ""], ["Gupta", "Ankit", ""], ["Yu", "Tao", ""], ["Tan", "Yi Chern", ""], ["Lin", "Xi Victoria", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Rajani", "Nazneen Fatema", ""]]}, {"id": "2007.02880", "submitter": "Prakamya Mishra", "authors": "Prakamya Mishra and Pranav Mathur", "title": "Contextualized Spoken Word Representations from Convolutional\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of work has been done to build text-based language models for\nperforming different NLP tasks, but not much research has been done in the case\nof audio-based language models. This paper proposes a Convolutional Autoencoder\nbased neural architecture to model syntactically and semantically adequate\ncontextualized representations of varying length spoken words. The use of such\nrepresentations can not only lead to great advances in the audio-based NLP\ntasks but can also curtail the loss of information like tone, expression,\naccent, etc while converting speech to text to perform these tasks. The\nperformance of the proposed model is validated by (1) examining the generated\nvector space, and (2) evaluating its performance on three benchmark datasets\nfor measuring word similarities, against existing widely used text-based\nlanguage models that are trained on the transcriptions. The proposed model was\nable to demonstrate its robustness when compared to the other two\nlanguage-based models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:48:11 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 17:31:34 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Mishra", "Prakamya", ""], ["Mathur", "Pranav", ""]]}, {"id": "2007.03001", "submitter": "Vineel Pratap", "authors": "Vineel Pratap, Anuroop Sriram, Paden Tomasello, Awni Hannun, Vitaliy\n  Liptchinsky, Gabriel Synnaeve, Ronan Collobert", "title": "Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study training a single acoustic model for multiple languages with the aim\nof improving automatic speech recognition (ASR) performance on low-resource\nlanguages, and over-all simplifying deployment of ASR systems that support\ndiverse languages. We perform an extensive benchmark on 51 languages, with\nvarying amount of training data by language(from 100 hours to 1100 hours). We\ncompare three variants of multilingual training from a single joint model\nwithout knowing the input language, to using this information, to multiple\nheads (one per language cluster). We show that multilingual training of ASR\nmodels on several languages can improve recognition performance, in particular,\non low resource languages. We see 20.9%, 23% and 28.8% average WER relative\nreduction compared to monolingual baselines on joint model, joint model with\nlanguage input and multi head model respectively. To our knowledge, this is the\nfirst work studying multilingual ASR at massive scale, with more than 50\nlanguages and more than 16,000 hours of audio across them.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 18:43:38 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:02:06 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Pratap", "Vineel", ""], ["Sriram", "Anuroop", ""], ["Tomasello", "Paden", ""], ["Hannun", "Awni", ""], ["Liptchinsky", "Vitaliy", ""], ["Synnaeve", "Gabriel", ""], ["Collobert", "Ronan", ""]]}, {"id": "2007.03006", "submitter": "Tom Kocmi", "authors": "Tom Kocmi, Martin Popel, Ondrej Bojar", "title": "Announcing CzEng 2.0 Parallel Corpus with over 2 Gigawords", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new release of the Czech-English parallel corpus CzEng 2.0\nconsisting of over 2 billion words (2 \"gigawords\") in each language. The corpus\ncontains document-level information and is filtered with several techniques to\nlower the amount of noise. In addition to the data in the previous version of\nCzEng, it contains new authentic and also high-quality synthetic parallel data.\nCzEng is freely available for research and educational purposes.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 18:48:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kocmi", "Tom", ""], ["Popel", "Martin", ""], ["Bojar", "Ondrej", ""]]}, {"id": "2007.03020", "submitter": "Lakshya Kumar", "authors": "Shreyas Mangalgi, Lakshya Kumar and Ravindra Babu Tallamraju", "title": "Deep Contextual Embeddings for Address Classification in E-commerce", "comments": "9 Pages, 8 Figures, AI for fashion supply chain, KDD2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce customers in developing nations like India tend to follow no fixed\nformat while entering shipping addresses. Parsing such addresses is challenging\nbecause of a lack of inherent structure or hierarchy. It is imperative to\nunderstand the language of addresses, so that shipments can be routed without\ndelays. In this paper, we propose a novel approach towards understanding\ncustomer addresses by deriving motivation from recent advances in Natural\nLanguage Processing (NLP). We also formulate different pre-processing steps for\naddresses using a combination of edit distance and phonetic algorithms. Then we\napproach the task of creating vector representations for addresses using\nWord2Vec with TF-IDF, Bi-LSTM and BERT based approaches. We compare these\napproaches with respect to sub-region classification task for North and South\nIndian cities. Through experiments, we demonstrate the effectiveness of\ngeneralized RoBERTa model, pre-trained over a large address corpus for language\nmodelling task. Our proposed RoBERTa model achieves a classification accuracy\nof around 90% with minimal text preprocessing for sub-region classification\ntask outperforming all other approaches. Once pre-trained, the RoBERTa model\ncan be fine-tuned for various downstream tasks in supply chain like pincode\nsuggestion and geo-coding. The model generalizes well for such tasks even with\nlimited labelled data. To the best of our knowledge, this is the first of its\nkind research proposing a novel approach of understanding customer addresses in\ne-commerce domain by pre-training language models and fine-tuning them for\ndifferent purposes.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 19:06:34 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Mangalgi", "Shreyas", ""], ["Kumar", "Lakshya", ""], ["Tallamraju", "Ravindra Babu", ""]]}, {"id": "2007.03028", "submitter": "Chen-Han Tsai", "authors": "Chen-Han Tsai, Nahum Kiryati, Eli Konen, Miri Sklair-Levy, Arnaldo\n  Mayer", "title": "Labeling of Multilingual Breast MRI Reports", "comments": "10 pages, 5 figures, MICCAI LABELS Workshop 2020", "journal-ref": "Lecture Notes in Computer Science 12446 (2020) 233-241", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical reports are an essential medium in recording a patient's condition\nthroughout a clinical trial. They contain valuable information that can be\nextracted to generate a large labeled dataset needed for the development of\nclinical tools. However, the majority of medical reports are stored in an\nunregularized format, and a trained human annotator (typically a doctor) must\nmanually assess and label each case, resulting in an expensive and time\nconsuming procedure. In this work, we present a framework for developing a\nmultilingual breast MRI report classifier using a custom-built language\nrepresentation called LAMBR. Our proposed method overcomes practical challenges\nfaced in clinical settings, and we demonstrate improved performance in\nextracting labels from medical reports when compared with conventional\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 19:22:44 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:06:47 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 13:07:54 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Tsai", "Chen-Han", ""], ["Kiryati", "Nahum", ""], ["Konen", "Eli", ""], ["Sklair-Levy", "Miri", ""], ["Mayer", "Arnaldo", ""]]}, {"id": "2007.03140", "submitter": "Yi-Jian Liu", "authors": "Guang Liu, Gang Tu, Zheng Li, Yi-Jian Liu", "title": "Research on Annotation Rules and Recognition Algorithm Based on Phrase\n  Window", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  At present, most Natural Language Processing technology is based on the\nresults of Word Segmentation for Dependency Parsing, which mainly uses an\nend-to-end method based on supervised learning. There are two main problems\nwith this method: firstly, the la-beling rules are complex and the data is too\ndifficult to label, the workload of which is large; secondly, the algorithm\ncannot recognize the multi-granularity and diversity of language components. In\norder to solve these two problems, we propose labeling rules based on phrase\nwindows, and designed corresponding phrase recognition algorithms. The labeling\nrule uses phrases as the minimum unit, di-vides sentences into 7 types of\nnestable phrase types, and marks the grammatical dependencies between phrases.\nThe corresponding algorithm, drawing on the idea of identifying the target area\nin the image field, can find the start and end positions of various phrases in\nthe sentence, and realize the synchronous recognition of nested phrases and\ngrammatical dependencies. The results of the experiment shows that the labeling\nrule is convenient and easy to use, and there is no ambiguity; the algorithm is\nmore grammatically multi-granular and diverse than the end-to-end algorithm.\nExperiments on the CPWD dataset improve the accuracy of the end-to-end method\nby about 1 point. The corresponding method was applied to the CCL2018\ncompetition, and the first place in the Chinese Metaphor Sentiment Analysis\nTask.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 00:19:47 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Liu", "Guang", ""], ["Tu", "Gang", ""], ["Li", "Zheng", ""], ["Liu", "Yi-Jian", ""]]}, {"id": "2007.03184", "submitter": "Yang Fang", "authors": "Yang Fang, Xiang Zhao, Yifan Chen, Weidong Xiao, Maarten de Rijke", "title": "Pre-Trained Models for Heterogeneous Information Networks", "comments": "Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In network representation learning we learn how to represent heterogeneous\ninformation networks in a low-dimensional space so as to facilitate effective\nsearch, classification, and prediction solutions. Previous network\nrepresentation learning methods typically require sufficient task-specific\nlabeled data to address domain-specific problems. The trained model usually\ncannot be transferred to out-of-domain datasets. We propose a self-supervised\npre-training and fine-tuning framework, PF-HIN, to capture the features of a\nheterogeneous information network. Unlike traditional network representation\nlearning models that have to train the entire model all over again for every\ndownstream task and dataset, PF-HIN only needs to fine-tune the model and a\nsmall number of extra task-specific parameters, thus improving model efficiency\nand effectiveness. During pre-training, we first transform the neighborhood of\na given node into a sequence. PF-HIN is pre-trained based on two\nself-supervised tasks, masked node modeling and adjacent node prediction. We\nadopt deep bi-directional transformer encoders to train the model, and leverage\nfactorized embedding parameterization and cross-layer parameter sharing to\nreduce the parameters. In the fine-tuning stage, we choose four benchmark\ndownstream tasks, i.e., link prediction, similarity search, node\nclassification, and node clustering. PF-HIN consistently and significantly\noutperforms state-of-the-art alternatives on each of these tasks, on four\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 03:36:28 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 09:53:57 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fang", "Yang", ""], ["Zhao", "Xiang", ""], ["Chen", "Yifan", ""], ["Xiao", "Weidong", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2007.03310", "submitter": "Xiaoze Jiang", "authors": "Xiaoze Jiang, Jing Yu, Yajing Sun, Zengchang Qin, Zihao Zhu, Yue Hu,\n  Qi Wu", "title": "DAM: Deliberation, Abandon and Memory Networks for Generating Detailed\n  and Non-repetitive Responses in Visual Dialogue", "comments": "Accepted by IJCAI 2020. SOLE copyright holder is IJCAI (International\n  Joint Conferences on Artificial Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Dialogue task requires an agent to be engaged in a conversation with\nhuman about an image. The ability of generating detailed and non-repetitive\nresponses is crucial for the agent to achieve human-like conversation. In this\npaper, we propose a novel generative decoding architecture to generate\nhigh-quality responses, which moves away from decoding the whole encoded\nsemantics towards the design that advocates both transparency and flexibility.\nIn this architecture, word generation is decomposed into a series of\nattention-based information selection steps, performed by the novel recurrent\nDeliberation, Abandon and Memory (DAM) module. Each DAM module performs an\nadaptive combination of the response-level semantics captured from the encoder\nand the word-level semantics specifically selected for generating each word.\nTherefore, the responses contain more detailed and non-repetitive descriptions\nwhile maintaining the semantic accuracy. Furthermore, DAM is flexible to\ncooperate with existing visual dialogue encoders and adaptive to the encoder\nstructures by constraining the information selection mode in DAM. We apply DAM\nto three typical encoders and verify the performance on the VisDial v1.0\ndataset. Experimental results show that the proposed models achieve new\nstate-of-the-art performance with high-quality responses. The code is available\nat https://github.com/JXZe/DAM.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 09:49:47 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Jiang", "Xiaoze", ""], ["Yu", "Jing", ""], ["Sun", "Yajing", ""], ["Qin", "Zengchang", ""], ["Zhu", "Zihao", ""], ["Hu", "Yue", ""], ["Wu", "Qi", ""]]}, {"id": "2007.03325", "submitter": "Graham Spinks", "authors": "Graham Spinks, Marie-Francine Moens", "title": "Structured (De)composable Representations Trained with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a novel technique for representing templates and instances\nof concept classes. A template representation refers to the generic\nrepresentation that captures the characteristics of an entire class. The\nproposed technique uses end-to-end deep learning to learn structured and\ncomposable representations from input images and discrete labels. The obtained\nrepresentations are based on distance estimates between the distributions given\nby the class label and those given by contextual information, which are modeled\nas environments. We prove that the representations have a clear structure\nallowing to decompose the representation into factors that represent classes\nand environments. We evaluate our novel technique on classification and\nretrieval tasks involving different modalities (visual and language data).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:20:31 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Spinks", "Graham", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2007.03338", "submitter": "Mehdi Ghatee Dr.", "authors": "Marzieh Heidari, Mehdi Ghatee, Ahmad Nickabadi, Arash Pourhasan Nezhad", "title": "Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent\n  Experts", "comments": "13 pages, 4 figures and 5 tables, extracted from an MSc thesis in the\n  Amirkabir University of Technology, Tehran, Iran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With great advances in vision and natural language processing, the generation\nof image captions becomes a need. In a recent paper, Mathews, Xie and He [1],\nextended a new model to generate styled captions by separating semantics and\nstyle. In continuation of this work, here a new captioning model is developed\nincluding an image encoder to extract the features, a mixture of recurrent\nnetworks to embed the set of extracted features to a set of words, and a\nsentence generator that combines the obtained words as a stylized sentence. The\nresulted system that entitled as Mixture of Recurrent Experts (MoRE), uses a\nnew training algorithm that derives singular value decomposition (SVD) from\nweighting matrices of Recurrent Neural Networks (RNNs) to increase the\ndiversity of captions. Each decomposition step depends on a distinctive factor\nbased on the number of RNNs in MoRE. Since the used sentence generator gives a\nstylized language corpus without paired images, our captioning model can do the\nsame. Besides, the styled and diverse captions are extracted without training\non a densely labeled or styled dataset. To validate this captioning model, we\nuse Microsoft COCO which is a standard factual image caption dataset. We show\nthat the proposed captioning model can generate a diverse and stylized image\ncaptions without the necessity of extra-labeling. The results also show better\ndescriptions in terms of content accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:00:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Heidari", "Marzieh", ""], ["Ghatee", "Mehdi", ""], ["Nickabadi", "Ahmad", ""], ["Nezhad", "Arash Pourhasan", ""]]}, {"id": "2007.03356", "submitter": "Jack Rae", "authors": "Jack W. Rae and Ali Razavi", "title": "Do Transformers Need Deep Long-Range Memory", "comments": "published at 58th Annual Meeting of the Association for Computational\n  Linguistics. 6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep attention models have advanced the modelling of sequential data across\nmany domains. For language modelling in particular, the Transformer-XL -- a\nTransformer augmented with a long-range memory of past activations -- has been\nshown to be state-of-the-art across a variety of well-studied benchmarks. The\nTransformer-XL incorporates a long-range memory at every layer of the network,\nwhich renders its state to be thousands of times larger than RNN predecessors.\nHowever it is unclear whether this is necessary. We perform a set of\ninterventions to show that comparable performance can be obtained with 6X fewer\nlong range memories and better performance can be obtained by limiting the\nrange of attention in lower layers of the network.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:48:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Rae", "Jack W.", ""], ["Razavi", "Ali", ""]]}, {"id": "2007.03405", "submitter": "Jong Won Park", "authors": "Jong Won Park", "title": "Continual BERT: Continual Learning for Adaptive Extractive Summarization\n  of COVID-19 Literature", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scientific community continues to publish an overwhelming amount of new\nresearch related to COVID-19 on a daily basis, leading to much literature\nwithout little to no attention. To aid the community in understanding the\nrapidly flowing array of COVID-19 literature, we propose a novel BERT\narchitecture that provides a brief yet original summarization of lengthy\npapers. The model continually learns on new data in online fashion while\nminimizing catastrophic forgetting, thus fitting to the need of the community.\nBenchmark and manual examination of its performance show that the model provide\na sound summary of new scientific literature.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 13:16:19 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 08:02:30 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Park", "Jong Won", ""]]}, {"id": "2007.03443", "submitter": "Alexander Ruch", "authors": "Liz McQuillan, Erin McAweeney, Alicia Bargar, Alex Ruch", "title": "Cultural Convergence: Insights into the behavior of misinformation\n  networks on Twitter", "comments": "15 pages (7 for paper, 3 for reference, 5 for appendix), 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can the birth and evolution of ideas and communities in a network be\nstudied over time? We use a multimodal pipeline, consisting of network mapping,\ntopic modeling, bridging centrality, and divergence to analyze Twitter data\nsurrounding the COVID-19 pandemic. We use network mapping to detect accounts\ncreating content surrounding COVID-19, then Latent Dirichlet Allocation to\nextract topics, and bridging centrality to identify topical and non-topical\nbridges, before examining the distribution of each topic and bridge over time\nand applying Jensen-Shannon divergence of topic distributions to show\ncommunities that are converging in their topical narratives.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 13:50:24 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["McQuillan", "Liz", ""], ["McAweeney", "Erin", ""], ["Bargar", "Alicia", ""], ["Ruch", "Alex", ""]]}, {"id": "2007.03500", "submitter": "Matthew Ciolino", "authors": "Matthew Ciolino, David Noever, Josh Kalin", "title": "The Go Transformer: Natural Language Modeling for Game Play", "comments": "8 Pages, 5 Figures, 1 Table, IEEE Format, Ai4i 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work applies natural language modeling to generate plausible strategic\nmoves in the ancient game of Go. We train the Generative Pretrained Transformer\n(GPT-2) to mimic the style of Go champions as archived in Smart Game Format\n(SGF), which offers a text description of move sequences. The trained model\nfurther generates valid but previously unseen strategies for Go. Because GPT-2\npreserves punctuation and spacing, the raw output of the text generator\nprovides inputs to game visualization and creative patterns, such as the Sabaki\nproject's game engine using auto-replays. Results demonstrate that language\nmodeling can capture both the sequencing format of championship Go games and\ntheir strategic formations. Compared to random game boards, the GPT-2\nfine-tuning shows efficient opening move sequences favoring corner play over\nless advantageous center and side play. Game generation as a language modeling\ntask offers novel approaches to more than 40 other board games where historical\ntext annotation provides training data (e.g., Amazons & Connect 4/6).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:37:27 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 18:10:00 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 19:37:21 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ciolino", "Matthew", ""], ["Noever", "David", ""], ["Kalin", "Josh", ""]]}, {"id": "2007.03541", "submitter": "Lalita Lowphansirikul", "authors": "Lalita Lowphansirikul, Charin Polpanumas, Attapol T. Rutherford and\n  Sarana Nutanong", "title": "scb-mt-en-th-2020: A Large English-Thai Parallel Corpus", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of our work is to build a large-scale English-Thai\ndataset for machine translation. We construct an English-Thai machine\ntranslation dataset with over 1 million segment pairs, curated from various\nsources, namely news, Wikipedia articles, SMS messages, task-based dialogs,\nweb-crawled data and government documents. Methodology for gathering data,\nbuilding parallel texts and removing noisy sentence pairs are presented in a\nreproducible manner. We train machine translation models based on this dataset.\nOur models' performance are comparable to that of Google Translation API (as of\nMay 2020) for Thai-English and outperform Google when the Open Parallel Corpus\n(OPUS) is included in the training data for both Thai-English and English-Thai\ntranslation. The dataset, pre-trained models, and source code to reproduce our\nwork are available for public use.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:14:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Lowphansirikul", "Lalita", ""], ["Polpanumas", "Charin", ""], ["Rutherford", "Attapol T.", ""], ["Nutanong", "Sarana", ""]]}, {"id": "2007.03596", "submitter": "Han Wang", "authors": "Wang Han, Wesley Yeung, Angeline Tung, Joey Tay Ai Meng, Davin\n  Ryanputera, Feng Mengling, Shalini Arulanadam", "title": "An Emergency Medical Services Clinical Audit System driven by Named\n  Entity Recognition from Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical performance audits are routinely performed in Emergency Medical\nServices (EMS) to ensure adherence to treatment protocols, to identify\nindividual areas of weakness for remediation, and to discover systemic\ndeficiencies to guide the development of the training syllabus. At present,\nthese audits are performed by manual chart review which is time-consuming and\nlaborious. In this paper, we present an automatic audit system based on both\nthe structured and unstructured ambulance case records and clinical notes with\na deep neural network-based named entities recognition model. The dataset used\nin this study contained 58,898 unlabelled ambulance incidents encountered by\nthe Singapore Civil Defence Force from 1st April 2019 to 30th June 2019. A\nweakly-supervised training approach was adopted to label the sentences. Later\non, we trained three different models to perform the NER task. All three models\nachieve F1 scores of around 0.981 under entity type matching evaluation and\naround 0.976 under strict evaluation, while the BiLSTM-CRF model is 1~2 orders\nof magnitude lighter and faster than our BERT-based models. Overall, our\napproach yielded a named entity recognition model that could reliably identify\nclinical entities from unstructured paramedic free-text reports. Our proposed\nsystem may improve the efficiency of clinical performance audits and can also\nhelp with EMS database research.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 16:32:44 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Han", "Wang", ""], ["Yeung", "Wesley", ""], ["Tung", "Angeline", ""], ["Meng", "Joey Tay Ai", ""], ["Ryanputera", "Davin", ""], ["Mengling", "Feng", ""], ["Arulanadam", "Shalini", ""]]}, {"id": "2007.03626", "submitter": "Jianing Yang", "authors": "Jianing Yang, Yuying Zhu, Yongxin Wang, Ruitao Yi, Amir Zadeh,\n  Louis-Philippe Morency", "title": "What Gives the Answer Away? Question Answering Bias Analysis on Video QA\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering biases in video QA datasets can mislead multimodal model\nto overfit to QA artifacts and jeopardize the model's ability to generalize.\nUnderstanding how strong these QA biases are and where they come from helps the\ncommunity measure progress more accurately and provide researchers insights to\ndebug their models. In this paper, we analyze QA biases in popular video\nquestion answering datasets and discover pretrained language models can answer\n37-48% questions correctly without using any multimodal context information,\nfar exceeding the 20% random guess baseline for 5-choose-1 multiple-choice\nquestions. Our ablation study shows biases can come from annotators and type of\nquestions. Specifically, annotators that have been seen during training are\nbetter predicted by the model and reasoning, abstract questions incur more\nbiases than factual, direct questions. We also show empirically that using\nannotator-non-overlapping train-test splits can reduce QA biases for video QA\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:00:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yang", "Jianing", ""], ["Zhu", "Yuying", ""], ["Wang", "Yongxin", ""], ["Yi", "Ruitao", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2007.03765", "submitter": "Nils Feldhus", "authors": "Karolina Zaczynska, Nils Feldhus, Robert Schwarzenberg, Aleksandra\n  Gabryszak, Sebastian M\\\"oller", "title": "Evaluating German Transformer Language Models with Syntactic Agreement\n  Tests", "comments": "SwissText + KONVENS 2020", "journal-ref": "Proceedings of the 5th Swiss Text Analytics Conference and the\n  16th Conference on Natural Language Processing, SwissText/KONVENS 2020,\n  Zurich, Switzerland, June 23-25, 2020 [online only]. CEUR Workshop\n  Proceedings 2624", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained transformer language models (TLMs) have recently refashioned\nnatural language processing (NLP): Most state-of-the-art NLP models now operate\non top of TLMs to benefit from contextualization and knowledge induction. To\nexplain their success, the scientific community conducted numerous analyses.\nBesides other methods, syntactic agreement tests were utilized to analyse TLMs.\nMost of the studies were conducted for the English language, however. In this\nwork, we analyse German TLMs. To this end, we design numerous agreement tasks,\nsome of which consider peculiarities of the German language. Our experimental\nresults show that state-of-the-art German TLMs generally perform well on\nagreement tasks, but we also identify and discuss syntactic structures that\npush them to their limits.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 20:01:42 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Zaczynska", "Karolina", ""], ["Feldhus", "Nils", ""], ["Schwarzenberg", "Robert", ""], ["Gabryszak", "Aleksandra", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "2007.03771", "submitter": "Kartikey Pant", "authors": "Kartikey Pant and Tanvi Dadu", "title": "Cross-lingual Inductive Transfer to Detect Offensive Language", "comments": "Accepted at OffenseEval 2020 to be held at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing use of social media and its availability, many instances of\nthe use of offensive language have been observed across multiple languages and\ndomains. This phenomenon has given rise to the growing need to detect the\noffensive language used in social media cross-lingually. In OffensEval 2020,\nthe organizers have released the \\textit{multilingual Offensive Language\nIdentification Dataset} (mOLID), which contains tweets in five different\nlanguages, to detect offensive language. In this work, we introduce a\ncross-lingual inductive approach to identify the offensive language in tweets\nusing the contextual word embedding \\textit{XLM-RoBERTa} (XLM-R). We show that\nour model performs competitively on all five languages, obtaining the fourth\nposition in the English task with an F1-score of $0.919$ and eighth position in\nthe Turkish task with an F1-score of $0.781$. Further experimentation proves\nthat our model works competitively in a zero-shot learning environment, and is\nextensible to other languages.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 20:10:31 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Pant", "Kartikey", ""], ["Dadu", "Tanvi", ""]]}, {"id": "2007.03774", "submitter": "Xin Wang", "authors": "Xin Wang", "title": "The curious case of developmental BERTology: On sparsity, transfer\n  learning, generalization and the brain", "comments": "9 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this essay, we explore a point of intersection between deep learning and\nneuroscience, through the lens of large language models, transfer learning and\nnetwork compression. Just like perceptual and cognitive neurophysiology has\ninspired effective deep neural network architectures which in turn make a\nuseful model for understanding the brain, here we explore how biological neural\ndevelopment might inspire efficient and robust optimization procedures which in\nturn serve as a useful model for the maturation and aging of the brain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 20:16:30 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wang", "Xin", ""]]}, {"id": "2007.03777", "submitter": "Huaiyi Huang", "authors": "Huaiyi Huang, Yuqi Zhang, Qingqiu Huang, Zhengkui Guo, Ziwei Liu, and\n  Dahua Lin", "title": "Placepedia: Comprehensive Place Understanding with Multi-Faceted\n  Annotations", "comments": "To appear in ECCV 2020. Dataset is available at:\n  https://hahehi.github.io/placepedia.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place is an important element in visual understanding. Given a photo of a\nbuilding, people can often tell its functionality, e.g. a restaurant or a shop,\nits cultural style, e.g. Asian or European, as well as its economic type, e.g.\nindustry oriented or tourism oriented. While place recognition has been widely\nstudied in previous work, there remains a long way towards comprehensive place\nunderstanding, which is far beyond categorizing a place with an image and\nrequires information of multiple aspects. In this work, we contribute\nPlacepedia, a large-scale place dataset with more than 35M photos from 240K\nunique places. Besides the photos, each place also comes with massive\nmulti-faceted information, e.g. GDP, population, etc., and labels at multiple\nlevels, including function, city, country, etc.. This dataset, with its large\namount of data and rich annotations, allows various studies to be conducted.\nParticularly, in our studies, we develop 1) PlaceNet, a unified framework for\nmulti-level place recognition, and 2) a method for city embedding, which can\nproduce a vector representation for a city that captures both visual and\nmulti-faceted side information. Such studies not only reveal key challenges in\nplace understanding, but also establish connections between visual observations\nand underlying socioeconomic/cultural implications.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 20:17:01 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 08:17:10 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 16:38:50 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 08:56:05 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Huang", "Huaiyi", ""], ["Zhang", "Yuqi", ""], ["Huang", "Qingqiu", ""], ["Guo", "Zhengkui", ""], ["Liu", "Ziwei", ""], ["Lin", "Dahua", ""]]}, {"id": "2007.03805", "submitter": "Tuan Manh Lai", "authors": "Tuan Manh Lai, Trung Bui, Nedim Lipka", "title": "ISA: An Intelligent Shopping Assistant", "comments": "Accepted by AACL 2020 (Demo)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growth of e-commerce, brick-and-mortar stores are still the\npreferred destinations for many people. In this paper, we present ISA, a\nmobile-based intelligent shopping assistant that is designed to improve\nshopping experience in physical stores. ISA assists users by leveraging\nadvanced techniques in computer vision, speech processing, and natural language\nprocessing. An in-store user only needs to take a picture or scan the barcode\nof the product of interest, and then the user can talk to the assistant about\nthe product. The assistant can also guide the user through the purchase process\nor recommend other similar products to the user. We take a data-driven approach\nin building the engines of ISA's natural language processing component, and the\nengines achieve good performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 21:57:34 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 05:42:24 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lai", "Tuan Manh", ""], ["Bui", "Trung", ""], ["Lipka", "Nedim", ""]]}, {"id": "2007.03819", "submitter": "Charlie Welch", "authors": "Charles Welch, Allison Lahnala, Ver\\'onica P\\'erez-Rosas, Siqi Shen,\n  Sarah Seraj, Larry An, Kenneth Resnicow, James Pennebaker, Rada Mihalcea", "title": "Expressive Interviewing: A Conversational System for Coping with\n  COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing COVID-19 pandemic has raised concerns for many regarding personal\nand public health implications, financial security and economic stability.\nAlongside many other unprecedented challenges, there are increasing concerns\nover social isolation and mental health. We introduce \\textit{Expressive\nInterviewing}--an interview-style conversational system that draws on ideas\nfrom motivational interviewing and expressive writing. Expressive Interviewing\nseeks to encourage users to express their thoughts and feelings through writing\nby asking them questions about how COVID-19 has impacted their lives. We\npresent relevant aspects of the system's design and implementation as well as\nquantitative and qualitative analyses of user interactions with the system. In\naddition, we conduct a comparative evaluation with a general purpose dialogue\nsystem for mental health that shows our system potential in helping users to\ncope with COVID-19 issues.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 22:52:14 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Welch", "Charles", ""], ["Lahnala", "Allison", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Shen", "Siqi", ""], ["Seraj", "Sarah", ""], ["An", "Larry", ""], ["Resnicow", "Kenneth", ""], ["Pennebaker", "James", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2007.03834", "submitter": "Tai-Danae Bradley", "authors": "Tai-Danae Bradley and Yiannis Vlassopoulos", "title": "Language Modeling with Reduced Densities", "comments": "19 pages; v2: added reference; v3: revised abstract and introduction\n  for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work originates from the observation that today's state of the art\nstatistical language models are impressive not only for their performance, but\nalso - and quite crucially - because they are built entirely from correlations\nin unstructured text data. The latter observation prompts a fundamental\nquestion that lies at the heart of this paper: What mathematical structure\nexists in unstructured text data? We put forth enriched category theory as a\nnatural answer. We show that sequences of symbols from a finite alphabet, such\nas those found in a corpus of text, form a category enriched over\nprobabilities. We then address a second fundamental question: How can this\ninformation be stored and modeled in a way that preserves the categorical\nstructure? We answer this by constructing a functor from our enriched category\nof text to a particular enriched category of reduced density operators. The\nlatter leverages the Loewner order on positive semidefinite operators, which\ncan further be interpreted as a toy example of entailment.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 00:41:53 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 00:24:05 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 12:28:19 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bradley", "Tai-Danae", ""], ["Vlassopoulos", "Yiannis", ""]]}, {"id": "2007.03848", "submitter": "Anoop Cherian", "authors": "Shijie Geng, Peng Gao, Moitreya Chatterjee, Chiori Hori, Jonathan Le\n  Roux, Yongfeng Zhang, Hongsheng Li, Anoop Cherian", "title": "Dynamic Graph Representation Learning for Video Dialog via Multi-Modal\n  Shuffled Transformers", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an input video, its associated audio, and a brief caption, the\naudio-visual scene aware dialog (AVSD) task requires an agent to indulge in a\nquestion-answer dialog with a human about the audio-visual content. This task\nthus poses a challenging multi-modal representation learning and reasoning\nscenario, advancements into which could influence several human-machine\ninteraction applications. To solve this task, we introduce a\nsemantics-controlled multi-modal shuffled Transformer reasoning framework,\nconsisting of a sequence of Transformer modules, each taking a modality as\ninput and producing representations conditioned on the input question. Our\nproposed Transformer variant uses a shuffling scheme on their multi-head\noutputs, demonstrating better regularization. To encode fine-grained visual\ninformation, we present a novel dynamic scene graph representation learning\npipeline that consists of an intra-frame reasoning layer producing\nspatio-semantic graph representations for every frame, and an inter-frame\naggregation module capturing temporal cues. Our entire pipeline is trained\nend-to-end. We present experiments on the benchmark AVSD dataset, both on\nanswer generation and selection tasks. Our results demonstrate state-of-the-art\nperformances on all evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 02:00:22 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 20:04:33 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Geng", "Shijie", ""], ["Gao", "Peng", ""], ["Chatterjee", "Moitreya", ""], ["Hori", "Chiori", ""], ["Roux", "Jonathan Le", ""], ["Zhang", "Yongfeng", ""], ["Li", "Hongsheng", ""], ["Cherian", "Anoop", ""]]}, {"id": "2007.03860", "submitter": "Yi-Jian Liu", "authors": "Zheng Li, Gang Tu, Guang Liu, Zhi-Qiang Zhan, Yi-Jian Liu", "title": "Research on multi-dimensional end-to-end phrase recognition algorithm\n  based on background knowledge", "comments": "in Chinese language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  At present, the deep end-to-end method based on supervised learning is used\nin entity recognition and dependency analysis. There are two problems in this\nmethod: firstly, background knowledge cannot be introduced; secondly, multi\ngranularity and nested features of natural language cannot be recognized. In\norder to solve these problems, the annotation rules based on phrase window are\nproposed, and the corresponding multi-dimensional end-to-end phrase recognition\nalgorithm is designed. This annotation rule divides sentences into seven types\nof nested phrases, and indicates the dependency between phrases. The algorithm\ncan not only introduce background knowledge, recognize all kinds of nested\nphrases in sentences, but also recognize the dependency between phrases. The\nexperimental results show that the annotation rule is easy to use and has no\nambiguity; the matching algorithm is more consistent with the multi granularity\nand diversity characteristics of syntax than the traditional end-to-end\nalgorithm. The experiment on CPWD dataset, by introducing background knowledge,\nthe new algorithm improves the accuracy of the end-to-end method by more than\none point. The corresponding method was applied to the CCL 2018 competition and\nwon the first place in the task of Chinese humor type recognition.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 02:30:00 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Li", "Zheng", ""], ["Tu", "Gang", ""], ["Liu", "Guang", ""], ["Zhan", "Zhi-Qiang", ""], ["Liu", "Yi-Jian", ""]]}, {"id": "2007.03875", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Shulin Cao, Liangming Pan, Yutong Xiang, Lei Hou, Juanzi\n  Li, Hanwang Zhang, Bin He", "title": "KQA Pro: A Large-Scale Dataset with Interpretable Programs and Accurate\n  SPARQLs for Complex Question Answering over Knowledge Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex question answering over knowledge base (Complex KBQA) is challenging\nbecause it requires various compositional reasoning capabilities, such as\nmulti-hop inference, attribute comparison, set operation, and etc. Existing\nbenchmarks have some shortcomings that limit the development of Complex KBQA:\n1) they only provide QA pairs without explicit reasoning processes; 2)\nquestions are either generated by templates, leading to poor diversity, or on a\nsmall scale. To this end, we introduce KQA Pro, a large-scale dataset for\nComplex KBQA. We define a compositional and highly-interpretable formal format,\nnamed Program, to represent the reasoning process of complex questions. We\npropose compositional strategies to generate questions, corresponding SPARQLs,\nand Programs with a small number of templates, and then paraphrase the\ngenerated questions to natural language questions (NLQ) by crowdsourcing,\ngiving rise to around 120K diverse instances. SPARQL and Program depict two\ncomplementary solutions to answer complex questions, which can benefit a large\nspectrum of QA methods. Besides the QA task, KQA Pro can also serves for the\nsemantic parsing task. As far as we know, it is currently the largest corpus of\nNLQ-to-SPARQL and NLQ-to-Program. We conduct extensive experiments to evaluate\nwhether machines can learn to answer our complex questions in different cases,\nthat is, with only QA supervision or with intermediate SPARQL/Program\nsupervision. We find that state-of-the-art KBQA methods learnt from only QA\npairs perform very poor on our dataset, implying our questions are more\nchallenging than previous datasets. However, pretrained models learnt from our\nNLQ-to-SPARQL and NLQ-to-Program annotations surprisingly achieve about 90\\%\nanswering accuracy, which is even close to the human expert performance...\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 03:28:04 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 10:15:29 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Shi", "Jiaxin", ""], ["Cao", "Shulin", ""], ["Pan", "Liangming", ""], ["Xiang", "Yutong", ""], ["Hou", "Lei", ""], ["Li", "Juanzi", ""], ["Zhang", "Hanwang", ""], ["He", "Bin", ""]]}, {"id": "2007.03876", "submitter": "Eda Okur", "authors": "Eda Okur, Shachi H Kumar, Saurav Sahay, Lama Nachman", "title": "Audio-Visual Understanding of Passenger Intents for In-Cabin\n  Conversational Agents", "comments": "ACL 2020 - Second Grand-Challenge and Workshop on Multimodal Language\n  (Challenge-HML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building multimodal dialogue understanding capabilities situated in the\nin-cabin context is crucial to enhance passenger comfort in autonomous vehicle\n(AV) interaction systems. To this end, understanding passenger intents from\nspoken interactions and vehicle vision systems is a crucial component for\ndeveloping contextual and visually grounded conversational agents for AV.\nTowards this goal, we explore AMIE (Automated-vehicle Multimodal In-cabin\nExperience), the in-cabin agent responsible for handling multimodal\npassenger-vehicle interactions. In this work, we discuss the benefits of a\nmultimodal understanding of in-cabin utterances by incorporating\nverbal/language input together with the non-verbal/acoustic and visual clues\nfrom inside and outside the vehicle. Our experimental results outperformed\ntext-only baselines as we achieved improved performances for intent detection\nwith a multimodal approach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 03:31:03 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Okur", "Eda", ""], ["Kumar", "Shachi H", ""], ["Sahay", "Saurav", ""], ["Nachman", "Lama", ""]]}, {"id": "2007.03900", "submitter": "Zeynab Raeesy", "authors": "Surabhi Punjabi, Harish Arsikere, Zeynab Raeesy, Chander Chandak,\n  Nikhil Bhave, Ankish Bansal, Markus M\\\"uller, Sergio Murillo, Ariya Rastrow,\n  Sri Garimella, Roland Maas, Mat Hans, Athanasios Mouchtaris, Siegfried\n  Kunzmann", "title": "Streaming End-to-End Bilingual ASR Systems with Joint Language\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual ASR technology simplifies model training and deployment, but its\naccuracy is known to depend on the availability of language information at\nruntime. Since language identity is seldom known beforehand in real-world\nscenarios, it must be inferred on-the-fly with minimum latency. Furthermore, in\nvoice-activated smart assistant systems, language identity is also required for\ndownstream processing of ASR output. In this paper, we introduce streaming,\nend-to-end, bilingual systems that perform both ASR and language identification\n(LID) using the recurrent neural network transducer (RNN-T) architecture. On\nthe input side, embeddings from pretrained acoustic-only LID classifiers are\nused to guide RNN-T training and inference, while on the output side, language\ntargets are jointly modeled with ASR targets. The proposed method is applied to\ntwo language pairs: English-Spanish as spoken in the United States, and\nEnglish-Hindi as spoken in India. Experiments show that for English-Spanish,\nthe bilingual joint ASR-LID architecture matches monolingual ASR and\nacoustic-only LID accuracies. For the more challenging (owing to\nwithin-utterance code switching) case of English-Hindi, English ASR and LID\nmetrics show degradation. Overall, in scenarios where users switch dynamically\nbetween languages, the proposed architecture offers a promising simplification\nover running multiple monolingual ASR models and an LID classifier in parallel.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 05:00:25 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Punjabi", "Surabhi", ""], ["Arsikere", "Harish", ""], ["Raeesy", "Zeynab", ""], ["Chandak", "Chander", ""], ["Bhave", "Nikhil", ""], ["Bansal", "Ankish", ""], ["M\u00fcller", "Markus", ""], ["Murillo", "Sergio", ""], ["Rastrow", "Ariya", ""], ["Garimella", "Sri", ""], ["Maas", "Roland", ""], ["Hans", "Mat", ""], ["Mouchtaris", "Athanasios", ""], ["Kunzmann", "Siegfried", ""]]}, {"id": "2007.03909", "submitter": "Clara Meister", "authors": "Clara Meister, Tim Vieira, Ryan Cotterell", "title": "Best-First Beam Search", "comments": "TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding for many NLP tasks requires an effective heuristic algorithm for\napproximating exact search since the problem of searching the full output space\nis often intractable, or impractical in many settings. The default algorithm\nfor this job is beam search -- a pruned version of breadth-first search. Quite\nsurprisingly, beam search often returns better results than exact inference due\nto beneficial search bias for NLP tasks. In this work, we show that the\nstandard implementation of beam search can be made up to 10x faster in\npractice. Our method assumes that the scoring function is monotonic in the\nsequence length, which allows us to safely prune hypotheses that cannot be in\nthe final set of hypotheses early on. We devise effective monotonic\napproximations to popular nonmonontic scoring functions, including length\nnormalization and mutual information decoding. Lastly, we propose a\nmemory-reduced variant of Best-First Beam Search, which has a similar\nbeneficial search bias in terms of downstream performance, but runs in a\nfraction of the time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 05:56:01 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 09:56:49 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 09:31:46 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Meister", "Clara", ""], ["Vieira", "Tim", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2007.03988", "submitter": "Quanming Yao", "authors": "Yu Liu and Quanming Yao and Yong Li", "title": "Generalizing Tensor Decomposition for N-ary Relational Knowledge Bases", "comments": "WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of knowledge bases (KBs), link prediction task,\nwhich completes KBs with missing facts, has been broadly studied in especially\nbinary relational KBs (a.k.a knowledge graph) with powerful tensor\ndecomposition related methods. However, the ubiquitous n-ary relational KBs\nwith higher-arity relational facts are paid less attention, in which existing\ntranslation based and neural network based approaches have weak expressiveness\nand high complexity in modeling various relations. Tensor decomposition has not\nbeen considered for n-ary relational KBs, while directly extending tensor\ndecomposition related methods of binary relational KBs to the n-ary case does\nnot yield satisfactory results due to exponential model complexity and their\nstrong assumptions on binary relations. To generalize tensor decomposition for\nn-ary relational KBs, in this work, we propose GETD, a generalized model based\non Tucker decomposition and Tensor Ring decomposition. The existing negative\nsampling technique is also generalized to the n-ary case for GETD. In addition,\nwe theoretically prove that GETD is fully expressive to completely represent\nany KBs. Extensive evaluations on two representative n-ary relational KB\ndatasets demonstrate the superior performance of GETD, significantly improving\nthe state-of-the-art methods by over 15\\%. Moreover, GETD further obtains the\nstate-of-the-art results on the benchmark binary relational KB datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 09:49:38 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Liu", "Yu", ""], ["Yao", "Quanming", ""], ["Li", "Yong", ""]]}, {"id": "2007.04032", "submitter": "Yuanhang Zhou", "authors": "Kun Zhou, Wayne Xin Zhao, Shuqing Bian, Yuanhang Zhou, Ji-Rong Wen,\n  Jingsong Yu", "title": "Improving Conversational Recommender Systems via Knowledge Graph based\n  Semantic Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational recommender systems (CRS) aim to recommend high-quality items\nto users through interactive conversations. Although several efforts have been\nmade for CRS, two major issues still remain to be solved. First, the\nconversation data itself lacks of sufficient contextual information for\naccurately understanding users' preference. Second, there is a semantic gap\nbetween natural language expression and item-level user preference. To address\nthese issues, we incorporate both word-oriented and entity-oriented knowledge\ngraphs (KG) to enhance the data representations in CRSs, and adopt Mutual\nInformation Maximization to align the word-level and entity-level semantic\nspaces. Based on the aligned semantic representations, we further develop a\nKG-enhanced recommender component for making accurate recommendations, and a\nKG-enhanced dialog component that can generate informative keywords or entities\nin the response text. Extensive experiments have demonstrated the effectiveness\nof our approach in yielding better performance on both recommendation and\nconversation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 11:14:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Zhou", "Kun", ""], ["Zhao", "Wayne Xin", ""], ["Bian", "Shuqing", ""], ["Zhou", "Yuanhang", ""], ["Wen", "Ji-Rong", ""], ["Yu", "Jingsong", ""]]}, {"id": "2007.04070", "submitter": "Inigo Jauregi Unanue", "authors": "Binh Thanh Kieu, Inigo Jauregi Unanue, Son Bao Pham, Hieu Xuan Phan,\n  Massimo Piccardi", "title": "Learning Neural Textual Representations for Citation Recommendation", "comments": "Accepted in ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the scientific literature, manually selecting\nappropriate citations for a paper is becoming increasingly challenging and\ntime-consuming. While several approaches for automated citation recommendation\nhave been proposed in the recent years, effective document representations for\ncitation recommendation are still elusive to a large extent. For this reason,\nin this paper we propose a novel approach to citation recommendation which\nleverages a deep sequential representation of the documents (Sentence-BERT)\ncascaded with Siamese and triplet networks in a submodular scoring function. To\nthe best of our knowledge, this is the first approach to combine deep\nrepresentations and submodular selection for a task of citation recommendation.\nExperiments have been carried out using a popular benchmark dataset - the ACL\nAnthology Network corpus - and evaluated against baselines and a\nstate-of-the-art approach using metrics such as the MRR and F1-at-k score. The\nresults show that the proposed approach has been able to outperform all the\ncompared approaches in every measured metric.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:38:50 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Kieu", "Binh Thanh", ""], ["Unanue", "Inigo Jauregi", ""], ["Pham", "Son Bao", ""], ["Phan", "Hieu Xuan", ""], ["Piccardi", "Massimo", ""]]}, {"id": "2007.04134", "submitter": "Abhinav Shukla", "authors": "Abhinav Shukla, Stavros Petridis, Maja Pantic", "title": "Learning Speech Representations from Raw Audio by Joint Audiovisual\n  Self-Supervision", "comments": "Accepted at the Workshop on Self-supervision in Audio and Speech at\n  ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intuitive interaction between the audio and visual modalities is valuable\nfor cross-modal self-supervised learning. This concept has been demonstrated\nfor generic audiovisual tasks like video action recognition and acoustic scene\nclassification. However, self-supervision remains under-explored for\naudiovisual speech. We propose a method to learn self-supervised speech\nrepresentations from the raw audio waveform. We train a raw audio encoder by\ncombining audio-only self-supervision (by predicting informative audio\nattributes) with visual self-supervision (by generating talking faces from\naudio). The visual pretext task drives the audio representations to capture\ninformation related to lip movements. This enriches the audio encoder with\nvisual information and the encoder can be used for evaluation without the\nvisual modality. Our method attains competitive performance with respect to\nexisting self-supervised audio features on established isolated word\nclassification benchmarks, and significantly outperforms other methods at\nlearning from fewer labels. Notably, our method also outperforms fully\nsupervised training, thus providing a strong initialization for speech related\ntasks. Our results demonstrate the potential of multimodal self-supervision in\naudiovisual speech for learning good audio representations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 14:07:06 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Shukla", "Abhinav", ""], ["Petridis", "Stavros", ""], ["Pantic", "Maja", ""]]}, {"id": "2007.04181", "submitter": "Dylan Grosz", "authors": "Dylan Grosz, Patricia Conde-Cespedes", "title": "Automatic Detection of Sexist Statements Commonly Used at the Workplace", "comments": "Published at the PAKDD 2020 Workshop on Learning Data Representation\n  for Clustering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting hate speech in the workplace is a unique classification task, as\nthe underlying social context implies a subtler version of conventional hate\nspeech. Applications regarding a state-of the-art workplace sexism detection\nmodel include aids for Human Resources departments, AI chatbots and sentiment\nanalysis. Most existing hate speech detection methods, although robust and\naccurate, focus on hate speech found on social media, specifically Twitter. The\ncontext of social media is much more anonymous than the workplace, therefore it\ntends to lend itself to more aggressive and \"hostile\" versions of sexism.\nTherefore, datasets with large amounts of \"hostile\" sexism have a slightly\neasier detection task since \"hostile\" sexist statements can hinge on a couple\nwords that, regardless of context, tip the model off that a statement is\nsexist. In this paper we present a dataset of sexist statements that are more\nlikely to be said in the workplace as well as a deep learning model that can\nachieve state-of-the art results. Previous research has created\nstate-of-the-art models to distinguish \"hostile\" and \"benevolent\" sexism based\nsimply on aggregated Twitter data. Our deep learning methods, initialized with\nGloVe or random word embeddings, use LSTMs with attention mechanisms to\noutperform those models on a more diverse, filtered dataset that is more\ntargeted towards workplace sexism, leading to an F1 score of 0.88.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:14:29 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Grosz", "Dylan", ""], ["Conde-Cespedes", "Patricia", ""]]}, {"id": "2007.04205", "submitter": "Mar\\'ia Andrea Cruz Bland\\'on", "authors": "Mar\\'ia Andrea Cruz Bland\\'on and Okko R\\\"as\\\"anen", "title": "Analysis of Predictive Coding Models for Phonemic Representation\n  Learning in Small Datasets", "comments": "7 pages, 5 figures, 5 tables. Accepted paper at the workshop on\n  Self-supervision in Audio and Speech at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network models using predictive coding are interesting from the\nviewpoint of computational modelling of human language acquisition, where the\nobjective is to understand how linguistic units could be learned from speech\nwithout any labels. Even though several promising predictive coding -based\nlearning algorithms have been proposed in the literature, it is currently\nunclear how well they generalise to different languages and training dataset\nsizes. In addition, despite that such models have shown to be effective\nphonemic feature learners, it is unclear whether minimisation of the predictive\nloss functions of these models also leads to optimal phoneme-like\nrepresentations. The present study investigates the behaviour of two predictive\ncoding models, Autoregressive Predictive Coding and Contrastive Predictive\nCoding, in a phoneme discrimination task (ABX task) for two languages with\ndifferent dataset sizes. Our experiments show a strong correlation between the\nautoregressive loss and the phoneme discrimination scores with the two\ndatasets. However, to our surprise, the CPC model shows rapid convergence\nalready after one pass over the training data, and, on average, its\nrepresentations outperform those of APC on both languages.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:46:13 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Bland\u00f3n", "Mar\u00eda Andrea Cruz", ""], ["R\u00e4s\u00e4nen", "Okko", ""]]}, {"id": "2007.04239", "submitter": "Zaid Alyafeai Mr", "authors": "Zaid Alyafeai, Maged Saeed AlShaibani, Irfan Ahmad", "title": "A Survey on Transfer Learning in Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models usually require a huge amount of data. However, these\nlarge datasets are not always attainable. This is common in many challenging\nNLP tasks. Consider Neural Machine Translation, for instance, where curating\nsuch large datasets may not be possible specially for low resource languages.\nAnother limitation of deep learning models is the demand for huge computing\nresources. These obstacles motivate research to question the possibility of\nknowledge transfer using large trained models. The demand for transfer learning\nis increasing as many large models are emerging. In this survey, we feature the\nrecent transfer learning advances in the field of NLP. We also provide a\ntaxonomy for categorizing different transfer learning approaches from the\nliterature.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 21:52:31 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Alyafeai", "Zaid", ""], ["AlShaibani", "Maged Saeed", ""], ["Ahmad", "Irfan", ""]]}, {"id": "2007.04245", "submitter": "Ka Chun Lam", "authors": "Ka Chun Lam, Francisco Pereira, Maryam Vaziri-Pashkam, Kristin\n  Woodard, Emalie McMahon", "title": "Mental representations of objects reflect the ways in which we interact\n  with them", "comments": "17 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to interact with objects in our environment, humans rely on an\nunderstanding of the actions that can be performed on them, as well as their\nproperties. When considering concrete motor actions, this knowledge has been\ncalled the object affordance. Can this notion be generalized to any type of\ninteraction that one can have with an object? In this paper we introduce a\nmethod to represent objects in a space where each dimension corresponds to a\nbroad mode of interaction, based on verb selectional preferences in text\ncorpora. This object embedding makes it possible to predict human judgments of\nverb applicability to objects better than a variety of alternative approaches.\nFurthermore, we show that the dimensions in this space can be used to predict\ncategorical and functional dimensions in a state-of-the-art mental\nrepresentation of objects, derived solely from human judgements of object\nsimilarity. These results suggest that interaction knowledge accounts for a\nlarge part of mental representations of objects.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 22:05:56 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:06:41 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lam", "Ka Chun", ""], ["Pereira", "Francisco", ""], ["Vaziri-Pashkam", "Maryam", ""], ["Woodard", "Kristin", ""], ["McMahon", "Emalie", ""]]}, {"id": "2007.04247", "submitter": "Mehmet Aydar", "authors": "Mehmet Aydar and Ozge Bozal and Furkan Ozbay", "title": "Neural relation extraction: a survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural relation extraction discovers semantic relations between entities from\nunstructured text using deep learning methods. In this study, we present a\ncomprehensive review of methods on neural network based relation extraction. We\ndiscuss advantageous and incompetent sides of existing studies and investigate\nadditional research directions and improvement ideas in this field.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 13:47:58 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Aydar", "Mehmet", ""], ["Bozal", "Ozge", ""], ["Ozbay", "Furkan", ""]]}, {"id": "2007.04248", "submitter": "Nazakat Ali", "authors": "Nazakat Ali", "title": "Chatbot: A Conversational Agent employed with Named Entity Recognition\n  Model using Artificial Neural Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatbot is a technology that is used to mimic human behavior using natural\nlanguage. There are different types of Chatbot that can be used as\nconversational agent in various business domains in order to increase the\ncustomer service and satisfaction. For any business domain, it requires a\nknowledge base to be built for that domain and design an information retrieval\nbased system that can respond the user with a piece of documentation or\ngenerated sentences. The core component of a Chatbot is Natural Language\nUnderstanding (NLU) which has been impressively improved by deep learning\nmethods. But we often lack such properly built NLU modules and requires more\ntime to build it from scratch for high quality conversations. This may\nencourage fresh learners to build a Chatbot from scratch with simple\narchitecture and using small dataset, although it may have reduced\nfunctionality, rather than building high quality data driven methods. This\nresearch focuses on Named Entity Recognition (NER) and Intent Classification\nmodels which can be integrated into NLU service of a Chatbot. Named entities\nwill be inserted manually in the knowledge base and automatically detected in a\ngiven sentence. The NER model in the proposed architecture is based on\nartificial neural network which is trained on manually created entities and\nevaluated using CoNLL-2003 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:47:21 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Ali", "Nazakat", ""]]}, {"id": "2007.04249", "submitter": "Subramaniam Kazhuparambil Mr.", "authors": "Subramaniam Kazhuparambil (1) and Abhishek Kaushik (1 and 2) ((1)\n  Dublin Business School, (2) Dublin City University)", "title": "Cooking Is All About People: Comment Classification On Cookery Channels\n  Using BERT and Classification Models (Malayalam-English Mix-Code)", "comments": "Rectified typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The scope of a lucrative career promoted by Google through its video\ndistribution platform YouTube has attracted a large number of users to become\ncontent creators. An important aspect of this line of work is the feedback\nreceived in the form of comments which show how well the content is being\nreceived by the audience. However, volume of comments coupled with spam and\nlimited tools for comment classification makes it virtually impossible for a\ncreator to go through each and every comment and gather constructive feedback.\nAutomatic classification of comments is a challenge even for established\nclassification models, since comments are often of variable lengths riddled\nwith slang, symbols and abbreviations. This is a greater challenge where\ncomments are multilingual as the messages are often rife with the respective\nvernacular. In this work, we have evaluated top-performing classification\nmodels for classifying comments which are a mix of different combinations of\nEnglish and Malayalam (only English, only Malayalam and Mix of English and\nMalayalam). The statistical analysis of results indicates that Multinomial\nNaive Bayes, K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Random\nForest and Decision Trees offer similar level of accuracy in comment\nclassification. Further, we have also evaluated 3 multilingual transformer\nbased language models (BERT, DISTILBERT and XLM) and compared their performance\nto the traditional machine learning classification techniques. XLM was the\ntop-performing BERT model with an accuracy of 67.31. Random Forest with Term\nFrequency Vectorizer was the best performing model out of all the traditional\nclassification models with an accuracy of 63.59.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 19:07:06 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 12:57:24 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 08:40:09 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kazhuparambil", "Subramaniam", "", "1 and 2"], ["Kaushik", "Abhishek", "", "1 and 2"]]}, {"id": "2007.04297", "submitter": "Shivang Chopra", "authors": "Shreya Singal, Tanishq Goel, Shivang Chopra, Sonika Dahiya", "title": "Open Domain Suggestion Mining Leveraging Fine-Grained Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suggestion mining tasks are often semantically complex and lack sophisticated\nmethodologies that can be applied to real-world data. The presence of\nsuggestions across a large diversity of domains and the absence of large\nlabelled and balanced datasets render this task particularly challenging to\ndeal with. In an attempt to overcome these challenges, we propose a two-tier\npipeline that leverages Discourse Marker based oversampling and fine-grained\nsuggestion mining techniques to retrieve suggestions from online forums.\nThrough extensive comparison on a real-world open-domain suggestion dataset, we\ndemonstrate how the oversampling technique combined with transformer based\nfine-grained analysis can beat the state of the art. Additionally, we perform\nextensive qualitative and qualitative analysis to give construct validity to\nour proposed pipeline. Finally, we discuss the practical, computational and\nreproducibility aspects of the deployment of our pipeline across the web.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 21:01:52 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 19:47:47 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Singal", "Shreya", ""], ["Goel", "Tanishq", ""], ["Chopra", "Shivang", ""], ["Dahiya", "Sonika", ""]]}, {"id": "2007.04298", "submitter": "Quanshi Zhang", "authors": "Die Zhang, Huilin Zhou, Hao Zhang, Xiaoyi Bao, Da Huo, Ruizhao Chen,\n  Xu Cheng, Mengyue Wu, Quanshi Zhang", "title": "Building Interpretable Interaction Trees for Deep NLP Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method to disentangle and quantify interactions among\nwords that are encoded inside a DNN for natural language processing. We\nconstruct a tree to encode salient interactions extracted by the DNN. Six\nmetrics are proposed to analyze properties of interactions between constituents\nin a sentence. The interaction is defined based on Shapley values of words,\nwhich are considered as an unbiased estimation of word contributions to the\nnetwork prediction. Our method is used to quantify word interactions encoded\ninside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental\nresults have provided a new perspective to understand these DNNs, and have\ndemonstrated the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 10:26:50 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 15:07:07 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhang", "Die", ""], ["Zhou", "Huilin", ""], ["Zhang", "Hao", ""], ["Bao", "Xiaoyi", ""], ["Huo", "Da", ""], ["Chen", "Ruizhao", ""], ["Cheng", "Xu", ""], ["Wu", "Mengyue", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2007.04300", "submitter": "Paulo Finardi", "authors": "Gustavo Plensack and Paulo Finardi", "title": "Normalizador Neural de Datas e Endere\\c{c}os", "comments": "7 pages, in Portuguese, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Documents of any kind present a wide variety of date and address formats, in\nsome cases dates can be written entirely in full or even have different types\nof separators. The pattern disorder in addresses is even greater due to the\ngreater possibility of interchanging between streets, neighborhoods, cities and\nstates. In the context of natural language processing, problems of this nature\nare handled by rigid tools such as ReGex or DateParser, which are efficient as\nlong as the expected input is pre-configured. When these algorithms are given\nan unexpected format, errors and unwanted outputs happen. To circumvent this\nchallenge, we present a solution with deep neural networks state of art T5 that\ntreats non-preconfigured formats of dates and addresses with accuracy above 90%\nin some cases. With this model, our proposal brings generalization to the task\nof normalizing dates and addresses. We also deal with this problem with noisy\ndata that simulates possible errors in the text.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 20:24:35 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 01:03:47 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Plensack", "Gustavo", ""], ["Finardi", "Paulo", ""]]}, {"id": "2007.04301", "submitter": "Aref Jafari", "authors": "Aref Jafari, Ali Ghodsi", "title": "Segmentation Approach for Coreference Resolution Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In coreference resolution, it is important to consider all members of a\ncoreference cluster and decide about all of them at once. This technique can\nhelp to avoid losing precision and also in finding long-distance relations. The\npresented paper is a report of an ongoing study on an idea which proposes a new\napproach for coreference resolution which can resolve all coreference mentions\nto a given mention in the document in one pass. This has been accomplished by\ndefining an embedding method for the position of all members of a coreference\ncluster in a document and resolving all of them for a given mention. In the\nproposed method, the BERT model has been used for encoding the documents and a\nhead network designed to capture the relations between the embedded tokens.\nThese are then converted to the proposed span position embedding matrix which\nembeds the position of all coreference mentions in the document. We tested this\nidea on CoNLL 2012 dataset and although the preliminary results from this\nmethod do not quite meet the state-of-the-art results, they are promising and\nthey can capture features like long-distance relations better than the other\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 16:44:28 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Jafari", "Aref", ""], ["Ghodsi", "Ali", ""]]}, {"id": "2007.04302", "submitter": "Ravi Vadlamani", "authors": "Akhilesh Kumar Gangwar and Vadlamani Ravi", "title": "A Novel BGCapsule Network for Text Classification", "comments": "14 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Several text classification tasks such as sentiment analysis, news\ncategorization, multi-label classification and opinion classification are\nchallenging problems even for modern deep learning networks. Recently, Capsule\nNetworks (CapsNets) are proposed for image classification. It has been shown\nthat CapsNets have several advantages over Convolutional Neural Networks\n(CNNs), while their validity in the domain of text has been less explored. In\nthis paper, we propose a novel hybrid architecture viz., BGCapsule, which is a\nCapsule model preceded by an ensemble of Bidirectional Gated Recurrent Units\n(BiGRU) for several text classification tasks. We employed an ensemble of\nBidirectional GRUs for feature extraction layer preceding the primary capsule\nlayer. The hybrid architecture, after performing basic pre-processing steps,\nconsists of five layers: an embedding layer based on GloVe, a BiGRU based\nensemble layer, a primary capsule layer, a flatten layer and fully connected\nReLU layer followed by a fully connected softmax layer. In order to evaluate\nthe effectiveness of BGCapsule, we conducted extensive experiments on five\nbenchmark datasets (ranging from 10,000 records to 700,000 records) including\nMovie Review (MR Imdb 2005), AG News dataset, Dbpedia ontology dataset, Yelp\nReview Full dataset and Yelp review polarity dataset. These benchmarks cover\nseveral text classification tasks such as news categorization, sentiment\nanalysis, multiclass classification, multi-label classification and opinion\nclassification. We found that our proposed architecture (BGCapsule) achieves\nbetter accuracy compared to the existing methods without the help of any\nexternal linguistic knowledge such as positive sentiment keywords and negative\nsentiment keywords. Further, BGCapsule converged faster compared to other\nextant techniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 06:07:29 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Gangwar", "Akhilesh Kumar", ""], ["Ravi", "Vadlamani", ""]]}, {"id": "2007.04303", "submitter": "Aditya Sharma", "authors": "Aditya Sharma, Alex Daniels", "title": "Tweets Sentiment Analysis via Word Embeddings and Machine Learning\n  Techniques", "comments": "This submission has been removed by arXiv administrators due to\n  copyright infringement and text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sentiment analysis of social media data consists of attitudes, assessments,\nand emotions which can be considered a way human think. Understanding and\nclassifying the large collection of documents into positive and negative\naspects are a very difficult task. Social networks such as Twitter, Facebook,\nand Instagram provide a platform in order to gather information about peoples\nsentiments and opinions. Considering the fact that people spend hours daily on\nsocial media and share their opinion on various different topics helps us\nanalyze sentiments better. More and more companies are using social media tools\nto provide various services and interact with customers. Sentiment Analysis\n(SA) classifies the polarity of given tweets to positive and negative tweets in\norder to understand the sentiments of the public. This paper aims to perform\nsentiment analysis of real-time 2019 election twitter data using the feature\nselection model word2vec and the machine learning algorithm random forest for\nsentiment classification. Word2vec with Random Forest improves the accuracy of\nsentiment analysis significantly compared to traditional methods such as BOW\nand TF-IDF. Word2vec improves the quality of features by considering contextual\nsemantics of words in a text hence improving the accuracy of machine learning\nand sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 08:10:30 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Sharma", "Aditya", ""], ["Daniels", "Alex", ""]]}, {"id": "2007.04304", "submitter": "Oliver Roesler", "authors": "Oliver Roesler", "title": "Unsupervised Online Grounding of Natural Language during Human-Robot\n  Interactions", "comments": "11 pages, 6 figures, 3 tables; Published in Proceedings of the Second\n  Grand Challenge and Workshop on Multimodal Language (Challenge-HML) in the\n  58th Annual Meeting of the Association for Computational Linguistics (ACL\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing humans to communicate through natural language with robots requires\nconnections between words and percepts. The process of creating these\nconnections is called symbol grounding and has been studied for nearly three\ndecades. Although many studies have been conducted, not many considered\ngrounding of synonyms and the employed algorithms either work only offline or\nin a supervised manner. In this paper, a cross-situational learning based\ngrounding framework is proposed that allows grounding of words and phrases\nthrough corresponding percepts without human supervision and online, i.e. it\ndoes not require any explicit training phase, but instead updates the obtained\nmappings for every new encountered situation. The proposed framework is\nevaluated through an interaction experiment between a human tutor and a robot,\nand compared to an existing unsupervised grounding framework. The results show\nthat the proposed framework is able to ground words through their corresponding\npercepts online and in an unsupervised manner, while outperforming the baseline\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 17:48:26 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Roesler", "Oliver", ""]]}, {"id": "2007.04422", "submitter": "Vatsal Goel", "authors": "Vatsal Goel, Mohit Chandak, Ashish Anand and Prithwijit Guha", "title": "IQ-VQA: Intelligent Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though there has been tremendous progress in the field of Visual\nQuestion Answering, models today still tend to be inconsistent and brittle. To\nthis end, we propose a model-independent cyclic framework which increases\nconsistency and robustness of any VQA architecture. We train our models to\nanswer the original question, generate an implication based on the answer and\nthen also learn to answer the generated implication correctly. As a part of the\ncyclic framework, we propose a novel implication generator which can generate\nimplied questions from any question-answer pair. As a baseline for future works\non consistency, we provide a new human annotated VQA-Implications dataset. The\ndataset consists of ~30k questions containing implications of 3 types - Logical\nEquivalence, Necessary Condition and Mutual Exclusion - made from the VQA v2.0\nvalidation dataset. We show that our framework improves consistency of VQA\nmodels by ~15% on the rule-based dataset, ~7% on VQA-Implications dataset and\nrobustness by ~2%, without degrading their performance. In addition, we also\nquantitatively show improvement in attention maps which highlights better\nmulti-modal understanding of vision and language.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 20:41:52 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Goel", "Vatsal", ""], ["Chandak", "Mohit", ""], ["Anand", "Ashish", ""], ["Guha", "Prithwijit", ""]]}, {"id": "2007.04428", "submitter": "Baber Khalid", "authors": "Baber Khalid, Malihe Alikhani, Michael Fellner, Brian McMahan, Matthew\n  Stone", "title": "Discourse Coherence, Reference Grounding and Goal Oriented Dialogue", "comments": "Accepted for Publishing at SemDial 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior approaches to realizing mixed-initiative human--computer referential\ncommunication have adopted information-state or collaborative problem-solving\napproaches. In this paper, we argue for a new approach, inspired by\ncoherence-based models of discourse such as SDRT \\cite{asher-lascarides:2003a},\nin which utterances attach to an evolving discourse structure and the\nassociated knowledge graph of speaker commitments serves as an interface to\nreal-world reasoning and conversational strategy. As first steps towards\nimplementing the approach, we describe a simple dialogue system in a\nreferential communication domain that accumulates constraints across discourse,\ninterprets them using a learned probabilistic model, and plans clarification\nusing reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 20:53:14 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Khalid", "Baber", ""], ["Alikhani", "Malihe", ""], ["Fellner", "Michael", ""], ["McMahan", "Brian", ""], ["Stone", "Matthew", ""]]}, {"id": "2007.04508", "submitter": "Dustin Stoltz", "authors": "Dustin S. Stoltz and Marshall A. Taylor", "title": "Cultural Cartography with Word Embeddings", "comments": null, "journal-ref": null, "doi": "10.1016/j.poetic.2021.101567", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Using the frequency of keywords is a classic approach in the formal analysis\nof text, but has the drawback of glossing over the relationality of word\nmeanings. Word embedding models overcome this problem by constructing a\nstandardized and continuous \"meaning space\" where words are assigned a location\nbased on relations of similarity to other words based on how they are used in\nnatural language samples. We show how word embeddings are commensurate with\nprevailing theories of meaning in sociology and can be put to the task of\ninterpretation via two kinds of navigation. First, one can hold terms constant\nand measure how the embedding space moves around them--much like astronomers\nmeasured the changing of celestial bodies with the seasons. Second, one can\nalso hold the embedding space constant and see how documents or authors move\nrelative to it--just as ships use the stars on a given night to determine their\nlocation. Using the empirical case of immigration discourse in the United\nStates, we demonstrate the merits of these two broad strategies for advancing\nimportant topics in cultural theory, including social marking, media fields,\necho chambers, and cultural diffusion and change more broadly.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 01:58:28 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 20:58:20 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 15:48:56 GMT"}, {"version": "v4", "created": "Mon, 3 May 2021 21:13:27 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Stoltz", "Dustin S.", ""], ["Taylor", "Marshall A.", ""]]}, {"id": "2007.04526", "submitter": "Shiwei Zhang", "authors": "Shiwei Zhang, Xiuzhen Zhang, Jey Han Lau, Jeffrey Chan, and Cecile\n  Paris", "title": "Less is More: Rejecting Unreliable Reviews for Product Question\n  Answering", "comments": "ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promptly and accurately answering questions on products is important for\ne-commerce applications. Manually answering product questions (e.g. on\ncommunity question answering platforms) results in slow response and does not\nscale. Recent studies show that product reviews are a good source for\nreal-time, automatic product question answering (PQA). In the literature, PQA\nis formulated as a retrieval problem with the goal to search for the most\nrelevant reviews to answer a given product question. In this paper, we focus on\nthe issue of answerability and answer reliability for PQA using reviews. Our\ninvestigation is based on the intuition that many questions may not be\nanswerable with a finite set of reviews. When a question is not answerable, a\nsystem should return nil answers rather than providing a list of irrelevant\nreviews, which can have significant negative impact on user experience.\nMoreover, for answerable questions, only the most relevant reviews that answer\nthe question should be included in the result. We propose a conformal\nprediction based framework to improve the reliability of PQA systems, where we\nreject unreliable answers so that the returned results are more concise and\naccurate at answering the product question, including returning nil answers for\nunanswerable questions. Experiments on a widely used Amazon dataset show\nencouraging results of our proposed framework. More broadly, our results\ndemonstrate a novel and effective application of conformal methods to a\nretrieval task.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 03:08:55 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Zhang", "Shiwei", ""], ["Zhang", "Xiuzhen", ""], ["Lau", "Jey Han", ""], ["Chan", "Jeffrey", ""], ["Paris", "Cecile", ""]]}, {"id": "2007.04571", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Majid Ramezani, Mohammad-Reza Feizi-Derakhshi, Mohammad-Ali Balafar,\n  Meysam Asgari-Chenaghlu, Ali-Reza Feizi-Derakhshi, Narjes Nikzad-Khasmakhi,\n  Mehrdad Ranjbar-Khadivi, Zoleikha Jahanbakhsh-Nagadeh, Elnaz\n  Zafarani-Moattar, Taymaz Rahkar-Farshi", "title": "Automatic Personality Prediction; an Enhanced Method Using Ensemble\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human personality is significantly represented by those words which he/she\nuses in his/her speech or writing. As a consequence of spreading the\ninformation infrastructures (specifically the Internet and social media), human\ncommunications have reformed notably from face to face communication.\nGenerally, Automatic Personality Prediction (or Perception) (APP) is the\nautomated forecasting of the personality on different types of human\ngenerated/exchanged contents (like text, speech, image, video, etc.). The major\nobjective of this study is to enhance the accuracy of APP from the text. To\nthis end, we suggest five new APP methods including term frequency\nvector-based, ontology-based, enriched ontology-based, latent semantic analysis\n(LSA)-based, and deep learning-based (BiLSTM) methods. These methods as the\nbase ones, contribute to each other to enhance the APP accuracy through\nensemble modeling (stacking) based on a hierarchical attention network (HAN) as\nthe meta-model. The results show that ensemble modeling enhances the accuracy\nof APP.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 06:05:10 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 07:37:07 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ramezani", "Majid", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Balafar", "Mohammad-Ali", ""], ["Asgari-Chenaghlu", "Meysam", ""], ["Feizi-Derakhshi", "Ali-Reza", ""], ["Nikzad-Khasmakhi", "Narjes", ""], ["Ranjbar-Khadivi", "Mehrdad", ""], ["Jahanbakhsh-Nagadeh", "Zoleikha", ""], ["Zafarani-Moattar", "Elnaz", ""], ["Rahkar-Farshi", "Taymaz", ""]]}, {"id": "2007.04590", "submitter": "Yi Ren", "authors": "Yi Ren, Xu Tan, Tao Qin, Jian Luan, Zhou Zhao, Tie-Yan Liu", "title": "DeepSinger: Singing Voice Synthesis with Data Mined From the Web", "comments": "Accepted by KDD2020 research track", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop DeepSinger, a multi-lingual multi-singer singing\nvoice synthesis (SVS) system, which is built from scratch using singing\ntraining data mined from music websites. The pipeline of DeepSinger consists of\nseveral steps, including data crawling, singing and accompaniment separation,\nlyrics-to-singing alignment, data filtration, and singing modeling.\nSpecifically, we design a lyrics-to-singing alignment model to automatically\nextract the duration of each phoneme in lyrics starting from coarse-grained\nsentence level to fine-grained phoneme level, and further design a\nmulti-lingual multi-singer singing model based on a feed-forward Transformer to\ndirectly generate linear-spectrograms from lyrics, and synthesize voices using\nGriffin-Lim. DeepSinger has several advantages over previous SVS systems: 1) to\nthe best of our knowledge, it is the first SVS system that directly mines\ntraining data from music websites, 2) the lyrics-to-singing alignment model\nfurther avoids any human efforts for alignment labeling and greatly reduces\nlabeling cost, 3) the singing model based on a feed-forward Transformer is\nsimple and efficient, by removing the complicated acoustic feature modeling in\nparametric synthesis and leveraging a reference encoder to capture the timbre\nof a singer from noisy singing data, and 4) it can synthesize singing voices in\nmultiple languages and multiple singers. We evaluate DeepSinger on our mined\nsinging dataset that consists of about 92 hours data from 89 singers on three\nlanguages (Chinese, Cantonese and English). The results demonstrate that with\nthe singing data purely mined from the Web, DeepSinger can synthesize\nhigh-quality singing voices in terms of both pitch accuracy and voice\nnaturalness (footnote: Our audio samples are shown in\nhttps://speechresearch.github.io/deepsinger/.)\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 07:00:48 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 14:37:45 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Ren", "Yi", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Luan", "Jian", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2007.04626", "submitter": "Alberto Barbado Gonzalez", "authors": "Alberto Barbado, V\\'ictor Fresno, \\'Angeles Manjarr\\'es Riesco,\n  Salvador Ros", "title": "DISCO PAL: Diachronic Spanish Sonnet Corpus with Psychological and\n  Affective Labels", "comments": "24 pages, 3 figures, 17 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, there are many applications of text mining over corpora from\ndifferent languages. However, most of them are based on texts in prose, lacking\napplications that work with poetry texts. An example of an application of text\nmining in poetry is the usage of features derived from their individual words\nin order to capture the lexical, sublexical and interlexical meaning, and infer\nthe General Affective Meaning (GAM) of the text. However, even though this\nproposal has been proved as useful for poetry in some languages, there is a\nlack of studies for both Spanish poetry and for highly-structured poetic\ncompositions such as sonnets. This article presents a study over an annotated\ncorpus of Spanish sonnets, in order to analyse if it is possible to build\nfeatures from their individual words for predicting their GAM. The purpose of\nthis is to model sonnets at an affective level. The article also analyses the\nrelationship between the GAM of the sonnets and the content itself. For this,\nwe consider the content from a psychological perspective, identifying with tags\nwhen a sonnet is related to a specific term. Then, we study how GAM changes\naccording to each of those psychological terms.\n  The corpus used contains 274 Spanish sonnets from authors of different\ncenturies, from 15th to 19th. This corpus was annotated by different domain\nexperts. The experts annotated the poems with affective and lexico-semantic\nfeatures, as well as with domain concepts that belong to psychology. Thanks to\nthis, the corpus of sonnets can be used in different applications, such as\npoetry recommender systems, personality text mining studies of the authors, or\nthe usage of poetry for therapeutic purposes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 08:26:22 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 07:58:15 GMT"}, {"version": "v3", "created": "Sun, 20 Jun 2021 19:19:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Barbado", "Alberto", ""], ["Fresno", "V\u00edctor", ""], ["Riesco", "\u00c1ngeles Manjarr\u00e9s", ""], ["Ros", "Salvador", ""]]}, {"id": "2007.04629", "submitter": "Ali Basirat", "authors": "Ali Basirat, Christian Hardmeier, Joakim Nivre", "title": "Principal Word Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize principal component analysis for embedding words into a vector\nspace. The generalization is made in two major levels. The first is to\ngeneralize the concept of the corpus as a counting process which is defined by\nthree key elements vocabulary set, feature (annotation) set, and context. This\ngeneralization enables the principal word embedding method to generate word\nvectors with regard to different types of contexts and different types of\nannotations provided for a corpus. The second is to generalize the\ntransformation step used in most of the word embedding methods. To this end, we\ndefine two levels of transformations. The first is a quadratic transformation,\nwhich accounts for different types of weighting over the vocabulary units and\ncontextual features. Second is an adaptive non-linear transformation, which\nreshapes the data distribution to be meaningful to principal component\nanalysis. The effect of these generalizations on the word vectors is\nintrinsically studied with regard to the spread and the discriminability of the\nword vectors. We also provide an extrinsic evaluation of the contribution of\nthe principal word vectors on a word similarity benchmark and the task of\ndependency parsing. Our experiments are finalized by a comparison between the\nprincipal word vectors and other sets of word vectors generated with popular\nword embedding methods. The results obtained from our intrinsic evaluation\nmetrics show that the spread and the discriminability of the principal word\nvectors are higher than that of other word embedding methods. The results\nobtained from the extrinsic evaluation metrics show that the principal word\nvectors are better than some of the word embedding methods and on par with\npopular methods of word embedding.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 08:29:57 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Basirat", "Ali", ""], ["Hardmeier", "Christian", ""], ["Nivre", "Joakim", ""]]}, {"id": "2007.04686", "submitter": "Ali Basirat", "authors": "Ali Basirat, Joakim Nivre", "title": "Greedy Transition-Based Dependency Parsing with Discrete and Continuous\n  Supertag Features", "comments": "This paper was originally submitted to EMNLP 2015 and has not been\n  previously published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of rich supertag features in greedy transition-based\ndependency parsing. While previous studies have shown that sparse boolean\nfeatures representing the 1-best supertag of a word can improve parsing\naccuracy, we show that we can get further improvements by adding a continuous\nvector representation of the entire supertag distribution for a word. In this\nway, we achieve the best results for greedy transition-based parsing with\nsupertag features with $88.6\\%$ LAS and $90.9\\%$ UASon the English Penn\nTreebank converted to Stanford Dependencies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 10:29:19 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Basirat", "Ali", ""], ["Nivre", "Joakim", ""]]}, {"id": "2007.04792", "submitter": "David Schlangen", "authors": "David Schlangen", "title": "Targeting the Benchmark: On Methodology in Current Natural Language\n  Processing Research", "comments": "arXiv admin note: text overlap with arXiv:1908.10747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has become a common pattern in our field: One group introduces a language\ntask, exemplified by a dataset, which they argue is challenging enough to serve\nas a benchmark. They also provide a baseline model for it, which then soon is\nimproved upon by other groups. Often, research efforts then move on, and the\npattern repeats itself. What is typically left implicit is the argumentation\nfor why this constitutes progress, and progress towards what. In this paper, we\ntry to step back for a moment from this pattern and work out possible\nargumentations and their parts.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 19:28:18 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Schlangen", "David", ""]]}, {"id": "2007.04874", "submitter": "Effi Levi", "authors": "Effi Levi, Guy Mor, Shaul Shenhav, Tamir Sheafer", "title": "CompRes: A Dataset for Narrative Structure in News", "comments": "Accpted to the First Joint Workshop on Narrative Understanding,\n  Storylines, and Events, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the task of automatically detecting narrative structures\nin raw texts. Previous works have utilized the oral narrative theory by Labov\nand Waletzky to identify various narrative elements in personal stories texts.\nInstead, we direct our focus to news articles, motivated by their growing\nsocial impact as well as their role in creating and shaping public opinion.\n  We introduce CompRes -- the first dataset for narrative structure in news\nmedia. We describe the process in which the dataset was constructed: first, we\ndesigned a new narrative annotation scheme, better suited for news media, by\nadapting elements from the narrative theory of Labov and Waletzky (Complication\nand Resolution) and adding a new narrative element of our own (Success); then,\nwe used that scheme to annotate a set of 29 English news articles (containing\n1,099 sentences) collected from news and partisan websites. We use the\nannotated dataset to train several supervised models to identify the different\nnarrative elements, achieving an $F_1$ score of up to 0.7. We conclude by\nsuggesting several promising directions for future work.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 15:21:59 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Levi", "Effi", ""], ["Mor", "Guy", ""], ["Shenhav", "Shaul", ""], ["Sheafer", "Tamir", ""]]}, {"id": "2007.05044", "submitter": "Alexey Bukhtiyarov", "authors": "Alexey Bukhtiyarov, Ilya Gusev", "title": "Advances of Transformer-Based Models for News Headline Generation", "comments": "Version 2; Accepted to AINL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models based on Transformer architecture are the reason\nfor recent breakthroughs in many areas of NLP, including sentiment analysis,\nquestion answering, named entity recognition. Headline generation is a special\nkind of text summarization task. Models need to have strong natural language\nunderstanding that goes beyond the meaning of individual words and sentences\nand an ability to distinguish essential information to succeed in it. In this\npaper, we fine-tune two pretrained Transformer-based models (mBART and\nBertSumAbs) for that task and achieve new state-of-the-art results on the RIA\nand Lenta datasets of Russian news. BertSumAbs increases ROUGE on average by\n2.9 and 2.0 points respectively over previous best score achieved by\nPhrase-Based Attentional Transformer and CopyNet.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 19:34:18 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 06:54:07 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bukhtiyarov", "Alexey", ""], ["Gusev", "Ilya", ""]]}, {"id": "2007.05163", "submitter": "Leonard Poon", "authors": "Leonard K. M. Poon and Nevin L. Zhang and Haoran Xie and Gary Cheng", "title": "Handling Collocations in Hierarchical Latent Tree Analysis for Topic\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling has been one of the most active research areas in machine\nlearning in recent years. Hierarchical latent tree analysis (HLTA) has been\nrecently proposed for hierarchical topic modeling and has shown superior\nperformance over state-of-the-art methods. However, the models used in HLTA\nhave a tree structure and cannot represent the different meanings of multiword\nexpressions sharing the same word appropriately. Therefore, we propose a method\nfor extracting and selecting collocations as a preprocessing step for HLTA. The\nselected collocations are replaced with single tokens in the bag-of-words model\nbefore running HLTA. Our empirical evaluation shows that the proposed method\nled to better performance of HLTA on three of the four data sets tested.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 04:56:36 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Poon", "Leonard K. M.", ""], ["Zhang", "Nevin L.", ""], ["Xie", "Haoran", ""], ["Cheng", "Gary", ""]]}, {"id": "2007.05194", "submitter": "Matiss Rikters", "authors": "Uga Spro\\c{g}is and Mat\\=iss Rikters", "title": "What Can We Learn From Almost a Decade of Food Tweets", "comments": null, "journal-ref": "In Proceedings of the 9th Conference Human Language Technologies -\n  The Baltic Perspective (Baltic HLT 2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Latvian Twitter Eater Corpus - a set of tweets in the narrow\ndomain related to food, drinks, eating and drinking. The corpus has been\ncollected over time-span of over 8 years and includes over 2 million tweets\nentailed with additional useful data. We also separate two sub-corpora of\nquestion and answer tweets and sentiment annotated tweets. We analyse contents\nof the corpus and demonstrate use-cases for the sub-corpora by training\ndomain-specific question-answering and sentiment-analysis models using data\nfrom the corpus.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 06:36:13 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 07:38:09 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Spro\u0123is", "Uga", ""], ["Rikters", "Mat\u012bss", ""]]}, {"id": "2007.05234", "submitter": "Alexander Fraser", "authors": "Anita Ramm, Ekaterina Lapshinova-Koltunski, Alexander Fraser", "title": "Pragmatic information in translation: a corpus-based study of tense and\n  mood in English and German", "comments": "Technical Report of CIS, LMU Munich. September 19th, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical tense and mood are important linguistic phenomena to consider in\nnatural language processing (NLP) research. We consider the correspondence\nbetween English and German tense and mood in translation. Human translators do\nnot find this correspondence easy, and as we will show through careful\nanalysis, there are no simplistic ways to map tense and mood from one language\nto another. Our observations about the challenges of human translation of tense\nand mood have important implications for multilingual NLP. Of particular\nimportance is the challenge of modeling tense and mood in rule-based,\nphrase-based statistical and neural machine translation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 08:15:59 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ramm", "Anita", ""], ["Lapshinova-Koltunski", "Ekaterina", ""], ["Fraser", "Alexander", ""]]}, {"id": "2007.05290", "submitter": "Yingce Xia", "authors": "Xueqing Wu, Lewen Wang, Yingce Xia, Weiqing Liu, Lijun Wu, Shufang\n  Xie, Tao Qin, Tie-Yan Liu", "title": "Temporally Correlated Task Scheduling for Sequence Learning", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence learning has attracted much research attention from the machine\nlearning community in recent years. In many applications, a sequence learning\ntask is usually associated with multiple temporally correlated auxiliary tasks,\nwhich are different in terms of how much input information to use or which\nfuture step to predict. For example, (i) in simultaneous machine translation,\none can conduct translation under different latency (i.e., how many input words\nto read/wait before translation); (ii) in stock trend forecasting, one can\npredict the price of a stock in different future days (e.g., tomorrow, the day\nafter tomorrow). While it is clear that those temporally correlated tasks can\nhelp each other, there is a very limited exploration on how to better leverage\nmultiple auxiliary tasks to boost the performance of the main task. In this\nwork, we introduce a learnable scheduler to sequence learning, which can\nadaptively select auxiliary tasks for training depending on the model status\nand the current training data. The scheduler and the model for the main task\nare jointly trained through bi-level optimization. Experiments show that our\nmethod significantly improves the performance of simultaneous machine\ntranslation and stock trend forecasting.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 10:28:54 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 12:39:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wu", "Xueqing", ""], ["Wang", "Lewen", ""], ["Xia", "Yingce", ""], ["Liu", "Weiqing", ""], ["Wu", "Lijun", ""], ["Xie", "Shufang", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2007.05302", "submitter": "Andreas Vogelsang", "authors": "Kim Julian G\\\"ulle, Nicholas Ford, Patrick Ebel, Florian Brokhausen,\n  Andreas Vogelsang", "title": "Topic Modeling on User Stories using Word Mover's Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requirements elicitation has recently been complemented with crowd-based\ntechniques, which continuously involve large, heterogeneous groups of users who\nexpress their feedback through a variety of media. Crowd-based elicitation has\ngreat potential for engaging with (potential) users early on but also results\nin large sets of raw and unstructured feedback. Consolidating and analyzing\nthis feedback is a key challenge for turning it into sensible user\nrequirements. In this paper, we focus on topic modeling as a means to identify\ntopics within a large set of crowd-generated user stories and compare three\napproaches: (1) a traditional approach based on Latent Dirichlet Allocation,\n(2) a combination of word embeddings and principal component analysis, and (3)\na combination of word embeddings and Word Mover's Distance. We evaluate the\napproaches on a publicly available set of 2,966 user stories written and\ncategorized by crowd workers. We found that a combination of word embeddings\nand Word Mover's Distance is most promising. Depending on the word embeddings\nwe use in our approaches, we manage to cluster the user stories in two ways:\none that is closer to the original categorization and another that allows new\ninsights into the dataset, e.g. to find potentially new categories.\nUnfortunately, no measure exists to rate the quality of our results\nobjectively. Still, our findings provide a basis for future work towards\nanalyzing crowd-sourced user stories.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 11:05:42 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 09:22:50 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["G\u00fclle", "Kim Julian", ""], ["Ford", "Nicholas", ""], ["Ebel", "Patrick", ""], ["Brokhausen", "Florian", ""], ["Vogelsang", "Andreas", ""]]}, {"id": "2007.05374", "submitter": "Daniel Deutsch", "authors": "Daniel Deutsch, Dan Roth", "title": "SacreROUGE: An Open-Source Library for Using and Developing\n  Summarization Evaluation Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SacreROUGE, an open-source library for using and developing\nsummarization evaluation metrics. SacreROUGE removes many obstacles that\nresearchers face when using or developing metrics: (1) The library provides\nPython wrappers around the official implementations of existing evaluation\nmetrics so they share a common, easy-to-use interface; (2) it provides\nfunctionality to evaluate how well any metric implemented in the library\ncorrelates to human-annotated judgments, so no additional code needs to be\nwritten for a new evaluation metric; and (3) it includes scripts for loading\ndatasets that contain human judgments so they can easily be used for\nevaluation. This work describes the design of the library, including the core\nMetric interface, the command-line API for evaluating summarization models and\nmetrics, and the scripts to load and reformat publicly available datasets. The\ndevelopment of SacreROUGE is ongoing and open to contributions from the\ncommunity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 13:26:37 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Deutsch", "Daniel", ""], ["Roth", "Dan", ""]]}, {"id": "2007.05608", "submitter": "Jean Oh", "authors": "Junjiao Tian and Jean Oh", "title": "Image Captioning with Compositional Neural Module Networks", "comments": "International Joint Conference on Artificial Intelligence (IJCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image captioning where fluency is an important factor in evaluation, e.g.,\n$n$-gram metrics, sequential models are commonly used; however, sequential\nmodels generally result in overgeneralized expressions that lack the details\nthat may be present in an input image. Inspired by the idea of the\ncompositional neural module networks in the visual question answering task, we\nintroduce a hierarchical framework for image captioning that explores both\ncompositionality and sequentiality of natural language. Our algorithm learns to\ncompose a detail-rich sentence by selectively attending to different modules\ncorresponding to unique aspects of each object detected in an input image to\ninclude specific descriptions such as counts and color. In a set of experiments\non the MSCOCO dataset, the proposed model outperforms a state-of-the art model\nacross multiple evaluation metrics, more importantly, presenting visually\ninterpretable results. Furthermore, the breakdown of subcategories $f$-scores\nof the SPICE metric and human evaluation on Amazon Mechanical Turk show that\nour compositional module networks effectively generate accurate and detailed\ncaptions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 20:58:04 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tian", "Junjiao", ""], ["Oh", "Jean", ""]]}, {"id": "2007.05609", "submitter": "Rongqing Huang", "authors": "Rongqing Huang, Ossama Abdel-hamid, Xinwei Li, Gunnar Evermann", "title": "Class LM and word mapping for contextual biasing in End-to-End ASR", "comments": "In Proc. of INTERSPEECH 2020", "journal-ref": "Proc. of INTERSPEECH 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, all-neural, end-to-end (E2E) ASR systems gained rapid\ninterest in the speech recognition community. They convert speech input to text\nunits in a single trainable Neural Network model. In ASR, many utterances\ncontain rich named entities. Such named entities may be user or location\nspecific and they are not seen during training. A single model makes it\ninflexible to utilize dynamic contextual information during inference. In this\npaper, we propose to train a context aware E2E model and allow the beam search\nto traverse into the context FST during inference. We also propose a simple\nmethod to adjust the cost discrepancy between the context FST and the base\nmodel. This algorithm is able to reduce the named entity utterance WER by 57%\nwith little accuracy degradation on regular utterances. Although an E2E model\ndoes not need pronunciation dictionary, it's interesting to make use of\nexisting pronunciation knowledge to improve accuracy. In this paper, we propose\nan algorithm to map the rare entity words to common words via pronunciation and\ntreat the mapped words as an alternative form to the original word during\nrecognition. This algorithm further reduces the WER on the named entity\nutterances by another 31%.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 20:58:44 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 18:12:32 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 14:06:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Huang", "Rongqing", ""], ["Abdel-hamid", "Ossama", ""], ["Li", "Xinwei", ""], ["Evermann", "Gunnar", ""]]}, {"id": "2007.05612", "submitter": "Hussein Al-Natsheh", "authors": "Bashar Talafha, Mohammad Ali, Muhy Eddin Za'ter, Haitham Seelawi,\n  Ibraheem Tuffaha, Mostafa Samir, Wael Farhan, Hussein T. Al-Natsheh", "title": "Multi-Dialect Arabic BERT for Country-Level Dialect Identification", "comments": "Accepted at the Fifth Arabic Natural Language Processing Workshop\n  (WANLP2020) co-located with the 28th International Conference on\n  Computational Linguistics (COLING'2020), Barcelona, Spain, 12 Dec. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic dialect identification is a complex problem for a number of inherent\nproperties of the language itself. In this paper, we present the experiments\nconducted, and the models developed by our competing team, Mawdoo3 AI, along\nthe way to achieving our winning solution to subtask 1 of the Nuanced Arabic\nDialect Identification (NADI) shared task. The dialect identification subtask\nprovides 21,000 country-level labeled tweets covering all 21 Arab countries. An\nunlabeled corpus of 10M tweets from the same domain is also presented by the\ncompetition organizers for optional use. Our winning solution itself came in\nthe form of an ensemble of different training iterations of our pre-trained\nBERT model, which achieved a micro-averaged F1-score of 26.78% on the subtask\nat hand. We publicly release the pre-trained language model component of our\nwinning solution under the name of Multi-dialect-Arabic-BERT model, for any\ninterested researcher out there.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 21:11:46 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Talafha", "Bashar", ""], ["Ali", "Mohammad", ""], ["Za'ter", "Muhy Eddin", ""], ["Seelawi", "Haitham", ""], ["Tuffaha", "Ibraheem", ""], ["Samir", "Mostafa", ""], ["Farhan", "Wael", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "2007.05618", "submitter": "Vaibhav Jain", "authors": "Vaibhav Jain", "title": "GloVeInit at SemEval-2020 Task 1: Using GloVe Vector Initialization for\n  Unsupervised Lexical Semantic Change Detection", "comments": "To be presented at the 2020 International Workshop on Semantic\n  Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a vector initialization approach for the SemEval2020 Task\n1: Unsupervised Lexical Semantic Change Detection. Given two corpora belonging\nto different time periods and a set of target words, this task requires us to\nclassify whether a word gained or lost a sense over time (subtask 1) and to\nrank them on the basis of the changes in their word senses (subtask 2). The\nproposed approach is based on using Vector Initialization method to align GloVe\nembeddings. The idea is to consecutively train GloVe embeddings for both\ncorpora, while using the first model to initialize the second one. This paper\nis based on the hypothesis that GloVe embeddings are more suited for the Vector\nInitialization method than SGNS embeddings. It presents an intuitive reasoning\nbehind this hypothesis, and also talks about the impact of various factors and\nhyperparameters on the performance of the proposed approach. Our model ranks\n13th and 10th among 33 teams in the two subtasks. The implementation has been\nshared publicly.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 21:35:17 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jain", "Vaibhav", ""]]}, {"id": "2007.05651", "submitter": "Jinfeng Li", "authors": "Jinfeng Li, Yuliang Li, Xiaolan Wang, Wang-Chiew Tan", "title": "Deep or Simple Models for Semantic Tagging? It Depends on your Data\n  [Experiments]", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic tagging, which has extensive applications in text mining, predicts\nwhether a given piece of text conveys the meaning of a given semantic tag. The\nproblem of semantic tagging is largely solved with supervised learning and\ntoday, deep learning models are widely perceived to be better for semantic\ntagging. However, there is no comprehensive study supporting the popular\nbelief. Practitioners often have to train different types of models for each\nsemantic tagging task to identify the best model. This process is both\nexpensive and inefficient.\n  We embark on a systematic study to investigate the following question: Are\ndeep models the best performing model for all semantic tagging tasks? To answer\nthis question, we compare deep models against \"simple models\" over datasets\nwith varying characteristics. Specifically, we select three prevalent deep\nmodels (i.e. CNN, LSTM, and BERT) and two simple models (i.e. LR and SVM), and\ncompare their performance on the semantic tagging task over 21 datasets.\nResults show that the size, the label ratio, and the label cleanliness of a\ndataset significantly impact the quality of semantic tagging. Simple models\nachieve similar tagging quality to deep models on large datasets, but the\nruntime of simple models is much shorter. Moreover, simple models can achieve\nbetter tagging quality than deep models when targeting datasets show worse\nlabel cleanliness and/or more severe imbalance. Based on these findings, our\nstudy can systematically guide practitioners in selecting the right learning\nmodel for their semantic tagging task.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 00:05:50 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 22:45:08 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Li", "Jinfeng", ""], ["Li", "Yuliang", ""], ["Wang", "Xiaolan", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2007.05727", "submitter": "Mohd Zeeshan Ansari", "authors": "Mohd Zeeshan Ansari, Tanvir Ahmad and Ana Fatima", "title": "Feature Selection on Noisy Twitter Short Text Messages for Language\n  Identification", "comments": null, "journal-ref": "International Journal of Recent Technology and Engineering,\n  Volume-8, Issue-4, Nov 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of written language identification involves typically the detection\nof the languages present in a sample of text. Moreover, a sequence of text may\nnot belong to a single inherent language but also may be mixture of text\nwritten in multiple languages. This kind of text is generated in large volumes\nfrom social media platforms due to its flexible and user friendly environment.\nSuch text contains very large number of features which are essential for\ndevelopment of statistical, probabilistic as well as other kinds of language\nmodels. The large number of features have rich as well as irrelevant and\nredundant features which have diverse effect over the performance of the\nlearning model. Therefore, feature selection methods are significant in\nchoosing feature that are most relevant for an efficient model. In this\narticle, we basically consider the Hindi-English language identification task\nas Hindi and English are often two most widely spoken languages of India. We\napply different feature selection algorithms across various learning algorithms\nin order to analyze the effect of the algorithm as well as the number of\nfeatures on the performance of the task. The methodology focuses on the word\nlevel language identification using a novel dataset of 6903 tweets extracted\nfrom Twitter. Various n-gram profiles are examined with different feature\nselection algorithms over many classifiers. Finally, an exhaustive comparative\nanalysis is put forward with respect to the overall experiments conducted for\nthe task.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 09:22:01 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ansari", "Mohd Zeeshan", ""], ["Ahmad", "Tanvir", ""], ["Fatima", "Ana", ""]]}, {"id": "2007.05772", "submitter": "Dana Halabi", "authors": "Dana Halabi, Ebaa Fayyoumi, Arafat Awajan", "title": "I3rab: A New Arabic Dependency Treebank Based on Arabic Grammatical\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treebanks are valuable linguistic resources that include the syntactic\nstructure of a language sentence in addition to POS-tags and morphological\nfeatures. They are mainly utilized in modeling statistical parsers. Although\nthe statistical natural language parser has recently become more accurate for\nlanguages such as English, those for the Arabic language still have low\naccuracy. The purpose of this paper is to construct a new Arabic dependency\ntreebank based on the traditional Arabic grammatical theory and the\ncharacteristics of the Arabic language, to investigate their effects on the\naccuracy of statistical parsers. The proposed Arabic dependency treebank,\ncalled I3rab, contrasts with existing Arabic dependency treebanks in two main\nconcepts. The first concept is the approach of determining the main word of the\nsentence, and the second concept is the representation of the joined and covert\npronouns. To evaluate I3rab, we compared its performance against a subset of\nPrague Arabic Dependency Treebank that shares a comparable level of details.\nThe conducted experiments show that the percentage improvement reached up to\n7.5% in UAS and 18.8% in LAS.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 13:34:44 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Halabi", "Dana", ""], ["Fayyoumi", "Ebaa", ""], ["Awajan", "Arafat", ""]]}, {"id": "2007.05872", "submitter": "Jeanna Matthews", "authors": "Esma Wali, Yan Chen, Christopher Mahoney, Thomas Middleton, Marzieh\n  Babaeianjelodar, Mariama Njie, Jeanna Neefe Matthews", "title": "Is Machine Learning Speaking my Language? A Critical Look at the\n  NLP-Pipeline Across 8 Human Languages", "comments": "Participatory Approaches to Machine Learning Workshop, 37th\n  International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) is increasingly used as a key ingredient in\ncritical decision-making systems such as resume parsers used in sorting a list\nof job candidates. NLP systems often ingest large corpora of human text,\nattempting to learn from past human behavior and decisions in order to produce\nsystems that will make recommendations about our future world. Over 7000 human\nlanguages are being spoken today and the typical NLP pipeline underrepresents\nspeakers of most of them while amplifying the voices of speakers of other\nlanguages. In this paper, a team including speakers of 8 languages - English,\nChinese, Urdu, Farsi, Arabic, French, Spanish, and Wolof - takes a critical\nlook at the typical NLP pipeline and how even when a language is technically\nsupported, substantial caveats remain to prevent full participation. Despite\nhuge and admirable investments in multilingual support in many tools and\nresources, we are still making NLP-guided decisions that systematically and\ndramatically underrepresent the voices of much of the world.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 22:56:37 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Wali", "Esma", ""], ["Chen", "Yan", ""], ["Mahoney", "Christopher", ""], ["Middleton", "Thomas", ""], ["Babaeianjelodar", "Marzieh", ""], ["Njie", "Mariama", ""], ["Matthews", "Jeanna Neefe", ""]]}, {"id": "2007.05891", "submitter": "Yi Tay", "authors": "Yi Tay, Zhe Zhao, Dara Bahri, Donald Metzler, Da-Cheng Juan", "title": "HyperGrid: Efficient Multi-Task Transformers with Grid-wise Decomposable\n  Hyper Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving state-of-the-art performance on natural language understanding\ntasks typically relies on fine-tuning a fresh model for every task.\nConsequently, this approach leads to a higher overall parameter cost, along\nwith higher technical maintenance for serving multiple models. Learning a\nsingle multi-task model that is able to do well for all the tasks has been a\nchallenging and yet attractive proposition. In this paper, we propose\n\\textsc{HyperGrid}, a new approach for highly effective multi-task learning.\nThe proposed approach is based on a decomposable hypernetwork that learns\ngrid-wise projections that help to specialize regions in weight matrices for\ndifferent tasks. In order to construct the proposed hypernetwork, our method\nlearns the interactions and composition between a global (task-agnostic) state\nand a local task-specific state. We apply our proposed \\textsc{HyperGrid} on\nthe current state-of-the-art T5 model, demonstrating strong performance across\nthe GLUE and SuperGLUE benchmarks when using only a single multi-task model.\nOur method helps bridge the gap between fine-tuning and multi-task learning\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 02:49:16 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tay", "Yi", ""], ["Zhao", "Zhe", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "2007.05916", "submitter": "Xian Shi", "authors": "Xian Shi, Qiangze Feng, Lei Xie", "title": "The ASRU 2019 Mandarin-English Code-Switching Speech Recognition\n  Challenge: Open Datasets, Tracks, Methods and Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching (CS) is a common phenomenon and recognizing CS speech is\nchallenging. But CS speech data is scarce and there' s no common testbed in\nrelevant research. This paper describes the design and main outcomes of the\nASRU 2019 Mandarin-English code-switching speech recognition challenge, which\naims to improve the ASR performance in Mandarin-English code-switching\nsituation. 500 hours Mandarin speech data and 240 hours Mandarin-English\nintra-sentencial CS data are released to the participants. Three tracks were\nset for advancing the AM and LM part in traditional DNN-HMM ASR system, as well\nas exploring the E2E models' performance. The paper then presents an overview\nof the results and system performance in the three tracks. It turns out that\ntraditional ASR system benefits from pronunciation lexicon, CS text generating\nand data augmentation. In E2E track, however, the results highlight the\nimportance of using language identification, building-up a rational set of\nmodeling units and spec-augment. The other details in model training and method\ncomparsion are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 05:38:57 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Shi", "Xian", ""], ["Feng", "Qiangze", ""], ["Xie", "Lei", ""]]}, {"id": "2007.05976", "submitter": "Saptarshi Ghosh Dr.", "authors": "Shalmoli Ghosh, Prajwal Singhania, Siddharth Singh, Koustav Rudra,\n  Saptarshi Ghosh", "title": "Stance Detection in Web and Social Media: A Comparative Study", "comments": null, "journal-ref": "Proceedings of Conference and Labs of the Evaluation Forum (CLEF)\n  2019; Lecture Notes in Computer Science, vol 11696, pp. 75-87", "doi": "10.1007/978-3-030-28577-7_4", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online forums and social media platforms are increasingly being used to\ndiscuss topics of varying polarities where different people take different\nstances. Several methodologies for automatic stance detection from text have\nbeen proposed in literature. To our knowledge, there has not been any\nsystematic investigation towards their reproducibility, and their comparative\nperformances. In this work, we explore the reproducibility of several existing\nstance detection models, including both neural models and classical\nclassifier-based models. Through experiments on two datasets -- (i)~the popular\nSemEval microblog dataset, and (ii)~a set of health-related online news\narticles -- we also perform a detailed comparative analysis of various methods\nand explore their shortcomings. Implementations of all algorithms discussed in\nthis paper are available at\nhttps://github.com/prajwal1210/Stance-Detection-in-Web-and-Social-Media.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 12:39:35 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ghosh", "Shalmoli", ""], ["Singhania", "Prajwal", ""], ["Singh", "Siddharth", ""], ["Rudra", "Koustav", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "2007.06018", "submitter": "Lei Li", "authors": "Yuxuan Song, Ning Miao, Hao Zhou, Lantao Yu, Mingxuan Wang, Lei Li", "title": "Improving Maximum Likelihood Training for Text Generation with Density\n  Ratio Estimation", "comments": "Accepted to International Conference on Artificial Intelligence and\n  Statistics 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-regressive sequence generative models trained by Maximum Likelihood\nEstimation suffer the exposure bias problem in practical finite sample\nscenarios. The crux is that the number of training samples for Maximum\nLikelihood Estimation is usually limited and the input data distributions are\ndifferent at training and inference stages. Many method shave been proposed to\nsolve the above problem (Yu et al., 2017; Lu et al., 2018), which relies on\nsampling from the non-stationary model distribution and suffers from high\nvariance or biased estimations. In this paper, we propose{\\psi}-MLE, a new\ntraining scheme for auto-regressive sequence generative models, which is\neffective and stable when operating at large sample space encountered in text\ngeneration. We derive our algorithm from a new perspective of self-augmentation\nand introduce bias correction with density ratio estimation. Extensive\nexperimental results on synthetic data and real-world text generation tasks\ndemonstrate that our method stably outperforms Maximum Likelihood Estimation\nand other state-of-the-art sequence generative models in terms of both quality\nand diversity.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 15:31:24 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Song", "Yuxuan", ""], ["Miao", "Ning", ""], ["Zhou", "Hao", ""], ["Yu", "Lantao", ""], ["Wang", "Mingxuan", ""], ["Li", "Lei", ""]]}, {"id": "2007.06028", "submitter": "Andy T. Liu", "authors": "Andy T. Liu, Shang-Wen Li, and Hung-yi Lee", "title": "TERA: Self-Supervised Learning of Transformer Encoder Representation for\n  Speech", "comments": "Submitted to IEEE/ACM TASLP, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a self-supervised speech pre-training method called TERA, which\nstands for Transformer Encoder Representations from Alteration. Recent\napproaches often learn through the formulation of a single auxiliary task like\ncontrastive prediction, autoregressive prediction, or masked reconstruction.\nUnlike previous approaches, we use a multi-target auxiliary task to pre-train\nTransformer Encoders on a large amount of unlabeled speech. The model learns\nthrough the reconstruction of acoustic frames from its altered counterpart,\nwhere we use a stochastic policy to alter along three dimensions: temporal,\nchannel, and magnitude. TERA can be used to extract speech representations or\nfine-tune with downstream models. We evaluate TERA on several downstream tasks,\nincluding phoneme classification, speaker recognition, and speech recognition.\nTERA achieved strong performance on these tasks by improving upon surface\nfeatures and outperforming previous methods. In our experiments, we show that\nthrough alteration along different dimensions, the model learns to encode\ndistinct aspects of speech. We explore different knowledge transfer methods to\nincorporate the pre-trained model with downstream models. Furthermore, we show\nthat the proposed method can be easily transferred to another dataset not used\nin pre-training.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 16:19:00 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 17:30:54 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Liu", "Andy T.", ""], ["Li", "Shang-Wen", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2007.06077", "submitter": "Aditya Mogadala", "authors": "Aditya Mogadala and Marius Mosbach and Dietrich Klakow", "title": "Sparse Graph to Sequence Learning for Vision Conditioned Long Textual\n  Sequence Generation", "comments": "International Conference on Machine Learning (ICML) 2020 Workshop\n  (https://logicalreasoninggnn.github.io/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating longer textual sequences when conditioned on the visual\ninformation is an interesting problem to explore. The challenge here\nproliferate over the standard vision conditioned sentence-level generation\n(e.g., image or video captioning) as it requires to produce a brief and\ncoherent story describing the visual content. In this paper, we mask this\nVision-to-Sequence as Graph-to-Sequence learning problem and approach it with\nthe Transformer architecture. To be specific, we introduce Sparse\nGraph-to-Sequence Transformer (SGST) for encoding the graph and decoding a\nsequence. The encoder aims to directly encode graph-level semantics, while the\ndecoder is used to generate longer sequences. Experiments conducted with the\nbenchmark image paragraph dataset show that our proposed achieve 13.3%\nimprovement on the CIDEr evaluation measure when comparing to the previous\nstate-of-the-art approach.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 19:54:32 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mogadala", "Aditya", ""], ["Mosbach", "Marius", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2007.06078", "submitter": "Mudit Verma", "authors": "Mudit Verma, Arun Balaji Buduru", "title": "Fine-grained Language Identification with Multilingual CapsNet Model", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to a drastic improvement in the quality of internet services worldwide,\nthere is an explosion of multilingual content generation and consumption. This\nis especially prevalent in countries with large multilingual audience, who are\nincreasingly consuming media outside their linguistic familiarity/preference.\nHence, there is an increasing need for real-time and fine-grained content\nanalysis services, including language identification, content transcription,\nand analysis. Accurate and fine-grained spoken language detection is an\nessential first step for all the subsequent content analysis algorithms.\nCurrent techniques in spoken language detection may lack on one of these\nfronts: accuracy, fine-grained detection, data requirements, manual effort in\ndata collection \\& pre-processing. Hence in this work, a real-time language\ndetection approach to detect spoken language from 5 seconds' audio clips with\nan accuracy of 91.8\\% is presented with exiguous data requirements and minimal\npre-processing. Novel architectures for Capsule Networks is proposed which\noperates on spectrogram images of the provided audio snippets. We use previous\napproaches based on Recurrent Neural Networks and iVectors to present the\nresults. Finally we show a ``Non-Class'' analysis to further stress on why\nCapsNet architecture works for LID task.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 20:01:22 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Verma", "Mudit", ""], ["Buduru", "Arun Balaji", ""]]}, {"id": "2007.06104", "submitter": "Roman Yangarber", "authors": "Jos\\'e Mar\\'ia Hoya Quecedo, Maximilian W. Koppatz, Giacomo Furlan,\n  Roman Yangarber", "title": "Neural disambiguation of lemma and part of speech in morphologically\n  rich languages", "comments": "This paper contains corrigenda to a previously published paper (Hoya\n  Quecedo et al., 2020). It corrects a mistake in the original evaluation\n  setup, and the results reported in Section 6., in Tables 5, 6, and 7", "journal-ref": "Proceedings of LREC-2020: the 12th Conference on Language\n  Resources and Evaluation", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of disambiguating the lemma and part of speech of\nambiguous words in morphologically rich languages. We propose a method for\ndisambiguating ambiguous words in context, using a large un-annotated corpus of\ntext, and a morphological analyser -- with no manual disambiguation or data\nannotation. We assume that the morphological analyser produces multiple\nanalyses for ambiguous words. The idea is to train recurrent neural networks on\nthe output that the morphological analyser produces for unambiguous words. We\npresent performance on POS and lemma disambiguation that reaches or surpasses\nthe state of the art -- including supervised models -- using no manually\nannotated data. We evaluate the method on several morphologically rich\nlanguages.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 21:48:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Quecedo", "Jos\u00e9 Mar\u00eda Hoya", ""], ["Koppatz", "Maximilian W.", ""], ["Furlan", "Giacomo", ""], ["Yangarber", "Roman", ""]]}, {"id": "2007.06162", "submitter": "Ning Miao", "authors": "Ning Miao, Yuxuan Song, Hao Zhou, Lei Li", "title": "Do You Have the Right Scissors? Tailoring Pre-trained Language Models\n  via Monte-Carlo Methods", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been a common approach to pre-train a language model on a large corpus\nand fine-tune it on task-specific data. In practice, we observe that\nfine-tuning a pre-trained model on a small dataset may lead to over- and/or\nunder-estimation problem. In this paper, we propose MC-Tailor, a novel method\nto alleviate the above issue in text generation tasks by truncating and\ntransferring the probability mass from over-estimated regions to\nunder-estimated ones. Experiments on a variety of text generation datasets show\nthat MC-Tailor consistently and significantly outperforms the fine-tuning\napproach. Our code is available at this url.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 02:53:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Miao", "Ning", ""], ["Song", "Yuxuan", ""], ["Zhou", "Hao", ""], ["Li", "Lei", ""]]}, {"id": "2007.06174", "submitter": "Ning Miao", "authors": "Huangzhao Zhang, Hao Zhou, Ning Miao, Lei Li", "title": "Generating Fluent Adversarial Examples for Natural Languages", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently building an adversarial attacker for natural language processing\n(NLP) tasks is a real challenge. Firstly, as the sentence space is discrete, it\nis difficult to make small perturbations along the direction of gradients.\nSecondly, the fluency of the generated examples cannot be guaranteed. In this\npaper, we propose MHA, which addresses both problems by performing\nMetropolis-Hastings sampling, whose proposal is designed with the guidance of\ngradients. Experiments on IMDB and SNLI show that our proposed MHA outperforms\nthe baseline model on attacking capability. Adversarial training with MAH also\nleads to better robustness and performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 03:56:37 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhang", "Huangzhao", ""], ["Zhou", "Hao", ""], ["Miao", "Ning", ""], ["Li", "Lei", ""]]}, {"id": "2007.06198", "submitter": "Gouthaman Kv", "authors": "Gouthaman KV and Anurag Mittal", "title": "Reducing Language Biases in Visual Question Answering with\n  Visually-Grounded Question Encoder", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that current VQA models are heavily biased on the\nlanguage priors in the train set to answer the question, irrespective of the\nimage. E.g., overwhelmingly answer \"what sport is\" as \"tennis\" or \"what color\nbanana\" as \"yellow.\" This behavior restricts them from real-world application\nscenarios. In this work, we propose a novel model-agnostic question encoder,\nVisually-Grounded Question Encoder (VGQE), for VQA that reduces this effect.\nVGQE utilizes both visual and language modalities equally while encoding the\nquestion. Hence the question representation itself gets sufficient\nvisual-grounding, and thus reduces the dependency of the model on the language\npriors. We demonstrate the effect of VGQE on three recent VQA models and\nachieve state-of-the-art results on the bias-sensitive split of the VQAv2\ndataset; VQA-CPv2. Further, unlike the existing bias-reduction techniques, on\nthe standard VQAv2 benchmark, our approach does not drop the accuracy; instead,\nit improves the performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 05:36:36 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 13:09:29 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["KV", "Gouthaman", ""], ["Mittal", "Anurag", ""]]}, {"id": "2007.06225", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rihawi,\n  Yu Wang, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Martin\n  Steinegger, Debsindhu Bhowmik, Burkhard Rost", "title": "ProtTrans: Towards Cracking the Language of Life's Code Through\n  Self-Supervised Deep Learning and High Performance Computing", "comments": "17 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational biology and bioinformatics provide vast data gold-mines from\nprotein sequences, ideal for Language Models taken from NLP. These LMs reach\nfor new prediction frontiers at low inference costs. Here, we trained two\nauto-regressive models (Transformer-XL, XLNet) and four auto-encoder models\n(BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393\nbillion amino acids. The LMs were trained on the Summit supercomputer using\n5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that\nthe raw protein LM-embeddings from unlabeled data captured some biophysical\nfeatures of protein sequences. We validated the advantage of using the\nembeddings as exclusive input for several subsequent tasks. The first was a\nper-residue prediction of protein secondary structure (3-state accuracy\nQ3=81%-87%); the second were per-protein predictions of protein sub-cellular\nlocalization (ten-state accuracy: Q10=81%) and membrane vs. water-soluble\n(2-state accuracy Q2=91%). For the per-residue predictions the transfer of the\nmost informative embeddings (ProtT5) for the first time outperformed the\nstate-of-the-art without using evolutionary information thereby bypassing\nexpensive database searches. Taken together, the results implied that protein\nLMs learned some of the grammar of the language of life. To facilitate future\nwork, we released our models at https://github.com/agemagician/ProtTrans.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 07:54:20 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 21:18:05 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 20:18:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Heinzinger", "Michael", ""], ["Dallago", "Christian", ""], ["Rihawi", "Ghalia", ""], ["Wang", "Yu", ""], ["Jones", "Llion", ""], ["Gibbs", "Tom", ""], ["Feher", "Tamas", ""], ["Angerer", "Christoph", ""], ["Steinegger", "Martin", ""], ["Bhowmik", "Debsindhu", ""], ["Rost", "Burkhard", ""]]}, {"id": "2007.06257", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Qiuhui Liu and Deyi Xiong and Josef van Genabith", "title": "Transformer with Depth-Wise LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the depth of models allows neural models to model complicated\nfunctions but may also lead to optimization issues. The Transformer translation\nmodel employs the residual connection to ensure its convergence. In this paper,\nwe suggest that the residual connection has its drawbacks, and propose to train\nTransformers with the depth-wise LSTM which regards outputs of layers as steps\nin time series instead of residual connections, under the motivation that the\nvanishing gradient problem suffered by deep networks is the same as recurrent\nnetworks applied to long sequences, while LSTM (Hochreiter and Schmidhuber,\n1997) has been proven of good capability in capturing long-distance\nrelationship, and its design may alleviate some drawbacks of residual\nconnections while ensuring the convergence. We integrate the computation of\nmulti-head attention networks and feed-forward networks with the depth-wise\nLSTM for the Transformer, which shows how to utilize the depth-wise LSTM like\nthe residual connection. Our experiment with the 6-layer Transformer shows that\nour approach can bring about significant BLEU improvements in both WMT 14\nEnglish-German and English-French tasks, and our deep Transformer experiment\ndemonstrates the effectiveness of the depth-wise LSTM on the convergence of\ndeep Transformers. Additionally, we propose to measure the impacts of the\nlayer's non-linearity on the performance by distilling the analyzing layer of\nthe trained model into a linear transformation and observing the performance\ndegradation with the replacement. Our analysis results support the more\nefficient use of per-layer non-linearity with depth-wise LSTM than with\nresidual connections.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:19:34 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Xu", "Hongfei", ""], ["Liu", "Qiuhui", ""], ["Xiong", "Deyi", ""], ["van Genabith", "Josef", ""]]}, {"id": "2007.06258", "submitter": "Johannes Reich", "authors": "Johannes Reich", "title": "A theory of interaction semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this article is to delineate a theory of interaction semantics and\nthereby provide a proper understanding of the \"meaning\" of the exchanged\ncharacters within an interaction. The idea is to describe the interaction\n(between discrete systems) by a mechanism that depends on information exchange,\nthat is, on the identical naming of the \"exchanged\" characters -- by a\nprotocol. Complementing a nondeterministic protocol with decisions to a game in\nits interactive form (GIF) makes it interpretable in the sense of an execution.\nThe consistency of such a protocol depends on the particular choice of its sets\nof characters. Thus, assigning a protocol its sets of charaacters makes it\nconsistent or not, creating a fulfillment relation. The interpretation of the\ncharacters during GIF execution results in their meaning. The proposed theory\nof interaction semantics is consistent with the model of information transport\nand processing, it has a clear relation to models of formal semantics, it\naccounts for the fact that the meaning of a character is invariant against\nrenaming and locates the concept of meaning in the technical description of\ninteractions. It defines when two different characters have the same meaning\nand what an \"interpretation\" and what an \"interpretation context\" is as well as\nunder which conditions meaning is compositional.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:22:59 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Reich", "Johannes", ""]]}, {"id": "2007.06273", "submitter": "Amandeep Bhatia", "authors": "Amandeep Singh Bhatia, Shenggen Zheng", "title": "RNA-2QCFA: Evolving Two-way Quantum Finite Automata with Classical\n  States for RNA Secondary Structures", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the use of mathematical methods and computer science applications\nhave got significant response among biochemists and biologists to modeling the\nbiological systems. The computational and mathematical methods have enormous\npotential for modeling the deoxyribonucleic acid (DNA) and ribonucleic acid\n(RNA) structures. The modeling of DNA and RNA secondary structures using\nautomata theory had a significant impact in the fields of computer science. It\nis a natural goal to model the RNA secondary biomolecular structures using\nquantum computational models. Two-way quantum finite automata with classical\nstates are more dominant than two-way probabilistic finite automata in language\nrecognition. The main objective of this paper is on using two-way quantum\nfinite automata with classical states to simulate, model and analyze the\nribonucleic acid (RNA) sequences.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:54:09 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bhatia", "Amandeep Singh", ""], ["Zheng", "Shenggen", ""]]}, {"id": "2007.06290", "submitter": "Ivan P Yamshchikov", "authors": "Yana Agafonova, Alexey Tikhonov, Ivan P. Yamshchikov", "title": "Paranoid Transformer: Reading Narrative of Madness as Computational\n  Approach to Creativity", "comments": null, "journal-ref": null, "doi": "10.3390/fi12110182", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers revisits the receptive theory in context of computational\ncreativity. It presents a case study of a Paranoid Transformer - a fully\nautonomous text generation engine with raw output that could be read as the\nnarrative of a mad digital persona without any additional human post-filtering.\nWe describe technical details of the generative system, provide examples of\noutput and discuss the impact of receptive theory, chance discovery and\nsimulation of fringe mental state on the understanding of computational\ncreativity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:18:24 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Agafonova", "Yana", ""], ["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "2007.06351", "submitter": "Thanh Vu", "authors": "Thanh Vu, Dat Quoc Nguyen, Anthony Nguyen", "title": "A Label Attention Model for ICD Coding from Clinical Text", "comments": "In Proceedings of IJCAI 2020 (Main Track)", "journal-ref": null, "doi": "10.24963/ijcai.2020/461", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICD coding is a process of assigning the International Classification of\nDisease diagnosis codes to clinical/medical notes documented by health\nprofessionals (e.g. clinicians). This process requires significant human\nresources, and thus is costly and prone to error. To handle the problem,\nmachine learning has been utilized for automatic ICD coding. Previous\nstate-of-the-art models were based on convolutional neural networks, using a\nsingle/several fixed window sizes. However, the lengths and interdependence\nbetween text fragments related to ICD codes in clinical text vary\nsignificantly, leading to the difficulty of deciding what the best window sizes\nare. In this paper, we propose a new label attention model for automatic ICD\ncoding, which can handle both the various lengths and the interdependence of\nthe ICD code related text fragments. Furthermore, as the majority of ICD codes\nare not frequently used, leading to the extremely imbalanced data issue, we\nadditionally propose a hierarchical joint learning mechanism extending our\nlabel attention model to handle the issue, using the hierarchical relationships\namong the codes. Our label attention model achieves new state-of-the-art\nresults on three benchmark MIMIC datasets, and the joint learning mechanism\nhelps improve the performances for infrequent codes.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 12:42:43 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Vu", "Thanh", ""], ["Nguyen", "Dat Quoc", ""], ["Nguyen", "Anthony", ""]]}, {"id": "2007.06390", "submitter": "Sherzod Hakimov", "authors": "Golsa Tahmasebzadeh, Sherzod Hakimov, Eric M\\\"uller-Budack, Ralph\n  Ewerth", "title": "A Feature Analysis for Multimodal News Retrieval", "comments": "CLEOPATRA Workshop co-located with ESWC 2020", "journal-ref": "CLEOPATRA Workshop co-located with ESWC 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Content-based information retrieval is based on the information contained in\ndocuments rather than using metadata such as keywords. Most information\nretrieval methods are either based on text or image. In this paper, we\ninvestigate the usefulness of multimodal features for cross-lingual news search\nin various domains: politics, health, environment, sport, and finance. To this\nend, we consider five feature types for image and text and compare the\nperformance of the retrieval system using different combinations. Experimental\nresults show that retrieval results can be improved when considering both\nvisual and textual information. In addition, it is observed that among textual\nfeatures entity overlap outperforms word embeddings, while geolocation\nembeddings achieve better performance among visual features in the retrieval\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 14:09:29 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 08:38:47 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Tahmasebzadeh", "Golsa", ""], ["Hakimov", "Sherzod", ""], ["M\u00fcller-Budack", "Eric", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2007.06400", "submitter": "Florian Borchert", "authors": "Florian Borchert, Christina Lohr, Luise Modersohn, Thomas Langer,\n  Markus Follmann, Jan Philipp Sachs, Udo Hahn and Matthieu-P. Schapranow", "title": "GGPONC: A Corpus of German Medical Text with Rich Metadata Based on\n  Clinical Practice Guidelines", "comments": "LOUHI Workshop @ EMNLP '20. Proceedings of the 11th International\n  Workshop on Health Text Mining and Information Analysis. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of publicly accessible text corpora is a major obstacle for progress\nin natural language processing. For medical applications, unfortunately, all\nlanguage communities other than English are low-resourced. In this work, we\npresent GGPONC (German Guideline Program in Oncology NLP Corpus), a freely\ndistributable German language corpus based on clinical practice guidelines for\noncology. This corpus is one of the largest ever built from German medical\ndocuments. Unlike clinical documents, clinical guidelines do not contain any\npatient-related information and can therefore be used without data protection\nrestrictions. Moreover, GGPONC is the first corpus for the German language\ncovering diverse conditions in a large medical subfield and provides a variety\nof metadata, such as literature references and evidence levels. By applying and\nevaluating existing medical information extraction pipelines for German text,\nwe are able to draw comparisons for the use of medical language to other\ncorpora, medical and non-medical ones.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 14:25:49 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 09:22:02 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Borchert", "Florian", ""], ["Lohr", "Christina", ""], ["Modersohn", "Luise", ""], ["Langer", "Thomas", ""], ["Follmann", "Markus", ""], ["Sachs", "Jan Philipp", ""], ["Hahn", "Udo", ""], ["Schapranow", "Matthieu-P.", ""]]}, {"id": "2007.06477", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward\n  Grefenstette, Tim Rockt\\\"aschel", "title": "Learning Reasoning Strategies in End-to-End Differentiable Proving", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts to render deep learning models interpretable, data-efficient, and\nrobust have seen some success through hybridisation with rule-based systems,\nfor example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can\ninduce interpretable rules and learn representations from data via\nback-propagation, while providing logical explanations for their predictions.\nHowever, they are restricted by their computational complexity, as they need to\nconsider all possible proof paths for explaining a goal, thus rendering them\nunfit for large-scale applications. We present Conditional Theorem Provers\n(CTPs), an extension to NTPs that learns an optimal rule selection strategy via\ngradient-based optimisation. We show that CTPs are scalable and yield\nstate-of-the-art results on the CLUTRR dataset, which tests systematic\ngeneralisation of neural models by learning to reason over smaller graphs and\nevaluating on larger ones. Finally, CTPs show better link prediction results on\nstandard benchmarks in comparison with other neural-symbolic models, while\nbeing explainable. All source code and datasets are available online, at\nhttps://github.com/uclnlp/ctp.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:22:14 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 08:40:14 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 16:17:34 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Minervini", "Pasquale", ""], ["Riedel", "Sebastian", ""], ["Stenetorp", "Pontus", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2007.06486", "submitter": "Emir Demirel", "authors": "Emir Demirel, Sven Ahlback, Simon Dixon", "title": "Automatic Lyrics Transcription using Dilated Convolutional Neural\n  Networks with Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speech recognition is a well developed research field so that the current\nstate of the art systems are being used in many applications in the software\nindustry, yet as by today, there still does not exist such robust system for\nthe recognition of words and sentences from singing voice. This paper proposes\na complete pipeline for this task which may commonly be referred as automatic\nlyrics transcription (ALT). We have trained convolutional time-delay neural\nnetworks with self-attention on monophonic karaoke recordings using a sequence\nclassification objective for building the acoustic model. The dataset used in\nthis study, DAMP - Sing! 300x30x2 [1] is filtered to have songs with only\nEnglish lyrics. Different language models are tested including MaxEnt and\nRecurrent Neural Networks based methods which are trained on the lyrics of pop\nsongs in English. An in-depth analysis of the self-attention mechanism is held\nwhile tuning its context width and the number of attention heads. Using the\nbest settings, our system achieves notable improvement to the state-of-the-art\nin ALT and provides a new baseline for the task.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:36:30 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 15:26:48 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Demirel", "Emir", ""], ["Ahlback", "Sven", ""], ["Dixon", "Simon", ""]]}, {"id": "2007.06493", "submitter": "Xuan-Son Vu", "authors": "Xuan-Son Vu, Thanh Vu, Mai-Vu Tran, Thanh Le-Cong, Huyen T M. Nguyen", "title": "HSD Shared Task in VLSP Campaign 2019:Hate Speech Detection for Social\n  Good", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the organisation of the \"HateSpeech Detection\" (HSD) task\nat the VLSP workshop 2019 on detecting the fine-grained presence of hate speech\nin Vietnamese textual items (i.e., messages) extracted from Facebook, which is\nthe most popular social network site (SNS) in Vietnam. The task is organised as\na multi-class classification task and based on a large-scale dataset containing\n25,431 Vietnamese textual items from Facebook. The task participants were\nchallenged to build a classification model that is capable of classifying an\nitem to one of 3 classes, i.e., \"HATE\", \"OFFENSIVE\" and \"CLEAN\". HSD attracted\na large number of participants and was a popular task at VLSP 2019. In\nparticular, there were 71 teams signed up for the task, 14 of them submitted\nresults with 380 valid submissions from 20th September 2019 to 4th October\n2019.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:43:14 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Vu", "Xuan-Son", ""], ["Vu", "Thanh", ""], ["Tran", "Mai-Vu", ""], ["Le-Cong", "Thanh", ""], ["Nguyen", "Huyen T M.", ""]]}, {"id": "2007.06511", "submitter": "Aarzoo Dhiman", "authors": "Aarzoo Dhiman and Durga Toshniwal", "title": "An Enhanced Text Classification to Explore Health based Indian\n  Government Policy Tweets", "comments": "Accepted to KDD 2020: Applied Data Science for Healthcare Workshop (4\n  pages, 2 figures, 2 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Government-sponsored policy-making and scheme generations is one of the means\nof protecting and promoting the social, economic, and personal development of\nthe citizens. The evaluation of effectiveness of these schemes done by\ngovernment only provide the statistical information in terms of facts and\nfigures which do not include the in-depth knowledge of public perceptions,\nexperiences and views on the topic. In this research work, we propose an\nimproved text classification framework that classifies the Twitter data of\ndifferent health-based government schemes. The proposed framework leverages the\nlanguage representation models (LR models) BERT, ELMO, and USE. However, these\nLR models have less real-time applicability due to the scarcity of the ample\nannotated data. To handle this, we propose a novel GloVe word embeddings and\nclass-specific sentiments based text augmentation approach (named Mod-EDA)\nwhich boosts the performance of text classification task by increasing the size\nof labeled data. Furthermore, the trained model is leveraged to identify the\nlevel of engagement of citizens towards these policies in different communities\nsuch as middle-income and low-income groups.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 17:04:44 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 12:37:18 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Dhiman", "Aarzoo", ""], ["Toshniwal", "Durga", ""]]}, {"id": "2007.06761", "submitter": "Alex Warstadt", "authors": "Alex Warstadt, Samuel R. Bowman", "title": "Can neural networks acquire a structural bias from raw linguistic data?", "comments": "To appear in Proceedings of 42nd Annual Meeting of the Cognitive\n  Science Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate whether BERT, a widely used neural network for sentence\nprocessing, acquires an inductive bias towards forming structural\ngeneralizations through pretraining on raw data. We conduct four experiments\ntesting its preference for structural vs. linear generalizations in different\nstructure-dependent phenomena. We find that BERT makes a structural\ngeneralization in 3 out of 4 empirical domains---subject-auxiliary inversion,\nreflexive binding, and verb tense detection in embedded clauses---but makes a\nlinear generalization when tested on NPI licensing. We argue that these results\nare the strongest evidence so far from artificial learners supporting the\nproposition that a structural bias can be acquired from raw data. If this\nconclusion is correct, it is tentative evidence that some linguistic universals\ncan be acquired by learners without innate biases. However, the precise\nimplications for human language acquisition are unclear, as humans learn\nlanguage from significantly less data than BERT.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 01:41:25 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 20:04:47 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Warstadt", "Alex", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "2007.06778", "submitter": "Lifu Tu", "authors": "Lifu Tu, Garima Lalwani, Spandana Gella, He He", "title": "An Empirical Study on Robustness to Spurious Correlations using\n  Pre-trained Language Models", "comments": "Accepted to TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that pre-trained language models such as BERT improve\nrobustness to spurious correlations in the dataset. Intrigued by these results,\nwe find that the key to their success is generalization from a small amount of\ncounterexamples where the spurious correlations do not hold. When such minority\nexamples are scarce, pre-trained models perform as poorly as models trained\nfrom scratch. In the case of extreme minority, we propose to use multi-task\nlearning (MTL) to improve generalization. Our experiments on natural language\ninference and paraphrase identification show that MTL with the right auxiliary\ntasks significantly improves performance on challenging examples without\nhurting the in-distribution performance. Further, we show that the gain from\nMTL mainly comes from improved generalization from the minority examples. Our\nresults highlight the importance of data diversity for overcoming spurious\ncorrelations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 02:34:59 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 16:18:25 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 15:51:37 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Tu", "Lifu", ""], ["Lalwani", "Garima", ""], ["Gella", "Spandana", ""], ["He", "He", ""]]}, {"id": "2007.06796", "submitter": "Anubha Kabra Ms", "authors": "Yaman Kumar, Mehar Bhatia, Anubha Kabra, Jessy Junyi Li, Di Jin, Rajiv\n  Ratn Shah", "title": "Calling Out Bluff: Attacking the Robustness of Automatic Scoring Systems\n  with Simple Adversarial Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant progress has been made in deep-learning based Automatic Essay\nScoring (AES) systems in the past two decades. The performance commonly\nmeasured by the standard performance metrics like Quadratic Weighted Kappa\n(QWK), and accuracy points to the same. However, testing on common-sense\nadversarial examples of these AES systems reveal their lack of natural language\nunderstanding capability. Inspired by common student behaviour during\nexaminations, we propose a task agnostic adversarial evaluation scheme for AES\nsystems to test their natural language understanding capabilities and overall\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 03:49:43 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:24:07 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 06:46:13 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Kumar", "Yaman", ""], ["Bhatia", "Mehar", ""], ["Kabra", "Anubha", ""], ["Li", "Jessy Junyi", ""], ["Jin", "Di", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2007.06833", "submitter": "Efthymios Tzinis", "authors": "Efthymios Tzinis, Zhepei Wang and Paris Smaragdis", "title": "Sudo rm -rf: Efficient Networks for Universal Audio Source Separation", "comments": "accepted to MLSP 2020", "journal-ref": "Published in 2020 IEEE 30th International Workshop on Machine\n  Learning for Signal Processing (MLSP)", "doi": "10.1109/MLSP49062.2020.9231900", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient neural network for end-to-end general\npurpose audio source separation. Specifically, the backbone structure of this\nconvolutional network is the SUccessive DOwnsampling and Resampling of\nMulti-Resolution Features (SuDoRMRF) as well as their aggregation which is\nperformed through simple one-dimensional convolutions. In this way, we are able\nto obtain high quality audio source separation with limited number of floating\npoint operations, memory requirements, number of parameters and latency. Our\nexperiments on both speech and environmental sound separation datasets show\nthat SuDoRMRF performs comparably and even surpasses various state-of-the-art\napproaches with significantly higher computational resource requirements.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 05:46:38 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Tzinis", "Efthymios", ""], ["Wang", "Zhepei", ""], ["Smaragdis", "Paris", ""]]}, {"id": "2007.06877", "submitter": "Jiuniu Wang", "authors": "Jiuniu Wang, Wenjia Xu, Qingzhong Wang, Antoni B. Chan", "title": "Compare and Reweight: Distinctive Image Captioning Using Similar Images\n  Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": "Accepted at ECCV 2020 (oral)", "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of image captioning models has been developed, achieving\nsignificant improvement based on popular metrics, such as BLEU, CIDEr, and\nSPICE. However, although the generated captions can accurately describe the\nimage, they are generic for similar images and lack distinctiveness, i.e.,\ncannot properly describe the uniqueness of each image. In this paper, we aim to\nimprove the distinctiveness of image captions through training with sets of\nsimilar images. First, we propose a distinctiveness metric -- between-set CIDEr\n(CIDErBtw) to evaluate the distinctiveness of a caption with respect to those\nof similar images. Our metric shows that the human annotations of each image\nare not equivalent based on distinctiveness. Thus we propose several new\ntraining strategies to encourage the distinctiveness of the generated caption\nfor each image, which are based on using CIDErBtw in a weighted loss function\nor as a reinforcement learning reward. Finally, extensive experiments are\nconducted, showing that our proposed approach significantly improves both\ndistinctiveness (as measured by CIDErBtw and retrieval metrics) and accuracy\n(e.g., as measured by CIDEr) for a wide variety of image captioning baselines.\nThese results are further confirmed through a user study.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 07:40:39 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Jiuniu", ""], ["Xu", "Wenjia", ""], ["Wang", "Qingzhong", ""], ["Chan", "Antoni B.", ""]]}, {"id": "2007.06897", "submitter": "Naman Jain", "authors": "Sriram Balasubramanian, Naman Jain, Gaurav Jindal, Abhijeet Awasthi,\n  Sunita Sarawagi", "title": "What's in a Name? Are BERT Named Entity Representations just as Good for\n  any other Name?", "comments": "Accepted at RepL4NLP, ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate named entity representations of BERT-based NLP models by\ninvestigating their robustness to replacements from the same typed class in the\ninput. We highlight that on several tasks while such perturbations are natural,\nstate of the art trained models are surprisingly brittle. The brittleness\ncontinues even with the recent entity-aware BERT models. We also try to discern\nthe cause of this non-robustness, considering factors such as tokenization and\nfrequency of occurrence. Then we provide a simple method that ensembles\npredictions from multiple replacements while jointly modeling the uncertainty\nof type annotations and label predictions. Experiments on three NLP tasks show\nthat our method enhances robustness and increases accuracy on both natural and\nadversarial datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:14:00 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Balasubramanian", "Sriram", ""], ["Jain", "Naman", ""], ["Jindal", "Gaurav", ""], ["Awasthi", "Abhijeet", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "2007.06898", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Anjana Arunkumar, Chris Bryan and Chitta Baral", "title": "Our Evaluation Metric Needs an Update to Encourage Generalization", "comments": "Accepted to ICML UDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that surpass human performance on several popular benchmarks display\nsignificant degradation in performance on exposure to Out of Distribution (OOD)\ndata. Recent research has shown that models overfit to spurious biases and\n`hack' datasets, in lieu of learning generalizable features like humans. In\norder to stop the inflation in model performance -- and thus overestimation in\nAI systems' capabilities -- we propose a simple and novel evaluation metric,\nWOOD Score, that encourages generalization during evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:15:19 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Mishra", "Swaroop", ""], ["Arunkumar", "Anjana", ""], ["Bryan", "Chris", ""], ["Baral", "Chitta", ""]]}, {"id": "2007.06908", "submitter": "Davide Chiarella", "authors": "P. Cutugno, D. Chiarella, R. Lucentini, L. Marconi and G. Morgavi", "title": "Language, communication and society: a gender based linguistics analysis", "comments": "7 pages, Mladenov et al., Recent Advances in Communications -\n  Proceedings of the 19th International Conference on Communications (part of\n  19th International Conference on Circuits, Systems, Communications and\n  Computers 2015)", "journal-ref": "Recent Advances in Electrical Engineering Series Volume 50, pag.\n  154-160, 2015, WSEAS Press. Athens ISBN: 9781618043184 ISSN: 1790-5117", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to find evidence for supporting the hypothesis\nthat language is the mirror of our thinking, our prejudices and cultural\nstereotypes. In this analysis, a questionnaire was administered to 537 people.\nThe answers have been analysed to see if gender stereotypes were present such\nas the attribution of psychological and behavioural characteristics. In\nparticular, the aim was to identify, if any, what are the stereotyped images,\nwhich emerge in defining the roles of men and women in modern society.\nMoreover, the results given can be a good starting point to understand if\ngender stereotypes, and the expectations they produce, can result in\npenalization or inequality. If so, the language and its use would create\ninherently a gender bias, which influences evaluations both in work settings\nboth in everyday life.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:38:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Cutugno", "P.", ""], ["Chiarella", "D.", ""], ["Lucentini", "R.", ""], ["Marconi", "L.", ""], ["Morgavi", "G.", ""]]}, {"id": "2007.06915", "submitter": "Davide Chiarella", "authors": "Andrea Cerniglia, Davide Chiarella, Paola Cutugno, Lucia Marconi, Anna\n  Magrini, Gelsomina Di Feo, Melissa Ferretti", "title": "Questionnaire analysis to define the most suitable survey for port-noise\n  investigation", "comments": "8 pages, Proceedings of the 26th International Congress on Sound and\n  Vibration. ISBN 978-1-9991810-0-0 ISSN 2329-3675", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high level of noise pollution affecting the areas between ports and\nlogistic platforms represents a problem that can be faced from different points\nof view. Acoustic monitoring, mapping, short-term measurements, port and road\ntraffic flows analyses can give useful indications on the strategies to be\nproposed for a better management of the problem. A survey campaign through the\npreparation of questionnaires to be submitted to the population exposed to\nnoise in the back-port areas will help to better understand the subjective\npoint of view. The paper analyses a sample of questions suitable for the\nspecific research, chosen as part of the wide database of questionnaires\ninternationally proposed for subjective investigations. The preliminary results\nof a first data collection campaign are considered to verify the adequacy of\nthe number, the type of questions, and the type of sample noise used for the\nsurvey. The questionnaire will be optimized to be distributed in the TRIPLO\nproject (TRansports and Innovative sustainable connections between Ports and\nLOgistic platforms). The results of this survey will be the starting point for\nthe linguistic investigation carried out in combination with the acoustic\nmonitoring, to improve understanding the connections between personal feeling\nand technical aspects.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:52:55 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Cerniglia", "Andrea", ""], ["Chiarella", "Davide", ""], ["Cutugno", "Paola", ""], ["Marconi", "Lucia", ""], ["Magrini", "Anna", ""], ["Di Feo", "Gelsomina", ""], ["Ferretti", "Melissa", ""]]}, {"id": "2007.06934", "submitter": "Lun Yiu Nie", "authors": "Lun Yiu Nie, Cuiyun Gao, Zhicong Zhong, Wai Lam, Yang Liu and Zenglin\n  Xu", "title": "CoreGen: Contextualized Code Representation Learning for Commit Message\n  Generation", "comments": "[J]. Neurocomputing, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic generation of high-quality commit messages for code commits can\nsubstantially facilitate software developers' works and coordination. However,\nthe semantic gap between source code and natural language poses a major\nchallenge for the task. Several studies have been proposed to alleviate the\nchallenge but none explicitly involves code contextual information during\ncommit message generation. Specifically, existing research adopts static\nembedding for code tokens, which maps a token to the same vector regardless of\nits context. In this paper, we propose a novel Contextualized code\nrepresentation learning strategy for commit message Generation (CoreGen).\nCoreGen first learns contextualized code representations which exploit the\ncontextual information behind code commit sequences. The learned\nrepresentations of code commits built upon Transformer are then fine-tuned for\ndownstream commit message generation. Experiments on the benchmark dataset\ndemonstrate the superior effectiveness of our model over the baseline models\nwith at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we also\nhighlight the future opportunities in training contextualized code\nrepresentations on larger code corpus as a solution to low-resource tasks and\nadapting the contextualized code representation framework to other code-to-text\ngeneration tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 09:43:26 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 19:28:04 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 08:09:27 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nie", "Lun Yiu", ""], ["Gao", "Cuiyun", ""], ["Zhong", "Zhicong", ""], ["Lam", "Wai", ""], ["Liu", "Yang", ""], ["Xu", "Zenglin", ""]]}, {"id": "2007.06943", "submitter": "Xuancheng Huang", "authors": "Xuancheng Huang, Jiacheng Zhang, Zhixing Tan, Derek F. Wong, Huanbo\n  Luan, Jingfang Xu, Maosong Sun, Yang Liu", "title": "Modeling Voting for System Combination in Machine Translation", "comments": "Accepted by main track of IJCAI2020;SOLE copyright holder is IJCAI\n  (international Joint Conferences on Artificial Intelligence), all rights\n  reserved. https://www.ijcai.org/Proceedings/2020/511", "journal-ref": null, "doi": "10.24963/ijcai.2020/511", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System combination is an important technique for combining the hypotheses of\ndifferent machine translation systems to improve translation performance.\nAlthough early statistical approaches to system combination have been proven\neffective in analyzing the consensus between hypotheses, they suffer from the\nerror propagation problem due to the use of pipelines. While this problem has\nbeen alleviated by end-to-end training of multi-source sequence-to-sequence\nmodels recently, these neural models do not explicitly analyze the relations\nbetween hypotheses and fail to capture their agreement because the attention to\na word in a hypothesis is calculated independently, ignoring the fact that the\nword might occur in multiple hypotheses. In this work, we propose an approach\nto modeling voting for system combination in machine translation. The basic\nidea is to enable words in hypotheses from different systems to vote on words\nthat are representative and should get involved in the generation process. This\ncan be done by quantifying the influence of each voter and its preference for\neach candidate. Our approach combines the advantages of statistical and neural\nmethods since it can not only analyze the relations between hypotheses but also\nallow for end-to-end training. Experiments show that our approach is capable of\nbetter taking advantage of the consensus between hypotheses and achieves\nsignificant improvements over state-of-the-art baselines on Chinese-English and\nEnglish-German machine translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 09:59:38 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Huang", "Xuancheng", ""], ["Zhang", "Jiacheng", ""], ["Tan", "Zhixing", ""], ["Wong", "Derek F.", ""], ["Luan", "Huanbo", ""], ["Xu", "Jingfang", ""], ["Sun", "Maosong", ""], ["Liu", "Yang", ""]]}, {"id": "2007.06949", "submitter": "Bal\\'azs Tarj\\'an", "authors": "Bal\\'azs Tarj\\'an, Gy\\\"orgy Szasz\\'ak, Tibor Fegy\\'o, P\\'eter Mihajlik", "title": "Deep Transformer based Data Augmentation with Subword Units for\n  Morphologically Rich Online ASR", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Deep Transformer models have proven to be particularly powerful in\nlanguage modeling tasks for ASR. Their high complexity, however, makes them\nvery difficult to apply in the first (single) pass of an online system. Recent\nstudies showed that a considerable part of the knowledge of neural network\nLanguage Models (LM) can be transferred to traditional n-grams by using neural\ntext generation based data augmentation. In our paper, we pre-train a GPT-2\nTransformer LM on a general text corpus and fine-tune it on our Hungarian\nconversational call center ASR task. We show that although data augmentation\nwith Transformer-generated text works well for isolating languages, it causes a\nvocabulary explosion in a morphologically rich language. Therefore, we propose\na new method called subword-based neural text augmentation, where we retokenize\nthe generated text into statistically derived subwords. We compare Morfessor\nand BPE statistical subword tokenizers and show that both methods can\nsignificantly improve the WER while greatly reducing vocabulary size and memory\nrequirements. Finally, we also demonstrate that subword-based neural text\naugmentation outperforms the word-based approach not only in terms of overall\nWER but also in recognition of OOV words.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 10:22:05 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 14:14:27 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 09:03:13 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Tarj\u00e1n", "Bal\u00e1zs", ""], ["Szasz\u00e1k", "Gy\u00f6rgy", ""], ["Fegy\u00f3", "Tibor", ""], ["Mihajlik", "P\u00e9ter", ""]]}, {"id": "2007.06954", "submitter": "Yinping Yang Dr", "authors": "Raj Kumar Gupta, Ajay Vishwanath, Yinping Yang", "title": "Global Reactions to COVID-19 on Twitter: A Labelled Dataset with Latent\n  Topic, Sentiment and Emotion Attributes", "comments": "Updated with the complete 2020 data (28 Jan 2020-1 Jan 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a large, labelled dataset on people's responses and\nexpressions related to the COVID-19 pandemic over the Twitter platform. From 28\nJanuary 2020 to 1 Jan 2021, we retrieved over 132 million public Twitter posts\n(i.e., tweets) from more than 20 million unique users using four keywords:\n\"corona\", \"wuhan\", \"nCov\" and \"covid\". Leveraging natural language processing\ntechniques and pre-trained machine learning-based emotion analytic algorithms,\nwe labelled each tweet with seventeen latent semantic attributes, including a)\nten binary attributes indicating the tweet's relevance or irrelevance to the\ntop ten detected topics, b) five quantitative emotion intensity attributes\nindicating the degree of intensity of the valence or sentiment (from extremely\nnegative to extremely positive), and the degree of intensity of fear, of anger,\nof sadness and of joy emotions (from barely noticeable to extremely high\nintensity), and c) two qualitative attributes indicating the sentiment category\nand the dominant emotion category the tweet is mainly expressing. We report the\ndescriptive statistics around the topic, sentiment and emotion attributes, and\ntheir temporal distributions, and discuss the dataset's possible usage in\ncommunication, psychology, public health, economics, and epidemiology research.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 10:30:47 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 11:39:23 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 05:49:29 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 10:39:40 GMT"}, {"version": "v5", "created": "Sat, 5 Sep 2020 04:12:15 GMT"}, {"version": "v6", "created": "Tue, 16 Feb 2021 13:31:40 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Gupta", "Raj Kumar", ""], ["Vishwanath", "Ajay", ""], ["Yang", "Yinping", ""]]}, {"id": "2007.07151", "submitter": "Kundan Krishna", "authors": "Kundan Krishna, Amy Pavel, Benjamin Schloss, Jeffrey P. Bigham,\n  Zachary C. Lipton", "title": "Extracting Structured Data from Physician-Patient Conversations By\n  Predicting Noteworthy Utterances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite diverse efforts to mine various modalities of medical data, the\nconversations between physicians and patients at the time of care remain an\nuntapped source of insights. In this paper, we leverage this data to extract\nstructured information that might assist physicians with post-visit\ndocumentation in electronic health records, potentially lightening the clerical\nburden. In this exploratory study, we describe a new dataset consisting of\nconversation transcripts, post-visit summaries, corresponding supporting\nevidence (in the transcript), and structured labels. We focus on the tasks of\nrecognizing relevant diagnoses and abnormalities in the review of organ systems\n(RoS). One methodological challenge is that the conversations are long (around\n1500 words), making it difficult for modern deep-learning models to use them as\ninput. To address this challenge, we extract noteworthy utterances---parts of\nthe conversation likely to be cited as evidence supporting some summary\nsentence. We find that by first filtering for (predicted) noteworthy\nutterances, we can significantly boost predictive performance for recognizing\nboth diagnoses and RoS abnormalities.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 16:10:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Krishna", "Kundan", ""], ["Pavel", "Amy", ""], ["Schloss", "Benjamin", ""], ["Bigham", "Jeffrey P.", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2007.07196", "submitter": "ChengHao Ho", "authors": "Hung-yi Lee, Cheng-Hao Ho, Chien-Fu Lin, Chiung-Chih Chang, Chih-Wei\n  Lee, Yau-Shian Wang, Tsung-Yuan Hsu and Kuan-Yu Chen", "title": "Investigation of Sentiment Controllable Chatbot", "comments": "arXiv admin note: text overlap with arXiv:1804.02504", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional seq2seq chatbot models attempt only to find sentences with the\nhighest probabilities conditioned on the input sequences, without considering\nthe sentiment of the output sentences. In this paper, we investigate four\nmodels to scale or adjust the sentiment of the chatbot response: a\npersona-based model, reinforcement learning, a plug and play model, and\nCycleGAN, all based on the seq2seq model. We also develop machine-evaluated\nmetrics to estimate whether the responses are reasonable given the input. These\nmetrics, together with human evaluation, are used to analyze the performance of\nthe four models in terms of different aspects; reinforcement learning and\nCycleGAN are shown to be very attractive.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 16:04:30 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lee", "Hung-yi", ""], ["Ho", "Cheng-Hao", ""], ["Lin", "Chien-Fu", ""], ["Chang", "Chiung-Chih", ""], ["Lee", "Chih-Wei", ""], ["Wang", "Yau-Shian", ""], ["Hsu", "Tsung-Yuan", ""], ["Chen", "Kuan-Yu", ""]]}, {"id": "2007.07229", "submitter": "Narjes Nikzad-Khasmakhi", "authors": "N. Nikzad-Khasmakhi, M. A. Balafar, M.Reza Feizi-Derakhshi, Cina\n  Motamed", "title": "BERTERS: Multimodal Representation Learning for Expert Recommendation\n  System with Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of an expert recommendation system is to trace a set of\ncandidates' expertise and preferences, recognize their expertise patterns, and\nidentify experts. In this paper, we introduce a multimodal classification\napproach for expert recommendation system (BERTERS). In our proposed system,\nthe modalities are derived from text (articles published by candidates) and\ngraph (their co-author connections) information. BERTERS converts text into a\nvector using the Bidirectional Encoder Representations from Transformer (BERT).\nAlso, a graph Representation technique called ExEm is used to extract the\nfeatures of candidates from the co-author network. Final representation of a\ncandidate is the concatenation of these vectors and other features. Eventually,\na classifier is built on the concatenation of features. This multimodal\napproach can be used in both the academic community and the community question\nanswering. To verify the effectiveness of BERTERS, we analyze its performance\non multi-label classification and visualization tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:30:16 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Nikzad-Khasmakhi", "N.", ""], ["Balafar", "M. A.", ""], ["Feizi-Derakhshi", "M. Reza", ""], ["Motamed", "Cina", ""]]}, {"id": "2007.07287", "submitter": "Salvador Barbosa", "authors": "Salvador E. Barbosa", "title": "Using Holographically Compressed Embeddings in Question Answering", "comments": "12 pages, 6 figures, 1 table, 9th International Conference on\n  Advanced Information Technologies and Applications (ICAITA 2020), July 11~12,\n  2020, Toronto, Canada, Advanced Natural Language Processing Sub-Conference\n  (AdNLP 2020)", "journal-ref": null, "doi": "10.5121/csit.2020.100919", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word vector representations are central to deep learning natural language\nprocessing models. Many forms of these vectors, known as embeddings, exist,\nincluding word2vec and GloVe. Embeddings are trained on large corpora and learn\nthe word's usage in context, capturing the semantic relationship between words.\nHowever, the semantics from such training are at the level of distinct words\n(known as word types), and can be ambiguous when, for example, a word type can\nbe either a noun or a verb. In question answering, parts-of-speech and named\nentity types are important, but encoding these attributes in neural models\nexpands the size of the input. This research employs holographic compression of\npre-trained embeddings, to represent a token, its part-of-speech, and named\nentity type, in the same dimension as representing only the token. The\nimplementation, in a modified question answering recurrent deep learning\nnetwork, shows that semantic relationships are preserved, and yields strong\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 18:29:49 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Barbosa", "Salvador E.", ""]]}, {"id": "2007.07318", "submitter": "Johannes Lochter", "authors": "Johannes V. Lochter, Renato M. Silva, Tiago A. Almeida", "title": "Deep learning models for representing out-of-vocabulary words", "comments": "Preprint of the paper accepted at the 9th Brazilian Conference on\n  Intelligent Systems (BRACIS'2020). To facilitate reproducibility, the results\n  were updated using a fixed random seed for all methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication has become increasingly dynamic with the popularization of\nsocial networks and applications that allow people to express themselves and\ncommunicate instantly. In this scenario, distributed representation models have\ntheir quality impacted by new words that appear frequently or that are derived\nfrom spelling errors. These words that are unknown by the models, known as\nout-of-vocabulary (OOV) words, need to be properly handled to not degrade the\nquality of the natural language processing (NLP) applications, which depend on\nthe appropriate vector representation of the texts. To better understand this\nproblem and finding the best techniques to handle OOV words, in this study, we\npresent a comprehensive performance evaluation of deep learning models for\nrepresenting OOV words. We performed an intrinsic evaluation using a benchmark\ndataset and an extrinsic evaluation using different NLP tasks: text\ncategorization, named entity recognition, and part-of-speech tagging. Although\nthe results indicated that the best technique for handling OOV words is\ndifferent for each task, Comick, a deep learning method that infers the\nembedding based on the context and the morphological structure of the OOV word,\nobtained promising results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 19:31:25 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 14:40:56 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Lochter", "Johannes V.", ""], ["Silva", "Renato M.", ""], ["Almeida", "Tiago A.", ""]]}, {"id": "2007.07389", "submitter": "Soroush Vosoughi Dr", "authors": "Weicheng Ma, Ruibo Liu, Lili Wang, Soroush Vosoughi", "title": "Emoji Prediction: Extensions and Benchmarking", "comments": "In Proceedings of the 9th KDD Workshop on Issues of Sentiment\n  Discovery and Opinion Mining (WISDOM 20). San Diego, CA, USA, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emojis are a succinct form of language which can express concrete meanings,\nemotions, and intentions. Emojis also carry signals that can be used to better\nunderstand communicative intent. They have become a ubiquitous part of our\ndaily lives, making them an important part of understanding user-generated\ncontent. The emoji prediction task aims at predicting the proper set of emojis\nassociated with a piece of text. Through emoji prediction, models can learn\nrich representations of the communicative intent of the written text. While\nexisting research on the emoji prediction task focus on a small subset of emoji\ntypes closely related to certain emotions, this setting oversimplifies the task\nand wastes the expressive power of emojis. In this paper, we extend the\nexisting setting of the emoji prediction task to include a richer set of emojis\nand to allow multi-label classification on the task. We propose novel models\nfor multi-class and multi-label emoji prediction based on Transformer networks.\nWe also construct multiple emoji prediction datasets from Twitter using\nheuristics. The BERT models achieve state-of-the-art performances on all our\ndatasets under all the settings, with relative improvements of 27.21% to\n236.36% in accuracy, 2.01% to 88.28% in top-5 accuracy and 65.19% to 346.79% in\nF-1 score, compared to the prior state-of-the-art. Our results demonstrate the\nefficacy of deep Transformer-based models on the emoji prediction task. We also\nrelease our datasets at\nhttps://github.com/hikari-NYU/Emoji_Prediction_Datasets_MMS for future\nresearchers.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 22:41:20 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Ma", "Weicheng", ""], ["Liu", "Ruibo", ""], ["Wang", "Lili", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2007.07403", "submitter": "Avisha Das", "authors": "Avisha Das and Rakesh M. Verma", "title": "Modeling Coherency in Generated Emails by Leveraging Deep Neural\n  Learners", "comments": "Accepted for Publication at Computaci\\'on y Sistemas (CyS); Poster at\n  CiCLing 2019 and WiML@ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced machine learning and natural language techniques enable attackers to\nlaunch sophisticated and targeted social engineering-based attacks. To counter\nthe active attacker issue, researchers have since resorted to proactive methods\nof detection. Email masquerading using targeted emails to fool the victim is an\nadvanced attack method. However automatic text generation requires controlling\nthe context and coherency of the generated content, which has been identified\nas an increasingly difficult problem. The method used leverages a hierarchical\ndeep neural model which uses a learned representation of the sentences in the\ninput document to generate structured written emails. We demonstrate the\ngeneration of short and targeted text messages using the deep model. The global\ncoherency of the synthesized text is evaluated using a qualitative study as\nwell as multiple quantitative measures.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 23:47:08 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Das", "Avisha", ""], ["Verma", "Rakesh M.", ""]]}, {"id": "2007.07455", "submitter": "Yingjie Hu", "authors": "Jimin Wang, Yingjie Hu", "title": "Are We There Yet? Evaluating State-of-the-Art Neural Network based\n  Geoparsers Using EUPEG as a Benchmarking Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geoparsing is an important task in geographic information retrieval. A\ngeoparsing system, known as a geoparser, takes some texts as the input and\noutputs the recognized place mentions and their location coordinates. In June\n2019, a geoparsing competition, Toponym Resolution in Scientific Papers, was\nheld as one of the SemEval 2019 tasks. The winning teams developed neural\nnetwork based geoparsers that achieved outstanding performances (over 90%\nprecision, recall, and F1 score for toponym recognition). This exciting result\nbrings the question \"are we there yet?\", namely have we achieved high enough\nperformances to possibly consider the problem of geoparsing as solved? One\nlimitation of this competition is that the developed geoparsers were tested on\nonly one dataset which has 45 research articles collected from the particular\ndomain of Bio-medicine. It is known that the same geoparser can have very\ndifferent performances on different datasets. Thus, this work performs a\nsystematic evaluation of these state-of-the-art geoparsers using our recently\ndeveloped benchmarking platform EUPEG that has eight annotated datasets, nine\nbaseline geoparsers, and eight performance metrics. The evaluation result\nsuggests that these new geoparsers indeed improve the performances of\ngeoparsing on multiple datasets although some challenges remain.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 03:13:15 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Wang", "Jimin", ""], ["Hu", "Yingjie", ""]]}, {"id": "2007.07562", "submitter": "Vladimir Kokh", "authors": "Pavel Blinov, Manvel Avetisian, Vladimir Kokh, Dmitry Umerenkov,\n  Alexander Tuzhilin", "title": "Predicting Clinical Diagnosis from Patients Electronic Health Records\n  Using BERT-based Neural Networks", "comments": "To be published in the proceedings of 2020 International Conference\n  on Artificial Intelligence in Medicine, Minneapolis MN, USA", "journal-ref": null, "doi": "10.1007/978-3-030-59137-3_11", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of predicting clinical diagnoses from\ntextual Electronic Health Records (EHR) data. We show the importance of this\nproblem in medical community and present comprehensive historical review of the\nproblem and proposed methods. As the main scientific contributions we present a\nmodification of Bidirectional Encoder Representations from Transformers (BERT)\nmodel for sequence classification that implements a novel way of\nFully-Connected (FC) layer composition and a BERT model pretrained only on\ndomain data. To empirically validate our model, we use a large-scale Russian\nEHR dataset consisting of about 4 million unique patient visits. This is the\nlargest such study for the Russian language and one of the largest globally. We\nperformed a number of comparative experiments with other text representation\nmodels on the task of multiclass classification for 265 disease subset of\nICD-10. The experiments demonstrate improved performance of our models compared\nto other baselines, including a fine-tuned Russian BERT (RuBERT) variant. We\nalso show comparable performance of our model with a panel of experienced\nmedical experts. This allows us to hope that implementation of this system will\nreduce misdiagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 09:22:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Blinov", "Pavel", ""], ["Avetisian", "Manvel", ""], ["Kokh", "Vladimir", ""], ["Umerenkov", "Dmitry", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2007.07670", "submitter": "Rohan Kumar", "authors": "Subhadeep Maji, Rohan Kumar, Manish Bansal, Kalyani Roy and Pawan\n  Goyal", "title": "Logic Constrained Pointer Networks for Interpretable Textual Similarity", "comments": "Accepted at IJCAI 2020 Main Track. Sole copyright holder is IJCAI,\n  all rights reserved. Available at https://www.ijcai.org/Proceedings/2020/333", "journal-ref": "IJCAI 2020, Pages 2405-2411", "doi": "10.24963/ijcai.2020/333", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematically discovering semantic relationships in text is an important and\nextensively studied area in Natural Language Processing, with various tasks\nsuch as entailment, semantic similarity, etc. Decomposability of sentence-level\nscores via subsequence alignments has been proposed as a way to make models\nmore interpretable. We study the problem of aligning components of sentences\nleading to an interpretable model for semantic textual similarity. In this\npaper, we introduce a novel pointer network based model with a sentinel gating\nfunction to align constituent chunks, which are represented using BERT. We\nimprove this base model with a loss function to equally penalize misalignments\nin both sentences, ensuring the alignments are bidirectional. Finally, to guide\nthe network with structured external knowledge, we introduce first-order logic\nconstraints based on ConceptNet and syntactic knowledge. The model achieves an\nF1 score of 97.73 and 96.32 on the benchmark SemEval datasets for the chunk\nalignment task, showing large improvements over the existing solutions. Source\ncode is available at\nhttps://github.com/manishb89/interpretable_sentence_similarity\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 13:01:44 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Maji", "Subhadeep", ""], ["Kumar", "Rohan", ""], ["Bansal", "Manish", ""], ["Roy", "Kalyani", ""], ["Goyal", "Pawan", ""]]}, {"id": "2007.07683", "submitter": "Qianhui Wu", "authors": "Qianhui Wu and Zijia Lin and B\\\"orje F. Karlsson and Biqing Huang and\n  Jian-Guang Lou", "title": "UniTrans: Unifying Model Transfer and Data Transfer for Cross-Lingual\n  Named Entity Recognition with Unlabeled Data", "comments": "This paper is accepted by IJCAI 2020. Code is available at\n  https://github.com/microsoft/vert-papers/tree/master/papers/UniTrans", "journal-ref": "In IJCAI, pages 3926-3932, 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior works in cross-lingual named entity recognition (NER) with no/little\nlabeled data fall into two primary categories: model transfer based and data\ntransfer based methods. In this paper we find that both method types can\ncomplement each other, in the sense that, the former can exploit context\ninformation via language-independent features but sees no task-specific\ninformation in the target language; while the latter generally generates pseudo\ntarget-language training data via translation but its exploitation of context\ninformation is weakened by inaccurate translations. Moreover, prior works\nrarely leverage unlabeled data in the target language, which can be\neffortlessly collected and potentially contains valuable information for\nimproved results. To handle both problems, we propose a novel approach termed\nUniTrans to Unify both model and data Transfer for cross-lingual NER, and\nfurthermore, to leverage the available information from unlabeled\ntarget-language data via enhanced knowledge distillation. We evaluate our\nproposed UniTrans over 4 target languages on benchmark datasets. Our\nexperimental results show that it substantially outperforms the existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 13:46:50 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Wu", "Qianhui", ""], ["Lin", "Zijia", ""], ["Karlsson", "B\u00f6rje F.", ""], ["Huang", "Biqing", ""], ["Lou", "Jian-Guang", ""]]}, {"id": "2007.07689", "submitter": "Jenthe Thienpondt", "authors": "Jenthe Thienpondt, Brecht Desplanques, Kris Demuynck", "title": "Cross-Lingual Speaker Verification with Domain-Balanced Hard Prototype\n  Mining and Language-Dependent Score Normalization", "comments": "proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-2662", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the top-scoring IDLab submission for the\ntext-independent task of the Short-duration Speaker Verification (SdSV)\nChallenge 2020. The main difficulty of the challenge exists in the large degree\nof varying phonetic overlap between the potentially cross-lingual trials, along\nwith the limited availability of in-domain DeepMine Farsi training data. We\nintroduce domain-balanced hard prototype mining to fine-tune the\nstate-of-the-art ECAPA-TDNN x-vector based speaker embedding extractor. The\nsample mining technique efficiently exploits speaker distances between the\nspeaker prototypes of the popular AAM-softmax loss function to construct\nchallenging training batches that are balanced on the domain-level. To enhance\nthe scoring of cross-lingual trials, we propose a language-dependent s-norm\nscore normalization. The imposter cohort only contains data from the Farsi\ntarget-domain which simulates the enrollment data always being Farsi. In case a\nGaussian-Backend language model detects the test speaker embedding to contain\nEnglish, a cross-language compensation offset determined on the AAM-softmax\nspeaker prototypes is subtracted from the maximum expected imposter mean score.\nA fusion of five systems with minor topological tweaks resulted in a final\nMinDCF and EER of 0.065 and 1.45% respectively on the SdSVC evaluation set.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 13:58:18 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 13:42:58 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Thienpondt", "Jenthe", ""], ["Desplanques", "Brecht", ""], ["Demuynck", "Kris", ""]]}, {"id": "2007.07691", "submitter": "Jerin Philip", "authors": "Shashank Siripragada, Jerin Philip, Vinay P. Namboodiri, C V Jawahar", "title": "A Multilingual Parallel Corpora Collection Effort for Indian Languages", "comments": "9 pages. Accepted in LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present sentence aligned parallel corpora across 10 Indian Languages -\nHindi, Telugu, Tamil, Malayalam, Gujarati, Urdu, Bengali, Oriya, Marathi,\nPunjabi, and English - many of which are categorized as low resource. The\ncorpora are compiled from online sources which have content shared across\nlanguages. The corpora presented significantly extends present resources that\nare either not large enough or are restricted to a specific domain (such as\nhealth). We also provide a separate test corpus compiled from an independent\nonline source that can be independently used for validating the performance in\n10 Indian languages. Alongside, we report on the methods of constructing such\ncorpora using tools enabled by recent advances in machine translation and\ncross-lingual retrieval using deep neural network based methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:00:18 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Siripragada", "Shashank", ""], ["Philip", "Jerin", ""], ["Namboodiri", "Vinay P.", ""], ["Jawahar", "C V", ""]]}, {"id": "2007.07728", "submitter": "Jianhao Yan", "authors": "Jianhao Yan, Fandong Meng, Jie Zhou", "title": "Dual Past and Future for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though remarkable successes have been achieved by Neural Machine Translation\n(NMT) in recent years, it still suffers from the inadequate-translation\nproblem. Previous studies show that explicitly modeling the Past and Future\ncontents of the source sentence is beneficial for translation performance.\nHowever, it is not clear whether the commonly used heuristic objective is good\nenough to guide the Past and Future. In this paper, we present a novel dual\nframework that leverages both source-to-target and target-to-source NMT models\nto provide a more direct and accurate supervision signal for the Past and\nFuture modules. Experimental results demonstrate that our proposed method\nsignificantly improves the adequacy of NMT predictions and surpasses previous\nmethods in two well-studied translation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 14:52:24 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 03:51:43 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Yan", "Jianhao", ""], ["Meng", "Fandong", ""], ["Zhou", "Jie", ""]]}, {"id": "2007.07758", "submitter": "Manuel Ladron de Guevara", "authors": "Manuel Ladron de Guevara, Christopher George, Akshat Gupta, Daragh\n  Byrne, Ramesh Krishnamurti", "title": "Multimodal Word Sense Disambiguation in Creative Practice", "comments": "9 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is ambiguous; many terms and expressions can convey the same idea.\nThis is especially true in creative practice, where ideas and design intents\nare highly subjective. We present a dataset, Ambiguous Descriptions of Art\nImages (ADARI), of contemporary workpieces, which aims to provide a\nfoundational resource for subjective image description and multimodal word\ndisambiguation in the context of creative practice. The dataset contains a\ntotal of 240k images labeled with 260k descriptive sentences. It is\nadditionally organized into sub-domains of architecture, art, design, fashion,\nfurniture, product design and technology. In subjective image description,\nlabels are not deterministic: for example, the ambiguous label dynamic might\ncorrespond to hundreds of different images. To understand this complexity, we\nanalyze the ambiguity and relevance of text with respect to images using the\nstate-of-the-art pre-trained BERT model for sentence classification. We provide\na baseline for multi-label classification tasks and demonstrate the potential\nof multimodal approaches for understanding ambiguity in design intentions. We\nhope that ADARI dataset and baselines constitute a first step towards\nsubjective label classification.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 15:34:35 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 17:54:10 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["de Guevara", "Manuel Ladron", ""], ["George", "Christopher", ""], ["Gupta", "Akshat", ""], ["Byrne", "Daragh", ""], ["Krishnamurti", "Ramesh", ""]]}, {"id": "2007.07779", "submitter": "Jonas Pfeiffer", "authors": "Jonas Pfeiffer, Andreas R\\\"uckl\\'e, Clifton Poth, Aishwarya Kamath,\n  Ivan Vuli\\'c, Sebastian Ruder, Kyunghyun Cho, Iryna Gurevych", "title": "AdapterHub: A Framework for Adapting Transformers", "comments": "EMNLP 2020: Systems Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current modus operandi in NLP involves downloading and fine-tuning\npre-trained models consisting of millions or billions of parameters. Storing\nand sharing such large trained models is expensive, slow, and time-consuming,\nwhich impedes progress towards more general and versatile NLP methods that\nlearn from and for many tasks. Adapters -- small learnt bottleneck layers\ninserted within each layer of a pre-trained model -- ameliorate this issue by\navoiding full fine-tuning of the entire model. However, sharing and integrating\nadapter layers is not straightforward. We propose AdapterHub, a framework that\nallows dynamic \"stitching-in\" of pre-trained adapters for different tasks and\nlanguages. The framework, built on top of the popular HuggingFace Transformers\nlibrary, enables extremely easy and quick adaptations of state-of-the-art\npre-trained models (e.g., BERT, RoBERTa, XLM-R) across tasks and languages.\nDownloading, sharing, and training adapters is as seamless as possible using\nminimal changes to the training scripts and a specialized infrastructure. Our\nframework enables scalable and easy access to sharing of task-specific models,\nparticularly in low-resource scenarios. AdapterHub includes all recent adapter\narchitectures and can be found at https://AdapterHub.ml.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 15:56:05 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:22:21 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 10:16:39 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Pfeiffer", "Jonas", ""], ["R\u00fcckl\u00e9", "Andreas", ""], ["Poth", "Clifton", ""], ["Kamath", "Aishwarya", ""], ["Vuli\u0107", "Ivan", ""], ["Ruder", "Sebastian", ""], ["Cho", "Kyunghyun", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2007.07803", "submitter": "Anant Khandelwal", "authors": "Anant Khandelwal", "title": "Fine-Tune Longformer for Jointly Predicting Rumor Stance and Veracity", "comments": "10 pages, 2 figures, 6 tables; Accepted at ACM CoDS-COMAD 2021", "journal-ref": null, "doi": "10.1145/3430984.3431007", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increased usage of social media caused the popularity of news and events\nwhich are not even verified, resulting in spread of rumors allover the web. Due\nto widely available social media platforms and increased usage caused the data\nto be available in huge amounts.The manual methods to process such large data\nis costly and time-taking, so there has been an increased attention to process\nand verify such content automatically for the presence of rumors. A lot of\nresearch studies reveal that to identify the stances of posts in the discussion\nthread of such events and news is an important preceding step before identify\nthe rumor veracity. In this paper,we propose a multi-task learning framework\nfor jointly predicting rumor stance and veracity on the dataset released at\nSemEval 2019 RumorEval: Determining rumor veracity and support for\nrumors(SemEval 2019 Task 7), which includes social media rumors stem from a\nvariety of breaking news stories from Reddit as well as Twit-ter. Our framework\nconsists of two parts: a) The bottom part of our framework classifies the\nstance for each post in the conversation thread discussing a rumor via\nmodelling the multi-turn conversation and make each post aware of its\nneighboring posts. b) The upper part predicts the rumor veracity of the\nconversation thread with stance evolution obtained from the bottom part.\nExperimental results on SemEval 2019 Task 7 dataset show that our method\noutperforms previous methods on both rumor stance classification and veracity\nprediction\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:09:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:25:20 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Khandelwal", "Anant", ""]]}, {"id": "2007.07825", "submitter": "Alain-J\\'er\\^ome Foug\\`eres", "authors": "Alain-J\\'er\\^ome Foug\\`eres and Egon Ostrosi", "title": "Intelligent requirements engineering from natural language and their\n  chaining toward CAD models", "comments": "15 pages, conference TMCE2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper assumes that design language plays an important role in how\ndesigners design and on the creativity of designers. Designers use and develop\nmodels as an aid to thinking, a focus for discussion and decision-making and a\nmeans of evaluating the reliability of the proposals. This paper proposes an\nintelligent method for requirements engineering from natural language and their\nchaining toward CAD models. The transition from linguistic analysis to the\nrepresentation of engineering requirements consists of the translation of the\nsyntactic structure into semantic form represented by conceptual graphs. Based\non the isomorphism between conceptual graphs and predicate logic, a formal\nlanguage of the specification is proposed. The outcome of this language is\nchained and translated in Computer Aided Three-Dimensional Interactive\nApplication (CATIA) models. The tool (EGEON: Engineering desiGn sEmantics\nelabOration and applicatioN) is developed to represent the semantic network of\nengineering requirements. A case study on the design of a car door hinge is\npresented to illustrates the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 17:53:01 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Foug\u00e8res", "Alain-J\u00e9r\u00f4me", ""], ["Ostrosi", "Egon", ""]]}, {"id": "2007.07834", "submitter": "Li Dong", "authors": "Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal, Wenhui Wang,\n  Xia Song, Xian-Ling Mao, Heyan Huang, Ming Zhou", "title": "InfoXLM: An Information-Theoretic Framework for Cross-Lingual Language\n  Model Pre-Training", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an information-theoretic framework that formulates\ncross-lingual language model pre-training as maximizing mutual information\nbetween multilingual-multi-granularity texts. The unified view helps us to\nbetter understand the existing methods for learning cross-lingual\nrepresentations. More importantly, inspired by the framework, we propose a new\npre-training task based on contrastive learning. Specifically, we regard a\nbilingual sentence pair as two views of the same meaning and encourage their\nencoded representations to be more similar than the negative examples. By\nleveraging both monolingual and parallel corpora, we jointly train the pretext\ntasks to improve the cross-lingual transferability of pre-trained models.\nExperimental results on several benchmarks show that our approach achieves\nconsiderably better performance. The code and pre-trained models are available\nat https://aka.ms/infoxlm.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 16:58:01 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 13:29:07 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chi", "Zewen", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Yang", "Nan", ""], ["Singhal", "Saksham", ""], ["Wang", "Wenhui", ""], ["Song", "Xia", ""], ["Mao", "Xian-Ling", ""], ["Huang", "Heyan", ""], ["Zhou", "Ming", ""]]}, {"id": "2007.07841", "submitter": "Paul Tardy", "authors": "Paul Tardy, David Janiszek, Yannick Est\\`eve, Vincent Nguyen", "title": "Align then Summarize: Automatic Alignment Methods for Summarization\n  Corpus Creation", "comments": null, "journal-ref": "LREC 2020 -- Proceedings of The 12th Language Resources and\n  Evaluation Conference, 2020, pp. 6718--6724", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing texts is not a straightforward task. Before even considering text\nsummarization, one should determine what kind of summary is expected. How much\nshould the information be compressed? Is it relevant to reformulate or should\nthe summary stick to the original phrasing? State-of-the-art on automatic text\nsummarization mostly revolves around news articles. We suggest that considering\na wider variety of tasks would lead to an improvement in the field, in terms of\ngeneralization and robustness. We explore meeting summarization: generating\nreports from automatic transcriptions. Our work consists in segmenting and\naligning transcriptions with respect to reports, to get a suitable dataset for\nneural summarization. Using a bootstrapping approach, we provide pre-alignments\nthat are corrected by human annotators, making a validation set against which\nwe evaluate automatic models. This consistently reduces annotators' efforts by\nproviding iteratively better pre-alignment and maximizes the corpus size by\nusing annotations from our automatic alignment models. Evaluation is conducted\non \\publicmeetings, a novel corpus of aligned public meetings. We report\nautomatic alignment and summarization performances on this corpus and show that\nautomatic alignment is relevant for data annotation since it leads to large\nimprovement of almost +4 on all ROUGE scores on the summarization task.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:03:34 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Tardy", "Paul", ""], ["Janiszek", "David", ""], ["Est\u00e8ve", "Yannick", ""], ["Nguyen", "Vincent", ""]]}, {"id": "2007.07846", "submitter": "Jimmy Lin", "authors": "Edwin Zhang, Nikhil Gupta, Raphael Tang, Xiao Han, Ronak Pradeep,\n  Kuang Lu, Yue Zhang, Rodrigo Nogueira, Kyunghyun Cho, Hui Fang, Jimmy Lin", "title": "Covidex: Neural Ranking Models and Keyword Search Infrastructure for the\n  COVID-19 Open Research Dataset", "comments": "arXiv admin note: text overlap with arXiv:2004.05125", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Covidex, a search engine that exploits the latest neural ranking\nmodels to provide information access to the COVID-19 Open Research Dataset\ncurated by the Allen Institute for AI. Our system has been online and serving\nusers since late March 2020. The Covidex is the user application component of\nour three-pronged strategy to develop technologies for helping domain experts\ntackle the ongoing global pandemic. In addition, we provide robust and\neasy-to-use keyword search infrastructure that exploits mature fusion-based\nmethods as well as standalone neural ranking models that can be incorporated\ninto other applications. These techniques have been evaluated in the ongoing\nTREC-COVID challenge: Our infrastructure and baselines have been adopted by\nmany participants, including some of the highest-scoring runs in rounds 1, 2,\nand 3. In round 3, we report the highest-scoring run that takes advantage of\nprevious training data and the second-highest fully automatic run.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 16:26:01 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Zhang", "Edwin", ""], ["Gupta", "Nikhil", ""], ["Tang", "Raphael", ""], ["Han", "Xiao", ""], ["Pradeep", "Ronak", ""], ["Lu", "Kuang", ""], ["Zhang", "Yue", ""], ["Nogueira", "Rodrigo", ""], ["Cho", "Kyunghyun", ""], ["Fang", "Hui", ""], ["Lin", "Jimmy", ""]]}, {"id": "2007.07860", "submitter": "Vijay Keswani", "authors": "Vijay Keswani and L. Elisa Celis", "title": "Dialect Diversity in Text Summarization on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussions on Twitter involve participation from different communities with\ndifferent dialects and it is often necessary to summarize a large number of\nposts into a representative sample to provide a synopsis. Yet, any such\nrepresentative sample should sufficiently portray the underlying dialect\ndiversity to present the voices of different participating communities\nrepresenting the dialects. Extractive summarization algorithms perform the task\nof constructing subsets that succinctly capture the topic of any given set of\nposts. However, we observe that there is dialect bias in the summaries\ngenerated by common summarization approaches, i.e., they often return summaries\nthat under-represent certain dialects.\n  The vast majority of existing \"fair\" summarization approaches require\nsocially salient attribute labels (in this case, dialect) to ensure that the\ngenerated summary is fair with respect to the socially salient attribute.\nNevertheless, in many applications, these labels do not exist. Furthermore, due\nto the ever-evolving nature of dialects in social media, it is unreasonable to\nlabel or accurately infer the dialect of every social media post. To correct\nfor the dialect bias, we employ a framework that takes an existing text\nsummarization algorithm as a blackbox and, using a small set of dialect-diverse\nsentences, returns a summary that is relatively more dialect-diverse.\nCrucially, this approach does not need the posts being summarized to have\ndialect labels, ensuring that the diversification process is independent of\ndialect classification/identification models. We show the efficacy of our\napproach on Twitter datasets containing posts written in dialects used by\ndifferent social groups defined by race or gender; in all cases, our approach\nleads to improved dialect diversity compared to standard text summarization\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:24:41 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 22:49:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Keswani", "Vijay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2007.07884", "submitter": "Yudhanjaya Wijeratne", "authors": "Yudhanjaya Wijeratne, Nisansa de Silva", "title": "Sinhala Language Corpora and Stopwords from a Decade of Sri Lankan\n  Facebook", "comments": "10 pages; Github repo of data linked in summary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents two colloquial Sinhala language corpora from the language\nefforts of the Data, Analysis and Policy team of LIRNEasia, as well as a list\nof algorithmically derived stopwords. The larger of the two corpora spans 2010\nto 2020 and contains 28,825,820 to 29,549,672 words of multilingual text posted\nby 533 Sri Lankan Facebook pages, including politics, media, celebrities, and\nother categories; the smaller corpus amounts to 5,402,76 words of only Sinhala\ntext extracted from the larger. Both corpora have markers for their date of\ncreation, page of origin, and content type.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:57:56 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Wijeratne", "Yudhanjaya", ""], ["de Silva", "Nisansa", ""]]}, {"id": "2007.07996", "submitter": "Preslav Nakov", "authors": "Firoj Alam, Fahim Dalvi, Shaden Shaar, Nadir Durrani, Hamdy Mubarak,\n  Alex Nikolov, Giovanni Da San Martino, Ahmed Abdelali, Hassan Sajjad, Kareem\n  Darwish, Preslav Nakov", "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "comments": "COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 21:18:30 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 08:52:10 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Alam", "Firoj", ""], ["Dalvi", "Fahim", ""], ["Shaar", "Shaden", ""], ["Durrani", "Nadir", ""], ["Mubarak", "Hamdy", ""], ["Nikolov", "Alex", ""], ["Martino", "Giovanni Da San", ""], ["Abdelali", "Ahmed", ""], ["Sajjad", "Hassan", ""], ["Darwish", "Kareem", ""], ["Nakov", "Preslav", ""]]}, {"id": "2007.07997", "submitter": "Preslav Nakov", "authors": "Alberto Barron-Cedeno, Tamer Elsayed, Preslav Nakov, Giovanni Da San\n  Martino, Maram Hasanain, Reem Suwaileh, Fatima Haouari, Nikolay Babulkov,\n  Bayan Hamdan, Alex Nikolov, Shaden Shaar, and Zien Sheikh Ali", "title": "Overview of CheckThat! 2020: Automatic Identification and Verification\n  of Claims in Social Media", "comments": "Check-Worthiness Estimation, Fact-Checking, Veracity, Evidence-based\n  Verification, Detecting Previously Fact-Checked Claims, Social Media\n  Verification, Computational Journalism, COVID-19", "journal-ref": "CLEF-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of the third edition of the CheckThat! Lab at CLEF\n2020. The lab featured five tasks in two different languages: English and\nArabic. The first four tasks compose the full pipeline of claim verification in\nsocial media: Task 1 on check-worthiness estimation, Task 2 on retrieving\npreviously fact-checked claims, Task 3 on evidence retrieval, and Task 4 on\nclaim verification. The lab is completed with Task 5 on check-worthiness\nestimation in political debates and speeches. A total of 67 teams registered to\nparticipate in the lab (up from 47 at CLEF 2019), and 23 of them actually\nsubmitted runs (compared to 14 at CLEF 2019). Most teams used deep neural\nnetworks based on BERT, LSTMs, or CNNs, and achieved sizable improvements over\nthe baselines on all tasks. Here we describe the tasks setup, the evaluation\nresults, and a summary of the approaches used by the participants, and we\ndiscuss some lessons learned. Last but not least, we release to the research\ncommunity all datasets from the lab as well as the evaluation scripts, which\nshould enable further research in the important tasks of check-worthiness\nestimation and automatic claim verification.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 21:19:32 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Barron-Cedeno", "Alberto", ""], ["Elsayed", "Tamer", ""], ["Nakov", "Preslav", ""], ["Martino", "Giovanni Da San", ""], ["Hasanain", "Maram", ""], ["Suwaileh", "Reem", ""], ["Haouari", "Fatima", ""], ["Babulkov", "Nikolay", ""], ["Hamdan", "Bayan", ""], ["Nikolov", "Alex", ""], ["Shaar", "Shaden", ""], ["Ali", "Zien Sheikh", ""]]}, {"id": "2007.08005", "submitter": "Lei Li", "authors": "Runxin Xu, Jun Cao, Mingxuan Wang, Jiaze Chen, Hao Zhou, Ying Zeng,\n  Yuping Wang, Li Chen, Xiang Yin, Xijin Zhang, Songcheng Jiang, Yuxuan Wang,\n  Lei Li", "title": "Xiaomingbot: A Multilingual Robot News Reporter", "comments": "Accepted to ACL 2020 - system demonstration", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the building of Xiaomingbot, an intelligent, multilingual\nand multimodal software robot equipped with four integral capabilities: news\ngeneration, news translation, news reading and avatar animation. Its system\nsummarizes Chinese news that it automatically generates from data tables. Next,\nit translates the summary or the full article into multiple languages, and\nreads the multilingual rendition through synthesized speech. Notably,\nXiaomingbot utilizes a voice cloning technology to synthesize the speech\ntrained from a real person's voice data in one input language. The proposed\nsystem enjoys several merits: it has an animated avatar, and is able to\ngenerate and read multilingual news. Since it was put into practice,\nXiaomingbot has written over 600,000 articles, and gained over 150,000\nfollowers on social media platforms.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 14:49:41 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Xu", "Runxin", ""], ["Cao", "Jun", ""], ["Wang", "Mingxuan", ""], ["Chen", "Jiaze", ""], ["Zhou", "Hao", ""], ["Zeng", "Ying", ""], ["Wang", "Yuping", ""], ["Chen", "Li", ""], ["Yin", "Xiang", ""], ["Zhang", "Xijin", ""], ["Jiang", "Songcheng", ""], ["Wang", "Yuxuan", ""], ["Li", "Lei", ""]]}, {"id": "2007.08024", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Stefano Cresci, Alberto Barron-Cedeno,\n  Seunghak Yu, Roberto Di Pietro, Preslav Nakov", "title": "A Survey on Computational Propaganda Detection", "comments": "propaganda detection, disinformation, misinformation, fake news,\n  media bias", "journal-ref": "IJCAI-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 22:25:51 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Cresci", "Stefano", ""], ["Barron-Cedeno", "Alberto", ""], ["Yu", "Seunghak", ""], ["Di Pietro", "Roberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "2007.08052", "submitter": "Yang Jiao", "authors": "Yang Jiao", "title": "Translate Reverberated Speech to Anechoic Ones: Speech Dereverberation\n  with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single channel speech dereverberation is considered in this work. Inspired by\nthe recent success of Bidirectional Encoder Representations from Transformers\n(BERT) model in the domain of Natural Language Processing (NLP), we investigate\nits applicability as backbone sequence model to enhance reverberated speech\nsignal. We present a variation of the basic BERT model: a pre-sequence network,\nwhich extracts local spectral-temporal information and/or provides order\ninformation, before the backbone sequence model. In addition, we use\npre-trained neural vocoder for implicit phase reconstruction. To evaluate our\nmethod, we used the data from the 3rd CHiME challenge, and compare our results\nwith other methods. Experiments show that the proposed method outperforms\ntraditional method WPE, and achieve comparable performance with\nstate-of-the-art BLSTM-based sequence models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 00:45:27 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Jiao", "Yang", ""]]}, {"id": "2007.08100", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Irene Mengze Li, Emily Zheng, Yao Chong Lim, Ruslan\n  Salakhutdinov, Louis-Philippe Morency", "title": "Towards Debiasing Sentence Representations", "comments": "ACL 2020, code available at https://github.com/pliang279/sent_debias", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As natural language processing methods are increasingly deployed in\nreal-world scenarios such as healthcare, legal systems, and social science, it\nbecomes necessary to recognize the role they potentially play in shaping social\nbiases and stereotypes. Previous work has revealed the presence of social\nbiases in widely used word embeddings involving gender, race, religion, and\nother social constructs. While some methods were proposed to debias these\nword-level embeddings, there is a need to perform debiasing at the\nsentence-level given the recent shift towards new contextualized sentence\nrepresentations such as ELMo and BERT. In this paper, we investigate the\npresence of social biases in sentence-level representations and propose a new\nmethod, Sent-Debias, to reduce these biases. We show that Sent-Debias is\neffective in removing biases, and at the same time, preserves performance on\nsentence-level downstream tasks such as sentiment analysis, linguistic\nacceptability, and natural language understanding. We hope that our work will\ninspire future research on characterizing and removing social biases from\nwidely adopted sentence representations for fairer NLP.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 04:22:30 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liang", "Paul Pu", ""], ["Li", "Irene Mengze", ""], ["Zheng", "Emily", ""], ["Lim", "Yao Chong", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2007.08124", "submitter": "Jian Liu", "authors": "Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, Yue Zhang", "title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with\n  Logical Reasoning", "comments": "Accepted by IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading is a fundamental task for testing the capability of natural\nlanguage understanding, which is closely related to human cognition in many\naspects. With the rising of deep learning techniques, algorithmic models rival\nhuman performances on simple QA, and thus increasingly challenging machine\nreading datasets have been proposed. Though various challenges such as evidence\nintegration and commonsense knowledge have been integrated, one of the\nfundamental capabilities in human reading, namely logical reasoning, is not\nfully investigated. We build a comprehensive dataset, named LogiQA, which is\nsourced from expert-written questions for testing human Logical reasoning. It\nconsists of 8,678 QA instances, covering multiple types of deductive reasoning.\nResults show that state-of-the-art neural models perform by far worse than\nhuman ceiling. Our dataset can also serve as a benchmark for reinvestigating\nlogical AI under the deep learning NLP setting. The dataset is freely available\nat https://github.com/lgw863/LogiQA-dataset\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 05:52:16 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liu", "Jian", ""], ["Cui", "Leyang", ""], ["Liu", "Hanmeng", ""], ["Huang", "Dandan", ""], ["Wang", "Yile", ""], ["Zhang", "Yue", ""]]}, {"id": "2007.08186", "submitter": "Ning Ding", "authors": "Ning Ding, Dingkun Long, Guangwei Xu, Muhua Zhu, Pengjun Xie, Xiaobin\n  Wang, Hai-Tao Zheng", "title": "Coupling Distant Annotation and Adversarial Training for Cross-Domain\n  Chinese Word Segmentation", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully supervised neural approaches have achieved significant progress in the\ntask of Chinese word segmentation (CWS). Nevertheless, the performance of\nsupervised models tends to drop dramatically when they are applied to\nout-of-domain data. Performance degradation is caused by the distribution gap\nacross domains and the out of vocabulary (OOV) problem. In order to\nsimultaneously alleviate these two issues, this paper proposes to couple\ndistant annotation and adversarial training for cross-domain CWS. For distant\nannotation, we rethink the essence of \"Chinese words\" and design an automatic\ndistant annotation mechanism that does not need any supervision or pre-defined\ndictionaries from the target domain. The approach could effectively explore\ndomain-specific words and distantly annotate the raw texts for the target\ndomain. For adversarial training, we develop a sentence-level training\nprocedure to perform noise reduction and maximum utilization of the source\ndomain information. Experiments on multiple real-world datasets across various\ndomains show the superiority and robustness of our model, significantly\noutperforming previous state-of-the-art cross-domain CWS methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 08:54:17 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 07:51:48 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Ding", "Ning", ""], ["Long", "Dingkun", ""], ["Xu", "Guangwei", ""], ["Zhu", "Muhua", ""], ["Xie", "Pengjun", ""], ["Wang", "Xiaobin", ""], ["Zheng", "Hai-Tao", ""]]}, {"id": "2007.08416", "submitter": "Lingwei Wei", "authors": "Dou Hu and Lingwei Wei", "title": "SLK-NER: Exploiting Second-order Lexicon Knowledge for Chinese NER", "comments": "5 pages, The work is accepted by SEKE2020", "journal-ref": null, "doi": "10.18293/SEKE2020-153", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although character-based models using lexicon have achieved promising results\nfor Chinese named entity recognition (NER) task, some lexical words would\nintroduce erroneous information due to wrongly matched words. Existing\nresearches proposed many strategies to integrate lexicon knowledge. However,\nthey performed with simple first-order lexicon knowledge, which provided\ninsufficient word information and still faced the challenge of matched word\nboundary conflicts; or explored the lexicon knowledge with graph where\nhigher-order information introducing negative words may disturb the\nidentification. To alleviate the above limitations, we present new insight into\nsecond-order lexicon knowledge (SLK) of each character in the sentence to\nprovide more lexical word information including semantic and word boundary\nfeatures. Based on these, we propose a SLK-based model with a novel strategy to\nintegrate the above lexicon knowledge. The proposed model can exploit more\ndiscernible lexical words information with the help of global context.\nExperimental results on three public datasets demonstrate the validity of SLK.\nThe proposed model achieves more excellent performance than the\nstate-of-the-art comparison methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 15:53:02 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hu", "Dou", ""], ["Wei", "Lingwei", ""]]}, {"id": "2007.08426", "submitter": "Leonardo F. R. Ribeiro", "authors": "Leonardo F. R. Ribeiro, Martin Schmitt, Hinrich Sch\\\"utze, Iryna\n  Gurevych", "title": "Investigating Pretrained Language Models for Graph-to-Text Generation", "comments": "Our code and pretrained model checkpoints are available at\n  https://github.com/UKPLab/plms-graph2text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-to-text generation aims to generate fluent texts from graph-based data.\nIn this paper, we investigate two recently proposed pretrained language models\n(PLMs) and analyze the impact of different task-adaptive pretraining strategies\nfor PLMs in graph-to-text generation. We present a study across three graph\ndomains: meaning representations, Wikipedia knowledge graphs (KGs) and\nscientific KGs. We show that the PLMs BART and T5 achieve new state-of-the-art\nresults and that task-adaptive pretraining strategies improve their performance\neven further. In particular, we report new state-of-the-art BLEU scores of\n49.72 on LDC2017T10, 59.70 on WebNLG, and 25.66 on AGENDA datasets - a relative\nimprovement of 31.8%, 4.5%, and 42.4%, respectively. In an extensive analysis,\nwe identify possible reasons for the PLMs' success on graph-to-text tasks. We\nfind evidence that their knowledge about true facts helps them perform well\neven when the input graph representation is reduced to a simple bag of node and\nedge labels.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:05:34 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 16:37:44 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ribeiro", "Leonardo F. R.", ""], ["Schmitt", "Martin", ""], ["Sch\u00fctze", "Hinrich", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2007.08445", "submitter": "Lingwei Wei", "authors": "Lingwei Wei, Dou Hu, Wei Zhou, Xuehai Tang, Xiaodan Zhang, Xin Wang,\n  Jizhong Han, Songlin Hu", "title": "Hierarchical Interaction Networks with Rethinking Mechanism for\n  Document-level Sentiment Analysis", "comments": "17 pages, accepted by ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level Sentiment Analysis (DSA) is more challenging due to vague\nsemantic links and complicate sentiment information. Recent works have been\ndevoted to leveraging text summarization and have achieved promising results.\nHowever, these summarization-based methods did not take full advantage of the\nsummary including ignoring the inherent interactions between the summary and\ndocument. As a result, they limited the representation to express major points\nin the document, which is highly indicative of the key sentiment. In this\npaper, we study how to effectively generate a discriminative representation\nwith explicit subject patterns and sentiment contexts for DSA. A Hierarchical\nInteraction Networks (HIN) is proposed to explore bidirectional interactions\nbetween the summary and document at multiple granularities and learn\nsubject-oriented document representations for sentiment classification.\nFurthermore, we design a Sentiment-based Rethinking mechanism (SR) by refining\nthe HIN with sentiment label information to learn a more sentiment-aware\ndocument representation. We extensively evaluate our proposed models on three\npublic datasets. The experimental results consistently demonstrate the\neffectiveness of our proposed models and show that HIN-SR outperforms various\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:27:38 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 04:55:49 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 05:33:11 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Wei", "Lingwei", ""], ["Hu", "Dou", ""], ["Zhou", "Wei", ""], ["Tang", "Xuehai", ""], ["Zhang", "Xiaodan", ""], ["Wang", "Xin", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "2007.08557", "submitter": "Lili Mou", "authors": "Jingjing Li, Zichao Li, Lili Mou, Xin Jiang, Michael R. Lyu, Irwin\n  King", "title": "Unsupervised Text Generation by Learning from Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present TGLS, a novel framework to unsupervised Text\nGeneration by Learning from Search. We start by applying a strong search\nalgorithm (in particular, simulated annealing) towards a heuristically defined\nobjective that (roughly) estimates the quality of sentences. Then, a\nconditional generative model learns from the search results, and meanwhile\nsmooth out the noise of search. The alternation between search and learning can\nbe repeated for performance bootstrapping. We demonstrate the effectiveness of\nTGLS on two real-world natural language generation tasks, paraphrase generation\nand text formalization. Our model significantly outperforms unsupervised\nbaseline methods in both tasks. Especially, it achieves comparable performance\nwith the state-of-the-art supervised methods in paraphrase generation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 04:34:48 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Li", "Jingjing", ""], ["Li", "Zichao", ""], ["Mou", "Lili", ""], ["Jiang", "Xin", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2007.08617", "submitter": "Chris Thomas", "authors": "Christopher Thomas and Adriana Kovashka", "title": "Preserving Semantic Neighborhoods for Robust Cross-modal Retrieval", "comments": null, "journal-ref": "ECCV 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of multimodal data (e.g. social media posts) has inspired\ninterest in cross-modal retrieval methods. Popular approaches rely on a variety\nof metric learning losses, which prescribe what the proximity of image and text\nshould be, in the learned space. However, most prior methods have focused on\nthe case where image and text convey redundant information; in contrast,\nreal-world image-text pairs convey complementary information with little\noverlap. Further, images in news articles and media portray topics in a\nvisually diverse fashion; thus, we need to take special care to ensure a\nmeaningful image representation. We propose novel within-modality losses which\nencourage semantic coherency in both the text and image subspaces, which does\nnot necessarily align with visual coherency. Our method ensures that not only\nare paired images and texts close, but the expected image-image and text-text\nrelationships are also observed. Our approach improves the results of\ncross-modal retrieval on four datasets compared to five baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 20:32:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Thomas", "Christopher", ""], ["Kovashka", "Adriana", ""]]}, {"id": "2007.08657", "submitter": "Dominik \\.Zurek", "authors": "Dominik \\.Zurek and Marcin Pietro\\'n", "title": "Training with reduced precision of a support vector machine model for\n  text classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the impact of using quantization on the efficiency of\nmulti-class text classification in the training process of a support vector\nmachine (SVM). This work is focused on comparing the efficiency of SVM model\ntrained using reduced precision with its original form. The main advantage of\nusing quantization is decrease in computation time and in memory footprint on\nthe dedicated hardware platform which supports low precision computation like\nGPU (16-bit) or FPGA (any bit-width). The paper presents the impact of a\nprecision reduction of the SVM training process on text classification\naccuracy. The implementation of the CPU was performed using the OpenMP library.\nAdditionally, the results of the implementation of the GPU using double, single\nand half precision are presented.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 11:59:30 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["\u017burek", "Dominik", ""], ["Pietro\u0144", "Marcin", ""]]}, {"id": "2007.08670", "submitter": "Tom Williams", "authors": "Ryan Blake Jackson and Tom Williams", "title": "Enabling Morally Sensitive Robotic Clarification Requests", "comments": "Accepted for nonarchival presentation at Advances in Cognitive\n  Systems (ACS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of current natural language oriented robot architectures enables\ncertain architectural components to circumvent moral reasoning capabilities.\nOne example of this is reflexive generation of clarification requests as soon\nas referential ambiguity is detected in a human utterance. As shown in previous\nresearch, this can lead robots to (1) miscommunicate their moral dispositions\nand (2) weaken human perception or application of moral norms within their\ncurrent context. We present a solution to these problems by performing moral\nreasoning on each potential disambiguation of an ambiguous human utterance and\nresponding accordingly, rather than immediately and naively requesting\nclarification. We implement our solution in the DIARC robot architecture,\nwhich, to our knowledge, is the only current robot architecture with both moral\nreasoning and clarification request generation capabilities. We then evaluate\nour method with a human subjects experiment, the results of which indicate that\nour approach successfully ameliorates the two identified concerns.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 22:12:35 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Jackson", "Ryan Blake", ""], ["Williams", "Tom", ""]]}, {"id": "2007.08672", "submitter": "Tom Williams", "authors": "Tom Williams and Torin Johnson and Will Culpepper and Kellyn Larson", "title": "Toward Forgetting-Sensitive Referring Expression Generationfor\n  Integrated Robot Architectures", "comments": "Accepted for (nonarchival) presentation at Advances in Cognitive\n  Systems (ACS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To engage in human-like dialogue, robots require the ability to describe the\nobjects, locations, and people in their environment, a capability known as\n\"Referring Expression Generation.\" As speakers repeatedly refer to similar\nobjects, they tend to re-use properties from previous descriptions, in part to\nhelp the listener, and in part due to cognitive availability of those\nproperties in working memory (WM). Because different theories of working memory\n\"forgetting\" necessarily lead to differences in cognitive availability, we\nhypothesize that they will similarly result in generation of different\nreferring expressions. To design effective intelligent agents, it is thus\nnecessary to determine how different models of forgetting may be differentially\neffective at producing natural human-like referring expressions. In this work,\nwe computationalize two candidate models of working memory forgetting within a\nrobot cognitive architecture, and demonstrate how they lead to cognitive\navailability-based differences in generated referring expressions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 22:20:15 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Williams", "Tom", ""], ["Johnson", "Torin", ""], ["Culpepper", "Will", ""], ["Larson", "Kellyn", ""]]}, {"id": "2007.08742", "submitter": "Yongjing Yin", "authors": "Yongjing Yin, Fandong Meng, Jinsong Su, Chulun Zhou, Zhengyuan Yang,\n  Jie Zhou, Jiebo Luo", "title": "A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal neural machine translation (NMT) aims to translate source\nsentences into a target language paired with images. However, dominant\nmulti-modal NMT models do not fully exploit fine-grained semantic\ncorrespondences between semantic units of different modalities, which have\npotential to refine multi-modal representation learning. To deal with this\nissue, in this paper, we propose a novel graph-based multi-modal fusion encoder\nfor NMT. Specifically, we first represent the input sentence and image using a\nunified multi-modal graph, which captures various semantic relationships\nbetween multi-modal semantic units (words and visual objects). We then stack\nmultiple graph-based multi-modal fusion layers that iteratively perform\nsemantic interactions to learn node representations. Finally, these\nrepresentations provide an attention-based context vector for the decoder. We\nevaluate our proposed encoder on the Multi30K datasets. Experimental results\nand in-depth analysis show the superiority of our multi-modal NMT model.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 04:06:09 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Yin", "Yongjing", ""], ["Meng", "Fandong", ""], ["Su", "Jinsong", ""], ["Zhou", "Chulun", ""], ["Yang", "Zhengyuan", ""], ["Zhou", "Jie", ""], ["Luo", "Jiebo", ""]]}, {"id": "2007.08749", "submitter": "Benjamin Schloss PhD", "authors": "Benjamin Schloss and Sandeep Konam", "title": "Towards an Automated SOAP Note: Classifying Utterances from Medical\n  Conversations", "comments": "21 pages,1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summaries generated from medical conversations can improve recall and\nunderstanding of care plans for patients and reduce documentation burden for\ndoctors. Recent advancements in automatic speech recognition (ASR) and natural\nlanguage understanding (NLU) offer potential solutions to generate these\nsummaries automatically, but rigorous quantitative baselines for benchmarking\nresearch in this domain are lacking. In this paper, we bridge this gap for two\ntasks: classifying utterances from medical conversations according to (i) the\nSOAP section and (ii) the speaker role. Both are fundamental building blocks\nalong the path towards an end-to-end, automated SOAP note for medical\nconversations. We provide details on a dataset that contains human and ASR\ntranscriptions of medical conversations and corresponding machine learning\noptimized SOAP notes. We then present a systematic analysis in which we adapt\nan existing deep learning architecture to the two aforementioned tasks. The\nresults suggest that modelling context in a hierarchical manner, which captures\nboth word and utterance level context, yields substantial improvements on both\nclassification tasks. Additionally, we develop and analyze a modular method for\nadapting our model to ASR output.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 04:19:30 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 02:06:50 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 15:35:18 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Schloss", "Benjamin", ""], ["Konam", "Sandeep", ""]]}, {"id": "2007.08751", "submitter": "Noa Garcia", "authors": "Noa Garcia and Yuta Nakashima", "title": "Knowledge-Based Video Question Answering with Unsupervised Scene\n  Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand movies, humans constantly reason over the dialogues and actions\nshown in specific scenes and relate them to the overall storyline already seen.\nInspired by this behaviour, we design ROLL, a model for knowledge-based video\nstory question answering that leverages three crucial aspects of movie\nunderstanding: dialog comprehension, scene reasoning, and storyline recalling.\nIn ROLL, each of these tasks is in charge of extracting rich and diverse\ninformation by 1) processing scene dialogues, 2) generating unsupervised video\nscene descriptions, and 3) obtaining external knowledge in a weakly supervised\nfashion. To answer a given question correctly, the information generated by\neach inspired-cognitive task is encoded via Transformers and fused through a\nmodality weighting mechanism, which balances the information from the different\nsources. Exhaustive evaluation demonstrates the effectiveness of our approach,\nwhich yields a new state-of-the-art on two challenging video question answering\ndatasets: KnowIT VQA and TVQA+.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 04:26:38 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Garcia", "Noa", ""], ["Nakashima", "Yuta", ""]]}, {"id": "2007.08772", "submitter": "Jinglin Liu", "authors": "Jinglin Liu, Yi Ren, Xu Tan, Chen Zhang, Tao Qin, Zhou Zhao, Tie-Yan\n  Liu", "title": "Task-Level Curriculum Learning for Non-Autoregressive Neural Machine\n  Translation", "comments": "Accepted at IJCAI 2020 Main Track. Sole copyright holder is IJCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive translation (NAT) achieves faster inference speed but at\nthe cost of worse accuracy compared with autoregressive translation (AT). Since\nAT and NAT can share model structure and AT is an easier task than NAT due to\nthe explicit dependency on previous target-side tokens, a natural idea is to\ngradually shift the model training from the easier AT task to the harder NAT\ntask. To smooth the shift from AT training to NAT training, in this paper, we\nintroduce semi-autoregressive translation (SAT) as intermediate tasks. SAT\ncontains a hyperparameter k, and each k value defines a SAT task with different\ndegrees of parallelism. Specially, SAT covers AT and NAT as its special cases:\nit reduces to AT when k = 1 and to NAT when k = N (N is the length of target\nsentence). We design curriculum schedules to gradually shift k from 1 to N,\nwith different pacing functions and number of tasks trained at the same time.\nWe called our method as task-level curriculum learning for NAT (TCL-NAT).\nExperiments on IWSLT14 De-En, IWSLT16 En-De, WMT14 En-De and De-En datasets\nshow that TCL-NAT achieves significant accuracy improvements over previous NAT\nbaselines and reduces the performance gap between NAT and AT models to 1-2 BLEU\npoints, demonstrating the effectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 06:06:54 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Liu", "Jinglin", ""], ["Ren", "Yi", ""], ["Tan", "Xu", ""], ["Zhang", "Chen", ""], ["Qin", "Tao", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2007.08818", "submitter": "Shoukang Hu", "authors": "Shoukang Hu, Xurong Xie, Shansong Liu, Mingyu Cui, Mengzhe Geng,\n  Xunying Liu, Helen Meng", "title": "Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks", "comments": "Accepted by ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) based automatic speech recognition (ASR) systems\nare often designed using expert knowledge and empirical evaluation. In this\npaper, a range of neural architecture search (NAS) techniques are used to\nautomatically learn two types of hyper-parameters of state-of-the-art factored\ntime delay neural networks (TDNNs): i) the left and right splicing context\noffsets; and ii) the dimensionality of the bottleneck linear projection at each\nhidden layer. These include the DARTS method integrating architecture selection\nwith lattice-free MMI (LF-MMI) TDNN training; Gumbel-Softmax and pipelined\nDARTS reducing the confusion over candidate architectures and improving the\ngeneralization of architecture selection; and Penalized DARTS incorporating\nresource constraints to adjust the trade-off between performance and system\ncomplexity. Parameter sharing among candidate architectures allows efficient\nsearch over up to $7^{28}$ different TDNN systems. Experiments conducted on the\n300-hour Switchboard corpus suggest the auto-configured systems consistently\noutperform the baseline LF-MMI TDNN systems using manual network design or\nrandom architecture search after LHUC speaker adaptation and RNNLM rescoring.\nAbsolute word error rate (WER) reductions up to 1.0\\% and relative model size\nreduction of 28\\% were obtained. Consistent performance improvements were also\nobtained on a UASpeech disordered speech recognition task using the proposed\nNAS approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 08:32:11 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:27:18 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 14:34:06 GMT"}, {"version": "v4", "created": "Sun, 7 Feb 2021 14:54:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hu", "Shoukang", ""], ["Xie", "Xurong", ""], ["Liu", "Shansong", ""], ["Cui", "Mingyu", ""], ["Geng", "Mengzhe", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "2007.08954", "submitter": "Jinming Zhao Ms", "authors": "Jinming Zhao, Ming Liu, Longxiang Gao, Yuan Jin, Lan Du, He Zhao, He\n  Zhang and Gholamreza Haffari", "title": "SummPip: Unsupervised Multi-Document Summarization with Sentence Graph\n  Compression", "comments": "accepted to SIGIR 2020", "journal-ref": null, "doi": "10.1145/3397271.3401327", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining training data for multi-document summarization (MDS) is time\nconsuming and resource-intensive, so recent neural models can only be trained\nfor limited domains. In this paper, we propose SummPip: an unsupervised method\nfor multi-document summarization, in which we convert the original documents to\na sentence graph, taking both linguistic and deep representation into account,\nthen apply spectral clustering to obtain multiple clusters of sentences, and\nfinally compress each cluster to generate the final summary. Experiments on\nMulti-News and DUC-2004 datasets show that our method is competitive to\nprevious unsupervised methods and is even comparable to the neural supervised\napproaches. In addition, human evaluation shows our system produces consistent\nand complete summaries compared to human written ones.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 13:01:15 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 10:20:12 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zhao", "Jinming", ""], ["Liu", "Ming", ""], ["Gao", "Longxiang", ""], ["Jin", "Yuan", ""], ["Du", "Lan", ""], ["Zhao", "He", ""], ["Zhang", "He", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2007.08970", "submitter": "Marc van Zee", "authors": "Daniel Furrer, Marc van Zee, Nathan Scales, Nathanael Sch\\\"arli", "title": "Compositional Generalization in Semantic Parsing: Pre-training vs.\n  Specialized Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While mainstream machine learning methods are known to have limited ability\nto compositionally generalize, new architectures and techniques continue to be\nproposed to address this limitation. We investigate state-of-the-art techniques\nand architectures in order to assess their effectiveness in improving\ncompositional generalization in semantic parsing tasks based on the SCAN and\nCFQ datasets. We show that masked language model (MLM) pre-training rivals\nSCAN-inspired architectures on primitive holdout splits. On a more complex\ncompositional task, we show that pre-training leads to significant improvements\nin performance vs. comparable non-pre-trained models, whereas architectures\nproposed to encourage compositional generalization on SCAN or in the area of\nalgorithm learning fail to lead to significant improvements. We establish a new\nstate of the art on the CFQ compositional generalization benchmark using MLM\npre-training together with an intermediate representation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 13:34:49 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 15:31:05 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Furrer", "Daniel", ""], ["van Zee", "Marc", ""], ["Scales", "Nathan", ""], ["Sch\u00e4rli", "Nathanael", ""]]}, {"id": "2007.09053", "submitter": "Nikhil Krishnaswamy", "authors": "Katherine Krajovic, Nikhil Krishnaswamy, Nathaniel J. Dimick, R. Pito\n  Salas, and James Pustejovsky", "title": "Situated Multimodal Control of a Mobile Robot: Navigation through a\n  Virtual Environment", "comments": "4 pages, 1 table, 4 figures, proceedings of RoboDIAL special session\n  a SigDIAL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new interface for controlling a navigation robot in novel\nenvironments using coordinated gesture and language. We use a TurtleBot3 robot\nwith a LIDAR and a camera, an embodied simulation of what the robot has\nencountered while exploring, and a cross-platform bridge facilitating generic\ncommunication. A human partner can deliver instructions to the robot using\nspoken English and gestures relative to the simulated environment, to guide the\nrobot through navigation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:37:01 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Krajovic", "Katherine", ""], ["Krishnaswamy", "Nikhil", ""], ["Dimick", "Nathaniel J.", ""], ["Salas", "R. Pito", ""], ["Pustejovsky", "James", ""]]}, {"id": "2007.09076", "submitter": "Yuanyuan Zhao", "authors": "Yuanyuan Zhao, Weiwei Sun and Xiaojun Wan", "title": "Constructing a Family Tree of Ten Indo-European Languages with\n  Delexicalized Cross-linguistic Transfer Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is reasonable to hypothesize that the divergence patterns formulated by\nhistorical linguists and typologists reflect constraints on human languages,\nand are thus consistent with Second Language Acquisition (SLA) in a certain\nway. In this paper, we validate this hypothesis on ten Indo-European languages.\nWe formalize the delexicalized transfer as interpretable tree-to-string and\ntree-to-tree patterns which can be automatically induced from web data by\napplying neural syntactic parsing and grammar induction technologies. This\nallows us to quantitatively probe cross-linguistic transfer and extend\ninquiries of SLA. We extend existing works which utilize mixed features and\nsupport the agreement between delexicalized cross-linguistic transfer and the\nphylogenetic structure resulting from the historical-comparative paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 15:56:54 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Zhao", "Yuanyuan", ""], ["Sun", "Weiwei", ""], ["Wan", "Xiaojun", ""]]}, {"id": "2007.09185", "submitter": "Minqi Jiang", "authors": "Minqi Jiang, Jelena Luketina, Nantas Nardelli, Pasquale Minervini,\n  Philip H. S. Torr, Shimon Whiteson, Tim Rockt\\\"aschel", "title": "WordCraft: An Environment for Benchmarking Commonsense Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to quickly solve a wide range of real-world tasks requires a\ncommonsense understanding of the world. Yet, how to best extract such knowledge\nfrom natural language corpora and integrate it with reinforcement learning (RL)\nagents remains an open challenge. This is partly due to the lack of lightweight\nsimulation environments that sufficiently reflect the semantics of the real\nworld and provide knowledge sources grounded with respect to observations in an\nRL environment. To better enable research on agents making use of commonsense\nknowledge, we propose WordCraft, an RL environment based on Little Alchemy 2.\nThis lightweight environment is fast to run and built upon entities and\nrelations inspired by real-world semantics. We evaluate several representation\nlearning methods on this new benchmark and propose a new method for integrating\nknowledge graphs with an RL agent.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 18:40:46 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Jiang", "Minqi", ""], ["Luketina", "Jelena", ""], ["Nardelli", "Nantas", ""], ["Minervini", "Pasquale", ""], ["Torr", "Philip H. S.", ""], ["Whiteson", "Shimon", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2007.09303", "submitter": "Xin Deng", "authors": "Xin Deng, Ross Smith, Genevieve Quintin", "title": "Semi-Supervised Learning Approach to Discover Enterprise User Insights\n  from Feedback and Support", "comments": "7 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the evolution of the cloud and customer centric culture, we inherently\naccumulate huge repositories of textual reviews, feedback, and support\ndata.This has driven enterprises to seek and research engagement patterns, user\nnetwork analysis, topic detections, etc.However, huge manual work is still\nnecessary to mine data to be able to mine actionable outcomes. In this paper,\nwe proposed and developed an innovative Semi-Supervised Learning approach by\nutilizing Deep Learning and Topic Modeling to have a better understanding of\nthe user voice.This approach combines a BERT-based multiclassification\nalgorithm through supervised learning combined with a novel Probabilistic and\nSemantic Hybrid Topic Inference (PSHTI) Model through unsupervised learning,\naiming at automating the process of better identifying the main topics or areas\nas well as the sub-topics from the textual feedback and support.There are three\nmajor break-through: 1. As the advancement of deep learning technology, there\nhave been tremendous innovations in the NLP field, yet the traditional topic\nmodeling as one of the NLP applications lag behind the tide of deep learning.\nIn the methodology and technical perspective, we adopt transfer learning to\nfine-tune a BERT-based multiclassification system to categorize the main topics\nand then utilize the novel PSHTI model to infer the sub-topics under the\npredicted main topics. 2. The traditional unsupervised learning-based topic\nmodels or clustering methods suffer from the difficulty of automatically\ngenerating a meaningful topic label, but our system enables mapping the top\nwords to the self-help issues by utilizing domain knowledge about the product\nthrough web-crawling. 3. This work provides a prominent showcase by leveraging\nthe state-of-the-art methodology in the real production to help shed light to\ndiscover user insights and drive business investment priorities.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 01:18:00 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:38:07 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 00:20:23 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Deng", "Xin", ""], ["Smith", "Ross", ""], ["Quintin", "Genevieve", ""]]}, {"id": "2007.09335", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Ozan Sener, Fei Sha, Vladlen Koltun", "title": "Drinking from a Firehose: Continual Learning with Web-scale Natural\n  Language", "comments": "Dataset Downloader: https://github.com/firehose-dataset/downloader\n  Source Code: https://github.com/firehose-dataset/congrad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning systems will interact with humans, with each other, and\nwith the physical world through time -- and continue to learn and adapt as they\ndo. An important open problem for continual learning is a large-scale benchmark\nthat enables realistic evaluation of algorithms. In this paper, we study a\nnatural setting for continual learning on a massive scale. We introduce the\nproblem of personalized online language learning (POLL), which involves fitting\npersonalized language models to a population of users that evolves over time.\nTo facilitate research on POLL, we collect massive datasets of Twitter posts.\nThese datasets, Firehose10M and Firehose100M, comprise 100 million tweets,\nposted by one million users over six years. Enabled by the Firehose datasets,\nwe present a rigorous evaluation of continual learning algorithms on an\nunprecedented scale. Based on this analysis, we develop a simple algorithm for\ncontinual gradient descent (ConGraD) that outperforms prior continual learning\nmethods on the Firehose datasets as well as earlier benchmarks. Collectively,\nthe POLL problem setting, the Firehose datasets, and the ConGraD algorithm\nenable a complete benchmark for reproducible research on web-scale continual\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 05:40:02 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:34:21 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hu", "Hexiang", ""], ["Sener", "Ozan", ""], ["Sha", "Fei", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2007.09456", "submitter": "Guillem Ramirez", "authors": "Guillem Ram\\'irez, Rumen Dangovski, Preslav Nakov, Marin\n  Solja\\v{c}i\\'c", "title": "On a Novel Application of Wasserstein-Procrustes for Unsupervised\n  Cross-Lingual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of unsupervised word embeddings, pre-trained on very large\nmonolingual text corpora, is at the core of the ongoing neural revolution in\nNatural Language Processing (NLP). Initially introduced for English, such\npre-trained word embeddings quickly emerged for a number of other languages.\nSubsequently, there have been a number of attempts to align the embedding\nspaces across languages, which could enable a number of cross-language NLP\napplications. Performing the alignment using unsupervised cross-lingual\nlearning (UCL) is especially attractive as it requires little data and often\nrivals supervised and semi-supervised approaches. Here, we analyze popular\nmethods for UCL and we find that often their objectives are, intrinsically,\nversions of the Wasserstein-Procrustes problem. Hence, we devise an approach to\nsolve Wasserstein-Procrustes in a direct way, which can be used to refine and\nto improve popular UCL methods such as iterative closest point (ICP),\nmultilingual unsupervised and supervised embeddings (MUSE) and supervised\nProcrustes methods. Our evaluation experiments on standard datasets show\nsizable improvements over these approaches. We believe that our rethinking of\nthe Wasserstein-Procrustes problem could enable further research, thus helping\nto develop better algorithms for aligning word embeddings across languages. Our\ncode and instructions to reproduce the experiments are available at\nhttps://github.com/guillemram97/wp-hungarian.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 15:35:09 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ram\u00edrez", "Guillem", ""], ["Dangovski", "Rumen", ""], ["Nakov", "Preslav", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "2007.09495", "submitter": "Rahim Dehkharghani", "authors": "Rahim Dehkharghani, Hojjat Emami", "title": "A novel approach to sentiment analysis in Persian using discourse and\n  external semantic information", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis attempts to identify, extract and quantify affective\nstates and subjective information from various types of data such as text,\naudio, and video. Many approaches have been proposed to extract the sentiment\nof individuals from documents written in natural languages in recent years. The\nmajority of these approaches have focused on English, while resource-lean\nlanguages such as Persian suffer from the lack of research work and language\nresources. Due to this gap in Persian, the current work is accomplished to\nintroduce new methods for sentiment analysis which have been applied on\nPersian. The proposed approach in this paper is two-fold: The first one is\nbased on classifier combination, and the second one is based on deep neural\nnetworks which benefits from word embedding vectors. Both approaches takes\nadvantage of local discourse information and external knowledge bases, and also\ncover several language issues such as negation and intensification,\nandaddresses different granularity levels, namely word, aspect, sentence,\nphrase and document-levels. To evaluate the performance of the proposed\napproach, a Persian dataset is collected from Persian hotel reviews referred as\nhotel reviews. The proposed approach has been compared to counterpart methods\nbased on the benchmark dataset. The experimental results approve the\neffectiveness of the proposed approach when compared to related works.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 18:40:40 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dehkharghani", "Rahim", ""], ["Emami", "Hojjat", ""]]}, {"id": "2007.09513", "submitter": "Koteswar Rao Jerripothula", "authors": "Koteswar Rao Jerripothula, Ankit Rai, Kanu Garg, Yashvardhan Singh\n  Rautela", "title": "Feature-level Rating System using Customer Reviews and Review Votes", "comments": "10 pages, 7 figures, and accepted by IEEE Transactions on\n  Computational Social Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies how we can obtain feature-level ratings of the mobile\nproducts from the customer reviews and review votes to influence decision\nmaking, both for new customers and manufacturers. Such a rating system gives a\nmore comprehensive picture of the product than what a product-level rating\nsystem offers. While product-level ratings are too generic, feature-level\nratings are particular; we exactly know what is good or bad about the product.\nThere has always been a need to know which features fall short or are doing\nwell according to the customer's perception. It keeps both the manufacturer and\nthe customer well-informed in the decisions to make in improving the product\nand buying, respectively. Different customers are interested in different\nfeatures. Thus, feature-level ratings can make buying decisions personalized.\nWe analyze the customer reviews collected on an online shopping site (Amazon)\nabout various mobile products and the review votes. Explicitly, we carry out a\nfeature-focused sentiment analysis for this purpose. Eventually, our analysis\nyields ratings to 108 features for 4k+ mobiles sold online. It helps in\ndecision making on how to improve the product (from the manufacturer's\nperspective) and in making the personalized buying decisions (from the buyer's\nperspective) a possibility. Our analysis has applications in recommender\nsystems, consumer research, etc.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 20:13:58 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Jerripothula", "Koteswar Rao", ""], ["Rai", "Ankit", ""], ["Garg", "Kanu", ""], ["Rautela", "Yashvardhan Singh", ""]]}, {"id": "2007.09536", "submitter": "Yu Meng", "authors": "Yu Meng, Yunyi Zhang, Jiaxin Huang, Yu Zhang, Chao Zhang, Jiawei Han", "title": "Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding", "comments": "KDD 2020 Research Track. (Code: https://github.com/yumeng5/JoSH)", "journal-ref": null, "doi": "10.1145/3394486.3403242", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining a set of meaningful topics organized into a hierarchy is intuitively\nappealing since topic correlations are ubiquitous in massive text corpora. To\naccount for potential hierarchical topic structures, hierarchical topic models\ngeneralize flat topic models by incorporating latent topic hierarchies into\ntheir generative modeling process. However, due to their purely unsupervised\nnature, the learned topic hierarchy often deviates from users' particular needs\nor interests. To guide the hierarchical topic discovery process with minimal\nuser supervision, we propose a new task, Hierarchical Topic Mining, which takes\na category tree described by category names only, and aims to mine a set of\nrepresentative terms for each category from a text corpus to help a user\ncomprehend his/her interested topics. We develop a novel joint tree and text\nembedding method along with a principled optimization procedure that allows\nsimultaneous modeling of the category tree structure and the corpus generative\nprocess in the spherical space for effective category-representative term\ndiscovery. Our comprehensive experiments show that our model, named JoSH, mines\na high-quality set of hierarchical topics with high efficiency and benefits\nweakly-supervised hierarchical text classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 23:30:47 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Meng", "Yu", ""], ["Zhang", "Yunyi", ""], ["Huang", "Jiaxin", ""], ["Zhang", "Yu", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "2007.09551", "submitter": "Soham Dan", "authors": "Soham Dan, Hangfeng He, Dan Roth", "title": "Understanding Spatial Relations through Multiple Modalities", "comments": null, "journal-ref": "LREC 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing spatial relations and reasoning about them is essential in\nmultiple applications including navigation, direction giving and human-computer\ninteraction in general. Spatial relations between objects can either be\nexplicit -- expressed as spatial prepositions, or implicit -- expressed by\nspatial verbs such as moving, walking, shifting, etc. Both these, but implicit\nrelations in particular, require significant common sense understanding. In\nthis paper, we introduce the task of inferring implicit and explicit spatial\nrelations between two entities in an image. We design a model that uses both\ntextual and visual information to predict the spatial relations, making use of\nboth positional and size information of objects and image embeddings. We\ncontrast our spatial model with powerful language models and show how our\nmodeling complements the power of these, improving prediction accuracy and\ncoverage and facilitates dealing with unseen subjects, objects and relations.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 01:35:08 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dan", "Soham", ""], ["He", "Hangfeng", ""], ["Roth", "Dan", ""]]}, {"id": "2007.09554", "submitter": "Qi Wu", "authors": "Yanyuan Qiao, Chaorui Deng, Qi Wu", "title": "Referring Expression Comprehension: A Survey of Methods and Datasets", "comments": "Accepted to IEEE TMM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring expression comprehension (REC) aims to localize a target object in\nan image described by a referring expression phrased in natural language.\nDifferent from the object detection task that queried object labels have been\npre-defined, the REC problem only can observe the queries during the test. It\nthus more challenging than a conventional computer vision problem. This task\nhas attracted a lot of attention from both computer vision and natural language\nprocessing community, and several lines of work have been proposed, from\nCNN-RNN model, modular network to complex graph-based model. In this survey, we\nfirst examine the state of the art by comparing modern approaches to the\nproblem. We classify methods by their mechanism to encode the visual and\ntextual modalities. In particular, we examine the common approach of joint\nembedding images and expressions to a common feature space. We also discuss\nmodular architectures and graph-based models that interface with structured\ngraph representation. In the second part of this survey, we review the datasets\navailable for training and evaluating REC systems. We then group results\naccording to the datasets, backbone models, settings so that they can be fairly\ncompared. Finally, we discuss promising future directions for the field, in\nparticular the compositional referring expression comprehension that requires\nlonger reasoning chain to address.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 01:45:02 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 04:56:24 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Qiao", "Yanyuan", ""], ["Deng", "Chaorui", ""], ["Wu", "Qi", ""]]}, {"id": "2007.09557", "submitter": "Soham Dan", "authors": "Soham Dan, Parisa Kordjamshidi, Julia Bonn, Archna Bhatia, Jon Cai,\n  Martha Palmer, Dan Roth", "title": "From Spatial Relations to Spatial Configurations", "comments": null, "journal-ref": "LREC 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial Reasoning from language is essential for natural language\nunderstanding. Supporting it requires a representation scheme that can capture\nspatial phenomena encountered in language as well as in images and videos.\nExisting spatial representations are not sufficient for describing spatial\nconfigurations used in complex tasks. This paper extends the capabilities of\nexisting spatial representation languages and increases coverage of the\nsemantic aspects that are needed to ground the spatial meaning of natural\nlanguage text in the world. Our spatial relation language is able to represent\na large, comprehensive set of spatial concepts crucial for reasoning and is\ndesigned to support the composition of static and dynamic spatial\nconfigurations. We integrate this language with the Abstract Meaning\nRepresentation(AMR) annotation schema and present a corpus annotated by this\nextended AMR. To exhibit the applicability of our representation scheme, we\nannotate text taken from diverse datasets and show how we extend the\ncapabilities of existing spatial representation languages with the fine-grained\ndecomposition of semantics and blend it seamlessly with AMRs of sentences and\ndiscourse representations as a whole.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 02:11:53 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dan", "Soham", ""], ["Kordjamshidi", "Parisa", ""], ["Bonn", "Julia", ""], ["Bhatia", "Archna", ""], ["Cai", "Jon", ""], ["Palmer", "Martha", ""], ["Roth", "Dan", ""]]}, {"id": "2007.09580", "submitter": "Chaorui Deng", "authors": "Chaorui Deng, Ning Ding, Mingkui Tan, Qi Wu", "title": "Length-Controllable Image Captioning", "comments": "To be appeared in ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed remarkable progress in the image captioning\ntask; however, most existing methods cannot control their captions,\n\\emph{e.g.}, choosing to describe the image either roughly or in detail. In\nthis paper, we propose to use a simple length level embedding to endow them\nwith this ability. Moreover, due to their autoregressive nature, the\ncomputational complexity of existing models increases linearly as the length of\nthe generated captions grows. Thus, we further devise a non-autoregressive\nimage captioning approach that can generate captions in a length-irrelevant\ncomplexity. We verify the merit of the proposed length level embedding on three\nmodels: two state-of-the-art (SOTA) autoregressive models with different types\nof decoder, as well as our proposed non-autoregressive model, to show its\ngeneralization ability. In the experiments, our length-controllable image\ncaptioning models not only achieve SOTA performance on the challenging MS COCO\ndataset but also generate length-controllable and diverse image captions.\nSpecifically, our non-autoregressive model outperforms the autoregressive\nbaselines in terms of controllability and diversity, and also significantly\nimproves the decoding efficiency for long captions. Our code and models are\nreleased at \\textcolor{magenta}{\\texttt{https://github.com/bearcatt/LaBERT}}.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 03:40:51 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Deng", "Chaorui", ""], ["Ding", "Ning", ""], ["Tan", "Mingkui", ""], ["Wu", "Qi", ""]]}, {"id": "2007.09604", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin", "title": "Meta-learning for Few-shot Natural Language Processing: A Survey", "comments": "no submission intent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot natural language processing (NLP) refers to NLP tasks that are\naccompanied with merely a handful of labeled examples. This is a real-world\nchallenge that an AI system must learn to handle. Usually we rely on collecting\nmore auxiliary information or developing a more efficient learning algorithm.\nHowever, the general gradient-based optimization in high capacity models, if\ntraining from scratch, requires many parameter-updating steps over a large\nnumber of labeled examples to perform well (Snell et al., 2017). If the target\ntask itself cannot provide more information, how about collecting more tasks\nequipped with rich annotations to help the model learning? The goal of\nmeta-learning is to train a model on a variety of tasks with rich annotations,\nsuch that it can solve a new task using only a few labeled samples. The key\nidea is to train the model's initial parameters such that the model has maximal\nperformance on a new task after the parameters have been updated through zero\nor a couple of gradient steps. There are already some surveys for\nmeta-learning, such as (Vilalta and Drissi, 2002; Vanschoren, 2018; Hospedales\net al., 2020). Nevertheless, this paper focuses on NLP domain, especially\nfew-shot applications. We try to provide clearer definitions, progress summary\nand some common datasets of applying meta-learning to few-shot NLP.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 06:36:41 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Yin", "Wenpeng", ""]]}, {"id": "2007.09655", "submitter": "Kareem Darwish", "authors": "Chereen Shurafa and Kareem Darwish and Wajdi Zaghouani", "title": "Political Framing: US COVID19 Blame Game", "comments": "Social Informatics 2020 (SocInfo2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the use of Twitter, framing has become a prominent presidential\ncampaign tool for politically active users. Framing is used to influence\nthoughts by evoking a particular perspective on an event. In this paper, we\nshow that the COVID19 pandemic rather than being viewed as a public health\nissue, political rhetoric surrounding it is mostly shaped through a blame frame\n(blame Trump, China, or conspiracies) and a support frame (support candidates)\nbacking the agenda of Republican and Democratic users in the lead up to the\n2020 presidential campaign. We elucidate the divergences between supporters of\nboth parties on Twitter via the use of frames. Additionally, we show how\nframing is used to positively or negatively reinforce users' thoughts. We look\nat how Twitter can efficiently be used to identify frames for topics through a\nreproducible pipeline.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 12:00:25 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Shurafa", "Chereen", ""], ["Darwish", "Kareem", ""], ["Zaghouani", "Wajdi", ""]]}, {"id": "2007.09679", "submitter": "Talip Ucar", "authors": "Talip Ucar, Adrian Gonzalez-Martin, Matthew Lee, Adrian Daniel Szwarc", "title": "One-Shot Learning for Language Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can infer a great deal about the meaning of a word, using the syntax\nand semantics of surrounding words even if it is their first time reading or\nhearing it. We can also generalise the learned concept of the word to new\ntasks. Despite great progress in achieving human-level performance in certain\ntasks (Silver et al., 2016), learning from one or few examples remains a key\nchallenge in machine learning, and has not thoroughly been explored in Natural\nLanguage Processing (NLP).\n  In this work we tackle the problem of oneshot learning for an NLP task by\nemploying ideas from recent developments in machine learning: embeddings,\nattention mechanisms (softmax) and similarity measures (cosine, Euclidean,\nPoincare, and Minkowski). We adapt the framework suggested in matching networks\n(Vinyals et al., 2016), and explore the effectiveness of the aforementioned\nmethods in one, two and three-shot learning problems on the task of predicting\nmissing word explored in (Vinyals et al., 2016) by using the WikiText-2\ndataset. Our work contributes in two ways: Our first contribution is that we\nexplore the effectiveness of different distance metrics on k-shot learning, and\nshow that there is no single best distance metric for k-shot learning, which\nchallenges common belief. We found that the performance of a distance metric\ndepends on the number of shots used during training. The second contribution of\nour work is that we establish a benchmark for one, two, and three-shot learning\non a language task with a publicly available dataset that can be used to\nbenchmark against in future research.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 14:33:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ucar", "Talip", ""], ["Gonzalez-Martin", "Adrian", ""], ["Lee", "Matthew", ""], ["Szwarc", "Adrian Daniel", ""]]}, {"id": "2007.09757", "submitter": "Diego Feijo", "authors": "Diego de Vargas Feijo, Viviane Pereira Moreira", "title": "Mono vs Multilingual Transformer-based Models: a Comparison across\n  Several Language Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A\nLite BERT) are methods for pre-training language models which can later be\nfine-tuned for a variety of Natural Language Understanding tasks. These methods\nhave been applied to a number of such tasks (mostly in English), achieving\nresults that outperform the state-of-the-art. In this paper, our contribution\nis twofold. First, we make available our trained BERT and Albert model for\nPortuguese. Second, we compare our monolingual and the standard multilingual\nmodels using experiments in semantic textual similarity, recognizing textual\nentailment, textual category classification, sentiment analysis, offensive\ncomment detection, and fake news detection, to assess the effectiveness of the\ngenerated language representations. The results suggest that both monolingual\nand multilingual models are able to achieve state-of-the-art and the advantage\nof training a single language model, if any, is small.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 19:13:20 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Feijo", "Diego de Vargas", ""], ["Moreira", "Viviane Pereira", ""]]}, {"id": "2007.09774", "submitter": "Brielen Madureira", "authors": "Brielen Madureira and David Schlangen", "title": "An Overview of Natural Language State Representation for Reinforcement\n  Learning", "comments": "Accepted to the ICML 2020 Workshop on Language in Reinforcement\n  Learning (LaReL). 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A suitable state representation is a fundamental part of the learning process\nin Reinforcement Learning. In various tasks, the state can either be described\nby natural language or be natural language itself. This survey outlines the\nstrategies used in the literature to build natural language state\nrepresentations. We appeal for more linguistically interpretable and grounded\nrepresentations, careful justification of design decisions and evaluation of\nthe effectiveness of different approaches.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 20:15:55 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Madureira", "Brielen", ""], ["Schlangen", "David", ""]]}, {"id": "2007.09820", "submitter": "Marina Dubova", "authors": "Marina Dubova, Arseny Moskvichev, Robert Goldstone", "title": "Reinforcement Communication Learning in Different Social Network\n  Structures", "comments": null, "journal-ref": "1st Workshop on Language in Reinforcement Learning, ICML 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network structure is one of the key determinants of human language\nevolution. Previous work has shown that the network of social interactions\nshapes decentralized learning in human groups, leading to the emergence of\ndifferent kinds of communicative conventions. We examined the effects of social\nnetwork organization on the properties of communication systems emerging in\ndecentralized, multi-agent reinforcement learning communities. We found that\nthe global connectivity of a social network drives the convergence of\npopulations on shared and symmetric communication systems, preventing the\nagents from forming many local \"dialects\". Moreover, the agent's degree is\ninversely related to the consistency of its use of communicative conventions.\nThese results show the importance of the basic properties of social network\nstructure on reinforcement communication learning and suggest a new\ninterpretation of findings on human convergence on word conventions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 23:57:30 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dubova", "Marina", ""], ["Moskvichev", "Arseny", ""], ["Goldstone", "Robert", ""]]}, {"id": "2007.09878", "submitter": "Xiangyang Mou", "authors": "Xiangyang Mou, Mo Yu, Bingsheng Yao, Chenghao Yang, Xiaoxiao Guo,\n  Saloni Potdar, Hui Su", "title": "Frustratingly Hard Evidence Retrieval for QA Over Books", "comments": "ACL 2020 NUSE Workshop, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of progress has been made to improve question answering (QA) in recent\nyears, but the special problem of QA over narrative book stories has not been\nexplored in-depth. We formulate BookQA as an open-domain QA task given its\nsimilar dependency on evidence retrieval. We further investigate how\nstate-of-the-art open-domain QA approaches can help BookQA. Besides achieving\nstate-of-the-art on the NarrativeQA benchmark, our study also reveals the\ndifficulty of evidence retrieval in books with a wealth of experiments and\nanalysis - which necessitates future effort on novel solutions for evidence\nretrieval in BookQA.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 04:10:08 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mou", "Xiangyang", ""], ["Yu", "Mo", ""], ["Yao", "Bingsheng", ""], ["Yang", "Chenghao", ""], ["Guo", "Xiaoxiao", ""], ["Potdar", "Saloni", ""], ["Su", "Hui", ""]]}, {"id": "2007.09903", "submitter": "Xiangyang Mou", "authors": "Xiangyang Mou, Brandyn Sigouin, Ian Steenstra, Hui Su", "title": "Multimodal Dialogue State Tracking By QA Approach with Data Augmentation", "comments": "AAAI DSTC8 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a more challenging state tracking task, Audio-Video Scene-Aware\nDialogue (AVSD), is catching an increasing amount of attention among\nresearchers. Different from purely text-based dialogue state tracking, the\ndialogue in AVSD contains a sequence of question-answer pairs about a video and\nthe final answer to the given question requires additional understanding of the\nvideo. This paper interprets the AVSD task from an open-domain Question\nAnswering (QA) point of view and proposes a multimodal open-domain QA system to\ndeal with the problem. The proposed QA system uses common encoder-decoder\nframework with multimodal fusion and attention. Teacher forcing is applied to\ntrain a natural language generator. We also propose a new data augmentation\napproach specifically under QA assumption. Our experiments show that our model\nand techniques bring significant improvements over the baseline model on the\nDSTC7-AVSD dataset and demonstrate the potentials of our data augmentation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 06:23:18 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mou", "Xiangyang", ""], ["Sigouin", "Brandyn", ""], ["Steenstra", "Ian", ""], ["Su", "Hui", ""]]}, {"id": "2007.09909", "submitter": "Fran\\c{c}ois Bry", "authors": "Fran\\c{c}ois Bry", "title": "Coinduction Plain and Simple", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Coinduction refers to both a technique for the definition of infinite\nstreams, so-called codata, and a technique for proving the equality of\ncoinductively specified codata. This article first reviews coinduction in\ndeclarative programming. Second, it reviews and slightly extends the formalism\ncommonly used for specifying codata. Third, it generalizes the coinduction\nproof principle, which has been originally specified for the equality predicate\nonly, to other predicates. This generalization makes the coinduction proof\nprinciple more intuitive and stresses its closeness with structural induction.\nThe article finally suggests in its conclusion extensions of functional and\nlogic programming with limited and decidable forms of the generalized\ncoinduction proof principle.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 06:52:54 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 08:23:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bry", "Fran\u00e7ois", ""]]}, {"id": "2007.09970", "submitter": "Simone Balloccu Mr", "authors": "Simone Balloccu, Ehud Reiter, Alexandra Johnstone, Claire Fyfe", "title": "How are you? Introducing stress-based text tailoring", "comments": null, "journal-ref": "IntelLang 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can stress affect not only your life but also how you read and interpret a\ntext? Healthcare has shown evidence of such dynamics and in this short paper we\ndiscuss customising texts based on user stress level, as it could represent a\ncritical factor when it comes to user engagement and behavioural change. We\nfirst show a real-world example in which user behaviour is influenced by\nstress, then, after discussing which tools can be employed to assess and\nmeasure it, we propose an initial method for tailoring the document by\nexploiting complexity reduction and affect enforcement. The result is a short\nand encouraging text which requires less commitment to be read and understood.\nWe believe this work in progress can raise some interesting questions on a\ntopic that is often overlooked in NLG.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 09:43:11 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Balloccu", "Simone", ""], ["Reiter", "Ehud", ""], ["Johnstone", "Alexandra", ""], ["Fyfe", "Claire", ""]]}, {"id": "2007.10021", "submitter": "Abhishek Singh", "authors": "Abhishek Singh and Surya Pratap Singh Parmar", "title": "Voice@SRIB at SemEval-2020 Task 9 and 12: Stacked Ensembling method for\n  Sentiment and Offensiveness detection in Social Media", "comments": "Changed title and few more changes. This version will be published in\n  SemEval2020. Added code Link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In social-media platforms such as Twitter, Facebook, and Reddit, people\nprefer to use code-mixed language such as Spanish-English, Hindi-English to\nexpress their opinions. In this paper, we describe different models we used,\nusing the external dataset to train embeddings, ensembling methods for\nSentimix, and OffensEval tasks. The use of pre-trained embeddings usually helps\nin multiple tasks such as sentence classification, and machine translation. In\nthis experiment, we haveused our trained code-mixed embeddings and twitter\npre-trained embeddings to SemEval tasks. We evaluate our models on macro\nF1-score, precision, accuracy, and recall on the datasets. We intend to show\nthat hyper-parameter tuning and data pre-processing steps help a lot in\nimproving the scores. In our experiments, we are able to achieve 0.886 F1-Macro\non OffenEval Greek language subtask post-evaluation, whereas the highest is\n0.852 during the Evaluation Period. We stood third in Spanglish competition\nwith our best F1-score of 0.756. Codalab username is asking28.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 11:54:43 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 17:06:19 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 10:02:35 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Singh", "Abhishek", ""], ["Parmar", "Surya Pratap Singh", ""]]}, {"id": "2007.10040", "submitter": "Louis Mahon", "authors": "Louis Mahon, Eleonora Giunchiglia, Bowen Li, Thomas Lukasiewicz", "title": "Knowledge Graph Extraction from Videos", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearly all existing techniques for automated video annotation (or captioning)\ndescribe videos using natural language sentences. However, this has several\nshortcomings: (i) it is very hard to then further use the generated natural\nlanguage annotations in automated data processing, (ii) generating natural\nlanguage annotations requires to solve the hard subtask of generating\nsemantically precise and syntactically correct natural language sentences,\nwhich is actually unrelated to the task of video annotation, (iii) it is\ndifficult to quantitatively measure performance, as standard metrics (e.g.,\naccuracy and F1-score) are inapplicable, and (iv) annotations are\nlanguage-specific. In this paper, we propose the new task of knowledge graph\nextraction from videos, i.e., producing a description in the form of a\nknowledge graph of the contents of a given video. Since no datasets exist for\nthis task, we also include a method to automatically generate them, starting\nfrom datasets where videos are annotated with natural language. We then\ndescribe an initial deep-learning model for knowledge graph extraction from\nvideos, and report results on MSVD* and MSR-VTT*, two datasets obtained from\nMSVD and MSR-VTT using our method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 12:23:39 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mahon", "Louis", ""], ["Giunchiglia", "Eleonora", ""], ["Li", "Bowen", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2007.10055", "submitter": "Fl\\'avio Santos", "authors": "Fl\\'avio Santos, Hendrik Macedo, Thiago Bispo, Cleber Zanchettin", "title": "Morphological Skip-Gram: Using morphological knowledge to improve word\n  representation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing models have attracted much interest in the deep\nlearning community. This branch of study is composed of some applications such\nas machine translation, sentiment analysis, named entity recognition, question\nand answer, and others. Word embeddings are continuous word representations,\nthey are an essential module for those applications and are generally used as\ninput word representation to the deep learning models. Word2Vec and GloVe are\ntwo popular methods to learn word embeddings. They achieve good word\nrepresentations, however, they learn representations with limited information\nbecause they ignore the morphological information of the words and consider\nonly one representation vector for each word. This approach implies that\nWord2Vec and GloVe are unaware of the word inner structure. To mitigate this\nproblem, the FastText model represents each word as a bag of characters\nn-grams. Hence, each n-gram has a continuous vector representation, and the\nfinal word representation is the sum of its characters n-grams vectors.\nNevertheless, the use of all n-grams character of a word is a poor approach\nsince some n-grams have no semantic relation with their words and increase the\namount of potentially useless information. This approach also increases the\ntraining phase time. In this work, we propose a new method for training word\nembeddings, and its goal is to replace the FastText bag of character n-grams\nfor a bag of word morphemes through the morphological analysis of the word.\nThus, words with similar context and morphemes are represented by vectors close\nto each other. To evaluate our new approach, we performed intrinsic evaluations\nconsidering 15 different tasks, and the results show a competitive performance\ncompared to FastText.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 12:47:36 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 09:01:52 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Santos", "Fl\u00e1vio", ""], ["Macedo", "Hendrik", ""], ["Bispo", "Thiago", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "2007.10276", "submitter": "Juan Banda", "authors": "Ramya Tekumalla, Juan M. Banda", "title": "Characterizing drug mentions in COVID-19 Twitter Chatter", "comments": "7 pages, 2 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the classification of COVID-19 as a global pandemic, there have been\nmany attempts to treat and contain the virus. Although there is no specific\nantiviral treatment recommended for COVID-19, there are several drugs that can\npotentially help with symptoms. In this work, we mined a large twitter dataset\nof 424 million tweets of COVID-19 chatter to identify discourse around drug\nmentions. While seemingly a straightforward task, due to the informal nature of\nlanguage use in Twitter, we demonstrate the need of machine learning alongside\ntraditional automated methods to aid in this task. By applying these\ncomplementary methods, we are able to recover almost 15% additional data,\nmaking misspelling handling a needed task as a pre-processing step when dealing\nwith social media data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 16:56:46 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 15:35:23 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Tekumalla", "Ramya", ""], ["Banda", "Juan M.", ""]]}, {"id": "2007.10286", "submitter": "Yaoyun Zhang", "authors": "Jingqi Wang, Noor Abu-el-rub, Josh Gray, Huy Anh Pham, Yujia Zhou,\n  Frank Manion, Mei Liu, Xing Song, Hua Xu, Masoud Rouhizadeh, Yaoyun Zhang", "title": "COVID-19 SignSym: a fast adaptation of a general clinical NLP tool to\n  identify and normalize COVID-19 signs and symptoms to OMOP common data model", "comments": "Journal of the American Medical Informatics Association, 2021", "journal-ref": null, "doi": "10.1093/jamia/ocab015", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic swept across the world rapidly, infecting millions of\npeople. An efficient tool that can accurately recognize important clinical\nconcepts of COVID-19 from free text in electronic health records (EHRs) will be\nvaluable to accelerate COVID-19 clinical research. To this end, this study aims\nat adapting the existing CLAMP natural language processing tool to quickly\nbuild COVID-19 SignSym, which can extract COVID-19 signs/symptoms and their 8\nattributes (body location, severity, temporal expression, subject, condition,\nuncertainty, negation, and course) from clinical text. The extracted\ninformation is also mapped to standard concepts in the Observational Medical\nOutcomes Partnership common data model. A hybrid approach of combining deep\nlearning-based models, curated lexicons, and pattern-based rules was applied to\nquickly build the COVID-19 SignSym from CLAMP, with optimized performance. Our\nextensive evaluation using 3 external sites with clinical notes of COVID-19\npatients, as well as the online medical dialogues of COVID-19, shows COVID-19\nSign-Sym can achieve high performance across data sources. The workflow used\nfor this study can be generalized to other use cases, where existing clinical\nnatural language processing tools need to be customized for specific\ninformation needs within a short time. COVID-19 SignSym is freely accessible to\nthe research community as a downloadable package\n(https://clamp.uth.edu/covid/nlp.php) and has been used by 16 healthcare\norganizations to support clinical research of COVID-19.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 15:57:26 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 16:09:57 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 14:08:35 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 17:15:48 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Wang", "Jingqi", ""], ["Abu-el-rub", "Noor", ""], ["Gray", "Josh", ""], ["Pham", "Huy Anh", ""], ["Zhou", "Yujia", ""], ["Manion", "Frank", ""], ["Liu", "Mei", ""], ["Song", "Xing", ""], ["Xu", "Hua", ""], ["Rouhizadeh", "Masoud", ""], ["Zhang", "Yaoyun", ""]]}, {"id": "2007.10287", "submitter": "Chongyan Chen", "authors": "Chongyan Chen, Islam Akef Ebeid, Yi Bu and Ying Ding", "title": "Coronavirus Knowledge Graph: A Case Study", "comments": "8 pages; Accepted by ACM KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of the novel COVID-19 pandemic has had a significant impact on\nglobal healthcare and the economy over the past few months. The virus's rapid\nwidespread has led to a proliferation in biomedical research addressing the\npandemic and its related topics. One of the essential Knowledge Discovery tools\nthat could help the biomedical research community understand and eventually\nfind a cure for COVID-19 are Knowledge Graphs. The CORD-19 dataset is a\ncollection of publicly available full-text research articles that have been\nrecently published on COVID-19 and coronavirus topics. Here, we use several\nMachine Learning, Deep Learning, and Knowledge Graph construction and mining\ntechniques to formalize and extract insights from the PubMed dataset and the\nCORD-19 dataset to identify COVID-19 related experts and bio-entities. Besides,\nwe suggest possible techniques to predict related diseases, drug candidates,\ngene, gene mutations, and related compounds as part of a systematic effort to\napply Knowledge Discovery methods to help biomedical researchers tackle the\npandemic.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 03:55:31 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Chongyan", ""], ["Ebeid", "Islam Akef", ""], ["Bu", "Yi", ""], ["Ding", "Ying", ""]]}, {"id": "2007.10310", "submitter": "Changhan Wang", "authors": "Changhan Wang, Anne Wu, Juan Pino", "title": "CoVoST 2 and Massively Multilingual Speech-to-Text Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech translation has recently become an increasingly popular topic of\nresearch, partly due to the development of benchmark datasets. Nevertheless,\ncurrent datasets cover a limited number of languages. With the aim to foster\nresearch in massive multilingual speech translation and speech translation for\nlow resource language pairs, we release CoVoST 2, a large-scale multilingual\nspeech translation corpus covering translations from 21 languages into English\nand from English into 15 languages. This represents the largest open dataset\navailable to date from total volume and language coverage perspective. Data\nsanity checks provide evidence about the quality of the data, which is released\nunder CC0 license. We also provide extensive speech recognition, bilingual and\nmultilingual machine translation and speech translation baselines with\nopen-source implementation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 17:53:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 17:53:10 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 06:07:01 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Changhan", ""], ["Wu", "Anne", ""], ["Pino", "Juan", ""]]}, {"id": "2007.10434", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra, Sebastian Hofstatter, Hamed Zamani and Nick Craswell", "title": "Conformer-Kernel with Query Term Independence for Document Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer-Kernel (TK) model has demonstrated strong reranking\nperformance on the TREC Deep Learning benchmark---and can be considered to be\nan efficient (but slightly less effective) alternative to BERT-based ranking\nmodels. In this work, we extend the TK architecture to the full retrieval\nsetting by incorporating the query term independence assumption. Furthermore,\nto reduce the memory complexity of the Transformer layers with respect to the\ninput sequence length, we propose a new Conformer layer. We show that the\nConformer's GPU memory requirement scales linearly with input sequence length,\nmaking it a more viable option when ranking long documents. Finally, we\ndemonstrate that incorporating explicit term matching signal into the model can\nbe particularly useful in the full retrieval setting. We present preliminary\nresults from our work in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 19:47:28 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Hofstatter", "Sebastian", ""], ["Zamani", "Hamed", ""], ["Craswell", "Nick", ""]]}, {"id": "2007.10534", "submitter": "Gullal Singh Cheema", "authors": "Gullal S. Cheema, Sherzod Hakimov, Ralph Ewerth", "title": "Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features", "comments": "CLEF2020-CheckThat!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 00:07:17 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 23:51:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Cheema", "Gullal S.", ""], ["Hakimov", "Sherzod", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2007.10610", "submitter": "Tongyu Lu", "authors": "Tongyu Lu, Lyucheng Yan, Gus Xia", "title": "Word Representation for Rhythms", "comments": "Construction of this paper is ill. The first author decides that this\n  paper needs thorough rewriting and more experiments should be done", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a word representation strategy for rhythm patterns. Using\n1034 pieces of Nottingham Dataset, a rhythm word dictionary whose size is 450\n(without control tokens) is generated. BERT model is created to explore\nsyntactic potentials of rhythm words. Our model is able to find overall music\nstructures and cluster different meters. In a larger scheme, a think mode -\nmusic as language - is proposed for systematic considerations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 05:39:12 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 11:12:34 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 06:56:35 GMT"}, {"version": "v4", "created": "Thu, 3 Sep 2020 10:53:53 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lu", "Tongyu", ""], ["Yan", "Lyucheng", ""], ["Xia", "Gus", ""]]}, {"id": "2007.10633", "submitter": "Tiejun Lv", "authors": "Xuewei Zhang, Tiejun Lv, Yuan Ren, Wei Ni, Norman C. Beaulieu", "title": "Analysis and Optimization of Service Delay for Multi-quality Videos in\n  Multi-tier Heterogeneous Network with Random Caching", "comments": "13 pages, 8 figures, IEEE Systems Journal, Accepted", "journal-ref": null, "doi": "10.1109/JSYST.2020.3009157", "report-no": null, "categories": "cs.NI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming to minimize service delay, we propose a new random caching scheme in\ndevice-to-device (D2D)-assisted heterogeneous network. To support diversified\nviewing qualities of multimedia video services, each video file is encoded into\na base layer (BL) and multiple enhancement layers (ELs) by scalable video\ncoding (SVC). A super layer, including the BL and several ELs, is transmitted\nto every user. We define and quantify the service delay of multi-quality videos\nby deriving successful transmission probabilities when a user is served by a\nD2D helper, a small-cell base station (SBS) and a macro-cell base station\n(MBS). We formulate a delay minimization problem subject to the limited cache\nsizes of D2D helpers and SBSs. The structure of the optimal solutions to the\nproblem is revealed, and then an improved standard gradient projection method\nis designed to effectively obtain the solutions. Both theoretical analysis and\nMonte-Carlo simulations validate the successful transmission probabilities.\nCompared with three benchmark caching policies, the proposed SVC-based random\ncaching scheme is superior in terms of reducing the service delay.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 07:28:46 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Zhang", "Xuewei", ""], ["Lv", "Tiejun", ""], ["Ren", "Yuan", ""], ["Ni", "Wei", ""], ["Beaulieu", "Norman C.", ""]]}, {"id": "2007.10681", "submitter": "Kaitao Song", "authors": "Kaitao Song, Xu Tan and Jianfeng Lu", "title": "Neural Machine Translation with Error Correction", "comments": "Accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) generates the next target token given as\ninput the previous ground truth target tokens during training while the\nprevious generated target tokens during inference, which causes discrepancy\nbetween training and inference as well as error propagation, and affects the\ntranslation accuracy. In this paper, we introduce an error correction mechanism\ninto NMT, which corrects the error information in the previous generated tokens\nto better predict the next token. Specifically, we introduce two-stream\nself-attention from XLNet into NMT decoder, where the query stream is used to\npredict the next token, and meanwhile the content stream is used to correct the\nerror information from the previous predicted tokens. We leverage scheduled\nsampling to simulate the prediction errors during training. Experiments on\nthree IWSLT translation datasets and two WMT translation datasets demonstrate\nthat our method achieves improvements over Transformer baseline and scheduled\nsampling. Further experimental analyses also verify the effectiveness of our\nproposed error correction mechanism to improve the translation quality.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 09:41:07 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["Lu", "Jianfeng", ""]]}, {"id": "2007.10712", "submitter": "Md Rabiul Awal", "authors": "Md Rabiul Awal, Rui Cao, Sandra Mitrovic, Roy Ka-Wei Lee", "title": "On Analyzing Antisocial Behaviors Amid COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has developed to be more than a bio-crisis as global\nnews has reported a sharp rise in xenophobia and discrimination in both online\nand offline communities. Such toxic behaviors take a heavy toll on society,\nespecially during these daunting times. Despite the gravity of the issue, very\nfew studies have studied online antisocial behaviors amid the COVID-19\npandemic. In this paper, we fill the research gap by collecting and annotating\na large dataset of over 40 million COVID-19 related tweets. Specially, we\npropose an annotation framework to annotate the antisocial behavior tweets\nautomatically. We also conduct an empirical analysis of our annotated dataset\nand found that new abusive lexicons are introduced amid the COVID-19 pandemic.\nOur study also identified the vulnerable targets of antisocial behaviors and\nthe factors that influence the spreading of online antisocial content.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 11:11:35 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Awal", "Md Rabiul", ""], ["Cao", "Rui", ""], ["Mitrovic", "Sandra", ""], ["Lee", "Roy Ka-Wei", ""]]}, {"id": "2007.10718", "submitter": "M. F. Mridha", "authors": "M. F. Mridha, Md. Saifur Rahman, Abu Quwsar Ohi", "title": "Human Abnormality Detection Based on Bengali Text", "comments": "The paper is accepted in IEEE Region 10 Symposium (TENSYMP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of natural language processing and human-computer interaction,\nhuman attitudes and sentiments have attracted the researchers. However, in the\nfield of human-computer interaction, human abnormality detection has not been\ninvestigated extensively and most works depend on image-based information. In\nnatural language processing, effective meaning can potentially convey by all\nwords. Each word may bring out difficult encounters because of their semantic\nconnection with ideas or categories. In this paper, an efficient and effective\nhuman abnormality detection model is introduced, that only uses Bengali text.\nThis proposed model can recognize whether the person is in a normal or abnormal\nstate by analyzing their typed Bengali text. To the best of our knowledge, this\nis the first attempt in developing a text based human abnormality detection\nsystem. We have created our Bengali dataset (contains 2000 sentences) that is\ngenerated by voluntary conversations. We have performed the comparative\nanalysis by using Naive Bayes and Support Vector Machine as classifiers. Two\ndifferent feature extraction techniques count vector, and TF-IDF is used to\nexperiment on our constructed dataset. We have achieved a maximum 89% accuracy\nand 92% F1-score with our constructed dataset in our experiment.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 11:21:26 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Mridha", "M. F.", ""], ["Rahman", "Md. Saifur", ""], ["Ohi", "Abu Quwsar", ""]]}, {"id": "2007.10819", "submitter": "Ashutosh Modi", "authors": "Ayush Kumar, Harsh Agarwal, Keshav Bansal, Ashutosh Modi", "title": "BAKSA at SemEval-2020 Task 9: Bolstering CNN with Self-Attention for\n  Sentiment Analysis of Code Mixed Text", "comments": "6 pages, 8 figures, 2 tables. Accepted at Proceedings of the 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis of code-mixed text has diversified applications in opinion\nmining ranging from tagging user reviews to identifying social or political\nsentiments of a sub-population. In this paper, we present an ensemble\narchitecture of convolutional neural net (CNN) and self-attention based LSTM\nfor sentiment analysis of code-mixed tweets. While the CNN component helps in\nthe classification of positive and negative tweets, the self-attention based\nLSTM, helps in the classification of neutral tweets, because of its ability to\nidentify correct sentiment among multiple sentiment bearing units. We achieved\nF1 scores of 0.707 (ranked 5th) and 0.725 (ranked 13th) on Hindi-English\n(Hinglish) and Spanish-English (Spanglish) datasets, respectively. The\nsubmissions for Hinglish and Spanglish tasks were made under the usernames\nayushk and harsh_6 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:05:51 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kumar", "Ayush", ""], ["Agarwal", "Harsh", ""], ["Bansal", "Keshav", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10820", "submitter": "Sahil Dhull", "authors": "Vipul Singhal, Sahil Dhull, Rishabh Agarwal and Ashutosh Modi", "title": "IITK at SemEval-2020 Task 10: Transformers for Emphasis Selection", "comments": "6 pages, 3 figures, 3 tables. Accepted at Proceedings of 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the system proposed for addressing the research problem\nposed in Task 10 of SemEval-2020: Emphasis Selection For Written Text in Visual\nMedia. We propose an end-to-end model that takes as input the text and\ncorresponding to each word gives the probability of the word to be emphasized.\nOur results show that transformer-based models are particularly effective in\nthis task. We achieved the best Matchm score (described in section 2.2) of\n0.810 and were ranked third on the leaderboard.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:05:56 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Singhal", "Vipul", ""], ["Dhull", "Sahil", ""], ["Agarwal", "Rishabh", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10822", "submitter": "Vishal Keswani", "authors": "Vishal Keswani, Sakshi Singh, Suryansh Agarwal, Ashutosh Modi", "title": "IITK at SemEval-2020 Task 8: Unimodal and Bimodal Sentiment Analysis of\n  Internet Memes", "comments": "7 pages, 2 figures, 3 tables. Accepted at Proceedings of the 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is abundant in visual and textual information presented together\nor in isolation. Memes are the most popular form, belonging to the former\nclass. In this paper, we present our approaches for the Memotion Analysis\nproblem as posed in SemEval-2020 Task 8. The goal of this task is to classify\nmemes based on their emotional content and sentiment. We leverage techniques\nfrom Natural Language Processing (NLP) and Computer Vision (CV) towards the\nsentiment classification of internet memes (Subtask A). We consider Bimodal\n(text and image) as well as Unimodal (text-only) techniques in our study\nranging from the Na\\\"ive Bayes classifier to Transformer-based approaches. Our\nresults show that a text-only approach, a simple Feed Forward Neural Network\n(FFNN) with Word2vec embeddings as input, performs superior to all the others.\nWe stand first in the Sentiment analysis task with a relative improvement of\n63% over the baseline macro-F1 score. Our work is relevant to any task\nconcerned with the combination of different modalities.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:06:26 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Keswani", "Vishal", ""], ["Singh", "Sakshi", ""], ["Agarwal", "Suryansh", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10827", "submitter": "Paramansh Singh", "authors": "Paramansh Singh, Siraj Sandhu, Subham Kumar, Ashutosh Modi", "title": "newsSweeper at SemEval-2020 Task 11: Context-Aware Rich Feature\n  Representations For Propaganda Classification", "comments": "7 pages, 4 figures, 2 tables Accepted at Proceedings of the 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submissions to SemEval 2020 Task 11: Detection of\nPropaganda Techniques in News Articles for each of the two subtasks of Span\nIdentification and Technique Classification. We make use of pre-trained BERT\nlanguage model enhanced with tagging techniques developed for the task of Named\nEntity Recognition (NER), to develop a system for identifying propaganda spans\nin the text. For the second subtask, we incorporate contextual features in a\npre-trained RoBERTa model for the classification of propaganda techniques. We\nwere ranked 5th in the propaganda technique classification subtask.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:06:59 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Singh", "Paramansh", ""], ["Sandhu", "Siraj", ""], ["Kumar", "Subham", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10830", "submitter": "Sandeep Routray", "authors": "Soumya Ranjan Dash, Sandeep Routray, Prateek Varshney, Ashutosh Modi", "title": "CS-NET at SemEval-2020 Task 4: Siamese BERT for ComVE", "comments": "6 pages, 2 figures, 2 tables Accepted at Proceedings of the 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our system for Task 4 of SemEval 2020, which\ninvolves differentiating between natural language statements that confirm to\ncommon sense and those that do not. The organizers propose three subtasks -\nfirst, selecting between two sentences, the one which is against common sense.\nSecond, identifying the most crucial reason why a statement does not make\nsense. Third, generating novel reasons for explaining the against common sense\nstatement. Out of the three subtasks, this paper reports the system description\nof subtask A and subtask B. This paper proposes a model based on transformer\nneural network architecture for addressing the subtasks. The novelty in work\nlies in the architecture design, which handles the logical implication of\ncontradicting statements and simultaneous information extraction from both\nsentences. We use a parallel instance of transformers, which is responsible for\na boost in the performance. We achieved an accuracy of 94.8% in subtask A and\n89% in subtask B on the test set.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:08:02 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Dash", "Soumya Ranjan", ""], ["Routray", "Sandeep", ""], ["Varshney", "Prateek", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10866", "submitter": "Shashank Gupta", "authors": "Anirudh Anil Ojha, Rohin Garg, Shashank Gupta and Ashutosh Modi", "title": "IITK-RSA at SemEval-2020 Task 5: Detecting Counterfactuals", "comments": "10 pages, 1 figure, 4 tables. For associated code, see\n  https://github.com/gargrohin/Counterfactuals-NLP. Accepted at Proceedings of\n  14th International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our efforts in tackling Task 5 of SemEval-2020. The task\ninvolved detecting a class of textual expressions known as counterfactuals and\nseparating them into their constituent elements. Counterfactual statements\ndescribe events that have not or could not have occurred and the possible\nimplications of such events. While counterfactual reasoning is natural for\nhumans, understanding these expressions is difficult for artificial agents due\nto a variety of linguistic subtleties. Our final submitted approaches were an\nensemble of various fine-tuned transformer-based and CNN-based models for the\nfirst subtask and a transformer model with dependency tree information for the\nsecond subtask. We ranked 4-th and 9-th in the overall leaderboard. We also\nexplored various other approaches that involved the use of classical methods,\nother neural architectures and the incorporation of different linguistic\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 14:45:53 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ojha", "Anirudh Anil", ""], ["Garg", "Rohin", ""], ["Gupta", "Shashank", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10873", "submitter": "Anxiang Zhang", "authors": "Yu Zhao, Anxiang Zhang, Ruobing Xie, Kang Liu, Xiaojie Wang", "title": "Connecting Embeddings for Knowledge Graph Entity Typing", "comments": null, "journal-ref": "Association for Computational Linguistics, 2020, 6419--6428", "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) entity typing aims at inferring possible missing entity\ntype instances in KG, which is a very significant but still under-explored\nsubtask of knowledge graph completion. In this paper, we propose a novel\napproach for KG entity typing which is trained by jointly utilizing local\ntyping knowledge from existing entity type assertions and global triple\nknowledge from KGs. Specifically, we present two distinct knowledge-driven\neffective mechanisms of entity type inference. Accordingly, we build two novel\nembedding models to realize the mechanisms. Afterward, a joint model with them\nis used to infer missing entity type instances, which favors inferences that\nagree with both entity type instances and triple knowledge in KGs. Experimental\nresults on two real-world datasets (Freebase and YAGO) demonstrate the\neffectiveness of our proposed mechanisms and models for improving KG entity\ntyping. The source code and data of this paper can be obtained from:\nhttps://github.com/ Adam1679/ConnectE\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 15:00:01 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Zhao", "Yu", ""], ["Zhang", "Anxiang", ""], ["Xie", "Ruobing", ""], ["Liu", "Kang", ""], ["Wang", "Xiaojie", ""]]}, {"id": "2007.10877", "submitter": "Karishma Laud", "authors": "Karishma Laud, Jagriti Singh, Randeep Kumar Sahu, Ashutosh Modi", "title": "problemConquero at SemEval-2020 Task 12: Transformer and Soft\n  label-based approaches", "comments": "10 pages,2 figures,8 tables, Accepted at Proceedings of the 14th\n  International Workshop on Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present various systems submitted by our team\nproblemConquero for SemEval-2020 Shared Task 12 Multilingual Offensive Language\nIdentification in Social Media. We participated in all the three sub-tasks of\nOffensEval-2020, and our final submissions during the evaluation phase included\ntransformer-based approaches and a soft label-based approach. BERT based\nfine-tuned models were submitted for each language of sub-task A (offensive\ntweet identification). RoBERTa based fine-tuned model for sub-task B (automatic\ncategorization of offense types) was submitted. We submitted two models for\nsub-task C (offense target identification), one using soft labels and the other\nusing BERT based fine-tuned model. Our ranks for sub-task A were Greek-19 out\nof 37, Turkish-22 out of 46, Danish-26 out of 39, Arabic-39 out of 53, and\nEnglish-20 out of 85. We achieved a rank of 28 out of 43 for sub-task B. Our\nbest rank for sub-task C was 20 out of 39 using BERT based fine-tuned model.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 15:06:58 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Laud", "Karishma", ""], ["Singh", "Jagriti", ""], ["Sahu", "Randeep Kumar", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.10945", "submitter": "Xiangjue Dong", "authors": "Xiangjue Dong and Jinho D. Choi", "title": "XD at SemEval-2020 Task 12: Ensemble Approach to Offensive Language\n  Identification in Social Media Using Transformer Encoders", "comments": "To be published in SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents six document classification models using the latest\ntransformer encoders and a high-performing ensemble model for a task of\noffensive language identification in social media. For the individual models,\ndeep transformer layers are applied to perform multi-head attentions. For the\nensemble model, the utterance representations taken from those individual\nmodels are concatenated and fed into a linear decoder to make the final\ndecisions. Our ensemble model outperforms the individual models and shows up to\n8.6% improvement over the individual models on the development set. On the test\nset, it achieves macro-F1 of 90.9% and becomes one of the high performing\nsystems among 85 participants in the sub-task A of this shared task. Our\nanalysis shows that although the ensemble model significantly improves the\naccuracy on the development set, the improvement is not as evident on the test\nset.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 17:03:00 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Dong", "Xiangjue", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2007.11053", "submitter": "Josimar Chire Saire", "authors": "Honorio Apaza Alanoca, Americo A. Rubin de Celis Vidal, and Josimar\n  Edinson Chire Saire", "title": "Curriculum Vitae Recommendation Based on Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last years, the development in diverse areas related to computer\nscience and internet, allowed to generate new alternatives for decision making\nin the selection of personnel for state and private companies. In order to\noptimize this selection process, the recommendation systems are the most\nsuitable for working with explicit information related to the likes and\ndislikes of employers or end users, since this information allows to generate\nlists of recommendations based on collaboration or similarity of content.\nTherefore, this research takes as a basis these characteristics contained in\nthe database of curricula and job offers, which correspond to the Peruvian\nambit, which highlights the experience, knowledge and skills of each candidate,\nwhich are described in textual terms or words. This research focuses on the\nproblem: how we can take advantage from the growth of unstructured information\nabout job offers and curriculum vitae on different websites for CV\nrecommendation. So, we use the techniques from Text Mining and Natural Language\nProcessing. Then, as a relevant technique for the present study, we emphasize\nthe technique frequency of the Term - Inverse Frequency of the documents\n(TF-IDF), which allows identifying the most relevant CVs in relation to a job\noffer of website through the average values (TF-IDF). So, the weighted value\ncan be used as a qualification value of the relevant curriculum vitae for the\nrecommendation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 19:29:26 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Alanoca", "Honorio Apaza", ""], ["Vidal", "Americo A. Rubin de Celis", ""], ["Saire", "Josimar Edinson Chire", ""]]}, {"id": "2007.11057", "submitter": "Mingxuan Chen", "authors": "Mingxuan Chen, Ning Wang, K.P. Subbalakshmi", "title": "Explainable Rumor Detection using Inter and Intra-feature Attention\n  Networks", "comments": "14 pages, 6 figures, TrueFact2020(KDD2020 workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With social media becoming ubiquitous, information consumption from this\nmedia has also increased. However, one of the serious problems that have\nemerged with this increase, is the propagation of rumors. Therefore, rumor\nidentification is a very critical task with significant implications to\neconomy, democracy as well as public health and safety. We tackle the problem\nof automated detection of rumors in social media in this paper by designing a\nmodular explainable architecture that uses both latent and handcrafted features\nand can be expanded to as many new classes of features as desired. This\napproach will allow the end user to not only determine whether the piece of\ninformation on the social media is real of a rumor, but also give explanations\non why the algorithm arrived at its conclusion. Using attention mechanisms, we\nare able to interpret the relative importance of each of these features as well\nas the relative importance of the feature classes themselves. The advantage of\nthis approach is that the architecture is expandable to more handcrafted\nfeatures as they become available and also to conduct extensive testing to\ndetermine the relative influences of these features in the final decision.\nExtensive experimentation on popular datasets and benchmarking against eleven\ncontemporary algorithms, show that our approach performs significantly better\nin terms of F-score and accuracy while also being interpretable.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 19:35:39 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Chen", "Mingxuan", ""], ["Wang", "Ning", ""], ["Subbalakshmi", "K. P.", ""]]}, {"id": "2007.11073", "submitter": "Muhammad Khalifa", "authors": "Muhammad Khalifa and Aminul Islam", "title": "Will Your Forthcoming Book be Successful? Predicting Book Success with\n  CNN and Readability Scores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the potential success of a book in advance is vital in many\napplications. This could help both publishers and readers in their decision\nmaking process whether or not a book is worth publishing and reading,\nrespectively. This prediction could also help authors decide whether a book\ndraft is good enough to send to a publisher. We propose a model that leverages\nConvolutional Neural Networks along with readability indices. Unlike previous\nmethods, our method includes no count-based, lexical, or syntactic hand-crafted\nfeatures. Instead, we make use of a pre-trained sentence encoder to encode the\nbook sentences. We highlight the connection between this task and book genre\nidentification by showing that embeddings that are good at capturing the\nseparability of book genres are better for the book success prediction task. We\nalso show that only the first 1K sentences are good enough to predict the\nsuccessability of books. Our proposed model outperforms strong baselines on\nthis task by as large as 6.4% F1-score.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 20:11:18 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Khalifa", "Muhammad", ""], ["Islam", "Aminul", ""]]}, {"id": "2007.11171", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu, Chang-Ting Chu, Wei-Ting Chang, and Ti-Yong Zheng", "title": "When Classical Chinese Meets Machine Learning: Explaining the Relative\n  Performances of Word and Sentence Segmentation Tasks", "comments": "4 pages, 1 figure, 2 tables, 2020 International Conference on Digital\n  Humanities (Alliance of Digital Humanities Organizations, ADHO)", "journal-ref": null, "doi": "10.17613/r3kx-ng78", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three major text sources about the Tang Dynasty of China in our\nexperiments that aim to segment text written in classical Chinese. These\ncorpora include a collection of Tang Tomb Biographies, the New Tang Book, and\nthe Old Tang Book. We show that it is possible to achieve satisfactory\nsegmentation results with the deep learning approach. More interestingly, we\nfound that some of the relative superiority that we observed among different\ndesigns of experiments may be explainable. The relative relevance among the\ntraining corpora provides hints/explanation for the observed differences in\nsegmentation results that were achieved when we employed different combinations\nof corpora to train the classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 02:42:01 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Chu", "Chang-Ting", ""], ["Chang", "Wei-Ting", ""], ["Zheng", "Ti-Yong", ""]]}, {"id": "2007.11189", "submitter": "Madhura Jayaratne", "authors": "Madhura Jayaratne and Buddhi Jayatilleke", "title": "Predicting Job-Hopping Motive of Candidates Using Answers to Open-ended\n  Interview Questions", "comments": "JCSS version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant proportion of voluntary employee turnover includes people who\nfrequently move from job to job, known as job-hopping. Our work shows that\nlanguage used in responding to interview questions on past behaviour and\nsituational judgement is predictive of job-hopping motive as measured by the\nJob-Hopping Motives (JHM) Scale. The study is based on responses from over\n45,000 job applicants who completed an online chat interview and self-rated\nthemselves on JHM Scale. Five different methods of text representation were\nevaluated, namely four open-vocabulary approaches (TF-IDF, LDA, Glove word\nembeddings and Doc2Vec document embeddings) and one closed-vocabulary approach\n(LIWC). The Glove embeddings provided the best results with a correlation of r\n= 0.35 between sequences of words used and the JHM Scale. Further analysis also\nshowed a correlation of r = 0.25 between language-based job-hopping motive and\nthe personality trait Openness to experience and a correlation of r = -0.09\nwith the trait Agreeableness.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 03:41:32 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 04:02:41 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Jayaratne", "Madhura", ""], ["Jayatilleke", "Buddhi", ""]]}, {"id": "2007.11198", "submitter": "Austin Silveria", "authors": "Austin Silveria", "title": "Exploratory Search with Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploratory search aims to guide users through a corpus rather than\npinpointing exact information. We propose an exploratory search system based on\nhierarchical clusters and document summaries using sentence embeddings. With\nsentence embeddings, we represent documents as the mean of their embedded\nsentences, extract summaries containing sentences close to this document\nrepresentation and extract keyphrases close to the document representation. To\nevaluate our search system, we scrape our personal search history over the past\nyear and report our experience with the system. We then discuss motivating use\ncases of an exploratory search system of this nature and conclude with possible\ndirections of future work.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 04:46:54 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Silveria", "Austin", ""]]}, {"id": "2007.11201", "submitter": "Vishal Keswani", "authors": "Vishal Keswani, Sakshi Singh, Ashutosh Modi", "title": "IITK at the FinSim Task: Hypernym Detection in Financial Domain via\n  Context-Free and Contextualized Word Embeddings", "comments": "6 pages, 1 figure, 4 tables. Accepted at the Second Workshop on\n  Financial Technology and Natural Language Processing (FinNLP-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our approaches for the FinSim 2020 shared task on\n\"Learning Semantic Representations for the Financial Domain\". The goal of this\ntask is to classify financial terms into the most relevant hypernym (or\ntop-level) concept in an external ontology. We leverage both context-dependent\nand context-independent word embeddings in our analysis. Our systems deploy\nWord2vec embeddings trained from scratch on the corpus (Financial Prospectus in\nEnglish) along with pre-trained BERT embeddings. We divide the test dataset\ninto two subsets based on a domain rule. For one subset, we use unsupervised\ndistance measures to classify the term. For the second subset, we use simple\nsupervised classifiers like Naive Bayes, on top of the embeddings, to arrive at\na final prediction. Finally, we combine both the results. Our system ranks 1st\nbased on both the metrics, i.e., mean rank and accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 04:56:23 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Keswani", "Vishal", ""], ["Singh", "Sakshi", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.11314", "submitter": "Nicole Peinelt", "authors": "Nicole Peinelt, Dong Nguyen and Maria Liakata", "title": "Better Early than Late: Fusing Topics with Word Embeddings for Neural\n  Question Paraphrase Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question paraphrase identification is a key task in Community Question\nAnswering (CQA) to determine if an incoming question has been previously asked.\nMany current models use word embeddings to identify duplicate questions, but\nthe use of topic models in feature-engineered systems suggests that they can be\nhelpful for this task, too. We therefore propose two ways of merging topics\nwith word embeddings (early vs. late fusion) in a new neural architecture for\nquestion paraphrase identification. Our results show that our system\noutperforms neural baselines on multiple CQA datasets, while an ablation study\nhighlights the importance of topics and especially early topic-embedding fusion\nin our architecture.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 10:09:26 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Peinelt", "Nicole", ""], ["Nguyen", "Dong", ""], ["Liakata", "Maria", ""]]}, {"id": "2007.11348", "submitter": "Ori Shapira", "authors": "Ori Shapira and Ran Levy", "title": "Massive Multi-Document Summarization of Product Reviews with Weak\n  Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product reviews summarization is a type of Multi-Document Summarization (MDS)\ntask in which the summarized document sets are often far larger than in\ntraditional MDS (up to tens of thousands of reviews). We highlight this\ndifference and coin the term \"Massive Multi-Document Summarization\" (MMDS) to\ndenote an MDS task that involves hundreds of documents or more. Prior work on\nproduct reviews summarization considered small samples of the reviews, mainly\ndue to the difficulty of handling massive document sets. We show that\nsummarizing small samples can result in loss of important information and\nprovide misleading evaluation results. We propose a schema for summarizing a\nmassive set of reviews on top of a standard summarization algorithm. Since\nwriting large volumes of reference summaries needed for advanced neural network\nmodels is impractical, our solution relies on weak supervision. Finally, we\npropose an evaluation scheme that is based on multiple crowdsourced reference\nsummaries and aims to capture the massive review collection. We show that an\ninitial implementation of our schema significantly improves over several\nbaselines in ROUGE scores, and exhibits strong coherence in a manual linguistic\nquality assessment.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 11:22:57 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Shapira", "Ori", ""], ["Levy", "Ran", ""]]}, {"id": "2007.11381", "submitter": "Carlos Ramisch", "authors": "Caroline Pasquer (1), Agata Savary (1), Jean-Yves Antoine (1), Carlos\n  Ramisch (2), Nicolas Labroche (1), Arnaud Giacometti (1) ((1) University of\n  Tours, France, (2) Aix Marseille Univ, Universit\\'e de Toulon, CNRS, LIS,\n  Marseille, France)", "title": "To Be or Not To Be a Verbal Multiword Expression: A Quest for\n  Discriminating Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic identification of mutiword expressions (MWEs) is a pre-requisite\nfor semantically-oriented downstream applications. This task is challenging\nbecause MWEs, especially verbal ones (VMWEs), exhibit surface variability.\nHowever, this variability is usually more restricted than in regular (non-VMWE)\nconstructions, which leads to various variability profiles. We use this fact to\ndetermine the optimal set of features which could be used in a supervised\nclassification setting to solve a subproblem of VMWE identification: the\nidentification of occurrences of previously seen VMWEs. Surprisingly, a simple\ncustom frequency-based feature selection method proves more efficient than\nother standard methods such as Chi-squared test, information gain or decision\ntrees. An SVM classifier using the optimal set of only 6 features outperforms\nthe best systems from a recent shared task on the French seen data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 12:47:11 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Pasquer", "Caroline", ""], ["Savary", "Agata", ""], ["Antoine", "Jean-Yves", ""], ["Ramisch", "Carlos", ""], ["Labroche", "Nicolas", ""], ["Giacometti", "Arnaud", ""]]}, {"id": "2007.11464", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg, Barbara McGillivray, Simon Hengchen, Haim\n  Dubossarsky, Nina Tahmasebi", "title": "SemEval-2020 Task 1: Unsupervised Lexical Semantic Change Detection", "comments": "SemEval@COLING2020, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lexical Semantic Change detection, i.e., the task of identifying words that\nchange meaning over time, is a very active research area, with applications in\nNLP, lexicography, and linguistics. Evaluation is currently the most pressing\nproblem in Lexical Semantic Change detection, as no gold standards are\navailable to the community, which hinders progress. We present the results of\nthe first shared task that addresses this gap by providing researchers with an\nevaluation framework and manually annotated, high-quality datasets for English,\nGerman, Latin, and Swedish. 33 teams submitted 186 systems, which were\nevaluated on two subtasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 14:37:42 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 23:06:23 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["McGillivray", "Barbara", ""], ["Hengchen", "Simon", ""], ["Dubossarsky", "Haim", ""], ["Tahmasebi", "Nina", ""]]}, {"id": "2007.11648", "submitter": "Mittul Singh", "authors": "Mittul Singh, Peter Smit, Sami Virpioja, Mikko Kurimo", "title": "Effects of Language Relatedness for Cross-lingual Transfer Learning in\n  Character-Based Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-based Neural Network Language Models (NNLM) have the advantage of\nsmaller vocabulary and thus faster training times in comparison to NNLMs based\non multi-character units. However, in low-resource scenarios, both the\ncharacter and multi-character NNLMs suffer from data sparsity. In such\nscenarios, cross-lingual transfer has improved multi-character NNLM performance\nby allowing information transfer from a source to the target language. In the\nsame vein, we propose to use cross-lingual transfer for character NNLMs applied\nto low-resource Automatic Speech Recognition (ASR). However, applying\ncross-lingual transfer to character NNLMs is not as straightforward. We observe\nthat relatedness of the source language plays an important role in\ncross-lingual pretraining of character NNLMs. We evaluate this aspect on ASR\ntasks for two target languages: Finnish (with English and Estonian as source)\nand Swedish (with Danish, Norwegian, and English as source). Prior work has\nobserved no difference between using the related or unrelated language for\nmulti-character NNLMs. We, however, show that for character-based NNLMs, only\npretraining with a related language improves the ASR performance, and using an\nunrelated language may deteriorate it. We also observe that the benefits are\nlarger when there is much lesser target data than source data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 19:52:34 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Singh", "Mittul", ""], ["Smit", "Peter", ""], ["Virpioja", "Sami", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2007.11668", "submitter": "Bo Wu", "authors": "Bo Wu, Haoyu Qin, Alireza Zareian, Carl Vondrick, Shih-Fu Chang", "title": "Analogical Reasoning for Visually Grounded Language Acquisition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children acquire language subconsciously by observing the surrounding world\nand listening to descriptions. They can discover the meaning of words even\nwithout explicit language knowledge, and generalize to novel compositions\neffortlessly. In this paper, we bring this ability to AI, by studying the task\nof Visually grounded Language Acquisition (VLA). We propose a multimodal\ntransformer model augmented with a novel mechanism for analogical reasoning,\nwhich approximates novel compositions by learning semantic mapping and\nreasoning operations from previously seen compositions. Our proposed method,\nAnalogical Reasoning Transformer Networks (ARTNet), is trained on raw\nmultimedia data (video frames and transcripts), and after observing a set of\ncompositions such as \"washing apple\" or \"cutting carrot\", it can generalize and\nrecognize new compositions in new video frames, such as \"washing carrot\" or\n\"cutting apple\". To this end, ARTNet refers to relevant instances in the\ntraining data and uses their visual features and captions to establish\nanalogies with the query image. Then it chooses the suitable verb and noun to\ncreate a new composition that describes the new image best. Extensive\nexperiments on an instructional video dataset demonstrate that the proposed\nmethod achieves significantly better generalization capability and recognition\naccuracy compared to state-of-the-art transformer models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 20:51:58 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Wu", "Bo", ""], ["Qin", "Haoyu", ""], ["Zareian", "Alireza", ""], ["Vondrick", "Carl", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "2007.11690", "submitter": "Aditya Mogadala", "authors": "Aditya Mogadala and Xiaoyu Shen and Dietrich Klakow", "title": "Integrating Image Captioning with Rule-based Entity Masking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an image, generating its natural language description (i.e., caption)\nis a well studied problem. Approaches proposed to address this problem usually\nrely on image features that are difficult to interpret. Particularly, these\nimage features are subdivided into global and local features, where global\nfeatures are extracted from the global representation of the image, while local\nfeatures are extracted from the objects detected locally in an image. Although,\nlocal features extract rich visual information from the image, existing models\ngenerate captions in a blackbox manner and humans have difficulty interpreting\nwhich local objects the caption is aimed to represent. Hence in this paper, we\npropose a novel framework for the image captioning with an explicit object\n(e.g., knowledge graph entity) selection process while still maintaining its\nend-to-end training ability. The model first explicitly selects which local\nentities to include in the caption according to a human-interpretable mask,\nthen generate proper captions by attending to selected entities. Experiments\nconducted on the MSCOCO dataset demonstrate that our method achieves good\nperformance in terms of the caption quality and diversity with a more\ninterpretable generating process than previous counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 21:27:12 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mogadala", "Aditya", ""], ["Shen", "Xiaoyu", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2007.11756", "submitter": "Swati Padhee", "authors": "Swati Padhee (1), Tanay Kumar Saha (2), Joel Tetreault (2), and\n  Alejandro Jaimes (2) ((1) Wright State University, Dayton, OH, (2) Dataminr\n  Inc., New York, NY)", "title": "Clustering of Social Media Messages for Humanitarian Aid Response during\n  Crisis", "comments": "6 pages, 1 figure. Research work was done while Swati was interning\n  at Dataminr Inc. and presented at the AI for Social Good, Harvard CRCS\n  Workshop 2020 (https://aiforgood2020.github.io)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has quickly grown into an essential tool for people to\ncommunicate and express their needs during crisis events. Prior work in\nanalyzing social media data for crisis management has focused primarily on\nautomatically identifying actionable (or, informative) crisis-related messages.\nIn this work, we show that recent advances in Deep Learning and Natural\nLanguage Processing outperform prior approaches for the task of classifying\ninformativeness and encourage the field to adopt them for their research or\neven deployment. We also extend these methods to two sub-tasks of\ninformativeness and find that the Deep Learning methods are effective here as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 02:18:05 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Padhee", "Swati", ""], ["Saha", "Tanay Kumar", ""], ["Tetreault", "Joel", ""], ["Jaimes", "Alejandro", ""]]}, {"id": "2007.11768", "submitter": "Mansi Ranjit Mane", "authors": "Mansi Ranjit Mane, Shashank Kedia, Aditya Mantha, Stephen Guo, Kannan\n  Achan", "title": "Product Title Generation for Conversational Systems using BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through recent advancements in speech technology and introduction of smart\ndevices, such as Amazon Alexa and Google Home, increasing number of users are\ninteracting with applications through voice. E-commerce companies typically\ndisplay short product titles on their webpages, either human-curated or\nalgorithmically generated, when brevity is required, but these titles are\ndissimilar from natural spoken language. For example, \"Lucky Charms Gluten Free\nBreak-fast Cereal, 20.5 oz a box Lucky Charms Gluten Free\" is acceptable to\ndisplay on a webpage, but \"a 20.5 ounce box of lucky charms gluten free cereal\"\nis easier to comprehend over a conversational system. As compared to display\ndevices, where images and detailed product information can be presented to\nusers, short titles for products are necessary when interfacing with voice\nassistants. We propose a sequence-to-sequence approach using BERT to generate\nshort, natural, spoken language titles from input web titles. Our extensive\nexperiments on a real-world industry dataset and human evaluation of model\noutputs, demonstrate that BERT summarization outperforms comparable baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 03:15:19 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Mane", "Mansi Ranjit", ""], ["Kedia", "Shashank", ""], ["Mantha", "Aditya", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""]]}, {"id": "2007.11794", "submitter": "Kyungmin Lee", "authors": "Kyungmin Lee, Chiyoun Park, Ilhwan Kim, Namhoon Kim, Jaewon Lee", "title": "Applying GPGPU to Recurrent Neural Network Language Model based Fast\n  Network Search in the Real-Time LVCSR", "comments": "4 pages, 2 figures, Interspeech2015(Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network Language Models (RNNLMs) have started to be used in\nvarious fields of speech recognition due to their outstanding performance.\nHowever, the high computational complexity of RNNLMs has been a hurdle in\napplying the RNNLM to a real-time Large Vocabulary Continuous Speech\nRecognition (LVCSR). In order to accelerate the speed of RNNLM-based network\nsearches during decoding, we apply the General Purpose Graphic Processing Units\n(GPGPUs). This paper proposes a novel method of applying GPGPUs to RNNLM-based\ngraph traversals. We have achieved our goal by reducing redundant computations\non CPUs and amount of transfer between GPGPUs and CPUs. The proposed approach\nwas evaluated on both WSJ corpus and in-house data. Experiments shows that the\nproposed approach achieves the real-time speed in various circumstances while\nmaintaining the Word Error Rate (WER) to be relatively 10% lower than that of\nn-gram models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 05:15:14 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Lee", "Kyungmin", ""], ["Park", "Chiyoun", ""], ["Kim", "Ilhwan", ""], ["Kim", "Namhoon", ""], ["Lee", "Jaewon", ""]]}, {"id": "2007.11865", "submitter": "Kathleen Siminyu", "authors": "Kathleen Siminyu, Sackey Freshia, Jade Abbott, Vukosi Marivate", "title": "AI4D -- African Language Dataset Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As language and speech technologies become more advanced, the lack of\nfundamental digital resources for African languages, such as data, spell\ncheckers and Part of Speech taggers, means that the digital divide between\nthese languages and others keeps growing. This work details the organisation of\nthe AI4D - African Language Dataset Challenge, an effort to incentivize the\ncreation, organization and discovery of African language datasets through a\ncompetitive challenge. We particularly encouraged the submission of annotated\ndatasets which can be used for training task-specific supervised machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:48:06 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Siminyu", "Kathleen", ""], ["Freshia", "Sackey", ""], ["Abbott", "Jade", ""], ["Marivate", "Vukosi", ""]]}, {"id": "2007.11888", "submitter": "Siyu Huang", "authors": "Tao Jin, Siyu Huang, Ming Chen, Yingming Li, Zhongfei Zhang", "title": "SBAT: Video Captioning with Sparse Boundary-Aware Transformer", "comments": "Appearing at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the problem of applying the transformer structure\nto video captioning effectively. The vanilla transformer is proposed for\nuni-modal language generation task such as machine translation. However, video\ncaptioning is a multimodal learning problem, and the video features have much\nredundancy between different time steps. Based on these concerns, we propose a\nnovel method called sparse boundary-aware transformer (SBAT) to reduce the\nredundancy in video representation. SBAT employs boundary-aware pooling\noperation for scores from multihead attention and selects diverse features from\ndifferent scenarios. Also, SBAT includes a local correlation scheme to\ncompensate for the local information loss brought by sparse operation. Based on\nSBAT, we further propose an aligned cross-modal encoding scheme to boost the\nmultimodal interaction. Experimental results on two benchmark datasets show\nthat SBAT outperforms the state-of-the-art methods under most of the metrics.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 09:57:25 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Jin", "Tao", ""], ["Huang", "Siyu", ""], ["Chen", "Ming", ""], ["Li", "Yingming", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "2007.11949", "submitter": "Konstantinos Perifanos", "authors": "Konstantinos Perifanos, Eirini Florou, Dionysis Goutsos", "title": "Deep Learning based, end-to-end metaphor detection in Greek language\n  with Recurrent and Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents and benchmarks a number of end-to-end Deep Learning based\nmodels for metaphor detection in Greek. We combine Convolutional Neural\nNetworks and Recurrent Neural Networks with representation learning to bear on\nthe metaphor detection problem for the Greek language. The models presented\nachieve exceptional accuracy scores, significantly improving the previous state\nof the art results, which had already achieved accuracy 0.82. Furthermore, no\nspecial preprocessing, feature engineering or linguistic knowledge is used in\nthis work. The methods presented achieve accuracy of 0.92 and F-score 0.92 with\nConvolutional Neural Networks (CNNs) and bidirectional Long Short Term Memory\nnetworks (LSTMs). Comparable results of 0.91 accuracy and 0.91 F-score are also\nachieved with bidirectional Gated Recurrent Units (GRUs) and Convolutional\nRecurrent Neural Nets (CRNNs). The models are trained and evaluated only on the\nbasis of the training tuples, the sentences and their labels. The outcome is a\nstate of the art collection of metaphor detection models, trained on limited\nlabelled resources, which can be extended to other languages and similar tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 12:02:40 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Perifanos", "Konstantinos", ""], ["Florou", "Eirini", ""], ["Goutsos", "Dionysis", ""]]}, {"id": "2007.12053", "submitter": "Szymon Talaga", "authors": "Andreia Sofia Teixeira, Szymon Talaga, Trevor James Swanson, Massimo\n  Stella", "title": "Revealing semantic and emotional structure of suicide notes with\n  cognitive network science", "comments": "Significantly revised version (in particular balance analysis); 22\n  pages (with SI); 5 figures; 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding the cognitive and emotional perceptions of people who commit\nsuicide is one of the most sensitive scientific challenges. There are\ncircumstances where people feel the need to leave something written, an\nartifact where they express themselves, registering their last words and\nfeelings. These suicide notes are of utmost importance for better understanding\nthe psychology of suicidal ideation. This work gives structure to the\nlinguistic content of suicide notes, revealing interconnections between\ncognitive and emotional states of people who committed suicide. We build upon\ncognitive network science, psycholinguistics and semantic frame theory to\nintroduce a network representation of the mindset expressed in suicide notes.\nOur cognitive network representation enables the quantitative analysis of the\nlanguage in suicide notes through structural balance theory, semantic\nprominence and emotional profiling. Our results indicate that the emotional\nsyntax connecting positively- and negatively-valenced terms gives rise to a\ndegree of structural balance that is significantly higher than null models\nwhere the affective structure was randomized. We show that suicide notes are\naffectively compartmentalized such that positive concepts tend to cluster\ntogether and dominate the overall network structure. A key positive concept is\n\"love\", which integrates information relating the self to others in ways that\nare semantically prominent across suicide notes. The emotions populating the\nsemantic frame of \"love\" combine joy and trust with anticipation and sadness,\nwhich connects with psychological theories about meaning-making and narrative\npsychology. Our results open new ways for understanding the structure of\ngenuine suicide notes informing future research for suicide prevention.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:11:32 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 21:01:36 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 21:07:20 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Teixeira", "Andreia Sofia", ""], ["Talaga", "Szymon", ""], ["Swanson", "Trevor James", ""], ["Stella", "Massimo", ""]]}, {"id": "2007.12076", "submitter": "Aditya Srivastava", "authors": "Aditya Srivastava, V. Harsha Vardhan", "title": "HCMS at SemEval-2020 Task 9: A Neural Approach to Sentiment Analysis for\n  Code-Mixed Texts", "comments": "6 pages, 2 figures, 4 tables, math equations, to be published in the\n  proceedings of the 14th International Workshop on Semantic Evaluation\n  (SemEval) 2020, Association for Computational Linguistics (ACL). Code for the\n  paper is available at https://github.com/IamAdiSri/hcms-semeval20 . Data and\n  task description is available at\n  https://competitions.codalab.org/competitions/20654", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems involving code-mixed language are often plagued by a lack of\nresources and an absence of materials to perform sophisticated transfer\nlearning with. In this paper we describe our submission to the Sentimix\nHindi-English task involving sentiment classification of code-mixed texts, and\nwith an F1 score of 67.1%, we demonstrate that simple convolution and attention\nmay well produce reasonable results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:39:53 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Srivastava", "Aditya", ""], ["Vardhan", "V. Harsha", ""]]}, {"id": "2007.12081", "submitter": "Thoudam Doren Singh", "authors": "Subhra Jyoti Baroi, Nivedita Singh, Ringki Das, Thoudam Doren Singh", "title": "NITS-Hinglish-SentiMix at SemEval-2020 Task 9: Sentiment Analysis For\n  Code-Mixed Social Media Text Using an Ensemble Model", "comments": "In Proceedings of the 14th International Workshop on Semantic\n  Evaluation (SemEval-2020), Barcelona, Spain, December. Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment Analysis is the process of deciphering what a sentence emotes and\nclassifying them as either positive, negative, or neutral. In recent times,\nIndia has seen a huge influx in the number of active social media users and\nthis has led to a plethora of unstructured text data. Since the Indian\npopulation is generally fluent in both Hindi and English, they end up\ngenerating code-mixed Hinglish social media text i.e. the expressions of Hindi\nlanguage, written in the Roman script alongside other English words. The\nability to adequately comprehend the notions in these texts is truly necessary.\nOur team, rns2020 participated in Task 9 at SemEval2020 intending to design a\nsystem to carry out the sentiment analysis of code-mixed social media text.\nThis work proposes a system named NITS-Hinglish-SentiMix to viably complete the\nsentiment analysis of such code-mixed Hinglish text. The proposed framework has\nrecorded an F-Score of 0.617 on the test data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:45:12 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 17:55:18 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Baroi", "Subhra Jyoti", ""], ["Singh", "Nivedita", ""], ["Das", "Ringki", ""], ["Singh", "Thoudam Doren", ""]]}, {"id": "2007.12144", "submitter": "Oladapo Oyebode", "authors": "Oladapo Oyebode, Chinenye Ndulue, Ashfaq Adib, Dinesh Mulchandani,\n  Banuchitra Suruliraj, Fidelia Anulika Orji, Christine Chambers, Sandra Meier,\n  and Rita Orji", "title": "Health, Psychosocial, and Social issues emanating from COVID-19 pandemic\n  based on Social Media Comments using Natural Language Processing", "comments": null, "journal-ref": "JMIR Medical Informatics. 2021. 9(4):e22734", "doi": "10.2196/22734", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has caused a global health crisis that affects many\naspects of human lives. In the absence of vaccines and antivirals, several\nbehavioural change and policy initiatives, such as physical distancing, have\nbeen implemented to control the spread of the coronavirus. Social media data\ncan reveal public perceptions toward how governments and health agencies across\nthe globe are handling the pandemic, as well as the impact of the disease on\npeople regardless of their geographic locations in line with various factors\nthat hinder or facilitate the efforts to control the spread of the pandemic\nglobally. This paper aims to investigate the impact of the COVID-19 pandemic on\npeople globally using social media data. We apply natural language processing\n(NLP) and thematic analysis to understand public opinions, experiences, and\nissues with respect to the COVID-19 pandemic using social media data. First, we\ncollect over 47 million COVID-19-related comments from Twitter, Facebook,\nYouTube, and three online discussion forums. Second, we perform data\npreprocessing which involves applying NLP techniques to clean and prepare the\ndata for automated theme extraction. Third, we apply context-aware NLP approach\nto extract meaningful keyphrases or themes from over 1 million randomly\nselected comments, as well as compute sentiment scores for each theme and\nassign sentiment polarity based on the scores using lexicon-based technique.\nFourth, we categorize related themes into broader themes. A total of 34\nnegative themes emerged, out of which 15 are health-related issues,\npsychosocial issues, and social issues related to the COVID-19 pandemic from\nthe public perspective. In addition, 20 positive themes emerged from our\nresults. Finally, we recommend interventions that can help address the negative\nissues based on the positive themes and other remedial ideas rooted in\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 17:19:50 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Oyebode", "Oladapo", ""], ["Ndulue", "Chinenye", ""], ["Adib", "Ashfaq", ""], ["Mulchandani", "Dinesh", ""], ["Suruliraj", "Banuchitra", ""], ["Orji", "Fidelia Anulika", ""], ["Chambers", "Christine", ""], ["Meier", "Sandra", ""], ["Orji", "Rita", ""]]}, {"id": "2007.12212", "submitter": "Anurag Roy", "authors": "Anurag Roy, Vinay Kumar Verma, Kripabandhu Ghosh, Saptarshi Ghosh", "title": "ZSCRGAN: A GAN-based Expectation Maximization Model for Zero-Shot\n  Retrieval of Images from Textual Descriptions", "comments": "Accepted in CIKM-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing algorithms for cross-modal Information Retrieval are based on a\nsupervised train-test setup, where a model learns to align the mode of the\nquery (e.g., text) to the mode of the documents (e.g., images) from a given\ntraining set. Such a setup assumes that the training set contains an exhaustive\nrepresentation of all possible classes of queries. In reality, a retrieval\nmodel may need to be deployed on previously unseen classes, which implies a\nzero-shot IR setup. In this paper, we propose a novel GAN-based model for\nzero-shot text to image retrieval. When given a textual description as the\nquery, our model can retrieve relevant images in a zero-shot setup. The\nproposed model is trained using an Expectation-Maximization framework.\nExperiments on multiple benchmark datasets show that our proposed model\ncomfortably outperforms several state-of-the-art zero-shot text to image\nretrieval models, as well as zero-shot classification and hashing models\nsuitably used for retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 18:50:03 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 11:57:35 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 11:41:12 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Roy", "Anurag", ""], ["Verma", "Vinay Kumar", ""], ["Ghosh", "Kripabandhu", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "2007.12223", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang,\n  Zhangyang Wang, Michael Carbin", "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing (NLP), enormous pre-trained models like BERT\nhave become the standard starting point for training on a range of downstream\ntasks, and similar trends are emerging in other areas of deep learning. In\nparallel, work on the lottery ticket hypothesis has shown that models for NLP\nand computer vision contain smaller matching subnetworks capable of training in\nisolation to full accuracy and transferring to other tasks. In this work, we\ncombine these observations to assess whether such trainable, transferrable\nsubnetworks exist in pre-trained BERT models. For a range of downstream tasks,\nwe indeed find matching subnetworks at 40% to 90% sparsity. We find these\nsubnetworks at (pre-trained) initialization, a deviation from prior NLP\nresearch where they emerge only after some amount of training. Subnetworks\nfound on the masked language modeling task (the same task used to pre-train the\nmodel) transfer universally; those found on other tasks transfer in a limited\nfashion if at all. As large-scale pre-training becomes an increasingly central\nparadigm in deep learning, our results demonstrate that the main lottery ticket\nobservations remain relevant in this context. Codes available at\nhttps://github.com/VITA-Group/BERT-Tickets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 19:35:39 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 20:10:29 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Tianlong", ""], ["Frankle", "Jonathan", ""], ["Chang", "Shiyu", ""], ["Liu", "Sijia", ""], ["Zhang", "Yang", ""], ["Wang", "Zhangyang", ""], ["Carbin", "Michael", ""]]}, {"id": "2007.12374", "submitter": "Siddhant Arora", "authors": "Siddhant Arora", "title": "A Survey on Graph Neural Networks for Knowledge Graph Completion", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs are increasingly becoming popular for a variety of\ndownstream tasks like Question Answering and Information Retrieval. However,\nthe Knowledge Graphs are often incomplete, thus leading to poor performance. As\na result, there has been a lot of interest in the task of Knowledge Base\nCompletion. More recently, Graph Neural Networks have been used to capture\nstructural information inherently stored in these Knowledge Graphs and have\nbeen shown to achieve SOTA performance across a variety of datasets. In this\nsurvey, we understand the various strengths and weaknesses of the proposed\nmethodology and try to find new exciting research problems in this area that\nrequire further investigation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 06:46:46 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Arora", "Siddhant", ""]]}, {"id": "2007.12390", "submitter": "Jaeyoul Shin", "authors": "Jaeyoul Shin, Taeuk Kim and Sang-goo Lee", "title": "IDS at SemEval-2020 Task 10: Does Pre-trained Language Model Know What\n  to Emphasize?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method that enables us to determine words that deserve to\nbe emphasized from written text in visual media, relying only on the\ninformation from the self-attention distributions of pre-trained language\nmodels (PLMs). With extensive experiments and analyses, we show that 1) our\nzero-shot approach is superior to a reasonable baseline that adopts TF-IDF and\nthat 2) there exist several attention heads in PLMs specialized for emphasis\nselection, confirming that PLMs are capable of recognizing important words in\nsentences.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 07:28:47 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Shin", "Jaeyoul", ""], ["Kim", "Taeuk", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2007.12432", "submitter": "Aina Gar\\'i Soler", "authors": "Aina Gar\\'i Soler, Marianna Apidianaki", "title": "MULTISEM at SemEval-2020 Task 3: Fine-tuning BERT for Lexical Meaning", "comments": "8 pages, 2 tables. Accepted at the 14th International Workshop on\n  Semantic Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the MULTISEM systems submitted to SemEval 2020 Task 3: Graded Word\nSimilarity in Context (GWSC). We experiment with injecting semantic knowledge\ninto pre-trained BERT models through fine-tuning on lexical semantic tasks\nrelated to GWSC. We use existing semantically annotated datasets and propose to\napproximate similarity through automatically generated lexical substitutes in\ncontext. We participate in both GWSC subtasks and address two languages,\nEnglish and Finnish. Our best English models occupy the third and fourth\npositions in the ranking for the two subtasks. Performance is lower for the\nFinnish models which are mid-ranked in the respective subtasks, highlighting\nthe important role of data availability for fine-tuning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 09:50:26 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Soler", "Aina Gar\u00ed", ""], ["Apidianaki", "Marianna", ""]]}, {"id": "2007.12544", "submitter": "Bertelt Braaksma", "authors": "Bertelt Braaksma, Richard Scholtens, Stan van Suijlekom, Remy Wang,\n  Ahmet \\\"Ust\\\"un", "title": "FiSSA at SemEval-2020 Task 9: Fine-tuned For Feelings", "comments": "In Proceedings of the 14th International Workshop on Semantic\n  Evaluation (SemEval-2020), Barcelona, Spain, December. Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present our approach for sentiment classification on\nSpanish-English code-mixed social media data in the SemEval-2020 Task 9. We\ninvestigate performance of various pre-trained Transformer models by using\ndifferent fine-tuning strategies. We explore both monolingual and multilingual\nmodels with the standard fine-tuning method. Additionally, we propose a custom\nmodel that we fine-tune in two steps: once with a language modeling objective,\nand once with a task-specific objective. Although two-step fine-tuning improves\nsentiment classification performance over the base model, the large\nmultilingual XLM-RoBERTa model achieves best weighted F1-score with 0.537 on\ndevelopment data and 0.739 on test data. With this score, our team jupitter\nplaced tenth overall in the competition.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 14:48:27 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 15:41:22 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 07:11:18 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Braaksma", "Bertelt", ""], ["Scholtens", "Richard", ""], ["van Suijlekom", "Stan", ""], ["Wang", "Remy", ""], ["\u00dcst\u00fcn", "Ahmet", ""]]}, {"id": "2007.12561", "submitter": "Sainik Mahata", "authors": "Avishek Garain, Sainik Kumar Mahata, Dipankar Das", "title": "JUNLP@SemEval-2020 Task 9:Sentiment Analysis of Hindi-English code mixed\n  data using Grid Search Cross Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-mixing is a phenomenon which arises mainly in multilingual societies.\nMultilingual people, who are well versed in their native languages and also\nEnglish speakers, tend to code-mix using English-based phonetic typing and the\ninsertion of anglicisms in their main language. This linguistic phenomenon\nposes a great challenge to conventional NLP domains such as Sentiment Analysis,\nMachine Translation, and Text Summarization, to name a few. In this work, we\nfocus on working out a plausible solution to the domain of Code-Mixed Sentiment\nAnalysis. This work was done as participation in the SemEval-2020 Sentimix\nTask, where we focused on the sentiment analysis of English-Hindi code-mixed\nsentences. our username for the submission was \"sainik.mahata\" and team name\nwas \"JUNLP\". We used feature extraction algorithms in conjunction with\ntraditional machine learning algorithms such as SVR and Grid Search in an\nattempt to solve the task. Our approach garnered an f1-score of 66.2\\% when\ntested using metrics prepared by the organizers of the task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:06:48 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 10:04:07 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Garain", "Avishek", ""], ["Mahata", "Sainik Kumar", ""], ["Das", "Dipankar", ""]]}, {"id": "2007.12569", "submitter": "Jenny Copara", "authors": "Jenny Copara and Nona Naderi and Julien Knafou and Patrick Ruch and\n  Douglas Teodoro", "title": "Named entity recognition in chemical patents using ensemble of\n  contextual language models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chemical patent documents describe a broad range of applications holding key\nreaction and compound information, such as chemical structure, reaction\nformulas, and molecular properties. These informational entities should be\nfirst identified in text passages to be utilized in downstream tasks. Text\nmining provides means to extract relevant information from chemical patents\nthrough information extraction techniques. As part of the Information\nExtraction task of the Cheminformatics Elsevier Melbourne University challenge,\nin this work we study the effectiveness of contextualized language models to\nextract reaction information in chemical patents. We assess transformer\narchitectures trained on a generic and specialised corpora to propose a new\nensemble model. Our best model, based on a majority ensemble approach, achieves\nan exact F1-score of 92.30% and a relaxed F1-score of 96.24%. The results show\nthat ensemble of contextualized language models can provide an effective method\nto extract information from chemical patents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:23:45 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:54:53 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Copara", "Jenny", ""], ["Naderi", "Nona", ""], ["Knafou", "Julien", ""], ["Ruch", "Patrick", ""], ["Teodoro", "Douglas", ""]]}, {"id": "2007.12603", "submitter": "Anup Anand Deshmukh", "authors": "Anup Anand Deshmukh and Udhav Sethi", "title": "IR-BERT: Leveraging BERT for Semantic Search in Background Linking for\n  News Articles", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes our two approaches for the background linking task of\nTREC 2020 News Track. The main objective of this task is to recommend a list of\nrelevant articles that the reader should refer to in order to understand the\ncontext and gain background information of the query article. Our first\napproach focuses on building an effective search query by combining weighted\nkeywords extracted from the query document and uses BM25 for retrieval. The\nsecond approach leverages the capability of SBERT (Nils Reimers et al.) to\nlearn contextual representations of the query in order to perform semantic\nsearch over the corpus. We empirically show that employing a language model\nbenefits our approach in understanding the context as well as the background of\nthe query article. The proposed approaches are evaluated on the TREC 2018\nWashington Post dataset and our best model outperforms the TREC median as well\nas the highest scoring model of 2018 in terms of the nDCG@5 metric. We further\npropose a diversity measure to evaluate the effectiveness of the various\napproaches in retrieving a diverse set of documents. This would potentially\nmotivate researchers to work on introducing diversity in their recommended\nlist. We have open sourced our implementation on Github and plan to submit our\nruns for the background linking task in TREC 2020.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 16:02:14 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Deshmukh", "Anup Anand", ""], ["Sethi", "Udhav", ""]]}, {"id": "2007.12626", "submitter": "Alexander Fabbri", "authors": "Alexander R. Fabbri, Wojciech Kry\\'sci\\'nski, Bryan McCann, Caiming\n  Xiong, Richard Socher, Dragomir Radev", "title": "SummEval: Re-evaluating Summarization Evaluation", "comments": "11 pages, 4 tables, 2 figures; pre-MIT Press publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scarcity of comprehensive up-to-date studies on evaluation metrics for\ntext summarization and the lack of consensus regarding evaluation protocols\ncontinue to inhibit progress. We address the existing shortcomings of\nsummarization evaluation methods along five dimensions: 1) we re-evaluate 14\nautomatic evaluation metrics in a comprehensive and consistent fashion using\nneural summarization model outputs along with expert and crowd-sourced human\nannotations, 2) we consistently benchmark 23 recent summarization models using\nthe aforementioned automatic evaluation metrics, 3) we assemble the largest\ncollection of summaries generated by models trained on the CNN/DailyMail news\ndataset and share it in a unified format, 4) we implement and share a toolkit\nthat provides an extensible and unified API for evaluating summarization models\nacross a broad range of automatic metrics, 5) we assemble and share the largest\nand most diverse, in terms of model types, collection of human judgments of\nmodel-generated summaries on the CNN/Daily Mail dataset annotated by both\nexpert judges and crowd-source workers. We hope that this work will help\npromote a more complete evaluation protocol for text summarization as well as\nadvance research in developing evaluation metrics that better correlate with\nhuman judgments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 16:25:19 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 15:34:55 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 21:34:55 GMT"}, {"version": "v4", "created": "Mon, 1 Feb 2021 19:56:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Fabbri", "Alexander R.", ""], ["Kry\u015bci\u0144ski", "Wojciech", ""], ["McCann", "Bryan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Radev", "Dragomir", ""]]}, {"id": "2007.12720", "submitter": "Xiaoxue Zang", "authors": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo\n  Zhang, Jindong Chen", "title": "MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections\n  and State Tracking Baselines", "comments": null, "journal-ref": "Proceedings of the 2nd Workshop on Natural Language Processing for\n  Conversational AI (2020) 109-117", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MultiWOZ is a well-known task-oriented dialogue dataset containing over\n10,000 annotated dialogues spanning 8 domains. It is extensively used as a\nbenchmark for dialogue state tracking. However, recent works have reported\npresence of substantial noise in the dialogue state annotations. MultiWOZ 2.1\nidentified and fixed many of these erroneous annotations and user utterances,\nresulting in an improved version of this dataset. This work introduces MultiWOZ\n2.2, which is a yet another improved version of this dataset. Firstly, we\nidentify and fix dialogue state annotation errors across 17.3% of the\nutterances on top of MultiWOZ 2.1. Secondly, we redefine the ontology by\ndisallowing vocabularies of slots with a large number of possible values (e.g.,\nrestaurant name, time of booking). In addition, we introduce slot span\nannotations for these slots to standardize them across recent models, which\npreviously used custom string matching heuristics to generate them. We also\nbenchmark a few state of the art dialogue state tracking models on the\ncorrected dataset to facilitate comparison for future work. In the end, we\ndiscuss best practices for dialogue data collection that can help avoid\nannotation errors.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 22:52:14 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zang", "Xiaoxue", ""], ["Rastogi", "Abhinav", ""], ["Sunkara", "Srinivas", ""], ["Gupta", "Raghav", ""], ["Zhang", "Jianguo", ""], ["Chen", "Jindong", ""]]}, {"id": "2007.12731", "submitter": "Colby Wise", "authors": "Colby Wise, Vassilis N. Ioannidis, Miguel Romero Calvo, Xiang Song,\n  George Price, Ninad Kulkarni, Ryan Brand, Parminder Bhatia, George Karypis", "title": "COVID-19 Knowledge Graph: Accelerating Information Retrieval and\n  Discovery for Scientific Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease (COVID-19) has claimed the lives of over 350,000\npeople and infected more than 6 million people worldwide. Several search\nengines have surfaced to provide researchers with additional tools to find and\nretrieve information from the rapidly growing corpora on COVID-19. These\nengines lack extraction and visualization tools necessary to retrieve and\ninterpret complex relations inherent to scientific literature. Moreover,\nbecause these engines mainly rely upon semantic information, their ability to\ncapture complex global relationships across documents is limited, which reduces\nthe quality of similarity-based article recommendations for users. In this\nwork, we present the COVID-19 Knowledge Graph (CKG), a heterogeneous graph for\nextracting and visualizing complex relationships between COVID-19 scientific\narticles. The CKG combines semantic information with document topological\ninformation for the application of similar document retrieval. The CKG is\nconstructed using the latent schema of the data, and then enriched with\nbiomedical entity information extracted from the unstructured text of articles\nusing scalable AWS technologies to form relations in the graph. Finally, we\npropose a document similarity engine that leverages low-dimensional graph\nembeddings from the CKG with semantic embeddings for similar article retrieval.\nAnalysis demonstrates the quality of relationships in the CKG and shows that it\ncan be used to uncover meaningful information in COVID-19 scientific articles.\nThe CKG helps power www.cord19.aws and is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 18:29:43 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Wise", "Colby", ""], ["Ioannidis", "Vassilis N.", ""], ["Calvo", "Miguel Romero", ""], ["Song", "Xiang", ""], ["Price", "George", ""], ["Kulkarni", "Ninad", ""], ["Brand", "Ryan", ""], ["Bhatia", "Parminder", ""], ["Karypis", "George", ""]]}, {"id": "2007.12733", "submitter": "Soroush Javdan", "authors": "Soroush Javdan, Taha Shangipour ataei and Behrouz Minaei-Bidgoli", "title": "IUST at SemEval-2020 Task 9: Sentiment Analysis for Code-Mixed Social\n  Media Text using Deep Neural Networks and Linear Baselines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment Analysis is a well-studied field of Natural Language Processing.\nHowever, the rapid growth of social media and noisy content within them poses\nsignificant challenges in addressing this problem with well-established methods\nand tools. One of these challenges is code-mixing, which means using different\nlanguages to convey thoughts in social media texts. Our group, with the name of\nIUST(username: TAHA), participated at the SemEval-2020 shared task 9 on\nSentiment Analysis for Code-Mixed Social Media Text, and we have attempted to\ndevelop a system to predict the sentiment of a given code-mixed tweet. We used\ndifferent preprocessing techniques and proposed to use different methods that\nvary from NBSVM to more complicated deep neural network models. Our best\nperforming method obtains an F1 score of 0.751 for the Spanish-English sub-task\nand 0.706 over the Hindi-English sub-task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 18:48:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Javdan", "Soroush", ""], ["ataei", "Taha Shangipour", ""], ["Minaei-Bidgoli", "Behrouz", ""]]}, {"id": "2007.12741", "submitter": "Matthias Sperber", "authors": "Matthias Sperber, Hendra Setiawan, Christian Gollan, Udhyakumar\n  Nallasamy, Matthias Paulik", "title": "Consistent Transcription and Translation of Speech", "comments": "Accepted at TACL (pre-MIT Press publication version); added dataset\n  link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional paradigm in speech translation starts with a speech\nrecognition step to generate transcripts, followed by a translation step with\nthe automatic transcripts as input. To address various shortcomings of this\nparadigm, recent work explores end-to-end trainable direct models that\ntranslate without transcribing. However, transcripts can be an indispensable\noutput in practical applications, which often display transcripts alongside the\ntranslations to users.\n  We make this common requirement explicit and explore the task of jointly\ntranscribing and translating speech. While high accuracy of transcript and\ntranslation are crucial, even highly accurate systems can suffer from\ninconsistencies between both outputs that degrade the user experience. We\nintroduce a methodology to evaluate consistency and compare several modeling\napproaches, including the traditional cascaded approach and end-to-end models.\nWe find that direct models are poorly suited to the joint\ntranscription/translation task, but that end-to-end models that feature a\ncoupled inference procedure are able to achieve strong consistency. We further\nintroduce simple techniques for directly optimizing for consistency, and\nanalyze the resulting trade-offs between consistency, transcription accuracy,\nand translation accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 19:17:26 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 07:57:57 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Sperber", "Matthias", ""], ["Setiawan", "Hendra", ""], ["Gollan", "Christian", ""], ["Nallasamy", "Udhyakumar", ""], ["Paulik", "Matthias", ""]]}, {"id": "2007.12750", "submitter": "Jiasen Lu", "authors": "Michael Cogswell, Jiasen Lu, Rishabh Jain, Stefan Lee, Devi Parikh,\n  Dhruv Batra", "title": "Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we develop visually grounded dialog agents that can efficiently adapt to\nnew tasks without forgetting how to talk to people? Such agents could leverage\na larger variety of existing data to generalize to new tasks, minimizing\nexpensive data collection and annotation. In this work, we study a setting we\ncall \"Dialog without Dialog\", which requires agents to develop visually\ngrounded dialog models that can adapt to new tasks without language level\nsupervision. By factorizing intention and language, our model minimizes\nlinguistic drift after fine-tuning for new tasks. We present qualitative\nresults, automated metrics, and human studies that all show our model can adapt\nto new tasks and maintain language quality. Baselines either fail to perform\nwell at new tasks or experience language drift, becoming unintelligible to\nhumans. Code has been made available at\nhttps://github.com/mcogswell/dialog_without_dialog\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 19:35:57 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cogswell", "Michael", ""], ["Lu", "Jiasen", ""], ["Jain", "Rishabh", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "2007.12770", "submitter": "David Yu-Tung Hui", "authors": "David Yu-Tung Hui, Maxime Chevalier-Boisvert, Dzmitry Bahdanau, Yoshua\n  Bengio", "title": "BabyAI 1.1", "comments": "9 pages, 1 figure, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BabyAI platform is designed to measure the sample efficiency of training\nan agent to follow grounded-language instructions. BabyAI 1.0 presents baseline\nresults of an agent trained by deep imitation or reinforcement learning. BabyAI\n1.1 improves the agent's architecture in three minor ways. This increases\nreinforcement learning sample efficiency by up to 3 times and improves\nimitation learning performance on the hardest level from 77 % to 90.4 %. We\nhope that these improvements increase the computational efficiency of BabyAI\nexperiments and help users design better agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 21:19:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hui", "David Yu-Tung", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2007.12913", "submitter": "Ilya Dimov", "authors": "Ilya Dimov, Vladislav Korzun and Ivan Smurov", "title": "NoPropaganda at SemEval-2020 Task 11: A Borrowed Approach to Sequence\n  Tagging and Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our contribution to SemEval-2020 Task 11: Detection Of\nPropaganda Techniques In News Articles. We start with simple LSTM baselines and\nmove to an autoregressive transformer decoder to predict long continuous\npropaganda spans for the first subtask. We also adopt an approach from relation\nextraction by enveloping spans mentioned above with special tokens for the\nsecond subtask of propaganda technique classification. Our models report an\nF-score of 44.6% and a micro-averaged F-score of 58.2% for those tasks\naccordingly.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 11:35:57 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Dimov", "Ilya", ""], ["Korzun", "Vladislav", ""], ["Smurov", "Ivan", ""]]}, {"id": "2007.12916", "submitter": "Naman Jain", "authors": "Naman Jain, Ankush Chauhan, Atharva Chewale, Ojas Mithbavkar, Ujjaval\n  Shah, Mayank Singh", "title": "Bollyrics: Automatic Lyrics Generator for Romanised Hindi", "comments": "Submitted to NLP4MusA Workshop, ISMIR'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Song lyrics convey a meaningful story in a creative manner with complex\nrhythmic patterns. Researchers have been successful in generating and analyisng\nlyrics for poetry and songs in English and Chinese. But there are no works\nwhich explore the Hindi language datasets. Given the popularity of Hindi songs\nacross the world and the ambiguous nature of romanized Hindi script, we propose\nBollyrics, an automatic lyric generator for romanized Hindi songs. We propose\nsimple techniques to capture rhyming patterns before and during the model\ntraining process in Hindi language. The dataset and codes are available\npublicly at https://github.com/lingo-iitgn/Bollyrics.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 12:02:26 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Jain", "Naman", ""], ["Chauhan", "Ankush", ""], ["Chewale", "Atharva", ""], ["Mithbavkar", "Ojas", ""], ["Shah", "Ujjaval", ""], ["Singh", "Mayank", ""]]}, {"id": "2007.12929", "submitter": "Christian Meurisch", "authors": "Bekir Bayrak, Florian Giger, Christian Meurisch", "title": "Insightful Assistant: AI-compatible Operation Graph Representations for\n  Enhancing Industrial Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in voice-controlled assistants paved the way into the consumer\nmarket. For professional or industrial use, the capabilities of such assistants\nare too limited or too time-consuming to implement due to the higher complexity\nof data, possible AI-based operations, and requests. In the light of these\ndeficits, this paper presents Insightful Assistant---a pipeline concept based\non a novel operation graph representation resulting from the intents detected.\nUsing a predefined set of semantically annotated (executable) functions, each\nnode of the operation graph is assigned to a function for execution. Besides\nbasic operations, such functions can contain artificial intelligence (AI) based\noperations (e.g., anomaly detection). The result is then visualized to the user\naccording to type and extracted user preferences in an automated way. We\nfurther collected a unique crowd-sourced set of 869 requests, each with four\ndifferent variants expected visualization, for an industrial dataset. The\nevaluation of our proof-of-concept prototype on this dataset shows its\nfeasibility: it achieves an accuracy of up to 95.0% (74.5%) for simple\n(complex) request detection with different variants and a top3-accuracy up to\n95.4% for data-/user-adaptive visualization.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 13:46:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bayrak", "Bekir", ""], ["Giger", "Florian", ""], ["Meurisch", "Christian", ""]]}, {"id": "2007.12946", "submitter": "Ted Pedersen", "authors": "Ted Pedersen", "title": "Duluth at SemEval-2020 Task 12: Offensive Tweet Identification in\n  English with Logistic Regression", "comments": "10 pages, To appear in the Proceedings of the 14th International\n  Workshop on Semantic Evaluation (SemEval--2020), December 12-13, 2020,\n  Barcelona (a COLING-2020 workshop, aka OffensEval--2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the Duluth systems that participated in SemEval--2020\nTask 12, Multilingual Offensive Language Identification in Social Media\n(OffensEval--2020). We participated in the three English language tasks. Our\nsystems provide a simple Machine Learning baseline using logistic regression.\nWe trained our models on the distantly supervised training data made available\nby the task organizers and used no other resources. As might be expected we did\nnot rank highly in the comparative evaluation: 79th of 85 in Task A, 34th of 43\nin Task B, and 24th of 39 in Task C. We carried out a qualitative analysis of\nour results and found that the class labels in the gold standard data are\nsomewhat noisy. We hypothesize that the extremely high accuracy (> 90%) of the\ntop ranked systems may reflect methods that learn the training data very well\nbut may not generalize to the task of identifying offensive language in\nEnglish. This analysis includes examples of tweets that despite being mildly\nredacted are still offensive.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 14:49:31 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pedersen", "Ted", ""]]}, {"id": "2007.12949", "submitter": "Ted Pedersen", "authors": "Ted Pedersen", "title": "Duluth at SemEval-2019 Task 6: Lexical Approaches to Identify and\n  Categorize Offensive Tweets", "comments": "7 pages, Appears in the Proceedings of the 13th International\n  Workshop on Semantic Eva luation (SemEval 2019), June 2019, pp. 593-599,\n  Minneapolis, MN (a NAACL-2019 workshop, aka OffenseEval--2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the Duluth systems that participated in SemEval--2019\nTask 6, Identifying and Categorizing Offensive Language in Social Media\n(OffensEval). For the most part these systems took traditional Machine Learning\napproaches that built classifiers from lexical features found in manually\nlabeled training data. However, our most successful system for classifying a\ntweet as offensive (or not) was a rule-based black--list approach, and we also\nexperimented with combining the training data from two different but related\nSemEval tasks. Our best systems in each of the three OffensEval tasks placed in\nthe middle of the comparative evaluation, ranking 57th of 103 in task A, 39th\nof 75 in task B, and 44th of 65 in task C.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 14:56:10 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pedersen", "Ted", ""]]}, {"id": "2007.12969", "submitter": "Ahmed Abbasi", "authors": "Ahmed Abbasi, David G. Dobolyi, Richard G. Netemeyer", "title": "Constructing a Testbed for Psychometric Natural Language Processing", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychometric measures of ability, attitudes, perceptions, and beliefs are\ncrucial for understanding user behaviors in various contexts including health,\nsecurity, e-commerce, and finance. Traditionally, psychometric dimensions have\nbeen measured and collected using survey-based methods. Inferring such\nconstructs from user-generated text could afford opportunities for timely,\nunobtrusive, collection and analysis. In this paper, we describe our efforts to\nconstruct a corpus for psychometric natural language processing (NLP). We\ndiscuss our multi-step process to align user text with their survey-based\nresponse items and provide an overview of the resulting testbed which\nencompasses survey-based psychometric measures and accompanying user-generated\ntext from over 8,500 respondents. We report preliminary results on the use of\nthe text to categorize/predict users' survey response labels. We also discuss\nthe important implications of our work and resulting testbed for future\npsychometric NLP research.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 16:29:24 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Abbasi", "Ahmed", ""], ["Dobolyi", "David G.", ""], ["Netemeyer", "Richard G.", ""]]}, {"id": "2007.12988", "submitter": "Thayer Alshaabi", "authors": "Thayer Alshaabi, Jane L. Adams, Michael V. Arnold, Joshua R. Minot,\n  David R. Dewhurst, Andrew J. Reagan, Christopher M. Danforth, and Peter\n  Sheridan Dodds", "title": "Storywrangler: A massive exploratorium for sociolinguistic, cultural,\n  socioeconomic, and political timelines using Twitter", "comments": "Main text: 15 pages, 6 figures; Supplementary text: 23 pages, 11\n  figures, 15 tables. Website: https://storywrangling.org/", "journal-ref": "Sci.Adv. 7 eabe6534 (2021)", "doi": "10.1126/sciadv.abe6534", "report-no": null, "categories": "cs.SI cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-time, social media data strongly imprints world events, popular\nculture, and day-to-day conversations by millions of ordinary people at a scale\nthat is scarcely conventionalized and recorded. Vitally, and absent from many\nstandard corpora such as books and news archives, sharing and commenting\nmechanisms are native to social media platforms, enabling us to quantify social\namplification (i.e., popularity) of trending storylines and contemporary\ncultural phenomena. Here, we describe Storywrangler, a natural language\nprocessing instrument designed to carry out an ongoing, day-scale curation of\nover 100 billion tweets containing roughly 1 trillion 1-grams from 2008 to\n2021. For each day, we break tweets into unigrams, bigrams, and trigrams\nspanning over 100 languages. We track n-gram usage frequencies, and generate\nZipf distributions, for words, hashtags, handles, numerals, symbols, and\nemojis. We make the data set available through an interactive time series\nviewer, and as downloadable time series and daily distributions. Although\nStorywrangler leverages Twitter data, our method of extracting and tracking\ndynamic changes of n-grams can be extended to any similar social media\nplatform. We showcase a few examples of the many possible avenues of study we\naim to enable including how social amplification can be visualized through\n'contagiograms'. We also present some example case studies that bridge n-gram\ntime series with disparate data sources to explore sociotechnical dynamics of\nfamous individuals, box office success, and social unrest.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 18:09:22 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 18:48:33 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 23:08:38 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 19:50:57 GMT"}, {"version": "v5", "created": "Fri, 16 Jul 2021 18:32:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alshaabi", "Thayer", ""], ["Adams", "Jane L.", ""], ["Arnold", "Michael V.", ""], ["Minot", "Joshua R.", ""], ["Dewhurst", "David R.", ""], ["Reagan", "Andrew J.", ""], ["Danforth", "Christopher M.", ""], ["Dodds", "Peter Sheridan", ""]]}, {"id": "2007.13002", "submitter": "Siyuan Feng", "authors": "Siyuan Feng, Odette Scharenborg", "title": "Unsupervised Subword Modeling Using Autoregressive Pretraining and\n  Cross-Lingual Phone-Aware Modeling", "comments": "5 pages, 3 figures. Accepted for publication in INTERSPEECH 2020,\n  Shanghai, China", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1170", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study addresses unsupervised subword modeling, i.e., learning feature\nrepresentations that can distinguish subword units of a language. The proposed\napproach adopts a two-stage bottleneck feature (BNF) learning framework,\nconsisting of autoregressive predictive coding (APC) as a front-end and a\nDNN-BNF model as a back-end. APC pretrained features are set as input features\nto a DNN-BNF model. A language-mismatched ASR system is used to provide\ncross-lingual phone labels for DNN-BNF model training. Finally, BNFs are\nextracted as the subword-discriminative feature representation. A second aim of\nthis work is to investigate the robustness of our approach's effectiveness to\ndifferent amounts of training data. The results on Libri-light and the\nZeroSpeech 2017 databases show that APC is effective in front-end feature\npretraining. Our whole system outperforms the state of the art on both\ndatabases. Cross-lingual phone labels for English data by a Dutch ASR\noutperform those by a Mandarin ASR, possibly linked to the larger similarity of\nDutch compared to Mandarin with English. Our system is less sensitive to\ntraining data amount when the training data is over 50 hours. APC pretraining\nleads to a reduction of needed training material from over 5,000 hours to\naround 200 hours with little performance degradation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 19:41:41 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 19:15:48 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Feng", "Siyuan", ""], ["Scharenborg", "Odette", ""]]}, {"id": "2007.13024", "submitter": "C.-H. Huck Yang", "authors": "Jun Qi, Hu Hu, Yannan Wang, Chao-Han Huck Yang, Sabato Marco\n  Siniscalchi, Chin-Hui Lee", "title": "Exploring Deep Hybrid Tensor-to-Vector Network Architectures for\n  Regression Based Speech Enhancement", "comments": "Accepted to InterSpeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates different trade-offs between the number of model\nparameters and enhanced speech qualities by employing several deep\ntensor-to-vector regression models for speech enhancement. We find that a\nhybrid architecture, namely CNN-TT, is capable of maintaining a good quality\nperformance with a reduced model parameter size. CNN-TT is composed of several\nconvolutional layers at the bottom for feature extraction to improve speech\nquality and a tensor-train (TT) output layer on the top to reduce model\nparameters. We first derive a new upper bound on the generalization power of\nthe convolutional neural network (CNN) based vector-to-vector regression\nmodels. Then, we provide experimental evidence on the Edinburgh noisy speech\ncorpus to demonstrate that, in single-channel speech enhancement, CNN\noutperforms DNN at the expense of a small increment of model sizes. Besides,\nCNN-TT slightly outperforms the CNN counterpart by utilizing only 32\\% of the\nCNN model parameters. Besides, further performance improvement can be attained\nif the number of CNN-TT parameters is increased to 44\\% of the CNN model size.\nFinally, our experiments of multi-channel speech enhancement on a simulated\nnoisy WSJ0 corpus demonstrate that our proposed hybrid CNN-TT architecture\nachieves better results than both DNN and CNN models in terms of\nbetter-enhanced speech qualities and smaller parameter sizes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 22:21:05 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 00:07:39 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Qi", "Jun", ""], ["Hu", "Hu", ""], ["Wang", "Yannan", ""], ["Yang", "Chao-Han Huck", ""], ["Siniscalchi", "Sabato Marco", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2007.13027", "submitter": "Manar Samad", "authors": "Manar D. Samad, Nalin D. Khounviengxay, Megan A. Witherow", "title": "Effect of Text Processing Steps on Twitter Sentiment Classification\n  using Word Embedding", "comments": "14 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Processing of raw text is the crucial first step in text classification and\nsentiment analysis. However, text processing steps are often performed using\noff-the-shelf routines and pre-built word dictionaries without optimizing for\ndomain, application, and context. This paper investigates the effect of seven\ntext processing scenarios on a particular text domain (Twitter) and application\n(sentiment classification). Skip gram-based word embeddings are developed to\ninclude Twitter colloquial words, emojis, and hashtag keywords that are often\nremoved for being unavailable in conventional literature corpora. Our\nexperiments reveal negative effects on sentiment classification of two common\ntext processing steps: 1) stop word removal and 2) averaging of word vectors to\nrepresent individual tweets. New effective steps for 1) including non-ASCII\nemoji characters, 2) measuring word importance from word embedding, 3)\naggregating word vectors into a tweet embedding, and 4) developing linearly\nseparable feature space have been proposed to optimize the sentiment\nclassification pipeline. The best combination of text processing steps yields\nthe highest average area under the curve (AUC) of 88.4 (+/-0.4) in classifying\n14,640 tweets with three sentiment labels. Word selection from context-driven\nword embedding reveals that only the ten most important words in Tweets\ncumulatively yield over 98% of the maximum accuracy. Results demonstrate a\nmeans for data-driven selection of important words in tweet classification as\nopposed to using pre-built word dictionaries. The proposed tweet embedding is\nrobust to and alleviates the need for several text processing steps.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 22:44:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Samad", "Manar D.", ""], ["Khounviengxay", "Nalin D.", ""], ["Witherow", "Megan A.", ""]]}, {"id": "2007.13058", "submitter": "Jia Su", "authors": "Jia Su, Yi Guan, Yuge Li, Weile Chen, He Lv, Yageng Yan", "title": "Do recommender systems function in the health domain: a system review", "comments": "32 pages, 1 table, 1 figure, 38 discussed articles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have fulfilled an important role in everyday life.\nRecommendations such as news by Google, videos by Netflix, goods by e-commerce\nproviders, etc. have heavily changed everyones lifestyle. Health domains\ncontain similar decision-making problems such as what to eat, how to exercise,\nand what is the proper medicine for a patient. Recently, studies focused on\nrecommender systems to solve health problems have attracted attention. In this\npaper, we review aspects of health recommender systems including interests,\nmethods, evaluation, future challenges and trend issues. We find that 1) health\nrecommender systems have their own health concern limitations that cause them\nto focus on less-risky recommendations such as diet recommendation; 2)\ntraditional recommender methods such as content-based and collaborative\nfiltering methods can hardly handle health constraints, but knowledge-based\nmethods function more than ever; 3) evaluating a health recommendation is more\ncomplicated than evaluating a commercial one because multiple dimensions in\naddition to accuracy should be considered. Recommender systems can function\nwell in the health domain after the solution of several key problems. Our work\nis a systematic review of health recommender system studies, we show current\nconditions and future directions. It is believed that this review will help\ndomain researchers and promote health recommender systems to the next step.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 04:58:47 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Su", "Jia", ""], ["Guan", "Yi", ""], ["Li", "Yuge", ""], ["Chen", "Weile", ""], ["Lv", "He", ""], ["Yan", "Yageng", ""]]}, {"id": "2007.13061", "submitter": "Mark Hopkins", "authors": "Vinay Gopalan, Mark Hopkins", "title": "Reed at SemEval-2020 Task 9: Fine-Tuning and Bag-of-Words Approaches to\n  Code-Mixed Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the task of sentiment analysis on Hinglish (code-mixed\nHindi-English) tweets as participants of Task 9 of the SemEval-2020\ncompetition, known as the SentiMix task. We had two main approaches: 1)\napplying transfer learning by fine-tuning pre-trained BERT models and 2)\ntraining feedforward neural networks on bag-of-words representations. During\nthe evaluation phase of the competition, we obtained an F-score of 71.3% with\nour best model, which placed $4^{th}$ out of 62 entries in the official system\nrankings.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 05:48:46 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 05:13:57 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gopalan", "Vinay", ""], ["Hopkins", "Mark", ""]]}, {"id": "2007.13069", "submitter": "Yunqi Qiu", "authors": "Bin Fu, Yunqi Qiu, Chengguang Tang, Yang Li, Haiyang Yu, Jian Sun", "title": "A Survey on Complex Question Answering over Knowledge Base: Recent\n  Advances and Challenges", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA) over Knowledge Base (KB) aims to automatically answer\nnatural language questions via well-structured relation information between\nentities stored in knowledge bases. In order to make KBQA more applicable in\nactual scenarios, researchers have shifted their attention from simple\nquestions to complex questions, which require more KB triples and constraint\ninference. In this paper, we introduce the recent advances in complex QA.\nBesides traditional methods relying on templates and rules, the research is\ncategorized into a taxonomy that contains two main branches, namely Information\nRetrieval-based and Neural Semantic Parsing-based. After describing the methods\nof these branches, we analyze directions for future research and introduce the\nmodels proposed by the Alime team.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 07:13:32 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fu", "Bin", ""], ["Qiu", "Yunqi", ""], ["Tang", "Chengguang", ""], ["Li", "Yang", ""], ["Yu", "Haiyang", ""], ["Sun", "Jian", ""]]}, {"id": "2007.13184", "submitter": "Ali Safaya", "authors": "Ali Safaya, Moutasem Abdullatif, Deniz Yuret", "title": "KUISAIL at SemEval-2020 Task 12: BERT-CNN for Offensive Speech\n  Identification in Social Media", "comments": "to be published in the proceedings of the 14th International Workshop\n  on Semantic Evaluation (SemEval2020), Association for Computational\n  Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our approach to utilize pre-trained BERT models\nwith Convolutional Neural Networks for sub-task A of the Multilingual Offensive\nLanguage Identification shared task (OffensEval 2020), which is a part of the\nSemEval 2020. We show that combining CNN with BERT is better than using BERT on\nits own, and we emphasize the importance of utilizing pre-trained language\nmodels for downstream tasks. Our system, ranked 4th with macro averaged\nF1-Score of 0.897 in Arabic, 4th with score of 0.843 in Greek, and 3rd with\nscore of 0.814 in Turkish. Additionally, we present ArabicBERT, a set of\npre-trained transformer language models for Arabic that we share with the\ncommunity.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 17:26:20 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Safaya", "Ali", ""], ["Abdullatif", "Moutasem", ""], ["Yuret", "Deniz", ""]]}, {"id": "2007.13306", "submitter": "Serena Kim", "authors": "Serena Y. Kim, Koushik Ganesan, Princess Dickens, and Soumya Panda", "title": "Public Sentiment Toward Solar Energy: Opinion Mining of Twitter Using a\n  Transformer-Based Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public acceptance and support for renewable energy are important determinants\nof renewable energy policies and market conditions. This paper examines public\nsentiment toward solar energy in the United States using data from Twitter, a\nmicro-blogging platform in which people post messages, known as tweets. We\nfiltered tweets specific to solar energy and performed a classification task\nusing Robustly optimized Bidirectional Encoder Representations from\nTransformers (RoBERTa). Analyzing 71,262 tweets during the period of late\nJanuary to early July 2020, we find public sentiment varies significantly\nacross states. Within the study period, the Northeastern U.S. region shows more\npositive sentiment toward solar energy than did the Southern U.S. region. Solar\nradiation does not correlate to variation in solar sentiment across states. We\nalso find that public sentiment toward solar correlates to renewable energy\npolicy and market conditions, specifically, Renewable Portfolio Standards (RPS)\ntargets, customer-friendly net metering policies, and a mature solar market.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 04:31:18 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kim", "Serena Y.", ""], ["Ganesan", "Koushik", ""], ["Dickens", "Princess", ""], ["Panda", "Soumya", ""]]}, {"id": "2007.13339", "submitter": "Hamada Nayel", "authors": "Hamada A. Nayel", "title": "NAYEL at SemEval-2020 Task 12: TF/IDF-Based Approach for Automatic\n  Offensive Language Detection in Arabic Tweets", "comments": "Working notes of NAYEL's team submission to task 12 at SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the system submitted to \"SemEval-2020 Task 12\". The\nproposed system aims at automatically identify the Offensive Language in Arabic\nTweets. A machine learning based approach has been used to design our system.\nWe implemented a linear classifier with Stochastic Gradient Descent (SGD) as\noptimization algorithm. Our model reported 84.20%, 81.82% f1-score on\ndevelopment set and test set respectively. The best performed system and the\nsystem in the last rank reported 90.17% and 44.51% f1-score on test set\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 07:44:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nayel", "Hamada A.", ""]]}, {"id": "2007.13520", "submitter": "Arindam Pal", "authors": "Jagriti Jalal, Mayank Singh, Arindam Pal, Lipika Dey, Animesh\n  Mukherjee", "title": "Identification, Tracking and Impact: Understanding the trade secret of\n  catchphrases", "comments": "To be published in the proceedings of the ACM/IEEE Joint Conference\n  on Digital Libraries (JCDL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the topical evolution in industrial innovation is a challenging\nproblem. With the advancement in the digital repositories in the form of patent\ndocuments, it is becoming increasingly more feasible to understand the\ninnovation secrets -- \"catchphrases\" of organizations. However, searching and\nunderstanding this enormous textual information is a natural bottleneck. In\nthis paper, we propose an unsupervised method for the extraction of\ncatchphrases from the abstracts of patents granted by the U.S. Patent and\nTrademark Office over the years. Our proposed system achieves substantial\nimprovement, both in terms of precision and recall, against state-of-the-art\ntechniques. As a second objective, we conduct an extensive empirical study to\nunderstand the temporal evolution of the catchphrases across various\norganizations. We also show how the overall innovation evolution in the form of\nintroduction of newer catchphrases in an organization's patents correlates with\nthe future citations received by the patents filed by that organization. Our\ncode and data sets will be placed in the public domain soon.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 06:11:25 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Jalal", "Jagriti", ""], ["Singh", "Mayank", ""], ["Pal", "Arindam", ""], ["Dey", "Lipika", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2007.13542", "submitter": "Robin Algayres", "authors": "Robin Algayres, Mohamed Salah Zaiem, Benoit Sagot, Emmanuel Dupoux", "title": "Evaluating the reliability of acoustic speech embeddings", "comments": "Conference paper at Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech embeddings are fixed-size acoustic representations of variable-length\nspeech sequences. They are increasingly used for a variety of tasks ranging\nfrom information retrieval to unsupervised term discovery and speech\nsegmentation. However, there is currently no clear methodology to compare or\noptimise the quality of these embeddings in a task-neutral way. Here, we\nsystematically compare two popular metrics, ABX discrimination and Mean Average\nPrecision (MAP), on 5 languages across 17 embedding methods, ranging from\nsupervised to fully unsupervised, and using different loss functions\n(autoencoders, correspondence autoencoders, siamese). Then we use the ABX and\nMAP to predict performances on a new downstream task: the unsupervised\nestimation of the frequencies of speech segments in a given corpus. We find\nthat overall, ABX and MAP correlate with one another and with frequency\nestimation. However, substantial discrepancies appear in the fine-grained\ndistinctions across languages and/or embedding methods. This makes it\nunrealistic at present to propose a task-independent silver bullet method for\ncomputing the intrinsic quality of speech embeddings. There is a need for more\ndetailed analysis of the metrics currently used to evaluate such embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 13:24:09 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 13:08:49 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Algayres", "Robin", ""], ["Zaiem", "Mohamed Salah", ""], ["Sagot", "Benoit", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2007.13626", "submitter": "Alymzhan Toleu", "authors": "Gulmira Tolegen, Alymzhan Toleu, Orken Mamyrbayev and Rustam\n  Mussabayev", "title": "Neural Named Entity Recognition for Kazakh", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several neural networks to address the task of named entity\nrecognition for morphologically complex languages (MCL). Kazakh is a\nmorphologically complex language in which each root/stem can produce hundreds\nor thousands of variant word forms. This nature of the language could lead to a\nserious data sparsity problem, which may prevent the deep learning models from\nbeing well trained for under-resourced MCLs. In order to model the MCLs' words\neffectively, we introduce root and entity tag embedding plus tensor layer to\nthe neural networks. The effects of those are significant for improving NER\nmodel performance of MCLs. The proposed models outperform state-of-the-art\nincluding character-based approaches, and can be potentially applied to other\nmorphologically complex languages.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 16:45:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tolegen", "Gulmira", ""], ["Toleu", "Alymzhan", ""], ["Mamyrbayev", "Orken", ""], ["Mussabayev", "Rustam", ""]]}, {"id": "2007.13798", "submitter": "Saurab Dulal", "authors": "Nobal B. Niraula and Saurab Dulal and Diwa Koirala", "title": "Linguistic Taboos and Euphemisms in Nepali", "comments": "10 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Languages across the world have words, phrases, and behaviors -- the taboos\n-- that are avoided in public communication considering them as obscene or\ndisturbing to the social, religious, and ethical values of society. However,\npeople deliberately use these linguistic taboos and other language constructs\nto make hurtful, derogatory, and obscene comments. It is nearly impossible to\nconstruct a universal set of offensive or taboo terms because offensiveness is\ndetermined entirely by different factors such as socio-physical setting,\nspeaker-listener relationship, and word choices. In this paper, we present a\ndetailed corpus-based study of offensive language in Nepali. We identify and\ndescribe more than 18 different categories of linguistic offenses including\npolitics, religion, race, and sex. We discuss 12 common euphemisms such as\nsynonym, metaphor and circumlocution. In addition, we introduce a manually\nconstructed data set of over 1000 offensive and taboo terms popular among\ncontemporary speakers. This in-depth study of offensive language and resource\nwill provide a foundation for several downstream tasks such as offensive\nlanguage detection and language learning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 18:25:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Niraula", "Nobal B.", ""], ["Dulal", "Saurab", ""], ["Koirala", "Diwa", ""]]}, {"id": "2007.13802", "submitter": "Jinxi Guo", "authors": "Jinxi Guo, Gautam Tiwari, Jasha Droppo, Maarten Van Segbroeck, Che-Wei\n  Huang, Andreas Stolcke, Roland Maas", "title": "Efficient minimum word error rate training of RNN-Transducer for\n  end-to-end speech recognition", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel and efficient minimum word error rate (MWER)\ntraining method for RNN-Transducer (RNN-T). Unlike previous work on this topic,\nwhich performs on-the-fly limited-size beam-search decoding and generates\nalignment scores for expected edit-distance computation, in our proposed\nmethod, we re-calculate and sum scores of all the possible alignments for each\nhypothesis in N-best lists. The hypothesis probability scores and\nback-propagated gradients are calculated efficiently using the forward-backward\nalgorithm. Moreover, the proposed method allows us to decouple the decoding and\ntraining processes, and thus we can perform offline parallel-decoding and MWER\ntraining for each subset iteratively. Experimental results show that this\nproposed semi-on-the-fly method can speed up the on-the-fly method by 6 times\nand result in a similar WER improvement (3.6%) over a baseline RNN-T model. The\nproposed MWER training can also effectively reduce high-deletion errors (9.2%\nWER-reduction) introduced by RNN-T models when EOS is added for endpointer.\nFurther improvement can be achieved if we use a proposed RNN-T rescoring method\nto re-rank hypotheses and use external RNN-LM to perform additional rescoring.\nThe best system achieves a 5% relative improvement on an English test-set of\nreal far-field recordings and a 11.6% WER reduction on music-domain utterances.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 18:33:35 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Guo", "Jinxi", ""], ["Tiwari", "Gautam", ""], ["Droppo", "Jasha", ""], ["Van Segbroeck", "Maarten", ""], ["Huang", "Che-Wei", ""], ["Stolcke", "Andreas", ""], ["Maas", "Roland", ""]]}, {"id": "2007.13826", "submitter": "Bharath Kandimalla", "authors": "Bharath Kandimalla, Shaurya Rohatgi, Jian Wu and C Lee Giles", "title": "Large Scale Subject Category Classification of Scholarly Papers with\n  Deep Attentive Neural Networks", "comments": "submitted to \"Frontiers Mining Scientific Papers Volume II: Knowledge\n  Discovery and Data Exploitation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subject categories of scholarly papers generally refer to the knowledge\ndomain(s) to which the papers belong, examples being computer science or\nphysics. Subject category information can be used for building faceted search\nfor digital library search engines. This can significantly assist users in\nnarrowing down their search space of relevant documents. Unfortunately, many\nacademic papers do not have such information as part of their metadata.\nExisting methods for solving this task usually focus on unsupervised learning\nthat often relies on citation networks. However, a complete list of papers\nciting the current paper may not be readily available. In particular, new\npapers that have few or no citations cannot be classified using such methods.\nHere, we propose a deep attentive neural network (DANN) that classifies\nscholarly papers using only their abstracts. The network is trained using 9\nmillion abstracts from Web of Science (WoS). We also use the WoS schema that\ncovers 104 subject categories. The proposed network consists of two\nbi-directional recurrent neural networks followed by an attention layer. We\ncompare our model against baselines by varying the architecture and text\nrepresentation. Our best model achieves micro-F1 measure of 0.76 with F1 of\nindividual subject categories ranging from 0.50-0.95. The results showed the\nimportance of retraining word embedding models to maximize the vocabulary\noverlap and the effectiveness of the attention mechanism. The combination of\nword vectors with TFIDF outperforms character and sentence level embedding\nmodels. We discuss imbalanced samples and overlapping categories and suggest\npossible strategies for mitigation. We also determine the subject category\ndistribution in CiteSeerX by classifying a random sample of one million\nacademic papers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 19:42:42 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Kandimalla", "Bharath", ""], ["Rohatgi", "Shaurya", ""], ["Wu", "Jian", ""], ["Giles", "C Lee", ""]]}, {"id": "2007.13840", "submitter": "Nora Aguirre-Celis E", "authors": "N. Aguirre-Celis and R. Miikkulainen", "title": "Characterizing the Effect of Sentence Context on Word Meanings: Mapping\n  Brain to Behavior", "comments": "7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic feature models have become a popular tool for prediction and\ninterpretation of fMRI data. In particular, prior work has shown that\ndifferences in the fMRI patterns in sentence reading can be explained by\ncontext-dependent changes in the semantic feature representations of the words.\nHowever, whether the subjects are aware of such changes and agree with them has\nbeen an open question. This paper aims to answer this question through a\nhuman-subject study. Subjects were asked to judge how the word change from\ntheir generic meaning when the words were used in specific sentences. The\njudgements were consistent with the model predictions well above chance. Thus,\nthe results support the hypothesis that word meaning change systematically\ndepending on sentence context.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:12:30 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 23:38:38 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 22:59:25 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Aguirre-Celis", "N.", ""], ["Miikkulainen", "R.", ""]]}, {"id": "2007.13913", "submitter": "David Chan", "authors": "David M. Chan, Sudheendra Vijayanarasimhan, David A. Ross, John Canny", "title": "Active Learning for Video Description With Cluster-Regularized Ensemble\n  Ranking", "comments": "Published at the 15th Asian Conference on Computer Vision (ACCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic video captioning aims to train models to generate text descriptions\nfor all segments in a video, however, the most effective approaches require\nlarge amounts of manual annotation which is slow and expensive. Active learning\nis a promising way to efficiently build a training set for video captioning\ntasks while reducing the need to manually label uninformative examples. In this\nwork we both explore various active learning approaches for automatic video\ncaptioning and show that a cluster-regularized ensemble strategy provides the\nbest active learning approach to efficiently gather training sets for video\ncaptioning. We evaluate our approaches on the MSR-VTT and LSMDC datasets using\nboth transformer and LSTM based captioning models and show that our novel\nstrategy can achieve high performance while using up to 60% fewer training data\nthan the strong state of the art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 23:52:41 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 17:39:56 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 23:38:20 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Chan", "David M.", ""], ["Vijayanarasimhan", "Sudheendra", ""], ["Ross", "David A.", ""], ["Canny", "John", ""]]}, {"id": "2007.13928", "submitter": "Hung Hoang Manh", "authors": "Hoang Manh Hung, Hyung-Jeong Yang, Soo-Hyung Kim, and Guee-Sang Lee", "title": "Variants of BERT, Random Forests and SVM approach for Multimodal\n  Emotion-Target Sub-challenge", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition has become a major problem in computer vision in recent\nyears that made a lot of effort by researchers to overcome the difficulties in\nthis task. In the field of affective computing, emotion recognition has a wide\nrange of applications, such as healthcare, robotics, human-computer\ninteraction. Due to its practical importance for other tasks, many techniques\nand approaches have been investigated for different problems and various data\nsources. Nevertheless, comprehensive fusion of the audio-visual and language\nmodalities to get the benefits from them is still a problem to solve. In this\npaper, we present and discuss our classification methodology for MuSe-Topic\nSub-challenge, as well as the data and results. For the topic classification,\nwe ensemble two language models which are ALBERT and RoBERTa to predict 10\nclasses of topics. Moreover, for the classification of valence and arousal, SVM\nand Random forests are employed in conjunction with feature selection to\nenhance the performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 01:15:50 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Hung", "Hoang Manh", ""], ["Yang", "Hyung-Jeong", ""], ["Kim", "Soo-Hyung", ""], ["Lee", "Guee-Sang", ""]]}, {"id": "2007.13968", "submitter": "Li Yuan", "authors": "Li Yuan, Jin Wang and Xuejie Zhang", "title": "YNU-HPCC at SemEval-2020 Task 8: Using a Parallel-Channel Model for\n  Memotion Analysis", "comments": "5pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the growing ubiquity of Internet memes on social media\nplatforms, such as Facebook, Instagram, and Twitter, has become a topic of\nimmense interest. However, the classification and recognition of memes is much\nmore complicated than that of social text since it involves visual cues and\nlanguage understanding. To address this issue, this paper proposed a\nparallel-channel model to process the textual and visual information in memes\nand then analyze the sentiment polarity of memes. In the shared task of\nidentifying and categorizing memes, we preprocess the dataset according to the\nlanguage behaviors on social media. Then, we adapt and fine-tune the\nBidirectional Encoder Representations from Transformers (BERT), and two types\nof convolutional neural network models (CNNs) were used to extract the features\nfrom the pictures. We applied an ensemble model that combined the BiLSTM,\nBIGRU, and Attention models to perform cross domain suggestion mining. The\nofficially released results show that our system performs better than the\nbaseline algorithm. Our team won nineteenth place in subtask A (Sentiment\nClassification). The code of this paper is availabled at :\nhttps://github.com/YuanLi95/Semveal2020-Task8-emotion-analysis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 03:20:31 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Yuan", "Li", ""], ["Wang", "Jin", ""], ["Zhang", "Xuejie", ""]]}, {"id": "2007.13974", "submitter": "Fatemah Husain", "authors": "Fatemah Husain, Jooyeon Lee, Samuel Henry, and Ozlem Uzuner", "title": "SalamNET at SemEval-2020 Task12: Deep Learning Approach for Arabic\n  Offensive Language Detection", "comments": "In Proceedings of the International Workshop on Semantic Evaluation\n  (SemEval) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes SalamNET, an Arabic offensive language detection system\nthat has been submitted to SemEval 2020 shared task 12: Multilingual Offensive\nLanguage Identification in Social Media. Our approach focuses on applying\nmultiple deep learning models and conducting in depth error analysis of results\nto provide system implications for future development considerations. To pursue\nour goal, a Recurrent Neural Network (RNN), a Gated Recurrent Unit (GRU), and\nLong-Short Term Memory (LSTM) models with different design architectures have\nbeen developed and evaluated. The SalamNET, a Bi-directional Gated Recurrent\nUnit (Bi-GRU) based model, reports a macro-F1 score of 0.83.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 03:47:26 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Husain", "Fatemah", ""], ["Lee", "Jooyeon", ""], ["Henry", "Samuel", ""], ["Uzuner", "Ozlem", ""]]}, {"id": "2007.14062", "submitter": "Manzil Zaheer", "authors": "Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris\n  Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang,\n  Amr Ahmed", "title": "Big Bird: Transformers for Longer Sequences", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers-based models, such as BERT, have been one of the most successful\ndeep learning models for NLP. Unfortunately, one of their core limitations is\nthe quadratic dependency (mainly in terms of memory) on the sequence length due\nto their full attention mechanism. To remedy this, we propose, BigBird, a\nsparse attention mechanism that reduces this quadratic dependency to linear. We\nshow that BigBird is a universal approximator of sequence functions and is\nTuring complete, thereby preserving these properties of the quadratic, full\nattention model. Along the way, our theoretical analysis reveals some of the\nbenefits of having $O(1)$ global tokens (such as CLS), that attend to the\nentire sequence as part of the sparse attention mechanism. The proposed sparse\nattention can handle sequences of length up to 8x of what was previously\npossible using similar hardware. As a consequence of the capability to handle\nlonger context, BigBird drastically improves performance on various NLP tasks\nsuch as question answering and summarization. We also propose novel\napplications to genomics data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:34:04 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 07:41:50 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Zaheer", "Manzil", ""], ["Guruganesh", "Guru", ""], ["Dubey", "Avinava", ""], ["Ainslie", "Joshua", ""], ["Alberti", "Chris", ""], ["Ontanon", "Santiago", ""], ["Pham", "Philip", ""], ["Ravula", "Anirudh", ""], ["Wang", "Qifan", ""], ["Yang", "Li", ""], ["Ahmed", "Amr", ""]]}, {"id": "2007.14071", "submitter": "Xinzhi Wang", "authors": "Xinzhi Wang, Luyao Kou, Vijayan Sugumaran, Xiangfeng Luo, and Hui\n  Zhang", "title": "Emotion Correlation Mining Through Deep Learning Models on Natural\n  Language Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion analysis has been attracting researchers' attention. Most previous\nworks in the artificial intelligence field focus on recognizing emotion rather\nthan mining the reason why emotions are not or wrongly recognized. Correlation\namong emotions contributes to the failure of emotion recognition. In this\npaper, we try to fill the gap between emotion recognition and emotion\ncorrelation mining through natural language text from web news. Correlation\namong emotions, expressed as the confusion and evolution of emotion, is\nprimarily caused by human emotion cognitive bias. To mine emotion correlation\nfrom emotion recognition through text, three kinds of features and two deep\nneural network models are presented. The emotion confusion law is extracted\nthrough orthogonal basis. The emotion evolution law is evaluated from three\nperspectives, one-step shift, limited-step shifts, and shortest path transfer.\nThe method is validated using three datasets-the titles, the bodies, and the\ncomments of news articles, covering both objective and subjective texts in\nvarying lengths (long and short). The experimental results show that, in\nsubjective comments, emotions are easily mistaken as anger. Comments tend to\narouse emotion circulations of love-anger and sadness-anger. In objective news,\nit is easy to recognize text emotion as love and cause fear-joy circulation.\nThat means, journalists may try to attract attention using fear and joy words\nbut arouse the emotion love instead; After news release, netizens generate\nemotional comments to express their intense emotions, i.e., anger, sadness, and\nlove. These findings could provide insights for applications regarding\naffective interaction such as network public sentiment, social media\ncommunication, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:59:16 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wang", "Xinzhi", ""], ["Kou", "Luyao", ""], ["Sugumaran", "Vijayan", ""], ["Luo", "Xiangfeng", ""], ["Zhang", "Hui", ""]]}, {"id": "2007.14074", "submitter": "Sainik Mahata", "authors": "Sainik Kumar Mahata, Amrita Chandra, Dipankar Das, Sivaji\n  Bandyopadhyay", "title": "Preparation of Sentiment tagged Parallel Corpus and Testing its effect\n  on Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current work, we explore the enrichment in the machine translation\noutput when the training parallel corpus is augmented with the introduction of\nsentiment analysis. The paper discusses the preparation of the same sentiment\ntagged English-Bengali parallel corpus. The preparation of raw parallel corpus,\nsentiment analysis of the sentences and the training of a Character Based\nNeural Machine Translation model using the same has been discussed extensively\nin this paper. The output of the translation model has been compared with a\nbase-line translation model using automated metrics such as BLEU and TER as\nwell as manually.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 09:04:47 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Mahata", "Sainik Kumar", ""], ["Chandra", "Amrita", ""], ["Das", "Dipankar", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "2007.14128", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Josef Jon, Martin Docekal, Pavel Smrz", "title": "BUT-FIT at SemEval-2020 Task 5: Automatic detection of counterfactual\n  statements with deep pre-trained language representation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper describes BUT-FIT's submission at SemEval-2020 Task 5: Modelling\nCausal Reasoning in Language: Detecting Counterfactuals. The challenge focused\non detecting whether a given statement contains a counterfactual (Subtask 1)\nand extracting both antecedent and consequent parts of the counterfactual from\nthe text (Subtask 2). We experimented with various state-of-the-art language\nrepresentation models (LRMs). We found RoBERTa LRM to perform the best in both\nsubtasks. We achieved the first place in both exact match and F1 for Subtask 2\nand ranked second for Subtask 1.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 11:16:11 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Fajcik", "Martin", ""], ["Jon", "Josef", ""], ["Docekal", "Martin", ""], ["Smrz", "Pavel", ""]]}, {"id": "2007.14200", "submitter": "Qian Zhao", "authors": "Qian Zhao, Siyu Tao, Jie Zhou, Linlin Wang, Xin Lin and Liang He", "title": "ECNU-SenseMaker at SemEval-2020 Task 4: Leveraging Heterogeneous\n  Knowledge Resources for Commonsense Validation and Explanation", "comments": "10 pages, 2 figures, accepted by Proceedings of the 14th\n  International Workshop on Semantic Evaluation (SemEval 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our system for SemEval-2020 Task 4: Commonsense\nValidation and Explanation (Wang et al., 2020). We propose a novel\nKnowledge-enhanced Graph Attention Network (KEGAT) architecture for this task,\nleveraging heterogeneous knowledge from both the structured knowledge base\n(i.e. ConceptNet) and unstructured text to better improve the ability of a\nmachine in commonsense understanding. This model has a powerful commonsense\ninference capability via utilizing suitable commonsense incorporation methods\nand upgraded data augmentation techniques. Besides, an internal sharing\nmechanism is cooperated to prohibit our model from insufficient and excessive\nreasoning for commonsense. As a result, this model performs quite well in both\nvalidation and explanation. For instance, it achieves state-of-the-art accuracy\nin the subtask called Commonsense Explanation (Multi-Choice). We officially\nname the system as ECNU-SenseMaker. Code is publicly available at\nhttps://github.com/ECNU-ICA/ECNU-SenseMaker.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:30:46 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Zhao", "Qian", ""], ["Tao", "Siyu", ""], ["Zhou", "Jie", ""], ["Wang", "Linlin", ""], ["Lin", "Xin", ""], ["He", "Liang", ""]]}, {"id": "2007.14222", "submitter": "Ali Basirat", "authors": "Marc Allassonni\\`ere-Tang and Ali Basirat", "title": "Word embedding and neural network on grammatical gender -- A case study\n  of Swedish", "comments": "The paper was submitted to Nordic Journal of Linguistics in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the information provided by the word embeddings about the\ngrammatical gender in Swedish. We wish that this paper may serve as one of the\nbridges to connect the methods of computational linguistics and general\nlinguistics. Taking nominal classification in Swedish as a case study, we first\nshow how the information about grammatical gender in language can be captured\nby word embedding models and artificial neural networks. Then, we match our\nresults with previous linguistic hypotheses on assignment and usage of\ngrammatical gender in Swedish and analyze the errors made by the computational\nmodel from a linguistic perspective.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:50:17 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Allassonni\u00e8re-Tang", "Marc", ""], ["Basirat", "Ali", ""]]}, {"id": "2007.14310", "submitter": "Anton Golubev", "authors": "Anton Golubev and Natalia Loukachevitch", "title": "Improving Results on Russian Sentiment Datasets", "comments": "13 pages, 8 tables. Accepted to AINL-2020 conference\n  (https://ainlconf.ru/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we test standard neural network architectures (CNN, LSTM,\nBiLSTM) and recently appeared BERT architectures on previous Russian sentiment\nevaluation datasets. We compare two variants of Russian BERT and show that for\nall sentiment tasks in this study the conversational variant of Russian BERT\nperforms better. The best results were achieved by BERT-NLI model, which treats\nsentiment classification tasks as a natural language inference task. On one of\nthe datasets, this model practically achieves the human level.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:29:19 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Golubev", "Anton", ""], ["Loukachevitch", "Natalia", ""]]}, {"id": "2007.14435", "submitter": "Harm de Vries", "authors": "Harm de Vries, Dzmitry Bahdanau, Christopher Manning", "title": "Towards Ecologically Valid Research on Language User Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language User Interfaces (LUIs) could improve human-machine interaction for a\nwide variety of tasks, such as playing music, getting insights from databases,\nor instructing domestic robots. In contrast to traditional hand-crafted\napproaches, recent work attempts to build LUIs in a data-driven way using\nmodern deep learning methods. To satisfy the data needs of such learning\nalgorithms, researchers have constructed benchmarks that emphasize the quantity\nof collected data at the cost of its naturalness and relevance to real-world\nLUI use cases. As a consequence, research findings on such benchmarks might not\nbe relevant for developing practical LUIs. The goal of this paper is to\nbootstrap the discussion around this issue, which we refer to as the\nbenchmarks' low ecological validity. To this end, we describe what we deem an\nideal methodology for machine learning research on LUIs and categorize five\ncommon ways in which recent benchmarks deviate from it. We give concrete\nexamples of the five kinds of deviations and their consequences. Lastly, we\noffer a number of recommendations as to how to increase the ecological validity\nof machine learning research on LUIs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 19:09:11 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["de Vries", "Harm", ""], ["Bahdanau", "Dzmitry", ""], ["Manning", "Christopher", ""]]}, {"id": "2007.14454", "submitter": "James Ravenscroft", "authors": "James Ravenscroft and Amanda Clare and Maria Liakata", "title": "Measuring prominence of scientific work in online news as a proxy for\n  impact", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The impact made by a scientific paper on the work of other academics has many\nestablished metrics, including metrics based on citation counts and social\nmedia commenting. However, determination of the impact of a scientific paper on\nthe wider society is less well established. For example, is it important for\nscientific work to be newsworthy? Here we present a new corpus of newspaper\narticles linked to the scientific papers that they describe. We find that\nImpact Case studies submitted to the UK Research Excellence Framework (REF)\n2014 that refer to scientific papers mentioned in newspaper articles were\nawarded a higher score in the REF assessment. The papers associated with these\ncase studies also feature prominently in the newspaper articles. We hypothesise\nthat such prominence can be a useful proxy for societal impact. We therefore\nprovide a novel baseline approach for measuring the prominence of scientific\npapers mentioned within news articles. Our measurement of prominence is based\non semantic similarity through a graph-based ranking algorithm. We find that\nscientific papers with an associated REF case study are more likely to have a\nstronger prominence score. This supports our hypothesis that linguistic\nprominence in news can be used to suggest the wider non-academic impact of\nscientific work.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 19:52:21 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Ravenscroft", "James", ""], ["Clare", "Amanda", ""], ["Liakata", "Maria", ""]]}, {"id": "2007.14474", "submitter": "Katy B\\\"orner", "authors": "Katy B\\\"orner, Ellen M. Quardokus, Bruce W. Herr II, Leonard E. Cross,\n  Elizabeth G. Record, Yingnan Ju, Andreas D. Bueckle, James P. Sluka, Jonathan\n  C. Silverstein, Kristen M. Browne, Sanjay Jain, Clive H. Wasserfall, Marda L.\n  Jorgensen, Jeffrey M. Spraggins, Nathan H. Patterson, Mark A. Musen, Griffin\n  M. Weber", "title": "Construction and Usage of a Human Body Common Coordinate Framework\n  Comprising Clinical, Semantic, and Spatial Ontologies", "comments": "24 pages with SI, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The National Institutes of Health's (NIH) Human Biomolecular Atlas Program\n(HuBMAP) aims to create a comprehensive high-resolution atlas of all the cells\nin the healthy human body. Multiple laboratories across the United States are\ncollecting tissue specimens from different organs of donors who vary in sex,\nage, and body size. Integrating and harmonizing the data derived from these\nsamples and 'mapping' them into a common three-dimensional (3D) space is a\nmajor challenge. The key to making this possible is a 'Common Coordinate\nFramework' (CCF), which provides a semantically annotated, 3D reference system\nfor the entire body. The CCF enables contributors to HuBMAP to 'register'\nspecimens and datasets within a common spatial reference system, and it\nsupports a standardized way to query and 'explore' data in a spatially and\nsemantically explicit manner. [...] This paper describes the construction and\nusage of a CCF for the human body and its reference implementation in HuBMAP.\nThe CCF consists of (1) a CCF Clinical Ontology, which provides metadata about\nthe specimen and donor (the 'who'); (2) a CCF Semantic Ontology, which\ndescribes 'what' part of the body a sample came from and details anatomical\nstructures, cell types, and biomarkers (ASCT+B); and (3) a CCF Spatial\nOntology, which indicates 'where' a tissue sample is located in a 3D coordinate\nsystem. An initial version of all three CCF ontologies has been implemented for\nthe first HuBMAP Portal release. It was successfully used by Tissue Mapping\nCenters to semantically annotate and spatially register 48 kidney and spleen\ntissue blocks. The blocks can be queried and explored in their clinical,\nsemantic, and spatial context via the CCF user interface in the HuBMAP Portal.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 20:35:56 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["B\u00f6rner", "Katy", ""], ["Quardokus", "Ellen M.", ""], ["Herr", "Bruce W.", "II"], ["Cross", "Leonard E.", ""], ["Record", "Elizabeth G.", ""], ["Ju", "Yingnan", ""], ["Bueckle", "Andreas D.", ""], ["Sluka", "James P.", ""], ["Silverstein", "Jonathan C.", ""], ["Browne", "Kristen M.", ""], ["Jain", "Sanjay", ""], ["Wasserfall", "Clive H.", ""], ["Jorgensen", "Marda L.", ""], ["Spraggins", "Jeffrey M.", ""], ["Patterson", "Nathan H.", ""], ["Musen", "Mark A.", ""], ["Weber", "Griffin M.", ""]]}, {"id": "2007.14477", "submitter": "Sean MacAvaney", "authors": "Sajad Sotudeh, Tong Xiang, Hao-Ren Yao, Sean MacAvaney, Eugene Yang,\n  Nazli Goharian, Ophir Frieder", "title": "GUIR at SemEval-2020 Task 12: Domain-Tuned Contextualized Models for\n  Offensive Language Detection", "comments": "SemEval 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offensive language detection is an important and challenging task in natural\nlanguage processing. We present our submissions to the OffensEval 2020 shared\ntask, which includes three English sub-tasks: identifying the presence of\noffensive language (Sub-task A), identifying the presence of target in\noffensive language (Sub-task B), and identifying the categories of the target\n(Sub-task C). Our experiments explore using a domain-tuned contextualized\nlanguage model (namely, BERT) for this task. We also experiment with different\ncomponents and configurations (e.g., a multi-view SVM) stacked upon BERT models\nfor specific sub-tasks. Our submissions achieve F1 scores of 91.7% in Sub-task\nA, 66.5% in Sub-task B, and 63.2% in Sub-task C. We perform an ablation study\nwhich reveals that domain tuning considerably improves the classification\nperformance. Furthermore, error analysis shows common misclassification errors\nmade by our model and outlines research directions for future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 20:45:43 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sotudeh", "Sajad", ""], ["Xiang", "Tong", ""], ["Yao", "Hao-Ren", ""], ["MacAvaney", "Sean", ""], ["Yang", "Eugene", ""], ["Goharian", "Nazli", ""], ["Frieder", "Ophir", ""]]}, {"id": "2007.14576", "submitter": "Sainik Mahata", "authors": "Tathagata Raha, Sainik Kumar Mahata, Dipankar Das, Sivaji\n  Bandyopadhyay", "title": "Development of POS tagger for English-Bengali Code-Mixed data", "comments": "Accepted and published in The sixteenth International Conference on\n  Natural Language Processing (ICON-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-mixed texts are widespread nowadays due to the advent of social media.\nSince these texts combine two languages to formulate a sentence, it gives rise\nto various research problems related to Natural Language Processing. In this\npaper, we try to excavate one such problem, namely, Parts of Speech tagging of\ncode-mixed texts. We have built a system that can POS tag English-Bengali\ncode-mixed data where the Bengali words were written in Roman script. Our\napproach initially involves the collection and cleaning of English-Bengali\ncode-mixed tweets. These tweets were used as a development dataset for building\nour system. The proposed system is a modular approach that starts by tagging\nindividual tokens with their respective languages and then passes them to\ndifferent POS taggers, designed for different languages (English and Bengali,\nin our case). Tags given by the two systems are later joined together and the\nfinal result is then mapped to a universal POS tag set. Our system was checked\nusing 100 manually POS tagged code-mixed sentences and it returned an accuracy\nof 75.29%\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 03:42:07 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Raha", "Tathagata", ""], ["Mahata", "Sainik Kumar", ""], ["Das", "Dipankar", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "2007.14587", "submitter": "T.J. Tsai", "authors": "TJ Tsai and Kevin Ji", "title": "Composer Style Classification of Piano Sheet Music Images Using Language\n  Model Pretraining", "comments": "8 pages, 7 figures. Accepted paper at the International Society for\n  Music Information Retrieval Conference (ISMIR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies composer style classification of piano sheet music images.\nPrevious approaches to the composer classification task have been limited by a\nscarcity of data. We address this issue in two ways: (1) we recast the problem\nto be based on raw sheet music images rather than a symbolic music format, and\n(2) we propose an approach that can be trained on unlabeled data. Our approach\nfirst converts the sheet music image into a sequence of musical \"words\" based\non the bootleg feature representation, and then feeds the sequence into a text\nclassifier. We show that it is possible to significantly improve classifier\nperformance by first training a language model on a set of unlabeled data,\ninitializing the classifier with the pretrained language model weights, and\nthen finetuning the classifier on a small amount of labeled data. We train\nAWD-LSTM, GPT-2, and RoBERTa language models on all piano sheet music images in\nIMSLP. We find that transformer-based architectures outperform CNN and LSTM\nmodels, and pretraining boosts classification accuracy for the GPT-2 model from\n46\\% to 70\\% on a 9-way classification task. The trained model can also be used\nas a feature extractor that projects piano sheet music into a feature space\nthat characterizes compositional style.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 04:13:59 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Tsai", "TJ", ""], ["Ji", "Kevin", ""]]}, {"id": "2007.14626", "submitter": "Yuankai Qi", "authors": "Yuankai Qi, Zizheng Pan, Shengping Zhang, Anton van den Hengel, Qi Wu", "title": "Object-and-Action Aware Model for Visual Language Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-Language Navigation (VLN) is unique in that it requires turning\nrelatively general natural-language instructions into robot agent actions, on\nthe basis of the visible environment. This requires to extract value from two\nvery different types of natural-language information. The first is object\ndescription (e.g., 'table', 'door'), each presenting as a tip for the agent to\ndetermine the next action by finding the item visible in the environment, and\nthe second is action specification (e.g., 'go straight', 'turn left') which\nallows the robot to directly predict the next movements without relying on\nvisual perceptions. However, most existing methods pay few attention to\ndistinguish these information from each other during instruction encoding and\nmix together the matching between textual object/action encoding and visual\nperception/orientation features of candidate viewpoints. In this paper, we\npropose an Object-and-Action Aware Model (OAAM) that processes these two\ndifferent forms of natural language based instruction separately. This enables\neach process to match object-centered/action-centered instruction to their own\ncounterpart visual perception/action orientation flexibly. However, one\nside-issue caused by above solution is that an object mentioned in instructions\nmay be observed in the direction of two or more candidate viewpoints, thus the\nOAAM may not predict the viewpoint on the shortest path as the next action. To\nhandle this problem, we design a simple but effective path loss to penalize\ntrajectories deviating from the ground truth path. Experimental results\ndemonstrate the effectiveness of the proposed model and path loss, and the\nsuperiority of their combination with a 50% SPL score on the R2R dataset and a\n40% CLS score on the R4R dataset in unseen environments, outperforming the\nprevious state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 06:32:18 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Qi", "Yuankai", ""], ["Pan", "Zizheng", ""], ["Zhang", "Shengping", ""], ["Hengel", "Anton van den", ""], ["Wu", "Qi", ""]]}, {"id": "2007.14640", "submitter": "Yuhao Zhang", "authors": "Yuhao Zhang, Yuhui Zhang, Peng Qi, Christopher D. Manning, Curtis P.\n  Langlotz", "title": "Biomedical and Clinical English Model Packages in the Stanza Python NLP\n  Library", "comments": "Website: https://stanfordnlp.github.io/stanza/; demo page:\n  http://stanza.run/bio", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce biomedical and clinical English model packages for the Stanza\nPython NLP library. These packages offer accurate syntactic analysis and named\nentity recognition capabilities for biomedical and clinical text, by combining\nStanza's fully neural architecture with a wide variety of open datasets as well\nas large-scale unsupervised biomedical and clinical text data. We show via\nextensive experiments that our packages achieve syntactic analysis and named\nentity recognition performance that is on par with or surpasses\nstate-of-the-art results. We further show that these models do not compromise\nspeed compared to existing toolkits when GPU acceleration is available, and are\nmade easy to download and use with Stanza's Python interface. A demonstration\nof our packages is available at: http://stanza.run/bio.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 07:27:41 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Zhang", "Yuhao", ""], ["Zhang", "Yuhui", ""], ["Qi", "Peng", ""], ["Manning", "Christopher D.", ""], ["Langlotz", "Curtis P.", ""]]}, {"id": "2007.14682", "submitter": "Philipp Rimle", "authors": "Philipp Rimle, Pelin Dogan, Markus Gross", "title": "Enriching Video Captions With Contextual Text", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding video content and generating caption with context is an\nimportant and challenging task. Unlike prior methods that typically attempt to\ngenerate generic video captions without context, our architecture\ncontextualizes captioning by infusing extracted information from relevant text\ndata. We propose an end-to-end sequence-to-sequence model which generates video\ncaptions based on visual input, and mines relevant knowledge such as names and\nlocations from contextual text. In contrast to previous approaches, we do not\npreprocess the text further, and let the model directly learn to attend over\nit. Guided by the visual input, the model is able to copy words from the\ncontextual text via a pointer-generator network, allowing to produce more\nspecific video captions. We show competitive performance on the News Video\nDataset and, through ablation studies, validate the efficacy of contextual\nvideo captioning as well as individual design choices in our model\narchitecture.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 08:58:52 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Rimle", "Philipp", ""], ["Dogan", "Pelin", ""], ["Gross", "Markus", ""]]}, {"id": "2007.14936", "submitter": "Mirko Lai", "authors": "Mirko Lai and Viviana Patti and Giancarlo Ruffo and Paolo Rosso", "title": "#Brexit: Leave or Remain? The Role of User's Community and Diachronic\n  Evolution on Stance Detection", "comments": "To appear in Journal of Intelligent & Fuzzy Systems", "journal-ref": null, "doi": "10.3233/JIFS-179895", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest has grown around the classification of stance that users assume\nwithin online debates in recent years. Stance has been usually addressed by\nconsidering users posts in isolation, while social studies highlight that\nsocial communities may contribute to influence users' opinion. Furthermore,\nstance should be studied in a diachronic perspective, since it could help to\nshed light on users' opinion shift dynamics that can be recorded during the\ndebate. We analyzed the political discussion in UK about the BREXIT referendum\non Twitter, proposing a novel approach and annotation schema for stance\ndetection, with the main aim of investigating the role of features related to\nsocial network community and diachronic stance evolution. Classification\nexperiments show that such features provide very useful clues for detecting\nstance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:19:02 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Lai", "Mirko", ""], ["Patti", "Viviana", ""], ["Ruffo", "Giancarlo", ""], ["Rosso", "Paolo", ""]]}, {"id": "2007.14966", "submitter": "Sourya Basu", "authors": "Sourya Basu, Govardana Sachitanandam Ramachandran, Nitish Shirish\n  Keskar, Lav R. Varshney", "title": "Mirostat: A Neural Text Decoding Algorithm that Directly Controls\n  Perplexity", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text decoding is important for generating high-quality texts using\nlanguage models. To generate high-quality text, popular decoding algorithms\nlike top-k, top-p (nucleus), and temperature-based sampling truncate or distort\nthe unreliable low probability tail of the language model. Though these methods\ngenerate high-quality text after parameter tuning, they are ad hoc. Not much is\nknown about the control they provide over the statistics of the output, which\nis important since recent reports show text quality is highest for a specific\nrange of likelihoods. Here, first we provide a theoretical analysis of\nperplexity in top-k, top-p, and temperature sampling, finding that\ncross-entropy behaves approximately linearly as a function of p in top-p\nsampling whereas it is a nonlinear function of k in top-k sampling, under\nZipfian statistics. We use this analysis to design a feedback-based adaptive\ntop-k text decoding algorithm called mirostat that generates text (of any\nlength) with a predetermined value of perplexity, and thereby high-quality text\nwithout any tuning. Experiments show that for low values of k and p in top-k\nand top-p sampling, perplexity drops significantly with generated text length,\nwhich is also correlated with excessive repetitions in the text (the boredom\ntrap). On the other hand, for large values of k and p, we find that perplexity\nincreases with generated text length, which is correlated with incoherence in\nthe text (confusion trap). Mirostat avoids both traps: experiments show that\ncross-entropy has a near-linear relation with repetition in generated text.\nThis relation is almost independent of the sampling method but slightly\ndependent on the model used. Hence, for a given language model, control over\nperplexity also gives control over repetitions. Experiments with human raters\nfor fluency, coherence, and quality further verify our findings.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 17:22:26 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 21:36:02 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Basu", "Sourya", ""], ["Ramachandran", "Govardana Sachitanandam", ""], ["Keskar", "Nitish Shirish", ""], ["Varshney", "Lav R.", ""]]}, {"id": "2007.14987", "submitter": "Patrick Jenkins", "authors": "Patrick Jenkins, Rishabh Sachdeva, Gaoussou Youssouf Kebe, Padraig\n  Higgins, Kasra Darvish, Edward Raff, Don Engel, John Winder, Francis Ferraro,\n  Cynthia Matuszek", "title": "Presentation and Analysis of a Multimodal Dataset for Grounded Language\n  Learning", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounded language acquisition -- learning how language-based interactions\nrefer to the world around them -- is amajor area of research in robotics, NLP,\nand HCI. In practice the data used for learning consists almost entirely of\ntextual descriptions, which tend to be cleaner, clearer, and more grammatical\nthan actual human interactions. In this work, we present the Grounded Language\nDataset (GoLD), a multimodal dataset of common household objects described by\npeople using either spoken or written language. We analyze the differences and\npresent an experiment showing how the different modalities affect language\nlearning from human in-put. This will enable researchers studying the\nintersection of robotics, NLP, and HCI to better investigate how the multiple\nmodalities of image, text, and speech interact, as well as show differences in\nthe vernacular of these modalities impact results.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 17:58:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 15:37:58 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 15:25:34 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 16:47:50 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Jenkins", "Patrick", ""], ["Sachdeva", "Rishabh", ""], ["Kebe", "Gaoussou Youssouf", ""], ["Higgins", "Padraig", ""], ["Darvish", "Kasra", ""], ["Raff", "Edward", ""], ["Engel", "Don", ""], ["Winder", "John", ""], ["Ferraro", "Francis", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "2007.15066", "submitter": "Jiayuan Ding", "authors": "Jiayuan Ding, Mayank Kejriwal", "title": "An Experimental Study of The Effects of Position Bias on Emotion\n  CauseExtraction", "comments": "9 pages, 2 figures, 9 tables, bias, position bias, unbalanced labels,\n  deep neural network models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion Cause Extraction (ECE) aims to identify emotion causes from a\ndocument after annotating the emotion keywords. Some baselines have been\nproposed to address this problem, such as rule-based, commonsense based and\nmachine learning methods. We show, however, that a simple random selection\napproach toward ECE that does not require observing the text achieves similar\nperformance compared to the baselines. We utilized only position information\nrelative to the emotion cause to accomplish this goal. Since position\ninformation alone without observing the text resulted in higher F-measure, we\ntherefore uncovered a bias in the ECE single genre Sina-news benchmark. Further\nanalysis showed that an imbalance of emotional cause location exists in the\nbenchmark, with a majority of cause clauses immediately preceding the central\nemotion clause. We examine the bias from a linguistic perspective, and show\nthat high accuracy rate of current state-of-art deep learning models that\nutilize location information is only evident in datasets that contain such\nposition biases. The accuracy drastically reduced when a dataset with balanced\nlocation distribution is introduced. We therefore conclude that it is the\ninnate bias in this benchmark that caused high accuracy rate of these deep\nlearning models in ECE. We hope that the case study in this paper presents both\na cautionary lesson, as well as a template for further studies, in interpreting\nthe superior fit of deep learning models without checking for bias.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 08:02:36 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ding", "Jiayuan", ""], ["Kejriwal", "Mayank", ""]]}, {"id": "2007.15072", "submitter": "Xin Dong", "authors": "Xin Dong, Yaxin Zhu, Yupeng Zhang, Zuohui Fu, Dongkuan Xu, Sen Yang,\n  Gerard de Melo", "title": "Leveraging Adversarial Training in Self-Learning for Cross-Lingual Text\n  Classification", "comments": "SIGIR 2020 (Short Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cross-lingual text classification, one seeks to exploit labeled data from\none language to train a text classification model that can then be applied to a\ncompletely different language. Recent multilingual representation models have\nmade it much easier to achieve this. Still, there may still be subtle\ndifferences between languages that are neglected when doing so. To address\nthis, we present a semi-supervised adversarial training process that minimizes\nthe maximal loss for label-preserving input perturbations. The resulting model\nthen serves as a teacher to induce labels for unlabeled target language samples\nthat can be used during further adversarial training, allowing us to gradually\nadapt our model to the target language. Compared with a number of strong\nbaselines, we observe significant gains in effectiveness on document and intent\nclassification for a diverse set of languages.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 19:38:35 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Dong", "Xin", ""], ["Zhu", "Yaxin", ""], ["Zhang", "Yupeng", ""], ["Fu", "Zuohui", ""], ["Xu", "Dongkuan", ""], ["Yang", "Sen", ""], ["de Melo", "Gerard", ""]]}, {"id": "2007.15074", "submitter": "Siyuan Feng", "authors": "Siyuan Feng", "title": "Exploiting Cross-Lingual Knowledge in Unsupervised Acoustic Modeling for\n  Low-Resource Languages", "comments": "Ph.D. Thesis Submitted in May 2020 in partial fulfilment of the\n  requirements for the Degree of Doctor of Philosophy in Electronic\n  Engineering, The Chinese University of Hong Kong (CUHK) 134 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Short version of Abstract) This thesis describes an investigation on\nunsupervised acoustic modeling (UAM) for automatic speech recognition (ASR) in\nthe zero-resource scenario, where only untranscribed speech data is assumed to\nbe available. UAM is not only important in addressing the general problem of\ndata scarcity in ASR technology development but also essential to many\nnon-mainstream applications, for examples, language protection, language\nacquisition and pathological speech assessment. The present study is focused on\ntwo research problems. The first problem concerns unsupervised discovery of\nbasic (subword level) speech units in a given language. Under the zero-resource\ncondition, the speech units could be inferred only from the acoustic signals,\nwithout requiring or involving any linguistic direction and/or constraints. The\nsecond problem is referred to as unsupervised subword modeling. In its essence\na frame-level feature representation needs to be learned from untranscribed\nspeech. The learned feature representation is the basis of subword unit\ndiscovery. It is desired to be linguistically discriminative and robust to\nnon-linguistic factors. Particularly extensive use of cross-lingual knowledge\nin subword unit discovery and modeling is a focus of this research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 19:45:17 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Feng", "Siyuan", ""]]}, {"id": "2007.15121", "submitter": "Arjun Roy", "authors": "Arjun Roy, Pavlos Fafalios, Asif Ekbal, Xiaofei Zhu, Stefan Dietze", "title": "Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents", "comments": "This is a pre-print version of the Journal paper published in J\n  Intell Inf Syst (2021) (Springer). https://rdcu.be/ckLiC", "journal-ref": null, "doi": "10.1007/s10844-021-00642-z", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 21:40:01 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 17:10:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Roy", "Arjun", ""], ["Fafalios", "Pavlos", ""], ["Ekbal", "Asif", ""], ["Zhu", "Xiaofei", ""], ["Dietze", "Stefan", ""]]}, {"id": "2007.15135", "submitter": "Hao Zhu", "authors": "Hao Zhu, Yonatan Bisk, Graham Neubig", "title": "The Return of Lexical Dependencies: Neural Lexicalized PCFGs", "comments": "Accepted at TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we demonstrate that $\\textit{context free grammar (CFG) based\nmethods for grammar induction benefit from modeling lexical dependencies}$.\nThis contrasts to the most popular current methods for grammar induction, which\nfocus on discovering $\\textit{either}$ constituents $\\textit{or}$ dependencies.\nPrevious approaches to marry these two disparate syntactic formalisms (e.g.\nlexicalized PCFGs) have been plagued by sparsity, making them unsuitable for\nunsupervised grammar induction. However, in this work, we present novel neural\nmodels of lexicalized PCFGs which allow us to overcome sparsity problems and\neffectively induce both constituents and dependencies within a single model.\nExperiments demonstrate that this unified framework results in stronger results\non both representations than achieved when modeling either formalism alone.\nCode is available at https://github.com/neulab/neural-lpcfg.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:12:49 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Zhu", "Hao", ""], ["Bisk", "Yonatan", ""], ["Neubig", "Graham", ""]]}, {"id": "2007.15153", "submitter": "Divya Gopinath", "authors": "Divya Gopinath, Monica Agrawal, Luke Murray, Steven Horng, David\n  Karger, David Sontag", "title": "Fast, Structured Clinical Documentation via Contextual Autocomplete", "comments": "Published in Machine Learning for Healthcare 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system that uses a learned autocompletion mechanism to\nfacilitate rapid creation of semi-structured clinical documentation. We\ndynamically suggest relevant clinical concepts as a doctor drafts a note by\nleveraging features from both unstructured and structured medical data. By\nconstraining our architecture to shallow neural networks, we are able to make\nthese suggestions in real time. Furthermore, as our algorithm is used to write\na note, we can automatically annotate the documentation with clean labels of\nclinical concepts drawn from medical vocabularies, making notes more structured\nand readable for physicians, patients, and future algorithms. To our knowledge,\nthis system is the only machine learning-based documentation utility for\nclinical notes deployed in a live hospital setting, and it reduces keystroke\nburden of clinical concepts by 67% in real environments.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 23:43:15 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Gopinath", "Divya", ""], ["Agrawal", "Monica", ""], ["Murray", "Luke", ""], ["Horng", "Steven", ""], ["Karger", "David", ""], ["Sontag", "David", ""]]}, {"id": "2007.15188", "submitter": "Jinyu Li", "authors": "Jinyu Li, Rui Zhao, Zhong Meng, Yanqing Liu, Wenning Wei, Sarangarajan\n  Parthasarathy, Vadim Mazalov, Zhenghao Wang, Lei He, Sheng Zhao, and Yifan\n  Gong", "title": "Developing RNN-T Models Surpassing High-Performance Hybrid Models with\n  Customization Capability", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of its streaming nature, recurrent neural network transducer (RNN-T)\nis a very promising end-to-end (E2E) model that may replace the popular hybrid\nmodel for automatic speech recognition. In this paper, we describe our recent\ndevelopment of RNN-T models with reduced GPU memory consumption during\ntraining, better initialization strategy, and advanced encoder modeling with\nfuture lookahead. When trained with Microsoft's 65 thousand hours of anonymized\ntraining data, the developed RNN-T model surpasses a very well trained hybrid\nmodel with both better recognition accuracy and lower latency. We further study\nhow to customize RNN-T models to a new domain, which is important for deploying\nE2E models to practical scenarios. By comparing several methods leveraging\ntext-only data in the new domain, we found that updating RNN-T's prediction and\njoint networks using text-to-speech generated from domain-specific text is the\nmost effective.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 02:35:20 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Li", "Jinyu", ""], ["Zhao", "Rui", ""], ["Meng", "Zhong", ""], ["Liu", "Yanqing", ""], ["Wei", "Wenning", ""], ["Parthasarathy", "Sarangarajan", ""], ["Mazalov", "Vadim", ""], ["Wang", "Zhenghao", ""], ["He", "Lei", ""], ["Zhao", "Sheng", ""], ["Gong", "Yifan", ""]]}, {"id": "2007.15207", "submitter": "Shayne Longpre", "authors": "Shayne Longpre, Yi Lu, Joachim Daiber", "title": "MKQA: A Linguistically Diverse Benchmark for Multilingual Open Domain\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in cross-lingual modeling depends on challenging, realistic, and\ndiverse evaluation sets. We introduce Multilingual Knowledge Questions and\nAnswers (MKQA), an open-domain question answering evaluation set comprising 10k\nquestion-answer pairs aligned across 26 typologically diverse languages (260k\nquestion-answer pairs in total). The goal of this dataset is to provide a\nchallenging benchmark for question answering quality across a wide set of\nlanguages. Answers are based on a language-independent data representation,\nmaking results comparable across languages and independent of language-specific\npassages. With 26 languages, this dataset supplies the widest range of\nlanguages to-date for evaluating question answering. We benchmark\nstate-of-the-art extractive question answering baselines, trained on Natural\nQuestions, including Multilingual BERT, and XLM-RoBERTa, in zero shot and\ntranslation settings. Results indicate this dataset is challenging, especially\nin low-resource languages.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:33:46 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Longpre", "Shayne", ""], ["Lu", "Yi", ""], ["Daiber", "Joachim", ""]]}, {"id": "2007.15211", "submitter": "Victor Dibia", "authors": "Victor Dibia", "title": "NeuralQA: A Usable Library for Question Answering (Contextual Query\n  Expansion + BERT) on Large Datasets", "comments": "Published at Proceedings of the 2020 Conference on Empirical Methods\n  in Natural Language Processing: System Demonstrations. (EMNLP 2020), Demo\n  track. 8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing tools for Question Answering (QA) have challenges that limit their\nuse in practice. They can be complex to set up or integrate with existing\ninfrastructure, do not offer configurable interactive interfaces, and do not\ncover the full set of subtasks that frequently comprise the QA pipeline (query\nexpansion, retrieval, reading, and explanation/sensemaking). To help address\nthese issues, we introduce NeuralQA - a usable library for QA on large\ndatasets. NeuralQA integrates well with existing infrastructure (e.g.,\nElasticSearch instances and reader models trained with the HuggingFace\nTransformers API) and offers helpful defaults for QA subtasks. It introduces\nand implements contextual query expansion (CQE) using a masked language model\n(MLM) as well as relevant snippets (RelSnip) - a method for condensing large\ndocuments into smaller passages that can be speedily processed by a document\nreader model. Finally, it offers a flexible user interface to support workflows\nfor research explorations (e.g., visualization of gradient-based explanations\nto support qualitative inspection of model behaviour) and large scale search\ndeployment. Code and documentation for NeuralQA is available as open source on\nGithub (https://github.com/victordibia/neuralqa}{Github).\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:38:30 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 03:06:09 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dibia", "Victor", ""]]}, {"id": "2007.15280", "submitter": "Xi Victoria Lin", "authors": "Jichuan Zeng, Xi Victoria Lin, Caiming Xiong, Richard Socher, Michael\n  R. Lyu, Irwin King, Steven C.H. Hoi", "title": "Photon: A Robust Cross-Domain Text-to-SQL System", "comments": "ACL 2020 system demonstration paper extended . The first two authors\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language interfaces to databases (NLIDB) democratize end user access\nto relational data. Due to fundamental differences between natural language\ncommunication and programming, it is common for end users to issue questions\nthat are ambiguous to the system or fall outside the semantic scope of its\nunderlying query language. We present Photon, a robust, modular, cross-domain\nNLIDB that can flag natural language input to which a SQL mapping cannot be\nimmediately determined. Photon consists of a strong neural semantic parser\n(63.2\\% structure accuracy on the Spider dev benchmark), a human-in-the-loop\nquestion corrector, a SQL executor and a response generator. The question\ncorrector is a discriminative neural sequence editor which detects confusion\nspan(s) in the input question and suggests rephrasing until a translatable\ninput is given by the user or a maximum number of iterations are conducted.\nExperiments on simulated data show that the proposed method effectively\nimproves the robustness of text-to-SQL system against untranslatable user\ninput. The live demo of our system is available at http://naturalsql.com.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 07:44:48 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 08:59:06 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zeng", "Jichuan", ""], ["Lin", "Xi Victoria", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2007.15296", "submitter": "Paul Tardy", "authors": "Paul Tardy, Louis de Seynes, Fran\\c{c}ois Hernandez, Vincent Nguyen,\n  David Janiszek, Yannick Est\\`eve", "title": "Leverage Unlabeled Data for Abstractive Speech Summarization with\n  Self-Supervised Learning and Back-Summarization", "comments": "To be published in Proceedings of SPECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised approaches for Neural Abstractive Summarization require large\nannotated corpora that are costly to build. We present a French meeting\nsummarization task where reports are predicted based on the automatic\ntranscription of the meeting audio recordings. In order to build a corpus for\nthis task, it is necessary to obtain the (automatic or manual) transcription of\neach meeting, and then to segment and align it with the corresponding manual\nreport to produce training examples suitable for training. On the other hand,\nwe have access to a very large amount of unaligned data, in particular reports\nwithout corresponding transcription. Reports are professionally written and\nwell formatted making pre-processing straightforward. In this context, we study\nhow to take advantage of this massive amount of unaligned data using two\napproaches (i) self-supervised pre-training using a target-side denoising\nencoder-decoder model; (ii) back-summarization i.e. reversing the summarization\nprocess by learning to predict the transcription given the report, in order to\nalign single reports with generated transcription, and use this synthetic\ndataset for further training. We report large improvements compared to the\nprevious baseline (trained on aligned data only) for both approaches on two\nevaluation sets. Moreover, combining the two gives even better results,\noutperforming the baseline by a large margin of +6 ROUGE-1 and ROUGE-L and +5\nROUGE-2 on two evaluation sets\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 08:22:47 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 10:12:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tardy", "Paul", ""], ["de Seynes", "Louis", ""], ["Hernandez", "Fran\u00e7ois", ""], ["Nguyen", "Vincent", ""], ["Janiszek", "David", ""], ["Est\u00e8ve", "Yannick", ""]]}, {"id": "2007.15342", "submitter": "Ramon Ferrer-i-Cancho", "authors": "Ramon Ferrer-i-Cancho, Carlos G\\'omez-Rodr\\'iguez, Juan Luis Esteban\n  and Llu\\'is Alemany-Puig", "title": "The optimality of syntactic dependency distances", "comments": "A clearer explanation of the importance of the article (for research\n  in quantitative syntax and quantitative typology) and its main contribution\n  with respect to previous research (the new score Omega versus other\n  traditional measures of dependency distance)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often stated that human languages, as other biological systems, are\nshaped by cost-cutting pressures but, to what extent? Attempts to quantify the\ndegree of optimality of languages by means of an optimality score have been\nscarce and focused mostly on English. Here we recast the problem of the\noptimality of the word order of a sentence as an optimization problem on a\nspatial network where the vertices are words, arcs indicate syntactic\ndependencies and the space is defined by the linear order of the words in the\nsentence. We introduce a new score to quantify the cognitive pressure to reduce\nthe distance between linked words in a sentence. The analysis of sentences from\n93 languages representing 19 linguistic families reveals that half of languages\nare optimized to a 70% or more. The score indicates that distances are not\nsignificantly reduced in a few languages and confirms two theoretical\npredictions, i.e. that longer sentences are more optimized and that distances\nare more likely to be longer than expected by chance in short sentences. We\npresent a new hierarchical ranking of languages by their degree of\noptimization. The statistical advantages of the new score call for a\nreevaluation of the evolution of dependency distance over time in languages as\nwell as the relationship between dependency distance and linguistic competence.\nFinally, the principles behind the design of the score can be extended to\ndevelop more powerful normalizations of topological distances or physical\ndistances in more dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 09:40:41 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 22:15:22 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 13:25:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Esteban", "Juan Luis", ""], ["Alemany-Puig", "Llu\u00eds", ""]]}, {"id": "2007.15619", "submitter": "Raunak Shah", "authors": "Tushar Goswamy, Naishadh Parmar, Ayush Gupta, Vatsalya Tandon, Raunak\n  Shah, Varun Goyal, Sanyog Gupta, Karishma Laud, Shivam Gupta, Sudhanshu\n  Mishra, Ashutosh Modi", "title": "AI-based Monitoring and Response System for Hospital Preparedness\n  towards COVID-19 in Southeast Asia", "comments": "5 pages, 5 figures. Accepted to the ICML 2020 Workshop on Healthcare\n  Systems, Population Health, and the Role of Health-Tech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research paper proposes a COVID-19 monitoring and response system to\nidentify the surge in the volume of patients at hospitals and shortage of\ncritical equipment like ventilators in South-east Asian countries, to\nunderstand the burden on health facilities. This can help authorities in these\nregions with resource planning measures to redirect resources to the regions\nidentified by the model. Due to the lack of publicly available data on the\ninflux of patients in hospitals, or the shortage of equipment, ICU units or\nhospital beds that regions in these countries might be facing, we leverage\nTwitter data for gleaning this information. The approach has yielded accurate\nresults for states in India, and we are working on validating the model for the\nremaining countries so that it can serve as a reliable tool for authorities to\nmonitor the burden on hospitals.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 17:39:13 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Goswamy", "Tushar", ""], ["Parmar", "Naishadh", ""], ["Gupta", "Ayush", ""], ["Tandon", "Vatsalya", ""], ["Shah", "Raunak", ""], ["Goyal", "Varun", ""], ["Gupta", "Sanyog", ""], ["Laud", "Karishma", ""], ["Gupta", "Shivam", ""], ["Mishra", "Sudhanshu", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.15620", "submitter": "Dan Bareket", "authors": "Dan Bareket and Reut Tsarfaty", "title": "Neural Modeling for Named Entities and Morphology (NEMO^2)", "comments": "Accepted to TACL. This is a pre-MIT Press publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Named Entity Recognition (NER) is a fundamental NLP task, commonly formulated\nas classification over a sequence of tokens. Morphologically-Rich Languages\n(MRLs) pose a challenge to this basic formulation, as the boundaries of Named\nEntities do not necessarily coincide with token boundaries, rather, they\nrespect morphological boundaries. To address NER in MRLs we then need to answer\ntwo fundamental questions, namely, what are the basic units to be labeled, and\nhow can these units be detected and classified in realistic settings, i.e.,\nwhere no gold morphology is available. We empirically investigate these\nquestions on a novel NER benchmark, with parallel tokenlevel and morpheme-level\nNER annotations, which we develop for Modern Hebrew, a morphologically\nrich-and-ambiguous language. Our results show that explicitly modeling\nmorphological boundaries leads to improved NER performance, and that a novel\nhybrid architecture, in which NER precedes and prunes morphological\ndecomposition, greatly outperforms the standard pipeline, where morphological\ndecomposition strictly precedes NER, setting a new performance bar for both\nHebrew NER and Hebrew morphological decomposition tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 17:43:14 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 07:31:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bareket", "Dan", ""], ["Tsarfaty", "Reut", ""]]}, {"id": "2007.15681", "submitter": "Matej Martinc", "authors": "Matej Martinc, Bla\\v{z} \\v{S}krlj, Sergej Pirkmajer, Nada Lavra\\v{c},\n  Bojan Cestnik, Martin Marzidov\\v{s}ek, Senja Pollak", "title": "COVID-19 therapy target discovery with context-aware literature mining", "comments": "Accepted to the 23rd International Conference on Discovery Science\n  (DS 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-61527-7_8", "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The abundance of literature related to the widespread COVID-19 pandemic is\nbeyond manual inspection of a single expert. Development of systems, capable of\nautomatically processing tens of thousands of scientific publications with the\naim to enrich existing empirical evidence with literature-based associations is\nchallenging and relevant. We propose a system for contextualization of\nempirical expression data by approximating relations between entities, for\nwhich representations were learned from one of the largest COVID-19-related\nliterature corpora. In order to exploit a larger scientific context by transfer\nlearning, we propose a novel embedding generation technique that leverages\nSciBERT language model pretrained on a large multi-domain corpus of scientific\npublications and fine-tuned for domain adaptation on the CORD-19 dataset. The\nconducted manual evaluation by the medical expert and the quantitative\nevaluation based on therapy targets identified in the related work suggest that\nthe proposed method can be successfully employed for COVID-19 therapy target\ndiscovery and that it outperforms the baseline FastText method by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 18:37:36 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:19:10 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Martinc", "Matej", ""], ["\u0160krlj", "Bla\u017e", ""], ["Pirkmajer", "Sergej", ""], ["Lavra\u010d", "Nada", ""], ["Cestnik", "Bojan", ""], ["Marzidov\u0161ek", "Martin", ""], ["Pollak", "Senja", ""]]}, {"id": "2007.15700", "submitter": "Radu Tudor Ionescu", "authors": "Mihaela G\\u{a}man, Radu Tudor Ionescu", "title": "The Unreasonable Effectiveness of Machine Learning in Moldavian versus\n  Romanian Dialect Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide a follow-up on the Moldavian versus Romanian\nCross-Dialect Topic Identification (MRC) shared task of the VarDial 2019\nEvaluation Campaign. The shared task included two sub-task types: one that\nconsisted in discriminating between the Moldavian and the Romanian dialects and\none that consisted in classifying documents by topic across the two dialects of\nRomanian. Participants achieved impressive scores, e.g. the top model for\nMoldavian versus Romanian dialect identification obtained a macro F1 score of\n0.895. We conduct a subjective evaluation by human annotators, showing that\nhumans attain much lower accuracy rates compared to machine learning (ML)\nmodels. Hence, it remains unclear why the methods proposed by participants\nattain such high accuracy rates. Our goal is to understand (i) why the proposed\nmethods work so well (by visualizing the discriminative features) and (ii) to\nwhat extent these methods can keep their high accuracy levels, e.g. when we\nshorten the text samples to single sentences or when use tweets at inference\ntime. A secondary goal of our work is to propose an improved ML model using\nensemble learning. Our experiments show that ML models can accurately identify\nthe dialects, even at the sentence level and across different domains (news\narticles versus tweets). We also analyze the most discriminative features of\nthe best performing models, providing some explanations behind the decisions\ntaken by these models. Interestingly, we learn new dialectal patterns\npreviously unknown to us or to our human annotators. Furthermore, we conduct\nexperiments showing that the machine learning performance on the MRC shared\ntask can be improved through an ensemble based on classifier stacking.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 19:25:00 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["G\u0103man", "Mihaela", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2007.15779", "submitter": "Tristan Naumann", "authors": "Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong\n  Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon", "title": "Domain-Specific Language Model Pretraining for Biomedical Natural\n  Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining large neural language models, such as BERT, has led to impressive\ngains on many natural language processing (NLP) tasks. However, most\npretraining efforts focus on general domain corpora, such as newswire and Web.\nA prevailing assumption is that even domain-specific pretraining can benefit by\nstarting from general-domain language models. In this paper, we challenge this\nassumption by showing that for domains with abundant unlabeled text, such as\nbiomedicine, pretraining language models from scratch results in substantial\ngains over continual pretraining of general-domain language models. To\nfacilitate this investigation, we compile a comprehensive biomedical NLP\nbenchmark from publicly-available datasets. Our experiments show that\ndomain-specific pretraining serves as a solid foundation for a wide range of\nbiomedical NLP tasks, leading to new state-of-the-art results across the board.\nFurther, in conducting a thorough evaluation of modeling choices, both for\npretraining and task-specific fine-tuning, we discover that some common\npractices are unnecessary with BERT models, such as using complex tagging\nschemes in named entity recognition (NER). To help accelerate research in\nbiomedical NLP, we have released our state-of-the-art pretrained and\ntask-specific models for the community, and created a leaderboard featuring our\nBLURB benchmark (short for Biomedical Language Understanding & Reasoning\nBenchmark) at https://aka.ms/BLURB.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 00:04:15 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 02:01:07 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 22:26:29 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 19:13:59 GMT"}, {"version": "v5", "created": "Fri, 25 Jun 2021 00:38:22 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Gu", "Yu", ""], ["Tinn", "Robert", ""], ["Cheng", "Hao", ""], ["Lucas", "Michael", ""], ["Usuyama", "Naoto", ""], ["Liu", "Xiaodong", ""], ["Naumann", "Tristan", ""], ["Gao", "Jianfeng", ""], ["Poon", "Hoifung", ""]]}, {"id": "2007.15780", "submitter": "Cristina Garbacea", "authors": "Cristina Garbacea, Qiaozhu Mei", "title": "Neural Language Generation: Formulation, Methods, and Evaluation", "comments": "70 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural network-based generative modeling have reignited\nthe hopes in having computer systems capable of seamlessly conversing with\nhumans and able to understand natural language. Neural architectures have been\nemployed to generate text excerpts to various degrees of success, in a\nmultitude of contexts and tasks that fulfil various user needs. Notably, high\ncapacity deep learning models trained on large scale datasets demonstrate\nunparalleled abilities to learn patterns in the data even in the lack of\nexplicit supervision signals, opening up a plethora of new possibilities\nregarding producing realistic and coherent texts. While the field of natural\nlanguage generation is evolving rapidly, there are still many open challenges\nto address. In this survey we formally define and categorize the problem of\nnatural language generation. We review particular application tasks that are\ninstantiations of these general formulations, in which generating natural\nlanguage is of practical importance. Next we include a comprehensive outline of\nmethods and neural architectures employed for generating diverse texts.\nNevertheless, there is no standard way to assess the quality of text produced\nby these generative models, which constitutes a serious bottleneck towards the\nprogress of the field. To this end, we also review current approaches to\nevaluating natural language generation systems. We hope this survey will\nprovide an informative overview of formulations, methods, and assessments of\nneural natural language generation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 00:08:28 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Garbacea", "Cristina", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2007.15797", "submitter": "Xuan Dong", "authors": "Xuan Dong and Donald S. Williamson", "title": "A Pyramid Recurrent Network for Predicting Crowdsourced Speech-Quality\n  Ratings of Real-World Signals", "comments": "Proceeding of INTERSPEECH", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-world capabilities of objective speech quality measures are limited\nsince current measures (1) are developed from simulated data that does not\nadequately model real environments; or they (2) predict objective scores that\nare not always strongly correlated with subjective ratings. Additionally, a\nlarge dataset of real-world signals with listener quality ratings does not\ncurrently exist, which would help facilitate real-world assessment. In this\npaper, we collect and predict the perceptual quality of real-world speech\nsignals that are evaluated by human listeners. We first collect a large quality\nrating dataset by conducting crowdsourced listening studies on two real-world\ncorpora. We further develop a novel approach that predicts human quality\nratings using a pyramid bidirectional long short term memory (pBLSTM) network\nwith an attention mechanism. The results show that the proposed model achieves\nstatistically lower estimation errors than prior assessment approaches, where\nthe predicted scores strongly correlate with human judgments.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 01:46:06 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Dong", "Xuan", ""], ["Williamson", "Donald S.", ""]]}, {"id": "2007.15813", "submitter": "Hongyu Zhang", "authors": "Thomas Dowdell, Hongyu Zhang", "title": "Language Modelling for Source Code with Transformer-XL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been found that software, like natural language texts, exhibits\n\"naturalness\", which can be captured by statistical language models. In recent\nyears, neural language models have been proposed to represent the naturalness\nof software through deep learning. In this paper, we conduct an experimental\nevaluation of state-of-the-art neural language models for source code,\nincluding RNN-based models and Transformer-XL based models. Through experiments\non a large-scale Python code corpus, we find that the Transformer-XL model\noutperforms RNN-based models (including LSTM and GRU models) in capturing the\nnaturalness of software, with far less computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 02:42:18 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Dowdell", "Thomas", ""], ["Zhang", "Hongyu", ""]]}, {"id": "2007.15823", "submitter": "Cristina Garbacea", "authors": "Cristina Garbacea, Mengtian Guo, Samuel Carton, Qiaozhu Mei", "title": "Explainable Prediction of Text Complexity: The Missing Preliminaries for\n  Text Simplification", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text simplification reduces the language complexity of professional content\nfor accessibility purposes. End-to-end neural network models have been widely\nadopted to directly generate the simplified version of input text, usually\nfunctioning as a blackbox. We show that text simplification can be decomposed\ninto a compact pipeline of tasks to ensure the transparency and explainability\nof the process. The first two steps in this pipeline are often neglected: 1) to\npredict whether a given piece of text needs to be simplified, and 2) if yes, to\nidentify complex parts of the text. The two tasks can be solved separately\nusing either lexical or deep learning methods, or solved jointly. Simply\napplying explainable complexity prediction as a preliminary step, the\nout-of-sample text simplification performance of the state-of-the-art,\nblack-box simplification models can be improved by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 03:33:37 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:28:32 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Garbacea", "Cristina", ""], ["Guo", "Mengtian", ""], ["Carton", "Samuel", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "2007.15868", "submitter": "Shota Horiguchi", "authors": "Shota Horiguchi, Yusuke Fujita, Kenji Nagamatsu", "title": "Utterance-Wise Meeting Transcription System Using Asynchronous\n  Distributed Microphones", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework for meeting transcription using asynchronous microphones is\nproposed in this paper. It consists of audio synchronization, speaker\ndiarization, utterance-wise speech enhancement using guided source separation,\nautomatic speech recognition, and duplication reduction. Doing speaker\ndiarization before speech enhancement enables the system to deal with\noverlapped speech without considering sampling frequency mismatch between\nmicrophones. Evaluation on our real meeting datasets showed that our framework\nachieved a character error rate (CER) of 28.7 % by using 11 distributed\nmicrophones, while a monaural microphone placed on the center of the table had\na CER of 38.2 %. We also showed that our framework achieved CER of 21.8 %,\nwhich is only 2.1 percentage points higher than the CER in headset\nmicrophone-based transcription.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 06:50:04 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Horiguchi", "Shota", ""], ["Fujita", "Yusuke", ""], ["Nagamatsu", "Kenji", ""]]}, {"id": "2007.15871", "submitter": "Han Zhang", "authors": "Han Zhang", "title": "Improving NER's Performance with Massive financial corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large deep neural networks needs massive high quality annotation\ndata, but the time and labor costs are too expensive for small business. We\nstart a company-name recognition task with a small scale and low quality\ntraining data, then using skills to enhanced model training speed and\npredicting performance with minimum labor cost. The methods we use involve\npre-training a lite language model such as Albert-small or Electra-small in\nfinancial corpus, knowledge of distillation and multi-stage learning. The\nresult is that we raised the recall rate by nearly 20 points and get 4 times as\nfast as BERT-CRF model.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 07:00:34 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Zhang", "Han", ""]]}, {"id": "2007.15916", "submitter": "Justin Van Der Hout", "authors": "Justin van der Hout, Zolt\\'an D'Haese, Mark Hasegawa-Johnson, Odette\n  Scharenborg", "title": "Evaluating Automatically Generated Phoneme Captions for Images", "comments": "Accepted at Interspeech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image2Speech is the relatively new task of generating a spoken description of\nan image. This paper presents an investigation into the evaluation of this\ntask. For this, first an Image2Speech system was implemented which generates\nimage captions consisting of phoneme sequences. This system outperformed the\noriginal Image2Speech system on the Flickr8k corpus. Subsequently, these\nphoneme captions were converted into sentences of words. The captions were\nrated by human evaluators for their goodness of describing the image. Finally,\nseveral objective metric scores of the results were correlated with these human\nratings. Although BLEU4 does not perfectly correlate with human ratings, it\nobtained the highest correlation among the investigated metrics, and is the\nbest currently existing metric for the Image2Speech task. Current metrics are\nlimited by the fact that they assume their input to be words. A more\nappropriate metric for the Image2Speech task should assume its input to be\nparts of words, i.e. phonemes, instead.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 09:21:13 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["van der Hout", "Justin", ""], ["D'Haese", "Zolt\u00e1n", ""], ["Hasegawa-Johnson", "Mark", ""], ["Scharenborg", "Odette", ""]]}, {"id": "2007.15960", "submitter": "Xiangpeng Wei", "authors": "Xiangpeng Wei, Rongxiang Weng, Yue Hu, Luxi Xing, Heng Yu, Weihua Luo", "title": "On Learning Universal Representations Across Languages", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated the overwhelming advantage of cross-lingual\npre-trained models (PTMs), such as multilingual BERT and XLM, on cross-lingual\nNLP tasks. However, existing approaches essentially capture the co-occurrence\namong tokens through involving the masked language model (MLM) objective with\ntoken-level cross entropy. In this work, we extend these approaches to learn\nsentence-level representations and show the effectiveness on cross-lingual\nunderstanding and generation. Specifically, we propose a Hierarchical\nContrastive Learning (HiCTL) method to (1) learn universal representations for\nparallel sentences distributed in one or multiple languages and (2) distinguish\nthe semantically-related words from a shared cross-lingual vocabulary for each\nsentence. We conduct evaluations on two challenging cross-lingual tasks, XTREME\nand machine translation. Experimental results show that the HiCTL outperforms\nthe state-of-the-art XLM-R by an absolute gain of 4.2% accuracy on the XTREME\nbenchmark as well as achieves substantial improvements on both of the\nhigh-resource and low-resource English-to-X translation tasks over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 10:58:39 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 02:50:21 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 08:10:55 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 02:30:57 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wei", "Xiangpeng", ""], ["Weng", "Rongxiang", ""], ["Hu", "Yue", ""], ["Xing", "Luxi", ""], ["Yu", "Heng", ""], ["Luo", "Weihua", ""]]}, {"id": "2007.16006", "submitter": "Lucas Rettenmeier", "authors": "Lucas Rettenmeier", "title": "Word Embeddings: Stability and Semantic Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are computed by a class of techniques within natural language\nprocessing (NLP), that create continuous vector representations of words in a\nlanguage from a large text corpus. The stochastic nature of the training\nprocess of most embedding techniques can lead to surprisingly strong\ninstability, i.e. subsequently applying the same technique to the same data\ntwice, can produce entirely different results. In this work, we present an\nexperimental study on the instability of the training process of three of the\nmost influential embedding techniques of the last decade: word2vec, GloVe and\nfastText. Based on the experimental results, we propose a statistical model to\ndescribe the instability of embedding techniques and introduce a novel metric\nto measure the instability of the representation of an individual word.\nFinally, we propose a method to minimize the instability - by computing a\nmodified average over multiple runs - and apply it to a specific linguistic\nproblem: The detection and quantification of semantic change, i.e. measuring\nchanges in the meaning and usage of words over time.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 16:03:50 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Rettenmeier", "Lucas", ""]]}, {"id": "2007.16007", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "Exploring Swedish & English fastText Embeddings for NER with the\n  Transformer", "comments": "11 pages, 2 figures, 8 tables; added new references and clarification\n  about other possible models for NER", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, our main contributions are that embeddings from relatively\nsmaller corpora can outperform ones from larger corpora and we make the new\nSwedish analogy test set publicly available. To achieve a good network\nperformance in natural language processing (NLP) downstream tasks, several\nfactors play important roles: dataset size, the right hyper-parameters, and\nwell-trained embeddings. We show that, with the right set of hyper-parameters,\ngood network performance can be reached even on smaller datasets. We evaluate\nthe embeddings at both the intrinsic and extrinsic levels. The embeddings are\ndeployed with the Transformer in named entity recognition (NER) task and\nsignificance tests conducted. This is done for both Swedish and English. We\nobtain better performance in both languages on the downstream task with smaller\ntraining data, compared to recently released, Common Crawl versions; and\ncharacter n-grams appear useful for Swedish, a morphologically rich language.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:51:09 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 06:06:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2007.16008", "submitter": "Joseph Worsham", "authors": "Joseph Worsham and Jugal Kalita", "title": "Multi-task learning for natural language processing in the 2020s: where\n  are we going?", "comments": "12 pages, 2 figures. Published in Elsevier Pattern Recognition\n  Letters Volume 136. Accepted manuscript published here", "journal-ref": "Pattern Recognition Letters 136 (2020) 120-126", "doi": "10.1016/j.patrec.2020.05.031", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) significantly pre-dates the deep learning era, and\nit has seen a resurgence in the past few years as researchers have been\napplying MTL to deep learning solutions for natural language tasks. While\nsteady MTL research has always been present, there is a growing interest driven\nby the impressive successes published in the related fields of transfer\nlearning and pre-training, such as BERT, and the release of new challenge\nproblems, such as GLUE and the NLP Decathlon (decaNLP). These efforts place\nmore focus on how weights are shared across networks, evaluate the re-usability\nof network components and identify use cases where MTL can significantly\noutperform single-task solutions. This paper strives to provide a comprehensive\nsurvey of the numerous recent MTL contributions to the field of natural\nlanguage processing and provide a forum to focus efforts on the hardest\nunsolved problems in the next decade. While novel models that improve\nperformance on NLP benchmarks are continually produced, lasting MTL challenges\nremain unsolved which could hold the key to better language understanding,\nknowledge discovery and natural language interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 13:44:57 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Worsham", "Joseph", ""], ["Kalita", "Jugal", ""]]}, {"id": "2007.16009", "submitter": "Tom Williams", "authors": "Poulomi Pal and Tom Williams", "title": "Toward Givenness Hierarchy Theoretic Natural Language Generation", "comments": "Extended Abstract accepted for (non-archival) presentation at\n  Advances in Cognitive Systems 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-capable interactive robots participating in dialogues with human\ninterlocutors must be able to naturally and efficiently communicate about the\nentities in their environment. A key aspect of such communication is the use of\nanaphoric language. The linguistic theory of the Givenness Hierarchy(GH)\nsuggests that humans use anaphora based on the cognitive statuses their\nreferents have in the minds of their interlocutors. In previous work,\nresearchers presented GH-theoretic approaches to robot anaphora understanding.\nIn this paper we describe how the GH might need to be used quite differently to\nfacilitate robot anaphora generation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 17:51:29 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Pal", "Poulomi", ""], ["Williams", "Tom", ""]]}, {"id": "2007.16010", "submitter": "Subhadip Maji", "authors": "Subhadip Maji, Arijit Ghosh Chowdhury, Raghav Bali and Vamsi M\n  Bhandaru", "title": "Exclusion and Inclusion -- A model agnostic approach to feature\n  importance in DNNs", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks in NLP have enabled systems to learn complex non-linear\nrelationships. One of the major bottlenecks towards being able to use DNNs for\nreal world applications is their characterization as black boxes. To solve this\nproblem, we introduce a model agnostic algorithm which calculates phrase-wise\nimportance of input features. We contend that our method is generalizable to a\ndiverse set of tasks, by carrying out experiments for both Regression and\nClassification. We also observe that our approach is robust to outliers,\nimplying that it only captures the essential aspects of the input.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 07:50:53 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Maji", "Subhadip", ""], ["Chowdhury", "Arijit Ghosh", ""], ["Bali", "Raghav", ""], ["Bhandaru", "Vamsi M", ""]]}, {"id": "2007.16011", "submitter": "Nagender Aneja", "authors": "Sandhya Aneja and Siti Nur Afikah Bte Abdul Mazid and Nagender Aneja", "title": "Neural Machine Translation model for University Email Application", "comments": "International Conference on Natural Language Processing (ICNLP 2020),\n  July 11-13, 2020", "journal-ref": "International Conference on Natural Language Processing (ICNLP\n  2020), July 11-13, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation has many applications such as news translation, email\ntranslation, official letter translation etc. Commercial translators, e.g.\nGoogle Translation lags in regional vocabulary and are unable to learn the\nbilingual text in the source and target languages within the input. In this\npaper, a regional vocabulary-based application-oriented Neural Machine\nTranslation (NMT) model is proposed over the data set of emails used at the\nUniversity for communication over a period of three years. A state-of-the-art\nSequence-to-Sequence Neural Network for ML -> EN and EN -> ML translations is\ncompared with Google Translate using Gated Recurrent Unit Recurrent Neural\nNetwork machine translation model with attention decoder. The low BLEU score of\nGoogle Translation in comparison to our model indicates that the application\nbased regional models are better. The low BLEU score of EN -> ML of our model\nand Google Translation indicates that the Malay Language has complex language\nfeatures corresponding to English.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 15:05:16 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Aneja", "Sandhya", ""], ["Mazid", "Siti Nur Afikah Bte Abdul", ""], ["Aneja", "Nagender", ""]]}, {"id": "2007.16012", "submitter": "Josh Payne", "authors": "Josh Payne, Mario Srouji, Dian Ang Yap, Vineet Kosaraju", "title": "BERT Learns (and Teaches) Chemistry", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computational organic chemistry is becoming increasingly data-driven.\nThere remain a large number of important unsolved problems in this area such as\nproduct prediction given reactants, drug discovery, and metric-optimized\nmolecule synthesis, but efforts to solve these problems using machine learning\nhave also increased in recent years. In this work, we propose the use of\nattention to study functional groups and other property-impacting molecular\nsubstructures from a data-driven perspective, using a transformer-based model\n(BERT) on datasets of string representations of molecules and analyzing the\nbehavior of its attention heads. We then apply the representations of\nfunctional groups and atoms learned by the model to tackle problems of\ntoxicity, solubility, drug-likeness, and synthesis accessibility on smaller\ndatasets using the learned representations as features for graph convolution\nand attention models on the graph structure of molecules, as well as\nfine-tuning of BERT. Finally, we propose the use of attention visualization as\na helpful tool for chemistry practitioners and students to quickly identify\nimportant substructures in various chemical properties.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 00:23:07 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Payne", "Josh", ""], ["Srouji", "Mario", ""], ["Yap", "Dian Ang", ""], ["Kosaraju", "Vineet", ""]]}, {"id": "2007.16013", "submitter": "Denis Filimonov", "authors": "Denis Filimonov, Ravi Teja Gadde, Ariya Rastrow", "title": "Neural Composition: Learning to Generate from Multiple Models", "comments": "Self-Supervised Learning for Speech and Audio Processing Workshop @\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposing models into multiple components is critically important in many\napplications such as language modeling (LM) as it enables adapting individual\ncomponents separately and biasing of some components to the user's personal\npreferences. Conventionally, contextual and personalized adaptation for\nlanguage models, are achieved through class-based factorization, which requires\nclass-annotated data, or through biasing to individual phrases which is limited\nin scale. In this paper, we propose a system that combines model-defined\ncomponents, by learning when to activate the generation process from each\nindividual component, and how to combine probability distributions from each\ncomponent, directly from unlabeled text data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 22:58:53 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 23:41:47 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Filimonov", "Denis", ""], ["Gadde", "Ravi Teja", ""], ["Rastrow", "Ariya", ""]]}, {"id": "2007.16127", "submitter": "Monica Agrawal", "authors": "Monica Agrawal, Chloe O'Connell, Yasmin Fatemi, Ariel Levy, David\n  Sontag", "title": "Robust Benchmarking for Machine Learning of Clinical Entity Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical studies often require understanding elements of a patient's\nnarrative that exist only in free text clinical notes. To transform notes into\nstructured data for downstream use, these elements are commonly extracted and\nnormalized to medical vocabularies. In this work, we audit the performance of\nand indicate areas of improvement for state-of-the-art systems. We find that\nhigh task accuracies for clinical entity normalization systems on the 2019 n2c2\nShared Task are misleading, and underlying performance is still brittle.\nNormalization accuracy is high for common concepts (95.3%), but much lower for\nconcepts unseen in training data (69.3%). We demonstrate that current\napproaches are hindered in part by inconsistencies in medical vocabularies,\nlimitations of existing labeling schemas, and narrow evaluation techniques. We\nreformulate the annotation framework for clinical entity extraction to factor\nin these issues to allow for robust end-to-end system benchmarking. We evaluate\nconcordance of annotations from our new framework between two annotators and\nachieve a Jaccard similarity of 0.73 for entity recognition and an agreement of\n0.83 for entity normalization. We propose a path forward to address the\ndemonstrated need for the creation of a reference standard to spur method\ndevelopment in entity recognition and normalization.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:14:05 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Agrawal", "Monica", ""], ["O'Connell", "Chloe", ""], ["Fatemi", "Yasmin", ""], ["Levy", "Ariel", ""], ["Sontag", "David", ""]]}, {"id": "2007.16152", "submitter": "Patrick Schrempf", "authors": "Patrick Schrempf, Hannah Watson, Shadia Mikhael, Maciej Pajak,\n  Mat\\'u\\v{s} Falis, Aneta Lisowska, Keith W. Muir, David Harris-Birtill,\n  Alison Q. O'Neil", "title": "Paying Per-label Attention for Multi-label Extraction from Radiology\n  Reports", "comments": "Accepted to MICCAI 2020 LABELS workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training medical image analysis models requires large amounts of expertly\nannotated data which is time-consuming and expensive to obtain. Images are\noften accompanied by free-text radiology reports which are a rich source of\ninformation. In this paper, we tackle the automated extraction of structured\nlabels from head CT reports for imaging of suspected stroke patients, using\ndeep learning. Firstly, we propose a set of 31 labels which correspond to\nradiographic findings (e.g. hyperdensity) and clinical impressions (e.g.\nhaemorrhage) related to neurological abnormalities. Secondly, inspired by\nprevious work, we extend existing state-of-the-art neural network models with a\nlabel-dependent attention mechanism. Using this mechanism and simple synthetic\ndata augmentation, we are able to robustly extract many labels with a single\nmodel, classified according to the radiologist's reporting (positive,\nuncertain, negative). This approach can be used in further research to\neffectively extract many labels from medical text.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:11:09 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 16:17:18 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 17:08:51 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Schrempf", "Patrick", ""], ["Watson", "Hannah", ""], ["Mikhael", "Shadia", ""], ["Pajak", "Maciej", ""], ["Falis", "Mat\u00fa\u0161", ""], ["Lisowska", "Aneta", ""], ["Muir", "Keith W.", ""], ["Harris-Birtill", "David", ""], ["O'Neil", "Alison Q.", ""]]}, {"id": "2007.16193", "submitter": "Xutai Ma", "authors": "Xutai Ma, Mohammad Javad Dousti, Changhan Wang, Jiatao Gu, Juan Pino", "title": "SimulEval: An Evaluation Toolkit for Simultaneous Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous translation on both text and speech focuses on a real-time and\nlow-latency scenario where the model starts translating before reading the\ncomplete source input. Evaluating simultaneous translation models is more\ncomplex than offline models because the latency is another factor to consider\nin addition to translation quality. The research community, despite its growing\nfocus on novel modeling approaches to simultaneous translation, currently lacks\na universal evaluation procedure. Therefore, we present SimulEval, an\neasy-to-use and general evaluation toolkit for both simultaneous text and\nspeech translation. A server-client scheme is introduced to create a\nsimultaneous translation scenario, where the server sends source input and\nreceives predictions for evaluation and the client executes customized\npolicies. Given a policy, it automatically performs simultaneous decoding and\ncollectively reports several popular latency metrics. We also adapt latency\nmetrics from text simultaneous translation to the speech task. Additionally,\nSimulEval is equipped with a visualization interface to provide better\nunderstanding of the simultaneous decoding process of a system. SimulEval has\nalready been extensively used for the IWSLT 2020 shared task on simultaneous\nspeech translation. Code will be released upon publication.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 17:44:41 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ma", "Xutai", ""], ["Dousti", "Mohammad Javad", ""], ["Wang", "Changhan", ""], ["Gu", "Jiatao", ""], ["Pino", "Juan", ""]]}]