[{"id": "1711.00043", "submitter": "Guillaume Lample", "authors": "Guillaume Lample, Alexis Conneau, Ludovic Denoyer, Marc'Aurelio\n  Ranzato", "title": "Unsupervised Machine Translation Using Monolingual Corpora Only", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation has recently achieved impressive performance thanks to\nrecent advances in deep learning and the availability of large-scale parallel\ncorpora. There have been numerous attempts to extend these successes to\nlow-resource language pairs, yet requiring tens of thousands of parallel\nsentences. In this work, we take this research direction to the extreme and\ninvestigate whether it is possible to learn to translate even without any\nparallel data. We propose a model that takes sentences from monolingual corpora\nin two different languages and maps them into the same latent space. By\nlearning to reconstruct in both languages from this shared feature space, the\nmodel effectively learns to translate without using any labeled data. We\ndemonstrate our model on two widely used datasets and two language pairs,\nreporting BLEU scores of 32.8 and 15.1 on the Multi30k and WMT English-French\ndatasets, without using even a single parallel sentence at training time.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 18:31:11 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 13:30:28 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Lample", "Guillaume", ""], ["Conneau", "Alexis", ""], ["Denoyer", "Ludovic", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1711.00092", "submitter": "Shubhangi Tandon", "authors": "Amita Misra, Shereen Oraby, Shubhangi Tandon, Sharath TS, Pranav Anand\n  and Marilyn Walker", "title": "Summarizing Dialogic Arguments from Social Media", "comments": "Proceedings of the 21th Workshop on the Semantics and Pragmatics of\n  Dialogue (SemDial 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online argumentative dialog is a rich source of information on popular\nbeliefs and opinions that could be useful to companies as well as governmental\nor public policy agencies. Compact, easy to read, summaries of these dialogues\nwould thus be highly valuable. A priori, it is not even clear what form such a\nsummary should take. Previous work on summarization has primarily focused on\nsummarizing written texts, where the notion of an abstract of the text is well\ndefined. We collect gold standard training data consisting of five human\nsummaries for each of 161 dialogues on the topics of Gay Marriage, Gun Control\nand Abortion. We present several different computational models aimed at\nidentifying segments of the dialogues whose content should be used for the\nsummary, using linguistic features and Word2vec features with both SVMs and\nBidirectional LSTMs. We show that we can identify the most important arguments\nby using the dialog context with a best F-measure of 0.74 for gun control, 0.71\nfor gay marriage, and 0.67 for abortion.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 20:24:07 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Misra", "Amita", ""], ["Oraby", "Shereen", ""], ["Tandon", "Shubhangi", ""], ["TS", "Sharath", ""], ["Anand", "Pranav", ""], ["Walker", "Marilyn", ""]]}, {"id": "1711.00106", "submitter": "Victor Zhong", "authors": "Caiming Xiong, Victor Zhong, Richard Socher", "title": "DCN+: Mixed Objective and Deep Residual Coattention for Question\n  Answering", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional models for question answering optimize using cross entropy loss,\nwhich encourages exact answers at the cost of penalizing nearby or overlapping\nanswers that are sometimes equally accurate. We propose a mixed objective that\ncombines cross entropy loss with self-critical policy learning. The objective\nuses rewards derived from word overlap to solve the misalignment between\nevaluation metric and optimization objective. In addition to the mixed\nobjective, we improve dynamic coattention networks (DCN) with a deep residual\ncoattention encoder that is inspired by recent work in deep self-attention and\nresidual networks. Our proposals improve model performance across question\ntypes and input lengths, especially for long questions that requires the\nability to capture long-term dependencies. On the Stanford Question Answering\nDataset, our model achieves state-of-the-art results with 75.1% exact match\naccuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy\nand 86.0% F1.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 20:53:42 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 20:56:56 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Xiong", "Caiming", ""], ["Zhong", "Victor", ""], ["Socher", "Richard", ""]]}, {"id": "1711.00155", "submitter": "Pavlos Vougiouklis", "authors": "Pavlos Vougiouklis, Hady Elsahar, Lucie-Aim\\'ee Kaffee, Christoph\n  Gravier, Frederique Laforest, Jonathon Hare and Elena Simperl", "title": "Neural Wikipedian: Generating Textual Summaries from Knowledge Base\n  Triples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most people do not interact with Semantic Web data directly. Unless they have\nthe expertise to understand the underlying technology, they need textual or\nvisual interfaces to help them make sense of it. We explore the problem of\ngenerating natural language summaries for Semantic Web data. This is\nnon-trivial, especially in an open-domain context. To address this problem, we\nexplore the use of neural networks. Our system encodes the information from a\nset of triples into a vector of fixed dimensionality and generates a textual\nsummary by conditioning the output on the encoded vector. We train and evaluate\nour models on two corpora of loosely aligned Wikipedia snippets and DBpedia and\nWikidata triples with promising results.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 01:08:49 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Vougiouklis", "Pavlos", ""], ["Elsahar", "Hady", ""], ["Kaffee", "Lucie-Aim\u00e9e", ""], ["Gravier", "Christoph", ""], ["Laforest", "Frederique", ""], ["Hare", "Jonathon", ""], ["Simperl", "Elena", ""]]}, {"id": "1711.00179", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Hao Li, Zhou Zhao, Deng Cai, Xiaofei He", "title": "Keyword-based Query Comprehending via Multiple Optimized-Demand\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of machine reading task when the\nquestions are in the form of keywords, rather than natural language. In recent\nyears, researchers have achieved significant success on machine reading\ncomprehension tasks, such as SQuAD and TriviaQA. These datasets provide a\nnatural language question sentence and a pre-selected passage, and the goal is\nto answer the question according to the passage. However, in the situation of\ninteracting with machines by means of text, people are more likely to raise a\nquery in form of several keywords rather than a complete sentence. The\nkeyword-based query comprehension is a new challenge, because small variations\nto a question may completely change its semantical information, thus yield\ndifferent answers. In this paper, we propose a novel neural network system that\nconsists a Demand Optimization Model based on a passage-attention neural\nmachine translation and a Reader Model that can find the answer given the\noptimized question. The Demand Optimization Model optimizes the original query\nand output multiple reconstructed questions, then the Reader Model takes the\nnew questions as input and locate the answers from the passage. To make\npredictions robust, an evaluation mechanism will score the reconstructed\nquestions so the final answer strike a good balance between the quality of both\nthe Demand Optimization Model and the Reader Model. Experimental results on\nseveral datasets show that our framework significantly improves multiple strong\nbaselines on this challenging task.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 02:56:27 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Pan", "Boyuan", ""], ["Li", "Hao", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1711.00247", "submitter": "Bernardt Duvenhage", "authors": "Bernardt Duvenhage, Mfundo Ntini, Phala Ramonyai", "title": "Improved Text Language Identification for the South African Languages", "comments": "Accepted to appear in the proceedings of The 28th Annual Symposium of\n  the Pattern Recognition Association of South Africa, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual assistants and text chatbots have recently been gaining popularity.\nGiven the short message nature of text-based chat interactions, the language\nidentification systems of these bots might only have 15 or 20 characters to\nmake a prediction. However, accurate text language identification is important,\nespecially in the early stages of many multilingual natural language processing\npipelines.\n  This paper investigates the use of a naive Bayes classifier, to accurately\npredict the language family that a piece of text belongs to, combined with a\nlexicon based classifier to distinguish the specific South African language\nthat the text is written in. This approach leads to a 31% reduction in the\nlanguage detection error.\n  In the spirit of reproducible research the training and testing datasets as\nwell as the code are published on github. Hopefully it will be useful to create\na text language identification shared task for South African languages.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 08:27:46 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Duvenhage", "Bernardt", ""], ["Ntini", "Mfundo", ""], ["Ramonyai", "Phala", ""]]}, {"id": "1711.00279", "submitter": "Zichao Li", "authors": "Zichao Li, Xin Jiang, Lifeng Shang, Hang Li", "title": "Paraphrase Generation with Deep Reinforcement Learning", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of paraphrases from a given sentence is an important yet\nchallenging task in natural language processing (NLP), and plays a key role in\na number of applications such as question answering, search, and dialogue. In\nthis paper, we present a deep reinforcement learning approach to paraphrase\ngeneration. Specifically, we propose a new framework for the task, which\nconsists of a \\textit{generator} and an \\textit{evaluator}, both of which are\nlearned from data. The generator, built as a sequence-to-sequence learning\nmodel, can produce paraphrases given a sentence. The evaluator, constructed as\na deep matching model, can judge whether two sentences are paraphrases of each\nother. The generator is first trained by deep learning and then further\nfine-tuned by reinforcement learning in which the reward is given by the\nevaluator. For the learning of the evaluator, we propose two methods based on\nsupervised learning and inverse reinforcement learning respectively, depending\non the type of available training data. Empirical study shows that the learned\nevaluator can guide the generator to produce more accurate paraphrases.\nExperimental results demonstrate the proposed models (the generators)\noutperform the state-of-the-art methods in paraphrase generation in both\nautomatic evaluation and human evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 10:40:42 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 06:29:23 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 09:30:33 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Li", "Zichao", ""], ["Jiang", "Xin", ""], ["Shang", "Lifeng", ""], ["Li", "Hang", ""]]}, {"id": "1711.00294", "submitter": "Xiaojun Wan", "authors": "Shikang Du, Xiaojun Wan and Yajie Ye", "title": "Towards Automatic Generation of Entertaining Dialogues in Chinese\n  Crosstalks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crosstalk, also known by its Chinese name xiangsheng, is a traditional\nChinese comedic performing art featuring jokes and funny dialogues, and one of\nChina's most popular cultural elements. It is typically in the form of a\ndialogue between two performers for the purpose of bringing laughter to the\naudience, with one person acting as the leading comedian and the other as the\nsupporting role. Though general dialogue generation has been widely explored in\nprevious studies, it is unknown whether such entertaining dialogues can be\nautomatically generated or not. In this paper, we for the first time\ninvestigate the possibility of automatic generation of entertaining dialogues\nin Chinese crosstalks. Given the utterance of the leading comedian in each\ndialogue, our task aims to generate the replying utterance of the supporting\nrole. We propose a humor-enhanced translation model to address this task and\nhuman evaluation results demonstrate the efficacy of our proposed model. The\nfeasibility of automatic entertaining dialogue generation is also verified.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 11:29:27 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Du", "Shikang", ""], ["Wan", "Xiaojun", ""], ["Ye", "Yajie", ""]]}, {"id": "1711.00309", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang, Masao Utiyama, Eiichro Sumita, Graham Neubig, Satoshi\n  Nakamura", "title": "Improving Neural Machine Translation through Phrase-based Forced\n  Decoding", "comments": "IJCNLP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to traditional statistical machine translation (SMT), neural machine\ntranslation (NMT) often sacrifices adequacy for the sake of fluency. We propose\na method to combine the advantages of traditional SMT and NMT by exploiting an\nexisting phrase-based SMT model to compute the phrase-based decoding cost for\nan NMT output and then using this cost to rerank the n-best NMT outputs. The\nmain challenge in implementing this approach is that NMT outputs may not be in\nthe search space of the standard phrase-based decoding algorithm, because the\nsearch space of phrase-based SMT is limited by the phrase-based translation\nrule table. We propose a soft forced decoding algorithm, which can always\nsuccessfully find a decoding path for any NMT output. We show that using the\nforced decoding cost to rerank the NMT outputs can successfully improve\ntranslation quality on four different language pairs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 12:25:20 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Zhang", "Jingyi", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichro", ""], ["Neubig", "Graham", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1711.00313", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, Jaap Kamps", "title": "Avoiding Your Teacher's Mistakes: Training Neural Networks with\n  Controlled Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks requires massive amounts of training data, but\nfor many tasks only limited labeled data is available. This makes weak\nsupervision attractive, using weak or noisy signals like the output of\nheuristic methods or user click-through data for training. In a semi-supervised\nsetting, we can use a large set of data with weak labels to pretrain a neural\nnetwork and then fine-tune the parameters with a small amount of data with true\nlabels. This feels intuitively sub-optimal as these two independent stages\nleave the model unaware about the varying label quality. What if we could\nsomehow inform the model about the label quality? In this paper, we propose a\nsemi-supervised learning method where we train two neural networks in a\nmulti-task fashion: a \"target network\" and a \"confidence network\". The target\nnetwork is optimized to perform a given task and is trained using a large set\nof unlabeled data that are weakly annotated. We propose to weight the gradient\nupdates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model. We evaluate our learning strategy on two different\ntasks: document ranking and sentiment classification. The results demonstrate\nthat our approach not only enhances the performance compared to the baselines\nbut also speeds up the learning process from weak labels.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 12:38:59 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 14:30:18 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Severyn", "Aliaksei", ""], ["Rothe", "Sascha", ""], ["Kamps", "Jaap", ""]]}, {"id": "1711.00331", "submitter": "Lutfi Kerem Senel", "authors": "Lutfi Kerem Senel, Ihsan Utlu, Veysel Yucesoy, Aykut Koc, Tolga Cukur", "title": "Semantic Structure and Interpretability of Word Embeddings", "comments": "11 Pages, 8 Figures, accepted by IEEE/ACM Transactions on Audio,\n  Speech, and Language Processing", "journal-ref": "L. K. \\c{S}enel, \\.I. Utlu, V. Y\\\"ucesoy, A. Ko\\c{c} and T.\n  \\c{C}ukur, \"Semantic Structure and Interpretability of Word Embeddings,\" in\n  IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 26, no.\n  10, pp. 1769-1779, Oct. 2018", "doi": "10.1109/TASLP.2018.2837384", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense word embeddings, which encode semantic meanings of words to low\ndimensional vector spaces have become very popular in natural language\nprocessing (NLP) research due to their state-of-the-art performances in many\nNLP tasks. Word embeddings are substantially successful in capturing semantic\nrelations among words, so a meaningful semantic structure must be present in\nthe respective vector spaces. However, in many cases, this semantic structure\nis broadly and heterogeneously distributed across the embedding dimensions,\nwhich makes interpretation a big challenge. In this study, we propose a\nstatistical method to uncover the latent semantic structure in the dense word\nembeddings. To perform our analysis we introduce a new dataset (SEMCAT) that\ncontains more than 6500 words semantically grouped under 110 categories. We\nfurther propose a method to quantify the interpretability of the word\nembeddings; the proposed method is a practical alternative to the classical\nword intrusion test that requires human intervention.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 13:22:02 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 14:15:50 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 07:10:55 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Senel", "Lutfi Kerem", ""], ["Utlu", "Ihsan", ""], ["Yucesoy", "Veysel", ""], ["Koc", "Aykut", ""], ["Cukur", "Tolga", ""]]}, {"id": "1711.00350", "submitter": "Brenden Lake", "authors": "Brenden M. Lake and Marco Baroni", "title": "Generalization without systematicity: On the compositional skills of\n  sequence-to-sequence recurrent networks", "comments": "Published at the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "Lake, B. M. and Baroni, M. (2018). Generalization without\n  systematicity: On the compositional skills of sequence-to-sequence recurrent\n  networks. International Conference on Machine Learning (ICML)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can understand and produce new utterances effortlessly, thanks to\ntheir compositional skills. Once a person learns the meaning of a new verb\n\"dax,\" he or she can immediately understand the meaning of \"dax twice\" or \"sing\nand dax.\" In this paper, we introduce the SCAN domain, consisting of a set of\nsimple compositional navigation commands paired with the corresponding action\nsequences. We then test the zero-shot generalization capabilities of a variety\nof recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence\nmethods. We find that RNNs can make successful zero-shot generalizations when\nthe differences between training and test commands are small, so that they can\napply \"mix-and-match\" strategies to solve the task. However, when\ngeneralization requires systematic compositional skills (as in the \"dax\"\nexample above), RNNs fail spectacularly. We conclude with a proof-of-concept\nexperiment in neural machine translation, suggesting that lack of systematicity\nmight be partially responsible for neural networks' notorious training data\nthirst.\n", "versions": [{"version": "v1", "created": "Tue, 31 Oct 2017 01:50:02 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 21:55:39 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 20:52:51 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Lake", "Brenden M.", ""], ["Baroni", "Marco", ""]]}, {"id": "1711.00354", "submitter": "Shinnosuke Takamichi", "authors": "Ryosuke Sonobe, Shinnosuke Takamichi, Hiroshi Saruwatari", "title": "JSUT corpus: free large-scale Japanese speech corpus for end-to-end\n  speech synthesis", "comments": "Submitted to ICASSP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Thanks to improvements in machine learning techniques including deep\nlearning, a free large-scale speech corpus that can be shared between academic\ninstitutions and commercial companies has an important role. However, such a\ncorpus for Japanese speech synthesis does not exist. In this paper, we designed\na novel Japanese speech corpus, named the \"JSUT corpus,\" that is aimed at\nachieving end-to-end speech synthesis. The corpus consists of 10 hours of\nreading-style speech data and its transcription and covers all of the main\npronunciations of daily-use Japanese characters. In this paper, we describe how\nwe designed and analyzed the corpus. The corpus is freely available online.\n", "versions": [{"version": "v1", "created": "Sat, 28 Oct 2017 05:28:01 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Sonobe", "Ryosuke", ""], ["Takamichi", "Shinnosuke", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1711.00482", "submitter": "Jacob Andreas", "authors": "Jacob Andreas, Dan Klein, Sergey Levine", "title": "Learning with Latent Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The named concepts and compositional operators present in natural language\nprovide a rich source of information about the kinds of abstractions humans use\nto navigate the world. Can this linguistic background knowledge improve the\ngenerality and efficiency of learned classifiers and control policies? This\npaper aims to show that using the space of natural language strings as a\nparameter space is an effective way to capture natural task structure. In a\npretraining phase, we learn a language interpretation model that transforms\ninputs (e.g. images) into outputs (e.g. labels) given natural language\ndescriptions. To learn a new concept (e.g. a classifier), we search directly in\nthe space of descriptions to minimize the interpreter's loss on training\nexamples. Crucially, our models do not require language data to learn these\nconcepts: language is used only in pretraining to impose structure on\nsubsequent learning. Results on image classification, text editing, and\nreinforcement learning show that, in all settings, models with a linguistic\nparameterization outperform those without.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 18:00:22 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Andreas", "Jacob", ""], ["Klein", "Dan", ""], ["Levine", "Sergey", ""]]}, {"id": "1711.00513", "submitter": "Rachel Bawden", "authors": "Rachel Bawden, Rico Sennrich, Alexandra Birch and Barry Haddow", "title": "Evaluating Discourse Phenomena in Neural Machine Translation", "comments": "Final version of paper to appear in Proceedings of NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine translation to tackle discourse phenomena, models must have\naccess to extra-sentential linguistic context. There has been recent interest\nin modelling context in neural machine translation (NMT), but models have been\nprincipally evaluated with standard automatic metrics, poorly adapted to\nevaluating discourse phenomena. In this article, we present hand-crafted,\ndiscourse test sets, designed to test the models' ability to exploit previous\nsource and target sentences. We investigate the performance of recently\nproposed multi-encoder NMT models trained on subtitles for English to French.\nWe also explore a novel way of exploiting context from the previous sentence.\nDespite gains using BLEU, multi-encoder models give limited improvement in the\nhandling of discourse phenomena: 50% accuracy on our coreference test set and\n53.5% for coherence/cohesion (compared to a non-contextual baseline of 50%). A\nsimple strategy of decoding the concatenation of the previous and current\nsentence leads to good performance, and our novel strategy of multi-encoding\nand decoding of two sentences leads to the best performance (72.5% for\ncoreference and 57% for coherence/cohesion), highlighting the importance of\ntarget-side context.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 19:00:22 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 23:25:01 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 12:05:27 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Bawden", "Rachel", ""], ["Sennrich", "Rico", ""], ["Birch", "Alexandra", ""], ["Haddow", "Barry", ""]]}, {"id": "1711.00520", "submitter": "Yuxuan Wang", "authors": "Yuxuan Wang, RJ Skerry-Ryan, Ying Xiao, Daisy Stanton, Joel Shor, Eric\n  Battenberg, Rob Clark, Rif A. Saurous", "title": "Uncovering Latent Style Factors for Expressive Speech Synthesis", "comments": "Submitted to NIPS ML4Audio workshop and ICASSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prosodic modeling is a core problem in speech synthesis. The key challenge is\nproducing desirable prosody from textual input containing only phonetic\ninformation. In this preliminary study, we introduce the concept of \"style\ntokens\" in Tacotron, a recently proposed end-to-end neural speech synthesis\nmodel. Using style tokens, we aim to extract independent prosodic styles from\ntraining data. We show that without annotation data or an explicit supervision\nsignal, our approach can automatically learn a variety of prosodic variations\nin a purely data-driven way. Importantly, each style token corresponds to a\nfixed style factor regardless of the given text sequence. As a result, we can\ncontrol the prosodic style of synthetic speech in a somewhat predictable and\nglobally consistent way.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 19:40:00 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Wang", "Yuxuan", ""], ["Skerry-Ryan", "RJ", ""], ["Xiao", "Ying", ""], ["Stanton", "Daisy", ""], ["Shor", "Joel", ""], ["Battenberg", "Eric", ""], ["Clark", "Rob", ""], ["Saurous", "Rif A.", ""]]}, {"id": "1711.00529", "submitter": "Angus Forbes", "authors": "Angus G. Forbes, Kristine Lee, Gus Hahn-Powell, Marco A.\n  Valenzuela-Esc\\'arcega, Mihai Surdeanu", "title": "Text Annotation Graphs: Annotating Complex Natural Language Phenomena", "comments": "Accepted to LREC'18,\n  http://lrec2018.lrec-conf.org/en/conference-programme/accepted-papers/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a new web-based software tool for annotating text, Text\nAnnotation Graphs, or TAG. It provides functionality for representing complex\nrelationships between words and word phrases that are not available in other\nsoftware tools, including the ability to define and visualize relationships\nbetween the relationships themselves (semantic hypergraphs). Additionally, we\ninclude an approach to representing text annotations in which annotation\nsubgraphs, or semantic summaries, are used to show relationships outside of the\nsequential context of the text itself. Users can use these subgraphs to quickly\nfind similar structures within the current document or external annotated\ndocuments. Initially, TAG was developed to support information extraction tasks\non a large database of biomedical articles. However, our software is flexible\nenough to support a wide range of annotation tasks for any domain. Examples are\nprovided that showcase TAG's capabilities on morphological parsing and event\nextraction tasks. The TAG software is available at: https://github.com/\nCreativeCodingLab/TextAnnotationGraphs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 20:24:39 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 18:33:54 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Forbes", "Angus G.", ""], ["Lee", "Kristine", ""], ["Hahn-Powell", "Gus", ""], ["Valenzuela-Esc\u00e1rcega", "Marco A.", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1711.00549", "submitter": "Anjishnu Kumar", "authors": "Anjishnu Kumar, Arpit Gupta, Julian Chan, Sam Tucker, Bjorn\n  Hoffmeister, Markus Dreyer, Stanislav Peshterliev, Ankur Gandhe, Denis\n  Filiminov, Ariya Rastrow, Christian Monson and Agnika Kumar", "title": "Just ASK: Building an Architecture for Extensible Self-Service Spoken\n  Language Understanding", "comments": "Published at the 1st Workshop on Conversational AI at NIPS 2017\n  (NIPS-WCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the design of the machine learning architecture that\nunderlies the Alexa Skills Kit (ASK) a large scale Spoken Language\nUnderstanding (SLU) Software Development Kit (SDK) that enables developers to\nextend the capabilities of Amazon's virtual assistant, Alexa. At Amazon, the\ninfrastructure powers over 25,000 skills deployed through the ASK, as well as\nAWS's Amazon Lex SLU Service. The ASK emphasizes flexibility, predictability\nand a rapid iteration cycle for third party developers. It imposes inductive\nbiases that allow it to learn robust SLU models from extremely small and sparse\ndatasets and, in doing so, removes significant barriers to entry for software\ndevelopers and dialogue systems researchers.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 22:10:11 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 09:19:37 GMT"}, {"version": "v3", "created": "Fri, 24 Nov 2017 00:37:00 GMT"}, {"version": "v4", "created": "Fri, 2 Mar 2018 13:58:04 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Kumar", "Anjishnu", ""], ["Gupta", "Arpit", ""], ["Chan", "Julian", ""], ["Tucker", "Sam", ""], ["Hoffmeister", "Bjorn", ""], ["Dreyer", "Markus", ""], ["Peshterliev", "Stanislav", ""], ["Gandhe", "Ankur", ""], ["Filiminov", "Denis", ""], ["Rastrow", "Ariya", ""], ["Monson", "Christian", ""], ["Kumar", "Agnika", ""]]}, {"id": "1711.00681", "submitter": "Akbar Karimi", "authors": "Akbar Karimi, Ebrahim Ansari and Bahram Sadeghi Bigham", "title": "Extracting an English-Persian Parallel Corpus from Comparable Corpora", "comments": "6 pages, 3 figures, 3 tables and published and presented at LREC2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel data are an important part of a reliable Statistical Machine\nTranslation (SMT) system. The more of these data are available, the better the\nquality of the SMT system. However, for some language pairs such as\nPersian-English, parallel sources of this kind are scarce. In this paper, a\nbidirectional method is proposed to extract parallel sentences from English and\nPersian document aligned Wikipedia. Two machine translation systems are\nemployed to translate from Persian to English and the reverse after which an IR\nsystem is used to measure the similarity of the translated sentences. Adding\nthe extracted sentences to the training data of the existing SMT systems is\nshown to improve the quality of the translation. Furthermore, the proposed\nmethod slightly outperforms the one-directional approach. The extracted corpus\nconsists of about 200,000 sentences which have been sorted by their degree of\nsimilarity calculated by the IR system and is freely available for public\naccess on the Web.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 11:00:09 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 11:22:21 GMT"}, {"version": "v3", "created": "Sun, 31 Mar 2019 18:01:37 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Karimi", "Akbar", ""], ["Ansari", "Ebrahim", ""], ["Bigham", "Bahram Sadeghi", ""]]}, {"id": "1711.00768", "submitter": "Ana Marasovi\\'c", "authors": "Ana Marasovi\\'c and Anette Frank", "title": "SRL4ORL: Improving Opinion Role Labeling using Multi-task Learning with\n  Semantic Role Labeling", "comments": "Published in NAACL 2018", "journal-ref": "Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language Technologies\n  (NAACL-HLT)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade, machine learning has been used to extract\nopinion-holder-target structures from text to answer the question \"Who\nexpressed what kind of sentiment towards what?\". Recent neural approaches do\nnot outperform the state-of-the-art feature-based models for Opinion Role\nLabeling (ORL). We suspect this is due to the scarcity of labeled training data\nand address this issue using different multi-task learning (MTL) techniques\nwith a related task which has substantially more data, i.e. Semantic Role\nLabeling (SRL). We show that two MTL models improve significantly over the\nsingle-task model for labeling of both holders and targets, on the development\nand the test sets. We found that the vanilla MTL model which makes predictions\nusing only shared ORL and SRL features, performs the best. With deeper analysis\nwe determine what works and what might be done to make further improvements for\nORL.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:47:00 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 09:43:10 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 13:31:22 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Marasovi\u0107", "Ana", ""], ["Frank", "Anette", ""]]}, {"id": "1711.00894", "submitter": "Swabha Swayamdipta", "authors": "Swabha Swayamdipta, Ankur P. Parikh, Tom Kwiatkowski", "title": "Multi-Mention Learning for Reading Comprehension with Neural Cascades", "comments": "Proceedings of ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension is a challenging task, especially when executed across\nlonger or across multiple evidence documents, where the answer is likely to\nreoccur. Existing neural architectures typically do not scale to the entire\nevidence, and hence, resort to selecting a single passage in the document\n(either via truncation or other means), and carefully searching for the answer\nwithin that passage. However, in some cases, this strategy can be suboptimal,\nsince by focusing on a specific passage, it becomes difficult to leverage\nmultiple mentions of the same answer throughout the document. In this work, we\ntake a different approach by constructing lightweight models that are combined\nin a cascade to find the answer. Each submodel consists only of feed-forward\nnetworks equipped with an attention mechanism, making it trivially\nparallelizable. We show that our approach can scale to approximately an order\nof magnitude larger evidence documents and can aggregate information at the\nrepresentation level from multiple mentions of each answer candidate across the\ndocument. Empirically, our approach achieves state-of-the-art performance on\nboth the Wikipedia and web domains of the TriviaQA dataset, outperforming more\ncomplex, recurrent architectures.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 19:13:55 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 23:27:02 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Swayamdipta", "Swabha", ""], ["Parikh", "Ankur P.", ""], ["Kwiatkowski", "Tom", ""]]}, {"id": "1711.00938", "submitter": "Manex Agirrezabal", "authors": "Manex Agirrezabal, I\\~naki Alegria, Mans Hulden", "title": "A Comparison of Feature-Based and Neural Scansion of Poetry", "comments": "RANLP 2017", "journal-ref": null, "doi": "10.26615/978-954-452-049-6_003", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic analysis of poetic rhythm is a challenging task that involves\nlinguistics, literature, and computer science. When the language to be analyzed\nis known, rule-based systems or data-driven methods can be used. In this paper,\nwe analyze poetic rhythm in English and Spanish. We show that the\nrepresentations of data learned from character-based neural models are more\ninformative than the ones from hand-crafted features, and that a\nBi-LSTM+CRF-model produces state-of-the art accuracy on scansion of poetry in\ntwo languages. Results also show that the information about whole word\nstructure, and not just independent syllables, is highly informative for\nperforming scansion.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 21:15:46 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Agirrezabal", "Manex", ""], ["Alegria", "I\u00f1aki", ""], ["Hulden", "Mans", ""]]}, {"id": "1711.01006", "submitter": "Yining Wang", "authors": "Yining Wang, Yang Zhao, Jiajun Zhang, Chengqing Zong, Zhengshan Xue", "title": "Towards Neural Machine Translation with Partially Aligned Corpora", "comments": "10 pages, 4 figures, Accepted as a long paper by IJCNLP-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural machine translation (NMT) has become the new paradigm, the\nparameter optimization requires large-scale parallel data which is scarce in\nmany domains and language pairs. In this paper, we address a new translation\nscenario in which there only exists monolingual corpora and phrase pairs. We\npropose a new method towards translation with partially aligned sentence pairs\nwhich are derived from the phrase pairs and monolingual corpora. To make full\nuse of the partially aligned corpora, we adapt the conventional NMT training\nmethod in two aspects. On one hand, different generation strategies are\ndesigned for aligned and unaligned target words. On the other hand, a different\nobjective function is designed to model the partially aligned parts. The\nexperiments demonstrate that our method can achieve a relatively good result in\nsuch a translation scenario, and tiny bitexts can boost translation quality to\na large extent.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 03:15:44 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Wang", "Yining", ""], ["Zhao", "Yang", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""], ["Xue", "Zhengshan", ""]]}, {"id": "1711.01048", "submitter": "Saurabh Garg", "authors": "Saurabh Garg, Tanmay Parekh, Preethi Jyothi", "title": "Dual Language Models for Code Switched Speech Recognition", "comments": "Accepted at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we present a simple and elegant approach to language modeling\nfor bilingual code-switched text. Since code-switching is a blend of two or\nmore different languages, a standard bilingual language model can be improved\nupon by using structures of the monolingual language models. We propose a novel\ntechnique called dual language models, which involves building two\ncomplementary monolingual language models and combining them using a\nprobabilistic model for switching between the two. We evaluate the efficacy of\nour approach using a conversational Mandarin-English speech corpus. We prove\nthe robustness of our model by showing significant improvements in perplexity\nmeasures over the standard bilingual language model without the use of any\nexternal information. Similar consistent improvements are also reflected in\nautomatic speech recognition error rates.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 07:56:31 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 13:46:46 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Garg", "Saurabh", ""], ["Parekh", "Tanmay", ""], ["Jyothi", "Preethi", ""]]}, {"id": "1711.01068", "submitter": "Raphael Shu", "authors": "Raphael Shu, Hideki Nakayama", "title": "Compressing Word Embeddings via Deep Compositional Code Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) models often require a massive number of\nparameters for word embeddings, resulting in a large storage or memory\nfootprint. Deploying neural NLP models to mobile devices requires compressing\nthe word embeddings without any significant sacrifices in performance. For this\npurpose, we propose to construct the embeddings with few basis vectors. For\neach word, the composition of basis vectors is determined by a hash code. To\nmaximize the compression rate, we adopt the multi-codebook quantization\napproach instead of binary coding scheme. Each code is composed of multiple\ndiscrete numbers, such as (3, 2, 1, 8), where the value of each component is\nlimited to a fixed range. We propose to directly learn the discrete codes in an\nend-to-end neural network by applying the Gumbel-softmax trick. Experiments\nshow the compression rate achieves 98% in a sentiment analysis task and 94% ~\n99% in machine translation tasks without performance loss. In both tasks, the\nproposed method can improve the model performance by slightly lowering the\ncompression rate. Compared to other approaches such as character-level\nsegmentation, the proposed method is language-independent and does not require\nmodifications to the network architecture.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 09:05:44 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 15:31:45 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Shu", "Raphael", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1711.01100", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva", "title": "One Model to Rule them all: Multitask and Multilingual Modelling for\n  Lexical Analysis", "comments": "PhD thesis, University of Groningen", "journal-ref": null, "doi": null, "report-no": "GRODIL 164", "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When learning a new skill, you take advantage of your preexisting skills and\nknowledge. For instance, if you are a skilled violinist, you will likely have\nan easier time learning to play cello. Similarly, when learning a new language\nyou take advantage of the languages you already speak. For instance, if your\nnative language is Norwegian and you decide to learn Dutch, the lexical overlap\nbetween these two languages will likely benefit your rate of language\nacquisition. This thesis deals with the intersection of learning multiple tasks\nand learning multiple languages in the context of Natural Language Processing\n(NLP), which can be defined as the study of computational processing of human\nlanguage. Although these two types of learning may seem different on the\nsurface, we will see that they share many similarities.\n  The traditional approach in NLP is to consider a single task for a single\nlanguage at a time. However, recent advances allow for broadening this\napproach, by considering data for multiple tasks and languages simultaneously.\nThis is an important approach to explore further as the key to improving the\nreliability of NLP, especially for low-resource languages, is to take advantage\nof all relevant data whenever possible. In doing so, the hope is that in the\nlong term, low-resource languages can benefit from the advances made in NLP\nwhich are currently to a large extent reserved for high-resource languages.\nThis, in turn, may then have positive consequences for, e.g., language\npreservation, as speakers of minority languages will have a lower degree of\npressure to using high-resource languages. In the short term, answering the\nspecific research questions posed should be of use to NLP researchers working\ntowards the same goal.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 10:53:05 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Bjerva", "Johannes", ""]]}, {"id": "1711.01161", "submitter": "Neil Zeghidour", "authors": "Neil Zeghidour, Nicolas Usunier, Iasonas Kokkinos, Thomas Schatz,\n  Gabriel Synnaeve, Emmanuel Dupoux", "title": "Learning Filterbanks from Raw Speech for Phone Recognition", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a bank of complex filters that operates on the raw waveform and is\nfed into a convolutional neural network for end-to-end phone recognition. These\ntime-domain filterbanks (TD-filterbanks) are initialized as an approximation of\nmel-filterbanks, and then fine-tuned jointly with the remaining convolutional\narchitecture. We perform phone recognition experiments on TIMIT and show that\nfor several architectures, models trained on TD-filterbanks consistently\noutperform their counterparts trained on comparable mel-filterbanks. We get our\nbest performance by learning all front-end steps, from pre-emphasis up to\naveraging. Finally, we observe that the filters at convergence have an\nasymmetric impulse response, and that some of them remain almost analytic.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 13:56:53 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 13:56:25 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Zeghidour", "Neil", ""], ["Usunier", "Nicolas", ""], ["Kokkinos", "Iasonas", ""], ["Schatz", "Thomas", ""], ["Synnaeve", "Gabriel", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1711.01362", "submitter": "Venkatesh Duppada", "authors": "Venkatesh Duppada", "title": "\"Attention\" for Detecting Unreliable News in the Information Age", "comments": "AICS 2018, AAAI-18 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Unreliable news is any piece of information which is false or misleading,\ndeliberately spread to promote political, ideological and financial agendas.\nRecently the problem of unreliable news has got a lot of attention as the\nnumber instances of using news and social media outlets for propaganda have\nincreased rapidly. This poses a serious threat to society, which calls for\ntechnology to automatically and reliably identify unreliable news sources. This\npaper is an effort made in this direction to build systems for detecting\nunreliable news articles. In this paper, various NLP algorithms were built and\nevaluated on Unreliable News Data 2017 dataset. Variants of hierarchical\nattention networks (HAN) are presented for encoding and classifying news\narticles which achieve the best results of 0.944 ROC-AUC. Finally, Attention\nlayer weights are visualized to understand and give insight into the decisions\nmade by HANs. The results obtained are very promising and encouraging to deploy\nand use these systems in the real world to mitigate the problem of unreliable\nnews.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 23:48:18 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Duppada", "Venkatesh", ""]]}, {"id": "1711.01386", "submitter": "Yuan Yang", "authors": "Yuan Yang, Pengtao Xie, Xin Gao, Carol Cheng, Christy Li, Hongbao\n  Zhang and Eric Xing", "title": "Predicting Discharge Medications at Admission Time Based on Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting discharge medications right after a patient being admitted is an\nimportant clinical decision, which provides physicians with guidance on what\ntype of medication regimen to plan for and what possible changes on initial\nmedication may occur during an inpatient stay. It also facilitates medication\nreconciliation process with easy detection of medication discrepancy at\ndischarge time to improve patient safety. However, since the information\navailable upon admission is limited and patients' condition may evolve during\nan inpatient stay, these predictions could be a difficult decision for\nphysicians to make. In this work, we investigate how to leverage deep learning\ntechnologies to assist physicians in predicting discharge medications based on\ninformation documented in the admission note. We build a convolutional neural\nnetwork which takes an admission note as input and predicts the medications\nplaced on the patient at discharge time. Our method is able to distill semantic\npatterns from unstructured and noisy texts, and is capable of capturing the\npharmacological correlations among medications. We evaluate our method on 25K\npatient visits and compare with 4 strong baselines. Our methods demonstrate a\n20% increase in macro-averaged F1 score than the best baseline.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 03:04:40 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 19:33:22 GMT"}, {"version": "v3", "created": "Tue, 5 Dec 2017 17:13:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Yang", "Yuan", ""], ["Xie", "Pengtao", ""], ["Gao", "Xin", ""], ["Cheng", "Carol", ""], ["Li", "Christy", ""], ["Zhang", "Hongbao", ""], ["Xing", "Eric", ""]]}, {"id": "1711.01416", "submitter": "Vasily Pestun", "authors": "Vasily Pestun, John Terilla, Yiannis Vlassopoulos", "title": "Language as a matrix product state", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical model for natural language that begins by\nconsidering language as a monoid, then representing it in complex matrices with\na compatible translation invariant probability measure. We interpret the\nprobability measure as arising via the Born rule from a translation invariant\nmatrix product state.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 09:11:18 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Pestun", "Vasily", ""], ["Terilla", "John", ""], ["Vlassopoulos", "Yiannis", ""]]}, {"id": "1711.01427", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xu Sun, Sujian Li, Xiaoyan Cai and Bingzhen Wei", "title": "Deep Stacking Networks for Low-Resource Chinese Word Segmentation with\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have proven to be effective in Chinese word\nsegmentation. However, this promising performance relies on large-scale\ntraining data. Neural networks with conventional architectures cannot achieve\nthe desired results in low-resource datasets due to the lack of labelled\ntraining data. In this paper, we propose a deep stacking framework to improve\nthe performance on word segmentation tasks with insufficient data by\nintegrating datasets from diverse domains. Our framework consists of two parts,\ndomain-based models and deep stacking networks. The domain-based models are\nused to learn knowledge from different datasets. The deep stacking networks are\ndesigned to integrate domain-based models. To reduce model conflicts, we\ninnovatively add communication paths among models and design various structures\nof deep stacking networks, including Gaussian-based Stacking Networks,\nConcatenate-based Stacking Networks, Sequence-based Stacking Networks and\nTree-based Stacking Networks. We conduct experiments on six low-resource\ndatasets from various domains. Our proposed framework shows significant\nperformance improvements on all datasets compared with several strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 12:24:26 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Xu", "Jingjing", ""], ["Sun", "Xu", ""], ["Li", "Sujian", ""], ["Cai", "Xiaoyan", ""], ["Wei", "Bingzhen", ""]]}, {"id": "1711.01505", "submitter": "Sudha Rao", "authors": "Allyson Ettinger, Sudha Rao, Hal Daum\\'e III, Emily M. Bender", "title": "Towards Linguistically Generalizable NLP Systems: A Workshop and Shared\n  Task", "comments": "Updated version of the EMNLP Workshop and Shared Task description\n  paper, Proceedings of the First Workshop on Building Linguistically\n  Generalizable NLP Systems. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a summary of the first Workshop on Building\nLinguistically Generalizable Natural Language Processing Systems, and the\nassociated Build It Break It, The Language Edition shared task. The goal of\nthis workshop was to bring together researchers in NLP and linguistics with a\nshared task aimed at testing the generalizability of NLP systems beyond the\ndistributions of their training data. We describe the motivation, setup, and\nparticipation of the shared task, provide discussion of some highlighted\nresults, and discuss lessons learned.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 22:46:54 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Ettinger", "Allyson", ""], ["Rao", "Sudha", ""], ["Daum\u00e9", "Hal", "III"], ["Bender", "Emily M.", ""]]}, {"id": "1711.01515", "submitter": "Yu-An Chung", "authors": "Yu-An Chung and James Glass", "title": "Learning Word Embeddings from Speech", "comments": "Accepted by Machine Learning for Audio Signal Processing (ML4Audio),\n  31st Conference on Neural Information Processing Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel deep neural network architecture,\nSequence-to-Sequence Audio2Vec, for unsupervised learning of fixed-length\nvector representations of audio segments excised from a speech corpus, where\nthe vectors contain semantic information pertaining to the segments, and are\nclose to other vectors in the embedding space if their corresponding segments\nare semantically similar. The design of the proposed model is based on the RNN\nEncoder-Decoder framework, and borrows the methodology of continuous skip-grams\nfor training. The learned vector representations are evaluated on 13 widely\nused word similarity benchmarks, and achieved competitive results to that of\nGloVe. The biggest advantage of the proposed model is its capability of\nextracting semantic information of audio segments taken directly from raw\nspeech, without relying on any other modalities such as text or images, which\nare challenging and expensive to collect and annotate.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 01:36:58 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "1711.01563", "submitter": "Daochen Zha", "authors": "Daochen Zha, Chenliang Li", "title": "Multi-label Dataless Text Classification with Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually labeling documents is tedious and expensive, but it is essential for\ntraining a traditional text classifier. In recent years, a few dataless text\nclassification techniques have been proposed to address this problem. However,\nexisting works mainly center on single-label classification problems, that is,\neach document is restricted to belonging to a single category. In this paper,\nwe propose a novel Seed-guided Multi-label Topic Model, named SMTM. With a few\nseed words relevant to each category, SMTM conducts multi-label classification\nfor a collection of documents without any labeled document. In SMTM, each\ncategory is associated with a single category-topic which covers the meaning of\nthe category. To accommodate with multi-labeled documents, we explicitly model\nthe category sparsity in SMTM by using spike and slab prior and weak smoothing\nprior. That is, without using any threshold tuning, SMTM automatically selects\nthe relevant categories for each document. To incorporate the supervision of\nthe seed words, we propose a seed-guided biased GPU (i.e., generalized Polya\nurn) sampling procedure to guide the topic inference of SMTM. Experiments on\ntwo public datasets show that SMTM achieves better classification accuracy than\nstate-of-the-art alternatives and even outperforms supervised solutions in some\nscenarios.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 11:34:46 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Zha", "Daochen", ""], ["Li", "Chenliang", ""]]}, {"id": "1711.01567", "submitter": "Anuroop Sriram", "authors": "Anuroop Sriram, Heewoo Jun, Yashesh Gaur and Sanjeev Satheesh", "title": "Robust Speech Recognition Using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a general, scalable, end-to-end framework that uses the\ngenerative adversarial network (GAN) objective to enable robust speech\nrecognition. Encoders trained with the proposed approach enjoy improved\ninvariance by learning to map noisy audio to the same embedding space as that\nof clean audio. Unlike previous methods, the new framework does not rely on\ndomain expertise or simplifying assumptions as are often needed in signal\nprocessing, and directly encourages robustness in a data-driven way. We show\nthe new approach improves simulated far-field speech recognition of vanilla\nsequence-to-sequence models without specialized front-ends or preprocessing.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 12:00:18 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Sriram", "Anuroop", ""], ["Jun", "Heewoo", ""], ["Gaur", "Yashesh", ""], ["Satheesh", "Sanjeev", ""]]}, {"id": "1711.01684", "submitter": "Anjalie Field", "authors": "Anjalie Field", "title": "Authorship Analysis of Xenophon's Cyropaedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past several decades, many authorship attribution studies have used\ncomputational methods to determine the authors of disputed texts. Disputed\nauthorship is a common problem in Classics, since little information about\nancient documents has survived the centuries. Many scholars have questioned the\nauthenticity of the final chapter of Xenophon's Cyropaedia, a 4th century B.C.\nhistorical text. In this study, we use N-grams frequency vectors with a cosine\nsimilarity function and word frequency vectors with Naive Bayes Classifiers\n(NBC) and Support Vector Machines (SVM) to analyze the authorship of the\nCyropaedia. Although the N-gram analysis shows that the epilogue of the\nCyropaedia differs slightly from the rest of the work, comparing the analysis\nof Xenophon with analyses of Aristotle and Plato suggests that this difference\nis not significant. Both NBC and SVM analyses of word frequencies show that the\nfinal chapter of the Cyropaedia is closely related to the other chapters of the\nCyropaedia. Therefore, this analysis suggests that the disputed chapter was\nwritten by Xenophon. This information can help scholars better understand the\nCyropaedia and also demonstrates the usefulness of applying modern authorship\nanalysis techniques to classical literature.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 00:39:31 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Field", "Anjalie", ""]]}, {"id": "1711.01694", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Tara N. Sainath, Ron J. Weiss, Bo Li, Pedro Moreno,\n  Eugene Weinstein, Kanishka Rao", "title": "Multilingual Speech Recognition With A Single End-To-End Model", "comments": "Accepted in ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a conventional automatic speech recognition (ASR) system to support\nmultiple languages is challenging because the sub-word unit, lexicon and word\ninventories are typically language specific. In contrast, sequence-to-sequence\nmodels are well suited for multilingual ASR because they encapsulate an\nacoustic, pronunciation and language model jointly in a single network. In this\nwork we present a single sequence-to-sequence ASR model trained on 9 different\nIndian languages, which have very little overlap in their scripts.\nSpecifically, we take a union of language-specific grapheme sets and train a\ngrapheme-based sequence-to-sequence model jointly on data from all languages.\nWe find that this model, which is not explicitly given any information about\nlanguage identity, improves recognition performance by 21% relative compared to\nanalogous sequence-to-sequence models trained on each language individually. By\nmodifying the model to accept a language identifier as an additional input\nfeature, we further improve performance by an additional 7% relative and\neliminate confusion between different languages.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 01:55:45 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 08:59:27 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Sainath", "Tara N.", ""], ["Weiss", "Ron J.", ""], ["Li", "Bo", ""], ["Moreno", "Pedro", ""], ["Weinstein", "Eugene", ""], ["Rao", "Kanishka", ""]]}, {"id": "1711.01701", "submitter": "Wei Li", "authors": "Wei Li, Zheng Yang", "title": "Distributed Representation for Traditional Chinese Medicine Herb via\n  Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Chinese Medicine (TCM) has accumulated a big amount of precious\nresource in the long history of development. TCM prescriptions that consist of\nTCM herbs are an important form of TCM treatment, which are similar to natural\nlanguage documents, but in a weakly ordered fashion. Directly adapting language\nmodeling style methods to learn the embeddings of the herbs can be problematic\nas the herbs are not strictly in order, the herbs in the front of the\nprescription can be connected to the very last ones. In this paper, we propose\nto represent TCM herbs with distributed representations via Prescription Level\nLanguage Modeling (PLLM). In one of our experiments, the correlation between\nour calculated similarity between medicines and the judgment of professionals\nachieves a Spearman score of 55.35 indicating a strong correlation, which\nsurpasses human beginners (TCM related field bachelor student) by a big margin\n(over 10%).\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 03:05:05 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Li", "Wei", ""], ["Yang", "Zheng", ""]]}, {"id": "1711.01731", "submitter": "Xiaorui Liu", "authors": "Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang", "title": "A Survey on Dialogue Systems: Recent Advances and New Frontiers", "comments": "13 pages. arXiv admin note: text overlap with arXiv:1703.01008 by\n  other authors", "journal-ref": null, "doi": "10.1145/3166054.3166058", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems have attracted more and more attention. Recent advances on\ndialogue systems are overwhelmingly contributed by deep learning techniques,\nwhich have been employed to enhance a wide range of big data applications such\nas computer vision, natural language processing, and recommender systems. For\ndialogue systems, deep learning can leverage a massive amount of data to learn\nmeaningful feature representations and response generation strategies, while\nrequiring a minimum amount of hand-crafting. In this article, we give an\noverview to these recent advances on dialogue systems from various perspectives\nand discuss some possible research directions. In particular, we generally\ndivide existing dialogue systems into task-oriented and non-task-oriented\nmodels, then detail how deep learning techniques help them with representative\nalgorithms and finally discuss some appealing research directions that can\nbring the dialogue system research into a new frontier.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 05:20:54 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 16:27:31 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 18:44:11 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Chen", "Hongshen", ""], ["Liu", "Xiaorui", ""], ["Yin", "Dawei", ""], ["Tang", "Jiliang", ""]]}, {"id": "1711.01804", "submitter": "Luk\\'a\\v{s} Svoboda", "authors": "Lukas Svoboda, Slobodan Beliga", "title": "Evaluation of Croatian Word Embeddings", "comments": "In review process on LREC 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Croatian is poorly resourced and highly inflected language from Slavic\nlanguage family. Nowadays, research is focusing mostly on English. We created a\nnew word analogy corpus based on the original English Word2vec word analogy\ncorpus and added some of the specific linguistic aspects from Croatian\nlanguage. Next, we created Croatian WordSim353 and RG65 corpora for a basic\nevaluation of word similarities. We compared created corpora on two popular\nword representation models, based on Word2Vec tool and fastText tool. Models\nhas been trained on 1.37B tokens training data corpus and tested on a new\nrobust Croatian word analogy corpus. Results show that models are able to\ncreate meaningful word representation. This research has shown that free word\norder and the higher morphological complexity of Croatian language influences\nthe quality of resulting word embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 09:40:41 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 22:28:25 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Svoboda", "Lukas", ""], ["Beliga", "Slobodan", ""]]}, {"id": "1711.01921", "submitter": "Rakshith Shetty", "authors": "Rakshith Shetty and Bernt Schiele and Mario Fritz", "title": "$A^{4}NT$: Author Attribute Anonymity by Adversarial Training of Neural\n  Machine Translation", "comments": "16 pages, 10 figures and 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based analysis methods allow to reveal privacy relevant author\nattributes such as gender, age and identify of the text's author. Such methods\ncan compromise the privacy of an anonymous author even when the author tries to\nremove privacy sensitive content. In this paper, we propose an automatic\nmethod, called Adversarial Author Attribute Anonymity Neural Translation\n($A^4NT$), to combat such text-based adversaries. We combine\nsequence-to-sequence language models used in machine translation and generative\nadversarial networks to obfuscate author attributes. Unlike machine translation\ntechniques which need paired data, our method can be trained on unpaired\ncorpora of text containing different authors. Importantly, we propose and\nevaluate techniques to impose constraints on our $A^4NT$ to preserve the\nsemantics of the input text. $A^4NT$ learns to make minimal changes to the\ninput text to successfully fool author attribute classifiers, while aiming to\nmaintain the meaning of the input. We show through experiments on two different\ndatasets and three settings that our proposed method is effective in fooling\nthe author attribute classifiers and thereby improving the anonymity of\nauthors.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 14:54:56 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 16:56:09 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 10:37:27 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Shetty", "Rakshith", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1711.01985", "submitter": "Tomek Korbak", "authors": "Tomasz Korbak and Paulina \\.Zak", "title": "Fine-tuning Tree-LSTM for phrase-level sentiment classification on a\n  Polish dependency treebank. Submission to PolEval task 2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a variant of Child-Sum Tree-LSTM deep neural network (Tai et al,\n2015) fine-tuned for working with dependency trees and morphologically rich\nlanguages using the example of Polish. Fine-tuning included applying a custom\nregularization technique (zoneout, described by (Krueger et al., 2016), and\nfurther adapted for Tree-LSTMs) as well as using pre-trained word embeddings\nenhanced with sub-word information (Bojanowski et al., 2016). The system was\nimplemented in PyTorch and evaluated on phrase-level sentiment labeling task as\npart of the PolEval competition.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 14:52:08 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Korbak", "Tomasz", ""], ["\u017bak", "Paulina", ""]]}, {"id": "1711.02012", "submitter": "Rahul Aralikatte", "authors": "Senthil Mani, Neelamadhav Gantayat, Rahul Aralikatte, Monika Gupta,\n  Sampath Dechu, Anush Sankaran, Shreya Khare, Barry Mitchell, Hemamalini\n  Subramanian, Hema Venkatarangan", "title": "Hi, how can I help you?: Automating enterprise IT support help desks", "comments": "To appear in IAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering is one of the primary challenges of natural language\nunderstanding. In realizing such a system, providing complex long answers to\nquestions is a challenging task as opposed to factoid answering as the former\nneeds context disambiguation. The different methods explored in the literature\ncan be broadly classified into three categories namely: 1) classification\nbased, 2) knowledge graph based and 3) retrieval based. Individually, none of\nthem address the need of an enterprise wide assistance system for an IT support\nand maintenance domain. In this domain the variance of answers is large ranging\nfrom factoid to structured operating procedures; the knowledge is present\nacross heterogeneous data sources like application specific documentation,\nticket management systems and any single technique for a general purpose\nassistance is unable to scale for such a landscape. To address this, we have\nbuilt a cognitive platform with capabilities adopted for this domain. Further,\nwe have built a general purpose question answering system leveraging the\nplatform that can be instantiated for multiple products, technologies in the\nsupport domain. The system uses a novel hybrid answering model that\norchestrates across a deep learning classifier, a knowledge graph based context\ndisambiguation module and a sophisticated bag-of-words search system. This\norchestration performs context switching for a provided question and also does\na smooth hand-off of the question to a human expert if none of the automated\ntechniques can provide a confident answer. This system has been deployed across\n675 internal enterprise IT support and maintenance projects.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 20:04:06 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Mani", "Senthil", ""], ["Gantayat", "Neelamadhav", ""], ["Aralikatte", "Rahul", ""], ["Gupta", "Monika", ""], ["Dechu", "Sampath", ""], ["Sankaran", "Anush", ""], ["Khare", "Shreya", ""], ["Mitchell", "Barry", ""], ["Subramanian", "Hemamalini", ""], ["Venkatarangan", "Hema", ""]]}, {"id": "1711.02013", "submitter": "Yikang Shen", "authors": "Yikang Shen, Zhouhan Lin, Chin-Wei Huang, Aaron Courville", "title": "Neural Language Modeling by Jointly Learning Syntax and Lexicon", "comments": "16 pages, 5 figures, ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural language model capable of unsupervised syntactic\nstructure induction. The model leverages the structure information to form\nbetter semantic representations and better language modeling. Standard\nrecurrent neural networks are limited by their structure and fail to\nefficiently use syntactic information. On the other hand, tree-structured\nrecursive networks usually require additional structural supervision at the\ncost of human expert annotation. In this paper, We propose a novel neural\nlanguage model, called the Parsing-Reading-Predict Networks (PRPN), that can\nsimultaneously induce the syntactic structure from unannotated sentences and\nleverage the inferred structure to learn a better language model. In our model,\nthe gradient can be directly back-propagated from the language model loss into\nthe neural parsing network. Experiments show that the proposed model can\ndiscover the underlying syntactic structure and achieve state-of-the-art\nperformance on word/character-level language model tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 23:02:52 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 04:48:35 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Shen", "Yikang", ""], ["Lin", "Zhouhan", ""], ["Huang", "Chin-Wei", ""], ["Courville", "Aaron", ""]]}, {"id": "1711.02085", "submitter": "Minjoon Seo", "authors": "Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi", "title": "Neural Speed Reading via Skim-RNN", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the principles of speed reading, we introduce Skim-RNN, a\nrecurrent neural network (RNN) that dynamically decides to update only a small\nfraction of the hidden state for relatively unimportant input tokens. Skim-RNN\ngives computational advantage over an RNN that always updates the entire hidden\nstate. Skim-RNN uses the same input and output interfaces as a standard RNN and\ncan be easily used instead of RNNs in existing models. In our experiments, we\nshow that Skim-RNN can achieve significantly reduced computational cost without\nlosing accuracy compared to standard RNNs across five different natural\nlanguage tasks. In addition, we demonstrate that the trade-off between accuracy\nand speed of Skim-RNN can be dynamically controlled during inference time in a\nstable manner. Our analysis also shows that Skim-RNN running on a single CPU\noffers lower latency compared to standard RNNs on GPUs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 18:58:46 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 08:25:56 GMT"}, {"version": "v3", "created": "Thu, 29 Mar 2018 03:25:36 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Seo", "Minjoon", ""], ["Min", "Sewon", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1711.02132", "submitter": "Karim Ahmed", "authors": "Karim Ahmed, Nitish Shirish Keskar, Richard Socher", "title": "Weighted Transformer Network for Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art results on neural machine translation often use attentional\nsequence-to-sequence models with some form of convolution or recursion. Vaswani\net al. (2017) propose a new architecture that avoids recurrence and convolution\ncompletely. Instead, it uses only self-attention and feed-forward layers. While\nthe proposed architecture achieves state-of-the-art results on several machine\ntranslation tasks, it requires a large number of parameters and training\niterations to converge. We propose Weighted Transformer, a Transformer with\nmodified attention layers, that not only outperforms the baseline network in\nBLEU score but also converges 15-40% faster. Specifically, we replace the\nmulti-head attention by multiple self-attention branches that the model learns\nto combine during the training process. Our model improves the state-of-the-art\nperformance by 0.5 BLEU points on the WMT 2014 English-to-German translation\ntask and by 0.4 on the English-to-French translation task.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 19:35:00 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Ahmed", "Karim", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1711.02162", "submitter": "Prafulla Kumar Choubey", "authors": "Prafulla Kumar Choubey and Ruihong Huang", "title": "TAMU at KBP 2017: Event Nugget Detection and Coreference Resolution", "comments": "TAC KBP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe TAMU's system submitted to the TAC KBP 2017 event\nnugget detection and coreference resolution task. Our system builds on the\nstatistical and empirical observations made on training and development data.\nWe found that modifiers of event nuggets tend to have unique syntactic\ndistribution. Their parts-of-speech tags and dependency relations provides them\nessential characteristics that are useful in identifying their span and also\ndefining their types and realis status. We further found that the joint\nmodeling of event span detection and realis status identification performs\nbetter than the individual models for both tasks. Our simple system designed\nusing minimal features achieved the micro-average F1 scores of 57.72, 44.27 and\n42.47 for event span detection, type identification and realis status\nclassification tasks respectively. Also, our system achieved the CoNLL F1 score\nof 27.20 in event coreference resolution task.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 20:30:50 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 06:02:10 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Choubey", "Prafulla Kumar", ""], ["Huang", "Ruihong", ""]]}, {"id": "1711.02173", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, Yonatan Bisk", "title": "Synthetic and Natural Noise Both Break Neural Machine Translation", "comments": "ICLR 2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-based neural machine translation (NMT) models alleviate\nout-of-vocabulary issues, learn morphology, and move us closer to completely\nend-to-end translation systems. Unfortunately, they are also very brittle and\neasily falter when presented with noisy data. In this paper, we confront NMT\nmodels with synthetic and natural sources of noise. We find that\nstate-of-the-art models fail to translate even moderately noisy texts that\nhumans have no trouble comprehending. We explore two approaches to increase\nmodel robustness: structure-invariant word representations and robust training\non noisy texts. We find that a model based on a character convolutional neural\nnetwork is able to simultaneously learn representations robust to multiple\nkinds of noise.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 20:59:58 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 19:44:38 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Bisk", "Yonatan", ""]]}, {"id": "1711.02207", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Michael L. Seltzer", "title": "Towards Language-Universal End-to-End Speech Recognition", "comments": "submitted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building speech recognizers in multiple languages typically involves\nreplicating a monolingual training recipe for each language, or utilizing a\nmulti-task learning approach where models for different languages have separate\noutput labels but share some internal parameters. In this work, we exploit\nrecent progress in end-to-end speech recognition to create a single\nmultilingual speech recognition system capable of recognizing any of the\nlanguages seen in training. To do so, we propose the use of a universal\ncharacter set that is shared among all languages. We also create a\nlanguage-specific gating mechanism within the network that can modulate the\nnetwork's internal representations in a language-specific way. We evaluate our\nproposed approach on the Microsoft Cortana task across three languages and show\nthat our system outperforms both the individual monolingual systems and systems\nbuilt with a multi-task learning approach. We also show that this model can be\nused to initialize a monolingual speech recognizer, and can be used to create a\nbilingual model for use in code-switching scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 22:48:55 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Kim", "Suyoun", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1711.02212", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Michael L. Seltzer, Jinyu Li, Rui Zhao", "title": "Improved training for online end-to-end speech recognition systems", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high accuracy with end-to-end speech recognizers requires careful\nparameter initialization prior to training. Otherwise, the networks may fail to\nfind a good local optimum. This is particularly true for online networks, such\nas unidirectional LSTMs. Currently, the best strategy to train such systems is\nto bootstrap the training from a tied-triphone system. However, this is time\nconsuming, and more importantly, is impossible for languages without a\nhigh-quality pronunciation lexicon. In this work, we propose an initialization\nstrategy that uses teacher-student learning to transfer knowledge from a large,\nwell-trained, offline end-to-end speech recognition model to an online\nend-to-end model, eliminating the need for a lexicon or any other linguistic\nresources. We also explore curriculum learning and label smoothing and show how\nthey can be combined with the proposed teacher-student learning for further\nimprovements. We evaluate our methods on a Microsoft Cortana personal assistant\ntask and show that the proposed method results in a 19 % relative improvement\nin word error rate compared to a randomly-initialized baseline system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 22:59:48 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 19:39:17 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Kim", "Suyoun", ""], ["Seltzer", "Michael L.", ""], ["Li", "Jinyu", ""], ["Zhao", "Rui", ""]]}, {"id": "1711.02281", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li and Richard\n  Socher", "title": "Non-Autoregressive Neural Machine Translation", "comments": "Accepted by ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to neural machine translation condition each output word\non previously generated outputs. We introduce a model that avoids this\nautoregressive property and produces its outputs in parallel, allowing an order\nof magnitude lower latency during inference. Through knowledge distillation,\nthe use of input token fertilities as a latent variable, and policy gradient\nfine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative\nto the autoregressive Transformer network used as a teacher. We demonstrate\nsubstantial cumulative improvements associated with each of the three aspects\nof our training strategy, and validate our approach on IWSLT 2016\nEnglish-German and two WMT language pairs. By sampling fertilities in parallel\nat inference time, our non-autoregressive model achieves near-state-of-the-art\nperformance of 29.8 BLEU on WMT 2016 English-Romanian.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 04:42:48 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 03:37:52 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Gu", "Jiatao", ""], ["Bradbury", "James", ""], ["Xiong", "Caiming", ""], ["Li", "Victor O. K.", ""], ["Socher", "Richard", ""]]}, {"id": "1711.02295", "submitter": "Ricardo Baeza-Yates", "authors": "Ricardo Baeza-Yates, Zeinab Liaghat", "title": "Quality-Efficiency Trade-offs in Machine Learning for Text Processing", "comments": "Ten pages, long version of paper that will be presented at IEEE Big\n  Data 2017 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining, machine learning, and natural language processing are powerful\ntechniques that can be used together to extract information from large texts.\nDepending on the task or problem at hand, there are many different approaches\nthat can be used. The methods available are continuously being optimized, but\nnot all these methods have been tested and compared in a set of problems that\ncan be solved using supervised machine learning algorithms. The question is\nwhat happens to the quality of the methods if we increase the training data\nsize from, say, 100 MB to over 1 GB? Moreover, are quality gains worth it when\nthe rate of data processing diminishes? Can we trade quality for time\nefficiency and recover the quality loss by just being able to process more\ndata? We attempt to answer these questions in a general way for text processing\ntasks, considering the trade-offs involving training data size, learning time,\nand quality obtained. We propose a performance trade-off framework and apply it\nto three important text processing problems: Named Entity Recognition,\nSentiment Analysis and Document Classification. These problems were also chosen\nbecause they have different levels of object granularity: words, paragraphs,\nand documents. For each problem, we selected several supervised machine\nlearning algorithms and we evaluated the trade-offs of them on large publicly\navailable data sets (news, reviews, patents). To explore these trade-offs, we\nuse different data subsets of increasing size ranging from 50 MB to several GB.\nWe also consider the impact of the data set and the evaluation technique. We\nfind that the results do not change significantly and that most of the time the\nbest algorithms is the fastest. However, we also show that the results for\nsmall data (say less than 100 MB) are different from the results for big data\nand in those cases the best algorithm is much harder to determine.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 05:43:34 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Baeza-Yates", "Ricardo", ""], ["Liaghat", "Zeinab", ""]]}, {"id": "1711.02509", "submitter": "Ji Wen", "authors": "Ji Wen", "title": "Structure Regularized Bidirectional Recurrent Convolutional Neural\n  Network for Relation Classification", "comments": "arXiv admin note: text overlap with arXiv:1411.6243 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation classification is an important semantic processing task in the field\nof natural language processing (NLP). In this paper, we present a novel model,\nStructure Regularized Bidirectional Recurrent Convolutional Neural\nNetwork(SR-BRCNN), to classify the relation of two entities in a sentence, and\nthe new dataset of Chinese Sanwen for named entity recognition and relation\nclassification. Some state-of-the-art systems concentrate on modeling the\nshortest dependency path (SDP) between two entities leveraging convolutional or\nrecurrent neural networks. We further explore how to make full use of the\ndependency relations information in the SDP and how to improve the model by the\nmethod of structure regularization. We propose a structure regularized model to\nlearn relation representations along the SDP extracted from the forest formed\nby the structure regularized dependency tree, which benefits reducing the\ncomplexity of the whole model and helps improve the $F_{1}$ score by 10.3.\nExperimental results show that our method outperforms the state-of-the-art\napproaches on the Chinese Sanwen task and performs as well on the SemEval-2010\nTask 8 dataset\\footnote{The Chinese Sanwen corpus this paper developed and used\nwill be released in the further.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 06:21:01 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Wen", "Ji", ""]]}, {"id": "1711.02604", "submitter": "Edouard Grave", "authors": "Edouard Grave, Moustapha Cisse, Armand Joulin", "title": "Unbounded cache model for online language modeling with open vocabulary", "comments": "Accepted to NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, continuous cache models were proposed as extensions to recurrent\nneural network language models, to adapt their predictions to local changes in\nthe data distribution. These models only capture the local context, of up to a\nfew thousands tokens. In this paper, we propose an extension of continuous\ncache models, which can scale to larger contexts. In particular, we use a large\nscale non-parametric memory component that stores all the hidden activations\nseen in the past. We leverage recent advances in approximate nearest neighbor\nsearch and quantization algorithms to store millions of representations while\nsearching them efficiently. We conduct extensive experiments showing that our\napproach significantly improves the perplexity of pre-trained language models\non new distributions, and can scale efficiently to much larger contexts than\npreviously proposed local cache models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 16:51:52 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Grave", "Edouard", ""], ["Cisse", "Moustapha", ""], ["Joulin", "Armand", ""]]}, {"id": "1711.02608", "submitter": "Diego Amancio Dr.", "authors": "Jorge V. Tohalino and Diego R. Amancio", "title": "Extractive Multi-document Summarization Using Multilayer Networks", "comments": null, "journal-ref": "Physica A 503, 526-539 (2018)", "doi": "10.1016/j.physa.2018.03.013", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huge volumes of textual information has been produced every single day. In\norder to organize and understand such large datasets, in recent years,\nsummarization techniques have become popular. These techniques aims at finding\nrelevant, concise and non-redundant content from such a big data. While network\nmethods have been adopted to model texts in some scenarios, a systematic\nevaluation of multilayer network models in the multi-document summarization\ntask has been limited to a few studies. Here, we evaluate the performance of a\nmultilayer-based method to select the most relevant sentences in the context of\nan extractive multi document summarization (MDS) task. In the adopted model,\nnodes represent sentences and edges are created based on the number of shared\nwords between sentences. Differently from previous studies in multi-document\nsummarization, we make a distinction between edges linking sentences from\ndifferent documents (inter-layer) and those connecting sentences from the same\ndocument (intra-layer). As a proof of principle, our results reveal that such a\ndiscrimination between intra- and inter-layer in a multilayered representation\nis able to improve the quality of the generated summaries. This piece of\ninformation could be used to improve current statistical methods and related\ntextual models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 17:01:55 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Tohalino", "Jorge V.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "1711.02781", "submitter": "Tao Lin", "authors": "Huiting Liu, Tao Lin, Hanfei Sun, Weijian Lin, Chih-Wei Chang, Teng\n  Zhong, Alexander Rudnicky", "title": "RubyStar: A Non-Task-Oriented Mixture Model Dialog System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RubyStar is a dialog system designed to create \"human-like\" conversation by\ncombining different response generation strategies. RubyStar conducts a\nnon-task-oriented conversation on general topics by using an ensemble of\nrule-based, retrieval-based and generative methods. Topic detection, engagement\nmonitoring, and context tracking are used for managing interaction. Predictable\nelements of conversation, such as the bot's backstory and simple question\nanswering are handled by separate modules. We describe a rating scheme we\ndeveloped for evaluating response generation. We find that character-level RNN\nis an effective generation model for general responses, with proper parameter\nsettings; however other kinds of conversation topics might benefit from using\nother models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 00:57:39 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 02:42:40 GMT"}, {"version": "v3", "created": "Sat, 16 Dec 2017 04:18:55 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Liu", "Huiting", ""], ["Lin", "Tao", ""], ["Sun", "Hanfei", ""], ["Lin", "Weijian", ""], ["Chang", "Chih-Wei", ""], ["Zhong", "Teng", ""], ["Rudnicky", "Alexander", ""]]}, {"id": "1711.02799", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Arash Mehrjou, Stephan Gouws, Jaap Kamps, Bernhard\n  Sch\\\"olkopf", "title": "Fidelity-Weighted Learning", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks requires many training samples, but in practice\ntraining labels are expensive to obtain and may be of varying quality, as some\nmay be from trusted expert labelers while others might be from heuristics or\nother sources of weak supervision such as crowd-sourcing. This creates a\nfundamental quality versus-quantity trade-off in the learning process. Do we\nlearn from the small amount of high-quality data or the potentially large\namount of weakly-labeled data? We argue that if the learner could somehow know\nand take the label-quality into account when learning the data representation,\nwe could get the best of both worlds. To this end, we propose\n\"fidelity-weighted learning\" (FWL), a semi-supervised student-teacher approach\nfor training deep neural networks using weakly-labeled data. FWL modulates the\nparameter updates to a student network (trained on the task we care about) on a\nper-sample basis according to the posterior confidence of its label-quality\nestimated by a teacher (who has access to the high-quality labels). Both\nstudent and teacher are learned from the data. We evaluate FWL on two tasks in\ninformation retrieval and natural language processing where we outperform\nstate-of-the-art alternative semi-supervised methods, indicating that our\napproach makes better use of strong and weak labels, and leads to better\ntask-dependent data representations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 02:05:11 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 14:27:21 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Mehrjou", "Arash", ""], ["Gouws", "Stephan", ""], ["Kamps", "Jaap", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1711.02918", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko, Dmitry Ustalov, Stefano Faralli, Simone P.\n  Ponzetto, Chris Biemann", "title": "Improving Hypernymy Extraction with Distributional Semantic Classes", "comments": "In Proceedings of the 11th Conference on Language Resources and\n  Evaluation (LREC 2018). Miyazaki, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we show how distributionally-induced semantic classes can be\nhelpful for extracting hypernyms. We present methods for inducing sense-aware\nsemantic classes using distributional semantics and using these induced\nsemantic classes for filtering noisy hypernymy relations. Denoising of\nhypernyms is performed by labeling each semantic class with its hypernyms. On\nthe one hand, this allows us to filter out wrong extractions using the global\nstructure of distributionally similar senses. On the other hand, we infer\nmissing hypernyms via label propagation to cluster terms. We conduct a\nlarge-scale crowdsourcing study showing that processing of automatically\nextracted hypernyms using our approach improves the quality of the hypernymy\nextraction in terms of both precision and recall. Furthermore, we show the\nutility of our method in the domain taxonomy induction task, achieving the\nstate-of-the-art results on a SemEval'16 task on taxonomy induction.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 12:29:18 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 16:24:23 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Panchenko", "Alexander", ""], ["Ustalov", "Dmitry", ""], ["Faralli", "Stefano", ""], ["Ponzetto", "Simone P.", ""], ["Biemann", "Chris", ""]]}, {"id": "1711.03147", "submitter": "Clemente Rubio-Manzano", "authors": "Clemente Rubio-Manzano, Martin Pereira-Fari\\~na", "title": "On the incorporation of interval-valued fuzzy sets into the Bousi-Prolog\n  system: declarative semantics, implementation and applications", "comments": null, "journal-ref": "Interactions Between Computational Intelligence and Mathematics\n  Studies in Computational Intelligence, vol 794. Springer 2018", "doi": "10.1007/978-3-030-01632-6_1", "report-no": null, "categories": "cs.AI cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyse the benefits of incorporating interval-valued fuzzy\nsets into the Bousi-Prolog system. A syntax, declarative semantics and im-\nplementation for this extension is presented and formalised. We show, by using\npotential applications, that fuzzy logic programming frameworks enhanced with\nthem can correctly work together with lexical resources and ontologies in order\nto improve their capabilities for knowledge representation and reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 20:25:43 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Rubio-Manzano", "Clemente", ""], ["Pereira-Fari\u00f1a", "Martin", ""]]}, {"id": "1711.03225", "submitter": "Qizhe Xie", "authors": "Qizhe Xie, Guokun Lai, Zihang Dai, Eduard Hovy", "title": "Large-scale Cloze Test Dataset Created by Teachers", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloze tests are widely adopted in language exams to evaluate students'\nlanguage proficiency. In this paper, we propose the first large-scale\nhuman-created cloze test dataset CLOTH, containing questions used in\nmiddle-school and high-school language exams. With missing blanks carefully\ncreated by teachers and candidate choices purposely designed to be nuanced,\nCLOTH requires a deeper language understanding and a wider attention span than\npreviously automatically-generated cloze datasets. We test the performance of\ndedicatedly designed baseline models including a language model trained on the\nOne Billion Word Corpus and show humans outperform them by a significant\nmargin. We investigate the source of the performance gap, trace model\ndeficiencies to some distinct properties of CLOTH, and identify the limited\nability of comprehending the long-term context to be the key bottleneck.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 01:41:12 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 17:06:01 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 01:51:13 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Xie", "Qizhe", ""], ["Lai", "Guokun", ""], ["Dai", "Zihang", ""], ["Hovy", "Eduard", ""]]}, {"id": "1711.03226", "submitter": "Meng Qu", "authors": "Meng Qu, Xiang Ren, Yu Zhang, Jiawei Han", "title": "Weakly-supervised Relation Extraction by Pattern-enhanced Embedding\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relations from text corpora is an important task in text mining.\nIt becomes particularly challenging when focusing on weakly-supervised relation\nextraction, that is, utilizing a few relation instances (i.e., a pair of\nentities and their relation) as seeds to extract more instances from corpora.\nExisting distributional approaches leverage the corpus-level co-occurrence\nstatistics of entities to predict their relations, and require large number of\nlabeled instances to learn effective relation classifiers. Alternatively,\npattern-based approaches perform bootstrapping or apply neural networks to\nmodel the local contexts, but still rely on large number of labeled instances\nto build reliable models. In this paper, we study integrating the\ndistributional and pattern-based methods in a weakly-supervised setting, such\nthat the two types of methods can provide complementary supervision for each\nother to build an effective, unified model. We propose a novel co-training\nframework with a distributional module and a pattern module. During training,\nthe distributional module helps the pattern module discriminate between the\ninformative patterns and other patterns, and the pattern module generates some\nhighly-confident instances to improve the distributional module. The whole\nframework can be effectively optimized by iterating between improving the\npattern module and updating the distributional module. We conduct experiments\non two tasks: knowledge base completion with text corpora and corpus-level\nrelation extraction. Experimental results prove the effectiveness of our\nframework in the weakly-supervised setting.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 01:42:14 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 02:54:11 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Qu", "Meng", ""], ["Ren", "Xiang", ""], ["Zhang", "Yu", ""], ["Han", "Jiawei", ""]]}, {"id": "1711.03230", "submitter": "Yelong Shen", "authors": "Yelong Shen and Xiaodong Liu and Kevin Duh and Jianfeng Gao", "title": "An Empirical Analysis of Multiple-Turn Reasoning Strategies in Reading\n  Comprehension Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension (RC) is a challenging task that requires synthesis of\ninformation across sentences and multiple turns of reasoning. Using a\nstate-of-the-art RC model, we empirically investigate the performance of\nsingle-turn and multiple-turn reasoning on the SQuAD and MS MARCO datasets. The\nRC model is an end-to-end neural network with iterative attention, and uses\nreinforcement learning to dynamically control the number of turns. We find that\nmultiple-turn reasoning outperforms single-turn reasoning for all question and\nanswer types; further, we observe that enabling a flexible number of turns\ngenerally improves upon a fixed multiple-turn strategy. %across all question\ntypes, and is particularly beneficial to questions with lengthy, descriptive\nanswers. We achieve results competitive to the state-of-the-art on these two\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 01:56:00 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Shen", "Yelong", ""], ["Liu", "Xiaodong", ""], ["Duh", "Kevin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1711.03373", "submitter": "Ziqi Zhang", "authors": "Ziqi Zhang, Jie Gao, Fabio Ciravegna", "title": "SemRe-Rank: Improving Automatic Term Extraction By Incorporating\n  Semantic Relatedness With Personalised PageRank", "comments": "Accepted by ACM TKDD. This is a pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Term Extraction deals with the extraction of terminology from a\ndomain specific corpus, and has long been an established research area in data\nand knowledge acquisition. ATE remains a challenging task as it is known that\nthere is no existing ATE methods that can consistently outperform others in any\ndomain. This work adopts a refreshed perspective to this problem: instead of\nsearching for such a 'one-size-fit-all' solution that may never exist, we\npropose to develop generic methods to 'enhance' existing ATE methods. We\nintroduce SemRe-Rank, the first method based on this principle, to incorporate\nsemantic relatedness - an often overlooked venue - into an existing ATE method\nto further improve its performance. SemRe-Rank incorporates word embeddings\ninto a personalised PageRank process to compute 'semantic importance' scores\nfor candidate terms from a graph of semantically related words (nodes), which\nare then used to revise the scores of candidate terms computed by a base ATE\nalgorithm. Extensively evaluated with 13 state-of-the-art base ATE methods on\nfour datasets of diverse nature, it is shown to have achieved widespread\nimprovement over all base methods and across all datasets, with up to 15\npercentage points when measured by the Precision in the top ranked K candidate\nterms (the average for a set of K's), or up to 28 percentage points in F1\nmeasured at a K that equals to the expected real terms in the candidates (F1 in\nshort). Compared to an alternative approach built on the well-known TextRank\nalgorithm, SemRe-Rank can potentially outperform by up to 8 points in Precision\nat top K, or up to 17 points in F1.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 13:39:21 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 20:55:54 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 20:52:19 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Zhang", "Ziqi", ""], ["Gao", "Jie", ""], ["Ciravegna", "Fabio", ""]]}, {"id": "1711.03381", "submitter": "Yinpei Dai", "authors": "Yinpei Dai, Zhijian Ou, Dawei Ren, Pengfei Yu", "title": "Tracking of enriched dialog states for flexible conversational\n  information access", "comments": "5 pages, 2 figures, accepted by ICASSP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog state tracking (DST) is a crucial component in a task-oriented dialog\nsystem for conversational information access. A common practice in current\ndialog systems is to define the dialog state by a set of slot-value pairs. Such\nrepresentation of dialog states and the slot-filling based DST have been widely\nemployed, but suffer from three drawbacks. (1) The dialog state can contain\nonly a single value for a slot, and (2) can contain only users' affirmative\npreference over the values for a slot. (3) Current task-based dialog systems\nmainly focus on the searching task, while the enquiring task is also very\ncommon in practice. The above observations motivate us to enrich current\nrepresentation of dialog states and collect a brand new dialog dataset about\nmovies, based upon which we build a new DST, called enriched DST (EDST), for\nflexible accessing movie information. The EDST supports the searching task, the\nenquiring task and their mixed task. We show that the new EDST method not only\nachieves good results on Iqiyi dataset, but also outperforms other\nstate-of-the-art DST methods on the traditional dialog datasets, WOZ2.0 and\nDSTC2.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:10:45 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 16:23:46 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Dai", "Yinpei", ""], ["Ou", "Zhijian", ""], ["Ren", "Dawei", ""], ["Yu", "Pengfei", ""]]}, {"id": "1711.03438", "submitter": "Baoxu Shi", "authors": "Baoxu Shi, Tim Weninger", "title": "Open-World Knowledge Graph Completion", "comments": "8 pages, accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) have been applied to many tasks including Web search,\nlink prediction, recommendation, natural language processing, and entity\nlinking. However, most KGs are far from complete and are growing at a rapid\npace. To address these problems, Knowledge Graph Completion (KGC) has been\nproposed to improve KGs by filling in its missing connections. Unlike existing\nmethods which hold a closed-world assumption, i.e., where KGs are fixed and new\nentities cannot be easily added, in the present work we relax this assumption\nand propose a new open-world KGC task. As a first attempt to solve this task we\nintroduce an open-world KGC model called ConMask. This model learns embeddings\nof the entity's name and parts of its text-description to connect unseen\nentities to the KG. To mitigate the presence of noisy text descriptions,\nConMask uses a relationship-dependent content masking to extract relevant\nsnippets and then trains a fully convolutional neural network to fuse the\nextracted snippets with entities in the KG. Experiments on large data sets,\nboth old and new, show that ConMask performs well in the open-world KGC task\nand even outperforms existing KGC models on the standard closed-world KGC task.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 15:58:55 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Shi", "Baoxu", ""], ["Weninger", "Tim", ""]]}, {"id": "1711.03483", "submitter": "Eloi Zablocki", "authors": "\\'Eloi Zablocki, Benjamin Piwowarski, Laure Soulier, Patrick Gallinari", "title": "Learning Multi-Modal Word Representation Grounded in Visual Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing the semantics of words is a long-standing problem for the\nnatural language processing community. Most methods compute word semantics\ngiven their textual context in large corpora. More recently, researchers\nattempted to integrate perceptual and visual features. Most of these works\nconsider the visual appearance of objects to enhance word representations but\nthey ignore the visual environment and context in which objects appear. We\npropose to unify text-based techniques with vision-based techniques by\nsimultaneously leveraging textual and visual context to learn multimodal word\nembeddings. We explore various choices for what can serve as a visual context\nand present an end-to-end method to integrate visual context elements in a\nmultimodal skip-gram model. We provide experiments and extensive analysis of\nthe obtained results.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 17:28:07 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Zablocki", "\u00c9loi", ""], ["Piwowarski", "Benjamin", ""], ["Soulier", "Laure", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1711.03541", "submitter": "Sreeram Ganji Mr.", "authors": "Ganji Sreeram and Rohit Sinha", "title": "Language Modeling for Code-Switched Data: Challenges and Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lately, the problem of code-switching has gained a lot of attention and has\nemerged as an active area of research. In bilingual communities, the speakers\ncommonly embed the words and phrases of a non-native language into the syntax\nof a native language in their day-to-day communications. The code-switching is\na global phenomenon among multilingual communities, still very limited acoustic\nand linguistic resources are available as yet. For developing effective speech\nbased applications, the ability of the existing language technologies to deal\nwith the code-switched data can not be over emphasized. The code-switching is\nbroadly classified into two modes: inter-sentential and intra-sentential\ncode-switching. In this work, we have studied the intra-sentential problem in\nthe context of code-switching language modeling task. The salient contributions\nof this paper includes: (i) the creation of Hindi-English code-switching text\ncorpus by crawling a few blogging sites educating about the usage of the\nInternet (ii) the exploration of the parts-of-speech features towards more\neffective modeling of Hindi-English code-switched data by the monolingual\nlanguage model (LM) trained on native (Hindi) language data, and (iii) the\nproposal of a novel textual factor referred to as the code-switch factor\n(CS-factor), which allows the LM to predict the code-switching instances. In\nthe context of recognition of the code-switching data, the substantial\nreduction in the PPL is achieved with the use of POS factors and also the\nproposed CS-factor provides independent as well as additive gain in the PPL.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 06:29:28 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Sreeram", "Ganji", ""], ["Sinha", "Rohit", ""]]}, {"id": "1711.03602", "submitter": "WooJin Chung", "authors": "WooJin Chung, Sheng-Fu Wang, and Samuel R. Bowman", "title": "The Lifted Matrix-Space Model for Semantic Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-structured neural network architectures for sentence encoding draw\ninspiration from the approach to semantic composition generally seen in formal\nlinguistics, and have shown empirical improvements over comparable sequence\nmodels by doing so. Moreover, adding multiplicative interaction terms to the\ncomposition functions in these models can yield significant further\nimprovements. However, existing compositional approaches that adopt such a\npowerful composition function scale poorly, with parameter counts exploding as\nmodel dimension or vocabulary size grows. We introduce the Lifted Matrix-Space\nmodel, which uses a global transformation to map vector word embeddings to\nmatrices, which can then be composed via an operation based on matrix-matrix\nmultiplication. Its composition function effectively transmits a larger number\nof activations across layers with relatively few model parameters. We evaluate\nour model on the Stanford NLI corpus, the Multi-Genre NLI corpus, and the\nStanford Sentiment Treebank and find that it consistently outperforms TreeLSTM\n(Tai et al., 2015), the previous best known composition function for\ntree-structured models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 20:58:07 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 05:12:39 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Chung", "WooJin", ""], ["Wang", "Sheng-Fu", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1711.03688", "submitter": "Sameen Maruf", "authors": "Sameen Maruf, Gholamreza Haffari", "title": "Document Context Neural Machine Translation with Memory Networks", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a document-level neural machine translation model which takes both\nsource and target document context into account using memory networks. We model\nthe problem as a structured prediction problem with interdependencies among the\nobserved and hidden variables, i.e., the source sentences and their unobserved\ntarget translations in the document. The resulting structured prediction\nproblem is tackled with a neural translation model equipped with two memory\ncomponents, one each for the source and target side, to capture the documental\ninterdependencies. We train the model end-to-end, and propose an iterative\ndecoding algorithm based on block coordinate descent. Experimental results of\nEnglish translations from French, German, and Estonian documents show that our\nmodel is effective in exploiting both source and target document context, and\nstatistically significantly outperforms the previous work in terms of BLEU and\nMETEOR.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 04:35:14 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 05:52:02 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Maruf", "Sameen", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1711.03689", "submitter": "Taku Kato", "authors": "Taku Kato, Takahiro Shinozaki", "title": "Reinforcement Learning of Speech Recognition System Based on Policy\n  Gradient and Hypothesis Selection", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition systems have achieved high recognition performance for\nseveral tasks. However, the performance of such systems is dependent on the\ntremendously costly development work of preparing vast amounts of task-matched\ntranscribed speech data for supervised training. The key problem here is the\ncost of transcribing speech data. The cost is repeatedly required to support\nnew languages and new tasks. Assuming broad network services for transcribing\nspeech data for many users, a system would become more self-sufficient and more\nuseful if it possessed the ability to learn from very light feedback from the\nusers without annoying them. In this paper, we propose a general reinforcement\nlearning framework for speech recognition systems based on the policy gradient\nmethod. As a particular instance of the framework, we also propose a hypothesis\nselection-based reinforcement learning method. The proposed framework provides\na new view for several existing training and adaptation methods. The\nexperimental results show that the proposed method improves the recognition\nperformance compared to unsupervised adaptation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 04:42:44 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Kato", "Taku", ""], ["Shinozaki", "Takahiro", ""]]}, {"id": "1711.03697", "submitter": "Weiyan Wang", "authors": "Weiyan Wang, Yuxiang WU, Yu Zhang, Zhongqi Lu, Kaixiang Mo, Qiang Yang", "title": "Integrating User and Agent Models: A Deep Task-Oriented Dialogue System", "comments": "9 pages, 7 figures, it's a revised version of our previously\n  attempted submission to IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialogue systems can efficiently serve a large number of\ncustomers and relieve people from tedious works. However, existing\ntask-oriented dialogue systems depend on handcrafted actions and states or\nextra semantic labels, which sometimes degrades user experience despite the\nintensive human intervention. Moreover, current user simulators have limited\nexpressive ability so that deep reinforcement Seq2Seq models have to rely on\nselfplay and only work in some special cases. To address those problems, we\npropose a uSer and Agent Model IntegrAtion (SAMIA) framework inspired by an\nobservation that the roles of the user and agent models are asymmetric.\nFirstly, this SAMIA framework model the user model as a Seq2Seq learning\nproblem instead of ranking or designing rules. Then the built user model is\nused as a leverage to train the agent model by deep reinforcement learning. In\nthe test phase, the output of the agent model is filtered by the user model to\nenhance the stability and robustness. Experiments on a real-world coffee\nordering dataset verify the effectiveness of the proposed SAMIA framework.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 05:27:44 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Wang", "Weiyan", ""], ["WU", "Yuxiang", ""], ["Zhang", "Yu", ""], ["Lu", "Zhongqi", ""], ["Mo", "Kaixiang", ""], ["Yang", "Qiang", ""]]}, {"id": "1711.03736", "submitter": "Masoud Fatemi", "authors": "Masoud Fatemi and Mehran Safayani", "title": "Joint Sentiment/Topic Modeling on Text Data Using Boosted Restricted\n  Boltzmann Machine", "comments": null, "journal-ref": null, "doi": "10.1007/s11042-019-7427-5", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently by the development of the Internet and the Web, different types of\nsocial media such as web blogs become an immense source of text data. Through\nthe processing of these data, it is possible to discover practical information\nabout different topics, individuals opinions and a thorough understanding of\nthe society. Therefore, applying models which can automatically extract the\nsubjective information from the documents would be efficient and helpful. Topic\nmodeling methods, also sentiment analysis are the most raised topics in the\nnatural language processing and text mining fields. In this paper a new\nstructure for joint sentiment-topic modeling based on Restricted Boltzmann\nMachine (RBM) which is a type of neural networks is proposed. By modifying the\nstructure of RBM as well as appending a layer which is analogous to sentiment\nof text data to it, we propose a generative structure for joint sentiment topic\nmodeling based on neutral networks. The proposed method is supervised and\ntrained by the Contrastive Divergence algorithm. The new attached layer in the\nproposed model is a layer with the multinomial probability distribution which\ncan be used in text data sentiment classification or any other supervised\napplication. The proposed model is compared with existing models in the\nexperiments such as evaluating as a generative model, sentiment classification,\ninformation retrieval and the corresponding results demonstrate the efficiency\nof the method.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 09:17:02 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Fatemi", "Masoud", ""], ["Safayani", "Mehran", ""]]}, {"id": "1711.03754", "submitter": "Todor Mihaylov", "authors": "Todor Mihaylov, Zornitsa Kozareva, Anette Frank", "title": "Neural Skill Transfer from Supervised Language Tasks to Reading\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension is a challenging task in natural language processing\nand requires a set of skills to be solved. While current approaches focus on\nsolving the task as a whole, in this paper, we propose to use a neural network\n`skill' transfer approach. We transfer knowledge from several lower-level\nlanguage tasks (skills) including textual entailment, named entity recognition,\nparaphrase detection and question type classification into the reading\ncomprehension model.\n  We conduct an empirical evaluation and show that transferring language skill\nknowledge leads to significant improvements for the task with much fewer steps\ncompared to the baseline model. We also show that the skill transfer approach\nis effective even with small amounts of training data. Another finding of this\nwork is that using token-wise deep label supervision for text classification\nimproves the performance of transfer learning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 10:13:51 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Mihaylov", "Todor", ""], ["Kozareva", "Zornitsa", ""], ["Frank", "Anette", ""]]}, {"id": "1711.03759", "submitter": "Jie Yang", "authors": "Jie Yang, Yue Zhang, Linwei Li, Xingxuan Li", "title": "YEDDA: A Lightweight Collaborative Text Span Annotation Tool", "comments": "Accepted by ACL 2018 as demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce \\textsc{Yedda}, a lightweight but efficient and\ncomprehensive open-source tool for text span annotation. \\textsc{Yedda}\nprovides a systematic solution for text span annotation, ranging from\ncollaborative user annotation to administrator evaluation and analysis. It\novercomes the low efficiency of traditional text annotation tools by annotating\nentities through both command line and shortcut keys, which are configurable\nwith custom labels. \\textsc{Yedda} also gives intelligent recommendations by\nlearning the up-to-date annotated text. An administrator client is developed to\nevaluate annotation quality of multiple annotators and generate detailed\ncomparison report for each annotator pair. Experiments show that the proposed\nsystem can reduce the annotation time by half compared with existing annotation\ntools. And the annotation time can be further compressed by 16.47\\% through\nintelligent recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 10:18:02 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 09:18:39 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 13:24:56 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Yang", "Jie", ""], ["Zhang", "Yue", ""], ["Li", "Linwei", ""], ["Li", "Xingxuan", ""]]}, {"id": "1711.03800", "submitter": "Arun Balajee Vasudevan", "authors": "Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool", "title": "Object Referring in Visual Scene with Spoken Language", "comments": "10 pages, Submitted to WACV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object referring has important applications, especially for human-machine\ninteraction. While having received great attention, the task is mainly attacked\nwith written language (text) as input rather than spoken language (speech),\nwhich is more natural. This paper investigates Object Referring with Spoken\nLanguage (ORSpoken) by presenting two datasets and one novel approach. Objects\nare annotated with their locations in images, text descriptions and speech\ndescriptions. This makes the datasets ideal for multi-modality learning. The\napproach is developed by carefully taking down ORSpoken problem into three\nsub-problems and introducing task-specific vision-language interactions at the\ncorresponding levels. Experiments show that our method outperforms competing\nmethods consistently and significantly. The approach is also evaluated in the\npresence of audio noise, showing the efficacy of the proposed vision-language\ninteraction methods in counteracting background noise.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 13:04:55 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 15:12:24 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Vasudevan", "Arun Balajee", ""], ["Dai", "Dengxin", ""], ["Van Gool", "Luc", ""]]}, {"id": "1711.03859", "submitter": "Diego Molla-Aliod", "authors": "Diego Molla", "title": "Towards the Use of Deep Reinforcement Learning with Global Policy For\n  Query-based Extractive Summarisation", "comments": "5 pages, 2 figures, 1 algorithm. As submitted for camera ready for\n  the 2017 Australasian Language Technology Association Workshop (ALTA 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised approaches for text summarisation suffer from the problem of\nmismatch between the target labels/scores of individual sentences and the\nevaluation score of the final summary. Reinforcement learning can solve this\nproblem by providing a learning mechanism that uses the score of the final\nsummary as a guide to determine the decisions made at the time of selection of\neach sentence. In this paper we present a proof-of-concept approach that\napplies a policy-gradient algorithm to learn a stochastic policy using an\nundiscounted reward. The method has been applied to a policy consisting of a\nsimple neural network and simple features. The resulting deep reinforcement\nlearning system is able to learn a global policy and obtain encouraging\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 15:14:49 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 16:05:20 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Molla", "Diego", ""]]}, {"id": "1711.03946", "submitter": "Robert Bamler", "authors": "Geng Ji, Robert Bamler, Erik B. Sudderth, Stephan Mandt", "title": "Bayesian Paragraph Vectors", "comments": "Presented at the NIPS 2017 workshop \"Advances in Approximate Bayesian\n  Inference\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2vec (Mikolov et al., 2013) has proven to be successful in natural\nlanguage processing by capturing the semantic relationships between different\nwords. Built on top of single-word embeddings, paragraph vectors (Le and\nMikolov, 2014) find fixed-length representations for pieces of text with\narbitrary lengths, such as documents, paragraphs, and sentences. In this work,\nwe propose a novel interpretation for neural-network-based paragraph vectors by\ndeveloping an unsupervised generative model whose maximum likelihood solution\ncorresponds to traditional paragraph vectors. This probabilistic formulation\nallows us to go beyond point estimates of parameters and to perform Bayesian\nposterior inference. We find that the entropy of paragraph vectors decreases\nwith the length of documents, and that information about posterior uncertainty\nimproves performance in supervised learning tasks such as sentiment analysis\nand paraphrase detection.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 18:09:15 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 20:37:31 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Ji", "Geng", ""], ["Bamler", "Robert", ""], ["Sudderth", "Erik B.", ""], ["Mandt", "Stephan", ""]]}, {"id": "1711.03953", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, William W. Cohen", "title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model", "comments": "ICLR Oral 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate language modeling as a matrix factorization problem, and show\nthat the expressiveness of Softmax-based models (including the majority of\nneural language models) is limited by a Softmax bottleneck. Given that natural\nlanguage is highly context-dependent, this further implies that in practice\nSoftmax with distributed word embeddings does not have enough capacity to model\nnatural language. We propose a simple and effective method to address this\nissue, and improve the state-of-the-art perplexities on Penn Treebank and\nWikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on\nthe large-scale 1B Word dataset, outperforming the baseline by over 5.6 points\nin perplexity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 18:29:00 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 20:40:35 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 01:15:08 GMT"}, {"version": "v4", "created": "Fri, 2 Mar 2018 20:20:52 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Yang", "Zhilin", ""], ["Dai", "Zihang", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1711.04044", "submitter": "Sahil Garg", "authors": "Sahil Garg and Aram Galstyan and Greg Ver Steeg and Irina Rish and\n  Guillermo Cecchi and Shuyang Gao", "title": "Kernelized Hashcode Representations for Relation Extraction", "comments": "To appear in the proceedings of conference, AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have produced state-of-the-art results for a number of NLP\ntasks such as relation extraction, but suffer from poor scalability due to the\nhigh cost of computing kernel similarities between natural language structures.\nA recently proposed technique, kernelized locality-sensitive hashing (KLSH),\ncan significantly reduce the computational cost, but is only applicable to\nclassifiers operating on kNN graphs. Here we propose to use random subspaces of\nKLSH codes for efficiently constructing an explicit representation of NLP\nstructures suitable for general classification methods. Further, we propose an\napproach for optimizing the KLSH model for classification problems by\nmaximizing an approximation of mutual information between the KLSH codes\n(feature vectors) and the class labels. We evaluate the proposed approach on\nbiomedical relation extraction datasets, and observe significant and robust\nimprovements in accuracy w.r.t. state-of-the-art classifiers, along with\ndrastic (orders-of-magnitude) speedup compared to conventional kernel methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 23:42:42 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 23:10:27 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 16:28:56 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 22:48:42 GMT"}, {"version": "v5", "created": "Mon, 3 Dec 2018 17:17:25 GMT"}, {"version": "v6", "created": "Mon, 25 Feb 2019 04:10:53 GMT"}, {"version": "v7", "created": "Mon, 20 May 2019 22:01:52 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Garg", "Sahil", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Gao", "Shuyang", ""]]}, {"id": "1711.04071", "submitter": "Liwei Cai", "authors": "Liwei Cai, William Yang Wang", "title": "KBGAN: Adversarial Learning for Knowledge Graph Embeddings", "comments": "To appear at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce KBGAN, an adversarial learning framework to improve the\nperformances of a wide range of existing knowledge graph embedding models.\nBecause knowledge graphs typically only contain positive facts, sampling useful\nnegative training examples is a non-trivial task. Replacing the head or tail\nentity of a fact with a uniformly randomly selected entity is a conventional\nmethod for generating negative facts, but the majority of the generated\nnegative facts can be easily discriminated from positive facts, and will\ncontribute little towards the training. Inspired by generative adversarial\nnetworks (GANs), we use one knowledge graph embedding model as a negative\nsample generator to assist the training of our desired model, which acts as the\ndiscriminator in GANs. This framework is independent of the concrete form of\ngenerator and discriminator, and therefore can utilize a wide variety of\nknowledge graph embedding models as its building blocks. In experiments, we\nadversarially train two translation-based models, TransE and TransD, each with\nassistance from one of the two probability-based models, DistMult and ComplEx.\nWe evaluate the performances of KBGAN on the link prediction task, using three\nknowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental\nresults show that adversarial training substantially improves the performances\nof target embedding models under various settings.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 03:46:53 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 01:31:45 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 14:36:17 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Cai", "Liwei", ""], ["Wang", "William Yang", ""]]}, {"id": "1711.04075", "submitter": "Haoran Shi", "authors": "Haoran Shi, Pengtao Xie, Zhiting Hu, Ming Zhang, and Eric P. Xing", "title": "Towards Automated ICD Coding Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  International Classification of Diseases(ICD) is an authoritative health care\nclassification system of different diseases and conditions for clinical and\nmanagement purposes. Considering the complicated and dedicated process to\nassign correct codes to each patient admission based on overall diagnosis, we\npropose a hierarchical deep learning model with attention mechanism which can\nautomatically assign ICD diagnostic codes given written diagnosis. We utilize\ncharacter-aware neural language models to generate hidden representations of\nwritten diagnosis descriptions and ICD codes, and design an attention mechanism\nto address the mismatch between the numbers of descriptions and corresponding\ncodes. Our experimental results show the strong potential of automated ICD\ncoding from diagnosis descriptions. Our best model achieves 0.53 and 0.90 of F1\nscore and area under curve of receiver operating characteristic respectively.\nThe result outperforms those achieved using character-unaware encoding method\nor without attention mechanism. It indicates that our proposed deep learning\nmodel can code automatically in a reasonable way and provide a framework for\ncomputer-auxiliary ICD coding.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 04:34:51 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 01:48:29 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 16:16:11 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Shi", "Haoran", ""], ["Xie", "Pengtao", ""], ["Hu", "Zhiting", ""], ["Zhang", "Ming", ""], ["Xing", "Eric P.", ""]]}, {"id": "1711.04079", "submitter": "Kaixiang Mo", "authors": "Kaixiang Mo, Yu Zhang, Qiang Yang, Pascale Fung", "title": "Fine Grained Knowledge Transfer for Personalized Task-oriented Dialogue\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a personalized dialogue system requires a lot of data, and the data\ncollected for a single user is usually insufficient. One common practice for\nthis problem is to share training dialogues between different users and train\nmultiple sequence-to-sequence dialogue models together with transfer learning.\nHowever, current sequence-to-sequence transfer learning models operate on the\nentire sentence, which might cause negative transfer if different personal\ninformation from different users is mixed up. We propose a personalized decoder\nmodel to transfer finer granularity phrase-level knowledge between different\nusers while keeping personal preferences of each user intact. A novel personal\ncontrol gate is introduced, enabling the personalized decoder to switch between\ngenerating personalized phrases and shared phrases. The proposed personalized\ndecoder model can be easily combined with various deep models and can be\ntrained with reinforcement learning. Real-world experimental results\ndemonstrate that the phrase-level personalized decoder improves the BLEU over\nmultiple sentence-level transfer baseline models by as much as 7.5%.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 05:14:02 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Mo", "Kaixiang", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""], ["Fung", "Pascale", ""]]}, {"id": "1711.04090", "submitter": "Xianda Zhou", "authors": "Xianda Zhou, William Yang Wang", "title": "MojiTalk: Generating Emotional Responses at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating emotional language is a key step towards building empathetic\nnatural language processing agents. However, a major challenge for this line of\nresearch is the lack of large-scale labeled training data, and previous studies\nare limited to only small sets of human annotated sentiment labels.\nAdditionally, explicitly controlling the emotion and sentiment of generated\ntext is also difficult. In this paper, we take a more radical approach: we\nexploit the idea of leveraging Twitter data that are naturally labeled with\nemojis. More specifically, we collect a large corpus of Twitter conversations\nthat include emojis in the response, and assume the emojis convey the\nunderlying emotions of the sentence. We then introduce a reinforced conditional\nvariational encoder approach to train a deep generative model on these\nconversations, which allows us to use emojis to control the emotion of the\ngenerated text. Experimentally, we show in our quantitative and qualitative\nanalyses that the proposed models can successfully generate high-quality\nabstractive conversation responses in accordance with designated emotions.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 07:20:51 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 05:10:42 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhou", "Xianda", ""], ["Wang", "William Yang", ""]]}, {"id": "1711.04115", "submitter": "Mitodru Niyogi", "authors": "Mitodru Niyogi (1), Asim K. Pal (2) ((1) Govt. College of Engineering\n  & Ceramic Technology, Kolkata, India, (2) Management Information Systems, IIM\n  Calcutta, Kolkata, India)", "title": "Discovering conversational topics and emotions associated with\n  Demonetization tweets in India", "comments": "6 pages, 11 figures. arXiv admin note: substantial text overlap with\n  arXiv:1608.02519 by other authors; text overlap with arXiv:1705.08094 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms contain great wealth of information which provides us\nopportunities explore hidden patterns or unknown correlations, and understand\npeople's satisfaction with what they are discussing. As one showcase, in this\npaper, we summarize the data set of Twitter messages related to recent\ndemonetization of all Rs. 500 and Rs. 1000 notes in India and explore insights\nfrom Twitter's data. Our proposed system automatically extracts the popular\nlatent topics in conversations regarding demonetization discussed in Twitter\nvia the Latent Dirichlet Allocation (LDA) based topic model and also identifies\nthe correlated topics across different categories. Additionally, it also\ndiscovers people's opinions expressed through their tweets related to the event\nunder consideration via the emotion analyzer. The system also employs an\nintuitive and informative visualization to show the uncovered insight.\nFurthermore, we use an evaluation measure, Normalized Mutual Information (NMI),\nto select the best LDA models. The obtained LDA results show that the tool can\nbe effectively used to extract discussion topics and summarize them for further\nmanual analysis.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 10:55:38 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Niyogi", "Mitodru", ""], ["Pal", "Asim K.", ""]]}, {"id": "1711.04154", "submitter": "Anna Potapenko", "authors": "Anna Potapenko, Artem Popov, Konstantin Vorontsov", "title": "Interpretable probabilistic embeddings: bridging the gap between topic\n  models and neural networks", "comments": "Appeared in AINL-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider probabilistic topic models and more recent word embedding\ntechniques from a perspective of learning hidden semantic representations.\nInspired by a striking similarity of the two approaches, we merge them and\nlearn probabilistic embeddings with online EM-algorithm on word co-occurrence\ndata. The resulting embeddings perform on par with Skip-Gram Negative Sampling\n(SGNS) on word similarity tasks and benefit in the interpretability of the\ncomponents. Next, we learn probabilistic document embeddings that outperform\nparagraph2vec on a document similarity task and require less memory and time\nfor training. Finally, we employ multimodal Additive Regularization of Topic\nModels (ARTM) to obtain a high sparsity and learn embeddings for other\nmodalities, such as timestamps and categories. We observe further improvement\nof word similarity performance and meaningful inter-modality similarities.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 15:35:22 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Potapenko", "Anna", ""], ["Popov", "Artem", ""], ["Vorontsov", "Konstantin", ""]]}, {"id": "1711.04168", "submitter": "Maksims Volkovs", "authors": "Chundi Liu, Shunan Zhao, Maksims Volkovs", "title": "Unsupervised Document Embedding With CNNs", "comments": "Major revision with additional experiments and model description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for unsupervised document embedding. Leading existing\napproaches either require complex inference or use recurrent neural networks\n(RNN) that are difficult to parallelize. We take a different route and develop\na convolutional neural network (CNN) embedding model. Our CNN architecture is\nfully parallelizable resulting in over 10x speedup in inference time over RNN\nmodels. Parallelizable architecture enables to train deeper models where each\nsuccessive layer has increasingly larger receptive field and models longer\nrange semantic structure within the document. We additionally propose a fully\nunsupervised learning algorithm to train this model based on stochastic forward\nprediction. Empirical results on two public benchmarks show that our approach\nproduces comparable to state-of-the-art accuracy at a fraction of computational\ncost.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 16:43:38 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 17:33:30 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 01:54:17 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Liu", "Chundi", ""], ["Zhao", "Shunan", ""], ["Volkovs", "Maksims", ""]]}, {"id": "1711.04204", "submitter": "Frank F. Xu", "authors": "Frank F. Xu, Bill Yuchen Lin, Kenny Q. Zhu", "title": "Automatic Extraction of Commonsense LocatedNear Knowledge", "comments": "Accepted by ACL 2018. A preliminary version is presented on\n  AKBC@NIPS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LocatedNear relation is a kind of commonsense knowledge describing two\nphysical objects that are typically found near each other in real life. In this\npaper, we study how to automatically extract such relationship through a\nsentence-level relation classifier and aggregating the scores of entity pairs\nfrom a large corpus. Also, we release two benchmark datasets for evaluation and\nfuture research.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 22:25:55 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 01:39:18 GMT"}, {"version": "v3", "created": "Sun, 13 May 2018 00:01:04 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Xu", "Frank F.", ""], ["Lin", "Bill Yuchen", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1711.04231", "submitter": "Kehai Chen", "authors": "Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, and Tiejun Zhao", "title": "Syntax-Directed Attention for Neural Machine Translation", "comments": "AAAI2018, revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism, including global attention and local attention, plays a\nkey role in neural machine translation (NMT). Global attention attends to all\nsource words for word prediction. In comparison, local attention selectively\nlooks at fixed-window source words. However, alignment weights for the current\ntarget word often decrease to the left and right by linear distance centering\non the aligned source position and neglect syntax-directed distance\nconstraints. In this paper, we extend local attention with syntax-distance\nconstraint, to focus on syntactically related source words with the predicted\ntarget word, thus learning a more effective context vector for word prediction.\nMoreover, we further propose a double context NMT architecture, which consists\nof a global context vector and a syntax-directed context vector over the global\nattention, to provide more translation performance for NMT from source\nrepresentation. The experiments on the large-scale Chinese-to-English and\nEnglish-to-Germen translation tasks show that the proposed approach achieves a\nsubstantial and significant improvement over the baseline system.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 03:35:48 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 03:04:12 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 05:26:06 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Chen", "Kehai", ""], ["Wang", "Rui", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1711.04289", "submitter": "Qian Chen", "authors": "Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Diana Inkpen, Si Wei", "title": "Neural Natural Language Inference Models Enhanced with External\n  Knowledge", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-1224", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling natural language inference is a very challenging task. With the\navailability of large annotated data, it has recently become feasible to train\ncomplex models such as neural-network-based inference models, which have shown\nto achieve the state-of-the-art performance. Although there exist relatively\nlarge annotated data, can machines learn all knowledge needed to perform\nnatural language inference (NLI) from these data? If not, how can\nneural-network-based NLI models benefit from external knowledge and how to\nbuild NLI models to leverage it? In this paper, we enrich the state-of-the-art\nneural natural language inference models with external knowledge. We\ndemonstrate that the proposed models improve neural NLI models to achieve the\nstate-of-the-art performance on the SNLI and MultiNLI datasets.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 13:12:19 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 03:21:29 GMT"}, {"version": "v3", "created": "Sat, 23 Jun 2018 11:32:06 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chen", "Qian", ""], ["Zhu", "Xiaodan", ""], ["Ling", "Zhen-Hua", ""], ["Inkpen", "Diana", ""], ["Wei", "Si", ""]]}, {"id": "1711.04352", "submitter": "Felix Wu", "authors": "Felix Wu, Ni Lao, John Blitzer, Guandao Yang, Kilian Weinberger", "title": "Fast Reading Comprehension with ConvNets", "comments": "15 pages, 10 figures, submitted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep reading comprehension models are dominated by recurrent\nneural nets. Their sequential nature is a natural fit for language, but it also\nprecludes parallelization within an instances and often becomes the bottleneck\nfor deploying such models to latency critical scenarios. This is particularly\nproblematic for longer texts. Here we present a convolutional architecture as\nan alternative to these recurrent architectures. Using simple dilated\nconvolutional units in place of recurrent ones, we achieve results comparable\nto the state of the art on two question answering tasks, while at the same time\nachieving up to two orders of magnitude speedups for question answering.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 20:40:25 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Wu", "Felix", ""], ["Lao", "Ni", ""], ["Blitzer", "John", ""], ["Yang", "Guandao", ""], ["Weinberger", "Kilian", ""]]}, {"id": "1711.04411", "submitter": "Chunqi Wang", "authors": "Chunqi Wang, Bo Xu", "title": "Convolutional Neural Network with Word Embeddings for Chinese Word\n  Segmentation", "comments": "will be published by IJCNLP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-based sequence labeling framework is flexible and efficient for\nChinese word segmentation (CWS). Recently, many character-based neural models\nhave been applied to CWS. While they obtain good performance, they have two\nobvious weaknesses. The first is that they heavily rely on manually designed\nbigram feature, i.e. they are not good at capturing n-gram features\nautomatically. The second is that they make no use of full word information.\nFor the first weakness, we propose a convolutional neural model, which is able\nto capture rich n-gram features without any feature engineering. For the second\none, we propose an effective approach to integrate the proposed model with word\nembeddings. We evaluate the model on two benchmark datasets: PKU and MSR.\nWithout any feature engineering, the model obtains competitive performance --\n95.7% on PKU and 97.3% on MSR. Armed with word embeddings, the model achieves\nstate-of-the-art performance on both datasets -- 96.5% on PKU and 98.0% on MSR,\nwithout using any external labeled resource.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 03:47:52 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Wang", "Chunqi", ""], ["Xu", "Bo", ""]]}, {"id": "1711.04434", "submitter": "Ziqiang Cao", "authors": "Ziqiang Cao, Furu Wei, Wenjie Li, Sujian Li", "title": "Faithful to the Original: Fact Aware Neural Abstractive Summarization", "comments": "8 pages, 3 figures, AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unlike extractive summarization, abstractive summarization has to fuse\ndifferent parts of the source text, which inclines to create fake facts. Our\npreliminary study reveals nearly 30% of the outputs from a state-of-the-art\nneural summarization system suffer from this problem. While previous\nabstractive summarization approaches usually focus on the improvement of\ninformativeness, we argue that faithfulness is also a vital prerequisite for a\npractical abstractive summarization system. To avoid generating fake facts in a\nsummary, we leverage open information extraction and dependency parse\ntechnologies to extract actual fact descriptions from the source text. The\ndual-attention sequence-to-sequence framework is then proposed to force the\ngeneration conditioned on both the source text and the extracted fact\ndescriptions. Experiments on the Gigaword benchmark dataset demonstrate that\nour model can greatly reduce fake summaries by 80%. Notably, the fact\ndescriptions also bring significant improvement on informativeness since they\noften condense the meaning of the source text.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 06:34:29 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Cao", "Ziqiang", ""], ["Wei", "Furu", ""], ["Li", "Wenjie", ""], ["Li", "Sujian", ""]]}, {"id": "1711.04436", "submitter": "Xiaojun Xu", "authors": "Xiaojun Xu, Chang Liu, Dawn Song", "title": "SQLNet: Generating Structured Queries From Natural Language Without\n  Reinforcement Learning", "comments": "Submitting to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthesizing SQL queries from natural language is a long-standing open\nproblem and has been attracting considerable interest recently. Toward solving\nthe problem, the de facto approach is to employ a sequence-to-sequence-style\nmodel. Such an approach will necessarily require the SQL queries to be\nserialized. Since the same SQL query may have multiple equivalent\nserializations, training a sequence-to-sequence-style model is sensitive to the\nchoice from one of them. This phenomenon is documented as the \"order-matters\"\nproblem. Existing state-of-the-art approaches rely on reinforcement learning to\nreward the decoder when it generates any of the equivalent serializations.\nHowever, we observe that the improvement from reinforcement learning is\nlimited.\n  In this paper, we propose a novel approach, i.e., SQLNet, to fundamentally\nsolve this problem by avoiding the sequence-to-sequence structure when the\norder does not matter. In particular, we employ a sketch-based approach where\nthe sketch contains a dependency graph so that one prediction can be done by\ntaking into consideration only the previous predictions that it depends on. In\naddition, we propose a sequence-to-set model as well as the column attention\nmechanism to synthesize the query based on the sketch. By combining all these\nnovel techniques, we show that SQLNet can outperform the prior art by 9% to 13%\non the WikiSQL task.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 06:41:29 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Xu", "Xiaojun", ""], ["Liu", "Chang", ""], ["Song", "Dawn", ""]]}, {"id": "1711.04452", "submitter": "Georgina Nugent Folan", "authors": "Jennifer Edmond, Georgina Nugent Folan", "title": "Digitising Cultural Complexity: Representing Rich Cultural Data in a Big\n  Data environment", "comments": "Ways of Being in a Digital Age - A Review Conference, Oct 2017,\n  Liverpool, United Kingdom. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DB cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major terminological forces driving ICT integration in research\ntoday is that of \"big data.\" While the phrase sounds inclusive and integrative,\n\"big data\" approaches are highly selective, excluding input that cannot be\neffectively structured, represented, or digitised. Data of this complex sort is\nprecisely the kind that human activity produces, but the technological\nimperative to enhance signal through the reduction of noise does not\naccommodate this richness. Data and the computational approaches that\nfacilitate \"big data\" have acquired a perceived objectivity that belies their\ncurated, malleable, reactive, and performative nature. In an input environment\nwhere anything can \"be data\" once it is entered into the system as \"data,\" data\ncleaning and processing, together with the metadata and information\narchitectures that structure and facilitate our cultural archives acquire a\ncapacity to delimit what data are. This engenders a process of simplification\nthat has major implications for the potential for future innovation within\nresearch environments that depend on rich material yet are increasingly\nmediated by digital technologies. This paper presents the preliminary findings\nof the European-funded KPLEX (Knowledge Complexity) project which investigates\nthe delimiting effect digital mediation and datafication has on rich, complex\ncultural data. The paper presents a systematic review of existing implicit\ndefinitions of data, elaborating on the implications of these definitions and\nhighlighting the ways in which metadata and computational technologies can\nrestrict the interpretative potential of data. It sheds light on the gap\nbetween analogue or augmented digital practices and fully computational ones,\nand the strategies researchers have developed to deal with this gap. The paper\nproposes a reconceptualisation of data as it is functionally employed within\ndigitally-mediated research so as to incorporate and acknowledge the richness\nand complexity of our source materials.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 07:31:24 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Edmond", "Jennifer", ""], ["Folan", "Georgina Nugent", ""]]}, {"id": "1711.04457", "submitter": "Yining Wang", "authors": "Yining Wang, Long Zhou, Jiajun Zhang, Chengqing Zong", "title": "Word, Subword or Character? An Empirical Study of Granularity in\n  Chinese-English NMT", "comments": "15 pages,3 figures,CWMT2017. arXiv admin note: text overlap with\n  arXiv:1609.08144 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT), a new approach to machine translation, has\nbeen proved to outperform conventional statistical machine translation (SMT)\nacross a variety of language pairs. Translation is an open-vocabulary problem,\nbut most existing NMT systems operate with a fixed vocabulary, which causes the\nincapability of translating rare words. This problem can be alleviated by using\ndifferent translation granularities, such as character, subword and hybrid\nword-character. Translation involving Chinese is one of the most difficult\ntasks in machine translation, however, to the best of our knowledge, there has\nnot been any other work exploring which translation granularity is most\nsuitable for Chinese in NMT. In this paper, we conduct an extensive comparison\nusing Chinese-English NMT as a case study. Furthermore, we discuss the\nadvantages and disadvantages of various translation granularities in detail.\nOur experiments show that subword model performs best for Chinese-to-English\ntranslation with the vocabulary which is not so big while hybrid word-character\nmodel is most suitable for English-to-Chinese translation. Moreover,\nexperiments of different granularities show that Hybrid_BPE method can achieve\nbest result on Chinese-to-English translation task.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 07:42:56 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Wang", "Yining", ""], ["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1711.04498", "submitter": "Yong Zhang", "authors": "Yong Zhang, Hongming Zhou, Nganmeng Tan, Saeed Bagheri, Meng Joo Er", "title": "Targeted Advertising Based on Browsing History", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Audience interest, demography, purchase behavior and other possible\nclassifications are ex- tremely important factors to be carefully studied in a\ntargeting campaign. This information can help advertisers and publishers\ndeliver advertisements to the right audience group. How- ever, it is not easy\nto collect such information, especially for the online audience with whom we\nhave limited interaction and minimum deterministic knowledge. In this paper, we\npro- pose a predictive framework that can estimate online audience demographic\nattributes based on their browsing histories. Under the proposed framework,\nfirst, we retrieve the content of the websites visited by audience, and\nrepresent the content as website feature vectors; second, we aggregate the\nvectors of websites that audience have visited and arrive at feature vectors\nrepresenting the users; finally, the support vector machine is exploited to\npredict the audience demographic attributes. The key to achieving good\nprediction performance is preparing representative features of the audience.\nWord Embedding, a widely used tech- nique in natural language processing tasks,\ntogether with term frequency-inverse document frequency weighting scheme is\nused in the proposed method. This new representation ap- proach is unsupervised\nand very easy to implement. The experimental results demonstrate that the new\naudience feature representation method is more powerful than existing baseline\nmethods, leading to a great improvement in prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 10:06:22 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Zhang", "Yong", ""], ["Zhou", "Hongming", ""], ["Tan", "Nganmeng", ""], ["Bagheri", "Saeed", ""], ["Er", "Meng Joo", ""]]}, {"id": "1711.04564", "submitter": "Markus M\\\"uller", "authors": "Markus M\\\"uller, Sebastian St\\\"uker, Alex Waibel", "title": "Phonemic and Graphemic Multilingual CTC Based Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training automatic speech recognition (ASR) systems requires large amounts of\ndata in the target language in order to achieve good performance. Whereas large\ntraining corpora are readily available for languages like English, there exists\na long tail of languages which do suffer from a lack of resources. One method\nto handle data sparsity is to use data from additional source languages and\nbuild a multilingual system. Recently, ASR systems based on recurrent neural\nnetworks (RNNs) trained with connectionist temporal classification (CTC) have\ngained substantial research interest. In this work, we extended our previous\napproach towards training CTC-based systems multilingually. Our systems feature\na global phone set, based on the joint phone sets of each source language. We\nevaluated the use of different language combinations as well as the addition of\nLanguage Feature Vectors (LFVs). As contrastive experiment, we built systems\nbased on graphemes as well. Systems having a multilingual phone set are known\nto suffer in performance compared to their monolingual counterparts. With our\nproposed approach, we could reduce the gap between these mono- and multilingual\nsetups, using either graphemes or phonemes.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 13:13:40 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["M\u00fcller", "Markus", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1711.04569", "submitter": "Markus M\\\"uller", "authors": "Markus M\\\"uller, Sebastian St\\\"uker, Alex Waibel", "title": "Multilingual Adaptation of RNN Based ASR Systems", "comments": "5 pages, 1 figure, to appear in 2018 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on multilingual systems based on recurrent neural\nnetworks (RNNs), trained using the Connectionist Temporal Classification (CTC)\nloss function. Using a multilingual set of acoustic units poses difficulties.\nTo address this issue, we proposed Language Feature Vectors (LFVs) to train\nlanguage adaptive multilingual systems. Language adaptation, in contrast to\nspeaker adaptation, needs to be applied not only on the feature level, but also\nto deeper layers of the network. In this work, we therefore extended our\nprevious approach by introducing a novel technique which we call \"modulation\".\nBased on this method, we modulated the hidden layers of RNNs using LFVs. We\nevaluated this approach in both full and low resource conditions, as well as\nfor grapheme and phone based systems. Lower error rates throughout the\ndifferent conditions could be achieved by the use of the modulation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 13:22:54 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 13:44:46 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["M\u00fcller", "Markus", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1711.04731", "submitter": "Keith Carlson", "authors": "Keith Carlson, Allen Riddell, Daniel Rockmore", "title": "Evaluating prose style transfer with the Bible", "comments": null, "journal-ref": "Carlson, Keith, Allen Riddell, and Daniel Rockmore. \"Evaluating\n  prose style transfer with the Bible.\" Royal Society open science 5.10 (2018):\n  171920", "doi": "10.1098/rsos.171920", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the prose style transfer task a system, provided with text input and a\ntarget prose style, produces output which preserves the meaning of the input\ntext but alters the style. These systems require parallel data for evaluation\nof results and usually make use of parallel data for training. Currently, there\nare few publicly available corpora for this task. In this work, we identify a\nhigh-quality source of aligned, stylistically distinct text in different\nversions of the Bible. We provide a standardized split, into training,\ndevelopment and testing data, of the public domain versions in our corpus. This\ncorpus is highly parallel since many Bible versions are included. Sentences are\naligned due to the presence of chapter and verse numbers within all versions of\nthe text. In addition to the corpus, we present the results, as measured by the\nBLEU and PINC metrics, of several models trained on our data which can serve as\nbaselines for future research. While we present these data as a style transfer\ncorpus, we believe that it is of unmatched quality and may be useful for other\nnatural language tasks as well.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 17:59:26 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 18:43:56 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Carlson", "Keith", ""], ["Riddell", "Allen", ""], ["Rockmore", "Daniel", ""]]}, {"id": "1711.04805", "submitter": "David Grangier", "authors": "David Grangier, Michael Auli", "title": "QuickEdit: Editing Text & Translations by Crossing Words Out", "comments": "NAACL'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for computer-assisted text editing. It applies to\ntranslation post-editing and to paraphrasing. Our proposal relies on very\nsimple interactions: a human editor modifies a sentence by marking tokens they\nwould like the system to change. Our model then generates a new sentence which\nreformulates the initial sentence by avoiding marked words. The approach builds\nupon neural sequence-to-sequence modeling and introduces a neural network which\ntakes as input a sentence along with change markers. Our model is trained on\ntranslation bitext by simulating post-edits. We demonstrate the advantage of\nour approach for translation post-editing through simulated post-edits. We also\nevaluate our model for paraphrasing through a user study.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 19:23:47 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 21:57:37 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Grangier", "David", ""], ["Auli", "Michael", ""]]}, {"id": "1711.04903", "submitter": "Michihiro Yasunaga", "authors": "Michihiro Yasunaga, Jungo Kasai, Dragomir Radev", "title": "Robust Multilingual Part-of-Speech Tagging via Adversarial Training", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is a powerful regularization method for neural\nnetworks, aiming to achieve robustness to input perturbations. Yet, the\nspecific effects of the robustness obtained from AT are still unclear in the\ncontext of natural language processing. In this paper, we propose and analyze a\nneural POS tagging model that exploits AT. In our experiments on the Penn\nTreebank WSJ corpus and the Universal Dependencies (UD) dataset (27 languages),\nwe find that AT not only improves the overall tagging accuracy, but also 1)\nprevents over-fitting well in low resource languages and 2) boosts tagging\naccuracy for rare / unseen words. We also demonstrate that 3) the improved\ntagging performance by AT contributes to the downstream task of dependency\nparsing, and that 4) AT helps the model to learn cleaner word representations.\n5) The proposed AT model is generally effective in different sequence labeling\ntasks. These positive results motivate further use of AT for natural language\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 01:50:30 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 15:49:22 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Yasunaga", "Michihiro", ""], ["Kasai", "Jungo", ""], ["Radev", "Dragomir", ""]]}, {"id": "1711.04951", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Thanh Vu, Dai Quoc Nguyen, Mark Dras, Mark Johnson", "title": "From Word Segmentation to POS Tagging for Vietnamese", "comments": "To appear in Proceedings of the 15th Annual Workshop of the\n  Australasian Language Technology Association, ALTA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical comparison of two strategies for Vietnamese\nPart-of-Speech (POS) tagging from unsegmented text: (i) a pipeline strategy\nwhere we consider the output of a word segmenter as the input of a POS tagger,\nand (ii) a joint strategy where we predict a combined segmentation and POS tag\nfor each syllable. We also make a comparison between state-of-the-art (SOTA)\nfeature-based and neural network-based models. On the benchmark Vietnamese\ntreebank (Nguyen et al., 2009), experimental results show that the pipeline\nstrategy produces better scores of POS tagging from unsegmented text than the\njoint strategy, and the highest accuracy is obtained by using a feature-based\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 05:19:45 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Dai Quoc", ""], ["Dras", "Mark", ""], ["Johnson", "Mark", ""]]}, {"id": "1711.04956", "submitter": "Michael Auli", "authors": "Sergey Edunov, Myle Ott, Michael Auli, David Grangier, Marc'Aurelio\n  Ranzato", "title": "Classical Structured Prediction Losses for Sequence to Sequence Learning", "comments": "10 pages, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent work on training neural attention models at the\nsequence-level using either reinforcement learning-style methods or by\noptimizing the beam. In this paper, we survey a range of classical objective\nfunctions that have been widely used to train linear models for structured\nprediction and apply them to neural sequence to sequence models. Our\nexperiments show that these losses can perform surprisingly well by slightly\noutperforming beam search optimization in a like for like setup. We also report\nnew state of the art results on both IWSLT'14 German-English translation as\nwell as Gigaword abstractive summarization. On the larger WMT'14 English-French\ntranslation task, sequence-level training achieves 41.5 BLEU which is on par\nwith the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 05:47:08 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:43:21 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 15:56:41 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 13:53:56 GMT"}, {"version": "v5", "created": "Fri, 5 Oct 2018 21:28:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Edunov", "Sergey", ""], ["Ott", "Myle", ""], ["Auli", "Michael", ""], ["Grangier", "David", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1711.04964", "submitter": "Yichong Xu", "authors": "Yichong Xu, Jingjing Liu, Jianfeng Gao, Yelong Shen and Xiaodong Liu", "title": "Dynamic Fusion Networks for Machine Reading Comprehension", "comments": "13 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel neural model - Dynamic Fusion Network (DFN), for\nmachine reading comprehension (MRC). DFNs differ from most state-of-the-art\nmodels in their use of a dynamic multi-strategy attention process, in which\npassages, questions and answer candidates are jointly fused into attention\nvectors, along with a dynamic multi-step reasoning module for generating\nanswers. With the use of reinforcement learning, for each input sample that\nconsists of a question, a passage and a list of candidate answers, an instance\nof DFN with a sample-specific network architecture can be dynamically\nconstructed by determining what attention strategy to apply and how many\nreasoning steps to take. Experiments show that DFNs achieve the best result\nreported on RACE, a challenging MRC dataset that contains real human reading\nquestions in a wide variety of types. A detailed empirical analysis also\ndemonstrates that DFNs can produce attention vectors that summarize information\nfrom questions, passages and answer candidates more effectively than other\npopular MRC models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 06:17:54 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 19:33:05 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Xu", "Yichong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Shen", "Yelong", ""], ["Liu", "Xiaodong", ""]]}, {"id": "1711.04981", "submitter": "Yi Tay", "authors": "Yi Tay, Minh C. Phan, Luu Anh Tuan, Siu Cheung Hui", "title": "SkipFlow: Incorporating Neural Coherence Features for End-to-End\n  Automatic Text Scoring", "comments": "Accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has demonstrated tremendous potential for Automatic Text\nScoring (ATS) tasks. In this paper, we describe a new neural architecture that\nenhances vanilla neural network models with auxiliary neural coherence\nfeatures. Our new method proposes a new \\textsc{SkipFlow} mechanism that models\nrelationships between snapshots of the hidden representations of a long\nshort-term memory (LSTM) network as it reads. Subsequently, the semantic\nrelationships between multiple snapshots are used as auxiliary features for\nprediction. This has two main benefits. Firstly, essays are typically long\nsequences and therefore the memorization capability of the LSTM network may be\ninsufficient. Implicit access to multiple snapshots can alleviate this problem\nby acting as a protection against vanishing gradients. The parameters of the\n\\textsc{SkipFlow} mechanism also acts as an auxiliary memory. Secondly,\nmodeling relationships between multiple positions allows our model to learn\nfeatures that represent and approximate textual coherence. In our model, we\ncall this \\textit{neural coherence} features. Overall, we present a unified\ndeep learning architecture that generates neural coherence features as it reads\nin an end-to-end fashion. Our approach demonstrates state-of-the-art\nperformance on the benchmark ASAP dataset, outperforming not only feature\nengineering baselines but also other deep learning models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 07:20:23 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Tay", "Yi", ""], ["Phan", "Minh C.", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1711.04987", "submitter": "Daniel Fried", "authors": "Daniel Fried, Jacob Andreas, Dan Klein", "title": "Unified Pragmatic Models for Generating and Following Instructions", "comments": "NAACL 2018, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that explicit pragmatic inference aids in correctly generating and\nfollowing natural language instructions for complex, sequential tasks. Our\npragmatics-enabled models reason about why speakers produce certain\ninstructions, and about how listeners will react upon hearing them. Like\nprevious pragmatic models, we use learned base listener and speaker models to\nbuild a pragmatic speaker that uses the base listener to simulate the\ninterpretation of candidate descriptions, and a pragmatic listener that reasons\ncounterfactually about alternative descriptions. We extend these models to\ntasks with sequential structure. Evaluation of language generation and\ninterpretation shows that pragmatic inference improves state-of-the-art\nlistener models (at correctly interpreting human instructions) and speaker\nmodels (at producing instructions correctly interpreted by humans) in diverse\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 07:55:39 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 18:42:31 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 19:35:39 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Fried", "Daniel", ""], ["Andreas", "Jacob", ""], ["Klein", "Dan", ""]]}, {"id": "1711.05066", "submitter": "Jianpeng Cheng J", "authors": "Jianpeng Cheng and Siva Reddy and Vijay Saraswat and Mirella Lapata", "title": "Learning an Executable Neural Semantic Parser", "comments": "In Journal of Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes a neural semantic parser that maps natural language\nutterances onto logical forms which can be executed against a task-specific\nenvironment, such as a knowledge base or a database, to produce a response. The\nparser generates tree-structured logical forms with a transition-based approach\nwhich combines a generic tree-generation algorithm with domain-general\noperations defined by the logical language. The generation process is modeled\nby structured recurrent neural networks, which provide a rich encoding of the\nsentential context and generation history for making predictions. To tackle\nmismatches between natural language and logical form tokens, various attention\nmechanisms are explored. Finally, we consider different training settings for\nthe neural semantic parser, including a fully supervised training where\nannotated logical forms are given, weakly-supervised training where denotations\nare provided, and distant supervision where only unlabeled sentences and a\nknowledge base are available. Experiments across a wide range of datasets\ndemonstrate the effectiveness of our parser.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 12:00:36 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2018 12:02:45 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Cheng", "Jianpeng", ""], ["Reddy", "Siva", ""], ["Saraswat", "Vijay", ""], ["Lapata", "Mirella", ""]]}, {"id": "1711.05073", "submitter": "Wei He", "authors": "Wei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan\n  Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, Haifeng Wang", "title": "DuReader: a Chinese Machine Reading Comprehension Dataset from\n  Real-world Applications", "comments": "10 pages, ACL 2018 MRQA Workshop camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces DuReader, a new large-scale, open-domain Chinese ma-\nchine reading comprehension (MRC) dataset, designed to address real-world MRC.\nDuReader has three advantages over previous MRC datasets: (1) data sources:\nquestions and documents are based on Baidu Search and Baidu Zhidao; answers are\nmanually generated. (2) question types: it provides rich annotations for more\nquestion types, especially yes-no and opinion questions, that leaves more\nopportunity for the research community. (3) scale: it contains 200K questions,\n420K answers and 1M documents; it is the largest Chinese MRC dataset so far.\nExperiments show that human performance is well above current state-of-the-art\nbaseline systems, leaving plenty of room for the community to make\nimprovements. To help the community make these improvements, both DuReader and\nbaseline systems have been posted online. We also organize a shared competition\nto encourage the exploration of more models. Since the release of the task,\nthere are significant improvements over the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 12:13:44 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 11:45:41 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 12:07:19 GMT"}, {"version": "v4", "created": "Mon, 11 Jun 2018 03:26:30 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["He", "Wei", ""], ["Liu", "Kai", ""], ["Liu", "Jing", ""], ["Lyu", "Yajuan", ""], ["Zhao", "Shiqi", ""], ["Xiao", "Xinyan", ""], ["Liu", "Yuan", ""], ["Wang", "Yizhong", ""], ["Wu", "Hua", ""], ["She", "Qiaoqiao", ""], ["Liu", "Xuan", ""], ["Wu", "Tian", ""], ["Wang", "Haifeng", ""]]}, {"id": "1711.05116", "submitter": "Shuohang Wang", "authors": "Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu\n  Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, Murray Campbell", "title": "Evidence Aggregation for Answer Re-Ranking in Open-Domain Question\n  Answering", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular recent approach to answering open-domain questions is to first\nsearch for question-related passages and then apply reading comprehension\nmodels to extract answers. Existing methods usually extract answers from single\npassages independently. But some questions require a combination of evidence\nfrom across different sources to answer correctly. In this paper, we propose\ntwo models which make use of multiple passages to generate their answers. Both\nuse an answer-reranking approach which reorders the answer candidates generated\nby an existing state-of-the-art QA model. We propose two methods, namely,\nstrength-based re-ranking and coverage-based re-ranking, to make use of the\naggregated evidence from different passages to better determine the answer. Our\nmodels have achieved state-of-the-art results on three public open-domain QA\ndatasets: Quasar-T, SearchQA and the open-domain version of TriviaQA, with\nabout 8 percentage points of improvement over the former two datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 14:39:51 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 15:50:25 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Wang", "Shuohang", ""], ["Yu", "Mo", ""], ["Jiang", "Jing", ""], ["Zhang", "Wei", ""], ["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Wang", "Zhiguo", ""], ["Klinger", "Tim", ""], ["Tesauro", "Gerald", ""], ["Campbell", "Murray", ""]]}, {"id": "1711.05170", "submitter": "Diego Molla-Aliod", "authors": "Hamideh Hajiabadi, Diego Molla-Aliod, Reza Monsefi", "title": "On Extending Neural Networks with Loss Ensembles for Text Classification", "comments": "5 pages, 5 tables, 1 figure. Camera-ready submitted to The 2017\n  Australasian Language Technology Association Workshop (ALTA 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble techniques are powerful approaches that combine several weak\nlearners to build a stronger one. As a meta learning framework, ensemble\ntechniques can easily be applied to many machine learning techniques. In this\npaper we propose a neural network extended with an ensemble loss function for\ntext classification. The weight of each weak loss function is tuned within the\ntraining phase through the gradient propagation optimization method of the\nneural network. The approach is evaluated on several text classification\ndatasets. We also evaluate its performance in various environments with several\ndegrees of label noise. Experimental results indicate an improvement of the\nresults and strong resilience against label noise in comparison with other\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 16:19:34 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hajiabadi", "Hamideh", ""], ["Molla-Aliod", "Diego", ""], ["Monsefi", "Reza", ""]]}, {"id": "1711.05186", "submitter": "Anca Dumitrache", "authors": "Anca Dumitrache, Lora Aroyo, Chris Welty", "title": "False Positive and Cross-relation Signals in Distant Supervision Data", "comments": "in proceedings of the 6th Workshop on Automated Knowledge Base\n  Construction (AKBC) at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Distant supervision (DS) is a well-established method for relation extraction\nfrom text, based on the assumption that when a knowledge-base contains a\nrelation between a term pair, then sentences that contain that pair are likely\nto express the relation. In this paper, we use the results of a crowdsourcing\nrelation extraction task to identify two problems with DS data quality: the\nwidely varying degree of false positives across different relations, and the\nobserved causal connection between relations that are not considered by the DS\nmethod. The crowdsourcing data aggregation is performed using ambiguity-aware\nCrowdTruth metrics, that are used to capture and interpret inter-annotator\ndisagreement. We also present preliminary results of using the crowd to enhance\nDS training data for a relation classification model, without requiring the\ncrowd to annotate the entire set.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 16:50:40 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 19:52:06 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Dumitrache", "Anca", ""], ["Aroyo", "Lora", ""], ["Welty", "Chris", ""]]}, {"id": "1711.05198", "submitter": "Madhumita Sushil", "authors": "Madhumita Sushil, Simon \\v{S}uster, Kim Luyckx, Walter Daelemans", "title": "Unsupervised patient representations from clinical notes with\n  interpretable classification decisions", "comments": "Accepted poster at NIPS 2017 Workshop on Machine Learning for Health\n  (https://ml4health.github.io/2017/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have two main contributions in this work: 1. We explore the usage of a\nstacked denoising autoencoder, and a paragraph vector model to learn\ntask-independent dense patient representations directly from clinical notes. We\nevaluate these representations by using them as features in multiple supervised\nsetups, and compare their performance with those of sparse representations. 2.\nTo understand and interpret the representations, we explore the best encoded\nfeatures within the patient representations obtained from the autoencoder\nmodel. Further, we calculate the significance of the input features of the\ntrained classifiers when we use these pretrained representations as input.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 17:05:51 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Sushil", "Madhumita", ""], ["\u0160uster", "Simon", ""], ["Luyckx", "Kim", ""], ["Daelemans", "Walter", ""]]}, {"id": "1711.05217", "submitter": "David Grangier", "authors": "Angela Fan, David Grangier, Michael Auli", "title": "Controllable Abstractive Summarization", "comments": "ACL2018 Workshop on Neural Machine Translation and Generation\n  (NMT@ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current models for document summarization disregard user preferences such as\nthe desired length, style, the entities that the user might be interested in,\nor how much of the document the user has already read. We present a neural\nsummarization model with a simple but effective mechanism to enable users to\nspecify these high level attributes in order to control the shape of the final\nsummaries to better suit their needs. With user input, our system can produce\nhigh quality summaries that follow user preferences. Without user input, we set\nthe control variables automatically. On the full text CNN-Dailymail dataset, we\noutperform state of the art abstractive systems (both in terms of F1-ROUGE1\n40.38 vs. 39.53 and human evaluation).\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 17:30:26 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 18:56:24 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Fan", "Angela", ""], ["Grangier", "David", ""], ["Auli", "Michael", ""]]}, {"id": "1711.05240", "submitter": "Omer Goldman", "authors": "Omer Goldman and Veronica Latcinnik and Udi Naveh and Amir Globerson\n  and Jonathan Berant", "title": "Weakly-supervised Semantic Parsing with Abstract Examples", "comments": "CNLVR,NLVR. Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training semantic parsers from weak supervision (denotations) rather than\nstrong supervision (programs) complicates training in two ways. First, a large\nsearch space of potential programs needs to be explored at training time to\nfind a correct program. Second, spurious programs that accidentally lead to a\ncorrect denotation add noise to training. In this work we propose that in\nclosed worlds with clear semantic types, one can substantially alleviate these\nproblems by utilizing an abstract representation, where tokens in both the\nlanguage utterance and program are lifted to an abstract form. We show that\nthese abstractions can be defined with a handful of lexical rules and that they\nresult in sharing between different examples that alleviates the difficulties\nin training. To test our approach, we develop the first semantic parser for\nCNLVR, a challenging visual reasoning dataset, where the search space is large\nand overcoming spuriousness is critical, because denotations are either TRUE or\nFALSE, and thus random programs are likely to lead to a correct denotation. Our\nmethod substantially improves performance, and reaches 82.5% accuracy, a 14.7%\nabsolute accuracy improvement compared to the best reported accuracy so far.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 18:29:05 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 12:12:06 GMT"}, {"version": "v3", "created": "Sat, 12 May 2018 20:12:13 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 14:22:57 GMT"}, {"version": "v5", "created": "Wed, 13 Mar 2019 09:30:38 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Goldman", "Omer", ""], ["Latcinnik", "Veronica", ""], ["Naveh", "Udi", ""], ["Globerson", "Amir", ""], ["Berant", "Jonathan", ""]]}, {"id": "1711.05294", "submitter": "Shoaib Jameel", "authors": "Shoaib Jameel, Zied Bouraoui, Steven Schockaert", "title": "Modeling Semantic Relatedness using Global Relation Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models such as GloVe rely on co-occurrence statistics from a\nlarge corpus to learn vector representations of word meaning. These vectors\nhave proven to capture surprisingly fine-grained semantic and syntactic\ninformation. While we may similarly expect that co-occurrence statistics can be\nused to capture rich information about the relationships between different\nwords, existing approaches for modeling such relationships have mostly relied\non manipulating pre-trained word vectors. In this paper, we introduce a novel\nmethod which directly learns relation vectors from co-occurrence statistics. To\nthis end, we first introduce a variant of GloVe, in which there is an explicit\nconnection between word vectors and PMI weighted co-occurrence vectors. We then\nshow how relation vectors can be naturally embedded into the resulting vector\nspace.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 19:42:55 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Jameel", "Shoaib", ""], ["Bouraoui", "Zied", ""], ["Schockaert", "Steven", ""]]}, {"id": "1711.05313", "submitter": "Antoine Bosselut", "authors": "Antoine Bosselut, Omer Levy, Ari Holtzman, Corin Ennis, Dieter Fox,\n  Yejin Choi", "title": "Simulating Action Dynamics with Neural Process Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding procedural language requires anticipating the causal effects of\nactions, even when they are not explicitly stated. In this work, we introduce\nNeural Process Networks to understand procedural text through (neural)\nsimulation of action dynamics. Our model complements existing memory\narchitectures with dynamic entity tracking by explicitly modeling actions as\nstate transformers. The model updates the states of the entities by executing\nlearned action operators. Empirical results demonstrate that our proposed model\ncan reason about the unstated causal effects of actions, allowing it to provide\nmore accurate contextual information for understanding and generating\nprocedural text, all while offering more interpretable internal representations\nthan existing alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 21:07:38 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 18:22:50 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Bosselut", "Antoine", ""], ["Levy", "Omer", ""], ["Holtzman", "Ari", ""], ["Ennis", "Corin", ""], ["Fox", "Dieter", ""], ["Choi", "Yejin", ""]]}, {"id": "1711.05345", "submitter": "Yu-An Chung", "authors": "Yu-An Chung and Hung-Yi Lee and James Glass", "title": "Supervised and Unsupervised Transfer Learning for Question Answering", "comments": "To appear in NAACL HLT 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although transfer learning has been shown to be successful for tasks like\nobject and speech recognition, its applicability to question answering (QA) has\nyet to be well-studied. In this paper, we conduct extensive experiments to\ninvestigate the transferability of knowledge learned from a source QA dataset\nto a target dataset using two QA models. The performance of both models on a\nTOEFL listening comprehension test (Tseng et al., 2016) and MCTest (Richardson\net al., 2013) is significantly improved via a simple transfer learning\ntechnique from MovieQA (Tapaswi et al., 2016). In particular, one of the models\nachieves the state-of-the-art on all target datasets; for the TOEFL listening\ncomprehension test, it outperforms the previous best model by 7%. Finally, we\nshow that transfer learning is helpful even in unsupervised scenarios when\ncorrect answers for target QA dataset examples are not available.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 22:57:24 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 19:58:45 GMT"}, {"version": "v3", "created": "Sat, 21 Apr 2018 19:20:20 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Chung", "Yu-An", ""], ["Lee", "Hung-Yi", ""], ["Glass", "James", ""]]}, {"id": "1711.05350", "submitter": "Chen Zheng", "authors": "Chen Zheng, Shuangfei Zhai, Zhongfei Zhang", "title": "A Deep Learning Approach for Expert Identification in Question Answering\n  Communities", "comments": "7 pages. arXiv admin note: text overlap with arXiv:1403.6652 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an effective convolutional neural network\nframework for identifying the expert in question answering community. This\napproach uses the convolutional neural network and combines user feature\nrepresentations with question feature representations to compute scores that\nthe user who gets the highest score is the expert on this question. Unlike\nprior work, this method does not measure expert based on measure answer content\nquality to identify the expert but only require question sentence and user\nembedding feature to identify the expert. Remarkably, Our model can be applied\nto different languages and different domains. The proposed framework is trained\non two datasets, The first dataset is Stack Overflow and the second one is\nZhihu. The Top-1 accuracy results of our experiments show that our framework\noutperforms the best baseline framework for expert identification.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 23:10:59 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Zheng", "Chen", ""], ["Zhai", "Shuangfei", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1711.05380", "submitter": "Shaohui Kuang", "authors": "Shaohui Kuang, Junhui Li, Ant\\'onio Branco, Weihua Luo, Deyi Xiong", "title": "Attention Focusing for Neural Machine Translation by Bridging Source and\n  Target Embeddings", "comments": "9 pages, 6 figures. Accepted by ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural machine translation, a source sequence of words is encoded into a\nvector from which a target sequence is generated in the decoding phase.\nDifferently from statistical machine translation, the associations between\nsource words and their possible target counterparts are not explicitly stored.\nSource and target words are at the two ends of a long information processing\nprocedure, mediated by hidden states at both the source encoding and the target\ndecoding phases. This makes it possible that a source word is incorrectly\ntranslated into a target word that is not any of its admissible equivalent\ncounterparts in the target language.\n  In this paper, we seek to somewhat shorten the distance between source and\ntarget words in that procedure, and thus strengthen their association, by means\nof a method we term bridging source and target word embeddings. We experiment\nwith three strategies: (1) a source-side bridging model, where source word\nembeddings are moved one step closer to the output target sequence; (2) a\ntarget-side bridging model, which explores the more relevant source word\nembeddings for the prediction of the target sequence; and (3) a direct bridging\nmodel, which directly connects source and target word embeddings seeking to\nminimize errors in the translation of ones by the others.\n  Experiments and analysis presented in this paper demonstrate that the\nproposed bridging models are able to significantly improve quality of both\nsentence translation, in general, and alignment and translation of individual\nsource words with target words, in particular.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 02:12:34 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 05:09:47 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 13:09:02 GMT"}, {"version": "v4", "created": "Thu, 10 May 2018 05:13:59 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Kuang", "Shaohui", ""], ["Li", "Junhui", ""], ["Branco", "Ant\u00f3nio", ""], ["Luo", "Weihua", ""], ["Xiong", "Deyi", ""]]}, {"id": "1711.05408", "submitter": "Yining Chen", "authors": "Yining Chen, Sorcha Gilroy, Andreas Maletti, Jonathan May, Kevin\n  Knight", "title": "Recurrent Neural Networks as Weighted Language Recognizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the computational complexity of various problems for simple\nrecurrent neural networks (RNNs) as formal models for recognizing weighted\nlanguages. We focus on the single-layer, ReLU-activation, rational-weight RNNs\nwith softmax, which are commonly used in natural language processing\napplications. We show that most problems for such RNNs are undecidable,\nincluding consistency, equivalence, minimization, and the determination of the\nhighest-weighted string. However, for consistent RNNs the last problem becomes\ndecidable, although the solution length can surpass all computable bounds. If\nadditionally the string is limited to polynomial length, the problem becomes\nNP-complete and APX-hard. In summary, this shows that approximations and\nheuristic algorithms are necessary in practical applications of those RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 04:54:08 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2018 18:27:59 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Chen", "Yining", ""], ["Gilroy", "Sorcha", ""], ["Maletti", "Andreas", ""], ["May", "Jonathan", ""], ["Knight", "Kevin", ""]]}, {"id": "1711.05433", "submitter": "Yu-Ping Ruan", "authors": "Yu-Ping Ruan, Qian Chen, and Zhen-Hua Ling", "title": "A Sequential Neural Encoder with Latent Structured Description for\n  Modeling Sentences", "comments": "Accepted by IEEE Transactions on Audio, Speech, and Language\n  Processing", "journal-ref": null, "doi": "10.1109/TASLP.2017.2773198", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a sequential neural encoder with latent structured\ndescription (SNELSD) for modeling sentences. This model introduces latent\nchunk-level representations into conventional sequential neural encoders, i.e.,\nrecurrent neural networks (RNNs) with long short-term memory (LSTM) units, to\nconsider the compositionality of languages in semantic modeling. An SNELSD\nmodel has a hierarchical structure that includes a detection layer and a\ndescription layer. The detection layer predicts the boundaries of latent word\nchunks in an input sentence and derives a chunk-level vector for each word. The\ndescription layer utilizes modified LSTM units to process these chunk-level\nvectors in a recurrent manner and produces sequential encoding outputs. These\noutput vectors are further concatenated with word vectors or the outputs of a\nchain LSTM encoder to obtain the final sentence representation. All the model\nparameters are learned in an end-to-end manner without a dependency on\nadditional text chunking or syntax parsing. A natural language inference (NLI)\ntask and a sentiment analysis (SA) task are adopted to evaluate the performance\nof our proposed model. The experimental results demonstrate the effectiveness\nof the proposed SNELSD model on exploring task-dependent chunking patterns\nduring the semantic modeling of sentences. Furthermore, the proposed method\nachieves better performance than conventional chain LSTMs and tree-structured\nLSTMs on both tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 07:13:13 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Ruan", "Yu-Ping", ""], ["Chen", "Qian", ""], ["Ling", "Zhen-Hua", ""]]}, {"id": "1711.05443", "submitter": "Zhiyuan Tang", "authors": "Miao Zhang, Xiaofei Kang, Yanqing Wang, Lantian Li, Zhiyuan Tang,\n  Haisheng Dai, Dong Wang", "title": "Human and Machine Speaker Recognition Based on Short Trivial Events", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trivial events are ubiquitous in human to human conversations, e.g., cough,\nlaugh and sniff. Compared to regular speech, these trivial events are usually\nshort and unclear, thus generally regarded as not speaker discriminative and so\nare largely ignored by present speaker recognition research. However, these\ntrivial events are highly valuable in some particular circumstances such as\nforensic examination, as they are less subjected to intentional change, so can\nbe used to discover the genuine speaker from disguised speech. In this paper,\nwe collect a trivial event speech database that involves 75 speakers and 6\ntypes of events, and report preliminary speaker recognition results on this\ndatabase, by both human listeners and machines. Particularly, the deep feature\nlearning technique recently proposed by our group is utilized to analyze and\nrecognize the trivial events, which leads to acceptable equal error rates\n(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.\nComparing different types of events, 'hmm' seems more speaker discriminative.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 08:21:20 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 10:27:00 GMT"}, {"version": "v3", "created": "Tue, 6 Feb 2018 04:13:27 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Zhang", "Miao", ""], ["Kang", "Xiaofei", ""], ["Wang", "Yanqing", ""], ["Li", "Lantian", ""], ["Tang", "Zhiyuan", ""], ["Dai", "Haisheng", ""], ["Wang", "Dong", ""]]}, {"id": "1711.05447", "submitter": "Younggun Lee", "authors": "Younggun Lee, Azam Rabiee, Soo-Young Lee", "title": "Emotional End-to-End Neural Speech Synthesizer", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an emotional speech synthesizer based on the\nrecent end-to-end neural model, named Tacotron. Despite its benefits, we found\nthat the original Tacotron suffers from the exposure bias problem and\nirregularity of the attention alignment. Later, we address the problem by\nutilization of context vector and residual connection at recurrent neural\nnetworks (RNNs). Our experiments showed that the model could successfully train\nand generate speech for given emotion labels.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 08:27:35 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 02:07:43 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Lee", "Younggun", ""], ["Rabiee", "Azam", ""], ["Lee", "Soo-Young", ""]]}, {"id": "1711.05448", "submitter": "Shankar Kumar", "authors": "Shankar Kumar, Michael Nirschl, Daniel Holtmann-Rice, Hank Liao,\n  Ananda Theertha Suresh, Felix Yu", "title": "Lattice Rescoring Strategies for Long Short Term Memory Language Models\n  in Speech Recognition", "comments": "Accepted at ASRU 2017", "journal-ref": "Proceedings of ASRU 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network (RNN) language models (LMs) and Long Short Term\nMemory (LSTM) LMs, a variant of RNN LMs, have been shown to outperform\ntraditional N-gram LMs on speech recognition tasks. However, these models are\ncomputationally more expensive than N-gram LMs for decoding, and thus,\nchallenging to integrate into speech recognizers. Recent research has proposed\nthe use of lattice-rescoring algorithms using RNNLMs and LSTMLMs as an\nefficient strategy to integrate these models into a speech recognition system.\nIn this paper, we evaluate existing lattice rescoring algorithms along with new\nvariants on a YouTube speech recognition task. Lattice rescoring using LSTMLMs\nreduces the word error rate (WER) for this task by 8\\% relative to the WER\nobtained using an N-gram LM.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 08:30:56 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Kumar", "Shankar", ""], ["Nirschl", "Michael", ""], ["Holtmann-Rice", "Daniel", ""], ["Liao", "Hank", ""], ["Suresh", "Ananda Theertha", ""], ["Yu", "Felix", ""]]}, {"id": "1711.05467", "submitter": "Steven Du", "authors": "Du Steven and Xi Zhang", "title": "Aicyber's System for NLPCC 2017 Shared Task 2: Voting of Baselines", "comments": "6 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Aicyber's system for NLPCC 2017 shared task 2. It is\nformed by a voting of three deep learning based system trained on\ncharacter-enhanced word vectors and a well known bag-of-word model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:17:34 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Steven", "Du", ""], ["Zhang", "Xi", ""]]}, {"id": "1711.05468", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva and Isabelle Augenstein", "title": "Tracking Typological Traits of Uralic Languages in Distributed Language\n  Representations", "comments": "Finnish abstract included in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although linguistic typology has a long history, computational approaches\nhave only recently gained popularity. The use of distributed representations in\ncomputational linguistics has also become increasingly popular. A recent\ndevelopment is to learn distributed representations of language, such that\ntypologically similar languages are spatially close to one another. Although\nempirical successes have been shown for such language representations, they\nhave not been subjected to much typological probing. In this paper, we first\nlook at whether this type of language representations are empirically useful\nfor model transfer between Uralic languages in deep neural networks. We then\ninvestigate which typological features are encoded in these representations by\nattempting to predict features in the World Atlas of Language Structures, at\nvarious stages of fine-tuning of the representations. We focus on Uralic\nlanguages, and find that some typological traits can be automatically inferred\nwith accuracies well above a strong baseline.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:20:43 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1711.05472", "submitter": "Stefan Wagner", "authors": "Elmar Juergens and Florian Deissenboeck and Martin Feilkas and\n  Benjamin Hummel and Bernhard Schaetz and Stefan Wagner and Christoph Domann\n  and Jonathan Streit", "title": "Can clone detection support quality assessments of requirements\n  specifications?", "comments": "10 pages, 5 figures", "journal-ref": "Proceedings of the 32nd ACM/IEEE International Conference on\n  Software Engineering - Volume 2. Pages 79-88. ACM, 2010", "doi": "10.1145/1810295.1810308", "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their pivotal role in software engineering, considerable effort is\nspent on the quality assurance of software requirements specifications. As they\nare mainly described in natural language, relatively few means of automated\nquality assessment exist. However, we found that clone detection, a technique\nwidely applied to source code, is promising to assess one important quality\naspect in an automated way, namely redundancy that stems from copy&paste\noperations. This paper describes a large-scale case study that applied clone\ndetection to 28 requirements specifications with a total of 8,667 pages. We\nreport on the amount of redundancy found in real-world specifications, discuss\nits nature as well as its consequences and evaluate in how far existing code\nclone detection approaches can be applied to assess the quality of requirements\nspecifications in practice.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 09:33:44 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Juergens", "Elmar", ""], ["Deissenboeck", "Florian", ""], ["Feilkas", "Martin", ""], ["Hummel", "Benjamin", ""], ["Schaetz", "Bernhard", ""], ["Wagner", "Stefan", ""], ["Domann", "Christoph", ""], ["Streit", "Jonathan", ""]]}, {"id": "1711.05516", "submitter": "Shaonan Wang", "authors": "Shaonan Wang, Jiajun Zhang, Nan Lin, Chengqing Zong", "title": "Investigating Inner Properties of Multimodal Representation and Semantic\n  Compositionality with Brain-based Componential Semantics", "comments": "To appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal models have been proven to outperform text-based approaches on\nlearning semantic representations. However, it still remains unclear what\nproperties are encoded in multimodal representations, in what aspects do they\noutperform the single-modality representations, and what happened in the\nprocess of semantic compositionality in different input modalities. Considering\nthat multimodal models are originally motivated by human concept\nrepresentations, we assume that correlating multimodal representations with\nbrain-based semantics would interpret their inner properties to answer the\nabove questions. To that end, we propose simple interpretation methods based on\nbrain-based componential semantics. First we investigate the inner properties\nof multimodal representations by correlating them with corresponding\nbrain-based property vectors. Then we map the distributed vector space to the\ninterpretable brain-based componential space to explore the inner properties of\nsemantic compositionality. Ultimately, the present paper sheds light on the\nfundamental questions of natural language understanding, such as how to\nrepresent the meaning of words and how to combine word meanings into larger\nunits.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 12:18:44 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 00:04:26 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Wang", "Shaonan", ""], ["Zhang", "Jiajun", ""], ["Lin", "Nan", ""], ["Zong", "Chengqing", ""]]}, {"id": "1711.05538", "submitter": "Andreas Niekler", "authors": "Christian Kahmann, Andreas Niekler, Gerhard Heyer", "title": "Detecting and assessing contextual change in diachronic text documents\n  using context volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terms in diachronic text corpora may exhibit a high degree of semantic\ndynamics that is only partially captured by the common notion of semantic\nchange. The new measure of context volatility that we propose models the degree\nby which terms change context in a text collection over time. The computation\nof context volatility for a word relies on the significance-values of its\nco-occurrent terms and the corresponding co-occurrence ranks in sequential time\nspans. We define a baseline and present an efficient computational approach in\norder to overcome problems related to computational issues in the data\nstructure. Results are evaluated both, on synthetic documents that are used to\nsimulate contextual changes, and a real example based on British newspaper\ntexts.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 12:42:48 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Kahmann", "Christian", ""], ["Niekler", "Andreas", ""], ["Heyer", "Gerhard", ""]]}, {"id": "1711.05557", "submitter": "Chee Seng Chan", "authors": "Ying Hua Tan, Chee Seng Chan", "title": "Phrase-based Image Captioning with Hierarchical LSTM Model", "comments": "17 pages, 12 figures, ACCV2016 extension, phrase-based image\n  captioning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of caption to describe the content of an image has been\ngaining a lot of research interests recently, where most of the existing works\ntreat the image caption as pure sequential data. Natural language, however\npossess a temporal hierarchy structure, with complex dependencies between each\nsubsequence. In this paper, we propose a phrase-based hierarchical Long\nShort-Term Memory (phi-LSTM) model to generate image description. In contrast\nto the conventional solutions that generate caption in a pure sequential\nmanner, our proposed model decodes image caption from phrase to sentence. It\nconsists of a phrase decoder at the bottom hierarchy to decode noun phrases of\nvariable length, and an abbreviated sentence decoder at the upper hierarchy to\ndecode an abbreviated form of the image description. A complete image caption\nis formed by combining the generated phrases with sentence during the inference\nstage. Empirically, our proposed model shows a better or competitive result on\nthe Flickr8k, Flickr30k and MS-COCO datasets in comparison to the state-of-the\nart models. We also show that our proposed model is able to generate more novel\ncaptions (not seen in the training data) which are richer in word contents in\nall these three datasets.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 10:48:59 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Tan", "Ying Hua", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1711.05568", "submitter": "Zheqian Chen", "authors": "Zheqian Chen, Rongqin Yang, Zhou Zhao, Deng Cai, Xiaofei He", "title": "Dialogue Act Recognition via CRF-Attentive Structured Network", "comments": "10 pages, 4figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue Act Recognition (DAR) is a challenging problem in dialogue\ninterpretation, which aims to attach semantic labels to utterances and\ncharacterize the speaker's intention. Currently, many existing approaches\nformulate the DAR problem ranging from multi-classification to structured\nprediction, which suffer from handcrafted feature extensions and attentive\ncontextual structural dependencies. In this paper, we consider the problem of\nDAR from the viewpoint of extending richer Conditional Random Field (CRF)\nstructural dependencies without abandoning end-to-end training. We incorporate\nhierarchical semantic inference with memory mechanism on the utterance\nmodeling. We then extend structured attention network to the linear-chain\nconditional random field layer which takes into account both contextual\nutterances and corresponding dialogue acts. The extensive experiments on two\nmajor benchmark datasets Switchboard Dialogue Act (SWDA) and Meeting Recorder\nDialogue Act (MRDA) datasets show that our method achieves better performance\nthan other state-of-the-art solutions to the problem. It is a remarkable fact\nthat our method is nearly close to the human annotator's performance on SWDA\nwithin 2% gap.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 13:43:02 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Chen", "Zheqian", ""], ["Yang", "Rongqin", ""], ["Zhao", "Zhou", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1711.05603", "submitter": "Hosein Azarbonyad", "authors": "Hosein Azarbonyad, Mostafa Dehghani, Kaspar Beelen, Alexandra Arkut,\n  Maarten Marx, Jaap Kamps", "title": "Words are Malleable: Computing Semantic Shifts in Political and Media\n  Discourse", "comments": "In Proceedings of the 26th ACM International on Conference on\n  Information and Knowledge Management (CIKM2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers started to pay attention to the detection of temporal\nshifts in the meaning of words. However, most (if not all) of these approaches\nrestricted their efforts to uncovering change over time, thus neglecting other\nvaluable dimensions such as social or political variability. We propose an\napproach for detecting semantic shifts between different viewpoints--broadly\ndefined as a set of texts that share a specific metadata feature, which can be\na time-period, but also a social entity such as a political party. For each\nviewpoint, we learn a semantic space in which each word is represented as a low\ndimensional neural embedded vector. The challenge is to compare the meaning of\na word in one space to its meaning in another space and measure the size of the\nsemantic shifts. We compare the effectiveness of a measure based on optimal\ntransformations between the two spaces with a measure based on the similarity\nof the neighbors of the word in the respective spaces. Our experiments\ndemonstrate that the combination of these two performs best. We show that the\nsemantic shifts not only occur over time, but also along different viewpoints\nin a short period of time. For evaluation, we demonstrate how this approach\ncaptures meaningful semantic shifts and can help improve other tasks such as\nthe contrastive viewpoint summarization and ideology detection (measured as\nclassification accuracy) in political texts. We also show that the two laws of\nsemantic change which were empirically shown to hold for temporal shifts also\nhold for shifts across viewpoints. These laws state that frequent words are\nless likely to shift meaning while words with many senses are more likely to do\nso.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 14:51:20 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Azarbonyad", "Hosein", ""], ["Dehghani", "Mostafa", ""], ["Beelen", "Kaspar", ""], ["Arkut", "Alexandra", ""], ["Marx", "Maarten", ""], ["Kamps", "Jaap", ""]]}, {"id": "1711.05626", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta, Subburam Rajaram, Hinrich Sch\\\"utze, Bernt Andrassy", "title": "Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic topic modeling facilitates the identification of topical trends over\ntime in temporal collections of unstructured documents. We introduce a novel\nunsupervised neural dynamic topic model named as Recurrent Neural\nNetwork-Replicated Softmax Model (RNNRSM), where the discovered topics at each\ntime influence the topic discovery in the subsequent time steps. We account for\nthe temporal ordering of documents by explicitly modeling a joint distribution\nof latent topical dependencies over time, using distributional estimators with\ntemporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP\nresearch, we demonstrate that compared to state-of-the art topic models, RNNRSM\nshows better generalization, topic interpretation, evolution and trends. We\nalso introduce a metric (named as SPAN) to quantify the capability of dynamic\ntopic model to capture word evolution in topics over time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 15:33:59 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 09:17:46 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Rajaram", "Subburam", ""], ["Sch\u00fctze", "Hinrich", ""], ["Andrassy", "Bernt", ""]]}, {"id": "1711.05678", "submitter": "Syed Sarfaraz Akhtar", "authors": "Syed Sarfaraz Akhtar, Arihant Gupta, Avijit Vajpayee, Arjit Srivastava\n  and Manish Shrivastava", "title": "Unsupervised Morphological Expansion of Small Datasets for Improving\n  Word Embeddings", "comments": "CICLing 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a language independent, unsupervised method for building word\nembeddings using morphological expansion of text. Our model handles the problem\nof data sparsity and yields improved word embeddings by relying on training\nword embeddings on artificially generated sentences. We evaluate our method\nusing small sized training sets on eleven test sets for the word similarity\ntask across seven languages. Further, for English, we evaluated the impacts of\nour approach using a large training set on three standard test sets. Our method\nimproved results across all languages.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 17:14:44 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Akhtar", "Syed Sarfaraz", ""], ["Gupta", "Arihant", ""], ["Vajpayee", "Avijit", ""], ["Srivastava", "Arjit", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1711.05680", "submitter": "Syed Sarfaraz Akhtar", "authors": "Syed Sarfaraz Akhtar, Arihant Gupta, Avijit Vajpayee, Arjit\n  Srivastava, Madan Gopal Jhawar and Manish Shrivastava", "title": "An Unsupervised Approach for Mapping between Vector Spaces", "comments": "CICLing 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a language independent, unsupervised approach for transforming\nword embeddings from source language to target language using a transformation\nmatrix. Our model handles the problem of data scarcity which is faced by many\nlanguages in the world and yields improved word embeddings for words in the\ntarget language by relying on transformed embeddings of words of the source\nlanguage. We initially evaluate our approach via word similarity tasks on a\nsimilar language pair - Hindi as source and Urdu as the target language, while\nwe also evaluate our method on French and German as target languages and\nEnglish as source language. Our approach improves the current state of the art\nresults - by 13% for French and 19% for German. For Urdu, we saw an increment\nof 16% over our initial baseline score. We further explore the prospects of our\napproach by applying it on multiple models of the same language and\ntransferring words between the two models, thus solving the problem of missing\nwords in a model. We evaluate this on word similarity and word analogy tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 17:15:05 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 14:40:29 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Akhtar", "Syed Sarfaraz", ""], ["Gupta", "Arihant", ""], ["Vajpayee", "Avijit", ""], ["Srivastava", "Arjit", ""], ["Jhawar", "Madan Gopal", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1711.05715", "submitter": "Zachary Lipton", "authors": "Zachary Lipton, Xiujun Li, Jianfeng Gao, Lihong Li, Faisal Ahmed, Li\n  Deng", "title": "BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for\n  Task-Oriented Dialogue Systems", "comments": "Duplicate of article already in the arXiv: arXiv:1608.05081", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm that significantly improves the efficiency of\nexploration for deep Q-learning agents in dialogue systems. Our agents explore\nvia Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop\nneural network. Our algorithm learns much faster than common exploration\nstrategies such as \\epsilon-greedy, Boltzmann, bootstrapping, and\nintrinsic-reward-based ones. Additionally, we show that spiking the replay\nbuffer with experiences from just a few successful episodes can make Q-learning\nfeasible when it might otherwise fail.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 18:23:48 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 04:22:45 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Lipton", "Zachary", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Li", "Lihong", ""], ["Ahmed", "Faisal", ""], ["Deng", "Li", ""]]}, {"id": "1711.05732", "submitter": "John Wieting", "authors": "John Wieting, Kevin Gimpel", "title": "ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with\n  Millions of Machine Translations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe PARANMT-50M, a dataset of more than 50 million English-English\nsentential paraphrase pairs. We generated the pairs automatically by using\nneural machine translation to translate the non-English side of a large\nparallel corpus, following Wieting et al. (2017). Our hope is that ParaNMT-50M\ncan be a valuable resource for paraphrase generation and can provide a rich\nsource of semantic knowledge to improve downstream natural language\nunderstanding tasks. To show its utility, we use ParaNMT-50M to train\nparaphrastic sentence embeddings that outperform all supervised systems on\nevery SemEval semantic textual similarity competition, in addition to showing\nhow it can be used for paraphrase generation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 18:59:29 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:45:26 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Wieting", "John", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1711.05780", "submitter": "Michal Shmueli-Scheuer", "authors": "Tommy Sandbank, Michal Shmueli-Scheuer, Jonathan Herzig, David\n  Konopnicki, John Richards, David Piorkowski", "title": "Detecting Egregious Conversations between Customers and Virtual Agents", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual agents are becoming a prominent channel of interaction in customer\nservice. Not all customer interactions are smooth, however, and some can become\nalmost comically bad. In such instances, a human agent might need to step in\nand salvage the conversation. Detecting bad conversations is important since\ndisappointing customer service may threaten customer loyalty and impact\nrevenue. In this paper, we outline an approach to detecting such egregious\nconversations, using behavioral cues from the user, patterns in agent\nresponses, and user-agent interaction. Using logs of two commercial systems, we\nshow that using these features improves the detection F1-score by around 20%\nover using textual features alone. In addition, we show that those features are\ncommon across two quite different domains and, arguably, universal.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 19:56:24 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 09:10:02 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Sandbank", "Tommy", ""], ["Shmueli-Scheuer", "Michal", ""], ["Herzig", "Jonathan", ""], ["Konopnicki", "David", ""], ["Richards", "John", ""], ["Piorkowski", "David", ""]]}, {"id": "1711.05789", "submitter": "Yuan Yang", "authors": "Yuan Yang, Jingcheng Yu, Ye Hu, Xiaoyao Xu and Eric Nyberg", "title": "CMU LiveMedQA at TREC 2017 LiveQA: A Consumer Health Question Answering\n  System", "comments": "To appear in Proceedings of TREC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present LiveMedQA, a question answering system that is\noptimized for consumer health question. On top of the general QA system\npipeline, we introduce several new features that aim to exploit domain-specific\nknowledge and entity structures for better performance. This includes a\nquestion type/focus analyzer based on deep text classification model, a\ntree-based knowledge graph for answer generation and a complementary\nstructure-aware searcher for answer retrieval. LiveMedQA system is evaluated in\nthe TREC 2017 LiveQA medical subtask, where it received an average score of\n0.356 on a 3 point scale. Evaluation results revealed 3 substantial drawbacks\nin current LiveMedQA system, based on which we provide a detailed discussion\nand propose a few solutions that constitute the main focus of our subsequent\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 20:26:42 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Yang", "Yuan", ""], ["Yu", "Jingcheng", ""], ["Hu", "Ye", ""], ["Xu", "Xiaoyao", ""], ["Nyberg", "Eric", ""]]}, {"id": "1711.05795", "submitter": "Shikhar Murty", "authors": "Shikhar Murty, Patrick Verga, Luke Vilnis, Andrew McCallum", "title": "Finer Grained Entity Typing with TypeNet", "comments": "Accepted at 6th Workshop on Automated Knowledge Base Construction\n  (AKBC) at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the challenging problem of entity typing over an extremely fine\ngrained set of types, wherein a single mention or entity can have many\nsimultaneous and often hierarchically-structured types. Despite the importance\nof the problem, there is a relative lack of resources in the form of\nfine-grained, deep type hierarchies aligned to existing knowledge bases. In\nresponse, we introduce TypeNet, a dataset of entity types consisting of over\n1941 types organized in a hierarchy, obtained by manually annotating a mapping\nfrom 1081 Freebase types to WordNet. We also experiment with several models\ncomparable to state-of-the-art systems and explore techniques to incorporate a\nstructure loss on the hierarchy with the standard mention typing loss, as a\nfirst step towards future research on this dataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 20:37:44 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Murty", "Shikhar", ""], ["Verga", "Patrick", ""], ["Vilnis", "Luke", ""], ["McCallum", "Andrew", ""]]}, {"id": "1711.05851", "submitter": "Rajarshi Das", "authors": "Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Luke Vilnis, Ishan\n  Durugkar, Akshay Krishnamurthy, Alex Smola, Andrew McCallum", "title": "Go for a Walk and Arrive at the Answer: Reasoning Over Paths in\n  Knowledge Bases using Reinforcement Learning", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KB), both automatically and manually constructed, are often\nincomplete --- many valid facts can be inferred from the KB by synthesizing\nexisting information. A popular approach to KB completion is to infer new\nrelations by combinatory reasoning over the information found along other paths\nconnecting a pair of entities. Given the enormous size of KBs and the\nexponential number of paths, previous path-based models have considered only\nthe problem of predicting a missing relation given two entities or evaluating\nthe truth of a proposed triple. Additionally, these methods have traditionally\nused random paths between fixed entity pairs or more recently learned to pick\npaths between them. We propose a new algorithm MINERVA, which addresses the\nmuch more difficult and practical task of answering questions where the\nrelation is known, but only one entity. Since random walks are impractical in a\nsetting with combinatorially many destinations from a start node, we present a\nneural reinforcement learning approach which learns how to navigate the graph\nconditioned on the input query to find predictive paths. Empirically, this\napproach obtains state-of-the-art results on several datasets, significantly\noutperforming prior methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 23:45:18 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 06:56:06 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Das", "Rajarshi", ""], ["Dhuliawala", "Shehzaad", ""], ["Zaheer", "Manzil", ""], ["Vilnis", "Luke", ""], ["Durugkar", "Ishan", ""], ["Krishnamurthy", "Akshay", ""], ["Smola", "Alex", ""], ["McCallum", "Andrew", ""]]}, {"id": "1711.05885", "submitter": "Julian Michael", "authors": "Julian Michael, Gabriel Stanovsky, Luheng He, Ido Dagan, Luke\n  Zettlemoyer", "title": "Crowdsourcing Question-Answer Meaning Representations", "comments": "8 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Question-Answer Meaning Representations (QAMRs), which represent\nthe predicate-argument structure of a sentence as a set of question-answer\npairs. We also develop a crowdsourcing scheme to show that QAMRs can be labeled\nwith very little training, and gather a dataset with over 5,000 sentences and\n100,000 questions. A detailed qualitative analysis demonstrates that the\ncrowd-generated question-answer pairs cover the vast majority of\npredicate-argument relationships in existing datasets (including PropBank,\nNomBank, QA-SRL, and AMR) along with many previously under-resourced ones,\nincluding implicit arguments and relations. The QAMR data and annotation code\nis made publicly available to enable future work on how best to model these\ncomplex phenomena.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 01:53:19 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Michael", "Julian", ""], ["Stanovsky", "Gabriel", ""], ["He", "Luheng", ""], ["Dagan", "Ido", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1711.06004", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel", "title": "Remedies against the Vocabulary Gap in Information Retrieval", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engines rely heavily on term-based approaches that represent queries\nand documents as bags of words. Text---a document or a query---is represented\nby a bag of its words that ignores grammar and word order, but retains word\nfrequency counts. When presented with a search query, the engine then ranks\ndocuments according to their relevance scores by computing, among other things,\nthe matching degrees between query and document terms. While term-based\napproaches are intuitive and effective in practice, they are based on the\nhypothesis that documents that exactly contain the query terms are highly\nrelevant regardless of query semantics. Inversely, term-based approaches assume\ndocuments that do not contain query terms as irrelevant. However, it is known\nthat a high matching degree at the term level does not necessarily mean high\nrelevance and, vice versa, documents that match null query terms may still be\nrelevant. Consequently, there exists a vocabulary gap between queries and\ndocuments that occurs when both use different words to describe the same\nconcepts. It is the alleviation of the effect brought forward by this\nvocabulary gap that is the topic of this dissertation. More specifically, we\npropose (1) methods to formulate an effective query from complex textual\nstructures and (2) latent vector space models that circumvent the vocabulary\ngap in information retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 09:50:52 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Van Gysel", "Christophe", ""]]}, {"id": "1711.06061", "submitter": "Boyan Xu", "authors": "Ruichu Cai, Boyan Xu, Xiaoyan Yang, Zhenjie Zhang, Zijian Li, Zhihao\n  Liang", "title": "An Encoder-Decoder Framework Translating Natural Language to Database\n  Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation is going through a radical revolution, driven by the\nexplosive development of deep learning techniques using Convolutional Neural\nNetwork (CNN) and Recurrent Neural Network (RNN). In this paper, we consider a\nspecial case in machine translation problems, targeting to convert natural\nlanguage into Structured Query Language (SQL) for data retrieval over\nrelational database. Although generic CNN and RNN learn the grammar structure\nof SQL when trained with sufficient samples, the accuracy and training\nefficiency of the model could be dramatically improved, when the translation\nmodel is deeply integrated with the grammar rules of SQL. We present a new\nencoder-decoder framework, with a suite of new approaches, including new\nsemantic features fed into the encoder, grammar-aware states injected into the\nmemory of decoder, as well as recursive state management for sub-queries. These\ntechniques help the neural network better focus on understanding semantics of\noperations in natural language and save the efforts on SQL grammar learning.\nThe empirical evaluation on real world database and queries show that our\napproach outperform state-of-the-art solution by a significant margin.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 12:21:57 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 07:38:27 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Cai", "Ruichu", ""], ["Xu", "Boyan", ""], ["Yang", "Xiaoyan", ""], ["Zhang", "Zhenjie", ""], ["Li", "Zijian", ""], ["Liang", "Zhihao", ""]]}, {"id": "1711.06095", "submitter": "Radu-Laurentiu Vieriu", "authors": "Evgeny Stepanov, Stephane Lathuiliere, Shammur Absar Chowdhury,\n  Arindam Ghosh, Radu-Laurentiu Vieriu, Nicu Sebe, Giuseppe Riccardi", "title": "Depression Severity Estimation from Multiple Modalities", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is a major debilitating disorder which can affect people from all\nages. With a continuous increase in the number of annual cases of depression,\nthere is a need to develop automatic techniques for the detection of the\npresence and extent of depression. In this AVEC challenge we explore different\nmodalities (speech, language and visual features extracted from face) to design\nand develop automatic methods for the detection of depression. In psychology\nliterature, the PHQ-8 questionnaire is well established as a tool for measuring\nthe severity of depression. In this paper we aim to automatically predict the\nPHQ-8 scores from features extracted from the different modalities. We show\nthat visual features extracted from facial landmarks obtain the best\nperformance in terms of estimating the PHQ-8 results with a mean absolute error\n(MAE) of 4.66 on the development set. Behavioral characteristics from speech\nprovide an MAE of 4.73. Language features yield a slightly higher MAE of 5.17.\nWhen switching to the test set, our Turn Features derived from audio\ntranscriptions achieve the best performance, scoring an MAE of 4.11\n(corresponding to an RMSE of 4.94), which makes our system the winner of the\nAVEC 2017 depression sub-challenge.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 12:47:52 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Stepanov", "Evgeny", ""], ["Lathuiliere", "Stephane", ""], ["Chowdhury", "Shammur Absar", ""], ["Ghosh", "Arindam", ""], ["Vieriu", "Radu-Laurentiu", ""], ["Sebe", "Nicu", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1711.06141", "submitter": "Dac-Viet Lai", "authors": "Lai Dac Viet, Vu Trong Sinh, Nguyen Le Minh, Ken Satoh", "title": "ConvAMR: Abstract meaning representation parsing for legal document", "comments": "SCIDOCA2017, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Convolutional neural networks (CNN) have recently achieved remarkable\nperformance in a wide range of applications. In this research, we equip\nconvolutional sequence-to-sequence (seq2seq) model with an efficient graph\nlinearization technique for abstract meaning representation parsing. Our\nlinearization method is better than the prior method at signaling the turn of\ngraph traveling. Additionally, convolutional seq2seq model is more appropriate\nand considerably faster than the recurrent neural network models in this task.\nOur method outperforms previous methods by a large margin on both the standard\ndataset LDC2014T12. Our result indicates that future works still have a room\nfor improving parsing model using graph linearization approach.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 15:27:53 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 17:21:15 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Viet", "Lai Dac", ""], ["Sinh", "Vu Trong", ""], ["Minh", "Nguyen Le", ""], ["Satoh", "Ken", ""]]}, {"id": "1711.06196", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz, Mihai Lupu, Allan Hanbury, Andres Duque", "title": "Addressing Cross-Lingual Word Sense Disambiguation on Low-Density\n  Languages: Application to Persian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of unsupervised methods in Cross-Lingual Word Sense\nDisambiguation (CL-WSD) with the application of English to Persian. Our\nproposed approach targets the languages with scarce resources (low-density) by\nexploiting word embedding and semantic similarity of the words in context. We\nevaluate the approach on a recent evaluation benchmark and compare it with the\nstate-of-the-art unsupervised system (CO-Graph). The results show that our\napproach outperforms both the standard baseline and the CO-Graph system in both\nof the task evaluation metrics (Out-Of-Five and Best result).\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 16:59:33 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 22:10:38 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 14:34:04 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Rekabsaz", "Navid", ""], ["Lupu", "Mihai", ""], ["Hanbury", "Allan", ""], ["Duque", "Andres", ""]]}, {"id": "1711.06232", "submitter": "Jia-Hong Huang", "authors": "Jia-Hong Huang, Cuong Duc Dao, Modar Alfadly, Bernard Ghanem", "title": "A Novel Framework for Robustness Analysis of Visual QA Models", "comments": "Accepted by the Thirty-Third AAAI Conference on Artificial\n  Intelligence, (AAAI-19), as an oral paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been playing an essential role in many computer\nvision tasks including Visual Question Answering (VQA). Until recently, the\nstudy of their accuracy was the main focus of research but now there is a trend\ntoward assessing the robustness of these models against adversarial attacks by\nevaluating their tolerance to varying noise levels. In VQA, adversarial attacks\ncan target the image and/or the proposed main question and yet there is a lack\nof proper analysis of the later. In this work, we propose a flexible framework\nthat focuses on the language part of VQA that uses semantically relevant\nquestions, dubbed basic questions, acting as controllable noise to evaluate the\nrobustness of VQA models. We hypothesize that the level of noise is positively\ncorrelated to the similarity of a basic question to the main question. Hence,\nto apply noise on any given main question, we rank a pool of basic questions\nbased on their similarity by casting this ranking task as a LASSO optimization\nproblem. Then, we propose a novel robustness measure, R_score, and two\nlarge-scale basic question datasets (BQDs) in order to standardize robustness\nanalysis for VQA models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 18:27:49 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 05:47:07 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 04:08:27 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Huang", "Jia-Hong", ""], ["Dao", "Cuong Duc", ""], ["Alfadly", "Modar", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1711.06238", "submitter": "Rajarshee Mitra", "authors": "Rajarshee Mitra", "title": "A Generative Approach to Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering has come a long way from answer sentence selection,\nrelational QA to reading and comprehension. We shift our attention to\ngenerative question answering (gQA) by which we facilitate machine to read\npassages and answer questions by learning to generate the answers. We frame the\nproblem as a generative task where the encoder being a network that models the\nrelationship between question and passage and encoding them to a vector thus\nfacilitating the decoder to directly form an abstraction of the answer. Not\nbeing able to retain facts and making repetitions are common mistakes that\naffect the overall legibility of answers. To counter these issues, we employ\ncopying mechanism and maintenance of coverage vector in our model respectively.\nOur results on MS-MARCO demonstrate it's superiority over baselines and we also\nshow qualitative examples where we improved in terms of correctness and\nreadability\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 18:34:16 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 13:37:40 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Mitra", "Rajarshee", ""]]}, {"id": "1711.06288", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Yelong Shen, Jianfeng Gao, Jingjing Liu, Xiaodong Liu", "title": "Language-Based Image Editing with Recurrent Attentive Models", "comments": "Accepted to CVPR 2018 as a Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of Language-Based Image Editing (LBIE). Given a\nsource image and a natural language description, we want to generate a target\nimage by editing the source image based on the description. We propose a\ngeneric modeling framework for two sub-tasks of LBIE: language-based image\nsegmentation and image colorization. The framework uses recurrent attentive\nmodels to fuse image and language features. Instead of using a fixed step size,\nwe introduce for each region of the image a termination gate to dynamically\ndetermine after each inference step whether to continue extrapolating\nadditional information from the textual description. The effectiveness of the\nframework is validated on three datasets. First, we introduce a synthetic\ndataset, called CoSaL, to evaluate the end-to-end performance of our LBIE\nsystem. Second, we show that the framework leads to state-of-the-art\nperformance on image segmentation on the ReferIt dataset. Third, we present the\nfirst language-based colorization result on the Oxford-102 Flowers dataset.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 19:10:21 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 04:04:30 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Chen", "Jianbo", ""], ["Shen", "Yelong", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Liu", "Xiaodong", ""]]}, {"id": "1711.06351", "submitter": "Anselm Rothe", "authors": "Anselm Rothe, Brenden M. Lake, Todd M. Gureckis", "title": "Question Asking as Program Generation", "comments": "Published in Advances in Neural Information Processing Systems (NIPS)\n  30, December 2017", "journal-ref": "Rothe, A., Lake, B. M., and Gureckis, T. M. (2017). Question\n  asking as program generation. Advances in Neural Information Processing\n  Systems 30", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of human intelligence is the ability to ask rich, creative, and\nrevealing questions. Here we introduce a cognitive model capable of\nconstructing human-like questions. Our approach treats questions as formal\nprograms that, when executed on the state of the world, output an answer. The\nmodel specifies a probability distribution over a complex, compositional space\nof programs, favoring concise programs that help the agent learn in the current\ncontext. We evaluate our approach by modeling the types of open-ended questions\ngenerated by humans who were attempting to learn about an ambiguous situation\nin a game. We find that our model predicts what questions people will ask, and\ncan creatively produce novel questions that were not present in the training\nset. In addition, we compare a number of model variants, finding that both\nquestion informativeness and complexity are important for producing human-like\nquestions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 23:27:04 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Rothe", "Anselm", ""], ["Lake", "Brenden M.", ""], ["Gureckis", "Todd M.", ""]]}, {"id": "1711.06729", "submitter": "Laura Gwilliams", "authors": "Laura Gwilliams, David Poeppel, Alec Marantz and Tal Linzen", "title": "Phonological (un)certainty weights lexical activation", "comments": "6 pages, 4 figures, accepted at: Cognitive Modeling and Computational\n  Linguistics (CMCL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spoken word recognition involves at least two basic computations. First is\nmatching acoustic input to phonological categories (e.g. /b/, /p/, /d/). Second\nis activating words consistent with those phonological categories. Here we test\nthe hypothesis that the listener's probability distribution over lexical items\nis weighted by the outcome of both computations: uncertainty about phonological\ndiscretisation and the frequency of the selected word(s). To test this, we\nrecord neural responses in auditory cortex using magnetoencephalography, and\nmodel this activity as a function of the size and relative activation of\nlexical candidates. Our findings indicate that towards the beginning of a word,\nthe processing system indeed weights lexical candidates by both phonological\ncertainty and lexical frequency; however, later into the word, activation is\nweighted by frequency alone.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 21:17:20 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Gwilliams", "Laura", ""], ["Poeppel", "David", ""], ["Marantz", "Alec", ""], ["Linzen", "Tal", ""]]}, {"id": "1711.06744", "submitter": "Ni Lao", "authors": "Fan Yang, Jiazhong Nie, William W. Cohen, Ni Lao", "title": "Learning to Organize Knowledge and Answer Questions with N-Gram Machines", "comments": "Presented at ICLR 2018 workshop\n  https://iclr.cc/Conferences/2018/Schedule?showEvent=580", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep neural networks have great success in natural language\nprocessing, they are limited at more knowledge intensive AI tasks, such as\nopen-domain Question Answering (QA). Existing end-to-end deep QA models need to\nprocess the entire text after observing the question, and therefore their\ncomplexity in responding a question is linear in the text size. This is\nprohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web.\nWe propose to solve this scalability issue by using symbolic meaning\nrepresentations, which can be indexed and retrieved efficiently with complexity\nthat is independent of the text size. We apply our approach, called the N-Gram\nMachine (NGM), to three representative tasks. First as proof-of-concept, we\ndemonstrate that NGM successfully solves the bAbI tasks of synthetic text.\nSecond, we show that NGM scales to large corpus by experimenting on \"life-long\nbAbI\", a special version of bAbI that contains millions of sentences. Lastly on\nthe WikiMovies dataset, we use NGM to induce latent structure (i.e. schema) and\nanswer questions from natural language Wikipedia text, with only QA pairs as\nweak supervision.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 22:02:53 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 22:59:15 GMT"}, {"version": "v3", "created": "Sun, 1 Jul 2018 07:09:45 GMT"}, {"version": "v4", "created": "Sun, 3 Mar 2019 02:42:26 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Yang", "Fan", ""], ["Nie", "Jiazhong", ""], ["Cohen", "William W.", ""], ["Lao", "Ni", ""]]}, {"id": "1711.06794", "submitter": "Pan Lu", "authors": "Pan Lu, Hongsheng Li, Wei Zhang, Jianyong Wang, Xiaogang Wang", "title": "Co-attending Free-form Regions and Detections with Multi-modal\n  Multiplicative Feature Embedding for Visual Question Answering", "comments": "To appear in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the Visual Question Answering (VQA) task has gained increasing\nattention in artificial intelligence. Existing VQA methods mainly adopt the\nvisual attention mechanism to associate the input question with corresponding\nimage regions for effective question answering. The free-form region based and\nthe detection-based visual attention mechanisms are mostly investigated, with\nthe former ones attending free-form image regions and the latter ones attending\npre-specified detection-box regions. We argue that the two attention mechanisms\nare able to provide complementary information and should be effectively\nintegrated to better solve the VQA problem. In this paper, we propose a novel\ndeep neural network for VQA that integrates both attention mechanisms. Our\nproposed framework effectively fuses features from free-form image regions,\ndetection boxes, and question representations via a multi-modal multiplicative\nfeature embedding scheme to jointly attend question-related free-form image\nregions and detection boxes for more accurate question answering. The proposed\nmethod is extensively evaluated on two publicly available datasets, COCO-QA and\nVQA, and outperforms state-of-the-art approaches. Source code is available at\nhttps://github.com/lupantech/dual-mfa-vqa.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 02:07:34 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 08:34:43 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Lu", "Pan", ""], ["Li", "Hongsheng", ""], ["Zhang", "Wei", ""], ["Wang", "Jianyong", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1711.06821", "submitter": "Guillem Collell", "authors": "Guillem Collell, Luc Van Gool, Marie-Francine Moens", "title": "Acquiring Common Sense Spatial Knowledge through Implicit Spatial\n  Templates", "comments": "To appear at AAAI 2018 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial understanding is a fundamental problem with wide-reaching real-world\napplications. The representation of spatial knowledge is often modeled with\nspatial templates, i.e., regions of acceptability of two objects under an\nexplicit spatial relationship (e.g., \"on\", \"below\", etc.). In contrast with\nprior work that restricts spatial templates to explicit spatial prepositions\n(e.g., \"glass on table\"), here we extend this concept to implicit spatial\nlanguage, i.e., those relationships (generally actions) for which the spatial\narrangement of the objects is only implicitly implied (e.g., \"man riding\nhorse\"). In contrast with explicit relationships, predicting spatial\narrangements from implicit spatial language requires significant common sense\nspatial understanding. Here, we introduce the task of predicting spatial\ntemplates for two objects under a relationship, which can be seen as a spatial\nquestion-answering task with a (2D) continuous output (\"where is the man w.r.t.\na horse when the man is walking the horse?\"). We present two simple\nneural-based models that leverage annotated images and structured text to learn\nthis task. The good performance of these models reveals that spatial locations\nare to a large extent predictable from implicit spatial language. Crucially,\nthe models attain similar performance in a challenging generalized setting,\nwhere the object-relation-object combinations (e.g.,\"man walking dog\") have\nnever been seen before. Next, we go one step further by presenting the models\nwith unseen objects (e.g., \"dog\"). In this scenario, we show that leveraging\nword embeddings enables the models to output accurate spatial predictions,\nproving that the models acquire solid common sense spatial knowledge allowing\nfor such generalization.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 07:00:44 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 02:41:36 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:23:13 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Collell", "Guillem", ""], ["Van Gool", "Luc", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1711.06826", "submitter": "Moontae Lee", "authors": "Moontae Lee, David Mimno", "title": "Low-dimensional Embeddings for Interpretable Anchor-based Topic\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anchor words algorithm performs provably efficient topic model inference\nby finding an approximate convex hull in a high-dimensional word co-occurrence\nspace. However, the existing greedy algorithm often selects poor anchor words,\nreducing topic quality and interpretability. Rather than finding an approximate\nconvex hull in a high-dimensional space, we propose to find an exact convex\nhull in a visualizable 2- or 3-dimensional space. Such low-dimensional\nembeddings both improve topics and clearly show users why the algorithm selects\ncertain words.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 07:52:40 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Lee", "Moontae", ""], ["Mimno", "David", ""]]}, {"id": "1711.06861", "submitter": "Zhenxin Fu", "authors": "Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao and Rui Yan", "title": "Style Transfer in Text: Exploration and Evaluation", "comments": "To appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style transfer is an important problem in natural language processing (NLP).\nHowever, the progress in language style transfer is lagged behind other\ndomains, such as computer vision, mainly because of the lack of parallel data\nand principle evaluation metrics. In this paper, we propose to learn style\ntransfer with non-parallel data. We explore two models to achieve this goal,\nand the key idea behind the proposed models is to learn separate content\nrepresentations and style representations using adversarial networks. We also\npropose novel evaluation metrics which measure two aspects of style transfer:\ntransfer strength and content preservation. We access our models and the\nevaluation metrics on two tasks: paper-news title transfer, and\npositive-negative review transfer. Results show that the proposed content\npreservation metric is highly correlate to human judgments, and the proposed\nmodels are able to generate sentences with higher style transfer strength and\nsimilar content preservation score comparing to auto-encoder.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 13:33:15 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 07:46:16 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Fu", "Zhenxin", ""], ["Tan", "Xiaoye", ""], ["Peng", "Nanyun", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1711.06872", "submitter": "Emma Strubell", "authors": "Sheshera Mysore, Edward Kim, Emma Strubell, Ao Liu, Haw-Shiuan Chang,\n  Srikrishna Kompella, Kevin Huang, Andrew McCallum, Elsa Olivetti", "title": "Automatically Extracting Action Graphs from Materials Science Synthesis\n  Procedures", "comments": "NIPS Workshop on Machine Learning for Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational synthesis planning approaches have achieved recent success in\norganic chemistry, where tabulated synthesis procedures are readily available\nfor supervised learning. The syntheses of inorganic materials, however, exist\nprimarily as natural language narratives contained within scientific journal\narticles. This synthesis information must first be extracted from the text in\norder to enable analogous synthesis planning methods for inorganic materials.\nIn this work, we present a system for automatically extracting structured\nrepresentations of synthesis procedures from the texts of materials science\njournal articles that describe explicit, experimental syntheses of inorganic\ncompounds. We define the structured representation as a set of linked events\nmade up of extracted scientific entities and evaluate two unsupervised\napproaches for extracting these structures on expert-annotated articles: a\nstrong heuristic baseline and a generative model of procedural text. We also\nevaluate a variety of supervised models for extracting scientific entities. Our\nresults provide insight into the nature of the data and directions for further\nwork in this exciting new area of research.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 15:28:17 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 18:41:55 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Mysore", "Sheshera", ""], ["Kim", "Edward", ""], ["Strubell", "Emma", ""], ["Liu", "Ao", ""], ["Chang", "Haw-Shiuan", ""], ["Kompella", "Srikrishna", ""], ["Huang", "Kevin", ""], ["McCallum", "Andrew", ""], ["Olivetti", "Elsa", ""]]}, {"id": "1711.06895", "submitter": "Hai Hu", "authors": "Hai Hu", "title": "Is China Entering WTO or shijie maoyi zuzhi--a Corpus Study of English\n  Acronyms in Chinese Newspapers", "comments": "To appear in Proceedings of the 28th North American Conference on\n  Chinese Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is one of the first studies that quantitatively examine the usage of\nEnglish acronyms (e.g. WTO) in Chinese texts. Using newspaper corpora, I try to\nanswer 1) for all instances of a concept that has an English acronym (e.g.\nWorld Trade Organization), what percentage is expressed in the English acronym\n(WTO), and what percentage in its Chinese translation (shijie maoyi zuzhi), and\n2) what factors are at play in language users' choice between the English and\nChinese forms? Results show that different concepts have different percentage\nfor English acronyms (PercentOfEn), ranging from 2% to 98%. Linear models show\nthat PercentOfEn for individual concepts can be predicted by language economy\n(how long the Chinese translation is), concept frequency, and whether the first\nappearance of the concept in Chinese newspapers is the English acronym or its\nChinese translation (all p < .05).\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 17:01:24 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Hu", "Hai", ""]]}, {"id": "1711.06899", "submitter": "Daniel Rockmore", "authors": "Daniel N. Rockmore, Chen Fang, Nicholas J. Foti, Tom Ginsburg, David\n  C. Krakauer", "title": "The Cultural Evolution of National Constitutions", "comments": "38 pages with supplemental information, 13 figures, 2 tables;\n  Accepted for publication the Journal of the Association for Information\n  Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how ideas from infectious disease and genetics can be used to\nuncover patterns of cultural inheritance and innovation in a corpus of 591\nnational constitutions spanning 1789 - 2008. Legal \"Ideas\" are encoded as\n\"topics\" - words statistically linked in documents - derived from topic\nmodeling the corpus of constitutions. Using these topics we derive a diffusion\nnetwork for borrowing from ancestral constitutions back to the US Constitution\nof 1789 and reveal that constitutions are complex cultural recombinants. We\nfind systematic variation in patterns of borrowing from ancestral texts and\n\"biological\"-like behavior in patterns of inheritance with the distribution of\n\"offspring\" arising through a bounded preferential-attachment process. This\nprocess leads to a small number of highly innovative (influential)\nconstitutions some of which have yet to have been identified as so in the\ncurrent literature. Our findings thus shed new light on the critical nodes of\nthe constitution-making network. The constitutional network structure reflects\nperiods of intense constitution creation, and systematic patterns of variation\nin constitutional life-span and temporal influence.\n", "versions": [{"version": "v1", "created": "Sat, 18 Nov 2017 17:10:25 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Rockmore", "Daniel N.", ""], ["Fang", "Chen", ""], ["Foti", "Nicholas J.", ""], ["Ginsburg", "Tom", ""], ["Krakauer", "David C.", ""]]}, {"id": "1711.06968", "submitter": "Imon Banerjee", "authors": "Imon Banerjee, Sriraman Madhavan, Roger Eric Goldman, Daniel L. Rubin", "title": "Intelligent Word Embeddings of Free-Text Radiology Reports", "comments": "AMIA Annual Symposium 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiology reports are a rich resource for advancing deep learning\napplications in medicine by leveraging the large volume of data continuously\nbeing updated, integrated, and shared. However, there are significant\nchallenges as well, largely due to the ambiguity and subtlety of natural\nlanguage. We propose a hybrid strategy that combines semantic-dictionary\nmapping and word2vec modeling for creating dense vector embeddings of free-text\nradiology reports. Our method leverages the benefits of both\nsemantic-dictionary mapping as well as unsupervised learning. Using the vector\nrepresentation, we automatically classify the radiology reports into three\nclasses denoting confidence in the diagnosis of intracranial hemorrhage by the\ninterpreting radiologist. We performed experiments with varying hyperparameter\nsettings of the word embeddings and a range of different classifiers. Best\nperformance achieved was a weighted precision of 88% and weighted recall of\n90%. Our work offers the potential to leverage unstructured electronic health\nrecord data by allowing direct analysis of narrative clinical notes.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 05:14:36 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Banerjee", "Imon", ""], ["Madhavan", "Sriraman", ""], ["Goldman", "Roger Eric", ""], ["Rubin", "Daniel L.", ""]]}, {"id": "1711.07010", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Ji Wen, Xu Sun, Qi Su", "title": "A Discourse-Level Named Entity Recognition and Relation Extraction\n  Dataset for Chinese Literature Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition and Relation Extraction for Chinese literature text\nis regarded as the highly difficult problem, partially because of the lack of\ntagging sets. In this paper, we build a discourse-level dataset from hundreds\nof Chinese literature articles for improving this task. To build a high quality\ndataset, we propose two tagging methods to solve the problem of data\ninconsistency, including a heuristic tagging method and a machine auxiliary\ntagging method. Based on this corpus, we also introduce several widely used\nmodels to conduct experiments. Experimental results not only show the\nusefulness of the proposed dataset, but also provide baselines for further\nresearch. The dataset is available at\nhttps://github.com/lancopku/Chinese-Literature-NER-RE-Dataset\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 12:29:59 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 02:27:01 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 05:04:28 GMT"}, {"version": "v4", "created": "Wed, 7 Nov 2018 13:10:48 GMT"}, {"version": "v5", "created": "Tue, 11 Jun 2019 01:51:12 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Xu", "Jingjing", ""], ["Wen", "Ji", ""], ["Sun", "Xu", ""], ["Su", "Qi", ""]]}, {"id": "1711.07019", "submitter": "Gholamreza Haffari", "authors": "Poorya Zaremoodi, Gholamreza Haffari", "title": "Incorporating Syntactic Uncertainty in Neural Machine Translation with\n  Forest-to-Sequence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating syntactic information in Neural Machine Translation models is a\nmethod to compensate their requirement for a large amount of parallel training\ntext, especially for low-resource language pairs. Previous works on using\nsyntactic information provided by (inevitably error-prone) parsers has been\npromising. In this paper, we propose a forest-to-sequence Attentional Neural\nMachine Translation model to make use of exponentially many parse trees of the\nsource sentence to compensate for the parser errors. Our method represents the\ncollection of parse trees as a packed forest, and learns a neural attentional\ntransduction model from the forest to the target sentence. Experiments on\nEnglish to German, Chinese and Persian translation show the superiority of our\nmethod over the tree-to-sequence and vanilla sequence-to-sequence neural\ntranslation models.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 13:57:30 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 00:37:27 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Zaremoodi", "Poorya", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1711.07065", "submitter": "Moontae Lee", "authors": "Moontae Lee, David Bindel, David Mimno", "title": "Prior-aware Dual Decomposition: Document-specific Topic Inference for\n  Spectral Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral topic modeling algorithms operate on matrices/tensors of word\nco-occurrence statistics to learn topic-specific word distributions. This\napproach removes the dependence on the original documents and produces\nsubstantial gains in efficiency and provable topic inference, but at a cost:\nthe model can no longer provide information about the topic composition of\nindividual documents. Recently Thresholded Linear Inverse (TLI) is proposed to\nmap the observed words of each document back to its topic composition. However,\nits linear characteristics limit the inference quality without considering the\nimportant prior information over topics. In this paper, we evaluate Simple\nProbabilistic Inverse (SPI) method and novel Prior-aware Dual Decomposition\n(PADD) that is capable of learning document-specific topic compositions in\nparallel. Experiments show that PADD successfully leverages topic correlations\nas a prior, notably outperforming TLI and learning quality topic compositions\ncomparable to Gibbs sampling on various data.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 19:56:23 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Lee", "Moontae", ""], ["Bindel", "David", ""], ["Mimno", "David", ""]]}, {"id": "1711.07128", "submitter": "Naveen Suda", "authors": "Yundong Zhang, Naveen Suda, Liangzhen Lai and Vikas Chandra", "title": "Hello Edge: Keyword Spotting on Microcontrollers", "comments": "Code available in github at\n  https://github.com/ARM-software/ML-KWS-for-MCU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) is a critical component for enabling speech based user\ninteractions on smart devices. It requires real-time response and high accuracy\nfor good user experience. Recently, neural networks have become an attractive\nchoice for KWS architecture because of their superior accuracy compared to\ntraditional speech processing algorithms. Due to its always-on nature, KWS\napplication has highly constrained power budget and typically runs on tiny\nmicrocontrollers with limited memory and compute capability. The design of\nneural network architecture for KWS must consider these constraints. In this\nwork, we perform neural network architecture evaluation and exploration for\nrunning KWS on resource-constrained microcontrollers. We train various neural\nnetwork architectures for keyword spotting published in literature to compare\ntheir accuracy and memory/compute requirements. We show that it is possible to\noptimize these neural network architectures to fit within the memory and\ncompute constraints of microcontrollers without sacrificing accuracy. We\nfurther explore the depthwise separable convolutional neural network (DS-CNN)\nand compare it against other neural network architectures. DS-CNN achieves an\naccuracy of 95.4%, which is ~10% higher than the DNN model with similar number\nof parameters.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 03:19:03 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 23:54:52 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 19:24:55 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Zhang", "Yundong", ""], ["Suda", "Naveen", ""], ["Lai", "Liangzhen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1711.07265", "submitter": "Hao Wang", "authors": "Hao Wang, Yves Lepage", "title": "Fast BTG-Forest-Based Hierarchical Sub-sentential Alignment", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel BTG-forest-based alignment method. Based on\na fast unsupervised initialization of parameters using variational IBM models,\nwe synchronously parse parallel sentences top-down and align hierarchically\nunder the constraint of BTG. Our two-step method can achieve the same run-time\nand comparable translation performance as fast_align while it yields smaller\nphrase tables. Final SMT results show that our method even outperforms in the\nexperiment of distantly related languages, e.g., English-Japanese.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 11:54:59 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Wang", "Hao", ""], ["Lepage", "Yves", ""]]}, {"id": "1711.07274", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu, Anshuman Tripathi, Katherine Chou, Chris Co, Navdeep\n  Jaitly, Diana Jaunzeikare, Anjuli Kannan, Patrick Nguyen, Hasim Sak, Ananth\n  Sankar, Justin Tansuwan, Nathan Wan, Yonghui Wu, Xuedong Zhang", "title": "Speech recognition for medical conversations", "comments": "Interspeech 2018 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explored building automatic speech recognition models for\ntranscribing doctor patient conversation. We collected a large scale dataset of\nclinical conversations ($14,000$ hr), designed the task to represent the real\nword scenario, and explored several alignment approaches to iteratively improve\ndata quality. We explored both CTC and LAS systems for building speech\nrecognition models. The LAS was more resilient to noisy data and CTC required\nmore data clean up. A detailed analysis is provided for understanding the\nperformance for clinical tasks. Our analysis showed the speech recognition\nmodels performed well on important medical utterances, while errors occurred in\ncausal conversations. Overall we believe the resulting models can provide\nreasonable quality in practice.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 12:07:22 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 17:54:30 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Tripathi", "Anshuman", ""], ["Chou", "Katherine", ""], ["Co", "Chris", ""], ["Jaitly", "Navdeep", ""], ["Jaunzeikare", "Diana", ""], ["Kannan", "Anjuli", ""], ["Nguyen", "Patrick", ""], ["Sak", "Hasim", ""], ["Sankar", "Ananth", ""], ["Tansuwan", "Justin", ""], ["Wan", "Nathan", ""], ["Wu", "Yonghui", ""], ["Zhang", "Xuedong", ""]]}, {"id": "1711.07280", "submitter": "Peter Anderson", "authors": "Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko\n  S\\\"underhauf, Ian Reid, Stephen Gould, Anton van den Hengel", "title": "Vision-and-Language Navigation: Interpreting visually-grounded\n  navigation instructions in real environments", "comments": "CVPR 2018 Spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot that can carry out a natural-language instruction has been a dream\nsince before the Jetsons cartoon series imagined a life of leisure mediated by\na fleet of attentive robot helpers. It is a dream that remains stubbornly\ndistant. However, recent advances in vision and language methods have made\nincredible progress in closely related areas. This is significant because a\nrobot interpreting a natural-language navigation instruction on the basis of\nwhat it sees is carrying out a vision and language process that is similar to\nVisual Question Answering. Both tasks can be interpreted as visually grounded\nsequence-to-sequence translation problems, and many of the same methods are\napplicable. To enable and encourage the application of vision and language\nmethods to the problem of interpreting visually-grounded navigation\ninstructions, we present the Matterport3D Simulator -- a large-scale\nreinforcement learning environment based on real imagery. Using this simulator,\nwhich can in future support a range of embodied vision and language tasks, we\nprovide the first benchmark dataset for visually-grounded natural language\nnavigation in real buildings -- the Room-to-Room (R2R) dataset.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 12:17:47 GMT"}, {"version": "v2", "created": "Fri, 24 Nov 2017 01:48:34 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2018 22:57:44 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Anderson", "Peter", ""], ["Wu", "Qi", ""], ["Teney", "Damien", ""], ["Bruce", "Jake", ""], ["Johnson", "Mark", ""], ["S\u00fcnderhauf", "Niko", ""], ["Reid", "Ian", ""], ["Gould", "Stephen", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1711.07341", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang, Chenguang Zhu, Yelong Shen, Weizhu Chen", "title": "FusionNet: Fusing via Fully-Aware Attention with Application to Machine\n  Comprehension", "comments": "Published in Sixth International Conference on Learning\n  Representations (ICLR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new neural structure called FusionNet, which extends\nexisting attention approaches from three perspectives. First, it puts forward a\nnovel concept of \"history of word\" to characterize attention information from\nthe lowest word-level embedding up to the highest semantic-level\nrepresentation. Second, it introduces an improved attention scoring function\nthat better utilizes the \"history of word\" concept. Third, it proposes a\nfully-aware multi-level attention mechanism to capture the complete information\nin one text (such as a question) and exploit it in its counterpart (such as\ncontext or passage) layer by layer. We apply FusionNet to the Stanford Question\nAnswering Dataset (SQuAD) and it achieves the first position for both single\nand ensemble model on the official SQuAD leaderboard at the time of writing\n(Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two\nadversarial SQuAD datasets and it sets up the new state-of-the-art on both\ndatasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to\n51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 03:52:41 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 04:56:45 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Zhu", "Chenguang", ""], ["Shen", "Yelong", ""], ["Chen", "Weizhu", ""]]}, {"id": "1711.07404", "submitter": "Dianna Radpour", "authors": "N. Dianna Radpour and Vinay Ashokkumar", "title": "Non-Contextual Modeling of Sarcasm using a Neural Network Benchmark", "comments": "2 tables, 2 figures, 7 pages, in AAAI Fall Symposium Series -\n  Symposium on Natural Communication for Human-Robot Collaboration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most crucial components of natural human-robot interaction is\nartificial intuition and its influence on dialog systems. The intuitive\ncapability that humans have is undeniably extraordinary, and so remains one of\nthe greatest challenges for natural communicative dialogue between humans and\nrobots. In this paper, we introduce a novel probabilistic modeling framework of\nidentifying, classifying and learning features of sarcastic text via training a\nneural network with human-informed sarcastic benchmarks. This is necessary for\nestablishing a comprehensive sentiment analysis schema that is sensitive to the\nnuances of sarcasm-ridden text by being trained on linguistic cues. We show\nthat our model provides a good fit for this type of real-world informed data,\nwith potential to achieve as accurate, if not more, than alternatives. Though\nthe implementation and benchmarking is an extensive task, it can be extended\nvia the same method that we present to capture different forms of nuances in\ncommunication and making for much more natural and engaging dialogue systems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 16:47:28 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Radpour", "N. Dianna", ""], ["Ashokkumar", "Vinay", ""]]}, {"id": "1711.07611", "submitter": "Noah Weber", "authors": "Noah Weber, Niranjan Balasubramanian, Nathanael Chambers", "title": "Event Representations with Tensor-based Compositions", "comments": "Accepted at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust and flexible event representations are important to many core areas in\nlanguage understanding. Scripts were proposed early on as a way of representing\nsequences of events for such understanding, and has recently attracted renewed\nattention. However, obtaining effective representations for modeling\nscript-like event sequences is challenging. It requires representations that\ncan capture event-level and scenario-level semantics. We propose a new\ntensor-based composition method for creating event representations. The method\ncaptures more subtle semantic interactions between an event and its entities\nand yields representations that are effective at multiple event-related tasks.\nWith the continuous representations, we also devise a simple schema generation\nmethod which produces better schemas compared to a prior discrete\nrepresentation based method. Our analysis shows that the tensors capture\ndistinct usages of a predicate even when there are only subtle differences in\ntheir surface realizations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 03:04:02 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Weber", "Noah", ""], ["Balasubramanian", "Niranjan", ""], ["Chambers", "Nathanael", ""]]}, {"id": "1711.07613", "submitter": "Qi Wu", "authors": "Qi Wu, Peng Wang, Chunhua Shen, Ian Reid, and Anton van den Hengel", "title": "Are You Talking to Me? Reasoned Visual Dialog Generation through\n  Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Visual Dialogue task requires an agent to engage in a conversation about\nan image with a human. It represents an extension of the Visual Question\nAnswering task in that the agent needs to answer a question about an image, but\nit needs to do so in light of the previous dialogue that has taken place. The\nkey challenge in Visual Dialogue is thus maintaining a consistent, and natural\ndialogue while continuing to answer questions correctly. We present a novel\napproach that combines Reinforcement Learning and Generative Adversarial\nNetworks (GANs) to generate more human-like responses to questions. The GAN\nhelps overcome the relative paucity of training data, and the tendency of the\ntypical MLE-based approach to generate overly terse answers. Critically, the\nGAN is tightly integrated into the attention mechanism that generates\nhuman-interpretable reasons for each answer. This means that the discriminative\nmodel of the GAN has the task of assessing whether a candidate answer is\ngenerated by a human or not, given the provided reason. This is significant\nbecause it drives the generative model to produce high quality answers that are\nwell supported by the associated reasoning. The method also generates the\nstate-of-the-art results on the primary benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 03:11:49 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Wu", "Qi", ""], ["Wang", "Peng", ""], ["Shen", "Chunhua", ""], ["Reid", "Ian", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1711.07614", "submitter": "Qi Wu", "authors": "Junjie Zhang, Qi Wu, Chunhua Shen, Jian Zhang, Jianfeng Lu, and Anton\n  van den Hengel", "title": "Asking the Difficult Questions: Goal-Oriented Visual Question Generation\n  via Intermediate Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in a variety of vision-and-language problems,\ndeveloping a method capable of asking intelligent, goal-oriented questions\nabout images is proven to be an inscrutable challenge. Towards this end, we\npropose a Deep Reinforcement Learning framework based on three new intermediate\nrewards, namely goal-achieved, progressive and informativeness that encourage\nthe generation of succinct questions, which in turn uncover valuable\ninformation towards the overall goal. By directly optimizing for questions that\nwork quickly towards fulfilling the overall goal, we avoid the tendency of\nexisting methods to generate long series of insane queries that add little\nvalue. We evaluate our model on the GuessWhat?! dataset and show that the\nresulting questions can help a standard Guesser identify a specific object in\nan image at a much higher success rate.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 03:15:30 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Zhang", "Junjie", ""], ["Wu", "Qi", ""], ["Shen", "Chunhua", ""], ["Zhang", "Jian", ""], ["Lu", "Jianfeng", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1711.07632", "submitter": "Xiaopeng Yang", "authors": "Xiaopeng Yang, Xiaowen Lin, Shunda Suo, and Ming Li", "title": "Generating Thematic Chinese Poetry using Conditional Variational\n  Autoencoders with Hybrid Decoders", "comments": "Accepted by IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer poetry generation is our first step towards computer writing.\nWriting must have a theme. The current approaches of using sequence-to-sequence\nmodels with attention often produce non-thematic poems. We present a novel\nconditional variational autoencoder with a hybrid decoder adding the\ndeconvolutional neural networks to the general recurrent neural networks to\nfully learn topic information via latent variables. This approach significantly\nimproves the relevance of the generated poems by representing each line of the\npoem not only in a context-sensitive manner but also in a holistic way that is\nhighly related to the given keyword and the learned topic. A proposed augmented\nword2vec model further improves the rhythm and symmetry. Tests show that the\ngenerated poems by our approach are mostly satisfying with regulated rules and\nconsistent themes, and 73.42% of them receive an Overall score no less than 3\n(the highest score is 5).\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 04:40:38 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 22:05:22 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 15:52:12 GMT"}, {"version": "v4", "created": "Thu, 5 Mar 2020 15:39:39 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Yang", "Xiaopeng", ""], ["Lin", "Xiaowen", ""], ["Suo", "Shunda", ""], ["Li", "Ming", ""]]}, {"id": "1711.07646", "submitter": "Yutong Shao", "authors": "Yutong Shao, Rico Sennrich, Bonnie Webber, Federico Fancellu", "title": "Evaluating Machine Translation Performance on Chinese Idioms with a\n  Blacklist Method", "comments": "Full paper accepted by LREC, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Idiom translation is a challenging problem in machine translation because the\nmeaning of idioms is non-compositional, and a literal (word-by-word)\ntranslation is likely to be wrong. In this paper, we focus on evaluating the\nquality of idiom translation of MT systems. We introduce a new evaluation\nmethod based on an idiom-specific blacklist of literal translations, based on\nthe insight that the occurrence of any blacklisted words in the translation\noutput indicates a likely translation error. We introduce a dataset, CIBB\n(Chinese Idioms Blacklists Bank), and perform an evaluation of a\nstate-of-the-art Chinese-English neural MT system. Our evaluation confirms that\na sizable number of idioms in our test set are mistranslated (46.1%), that\nliteral translation error is a common error type, and that our blacklist method\nis effective at identifying literal translation errors.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 06:34:06 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 08:32:35 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 07:21:43 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Shao", "Yutong", ""], ["Sennrich", "Rico", ""], ["Webber", "Bonnie", ""], ["Fancellu", "Federico", ""]]}, {"id": "1711.07656", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Cross Temporal Recurrent Networks for Ranking Question Answer Pairs", "comments": "Accepted to AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal gates play a significant role in modern recurrent-based neural\nencoders, enabling fine-grained control over recursive compositional operations\nover time. In recurrent models such as the long short-term memory (LSTM),\ntemporal gates control the amount of information retained or discarded over\ntime, not only playing an important role in influencing the learned\nrepresentations but also serving as a protection against vanishing gradients.\nThis paper explores the idea of learning temporal gates for sequence pairs\n(question and answer), jointly influencing the learned representations in a\npairwise manner. In our approach, temporal gates are learned via 1D\nconvolutional layers and then subsequently cross applied across question and\nanswer for joint learning. Empirically, we show that this conceptually simple\nsharing of temporal gates can lead to competitive performance across multiple\nbenchmarks. Intuitively, what our network achieves can be interpreted as\nlearning representations of question and answer pairs that are aware of what\neach other is remembering or forgetting, i.e., pairwise temporal gating. Via\nextensive experiments, we show that our proposed model achieves\nstate-of-the-art performance on two community-based QA datasets and competitive\nperformance on one factoid-based QA dataset.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 07:26:39 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1711.07798", "submitter": "Qingjie Liu", "authors": "Xingyue Chen, Yunhong Wang, Qingjie Liu", "title": "Visual and Textual Sentiment Analysis Using Deep Fusion Convolutional\n  Neural Networks", "comments": "Accepted as oral presentation by ICIP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is attracting more and more attentions and has become a\nvery hot research topic due to its potential applications in personalized\nrecommendation, opinion mining, etc. Most of the existing methods are based on\neither textual or visual data and can not achieve satisfactory results, as it\nis very hard to extract sufficient information from only one single modality\ndata. Inspired by the observation that there exists strong semantic correlation\nbetween visual and textual data in social medias, we propose an end-to-end deep\nfusion convolutional neural network to jointly learn textual and visual\nsentiment representations from training examples. The two modality information\nare fused together in a pooling layer and fed into fully-connected layers to\npredict the sentiment polarity. We evaluate the proposed approach on two widely\nused data sets. Results show that our method achieves promising result compared\nwith the state-of-the-art methods which clearly demonstrate its competency.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 14:19:48 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Chen", "Xingyue", ""], ["Wang", "Yunhong", ""], ["Liu", "Qingjie", ""]]}, {"id": "1711.07893", "submitter": "Thanh-Le Ha", "authors": "Thanh-Le Ha and Jan Niehues and Alexander Waibel", "title": "Effective Strategies in Zero-Shot Neural Machine Translation", "comments": "submitted to IWSLT17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed two strategies which can be applied to a\nmultilingual neural machine translation system in order to better tackle\nzero-shot scenarios despite not having any parallel corpus. The experiments\nshow that they are effective in terms of both performance and computing\nresources, especially in multilingual translation of unbalanced data in real\nzero-resourced condition when they alleviate the language bias problem.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 16:39:21 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 16:19:08 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Ha", "Thanh-Le", ""], ["Niehues", "Jan", ""], ["Waibel", "Alexander", ""]]}, {"id": "1711.07908", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan, Pengtao Xie, Mrinmaya Sachan, and Eric P Xing", "title": "Effective Use of Bidirectional Language Modeling for Transfer Learning\n  in Biomedical Named Entity Recognition", "comments": "Machine Learning for Healthcare (MLHC) 2018, Comments: 12 pages,\n  updated authors affiliations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical named entity recognition (NER) is a fundamental task in text\nmining of medical documents and has many applications. Deep learning based\napproaches to this task have been gaining increasing attention in recent years\nas their parameters can be learned end-to-end without the need for\nhand-engineered features. However, these approaches rely on high-quality\nlabeled data, which is expensive to obtain. To address this issue, we\ninvestigate how to use unlabeled text data to improve the performance of NER\nmodels. Specifically, we train a bidirectional language model (BiLM) on\nunlabeled data and transfer its weights to \"pretrain\" an NER model with the\nsame architecture as the BiLM, which results in a better parameter\ninitialization of the NER model. We evaluate our approach on four benchmark\ndatasets for biomedical NER and show that it leads to a substantial improvement\nin the F1 scores compared with the state-of-the-art approaches. We also show\nthat BiLM weight transfer leads to a faster model training and the pretrained\nmodel requires fewer training examples to achieve a particular F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 16:55:18 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 18:08:33 GMT"}, {"version": "v3", "created": "Wed, 15 Aug 2018 03:31:30 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Xie", "Pengtao", ""], ["Sachan", "Mrinmaya", ""], ["Xing", "Eric P", ""]]}, {"id": "1711.07915", "submitter": "Philipe Freitas Melo", "authors": "Philipe F. Melo, Daniel H. Dalip, Manoel M. Junior, Marcos A.\n  Gon\\c{c}alves, Fabr\\'icio Benevenuto", "title": "10Sent: A Stable Sentiment Analysis Method Based on the Combination of\n  Off-The-Shelf Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis has become a very important tool for analysis of social\nmedia data. There are several methods developed for this research field, many\nof them working very differently from each other, covering distinct aspects of\nthe problem and disparate strategies. Despite the large number of existent\ntechniques, there is no single one which fits well in all cases or for all data\nsources. Supervised approaches may be able to adapt to specific situations but\nthey require manually labeled training, which is very cumbersome and expensive\nto acquire, mainly for a new application. In this context, in here, we propose\nto combine several very popular and effective state-of-the-practice sentiment\nanalysis methods, by means of an unsupervised bootstrapped strategy for\npolarity classification. One of our main goals is to reduce the large\nvariability (lack of stability) of the unsupervised methods across different\ndomains (datasets). Our solution was thoroughly tested considering thirteen\ndifferent datasets in several domains such as opinions, comments, and social\nmedia. The experimental results demonstrate that our combined method (aka,\n10SENT) improves the effectiveness of the classification task, but more\nimportantly, it solves a key problem in the field. It is consistently among the\nbest methods in many data types, meaning that it can produce the best (or close\nto best) results in almost all considered contexts, without any additional\ncosts (e.g., manual labeling). Our self-learning approach is also very\nindependent of the base methods, which means that it is highly extensible to\nincorporate any new additional method that can be envisioned in the future.\nFinally, we also investigate a transfer learning approach for sentiment\nanalysis as a means to gather additional (unsupervised) information for the\nproposed approach and we show the potential of this technique to improve our\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 17:04:33 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Melo", "Philipe F.", ""], ["Dalip", "Daniel H.", ""], ["Junior", "Manoel M.", ""], ["Gon\u00e7alves", "Marcos A.", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "1711.07950", "submitter": "Jason  Weston", "authors": "Zhilin Yang, Saizheng Zhang, Jack Urbanek, Will Feng, Alexander H.\n  Miller, Arthur Szlam, Douwe Kiela, Jason Weston", "title": "Mastering the Dungeon: Grounded Language Learning by Mechanical Turker\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrary to most natural language processing research, which makes use of\nstatic datasets, humans learn language interactively, grounded in an\nenvironment. In this work we propose an interactive learning procedure called\nMechanical Turker Descent (MTD) and use it to train agents to execute natural\nlanguage commands grounded in a fantasy text adventure game. In MTD, Turkers\ncompete to train better agents in the short term, and collaborate by sharing\ntheir agents' skills in the long term. This results in a gamified, engaging\nexperience for the Turkers and a better quality teaching signal for the agents\ncompared to static datasets, as the Turkers naturally adapt the training data\nto the agent's abilities.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 18:21:16 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 02:08:18 GMT"}, {"version": "v3", "created": "Mon, 16 Apr 2018 15:48:58 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Yang", "Zhilin", ""], ["Zhang", "Saizheng", ""], ["Urbanek", "Jack", ""], ["Feng", "Will", ""], ["Miller", "Alexander H.", ""], ["Szlam", "Arthur", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""]]}, {"id": "1711.08010", "submitter": "Zhong Meng", "authors": "Zhong Meng, Zhuo Chen, Vadim Mazalov, Jinyu Li, Yifan Gong", "title": "Unsupervised Adaptation with Domain Separation Networks for Robust\n  Speech Recognition", "comments": "8 pages, 1 figure, ASRU 2017", "journal-ref": "2017 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Okinawa, 2017, pp. 214-221", "doi": "10.1109/ASRU.2017.8268938", "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation of speech signal aims at adapting a\nwell-trained source-domain acoustic model to the unlabeled data from target\ndomain. This can be achieved by adversarial training of deep neural network\n(DNN) acoustic models to learn an intermediate deep representation that is both\nsenone-discriminative and domain-invariant. Specifically, the DNN is trained to\njointly optimize the primary task of senone classification and the secondary\ntask of domain classification with adversarial objective functions. In this\nwork, instead of only focusing on learning a domain-invariant feature (i.e. the\nshared component between domains), we also characterize the difference between\nthe source and target domain distributions by explicitly modeling the private\ncomponent of each domain through a private component extractor DNN. The private\ncomponent is trained to be orthogonal with the shared component and thus\nimplicitly increases the degree of domain-invariance of the shared component. A\nreconstructor DNN is used to reconstruct the original speech feature from the\nprivate and shared components as a regularization. This domain separation\nframework is applied to the unsupervised environment adaptation task and\nachieved 11.08% relative WER reduction from the gradient reversal layer\ntraining, a representative adversarial training method, for automatic speech\nrecognition on CHiME-3 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 19:44:37 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:57:25 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", ""], ["Chen", "Zhuo", ""], ["Mazalov", "Vadim", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "1711.08016", "submitter": "Zhong Meng", "authors": "Zhong Meng, Shinji Watanabe, John R. Hershey, Hakan Erdogan", "title": "Deep Long Short-Term Memory Adaptive Beamforming Networks For\n  Multichannel Robust Speech Recognition", "comments": "in 2017 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "journal-ref": "2017 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), New Orleans, LA, 2017, pp. 271-275", "doi": "10.1109/ICASSP.2017.7952160", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Far-field speech recognition in noisy and reverberant conditions remains a\nchallenging problem despite recent deep learning breakthroughs. This problem is\ncommonly addressed by acquiring a speech signal from multiple microphones and\nperforming beamforming over them. In this paper, we propose to use a recurrent\nneural network with long short-term memory (LSTM) architecture to adaptively\nestimate real-time beamforming filter coefficients to cope with non-stationary\nenvironmental noise and dynamic nature of source and microphones positions\nwhich results in a set of timevarying room impulse responses. The LSTM adaptive\nbeamformer is jointly trained with a deep LSTM acoustic model to predict senone\nlabels. Further, we use hidden units in the deep LSTM acoustic model to assist\nin predicting the beamforming filter coefficients. The proposed system achieves\n7.97% absolute gain over baseline systems with no beamforming on CHiME-3 real\nevaluation set.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 20:03:03 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Meng", "Zhong", ""], ["Watanabe", "Shinji", ""], ["Hershey", "John R.", ""], ["Erdogan", "Hakan", ""]]}, {"id": "1711.08058", "submitter": "Ahmad Abdulkader", "authors": "Ahmad AbdulKader, Kareem Nassar, Mohamed Mahmoud, Daniel Galvez,\n  Chetan Patil", "title": "Multiple-Instance, Cascaded Classification for Keyword Spotting in\n  Narrow-Band Audio", "comments": "To be published in the proceedings of NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose using cascaded classifiers for a keyword spotting (KWS) task on\nnarrow-band (NB), 8kHz audio acquired in non-IID environments --- a more\nchallenging task than most state-of-the-art KWS systems face. We present a\nmodel that incorporates Deep Neural Networks (DNNs), cascading,\nmultiple-feature representations, and multiple-instance learning. The cascaded\nclassifiers handle the task's class imbalance and reduce power consumption on\ncomputationally-constrained devices via early termination. The KWS system\nachieves a false negative rate of 6% at an hourly false positive rate of 0.75\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 21:42:17 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["AbdulKader", "Ahmad", ""], ["Nassar", "Kareem", ""], ["Mahmoud", "Mohamed", ""], ["Galvez", "Daniel", ""], ["Patil", "Chetan", ""]]}, {"id": "1711.08083", "submitter": "Slava Mikhaylov", "authors": "Radoslaw Kowalski and Marc Esteve and Slava J. Mikhaylov", "title": "Application of Natural Language Processing to Determine User\n  Satisfaction in Public Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on customer satisfaction has increased substantially in recent\nyears. However, the relative importance and relationships between different\ndeterminants of satisfaction remains uncertain. Moreover, quantitative studies\nto date tend to test for significance of pre-determined factors thought to have\nan influence with no scalable means to identify other causes of user\nsatisfaction. The gaps in knowledge make it difficult to use available\nknowledge on user preference for public service improvement. Meanwhile, digital\ntechnology development has enabled new methods to collect user feedback, for\nexample through online forums where users can comment freely on their\nexperience. New tools are needed to analyze large volumes of such feedback. Use\nof topic models is proposed as a feasible solution to aggregate open-ended user\nopinions that can be easily deployed in the public sector. Generated insights\ncan contribute to a more inclusive decision-making process in public service\nprovision. This novel methodological approach is applied to a case of service\nreviews of publicly-funded primary care practices in England. Findings from the\nanalysis of 145,000 reviews covering almost 7,700 primary care centers indicate\nthat the quality of interactions with staff and bureaucratic exigencies are the\nkey issues driving user satisfaction across England.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 23:22:15 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Kowalski", "Radoslaw", ""], ["Esteve", "Marc", ""], ["Mikhaylov", "Slava J.", ""]]}, {"id": "1711.08195", "submitter": "Baoyu Jing", "authors": "Baoyu Jing, Pengtao Xie, Eric Xing", "title": "On the Automatic Generation of Medical Imaging Reports", "comments": "ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-1240", "report-no": "P18-1240", "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical imaging is widely used in clinical practice for diagnosis and\ntreatment. Report-writing can be error-prone for unexperienced physicians, and\ntime- consuming and tedious for experienced physicians. To address these\nissues, we study the automatic generation of medical imaging reports. This task\npresents several challenges. First, a complete report contains multiple\nheterogeneous forms of information, including findings and tags. Second,\nabnormal regions in medical images are difficult to identify. Third, the re-\nports are typically long, containing multiple sentences. To cope with these\nchallenges, we (1) build a multi-task learning framework which jointly performs\nthe pre- diction of tags and the generation of para- graphs, (2) propose a\nco-attention mechanism to localize regions containing abnormalities and\ngenerate narrations for them, (3) develop a hierarchical LSTM model to generate\nlong paragraphs. We demonstrate the effectiveness of the proposed methods on\ntwo publicly available datasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 09:45:51 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 21:49:03 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 17:45:14 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Jing", "Baoyu", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric", ""]]}, {"id": "1711.08231", "submitter": "Yi Zhang", "authors": "Yi Zhang, Xu Sun, Shuming Ma, Yang Yang, Xuancheng Ren", "title": "Does Higher Order LSTM Have Better Accuracy for Segmenting and Labeling\n  Sequence Data?", "comments": "Accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural models usually predict the tag of the current token\nindependent of the neighboring tags. The popular LSTM-CRF model considers the\ntag dependencies between every two consecutive tags. However, it is hard for\nexisting neural models to take longer distance dependencies of tags into\nconsideration. The scalability is mainly limited by the complex model\nstructures and the cost of dynamic programming during training. In our work, we\nfirst design a new model called \"high order LSTM\" to predict multiple tags for\nthe current token which contains not only the current tag but also the previous\nseveral tags. We call the number of tags in one prediction as \"order\". Then we\npropose a new method called Multi-Order BiLSTM (MO-BiLSTM) which combines low\norder and high order LSTMs together. MO-BiLSTM keeps the scalability to high\norder models with a pruning technique. We evaluate MO-BiLSTM on all-phrase\nchunking and NER datasets. Experiment results show that MO-BiLSTM achieves the\nstate-of-the-art result in chunking and highly competitive results in two NER\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 11:18:31 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 12:03:47 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 02:16:11 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Zhang", "Yi", ""], ["Sun", "Xu", ""], ["Ma", "Shuming", ""], ["Yang", "Yang", ""], ["Ren", "Xuancheng", ""]]}, {"id": "1711.08412", "submitter": "Nikhil Garg", "authors": "Nikhil Garg, Londa Schiebinger, Dan Jurafsky, James Zou", "title": "Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1720347115", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings use vectors to represent words such that the geometry between\nvectors captures semantic relationship between the words. In this paper, we\ndevelop a framework to demonstrate how the temporal dynamics of the embedding\ncan be leveraged to quantify changes in stereotypes and attitudes toward women\nand ethnic minorities in the 20th and 21st centuries in the United States. We\nintegrate word embeddings trained on 100 years of text data with the U.S.\nCensus to show that changes in the embedding track closely with demographic and\noccupation shifts over time. The embedding captures global social shifts --\ne.g., the women's movement in the 1960s and Asian immigration into the U.S --\nand also illuminates how specific adjectives and occupations became more\nclosely associated with certain populations over time. Our framework for\ntemporal analysis of word embedding opens up a powerful new intersection\nbetween machine learning and quantitative social science.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 17:39:58 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Garg", "Nikhil", ""], ["Schiebinger", "Londa", ""], ["Jurafsky", "Dan", ""], ["Zou", "James", ""]]}, {"id": "1711.08493", "submitter": "Bing Liu", "authors": "Bing Liu, Tong Yu, Ian Lane, Ole J. Mengshoel", "title": "Customized Nonlinear Bandits for Online Response Selection in Neural\n  Conversation Models", "comments": "Accepted at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog response selection is an important step towards natural response\ngeneration in conversational agents. Existing work on neural conversational\nmodels mainly focuses on offline supervised learning using a large set of\ncontext-response pairs. In this paper, we focus on online learning of response\nselection in retrieval-based dialog systems. We propose a contextual\nmulti-armed bandit model with a nonlinear reward function that uses distributed\nrepresentation of text for online response selection. A bidirectional LSTM is\nused to produce the distributed representations of dialog context and\nresponses, which serve as the input to a contextual bandit. In learning the\nbandit, we propose a customized Thompson sampling method that is applied to a\npolynomial feature space in approximating the reward. Experimental results on\nthe Ubuntu Dialogue Corpus demonstrate significant performance gains of the\nproposed method over conventional linear contextual bandits. Moreover, we\nreport encouraging response selection performance of the proposed neural bandit\nmodel using the Recall@k metric for a small set of online training samples.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 20:15:01 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Liu", "Bing", ""], ["Yu", "Tong", ""], ["Lane", "Ian", ""], ["Mengshoel", "Ole J.", ""]]}, {"id": "1711.08521", "submitter": "Ibrahim Aljarah", "authors": "Wadi' Hijawi, Hossam Faris, Ja'far Alqatawna, Ibrahim Aljarah, Ala' M.\n  Al-Zoubi, and Maria Habib", "title": "EMFET: E-mail Features Extraction Tool", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.32995.45603", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EMFET is an open source and flexible tool that can be used to extract a large\nnumber of features from any email corpus with emails saved in EML format. The\nextracted features can be categorized into three main groups: header features,\npayload (body) features, and attachment features. The purpose of the tool is to\nhelp practitioners and researchers to build datasets that can be used for\ntraining machine learning models for spam detection. So far, 140 features can\nbe extracted using EMFET. EMFET is extensible and easy to use. The source code\nof EMFET is publicly available at GitHub\n(https://github.com/WadeaHijjawi/EmailFeaturesExtraction)\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 22:24:20 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Hijawi", "Wadi'", ""], ["Faris", "Hossam", ""], ["Alqatawna", "Ja'far", ""], ["Aljarah", "Ibrahim", ""], ["Al-Zoubi", "Ala' M.", ""], ["Habib", "Maria", ""]]}, {"id": "1711.08609", "submitter": "Seyed Mahdi Rezaeinia", "authors": "Seyed Mahdi Rezaeinia, Ali Ghodsi, Rouhollah Rahmani", "title": "Improving the Accuracy of Pre-trained Word Embeddings for Sentiment\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is one of the well-known tasks and fast growing research\nareas in natural language processing (NLP) and text classifications. This\ntechnique has become an essential part of a wide range of applications\nincluding politics, business, advertising and marketing. There are various\ntechniques for sentiment analysis, but recently word embeddings methods have\nbeen widely used in sentiment classification tasks. Word2Vec and GloVe are\ncurrently among the most accurate and usable word embedding methods which can\nconvert words into meaningful vectors. However, these methods ignore sentiment\ninformation of texts and need a huge corpus of texts for training and\ngenerating exact vectors which are used as inputs of deep learning models. As a\nresult, because of the small size of some corpuses, researcher often have to\nuse pre-trained word embeddings which were trained on other large text corpus\nsuch as Google News with about 100 billion words. The increasing accuracy of\npre-trained word embeddings has a great impact on sentiment analysis research.\nIn this paper we propose a novel method, Improved Word Vectors (IWV), which\nincreases the accuracy of pre-trained word embeddings in sentiment analysis.\nOur method is based on Part-of-Speech (POS) tagging techniques, lexicon-based\napproaches and Word2Vec/GloVe methods. We tested the accuracy of our method via\ndifferent deep learning models and sentiment datasets. Our experiment results\nshow that Improved Word Vectors (IWV) are very effective for sentiment\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 08:25:23 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Rezaeinia", "Seyed Mahdi", ""], ["Ghodsi", "Ali", ""], ["Rahmani", "Rouhollah", ""]]}, {"id": "1711.08621", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Pratik Gajane, Stefan Riezler", "title": "Counterfactual Learning for Machine Translation: Degeneracies and\n  Solutions", "comments": "Workshop \"From 'What If?' To 'What Next?'\" at the 31st Conference on\n  Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning is a natural scenario to improve web-based machine\ntranslation services by offline learning from feedback logged during user\ninteractions. In order to avoid the risk of showing inferior translations to\nusers, in such scenarios mostly exploration-free deterministic logging policies\nare in place. We analyze possible degeneracies of inverse and reweighted\npropensity scoring estimators, in stochastic and deterministic settings, and\nrelate them to recently proposed techniques for counterfactual learning under\ndeterministic logging.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 08:54:05 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 13:25:49 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 13:47:21 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Lawrence", "Carolin", ""], ["Gajane", "Pratik", ""], ["Riezler", "Stefan", ""]]}, {"id": "1711.08726", "submitter": "Minghui Qiu", "authors": "Jianfei Yu and Minghui Qiu and Jing Jiang and Jun Huang and Shuangyong\n  Song and Wei Chu and Haiqing Chen", "title": "Modelling Domain Relationships for Transfer Learning on Retrieval-based\n  Question Answering Systems in E-commerce", "comments": "9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we study transfer learning for the PI and NLI problems, aiming\nto propose a general framework, which can effectively and efficiently adapt the\nshared knowledge learned from a resource-rich source domain to a resource- poor\ntarget domain. Specifically, since most existing transfer learning methods only\nfocus on learning a shared feature space across domains while ignoring the\nrelationship between the source and target domains, we propose to\nsimultaneously learn shared representations and domain relationships in a\nunified framework. Furthermore, we propose an efficient and effective hybrid\nmodel by combining a sentence encoding- based method and a sentence\ninteraction-based method as our base model. Extensive experiments on both\nparaphrase identification and natural language inference demonstrate that our\nbase model is efficient and has promising performance compared to the competing\nmodels, and our transfer learning method can help to significantly boost the\nperformance. Further analysis shows that the inter-domain and intra-domain\nrelationship captured by our model are insightful. Last but not least, we\ndeploy our transfer learning model for PI into our online chatbot system, which\ncan bring in significant improvements over our existing system. Finally, we\nlaunch our new system on the chatbot platform Eva in our E-commerce site\nAliExpress.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 15:00:43 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Yu", "Jianfei", ""], ["Qiu", "Minghui", ""], ["Jiang", "Jing", ""], ["Huang", "Jun", ""], ["Song", "Shuangyong", ""], ["Chu", "Wei", ""], ["Chen", "Haiqing", ""]]}, {"id": "1711.08792", "submitter": "Danish Pruthi", "authors": "Anant Subramanian, Danish Pruthi, Harsh Jhamtani, Taylor\n  Berg-Kirkpatrick, Eduard Hovy", "title": "SPINE: SParse Interpretable Neural Embeddings", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction without justification has limited utility. Much of the success of\nneural models can be attributed to their ability to learn rich, dense and\nexpressive representations. While these representations capture the underlying\ncomplexity and latent trends in the data, they are far from being\ninterpretable. We propose a novel variant of denoising k-sparse autoencoders\nthat generates highly efficient and interpretable distributed word\nrepresentations (word embeddings), beginning with existing word representations\nfrom state-of-the-art methods like GloVe and word2vec. Through large scale\nhuman evaluation, we report that our resulting word embedddings are much more\ninterpretable than the original GloVe and word2vec embeddings. Moreover, our\nembeddings outperform existing popular word embeddings on a diverse suite of\nbenchmark downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Nov 2017 18:00:29 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Subramanian", "Anant", ""], ["Pruthi", "Danish", ""], ["Jhamtani", "Harsh", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Hovy", "Eduard", ""]]}, {"id": "1711.08870", "submitter": "Namkyu Jung", "authors": "Namkyu Jung, Hyeong In Choi", "title": "Continuous Semantic Topic Embedding Model Using Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the continuous semantic topic embedding model (CSTEM)\nwhich finds latent topic variables in documents using continuous semantic\ndistance function between the topics and the words by means of the variational\nautoencoder(VAE). The semantic distance could be represented by any symmetric\nbell-shaped geometric distance function on the Euclidean space, for which the\nMahalanobis distance is used in this paper. In order for the semantic distance\nto perform more properly, we newly introduce an additional model parameter for\neach word to take out the global factor from this distance indicating how\nlikely it occurs regardless of its topic. It certainly improves the problem\nthat the Gaussian distribution which is used in previous topic model with\ncontinuous word embedding could not explain the semantic relation correctly and\nhelps to obtain the higher topic coherence. Through the experiments with the\ndataset of 20 Newsgroup, NIPS papers and CNN/Dailymail corpus, the performance\nof the recent state-of-the-art models is accomplished by our model as well as\ngenerating topic embedding vectors which makes possible to observe where the\ntopic vectors are embedded with the word vectors in the real Euclidean space\nand how the topics are related each other semantically.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 05:37:35 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Jung", "Namkyu", ""], ["Choi", "Hyeong In", ""]]}, {"id": "1711.08992", "submitter": "Kalin Stefanov", "authors": "Kalin Stefanov, Jonas Beskow and Giampiero Salvi", "title": "Self-Supervised Vision-Based Detection of the Active Speaker as Support\n  for Socially-Aware Language Acquisition", "comments": "10 pages, IEEE Transactions on Cognitive and Developmental Systems", "journal-ref": null, "doi": "10.1109/TCDS.2019.2927941", "report-no": null, "categories": "cs.CV cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a self-supervised method for visual detection of the\nactive speaker in a multi-person spoken interaction scenario. Active speaker\ndetection is a fundamental prerequisite for any artificial cognitive system\nattempting to acquire language in social settings. The proposed method is\nintended to complement the acoustic detection of the active speaker, thus\nimproving the system robustness in noisy conditions. The method can detect an\narbitrary number of possibly overlapping active speakers based exclusively on\nvisual information about their face. Furthermore, the method does not rely on\nexternal annotations, thus complying with cognitive development. Instead, the\nmethod uses information from the auditory modality to support learning in the\nvisual domain. This paper reports an extensive evaluation of the proposed\nmethod using a large multi-person face-to-face interaction dataset. The results\nshow good performance in a speaker dependent setting. However, in a speaker\nindependent setting the proposed method yields a significantly lower\nperformance. We believe that the proposed method represents an essential\ncomponent of any artificial cognitive system or robotic platform engaging in\nsocial interactions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 14:45:06 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 17:55:38 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Stefanov", "Kalin", ""], ["Beskow", "Jonas", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1711.09050", "submitter": "Peter Henderson", "authors": "Peter Henderson, Koustuv Sinha, Nicolas Angelard-Gontier, Nan Rosemary\n  Ke, Genevieve Fried, Ryan Lowe, Joelle Pineau", "title": "Ethical Challenges in Data-Driven Dialogue Systems", "comments": "In Submission to the AAAI/ACM conference on Artificial Intelligence,\n  Ethics, and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of dialogue systems as a medium for human-machine interaction is an\nincreasingly prevalent paradigm. A growing number of dialogue systems use\nconversation strategies that are learned from large datasets. There are well\ndocumented instances where interactions with these system have resulted in\nbiased or even offensive conversations due to the data-driven training process.\nHere, we highlight potential ethical issues that arise in dialogue systems\nresearch, including: implicit biases in data-driven systems, the rise of\nadversarial examples, potential sources of privacy violations, safety concerns,\nspecial considerations for reinforcement learning systems, and reproducibility\nconcerns. We also suggest areas stemming from these issues that deserve further\ninvestigation. Through this initial survey, we hope to spur research leading to\nrobust, safe, and ethically sound dialogue systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 17:14:34 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Henderson", "Peter", ""], ["Sinha", "Koustuv", ""], ["Angelard-Gontier", "Nicolas", ""], ["Ke", "Nan Rosemary", ""], ["Fried", "Genevieve", ""], ["Lowe", "Ryan", ""], ["Pineau", "Joelle", ""]]}, {"id": "1711.09055", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Lorenzo Jamone, Alexandre Bernardino and Giampiero\n  Salvi", "title": "Interactive Robot Learning of Gestures, Language and Affordances", "comments": "code available at https://github.com/gsaponaro/glu-gestures", "journal-ref": "International Workshop on Grounding Language Understanding (GLU),\n  Satellite of Interspeech 2017", "doi": "10.21437/GLU.2017-17", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing field in robotics and Artificial Intelligence (AI) research is\nhuman-robot collaboration, whose target is to enable effective teamwork between\nhumans and robots. However, in many situations human teams are still superior\nto human-robot teams, primarily because human teams can easily agree on a\ncommon goal with language, and the individual members observe each other\neffectively, leveraging their shared motor repertoire and sensorimotor\nresources. This paper shows that for cognitive robots it is possible, and\nindeed fruitful, to combine knowledge acquired from interacting with elements\nof the environment (affordance exploration) with the probabilistic observation\nof another agent's actions.\n  We propose a model that unites (i) learning robot affordances and word\ndescriptions with (ii) statistical recognition of human gestures with vision\nsensors. We discuss theoretical motivations, possible implementations, and we\nshow initial results which highlight that, after having acquired knowledge of\nits surrounding environment, a humanoid robot can generalize this knowledge to\nthe case when it observes another agent (human partner) performing the same\nmotor actions previously executed during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 17:34:32 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1711.09160", "submitter": "Tom Kocmi", "authors": "Tom Kocmi and Ond\\v{r}ej Bojar", "title": "An Exploration of Word Embedding Initialization in Deep-Learning Tasks", "comments": "Accepted to ICON 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are the interface between the world of discrete units of text\nprocessing and the continuous, differentiable world of neural networks. In this\nwork, we examine various random and pretrained initialization methods for\nembeddings used in deep networks and their effect on the performance on four\nNLP tasks with both recurrent and convolutional architectures. We confirm that\npretrained embeddings are a little better than random initialization,\nespecially considering the speed of learning. On the other hand, we do not see\nany significant difference between various methods of random initialization, as\nlong as the variance is kept reasonably low. High-variance initialization\nprevents the network to use the space of embeddings and forces it to use other\nfree parameters to accomplish the task. We support this hypothesis by observing\nthe performance in learning lexical relations and by the fact that the network\ncan learn to perform reasonably in its task even with fixed random embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 22:31:01 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Kocmi", "Tom", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1711.09181", "submitter": "Zhiwei Xu", "authors": "Siyuan Zhao, Zhiwei Xu, Limin Liu, Mengjie Guo", "title": "Towards Accurate Deceptive Opinion Spam Detection based on Word\n  Order-preserving CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, deep learning has been widely used. In natural language learning,\nthe analysis of complex semantics has been achieved because of its high degree\nof flexibility. The deceptive opinions detection is an important application\narea in deep learning model, and related mechanisms have been given attention\nand researched. On-line opinions are quite short, varied types and content. In\norder to effectively identify deceptive opinions, we need to comprehensively\nstudy the characteristics of deceptive opinions, and explore novel\ncharacteristics besides the textual semantics and emotional polarity that have\nbeen widely used in text analysis. The detection mechanism based on deep\nlearning has better self-adaptability and can effectively identify all kinds of\ndeceptive opinions. In this paper, we optimize the convolution neural network\nmodel by embedding the word order characteristics in its convolution layer and\npooling layer, which makes convolution neural network more suitable for various\ntext classification and deceptive opinions detection. The TensorFlow-based\nexperiments demonstrate that the detection mechanism proposed in this paper\nachieve more accurate deceptive opinion detection results.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 02:58:59 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 08:49:47 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Zhao", "Siyuan", ""], ["Xu", "Zhiwei", ""], ["Liu", "Limin", ""], ["Guo", "Mengjie", ""]]}, {"id": "1711.09271", "submitter": "Aditya Thakker", "authors": "Aditya Thakker, Suhail Barot, Sudhir Bagul", "title": "Acronym Disambiguation: A Domain Independent Approach", "comments": "6 Pages, 4 Figures, Accepted at International Conference on Natural\n  Language Processing (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acronyms are omnipresent. They usually express information that is repetitive\nand well known. But acronyms can also be ambiguous because there can be\nmultiple expansions for the same acronym. In this paper, we propose a general\nsystem for acronym disambiguation that can work on any acronym given some\ncontext information. We present methods for retrieving all the possible\nexpansions of an acronym from Wikipedia and AcronymsFinder.com. We propose to\nuse these expansions to collect all possible contexts in which these acronyms\nare used and then score them using a paragraph embedding technique called\nDoc2Vec. This method collectively led to achieving an accuracy of 90.9% in\nselecting the correct expansion for given acronym, on a dataset we scraped from\nWikipedia with 707 distinct acronyms and 14,876 disambiguations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 18:44:00 GMT"}, {"version": "v2", "created": "Sat, 2 Dec 2017 10:52:08 GMT"}, {"version": "v3", "created": "Sun, 17 Dec 2017 06:43:56 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Thakker", "Aditya", ""], ["Barot", "Suhail", ""], ["Bagul", "Sudhir", ""]]}, {"id": "1711.09285", "submitter": "Samira Abnar", "authors": "Samira Abnar and Rasyan Ahmed and Max Mijnheer and Willem Zuidema", "title": "Experiential, Distributional and Dependency-based Word Embeddings have\n  Complementary Roles in Decoding Brain Activity", "comments": "accepted at Cognitive Modeling and Computational Linguistics 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate 8 different word embedding models on their usefulness for\npredicting the neural activation patterns associated with concrete nouns. The\nmodels we consider include an experiential model, based on crowd-sourced\nassociation data, several popular neural and distributional models, and a model\nthat reflects the syntactic context of words (based on dependency parses). Our\ngoal is to assess the cognitive plausibility of these various embedding models,\nand understand how we can further improve our methods for interpreting brain\nimaging data.\n  We show that neural word embedding models exhibit superior performance on the\ntasks we consider, beating experiential word representation model. The\nsyntactically informed model gives the overall best performance when predicting\nbrain activation patterns from word embeddings; whereas the GloVe\ndistributional method gives the overall best performance when predicting in the\nreverse direction (words vectors from brain images). Interestingly, however,\nthe error patterns of these different models are markedly different. This may\nsupport the idea that the brain uses different systems for processing different\nkinds of words. Moreover, we suggest that taking the relative strengths of\ndifferent embedding models into account will lead to better models of the brain\nactivity associated with words.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 20:36:39 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Abnar", "Samira", ""], ["Ahmed", "Rasyan", ""], ["Mijnheer", "Max", ""], ["Zuidema", "Willem", ""]]}, {"id": "1711.09357", "submitter": "Yao Lu", "authors": "Linqing Liu, Yao Lu, Min Yang, Qiang Qu, Jia Zhu, Hongyan Li", "title": "Generative Adversarial Network for Abstractive Text Summarization", "comments": "AAAI 2018 abstract, Supplemental material:\n  http://likicode.com/textsum/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an adversarial process for abstractive text\nsummarization, in which we simultaneously train a generative model G and a\ndiscriminative model D. In particular, we build the generator G as an agent of\nreinforcement learning, which takes the raw text as input and predicts the\nabstractive summarization. We also build a discriminator which attempts to\ndistinguish the generated summary from the ground truth summary. Extensive\nexperiments demonstrate that our model achieves competitive ROUGE scores with\nthe state-of-the-art methods on CNN/Daily Mail dataset. Qualitatively, we show\nthat our model is able to generate more abstractive, readable and diverse\nsummaries.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 09:45:04 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Liu", "Linqing", ""], ["Lu", "Yao", ""], ["Yang", "Min", ""], ["Qu", "Qiang", ""], ["Zhu", "Jia", ""], ["Li", "Hongyan", ""]]}, {"id": "1711.09367", "submitter": "Zhaopeng Tu", "authors": "Zhaopeng Tu, Yang Liu, Shuming Shi, Tong Zhang", "title": "Learning to Remember Translation History with a Continuous Cache", "comments": "Accepted by TACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural machine translation (NMT) models generally translate\nsentences in isolation, missing the opportunity to take advantage of\ndocument-level information. In this work, we propose to augment NMT models with\na very light-weight cache-like memory network, which stores recent hidden\nrepresentations as translation history. The probability distribution over\ngenerated words is updated online depending on the translation history\nretrieved from the memory, endowing NMT models with the capability to\ndynamically adapt over time. Experiments on multiple domains with different\ntopics and styles show the effectiveness of the proposed approach with\nnegligible impact on the computational cost.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 10:44:55 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Tu", "Zhaopeng", ""], ["Liu", "Yang", ""], ["Shi", "Shuming", ""], ["Zhang", "Tong", ""]]}, {"id": "1711.09395", "submitter": "Igor Melnyk", "authors": "Igor Melnyk, Cicero Nogueira dos Santos, Kahini Wadhawan, Inkit Padhi,\n  Abhishek Kumar", "title": "Improved Neural Text Attribute Transfer with Non-parallel Data", "comments": "NIPS 2017 Workshop on Learning Disentangled Representations: from\n  Perception to Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text attribute transfer using non-parallel data requires methods that can\nperform disentanglement of content and linguistic attributes. In this work, we\npropose multiple improvements over the existing approaches that enable the\nencoder-decoder framework to cope with the text attribute transfer from\nnon-parallel data. We perform experiments on the sentiment transfer task using\ntwo datasets. For both datasets, our proposed method outperforms a strong\nbaseline in two of the three employed evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 14:42:52 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 23:20:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Melnyk", "Igor", ""], ["Santos", "Cicero Nogueira dos", ""], ["Wadhawan", "Kahini", ""], ["Padhi", "Inkit", ""], ["Kumar", "Abhishek", ""]]}, {"id": "1711.09476", "submitter": "Diego Moussallem", "authors": "Diego Moussallem and Matthias Wauer and Axel-Cyrille Ngonga Ngomo", "title": "Machine Translation using Semantic Web Technologies: A Survey", "comments": "23 pages, 2 figures, 4 tables", "journal-ref": null, "doi": "10.1016/j.websem.2018.07.001", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of machine translation approaches have recently been developed\nto facilitate the fluid migration of content across languages. However, the\nliterature suggests that many obstacles must still be dealt with to achieve\nbetter automatic translations. One of these obstacles is lexical and syntactic\nambiguity. A promising way of overcoming this problem is using Semantic Web\ntechnologies. This article presents the results of a systematic review of\nmachine translation approaches that rely on Semantic Web technologies for\ntranslating texts. Overall, our survey suggests that while Semantic Web\ntechnologies can enhance the quality of machine translation outputs for various\nproblems, the combination of both is still in its infancy.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 22:30:31 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 15:33:21 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2018 10:57:26 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Moussallem", "Diego", ""], ["Wauer", "Matthias", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1711.09502", "submitter": "Hao Zhou", "authors": "Zaixiang Zheng, Hao Zhou, Shujian Huang, Lili Mou, Xinyu Dai, Jiajun\n  Chen and Zhaopeng Tu", "title": "Modeling Past and Future for Neural Machine Translation", "comments": "Accepted by Transaction of ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural machine translation systems do not explicitly model what has\nbeen translated and what has not during the decoding phase. To address this\nproblem, we propose a novel mechanism that separates the source information\ninto two parts: translated Past contents and untranslated Future contents,\nwhich are modeled by two additional recurrent layers. The Past and Future\ncontents are fed to both the attention model and the decoder states, which\noffers NMT systems the knowledge of translated and untranslated contents.\nExperimental results show that the proposed approach significantly improves\ntranslation performance in Chinese-English, German-English and English-German\ntranslation tasks. Specifically, the proposed model outperforms the\nconventional coverage model in both of the translation quality and the\nalignment error rate.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 01:42:00 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 10:22:56 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Zheng", "Zaixiang", ""], ["Zhou", "Hao", ""], ["Huang", "Shujian", ""], ["Mou", "Lili", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1711.09534", "submitter": "Ziang Xie", "authors": "Ziang Xie", "title": "Neural Text Generation: A Practical Guide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have recently achieved great empirical success on\nmachine translation, dialogue response generation, summarization, and other\ntext generation tasks. At a high level, the technique has been to train\nend-to-end neural network models consisting of an encoder model to produce a\nhidden representation of the source text, followed by a decoder model to\ngenerate the target. While such models have significantly fewer pieces than\nearlier systems, significant tuning is still required to achieve good\nperformance. For text generation models in particular, the decoder can behave\nin undesired ways, such as by generating truncated or repetitive outputs,\noutputting bland and generic responses, or in some cases producing\nungrammatical gibberish. This paper is intended as a practical guide for\nresolving such undesired behavior in text generation models, with the aim of\nhelping enable real-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 04:50:15 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Xie", "Ziang", ""]]}, {"id": "1711.09573", "submitter": "Jian Li", "authors": "Jian Li, Yue Wang, Michael R. Lyu, Irwin King", "title": "Code Completion with Neural Attention and Pointer Networks", "comments": "Accepted in IJCAI 2018", "journal-ref": null, "doi": "10.24963/ijcai.2018/578", "report-no": "https://github.com/jack57lee/neuralCodeCompletion", "categories": "cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent code completion has become an essential research task to\naccelerate modern software development. To facilitate effective code completion\nfor dynamically-typed programming languages, we apply neural language models by\nlearning from large codebases, and develop a tailored attention mechanism for\ncode completion. However, standard neural language models even with attention\nmechanism cannot correctly predict the out-of-vocabulary (OoV) words that\nrestrict the code completion performance. In this paper, inspired by the\nprevalence of locally repeated terms in program source code, and the recently\nproposed pointer copy mechanism, we propose a pointer mixture network for\nbetter predicting OoV words in code completion. Based on the context, the\npointer mixture network learns to either generate a within-vocabulary word\nthrough an RNN component, or regenerate an OoV word from local context through\na pointer component. Experiments on two benchmarked datasets demonstrate the\neffectiveness of our attention mechanism and pointer mixture network on the\ncode completion task.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 08:17:16 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 15:04:18 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Li", "Jian", ""], ["Wang", "Yue", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1711.09645", "submitter": "Stefanos Angelidis", "authors": "Stefanos Angelidis, Mirella Lapata", "title": "Multiple Instance Learning Networks for Fine-Grained Sentiment Analysis", "comments": "Final published version. Please cite using appropriate date (2018).\n  Link to journal:\n  http://www.transacl.org/ojs/index.php/tacl/article/view/1225/277", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (TACL), 2018, Volume 6, pages 17-31", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the task of fine-grained sentiment analysis from the perspective\nof multiple instance learning (MIL). Our neural model is trained on document\nsentiment labels, and learns to predict the sentiment of text segments, i.e.\nsentences or elementary discourse units (EDUs), without segment-level\nsupervision. We introduce an attention-based polarity scoring method for\nidentifying positive and negative text snippets and a new dataset which we call\nSPOT (as shorthand for Segment-level POlariTy annotations) for evaluating\nMIL-style sentiment models like ours. Experimental results demonstrate superior\nperformance against multiple baselines, whereas a judgement elicitation study\nshows that EDU-level opinion extraction produces more informative summaries\nthan sentence-based alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 12:21:22 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 15:53:12 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Angelidis", "Stefanos", ""], ["Lapata", "Mirella", ""]]}, {"id": "1711.09684", "submitter": "Aniruddha Tammewar", "authors": "Aniruddha Tammewar, Monik Pamecha, Chirag Jain, Apurva Nagvenkar,\n  Krupal Modi", "title": "Production Ready Chatbots: Generate if not Retrieve", "comments": "DEEPDIAL-18, AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a hybrid model that combines a neural\nconversational model and a rule-based graph dialogue system that assists users\nin scheduling reminders through a chat conversation. The graph based system has\nhigh precision and provides a grammatically accurate response but has a low\nrecall. The neural conversation model can cater to a variety of requests, as it\ngenerates the responses word by word as opposed to using canned responses. The\nhybrid system shows significant improvements over the existing baseline system\nof rule based approach and caters to complex queries with a domain-restricted\nneural model. Restricting the conversation topic and combination of graph based\nretrieval system with a neural generative model makes the final system robust\nenough for a real world application.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 13:40:15 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Pamecha", "Monik", ""], ["Jain", "Chirag", ""], ["Nagvenkar", "Apurva", ""], ["Modi", "Krupal", ""]]}, {"id": "1711.09714", "submitter": "Giampiero Salvi", "authors": "Giampiero Salvi, Luis Montesano, Alexandre Bernardino, Jos\\'e\n  Santos-Victor", "title": "Language Bootstrapping: Learning Word Meanings From Perception-Action\n  Association", "comments": "code available at\n  https://github.com/giampierosalvi/AffordancesAndSpeech", "journal-ref": "in IEEE Transactions on Systems, Man, and Cybernetics, Part B\n  (Cybernetics), Volume: 42 Issue: 3, year 2012, pages 660-671", "doi": "10.1109/TSMCB.2011.2172420", "report-no": null, "categories": "cs.RO cs.CL cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of bootstrapping language acquisition for an\nartificial system similarly to what is observed in experiments with human\ninfants. Our method works by associating meanings to words in manipulation\ntasks, as a robot interacts with objects and listens to verbal descriptions of\nthe interactions. The model is based on an affordance network, i.e., a mapping\nbetween robot actions, robot perceptions, and the perceived effects of these\nactions upon objects. We extend the affordance model to incorporate spoken\nwords, which allows us to ground the verbal symbols to the execution of actions\nand the perception of the environment. The model takes verbal descriptions of a\ntask as the input and uses temporal co-occurrence to create links between\nspeech utterances and the involved objects, actions, and effects. We show that\nthe robot is able form useful word-to-meaning associations, even without\nconsidering grammatical structure in the learning process and in the presence\nof recognition errors. These word-to-meaning associations are embedded in the\nrobot's own understanding of its actions. Thus, they can be directly used to\ninstruct the robot to perform tasks and also allow to incorporate context in\nthe speech recognition task. We believe that the encouraging results with our\napproach may afford robots with a capacity to acquire language descriptors in\ntheir operation's environment as well as to shed some light as to how this\nchallenging process develops with human infants.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 14:42:26 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Salvi", "Giampiero", ""], ["Montesano", "Luis", ""], ["Bernardino", "Alexandre", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1711.09724", "submitter": "Tianyu Liu", "authors": "Tianyu Liu, Kexiang Wang, Lei Sha, Baobao Chang and Zhifang Sui", "title": "Table-to-text Generation by Structure-aware Seq2seq Learning", "comments": "Accepted by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Table-to-text generation aims to generate a description for a factual table\nwhich can be viewed as a set of field-value records. To encode both the content\nand the structure of a table, we propose a novel structure-aware seq2seq\narchitecture which consists of field-gating encoder and description generator\nwith dual attention. In the encoding phase, we update the cell memory of the\nLSTM unit by a field gate and its corresponding field value in order to\nincorporate field information into table representation. In the decoding phase,\ndual attention mechanism which contains word level attention and field level\nattention is proposed to model the semantic relevance between the generated\ndescription and the table. We conduct experiments on the \\texttt{WIKIBIO}\ndataset which contains over 700k biographies and corresponding infoboxes from\nWikipedia. The attention visualizations and case studies show that our model is\ncapable of generating coherent and informative descriptions based on the\ncomprehensive understanding of both the content and the structure of a table.\nAutomatic evaluations also show our model outperforms the baselines by a great\nmargin. Code for this work is available on\nhttps://github.com/tyliupku/wiki2bio.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 14:55:17 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Liu", "Tianyu", ""], ["Wang", "Kexiang", ""], ["Sha", "Lei", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "1711.09824", "submitter": "Xuan-Son Vu", "authors": "Xuan-Son Vu, Lucie Flekova, Lili Jiang, Iryna Gurevych", "title": "Lexical-semantic resources: yet powerful resources for automatic\n  personality classification", "comments": null, "journal-ref": "GWC 2018 The 9th Global WordNet Conference GWC 2018 The 9th Global\n  WordNet Conference GWC 2018 The 9th Global WordNet Conference GWC 2018, the\n  9th Global WordNet Conference", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we aim to reveal the impact of lexical-semantic resources,\nused in particular for word sense disambiguation and sense-level semantic\ncategorization, on automatic personality classification task. While stylistic\nfeatures (e.g., part-of-speech counts) have been shown their power in this\ntask, the impact of semantics beyond targeted word lists is relatively\nunexplored. We propose and extract three types of lexical-semantic features,\nwhich capture high-level concepts and emotions, overcoming the lexical gap of\nword n-grams. Our experimental results are comparable to state-of-the-art\nmethods, while no personality-specific resources are required.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 16:50:15 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Vu", "Xuan-Son", ""], ["Flekova", "Lucie", ""], ["Jiang", "Lili", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1711.09873", "submitter": "Zhongliang Li", "authors": "Zhongliang Li, Raymond Kulhanek, Shaojun Wang, Yunxin Zhao, Shuang Wu", "title": "Slim Embedding Layers for Recurrent Neural Language Models", "comments": "To appear at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural language models are the state-of-the-art models for language\nmodeling. When the vocabulary size is large, the space taken to store the model\nparameters becomes the bottleneck for the use of recurrent neural language\nmodels. In this paper, we introduce a simple space compression method that\nrandomly shares the structured parameters at both the input and output\nembedding layers of the recurrent neural language models to significantly\nreduce the size of model parameters, but still compactly represent the original\ninput and output embedding layers. The method is easy to implement and tune.\nExperiments on several data sets show that the new method can get similar\nperplexity and BLEU score results while only using a very tiny fraction of\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 18:43:52 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 02:26:09 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Li", "Zhongliang", ""], ["Kulhanek", "Raymond", ""], ["Wang", "Shaojun", ""], ["Zhao", "Yunxin", ""], ["Wu", "Shuang", ""]]}, {"id": "1711.10093", "submitter": "Jherez Taylor", "authors": "Jherez Taylor, Melvyn Peignon, Yi-Shin Chen", "title": "Surfacing contextual hate speech words within social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms have recently seen an increase in the occurrence of\nhate speech discourse which has led to calls for improved detection methods.\nMost of these rely on annotated data, keywords, and a classification technique.\nWhile this approach provides good coverage, it can fall short when dealing with\nnew terms produced by online extremist communities which act as original\nsources of words which have alternate hate speech meanings. These code words\n(which can be both created and adopted words) are designed to evade automatic\ndetection and often have benign meanings in regular discourse. As an example,\n\"skypes\", \"googles\", and \"yahoos\" are all instances of words which have an\nalternate meaning that can be used for hate speech. This overlap introduces\nadditional challenges when relying on keywords for both the collection of data\nthat is specific to hate speech, and downstream classification. In this work,\nwe develop a community detection approach for finding extremist hate speech\ncommunities and collecting data from their members. We also develop a word\nembedding model that learns the alternate hate speech meaning of words and\ndemonstrate the candidacy of our code words with several annotation\nexperiments, designed to determine if it is possible to recognize a word as\nbeing used for hate speech without knowing its alternate meaning. We report an\ninter-annotator agreement rate of K=0.871, and K=0.676 for data drawn from our\nextremist community and the keyword approach respectively, supporting our claim\nthat hate speech detection is a contextual task and does not depend on a fixed\nlist of keywords. Our goal is to advance the domain by providing a high quality\nhate speech dataset in addition to learned code words that can be fed into\nexisting classification approaches, thus improving the accuracy of automated\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 02:56:12 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Taylor", "Jherez", ""], ["Peignon", "Melvyn", ""], ["Chen", "Yi-Shin", ""]]}, {"id": "1711.10122", "submitter": "Oswaldo Ludwig", "authors": "Oswaldo Ludwig", "title": "End-to-end Adversarial Learning for Generative Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new adversarial learning method for generative\nconversational agents (GCA) besides a new model of GCA. Similar to previous\nworks on adversarial learning for dialogue generation, our method assumes the\nGCA as a generator that aims at fooling a discriminator that labels dialogues\nas human-generated or machine-generated; however, in our approach, the\ndiscriminator performs token-level classification, i.e. it indicates whether\nthe current token was generated by humans or machines. To do so, the\ndiscriminator also receives the context utterances (the dialogue history) and\nthe incomplete answer up to the current token as input. This new approach makes\npossible the end-to-end training by backpropagation. A self-conversation\nprocess enables to produce a set of generated data with more diversity for the\nadversarial training. This approach improves the performance on questions not\nrelated to the training data. Experimental results with human and adversarial\nevaluations show that the adversarial method yields significant performance\ngains over the usual teacher forcing training.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 04:42:24 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 03:52:57 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 23:10:49 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Ludwig", "Oswaldo", ""]]}, {"id": "1711.10124", "submitter": "Phuong Le-Hong", "authors": "Phuong Le-Hong, Thai Hoang Pham, Xuan Khoai Pham, Thi Minh Huyen\n  Nguyen, Thi Luong Nguyen, Minh Hiep Nguyen", "title": "Vietnamese Semantic Role Labelling", "comments": "Accepted to the VNU Journal of Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study semantic role labelling (SRL), a subtask of semantic\nparsing of natural language sentences and its application for the Vietnamese\nlanguage. We present our effort in building Vietnamese PropBank, the first\nVietnamese SRL corpus and a software system for labelling semantic roles of\nVietnamese texts. In particular, we present a novel constituent extraction\nalgorithm in the argument candidate identification step which is more suitable\nand more accurate than the common node-mapping method. In the machine learning\npart, our system integrates distributed word features produced by two recent\nunsupervised learning models in two learned statistical classifiers and makes\nuse of integer linear programming inference procedure to improve the accuracy.\nThe system is evaluated in a series of experiments and achieves a good result,\nan $F_1$ score of 74.77%. Our system, including corpus and software, is\navailable as an open source project for free research and we believe that it is\na good baseline for the development of future Vietnamese SRL systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 04:51:25 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Le-Hong", "Phuong", ""], ["Pham", "Thai Hoang", ""], ["Pham", "Xuan Khoai", ""], ["Nguyen", "Thi Minh Huyen", ""], ["Nguyen", "Thi Luong", ""], ["Nguyen", "Minh Hiep", ""]]}, {"id": "1711.10133", "submitter": "Cheng-Tao Chung", "authors": "Cheng-Tao Chung and Lin-Shan Lee", "title": "Unsupervised Discovery of Structured Acoustic Tokens with Applications\n  to Spoken Term Detection", "comments": null, "journal-ref": "IEEE Transactions on Audio, Speech, and Language Processing 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare two paradigms for unsupervised discovery of\nstructured acoustic tokens directly from speech corpora without any human\nannotation. The Multigranular Paradigm seeks to capture all available\ninformation in the corpora with multiple sets of tokens for different model\ngranularities. The Hierarchical Paradigm attempts to jointly learn several\nlevels of signal representations in a hierarchical structure. The two paradigms\nare unified within a theoretical framework in this paper. Query-by-Example\nSpoken Term Detection (QbE-STD) experiments on the QUESST dataset of MediaEval\n2015 verifies the competitiveness of the acoustic tokens. The Enhanced\nRelevance Score (ERS) proposed in this work improves both paradigms for the\ntask of QbE-STD. We also list results on the ABX evaluation task of the Zero\nResource Challenge 2015 for comparison of the Paradigms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 05:43:44 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Chung", "Cheng-Tao", ""], ["Lee", "Lin-Shan", ""]]}, {"id": "1711.10136", "submitter": "Jinyu Li", "authors": "Jinyu Li, Guoli Ye, Rui Zhao, Jasha Droppo and Yifan Gong", "title": "Acoustic-To-Word Model Without OOV", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the acoustic-to-word model based on the Connectionist Temporal\nClassification (CTC) criterion was shown as a natural end-to-end model directly\ntargeting words as output units. However, this type of word-based CTC model\nsuffers from the out-of-vocabulary (OOV) issue as it can only model limited\nnumber of words in the output layer and maps all the remaining words into an\nOOV output node. Therefore, such word-based CTC model can only recognize the\nfrequent words modeled by the network output nodes. It also cannot easily\nhandle the hot-words which emerge after the model is trained. In this study, we\nimprove the acoustic-to-word model with a hybrid CTC model which can predict\nboth words and characters at the same time. With a shared-hidden-layer\nstructure and modular design, the alignments of words generated from the\nword-based CTC and the character-based CTC are synchronized. Whenever the\nacoustic-to-word model emits an OOV token, we back off that OOV segment to the\nword output generated from the character-based CTC, hence solving the OOV or\nhot-words issue. Evaluated on a Microsoft Cortana voice assistant task, the\nproposed model can reduce the errors introduced by the OOV output token in the\nacoustic-to-word model by 30%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 05:55:11 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Li", "Jinyu", ""], ["Ye", "Guoli", ""], ["Zhao", "Rui", ""], ["Droppo", "Jasha", ""], ["Gong", "Yifan", ""]]}, {"id": "1711.10163", "submitter": "Xuancheng Ren", "authors": "Xuancheng Ren, Xu Sun", "title": "Hybrid Oracle: Making Use of Ambiguity in Transition-based Chinese\n  Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the training of transition-based dependency parsers, an oracle is used to\npredict a transition sequence for a sentence and its gold tree. However, the\ntransition system may exhibit ambiguity, that is, there can be multiple correct\ntransition sequences that form the gold tree. We propose to make use of the\nproperty in the training of neural dependency parsers, and present the Hybrid\nOracle. The new oracle gives all the correct transitions for a parsing state,\nwhich are used in the cross entropy loss function to provide better supervisory\nsignal. It is also used to generate different transition sequences for a\nsentence to better explore the training data and improve the generalization\nability of the parser. Evaluations show that the parsers trained using the\nhybrid oracle outperform the parsers using the traditional oracle in Chinese\ndependency parsing. We provide analysis from a linguistic view. The code is\navailable at https://github.com/lancopku/nndep .\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 07:58:34 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 01:33:57 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Ren", "Xuancheng", ""], ["Sun", "Xu", ""]]}, {"id": "1711.10203", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Sara Veldhoen, Willem Zuidema", "title": "Visualisation and 'diagnostic classifiers' reveal how recurrent and\n  recursive neural networks process hierarchical structure", "comments": "20 pages", "journal-ref": "Journal of Artificial Intelligence Research 61 (2018) 907-926", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how neural networks can learn and process languages with\nhierarchical, compositional semantics. To this end, we define the artificial\ntask of processing nested arithmetic expressions, and study whether different\ntypes of neural networks can learn to compute their meaning. We find that\nrecursive neural networks can find a generalising solution to this problem, and\nwe visualise this solution by breaking it up in three steps: project, sum and\nsquash. As a next step, we investigate recurrent neural networks, and show that\na gated recurrent unit, that processes its input incrementally, also performs\nvery well on this task. To develop an understanding of what the recurrent\nnetwork encodes, visualisation techniques alone do not suffice. Therefore, we\ndevelop an approach where we formulate and test multiple hypotheses on the\ninformation encoded and processed by the network. For each hypothesis, we\nderive predictions about features of the hidden state representations at each\ntime step, and train 'diagnostic classifiers' to test those predictions. Our\nresults indicate that the networks follow a strategy similar to our\nhypothesised 'cumulative strategy', which explains the high accuracy of the\nnetwork on novel expressions, the generalisation to longer expressions than\nseen in training, and the mild deterioration with increasing length. This is\nturn shows that diagnostic classifiers can be a useful technique for opening up\nthe black box of neural networks. We argue that diagnostic classification,\nunlike most visualisation techniques, does scale up from small networks in a\ntoy domain, to larger and deeper recurrent networks dealing with real-life\ndata, and may therefore contribute to a better understanding of the internal\ndynamics of current state-of-the-art models in natural language processing.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 09:41:34 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 09:01:41 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Veldhoen", "Sara", ""], ["Zuidema", "Willem", ""]]}, {"id": "1711.10307", "submitter": "Jean-Fran\\c{c}ois Delpech", "authors": "Jean-Fran\\c{c}ois Delpech", "title": "Semantic Technology-Assisted Review (STAR) Document analysis and\n  monitoring using random vectors", "comments": "13 pages, 9 tables, 21 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The review and analysis of large collections of documents and the periodic\nmonitoring of new additions thereto has greatly benefited from new developments\nin computer software. This paper demonstrates how using random vectors to\nconstruct a low-dimensional Euclidean space embedding words and documents\nenables fast and accurate computation of semantic similarities between them.\nWith this technique of Semantic Technology-Assisted Review (STAR), documents\ncan be selected, compared, classified, summarized and evaluated very quickly\nwith minimal expert involvement and high-quality results.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 14:28:54 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 13:50:46 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Delpech", "Jean-Fran\u00e7ois", ""]]}, {"id": "1711.10327", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Alexander Immer, Willi Raschkowski, Fabian Windheuser", "title": "Generative Interest Estimation for Document Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed representations of documents has pushed the\nstate-of-the-art in several natural language processing tasks and was\nsuccessfully applied to the field of recommender systems recently. In this\npaper, we propose a novel content-based recommender system based on learned\nrepresentations and a generative model of user interest. Our method works as\nfollows: First, we learn representations on a corpus of text documents. Then,\nwe capture a user's interest as a generative model in the space of the document\nrepresentations. In particular, we model the distribution of interest for each\nuser as a Gaussian mixture model (GMM). Recommendations can be obtained\ndirectly by sampling from a user's generative model. Using Latent semantic\nanalysis (LSA) as comparison, we compute and explore document representations\non the Delicious bookmarks dataset, a standard benchmark for recommender\nsystems. We then perform density estimation in both spaces and show that\nlearned representations outperform LSA in terms of predictive performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 15:00:24 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Hafner", "Danijar", ""], ["Immer", "Alexander", ""], ["Raschkowski", "Willi", ""], ["Windheuser", "Fabian", ""]]}, {"id": "1711.10331", "submitter": "Xu Sun", "authors": "Xu Sun, Weiwei Sun, Shuming Ma, Xuancheng Ren, Yi Zhang, Wenjie Li,\n  Houfeng Wang", "title": "Complex Structure Leads to Overfitting: A Structure Regularization\n  Decoding Method for Natural Language Processing", "comments": "arXiv admin note: text overlap with arXiv:1411.6243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent systems on structured prediction focus on increasing the level of\nstructural dependencies within the model. However, our study suggests that\ncomplex structures entail high overfitting risks. To control the\nstructure-based overfitting, we propose to conduct structure regularization\ndecoding (SR decoding). The decoding of the complex structure model is\nregularized by the additionally trained simple structure model. We\ntheoretically analyze the quantitative relations between the structural\ncomplexity and the overfitting risk. The analysis shows that complex structure\nmodels are prone to the structure-based overfitting. Empirical evaluations show\nthat the proposed method improves the performance of the complex structure\nmodels by reducing the structure-based overfitting. On the sequence labeling\ntasks, the proposed method substantially improves the performance of the\ncomplex neural network models. The maximum F1 error rate reduction is 36.4% for\nthe third-order model. The proposed method also works for the parsing task. The\nmaximum UAS improvement is 5.5% for the tri-sibling model. The results are\ncompetitive with or better than the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 07:47:02 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Sun", "Xu", ""], ["Sun", "Weiwei", ""], ["Ma", "Shuming", ""], ["Ren", "Xuancheng", ""], ["Zhang", "Yi", ""], ["Li", "Wenjie", ""], ["Wang", "Houfeng", ""]]}, {"id": "1711.10377", "submitter": "Hamid Bagheri", "authors": "Hamid Bagheri, Md Johirul Islam", "title": "Sentiment analysis of twitter data", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks are the main resources to gather information about people's\nopinion and sentiments towards different topics as they spend hours daily on\nsocial media and share their opinion. In this technical paper, we show the\napplication of sentimental analysis and how to connect to Twitter and run\nsentimental analysis queries. We run experiments on different queries from\npolitics to humanity and show the interesting results. We realized that the\nneutral sentiments for tweets are significantly high which clearly shows the\nlimitations of the current works.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 17:32:59 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 03:51:43 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Bagheri", "Hamid", ""], ["Islam", "Md Johirul", ""]]}, {"id": "1711.10705", "submitter": "Ruhi Sarikaya", "authors": "Young-Bum Kim, Sungjin Lee, Ruhi Sarikaya", "title": "Speaker-Sensitive Dual Memory Networks for Multi-Turn Slot Tagging", "comments": "5 pages conference paper accepted to IEEE ASRU 2017. Will be\n  published in December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-turn dialogs, natural language understanding models can introduce\nobvious errors by being blind to contextual information. To incorporate dialog\nhistory, we present a neural architecture with Speaker-Sensitive Dual Memory\nNetworks which encode utterances differently depending on the speaker. This\naddresses the different extents of information available to the system - the\nsystem knows only the surface form of user utterances while it has the exact\nsemantics of system output. We performed experiments on real user data from\nMicrosoft Cortana, a commercial personal assistant. The result showed a\nsignificant performance improvement over the state-of-the-art slot tagging\nmodels using contextual information.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 06:55:59 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Kim", "Young-Bum", ""], ["Lee", "Sungjin", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1711.10712", "submitter": "Bing Liu", "authors": "Bing Liu, Gokhan Tur, Dilek Hakkani-Tur, Pararth Shah, Larry Heck", "title": "End-to-End Optimization of Task-Oriented Dialogue Model with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a neural network based task-oriented dialogue\nsystem that can be optimized end-to-end with deep reinforcement learning (RL).\nThe system is able to track dialogue state, interface with knowledge bases, and\nincorporate query results into agent's responses to successfully complete\ntask-oriented dialogues. Dialogue policy learning is conducted with a hybrid\nsupervised and deep RL methods. We first train the dialogue agent in a\nsupervised manner by learning directly from task-oriented dialogue corpora, and\nfurther optimize it with deep RL during its interaction with users. In the\nexperiments on two different dialogue task domains, our model demonstrates\nrobust performance in tracking dialogue state and producing reasonable system\nresponses. We show that deep RL based optimization leads to significant\nimprovement on task success rate and reduction in dialogue length comparing to\nsupervised training model. We further show benefits of training task-oriented\ndialogue model end-to-end comparing to component-wise optimization with\nexperiment results on dialogue simulations and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 07:38:07 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 22:28:03 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Liu", "Bing", ""], ["Tur", "Gokhan", ""], ["Hakkani-Tur", "Dilek", ""], ["Shah", "Pararth", ""], ["Heck", "Larry", ""]]}, {"id": "1711.10837", "submitter": "Ahmed Hasan Zaidi", "authors": "Ahmed H. Zaidi, Russell Moore, Ted Briscoe", "title": "Curriculum Q-Learning for Visual Vocabulary Acquisition", "comments": "Accepted at Visually Grounded Interaction and Language Workshop (NIPS\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of curriculum plays a vital role in our learning process, both\nas children and adults. Presenting material in ascending order of difficulty\nthat also exploits prior knowledge can have a significant impact on the rate of\nlearning. However, the notion of difficulty and prior knowledge differs from\nperson to person. Motivated by the need for a personalised curriculum, we\npresent a novel method of curriculum learning for vocabulary words in the form\nof visual prompts. We employ a reinforcement learning model grounded in\npedagogical theories that emulates the actions of a tutor. We simulate three\nstudents with different levels of vocabulary knowledge in order to evaluate the\nhow well our model adapts to the environment. The results of the simulation\nreveal that through interaction, the model is able to identify the areas of\nweakness, as well as push students to the edge of their ZPD. We hypothesise\nthat these methods can also be effective in training agents to learn language\nrepresentations in a simulated environment where it has previously been shown\nthat order of words and prior knowledge play an important role in the efficacy\nof language learning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 13:21:22 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Zaidi", "Ahmed H.", ""], ["Moore", "Russell", ""], ["Briscoe", "Ted", ""]]}, {"id": "1711.10960", "submitter": "Moumita Bhattacharya", "authors": "Moumita Bhattacharya, Claudine Jurkovitz, Hagit Shatkay", "title": "Identifying Patterns of Associated-Conditions through Topic Models of\n  Electronic Medical Records", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple adverse health conditions co-occurring in a patient are typically\nassociated with poor prognosis and increased office or hospital visits.\nDeveloping methods to identify patterns of co-occurring conditions can assist\nin diagnosis. Thus identifying patterns of associations among co-occurring\nconditions is of growing interest. In this paper, we report preliminary results\nfrom a data-driven study, in which we apply a machine learning method, namely,\ntopic modeling, to electronic medical records, aiming to identify patterns of\nassociated conditions. Specifically, we use the well established latent\ndirichlet allocation, a method based on the idea that documents can be modeled\nas a mixture of latent topics, where each topic is a distribution over words.\nIn our study, we adapt the LDA model to identify latent topics in patients'\nEMRs. We evaluate the performance of our method both qualitatively, and show\nthat the obtained topics indeed align well with distinct medical phenomena\ncharacterized by co-occurring conditions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 21:39:19 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Bhattacharya", "Moumita", ""], ["Jurkovitz", "Claudine", ""], ["Shatkay", "Hagit", ""]]}, {"id": "1711.11017", "submitter": "Ethan Perez", "authors": "Simon Brodeur, Ethan Perez, Ankesh Anand, Florian Golemo, Luca\n  Celotti, Florian Strub, Jean Rouat, Hugo Larochelle, Aaron Courville", "title": "HoME: a Household Multimodal Environment", "comments": "Presented at NIPS 2017's Visually-Grounded Interaction and Language\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce HoME: a Household Multimodal Environment for artificial agents\nto learn from vision, audio, semantics, physics, and interaction with objects\nand other agents, all within a realistic context. HoME integrates over 45,000\ndiverse 3D house layouts based on the SUNCG dataset, a scale which may\nfacilitate learning, generalization, and transfer. HoME is an open-source,\nOpenAI Gym-compatible platform extensible to tasks in reinforcement learning,\nlanguage grounding, sound-based navigation, robotics, multi-agent learning, and\nmore. We hope HoME better enables artificial agents to learn as humans do: in\nan interactive, multimodal, and richly contextualized setting.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:45:59 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Brodeur", "Simon", ""], ["Perez", "Ethan", ""], ["Anand", "Ankesh", ""], ["Golemo", "Florian", ""], ["Celotti", "Luca", ""], ["Strub", "Florian", ""], ["Rouat", "Jean", ""], ["Larochelle", "Hugo", ""], ["Courville", "Aaron", ""]]}, {"id": "1711.11023", "submitter": "Pawe{\\l} Budzianowski", "authors": "I\\~nigo Casanueva, Pawe{\\l} Budzianowski, Pei-Hao Su, Nikola\n  Mrk\\v{s}i\\'c, Tsung-Hsien Wen, Stefan Ultes, Lina Rojas-Barahona, Steve\n  Young, Milica Ga\\v{s}i\\'c", "title": "A Benchmarking Environment for Reinforcement Learning Based Task\n  Oriented Dialogue Management", "comments": "Accepted at the Deep Reinforcement Learning Symposium, 31st\n  Conference on Neural Information Processing Systems (NIPS 2017) Paper updated\n  with minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue assistants are rapidly becoming an indispensable daily aid. To avoid\nthe significant effort needed to hand-craft the required dialogue flow, the\nDialogue Management (DM) module can be cast as a continuous Markov Decision\nProcess (MDP) and trained through Reinforcement Learning (RL). Several RL\nmodels have been investigated over recent years. However, the lack of a common\nbenchmarking framework makes it difficult to perform a fair comparison between\ndifferent models and their capability to generalise to different environments.\nTherefore, this paper proposes a set of challenging simulated environments for\ndialogue model development and evaluation. To provide some baselines, we\ninvestigate a number of representative parametric algorithms, namely deep\nreinforcement learning algorithms - DQN, A2C and Natural Actor-Critic and\ncompare them to a non-parametric model, GP-SARSA. Both the environments and\npolicy models are implemented using the publicly available PyDial toolkit and\nreleased on-line, in order to establish a testbed framework for further\nexperiments and to facilitate experimental reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:51:14 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 10:50:44 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Casanueva", "I\u00f1igo", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Wen", "Tsung-Hsien", ""], ["Ultes", "Stefan", ""], ["Rojas-Barahona", "Lina", ""], ["Young", "Steve", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1711.11027", "submitter": "Serhii Havrylov", "authors": "Arthur Bra\\v{z}inskas, Serhii Havrylov, Ivan Titov", "title": "Embedding Words as Distributions with a Bayesian Skip-gram Model", "comments": "COLING 2018. For the associated code, see\n  https://github.com/ixlan/BSG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for embedding words as probability densities in a\nlow-dimensional space. Rather than assuming that a word embedding is fixed\nacross the entire text collection, as in standard word embedding methods, in\nour Bayesian model we generate it from a word-specific prior density for each\noccurrence of a given word. Intuitively, for each word, the prior density\nencodes the distribution of its potential 'meanings'. These prior densities are\nconceptually similar to Gaussian embeddings. Interestingly, unlike the Gaussian\nembeddings, we can also obtain context-specific densities: they encode\nuncertainty about the sense of a word given its context and correspond to\nposterior distributions within our model. The context-dependent densities have\nmany potential applications: for example, we show that they can be directly\nused in the lexical substitution task. We describe an effective estimation\nmethod based on the variational autoencoding framework. We also demonstrate\nthat our embeddings achieve competitive results on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:55:48 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:44:44 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Havrylov", "Serhii", ""], ["Titov", "Ivan", ""]]}, {"id": "1711.11081", "submitter": "Angela Lin C", "authors": "Angela Lin", "title": "Improved Twitter Sentiment Analysis Using Naive Bayes and Custom\n  Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last couple decades, social network services like Twitter have\ngenerated large volumes of data about users and their interests, providing\nmeaningful business intelligence so organizations can better understand and\nengage their customers. All businesses want to know who is promoting their\nproducts, who is complaining about them, and how are these opinions bringing or\ndiminishing value to a company. Companies want to be able to identify their\nhigh-value customers and quantify the value each user brings. Many businesses\nuse social media metrics to calculate the user contribution score, which\nenables them to quantify the value that influential users bring on social\nmedia, so the businesses can offer them more differentiated services. However,\nthe score calculation can be refined to provide a better illustration of a\nuser's contribution. Using Microsoft Azure as a case study, we conducted\nTwitter sentiment analysis to develop a machine learning classification model\nthat identifies tweet contents and sentiments most illustrative of\npositive-value user contribution. Using data mining and AI-powered cognitive\ntools, we analyzed factors of social influence and specifically, promotional\nlanguage in the developer community. Our predictive model was a combination of\na traditional supervised machine learning algorithm and a custom-developed\nnatural language model for identifying promotional tweets, that identifies a\nproduct-specific promotion on Twitter with a 90% accuracy rate.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 20:04:23 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Lin", "Angela", ""]]}, {"id": "1711.11118", "submitter": "Robert Logan Iv", "authors": "Robert L. Logan IV, Samuel Humeau, Sameer Singh", "title": "Multimodal Attribute Extraction", "comments": "AKBC 2017 Workshop Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad goal of information extraction is to derive structured information\nfrom unstructured data. However, most existing methods focus solely on text,\nignoring other types of unstructured data such as images, video and audio which\ncomprise an increasing portion of the information on the web. To address this\nshortcoming, we propose the task of multimodal attribute extraction. Given a\ncollection of unstructured and semi-structured contextual information about an\nentity (such as a textual description, or visual depictions) the task is to\nextract the entity's underlying attributes. In this paper, we provide a dataset\ncontaining mixed-media data for over 2 million product items along with 7\nmillion attribute-value pairs describing the items which can be used to train\nattribute extractors in a weakly supervised manner. We provide a variety of\nbaselines which demonstrate the relative effectiveness of the individual modes\nof information towards solving the task, as well as study human performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 21:40:59 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Logan", "Robert L.", "IV"], ["Humeau", "Samuel", ""], ["Singh", "Sameer", ""]]}, {"id": "1711.11125", "submitter": "Filip Miscevic", "authors": "Filip Miscevic, Aida Nematzadeh, Suzanne Stevenson", "title": "Predicting and Explaining Human Semantic Search in a Cognitive Model", "comments": "To appear in proceedings for CMCL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has attempted to characterize the structure of semantic memory\nand the search algorithms which, together, best approximate human patterns of\nsearch revealed in a semantic fluency task. There are a number of models that\nseek to capture semantic search processes over networks, but they vary in the\ncognitive plausibility of their implementation. Existing work has also\nneglected to consider the constraints that the incremental process of language\nacquisition must place on the structure of semantic memory. Here we present a\nmodel that incrementally updates a semantic network, with limited computational\nsteps, and replicates many patterns found in human semantic fluency using a\nsimple random walk. We also perform thorough analyses showing that a\ncombination of both structural and semantic features are correlated with human\nperformance patterns.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 21:50:40 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Miscevic", "Filip", ""], ["Nematzadeh", "Aida", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "1711.11135", "submitter": "Xin Wang", "authors": "Xin Wang, Wenhu Chen, Jiawei Wu, Yuan-Fang Wang, William Yang Wang", "title": "Video Captioning via Hierarchical Reinforcement Learning", "comments": "CVPR 2018, with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video captioning is the task of automatically generating a textual\ndescription of the actions in a video. Although previous work (e.g.\nsequence-to-sequence model) has shown promising results in abstracting a coarse\ndescription of a short video, it is still very challenging to caption a video\ncontaining multiple fine-grained actions with a detailed description. This\npaper aims to address the challenge by proposing a novel hierarchical\nreinforcement learning framework for video captioning, where a high-level\nManager module learns to design sub-goals and a low-level Worker module\nrecognizes the primitive actions to fulfill the sub-goal. With this\ncompositional framework to reinforce video captioning at different levels, our\napproach significantly outperforms all the baseline methods on a newly\nintroduced large-scale dataset for fine-grained video captioning. Furthermore,\nour non-ensemble model has already achieved the state-of-the-art results on the\nwidely-used MSR-VTT dataset.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 22:23:59 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 08:38:19 GMT"}, {"version": "v3", "created": "Thu, 29 Mar 2018 07:06:47 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Wang", "Xin", ""], ["Chen", "Wenhu", ""], ["Wu", "Jiawei", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1711.11191", "submitter": "Yu Wu", "authors": "Yu Wu, Wei Wu, Dejian Yang, Can Xu, Zhoujun Li, Ming Zhou", "title": "Neural Response Generation with Dynamic Vocabularies", "comments": "accepted by AAAI18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study response generation for open domain conversation in chatbots.\nExisting methods assume that words in responses are generated from an identical\nvocabulary regardless of their inputs, which not only makes them vulnerable to\ngeneric patterns and irrelevant noise, but also causes a high cost in decoding.\nWe propose a dynamic vocabulary sequence-to-sequence (DVS2S) model which allows\neach input to possess their own vocabulary in decoding. In training, vocabulary\nconstruction and response generation are jointly learned by maximizing a lower\nbound of the true objective with a Monte Carlo sampling method. In inference,\nthe model dynamically allocates a small vocabulary for an input with the word\nprediction model, and conducts decoding only with the small vocabulary. Because\nof the dynamic vocabulary mechanism, DVS2S eludes many generic patterns and\nirrelevant words in generation, and enjoys efficient decoding at the same time.\nExperimental results on both automatic metrics and human annotations show that\nDVS2S can significantly outperform state-of-the-art methods in terms of\nresponse quality, but only requires 60% decoding time compared to the most\nefficient baseline.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 02:06:47 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Wu", "Yu", ""], ["Wu", "Wei", ""], ["Yang", "Dejian", ""], ["Xu", "Can", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "1711.11221", "submitter": "Shaohui Kuang", "authors": "Shaohui Kuang, Deyi Xiong, Weihua Luo, Guodong Zhou", "title": "Modeling Coherence for Neural Machine Translation with Dynamic and Topic\n  Caches", "comments": "Accepted by COLING2018,11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentences in a well-formed text are connected to each other via various links\nto form the cohesive structure of the text. Current neural machine translation\n(NMT) systems translate a text in a conventional sentence-by-sentence fashion,\nignoring such cross-sentence links and dependencies. This may lead to generate\nan incoherent target text for a coherent source text. In order to handle this\nissue, we propose a cache-based approach to modeling coherence for neural\nmachine translation by capturing contextual information either from recently\ntranslated sentences or the entire document. Particularly, we explore two types\nof caches: a dynamic cache, which stores words from the best translation\nhypotheses of preceding sentences, and a topic cache, which maintains a set of\ntarget-side topical words that are semantically related to the document to be\ntranslated. On this basis, we build a new layer to score target words in these\ntwo caches with a cache-based neural model. Here the estimated probabilities\nfrom the cache-based neural model are combined with NMT probabilities into the\nfinal word prediction probabilities via a gating mechanism. Finally, the\nproposed cache-based neural model is trained jointly with NMT system in an\nend-to-end manner. Experiments and analysis presented in this paper demonstrate\nthat the proposed cache-based model achieves substantial improvements over\nseveral state-of-the-art SMT and NMT baselines.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 04:30:53 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 13:27:26 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 09:25:29 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Kuang", "Shaohui", ""], ["Xiong", "Deyi", ""], ["Luo", "Weihua", ""], ["Zhou", "Guodong", ""]]}, {"id": "1711.11310", "submitter": "Bing Liu", "authors": "Bing Liu, Ian Lane", "title": "Multi-Domain Adversarial Learning for Slot Filling in Spoken Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to learn cross-domain representations for slot\nfilling task in spoken language understanding (SLU). Most of the recently\npublished SLU models are domain-specific ones that work on individual task\ndomains. Annotating data for each individual task domain is both financially\ncostly and non-scalable. In this work, we propose an adversarial training\nmethod in learning common features and representations that can be shared\nacross multiple domains. Model that produces such shared representations can be\ncombined with models trained on individual domain SLU data to reduce the amount\nof training samples required for developing a new domain. In our experiments\nusing data sets from multiple domains, we show that adversarial training helps\nin learning better domain-general SLU models, leading to improved slot filling\nF1 scores. We further show that applying adversarial learning on domain-general\nmodel also helps in achieving higher slot filling performance when the model is\njointly optimized with domain-specific models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 10:37:56 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Liu", "Bing", ""], ["Lane", "Ian", ""]]}, {"id": "1711.11383", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, Jaap Kamps", "title": "Learning to Learn from Weak Supervision by Full Supervision", "comments": "Accepted at NIPS Workshop on Meta-Learning (MetaLearn 2017), Long\n  Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method for training neural networks when we have\na large set of data with weak labels and a small amount of data with true\nlabels. In our proposed model, we train two neural networks: a target network,\nthe learner and a confidence network, the meta-learner. The target network is\noptimized to perform a given task and is trained using a large set of unlabeled\ndata that are weakly annotated. We propose to control the magnitude of the\ngradient updates to the target network using the scores provided by the second\nconfidence network, which is trained on a small amount of supervised data. Thus\nwe avoid that the weight updates computed from noisy labels harm the quality of\nthe target network model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 13:32:45 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Severyn", "Aliaksei", ""], ["Rothe", "Sascha", ""], ["Kamps", "Jaap", ""]]}, {"id": "1711.11486", "submitter": "Pawe{\\l} Budzianowski", "authors": "Christopher Tegho, Pawe{\\l} Budzianowski, Milica Ga\\v{s}i\\'c", "title": "Uncertainty Estimates for Efficient Neural Network-based Dialogue Policy\n  Optimisation", "comments": "Accepted at the Bayesian Deep Learning Workshop, 31st Conference on\n  Neural Information Processing Systems (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical dialogue management, the dialogue manager learns a policy that\nmaps a belief state to an action for the system to perform. Efficient\nexploration is key to successful policy optimisation. Current deep\nreinforcement learning methods are very promising but rely on epsilon-greedy\nexploration, thus subjecting the user to a random choice of action during\nlearning. Alternative approaches such as Gaussian Process SARSA (GPSARSA)\nestimate uncertainties and are sample efficient, leading to better user\nexperience, but on the expense of a greater computational complexity. This\npaper examines approaches to extract uncertainty estimates from deep Q-networks\n(DQN) in the context of dialogue management. We perform an extensive benchmark\nof deep Bayesian methods to extract uncertainty estimates, namely\nBayes-By-Backprop, dropout, its concrete variation, bootstrapped ensemble and\nalpha-divergences, combining it with DQN algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:09:02 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Tegho", "Christopher", ""], ["Budzianowski", "Pawe\u0142", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1711.11508", "submitter": "Ming Liu", "authors": "Ming Liu, Bo Lang, and Zepeng Gu", "title": "Calculating Semantic Similarity between Academic Articles using Topic\n  Event and Ontology", "comments": "21 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining semantic similarity between academic documents is crucial to many\ntasks such as plagiarism detection, automatic technical survey and semantic\nsearch. Current studies mostly focus on semantic similarity between concepts,\nsentences and short text fragments. However, document-level semantic matching\nis still based on statistical information in surface level, neglecting article\nstructures and global semantic meanings, which may cause the deviation in\ndocument understanding. In this paper, we focus on the document-level semantic\nsimilarity issue for academic literatures with a novel method. We represent\nacademic articles with topic events that utilize multiple information profiles,\nsuch as research purposes, methodologies and domains to integrally describe the\nresearch work, and calculate the similarity between topic events based on the\ndomain ontology to acquire the semantic similarity between articles.\nExperiments show that our approach achieves significant performance compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 16:58:46 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Liu", "Ming", ""], ["Lang", "Bo", ""], ["Gu", "Zepeng", ""]]}, {"id": "1711.11513", "submitter": "Gijs Wijnholds", "authors": "Michael Moortgat and Gijs Wijnholds", "title": "Lexical and Derivational Meaning in Vector-Based Models of\n  Relativisation", "comments": "10 page version to appear in Proceedings Amsterdam Colloquium,\n  updated with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sadrzadeh et al (2013) present a compositional distributional analysis of\nrelative clauses in English in terms of the Frobenius algebraic structure of\nfinite dimensional vector spaces. The analysis relies on distinct type\nassignments and lexical recipes for subject vs object relativisation. The\nsituation for Dutch is different: because of the verb final nature of Dutch,\nrelative clauses are ambiguous between a subject vs object relativisation\nreading. Using an extended version of Lambek calculus, we present a\ncompositional distributional framework that accounts for this derivational\nambiguity, and that allows us to give a single meaning recipe for the relative\npronoun reconciling the Frobenius semantics with the demands of Dutch\nderivational syntax.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 17:02:52 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 17:47:18 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Moortgat", "Michael", ""], ["Wijnholds", "Gijs", ""]]}, {"id": "1711.11543", "submitter": "Abhishek Das", "authors": "Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh,\n  Dhruv Batra", "title": "Embodied Question Answering", "comments": "20 pages, 13 figures, Webpage: https://embodiedqa.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where\nan agent is spawned at a random location in a 3D environment and asked a\nquestion (\"What color is the car?\"). In order to answer, the agent must first\nintelligently navigate to explore the environment, gather information through\nfirst-person (egocentric) vision, and then answer the question (\"orange\").\n  This challenging task requires a range of AI skills -- active perception,\nlanguage understanding, goal-driven navigation, commonsense reasoning, and\ngrounding of language into actions. In this work, we develop the environments,\nend-to-end-trained reinforcement learning agents, and evaluation protocols for\nEmbodiedQA.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 18:06:47 GMT"}, {"version": "v2", "created": "Fri, 1 Dec 2017 16:55:05 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Das", "Abhishek", ""], ["Datta", "Samyak", ""], ["Gkioxari", "Georgia", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}]