[{"id": "0901.2216", "submitter": "Animesh Mukherjee", "authors": "Animesh Mukherjee, Monojit Choudhury and Ravi Kannan", "title": "Discovering Global Patterns in Linguistic Networks through Spectral\n  Analysis: A Case Study of the Consonant Inventories", "comments": "In the proceedings of EACL 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that language and the socio-cognitive phenomena\nassociated with it can be aptly modeled and visualized through networks of\nlinguistic entities. However, most of the existing works on linguistic networks\nfocus only on the local properties of the networks. This study is an attempt to\nanalyze the structure of languages via a purely structural technique, namely\nspectral analysis, which is ideally suited for discovering the global\ncorrelations in a network. Application of this technique to PhoNet, the\nco-occurrence network of consonants, not only reveals several natural\nlinguistic principles governing the structure of the consonant inventories, but\nis also able to quantify their relative importance. We believe that this\npowerful technique can be successfully applied, in general, to study the\nstructure of natural languages.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2009 10:22:28 GMT"}], "update_date": "2009-01-18", "authors_parsed": [["Mukherjee", "Animesh", ""], ["Choudhury", "Monojit", ""], ["Kannan", "Ravi", ""]]}, {"id": "0901.2349", "submitter": "Eduardo G. Altmann", "authors": "Eduardo G. Altmann, Janet B. Pierrehumbert, and Adilson E. Motter", "title": "Beyond word frequency: Bursts, lulls, and scaling in the temporal\n  distributions of words", "comments": null, "journal-ref": "PLoS ONE 4 (11): e7678 (2009)", "doi": "10.1371/journal.pone.0007678", "report-no": null, "categories": "cs.CL cond-mat.dis-nn physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Zipf's discovery that word frequency distributions obey a power\nlaw established parallels between biological and physical processes, and\nlanguage, laying the groundwork for a complex systems perspective on human\ncommunication. More recent research has also identified scaling regularities in\nthe dynamics underlying the successive occurrences of events, suggesting the\npossibility of similar findings for language as well.\n  Methodology/Principal Findings: By considering frequent words in USENET\ndiscussion groups and in disparate databases where the language has different\nlevels of formality, here we show that the distributions of distances between\nsuccessive occurrences of the same word display bursty deviations from a\nPoisson process and are well characterized by a stretched exponential (Weibull)\nscaling. The extent of this deviation depends strongly on semantic type -- a\nmeasure of the logicality of each word -- and less strongly on frequency. We\ndevelop a generative model of this behavior that fully determines the dynamics\nof word usage.\n  Conclusions/Significance: Recurrence patterns of words are well described by\na stretched exponential distribution of recurrence times, an empirical scaling\nthat cannot be anticipated from Zipf's law. Because the use of words provides a\nuniquely precise and powerful lens on human thought and activity, our findings\nalso have implications for other overt manifestations of collective human\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2009 21:12:12 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2009 16:07:23 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Altmann", "Eduardo G.", ""], ["Pierrehumbert", "Janet B.", ""], ["Motter", "Adilson E.", ""]]}, {"id": "0901.2924", "submitter": "Alvaro Corral", "authors": "Alvaro Corral (1), Ramon Ferrer-i-Cancho (2), Gemma Boleda (2), Albert\n  Diaz-Guilera (3). ((1) Centre de Recerca Matematica, (2) U Politecnica\n  Catalunya, (3) U Barcelona)", "title": "Universal Complex Structures in Written Language", "comments": "Short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative linguistics has provided us with a number of empirical laws that\ncharacterise the evolution of languages and competition amongst them. In terms\nof language usage, one of the most influential results is Zipf's law of word\nfrequencies. Zipf's law appears to be universal, and may not even be unique to\nhuman language. However, there is ongoing controversy over whether Zipf's law\nis a good indicator of complexity. Here we present an alternative approach that\nputs Zipf's law in the context of critical phenomena (the cornerstone of\ncomplexity in physics) and establishes the presence of a large scale\n\"attraction\" between successive repetitions of words. Moreover, this phenomenon\nis scale-invariant and universal -- the pattern is independent of word\nfrequency and is observed in texts by different authors and written in\ndifferent languages. There is evidence, however, that the shape of the scaling\nrelation changes for words that play a key role in the text, implying the\nexistence of different \"universality classes\" in the repetition of words. These\nbehaviours exhibit striking parallels with complex catastrophic phenomena.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 21:19:55 GMT"}], "update_date": "2009-01-21", "authors_parsed": [["Corral", "Alvaro", ""], ["Ferrer-i-Cancho", "Ramon", ""], ["Boleda", "Gemma", ""], ["Diaz-Guilera", "Albert", ""], [".", "", ""]]}, {"id": "0901.3017", "submitter": "Ronojoy Adhikari", "authors": "Nisha Yadav, Hrishikesh Joglekar, Rajesh P. N. Rao, M. N. Vahia,\n  Iravatham Mahadevan and R. Adhikari", "title": "Statistical analysis of the Indus script using $n$-grams", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0009506", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Indus script is one of the major undeciphered scripts of the ancient\nworld. The small size of the corpus, the absence of bilingual texts, and the\nlack of definite knowledge of the underlying language has frustrated efforts at\ndecipherment since the discovery of the remains of the Indus civilisation.\nRecently, some researchers have questioned the premise that the Indus script\nencodes spoken language. Building on previous statistical approaches, we apply\nthe tools of statistical language processing, specifically $n$-gram Markov\nchains, to analyse the Indus script for syntax. Our main results are that the\nscript has well-defined signs which begin and end texts, that there is\ndirectionality and strong correlations in the sign order, and that there are\ngroups of signs which appear to have identical syntactic function. All these\nrequire no {\\it a priori} suppositions regarding the syntactic or semantic\ncontent of the signs, but follow directly from the statistical analysis. Using\ninformation theoretic measures, we find the information in the script to be\nintermediate between that of a completely random and a completely fixed\nordering of signs. Our study reveals that the Indus script is a structured sign\nsystem showing features of a formal language, but, at present, cannot\nconclusively establish that it encodes {\\it natural} language. Our $n$-gram\nMarkov model is useful for predicting signs which are missing or illegible in a\ncorpus of Indus texts. This work forms the basis for the development of a\nstochastic grammar which can be used to explore the syntax of the Indus script\nin greater detail.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2009 12:55:55 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Yadav", "Nisha", ""], ["Joglekar", "Hrishikesh", ""], ["Rao", "Rajesh P. N.", ""], ["Vahia", "M. N.", ""], ["Mahadevan", "Iravatham", ""], ["Adhikari", "R.", ""]]}, {"id": "0901.3291", "submitter": "Jaroslaw Kwapien", "authors": "Stanislaw Drozdz, Jaroslaw Kwapien, Adam Orczyk", "title": "Approaching the linguistic complexity", "comments": "to be published in conference proceedings", "journal-ref": "Complex Sciences, Lect. Notes ICST vol.4, 1044-1050 (Springer,\n  2009)", "doi": "10.1007/978-3-642-02466-5_104", "report-no": null, "categories": "cs.CL physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the rank-frequency distributions of words in selected English and\nPolish texts. We compare scaling properties of these distributions in both\nlanguages. We also study a few small corpora of Polish literary texts and find\nthat for a corpus consisting of texts written by different authors the basic\nscaling regime is broken more strongly than in the case of comparable corpus\nconsisting of texts written by the same author. Similarly, for a corpus\nconsisting of texts translated into Polish from other languages the scaling\nregime is broken more strongly than for a comparable corpus of native Polish\ntexts. Moreover, based on the British National Corpus, we consider the\nrank-frequency distributions of the grammatically basic forms of words (lemmas)\ntagged with their proper part of speech. We find that these distributions do\nnot scale if each part of speech is analyzed separately. The only part of\nspeech that independently develops a trace of scaling is verbs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jan 2009 15:24:59 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Drozdz", "Stanislaw", ""], ["Kwapien", "Jaroslaw", ""], ["Orczyk", "Adam", ""]]}, {"id": "0901.3990", "submitter": "Bernard Jacquemin", "authors": "Bernard Jacquemin (LIMSI), Sabine Ploux (L2C2)", "title": "Du corpus au dictionnaire", "comments": null, "journal-ref": "Cahiers de Linguistique. Revue de sociolinguistique et de\n  sociologie de la langue fran\\c{c}aise 33, 1 (2008) 63-84", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose an automatic process to build multi-lingual\nlexico-semantic resources. The goal of these resources is to browse\nsemantically textual information contained in texts of different languages.\nThis method uses a mathematical model called Atlas s\\'emantiques in order to\nrepresent the different senses of each word. It uses the linguistic relations\nbetween words to create graphs that are projected into a semantic space. These\nprojections constitute semantic maps that denote the sense trends of each given\nword. This model is fed with syntactic relations between words extracted from a\ncorpus. Therefore, the lexico-semantic resource produced describes all the\nwords and all their meanings observed in the corpus. The sense trends are\nexpressed by syntactic contexts, typical for a given meaning. The link between\neach sense trend and the utterances used to build the sense trend are also\nstored in an index. Thus all the instances of a word in a particular sense are\nlinked and can be browsed easily. And by using several corpora of different\nlanguages, several resources are built that correspond with each other through\nlanguages. It makes it possible to browse information through languages thanks\nto syntactic contexts translations (even if some of them are partial).\n", "versions": [{"version": "v1", "created": "Mon, 26 Jan 2009 15:52:21 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Jacquemin", "Bernard", "", "LIMSI"], ["Ploux", "Sabine", "", "L2C2"]]}, {"id": "0901.4180", "submitter": "Bj{\\o}rn Kjos-Hanssen", "authors": "Bj{\\o}rn Kjos-Hanssen and Alberto J. Evangelista", "title": "Google distance between words", "comments": "Presented at Frontiers in Undergraduate Research, University of\n  Connecticut, 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cilibrasi and Vitanyi have demonstrated that it is possible to extract the\nmeaning of words from the world-wide web. To achieve this, they rely on the\nnumber of webpages that are found through a Google search containing a given\nword and they associate the page count to the probability that the word appears\non a webpage. Thus, conditional probabilities allow them to correlate one word\nwith another word's meaning. Furthermore, they have developed a similarity\ndistance function that gauges how closely related a pair of words is. We\npresent a specific counterexample to the triangle inequality for this\nsimilarity distance function.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 06:29:10 GMT"}, {"version": "v2", "created": "Wed, 28 Jan 2015 20:10:34 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Kjos-Hanssen", "Bj\u00f8rn", ""], ["Evangelista", "Alberto J.", ""]]}, {"id": "0901.4375", "submitter": "Peter Bruza", "authors": "P.D. Bruza, K. Kitto, D. Nelson, C. McEvoy", "title": "Extracting Spooky-activation-at-a-distance from Considerations of\n  Entanglement", "comments": "13 pages, 2 figures; To appear in Proceedings of the Third Quantum\n  Interaction Symposium, Lecture Notes in Artificial Intelligence, vol 5494,\n  Springer, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following an early claim by Nelson & McEvoy \\cite{Nelson:McEvoy:2007}\nsuggesting that word associations can display `spooky action at a distance\nbehaviour', a serious investigation of the potentially quantum nature of such\nassociations is currently underway. This paper presents a simple quantum model\nof a word association system. It is shown that a quantum model of word\nentanglement can recover aspects of both the Spreading Activation equation and\nthe Spooky-activation-at-a-distance equation, both of which are used to model\nthe activation level of words in human memory.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jan 2009 23:59:59 GMT"}], "update_date": "2009-01-29", "authors_parsed": [["Bruza", "P. D.", ""], ["Kitto", "K.", ""], ["Nelson", "D.", ""], ["McEvoy", "C.", ""]]}, {"id": "0901.4784", "submitter": "Fabio G. Guerrero Moreno", "authors": "Fabio G. Guerrero", "title": "On the Entropy of Written Spanish", "comments": "Submitted to the IEEE Transactions on Information Theory", "journal-ref": "Revista Colombiana de Estadistica (RCE), Vol. 35, No. 3, Dec.\n  2012, pp 423-440", "doi": null, "report-no": null, "categories": "cs.CL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on results on the entropy of the Spanish language. They\nare based on an analysis of natural language for n-word symbols (n = 1 to 18),\ntrigrams, digrams, and characters. The results obtained in this work are based\non the analysis of twelve different literary works in Spanish, as well as a\n279917 word news file provided by the Spanish press agency EFE. Entropy values\nare calculated by a direct method using computer processing and the probability\nlaw of large numbers. Three samples of artificial Spanish language produced by\na first-order model software source are also analyzed and compared with natural\nSpanish language.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2009 03:46:01 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Guerrero", "Fabio G.", ""]]}]