[{"id": "2011.00033", "submitter": "Xutai Ma", "authors": "Xutai Ma, Yongqiang Wang, Mohammad Javad Dousti, Philipp Koehn, Juan\n  Pino", "title": "Streaming Simultaneous Speech Translation with Augmented Memory\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have achieved state-of-the-art performance on speech\ntranslation tasks. However, the model architecture is not efficient enough for\nstreaming scenarios since self-attention is computed over an entire input\nsequence and the computational cost grows quadratically with the length of the\ninput sequence. Nevertheless, most of the previous work on simultaneous speech\ntranslation, the task of generating translations from partial audio input,\nignores the time spent in generating the translation when analyzing the\nlatency. With this assumption, a system may have good latency quality\ntrade-offs but be inapplicable in real-time scenarios. In this paper, we focus\non the task of streaming simultaneous speech translation, where the systems are\nnot only capable of translating with partial input but are also able to handle\nvery long or continuous input. We propose an end-to-end transformer-based\nsequence-to-sequence model, equipped with an augmented memory transformer\nencoder, which has shown great success on the streaming automatic speech\nrecognition task with hybrid or transducer-based models. We conduct an\nempirical evaluation of the proposed model on segment, context and memory sizes\nand we compare our approach to a transformer with a unidirectional mask.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:28:42 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ma", "Xutai", ""], ["Wang", "Yongqiang", ""], ["Dousti", "Mohammad Javad", ""], ["Koehn", "Philipp", ""], ["Pino", "Juan", ""]]}, {"id": "2011.00057", "submitter": "Nishant Raj", "authors": "Harshit Jain and Nishant Raj and Suyash Mishra", "title": "A Sui Generis QA Approach using RoBERTa for Adverse Drug Event\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extraction of adverse drug events from biomedical literature and other\ntextual data is an important component to monitor drug-safety and this has\nattracted attention of many researchers in healthcare. Existing works are more\npivoted around entity-relation extraction using bidirectional long short term\nmemory networks (Bi-LSTM) which does not attain the best feature\nrepresentations. In this paper, we introduce a question answering framework\nthat exploits the robustness, masking and dynamic attention capabilities of\nRoBERTa by a technique of domain adaptation and attempt to overcome the\naforementioned limitations. Our model outperforms the prior work by 9.53%\nF1-Score.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 19:09:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Jain", "Harshit", ""], ["Raj", "Nishant", ""], ["Mishra", "Suyash", ""]]}, {"id": "2011.00061", "submitter": "Marzieh Fadaee", "authors": "Marzieh Fadaee, Olga Gureenkova, Fernando Rejon Barrera, Carsten\n  Schnober, Wouter Weerkamp, Jakub Zavrel", "title": "A New Neural Search and Insights Platform for Navigating and Organizing\n  AI Research", "comments": "Accepted to Workshop on Scholarly Document Processing (SDP) at EMNLP\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide AI researchers with modern tools for dealing with the explosive\ngrowth of the research literature in their field, we introduce a new platform,\nAI Research Navigator, that combines classical keyword search with neural\nretrieval to discover and organize relevant literature. The system provides\nsearch at multiple levels of textual granularity, from sentences to\naggregations across documents, both in natural language and through navigation\nin a domain-specific Knowledge Graph. We give an overview of the overall\narchitecture of the system and of the components for document analysis,\nquestion answering, search, analytics, expert search, and recommendations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 19:12:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fadaee", "Marzieh", ""], ["Gureenkova", "Olga", ""], ["Barrera", "Fernando Rejon", ""], ["Schnober", "Carsten", ""], ["Weerkamp", "Wouter", ""], ["Zavrel", "Jakub", ""]]}, {"id": "2011.00080", "submitter": "John Lalor", "authors": "John P. Lalor and Hong Yu", "title": "Dynamic Data Selection for Curriculum Learning via Ability Estimation", "comments": "Findings of EMNLP 2020, presented at CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Curriculum learning methods typically rely on heuristics to estimate the\ndifficulty of training examples or the ability of the model. In this work, we\npropose replacing difficulty heuristics with learned difficulty parameters. We\nalso propose Dynamic Data selection for Curriculum Learning via Ability\nEstimation (DDaCLAE), a strategy that probes model ability at each training\nepoch to select the best training examples at that point. We show that models\nusing learned difficulty and/or ability outperform heuristic-based curriculum\nlearning models on the GLUE classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:01:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lalor", "John P.", ""], ["Yu", "Hong", ""]]}, {"id": "2011.00091", "submitter": "Aswin Shanmugam Subramanian", "authors": "Aswin Shanmugam Subramanian, Chao Weng, Shinji Watanabe, Meng Yu, Yong\n  Xu, Shi-Xiong Zhang, Dong Yu", "title": "Directional ASR: A New Paradigm for E2E Multi-Speaker Speech Recognition\n  with Source Localization", "comments": "submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new paradigm for handling far-field multi-speaker data\nin an end-to-end neural network manner, called directional automatic speech\nrecognition (D-ASR), which explicitly models source speaker locations. In\nD-ASR, the azimuth angle of the sources with respect to the microphone array is\ndefined as a latent variable. This angle controls the quality of separation,\nwhich in turn determines the ASR performance. All three functionalities of\nD-ASR: localization, separation, and recognition are connected as a single\ndifferentiable neural network and trained solely based on ASR error\nminimization objectives. The advantages of D-ASR over existing methods are\nthreefold: (1) it provides explicit speaker locations, (2) it improves the\nexplainability factor, and (3) it achieves better ASR performance as the\nprocess is more streamlined. In addition, D-ASR does not require explicit\ndirection of arrival (DOA) supervision like existing data-driven localization\nmodels, which makes it more appropriate for realistic data. For the case of two\nsource mixtures, D-ASR achieves an average DOA prediction error of less than\nthree degrees. It also outperforms a strong far-field multi-speaker end-to-end\nsystem in both separation quality and ASR performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:26:28 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Subramanian", "Aswin Shanmugam", ""], ["Weng", "Chao", ""], ["Watanabe", "Shinji", ""], ["Yu", "Meng", ""], ["Xu", "Yong", ""], ["Zhang", "Shi-Xiong", ""], ["Yu", "Dong", ""]]}, {"id": "2011.00092", "submitter": "Dhruvil Gala", "authors": "Dhruvil Gala, Mohammad Omar Khursheed, Hannah Lerner, Brendan\n  O'Connor, Mohit Iyyer", "title": "Analyzing Gender Bias within Narrative Tropes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular media reflects and reinforces societal biases through the use of\ntropes, which are narrative elements, such as archetypal characters and plot\narcs, that occur frequently across media. In this paper, we specifically\ninvestigate gender bias within a large collection of tropes. To enable our\nstudy, we crawl tvtropes.org, an online user-created repository that contains\n30K tropes associated with 1.9M examples of their occurrences across film,\ntelevision, and literature. We automatically score the \"genderedness\" of each\ntrope in our TVTROPES dataset, which enables an analysis of (1) highly-gendered\ntopics within tropes, (2) the relationship between gender bias and popular\nreception, and (3) how the gender of a work's creator correlates with the types\nof tropes that they use.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:26:41 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Gala", "Dhruvil", ""], ["Khursheed", "Mohammad Omar", ""], ["Lerner", "Hannah", ""], ["O'Connor", "Brendan", ""], ["Iyyer", "Mohit", ""]]}, {"id": "2011.00093", "submitter": "Chaitanya Talnikar", "authors": "Chaitanya Talnikar, Tatiana Likhomanenko, Ronan Collobert, Gabriel\n  Synnaeve", "title": "Joint Masked CPC and CTC Training for ASR", "comments": "ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning (SSL) has shown promise in learning representations\nof audio that are useful for automatic speech recognition (ASR). But, training\nSSL models like wav2vec~2.0 requires a two-stage pipeline. In this paper we\ndemonstrate a single-stage training of ASR models that can utilize both\nunlabeled and labeled data. During training, we alternately minimize two\nlosses: an unsupervised masked Contrastive Predictive Coding (CPC) loss and the\nsupervised audio-to-text alignment loss Connectionist Temporal Classification\n(CTC). We show that this joint training method directly optimizes performance\nfor the downstream ASR task using unsupervised data while achieving similar\nword error rates to wav2vec~2.0 on the Librispeech 100-hour dataset. Finally,\nwe postulate that solving the contrastive task is a regularization for the\nsupervised CTC loss.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:28:20 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 18:59:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Talnikar", "Chaitanya", ""], ["Likhomanenko", "Tatiana", ""], ["Collobert", "Ronan", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "2011.00105", "submitter": "Kun Qian", "authors": "Kun Qian, Poornima Chozhiyath Raman, Yunyao Li, Lucian Popa", "title": "Learning Structured Representations of Entity Names using Active\n  Learning and Weak Supervision", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured representations of entity names are useful for many entity-related\ntasks such as entity normalization and variant generation. Learning the\nimplicit structured representations of entity names without context and\nexternal knowledge is particularly challenging. In this paper, we present a\nnovel learning framework that combines active learning and weak supervision to\nsolve this problem. Our experimental evaluation show that this framework\nenables the learning of high-quality models from merely a dozen or so labeled\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 21:01:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Qian", "Kun", ""], ["Raman", "Poornima Chozhiyath", ""], ["Li", "Yunyao", ""], ["Popa", "Lucian", ""]]}, {"id": "2011.00109", "submitter": "Houcemeddine Turki", "authors": "Houcemeddine Turki, Mohamed Ali Hadj Taieb, Mohamed Ben Aouicha", "title": "Semantic similarity-based approach to enhance supervised classification\n  learning accuracy", "comments": "Sent for review to Journal of the Association for Information Science\n  and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This brief communication discusses the usefulness of semantic similarity\nmeasures for the evaluation and amelioration of the accuracy of supervised\nclassification learning. It proposes a semantic similarity-based method to\nenhance the choice of adequate labels for the classification algorithm as well\nas two metrics (SS-Score and TD-Score) and a curve (SA-Curve) that can be\ncoupled to statistical evaluation measures of supervised classification\nlearning to take into consideration the impact of the semantic aspect of the\nlabels on the classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 21:18:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Turki", "Houcemeddine", ""], ["Taieb", "Mohamed Ali Hadj", ""], ["Aouicha", "Mohamed Ben", ""]]}, {"id": "2011.00136", "submitter": "Nathan Ng", "authors": "Nathan Ng and Marzyeh Ghassemi and Narendran Thangarajan and Jiacheng\n  Pan and Qi Guo", "title": "Improving Dialogue Breakdown Detection with Semi-Supervised Learning", "comments": "6 pages, 1 figure, accepted at the NeurIPS Workshop on Human in the\n  Loop Dialogue Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building user trust in dialogue agents requires smooth and consistent\ndialogue exchanges. However, agents can easily lose conversational context and\ngenerate irrelevant utterances. These situations are called dialogue breakdown,\nwhere agent utterances prevent users from continuing the conversation. Building\nsystems to detect dialogue breakdown allows agents to recover appropriately or\navoid breakdown entirely. In this paper we investigate the use of\nsemi-supervised learning methods to improve dialogue breakdown detection,\nincluding continued pre-training on the Reddit dataset and a manifold-based\ndata augmentation method. We demonstrate the effectiveness of these methods on\nthe Dialogue Breakdown Detection Challenge (DBDC) English shared task. Our\nsubmissions to the 2020 DBDC5 shared task place first, beating baselines and\nother submissions by over 12\\% accuracy. In ablations on DBDC4 data from 2019,\nour semi-supervised learning methods improve the performance of a baseline BERT\nmodel by 2\\% accuracy. These methods are applicable generally to any dialogue\ntask and provide a simple way to improve model performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 23:04:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ng", "Nathan", ""], ["Ghassemi", "Marzyeh", ""], ["Thangarajan", "Narendran", ""], ["Pan", "Jiacheng", ""], ["Guo", "Qi", ""]]}, {"id": "2011.00169", "submitter": "Hu Xu", "authors": "Hu Xu, Lei Shu, Philip S. Yu, Bing Liu", "title": "Understanding Pre-trained BERT for Aspect-based Sentiment Analysis", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the pre-trained hidden representations learned from\nreviews on BERT for tasks in aspect-based sentiment analysis (ABSA). Our work\nis motivated by the recent progress in BERT-based language models for ABSA.\nHowever, it is not clear how the general proxy task of (masked) language model\ntrained on unlabeled corpus without annotations of aspects or opinions can\nprovide important features for downstream tasks in ABSA. By leveraging the\nannotated datasets in ABSA, we investigate both the attentions and the learned\nrepresentations of BERT pre-trained on reviews. We found that BERT uses very\nfew self-attention heads to encode context words (such as prepositions or\npronouns that indicating an aspect) and opinion words for an aspect. Most\nfeatures in the representation of an aspect are dedicated to the fine-grained\nsemantics of the domain (or product category) and the aspect itself, instead of\ncarrying summarized opinions from its context. We hope this investigation can\nhelp future research in improving self-supervised learning, unsupervised\nlearning and fine-tuning for ABSA. The pre-trained model and code can be found\nat https://github.com/howardhsu/BERT-for-RRC-ABSA.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:21:43 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xu", "Hu", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""], ["Liu", "Bing", ""]]}, {"id": "2011.00192", "submitter": "Zitao Liu", "authors": "Haochen Liu, Zitao Liu, Zhongqin Wu, Jiliang Tang", "title": "Personalized Multimodal Feedback Generation in Education", "comments": "Accepted in The 28th International Conference on Computational\n  Linguistics (COLING 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic evaluation for school assignments is an important application\nof AI in the education field. In this work, we focus on the task of\npersonalized multimodal feedback generation, which aims to generate\npersonalized feedback for various teachers to evaluate students' assignments\ninvolving multimodal inputs such as images, audios, and texts. This task\ninvolves the representation and fusion of multimodal information and natural\nlanguage generation, which presents the challenges from three aspects: 1) how\nto encode and integrate multimodal inputs; 2) how to generate feedback specific\nto each modality; and 3) how to realize personalized feedback generation. In\nthis paper, we propose a novel Personalized Multimodal Feedback Generation\nNetwork (PMFGN) armed with a modality gate mechanism and a personalized bias\nmechanism to address these challenges. The extensive experiments on real-world\nK-12 education data show that our model significantly outperforms several\nbaselines by generating more accurate and diverse feedback. In addition,\ndetailed ablation experiments are conducted to deepen our understanding of the\nproposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 05:26:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Haochen", ""], ["Liu", "Zitao", ""], ["Wu", "Zhongqin", ""], ["Tang", "Jiliang", ""]]}, {"id": "2011.00200", "submitter": "Xu Xiang", "authors": "Xu Xiang", "title": "The xx205 System for the VoxCeleb Speaker Recognition Challenge 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes the systems submitted to the first and second tracks of\nthe VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020, which ranked second\nin both tracks. Three key points of the system pipeline are explored: (1)\ninvestigating multiple CNN architectures including ResNet, Res2Net and dual\npath network (DPN) to extract the x-vectors, (2) using a composite angular\nmargin softmax loss to train the speaker models, and (3) applying score\nnormalization and system fusion to boost the performance. Measured on the\nVoxSRC-20 Eval set, the best submitted systems achieve an EER of $3.808\\%$ and\na MinDCF of $0.1958$ in the close-condition track 1, and an EER of $3.798\\%$\nand a MinDCF of $0.1942$ in the open-condition track 2, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 06:36:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xiang", "Xu", ""]]}, {"id": "2011.00244", "submitter": "Rodrigo Alejandro Ch\\'avez Mulsa", "authors": "Rodrigo Alejandro Ch\\'avez Mulsa and Gerasimos Spanakis", "title": "Evaluating Bias In Dutch Word Embeddings", "comments": "Accepted at GeBNLP 2020, data at\n  https://github.com/Noixas/Official-Evaluating-Bias-In-Dutch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in Natural Language Processing has revealed that word\nembeddings can encode social biases present in the training data which can\naffect minorities in real world applications. This paper explores the gender\nbias implicit in Dutch embeddings while investigating whether English language\nbased approaches can also be used in Dutch. We implement the Word Embeddings\nAssociation Test (WEAT), Clustering and Sentence Embeddings Association Test\n(SEAT) methods to quantify the gender bias in Dutch word embeddings, then we\nproceed to reduce the bias with Hard-Debias and Sent-Debias mitigation methods\nand finally we evaluate the performance of the debiased embeddings in\ndownstream tasks. The results suggest that, among others, gender bias is\npresent in traditional and contextualized Dutch word embeddings. We highlight\nhow techniques used to measure and reduce bias created for English can be used\nin Dutch embeddings by adequately translating the data and taking into account\nthe unique characteristics of the language. Furthermore, we analyze the effect\nof the debiasing techniques on downstream tasks which show a negligible impact\non traditional embeddings and a 2% decrease in performance in contextualized\nembeddings. Finally, we release the translated Dutch datasets to the public\nalong with the traditional embeddings with mitigated bias.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 11:14:16 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:34:44 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mulsa", "Rodrigo Alejandro Ch\u00e1vez", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "2011.00245", "submitter": "Juntao Yu", "authors": "Juntao Yu, Nafise Sadat Moosavi, Silviu Paun and Massimo Poesio", "title": "Free the Plural: Unrestricted Split-Antecedent Anaphora Resolution", "comments": "accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Now that the performance of coreference resolvers on the simpler forms of\nanaphoric reference has greatly improved, more attention is devoted to more\ncomplex aspects of anaphora. One limitation of virtually all coreference\nresolution models is the focus on single-antecedent anaphors. Plural anaphors\nwith multiple antecedents-so-called split-antecedent anaphors (as in John met\nMary. They went to the movies) have not been widely studied, because they are\nnot annotated in ONTONOTES and are relatively infrequent in other corpora. In\nthis paper, we introduce the first model for unrestricted resolution of\nsplit-antecedent anaphors. We start with a strong baseline enhanced by BERT\nembeddings, and show that we can substantially improve its performance by\naddressing the sparsity issue. To do this, we experiment with auxiliary corpora\nwhere split-antecedent anaphors were annotated by the crowd, and with transfer\nlearning models using element-of bridging references and single-antecedent\ncoreference as auxiliary tasks. Evaluation on the gold annotated ARRAU corpus\nshows that the out best model uses a combination of three auxiliary corpora\nachieved F1 scores of 70% and 43.6% when evaluated in a lenient and strict\nsetting, respectively, i.e., 11 and 21 percentage points gain when compared\nwith our baseline.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 11:21:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yu", "Juntao", ""], ["Moosavi", "Nafise Sadat", ""], ["Paun", "Silviu", ""], ["Poesio", "Massimo", ""]]}, {"id": "2011.00259", "submitter": "Yudianto Sujana", "authors": "Yudianto Sujana, Jiawen Li, Hung-Yu Kao", "title": "Rumor Detection on Twitter Using Multiloss Hierarchical BiLSTM with an\n  Attenuation Factor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms such as Twitter have become a breeding ground for\nunverified information or rumors. These rumors can threaten people's health,\nendanger the economy, and affect the stability of a country. Many researchers\nhave developed models to classify rumors using traditional machine learning or\nvanilla deep learning models. However, previous studies on rumor detection have\nachieved low precision and are time consuming. Inspired by the hierarchical\nmodel and multitask learning, a multiloss hierarchical BiLSTM model with an\nattenuation factor is proposed in this paper. The model is divided into two\nBiLSTM modules: post level and event level. By means of this hierarchical\nstructure, the model can extract deep in-formation from limited quantities of\ntext. Each module has a loss function that helps to learn bilateral features\nand reduce the training time. An attenuation fac-tor is added at the post level\nto increase the accuracy. The results on two rumor datasets demonstrate that\nour model achieves better performance than that of state-of-the-art machine\nlearning and vanilla deep learning models.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 12:29:25 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 11:20:30 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Sujana", "Yudianto", ""], ["Li", "Jiawen", ""], ["Kao", "Hung-Yu", ""]]}, {"id": "2011.00286", "submitter": "Juntao Yu", "authors": "Abdulrahman Aloraini, Juntao Yu and Massimo Poesio", "title": "Neural Coreference Resolution for Arabic", "comments": "accepted at CRAC@COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No neural coreference resolver for Arabic exists, in fact we are not aware of\nany learning-based coreference resolver for Arabic since (Bjorkelund and Kuhn,\n2014). In this paper, we introduce a coreference resolution system for Arabic\nbased on Lee et al's end to end architecture combined with the Arabic version\nof bert and an external mention detector. As far as we know, this is the first\nneural coreference resolution system aimed specifically to Arabic, and it\nsubstantially outperforms the existing state of the art on OntoNotes 5.0 with a\ngain of 15.2 points conll F1. We also discuss the current limitations of the\ntask for Arabic and possible approaches that can tackle these challenges.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 14:34:43 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Aloraini", "Abdulrahman", ""], ["Yu", "Juntao", ""], ["Poesio", "Massimo", ""]]}, {"id": "2011.00310", "submitter": "Artem Kramov", "authors": "S. D. Pogorilyy and A. A. Kramov", "title": "Method of the coherence evaluation of Ukrainian text", "comments": "16 pages, in Ukrainian, 5 figures", "journal-ref": "Data Recording, Storage & Processing. 2018. Vol. 20, Issue 4. P.\n  64-75", "doi": "10.35681/1560-9189.2018", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the growing role of the SEO technologies, it is necessary to perform\nan automated analysis of the article's quality. Such approach helps both to\nreturn the most intelligible pages for the user's query and to raise the web\nsites positions to the top of query results. An automated assessment of a\ncoherence is a part of the complex analysis of the text. In this article, main\nmethods for text coherence measurements for Ukrainian language are analyzed.\nExpediency of using the semantic similarity graph method in comparison with\nother methods are explained. It is suggested the improvement of that method by\nthe pre-training of the neural network for vector representations of sentences.\nExperimental examination of the original method and its modifications is made.\nTraining and examination procedures are made on the corpus of Ukrainian texts,\nwhich were previously retrieved from abstracts and full texts of Ukrainian\nscientific articles. The testing procedure is implemented by performing of two\ntypical tasks for the text coherence assessment: document discrimination task\nand insertion task. Accordingly to the analysis it is defined the most\neffective combination of method's modification and its parameter for the\nmeasurement of the text coherence.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 16:48:55 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pogorilyy", "S. D.", ""], ["Kramov", "A. A.", ""]]}, {"id": "2011.00318", "submitter": "Gathika Ratnayaka", "authors": "Gathika Ratnayaka, Nisansa de Silva, Amal Shehan Perera, Ramesh\n  Pathirana", "title": "Effective Approach to Develop a Sentiment Annotator For Legal Domain in\n  a Low Resource Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the sentiments of legal opinions available in Legal Opinion Texts\ncan facilitate several use cases such as legal judgement prediction,\ncontradictory statements identification and party-based sentiment analysis.\nHowever, the task of developing a legal domain specific sentiment annotator is\nchallenging due to resource constraints such as lack of domain specific\nlabelled data and domain expertise. In this study, we propose novel techniques\nthat can be used to develop a sentiment annotator for the legal domain while\nminimizing the need for manual annotations of data.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 17:12:32 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ratnayaka", "Gathika", ""], ["de Silva", "Nisansa", ""], ["Perera", "Amal Shehan", ""], ["Pathirana", "Ramesh", ""]]}, {"id": "2011.00335", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Hila Gonen and Suzanne Stevenson", "title": "Pick a Fight or Bite your Tongue: Investigation of Gender Differences in\n  Idiomatic Language Usage", "comments": "COLING'2020, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of research on gender-linked language has established\nfoundations regarding cross-gender differences in lexical, emotional, and\ntopical preferences, along with their sociological underpinnings. We compile a\nnovel, large and diverse corpus of spontaneous linguistic productions annotated\nwith speakers' gender, and perform a first large-scale empirical study of\ndistinctions in the usage of \\textit{figurative language} between male and\nfemale authors. Our analyses suggest that (1) idiomatic choices reflect\ngender-specific lexical and semantic preferences in general language, (2) men's\nand women's idiomatic usages express higher emotion than their literal\nlanguage, with detectable, albeit more subtle, differences between male and\nfemale authors along the dimension of dominance compared to similar\ndistinctions in their literal utterances, and (3) contextual analysis of\nidiomatic expressions reveals considerable differences, reflecting subtle\ndivergences in usage environments, shaped by cross-gender communication styles\nand semantic biases.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:44:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Rabinovich", "Ella", ""], ["Gonen", "Hila", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "2011.00345", "submitter": "Thomas Kober", "authors": "Thomas Kober and Malihe Alikhani and Matthew Stone and Mark Steedman", "title": "Aspectuality Across Genre: A Distributional Semantics Approach", "comments": "to appear at Coling 2020 in oh so lovely virtual Barcelona :)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretation of the lexical aspect of verbs in English plays a crucial\nrole for recognizing textual entailment and learning discourse-level\ninferences. We show that two elementary dimensions of aspectual class, states\nvs. events, and telic vs. atelic events, can be modelled effectively with\ndistributional semantics. We find that a verb's local context is most\nindicative of its aspectual class, and demonstrate that closed class words tend\nto be stronger discriminating contexts than content words. Our approach\noutperforms previous work on three datasets. Lastly, we contribute a dataset of\nhuman--human conversations annotated with lexical aspect and present\nexperiments that show the correlation of telicity with genre and discourse\ngoals.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 19:37:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kober", "Thomas", ""], ["Alikhani", "Malihe", ""], ["Stone", "Matthew", ""], ["Steedman", "Mark", ""]]}, {"id": "2011.00346", "submitter": "Ahmed Ali", "authors": "Ahmed Ali, Yasser Hifny", "title": "Efficient Arabic emotion recognition using deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition from speech signal based on deep learning is an active\nresearch area. Convolutional neural networks (CNNs) may be the dominant method\nin this area. In this paper, we implement two neural architectures to address\nthis problem. The first architecture is an attention-based CNN-LSTM-DNN model.\nIn this novel architecture, the convolutional layers extract salient features\nand the bi-directional long short-term memory (BLSTM) layers handle the\nsequential phenomena of the speech signal. This is followed by an attention\nlayer, which extracts a summary vector that is fed to the fully connected dense\nlayer (DNN), which finally connects to a softmax output layer. The second\narchitecture is based on a deep CNN model. The results on an Arabic speech\nemotion recognition task show that our innovative approach can lead to\nsignificant improvements (2.2% absolute improvements) over a strong deep CNN\nbaseline system. On the other hand, the deep CNN models are significantly\nfaster than the attention based CNN-LSTM-DNN models in training and\nclassification.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 19:39:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ali", "Ahmed", ""], ["Hifny", "Yasser", ""]]}, {"id": "2011.00387", "submitter": "Kaize Ding", "authors": "Kaize Ding, Jianling Wang, Jundong Li, Dingcheng Li, Huan Liu", "title": "Be More with Less: Hypergraph Attention Networks for Inductive Text\n  Classification", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is a critical research topic with broad applications in\nnatural language processing. Recently, graph neural networks (GNNs) have\nreceived increasing attention in the research community and demonstrated their\npromising results on this canonical task. Despite the success, their\nperformance could be largely jeopardized in practice since they are: (1) unable\nto capture high-order interaction between words; (2) inefficient to handle\nlarge datasets and new documents. To address those issues, in this paper, we\npropose a principled model -- hypergraph attention networks (HyperGAT), which\ncan obtain more expressive power with less computational consumption for text\nrepresentation learning. Extensive experiments on various benchmark datasets\ndemonstrate the efficacy of the proposed approach on the text classification\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 00:21:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ding", "Kaize", ""], ["Wang", "Jianling", ""], ["Li", "Jundong", ""], ["Li", "Dingcheng", ""], ["Liu", "Huan", ""]]}, {"id": "2011.00398", "submitter": "Peng Su", "authors": "Peng Su, K. Vijay-Shanker", "title": "Investigation of BERT Model on Biomedical Relation Extraction Based on\n  Revised Fine-tuning Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of biomedical literature, designing automatic tools\nto extract information from the literature has great significance in biomedical\nresearch. Recently, transformer-based BERT models adapted to the biomedical\ndomain have produced leading results. However, all the existing BERT models for\nrelation classification only utilize partial knowledge from the last layer. In\nthis paper, we will investigate the method of utilizing the entire layer in the\nfine-tuning process of BERT model. To the best of our knowledge, we are the\nfirst to explore this method. The experimental results illustrate that our\nmethod improves the BERT model performance and outperforms the state-of-the-art\nmethods on three benchmark datasets for different relation extraction tasks. In\naddition, further analysis indicates that the key knowledge about the relations\ncan be learned from the last layer of BERT model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 01:47:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Su", "Peng", ""], ["Vijay-Shanker", "K.", ""]]}, {"id": "2011.00403", "submitter": "Yipeng Zhang", "authors": "Minh Tran, Yipeng Zhang, Mohammad Soleymani", "title": "Towards A Friendly Online Community: An Unsupervised Style Transfer\n  Framework for Profanity Redaction", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offensive and abusive language is a pressing problem on social media\nplatforms. In this work, we propose a method for transforming offensive\ncomments, statements containing profanity or offensive language, into\nnon-offensive ones. We design a RETRIEVE, GENERATE and EDIT unsupervised style\ntransfer pipeline to redact the offensive comments in a word-restricted manner\nwhile maintaining a high level of fluency and preserving the content of the\noriginal text. We extensively evaluate our method's performance and compare it\nto previous style transfer models using both automatic metrics and human\nevaluations. Experimental results show that our method outperforms other models\non human evaluations and is the only approach that consistently performs well\non all automatic evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 02:10:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tran", "Minh", ""], ["Zhang", "Yipeng", ""], ["Soleymani", "Mohammad", ""]]}, {"id": "2011.00406", "submitter": "Alexander H. Liu", "authors": "Alexander H. Liu, Yu-An Chung, James Glass", "title": "Non-Autoregressive Predictive Coding for Learning Speech Representations\n  from Local Dependencies", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised speech representations have been shown to be effective in a\nvariety of speech applications. However, existing representation learning\nmethods generally rely on the autoregressive model and/or observed global\ndependencies while generating the representation. In this work, we propose\nNon-Autoregressive Predictive Coding (NPC), a self-supervised method, to learn\na speech representation in a non-autoregressive manner by relying only on local\ndependencies of speech. NPC has a conceptually simple objective and can be\nimplemented easily with the introduced Masked Convolution Blocks. NPC offers a\nsignificant speedup for inference since it is parallelizable in time and has a\nfixed inference time for each time step regardless of the input sequence\nlength. We discuss and verify the effectiveness of NPC by theoretically and\nempirically comparing it with other methods. We show that the NPC\nrepresentation is comparable to other methods in speech experiments on phonetic\nand speaker classification while being more efficient.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 02:48:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Alexander H.", ""], ["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "2011.00416", "submitter": "Zhijing Jin", "authors": "Di Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, Rada Mihalcea", "title": "Deep Learning for Text Style Transfer: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text style transfer (TST) is an important task in natural language generation\n(NLG), which aims to control certain attributes in the generated text, such as\npoliteness, emotion, humor, and many others. It has a long history in the field\nof natural language processing (NLP), and recently has re-gained significant\nattention thanks to the promising performance brought by deep neural models. In\nthis paper, we present a systematic survey of the research on neural text style\ntransfer, spanning over 100 representative articles since the first neural text\nstyle transfer work in 2017. We discuss the task formulation, existing datasets\nand subtasks, evaluation, as well as the rich methodologies in the presence of\nparallel and non-parallel data. We also provide discussions on a variety of\nimportant topics regarding the future development of TST. Our curated paper\nlist is at https://github.com/zhijing-jin/Text_Style_Transfer_Survey\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:04:43 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 14:21:58 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 05:42:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Hu", "Zhiting", ""], ["Vechtomova", "Olga", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2011.00425", "submitter": "Arda Akdemir", "authors": "Arda Akdemir and Tetsuo Shibuya", "title": "Analyzing the Effect of Multi-task Learning for Biomedical Named Entity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing high-performing systems for detecting biomedical named entities\nhas major implications. State-of-the-art deep-learning based solutions for\nentity recognition often require large annotated datasets, which is not\navailable in the biomedical domain. Transfer learning and multi-task learning\nhave been shown to improve performance for low-resource domains. However, the\napplications of these methods are relatively scarce in the biomedical domain,\nand a theoretical understanding of why these methods improve the performance is\nlacking. In this study, we performed an extensive analysis to understand the\ntransferability between different biomedical entity datasets. We found useful\nmeasures to predict transferability between these datasets. Besides, we propose\ncombining transfer learning and multi-task learning to improve the performance\nof biomedical named entity recognition systems, which is not applied before to\nthe best of our knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:52:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Akdemir", "Arda", ""], ["Shibuya", "Tetsuo", ""]]}, {"id": "2011.00449", "submitter": "Suyu Ge", "authors": "Suyu Ge, Lu Cheng, Huan Liu", "title": "Improving Cyberbully Detection with User Interaction", "comments": "The Web Conference 2021", "journal-ref": null, "doi": "10.1145/3442381.3449828", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyberbullying, identified as intended and repeated online bullying behavior,\nhas become increasingly prevalent in the past few decades. Despite the\nsignificant progress made thus far, the focus of most existing work on\ncyberbullying detection lies in the independent content analysis of different\ncomments within a social media session. We argue that such leading notions of\nanalysis suffer from three key limitations: they overlook the temporal\ncorrelations among different comments; they only consider the content within a\nsingle comment rather than the topic coherence across comments; they remain\ngeneric and exploit limited interactions between social media users. In this\nwork, we observe that user comments in the same session may be inherently\nrelated, e.g., discussing similar topics, and their interaction may evolve over\ntime. We also show that modeling such topic coherence and temporal interaction\nare critical to capture the repetitive characteristics of bullying behavior,\nthus leading to better predicting performance. To achieve the goal, we first\nconstruct a unified temporal graph for each social media session. Drawing on\nrecent advances in graph neural network, we then propose a principled\ngraph-based approach for modeling the temporal dynamics and topic coherence\nthroughout user interactions. We empirically evaluate the effectiveness of our\napproach with the tasks of session-level bullying detection and comment-level\ncase study. Our code is released to public.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 08:47:33 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 03:16:57 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Ge", "Suyu", ""], ["Cheng", "Lu", ""], ["Liu", "Huan", ""]]}, {"id": "2011.00452", "submitter": "Hadeel Saadany", "authors": "Hadeel Saadany and Emad Mohamed and Constantin Orasan", "title": "Fake or Real? A Study of Arabic Satirical Fake News", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One very common type of fake news is satire which comes in a form of a news\nwebsite or an online platform that parodies reputable real news agencies to\ncreate a sarcastic version of reality. This type of fake news is often\ndisseminated by individuals on their online platforms as it has a much stronger\neffect in delivering criticism than through a straightforward message. However,\nwhen the satirical text is disseminated via social media without mention of its\nsource, it can be mistaken for real news. This study conducts several\nexploratory analyses to identify the linguistic properties of Arabic fake news\nwith satirical content. We exploit these features to build a number of machine\nlearning models capable of identifying satirical fake news with an accuracy of\nup to 98.6%.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 08:56:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Saadany", "Hadeel", ""], ["Mohamed", "Emad", ""], ["Orasan", "Constantin", ""]]}, {"id": "2011.00470", "submitter": "Miruna Pislar", "authors": "Miruna Pislar and Marek Rei", "title": "Seeing Both the Forest and the Trees: Multi-head Attention for Joint\n  Classification on Different Compositional Levels", "comments": null, "journal-ref": "COLING 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In natural languages, words are used in association to construct sentences.\nIt is not words in isolation, but the appropriate combination of hierarchical\nstructures that conveys the meaning of the whole sentence. Neural networks can\ncapture expressive language features; however, insights into the link between\nwords and sentences are difficult to acquire automatically. In this work, we\ndesign a deep neural network architecture that explicitly wires lower and\nhigher linguistic components; we then evaluate its ability to perform the same\ntask at different hierarchical levels. Settling on broad text classification\ntasks, we show that our model, MHAL, learns to simultaneously solve them at\ndifferent levels of granularity by fluidly transferring knowledge between\nhierarchies. Using a multi-head attention mechanism to tie the representations\nbetween single words and full sentences, MHAL systematically outperforms\nequivalent models that are not incentivized towards developing compositional\nrepresentations. Moreover, we demonstrate that, with the proposed architecture,\nthe sentence information flows naturally to individual words, allowing the\nmodel to behave like a sequence labeller (which is a lower, word-level task)\neven without any word supervision, in a zero-shot fashion.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:44:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pislar", "Miruna", ""], ["Rei", "Marek", ""]]}, {"id": "2011.00474", "submitter": "Zhen Wu", "authors": "Chengcan Ying and Zhen Wu and Xinyu Dai and Shujian Huang and Jiajun\n  Chen", "title": "Opinion Transmission Network for Jointly Improving Aspect-oriented\n  Opinion Words Extraction and Sentiment Classification", "comments": "Accepted by NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification (ALSC) and aspect oriented opinion\nwords extraction (AOWE) are two highly relevant aspect-based sentiment analysis\n(ABSA) subtasks. They respectively aim to detect the sentiment polarity and\nextract the corresponding opinion words toward a given aspect in a sentence.\nPrevious works separate them and focus on one of them by training neural models\non small-scale labeled data, while neglecting the connections between them. In\nthis paper, we propose a novel joint model, Opinion Transmission Network (OTN),\nto exploit the potential bridge between ALSC and AOWE to achieve the goal of\nfacilitating them simultaneously. Specifically, we design two tailor-made\nopinion transmission mechanisms to control opinion clues flow bidirectionally,\nrespectively from ALSC to AOWE and AOWE to ALSC. Experiment results on two\nbenchmark datasets show that our joint model outperforms strong baselines on\nthe two tasks. Further analysis also validates the effectiveness of opinion\ntransmission mechanisms.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 11:00:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ying", "Chengcan", ""], ["Wu", "Zhen", ""], ["Dai", "Xinyu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "2011.00476", "submitter": "Zhen Wu", "authors": "Zhen Wu and Chengcan Ying and Xinyu Dai and Shujian Huang and Jiajun\n  Chen", "title": "Transformer-based Multi-Aspect Modeling for Multi-Aspect Multi-Sentiment\n  Analysis", "comments": "Accepted by NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) aims at analyzing the sentiment of a\ngiven aspect in a sentence. Recently, neural network-based methods have\nachieved promising results in existing ABSA datasets. However, these datasets\ntend to degenerate to sentence-level sentiment analysis because most sentences\ncontain only one aspect or multiple aspects with the same sentiment polarity.\nTo facilitate the research of ABSA, NLPCC 2020 Shared Task 2 releases a new\nlarge-scale Multi-Aspect Multi-Sentiment (MAMS) dataset. In the MAMS dataset,\neach sentence contains at least two different aspects with different sentiment\npolarities, which makes ABSA more complex and challenging. To address the\nchallenging dataset, we re-formalize ABSA as a problem of multi-aspect\nsentiment analysis, and propose a novel Transformer-based Multi-aspect Modeling\nscheme (TMM), which can capture potential relations between multiple aspects\nand simultaneously detect the sentiment of all aspects in a sentence.\nExperiment results on the MAMS dataset show that our method achieves noticeable\nimprovements compared with strong baselines such as BERT and RoBERTa, and\nfinally ranks the 2nd in NLPCC 2020 Shared Task 2 Evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 11:06:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wu", "Zhen", ""], ["Ying", "Chengcan", ""], ["Dai", "Xinyu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "2011.00483", "submitter": "Vitou Phy", "authors": "Vitou Phy, Yang Zhao and Akiko Aizawa", "title": "Deconstruct to Reconstruct a Configurable Evaluation Metric for\n  Open-Domain Dialogue Systems", "comments": "15 pages, 4 figures, 7 tables, Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many automatic evaluation metrics have been proposed to score the overall\nquality of a response in open-domain dialogue. Generally, the overall quality\nis comprised of various aspects, such as relevancy, specificity, and empathy,\nand the importance of each aspect differs according to the task. For instance,\nspecificity is mandatory in a food-ordering dialogue task, whereas fluency is\npreferred in a language-teaching dialogue system. However, existing metrics are\nnot designed to cope with such flexibility. For example, BLEU score\nfundamentally relies only on word overlapping, whereas BERTScore relies on\nsemantic similarity between reference and candidate response. Thus, they are\nnot guaranteed to capture the required aspects, i.e., specificity. To design a\nmetric that is flexible to a task, we first propose making these qualities\nmanageable by grouping them into three groups: understandability, sensibleness,\nand likability, where likability is a combination of qualities that are\nessential for a task. We also propose a simple method to composite metrics of\neach aspect to obtain a single metric called USL-H, which stands for\nUnderstandability, Sensibleness, and Likability in Hierarchy. We demonstrated\nthat USL-H score achieves good correlations with human judgment and maintains\nits configurability towards different aspects and metrics.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 11:34:50 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Phy", "Vitou", ""], ["Zhao", "Yang", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2011.00519", "submitter": "Junru Lu", "authors": "Junru Lu, Gabriele Pergola, Lin Gui, Binyang Li, Yulan He", "title": "CHIME: Cross-passage Hierarchical Memory Network for Generative Review\n  Question Answering", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CHIME, a cross-passage hierarchical memory network for question\nanswering (QA) via text generation. It extends XLNet introducing an auxiliary\nmemory module consisting of two components: the context memory collecting\ncross-passage evidences, and the answer memory working as a buffer continually\nrefining the generated answers. Empirically, we show the efficacy of the\nproposed architecture in the multi-passage generative QA, outperforming the\nstate-of-the-art baselines with better syntactically well-formed answers and\nincreased precision in addressing the questions of the AmazonQA review dataset.\nAn additional qualitative analysis revealed the interpretability introduced by\nthe memory module.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:48:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lu", "Junru", ""], ["Pergola", "Gabriele", ""], ["Gui", "Lin", ""], ["Li", "Binyang", ""], ["He", "Yulan", ""]]}, {"id": "2011.00538", "submitter": "Badr AlKhamissi", "authors": "Badr AlKhamissi, Muhammad N. ElNokrashy and Mohamed Gabr", "title": "Deep Diacritization: Efficient Hierarchical Recurrence for Improved\n  Arabic Diacritization", "comments": "This work was accepted at the Fifth Arabic Natural Language\n  Processing Workshop (COLING/WANLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel architecture for labelling character sequences that\nachieves state-of-the-art results on the Tashkeela Arabic diacritization\nbenchmark. The core is a two-level recurrence hierarchy that operates on the\nword and character levels separately---enabling faster training and inference\nthan comparable traditional models. A cross-level attention module further\nconnects the two, and opens the door for network interpretability. The task\nmodule is a softmax classifier that enumerates valid combinations of\ndiacritics. This architecture can be extended with a recurrent decoder that\noptionally accepts priors from partially diacritized text, which improves\nresults. We employ extra tricks such as sentence dropout and majority voting to\nfurther boost the final result. Our best model achieves a WER of 5.34%,\noutperforming the previous state-of-the-art with a 30.56% relative error\nreduction.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:33:43 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["AlKhamissi", "Badr", ""], ["ElNokrashy", "Muhammad N.", ""], ["Gabr", "Mohamed", ""]]}, {"id": "2011.00543", "submitter": "Zining Zhu", "authors": "Zining Zhu, Yang Xu, Frank Rudzicz", "title": "Semantic coordinates analysis reveals language changes in the AI field", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic shifts can reflect changes in beliefs across hundreds of years, but\nit is less clear whether trends in fast-changing communities across a short\ntime can be detected. We propose semantic coordinates analysis, a method based\non semantic shifts, that reveals changes in language within publications of a\nfield (we use AI as example) across a short time span. We use GloVe-style\nprobability ratios to quantify the shifting directions and extents from\nmultiple viewpoints. We show that semantic coordinates analysis can detect\nshifts echoing changes of research interests (e.g., \"deep\" shifted further from\n\"rigorous\" to \"neural\"), and developments of research activities (e,g.,\n\"collaboration\" contains less \"competition\" than \"collaboration\"), based on\npublications spanning as short as 10 years.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:59:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhu", "Zining", ""], ["Xu", "Yang", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2011.00547", "submitter": "Huda Khayrallah", "authors": "Huda Khayrallah, Jo\\~ao Sedoc", "title": "SMRT Chatbots: Improving Non-Task-Oriented Dialog with Simulated\n  Multiple Reference Training", "comments": "EMNLP 2020 Camera Ready", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.403", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-task-oriented dialog models suffer from poor quality and non-diverse\nresponses. To overcome limited conversational data, we apply Simulated Multiple\nReference Training (SMRT; Khayrallah et al., 2020), and use a paraphraser to\nsimulate multiple responses per training prompt. We find SMRT improves over a\nstrong Transformer baseline as measured by human and automatic quality scores\nand lexical diversity. We also find SMRT is comparable to pretraining in human\nevaluation quality, and outperforms pretraining on automatic quality and\nlexical diversity, without requiring related-domain dialog data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:11:17 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Khayrallah", "Huda", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "2011.00559", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Sarthak Gupte, Marcos Zampieri, Ifeoma Nwogu", "title": "WLV-RIT at HASOC-Dravidian-CodeMix-FIRE2020: Offensive Language\n  Identification in Code-switched YouTube Comments", "comments": "Accepted to FIRE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the WLV-RIT entry to the Hate Speech and Offensive\nContent Identification in Indo-European Languages (HASOC) shared task 2020. The\nHASOC 2020 organizers provided participants with annotated datasets containing\nsocial media posts of code-mixed in Dravidian languages (Malayalam-English and\nTamil-English). We participated in task 1: Offensive comment identification in\nCode-mixed Malayalam Youtube comments. In our methodology, we take advantage of\navailable English data by applying cross-lingual contextual word embeddings and\ntransfer learning to make predictions to Malayalam data. We further improve the\nresults using various fine tuning strategies. Our system achieved 0.89 weighted\naverage F1 score for the test set and it ranked 5th place out of 12\nparticipants.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:52:08 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Gupte", "Sarthak", ""], ["Zampieri", "Marcos", ""], ["Nwogu", "Ifeoma", ""]]}, {"id": "2011.00564", "submitter": "Samuel Louvan", "authors": "Samuel Louvan and Bernardo Magnini", "title": "Recent Neural Methods on Slot Filling and Intent Classification for\n  Task-Oriented Dialogue Systems: A Survey", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, fostered by deep learning technologies and by the high\ndemand for conversational AI, various approaches have been proposed that\naddress the capacity to elicit and understand user's needs in task-oriented\ndialogue systems. We focus on two core tasks, slot filling (SF) and intent\nclassification (IC), and survey how neural-based models have rapidly evolved to\naddress natural language understanding in dialogue systems. We introduce three\nneural architectures: independent model, which model SF and IC separately,\njoint models, which exploit the mutual benefit of the two tasks simultaneously,\nand transfer learning models, that scale the model to new domains. We discuss\nthe current state of the research in SF and IC and highlight challenges that\nstill require attention.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:15:42 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Louvan", "Samuel", ""], ["Magnini", "Bernardo", ""]]}, {"id": "2011.00569", "submitter": "C.-H. Huck Yang", "authors": "Jia-Hong Huang, Chao-Han Huck Yang, Fangyu Liu, Meng Tian, Yi-Chieh\n  Liu, Ting-Wei Wu, I-Hung Lin, Kang Wang, Hiromasa Morikawa, Hernghua Chang,\n  Jesper Tegner, Marcel Worring", "title": "DeepOpht: Medical Report Generation for Retinal Images via Deep Models\n  and Visual Explanation", "comments": "Accepted to IEEE WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an AI-based method that intends to improve the\nconventional retinal disease treatment procedure and help ophthalmologists\nincrease diagnosis efficiency and accuracy. The proposed method is composed of\na deep neural networks-based (DNN-based) module, including a retinal disease\nidentifier and clinical description generator, and a DNN visual explanation\nmodule. To train and validate the effectiveness of our DNN-based module, we\npropose a large-scale retinal disease image dataset. Also, as ground truth, we\nprovide a retinal image dataset manually labeled by ophthalmologists to\nqualitatively show, the proposed AI-based method is effective. With our\nexperimental results, we show that the proposed method is quantitatively and\nqualitatively effective. Our method is capable of creating meaningful retinal\nimage descriptions and visual explanations that are clinically relevant.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:28:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Jia-Hong", ""], ["Yang", "Chao-Han Huck", ""], ["Liu", "Fangyu", ""], ["Tian", "Meng", ""], ["Liu", "Yi-Chieh", ""], ["Wu", "Ting-Wei", ""], ["Lin", "I-Hung", ""], ["Wang", "Kang", ""], ["Morikawa", "Hiromasa", ""], ["Chang", "Hernghua", ""], ["Tegner", "Jesper", ""], ["Worring", "Marcel", ""]]}, {"id": "2011.00578", "submitter": "Basma Alharbi", "authors": "Basma Alharbi, Hind Alamro, Manal Alshehri, Zuhair Khayyat, Manal\n  Kalkatawi, Inji Ibrahim Jaber, Xiangliang Zhang", "title": "ASAD: A Twitter-based Benchmark Arabic Sentiment Analysis Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a detailed description of a new Twitter-based benchmark\ndataset for Arabic Sentiment Analysis (ASAD), which is launched in a\ncompetition3, sponsored by KAUST for awarding 10000 USD, 5000 USD and 2000 USD\nto the first, second and third place winners, respectively. Compared to other\npublicly released Arabic datasets, ASAD is a large, high-quality annotated\ndataset(including 95K tweets), with three-class sentiment labels (positive,\nnegative and neutral). We presents the details of the data collection process\nand annotation process. In addition, we implement several baseline models for\nthe competition task and report the results as a reference for the participants\nto the competition.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:03:22 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 20:34:36 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 03:46:46 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Alharbi", "Basma", ""], ["Alamro", "Hind", ""], ["Alshehri", "Manal", ""], ["Khayyat", "Zuhair", ""], ["Kalkatawi", "Manal", ""], ["Jaber", "Inji Ibrahim", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2011.00584", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Carlos G\\'omez-Rodr\\'iguez, Michalina Strzyz, David Vilares", "title": "A Unifying Theory of Transition-based and Sequence Labeling Parsing", "comments": "Camera-ready version (final peer-reviewed manuscript) to appear at\n  proceedings of COLING 2020. 18 pages (incl. appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define a mapping from transition-based parsing algorithms that read\nsentences from left to right to sequence labeling encodings of syntactic trees.\nThis not only establishes a theoretical relation between transition-based\nparsing and sequence-labeling parsing, but also provides a method to obtain new\nencodings for fast and simple sequence labeling parsing from the many existing\ntransition-based parsers for different formalisms. Applying it to dependency\nparsing, we implement sequence labeling versions of four algorithms, showing\nthat they are learnable and obtain comparable performance to existing\nencodings.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:25:15 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Strzyz", "Michalina", ""], ["Vilares", "David", ""]]}, {"id": "2011.00592", "submitter": "Steffen Eger", "authors": "Martin Kerscher and Steffen Eger", "title": "Vec2Sent: Probing Sentence Embeddings with Natural Language Generation", "comments": "Accepted for publication in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introspect black-box sentence embeddings by conditionally generating from\nthem with the objective to retrieve the underlying discrete sentence. We\nperceive of this as a new unsupervised probing task and show that it correlates\nwell with downstream task performance. We also illustrate how the language\ngenerated from different encoders differs. We apply our approach to generate\nsentence analogies from sentence embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:46:53 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kerscher", "Martin", ""], ["Eger", "Steffen", ""]]}, {"id": "2011.00593", "submitter": "Kevin Liang", "authors": "Kevin J Liang, Weituo Hao, Dinghan Shen, Yufan Zhou, Weizhu Chen,\n  Changyou Chen, Lawrence Carin", "title": "MixKD: Towards Efficient Distillation of Large-scale Language Models", "comments": "ICLR 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale language models have recently demonstrated impressive empirical\nperformance. Nevertheless, the improved results are attained at the price of\nbigger models, more power consumption, and slower inference, which hinder their\napplicability to low-resource (both memory and computation) platforms.\nKnowledge distillation (KD) has been demonstrated as an effective framework for\ncompressing such big models. However, large-scale neural network systems are\nprone to memorize training instances, and thus tend to make inconsistent\npredictions when the data distribution is altered slightly. Moreover, the\nstudent model has few opportunities to request useful information from the\nteacher model when there is limited task-specific data available. To address\nthese issues, we propose MixKD, a data-agnostic distillation framework that\nleverages mixup, a simple yet efficient data augmentation approach, to endow\nthe resulting model with stronger generalization ability. Concretely, in\naddition to the original training examples, the student model is encouraged to\nmimic the teacher's behavior on the linear interpolation of example pairs as\nwell. We prove from a theoretical perspective that under reasonable conditions\nMixKD gives rise to a smaller gap between the generalization error and the\nempirical error. To verify its effectiveness, we conduct experiments on the\nGLUE benchmark, where MixKD consistently leads to significant gains over the\nstandard KD training, and outperforms several competitive baselines.\nExperiments under a limited-data setting and ablation studies further\ndemonstrate the advantages of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:47:51 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 06:38:05 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Liang", "Kevin J", ""], ["Hao", "Weituo", ""], ["Shen", "Dinghan", ""], ["Zhou", "Yufan", ""], ["Chen", "Weizhu", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "2011.00596", "submitter": "Michalina Strzyz", "authors": "Michalina Strzyz, David Vilares and Carlos G\\'omez-Rodr\\'iguez", "title": "Bracketing Encodings for 2-Planar Dependency Parsing", "comments": "COLING2020 (long papers), 13 pages (incl. appendix) with corrected\n  parsing speeds for Danish and Gothic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a bracketing-based encoding that can be used to represent any\n2-planar dependency tree over a sentence of length n as a sequence of n labels,\nhence providing almost total coverage of crossing arcs in sequence labeling\nparsing. First, we show that existing bracketing encodings for parsing as\nlabeling can only handle a very mild extension of projective trees. Second, we\novercome this limitation by taking into account the well-known property of\n2-planarity, which is present in the vast majority of dependency syntactic\nstructures in treebanks, i.e., the arcs of a dependency tree can be split into\ntwo planes such that arcs in a given plane do not cross. We take advantage of\nthis property to design a method that balances the brackets and that encodes\nthe arcs belonging to each of those planes, allowing for almost unrestricted\nnon-projectivity (round 99.9% coverage) in sequence labeling parsing. The\nexperiments show that our linearizations improve over the accuracy of the\noriginal bracketing encoding in highly non-projective treebanks (on average by\n0.4 LAS), while achieving a similar speed. Also, they are especially suitable\nwhen PoS tags are not used as input parameters to the models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:53:32 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 20:53:30 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Strzyz", "Michalina", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2011.00597", "submitter": "Simon Ging", "authors": "Simon Ging (1), Mohammadreza Zolfaghari (1), Hamed Pirsiavash (2),\n  Thomas Brox (1) ((1) University of Freiburg, (2) University of Maryland\n  Baltimore County)", "title": "COOT: Cooperative Hierarchical Transformer for Video-Text Representation\n  Learning", "comments": "27 pages, 5 figures, 19 tables. To be published in the 34th\n  conference on Neural Information Processing Systems (NeurIPS 2020). The first\n  two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world video-text tasks involve different levels of granularity,\nsuch as frames and words, clip and sentences or videos and paragraphs, each\nwith distinct semantics. In this paper, we propose a Cooperative hierarchical\nTransformer (COOT) to leverage this hierarchy information and model the\ninteractions between different levels of granularity and different modalities.\nThe method consists of three major components: an attention-aware feature\naggregation layer, which leverages the local temporal context (intra-level,\ne.g., within a clip), a contextual transformer to learn the interactions\nbetween low-level and high-level semantics (inter-level, e.g. clip-video,\nsentence-paragraph), and a cross-modal cycle-consistency loss to connect video\nand text. The resulting method compares favorably to the state of the art on\nseveral benchmarks while having few parameters. All code is available\nopen-source at https://github.com/gingsi/coot-videotext\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:54:09 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ging", "Simon", ""], ["Zolfaghari", "Mohammadreza", ""], ["Pirsiavash", "Hamed", ""], ["Brox", "Thomas", ""]]}, {"id": "2011.00615", "submitter": "Jon Ander Campos", "authors": "Jon Ander Campos, Kyunghyun Cho, Arantxa Otegi, Aitor Soroa, Gorka\n  Azkune, Eneko Agirre", "title": "Improving Conversational Question Answering Systems after Deployment\n  using Feedback-Weighted Learning", "comments": "Accepted at COLING 2020. 11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interaction of conversational systems with users poses an exciting\nopportunity for improving them after deployment, but little evidence has been\nprovided of its feasibility. In most applications, users are not able to\nprovide the correct answer to the system, but they are able to provide binary\n(correct, incorrect) feedback. In this paper we propose feedback-weighted\nlearning based on importance sampling to improve upon an initial supervised\nsystem using binary user feedback. We perform simulated experiments on document\nclassification (for development) and Conversational Question Answering datasets\nlike QuAC and DoQA, where binary user feedback is derived from gold\nannotations. The results show that our method is able to improve over the\ninitial supervised system, getting close to a fully-supervised system that has\naccess to the same labeled examples in in-domain experiments (QuAC), and even\nmatching in out-of-domain experiments (DoQA). Our work opens the prospect to\nexploit interactions with real users and improve conversational systems after\ndeployment.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:50:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Campos", "Jon Ander", ""], ["Cho", "Kyunghyun", ""], ["Otegi", "Arantxa", ""], ["Soroa", "Aitor", ""], ["Azkune", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "2011.00620", "submitter": "Maxwell Forbes", "authors": "Maxwell Forbes, Jena D. Hwang, Vered Shwartz, Maarten Sap, Yejin Choi", "title": "Social Chemistry 101: Learning to Reason about Social and Moral Norms", "comments": "Published at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social norms -- the unspoken commonsense rules about acceptable social\nbehavior -- are crucial in understanding the underlying causes and intents of\npeople's actions in narratives. For example, underlying an action such as\n\"wanting to call cops on my neighbors\" are social norms that inform our\nconduct, such as \"It is expected that you report crimes.\"\n  We present Social Chemistry, a new conceptual formalism to study people's\neveryday social norms and moral judgments over a rich spectrum of real life\nsituations described in natural language. We introduce Social-Chem-101, a\nlarge-scale corpus that catalogs 292k rules-of-thumb such as \"it is rude to run\na blender at 5am\" as the basic conceptual units. Each rule-of-thumb is further\nbroken down with 12 different dimensions of people's judgments, including\nsocial judgments of good and bad, moral foundations, expected cultural\npressure, and assumed legality, which together amount to over 4.5 million\nannotations of categorical labels and free-text descriptions.\n  Comprehensive empirical results based on state-of-the-art neural models\ndemonstrate that computational modeling of social norms is a promising research\ndirection. Our model framework, Neural Norm Transformer, learns and generalizes\nSocial-Chem-101 to successfully reason about previously unseen situations,\ngenerating relevant (and potentially novel) attribute-aware social\nrules-of-thumb.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 20:16:45 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:59:00 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Forbes", "Maxwell", ""], ["Hwang", "Jena D.", ""], ["Shwartz", "Vered", ""], ["Sap", "Maarten", ""], ["Choi", "Yejin", ""]]}, {"id": "2011.00633", "submitter": "Dietrich Trautmann", "authors": "Dietrich Trautmann", "title": "Aspect-Based Argument Mining", "comments": "Accepted to the 7th Workshop on Argument Mining (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational Argumentation in general and Argument Mining in particular are\nimportant research fields. In previous works, many of the challenges to\nautomatically extract and to some degree reason over natural language arguments\nwere addressed. The tools to extract argument units are increasingly available\nand further open problems can be addressed. In this work, we are presenting the\ntask of Aspect-Based Argument Mining (ABAM), with the essential subtasks of\nAspect Term Extraction (ATE) and Nested Segmentation (NS). At the first\ninstance, we create and release an annotated corpus with aspect information on\nthe token-level. We consider aspects as the main point(s) argument units are\naddressing. This information is important for further downstream tasks such as\nargument ranking, argument summarization and generation, as well as the search\nfor counter-arguments on the aspect-level. We present several experiments using\nstate-of-the-art supervised architectures and demonstrate their performance for\nboth of the subtasks. The annotated benchmark is available at\nhttps://github.com/trtm/ABAM.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 21:57:51 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Trautmann", "Dietrich", ""]]}, {"id": "2011.00669", "submitter": "Tejas Srinivasan", "authors": "Muhammad A. Shah, Shikib Mehri, Tejas Srinivasan", "title": "Reasoning Over History: Context Aware Visual Dialog", "comments": "Accepted to NLP Beyond Text workshop, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural models have been shown to exhibit strong performance on\nsingle-turn visual question answering (VQA) tasks, extending VQA to a\nmulti-turn, conversational setting remains a challenge. One way to address this\nchallenge is to augment existing strong neural VQA models with the mechanisms\nthat allow them to retain information from previous dialog turns. One strong\nVQA model is the MAC network, which decomposes a task into a series of\nattention-based reasoning steps. However, since the MAC network is designed for\nsingle-turn question answering, it is not capable of referring to past dialog\nturns. More specifically, it struggles with tasks that require reasoning over\nthe dialog history, particularly coreference resolution. We extend the MAC\nnetwork architecture with Context-aware Attention and Memory (CAM), which\nattends over control states in past dialog turns to determine the necessary\nreasoning operations for the current question. MAC nets with CAM achieve up to\n98.25% accuracy on the CLEVR-Dialog dataset, beating the existing\nstate-of-the-art by 30% (absolute). Our error analysis indicates that with CAM,\nthe model's performance particularly improved on questions that required\ncoreference resolution.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 01:25:13 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Shah", "Muhammad A.", ""], ["Mehri", "Shikib", ""], ["Srinivasan", "Tejas", ""]]}, {"id": "2011.00675", "submitter": "Chang Xu", "authors": "Chang Xu, Jun Wang, Yuqing Tang, Francisco Guzman, Benjamin I. P.\n  Rubinstein, Trevor Cohn", "title": "A Targeted Attack on Black-Box Neural Machine Translation with Parallel\n  Data Poisoning", "comments": "In Proceedings of the 2021 World Wide Web Conference (WWW 2021)", "journal-ref": null, "doi": "10.1145/3442381.3450034", "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As modern neural machine translation (NMT) systems have been widely deployed,\ntheir security vulnerabilities require close scrutiny. Most recently, NMT\nsystems have been found vulnerable to targeted attacks which cause them to\nproduce specific, unsolicited, and even harmful translations. These attacks are\nusually exploited in a white-box setting, where adversarial inputs causing\ntargeted translations are discovered for a known target system. However, this\napproach is less viable when the target system is black-box and unknown to the\nadversary (e.g., secured commercial systems). In this paper, we show that\ntargeted attacks on black-box NMT systems are feasible, based on poisoning a\nsmall fraction of their parallel training data. We show that this attack can be\nrealised practically via targeted corruption of web documents crawled to form\nthe system's training data. We then analyse the effectiveness of the targeted\npoisoning in two common NMT training scenarios: the from-scratch training and\nthe pre-train & fine-tune paradigm. Our results are alarming: even on the\nstate-of-the-art systems trained with massive parallel data (tens of millions),\nthe attacks are still successful (over 50% success rate) under surprisingly low\npoisoning budgets (e.g., 0.006%). Lastly, we discuss potential defences to\ncounter such attacks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 01:52:46 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 05:10:33 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Xu", "Chang", ""], ["Wang", "Jun", ""], ["Tang", "Yuqing", ""], ["Guzman", "Francisco", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Cohn", "Trevor", ""]]}, {"id": "2011.00677", "submitter": "Fajri Koto", "authors": "Fajri Koto and Afshin Rahimi and Jey Han Lau and Timothy Baldwin", "title": "IndoLEM and IndoBERT: A Benchmark Dataset and Pre-trained Language Model\n  for Indonesian NLP", "comments": "Accepted at COLING 2020 - The 28th International Conference on\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the Indonesian language is spoken by almost 200 million people and\nthe 10th most spoken language in the world, it is under-represented in NLP\nresearch. Previous work on Indonesian has been hampered by a lack of annotated\ndatasets, a sparsity of language resources, and a lack of resource\nstandardization. In this work, we release the IndoLEM dataset comprising seven\ntasks for the Indonesian language, spanning morpho-syntax, semantics, and\ndiscourse. We additionally release IndoBERT, a new pre-trained language model\nfor Indonesian, and evaluate it over IndoLEM, in addition to benchmarking it\nagainst existing resources. Our experiments show that IndoBERT achieves\nstate-of-the-art performance over most of the tasks in IndoLEM.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 01:54:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Koto", "Fajri", ""], ["Rahimi", "Afshin", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""]]}, {"id": "2011.00678", "submitter": "Shuhao Gu", "authors": "Shuhao Gu and Yang Feng", "title": "Investigating Catastrophic Forgetting During Continual Training for\n  Neural Machine Translation", "comments": "Coling2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) models usually suffer from catastrophic\nforgetting during continual training where the models tend to gradually forget\npreviously learned knowledge and swing to fit the newly added data which may\nhave a different distribution, e.g. a different domain. Although many methods\nhave been proposed to solve this problem, we cannot get to know what causes\nthis phenomenon yet. Under the background of domain adaptation, we investigate\nthe cause of catastrophic forgetting from the perspectives of modules and\nparameters (neurons). The investigation on the modules of the NMT model shows\nthat some modules have tight relation with the general-domain knowledge while\nsome other modules are more essential in the domain adaptation. And the\ninvestigation on the parameters shows that some parameters are important for\nboth the general-domain and in-domain translation and the great change of them\nduring continual training brings about the performance decline in\ngeneral-domain. We conduct experiments across different language pairs and\ndomains to ensure the validity and reliability of our findings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 01:55:06 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 08:49:42 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 06:56:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Gu", "Shuhao", ""], ["Feng", "Yang", ""]]}, {"id": "2011.00679", "submitter": "Fajri Koto", "authors": "Fajri Koto and Jey Han Lau and Timothy Baldwin", "title": "Liputan6: A Large-scale Indonesian Dataset for Text Summarization", "comments": "Accepted at AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a large-scale Indonesian summarization dataset.\nWe harvest articles from Liputan6.com, an online news portal, and obtain\n215,827 document-summary pairs. We leverage pre-trained language models to\ndevelop benchmark extractive and abstractive summarization methods over the\ndataset with multilingual and monolingual BERT-based models. We include a\nthorough error analysis by examining machine-generated summaries that have low\nROUGE scores, and expose both issues with ROUGE it-self, as well as with\nextractive and abstractive summarization models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 02:01:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Koto", "Fajri", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""]]}, {"id": "2011.00681", "submitter": "Evangelia Spiliopoulou", "authors": "Evangelia Spiliopoulou and Salvador Medina Maza and Eduard Hovy and\n  Alexander Hauptmann", "title": "Event-Related Bias Removal for Real-time Disaster Events", "comments": "To appear in EMNLP Findings 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has become an important tool to share information about crisis\nevents such as natural disasters and mass attacks. Detecting actionable posts\nthat contain useful information requires rapid analysis of huge volume of data\nin real-time. This poses a complex problem due to the large amount of posts\nthat do not contain any actionable information. Furthermore, the classification\nof information in real-time systems requires training on out-of-domain data, as\nwe do not have any data from a new emerging crisis. Prior work focuses on\nmodels pre-trained on similar event types. However, those models capture\nunnecessary event-specific biases, like the location of the event, which affect\nthe generalizability and performance of the classifiers on new unseen data from\nan emerging new event. In our work, we train an adversarial neural model to\nremove latent event-specific biases and improve the performance on tweet\nimportance classification.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 02:03:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Spiliopoulou", "Evangelia", ""], ["Maza", "Salvador Medina", ""], ["Hovy", "Eduard", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "2011.00682", "submitter": "Jackson Petty", "authors": "Robert Frank and Jackson Petty", "title": "Sequence-to-Sequence Networks Learn the Meaning of Reflexive Anaphora", "comments": "10 pages, 4 figures, 3 tables, accepted at CRAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reflexive anaphora present a challenge for semantic interpretation: their\nmeaning varies depending on context in a way that appears to require abstract\nvariables. Past work has raised doubts about the ability of recurrent networks\nto meet this challenge. In this paper, we explore this question in the context\nof a fragment of English that incorporates the relevant sort of contextual\nvariability. We consider sequence-to-sequence architectures with recurrent\nunits and show that such networks are capable of learning semantic\ninterpretations for reflexive anaphora which generalize to novel antecedents.\nWe explore the effect of attention mechanisms and different recurrent unit\ntypes on the type of training data that is needed for success as measured in\ntwo ways: how much lexical support is needed to induce an abstract reflexive\nmeaning (i.e., how many distinct reflexive antecedents must occur during\ntraining) and what contexts must a noun phrase occur in to support\ngeneralization of reflexive interpretation to this noun phrase?\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 02:06:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Frank", "Robert", ""], ["Petty", "Jackson", ""]]}, {"id": "2011.00692", "submitter": "Fei Liu", "authors": "Jia Jin Koay and Alexander Roustai and Xiaojin Dai and Dillon Burns\n  and Alec Kerrigan and Fei Liu", "title": "How Domain Terminology Affects Meeting Summarization Performance", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meetings are essential to modern organizations. Numerous meetings are held\nand recorded daily, more than can ever be comprehended. A meeting summarization\nsystem that identifies salient utterances from the transcripts to automatically\ngenerate meeting minutes can help. It empowers users to rapidly search and sift\nthrough large meeting collections. To date, the impact of domain terminology on\nthe performance of meeting summarization remains understudied, despite that\nmeetings are rich with domain knowledge. In this paper, we create gold-standard\nannotations for domain terminology on a sizable meeting corpus; they are known\nas jargon terms. We then analyze the performance of a meeting summarization\nsystem with and without jargon terms. Our findings reveal that domain\nterminology can have a substantial impact on summarization performance. We\npublicly release all domain terminology to advance research in meeting\nsummarization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 02:33:59 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 01:34:23 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Koay", "Jia Jin", ""], ["Roustai", "Alexander", ""], ["Dai", "Xiaojin", ""], ["Burns", "Dillon", ""], ["Kerrigan", "Alec", ""], ["Liu", "Fei", ""]]}, {"id": "2011.00696", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Sergey Feldman, Nazli Goharian, Doug Downey, Arman\n  Cohan", "title": "ABNIRML: Analyzing the Behavior of Neural IR Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies have demonstrated the effectiveness of pretrained\ncontextualized language models such as BERT and T5 for ad-hoc search. However,\nit is not well-understood why these methods are so effective, what makes some\nvariants more effective than others, and what pitfalls they may have. We\npresent a new comprehensive framework for Analyzing the Behavior of Neural IR\nModeLs (ABNIRML), which includes new types of diagnostic tests that allow us to\nprobe several characteristics---such as sensitivity to word order---that are\nnot addressed by previous techniques. To demonstrate the value of the\nframework, we conduct an extensive empirical study that yields insights into\nthe factors that contribute to the neural model's gains, and identify potential\nunintended biases the models exhibit. We find evidence that recent neural\nranking models have fundamentally different characteristics from prior ranking\nmodels. For instance, these models can be highly influenced by altered document\nword order, sentence order and inflectional endings. They can also exhibit\nunexpected behaviors when additional content is added to documents, or when\ndocuments are expressed with different levels of fluency or formality. We find\nthat these differences can depend on the architecture and not just the\nunderlying language model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:07:38 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["MacAvaney", "Sean", ""], ["Feldman", "Sergey", ""], ["Goharian", "Nazli", ""], ["Downey", "Doug", ""], ["Cohan", "Arman", ""]]}, {"id": "2011.00704", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Dan Goldwasser", "title": "Semi-supervised Autoencoding Projective Dependency Parsing", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two end-to-end autoencoding models for semi-supervised\ngraph-based projective dependency parsing. The first model is a Locally\nAutoencoding Parser (LAP) encoding the input using continuous latent variables\nin a sequential manner; The second model is a Globally Autoencoding Parser\n(GAP) encoding the input into dependency trees as latent variables, with exact\ninference. Both models consist of two parts: an encoder enhanced by deep neural\nnetworks (DNN) that can utilize the contextual information to encode the input\ninto latent variables, and a decoder which is a generative model able to\nreconstruct the input. Both LAP and GAP admit a unified structure with\ndifferent loss functions for labeled and unlabeled data with shared parameters.\nWe conducted experiments on WSJ and UD dependency parsing data sets, showing\nthat our models can exploit the unlabeled data to improve the performance given\na limited amount of labeled data, and outperform a previously proposed\nsemi-supervised model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:21:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2011.00740", "submitter": "Kaiji Lu", "authors": "Kaiji Lu, Zifan Wang, Piotr Mardziel, Anupam Datta", "title": "Abstracting Influence Paths for Explaining (Contextualization of) BERT\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While \"attention is all you need\" may be proving true, we do not yet know\nwhy: attention-based models such as BERT are superior but how they\ncontextualize information even for simple grammatical rules such as\nsubject-verb number agreement (SVA) is uncertain. We introduce multi-partite\npatterns, abstractions of sets of paths through a neural network model.\nPatterns quantify and localize the effect of an input concept (e.g., a\nsubject's number) on an output concept (e.g. corresponding verb's number) to\npaths passing through a sequence of model components, thus surfacing how BERT\ncontextualizes information. We describe guided pattern refinement, an efficient\nsearch procedure for finding patterns representative of concept-critical paths.\nWe discover that patterns generate succinct and meaningful explanations for\nBERT, highlighted by \"copy\" and \"transfer\" operations implemented by skip\nconnections and attention heads, respectively. We also show how pattern\nvisualizations help us understand how BERT contextualizes various grammatical\nconcepts, such as SVA across clauses, and why it makes errors in some cases\nwhile succeeding in others.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:28:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lu", "Kaiji", ""], ["Wang", "Zifan", ""], ["Mardziel", "Piotr", ""], ["Datta", "Anupam", ""]]}, {"id": "2011.00747", "submitter": "Hang Le", "authors": "Hang Le, Juan Pino, Changhan Wang, Jiatao Gu, Didier Schwab, Laurent\n  Besacier", "title": "Dual-decoder Transformer for Joint Automatic Speech Recognition and\n  Multilingual Speech Translation", "comments": "Accepted at COLING 2020 (Oral)", "journal-ref": "The 28th International Conference on Computational Linguistics\n  (COLING 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dual-decoder Transformer, a new model architecture that jointly\nperforms automatic speech recognition (ASR) and multilingual speech translation\n(ST). Our models are based on the original Transformer architecture (Vaswani et\nal., 2017) but consist of two decoders, each responsible for one task (ASR or\nST). Our major contribution lies in how these decoders interact with each\nother: one decoder can attend to different information sources from the other\nvia a dual-attention mechanism. We propose two variants of these architectures\ncorresponding to two different levels of dependencies between the decoders,\ncalled the parallel and cross dual-decoder Transformers, respectively.\nExtensive experiments on the MuST-C dataset show that our models outperform the\npreviously-reported highest translation performance in the multilingual\nsettings, and outperform as well bilingual one-to-one results. Furthermore, our\nparallel models demonstrate no trade-off between ASR and ST compared to the\nvanilla multi-task architecture. Our code and pre-trained models are available\nat https://github.com/formiel/speech-translation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:59:50 GMT"}], "update_date": "2020-11-21", "authors_parsed": [["Le", "Hang", ""], ["Pino", "Juan", ""], ["Wang", "Changhan", ""], ["Gu", "Jiatao", ""], ["Schwab", "Didier", ""], ["Besacier", "Laurent", ""]]}, {"id": "2011.00758", "submitter": "Milan Straka", "authors": "David Samuel, Milan Straka", "title": "\\'UFAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN", "comments": "Accepted at Cross-Framework Meaning Representation Parsing (MRP\n  2020), the CoNLL 2020 shared task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PERIN, a novel permutation-invariant approach to sentence-to-graph\nsemantic parsing. PERIN is a versatile, cross-framework and language\nindependent architecture for universal modeling of semantic structures. Our\nsystem participated in the CoNLL 2020 shared task, Cross-Framework Meaning\nRepresentation Parsing (MRP 2020), where it was evaluated on five different\nframeworks (AMR, DRG, EDS, PTG and UCCA) across four languages. PERIN was one\nof the winners of the shared task. The source code and pretrained models are\navailable at https://github.com/ufal/perin.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 05:47:08 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Samuel", "David", ""], ["Straka", "Milan", ""]]}, {"id": "2011.00766", "submitter": "Jungwoo Lim", "authors": "Jungwoo Lim, Dongsuk Oh, Yoonna Jang, Kisu Yang, Heuiseok Lim", "title": "I Know What You Asked: Graph Path Learning using AMR for Commonsense\n  Reasoning", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  CommonsenseQA is a task in which a correct answer is predicted through\ncommonsense reasoning with pre-defined knowledge. Most previous works have\naimed to improve the performance with distributed representation without\nconsidering the process of predicting the answer from the semantic\nrepresentation of the question. To shed light upon the semantic interpretation\nof the question, we propose an AMR-ConceptNet-Pruned (ACP) graph. The ACP graph\nis pruned from a full integrated graph encompassing Abstract Meaning\nRepresentation (AMR) graph generated from input questions and an external\ncommonsense knowledge graph, ConceptNet (CN). Then the ACP graph is exploited\nto interpret the reasoning path as well as to predict the correct answer on the\nCommonsenseQA task. This paper presents the manner in which the commonsense\nreasoning process can be interpreted with the relations and concepts provided\nby the ACP graph. Moreover, ACP-based models are shown to outperform the\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:22:01 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 04:13:36 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Lim", "Jungwoo", ""], ["Oh", "Dongsuk", ""], ["Jang", "Yoonna", ""], ["Yang", "Kisu", ""], ["Lim", "Heuiseok", ""]]}, {"id": "2011.00767", "submitter": "Aditi Chaudhary", "authors": "Aditi Chaudhary, Antonios Anastasopoulos, Zaid Sheikh, Graham Neubig", "title": "Reducing Confusion in Active Learning for Part-Of-Speech Tagging", "comments": "To appear in TACL 2020. This is a pre-MIT Press publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) uses a data selection algorithm to select useful\ntraining samples to minimize annotation cost. This is now an essential tool for\nbuilding low-resource syntactic analyzers such as part-of-speech (POS) taggers.\nExisting AL heuristics are generally designed on the principle of selecting\nuncertain yet representative training instances, where annotating these\ninstances may reduce a large number of errors. However, in an empirical study\nacross six typologically diverse languages (German, Swedish, Galician, North\nSami, Persian, and Ukrainian), we found the surprising result that even in an\noracle scenario where we know the true uncertainty of predictions, these\ncurrent heuristics are far from optimal. Based on this analysis, we pose the\nproblem of AL as selecting instances which maximally reduce the confusion\nbetween particular pairs of output tags. Extensive experimentation on the\naforementioned languages shows that our proposed AL strategy outperforms other\nAL strategies by a significant margin. We also present auxiliary results\ndemonstrating the importance of proper calibration of models, which we ensure\nthrough cross-view training, and analysis demonstrating how our proposed\nstrategy selects examples that more closely follow the oracle data\ndistribution.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:24:58 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 01:20:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chaudhary", "Aditi", ""], ["Anastasopoulos", "Antonios", ""], ["Sheikh", "Zaid", ""], ["Neubig", "Graham", ""]]}, {"id": "2011.00770", "submitter": "Liang Ding", "authors": "Liang Ding, Longyue Wang, Di Wu, Dacheng Tao and Zhaopeng Tu", "title": "Context-Aware Cross-Attention for Non-Autoregressive Translation", "comments": "To appear in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive translation (NAT) significantly accelerates the inference\nprocess by predicting the entire target sequence. However, due to the lack of\ntarget dependency modelling in the decoder, the conditional generation process\nheavily depends on the cross-attention. In this paper, we reveal a localness\nperception problem in NAT cross-attention, for which it is difficult to\nadequately capture source context. To alleviate this problem, we propose to\nenhance signals of neighbour source tokens into conventional cross-attention.\nExperimental results on several representative datasets show that our approach\ncan consistently improve translation quality over strong NAT baselines.\nExtensive analyses demonstrate that the enhanced cross-attention achieves\nbetter exploitation of source contexts by leveraging both local and global\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:34:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ding", "Liang", ""], ["Wang", "Longyue", ""], ["Wu", "Di", ""], ["Tao", "Dacheng", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2011.00777", "submitter": "Farhad Moghimifar", "authors": "Farhad Moghimifar, Lizhen Qu, Yue Zhuo, Mahsa Baktashmotlagh,\n  Gholamreza Haffari", "title": "COSMO: Conditional SEQ2SEQ-based Mixture Model for Zero-Shot Commonsense\n  Question Answering", "comments": "COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning refers to the ability of evaluating a social situation\nand acting accordingly. Identification of the implicit causes and effects of a\nsocial context is the driving capability which can enable machines to perform\ncommonsense reasoning. The dynamic world of social interactions requires\ncontext-dependent on-demand systems to infer such underlying information.\nHowever, current approaches in this realm lack the ability to perform\ncommonsense reasoning upon facing an unseen situation, mostly due to\nincapability of identifying a diverse range of implicit social relations. Hence\nthey fail to estimate the correct reasoning path. In this paper, we present\nConditional SEQ2SEQ-based Mixture model (COSMO), which provides us with the\ncapabilities of dynamic and diverse content generation. We use COSMO to\ngenerate context-dependent clauses, which form a dynamic Knowledge Graph (KG)\non-the-fly for commonsense reasoning. To show the adaptability of our model to\ncontext-dependant knowledge generation, we address the task of zero-shot\ncommonsense question answering. The empirical results indicate an improvement\nof up to +5.2% over the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 07:08:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Moghimifar", "Farhad", ""], ["Qu", "Lizhen", ""], ["Zhuo", "Yue", ""], ["Baktashmotlagh", "Mahsa", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2011.00780", "submitter": "Chao-Wei Huang", "authors": "Chao-Wei Huang and Yun-Nung Chen", "title": "Adapting Pretrained Transformer to Lattices for Spoken Language\n  Understanding", "comments": "ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattices are compact representations that encode multiple hypotheses, such as\nspeech recognition results or different word segmentations. It is shown that\nencoding lattices as opposed to 1-best results generated by automatic speech\nrecognizer (ASR) boosts the performance of spoken language understanding (SLU).\nRecently, pretrained language models with the transformer architecture have\nachieved the state-of-the-art results on natural language understanding, but\ntheir ability of encoding lattices has not been explored. Therefore, this paper\naims at adapting pretrained transformers to lattice inputs in order to perform\nunderstanding tasks specifically for spoken language. Our experiments on the\nbenchmark ATIS dataset show that fine-tuning pretrained transformers with\nlattice inputs yields clear improvement over fine-tuning with 1-best results.\nFurther evaluation demonstrates the effectiveness of our methods under\ndifferent acoustic conditions. Our code is available at\nhttps://github.com/MiuLab/Lattice-SLU\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 07:14:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Chao-Wei", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2011.00797", "submitter": "Zhuang Li", "authors": "Zhuang Li, Lizhen Qu, Gholamreza Haffari", "title": "Context Dependent Semantic Parsing: A Survey", "comments": "10 pages, acceteped by COLING'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of translating natural language utterances into\nmachine-readable meaning representations. Currently, most semantic parsing\nmethods are not able to utilize contextual information (e.g. dialogue and\ncomments history), which has a great potential to boost semantic parsing\nperformance. To address this issue, context dependent semantic parsing has\nrecently drawn a lot of attention. In this survey, we investigate progress on\nthe methods for the context dependent semantic parsing, together with the\ncurrent datasets and tasks. We then point out open problems and challenges for\nfuture research in this area. The collected resources for this topic are\navailable\nat:https://github.com/zhuang-li/Contextual-Semantic-Parsing-Paper-List.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 07:51:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Li", "Zhuang", ""], ["Qu", "Lizhen", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2011.00802", "submitter": "Zhongfen Deng", "authors": "Zhongfen Deng, Hao Peng, Congying Xia, Jianxin Li, Lifang He, Philip\n  S. Yu", "title": "Hierarchical Bi-Directional Self-Attention Networks for Paper Review\n  Rating Recommendation", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Review rating prediction of text reviews is a rapidly growing technology with\na wide range of applications in natural language processing. However, most\nexisting methods either use hand-crafted features or learn features using deep\nlearning with simple text corpus as input for review rating prediction,\nignoring the hierarchies among data. In this paper, we propose a Hierarchical\nbi-directional self-attention Network framework (HabNet) for paper review\nrating prediction and recommendation, which can serve as an effective\ndecision-making tool for the academic paper review process. Specifically, we\nleverage the hierarchical structure of the paper reviews with three levels of\nencoders: sentence encoder (level one), intra-review encoder (level two) and\ninter-review encoder (level three). Each encoder first derives contextual\nrepresentation of each level, then generates a higher-level representation, and\nafter the learning process, we are able to identify useful predictors to make\nthe final acceptance decision, as well as to help discover the inconsistency\nbetween numerical review ratings and text sentiment conveyed by reviewers.\nFurthermore, we introduce two new metrics to evaluate models in data imbalance\nsituations. Extensive experiments on a publicly available dataset (PeerRead)\nand our own collected dataset (OpenReview) demonstrate the superiority of the\nproposed approach compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:07:50 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Deng", "Zhongfen", ""], ["Peng", "Hao", ""], ["Xia", "Congying", ""], ["Li", "Jianxin", ""], ["He", "Lifang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2011.00834", "submitter": "Daniel Hershcovich", "authors": "Daniel Hershcovich, Nathan Schneider, Dotan Dvir, Jakob Prange, Miryam\n  de Lhoneux and Omri Abend", "title": "Comparison by Conversion: Reverse-Engineering UCCA from Syntax and\n  Lexical Semantics", "comments": "COLING 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building robust natural language understanding systems will require a clear\ncharacterization of whether and how various linguistic meaning representations\ncomplement each other. To perform a systematic comparative analysis, we\nevaluate the mapping between meaning representations from different frameworks\nusing two complementary methods: (i) a rule-based converter, and (ii) a\nsupervised delexicalized parser that parses to one framework using only\ninformation from the other as features. We apply these methods to convert the\nSTREUSLE corpus (with syntactic and lexical semantic annotations) to UCCA (a\ngraph-structured full-sentence meaning representation). Both methods yield\nsurprisingly accurate target representations, close to fully supervised UCCA\nparser quality---indicating that UCCA annotations are partially redundant with\nSTREUSLE annotations. Despite this substantial convergence between frameworks,\nwe find several important areas of divergence.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:03:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hershcovich", "Daniel", ""], ["Schneider", "Nathan", ""], ["Dvir", "Dotan", ""], ["Prange", "Jakob", ""], ["de Lhoneux", "Miryam", ""], ["Abend", "Omri", ""]]}, {"id": "2011.00860", "submitter": "Daniele Castellana", "authors": "Daniele Castellana, Davide Bacciu", "title": "Learning from Non-Binary Constituency Trees via Tensor Decomposition", "comments": "Accepted at COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing sentence constituency trees in binarised form is a common and\npopular approach in literature. However, constituency trees are non-binary by\nnature. The binarisation procedure changes deeply the structure, furthering\nconstituents that instead are close. In this work, we introduce a new approach\nto deal with non-binary constituency trees which leverages tensor-based models.\nIn particular, we show how a powerful composition function based on the\ncanonical tensor decomposition can exploit such a rich structure. A key point\nof our approach is the weight sharing constraint imposed on the factor\nmatrices, which allows limiting the number of model parameters. Finally, we\nintroduce a Tree-LSTM model which takes advantage of this composition function\nand we experimentally assess its performance on different NLP tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:06:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Castellana", "Daniele", ""], ["Bacciu", "Davide", ""]]}, {"id": "2011.00890", "submitter": "Yaoyiran Li", "authors": "Yaoyiran Li, Edoardo M. Ponti, Ivan Vuli\\'c and Anna Korhonen", "title": "Emergent Communication Pretraining for Few-Shot Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While state-of-the-art models that rely upon massively multilingual\npretrained encoders achieve sample efficiency in downstream applications, they\nstill require abundant amounts of unlabelled text. Nevertheless, most of the\nworld's languages lack such resources. Hence, we investigate a more radical\nform of unsupervised knowledge transfer in the absence of linguistic data. In\nparticular, for the first time we pretrain neural networks via emergent\ncommunication from referential games. Our key assumption is that grounding\ncommunication on images---as a crude approximation of real-world\nenvironments---inductively biases the model towards learning natural languages.\nOn the one hand, we show that this substantially benefits machine translation\nin few-shot settings. On the other hand, this also provides an extrinsic\nevaluation protocol to probe the properties of emergent languages ex vitro.\nIntuitively, the closer they are to natural languages, the higher the gains\nfrom pretraining on them should be. For instance, in this work we measure the\ninfluence of communication success and maximum sequence length on downstream\nperformances. Finally, we introduce a customised adapter layer and annealing\nstrategies for the regulariser of maximum-a-posteriori inference during\nfine-tuning. These turn out to be crucial to facilitate knowledge transfer and\nprevent catastrophic forgetting. Compared to a recurrent baseline, our method\nyields gains of $59.0\\%$$\\sim$$147.6\\%$ in BLEU score with only $500$ NMT\ntraining instances and $65.1\\%$$\\sim$$196.7\\%$ with $1,000$ NMT training\ninstances across four language pairs. These proof-of-concept results reveal the\npotential of emergent communication pretraining for both natural language\nprocessing tasks in resource-poor settings and extrinsic evaluation of\nartificial languages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:57:53 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Li", "Yaoyiran", ""], ["Ponti", "Edoardo M.", ""], ["Vuli\u0107", "Ivan", ""], ["Korhonen", "Anna", ""]]}, {"id": "2011.00905", "submitter": "Simon Razniewski", "authors": "Tuan-Phong Nguyen, Simon Razniewski, Gerhard Weikum", "title": "Advanced Semantics for Commonsense Knowledge Extraction", "comments": "Web interface available at https://ascent.mpi-inf.mpg.de", "journal-ref": "WWW 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge (CSK) about concepts and their properties is useful for\nAI applications such as robust chatbots. Prior works like ConceptNet, TupleKB\nand others compiled large CSK collections, but are restricted in their\nexpressiveness to subject-predicate-object (SPO) triples with simple concepts\nfor S and monolithic strings for P and O. Also, these projects have either\nprioritized precision or recall, but hardly reconcile these complementary\ngoals. This paper presents a methodology, called Ascent, to automatically build\na large-scale knowledge base (KB) of CSK assertions, with advanced\nexpressiveness and both better precision and recall than prior works. Ascent\ngoes beyond triples by capturing composite concepts with subgroups and aspects,\nand by refining assertions with semantic facets. The latter are important to\nexpress temporal and spatial validity of assertions and further qualifiers.\nAscent combines open information extraction with judicious cleaning using\nlanguage models. Intrinsic evaluation shows the superior size and quality of\nthe Ascent KB, and an extrinsic evaluation for QA-support tasks underlines the\nbenefits of Ascent.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 11:37:17 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 12:41:40 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Nguyen", "Tuan-Phong", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2011.00943", "submitter": "Yue Guan", "authors": "Yue Guan, Jingwen Leng, Chao Li, Quan Chen, Minyi Guo", "title": "How Far Does BERT Look At:Distance-based Clustering and Analysis of\n  BERT$'$s Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on the multi-head attention mechanism, especially that in\npre-trained models such as BERT, has shown us heuristics and clues in analyzing\nvarious aspects of the mechanism. As most of the research focus on probing\ntasks or hidden states, previous works have found some primitive patterns of\nattention head behavior by heuristic analytical methods, but a more systematic\nanalysis specific on the attention patterns still remains primitive. In this\nwork, we clearly cluster the attention heatmaps into significantly different\npatterns through unsupervised clustering on top of a set of proposed features,\nwhich corroborates with previous observations. We further study their\ncorresponding functions through analytical study. In addition, our proposed\nfeatures can be used to explain and calibrate different attention heads in\nTransformer models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 12:52:31 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 04:25:12 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Guan", "Yue", ""], ["Leng", "Jingwen", ""], ["Li", "Chao", ""], ["Chen", "Quan", ""], ["Guo", "Minyi", ""]]}, {"id": "2011.00948", "submitter": "Ryuto Konno", "authors": "Ryuto Konno, Yuichiroh Matsubayashi, Shun Kiyono, Hiroki Ouchi, Ryo\n  Takahashi, Kentaro Inui", "title": "An Empirical Study of Contextual Data Augmentation for Japanese Zero\n  Anaphora Resolution", "comments": "13 pages, accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One critical issue of zero anaphora resolution (ZAR) is the scarcity of\nlabeled data. This study explores how effectively this problem can be\nalleviated by data augmentation. We adopt a state-of-the-art data augmentation\nmethod, called the contextual data augmentation (CDA), that generates labeled\ntraining instances using a pretrained language model. The CDA has been reported\nto work well for several other natural language processing tasks, including\ntext classification and machine translation. This study addresses two\nunderexplored issues on CDA, that is, how to reduce the computational cost of\ndata augmentation and how to ensure the quality of the generated data. We also\npropose two methods to adapt CDA to ZAR: [MASK]-based augmentation and\nlinguistically-controlled masking. Consequently, the experimental results on\nJapanese ZAR show that our methods contribute to both the accuracy gain and the\ncomputation cost reduction. Our closer analysis reveals that the proposed\nmethod can improve the quality of the augmented training data when compared to\nthe conventional CDA.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:05:00 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:56:07 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Konno", "Ryuto", ""], ["Matsubayashi", "Yuichiroh", ""], ["Kiyono", "Shun", ""], ["Ouchi", "Hiroki", ""], ["Takahashi", "Ryo", ""], ["Inui", "Kentaro", ""]]}, {"id": "2011.00960", "submitter": "Marius Mosbach", "authors": "Marius Mosbach, Stefania Degaetano-Ortlieb, Marie-Pauline Krielke,\n  Badr M. Abdullah, Dietrich Klakow", "title": "A Closer Look at Linguistic Knowledge in Masked Language Models: The\n  Case of Relative Clauses in American English", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based language models achieve high performance on various tasks,\nbut we still lack understanding of the kind of linguistic knowledge they learn\nand rely on. We evaluate three models (BERT, RoBERTa, and ALBERT), testing\ntheir grammatical and semantic knowledge by sentence-level probing, diagnostic\ncases, and masked prediction tasks. We focus on relative clauses (in American\nEnglish) as a complex phenomenon needing contextual information and antecedent\nidentification to be resolved. Based on a naturalistic dataset, probing shows\nthat all three models indeed capture linguistic knowledge about grammaticality,\nachieving high performance. Evaluation on diagnostic cases and masked\nprediction tasks considering fine-grained linguistic knowledge, however, shows\npronounced model-specific weaknesses especially on semantic knowledge, strongly\nimpacting models' performance. Our results highlight the importance of (a)model\ncomparison in evaluation task and (b) building up claims of model performance\nand the linguistic knowledge they capture beyond purely probing-based\nevaluations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:25:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mosbach", "Marius", ""], ["Degaetano-Ortlieb", "Stefania", ""], ["Krielke", "Marie-Pauline", ""], ["Abdullah", "Badr M.", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2011.00961", "submitter": "Izumi Haruta", "authors": "Izumi Haruta, Koji Mineshima, and Daisuke Bekki", "title": "Combining Event Semantics and Degree Semantics for Natural Language\n  Inference", "comments": "5 pages, to appear in the Proceedings of COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In formal semantics, there are two well-developed semantic frameworks: event\nsemantics, which treats verbs and adverbial modifiers using the notion of\nevent, and degree semantics, which analyzes adjectives and comparatives using\nthe notion of degree. However, it is not obvious whether these frameworks can\nbe combined to handle cases in which the phenomena in question are interacting\nwith each other. Here, we study this issue by focusing on natural language\ninference (NLI). We implement a logic-based NLI system that combines event\nsemantics and degree semantics and their interaction with lexical knowledge. We\nevaluate the system on various NLI datasets containing linguistically\nchallenging problems. The results show that the system achieves high accuracies\non these datasets in comparison with previous logic-based systems and\ndeep-learning-based systems. This suggests that the two semantic frameworks can\nbe combined consistently to handle various combinations of linguistic phenomena\nwithout compromising the advantage of either framework.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:27:21 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Haruta", "Izumi", ""], ["Mineshima", "Koji", ""], ["Bekki", "Daisuke", ""]]}, {"id": "2011.00975", "submitter": "Dominique Fohr", "authors": "Dominique Fohr, Irina Illina", "title": "DNN-Based Semantic Model for Rescoring N-best Speech Recognition List", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The word error rate (WER) of an automatic speech recognition (ASR) system\nincreases when a mismatch occurs between the training and the testing\nconditions due to the noise, etc. In this case, the acoustic information can be\nless reliable. This work aims to improve ASR by modeling long-term semantic\nrelations to compensate for distorted acoustic features. We propose to perform\nthis through rescoring of the ASR N-best hypotheses list. To achieve this, we\ntrain a deep neural network (DNN). Our DNN rescoring model is aimed at\nselecting hypotheses that have better semantic consistency and therefore lower\nWER. We investigate two types of representations as part of input features to\nour DNN model: static word embeddings (from word2vec) and dynamic contextual\nembeddings (from BERT). Acoustic and linguistic features are also included. We\nperform experiments on the publicly available dataset TED-LIUM mixed with real\nnoise. The proposed rescoring approaches give significant improvement of the\nWER over the ASR system without rescoring models in two noisy conditions and\nwith n-gram and RNNLM.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:50:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fohr", "Dominique", ""], ["Illina", "Irina", ""]]}, {"id": "2011.01007", "submitter": "Steven Weber", "authors": "Steven Weber", "title": "The 2020s Political Economy of Machine Translation", "comments": "42 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the hypothesis that the diversity of human languages,\nright now a barrier to interoperability in communication and trade, will become\nsignificantly less of a barrier as machine translation technologies are\ndeployed over the next several years.But this new boundary-breaking technology\ndoes not reduce all boundaries equally, and it creates new challenges for the\ndistribution of ideas and thus for innovation and economic growth.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:28:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Weber", "Steven", ""]]}, {"id": "2011.01026", "submitter": "Ashkan Kazemi", "authors": "Ashkan Kazemi, Ver\\'onica P\\'erez-Rosas, Rada Mihalcea", "title": "Biased TextRank: Unsupervised Graph-Based Content Extraction", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Biased TextRank, a graph-based content extraction method\ninspired by the popular TextRank algorithm that ranks text spans according to\ntheir importance for language processing tasks and according to their relevance\nto an input \"focus.\" Biased TextRank enables focused content extraction for\ntext by modifying the random restarts in the execution of TextRank. The random\nrestart probabilities are assigned based on the relevance of the graph nodes to\nthe focus of the task. We present two applications of Biased TextRank: focused\nsummarization and explanation extraction, and show that our algorithm leads to\nimproved performance on two different datasets by significant ROUGE-N score\nmargins. Much like its predecessor, Biased TextRank is unsupervised, easy to\nimplement and orders of magnitude faster and lighter than current\nstate-of-the-art Natural Language Processing methods for similar tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:17:44 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kazemi", "Ashkan", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2011.01035", "submitter": "Akshar Nair", "authors": "Nikhil Fernandes, Alexandra Gkolia, Nicolas Pizzo, James Davenport,\n  Akshar Nair", "title": "Unification of HDP and LDA Models for Optimal Topic Clustering of\n  Subject Specific Question Banks", "comments": "8 pages, 5 figures, Submitted to EAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasingly popular trend in Universities for curriculum\ntransformation to make teaching more interactive and suitable for online\ncourses. An increase in the popularity of online courses would result in an\nincrease in the number of course-related queries for academics. This, coupled\nwith the fact that if lectures were delivered in a video on demand format,\nthere would be no fixed time where the majority of students could ask\nquestions. When questions are asked in a lecture there is a negligible chance\nof having similar questions repeatedly, but asynchronously this is more likely.\nIn order to reduce the time spent on answering each individual question,\nclustering them is an ideal choice. There are different unsupervised models fit\nfor text clustering, of which the Latent Dirichlet Allocation model is the most\ncommonly used. We use the Hierarchical Dirichlet Process to determine an\noptimal topic number input for our LDA model runs. Due to the probabilistic\nnature of these topic models, the outputs of them vary for different runs. The\ngeneral trend we found is that not all the topics were being used for\nclustering on the first run of the LDA model, which results in a less effective\nclustering. To tackle probabilistic output, we recursively use the LDA model on\nthe effective topics being used until we obtain an efficiency ratio of 1.\nThrough our experimental results we also establish a reasoning on how Zeno's\nparadox is avoided.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 18:21:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fernandes", "Nikhil", ""], ["Gkolia", "Alexandra", ""], ["Pizzo", "Nicolas", ""], ["Davenport", "James", ""], ["Nair", "Akshar", ""]]}, {"id": "2011.01043", "submitter": "Utkarsh Desai", "authors": "Raunak Sinha, Utkarsh Desai, Srikanth Tamilselvam, Senthil Mani", "title": "Evaluation of Siamese Networks for Semantic Code Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in the number of open repositories and discussion forums,\nthe use of natural language for semantic code search has become increasingly\ncommon. The accuracy of the results returned by such systems, however, can be\nlow due to 1) limited shared vocabulary between code and user query and 2)\ninadequate semantic understanding of user query and its relation to code\nsyntax. Siamese networks are well suited to learning such joint relations\nbetween data, but have not been explored in the context of code search. In this\nwork, we evaluate Siamese networks for this task by exploring multiple\nextraction network architectures. These networks independently process code and\ntext descriptions before passing them to a Siamese network to learn embeddings\nin a common space. We experiment on two different datasets and discover that\nSiamese networks can act as strong regularizers on networks that extract rich\ninformation from code and text, which in turn helps achieve impressive\nperformance on code search beating previous baselines on $2$ programming\nlanguages. We also analyze the embedding space of these networks and provide\ndirections to fully leverage the power of Siamese networks for semantic code\nsearch.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2020 06:07:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sinha", "Raunak", ""], ["Desai", "Utkarsh", ""], ["Tamilselvam", "Srikanth", ""], ["Mani", "Senthil", ""]]}, {"id": "2011.01060", "submitter": "Xanh Ho Thi", "authors": "Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara and Akiko Aizawa", "title": "Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of\n  Reasoning Steps", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A multi-hop question answering (QA) dataset aims to test reasoning and\ninference skills by requiring a model to read multiple paragraphs to answer a\ngiven question. However, current datasets do not provide a complete explanation\nfor the reasoning process from the question to the answer. Further, previous\nstudies revealed that many examples in existing multi-hop datasets do not\nrequire multi-hop reasoning to answer a question. In this study, we present a\nnew multi-hop QA dataset, called 2WikiMultiHopQA, which uses structured and\nunstructured data. In our dataset, we introduce the evidence information\ncontaining a reasoning path for multi-hop questions. The evidence information\nhas two benefits: (i) providing a comprehensive explanation for predictions and\n(ii) evaluating the reasoning skills of a model. We carefully design a pipeline\nand a set of templates when generating a question-answer pair that guarantees\nthe multi-hop steps and the quality of the questions. We also exploit the\nstructured format in Wikidata and use logical rules to create questions that\nare natural but still require multi-hop reasoning. Through experiments, we\ndemonstrate that our dataset is challenging for multi-hop models and it ensures\nthat multi-hop reasoning is required.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:42:40 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 07:47:48 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ho", "Xanh", ""], ["Nguyen", "Anh-Khoa Duong", ""], ["Sugawara", "Saku", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2011.01097", "submitter": "Marta R. Costa-juss\\`a", "authors": "Carlos Escolano, Marta R. Costa-juss\\`a, Jos\\'e A. R. Fonollosa,\n  Carlos Segura", "title": "Enabling Zero-shot Multilingual Spoken Language Translation with\n  Language-Specific Encoders and Decoders", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current end-to-end approaches to Spoken Language Translation (SLT) rely on\nlimited training resources, especially for multilingual settings. On the other\nhand, Multilingual Neural Machine Translation (MultiNMT) approaches rely on\nhigher quality and more massive data sets. Our proposed method extends a\nMultiNMT architecture based on language-specific encoders-decoders to the task\nof Multilingual SLT (MultiSLT) Our experiments on four different languages show\nthat coupling the speech encoder to the MultiNMT architecture produces similar\nquality translations compared to a bilingual baseline ($\\pm 0.2$ BLEU) while\neffectively allowing for zero-shot MultiSLT. Additionally, we propose using\nAdapter networks for SLT that produce consistent improvements of +1 BLEU points\nin all tested languages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:31:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Escolano", "Carlos", ""], ["Costa-juss\u00e0", "Marta R.", ""], ["Fonollosa", "Jos\u00e9 A. R.", ""], ["Segura", "Carlos", ""]]}, {"id": "2011.01102", "submitter": "Liangming Pan", "authors": "Yuxi Xie, Liangming Pan, Dongzhe Wang, Min-Yen Kan, Yansong Feng", "title": "Exploring Question-Specific Rewards for Generating Deep Questions", "comments": "COLING 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent question generation (QG) approaches often utilize the\nsequence-to-sequence framework (Seq2Seq) to optimize the log-likelihood of\nground-truth questions using teacher forcing. However, this training objective\nis inconsistent with actual question quality, which is often reflected by\ncertain global properties such as whether the question can be answered by the\ndocument. As such, we directly optimize for QG-specific objectives via\nreinforcement learning to improve question quality. We design three different\nrewards that target to improve the fluency, relevance, and answerability of\ngenerated questions. We conduct both automatic and human evaluations in\naddition to a thorough analysis to explore the effect of each QG-specific\nreward. We find that optimizing question-specific rewards generally leads to\nbetter performance in automatic evaluation metrics. However, only the rewards\nthat correlate well with human judgement (e.g., relevance) lead to real\nimprovement in question quality. Optimizing for the others, especially\nanswerability, introduces incorrect bias to the model, resulting in poor\nquestion quality. Our code is publicly available at\nhttps://github.com/YuxiXie/RL-for-Question-Generation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:37:30 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xie", "Yuxi", ""], ["Pan", "Liangming", ""], ["Wang", "Dongzhe", ""], ["Kan", "Min-Yen", ""], ["Feng", "Yansong", ""]]}, {"id": "2011.01103", "submitter": "Danilo Dess\\`i", "authors": "Danilo Dess\\`i, Francesco Osborne, Diego Reforgiato Recupero, Davide\n  Buscaldi, Enrico Motta", "title": "Generating Knowledge Graphs by Employing Natural Language Processing and\n  Machine Learning Techniques within the Scholarly Domain", "comments": "Accepted for publication in Future Generation Computer Systems\n  journal - Special Issue on Machine Learning and Knowledge Graphs", "journal-ref": null, "doi": "10.1016/j.future.2020.10.026", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous growth of scientific literature brings innovations and, at the\nsame time, raises new challenges. One of them is related to the fact that its\nanalysis has become difficult due to the high volume of published papers for\nwhich manual effort for annotations and management is required. Novel\ntechnological infrastructures are needed to help researchers, research policy\nmakers, and companies to time-efficiently browse, analyse, and forecast\nscientific research. Knowledge graphs i.e., large networks of entities and\nrelationships, have proved to be effective solution in this space. Scientific\nknowledge graphs focus on the scholarly domain and typically contain metadata\ndescribing research publications such as authors, venues, organizations,\nresearch topics, and citations. However, the current generation of knowledge\ngraphs lacks of an explicit representation of the knowledge presented in the\nresearch papers. As such, in this paper, we present a new architecture that\ntakes advantage of Natural Language Processing and Machine Learning methods for\nextracting entities and relationships from research publications and integrates\nthem in a large-scale knowledge graph. Within this research work, we i) tackle\nthe challenge of knowledge extraction by employing several state-of-the-art\nNatural Language Processing and Text Mining tools, ii) describe an approach for\nintegrating entities and relationships generated by these tools, iii) show the\nadvantage of such an hybrid system over alternative approaches, and vi) as a\nchosen use case, we generated a scientific knowledge graph including 109,105\ntriples, extracted from 26,827 abstracts of papers within the Semantic Web\ndomain. As our approach is general and can be applied to any domain, we expect\nthat it can facilitate the management, analysis, dissemination, and processing\nof scientific knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 08:31:40 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Dess\u00ec", "Danilo", ""], ["Osborne", "Francesco", ""], ["Recupero", "Diego Reforgiato", ""], ["Buscaldi", "Davide", ""], ["Motta", "Enrico", ""]]}, {"id": "2011.01130", "submitter": "Jose Patino", "authors": "Jose Patino, Natalia Tomashenko, Massimiliano Todisco, Andreas\n  Nautsch, Nicholas Evans", "title": "Speaker anonymisation using the McAdams coefficient", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymisation has the goal of manipulating speech signals in order to degrade\nthe reliability of automatic approaches to speaker recognition, while\npreserving other aspects of speech, such as those relating to intelligibility\nand naturalness. This paper reports an approach to anonymisation that, unlike\nother current approaches, requires no training data, is based upon well-known\nsignal processing techniques and is both efficient and effective. The proposed\nsolution uses the McAdams coefficient to transform the spectral envelope of\nspeech signals. Results derived using common VoicePrivacy 2020 databases and\nprotocols show that random, optimised transformations can outperform competing\nsolutions in terms of anonymisation while causing only modest, additional\ndegradations to intelligibility, even in the case of a semi-informed privacy\nadversary.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:07:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Patino", "Jose", ""], ["Tomashenko", "Natalia", ""], ["Todisco", "Massimiliano", ""], ["Nautsch", "Andreas", ""], ["Evans", "Nicholas", ""]]}, {"id": "2011.01136", "submitter": "Ruizhe Li", "authors": "Ruizhe Li, Xiao Li, Guanyi Chen, Chenghua Lin", "title": "Improving Variational Autoencoder for Text Modelling with Timestep-Wise\n  Regularisation", "comments": "Accepted by COLING 2020, final camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) is a popular and powerful model applied to\ntext modelling to generate diverse sentences. However, an issue known as\nposterior collapse (or KL loss vanishing) happens when the VAE is used in text\nmodelling, where the approximate posterior collapses to the prior, and the\nmodel will totally ignore the latent variables and be degraded to a plain\nlanguage model during text generation. Such an issue is particularly prevalent\nwhen RNN-based VAE models are employed for text modelling. In this paper, we\npropose a simple, generic architecture called Timestep-Wise Regularisation VAE\n(TWR-VAE), which can effectively avoid posterior collapse and can be applied to\nany RNN-based VAE models. The effectiveness and versatility of our model are\ndemonstrated in different tasks, including language modelling and dialogue\nresponse generation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:20:56 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 15:20:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Li", "Ruizhe", ""], ["Li", "Xiao", ""], ["Chen", "Guanyi", ""], ["Lin", "Chenghua", ""]]}, {"id": "2011.01139", "submitter": "Suphan Kirmizialtin", "authors": "Suphan Kirmizialtin, David Wrisley", "title": "Automated Transcription of Non-Latin Script Periodicals: A Case Study in\n  the Ottoman Turkish Print Archive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our study utilizes deep learning methods for the automated transcription of\nlate nineteenth- and early twentieth-century periodicals written in Arabic\nscript Ottoman Turkish (OT) using the Transkribus platform. We discuss the\nhistorical situation of OT text collections and how they were excluded for the\nmost part from the late twentieth century corpora digitization that took place\nin many Latin script languages. This exclusion has two basic reasons: the\ntechnical challenges of OCR for Arabic script languages, and the rapid\nabandonment of that very script in the Turkish historical context. In the\nspecific case of OT, opening periodical collections to digital tools require\ntraining HTR models to generate transcriptions in the Latin writing system of\ncontemporary readers of Turkish, and not, as some may expect, in right-to-left\nArabic script text. In the paper we discuss the challenges of training such\nmodels where one-to-one correspondence between the writing systems do not\nexist, and we report results based on our HTR experiments with two OT\nperiodicals from the early twentieth century. Finally, we reflect on potential\ndomain bias of HTR models in historical languages exhibiting spatio-temporal\nvariance as well as the significance of working between writing systems for\nlanguage communities that have experienced language reform and script change.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:28:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kirmizialtin", "Suphan", ""], ["Wrisley", "David", ""]]}, {"id": "2011.01154", "submitter": "Seid Muhie Yimam", "authors": "Seid Muhie Yimam and Abinew Ali Ayele and Gopalakrishnan Venkatesh and\n  Chris Biemann", "title": "Introducing various Semantic Models for Amharic: Experimentation and\n  Evaluation with multiple Tasks and Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The availability of different pre-trained semantic models enabled the quick\ndevelopment of machine learning components for downstream applications. Despite\nthe availability of abundant text data for low resource languages, only a few\nsemantic models are publicly available. Publicly available pre-trained models\nare usually built as a multilingual version of semantic models that can not fit\nwell for each language due to context variations. In this work, we introduce\ndifferent semantic models for Amharic. After we experiment with the existing\npre-trained semantic models, we trained and fine-tuned nine new different\nmodels using a monolingual text corpus. The models are build using word2Vec\nembeddings, distributional thesaurus (DT), contextual embeddings, and DT\nembeddings obtained via network embedding algorithms. Moreover, we employ these\nmodels for different NLP tasks and investigate their impact. We find that newly\ntrained models perform better than pre-trained multilingual models.\nFurthermore, models based on contextual embeddings from RoBERTA perform better\nthan the word2Vec models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:48:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yimam", "Seid Muhie", ""], ["Ayele", "Abinew Ali", ""], ["Venkatesh", "Gopalakrishnan", ""], ["Biemann", "Chris", ""]]}, {"id": "2011.01181", "submitter": "Rabab Alkhalifa", "authors": "Rabab Alkhalifa, Arkaitz Zubiaga", "title": "QMUL-SDS @ SardiStance: Leveraging Network Interactions to Boost\n  Performance on Stance Detection using Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our submission to the SardiStance 2020 shared task,\ndescribing the architecture used for Task A and Task B. While our submission\nfor Task A did not exceed the baseline, retraining our model using all the\ntraining tweets, showed promising results leading to (f-avg 0.601) using\nbidirectional LSTM with BERT multilingual embedding for Task A. For our\nsubmission for Task B, we ranked 6th (f-avg 0.709). With further investigation,\nour best experimented settings increased performance from (f-avg 0.573) to\n(f-avg 0.733) with same architecture and parameter settings and after only\nincorporating social interaction features -- highlighting the impact of social\ninteraction on the model's performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:17:51 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 14:14:15 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 17:28:23 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Alkhalifa", "Rabab", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "2011.01196", "submitter": "Brihi Joshi", "authors": "Brihi Joshi, Neil Shah, Francesco Barbieri, Leonardo Neves", "title": "The Devil is in the Details: Evaluating Limitations of Transformer-based\n  Methods for Granular Tasks", "comments": "Accepted at COLING 2020. Code available at\n  https://github.com/brihijoshi/granular-similarity-COLING-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual embeddings derived from transformer-based neural language models\nhave shown state-of-the-art performance for various tasks such as question\nanswering, sentiment analysis, and textual similarity in recent years.\nExtensive work shows how accurately such models can represent abstract,\nsemantic information present in text. In this expository work, we explore a\ntangent direction and analyze such models' performance on tasks that require a\nmore granular level of representation. We focus on the problem of textual\nsimilarity from two perspectives: matching documents on a granular level\n(requiring embeddings to capture fine-grained attributes in the text), and an\nabstract level (requiring embeddings to capture overall textual semantics). We\nempirically demonstrate, across two datasets from different domains, that\ndespite high performance in abstract document matching as expected, contextual\nembeddings are consistently (and at times, vastly) outperformed by simple\nbaselines like TF-IDF for more granular tasks. We then propose a simple but\neffective method to incorporate TF-IDF into models that use contextual\nembeddings, achieving relative improvements of up to 36% on granular tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:41:32 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Joshi", "Brihi", ""], ["Shah", "Neil", ""], ["Barbieri", "Francesco", ""], ["Neves", "Leonardo", ""]]}, {"id": "2011.01285", "submitter": "Jason Hartford", "authors": "Jason Hartford, Kevin Leyton-Brown, Hadas Raviv, Dan Padnos, Shahar\n  Lev, Barak Lenz", "title": "Exemplar Guided Active Learning", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of wisely using a limited budget to label a small\nsubset of a large unlabeled dataset. We are motivated by the NLP problem of\nword sense disambiguation. For any word, we have a set of candidate labels from\na knowledge base, but the label set is not necessarily representative of what\noccurs in the data: there may exist labels in the knowledge base that very\nrarely occur in the corpus because the sense is rare in modern English; and\nconversely there may exist true labels that do not exist in our knowledge base.\nOur aim is to obtain a classifier that performs as well as possible on examples\nof each \"common class\" that occurs with frequency above a given threshold in\nthe unlabeled set while annotating as few examples as possible from \"rare\nclasses\" whose labels occur with less than this frequency. The challenge is\nthat we are not informed which labels are common and which are rare, and the\ntrue label distribution may exhibit extreme skew. We describe an active\nlearning approach that (1) explicitly searches for rare classes by leveraging\nthe contextual embedding spaces provided by modern language models, and (2)\nincorporates a stopping rule that ignores classes once we prove that they occur\nbelow our target threshold with high probability. We prove that our algorithm\nonly costs logarithmically more than a hypothetical approach that knows all\ntrue label frequencies and show experimentally that incorporating automated\nsearch can significantly reduce the number of samples needed to reach target\naccuracy levels.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:01:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hartford", "Jason", ""], ["Leyton-Brown", "Kevin", ""], ["Raviv", "Hadas", ""], ["Padnos", "Dan", ""], ["Lev", "Shahar", ""], ["Lenz", "Barak", ""]]}, {"id": "2011.01314", "submitter": "Ganesh Jawahar", "authors": "Ganesh Jawahar, Muhammad Abdul-Mageed, Laks V.S. Lakshmanan", "title": "Automatic Detection of Machine Generated Text: A Critical Survey", "comments": "The 28th International Conference on Computational Linguistics\n  (COLING), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generative models (TGMs) excel in producing text that matches the style\nof human language reasonably well. Such TGMs can be misused by adversaries,\ne.g., by automatically generating fake news and fake product reviews that can\nlook authentic and fool humans. Detectors that can distinguish text generated\nby TGM from human written text play a vital role in mitigating such misuse of\nTGMs. Recently, there has been a flurry of works from both natural language\nprocessing (NLP) and machine learning (ML) communities to build accurate\ndetectors for English. Despite the importance of this problem, there is\ncurrently no work that surveys this fast-growing literature and introduces\nnewcomers to important research challenges. In this work, we fill this void by\nproviding a critical survey and review of this literature to facilitate a\ncomprehensive understanding of this problem. We conduct an in-depth error\nanalysis of the state-of-the-art detector and discuss research directions to\nguide future work in this exciting area.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:59:26 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Jawahar", "Ganesh", ""], ["Abdul-Mageed", "Muhammad", ""], ["Lakshmanan", "Laks V. S.", ""]]}, {"id": "2011.01403", "submitter": "Beliz Gunel", "authors": "Beliz Gunel, Jingfei Du, Alexis Conneau, Ves Stoyanov", "title": "Supervised Contrastive Learning for Pre-trained Language Model\n  Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art natural language understanding classification models follow\ntwo-stages: pre-training a large language model on an auxiliary task, and then\nfine-tuning the model on a task-specific labeled dataset using cross-entropy\nloss. However, the cross-entropy loss has several shortcomings that can lead to\nsub-optimal generalization and instability. Driven by the intuition that good\ngeneralization requires capturing the similarity between examples in one class\nand contrasting them with examples in other classes, we propose a supervised\ncontrastive learning (SCL) objective for the fine-tuning stage. Combined with\ncross-entropy, our proposed SCL loss obtains significant improvements over a\nstrong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in\nfew-shot learning settings, without requiring specialized architecture, data\naugmentations, memory banks, or additional unsupervised data. Our proposed\nfine-tuning objective leads to models that are more robust to different levels\nof noise in the fine-tuning training data, and can generalize better to related\ntasks with limited labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:10:39 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 02:05:56 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 20:27:44 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gunel", "Beliz", ""], ["Du", "Jingfei", ""], ["Conneau", "Alexis", ""], ["Stoyanov", "Ves", ""]]}, {"id": "2011.01421", "submitter": "Md Tahmid Rahman Laskar", "authors": "Md Tahmid Rahman Laskar, Enamul Hoque, Jimmy Xiangji Huang", "title": "WSL-DS: Weakly Supervised Learning with Distant Supervision for Query\n  Focused Multi-Document Abstractive Summarization", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Query Focused Multi-Document Summarization (QF-MDS) task, a set of\ndocuments and a query are given where the goal is to generate a summary from\nthese documents based on the given query. However, one major challenge for this\ntask is the lack of availability of labeled training datasets. To overcome this\nissue, in this paper, we propose a novel weakly supervised learning approach\nvia utilizing distant supervision. In particular, we use datasets similar to\nthe target dataset as the training data where we leverage pre-trained sentence\nsimilarity models to generate the weak reference summary of each individual\ndocument in a document set from the multi-document gold reference summaries.\nThen, we iteratively train our summarization model on each single-document to\nalleviate the computational complexity issue that occurs while training neural\nsummarization models in multiple documents (i.e., long sequences) at once.\nExperimental results in Document Understanding Conferences (DUC) datasets show\nthat our proposed approach sets a new state-of-the-art result in terms of\nvarious evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 02:02:55 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Laskar", "Md Tahmid Rahman", ""], ["Hoque", "Enamul", ""], ["Huang", "Jimmy Xiangji", ""]]}, {"id": "2011.01452", "submitter": "Jiacheng Wang", "authors": "Jiacheng Wang, Yong Fan, Duo Jiang, Shiqing Li", "title": "Meta-Learning for Natural Language Understanding under Continual\n  Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network has been recognized with its accomplishments on tackling\nvarious natural language understanding (NLU) tasks. Methods have been developed\nto train a robust model to handle multiple tasks to gain a general\nrepresentation of text. In this paper, we implement the model-agnostic\nmeta-learning (MAML) and Online aware Meta-learning (OML) meta-objective under\nthe continual framework for NLU tasks. We validate our methods on selected\nSuperGLUE and GLUE benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:41:10 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jiacheng", ""], ["Fan", "Yong", ""], ["Jiang", "Duo", ""], ["Li", "Shiqing", ""]]}, {"id": "2011.01459", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Bhuwan Dhingra, Graham Neubig, Zachary C. Lipton", "title": "Weakly- and Semi-supervised Evidence Extraction", "comments": "Accepted to the Findings of EMNLP 2020, to be presented at\n  BlackBoxNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many prediction tasks, stakeholders desire not only predictions but also\nsupporting evidence that a human can use to verify its correctness. However, in\npractice, additional annotations marking supporting evidence may only be\navailable for a minority of training examples (if available at all). In this\npaper, we propose new methods to combine few evidence annotations (strong\nsemi-supervision) with abundant document-level labels (weak supervision) for\nthe task of evidence extraction. Evaluating on two classification tasks that\nfeature evidence annotations, we find that our methods outperform baselines\nadapted from the interpretability literature to our task. Our approach yields\nsubstantial gains with as few as hundred evidence annotations. Code and\ndatasets to reproduce our work are available at\nhttps://github.com/danishpruthi/evidence-extraction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:05:00 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Pruthi", "Danish", ""], ["Dhingra", "Bhuwan", ""], ["Neubig", "Graham", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.01482", "submitter": "Qiang Wang", "authors": "Qiang Wang, Changliang Li, Yue Zhang, Tong Xiao, Jingbo Zhu", "title": "Layer-Wise Multi-View Learning for Neural Machine Translation", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neural machine translation is limited to the topmost encoder\nlayer's context representation and cannot directly perceive the lower encoder\nlayers. Existing solutions usually rely on the adjustment of network\narchitecture, making the calculation more complicated or introducing additional\nstructural restrictions. In this work, we propose layer-wise multi-view\nlearning to solve this problem, circumventing the necessity to change the model\nstructure. We regard each encoder layer's off-the-shelf output, a by-product in\nlayer-by-layer encoding, as the redundant view for the input sentence. In this\nway, in addition to the topmost encoder layer (referred to as the primary\nview), we also incorporate an intermediate encoder layer as the auxiliary view.\nWe feed the two views to a partially shared decoder to maintain independent\nprediction. Consistency regularization based on KL divergence is used to\nencourage the two views to learn from each other. Extensive experimental\nresults on five translation tasks show that our approach yields stable\nimprovements over multiple strong baselines. As another bonus, our method is\nagnostic to network architectures and can maintain the same inference speed as\nthe original model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 05:06:37 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Qiang", ""], ["Li", "Changliang", ""], ["Zhang", "Yue", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2011.01504", "submitter": "Harsh Patel", "authors": "Harsh Patel", "title": "BioNerFlair: biomedical named entity recognition using flair embedding\n  and sequence tagger", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: The proliferation of Biomedical research articles has made the\ntask of information retrieval more important than ever. Scientists and\nResearchers are having difficulty in finding articles that contain information\nrelevant to them. Proper extraction of biomedical entities like Disease,\nDrug/chem, Species, Gene/protein, can considerably improve the filtering of\narticles resulting in better extraction of relevant information. Performance on\nBioNer benchmarks has progressively improved because of progression in\ntransformers-based models like BERT, XLNet, OpenAI, GPT2, etc. These models\ngive excellent results; however, they are computationally expensive and we can\nachieve better scores for domain-specific tasks using other contextual\nstring-based models and LSTM-CRF based sequence tagger. Results: We introduce\nBioNerFlair, a method to train models for biomedical named entity recognition\nusing Flair plus GloVe embeddings and Bidirectional LSTM-CRF based sequence\ntagger. With almost the same generic architecture widely used for named entity\nrecognition, BioNerFlair outperforms previous state-of-the-art models. I\nperformed experiments on 8 benchmarks datasets for biomedical named entity\nrecognition. Compared to current state-of-the-art models, BioNerFlair achieves\nthe best F1-score of 90.17 beyond 84.72 on the BioCreative II gene mention\n(BC2GM) corpus, best F1-score of 94.03 beyond 92.36 on the BioCreative IV\nchemical and drug (BC4CHEMD) corpus, best F1-score of 88.73 beyond 78.58 on the\nJNLPBA corpus, best F1-score of 91.1 beyond 89.71 on the NCBI disease corpus,\nbest F1-score of 85.48 beyond 78.98 on the Species-800 corpus, while near best\nresults was observed on BC5CDR-chem, BC3CDR-disease, and LINNAEUS corpus.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 06:46:45 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Patel", "Harsh", ""]]}, {"id": "2011.01513", "submitter": "Yiming Cui", "authors": "Wentao Ma, Yiming Cui, Chenglei Si, Ting Liu, Shijin Wang, Guoping Hu", "title": "CharBERT: Character-aware Pre-trained Language Model", "comments": "12 pages, to appear at COLING 2020", "journal-ref": null, "doi": "10.18653/v1/2020.coling-main.4", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most pre-trained language models (PLMs) construct word representations at\nsubword level with Byte-Pair Encoding (BPE) or its variations, by which OOV\n(out-of-vocab) words are almost avoidable. However, those methods split a word\ninto subword units and make the representation incomplete and fragile. In this\npaper, we propose a character-aware pre-trained language model named CharBERT\nimproving on the previous methods (such as BERT, RoBERTa) to tackle these\nproblems. We first construct the contextual word embedding for each token from\nthe sequential character representations, then fuse the representations of\ncharacters and the subword representations by a novel heterogeneous interaction\nmodule. We also propose a new pre-training task named NLM (Noisy LM) for\nunsupervised character representation learning. We evaluate our method on\nquestion answering, sequence labeling, and text classification tasks, both on\nthe original datasets and adversarial misspelling test sets. The experimental\nresults show that our method can significantly improve the performance and\nrobustness of PLMs simultaneously. Pretrained models, evaluation sets, and code\nare available at https://github.com/wtma/CharBERT\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:13:06 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ma", "Wentao", ""], ["Cui", "Yiming", ""], ["Si", "Chenglei", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "2011.01536", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov", "title": "TransQuest: Translation Quality Estimation with Cross-lingual\n  Transformers", "comments": "Accepted to COLING 2020. arXiv admin note: text overlap with\n  arXiv:2010.05318", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen big advances in the field of sentence-level quality\nestimation (QE), largely as a result of using neural-based architectures.\nHowever, the majority of these methods work only on the language pair they are\ntrained on and need retraining for new language pairs. This process can prove\ndifficult from a technical point of view and is usually computationally\nexpensive. In this paper we propose a simple QE framework based on\ncross-lingual transformers, and we use it to implement and evaluate two\ndifferent neural architectures. Our evaluation shows that the proposed methods\nachieve state-of-the-art results outperforming current open-source quality\nestimation frameworks when trained on datasets from WMT. In addition, the\nframework proves very useful in transfer learning settings, especially when\ndealing with low-resourced languages, allowing us to obtain very competitive\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:34:44 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 12:20:48 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Orasan", "Constantin", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "2011.01549", "submitter": "Bosheng Ding", "authors": "Bosheng Ding, Linlin Liu, Lidong Bing, Canasai Kruengkrai, Thien Hai\n  Nguyen, Shafiq Joty, Luo Si, Chunyan Miao", "title": "DAGA: Data Augmentation with a Generation Approach for Low-resource\n  Tagging Tasks", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation techniques have been widely used to improve machine\nlearning performance as they enhance the generalization capability of models.\nIn this work, to generate high quality synthetic data for low-resource tagging\ntasks, we propose a novel augmentation method with language models trained on\nthe linearized labeled sentences. Our method is applicable to both supervised\nand semi-supervised settings. For the supervised settings, we conduct extensive\nexperiments on named entity recognition (NER), part of speech (POS) tagging and\nend-to-end target based sentiment analysis (E2E-TBSA) tasks. For the\nsemi-supervised settings, we evaluate our method on the NER task under the\nconditions of given unlabeled data only and unlabeled data plus a knowledge\nbase. The results show that our method can consistently outperform the\nbaselines, particularly when the given gold training data are less.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:49:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ding", "Bosheng", ""], ["Liu", "Linlin", ""], ["Bing", "Lidong", ""], ["Kruengkrai", "Canasai", ""], ["Nguyen", "Thien Hai", ""], ["Joty", "Shafiq", ""], ["Si", "Luo", ""], ["Miao", "Chunyan", ""]]}, {"id": "2011.01565", "submitter": "Yue Wang", "authors": "Yue Wang, Jing Li, Michael R. Lyu, and Irwin King", "title": "Cross-Media Keyphrase Prediction: A Unified Framework with\n  Multi-Modality Multi-Head Attention and Image Wordings", "comments": "EMNLP 2020 (14 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social media produces large amounts of contents every day. To help users\nquickly capture what they need, keyphrase prediction is receiving a growing\nattention. Nevertheless, most prior efforts focus on text modeling, largely\nignoring the rich features embedded in the matching images. In this work, we\nexplore the joint effects of texts and images in predicting the keyphrases for\na multimedia post. To better align social media style texts and images, we\npropose: (1) a novel Multi-Modality Multi-Head Attention (M3H-Att) to capture\nthe intricate cross-media interactions; (2) image wordings, in forms of optical\ncharacters and image attributes, to bridge the two modalities. Moreover, we\ndesign a unified framework to leverage the outputs of keyphrase classification\nand generation and couple their advantages. Extensive experiments on a\nlarge-scale dataset newly collected from Twitter show that our model\nsignificantly outperforms the previous state of the art based on traditional\nattention networks. Further analyses show that our multi-head attention is able\nto attend information from various aspects and boost classification or\ngeneration in diverse scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 08:44:18 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Yue", ""], ["Li", "Jing", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2011.01575", "submitter": "Anne Lauscher", "authors": "Anne Lauscher, Rafik Takieddin, Simone Paolo Ponzetto, and Goran\n  Glava\\v{s}", "title": "AraWEAT: Multidimensional Analysis of Biases in Arabic Word Embeddings", "comments": "accepted for WANLP 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that distributional word vector spaces often encode\nhuman biases like sexism or racism. In this work, we conduct an extensive\nanalysis of biases in Arabic word embeddings by applying a range of recently\nintroduced bias tests on a variety of embedding spaces induced from corpora in\nArabic. We measure the presence of biases across several dimensions, namely:\nembedding models (Skip-Gram, CBOW, and FastText) and vector sizes, types of\ntext (encyclopedic text, and news vs. user-generated content), dialects\n(Egyptian Arabic vs. Modern Standard Arabic), and time (diachronic analyses\nover corpora from different time periods). Our analysis yields several\ninteresting findings, e.g., that implicit gender bias in embeddings trained on\nArabic news corpora steadily increases over time (between 2007 and 2017). We\nmake the Arabic bias specifications (AraWEAT) publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 09:02:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lauscher", "Anne", ""], ["Takieddin", "Rafik", ""], ["Ponzetto", "Simone Paolo", ""], ["Glava\u0161", "Goran", ""]]}, {"id": "2011.01580", "submitter": "Si Sun", "authors": "Chenyan Xiong, Zhenghao Liu, Si Sun, Zhuyun Dai, Kaitao Zhang, Shi Yu,\n  Zhiyuan Liu, Hoifung Poon, Jianfeng Gao and Paul Bennett", "title": "CMT in TREC-COVID Round 2: Mitigating the Generalization Gaps from Web\n  to Special Domain Search", "comments": "5 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural rankers based on deep pretrained language models (LMs) have been shown\nto improve many information retrieval benchmarks. However, these methods are\naffected by their the correlation between pretraining domain and target domain\nand rely on massive fine-tuning relevance labels. Directly applying pretraining\nmethods to specific domains may result in suboptimal search quality because\nspecific domains may have domain adaption problems, such as the COVID domain.\nThis paper presents a search system to alleviate the special domain adaption\nproblem. The system utilizes the domain-adaptive pretraining and few-shot\nlearning technologies to help neural rankers mitigate the domain discrepancy\nand label scarcity problems. Besides, we also integrate dense retrieval to\nalleviate traditional sparse retrieval's vocabulary mismatch obstacle. Our\nsystem performs the best among the non-manual runs in Round 2 of the TREC-COVID\ntask, which aims to retrieve useful information from scientific literature\nrelated to COVID-19. Our code is publicly available at\nhttps://github.com/thunlp/OpenMatch.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 09:10:48 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Xiong", "Chenyan", ""], ["Liu", "Zhenghao", ""], ["Sun", "Si", ""], ["Dai", "Zhuyun", ""], ["Zhang", "Kaitao", ""], ["Yu", "Shi", ""], ["Liu", "Zhiyuan", ""], ["Poon", "Hoifung", ""], ["Gao", "Jianfeng", ""], ["Bennett", "Paul", ""]]}, {"id": "2011.01589", "submitter": "Anne Lauscher", "authors": "Lily Ng, Anne Lauscher, Joel Tetreault, Courtney Napoles", "title": "Creating a Domain-diverse Corpus for Theory-based Argument Quality\n  Assessment", "comments": "accepted for ArgMining 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models of argument quality (AQ) have focused primarily on\nassessing the overall quality or just one specific characteristic of an\nargument, such as its convincingness or its clarity. However, previous work has\nclaimed that assessment based on theoretical dimensions of argumentation could\nbenefit writers, but developing such models has been limited by the lack of\nannotated data. In this work, we describe GAQCorpus, the first large,\ndomain-diverse annotated corpus of theory-based AQ. We discuss how we designed\nthe annotation task to reliably collect a large number of judgments with\ncrowdsourcing, formulating theory-based guidelines that helped make subjective\njudgments of AQ more objective. We demonstrate how to identify arguments and\nadapt the annotation task for three diverse domains. Our work will inform\nresearch on theory-based argumentation annotation and enable the creation of\nmore diverse corpora to support computational AQ assessment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 09:40:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ng", "Lily", ""], ["Lauscher", "Anne", ""], ["Tetreault", "Joel", ""], ["Napoles", "Courtney", ""]]}, {"id": "2011.01599", "submitter": "Roman Klinger", "authors": "Laura Oberl\\\"ander, Kevin Reich and Roman Klinger", "title": "Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine\n  Learning to Infer the Emotions?", "comments": "accepted at the Third Workshop on Computational Modeling of People's\n  Opinions, Personality, and Emotions in Social Media (PEOPLES2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion recognition is predominantly formulated as text classification in\nwhich textual units are assigned to an emotion from a predefined inventory\n(e.g., fear, joy, anger, disgust, sadness, surprise, trust, anticipation). More\nrecently, semantic role labeling approaches have been developed to extract\nstructures from the text to answer questions like: \"who is described to feel\nthe emotion?\" (experiencer), \"what causes this emotion?\" (stimulus), and at\nwhich entity is it directed?\" (target). Though it has been shown that jointly\nmodeling stimulus and emotion category prediction is beneficial for both\nsubtasks, it remains unclear which of these semantic roles enables a classifier\nto infer the emotion. Is it the experiencer, because the identity of a person\nis biased towards a particular emotion (X is always happy)? Is it a particular\ntarget (everybody loves X) or a stimulus (doing X makes everybody sad)? We\nanswer these questions by training emotion classification models on five\navailable datasets annotated with at least one semantic role by masking the\nfillers of these roles in the text in a controlled manner and find that across\nmultiple corpora, stimuli and targets carry emotion information, while the\nexperiencer might be considered a confounder. Further, we analyze if informing\nthe model about the position of the role improves the classification decision.\nParticularly on literature corpora we find that the role information improves\nthe emotion classification.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:01:44 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 08:05:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Oberl\u00e4nder", "Laura", ""], ["Reich", "Kevin", ""], ["Klinger", "Roman", ""]]}, {"id": "2011.01612", "submitter": "Emily Ohman", "authors": "Emily \\\"Ohman, Marc P\\`amies, Kaisla Kajava, J\\\"org Tiedemann", "title": "XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce XED, a multilingual fine-grained emotion dataset. The dataset\nconsists of human-annotated Finnish (25k) and English sentences (30k), as well\nas projected annotations for 30 additional languages, providing new resources\nfor many low-resource languages. We use Plutchik's core emotions to annotate\nthe dataset with the addition of neutral to create a multilabel multiclass\ndataset. The dataset is carefully evaluated using language-specific BERT models\nand SVMs to show that XED performs on par with other similar datasets and is\ntherefore a useful tool for sentiment analysis and emotion detection.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:43:22 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 10:50:06 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["\u00d6hman", "Emily", ""], ["P\u00e0mies", "Marc", ""], ["Kajava", "Kaisla", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "2011.01615", "submitter": "Andreas van Cranenburgh", "authors": "Corb\\`en Poot, Andreas van Cranenburgh", "title": "A Benchmark of Rule-Based and Neural Coreference Resolution in Dutch\n  Novels and News", "comments": "Accepted for CRAC 2020 @ COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We evaluate a rule-based (Lee et al., 2013) and neural (Lee et al., 2018)\ncoreference system on Dutch datasets of two domains: literary novels and\nnews/Wikipedia text. The results provide insight into the relative strengths of\ndata-driven and knowledge-driven systems, as well as the influence of domain,\ndocument length, and annotation schemes. The neural system performs best on\nnews/Wikipedia text, while the rule-based system performs best on literature.\nThe neural system shows weaknesses with limited training data and long\ndocuments, while the rule-based system is affected by annotation differences.\nThe code and models used in this paper are available at\nhttps://github.com/andreasvc/crac2020\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:52:00 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Poot", "Corb\u00e8n", ""], ["van Cranenburgh", "Andreas", ""]]}, {"id": "2011.01624", "submitter": "Andreas van Cranenburgh", "authors": "Andreas van Cranenburgh, Corina Koolen", "title": "Results of a Single Blind Literary Taste Test with Short Anonymized\n  Novel Fragments", "comments": "Accepted for LaTeCH 2020 @ COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is an open question to what extent perceptions of literary quality are\nderived from text-intrinsic versus social factors. While supervised models can\npredict literary quality ratings from textual factors quite successfully, as\nshown in the Riddle of Literary Quality project (Koolen et al., 2020), this\ndoes not prove that social factors are not important, nor can we assume that\nreaders make judgments on literary quality in the same way and based on the\nsame information as machine learning models. We report the results of a pilot\nstudy to gauge the effect of textual features on literary ratings of\nDutch-language novels by participants in a controlled experiment with 48\nparticipants. In an exploratory analysis, we compare the ratings to those from\nthe large reader survey of the Riddle in which social factors were not\nexcluded, and to machine learning predictions of those literary ratings. We\nfind moderate to strong correlations of questionnaire ratings with the survey\nratings, but the predictions are closer to the survey ratings. Code and data:\nhttps://github.com/andreasvc/litquest\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:10:17 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["van Cranenburgh", "Andreas", ""], ["Koolen", "Corina", ""]]}, {"id": "2011.01675", "submitter": "Dianbo Sui", "authors": "Dianbo Sui, Yubo Chen, Kang Liu, Jun Zhao, Xiangrong Zeng, Shengping\n  Liu", "title": "Joint Entity and Relation Extraction with Set Prediction Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint entity and relation extraction task aims to extract all relational\ntriples from a sentence. In essence, the relational triples contained in a\nsentence are unordered. However, previous seq2seq based models require to\nconvert the set of triples into a sequence in the training phase. To break this\nbottleneck, we treat joint entity and relation extraction as a direct set\nprediction problem, so that the extraction model can get rid of the burden of\npredicting the order of multiple triples. To solve this set prediction problem,\nwe propose networks featured by transformers with non-autoregressive parallel\ndecoding. Unlike autoregressive approaches that generate triples one by one in\na certain order, the proposed networks directly output the final set of triples\nin one shot. Furthermore, we also design a set-based loss that forces unique\npredictions via bipartite matching. Compared with cross-entropy loss that\nhighly penalizes small shifts in triple order, the proposed bipartite matching\nloss is invariant to any permutation of predictions; thus, it can provide the\nproposed networks with a more accurate training signal by ignoring triple order\nand focusing on relation types and entities. Experiments on two benchmark\ndatasets show that our proposed model significantly outperforms current\nstate-of-the-art methods. Training code and trained models will be available at\nhttp://github.com/DianboWork/SPN4RE.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:04:31 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 12:47:21 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Sui", "Dianbo", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""], ["Zeng", "Xiangrong", ""], ["Liu", "Shengping", ""]]}, {"id": "2011.01678", "submitter": "Disong Wang", "authors": "Disong Wang, Songxiang Liu, Lifa Sun, Xixin Wu, Xunying Liu and Helen\n  Meng", "title": "Learning Explicit Prosody Models and Deep Speaker Embeddings for\n  Atypical Voice Conversion", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though significant progress has been made for the voice conversion (VC) of\ntypical speech, VC for atypical speech, e.g., dysarthric and second-language\n(L2) speech, remains a challenge, since it involves correcting for atypical\nprosody while maintaining speaker identity. To address this issue, we propose a\nVC system with explicit prosodic modelling and deep speaker embedding (DSE)\nlearning. First, a speech-encoder strives to extract robust phoneme embeddings\nfrom atypical speech. Second, a prosody corrector takes in phoneme embeddings\nto infer typical phoneme duration and pitch values. Third, a conversion model\ntakes phoneme embeddings and typical prosody features as inputs to generate the\nconverted speech, conditioned on the target DSE that is learned via speaker\nencoder or speaker adaptation. Extensive experiments demonstrate that speaker\nadaptation can achieve higher speaker similarity, and the speaker encoder based\nconversion model can greatly reduce dysarthric and non-native pronunciation\npatterns with improved speech intelligibility. A comparison of speech\nrecognition results between the original dysarthric speech and converted speech\nshow that absolute reduction of 47.6% character error rate (CER) and 29.3% word\nerror rate (WER) can be achieved.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:08:53 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 12:50:49 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Wang", "Disong", ""], ["Liu", "Songxiang", ""], ["Sun", "Lifa", ""], ["Wu", "Xixin", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "2011.01682", "submitter": "Ali Basirat", "authors": "Shifei Chen and Ali Basirat", "title": "Cross-lingual Word Embeddings beyond Zero-shot Machine Translation", "comments": "Accepted at the 8th Swedish Language Technology Conference\n  (SLTC-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the transferability of a multilingual neural machine translation\nmodel to unseen languages when the transfer is grounded solely on the\ncross-lingual word embeddings. Our experimental results show that the\ntranslation knowledge can transfer weakly to other languages and that the\ndegree of transferability depends on the languages' relatedness. We also\ndiscuss the limiting aspects of the multilingual architectures that cause weak\ntranslation transfer and suggest how to mitigate the limitations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:18:16 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Shifei", ""], ["Basirat", "Ali", ""]]}, {"id": "2011.01694", "submitter": "Zden\\v{e}k Kasner", "authors": "Zden\\v{e}k Kasner and Ond\\v{r}ej Du\\v{s}ek", "title": "Data-to-Text Generation with Iterative Text Editing", "comments": "Accepted for INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to data-to-text generation based on iterative\ntext editing. Our approach maximizes the completeness and semantic accuracy of\nthe output text while leveraging the abilities of recent pre-trained models for\ntext editing (LaserTagger) and language modeling (GPT-2) to improve the text\nfluency. To this end, we first transform data items to text using trivial\ntemplates, and then we iteratively improve the resulting text by a neural model\ntrained for the sentence fusion task. The output of the model is filtered by a\nsimple heuristic and reranked with an off-the-shelf pre-trained language model.\nWe evaluate our approach on two major data-to-text datasets (WebNLG, Cleaned\nE2E) and analyze its caveats and benefits. Furthermore, we show that our\nformulation of data-to-text generation opens up the possibility for zero-shot\ndomain adaptation using a general-domain dataset for sentence fusion.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:32:38 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 14:30:14 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Kasner", "Zden\u011bk", ""], ["Du\u0161ek", "Ond\u0159ej", ""]]}, {"id": "2011.01695", "submitter": "Ana-Maria Bucur", "authors": "Ana-Maria Bucur and Liviu P. Dinu", "title": "Detecting Early Onset of Depression from Social Media Text using Learned\n  Confidence Scores", "comments": "Accepted at Seventh Italian Conference on Computational Linguistics\n  CLiC-it 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational research on mental health disorders from written texts covers\nan interdisciplinary area between natural language processing and psychology. A\ncrucial aspect of this problem is prevention and early diagnosis, as suicide\nresulted from depression being the second leading cause of death for young\nadults. In this work, we focus on methods for detecting the early onset of\ndepression from social media texts, in particular from Reddit. To that end, we\nexplore the eRisk 2018 dataset and achieve good results with regard to the\nstate of the art by leveraging topic analysis and learned confidence scores to\nguide the decision process.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:34:04 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Bucur", "Ana-Maria", ""], ["Dinu", "Liviu P.", ""]]}, {"id": "2011.01696", "submitter": "Oliver Rausch", "authors": "Anton Sch\\\"afer, Nils Blach, Oliver Rausch, Maximilian Warm, Nils\n  Kr\\\"uger", "title": "Towards Automated Anamnesis Summarization: BERT-based Models for Symptom\n  Extraction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Professionals in modern healthcare systems are increasingly burdened by\ndocumentation workloads. Documentation of the initial patient anamnesis is\nparticularly relevant, forming the basis of successful further diagnostic\nmeasures. However, manually prepared notes are inherently unstructured and\noften incomplete. In this paper, we investigate the potential of modern NLP\ntechniques to support doctors in this matter. We present a dataset of German\npatient monologues, and formulate a well-defined information extraction task\nunder the constraints of real-world utility and practicality. In addition, we\npropose BERT-based models in order to solve said task. We can demonstrate\npromising performance of the models in both symptom identification and symptom\nattribute extraction, significantly outperforming simpler baselines.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:34:36 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sch\u00e4fer", "Anton", ""], ["Blach", "Nils", ""], ["Rausch", "Oliver", ""], ["Warm", "Maximilian", ""], ["Kr\u00fcger", "Nils", ""]]}, {"id": "2011.01703", "submitter": "Annette Rios", "authors": "Annette Rios and Mathias M\\\"uller and Rico Sennrich", "title": "Subword Segmentation and a Single Bridge Language Affect Zero-Shot\n  Neural Machine Translation", "comments": "Accepted at WMT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-shot neural machine translation is an attractive goal because of the\nhigh cost of obtaining data and building translation systems for new\ntranslation directions. However, previous papers have reported mixed success in\nzero-shot translation. It is hard to predict in which settings it will be\neffective, and what limits performance compared to a fully supervised system.\nIn this paper, we investigate zero-shot performance of a multilingual\nEN$\\leftrightarrow${FR,CS,DE,FI} system trained on WMT data. We find that\nzero-shot performance is highly unstable and can vary by more than 6 BLEU\nbetween training runs, making it difficult to reliably track improvements. We\nobserve a bias towards copying the source in zero-shot translation, and\ninvestigate how the choice of subword segmentation affects this bias. We find\nthat language-specific subword segmentation results in less subword copying at\ntraining time, and leads to better zero-shot performance compared to jointly\ntrained segmentation. A recent trend in multilingual models is to not train on\nparallel data between all language pairs, but have a single bridge language,\ne.g. English. We find that this negatively affects zero-shot translation and\nleads to a failure mode where the model ignores the language tag and instead\nproduces English output in zero-shot directions. We show that this bias towards\nEnglish can be effectively reduced with even a small amount of parallel data in\nsome of the non-English pairs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:45:54 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Rios", "Annette", ""], ["M\u00fcller", "Mathias", ""], ["Sennrich", "Rico", ""]]}, {"id": "2011.01709", "submitter": "Julien Balian", "authors": "Julien Balian, Raffaele Tavarone, Mathieu Poumeyrol, Alice Coucke", "title": "Small footprint Text-Independent Speaker Verification for Embedded\n  Systems", "comments": null, "journal-ref": "Acoustics, Speech and Signal Processing (ICASSP), 2021 IEEE\n  International Conference", "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network approaches to speaker verification have proven\nsuccessful, but typical computational requirements of State-Of-The-Art (SOTA)\nsystems make them unsuited for embedded applications. In this work, we present\na two-stage model architecture orders of magnitude smaller than common\nsolutions (237.5K learning parameters, 11.5MFLOPS) reaching a competitive\nresult of 3.31% Equal Error Rate (EER) on the well established VoxCeleb1\nverification test set. We demonstrate the possibility of running our solution\non small devices typical of IoT systems such as the Raspberry Pi 3B with a\nlatency smaller than 200ms on a 5s long utterance. Additionally, we evaluate\nour model on the acoustically challenging VOiCES corpus. We report a limited\nincrease in EER of 2.6 percentage points with respect to the best scoring model\nof the 2019 VOiCES from a Distance Challenge, against a reduction of 25.6 times\nin the number of learning parameters.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:53:05 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 16:18:53 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Balian", "Julien", ""], ["Tavarone", "Raffaele", ""], ["Poumeyrol", "Mathieu", ""], ["Coucke", "Alice", ""]]}, {"id": "2011.01785", "submitter": "Takaki Otake", "authors": "Takaki Otake, Sho Yokoi, Naoya Inoue, Ryo Takahashi, Tatsuki\n  Kuribayashi, Kentaro Inui", "title": "Modeling Event Salience in Narratives via Barthes' Cardinal Functions", "comments": "accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Events in a narrative differ in salience: some are more important to the\nstory than others. Estimating event salience is useful for tasks such as story\ngeneration, and as a tool for text analysis in narratology and folkloristics.\nTo compute event salience without any annotations, we adopt Barthes' definition\nof event salience and propose several unsupervised methods that require only a\npre-trained language model. Evaluating the proposed methods on folktales with\nevent salience annotation, we show that the proposed methods outperform\nbaseline methods and find fine-tuning a language model on narrative texts is a\nkey factor in improving the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:28:07 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Otake", "Takaki", ""], ["Yokoi", "Sho", ""], ["Inoue", "Naoya", ""], ["Takahashi", "Ryo", ""], ["Kuribayashi", "Tatsuki", ""], ["Inui", "Kentaro", ""]]}, {"id": "2011.01798", "submitter": "Henning Wachsmuth", "authors": "Jonas Dorsch and Henning Wachsmuth", "title": "Semi-Supervised Cleansing of Web Argument Corpora", "comments": "Accepted at ArgMining 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Debate portals and similar web platforms constitute one of the main text\nsources in computational argumentation research and its applications. While the\ncorpora built upon these sources are rich of argumentatively relevant content\nand structure, they also include text that is irrelevant, or even detrimental,\nto their purpose. In this paper, we present a precision-oriented approach to\ndetecting such irrelevant text in a semi-supervised way. Given a few seed\nexamples, the approach automatically learns basic lexical patterns of relevance\nand irrelevance and then incrementally bootstraps new patterns from sentences\nmatching the patterns. In the existing args.me corpus with 400k argumentative\ntexts, our approach detects almost 87k irrelevant sentences, at a precision of\n0.97 according to manual evaluation. With low effort, the approach can be\nadapted to other web argument corpora, providing a generic way to improve\ncorpus quality.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:45:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Dorsch", "Jonas", ""], ["Wachsmuth", "Henning", ""]]}, {"id": "2011.01837", "submitter": "Vid Kocijan", "authors": "Vid Kocijan, Oana-Maria Camburu, Thomas Lukasiewicz", "title": "The Gap on GAP: Tackling the Problem of Differing Data Distributions in\n  Bias-Measuring Datasets", "comments": "Accepted to AAAI 2021 conference and AFCI workshop at NeurIPS 2020\n  conference", "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnostic datasets that can detect biased models are an important\nprerequisite for bias reduction within natural language processing. However,\nundesired patterns in the collected data can make such tests incorrect. For\nexample, if the feminine subset of a gender-bias-measuring coreference\nresolution dataset contains sentences with a longer average distance between\nthe pronoun and the correct candidate, an RNN-based model may perform worse on\nthis subset due to long-term dependencies. In this work, we introduce a\ntheoretically grounded method for weighting test samples to cope with such\npatterns in the test data. We demonstrate the method on the GAP dataset for\ncoreference resolution. We annotate GAP with spans of all personal names and\nshow that examples in the female subset contain more personal names and a\nlonger distance between pronouns and their referents, potentially affecting the\nbias score in an undesired way. Using our weighting method, we find the set of\nweights on the test instances that should be used for coping with these\ncorrelations, and we re-evaluate 16 recently released coreference models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:50:13 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 10:27:16 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 16:36:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kocijan", "Vid", ""], ["Camburu", "Oana-Maria", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2011.01846", "submitter": "Denis Emelin", "authors": "Denis Emelin, Ivan Titov, Rico Sennrich", "title": "Detecting Word Sense Disambiguation Biases in Machine Translation for\n  Model-Agnostic Adversarial Attacks", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word sense disambiguation is a well-known source of translation errors in\nNMT. We posit that some of the incorrect disambiguation choices are due to\nmodels' over-reliance on dataset artifacts found in training data, specifically\nsuperficial word co-occurrences, rather than a deeper understanding of the\nsource text. We introduce a method for the prediction of disambiguation errors\nbased on statistical data properties, demonstrating its effectiveness across\nseveral domains and model types. Moreover, we develop a simple adversarial\nattack strategy that minimally perturbs sentences in order to elicit\ndisambiguation errors to further probe the robustness of translation models.\nOur findings indicate that disambiguation robustness varies substantially\nbetween domains and that different models trained on the same data are\nvulnerable to different attacks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:01:44 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Emelin", "Denis", ""], ["Titov", "Ivan", ""], ["Sennrich", "Rico", ""]]}, {"id": "2011.01856", "submitter": "Hannah Chen", "authors": "Hannah Chen, Yangfeng Ji, David Evans", "title": "Finding Friends and Flipping Frenemies: Automatic Paraphrase Dataset\n  Augmentation Using Graph Theory", "comments": "EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most NLP datasets are manually labeled, so suffer from inconsistent labeling\nor limited size. We propose methods for automatically improving datasets by\nviewing them as graphs with expected semantic properties. We construct a\nparaphrase graph from the provided sentence pair labels, and create an\naugmented dataset by directly inferring labels from the original sentence pairs\nusing a transitivity property. We use structural balance theory to identify\nlikely mislabelings in the graph, and flip their labels. We evaluate our\nmethods on paraphrase models trained using these datasets starting from a\npretrained BERT model, and find that the automatically-enhanced training sets\nresult in more accurate models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:18:03 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Hannah", ""], ["Ji", "Yangfeng", ""], ["Evans", "David", ""]]}, {"id": "2011.01860", "submitter": "Andreas Weise", "authors": "Andreas Weise, Rivka Levitan", "title": "Decoupling entrainment from consistency using deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human interlocutors tend to engage in adaptive behavior known as entrainment\nto become more similar to each other. Isolating the effect of consistency,\ni.e., speakers adhering to their individual styles, is a critical part of the\nanalysis of entrainment. We propose to treat speakers' initial vocal features\nas confounds for the prediction of subsequent outputs. Using two existing\nneural approaches to deconfounding, we define new measures of entrainment that\ncontrol for consistency. These successfully discriminate real interactions from\nfake ones. Interestingly, our stricter methods correlate with social variables\nin opposite direction from previous measures that do not account for\nconsistency. These results demonstrate the advantages of using neural networks\nto model entrainment, and raise questions regarding how to interpret prior\nassociations of conversation quality with entrainment measures that do not\naccount for consistency.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:30:05 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Weise", "Andreas", ""], ["Levitan", "Rivka", ""]]}, {"id": "2011.01861", "submitter": "Joshua Melton", "authors": "Joshua Melton, Arunkumar Bagavathi, Siddharth Krishnan", "title": "DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection", "comments": "Accepted at ICMLA20 Special Session: Machine Learning for Natural\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online hate speech on social media has become a fast-growing problem in\nrecent times. Nefarious groups have developed large content delivery networks\nacross several main-stream (Twitter and Facebook) and fringe (Gab, 4chan,\n8chan, etc.) outlets to deliver cascades of hate messages directed both at\nindividuals and communities. Thus addressing these issues has become a top\npriority for large-scale social media outlets. Three key challenges in\nautomated detection and classification of hateful content are the lack of\nclearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc.\n- and the lack of baseline models for fringe outlets such as Gab. In this work,\nwe propose a novel framework with three major contributions. (a) We engineer an\nensemble of deep learning models that combines the strengths of\nstate-of-the-art approaches, (b) we incorporate a tuning factor into this\nframework that leverages transfer learning to conduct automated hate speech\nclassification on unlabeled datasets, like Gab, and (c) we develop a weak\nsupervised learning methodology that allows our framework to train on unlabeled\ndata. Our ensemble models achieve an 83% hate recall on the HON dataset,\nsurpassing the performance of the state-of-the-art deep models. We demonstrate\nthat weak supervised training in combination with classifier tuning\nsignificantly increases model performance on unlabeled data from Gab, achieving\na hate recall of 67%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:32:50 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Melton", "Joshua", ""], ["Bagavathi", "Arunkumar", ""], ["Krishnan", "Siddharth", ""]]}, {"id": "2011.01900", "submitter": "Mahdi Namazifar", "authors": "Mahdi Namazifar, Gokhan Tur, Dilek Hakkani T\\\"ur", "title": "Warped Language Models for Noise Robust Language Understanding", "comments": "To appear at IEEE SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Masked Language Models (MLM) are self-supervised neural networks trained to\nfill in the blanks in a given sentence with masked tokens. Despite the\ntremendous success of MLMs for various text based tasks, they are not robust\nfor spoken language understanding, especially for spontaneous conversational\nspeech recognition noise. In this work we introduce Warped Language Models\n(WLM) in which input sentences at training time go through the same\nmodifications as in MLM, plus two additional modifications, namely inserting\nand dropping random tokens. These two modifications extend and contract the\nsentence in addition to the modifications in MLMs, hence the word \"warped\" in\nthe name. The insertion and drop modification of the input text during training\nof WLM resemble the types of noise due to Automatic Speech Recognition (ASR)\nerrors, and as a result WLMs are likely to be more robust to ASR noise. Through\ncomputational results we show that natural language understanding systems built\non top of WLMs perform better compared to those built based on MLMs, especially\nin the presence of ASR errors.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:26:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Namazifar", "Mahdi", ""], ["Tur", "Gokhan", ""], ["T\u00fcr", "Dilek Hakkani", ""]]}, {"id": "2011.01913", "submitter": "Kartikey Pant", "authors": "Tanvi Dadu and Kartikey Pant", "title": "Towards Code-switched Classification Exploiting Constituent Language\n  Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching is a commonly observed communicative phenomenon denoting a\nshift from one language to another within the same speech exchange. The\nanalysis of code-switched data often becomes an assiduous task, owing to the\nlimited availability of data. We propose converting code-switched data into its\nconstituent high resource languages for exploiting both monolingual and\ncross-lingual settings in this work. This conversion allows us to utilize the\nhigher resource availability for its constituent languages for multiple\ndownstream tasks.\n  We perform experiments for two downstream tasks, sarcasm detection and hate\nspeech detection, in the English-Hindi code-switched setting. These experiments\nshow an increase in 22% and 42.5% in F1-score for sarcasm detection and hate\nspeech detection, respectively, compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:43:19 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Dadu", "Tanvi", ""], ["Pant", "Kartikey", ""]]}, {"id": "2011.01986", "submitter": "Siyuan Feng", "authors": "Man-Ling Sung and Siyuan Feng and Tan Lee", "title": "Unsupervised Pattern Discovery from Thematic Speech Archives Based on\n  Multilingual Bottleneck Features", "comments": "8 pages, accepted and presented in APSIPA-APC 2018. This work was\n  done when Man-Ling Sung and Siyuan Feng were postgraduate students in the\n  Chinese University of Hong Kong", "journal-ref": null, "doi": "10.23919/APSIPA.2018.8659619", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study tackles the problem of automatically discovering spoken\nkeywords from untranscribed audio archives without requiring word-by-word\nspeech transcription by automatic speech recognition (ASR) technology. The\nproblem is of practical significance in many applications of speech analytics,\nincluding those concerning low-resource languages, and large amount of\nmultilingual and multi-genre data. We propose a two-stage approach, which\ncomprises unsupervised acoustic modeling and decoding, followed by pattern\nmining in acoustic unit sequences. The whole process starts by deriving and\nmodeling a set of subword-level speech units with untranscribed data. With the\nunsupervisedly trained acoustic models, a given audio archive is represented by\na pseudo transcription, from which spoken keywords can be discovered by string\nmining algorithms. For unsupervised acoustic modeling, a deep neural network\ntrained by multilingual speech corpora is used to generate speech segmentation\nand compute bottleneck features for segment clustering. Experimental results\nshow that the proposed system is able to effectively extract topic-related\nwords and phrases from the lecture recordings on MIT OpenCourseWare.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:06:48 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Sung", "Man-Ling", ""], ["Feng", "Siyuan", ""], ["Lee", "Tan", ""]]}, {"id": "2011.01991", "submitter": "Zhong Meng", "authors": "Zhong Meng, Sarangarajan Parthasarathy, Eric Sun, Yashesh Gaur,\n  Naoyuki Kanda, Liang Lu, Xie Chen, Rui Zhao, Jinyu Li, Yifan Gong", "title": "Internal Language Model Estimation for Domain-Adaptive End-to-End Speech\n  Recognition", "comments": "8 pages, 2 figures, SLT 2021", "journal-ref": "2021 IEEE Spoken Language Technology Workshop (SLT)", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The external language models (LM) integration remains a challenging task for\nend-to-end (E2E) automatic speech recognition (ASR) which has no clear division\nbetween acoustic and language models. In this work, we propose an internal LM\nestimation (ILME) method to facilitate a more effective integration of the\nexternal LM with all pre-existing E2E models with no additional model training,\nincluding the most popular recurrent neural network transducer (RNN-T) and\nattention-based encoder-decoder (AED) models. Trained with audio-transcript\npairs, an E2E model implicitly learns an internal LM that characterizes the\ntraining data in the source domain. With ILME, the internal LM scores of an E2E\nmodel are estimated and subtracted from the log-linear interpolation between\nthe scores of the E2E model and the external LM. The internal LM scores are\napproximated as the output of an E2E model when eliminating its acoustic\ncomponents. ILME can alleviate the domain mismatch between training and\ntesting, or improve the multi-domain E2E ASR. Experimented with 30K-hour\ntrained RNN-T and AED models, ILME achieves up to 15.5% and 6.8% relative word\nerror rate reductions from Shallow Fusion on out-of-domain LibriSpeech and\nin-domain Microsoft production test sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:11:04 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Meng", "Zhong", ""], ["Parthasarathy", "Sarangarajan", ""], ["Sun", "Eric", ""], ["Gaur", "Yashesh", ""], ["Kanda", "Naoyuki", ""], ["Lu", "Liang", ""], ["Chen", "Xie", ""], ["Zhao", "Rui", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2011.01993", "submitter": "Arash Einolghozati", "authors": "Arash Einolghozati, Anchit Gupta, Keith Diedrick, Sonal Gupta", "title": "Sound Natural: Content Rephrasing in Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task of rephrasing for a more natural virtual assistant.\nCurrently, virtual assistants work in the paradigm of intent slot tagging and\nthe slot values are directly passed as-is to the execution engine. However,\nthis setup fails in some scenarios such as messaging when the query given by\nthe user needs to be changed before repeating it or sending it to another user.\nFor example, for queries like 'ask my wife if she can pick up the kids' or\n'remind me to take my pills', we need to rephrase the content to 'can you pick\nup the kids' and 'take your pills' In this paper, we study the problem of\nrephrasing with messaging as a use case and release a dataset of 3000 pairs of\noriginal query and rephrased query. We show that BART, a pre-trained\ntransformers-based masked language model with auto-regressive decoding, is a\nstrong baseline for the task, and show improvements by adding a copy-pointer\nand copy loss to it. We analyze different tradeoffs of BART-based and\nLSTM-based seq2seq models, and propose a distilled LSTM-based seq2seq as the\nbest practical model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:15:46 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Einolghozati", "Arash", ""], ["Gupta", "Anchit", ""], ["Diedrick", "Keith", ""], ["Gupta", "Sonal", ""]]}, {"id": "2011.02048", "submitter": "Xutai Ma", "authors": "Xutai Ma, Juan Pino, Philipp Koehn", "title": "SimulMT to SimulST: Adapting Simultaneous Text Translation to End-to-End\n  Simultaneous Speech Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous text translation and end-to-end speech translation have recently\nmade great progress but little work has combined these tasks together. We\ninvestigate how to adapt simultaneous text translation methods such as wait-k\nand monotonic multihead attention to end-to-end simultaneous speech translation\nby introducing a pre-decision module. A detailed analysis is provided on the\nlatency-quality trade-offs of combining fixed and flexible pre-decision with\nfixed and flexible policies. We also design a novel computation-aware latency\nmetric, adapted from Average Lagging.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:47:58 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ma", "Xutai", ""], ["Pino", "Juan", ""], ["Koehn", "Philipp", ""]]}, {"id": "2011.02050", "submitter": "Ke Tran", "authors": "Ke Tran, Ming Tan", "title": "Generating Synthetic Data for Task-Oriented Semantic Parsing with\n  Hierarchical Representations", "comments": "Workshop on Structured Prediction for NLP, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern conversational AI systems support natural language understanding for a\nwide variety of capabilities. While a majority of these tasks can be\naccomplished using a simple and flat representation of intents and slots, more\nsophisticated capabilities require complex hierarchical representations\nsupported by semantic parsing. State-of-the-art semantic parsers are trained\nusing supervised learning with data labeled according to a hierarchical schema\nwhich might be costly to obtain or not readily available for a new domain. In\nthis work, we explore the possibility of generating synthetic data for neural\nsemantic parsing using a pretrained denoising sequence-to-sequence model (i.e.,\nBART). Specifically, we first extract masked templates from the existing\nlabeled utterances, and then fine-tune BART to generate synthetic utterances\nconditioning on the extracted templates. Finally, we use an auxiliary parser\n(AP) to filter the generated utterances. The AP guarantees the quality of the\ngenerated data. We show the potential of our approach when evaluating on the\nFacebook TOP dataset for navigation domain.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:55:40 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Tran", "Ke", ""], ["Tan", "Ming", ""]]}, {"id": "2011.02063", "submitter": "Djam\\'e Seddah", "authors": "Manuela Sanguinetti, Lauren Cassidy, Cristina Bosco, \\\"Ozlem\n  \\c{C}etino\\u{g}lu, Alessandra Teresa Cignarella, Teresa Lynn, Ines Rehbein,\n  Josef Ruppenhofer, Djam\\'e Seddah, Amir Zeldes", "title": "Treebanking User-Generated Content: a UD Based Overview of Guidelines,\n  Corpora and Unified Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article presents a discussion on the main linguistic phenomena which\ncause difficulties in the analysis of user-generated texts found on the web and\nin social media, and proposes a set of annotation guidelines for their\ntreatment within the Universal Dependencies (UD) framework of syntactic\nanalysis. Given on the one hand the increasing number of treebanks featuring\nuser-generated content, and its somewhat inconsistent treatment in these\nresources on the other, the aim of this article is twofold: (1) to provide a\ncondensed, though comprehensive, overview of such treebanks -- based on\navailable literature -- along with their main features and a comparative\nanalysis of their annotation criteria, and (2) to propose a set of tentative\nUD-based annotation guidelines, to promote consistent treatment of the\nparticular phenomena found in these types of texts. The overarching goal of\nthis article is to provide a common framework for researchers interested in\ndeveloping similar resources in UD, thus promoting cross-linguistic\nconsistency, which is a principle that has always been central to the spirit of\nUD.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 23:34:42 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Sanguinetti", "Manuela", ""], ["Cassidy", "Lauren", ""], ["Bosco", "Cristina", ""], ["\u00c7etino\u011flu", "\u00d6zlem", ""], ["Cignarella", "Alessandra Teresa", ""], ["Lynn", "Teresa", ""], ["Rehbein", "Ines", ""], ["Ruppenhofer", "Josef", ""], ["Seddah", "Djam\u00e9", ""], ["Zeldes", "Amir", ""]]}, {"id": "2011.02068", "submitter": "Sichang Tu", "authors": "Amir Zeldes, Lance Martin and Sichang Tu", "title": "Exhaustive Entity Recognition for Coptic: Challenges and Solutions", "comments": "9 pages, 2 figures, 5 tables. Accepted by The 4th Joint SIGHUM\n  Workshop on Computational Linguistics for Cultural Heritage, Social Sciences,\n  Humanities and Literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity recognition provides semantic access to ancient materials in the\nDigital Humanities: itexposes people and places of interest in texts that\ncannot be read exhaustively, facilitates linkingresources and can provide a\nwindow into text contents, even for texts with no translations. Inthis paper we\npresent entity recognition for Coptic, the language of Hellenistic era Egypt.\nWeevaluate NLP approaches to the task and lay out difficulties in applying them\nto a low-resource,morphologically complex language. We present solutions for\nnamed and non-named nested en-tity recognition and semi-automatic entity\nlinking to Wikipedia, relying on robust dependencyparsing, feature-based CRF\nmodels, and hand-crafted knowledge base resources, enabling highaccuracy NER\nwith orders of magnitude less data than those used for high resource\nlanguages.The results suggest avenues for research on other languages in\nsimilar settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 23:49:42 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zeldes", "Amir", ""], ["Martin", "Lance", ""], ["Tu", "Sichang", ""]]}, {"id": "2011.02070", "submitter": "Steffen Eger", "authors": "Taraka Rama and Lisa Beinborn and Steffen Eger", "title": "Probing Multilingual BERT for Genetic and Typological Signals", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We probe the layers in multilingual BERT (mBERT) for phylogenetic and\ngeographic language signals across 100 languages and compute language distances\nbased on the mBERT representations. We 1) employ the language distances to\ninfer and evaluate language trees, finding that they are close to the reference\nfamily tree in terms of quartet tree distance, 2) perform distance matrix\nregression analysis, finding that the language distances can be best explained\nby phylogenetic and worst by structural factors and 3) present a novel measure\nfor measuring diachronic meaning stability (based on cross-lingual\nrepresentation variability) which correlates significantly with published\nranked lists based on linguistic approaches. Our results contribute to the\nnascent field of typological interpretability of cross-lingual text\nrepresentations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:03:04 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Rama", "Taraka", ""], ["Beinborn", "Lisa", ""], ["Eger", "Steffen", ""]]}, {"id": "2011.02093", "submitter": "Mamoru Komachi", "authors": "Hongfei Wang, Michiki Kurosawa, Satoru Katsumata, and Mamoru Komachi", "title": "Chinese Grammatical Correction Using BERT-based Pre-trained Model", "comments": "6 pages; AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, pre-trained models have been extensively studied, and\nseveral downstream tasks have benefited from their utilization. In this study,\nwe verify the effectiveness of two methods that incorporate a BERT-based\npre-trained model developed by Cui et al. (2020) into an encoder-decoder model\non Chinese grammatical error correction tasks. We also analyze the error type\nand conclude that sentence-level errors are yet to be addressed.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 01:23:30 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Wang", "Hongfei", ""], ["Kurosawa", "Michiki", ""], ["Katsumata", "Satoru", ""], ["Komachi", "Mamoru", ""]]}, {"id": "2011.02099", "submitter": "Johanes Effendi", "authors": "Johanes Effendi, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Augmenting Images for ASR and TTS through Single-loop and Dual-loop\n  Multimodal Chain Framework", "comments": "Accepted at INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research has proposed a machine speech chain to enable automatic\nspeech recognition (ASR) and text-to-speech synthesis (TTS) to assist each\nother in semi-supervised learning and to avoid the need for a large amount of\npaired speech and text data. However, that framework still requires a large\namount of unpaired (speech or text) data. A prototype multimodal machine chain\nwas then explored to further reduce the need for a large amount of unpaired\ndata, which could improve ASR or TTS even when no more speech or text data were\navailable. Unfortunately, this framework relied on the image retrieval (IR)\nmodel, and thus it was limited to handling only those images that were already\nknown during training. Furthermore, the performance of this framework was only\ninvestigated with single-speaker artificial speech data. In this study, we\nrevamp the multimodal machine chain framework with image generation (IG) and\ninvestigate the possibility of augmenting image data for ASR and TTS using\nsingle-loop and dual-loop architectures on multispeaker natural speech data.\nExperimental results revealed that both single-loop and dual-loop multimodal\nchain frameworks enabled ASR and TTS to improve their performance using an\nimage-only dataset.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 02:26:02 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Effendi", "Johanes", ""], ["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2011.02121", "submitter": "Ryo Fujii", "authors": "Ryo Fujii, Masato Mita, Kaori Abe, Kazuaki Hanawa, Makoto Morishita,\n  Jun Suzuki and Kentaro Inui", "title": "PheMT: A Phenomenon-wise Dataset for Machine Translation Robustness on\n  User-Generated Contents", "comments": "15 pages, 4 figures, accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has shown drastic improvement in its quality\nwhen translating clean input, such as text from the news domain. However,\nexisting studies suggest that NMT still struggles with certain kinds of input\nwith considerable noise, such as User-Generated Contents (UGC) on the Internet.\nTo make better use of NMT for cross-cultural communication, one of the most\npromising directions is to develop a model that correctly handles these\nexpressions. Though its importance has been recognized, it is still not clear\nas to what creates the great gap in performance between the translation of\nclean input and that of UGC. To answer the question, we present a new dataset,\nPheMT, for evaluating the robustness of MT systems against specific linguistic\nphenomena in Japanese-English translation. Our experiments with the created\ndataset revealed that not only our in-house models but even widely used\noff-the-shelf systems are greatly disturbed by the presence of certain\nphenomena.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 04:44:47 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Fujii", "Ryo", ""], ["Mita", "Masato", ""], ["Abe", "Kaori", ""], ["Hanawa", "Kazuaki", ""], ["Morishita", "Makoto", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "2011.02126", "submitter": "Sashi Novitasari", "authors": "Sashi Novitasari, Andros Tjandra, Tomoya Yanagita, Sakriani Sakti,\n  Satoshi Nakamura", "title": "Incremental Machine Speech Chain Towards Enabling Listening while\n  Speaking in Real-time", "comments": "Accepted in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a human speech chain mechanism, a machine speech chain framework\nbased on deep learning was recently proposed for the semi-supervised\ndevelopment of automatic speech recognition (ASR) and text-to-speech synthesis\nTTS) systems. However, the mechanism to listen while speaking can be done only\nafter receiving entire input sequences. Thus, there is a significant delay when\nencountering long utterances. By contrast, humans can listen to what hey speak\nin real-time, and if there is a delay in hearing, they won't be able to\ncontinue speaking. In this work, we propose an incremental machine speech chain\ntowards enabling machine to listen while speaking in real-time. Specifically,\nwe construct incremental ASR (ISR) and incremental TTS (ITTS) by letting both\nsystems improve together through a short-term loop. Our experimental results\nreveal that our proposed framework is able to reduce delays due to long\nutterances while keeping a comparable performance to the non-incremental basic\nmachine speech chain.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 04:59:38 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Novitasari", "Sashi", ""], ["Tjandra", "Andros", ""], ["Yanagita", "Tomoya", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2011.02127", "submitter": "Sashi Novitasari", "authors": "Sashi Novitasari, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Sequence-to-Sequence Learning via Attention Transfer for Incremental\n  Speech Recognition", "comments": "Accepted in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence automatic speech recognition (ASR)\nrequires a significant delay to recognize long utterances because the output is\ngenerated after receiving entire input sequences. Although several studies\nrecently proposed sequence mechanisms for incremental speech recognition (ISR),\nusing different frameworks and learning algorithms is more complicated than the\nstandard ASR model. One main reason is because the model needs to decide the\nincremental steps and learn the transcription that aligns with the current\nshort speech segment. In this work, we investigate whether it is possible to\nemploy the original architecture of attention-based ASR for ISR tasks by\ntreating a full-utterance ASR as the teacher model and the ISR as the student\nmodel. We design an alternative student network that, instead of using a\nthinner or a shallower model, keeps the original architecture of the teacher\nmodel but with shorter sequences (few encoder and decoder states). Using\nattention transfer, the student network learns to mimic the same alignment\nbetween the current input short speech segments and the transcription. Our\nexperiments show that by delaying the starting time of recognition process with\nabout 1.7 sec, we can achieve comparable performance to one that needs to wait\nuntil the end.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 05:06:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Novitasari", "Sashi", ""], ["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2011.02128", "submitter": "Sashi Novitasari", "authors": "Sashi Novitasari, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "Cross-Lingual Machine Speech Chain for Javanese, Sundanese, Balinese,\n  and Bataks Speech Recognition and Synthesis", "comments": "Accepted in SLTU-CCURL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though over seven hundred ethnic languages are spoken in Indonesia, the\navailable technology remains limited that could support communication within\nindigenous communities as well as with people outside the villages. As a\nresult, indigenous communities still face isolation due to cultural barriers;\nlanguages continue to disappear. To accelerate communication, speech-to-speech\ntranslation (S2ST) technology is one approach that can overcome language\nbarriers. However, S2ST systems require machine translation (MT), speech\nrecognition (ASR), and synthesis (TTS) that rely heavily on supervised training\nand a broad set of language resources that can be difficult to collect from\nethnic communities. Recently, a machine speech chain mechanism was proposed to\nenable ASR and TTS to assist each other in semi-supervised learning. The\nframework was initially implemented only for monolingual languages. In this\nstudy, we focus on developing speech recognition and synthesis for these\nIndonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. We\nfirst separately train ASR and TTS of standard Indonesian in supervised\ntraining. We then develop ASR and TTS of ethnic languages by utilizing\nIndonesian ASR and TTS in a cross-lingual machine speech chain framework with\nonly text or only speech data removing the need for paired speech-text data of\nthose ethnic languages.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 05:13:32 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Novitasari", "Sashi", ""], ["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2011.02143", "submitter": "Alice Coucke", "authors": "St\\'ephane d'Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre\n  Caulier, Marc Lelarge", "title": "Conditioned Text Generation with Transfer for Closed-Domain Dialogue\n  Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.03698", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of training data for task-oriented dialogue systems is a well known\nproblem that is usually tackled with costly and time-consuming manual data\nannotation. An alternative solution is to rely on automatic text generation\nwhich, although less accurate than human supervision, has the advantage of\nbeing cheap and fast. Our contribution is twofold. First we show how to\noptimally train and control the generation of intent-specific sentences using a\nconditional variational autoencoder. Then we introduce a new protocol called\nquery transfer that allows to leverage a large unlabelled dataset, possibly\ncontaining irrelevant queries, to extract relevant information. Comparison with\ntwo different baselines shows that this method, in the appropriate regime,\nconsistently improves the diversity of the generated queries without\ncompromising their quality. We also demonstrate the effectiveness of our\ngeneration method as a data augmentation technique for language modelling\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:06:10 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Coucke", "Alice", ""], ["Caltagirone", "Francesco", ""], ["Caulier", "Alexandre", ""], ["Lelarge", "Marc", ""]]}, {"id": "2011.02160", "submitter": "Chenpeng Du", "authors": "Chenpeng Du, Hao Li, Yizhou Lu, Lan Wang, Yanmin Qian", "title": "Data Augmentation for End-to-end Code-switching Speech Recognition", "comments": "Accepted by SLT2021", "journal-ref": "2021 IEEE Spoken Language Technology Workshop (SLT)", "doi": "10.1109/slt48900.2021.9383620", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a code-switching end-to-end automatic speech recognition (ASR) model\nnormally requires a large amount of data, while code-switching data is often\nlimited. In this paper, three novel approaches are proposed for code-switching\ndata augmentation. Specifically, they are audio splicing with the existing\ncode-switching data, and TTS with new code-switching texts generated by word\ntranslation or word insertion. Our experiments on 200 hours Mandarin-English\ncode-switching dataset show that all the three proposed approaches yield\nsignificant improvements on code-switching ASR individually. Moreover, all the\nproposed approaches can be combined with recent popular SpecAugment, and an\naddition gain can be obtained. WER is significantly reduced by relative 24.0%\ncompared to the system without any data augmentation, and still relative 13.0%\ngain compared to the system with only SpecAugment\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:12:44 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Du", "Chenpeng", ""], ["Li", "Hao", ""], ["Lu", "Yizhou", ""], ["Wang", "Lan", ""], ["Qian", "Yanmin", ""]]}, {"id": "2011.02164", "submitter": "Tanzila Rahman", "authors": "Tanzila Rahman, Shih-Han Chou, Leonid Sigal and Giuseppe Carenini", "title": "An Improved Attention for Visual Question Answering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Visual Question Answering (VQA). Given an image\nand a free-form, open-ended, question, expressed in natural language, the goal\nof VQA system is to provide accurate answer to this question with respect to\nthe image. The task is challenging because it requires simultaneous and\nintricate understanding of both visual and textual information. Attention,\nwhich captures intra- and inter-modal dependencies, has emerged as perhaps the\nmost widely used mechanism for addressing these challenges. In this paper, we\npropose an improved attention-based architecture to solve VQA. We incorporate\nan Attention on Attention (AoA) module within encoder-decoder framework, which\nis able to determine the relation between attention results and queries.\nAttention module generates weighted average for each query. On the other hand,\nAoA module first generates an information vector and an attention gate using\nattention results and current context; and then adds another attention to\ngenerate final attended information by multiplying the two. We also propose\nmultimodal fusion module to combine both visual and textual information. The\ngoal of this fusion module is to dynamically decide how much information should\nbe considered from each modality. Extensive experiments on VQA-v2 benchmark\ndataset show that our method achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:34:54 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 21:30:01 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 19:59:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Rahman", "Tanzila", ""], ["Chou", "Shih-Han", ""], ["Sigal", "Leonid", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2011.02173", "submitter": "Riku Kawamura", "authors": "Riku Kawamura, Tatsuya Aoki, Hidetaka Kamigaito, Hiroya Takamura and\n  Manabu Okumura", "title": "Neural text normalization leveraging similarities of strings and sounds", "comments": "6 pages, accepted to COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose neural models that can normalize text by considering the\nsimilarities of word strings and sounds. We experimentally compared a model\nthat considers the similarities of both word strings and sounds, a model that\nconsiders only the similarity of word strings or of sounds, and a model without\nthe similarities as a baseline. Results showed that leveraging the word string\nsimilarity succeeded in dealing with misspellings and abbreviations, and taking\ninto account the sound similarity succeeded in dealing with phonetic\nsubstitutions and emphasized characters. So that the proposed models achieved\nhigher F$_1$ scores than the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 08:24:05 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kawamura", "Riku", ""], ["Aoki", "Tatsuya", ""], ["Kamigaito", "Hidetaka", ""], ["Takamura", "Hiroya", ""], ["Okumura", "Manabu", ""]]}, {"id": "2011.02177", "submitter": "Michael Fromm", "authors": "Michael Fromm, Max Berrendorf, Sandra Obermeier, Thomas Seidl, Evgeniy\n  Faerman", "title": "Diversity Aware Relevance Learning for Argument Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of retrieving relevant arguments for a\nquery claim covering diverse aspects. State-of-the-art methods rely on explicit\nmappings between claims and premises, and thus are unable to utilize large\navailable collections of premises without laborious and costly manual\nannotation. Their diversity approach relies on removing duplicates via\nclustering which does not directly ensure that the selected premises cover all\naspects. This work introduces a new multi-step approach for the argument\nretrieval problem. Rather than relying on ground-truth assignments, our\napproach employs a machine learning model to capture semantic relationships\nbetween arguments. Beyond that, it aims to cover diverse facets of the query,\ninstead of trying to identify duplicates explicitly. Our empirical evaluation\ndemonstrates that our approach leads to a significant improvement in the\nargument retrieval task even though it requires less data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 08:37:44 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 12:29:18 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 15:02:40 GMT"}, {"version": "v4", "created": "Wed, 17 Mar 2021 11:25:56 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Fromm", "Michael", ""], ["Berrendorf", "Max", ""], ["Obermeier", "Sandra", ""], ["Seidl", "Thomas", ""], ["Faerman", "Evgeniy", ""]]}, {"id": "2011.02207", "submitter": "Dongha Choi", "authors": "Dongha Choi and Hyunju Lee", "title": "Extracting Chemical-Protein Interactions via Calibrated Deep Neural\n  Network and Self-training", "comments": "10 pages, 4 figures, accepted for the Findings of EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of interactions between chemicals and proteins from several\nbiomedical articles is important in many fields of biomedical research such as\ndrug development and prediction of drug side effects. Several natural language\nprocessing methods, including deep neural network (DNN) models, have been\napplied to address this problem. However, these methods were trained with\nhard-labeled data, which tend to become over-confident, leading to degradation\nof the model reliability. To estimate the data uncertainty and improve the\nreliability, \"calibration\" techniques have been applied to deep learning\nmodels. In this study, to extract chemical--protein interactions, we propose a\nDNN-based approach incorporating uncertainty information and calibration\ntechniques. Our model first encodes the input sequence using a pre-trained\nlanguage-understanding model, following which it is trained using two\ncalibration methods: mixup training and addition of a confidence penalty loss.\nFinally, the model is re-trained with augmented data that are extracted using\nthe estimated uncertainties. Our approach has achieved state-of-the-art\nperformance with regard to the Biocreative VI ChemProt task, while preserving\nhigher calibration abilities than those of previous approaches. Furthermore,\nour approach also presents the possibilities of using uncertainty estimation\nfor performance improvement.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 10:14:31 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Choi", "Dongha", ""], ["Lee", "Hyunju", ""]]}, {"id": "2011.02243", "submitter": "Yacine Kessaci", "authors": "Carlos Miranda and Yacine Kessaci", "title": "Hybrid Supervised Reinforced Model for Dialogue Systems", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a recurrent hybrid model and training procedure for\ntask-oriented dialogue systems based on Deep Recurrent Q-Networks (DRQN). The\nmodel copes with both tasks required for Dialogue Management: State Tracking\nand Decision Making. It is based on modeling Human-Machine interaction into a\nlatent representation embedding an interaction context to guide the discussion.\nThe model achieves greater performance, learning speed and robustness than a\nnon-recurrent baseline. Moreover, results allow interpreting and validating the\npolicy evolution and the latent representations information-wise.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:03:12 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Miranda", "Carlos", ""], ["Kessaci", "Yacine", ""]]}, {"id": "2011.02252", "submitter": "Sri Karlapati", "authors": "Sri Karlapati, Ammar Abbas, Zack Hodari, Alexis Moinet, Arnaud Joly,\n  Penny Karanasou, Thomas Drugman", "title": "Prosodic Representation Learning and Contextual Sampling for Neural\n  Text-to-Speech", "comments": "5 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Kathaka, a model trained with a novel two-stage\ntraining process for neural speech synthesis with contextually appropriate\nprosody. In Stage I, we learn a prosodic distribution at the sentence level\nfrom mel-spectrograms available during training. In Stage II, we propose a\nnovel method to sample from this learnt prosodic distribution using the\ncontextual information available in text. To do this, we use BERT on text, and\ngraph-attention networks on parse trees extracted from text. We show a\nstatistically significant relative improvement of $13.2\\%$ in naturalness over\na strong baseline when compared to recordings. We also conduct an ablation\nstudy on variations of our sampling technique, and show a statistically\nsignificant improvement over the baseline in each case.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:20:21 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Karlapati", "Sri", ""], ["Abbas", "Ammar", ""], ["Hodari", "Zack", ""], ["Moinet", "Alexis", ""], ["Joly", "Arnaud", ""], ["Karanasou", "Penny", ""], ["Drugman", "Thomas", ""]]}, {"id": "2011.02266", "submitter": "Ali Araabi", "authors": "Ali Araabi, Christof Monz", "title": "Optimizing Transformer for Low-Resource Neural Machine Translation", "comments": "To be published in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language pairs with limited amounts of parallel data, also known as\nlow-resource languages, remain a challenge for neural machine translation.\nWhile the Transformer model has achieved significant improvements for many\nlanguage pairs and has become the de facto mainstream architecture, its\ncapability under low-resource conditions has not been fully investigated yet.\nOur experiments on different subsets of the IWSLT14 training data show that the\neffectiveness of Transformer under low-resource conditions is highly dependent\non the hyper-parameter settings. Our experiments show that using an optimized\nTransformer for low-resource conditions improves the translation quality up to\n7.3 BLEU points compared to using the Transformer default settings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:12:29 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Araabi", "Ali", ""], ["Monz", "Christof", ""]]}, {"id": "2011.02314", "submitter": "Kun Zhou", "authors": "Kun Zhou, Berrak Sisman, Haizhou Li", "title": "VAW-GAN for Disentanglement and Recomposition of Emotional Elements in\n  Speech", "comments": "Accepted by IEEE SLT 2021. arXiv admin note: text overlap with\n  arXiv:2005.07025", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotional voice conversion (EVC) aims to convert the emotion of speech from\none state to another while preserving the linguistic content and speaker\nidentity. In this paper, we study the disentanglement and recomposition of\nemotional elements in speech through variational autoencoding Wasserstein\ngenerative adversarial network (VAW-GAN). We propose a speaker-dependent EVC\nframework based on VAW-GAN, that includes two VAW-GAN pipelines, one for\nspectrum conversion, and another for prosody conversion. We train a spectral\nencoder that disentangles emotion and prosody (F0) information from spectral\nfeatures; we also train a prosodic encoder that disentangles emotion modulation\nof prosody (affective prosody) from linguistic prosody. At run-time, the\ndecoder of spectral VAW-GAN is conditioned on the output of prosodic VAW-GAN.\nThe vocoder takes the converted spectral and prosodic features to generate the\ntarget emotional speech. Experiments validate the effectiveness of our proposed\nmethod in both objective and subjective evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 08:49:33 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zhou", "Kun", ""], ["Sisman", "Berrak", ""], ["Li", "Haizhou", ""]]}, {"id": "2011.02320", "submitter": "Hengzhao Ma", "authors": "Hengzhao Ma, Jianzhong Li", "title": "PCP Theorems, SETH and More: Towards Proving Sub-linear Time\n  Inapproximability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the PCP-like theorem for sub-linear time\ninapproximability. Abboud et al. have devised the distributed PCP framework for\nsub-quadratic time inapproximability. We show that the distributed PCP theorem\ncan be generalized for proving arbitrary polynomial time inapproximability, but\nfails in the linear case. We prove the sub-linear PCP theorem by adapting from\nan MA-protocol for the Set Containment problem, and show how to use the theorem\nto prove both existing and new inapproximability results, exhibiting the power\nof the sub-linear PCP theorem. Considering the emerging research works on\nsub-linear time algorithms, the sub-linear PCP theorem is important in guiding\nthe research in sub-linear time approximation algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:39:41 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 12:18:07 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 03:52:59 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ma", "Hengzhao", ""], ["Li", "Jianzhong", ""]]}, {"id": "2011.02323", "submitter": "Kumar Shridhar", "authors": "Kushal Jain, Adwait Deshpande, Kumar Shridhar, Felix Laumann, Ayushman\n  Dash", "title": "Indic-Transformers: An Analysis of Transformer Language Models for\n  Indian Languages", "comments": "Accepted at ML-RSA @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models based on the Transformer architecture have achieved\nstate-of-the-art performance on a wide range of NLP tasks such as text\nclassification, question-answering, and token classification. However, this\nperformance is usually tested and reported on high-resource languages, like\nEnglish, French, Spanish, and German. Indian languages, on the other hand, are\nunderrepresented in such benchmarks. Despite some Indian languages being\nincluded in training multilingual Transformer models, they have not been the\nprimary focus of such work. In order to evaluate the performance on Indian\nlanguages specifically, we analyze these language models through extensive\nexperiments on multiple downstream tasks in Hindi, Bengali, and Telugu\nlanguage. Here, we compare the efficacy of fine-tuning model parameters of\npre-trained models against that of training a language model from scratch.\nMoreover, we empirically argue against the strict dependency between the\ndataset size and model performance, but rather encourage task-specific model\nand method selection. We achieve state-of-the-art performance on Hindi and\nBengali languages for text classification task. Finally, we present effective\nstrategies for handling the modeling of Indian languages and we release our\nmodel checkpoints for the community :\nhttps://huggingface.co/neuralspace-reverie.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:43:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Jain", "Kushal", ""], ["Deshpande", "Adwait", ""], ["Shridhar", "Kumar", ""], ["Laumann", "Felix", ""], ["Dash", "Ayushman", ""]]}, {"id": "2011.02378", "submitter": "Minghuan Tan", "authors": "Minghuan Tan and Jing Jiang", "title": "A BERT-based Dual Embedding Model for Chinese Idiom Prediction", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chinese idioms are special fixed phrases usually derived from ancient\nstories, whose meanings are oftentimes highly idiomatic and non-compositional.\nThe Chinese idiom prediction task is to select the correct idiom from a set of\ncandidate idioms given a context with a blank. We propose a BERT-based dual\nembedding model to encode the contextual words as well as to learn dual\nembeddings of the idioms. Specifically, we first match the embedding of each\ncandidate idiom with the hidden representation corresponding to the blank in\nthe context. We then match the embedding of each candidate idiom with the\nhidden representations of all the tokens in the context thorough context\npooling. We further propose to use two separate idiom embeddings for the two\nkinds of matching. Experiments on a recently released Chinese idiom cloze test\ndataset show that our proposed method performs better than the existing state\nof the art. Ablation experiments also show that both context pooling and dual\nembedding contribute to the improvement of performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:12:39 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Tan", "Minghuan", ""], ["Jiang", "Jing", ""]]}, {"id": "2011.02417", "submitter": "Tristan Thrush", "authors": "Tristan Thrush, Ethan Wilcox, and Roger Levy", "title": "Investigating Novel Verb Learning in BERT: Selectional Preference\n  Classes and Alternation-Based Syntactic Generalization", "comments": "Accepted to BlackboxNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies investigating the syntactic abilities of deep learning\nmodels have not targeted the relationship between the strength of the\ngrammatical generalization and the amount of evidence to which the model is\nexposed during training. We address this issue by deploying a novel\nword-learning paradigm to test BERT's few-shot learning capabilities for two\naspects of English verbs: alternations and classes of selectional preferences.\nFor the former, we fine-tune BERT on a single frame in a verbal-alternation\npair and ask whether the model expects the novel verb to occur in its sister\nframe. For the latter, we fine-tune BERT on an incomplete selectional network\nof verbal objects and ask whether it expects unattested but plausible\nverb/object pairs. We find that BERT makes robust grammatical generalizations\nafter just one or two instances of a novel word in fine-tuning. For the verbal\nalternation tests, we find that the model displays behavior that is consistent\nwith a transitivity bias: verbs seen few times are expected to take direct\nobjects, but verbs seen with direct objects are not expected to occur\nintransitively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:17:49 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Thrush", "Tristan", ""], ["Wilcox", "Ethan", ""], ["Levy", "Roger", ""]]}, {"id": "2011.02511", "submitter": "Carolin Lawrence", "authors": "Julia Kreutzer, Stefan Riezler, Carolin Lawrence", "title": "Offline Reinforcement Learning from Human Feedback in Real-World\n  Sequence-to-Sequence Tasks", "comments": "5th Workshop on Structured Prediction for NLP at ACL 2021 Previously\n  named \"Learning from Human Feedback: Challenges for Real-World Reinforcement\n  Learning in NLP\" and presented at Challenges of Real-World RL Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large volumes of interaction logs can be collected from NLP systems that are\ndeployed in the real world. How can this wealth of information be leveraged?\nUsing such interaction logs in an offline reinforcement learning (RL) setting\nis a promising approach. However, due to the nature of NLP tasks and the\nconstraints of production systems, a series of challenges arise. We present a\nconcise overview of these challenges and discuss possible solutions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 19:30:46 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 21:27:22 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 07:23:44 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kreutzer", "Julia", ""], ["Riezler", "Stefan", ""], ["Lawrence", "Carolin", ""]]}, {"id": "2011.02541", "submitter": "Shiva Taslimipoor", "authors": "Shiva Taslimipoor, Sara Bahaadini, Ekaterina Kochmar", "title": "MTLB-STRUCT @PARSEME 2020: Capturing Unseen Multiword Expressions Using\n  Multi-task Learning and Pre-trained Masked Language Models", "comments": "accepted for publication at MWE-LEX 2020 Workshop at COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a semi-supervised system that jointly learns verbal\nmultiword expressions (VMWEs) and dependency parse trees as an auxiliary task.\nThe model benefits from pre-trained multilingual BERT. BERT hidden layers are\nshared among the two tasks and we introduce an additional linear layer to\nretrieve VMWE tags. The dependency parse tree prediction is modelled by a\nlinear layer and a bilinear one plus a tree CRF on top of BERT. The system has\nparticipated in the open track of the PARSEME shared task 2020 and ranked first\nin terms of F1-score in identifying unseen VMWEs as well as VMWEs in general,\naveraged across all 14 languages.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:16:48 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Taslimipoor", "Shiva", ""], ["Bahaadini", "Sara", ""], ["Kochmar", "Ekaterina", ""]]}, {"id": "2011.02566", "submitter": "Benjamin Spiegel", "authors": "Benjamin A. Spiegel, Vincent Cheong, James E. Kaplan, Anthony Sanchez", "title": "MK-SQuIT: Synthesizing Questions using Iterative Template-filling", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to create a framework for synthetically generating\nquestion/query pairs with as little human input as possible. These datasets can\nbe used to train machine translation systems to convert natural language\nquestions into queries, a useful tool that could allow for more natural access\nto database information. Existing methods of dataset generation require human\ninput that scales linearly with the size of the dataset, resulting in small\ndatasets. Aside from a short initial configuration task, no human input is\nrequired during the query generation process of our system. We leverage\nWikiData, a knowledge base of RDF triples, as a source for generating the main\ncontent of questions and queries. Using multiple layers of question templating\nwe are able to sidestep some of the most challenging parts of query generation\nthat have been handled by humans in previous methods; humans never have to\nmodify, aggregate, inspect, annotate, or generate any questions or queries at\nany step in the process. Our system is easily configurable to multiple domains\nand can be modified to generate queries in natural languages other than\nEnglish. We also present an example dataset of 110,000 question/query pairs\nacross four WikiData domains. We then present a baseline model that we train\nusing the dataset which shows promise in a commercial QA setting.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 22:33:05 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Spiegel", "Benjamin A.", ""], ["Cheong", "Vincent", ""], ["Kaplan", "James E.", ""], ["Sanchez", "Anthony", ""]]}, {"id": "2011.02593", "submitter": "Chunting Zhou", "authors": "Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Paco Guzman, Luke\n  Zettlemoyer, Marjan Ghazvininejad", "title": "Detecting Hallucinated Content in Conditional Neural Sequence Generation", "comments": "Accepted by ACL-Finding 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence models can generate highly fluent sentences, but recent\nstudies have also shown that they are also prone to hallucinate additional\ncontent not supported by the input. These variety of fluent but wrong outputs\nare particularly problematic, as it will not be possible for users to tell they\nare being presented incorrect content. To detect these errors, we propose a\ntask to predict whether each token in the output sequence is hallucinated (not\ncontained in the input) and collect new manually annotated evaluation sets for\nthis task. We also introduce a method for learning to detect hallucinations\nusing pretrained language models fine tuned on synthetic data that includes\nautomatically inserted hallucinations Experiments on machine translation (MT)\nand abstractive summarization demonstrate that our proposed approach\nconsistently outperforms strong baselines on all benchmark datasets. We further\ndemonstrate how to use the token-level hallucination labels to define a\nfine-grained loss over the target sequence in low-resource MT and achieve\nsignificant improvements over strong baseline methods. We also apply our method\nto word-level quality estimation for MT and show its effectiveness in both\nsupervised and unsupervised settings. Codes and data available at\nhttps://github.com/violet-zct/fairseq-detect-hallucination.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 00:18:53 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 21:05:03 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 20:26:55 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhou", "Chunting", ""], ["Neubig", "Graham", ""], ["Gu", "Jiatao", ""], ["Diab", "Mona", ""], ["Guzman", "Paco", ""], ["Zettlemoyer", "Luke", ""], ["Ghazvininejad", "Marjan", ""]]}, {"id": "2011.02610", "submitter": "Zonglin Yang", "authors": "Zonglin Yang, Xinya Du, Alexander Rush, Claire Cardie", "title": "Improving Event Duration Prediction via Time-aware Pre-training", "comments": "to be published in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models in NLP rarely encode external world knowledge about length\nof time. We introduce two effective models for duration prediction, which\nincorporate external knowledge by reading temporal-related news sentences\n(time-aware pre-training). Specifically, one model predicts the range/unit\nwhere the duration value falls in (R-pred); and the other predicts the exact\nduration value E-pred. Our best model -- E-pred, substantially outperforms\nprevious work, and captures duration information more accurately than R-pred.\nWe also demonstrate our models are capable of duration prediction in the\nunsupervised setting, outperforming the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:52:11 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Yang", "Zonglin", ""], ["Du", "Xinya", ""], ["Rush", "Alexander", ""], ["Cardie", "Claire", ""]]}, {"id": "2011.02665", "submitter": "Tony Gracious", "authors": "Tony Gracious, Ambedkar Dukkipati", "title": "Adversarial Context Aware Network Embeddings for Textual Networks", "comments": "8 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning of textual networks poses a significant challenge as\nit involves capturing amalgamated information from two modalities: (i)\nunderlying network structure, and (ii) node textual attributes. For this, most\nexisting approaches learn embeddings of text and network structure by enforcing\nembeddings of connected nodes to be similar. Then for achieving a modality\nfusion they use the similarities between text embedding of a node with the\nstructure embedding of its connected node and vice versa. This implies that\nthese approaches require edge information for learning embeddings and they\ncannot learn embeddings of unseen nodes. In this paper we propose an approach\nthat achieves both modality fusion and the capability to learn embeddings of\nunseen nodes. The main feature of our model is that it uses an adversarial\nmechanism between text embedding based discriminator, and structure embedding\nbased generator to learn efficient representations. Then for learning\nembeddings of unseen nodes, we use the supervision provided by the text\nembedding based discriminator. In addition this, we propose a novel\narchitecture for learning text embedding that can combine both mutual attention\nand topological attention mechanism, which give more flexible text embeddings.\nThrough extensive experiments on real-world datasets, we demonstrate that our\nmodel makes substantial gains over several state-of-the-art benchmarks. In\ncomparison with previous state-of-the-art, it gives up to 7% improvement in\nperformance in predicting links among nodes seen in the training and up to 12%\nimprovement in performance in predicting links involving nodes not seen in\ntraining. Further, in the node classification task, it gives up to 2%\nimprovement in performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 05:20:01 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gracious", "Tony", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2011.02678", "submitter": "Andreas Stolcke", "authors": "Eunjung Han, Chul Lee, Andreas Stolcke", "title": "BW-EDA-EEND: Streaming End-to-End Neural Speaker Diarization for a\n  Variable Number of Speakers", "comments": null, "journal-ref": "Proc. IEEE ICASSP 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel online end-to-end neural diarization system, BW-EDA-EEND,\nthat processes data incrementally for a variable number of speakers. The system\nis based on the Encoder-Decoder-Attractor (EDA) architecture of Horiguchi et\nal., but utilizes the incremental Transformer encoder, attending only to its\nleft contexts and using block-level recurrence in the hidden states to carry\ninformation from block to block, making the algorithm complexity linear in\ntime. We propose two variants: For unlimited-latency BW-EDA-EEND, which\nprocesses inputs in linear time, we show only moderate degradation for up to\ntwo speakers using a context size of 10 seconds compared to offline EDA-EEND.\nWith more than two speakers, the accuracy gap between online and offline grows,\nbut the algorithm still outperforms a baseline offline clustering diarization\nsystem for one to four speakers with unlimited context size, and shows\ncomparable accuracy with context size of 10 seconds. For limited-latency\nBW-EDA-EEND, which produces diarization outputs block-by-block as audio\narrives, we show accuracy comparable to the offline clustering-based system.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:42:31 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:21:17 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Han", "Eunjung", ""], ["Lee", "Chul", ""], ["Stolcke", "Andreas", ""]]}, {"id": "2011.02686", "submitter": "Emily Sheng", "authors": "Emily Sheng and David Uthus", "title": "Investigating Societal Biases in a Poetry Composition System", "comments": "14 pages, 2nd Workshop on Gender Bias in NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing collection of work analyzing and mitigating societal\nbiases in language understanding, generation, and retrieval tasks, though\nexamining biases in creative tasks remains underexplored. Creative language\napplications are meant for direct interaction with users, so it is important to\nquantify and mitigate societal biases in these applications. We introduce a\nnovel study on a pipeline to mitigate societal biases when retrieving next\nverse suggestions in a poetry composition system. Our results suggest that data\naugmentation through sentiment style transfer has potential for mitigating\nsocietal biases.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 07:07:40 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Sheng", "Emily", ""], ["Uthus", "David", ""]]}, {"id": "2011.02687", "submitter": "Yeon Seonwoo", "authors": "Yeon Seonwoo, Ji-Hoon Kim, Jung-Woo Ha, Alice Oh", "title": "Context-Aware Answer Extraction in Question Answering", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive QA models have shown very promising performance in predicting the\ncorrect answer to a question for a given passage. However, they sometimes\nresult in predicting the correct answer text but in a context irrelevant to the\ngiven question. This discrepancy becomes especially important as the number of\noccurrences of the answer text in a passage increases. To resolve this issue,\nwe propose \\textbf{BLANC} (\\textbf{BL}ock \\textbf{A}ttentio\\textbf{N} for\n\\textbf{C}ontext prediction) based on two main ideas: context prediction as an\nauxiliary task in multi-task learning manner, and a block attention method that\nlearns the context prediction task. With experiments on reading comprehension,\nwe show that BLANC outperforms the state-of-the-art QA models, and the\nperformance gap increases as the number of answer text occurrences increases.\nWe also conduct an experiment of training the models using SQuAD and predicting\nthe supporting facts on HotpotQA and show that BLANC outperforms all baseline\nmodels in this zero-shot setting.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 07:10:08 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Seonwoo", "Yeon", ""], ["Kim", "Ji-Hoon", ""], ["Ha", "Jung-Woo", ""], ["Oh", "Alice", ""]]}, {"id": "2011.02690", "submitter": "Jan Botha", "authors": "Jan A. Botha, Zifei Shan, Daniel Gillick", "title": "Entity Linking in 100 Languages", "comments": "13 pages, 3 figures, 8 tables; published at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new formulation for multilingual entity linking, where\nlanguage-specific mentions resolve to a language-agnostic Knowledge Base. We\ntrain a dual encoder in this new setting, building on prior work with improved\nfeature representation, negative mining, and an auxiliary entity-pairing task,\nto obtain a single entity retrieval model that covers 100+ languages and 20\nmillion entities. The model outperforms state-of-the-art results from a far\nmore limited cross-lingual linking task. Rare entities and low-resource\nlanguages pose challenges at this large-scale, so we advocate for an increased\nfocus on zero- and few-shot evaluation. To this end, we provide Mewsli-9, a\nlarge new multilingual dataset (http://goo.gle/mewsli-dataset) matched to our\nsetting, and show how frequency-based analysis provided key insights for our\nmodel and training enhancements.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 07:28:35 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Botha", "Jan A.", ""], ["Shan", "Zifei", ""], ["Gillick", "Daniel", ""]]}, {"id": "2011.02705", "submitter": "Feng Ji", "authors": "Qianglong Chen, Feng Ji, Haiqing Chen and Yin Zhang", "title": "Improving Commonsense Question Answering by Graph-based Iterative\n  Retrieval over Multiple Knowledge Sources", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to facilitate natural language understanding, the key is to engage\ncommonsense or background knowledge. However, how to engage commonsense\neffectively in question answering systems is still under exploration in both\nresearch academia and industry. In this paper, we propose a novel\nquestion-answering method by integrating multiple knowledge sources, i.e.\nConceptNet, Wikipedia, and the Cambridge Dictionary, to boost the performance.\nMore concretely, we first introduce a novel graph-based iterative knowledge\nretrieval module, which iteratively retrieves concepts and entities related to\nthe given question and its choices from multiple knowledge sources. Afterward,\nwe use a pre-trained language model to encode the question, retrieved knowledge\nand choices, and propose an answer choice-aware attention mechanism to fuse all\nhidden representations of the previous modules. Finally, the linear classifier\nfor specific tasks is used to predict the answer. Experimental results on the\nCommonsenseQA dataset show that our method significantly outperforms other\ncompetitive methods and achieves the new state-of-the-art. In addition, further\nablation studies demonstrate the effectiveness of our graph-based iterative\nknowledge retrieval module and the answer choice-aware attention module in\nretrieving and synthesizing background knowledge from multiple knowledge\nsources.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:50:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Chen", "Qianglong", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhang", "Yin", ""]]}, {"id": "2011.02774", "submitter": "Han Zhu", "authors": "Han Zhu, Li Wang, Pengyuan Zhang, Yonghong Yan", "title": "Multi-Accent Adaptation based on Gate Mechanism", "comments": "Accepted in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When only a limited amount of accented speech data is available, to promote\nmulti-accent speech recognition performance, the conventional approach is\naccent-specific adaptation, which adapts the baseline model to multiple target\naccents independently. To simplify the adaptation procedure, we explore\nadapting the baseline model to multiple target accents simultaneously with\nmulti-accent mixed data. Thus, we propose using accent-specific top layer with\ngate mechanism (AST-G) to realize multi-accent adaptation. Compared with the\nbaseline model and accent-specific adaptation, AST-G achieves 9.8% and 1.9%\naverage relative WER reduction respectively. However, in real-world\napplications, we can't obtain the accent category label for inference in\nadvance. Therefore, we apply using an accent classifier to predict the accent\nlabel. To jointly train the acoustic model and the accent classifier, we\npropose the multi-task learning with gate mechanism (MTL-G). As the accent\nlabel prediction could be inaccurate, it performs worse than the\naccent-specific adaptation. Yet, in comparison with the baseline model, MTL-G\nachieves 5.1% average relative WER reduction.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:58:36 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhu", "Han", ""], ["Wang", "Li", ""], ["Zhang", "Pengyuan", ""], ["Yan", "Yonghong", ""]]}, {"id": "2011.02782", "submitter": "Han Zhu", "authors": "Han Zhu, Jiangjiang Zhao, Yuling Ren, Li Wang, Pengyuan Zhang", "title": "Domain Adaptation Using Class Similarity for Robust Speech Recognition", "comments": "Accepted in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When only limited target domain data is available, domain adaptation could be\nused to promote performance of deep neural network (DNN) acoustic model by\nleveraging well-trained source model and target domain data. However, suffering\nfrom domain mismatch and data sparsity, domain adaptation is very challenging.\nThis paper proposes a novel adaptation method for DNN acoustic model using\nclass similarity. Since the output distribution of DNN model contains the\nknowledge of similarity among classes, which is applicable to both source and\ntarget domain, it could be transferred from source to target model for the\nperformance improvement. In our approach, we first compute the frame level\nposterior probabilities of source samples using source model. Then, for each\nclass, probabilities of this class are used to compute a mean vector, which we\nrefer to as mean soft labels. During adaptation, these mean soft labels are\nused in a regularization term to train the target model. Experiments showed\nthat our approach outperforms fine-tuning using one-hot labels on both accent\nand noise adaptation task, especially when source and target domain are highly\nmismatched.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 12:26:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhu", "Han", ""], ["Zhao", "Jiangjiang", ""], ["Ren", "Yuling", ""], ["Wang", "Li", ""], ["Zhang", "Pengyuan", ""]]}, {"id": "2011.02788", "submitter": "Xiaoyu Guo", "authors": "Xiaoyu Guo, Jing Ma, Arkaitz Zubiaga", "title": "NUAA-QMUL at SemEval-2020 Task 8: Utilizing BERT and DenseNet for\n  Internet Meme Emotion Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our contribution to SemEval 2020 Task 8: Memotion\nAnalysis. Our system learns multi-modal embeddings from text and images in\norder to classify Internet memes by sentiment. Our model learns text embeddings\nusing BERT and extracts features from images with DenseNet, subsequently\ncombining both features through concatenation. We also compare our results with\nthose produced by DenseNet, ResNet, BERT, and BERT-ResNet. Our results show\nthat image classification models have the potential to help classifying memes,\nwith DenseNet outperforming ResNet. Adding text features is however not always\nhelpful for Memotion Analysis.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 12:39:30 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 14:42:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Guo", "Xiaoyu", ""], ["Ma", "Jing", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "2011.02821", "submitter": "Aloka Fernando", "authors": "Aloka Fernando, Surangika Ranathunga, Gihan Dias", "title": "Data Augmentation and Terminology Integration for Domain-Specific\n  Sinhala-English-Tamil Statistical Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out of vocabulary (OOV) is a problem in the context of Machine Translation\n(MT) in low-resourced languages. When source and/or target languages are\nmorphologically rich, it becomes even worse. Bilingual list integration is an\napproach to address the OOV problem. This allows more words to be translated\nthan are in the training data. However, since bilingual lists contain words in\nthe base form, it will not translate inflected forms for morphologically rich\nlanguages such as Sinhala and Tamil. This paper focuses on data augmentation\ntechniques where bilingual lexicon terms are expanded based on case-markers\nwith the objective of generating new words, to be used in Statistical machine\nTranslation (SMT). This data augmentation technique for dictionary terms shows\nimproved BLEU scores for Sinhala-English SMT.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:58:32 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 09:53:19 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 06:13:27 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Fernando", "Aloka", ""], ["Ranathunga", "Surangika", ""], ["Dias", "Gihan", ""]]}, {"id": "2011.02882", "submitter": "Yu-Sen Cheng", "authors": "Yu-Sen Cheng, Chun-Liang Shih, Tien-Hong Lo, Wen-Ting Tseng, Berlin\n  Chen", "title": "Query Expansion System for the VoxCeleb Speaker Recognition Challenge\n  2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we describe our submission to the VoxCeleb Speaker\nRecognition Challenge (VoxSRC) 2020. Two approaches are adopted. One is to\napply query expansion on speaker verification, which shows significant progress\ncompared to baseline in the study. Another is to use Kaldi extract x-vector and\nto combine its Probabilistic Linear Discriminant Analysis (PLDA) score with\nResNet score.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 05:24:18 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Cheng", "Yu-Sen", ""], ["Shih", "Chun-Liang", ""], ["Lo", "Tien-Hong", ""], ["Tseng", "Wen-Ting", ""], ["Chen", "Berlin", ""]]}, {"id": "2011.02917", "submitter": "Alessandro Suglia", "authors": "Alessandro Suglia, Antonio Vergari, Ioannis Konstas, Yonatan Bisk,\n  Emanuele Bastianelli, Andrea Vanzo, Oliver Lemon", "title": "Imagining Grounded Conceptual Representations from Perceptual\n  Information in Situated Guessing Games", "comments": "Accepted to the International Conference on Computational Linguistics\n  (COLING) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In visual guessing games, a Guesser has to identify a target object in a\nscene by asking questions to an Oracle. An effective strategy for the players\nis to learn conceptual representations of objects that are both discriminative\nand expressive enough to ask questions and guess correctly. However, as shown\nby Suglia et al. (2020), existing models fail to learn truly multi-modal\nrepresentations, relying instead on gold category labels for objects in the\nscene both at training and inference time. This provides an unnatural\nperformance advantage when categories at inference time match those at training\ntime, and it causes models to fail in more realistic \"zero-shot\" scenarios\nwhere out-of-domain object categories are involved. To overcome this issue, we\nintroduce a novel \"imagination\" module based on Regularized Auto-Encoders, that\nlearns context-aware and category-aware latent embeddings without relying on\ncategory labels at inference time. Our imagination module outperforms\nstate-of-the-art competitors by 8.26% gameplay accuracy in the CompGuessWhat?!\nzero-shot scenario (Suglia et al., 2020), and it improves the Oracle and\nGuesser accuracy by 2.08% and 12.86% in the GuessWhat?! benchmark, when no gold\ncategories are available at inference time. The imagination module also boosts\nreasoning about object properties and attributes.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:42:29 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Suglia", "Alessandro", ""], ["Vergari", "Antonio", ""], ["Konstas", "Ioannis", ""], ["Bisk", "Yonatan", ""], ["Bastianelli", "Emanuele", ""], ["Vanzo", "Andrea", ""], ["Lemon", "Oliver", ""]]}, {"id": "2011.02921", "submitter": "Naoyuki Kanda", "authors": "Naoyuki Kanda, Zhong Meng, Liang Lu, Yashesh Gaur, Xiaofei Wang, Zhuo\n  Chen, Takuya Yoshioka", "title": "Minimum Bayes Risk Training for End-to-End Speaker-Attributed ASR", "comments": "Submitted to ICASSP 2021. arXiv admin note: text overlap with\n  arXiv:2006.10930, arXiv:2008.04546", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an end-to-end speaker-attributed automatic speech recognition (E2E\nSA-ASR) model was proposed as a joint model of speaker counting, speech\nrecognition and speaker identification for monaural overlapped speech. In the\nprevious study, the model parameters were trained based on the\nspeaker-attributed maximum mutual information (SA-MMI) criterion, with which\nthe joint posterior probability for multi-talker transcription and speaker\nidentification are maximized over training data. Although SA-MMI training\nshowed promising results for overlapped speech consisting of various numbers of\nspeakers, the training criterion was not directly linked to the final\nevaluation metric, i.e., speaker-attributed word error rate (SA-WER). In this\npaper, we propose a speaker-attributed minimum Bayes risk (SA-MBR) training\nmethod where the parameters are trained to directly minimize the expected\nSA-WER over the training data. Experiments using the LibriSpeech corpus show\nthat the proposed SA-MBR training reduces the SA-WER by 9.0 % relative compared\nwith the SA-MMI-trained model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:28:57 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Meng", "Zhong", ""], ["Lu", "Liang", ""], ["Gaur", "Yashesh", ""], ["Wang", "Xiaofei", ""], ["Chen", "Zhuo", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "2011.02930", "submitter": "Ranya Aloufi", "authors": "Ranya Aloufi, Hamed Haddadi, David Boyle", "title": "Paralinguistic Privacy Protection at the Edge", "comments": "14 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2007.15064", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice user interfaces and digital assistants are rapidly entering our lives\nand becoming singular touch points spanning our devices. These always-on\nservices capture and transmit our audio data to powerful cloud services for\nfurther processing and subsequent actions. Our voices and raw audio signals\ncollected through these devices contain a host of sensitive paralinguistic\ninformation that is transmitted to service providers regardless of deliberate\nor false triggers. As our emotional patterns and sensitive attributes like our\nidentity, gender, mental well-being, are easily inferred using deep acoustic\nmodels, we encounter a new generation of privacy risks by using these services.\nOne approach to mitigate the risk of paralinguistic-based privacy breaches is\nto exploit a combination of cloud-based processing with privacy-preserving,\non-device paralinguistic information learning and filtering before transmitting\nvoice data. In this paper we introduce EDGY, a configurable, lightweight,\ndisentangled representation learning framework that transforms and filters\nhigh-dimensional voice data to identify and contain sensitive attributes at the\nedge prior to offloading to the cloud. We evaluate EDGY's on-device performance\nand explore optimization techniques, including model quantization and knowledge\ndistillation, to enable private, accurate and efficient representation learning\non resource-constrained devices. Our results show that EDGY runs in tens of\nmilliseconds with 0.2% relative improvement in ABX score or minimal performance\npenalties in learning linguistic representations from raw voice signals, using\na CPU and a single-core ARM processor without specialized hardware.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:11:35 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 20:32:21 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Aloufi", "Ranya", ""], ["Haddadi", "Hamed", ""], ["Boyle", "David", ""]]}, {"id": "2011.02935", "submitter": "Rabab Alkhalifa", "authors": "Rabab Alkhalifa, Adam Tsakalidis, Arkaitz Zubiaga, Maria Liakata", "title": "QMUL-SDS @ DIACR-Ita: Evaluating Unsupervised Diachronic Lexical\n  Semantics Classification in Italian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the results and main findings of our system for the\nDIACR-ITA 2020 Task. Our system focuses on using variations of training sets\nand different semantic detection methods. The task involves training, aligning\nand predicting a word's vector change from two diachronic Italian corpora. We\ndemonstrate that using Temporal Word Embeddings with a Compass C-BOW model is\nmore effective compared to different approaches including Logistic Regression\nand a Feed Forward Neural Network using accuracy. Our model ranked 3rd with an\naccuracy of 83.3%.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:00:35 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:08:33 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Alkhalifa", "Rabab", ""], ["Tsakalidis", "Adam", ""], ["Zubiaga", "Arkaitz", ""], ["Liakata", "Maria", ""]]}, {"id": "2011.02944", "submitter": "Konstantinos Christopher Tsiolis", "authors": "Jingyi He, KC Tsiolis, Kian Kenyon-Dean, Jackie Chi Kit Cheung", "title": "Learning Efficient Task-Specific Meta-Embeddings with Word Prisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings are trained to predict word cooccurrence statistics, which\nleads them to possess different lexical properties (syntactic, semantic, etc.)\ndepending on the notion of context defined at training time. These properties\nmanifest when querying the embedding space for the most similar vectors, and\nwhen used at the input layer of deep neural networks trained to solve\ndownstream NLP problems. Meta-embeddings combine multiple sets of differently\ntrained word embeddings, and have been shown to successfully improve intrinsic\nand extrinsic performance over equivalent models which use just one set of\nsource embeddings. We introduce word prisms: a simple and efficient\nmeta-embedding method that learns to combine source embeddings according to the\ntask at hand. Word prisms learn orthogonal transformations to linearly combine\nthe input source embeddings, which allows them to be very efficient at\ninference time. We evaluate word prisms in comparison to other meta-embedding\nmethods on six extrinsic evaluations and observe that word prisms offer\nimprovements in performance on all tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:08:50 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["He", "Jingyi", ""], ["Tsiolis", "KC", ""], ["Kenyon-Dean", "Kian", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "2011.02947", "submitter": "Zheng Yuan", "authors": "Zheng Yuan and Zhengyun Zhao and Haixia Sun and Jiao Li and Fei Wang\n  and Sheng Yu", "title": "CODER: Knowledge infused cross-lingual medical term embedding for term\n  normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes CODER: contrastive learning on knowledge graphs for\ncross-lingual medical term representation. CODER is designed for medical term\nnormalization by providing close vector representations for different terms\nthat represent the same or similar medical concepts with cross-lingual support.\nWe train CODER via contrastive learning on a medical knowledge graph (KG) named\nthe Unified Medical Language System, where similarities are calculated\nutilizing both terms and relation triplets from KG. Training with relations\ninjects medical knowledge into embeddings and aims to provide potentially\nbetter machine learning features. We evaluate CODER in zero-shot term\nnormalization, semantic similarity, and relation classification benchmarks,\nwhich show that CODERoutperforms various state-of-the-art biomedical word\nembedding, concept embeddings, and contextual embeddings. Our codes and models\nare available at https://github.com/GanjinZero/CODER.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:16:49 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 03:39:55 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 00:46:29 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yuan", "Zheng", ""], ["Zhao", "Zhengyun", ""], ["Sun", "Haixia", ""], ["Li", "Jiao", ""], ["Wang", "Fei", ""], ["Yu", "Sheng", ""]]}, {"id": "2011.02998", "submitter": "Changmao Li", "authors": "Changmao Li, Elaine Fisher, Rebecca Thomas, Steve Pittard, Vicki\n  Hertzberg, Jinho D. Choi", "title": "Competence-Level Prediction and Resume & Job Description Matching Using\n  Context-Aware Transformer Models", "comments": "Accepted by the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comprehensive study on resume classification to reduce\nthe time and labor needed to screen an overwhelming number of applications\nsignificantly, while improving the selection of suitable candidates. A total of\n6,492 resumes are extracted from 24,933 job applications for 252 positions\ndesignated into four levels of experience for Clinical Research Coordinators\n(CRC). Each resume is manually annotated to its most appropriate CRC position\nby experts through several rounds of triple annotation to establish guidelines.\nAs a result, a high Kappa score of 61% is achieved for inter-annotator\nagreement. Given this dataset, novel transformer-based classification models\nare developed for two tasks: the first task takes a resume and classifies it to\na CRC level (T1), and the second task takes both a resume and a job description\nto apply and predicts if the application is suited to the job T2. Our best\nmodels using section encoding and multi-head attention decoding give results of\n73.3% to T1 and 79.2% to T2. Our analysis shows that the prediction errors are\nmostly made among adjacent CRC levels, which are hard for even experts to\ndistinguish, implying the practical value of our models in real HR platforms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 17:47:03 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Li", "Changmao", ""], ["Fisher", "Elaine", ""], ["Thomas", "Rebecca", ""], ["Pittard", "Steve", ""], ["Hertzberg", "Vicki", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2011.03011", "submitter": "Dominic Seyler", "authors": "Dominic Seyler and Wei Liu and XiaoFeng Wang and ChengXiang Zhai", "title": "Towards Dark Jargon Interpretation in Underground Forums", "comments": null, "journal-ref": "ECIR 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dark jargons are benign-looking words that have hidden, sinister meanings and\nare used by participants of underground forums for illicit behavior. For\nexample, the dark term \"rat\" is often used in lieu of \"Remote Access Trojan\".\nIn this work we present a novel method towards automatically identifying and\ninterpreting dark jargons. We formalize the problem as a mapping from dark\nwords to \"clean\" words with no hidden meaning. Our method makes use of\ninterpretable representations of dark and clean words in the form of\nprobability distributions over a shared vocabulary. In our experiments we show\nour method to be effective in terms of dark jargon identification, as it\noutperforms another related method on simulated data. Using manual evaluation,\nwe show that our method is able to detect dark jargons in a real-world\nunderground forum dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:08:32 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 00:32:12 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Seyler", "Dominic", ""], ["Liu", "Wei", ""], ["Wang", "XiaoFeng", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "2011.03017", "submitter": "Patrick Huber", "authors": "Patrick Huber and Giuseppe Carenini", "title": "MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable\n  Distant Sentiment Supervision", "comments": "In Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP). 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of large and diverse discourse treebanks hinders the application of\ndata-driven approaches, such as deep-learning, to RST-style discourse parsing.\nIn this work, we present a novel scalable methodology to automatically generate\ndiscourse treebanks using distant supervision from sentiment-annotated\ndatasets, creating and publishing MEGA-DT, a new large-scale\ndiscourse-annotated corpus. Our approach generates discourse trees\nincorporating structure and nuclearity for documents of arbitrary length by\nrelying on an efficient heuristic beam-search strategy, extended with a\nstochastic component. Experiments on multiple datasets indicate that a\ndiscourse parser trained on our MEGA-DT treebank delivers promising\ninter-domain performance gains when compared to parsers trained on\nhuman-annotated discourse corpora.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:22:38 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2011.03020", "submitter": "Jiaxin Pei", "authors": "Jiaxin Pei and David Jurgens", "title": "Quantifying Intimacy in Language", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intimacy is a fundamental aspect of how we relate to others in social\nsettings. Language encodes the social information of intimacy through both\ntopics and other more subtle cues (such as linguistic hedging and swearing).\nHere, we introduce a new computational framework for studying expressions of\nthe intimacy in language with an accompanying dataset and deep learning model\nfor accurately predicting the intimacy level of questions (Pearson's r=0.87).\nThrough analyzing a dataset of 80.5M questions across social media, books, and\nfilms, we show that individuals employ interpersonal pragmatic moves in their\nlanguage to align their intimacy with social settings. Then, in three studies,\nwe further demonstrate how individuals modulate their intimacy to match social\nnorms around gender, social distance, and audience, each validating key\nfindings from studies in social psychology. Our work demonstrates that intimacy\nis a pervasive and impactful social dimension of language.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:27:20 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pei", "Jiaxin", ""], ["Jurgens", "David", ""]]}, {"id": "2011.03021", "submitter": "Patrick Huber", "authors": "Patrick Huber and Giuseppe Carenini", "title": "From Sentiment Annotations to Sentiment Prediction through Discourse\n  Augmentation", "comments": "In Proceedings of the 28 International Conference on Computational\n  Linguistics (COLING). 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis, especially for long documents, plausibly requires methods\ncapturing complex linguistics structures. To accommodate this, we propose a\nnovel framework to exploit task-related discourse for the task of sentiment\nanalysis. More specifically, we are combining the large-scale,\nsentiment-dependent MEGA-DT treebank with a novel neural architecture for\nsentiment prediction, based on a hybrid TreeLSTM hierarchical attention model.\nExperiments show that our framework using sentiment-related discourse\naugmentations for sentiment prediction enhances the overall performance for\nlong documents, even beyond previous approaches using well-established\ndiscourse parsers trained on human annotated data. We show that a simple\nensemble approach can further enhance performance by selectively using\ndiscourse, depending on the document length.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:28:13 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2011.03023", "submitter": "Mahdi Namazifar", "authors": "Mahdi Namazifar, Alexandros Papangelis, Gokhan Tur, Dilek\n  Hakkani-T\\\"ur", "title": "Language Model is All You Need: Natural Language Understanding as\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different flavors of transfer learning have shown tremendous impact in\nadvancing research and applications of machine learning. In this work we study\nthe use of a specific family of transfer learning, where the target domain is\nmapped to the source domain. Specifically we map Natural Language Understanding\n(NLU) problems to QuestionAnswering (QA) problems and we show that in low data\nregimes this approach offers significant improvements compared to other\napproaches to NLU. Moreover we show that these gains could be increased through\nsequential transfer learning across NLU problems from different domains. We\nshow that our approach could reduce the amount of required data for the same\nperformance by up to a factor of 10.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:31:22 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Namazifar", "Mahdi", ""], ["Papangelis", "Alexandros", ""], ["Tur", "Gokhan", ""], ["Hakkani-T\u00fcr", "Dilek", ""]]}, {"id": "2011.03072", "submitter": "Yuan Shangguan", "authors": "Jay Mahadeokar, Yuan Shangguan, Duc Le, Gil Keren, Hang Su, Thong Le,\n  Ching-Feng Yeh, Christian Fuegen, Michael L. Seltzer", "title": "Alignment Restricted Streaming Recurrent Neural Network Transducer", "comments": "Accepted for presentation at IEEE Spoken Language Technology Workshop\n  (SLT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the speech community in developing Recurrent\nNeural Network Transducer (RNN-T) models for automatic speech recognition (ASR)\napplications. RNN-T is trained with a loss function that does not enforce\ntemporal alignment of the training transcripts and audio. As a result, RNN-T\nmodels built with uni-directional long short term memory (LSTM) encoders tend\nto wait for longer spans of input audio, before streaming already decoded ASR\ntokens. In this work, we propose a modification to the RNN-T loss function and\ndevelop Alignment Restricted RNN-T (Ar-RNN-T) models, which utilize audio-text\nalignment information to guide the loss computation. We compare the proposed\nmethod with existing works, such as monotonic RNN-T, on LibriSpeech and\nin-house datasets. We show that the Ar-RNN-T loss provides a refined control to\nnavigate the trade-offs between the token emission delays and the Word Error\nRate (WER). The Ar-RNN-T models also improve downstream applications such as\nthe ASR End-pointing by guaranteeing token emissions within any given range of\nlatency. Moreover, the Ar-RNN-T loss allows for bigger batch sizes and 4 times\nhigher throughput for our LSTM model architecture, enabling faster training and\nconvergence on GPUs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 19:38:54 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mahadeokar", "Jay", ""], ["Shangguan", "Yuan", ""], ["Le", "Duc", ""], ["Keren", "Gil", ""], ["Su", "Hang", ""], ["Le", "Thong", ""], ["Yeh", "Ching-Feng", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "2011.03080", "submitter": "Momchil Hardalov", "authors": "Momchil Hardalov, Todor Mihaylov, Dimitrina Zlatkova, Yoan Dinkov,\n  Ivan Koychev, Preslav Nakov", "title": "EXAMS: A Multi-Subject High School Examinations Dataset for\n  Cross-Lingual and Multilingual Question Answering", "comments": "EMNLP 2020, 17 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose EXAMS -- a new benchmark dataset for cross-lingual and\nmultilingual question answering for high school examinations. We collected more\nthan 24,000 high-quality high school exam questions in 16 languages, covering 8\nlanguage families and 24 school subjects from Natural Sciences and Social\nSciences, among others.\n  EXAMS offers a fine-grained evaluation framework across multiple languages\nand subjects, which allows precise analysis and comparison of various models.\nWe perform various experiments with existing top-performing multilingual\npre-trained models and we show that EXAMS offers multiple challenges that\nrequire multilingual knowledge and reasoning in multiple domains. We hope that\nEXAMS will enable researchers to explore challenging reasoning and knowledge\ntransfer methods and pre-trained models for school question answering in\nvarious languages which was not possible before. The data, code, pre-trained\nmodels, and evaluation are available at https://github.com/mhardalov/exams-qa.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:06:50 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Hardalov", "Momchil", ""], ["Mihaylov", "Todor", ""], ["Zlatkova", "Dimitrina", ""], ["Dinkov", "Yoan", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "2011.03088", "submitter": "Yichen Jiang", "authors": "Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles Dognin, Maneesh\n  Singh, Mohit Bansal", "title": "HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification", "comments": "Findings of EMNLP 2020 (20 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce HoVer (HOppy VERification), a dataset for many-hop evidence\nextraction and fact verification. It challenges models to extract facts from\nseveral Wikipedia articles that are relevant to a claim and classify whether\nthe claim is Supported or Not-Supported by the facts. In HoVer, the claims\nrequire evidence to be extracted from as many as four English Wikipedia\narticles and embody reasoning graphs of diverse shapes. Moreover, most of the\n3/4-hop claims are written in multiple sentences, which adds to the complexity\nof understanding long-range dependency relations such as coreference. We show\nthat the performance of an existing state-of-the-art semantic-matching model\ndegrades significantly on our dataset as the number of reasoning hops\nincreases, hence demonstrating the necessity of many-hop reasoning to achieve\nstrong results. We hope that the introduction of this challenging dataset and\nthe accompanying evaluation task will encourage research in many-hop fact\nretrieval and information verification. We make the HoVer dataset publicly\navailable at https://hover-nlp.github.io\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:33:11 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 01:57:39 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jiang", "Yichen", ""], ["Bordia", "Shikha", ""], ["Zhong", "Zheng", ""], ["Dognin", "Charles", ""], ["Singh", "Maneesh", ""], ["Bansal", "Mohit", ""]]}, {"id": "2011.03092", "submitter": "El Moatez Billah Nagoudi", "authors": "El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed,\n  Tariq Alhindi, Hasan Cavusoglu", "title": "Machine Generation and Detection of Arabic Manipulated and Fake News", "comments": "10 pages, accepted in The Fifth Arabic Natural Language Processing\n  Workshop (WANLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news and deceptive machine-generated text are serious problems\nthreatening modern societies, including in the Arab world. This motivates work\non detecting false and manipulated stories online. However, a bottleneck for\nthis research is lack of sufficient data to train detection models. We present\na novel method for automatically generating Arabic manipulated (and potentially\nfake) news stories. Our method is simple and only depends on availability of\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\nfacilitate future work, we dispense with both of these requirements altogether\nby providing AraNews, a novel and large POS-tagged news dataset that can be\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\nhuman annotation study that casts light on the effects of machine manipulation\non text veracity. The study also measures human ability to detect Arabic\nmachine manipulated text generated by our method. Finally, we develop the first\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:50:22 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Nagoudi", "El Moatez Billah", ""], ["Elmadany", "AbdelRahim", ""], ["Abdul-Mageed", "Muhammad", ""], ["Alhindi", "Tariq", ""], ["Cavusoglu", "Hasan", ""]]}, {"id": "2011.03096", "submitter": "Tuan Manh Lai", "authors": "Quan Tran, Nhan Dam, Tuan Lai, Franck Dernoncourt, Trung Le, Nham Le\n  and Dinh Phung", "title": "Explain by Evidence: An Explainable Memory-based Neural Network for\n  Question Answering", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and explainability of deep neural networks are challenging\ndue to their scale, complexity, and the agreeable notions on which the\nexplaining process rests. Previous work, in particular, has focused on\nrepresenting internal components of neural networks through human-friendly\nvisuals and concepts. On the other hand, in real life, when making a decision,\nhuman tends to rely on similar situations and/or associations in the past.\nHence arguably, a promising approach to make the model transparent is to design\nit in a way such that the model explicitly connects the current sample with the\nseen ones, and bases its decision on these samples. Grounded on that principle,\nwe propose in this paper an explainable, evidence-based memory network\narchitecture, which learns to summarize the dataset and extract supporting\nevidences to make its decision. Our model achieves state-of-the-art performance\non two popular question answering datasets (i.e. TrecQA and WikiQA). Via\nfurther analysis, we show that this model can reliably trace the errors it has\nmade in the validation step to the training instances that might have caused\nthese errors. We believe that this error-tracing capability provides\nsignificant benefit in improving dataset quality in many applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:18:21 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tran", "Quan", ""], ["Dam", "Nhan", ""], ["Lai", "Tuan", ""], ["Dernoncourt", "Franck", ""], ["Le", "Trung", ""], ["Le", "Nham", ""], ["Phung", "Dinh", ""]]}, {"id": "2011.03109", "submitter": "Chunxi Liu", "authors": "Chunxi Liu, Frank Zhang, Duc Le, Suyoun Kim, Yatharth Saraf, Geoffrey\n  Zweig", "title": "Improving RNN Transducer Based ASR with Auxiliary Tasks", "comments": "Accepted for publication at IEEE Spoken Language Technology Workshop\n  (SLT), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) models with a single neural\nnetwork have recently demonstrated state-of-the-art results compared to\nconventional hybrid speech recognizers. Specifically, recurrent neural network\ntransducer (RNN-T) has shown competitive ASR performance on various benchmarks.\nIn this work, we examine ways in which RNN-T can achieve better ASR accuracy\nvia performing auxiliary tasks. We propose (i) using the same auxiliary task as\nprimary RNN-T ASR task, and (ii) performing context-dependent graphemic state\nprediction as in conventional hybrid modeling. In transcribing social media\nvideos with varying training data size, we first evaluate the streaming ASR\nperformance on three languages: Romanian, Turkish and German. We find that both\nproposed methods provide consistent improvements. Next, we observe that both\nauxiliary tasks demonstrate efficacy in learning deep transformer encoders for\nRNN-T criterion, thus achieving competitive results - 2.0%/4.2% WER on\nLibriSpeech test-clean/other - as compared to prior top performing models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:46:32 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 03:48:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Liu", "Chunxi", ""], ["Zhang", "Frank", ""], ["Le", "Duc", ""], ["Kim", "Suyoun", ""], ["Saraf", "Yatharth", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "2011.03118", "submitter": "Trideba Padhi Dr.", "authors": "Trideba Padhi, Astik Biswas, Febe De Wet, Ewald van der Westhuizen,\n  Thomas Niesler", "title": "Multilingual Bottleneck Features for Improving ASR Performance of\n  Code-Switched Speech in Under-Resourced Languages", "comments": "In Proceedings of The First Workshop on Speech Technologies for\n  Code-Switching in Multilingual Communities", "journal-ref": "http://festvox.org/cedar/WSTCSMC2020.pdf", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we explore the benefits of using multilingual bottleneck\nfeatures (mBNF) in acoustic modelling for the automatic speech recognition of\ncode-switched (CS) speech in African languages. The unavailability of annotated\ncorpora in the languages of interest has always been a primary challenge when\ndeveloping speech recognition systems for this severely under-resourced type of\nspeech. Hence, it is worthwhile to investigate the potential of using speech\ncorpora available for other better-resourced languages to improve speech\nrecognition performance. To achieve this, we train a mBNF extractor using nine\nSouthern Bantu languages that form part of the freely available multilingual\nNCHLT corpus. We append these mBNFs to the existing MFCCs, pitch features and\ni-vectors to train acoustic models for automatic speech recognition (ASR) in\nthe target code-switched languages. Our results show that the inclusion of the\nmBNF features leads to clear performance improvements over a baseline trained\nwithout the mBNFs for code-switched English-isiZulu, English-isiXhosa,\nEnglish-Sesotho and English-Setswana speech.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:51:42 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Padhi", "Trideba", ""], ["Biswas", "Astik", ""], ["De Wet", "Febe", ""], ["van der Westhuizen", "Ewald", ""], ["Niesler", "Thomas", ""]]}, {"id": "2011.03123", "submitter": "Alberto Calderone Dr.", "authors": "Alberto Calderone", "title": "PubSqueezer: A Text-Mining Web Tool to Transform Unstructured Documents\n  into Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The amount of scientific papers published every day is daunting and\nconstantly increasing. Keeping up with literature represents a challenge. If\none wants to start exploring new topics it is hard to have a big picture\nwithout reading lots of articles. Furthermore, as one reads through literature,\nmaking mental connections is crucial to ask new questions which might lead to\ndiscoveries. In this work, I present a web tool which uses a Text Mining\nstrategy to transform large collections of unstructured biomedical articles\ninto structured data. Generated results give a quick overview on complex topics\nwhich can possibly suggest not explicitly reported information. In particular,\nI show two Data Science analyses. First, I present a literature based rare\ndiseases network build using this tool in the hope that it will help clarify\nsome aspects of these less popular pathologies. Secondly, I show how a\nliterature based analysis conducted with PubSqueezer results allows to describe\nknown facts about SARS-CoV-2. In one sentence, data generated with PubSqueezer\nmake it easy to use scientific literate in any computational analysis such as\nmachine learning, natural language processing etc.\n  Availability: http://www.pubsqueezer.com\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 22:23:18 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 07:51:35 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Calderone", "Alberto", ""]]}, {"id": "2011.03138", "submitter": "Hao Zhang", "authors": "Hao Zhang and Jae Ro and Richard Sproat", "title": "Semi-supervised URL Segmentation with Recurrent Neural Networks\n  Pre-trained on Knowledge Graph Entities", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (2020) 4667--4675", "doi": "10.18653/v1/2020.coling-main.411", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breaking domain names such as openresearch into component words open and\nresearch is important for applications like Text-to-Speech synthesis and web\nsearch. We link this problem to the classic problem of Chinese word\nsegmentation and show the effectiveness of a tagging model based on Recurrent\nNeural Networks (RNNs) using characters as input. To compensate for the lack of\ntraining data, we propose a pre-training method on concatenated entity names in\na large knowledge database. Pre-training improves the model by 33% and brings\nthe sequence accuracy to 85%.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 23:31:00 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Zhang", "Hao", ""], ["Ro", "Jae", ""], ["Sproat", "Richard", ""]]}, {"id": "2011.03161", "submitter": "Wojciech Kry\\'sci\\'nski", "authors": "Hiroaki Hayashi, Wojciech Kry\\'sci\\'nski, Bryan McCann, Nazneen\n  Rajani, Caiming Xiong", "title": "What's New? Summarizing Contributions in Scientific Literature", "comments": "9 pages, 5 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With thousands of academic articles shared on a daily basis, it has become\nincreasingly difficult to keep up with the latest scientific findings. To\novercome this problem, we introduce a new task of disentangled paper\nsummarization, which seeks to generate separate summaries for the paper\ncontributions and the context of the work, making it easier to identify the key\nfindings shared in articles. For this purpose, we extend the S2ORC corpus of\nacademic articles, which spans a diverse set of domains ranging from economics\nto psychology, by adding disentangled \"contribution\" and \"context\" reference\nlabels. Together with the dataset, we introduce and analyze three baseline\napproaches: 1) a unified model controlled by input code prefixes, 2) a model\nwith separate generation heads specialized in generating the disentangled\noutputs, and 3) a training strategy that guides the model using additional\nsupervision coming from inbound and outbound citations. We also propose a\ncomprehensive automatic evaluation protocol which reports the relevance,\nnovelty, and disentanglement of generated outputs. Through a human study\ninvolving expert annotators, we show that in 79%, of cases our new task is\nconsidered more helpful than traditional scientific paper summarization.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 02:23:01 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 16:16:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hayashi", "Hiroaki", ""], ["Kry\u015bci\u0144ski", "Wojciech", ""], ["McCann", "Bryan", ""], ["Rajani", "Nazneen", ""], ["Xiong", "Caiming", ""]]}, {"id": "2011.03203", "submitter": "Grigorii Guz", "authors": "Grigorii Guz, Patrick Huber and Giuseppe Carenini", "title": "Unleashing the Power of Neural Discourse Parsers -- A Context and\n  Structure Aware Approach Using Large Scale Pretraining", "comments": "10 pages, 1 figure, COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RST-based discourse parsing is an important NLP task with numerous downstream\napplications, such as summarization, machine translation and opinion mining. In\nthis paper, we demonstrate a simple, yet highly accurate discourse parser,\nincorporating recent contextual language models. Our parser establishes the new\nstate-of-the-art (SOTA) performance for predicting structure and nuclearity on\ntwo key RST datasets, RST-DT and Instr-DT. We further demonstrate that\npretraining our parser on the recently available large-scale \"silver-standard\"\ndiscourse treebank MEGA-DT provides even larger performance benefits,\nsuggesting a novel and promising research direction in the field of discourse\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:11:26 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Guz", "Grigorii", ""], ["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2011.03228", "submitter": "Tomasz Dwojak", "authors": "Tomasz Dwojak, Micha{\\l} Pietruszka, {\\L}ukasz Borchmann, Jakub\n  Ch{\\l}\\k{e}dowski, Filip Grali\\'nski", "title": "From Dataset Recycling to Multi-Property Extraction and Beyond", "comments": "Accepted at CoNLL 2020; this article supersedes arXiv: 2006.08281", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates various Transformer architectures on the WikiReading\nInformation Extraction and Machine Reading Comprehension dataset. The proposed\ndual-source model outperforms the current state-of-the-art by a large margin.\nNext, we introduce WikiReading Recycled-a newly developed public dataset and\nthe task of multiple property extraction. It uses the same data as WikiReading\nbut does not inherit its predecessor's identified disadvantages. In addition,\nwe provide a human-annotated test set with diagnostic subsets for a detailed\nanalysis of model performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 08:22:12 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Dwojak", "Tomasz", ""], ["Pietruszka", "Micha\u0142", ""], ["Borchmann", "\u0141ukasz", ""], ["Ch\u0142\u0119dowski", "Jakub", ""], ["Grali\u0144ski", "Filip", ""]]}, {"id": "2011.03258", "submitter": "Jens Kaiser", "authors": "Jens Kaiser, Dominik Schlechtweg, Sabine Schulte im Walde", "title": "OP-IMS @ DIACR-Ita: Back to the Roots: SGNS+OP+CD still rocks Semantic\n  Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the results of our participation in the DIACR-Ita shared task on\nlexical semantic change detection for Italian. We exploit one of the earliest\nand most influential semantic change detection models based on Skip-Gram with\nNegative Sampling, Orthogonal Procrustes alignment and Cosine Distance and\nobtain the winning submission of the shared task with near to perfect accuracy\n.94. Our results once more indicate that, within the present task setup in\nlexical semantic change detection, the traditional type-based approaches yield\nexcellent performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:02:12 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Kaiser", "Jens", ""], ["Schlechtweg", "Dominik", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "2011.03259", "submitter": "Jan Pichl", "authors": "Jan Pichl, Petr Marek, Jakub Konr\\'ad, Martin Matul\\'ik, and Jan\n  \\v{S}ediv\\'y", "title": "Alquist 2.0: Alexa Prize Socialbot Based on Sub-Dialogue Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the second version of the dialogue system named Alquist\ncompeting in Amazon Alexa Prize 2018. We introduce a system leveraging\nontology-based topic structure called topic nodes. Each of the nodes consists\nof several sub-dialogues, and each sub-dialogue has its own LSTM-based model\nfor dialogue management. The sub-dialogues can be triggered according to the\ntopic hierarchy or a user intent which allows the bot to create a unique\nexperience during each session.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:06:10 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Pichl", "Jan", ""], ["Marek", "Petr", ""], ["Konr\u00e1d", "Jakub", ""], ["Matul\u00edk", "Martin", ""], ["\u0160ediv\u00fd", "Jan", ""]]}, {"id": "2011.03261", "submitter": "Jan Pichl", "authors": "Jan Pichl, Petr Marek, Jakub Konr\\'ad, Petr Lorenc, Van Duy Ta, and\n  Jan \\v{S}ediv\\'y", "title": "Alquist 3.0: Alexa Prize Bot Using Conversational Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The third version of the open-domain dialogue system Alquist developed within\nthe Alexa Prize 2020 competition is designed to conduct coherent and engaging\nconversations on popular topics. The main novel contribution is the\nintroduction of a system leveraging an innovative approach based on a\nconversational knowledge graph and adjacency pairs. The conversational\nknowledge graph allows the system to utilize knowledge expressed during the\ndialogue in consequent turns and across conversations. Dialogue adjacency pairs\ndivide the conversation into small conversational structures, which can be\ncombined and allow the system to react to a wide range of user inputs flexibly.\n  We discuss and describe Alquist's pipeline, data acquisition and processing,\ndialogue manager, NLG, knowledge aggregation, and a hierarchy of adjacency\npairs. We present the experimental results of the individual parts of the\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:10:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Pichl", "Jan", ""], ["Marek", "Petr", ""], ["Konr\u00e1d", "Jakub", ""], ["Lorenc", "Petr", ""], ["Ta", "Van Duy", ""], ["\u0160ediv\u00fd", "Jan", ""]]}, {"id": "2011.03281", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "Corpora Compared: The Case of the Swedish Gigaword & Wikipedia Corpora", "comments": "Presented at the Eighth Swedish Language Technology Conference (SLTC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we show that the difference in performance of embeddings from\ndifferently sourced data for a given language can be due to other factors\nbesides data size. Natural language processing (NLP) tasks usually perform\nbetter with embeddings from bigger corpora. However, broadness of covered\ndomain and noise can play important roles. We evaluate embeddings based on two\nSwedish corpora: The Gigaword and Wikipedia, in analogy (intrinsic) tests and\ndiscover that the embeddings from the Wikipedia corpus generally outperform\nthose from the Gigaword corpus, which is a bigger corpus. Downstream tests will\nbe required to have a definite evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 11:00:47 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2011.03286", "submitter": "Haryo Akbarianto Wibowo", "authors": "Haryo Akbarianto Wibowo, Tatag Aziz Prawiro, Muhammad Ihsan, Alham\n  Fikri Aji, Radityo Eko Prasojo, Rahmad Mahendra, Suci Fitriany", "title": "Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to\n  Formal Language with Iterative Forward-Translation", "comments": "6 pages, Camera ready to be presented at IALP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In its daily use, the Indonesian language is riddled with informality, that\nis, deviations from the standard in terms of vocabulary, spelling, and word\norder. On the other hand, current available Indonesian NLP models are typically\ndeveloped with the standard Indonesian in mind. In this work, we address a\nstyle-transfer from informal to formal Indonesian as a low-resource machine\ntranslation problem. We build a new dataset of parallel sentences of informal\nIndonesian and its formal counterpart. We benchmark several strategies to\nperform style transfer from informal to formal Indonesian. We also explore\naugmenting the training set with artificial forward-translated data. Since we\nare dealing with an extremely low-resource setting, we find that a phrase-based\nmachine translation approach outperforms the Transformer-based approach.\nAlternatively, a pre-trained GPT-2 fined-tuned to this task performed equally\nwell but costs more computational resource. Our findings show a promising step\ntowards leveraging machine translation models for style transfer. Our code and\ndata are available in https://github.com/haryoa/stif-indonesia\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 11:19:47 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 17:32:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Wibowo", "Haryo Akbarianto", ""], ["Prawiro", "Tatag Aziz", ""], ["Ihsan", "Muhammad", ""], ["Aji", "Alham Fikri", ""], ["Prasojo", "Radityo Eko", ""], ["Mahendra", "Rahmad", ""], ["Fitriany", "Suci", ""]]}, {"id": "2011.03287", "submitter": "Yova Kementchedjhieva", "authors": "Yova Kementchedjhieva, Di Lu, Joel Tetreault", "title": "The ApposCorpus: A new multilingual, multi-domain dataset for factual\n  appositive generation", "comments": "To appear at COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  News articles, image captions, product reviews and many other texts mention\npeople and organizations whose name recognition could vary for different\naudiences. In such cases, background information about the named entities could\nbe provided in the form of an appositive noun phrase, either written by a human\nor generated automatically. We expand on the previous work in appositive\ngeneration with a new, more realistic, end-to-end definition of the task,\ninstantiated by a dataset that spans four languages (English, Spanish, German\nand Polish), two entity types (person and organization) and two domains\n(Wikipedia and News). We carry out an extensive analysis of the data and the\ntask, pointing to the various modeling challenges it poses. The results we\nobtain with standard language generation methods show that the task is indeed\nnon-trivial, and leaves plenty of room for improvement.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 11:23:09 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Kementchedjhieva", "Yova", ""], ["Lu", "Di", ""], ["Tetreault", "Joel", ""]]}, {"id": "2011.03292", "submitter": "Yufan Jiang", "authors": "Yufan Jiang, Shuangzhi Wu, Jing Gong, Yahui Cheng, Peng Meng, Weiliang\n  Lin, Zhibo Chen and Mu li", "title": "Improving Machine Reading Comprehension with Single-choice Decision and\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-choice Machine Reading Comprehension (MMRC) aims to select the correct\nanswer from a set of options based on a given passage and question. Due to task\nspecific of MMRC, it is non-trivial to transfer knowledge from other MRC tasks\nsuch as SQuAD, Dream. In this paper, we simply reconstruct multi-choice to\nsingle-choice by training a binary classification to distinguish whether a\ncertain answer is correct. Then select the option with the highest confidence\nscore. We construct our model upon ALBERT-xxlarge model and estimate it on the\nRACE dataset. During training, We adopt AutoML strategy to tune better\nparameters. Experimental results show that the single-choice is better than\nmulti-choice. In addition, by transferring knowledge from other kinds of MRC\ntasks, our model achieves a new state-of-the-art results in both single and\nensemble settings.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 11:33:29 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 06:26:33 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Jiang", "Yufan", ""], ["Wu", "Shuangzhi", ""], ["Gong", "Jing", ""], ["Cheng", "Yahui", ""], ["Meng", "Peng", ""], ["Lin", "Weiliang", ""], ["Chen", "Zhibo", ""], ["li", "Mu", ""]]}, {"id": "2011.03322", "submitter": "Shen Gao", "authors": "Shen Gao, Xiuying Chen, Li Liu, Dongyan Zhao and Rui Yan", "title": "Learning to Respond with Your Favorite Stickers: A Framework of Unifying\n  Multi-Modality and User Preference in Multi-Turn Dialog", "comments": "Accepted by TOIS. arXiv admin note: substantial text overlap with\n  arXiv:2003.04679", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stickers with vivid and engaging expressions are becoming increasingly\npopular in online messaging apps, and some works are dedicated to automatically\nselect sticker response by matching the stickers image with previous\nutterances. However, existing methods usually focus on measuring the matching\ndegree between the dialog context and sticker image, which ignores the user\npreference of using stickers. Hence, in this paper, we propose to recommend an\nappropriate sticker to user based on multi-turn dialog context and sticker\nusing history of user. Two main challenges are confronted in this task. One is\nto model the sticker preference of user based on the previous sticker selection\nhistory. Another challenge is to jointly fuse the user preference and the\nmatching between dialog context and candidate sticker into final prediction\nmaking. To tackle these challenges, we propose a \\emph{Preference Enhanced\nSticker Response Selector} (PESRS) model. Specifically, PESRS first employs a\nconvolutional based sticker image encoder and a self-attention based multi-turn\ndialog encoder to obtain the representation of stickers and utterances. Next,\ndeep interaction network is proposed to conduct deep matching between the\nsticker and each utterance. Then, we model the user preference by using the\nrecently selected stickers as input, and use a key-value memory network to\nstore the preference representation. PESRS then learns the short-term and\nlong-term dependency between all interaction results by a fusion network, and\ndynamically fuse the user preference representation into the final sticker\nselection prediction. Extensive experiments conducted on a large-scale\nreal-world dialog dataset show that our model achieves the state-of-the-art\nperformance for all commonly-used metrics. Experiments also verify the\neffectiveness of each component of PESRS.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 03:31:17 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Gao", "Shen", ""], ["Chen", "Xiuying", ""], ["Liu", "Li", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2011.03327", "submitter": "Parth Patwa", "authors": "Parth Patwa, Shivam Sharma, Srinivas Pykl, Vineeth Guptha, Gitanjali\n  Kumari, Md Shad Akhtar, Asif Ekbal, Amitava Das, Tanmoy Chakraborty", "title": "Fighting an Infodemic: COVID-19 Fake News Dataset", "comments": "Published at CONSTRAINT-2021, Collocated with AAAI-2021", "journal-ref": null, "doi": "10.1007/978-3-030-73696-5_3", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news\nand rumors are rampant on social media. Believing in rumors can cause\nsignificant harm. This is further exacerbated at the time of a pandemic. To\ntackle this, we curate and release a manually annotated dataset of 10,700\nsocial media posts and articles of real and fake news on COVID-19. We benchmark\nthe annotated dataset with four machine learning baselines - Decision Tree,\nLogistic Regression, Gradient Boost, and Support Vector Machine (SVM). We\nobtain the best performance of 93.46% F1-score with SVM. The data and code is\navailable at: https://github.com/parthpatwa/covid19-fake-news-dectection\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 13:09:37 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 04:46:19 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 12:11:21 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 15:38:55 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Patwa", "Parth", ""], ["Sharma", "Shivam", ""], ["Pykl", "Srinivas", ""], ["Guptha", "Vineeth", ""], ["Kumari", "Gitanjali", ""], ["Akhtar", "Md Shad", ""], ["Ekbal", "Asif", ""], ["Das", "Amitava", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2011.03435", "submitter": "Revanth Reddy", "authors": "Revanth Gangi Reddy, Md Arafat Sultan, Efsun Sarioglu Kayi, Rong\n  Zhang, Vittorio Castelli, Avirup Sil", "title": "Answer Span Correction in Machine Reading Comprehension", "comments": "Accepted in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer validation in machine reading comprehension (MRC) consists of\nverifying an extracted answer against an input context and question pair.\nPrevious work has looked at re-assessing the \"answerability\" of the question\ngiven the extracted answer. Here we address a different problem: the tendency\nof existing MRC systems to produce partially correct answers when presented\nwith answerable questions. We explore the nature of such errors and propose a\npost-processing correction method that yields statistically significant\nperformance improvements over state-of-the-art MRC systems in both monolingual\nand multilingual evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:31:07 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Reddy", "Revanth Gangi", ""], ["Sultan", "Md Arafat", ""], ["Kayi", "Efsun Sarioglu", ""], ["Zhang", "Rong", ""], ["Castelli", "Vittorio", ""], ["Sil", "Avirup", ""]]}, {"id": "2011.03469", "submitter": "Gongbo Tang", "authors": "Gongbo Tang, Rico Sennrich, Joakim Nivre", "title": "Understanding Pure Character-Based Neural Machine Translation: The Case\n  of Translating Finnish into English", "comments": "accepted by COLING 2020, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown that deeper character-based neural machine translation\n(NMT) models can outperform subword-based models. However, it is still unclear\nwhat makes deeper character-based models successful. In this paper, we conduct\nan investigation into pure character-based models in the case of translating\nFinnish into English, including exploring the ability to learn word senses and\nmorphological inflections and the attention mechanism. We demonstrate that\nword-level information is distributed over the entire character sequence rather\nthan over a single character, and characters at different positions play\ndifferent roles in learning linguistic knowledge. In addition, character-based\nmodels need more layers to encode word senses which explains why only deeper\nmodels outperform subword-based models. The attention distribution pattern\nshows that separators attract a lot of attention and we explore a sparse\nword-level attention to enforce character hidden states to capture the full\nword-level information. Experimental results show that the word-level attention\nwith a single head results in 1.2 BLEU points drop.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:47:43 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tang", "Gongbo", ""], ["Sennrich", "Rico", ""], ["Nivre", "Joakim", ""]]}, {"id": "2011.03492", "submitter": "Saif M. Mohammad Dr.", "authors": "Saif M. Mohammad", "title": "Practical and Ethical Considerations in the Effective use of Emotion and\n  Sentiment Lexicons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicons of word-emotion associations are widely used in research and\nreal-world applications. As part of my research, I have created several such\nlexicons (e.g., the NRC Emotion Lexicon). This paper outlines some practical\nand ethical considerations involved in the effective use of these lexical\nresources.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:57:18 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 19:25:56 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mohammad", "Saif M.", ""]]}, {"id": "2011.03502", "submitter": "Quan Duong", "authors": "Quan Duong, Mika H\\\"am\\\"al\\\"ainen, Simon Hengchen", "title": "An Unsupervised method for OCR Post-Correction and Spelling\n  Normalisation for Finnish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historical corpora are known to contain errors introduced by OCR (optical\ncharacter recognition) methods used in the digitization process, often said to\nbe degrading the performance of NLP systems. Correcting these errors manually\nis a time-consuming process and a great part of the automatic approaches have\nbeen relying on rules or supervised machine learning. We build on previous work\non fully automatic unsupervised extraction of parallel data to train a\ncharacter-based sequence-to-sequence NMT (neural machine translation) model to\nconduct OCR error correction designed for English, and adapt it to Finnish by\nproposing solutions that take the rich morphology of the language into account.\nOur new method shows increased performance while remaining fully unsupervised,\nwith the added benefit of spelling normalisation. The source code and models\nare available on GitHub and Zenodo.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 18:19:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Duong", "Quan", ""], ["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Hengchen", "Simon", ""]]}, {"id": "2011.03568", "submitter": "Ron J Weiss", "authors": "Ron J. Weiss, RJ Skerry-Ryan, Eric Battenberg, Soroosh Mariooryad,\n  Diederik P. Kingma", "title": "Wave-Tacotron: Spectrogram-free end-to-end text-to-speech synthesis", "comments": "6 pages including supplement, 3 figures. accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a sequence-to-sequence neural network which directly generates\nspeech waveforms from text inputs. The architecture extends the Tacotron model\nby incorporating a normalizing flow into the autoregressive decoder loop.\nOutput waveforms are modeled as a sequence of non-overlapping fixed-length\nblocks, each one containing hundreds of samples. The interdependencies of\nwaveform samples within each block are modeled using the normalizing flow,\nenabling parallel training and synthesis. Longer-term dependencies are handled\nautoregressively by conditioning each flow on preceding blocks.This model can\nbe optimized directly with maximum likelihood, with-out using intermediate,\nhand-designed features nor additional loss terms. Contemporary state-of-the-art\ntext-to-speech (TTS) systems use a cascade of separately learned models: one\n(such as Tacotron) which generates intermediate features (such as spectrograms)\nfrom text, followed by a vocoder (such as WaveRNN) which generates waveform\nsamples from the intermediate features. The proposed system, in contrast, does\nnot use a fixed intermediate representation, and learns all parameters\nend-to-end. Experiments show that the proposed model generates speech with\nquality approaching a state-of-the-art neural TTS system, with significantly\nimproved generation speed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 19:30:07 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 19:07:32 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Weiss", "Ron J.", ""], ["Skerry-Ryan", "RJ", ""], ["Battenberg", "Eric", ""], ["Mariooryad", "Soroosh", ""], ["Kingma", "Diederik P.", ""]]}, {"id": "2011.03588", "submitter": "Md Shad Akhtar Dr.", "authors": "Mohit Bhardwaj, Md Shad Akhtar, Asif Ekbal, Amitava Das, Tanmoy\n  Chakraborty", "title": "Hostility Detection Dataset in Hindi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel hostility detection dataset in Hindi\nlanguage. We collect and manually annotate ~8200 online posts. The annotated\ndataset covers four hostility dimensions: fake news, hate speech, offensive,\nand defamation posts, along with a non-hostile label. The hostile posts are\nalso considered for multi-label tags due to a significant overlap among the\nhostile classes. We release this dataset as part of the CONSTRAINT-2021 shared\ntask on hostile post detection.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 20:33:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhardwaj", "Mohit", ""], ["Akhtar", "Md Shad", ""], ["Ekbal", "Asif", ""], ["Das", "Amitava", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2011.03646", "submitter": "Akshat Gupta", "authors": "Akshat Gupta, Xinjian Li, Sai Krishna Rallabandi, Alan W Black", "title": "Acoustics Based Intent Recognition Using Discovered Phonetic Units for\n  Low Resource Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advancements in language technologies, humans are now speaking to\ndevices. Increasing the reach of spoken language technologies requires building\nsystems in local languages. A major bottleneck here are the underlying\ndata-intensive parts that make up such systems, including automatic speech\nrecognition (ASR) systems that require large amounts of labelled data. With the\naim of aiding development of spoken dialog systems in low resourced languages,\nwe propose a novel acoustics based intent recognition system that uses\ndiscovered phonetic units for intent classification. The system is made up of\ntwo blocks - the first block is a universal phone recognition system that\ngenerates a transcript of discovered phonetic units for the input audio, and\nthe second block performs intent classification from the generated phonetic\ntranscripts. We propose a CNN+LSTM based architecture and present results for\ntwo languages families - Indic languages and Romance languages, for two\ndifferent intent recognition tasks. We also perform multilingual training of\nour intent classifier and show improved cross-lingual transfer and zero-shot\nperformance on an unknown language within the same language family.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:35:31 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 20:59:57 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gupta", "Akshat", ""], ["Li", "Xinjian", ""], ["Rallabandi", "Sai Krishna", ""], ["Black", "Alan W", ""]]}, {"id": "2011.03713", "submitter": "Parth Shah", "authors": "Richa Sharma, Parth Vipul Shah, Ashwini M. Joshi", "title": "Naturalization of Text by the Insertion of Pauses and Filler Words", "comments": "Keywords: Text transformation, natural speech, bigram, RNN, filler\n  words", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, we introduce a set of methods to naturalize text based on\nnatural human speech. Voice-based interactions provide a natural way of\ninterfacing with electronic systems and are seeing a widespread adaptation of\nlate. These computerized voices can be naturalized to some degree by inserting\npauses and filler words at appropriate positions. The first proposed text\ntransformation method uses the frequency of bigrams in the training data to\nmake appropriate insertions in the input sentence. It uses a probability\ndistribution to choose the insertions from a set of all possible insertions.\nThis method is fast and can be included before a Text-To-Speech module. The\nsecond method uses a Recurrent Neural Network to predict the next word to be\ninserted. It confirms the insertions given by the bigram method. Additionally,\nthe degree of naturalization can be controlled in both these methods. On the\nconduction of a blind survey, we conclude that the output of these text\ntransformation methods is comparable to natural speech.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 06:56:54 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Sharma", "Richa", ""], ["Shah", "Parth Vipul", ""], ["Joshi", "Ashwini M.", ""]]}, {"id": "2011.03722", "submitter": "Md Faisal Mahbub Chowdhury", "authors": "Abhijit Mishra, Md Faisal Mahbub Chowdhury, Sagar Manohar, Dan\n  Gutfreund and Karthik Sankaranarayanan", "title": "Template Controllable keywords-to-text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural model for the understudied task of\ngenerating text from keywords. The model takes as input a set of un-ordered\nkeywords, and part-of-speech (POS) based template instructions. This makes it\nideal for surface realization in any NLG setup. The framework is based on the\nencode-attend-decode paradigm, where keywords and templates are encoded first,\nand the decoder judiciously attends over the contexts derived from the encoded\nkeywords and templates to generate the sentences. Training exploits weak\nsupervision, as the model trains on a large amount of labeled data with\nkeywords and POS based templates prepared through completely automatic means.\nQualitative and quantitative performance analyses on publicly available\ntest-data in various domains reveal our system's superiority over baselines,\nbuilt using state-of-the-art neural machine translation and controllable\ntransfer techniques. Our approach is indifferent to the order of input\nkeywords.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 08:05:58 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Mishra", "Abhijit", ""], ["Chowdhury", "Md Faisal Mahbub", ""], ["Manohar", "Sagar", ""], ["Gutfreund", "Dan", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "2011.03755", "submitter": "Jason Angel", "authors": "Jason Angel, Carlos A. Rodriguez-Diaz, Alexander Gelbukh, Sergio\n  Jimenez", "title": "NLP-CIC @ DIACR-Ita: POS and Neighbor Based Distributional Models for\n  Lexical Semantic Change in Diachronic Italian Corpora", "comments": "Accepted at EVALITA 2020: Proceedings of Seventh Evaluation Campaign\n  of Natural Language Processing and Speech Tools for Italian. Final Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present our systems and findings on unsupervised lexical semantic change\nfor the Italian language in the DIACR-Ita shared-task at EVALITA 2020. The task\nis to determine whether a target word has evolved its meaning with time, only\nrelying on raw-text from two time-specific datasets. We propose two models\nrepresenting the target words across the periods to predict the changing words\nusing threshold and voting schemes. Our first model solely relies on\npart-of-speech usage and an ensemble of distance measures. The second model\nuses word embedding representation to extract the neighbor's relative distances\nacross spaces and propose \"the average of absolute differences\" to estimate\nlexical semantic change. Our models achieved competent results, ranking third\nin the DIACR-Ita competition. Furthermore, we experiment with the k_neighbor\nparameter of our second model to compare the impact of using \"the average of\nabsolute differences\" versus the cosine distance used in Hamilton et al.\n(2016).\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 11:27:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Angel", "Jason", ""], ["Rodriguez-Diaz", "Carlos A.", ""], ["Gelbukh", "Alexander", ""], ["Jimenez", "Sergio", ""]]}, {"id": "2011.03760", "submitter": "Jason Angel", "authors": "Jason Angel, Segun Taofeek Aroyehun, Alexander Gelbukh", "title": "NLP-CIC @ PRELEARN: Mastering prerequisites relations, from handcrafted\n  features to embeddings", "comments": "Accepted at EVALITA 2020: Proceedings of Seventh Evaluation Campaign\n  of Natural Language Processing and Speech Tools for Italian. Final Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present our systems and findings for the prerequisite relation learning\ntask (PRELEARN) at EVALITA 2020. The task aims to classify whether a pair of\nconcepts hold a prerequisite relation or not. We model the problem using\nhandcrafted features and embedding representations for in-domain and\ncross-domain scenarios. Our submissions ranked first place in both scenarios\nwith average F1 score of 0.887 and 0.690 respectively across domains on the\ntest sets. We made our code is freely available.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 12:13:09 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Angel", "Jason", ""], ["Aroyehun", "Segun Taofeek", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "2011.03770", "submitter": "Zhengyan Zhang", "authors": "Zhengyan Zhang, Fanchao Qi, Zhiyuan Liu, Qun Liu, Maosong Sun", "title": "Know What You Don't Need: Single-Shot Meta-Pruning for Attention Heads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep pre-trained Transformer models have achieved state-of-the-art results\nover a variety of natural language processing (NLP) tasks. By learning rich\nlanguage knowledge with millions of parameters, these models are usually\noverparameterized and significantly increase the computational overhead in\napplications. It is intuitive to address this issue by model compression. In\nthis work, we propose a method, called Single-Shot Meta-Pruning, to compress\ndeep pre-trained Transformers before fine-tuning. Specifically, we focus on\npruning unnecessary attention heads adaptively for different downstream tasks.\nTo measure the informativeness of attention heads, we train our Single-Shot\nMeta-Pruner (SMP) with a meta-learning paradigm aiming to maintain the\ndistribution of text representations after pruning. Compared with existing\ncompression methods for pre-trained models, our method can reduce the overhead\nof both fine-tuning and inference. Experimental results show that our pruner\ncan selectively prune 50% of attention heads with little impact on the\nperformance on downstream tasks and even provide better text representations.\nThe source code will be released in the future.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 12:58:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhang", "Zhengyan", ""], ["Qi", "Fanchao", ""], ["Liu", "Zhiyuan", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "2011.03783", "submitter": "Lifeng Han", "authors": "Lifeng Han, Gareth Jones, Alan Smeaton", "title": "AlphaMWE: Construction of Multilingual Parallel Corpora with MWE\n  Annotations", "comments": "Accepted to Proceedings of MWE-LEX2020@COLING, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we present the construction of multilingual parallel corpora\nwith annotation of multiword expressions (MWEs). MWEs include verbal MWEs\n(vMWEs) defined in the PARSEME shared task that have a verb as the head of the\nstudied terms. The annotated vMWEs are also bilingually and multilingually\naligned manually. The languages covered include English, Chinese, Polish, and\nGerman. Our original English corpus is taken from the PARSEME shared task in\n2018. We performed machine translation of this source corpus followed by human\npost editing and annotation of target MWEs. Strict quality control was applied\nfor error limitation, i.e., each MT output sentence received first manual post\nediting and annotation plus second manual quality rechecking. One of our\nfindings during corpora preparation is that accurate translation of MWEs\npresents challenges to MT systems. To facilitate further MT research, we\npresent a categorisation of the error types encountered by MT systems in\nperforming MWE related translation. To acquire a broader view of MT issues, we\nselected four popular state-of-the-art MT models for comparisons namely:\nMicrosoft Bing Translator, GoogleMT, Baidu Fanyi and DeepL MT. Because of the\nnoise removal, translation post editing and MWE annotation by human\nprofessionals, we believe our AlphaMWE dataset will be an asset for\ncross-lingual and multilingual research, such as MT and information extraction.\nOur multilingual corpora are available as open access at\ngithub.com/poethan/AlphaMWE.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 14:28:54 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Han", "Lifeng", ""], ["Jones", "Gareth", ""], ["Smeaton", "Alan", ""]]}, {"id": "2011.03798", "submitter": "Linlin Chao", "authors": "Linlin Chao, Jianshan He, Taifeng Wang, Wei Chu", "title": "PairRE: Knowledge Graph Embeddings via Paired Relation Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance based knowledge graph embedding methods show promising results on\nlink prediction task, on which two topics have been widely studied: one is the\nability to handle complex relations, such as N-to-1, 1-to-N and N-to-N, the\nother is to encode various relation patterns, such as symmetry/antisymmetry.\nHowever, the existing methods fail to solve these two problems at the same\ntime, which leads to unsatisfactory results. To mitigate this problem, we\npropose PairRE, a model with paired vectors for each relation representation.\nThe paired vectors enable an adaptive adjustment of the margin in loss function\nto fit for complex relations. Besides, PairRE is capable of encoding three\nimportant relation patterns, symmetry/antisymmetry, inverse and composition.\nGiven simple constraints on relation representations, PairRE can encode\nsubrelation further. Experiments on link prediction benchmarks demonstrate the\nproposed key capabilities of PairRE. Moreover, We set a new state-of-the-art on\ntwo knowledge graph datasets of the challenging Open Graph Benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 16:09:03 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 09:14:46 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 13:06:26 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chao", "Linlin", ""], ["He", "Jianshan", ""], ["Wang", "Taifeng", ""], ["Chu", "Wei", ""]]}, {"id": "2011.03803", "submitter": "Wenxuan Wang", "authors": "Wenxuan Wang and Zhaopeng Tu", "title": "Rethinking the Value of Transformer Components", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer becomes the state-of-the-art translation model, while it is not\nwell studied how each intermediate component contributes to the model\nperformance, which poses significant challenges for designing optimal\narchitectures. In this work, we bridge this gap by evaluating the impact of\nindividual component (sub-layer) in trained Transformer models from different\nperspectives. Experimental results across language pairs, training strategies,\nand model capacities show that certain components are consistently more\nimportant than the others. We also report a number of interesting findings that\nmight help humans better analyze, understand and improve Transformer models.\nBased on these observations, we further propose a new training strategy that\ncan improves translation performance by distinguishing the unimportant\ncomponents in training.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 16:31:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Wenxuan", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2011.03807", "submitter": "Peter Anderson", "authors": "Peter Anderson, Ayush Shrivastava, Joanne Truong, Arjun Majumdar, Devi\n  Parikh, Dhruv Batra, Stefan Lee", "title": "Sim-to-Real Transfer for Vision-and-Language Navigation", "comments": "CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the challenging problem of releasing a robot in a previously unseen\nenvironment, and having it follow unconstrained natural language navigation\ninstructions. Recent work on the task of Vision-and-Language Navigation (VLN)\nhas achieved significant progress in simulation. To assess the implications of\nthis work for robotics, we transfer a VLN agent trained in simulation to a\nphysical robot. To bridge the gap between the high-level discrete action space\nlearned by the VLN agent, and the robot's low-level continuous action space, we\npropose a subgoal model to identify nearby waypoints, and use domain\nrandomization to mitigate visual domain differences. For accurate sim and real\ncomparisons in parallel environments, we annotate a 325m2 office space with\n1.3km of navigation instructions, and create a digitized replica in simulation.\nWe find that sim-to-real transfer to an environment not seen in training is\nsuccessful if an occupancy map and navigation graph can be collected and\nannotated in advance (success rate of 46.8% vs. 55.9% in sim), but much more\nchallenging in the hardest setting with no prior mapping at all (success rate\nof 22.5%).\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 16:49:04 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Anderson", "Peter", ""], ["Shrivastava", "Ayush", ""], ["Truong", "Joanne", ""], ["Majumdar", "Arjun", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Lee", "Stefan", ""]]}, {"id": "2011.03856", "submitter": "Christopher Clark", "authors": "Christopher Clark, Mark Yatskar, and Luke Zettlemoyer", "title": "Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles", "comments": "In EMNLP Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datasets have been shown to contain incidental correlations created by\nidiosyncrasies in the data collection process. For example, sentence entailment\ndatasets can have spurious word-class correlations if nearly all contradiction\nsentences contain the word \"not\", and image recognition datasets can have\ntell-tale object-background correlations if dogs are always indoors. In this\npaper, we propose a method that can automatically detect and ignore these kinds\nof dataset-specific patterns, which we call dataset biases. Our method trains a\nlower capacity model in an ensemble with a higher capacity model. During\ntraining, the lower capacity model learns to capture relatively shallow\ncorrelations, which we hypothesize are likely to reflect dataset bias. This\nfrees the higher capacity model to focus on patterns that should generalize\nbetter. We ensure the models learn non-overlapping approaches by introducing a\nnovel method to make them conditionally independent. Importantly, our approach\ndoes not require the bias to be known in advance. We evaluate performance on\nsynthetic datasets, and four datasets built to penalize models that exploit\nknown biases on textual entailment, visual question answering, and image\nrecognition tasks. We show improvement in all settings, including a 10 point\ngain on the visual question answering dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 22:20:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Clark", "Christopher", ""], ["Yatskar", "Mark", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2011.03863", "submitter": "Kaixin Ma", "authors": "Kaixin Ma, Filip Ilievski, Jonathan Francis, Yonatan Bisk, Eric\n  Nyberg, Alessandro Oltramari", "title": "Knowledge-driven Data Construction for Zero-shot Evaluation in\n  Commonsense Question Answering", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in pre-trained neural language modeling have led to leaps\nin accuracy on commonsense question-answering benchmarks. However, there is\nincreasing concern that models overfit to specific tasks, without learning to\nutilize external knowledge or perform general semantic reasoning. In contrast,\nzero-shot evaluations have shown promise as a more robust measure of a model's\ngeneral reasoning abilities. In this paper, we propose a novel neuro-symbolic\nframework for zero-shot question answering across commonsense tasks. Guided by\na set of hypotheses, the framework studies how to transform various\npre-existing knowledge resources into a form that is most effective for\npre-training models. We vary the set of language models, training regimes,\nknowledge sources, and data generation strategies, and measure their impact\nacross tasks. Extending on prior work, we devise and compare four constrained\ndistractor-sampling strategies. We provide empirical results across five\ncommonsense question-answering tasks with data generated from five external\nknowledge resources. We show that, while an individual knowledge graph is\nbetter suited for specific tasks, a global knowledge graph brings consistent\ngains across different tasks. In addition, both preserving the structure of the\ntask as well as generating fair and informative questions help language models\nlearn more effectively.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 22:52:21 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 22:27:10 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ma", "Kaixin", ""], ["Ilievski", "Filip", ""], ["Francis", "Jonathan", ""], ["Bisk", "Yonatan", ""], ["Nyberg", "Eric", ""], ["Oltramari", "Alessandro", ""]]}, {"id": "2011.03870", "submitter": "Neema Kotonya", "authors": "Neema Kotonya and Francesca Toni", "title": "Explainable Automated Fact-Checking: A Survey", "comments": "Accepted to COLING 2020. Further resources available at\n  https://github.com/neemakot/Fact-Checking-Survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A number of exciting advances have been made in automated fact-checking\nthanks to increasingly larger datasets and more powerful systems, leading to\nimprovements in the complexity of claims which can be accurately fact-checked.\nHowever, despite these advances, there are still desirable functionalities\nmissing from the fact-checking pipeline. In this survey, we focus on the\nexplanation functionality -- that is fact-checking systems providing reasons\nfor their predictions. We summarize existing methods for explaining the\npredictions of fact-checking systems and we explore trends in this topic.\nFurther, we consider what makes for good explanations in this specific domain\nthrough a comparative analysis of existing fact-checking explanations against\nsome desirable properties. Finally, we propose further research directions for\ngenerating fact-checking explanations, and describe how these may lead to\nimprovements in the research area.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 23:56:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kotonya", "Neema", ""], ["Toni", "Francesca", ""]]}, {"id": "2011.03877", "submitter": "Shashank Jain", "authors": "Ankit Arun, Soumya Batra, Vikas Bhardwaj, Ashwini Challa, Pinar\n  Donmez, Peyman Heidari, Hakan Inan, Shashank Jain, Anuj Kumar, Shawn Mei,\n  Karthik Mohan, Michael White", "title": "Best Practices for Data-Efficient Modeling in NLG:How to Train\n  Production-Ready Neural Models with Less Data", "comments": "Accepted for publication in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation (NLG) is a critical component in conversational\nsystems, owing to its role of formulating a correct and natural text response.\nTraditionally, NLG components have been deployed using template-based\nsolutions. Although neural network solutions recently developed in the research\ncommunity have been shown to provide several benefits, deployment of such\nmodel-based solutions has been challenging due to high latency, correctness\nissues, and high data needs. In this paper, we present approaches that have\nhelped us deploy data-efficient neural solutions for NLG in conversational\nsystems to production. We describe a family of sampling and modeling techniques\nto attain production quality with light-weight neural network models using only\na fraction of the data that would be necessary otherwise, and show a thorough\ncomparison between each. Our results show that domain complexity dictates the\nappropriate approach to achieve high data efficiency. Finally, we distill the\nlessons from our experimental findings into a list of best practices for\nproduction-level NLG model development, and present them in a brief runbook.\nImportantly, the end products of all of the techniques are small\nsequence-to-sequence models (2Mb) that we can reliably deploy in production.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 00:38:08 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Arun", "Ankit", ""], ["Batra", "Soumya", ""], ["Bhardwaj", "Vikas", ""], ["Challa", "Ashwini", ""], ["Donmez", "Pinar", ""], ["Heidari", "Peyman", ""], ["Inan", "Hakan", ""], ["Jain", "Shashank", ""], ["Kumar", "Anuj", ""], ["Mei", "Shawn", ""], ["Mohan", "Karthik", ""], ["White", "Michael", ""]]}, {"id": "2011.03888", "submitter": "Chaojun Xiao", "authors": "Chaojun Xiao, Yuan Yao, Ruobing Xie, Xu Han, Zhiyuan Liu, Maosong Sun,\n  Fen Lin, Leyu Lin", "title": "Denoising Relation Extraction from Document-level Distant Supervision", "comments": "EMNLP 2020 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision (DS) has been widely used to generate auto-labeled data\nfor sentence-level relation extraction (RE), which improves RE performance.\nHowever, the existing success of DS cannot be directly transferred to the more\nchallenging document-level relation extraction (DocRE), since the inherent\nnoise in DS may be even multiplied in document level and significantly harm the\nperformance of RE. To address this challenge, we propose a novel pre-trained\nmodel for DocRE, which denoises the document-level DS data via multiple\npre-training tasks. Experimental results on the large-scale DocRE benchmark\nshow that our model can capture useful information from noisy DS data and\nachieve promising results.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 02:05:25 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Xiao", "Chaojun", ""], ["Yao", "Yuan", ""], ["Xie", "Ruobing", ""], ["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""]]}, {"id": "2011.03965", "submitter": "Satwik Bhattamishra", "authors": "Satwik Bhattamishra, Kabir Ahuja, Navin Goyal", "title": "On the Practical Ability of Recurrent Neural Networks to Recognize\n  Hierarchical Languages", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While recurrent models have been effective in NLP tasks, their performance on\ncontext-free languages (CFLs) has been found to be quite weak. Given that CFLs\nare believed to capture important phenomena such as hierarchical structure in\nnatural languages, this discrepancy in performance calls for an explanation. We\nstudy the performance of recurrent models on Dyck-n languages, a particularly\nimportant and well-studied class of CFLs. We find that while recurrent models\ngeneralize nearly perfectly if the lengths of the training and test strings are\nfrom the same range, they perform poorly if the test strings are longer. At the\nsame time, we observe that recurrent models are expressive enough to recognize\nDyck words of arbitrary lengths in finite precision if their depths are\nbounded. Hence, we evaluate our models on samples generated from Dyck languages\nwith bounded depth and find that they are indeed able to generalize to much\nhigher lengths. Since natural language datasets have nested dependencies of\nbounded depth, this may help explain why they perform well in modeling\nhierarchical dependencies in natural language data despite prior works\nindicating poor generalization performance on Dyck languages. We perform\nprobing studies to support our results and provide comparisons with\nTransformers.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 12:15:31 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhattamishra", "Satwik", ""], ["Ahuja", "Kabir", ""], ["Goyal", "Navin", ""]]}, {"id": "2011.03983", "submitter": "Sharath Chandra Guntuku", "authors": "Roshan Santosh, H. Andrew Schwartz, Johannes C. Eichstaedt, Lyle H.\n  Ungar, Sharath C. Guntuku", "title": "Detecting Emerging Symptoms of COVID-19 using Context-based Twitter\n  Embeddings", "comments": "In proceedings of EMNLP 2020 (Empirical Methods in NLP) workshop on\n  COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an iterative graph-based approach for the detection\nof symptoms of COVID-19, the pathology of which seems to be evolving. More\ngenerally, the method can be applied to finding context-specific words and\ntexts (e.g. symptom mentions) in large imbalanced corpora (e.g. all tweets\nmentioning #COVID-19). Given the novelty of COVID-19, we also test if the\nproposed approach generalizes to the problem of detecting Adverse Drug Reaction\n(ADR). We find that the approach applied to Twitter data can detect symptom\nmentions substantially before being reported by the Centers for Disease Control\n(CDC).\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 13:56:05 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Santosh", "Roshan", ""], ["Schwartz", "H. Andrew", ""], ["Eichstaedt", "Johannes C.", ""], ["Ungar", "Lyle H.", ""], ["Guntuku", "Sharath C.", ""]]}, {"id": "2011.03984", "submitter": "Zhen Han", "authors": "Zhen Han, Yunpu Ma, Peng Chen, Volker Tresp", "title": "DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for\n  Temporal Knowledge Graph Completion", "comments": "16 pages, accepted as long paper at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been increasing interest in learning representations of\ntemporal knowledge graphs (KGs), which record the dynamic relationships between\nentities over time. Temporal KGs often exhibit multiple simultaneous\nnon-Euclidean structures, such as hierarchical and cyclic structures. However,\nexisting embedding approaches for temporal KGs typically learn entity\nrepresentations and their dynamic evolution in the Euclidean space, which might\nnot capture such intrinsic structures very well. To this end, we propose Dy-\nERNIE, a non-Euclidean embedding approach that learns evolving entity\nrepresentations in a product of Riemannian manifolds, where the composed spaces\nare estimated from the sectional curvatures of underlying data. Product\nmanifolds enable our approach to better reflect a wide variety of geometric\nstructures on temporal KGs. Besides, to capture the evolutionary dynamics of\ntemporal KGs, we let the entity representations evolve according to a velocity\nvector defined in the tangent space at each timestamp. We analyze in detail the\ncontribution of geometric spaces to representation learning of temporal KGs and\nevaluate our model on temporal knowledge graph completion tasks. Extensive\nexperiments on three real-world datasets demonstrate significantly improved\nperformance, indicating that the dynamics of multi-relational graph data can be\nmore properly modeled by the evolution of embeddings on Riemannian manifolds.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 14:04:16 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 13:20:02 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Han", "Zhen", ""], ["Ma", "Yunpu", ""], ["Chen", "Peng", ""], ["Tresp", "Volker", ""]]}, {"id": "2011.03992", "submitter": "Ehud Reiter", "authors": "Craig Thomson and Ehud Reiter", "title": "A Gold Standard Methodology for Evaluating Accuracy in Data-To-Text\n  Systems", "comments": "To appear in INLG-2020. Resources available at\n  https://github.com/nlgcat/evaluating_accuracy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Natural Language Generation systems need to produce accurate texts. We\npropose a methodology for high-quality human evaluation of the accuracy of\ngenerated texts, which is intended to serve as a gold-standard for accuracy\nevaluations of data-to-text systems. We use our methodology to evaluate the\naccuracy of computer generated basketball summaries. We then show how our gold\nstandard evaluation can be used to validate automated metrics\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 14:49:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Thomson", "Craig", ""], ["Reiter", "Ehud", ""]]}, {"id": "2011.04000", "submitter": "Ashutosh Modi", "authors": "Ishika Singh and Ahsan Barkati and Tushar Goswamy and Ashutosh Modi", "title": "Adapting a Language Model for Controlled Affective Text Generation", "comments": "15 Pages (9 + 2 (references) + 4 (appendix)), accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human use language not just to convey information but also to express their\ninner feelings and mental states. In this work, we adapt the state-of-the-art\nlanguage generation models to generate affective (emotional) text. We posit a\nmodel capable of generating affect-driven and topic-focused sentences without\nlosing grammatical correctness as the affect intensity increases. We propose to\nincorporate emotion as prior for the probabilistic state-of-the-art text\ngeneration model such as GPT-2. The model gives a user the flexibility to\ncontrol the category and intensity of emotion as well as the topic of the\ngenerated text. Previous attempts at modelling fine-grained emotions fall out\non grammatical correctness at extreme intensities, but our model is resilient\nto this and delivers robust results at all intensities. We conduct automated\nevaluations and human studies to test the performance of our model and provide\na detailed comparison of the results with other models. In all evaluations, our\nmodel outperforms existing affective text generation models.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:24:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Singh", "Ishika", ""], ["Barkati", "Ahsan", ""], ["Goswamy", "Tushar", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2011.04004", "submitter": "Shucong Zhang", "authors": "Shucong Zhang, Erfan Loweimi, Peter Bell, Steve Renals", "title": "Stochastic Attention Head Removal: A simple and effective method for\n  improving Transformer Based ASR Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Transformer based models have shown competitive automatic speech\nrecognition (ASR) performance. One key factor in the success of these models is\nthe multi-head attention mechanism. However, for trained models, we have\npreviously observed that many attention matrices are close to diagonal,\nindicating the redundancy of the corresponding attention heads. We have also\nfound that some architectures with reduced numbers of attention heads have\nbetter performance. Since the search for the best structure is time\nprohibitive, we propose to randomly remove attention heads during training and\nkeep all attention heads at test time, thus the final model is an ensemble of\nmodels with different architectures. The proposed method also forces each head\nindependently learn the most useful patterns. We apply the proposed method to\ntrain Transformer based and Convolution-augmented Transformer (Conformer) based\nASR models. Our method gives consistent performance gains over strong baselines\non the Wall Street Journal, AISHELL, Switchboard and AMI datasets. To the best\nof our knowledge, we have achieved state-of-the-art end-to-end Transformer\nbased model performance on Switchboard and AMI.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:41:03 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 15:29:51 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Zhang", "Shucong", ""], ["Loweimi", "Erfan", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "2011.04006", "submitter": "Yi Tay", "authors": "Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri,\n  Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, Donald Metzler", "title": "Long Range Arena: A Benchmark for Efficient Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers do not scale very well to long sequence lengths largely because\nof quadratic self-attention complexity. In the recent months, a wide spectrum\nof efficient, fast Transformers have been proposed to tackle this problem, more\noften than not claiming superior or comparable model quality to vanilla\nTransformer models. To this date, there is no well-established consensus on how\nto evaluate this class of models. Moreover, inconsistent benchmarking on a wide\nspectrum of tasks and datasets makes it difficult to assess relative model\nquality amongst many models. This paper proposes a systematic and unified\nbenchmark, LRA, specifically focused on evaluating model quality under\nlong-context scenarios. Our benchmark is a suite of tasks consisting of\nsequences ranging from $1K$ to $16K$ tokens, encompassing a wide range of data\ntypes and modalities such as text, natural, synthetic images, and mathematical\nexpressions requiring similarity, structural, and visual-spatial reasoning. We\nsystematically evaluate ten well-established long-range Transformer models\n(Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers,\nSynthesizers, Sparse Transformers, and Longformers) on our newly proposed\nbenchmark suite. LRA paves the way towards better understanding this class of\nefficient Transformer models, facilitates more research in this direction, and\npresents new challenging tasks to tackle. Our benchmark code will be released\nat https://github.com/google-research/long-range-arena.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:53:56 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Tay", "Yi", ""], ["Dehghani", "Mostafa", ""], ["Abnar", "Samira", ""], ["Shen", "Yikang", ""], ["Bahri", "Dara", ""], ["Pham", "Philip", ""], ["Rao", "Jinfeng", ""], ["Yang", "Liu", ""], ["Ruder", "Sebastian", ""], ["Metzler", "Donald", ""]]}, {"id": "2011.04044", "submitter": "Yufei Feng", "authors": "Yufei Feng, Zi'ou Zheng, Quan Liu, Michael Greenspan, Xiaodan Zhu", "title": "Exploring End-to-End Differentiable Natural Logic Modeling", "comments": "10 pages", "journal-ref": "COLING 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore end-to-end trained differentiable models that integrate natural\nlogic with neural networks, aiming to keep the backbone of natural language\nreasoning based on the natural logic formalism while introducing subsymbolic\nvector representations and neural components. The proposed model adapts module\nnetworks to model natural logic operations, which is enhanced with a memory\ncomponent to model contextual information. Experiments show that the proposed\nframework can effectively model monotonicity-based reasoning, compared to the\nbaseline neural network models without built-in inductive bias for\nmonotonicity-based reasoning. Our proposed model shows to be robust when\ntransferred from upward to downward inference. We perform further analyses on\nthe performance of the proposed model on aggregation, showing the effectiveness\nof the proposed subcomponents on helping achieve better intermediate\naggregation performance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:18:15 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Feng", "Yufei", ""], ["Zheng", "Zi'ou", ""], ["Liu", "Quan", ""], ["Greenspan", "Michael", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2011.04096", "submitter": "Manik Bhandari", "authors": "Manik Bhandari, Pranav Gour, Atabak Ashfaq, Pengfei Liu", "title": "Metrics also Disagree in the Low Scoring Range: Revisiting Summarization\n  Evaluation Metrics", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text summarization, evaluating the efficacy of automatic metrics without\nhuman judgments has become recently popular. One exemplar work concludes that\nautomatic metrics strongly disagree when ranking high-scoring summaries. In\nthis paper, we revisit their experiments and find that their observations stem\nfrom the fact that metrics disagree in ranking summaries from any narrow\nscoring range. We hypothesize that this may be because summaries are similar to\neach other in a narrow scoring range and are thus, difficult to rank. Apart\nfrom the width of the scoring range of summaries, we analyze three other\nproperties that impact inter-metric agreement - Ease of Summarization,\nAbstractiveness, and Coverage. To encourage reproducible research, we make all\nour analysis code and data publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 22:26:06 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhandari", "Manik", ""], ["Gour", "Pranav", ""], ["Ashfaq", "Atabak", ""], ["Liu", "Pengfei", ""]]}, {"id": "2011.04124", "submitter": "Allen Kim", "authors": "Allen Kim, Charuta Pethe, Steven Skiena", "title": "What time is it? Temporal Analysis of Novels", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing the flow of time in a story is a crucial aspect of understanding\nit. Prior work related to time has primarily focused on identifying temporal\nexpressions or relative sequencing of events, but here we propose\ncomputationally annotating each line of a book with wall clock times, even in\nthe absence of explicit time-descriptive phrases. To do so, we construct a data\nset of hourly time phrases from 52,183 fictional books. We then construct a\ntime-of-day classification model that achieves an average error of 2.27 hours.\nFurthermore, we show that by analyzing a book in whole using dynamic\nprogramming of breakpoints, we can roughly partition a book into segments that\neach correspond to a particular time-of-day. This approach improves upon\nbaselines by over two hours. Finally, we apply our model to a corpus of\nliterature categorized by different periods in history, to show interesting\ntrends of hourly activity throughout the past. Among several observations we\nfind that the fraction of events taking place past 10 P.M jumps past 1880 -\ncoincident with the advent of the electric light bulb and city lights.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:11:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kim", "Allen", ""], ["Pethe", "Charuta", ""], ["Skiena", "Steven", ""]]}, {"id": "2011.04132", "submitter": "Fei Liu", "authors": "Kaiqiang Song and Chen Li and Xiaoyang Wang and Dong Yu and Fei Liu", "title": "Automatic Summarization of Open-Domain Podcast Episodes", "comments": "TREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present implementation details of our abstractive summarizers that achieve\ncompetitive results on the Podcast Summarization task of TREC 2020. A concise\ntextual summary that captures important information is crucial for users to\ndecide whether to listen to the podcast. Prior work focuses primarily on\nlearning contextualized representations. Instead, we investigate several\nless-studied aspects of neural abstractive summarization, including (i) the\nimportance of selecting important segments from transcripts to serve as input\nto the summarizer; (ii) striking a balance between the amount and quality of\ntraining instances; (iii) the appropriate summary length and start/end points.\nWe highlight the design considerations behind our system and offer key insights\ninto the strengths and weaknesses of neural abstractive systems. Our results\nsuggest that identifying important segments from transcripts to use as input to\nan abstractive summarizer is advantageous for summarizing long documents. Our\nbest system achieves a quality rating of 1.559 judged by NIST evaluators---an\nabsolute increase of 0.268 (+21%) over the creator descriptions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:31:05 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 17:34:35 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Song", "Kaiqiang", ""], ["Li", "Chen", ""], ["Wang", "Xiaoyang", ""], ["Yu", "Dong", ""], ["Liu", "Fei", ""]]}, {"id": "2011.04134", "submitter": "Harish Tayyar Madabushi PhD", "authors": "Harish Tayyar Madabushi, Laurence Romain, Dagmar Divjak, Petar Milin", "title": "CxGBERT: BERT meets Construction Grammar", "comments": "28th International Conference on Computational Linguistics (COLING\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While lexico-semantic elements no doubt capture a large amount of linguistic\ninformation, it has been argued that they do not capture all information\ncontained in text. This assumption is central to constructionist approaches to\nlanguage which argue that language consists of constructions, learned pairings\nof a form and a function or meaning that are either frequent or have a meaning\nthat cannot be predicted from its component parts. BERT's training objectives\ngive it access to a tremendous amount of lexico-semantic information, and while\nBERTology has shown that BERT captures certain important linguistic dimensions,\nthere have been no studies exploring the extent to which BERT might have access\nto constructional information. In this work we design several probes and\nconduct extensive experiments to answer this question. Our results allow us to\nconclude that BERT does indeed have access to a significant amount of\ninformation, much of which linguists typically call constructional information.\nThe impact of this observation is potentially far-reaching as it provides\ninsights into what deep learning methods learn from text, while also showing\nthat information contained in constructions is redundantly encoded in\nlexico-semantics.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:39:52 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Madabushi", "Harish Tayyar", ""], ["Romain", "Laurence", ""], ["Divjak", "Dagmar", ""], ["Milin", "Petar", ""]]}, {"id": "2011.04151", "submitter": "Yuntao Li", "authors": "Yuntao Li, Bei Chen, Qian Liu, Yan Gao, Jian-Guang Lou, Yan Zhang,\n  Dongmei Zhang", "title": "\"What Do You Mean by That?\" A Parser-Independent Interactive Approach\n  for Enhancing Text-to-SQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Interfaces to Databases systems, the text-to-SQL\ntechnique allows users to query databases by using natural language questions.\nThough significant progress in this area has been made recently, most parsers\nmay fall short when they are deployed in real systems. One main reason stems\nfrom the difficulty of fully understanding the users' natural language\nquestions. In this paper, we include human in the loop and present a novel\nparser-independent interactive approach (PIIA) that interacts with users using\nmulti-choice questions and can easily work with arbitrary parsers. Experiments\nwere conducted on two cross-domain datasets, the WikiSQL and the more complex\nSpider, with five state-of-the-art parsers. These demonstrated that PIIA is\ncapable of enhancing the text-to-SQL performance with limited interaction turns\nby using both simulation and human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:14:33 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Li", "Yuntao", ""], ["Chen", "Bei", ""], ["Liu", "Qian", ""], ["Gao", "Yan", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Yan", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2011.04163", "submitter": "Charuta Pethe", "authors": "Charuta Pethe, Allen Kim, Steven Skiena", "title": "Chapter Captor: Text Segmentation in Novels", "comments": "11 pages, 10 figures, Accepted at EMNLP 2020 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Books are typically segmented into chapters and sections, representing\ncoherent subnarratives and topics. We investigate the task of predicting\nchapter boundaries, as a proxy for the general task of segmenting long texts.\nWe build a Project Gutenberg chapter segmentation data set of 9,126 English\nnovels, using a hybrid approach combining neural inference and rule matching to\nrecognize chapter title headers in books, achieving an F1-score of 0.77 on this\ntask. Using this annotated data as ground truth after removing structural cues,\nwe present cut-based and neural methods for chapter segmentation, achieving an\nF1-score of 0.453 on the challenging task of exact break prediction over\nbook-length documents. Finally, we reveal interesting historical trends in the\nchapter structure of novels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:56:54 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Pethe", "Charuta", ""], ["Kim", "Allen", ""], ["Skiena", "Steven", ""]]}, {"id": "2011.04184", "submitter": "Takumi Aoki", "authors": "Takumi Aoki and Shunsuke Kitada and Hitoshi Iyatomi", "title": "Text Classification through Glyph-aware Disentangled Character Embedding\n  and Semantic Sub-character Augmentation", "comments": "6 pages, 3 figures, Accepted at AACL-IJCNLP 2020: Student Research\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new character-based text classification framework for\nnon-alphabetic languages, such as Chinese and Japanese. Our framework consists\nof a variational character encoder (VCE) and character-level text classifier.\nThe VCE is composed of a $\\beta$-variational auto-encoder ($\\beta$-VAE) that\nlearns the proposed glyph-aware disentangled character embedding (GDCE). Since\nour GDCE provides zero-mean unit-variance character embeddings that are\ndimensionally independent, it is applicable for our interpretable data\naugmentation, namely, semantic sub-character augmentation (SSA). In this paper,\nwe evaluated our framework using Japanese text classification tasks at the\ndocument- and sentence-level. We confirmed that our GDCE and SSA not only\nprovided embedding interpretability but also improved the classification\nperformance. Our proposal achieved a competitive result to the state-of-the-art\nmodel while also providing model interpretability. Our code is available on\nhttps://github.com/IyatomiLab/GDCE-SSA\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:38:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Aoki", "Takumi", ""], ["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "2011.04196", "submitter": "Peidong Wang", "authors": "Peidong Wang, DeLiang Wang", "title": "Efficient End-to-End Speech Recognition Using Performers in Conformers", "comments": "The current submission has not been reviewed by the coauthor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device end-to-end speech recognition poses a high requirement on model\nefficiency. Most prior works improve the efficiency by reducing model sizes. We\npropose to reduce the complexity of model architectures in addition to model\nsizes. More specifically, we reduce the floating-point operations in conformer\nby replacing the transformer module with a performer. The proposed\nattention-based efficient end-to-end speech recognition model yields\ncompetitive performance on the LibriSpeech corpus with 10 millions of\nparameters and linear computation complexity. The proposed model also\noutperforms previous lightweight end-to-end models by about 20% relatively in\nword error rate.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 05:22:57 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:07:46 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Peidong", ""], ["Wang", "DeLiang", ""]]}, {"id": "2011.04241", "submitter": "Shogo Fujita", "authors": "Shogo Fujita, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura", "title": "Pointing to Subwords for Generating Function Names in Source Code", "comments": "12 pages, accepted to COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the task of automatically generating a function name from source\ncode. Existing generators face difficulties in generating low-frequency or\nout-of-vocabulary subwords. In this paper, we propose two strategies for\ncopying low-frequency or out-of-vocabulary subwords in inputs. Our best\nperforming model showed an improvement over the conventional method in terms of\nour modified F1 and accuracy on the Java-small and Java-large datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 08:17:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Fujita", "Shogo", ""], ["Kamigaito", "Hidetaka", ""], ["Takamura", "Hiroya", ""], ["Okumura", "Manabu", ""]]}, {"id": "2011.04242", "submitter": "Ben Burtenshaw", "authors": "Ben Burtenshaw", "title": "AI Stories: An Interactive Narrative System for Children", "comments": "Originally submitted to the ICCC 2017 Doctoral Consortium\n  [https://computationalcreativity.net/iccc2017/doctoralconsortium/]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI Stories is a proposed interactive dialogue system, that lets children\nco-create narrative worlds through conversation. Over the next three years this\nsystem will be developed and tested within pediatric wards, where it offers a\nuseful resource between the gap of education and play. Telling and making\nstories is a fundamental part of language play, and its chatty and nonsensical\nqualities are important; therefore, the prologued usage an automated system\noffers is a benefit to children. In this paper I will present the current state\nof this project, in its more experimental and general guise. Conceptually\nstory-telling through dialogue relates to the preprint interpretation of story,\nbeyond the static and linear medium, where stories were performative, temporal,\nand social.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 08:17:22 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Burtenshaw", "Ben", ""]]}, {"id": "2011.04249", "submitter": "Cunhang Fan", "authors": "Cunhang Fan, Jiangyan Yi, Jianhua Tao, Zhengkun Tian, Bin Liu, Zhengqi\n  Wen", "title": "Gated Recurrent Fusion with Joint Training Framework for Robust\n  End-to-End Speech Recognition", "comments": "Accepted by IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint training framework for speech enhancement and recognition methods\nhave obtained quite good performances for robust end-to-end automatic speech\nrecognition (ASR). However, these methods only utilize the enhanced feature as\nthe input of the speech recognition component, which are affected by the speech\ndistortion problem. In order to address this problem, this paper proposes a\ngated recurrent fusion (GRF) method with joint training framework for robust\nend-to-end ASR. The GRF algorithm is used to dynamically combine the noisy and\nenhanced features. Therefore, the GRF can not only remove the noise signals\nfrom the enhanced features, but also learn the raw fine structures from the\nnoisy features so that it can alleviate the speech distortion. The proposed\nmethod consists of speech enhancement, GRF and speech recognition. Firstly, the\nmask based speech enhancement network is applied to enhance the input speech.\nSecondly, the GRF is applied to address the speech distortion problem. Thirdly,\nto improve the performance of ASR, the state-of-the-art speech transformer\nalgorithm is used as the speech recognition component. Finally, the joint\ntraining framework is utilized to optimize these three components,\nsimultaneously. Our experiments are conducted on an open-source Mandarin speech\ncorpus called AISHELL-1. Experimental results show that the proposed method\nachieves the relative character error rate (CER) reduction of 10.04\\% over the\nconventional joint enhancement and transformer method only using the enhanced\nfeatures. Especially for the low signal-to-noise ratio (0 dB), our proposed\nmethod can achieves better performances with 12.67\\% CER reduction, which\nsuggests the potential of our proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 08:52:05 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Fan", "Cunhang", ""], ["Yi", "Jiangyan", ""], ["Tao", "Jianhua", ""], ["Tian", "Zhengkun", ""], ["Liu", "Bin", ""], ["Wen", "Zhengqi", ""]]}, {"id": "2011.04264", "submitter": "Adam Fisch", "authors": "Adam Fisch, Kenton Lee, Ming-Wei Chang, Jonathan H. Clark, Regina\n  Barzilay", "title": "CapWAP: Captioning with a Purpose", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional image captioning task uses generic reference captions to\nprovide textual information about images. Different user populations, however,\nwill care about different visual aspects of images. In this paper, we propose a\nnew task, Captioning with a Purpose (CapWAP). Our goal is to develop systems\nthat can be tailored to be useful for the information needs of an intended\npopulation, rather than merely provide generic information about an image. In\nthis task, we use question-answer (QA) pairs---a natural expression of\ninformation need---from users, instead of reference captions, for both training\nand post-inference evaluation. We show that it is possible to use reinforcement\nlearning to directly optimize for the intended information need, by rewarding\noutputs that allow a question answering model to provide correct answers to\nsampled user questions. We convert several visual question answering datasets\ninto CapWAP datasets, and demonstrate that under a variety of scenarios our\npurposeful captioning system learns to anticipate and fulfill specific\ninformation needs better than its generic counterparts, as measured by QA\nperformance on user questions from unseen images, when using the caption alone\nas context.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:23:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Fisch", "Adam", ""], ["Lee", "Kenton", ""], ["Chang", "Ming-Wei", ""], ["Clark", "Jonathan H.", ""], ["Barzilay", "Regina", ""]]}, {"id": "2011.04266", "submitter": "Zhebin Zhang", "authors": "Zhebin Zhang, Sai Wu, Dawei Jiang, Gang Chen", "title": "BERT-JAM: Boosting BERT-Enhanced Neural Machine Translation with Joint\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT-enhanced neural machine translation (NMT) aims at leveraging\nBERT-encoded representations for translation tasks. A recently proposed\napproach uses attention mechanisms to fuse Transformer's encoder and decoder\nlayers with BERT's last-layer representation and shows enhanced performance.\nHowever, their method doesn't allow for the flexible distribution of attention\nbetween the BERT representation and the encoder/decoder representation. In this\nwork, we propose a novel BERT-enhanced NMT model called BERT-JAM which improves\nupon existing models from two aspects: 1) BERT-JAM uses joint-attention modules\nto allow the encoder/decoder layers to dynamically allocate attention between\ndifferent representations, and 2) BERT-JAM allows the encoder/decoder layers to\nmake use of BERT's intermediate representations by composing them using a gated\nlinear unit (GLU). We train BERT-JAM with a novel three-phase optimization\nstrategy that progressively unfreezes different components of BERT-JAM. Our\nexperiments show that BERT-JAM achieves SOTA BLEU scores on multiple\ntranslation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:30:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhang", "Zhebin", ""], ["Wu", "Sai", ""], ["Jiang", "Dawei", ""], ["Chen", "Gang", ""]]}, {"id": "2011.04297", "submitter": "Gurunath Reddy Madhumani", "authors": "Soumava Paul, Gurunath Reddy M, K Sreenivasa Rao and Partha Pratim Das", "title": "Knowledge Distillation for Singing Voice Detection", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Singing Voice Detection (SVD) has been an active area of research in music\ninformation retrieval (MIR). Currently, two deep neural network-based methods,\none based on CNN and the other on RNN, exist in literature that learn optimized\nfeatures for the voice detection (VD) task and achieve state-of-the-art\nperformance on common datasets. Both these models have a huge number of\nparameters (1.4M for CNN and 65.7K for RNN) and hence not suitable for\ndeployment on devices like smartphones or embedded sensors with limited\ncapacity in terms of memory and computation power. The most popular method to\naddress this issue is known as knowledge distillation in deep learning\nliterature (in addition to model compression) where a large pretrained network\nknown as the teacher is used to train a smaller student network. However, to\nthe best of our knowledge, such methods have not been explored yet in the\ndomain of SVD. In this paper, efforts have been made to investigate this issue\nusing both conventional as well as ensemble knowledge distillation techniques.\nThrough extensive experimentation on the publicly available Jamendo dataset, we\nshow that, not only it's possible to achieve comparable accuracies with far\nsmaller models (upto 1000x smaller in terms of parameters), but fascinatingly,\nin some cases, smaller models trained with distillation, even surpass the\ncurrent state-of-the-art models on voice detection performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:14:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Paul", "Soumava", ""], ["M", "Gurunath Reddy", ""], ["Rao", "K Sreenivasa", ""], ["Das", "Partha Pratim", ""]]}, {"id": "2011.04308", "submitter": "Rik Van Noord", "authors": "Rik van Noord, Antonio Toral, Johan Bos", "title": "Character-level Representations Improve DRS-based Semantic Parsing Even\n  in the Age of BERT", "comments": "EMNLP 2020 (long)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine character-level and contextual language model representations to\nimprove performance on Discourse Representation Structure parsing. Character\nrepresentations can easily be added in a sequence-to-sequence model in either\none encoder or as a fully separate encoder, with improvements that are robust\nto different language models, languages and data sets. For English, these\nimprovements are larger than adding individual sources of linguistic\ninformation or adding non-contextual embeddings. A new method of analysis based\non semantic tags demonstrates that the character-level representations improve\nperformance across a subset of selected semantic phenomena.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:24:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["van Noord", "Rik", ""], ["Toral", "Antonio", ""], ["Bos", "Johan", ""]]}, {"id": "2011.04372", "submitter": "Farhad Nooralahzadeh", "authors": "Farhad Nooralahzadeh", "title": "Low-Resource Adaptation of Neural NLP Models", "comments": "Thesis submitted for the degree of Philosophiae Doctor. Department of\n  Informatics, University of Oslo.\n  https://www.mn.uio.no/ifi/forskning/aktuelt/arrangementer/disputaser/2020/nooralahzadeh.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications of natural language processing (NLP) are challenging.\nNLP models rely heavily on supervised machine learning and require large\namounts of annotated data. These resources are often based on language data\navailable in large quantities, such as English newswire. However, in real-world\napplications of NLP, the textual resources vary across several dimensions, such\nas language, dialect, topic, and genre. It is challenging to find annotated\ndata of sufficient amount and quality. The objective of this thesis is to\ninvestigate methods for dealing with such low-resource scenarios in information\nextraction and natural language understanding. To this end, we study distant\nsupervision and sequential transfer learning in various low-resource settings.\nWe develop and adapt neural NLP models to explore a number of research\nquestions concerning NLP tasks with minimal or no training data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:13:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Nooralahzadeh", "Farhad", ""]]}, {"id": "2011.04393", "submitter": "Ziyang Luo", "authors": "Ziyang Luo, Artur Kulmizev, Xiaoxi Mao", "title": "Positional Artefacts Propagate Through Masked Language Model Embeddings", "comments": "Accepted as long paper at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we demonstrate that the contextualized word vectors derived\nfrom pretrained masked language model-based encoders share a common, perhaps\nundesirable pattern across layers. Namely, we find cases of persistent outlier\nneurons within BERT and RoBERTa's hidden state vectors that consistently bear\nthe smallest or largest values in said vectors. In an attempt to investigate\nthe source of this information, we introduce a neuron-level analysis method,\nwhich reveals that the outliers are closely related to information captured by\npositional embeddings. We also pre-train the RoBERTa-base models from scratch\nand find that the outliers disappear without using positional embeddings. These\noutliers, we find, are the major cause of anisotropy of encoders' raw vector\nspaces, and clipping them leads to increased similarity across vectors. We\ndemonstrate this in practice by showing that clipped vectors can more\naccurately distinguish word senses, as well as lead to better sentence\nembeddings when mean pooling. In three supervised tasks, we find that clipping\ndoes not affect the performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:49:39 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 09:24:11 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 01:38:12 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Luo", "Ziyang", ""], ["Kulmizev", "Artur", ""], ["Mao", "Xiaoxi", ""]]}, {"id": "2011.04446", "submitter": "Tanvirul Alam", "authors": "Tanvirul Alam, Akib Khan and Firoj Alam", "title": "Bangla Text Classification using Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:12:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Alam", "Tanvirul", ""], ["Khan", "Akib", ""], ["Alam", "Firoj", ""]]}, {"id": "2011.04451", "submitter": "Alper Ahmeto\\u{g}lu", "authors": "\\c{C}a\\u{g}la Aksoy, Alper Ahmeto\\u{g}lu, Tunga G\\\"ung\\\"or", "title": "Hierarchical Multitask Learning Approach for BERT", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that learning contextualized embeddings for words is\nbeneficial for downstream tasks. BERT is one successful example of this\napproach. It learns embeddings by solving two tasks, which are masked language\nmodel (masked LM) and the next sentence prediction (NSP). The pre-training of\nBERT can also be framed as a multitask learning problem. In this work, we adopt\nhierarchical multitask learning approaches for BERT pre-training. Pre-training\ntasks are solved at different layers instead of the last layer, and information\nfrom the NSP task is transferred to the masked LM task. Also, we propose a new\npre-training task bigram shift to encode word order information. We choose two\ndownstream tasks, one of which requires sentence-level embeddings (textual\nentailment), and the other requires contextualized embeddings of words\n(question answering). Due to computational restrictions, we use the downstream\ntask data instead of a large dataset for the pre-training to see the\nperformance of proposed models when given a restricted dataset. We test their\nperformance on several probing tasks to analyze learned embeddings. Our results\nshow that imposing a task hierarchy in pre-training improves the performance of\nembeddings.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 09:23:04 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Aksoy", "\u00c7a\u011fla", ""], ["Ahmeto\u011flu", "Alper", ""], ["G\u00fcng\u00f6r", "Tunga", ""]]}, {"id": "2011.04491", "submitter": "Aiswarya Vinod Kumar", "authors": "Jiachen Lian, Aiswarya Vinod Kumar, Hira Dhamyal, Bhiksha Raj, Rita\n  Singh", "title": "Masked Proxy Loss For Text-Independent Speaker Verification", "comments": "Accepted at Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-set speaker recognition can be regarded as a metric learning problem,\nwhich is to maximize inter-class variance and minimize intra-class variance.\nSupervised metric learning can be categorized into entity-based learning and\nproxy-based learning. Most of the existing metric learning objectives like\nContrastive, Triplet, Prototypical, GE2E, etc all belong to the former\ndivision, the performance of which is either highly dependent on sample mining\nstrategy or restricted by insufficient label information in the mini-batch.\nProxy-based losses mitigate both shortcomings, however, fine-grained\nconnections among entities are either not or indirectly leveraged. This paper\nproposes a Masked Proxy (MP) loss which directly incorporates both proxy-based\nrelationships and pair-based relationships. We further propose Multinomial\nMasked Proxy (MMP) loss to leverage the hardness of speaker pairs. These\nmethods have been applied to evaluate on VoxCeleb test set and reach\nstate-of-the-art Equal Error Rate(EER).\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:16:29 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 03:10:18 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Lian", "Jiachen", ""], ["Kumar", "Aiswarya Vinod", ""], ["Dhamyal", "Hira", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "2011.04499", "submitter": "Siyu Long", "authors": "Siyu Long and Ran Wang and Kun Tao and Jiali Zeng and Xin-Yu Dai", "title": "Synonym Knowledge Enhanced Reader for Chinese Idiom Reading\n  Comprehension", "comments": "12 pages, 3 figure, accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine reading comprehension (MRC) is the task that asks a machine to answer\nquestions based on a given context. For Chinese MRC, due to the non-literal and\nnon-compositional semantic characteristics, Chinese idioms pose unique\nchallenges for machines to understand. Previous studies tend to treat idioms\nseparately without fully exploiting the relationship among them. In this paper,\nwe first define the concept of literal meaning coverage to measure the\nconsistency between semantics and literal meanings for Chinese idioms. With the\ndefinition, we prove that the literal meanings of many idioms are far from\ntheir semantics, and we also verify that the synonymic relationship can\nmitigate this inconsistency, which would be beneficial for idiom comprehension.\nFurthermore, to fully utilize the synonymic relationship, we propose the\nsynonym knowledge enhanced reader. Specifically, for each idiom, we first\nconstruct a synonym graph according to the annotations from a high-quality\nsynonym dictionary or the cosine similarity between the pre-trained idiom\nembeddings and then incorporate the graph attention network and gate mechanism\nto encode the graph. Experimental results on ChID, a large-scale Chinese idiom\nreading comprehension dataset, show that our model achieves state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:28:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Long", "Siyu", ""], ["Wang", "Ran", ""], ["Tao", "Kun", ""], ["Zeng", "Jiali", ""], ["Dai", "Xin-Yu", ""]]}, {"id": "2011.04507", "submitter": "Betty van Aken", "authors": "Betty van Aken, Benjamin Winter, Alexander L\\\"oser, Felix A. Gers", "title": "VisBERT: Hidden-State Visualizations for Transformers", "comments": "Published in WWW '20: Companion Proceedings of the Web Conference\n  2020", "journal-ref": "Companion Proceedings of the Web Conference 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability and interpretability are two important concepts, the absence\nof which can and should impede the application of well-performing neural\nnetworks to real-world problems. At the same time, they are difficult to\nincorporate into the large, black-box models that achieve state-of-the-art\nresults in a multitude of NLP tasks. Bidirectional Encoder Representations from\nTransformers (BERT) is one such black-box model. It has become a staple\narchitecture to solve many different NLP tasks and has inspired a number of\nrelated Transformer models. Understanding how these models draw conclusions is\ncrucial for both their improvement and application. We contribute to this\nchallenge by presenting VisBERT, a tool for visualizing the contextual token\nrepresentations within BERT for the task of (multi-hop) Question Answering.\nInstead of analyzing attention weights, we focus on the hidden states resulting\nfrom each encoder block within the BERT model. This way we can observe how the\nsemantic representations are transformed throughout the layers of the model.\nVisBERT enables users to get insights about the model's internal state and to\nexplore its inference steps or potential shortcomings. The tool allows us to\nidentify distinct phases in BERT's transformations that are similar to a\ntraditional NLP pipeline and offer insights during failed predictions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:37:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["van Aken", "Betty", ""], ["Winter", "Benjamin", ""], ["L\u00f6ser", "Alexander", ""], ["Gers", "Felix A.", ""]]}, {"id": "2011.04512", "submitter": "Dongyub Lee", "authors": "Dongyub Lee, Byeongil Ko, Myeong Cheol Shin, Taesun Whang, Daniel Lee,\n  Eun Hwa Kim, EungGyun Kim, and Jaechoon Jo", "title": "Auxiliary Sequence Labeling Tasks for Disfluency Detection", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting disfluencies in spontaneous speech is an important preprocessing\nstep in natural language processing and speech recognition applications.\nExisting works for disfluency detection have focused on designing a single\nobjective only for disfluency detection, while auxiliary objectives utilizing\nlinguistic information of a word such as named entity or part-of-speech\ninformation can be effective. In this paper, we focus on detecting disfluencies\non spoken transcripts and propose a method utilizing named entity recognition\n(NER) and part-of-speech (POS) as auxiliary sequence labeling (SL) tasks for\ndisfluency detection. First, we investigate cases that utilizing linguistic\ninformation of a word can prevent mispredicting important words and can be\nhelpful for the correct detection of disfluencies. Second, we show that\ntraining a disfluency detection model with auxiliary SL tasks can improve its\nF-score in disfluency detection. Then, we analyze which auxiliary SL tasks are\ninfluential depending on baseline models. Experimental results on the widely\nused English Switchboard dataset show that our method outperforms the previous\nstate-of-the-art in disfluency detection.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 02:51:17 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 13:09:23 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lee", "Dongyub", ""], ["Ko", "Byeongil", ""], ["Shin", "Myeong Cheol", ""], ["Whang", "Taesun", ""], ["Lee", "Daniel", ""], ["Kim", "Eun Hwa", ""], ["Kim", "EungGyun", ""], ["Jo", "Jaechoon", ""]]}, {"id": "2011.04521", "submitter": "Marina Litvak Dr", "authors": "Natalia Vanetik, Marina Litvak, Sergey Shevchuk, and Lior Reznik", "title": "Automated Discovery of Mathematical Definitions in Text with Deep Neural\n  Networks", "comments": "42 pages, 10 figures, currently under review in Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic definition extraction from texts is an important task that has\nnumerous applications in several natural language processing fields such as\nsummarization, analysis of scientific texts, automatic taxonomy generation,\nontology generation, concept identification, and question answering. For\ndefinitions that are contained within a single sentence, this problem can be\nviewed as a binary classification of sentences into definitions and\nnon-definitions. In this paper, we focus on automatic detection of one-sentence\ndefinitions in mathematical texts, which are difficult to separate from\nsurrounding text. We experiment with several data representations, which\ninclude sentence syntactic structure and word embeddings, and apply deep\nlearning methods such as the Convolutional Neural Network (CNN) and the Long\nShort-Term Memory network (LSTM), in order to identify mathematical\ndefinitions. Our experiments demonstrate the superiority of CNN and its\ncombination with LSTM, when applied on the syntactically-enriched input\nrepresentation. We also present a new dataset for definition extraction from\nmathematical texts. We demonstrate that this dataset is beneficial for training\nsupervised models aimed at extraction of mathematical definitions. Our\nexperiments with different domains demonstrate that mathematical definitions\nrequire special treatment, and that using cross-domain learning is inefficient\nfor that task.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:57:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Vanetik", "Natalia", ""], ["Litvak", "Marina", ""], ["Shevchuk", "Sergey", ""], ["Reznik", "Lior", ""]]}, {"id": "2011.04548", "submitter": "Ivan Girardi", "authors": "Chiara Marchiori, Douglas Dykeman, Ivan Girardi, Adam Ivankay, Kevin\n  Thandiackal, Mario Zusag, Andrea Giovannini, Daniel Karpati, Henri Saenz", "title": "Artificial Intelligence Decision Support for Medical Triage", "comments": "10 pages, 5 figures, accepted to AMIA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying state-of-the-art machine learning and natural language processing on\napproximately one million of teleconsultation records, we developed a triage\nsystem, now certified and in use at the largest European telemedicine provider.\nThe system evaluates care alternatives through interactions with patients via a\nmobile application. Reasoning on an initial set of provided symptoms, the\ntriage application generates AI-powered, personalized questions to better\ncharacterize the problem and recommends the most appropriate point of care and\ntime frame for a consultation. The underlying technology was developed to meet\nthe needs for performance, transparency, user acceptance and ease of use,\ncentral aspects to the adoption of AI-based decision support systems. Providing\nsuch remote guidance at the beginning of the chain of care has significant\npotential for improving cost efficiency, patient experience and outcomes. Being\nremote, always available and highly scalable, this service is fundamental in\nhigh demand situations, such as the current COVID-19 outbreak.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:45:01 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Marchiori", "Chiara", ""], ["Dykeman", "Douglas", ""], ["Girardi", "Ivan", ""], ["Ivankay", "Adam", ""], ["Thandiackal", "Kevin", ""], ["Zusag", "Mario", ""], ["Giovannini", "Andrea", ""], ["Karpati", "Daniel", ""], ["Saenz", "Henri", ""]]}, {"id": "2011.04554", "submitter": "Ece Takmaz", "authors": "Ece Takmaz, Mario Giulianelli, Sandro Pezzelle, Arabella Sinclair,\n  Raquel Fern\\'andez", "title": "Refer, Reuse, Reduce: Generating Subsequent References in Visual and\n  Conversational Contexts", "comments": "In Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue participants often refer to entities or situations repeatedly within\na conversation, which contributes to its cohesiveness. Subsequent references\nexploit the common ground accumulated by the interlocutors and hence have\nseveral interesting properties, namely, they tend to be shorter and reuse\nexpressions that were effective in previous mentions. In this paper, we tackle\nthe generation of first and subsequent references in visually grounded\ndialogue. We propose a generation model that produces referring utterances\ngrounded in both the visual and the conversational context. To assess the\nreferring effectiveness of its output, we also implement a reference resolution\nsystem. Our experiments and analyses show that the model produces better, more\neffective referring utterances than a model not grounded in the dialogue\ncontext, and generates subsequent references that exhibit linguistic patterns\nakin to humans.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:53:54 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Takmaz", "Ece", ""], ["Giulianelli", "Mario", ""], ["Pezzelle", "Sandro", ""], ["Sinclair", "Arabella", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "2011.04592", "submitter": "Ece Takmaz", "authors": "Ece Takmaz, Sandro Pezzelle, Lisa Beinborn, Raquel Fern\\'andez", "title": "Generating Image Descriptions via Sequential Cross-Modal Alignment\n  Guided by Human Gaze", "comments": "In Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When speakers describe an image, they tend to look at objects before\nmentioning them. In this paper, we investigate such sequential cross-modal\nalignment by modelling the image description generation process\ncomputationally. We take as our starting point a state-of-the-art image\ncaptioning system and develop several model variants that exploit information\nfrom human gaze patterns recorded during language production. In particular, we\npropose the first approach to image description generation where visual\nprocessing is modelled $\\textit{sequentially}$. Our experiments and analyses\nconfirm that better descriptions can be obtained by exploiting gaze-driven\nattention and shed light on human cognitive processes by comparing different\nways of aligning the gaze modality with language production. We find that\nprocessing gaze data sequentially leads to descriptions that are better aligned\nto those produced by speakers, more diverse, and more natural${-}$particularly\nwhen gaze is encoded with a dedicated recurrent component.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:45:32 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Takmaz", "Ece", ""], ["Pezzelle", "Sandro", ""], ["Beinborn", "Lisa", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "2011.04637", "submitter": "Svetlana Stoyanchev", "authors": "Svetlana Stoyanchev, Simon Keizer and Rama Doddipatla", "title": "Action State Update Approach to Dialogue Management", "comments": "5 pages, 1 figure. Submitted to ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Utterance interpretation is one of the main functions of a dialogue manager,\nwhich is the key component of a dialogue system. We propose the action state\nupdate approach (ASU) for utterance interpretation, featuring a statistically\ntrained binary classifier used to detect dialogue state update actions in the\ntext of a user utterance. Our goal is to interpret referring expressions in\nuser input without a domain-specific natural language understanding component.\nFor training the model, we use active learning to automatically select\nsimulated training examples. With both user-simulated and interactive human\nevaluations, we show that the ASU approach successfully interprets user\nutterances in a dialogue system, including those with referring expressions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:49:41 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:03:22 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Stoyanchev", "Svetlana", ""], ["Keizer", "Simon", ""], ["Doddipatla", "Rama", ""]]}, {"id": "2011.04640", "submitter": "Justin Chiu", "authors": "Justin T. Chiu and Alexander M. Rush", "title": "Scaling Hidden Markov Language Models", "comments": "9 pages, accepted as a short paper at EMNLP 2020", "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hidden Markov model (HMM) is a fundamental tool for sequence modeling\nthat cleanly separates the hidden state from the emission structure. However,\nthis separation makes it difficult to fit HMMs to large datasets in modern NLP,\nand they have fallen out of use due to very poor performance compared to fully\nobserved models. This work revisits the challenge of scaling HMMs to language\nmodeling datasets, taking ideas from recent approaches to neural modeling. We\npropose methods for scaling HMMs to massive state spaces while maintaining\nefficient exact inference, a compact parameterization, and effective\nregularization. Experiments show that this approach leads to models that are\nmore accurate than previous HMM and n-gram-based methods, making progress\ntowards the performance of state-of-the-art neural models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:51:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chiu", "Justin T.", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2011.04696", "submitter": "Fernando M. Espinoza-Cuadros", "authors": "Fernando M. Espinoza-Cuadros, Juan M. Perero-Codosero, Javier\n  Ant\\'on-Mart\\'in, Luis A. Hern\\'andez-G\\'omez", "title": "Speaker De-identification System using Autoencoders and Adversarial\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast increase of web services and mobile apps, which collect personal\ndata from users, increases the risk that their privacy may be severely\ncompromised. In particular, the increasing variety of spoken language\ninterfaces and voice assistants empowered by the vertiginous breakthroughs in\nDeep Learning are prompting important concerns in the European Union to\npreserve speech data privacy. For instance, an attacker can record speech from\nusers and impersonate them to get access to systems requiring voice\nidentification. Hacking speaker profiles from users is also possible by means\nof existing technology to extract speaker, linguistic (e.g., dialect) and\nparalinguistic features (e.g., age) from the speech signal. In order to\nmitigate these weaknesses, in this paper, we propose a speaker\nde-identification system based on adversarial training and autoencoders in\norder to suppress speaker, gender, and accent information from speech.\nExperimental results show that combining adversarial learning and autoencoders\nincrease the equal error rate of a speaker verification system while preserving\nthe intelligibility of the anonymized spoken content.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:22:05 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Espinoza-Cuadros", "Fernando M.", ""], ["Perero-Codosero", "Juan M.", ""], ["Ant\u00f3n-Mart\u00edn", "Javier", ""], ["Hern\u00e1ndez-G\u00f3mez", "Luis A.", ""]]}, {"id": "2011.04732", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Yunyao Li, Siddhartha Brahma, and Huaiyu Zhu", "title": "CLAR: A Cross-Lingual Argument Regularizer for Semantic Role Labeling", "comments": "EMNLP 2020, ACL Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic role labeling (SRL) identifies predicate-argument structure(s) in a\ngiven sentence. Although different languages have different argument\nannotations, polyglot training, the idea of training one model on multiple\nlanguages, has previously been shown to outperform monolingual baselines,\nespecially for low resource languages. In fact, even a simple combination of\ndata has been shown to be effective with polyglot training by representing the\ndistant vocabularies in a shared representation space. Meanwhile, despite the\ndissimilarity in argument annotations between languages, certain argument\nlabels do share common semantic meaning across languages (e.g. adjuncts have\nmore or less similar semantic meaning across languages). To leverage such\nsimilarity in annotation space across languages, we propose a method called\nCross-Lingual Argument Regularizer (CLAR). CLAR identifies such linguistic\nannotation similarity across languages and exploits this information to map the\ntarget language arguments using a transformation of the space on which source\nlanguage arguments lie. By doing so, our experimental results show that CLAR\nconsistently improves SRL performance on multiple languages over monolingual\nand polyglot baselines for low resource languages.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:16:57 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Jindal", "Ishan", ""], ["Li", "Yunyao", ""], ["Brahma", "Siddhartha", ""], ["Zhu", "Huaiyu", ""]]}, {"id": "2011.04743", "submitter": "Congzheng Song", "authors": "Congzheng Song, Alexander M. Rush, Vitaly Shmatikov", "title": "Adversarial Semantic Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study semantic collisions: texts that are semantically unrelated but\njudged as similar by NLP models. We develop gradient-based approaches for\ngenerating semantic collisions and demonstrate that state-of-the-art models for\nmany tasks which rely on analyzing the meaning and similarity of texts--\nincluding paraphrase identification, document retrieval, response suggestion,\nand extractive summarization-- are vulnerable to semantic collisions. For\nexample, given a target query, inserting a crafted collision into an irrelevant\ndocument can shift its retrieval rank from 1000 to top 3. We show how to\ngenerate semantic collisions that evade perplexity-based filtering and discuss\nother potential mitigations. Our code is available at\nhttps://github.com/csong27/collision-bert.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:42:01 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Song", "Congzheng", ""], ["Rush", "Alexander M.", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2011.04748", "submitter": "Pragaash Ponnusamy", "authors": "Alireza Roshan-Ghias, Clint Solomon Mathialagan, Pragaash Ponnusamy,\n  Lambert Mathias, Chenlei Guo", "title": "Personalized Query Rewriting in Conversational AI Agents", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) systems in conversational AI agents often\nexperience errors in the form of misrecognitions by automatic speech\nrecognition (ASR) or semantic gaps in natural language understanding (NLU).\nThese errors easily translate to user frustrations, particularly so in\nrecurrent events e.g. regularly toggling an appliance, calling a frequent\ncontact, etc. In this work, we propose a query rewriting approach by leveraging\nusers' historically successful interactions as a form of memory. We present a\nneural retrieval model and a pointer-generator network with hierarchical\nattention and show that they perform significantly better at the query\nrewriting task with the aforementioned user memories than without. We also\nhighlight how our approach with the proposed models leverages the structural\nand semantic diversity in ASR's output towards recovering users' intents.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:45:39 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Roshan-Ghias", "Alireza", ""], ["Mathialagan", "Clint Solomon", ""], ["Ponnusamy", "Pragaash", ""], ["Mathias", "Lambert", ""], ["Guo", "Chenlei", ""]]}, {"id": "2011.04767", "submitter": "Ali Emami Mr.", "authors": "Ali Emami, Adam Trischler, Kaheer Suleman and Jackie Chi Kit Cheung", "title": "An Analysis of Dataset Overlap on Winograd-Style Tasks", "comments": "11 pages with references, accepted at COLING 2020", "journal-ref": "Coling2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Winograd Schema Challenge (WSC) and variants inspired by it have become\nimportant benchmarks for common-sense reasoning (CSR). Model performance on the\nWSC has quickly progressed from chance-level to near-human using neural\nlanguage models trained on massive corpora. In this paper, we analyze the\neffects of varying degrees of overlap between these training corpora and the\ntest instances in WSC-style tasks. We find that a large number of test\ninstances overlap considerably with the corpora on which state-of-the-art\nmodels are (pre)trained, and that a significant drop in classification accuracy\noccurs when we evaluate models on instances with minimal overlap. Based on\nthese results, we develop the KnowRef-60K dataset, which consists of over 60k\npronoun disambiguation problems scraped from web data. KnowRef-60K is the\nlargest corpus to date for WSC-style common-sense reasoning and exhibits a\nsignificantly lower proportion of overlaps with current pretraining corpora.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:11:17 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Emami", "Ali", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "2011.04784", "submitter": "Hasan Tanvir", "authors": "Hasan Tanvir, Claudia Kittask, Sandra Eiche, Kairit Sirts", "title": "EstBERT: A Pretrained Language-Specific BERT for Estonian", "comments": "NoDaLiDa 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents EstBERT, a large pretrained transformer-based\nlanguage-specific BERT model for Estonian. Recent work has evaluated\nmultilingual BERT models on Estonian tasks and found them to outperform the\nbaselines. Still, based on existing studies on other languages, a\nlanguage-specific BERT model is expected to improve over the multilingual ones.\nWe first describe the EstBERT pretraining process and then present the results\nof the models based on finetuned EstBERT for multiple NLP tasks, including POS\nand morphological tagging, named entity recognition and text classification.\nThe evaluation results show that the models based on EstBERT outperform\nmultilingual BERT models on five tasks out of six, providing further evidence\ntowards a view that training language-specific BERT models are still useful,\neven when multilingual models are available.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:33:53 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 14:17:55 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 09:44:08 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tanvir", "Hasan", ""], ["Kittask", "Claudia", ""], ["Eiche", "Sandra", ""], ["Sirts", "Kairit", ""]]}, {"id": "2011.04823", "submitter": "Alex Tamkin", "authors": "Alex Tamkin, Dan Jurafsky, Noah Goodman", "title": "Language Through a Prism: A Spectral Approach for Multiscale Language\n  Representations", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language exhibits structure at different scales, ranging from subwords to\nwords, sentences, paragraphs, and documents. To what extent do deep models\ncapture information at these scales, and can we force them to better capture\nstructure across this hierarchy? We approach this question by focusing on\nindividual neurons, analyzing the behavior of their activations at different\ntimescales. We show that signal processing provides a natural framework for\nseparating structure across scales, enabling us to 1) disentangle\nscale-specific information in existing embeddings and 2) train models to learn\nmore about particular scales. Concretely, we apply spectral filters to the\nactivations of a neuron across an input, producing filtered embeddings that\nperform well on part of speech tagging (word-level), dialog speech acts\nclassification (utterance-level), or topic classification (document-level),\nwhile performing poorly on the other tasks. We also present a prism layer for\ntraining models, which uses spectral filters to constrain different neurons to\nmodel structure at different scales. Our proposed BERT + Prism model can better\npredict masked tokens using long-range context and produces multiscale\nrepresentations that perform better at utterance- and document-level tasks. Our\nmethods are general and readily applicable to other domains besides language,\nsuch as images, audio, and video.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 23:17:43 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tamkin", "Alex", ""], ["Jurafsky", "Dan", ""], ["Goodman", "Noah", ""]]}, {"id": "2011.04839", "submitter": "Erica Cooper", "authors": "Erica Cooper, Xin Wang, Yi Zhao, Yusuke Yasuda, Junichi Yamagishi", "title": "Pretraining Strategies, Waveform Model Choice, and Acoustic\n  Configurations for Multi-Speaker End-to-End Speech Synthesis", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore pretraining strategies including choice of base corpus with the\naim of choosing the best strategy for zero-shot multi-speaker end-to-end\nsynthesis. We also examine choice of neural vocoder for waveform synthesis, as\nwell as acoustic configurations used for mel spectrograms and final audio\noutput. We find that fine-tuning a multi-speaker model from found audiobook\ndata that has passed a simple quality threshold can improve naturalness and\nsimilarity to unseen target speakers of synthetic speech. Additionally, we find\nthat listeners can discern between a 16kHz and 24kHz sampling rate, and that\nWaveRNN produces output waveforms of a comparable quality to WaveNet, with a\nfaster inference time.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 00:19:04 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Cooper", "Erica", ""], ["Wang", "Xin", ""], ["Zhao", "Yi", ""], ["Yasuda", "Yusuke", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "2011.04843", "submitter": "Congbo Ma", "authors": "Congbo Ma, Wei Emma Zhang, Mingyu Guo, Hu Wang, Quan Z. Sheng", "title": "Multi-document Summarization via Deep Learning Techniques: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summarization (MDS) is an effective tool for information\naggregation which generates an informative and concise summary from a cluster\nof topic-related documents. Our survey structurally overviews the recent deep\nlearning based multi-document summarization models via a proposed taxonomy and\nit is the first of its kind. Particularly, we propose a novel mechanism to\nsummarize the design strategies of neural networks and conduct a comprehensive\nsummary of the state-of-the-art. We highlight the differences among various\nobjective functions which are rarely discussed in the existing literature.\nFinally, we propose several future directions pertaining to this new and\nexciting development of the field.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 00:35:46 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 08:01:05 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ma", "Congbo", ""], ["Zhang", "Wei Emma", ""], ["Guo", "Mingyu", ""], ["Wang", "Hu", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "2011.04845", "submitter": "Katsuhito Sudoh", "authors": "Katsuhito Sudoh, Takatomo Kano, Sashi Novitasari, Tomoya Yanagita,\n  Sakriani Sakti, Satoshi Nakamura", "title": "Simultaneous Speech-to-Speech Translation System with Neural Incremental\n  ASR, MT, and TTS", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a newly developed, simultaneous neural speech-to-speech\ntranslation system and its evaluation. The system consists of three\nfully-incremental neural processing modules for automatic speech recognition\n(ASR), machine translation (MT), and text-to-speech synthesis (TTS). We\ninvestigated its overall latency in the system's Ear-Voice Span and speaking\nlatency along with module-level performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 00:40:20 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 09:25:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Sudoh", "Katsuhito", ""], ["Kano", "Takatomo", ""], ["Novitasari", "Sashi", ""], ["Yanagita", "Tomoya", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2011.04864", "submitter": "Hanmeng Liu", "authors": "Hanmeng Liu, Leyang Cui, Jian Liu, Yue Zhang", "title": "Natural Language Inference in Context -- Investigating Contextual\n  Reasoning over Long Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language inference (NLI) is a fundamental NLP task, investigating the\nentailment relationship between two texts. Popular NLI datasets present the\ntask at sentence-level. While adequate for testing semantic representations,\nthey fall short for testing contextual reasoning over long texts, which is a\nnatural part of the human inference process. We introduce ConTRoL, a new\ndataset for ConTextual Reasoning over Long texts. Consisting of 8,325\nexpert-designed \"context-hypothesis\" pairs with gold labels, ConTRoL is a\npassage-level NLI dataset with a focus on complex contextual reasoning types\nsuch as logical reasoning. It is derived from competitive selection and\nrecruitment test (verbal reasoning test) for police recruitment, with expert\nlevel quality. Compared with previous NLI benchmarks, the materials in ConTRoL\nare much more challenging, involving a range of reasoning types. Empirical\nresults show that state-of-the-art language models perform by far worse than\neducated humans. Our dataset can also serve as a testing-set for downstream\ntasks like Checking Factual Correctness of Summaries.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 02:31:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Liu", "Hanmeng", ""], ["Cui", "Leyang", ""], ["Liu", "Jian", ""], ["Zhang", "Yue", ""]]}, {"id": "2011.04867", "submitter": "Gita Sukthankar", "authors": "Ayesha Enayet and Gita Sukthankar", "title": "A Transfer Learning Approach for Dialogue Act Classification of GitHub\n  Issue Comments", "comments": "Poster at 2020 International Conference on Social Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social coding platforms, such as GitHub, serve as laboratories for studying\ncollaborative problem solving in open source software development; a key\nfeature is their ability to support issue reporting which is used by teams to\ndiscuss tasks and ideas. Analyzing the dialogue between team members, as\nexpressed in issue comments, can yield important insights about the performance\nof virtual teams. This paper presents a transfer learning approach for\nperforming dialogue act classification on issue comments. Since no large\nlabeled corpus of GitHub issue comments exists, employing transfer learning\nenables us to leverage standard dialogue act datasets in combination with our\nown GitHub comment dataset. We compare the performance of several word and\nsentence level encoding models including Global Vectors for Word\nRepresentations (GloVe), Universal Sentence Encoder (USE), and Bidirectional\nEncoder Representations from Transformers (BERT). Being able to map the issue\ncomments to dialogue acts is a useful stepping stone towards understanding\ncognitive team processes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 02:56:18 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Enayet", "Ayesha", ""], ["Sukthankar", "Gita", ""]]}, {"id": "2011.04883", "submitter": "Rachel Gardner", "authors": "Rachel Gardner, Maya Varma, Clare Zhu, Ranjay Krishna", "title": "Determining Question-Answer Plausibility in Crowdsourced Datasets Using\n  Multi-Task Learning", "comments": "Published at the 6th Workshop on Noisy User-generated Text (W-NUT)\n  2020 at EMNLP (6 pages, 4 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Datasets extracted from social networks and online forums are often prone to\nthe pitfalls of natural language, namely the presence of unstructured and noisy\ndata. In this work, we seek to enable the collection of high-quality\nquestion-answer datasets from social media by proposing a novel task for\nautomated quality analysis and data cleaning: question-answer (QA)\nplausibility. Given a machine or user-generated question and a crowd-sourced\nresponse from a social media user, we determine if the question and response\nare valid; if so, we identify the answer within the free-form response. We\ndesign BERT-based models to perform the QA plausibility task, and we evaluate\nthe ability of our models to generate a clean, usable question-answer dataset.\nOur highest-performing approach consists of a single-task model which\ndetermines the plausibility of the question, followed by a multi-task model\nwhich evaluates the plausibility of the response as well as extracts answers\n(Question Plausibility AUROC=0.75, Response Plausibility AUROC=0.78, Answer\nExtraction F1=0.665).\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 04:11:44 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gardner", "Rachel", ""], ["Varma", "Maya", ""], ["Zhu", "Clare", ""], ["Krishna", "Ranjay", ""]]}, {"id": "2011.04896", "submitter": "Soroosh Tayebi Arasteh", "authors": "Soroosh Tayebi Arasteh", "title": "Generalized LSTM-based End-to-End Text-Independent Speaker Verification", "comments": "7 pages, 7 tables, 6 figures. Research Internship project at the\n  Pattern Recognition Lab at FAU Erlangen-Nuremberg, as a part of Master's\n  curriculum. Re-implementation of the paper arXiv:1710.10467 by Wan et al", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing amount of available data and more affordable hardware\nsolutions have opened a gate to the realm of Deep Learning (DL). Due to the\nrapid advancements and ever-growing popularity of DL, it has begun to invade\nalmost every field, where machine learning is applicable, by altering the\ntraditional state-of-the-art methods. While many researchers in the speaker\nrecognition area have also started to replace the former state-of-the-art\nmethods with DL techniques, some of the traditional i-vector-based methods are\nstill state-of-the-art in the context of text-independent speaker verification\n(TI-SV). In this paper, we discuss the most recent generalized end-to-end\n(GE2E) DL technique based on Long Short-term Memory (LSTM) units for TI-SV by\nGoogle and compare different scenarios and aspects including utterance\nduration, training time, and accuracy to prove that our method outperforms the\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:17:06 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 15:50:00 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 16:36:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Arasteh", "Soroosh Tayebi", ""]]}, {"id": "2011.04906", "submitter": "Shucong Zhang", "authors": "Shucong Zhang, Erfan Loweimi, Peter Bell, Steve Renals", "title": "On the Usefulness of Self-Attention for Automatic Speech Recognition\n  with Transformers", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.13895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention models such as Transformers, which can capture temporal\nrelationships without being limited by the distance between events, have given\ncompetitive speech recognition results. However, we note the range of the\nlearned context increases from the lower to upper self-attention layers, whilst\nacoustic events often happen within short time spans in a left-to-right order.\nThis leads to a question: for speech recognition, is a global view of the\nentire sequence useful for the upper self-attention encoder layers in\nTransformers? To investigate this, we train models with lower\nself-attention/upper feed-forward layers encoders on Wall Street Journal and\nSwitchboard. Compared to baseline Transformers, no performance drop but minor\ngains are observed. We further developed a novel metric of the diagonality of\nattention matrices and found the learned diagonality indeed increases from the\nlower to upper encoder self-attention layers. We conclude the global view is\nunnecessary in training upper encoder layers.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:01:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Shucong", ""], ["Loweimi", "Erfan", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "2011.04946", "submitter": "Yian Zhang", "authors": "Yian Zhang, Alex Warstadt, Haau-Sing Li, and Samuel R. Bowman", "title": "When Do You Need Billions of Words of Pretraining Data?", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLP is currently dominated by general-purpose pretrained language models like\nRoBERTa, which achieve strong performance on NLU tasks through pretraining on\nbillions of words. But what exact knowledge or skills do Transformer LMs learn\nfrom large-scale pretraining that they cannot learn from less data? We adopt\nfour probing methods---classifier probing, information-theoretic probing,\nunsupervised relative acceptability judgment, and fine-tuning on NLU\ntasks---and draw learning curves that track the growth of these different\nmeasures of linguistic ability with respect to pretraining data volume using\nthe MiniBERTas, a group of RoBERTa models pretrained on 1M, 10M, 100M and 1B\nwords. We find that LMs require only about 10M or 100M words to learn\nrepresentations that reliably encode most syntactic and semantic features we\ntest. A much larger quantity of data is needed in order to acquire enough\ncommonsense knowledge and other skills required to master typical downstream\nNLU tasks. The results suggest that, while the ability to encode linguistic\nfeatures is almost certainly necessary for language understanding, it is likely\nthat other forms of knowledge are the major drivers of recent improvements in\nlanguage understanding among large pretrained models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 07:16:18 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Yian", ""], ["Warstadt", "Alex", ""], ["Li", "Haau-Sing", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "2011.05007", "submitter": "Quynh Ngoc Thi Do", "authors": "Quynh Do, Judith Gaspers, Tobias Roding, Melanie Bradford", "title": "To What Degree Can Language Borders Be Blurred In BERT-based\n  Multilingual Spoken Language Understanding?", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question as to what degree a BERT-based multilingual\nSpoken Language Understanding (SLU) model can transfer knowledge across\nlanguages. Through experiments we will show that, although it works\nsubstantially well even on distant language groups, there is still a gap to the\nideal multilingual performance. In addition, we propose a novel BERT-based\nadversarial model architecture to learn language-shared and language-specific\nrepresentations for multilingual SLU. Our experimental results prove that the\nproposed model is capable of narrowing the gap to the ideal multilingual\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:59:24 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Do", "Quynh", ""], ["Gaspers", "Judith", ""], ["Roding", "Tobias", ""], ["Bradford", "Melanie", ""]]}, {"id": "2011.05037", "submitter": "Ife Adebara", "authors": "Ife Adebara, El Moatez Billah Nagoudi, Muhammad Abdul Mageed", "title": "Translating Similar Languages: Role of Mutual Intelligibility in\n  Multilingual Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate different approaches to translate between similar languages\nunder low resource conditions, as part of our contribution to the WMT 2020\nSimilar Languages Translation Shared Task. We submitted Transformer-based\nbilingual and multilingual systems for all language pairs, in the two\ndirections. We also leverage back-translation for one of the language pairs,\nacquiring an improvement of more than 3 BLEU points. We interpret our results\nin light of the degree of mutual intelligibility (based on Jaccard similarity)\nbetween each pair, finding a positive correlation between mutual\nintelligibility and model performance. Our Spanish-Catalan model has the best\nperformance of all the five language pairs. Except for the case of\nHindi-Marathi, our bilingual models achieve better performance than the\nmultilingual models on all pairs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 10:58:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Adebara", "Ife", ""], ["Nagoudi", "El Moatez Billah", ""], ["Mageed", "Muhammad Abdul", ""]]}, {"id": "2011.05103", "submitter": "Anietie Andy", "authors": "Anietie Andy and Sharath Guntuku", "title": "Does Social Support Expressed in Post Titles Elicit Comments in Online\n  Substance Use Recovery Forums?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Individuals recovering from substance use often seek social support\n(emotional and informational) on online recovery forums, where they can both\nwrite and comment on posts, expressing their struggles and successes. A common\nchallenge in these forums is that certain posts (some of which may be support\nseeking) receive no comments. In this work, we use data from two Reddit\nsubstance recovery forums:/r/Leaves and/r/OpiatesRecovery, to determine the\nrelationship between the social supports expressed in the titles of posts and\nthe number of comments they receive. We show that the types of social support\nexpressed in post titles that elicit comments vary from one substance use\nrecovery forum to the other.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 14:00:42 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Andy", "Anietie", ""], ["Guntuku", "Sharath", ""]]}, {"id": "2011.05152", "submitter": "Elisa Gugliotta", "authors": "Elisa Gugliotta (1,2,3), Marco Dinarelli (2), Olivier Kraif (3) ((1)\n  Sapienza University of Rome, (2) Universit\\'e Grenoble Alpes - Laboratoire\n  LIG (Getalp group), (3) Universit\\'e Grenoble Alpes- Laboratoire LIDILEM)", "title": "Multi-Task Sequence Prediction For Tunisian Arabizi Multi-Level\n  Annotation", "comments": "Paper accepted at the Fifth Arabic Natural Language Processing\n  Workshop (WANLP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose a multi-task sequence prediction system, based on\nrecurrent neural networks and used to annotate on multiple levels an Arabizi\nTunisian corpus. The annotation performed are text classification,\ntokenization, PoS tagging and encoding of Tunisian Arabizi into CODA* Arabic\northography. The system is learned to predict all the annotation levels in\ncascade, starting from Arabizi input. We evaluate the system on the TIGER\nGerman corpus, suitably converting data to have a multi-task problem, in order\nto show the effectiveness of our neural architecture. We show also how we used\nthe system in order to annotate a Tunisian Arabizi corpus, which has been\nafterwards manually corrected and used to further evaluate sequence models on\nTunisian data. Our system is developed for the Fairseq framework, which allows\nfor a fast and easy use for any other sequence prediction problem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:19:01 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 22:11:39 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 09:40:55 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Gugliotta", "Elisa", ""], ["Dinarelli", "Marco", ""], ["Kraif", "Olivier", ""]]}, {"id": "2011.05188", "submitter": "Jupinder Parmar", "authors": "Jupinder Parmar, William Koehler, Martin Bringmann, Katharina Sophia\n  Volz, Berk Kapicioglu", "title": "Biomedical Information Extraction for Disease Gene Prioritization", "comments": "4th Knowledge Representation and Reasoning Meets Machine Learning\n  Workshop (KR2ML), at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a biomedical information extraction (IE) pipeline that extracts\nbiological relationships from text and demonstrate that its components, such as\nnamed entity recognition (NER) and relation extraction (RE), outperform\nstate-of-the-art in BioNLP. We apply it to tens of millions of PubMed abstracts\nto extract protein-protein interactions (PPIs) and augment these extractions to\na biomedical knowledge graph that already contains PPIs extracted from STRING,\nthe leading structured PPI database. We show that, despite already containing\nPPIs from an established structured source, augmenting our own IE-based\nextractions to the graph allows us to predict novel disease-gene associations\nwith a 20% relative increase in hit@30, an important step towards developing\ndrug targets for uncured diseases.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:38:42 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 16:56:12 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Parmar", "Jupinder", ""], ["Koehler", "William", ""], ["Bringmann", "Martin", ""], ["Volz", "Katharina Sophia", ""], ["Kapicioglu", "Berk", ""]]}, {"id": "2011.05197", "submitter": "Gabriele Sarti", "authors": "Gabriele Sarti", "title": "UmBERTo-MTSA @ AcCompl-It: Improving Complexity and Acceptability\n  Prediction with Multi-task Learning on Self-Supervised Annotations", "comments": "5 pages, Best system award for the AcCompl-It shared task at the\n  EVALITA 2020 workshop", "journal-ref": "Proceedings of the Seventh Evaluation Campaign of Natural Language\n  Processing and Speech Tools for Italian. Final Workshop (EVALITA 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work describes a self-supervised data augmentation approach used to\nimprove learning models' performances when only a moderate amount of labeled\ndata is available. Multiple copies of the original model are initially trained\non the downstream task. Their predictions are then used to annotate a large set\nof unlabeled examples. Finally, multi-task training is performed on the\nparallel annotations of the resulting training set, and final scores are\nobtained by averaging annotator-specific head predictions. Neural language\nmodels are fine-tuned using this procedure in the context of the AcCompl-it\nshared task at EVALITA 2020, obtaining considerable improvements in prediction\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:50:37 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Sarti", "Gabriele", ""]]}, {"id": "2011.05233", "submitter": "Keith Harrigian", "authors": "Keith Harrigian, Carlos Aguirre, Mark Dredze", "title": "On the State of Social Media Data for Mental Health Research", "comments": "Originally submitted to ICWSM in January 2020. v1 updated November\n  2020. v2 updated April 2021, to appear at CLPsych 2021. Supplementary\n  material at https://github.com/kharrigian/mental-health-datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data-driven methods for mental health treatment and surveillance have become\na major focus in computational science research in the last decade. However,\nprogress in the domain, in terms of both medical understanding and system\nperformance, remains bounded by the availability of adequate data. Prior\nsystematic reviews have not necessarily made it possible to measure the degree\nto which data-related challenges have affected research progress. In this\npaper, we offer an analysis specifically on the state of social media data that\nexists for conducting mental health research. We do so by introducing an\nopen-source directory of mental health datasets, annotated using a standardized\nschema to facilitate meta-analysis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:45:52 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 15:07:51 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Harrigian", "Keith", ""], ["Aguirre", "Carlos", ""], ["Dredze", "Mark", ""]]}, {"id": "2011.05249", "submitter": "David Owen", "authors": "David Owen, Jose Camacho Collados, Luis Espinosa-Anke", "title": "Towards Preemptive Detection of Depression and Anxiety in Twitter", "comments": "Social Media Mining for Health Applications (#SMM4H) | COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression and anxiety are psychiatric disorders that are observed in many\nareas of everyday life. For example, these disorders manifest themselves\nsomewhat frequently in texts written by nondiagnosed users in social media.\nHowever, detecting users with these conditions is not a straightforward task as\nthey may not explicitly talk about their mental state, and if they do,\ncontextual cues such as immediacy must be taken into account. When available,\nlinguistic flags pointing to probable anxiety or depression could be used by\nmedical experts to write better guidelines and treatments. In this paper, we\ndevelop a dataset designed to foster research in depression and anxiety\ndetection in Twitter, framing the detection task as a binary tweet\nclassification problem. We then apply state-of-the-art classification models to\nthis dataset, providing a competitive set of baselines alongside qualitative\nerror analysis. Our results show that language models perform reasonably well,\nand better than more traditional baselines. Nonetheless, there is clear room\nfor improvement, particularly with unbalanced training sets and in cases where\nseemingly obvious linguistic cues (keywords) are used counter-intuitively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:17:23 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Owen", "David", ""], ["Collados", "Jose Camacho", ""], ["Espinosa-Anke", "Luis", ""]]}, {"id": "2011.05257", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Vishal Pallagani, Amit Sheth", "title": "Medical Knowledge-enriched Textual Entailment Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the cardinal tasks in achieving robust medical question answering\nsystems is textual entailment. The existing approaches make use of an ensemble\nof pre-trained language models or data augmentation, often to clock higher\nnumbers on the validation metrics. However, two major shortcomings impede\nhigher success in identifying entailment: (1) understanding the focus/intent of\nthe question and (2) ability to utilize the real-world background knowledge to\ncapture the context beyond the sentence. In this paper, we present a novel\nMedical Knowledge-Enriched Textual Entailment framework that allows the model\nto acquire a semantic and global representation of the input medical text with\nthe help of a relevant domain-specific knowledge graph. We evaluate our\nframework on the benchmark MEDIQA-RQE dataset and manifest that the use of\nknowledge enriched dual-encoding mechanism help in achieving an absolute\nimprovement of 8.27% over SOTA language models. We have made the source code\navailable here.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:25:27 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Yadav", "Shweta", ""], ["Pallagani", "Vishal", ""], ["Sheth", "Amit", ""]]}, {"id": "2011.05268", "submitter": "Hanlin Zhang", "authors": "Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun,\n  Chenyan Xiong, Jian Tang", "title": "Towards Interpretable Natural Language Understanding with Explanations\n  as Latent Variables", "comments": "NeurIPS 2020. The first three authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently generating natural language explanations has shown very promising\nresults in not only offering interpretable explanations but also providing\nadditional information and supervision for prediction. However, existing\napproaches usually require a large set of human annotated explanations for\ntraining while collecting a large set of explanations is not only time\nconsuming but also expensive. In this paper, we develop a general framework for\ninterpretable natural language understanding that requires only a small set of\nhuman annotated explanations for training. Our framework treats natural\nlanguage explanations as latent variables that model the underlying reasoning\nprocess of a neural model. We develop a variational EM framework for\noptimization where an explanation generation module and an\nexplanation-augmented prediction module are alternatively optimized and\nmutually enhance each other. Moreover, we further propose an explanation-based\nself-training method under this framework for semi-supervised learning. It\nalternates between assigning pseudo-labels to unlabeled data and generating new\nexplanations to iteratively improve each other. Experiments on two natural\nlanguage understanding tasks demonstrate that our framework can not only make\neffective predictions in both supervised and semi-supervised settings, but also\ngenerate good natural language explanation.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 02:05:56 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 12:24:08 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Hu", "Jinyi", ""], ["Zhang", "Hanlin", ""], ["Liang", "Xiaodan", ""], ["Sun", "Maosong", ""], ["Xiong", "Chenyan", ""], ["Tang", "Jian", ""]]}, {"id": "2011.05284", "submitter": "Allahsera Auguste Tapo", "authors": "Allahsera Auguste Tapo, Bakary Coulibaly, S\\'ebastien Diarra,\n  Christopher Homan, Julia Kreutzer, Sarah Luger, Arthur Nagashima, Marcos\n  Zampieri, Michael Leventhal", "title": "Neural Machine Translation for Extremely Low-Resource African Languages:\n  A Case Study on Bambara", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-resource languages present unique challenges to (neural) machine\ntranslation. We discuss the case of Bambara, a Mande language for which\ntraining data is scarce and requires significant amounts of pre-processing.\nMore than the linguistic situation of Bambara itself, the socio-cultural\ncontext within which Bambara speakers live poses challenges for automated\nprocessing of this language. In this paper, we present the first parallel data\nset for machine translation of Bambara into and from English and French and the\nfirst benchmark results on machine translation to and from Bambara. We discuss\nchallenges in working with low-resource languages and propose strategies to\ncope with data scarcity in low-resource machine translation (MT).\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:04:26 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tapo", "Allahsera Auguste", ""], ["Coulibaly", "Bakary", ""], ["Diarra", "S\u00e9bastien", ""], ["Homan", "Christopher", ""], ["Kreutzer", "Julia", ""], ["Luger", "Sarah", ""], ["Nagashima", "Arthur", ""], ["Zampieri", "Marcos", ""], ["Leventhal", "Michael", ""]]}, {"id": "2011.05295", "submitter": "Phong Le", "authors": "Phong Le and Willem Zuidema", "title": "DoLFIn: Distributions over Latent Features for Interpretability", "comments": null, "journal-ref": "COLING 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting the inner workings of neural models is a key step in ensuring\nthe robustness and trustworthiness of the models, but work on neural network\ninterpretability typically faces a trade-off: either the models are too\nconstrained to be very useful, or the solutions found by the models are too\ncomplex to interpret. We propose a novel strategy for achieving\ninterpretability that -- in our experiments -- avoids this trade-off. Our\napproach builds on the success of using probability as the central quantity,\nsuch as for instance within the attention mechanism. In our architecture,\nDoLFIn (Distributions over Latent Features for Interpretability), we do no\ndetermine beforehand what each feature represents, and features go altogether\ninto an unordered set. Each feature has an associated probability ranging from\n0 to 1, weighing its importance for further processing. We show that, unlike\nattention and saliency map approaches, this set-up makes it straight-forward to\ncompute the probability with which an input component supports the decision the\nneural model makes. To demonstrate the usefulness of the approach, we apply\nDoLFIn to text classification, and show that DoLFIn not only provides\ninterpretable solutions, but even slightly outperforms the classical CNN and\nBiLSTM text classifiers on the SST2 and AG-news datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:32:53 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Le", "Phong", ""], ["Zuidema", "Willem", ""]]}, {"id": "2011.05367", "submitter": "Emilio Ferrara", "authors": "Samar Haider, Luca Luceri, Ashok Deb, Adam Badawy, Nanyun Peng, Emilio\n  Ferrara", "title": "Detecting Social Media Manipulation in Low-Resource Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Social media have been deliberately used for malicious purposes, including\npolitical manipulation and disinformation. Most research focuses on\nhigh-resource languages. However, malicious actors share content across\ncountries and languages, including low-resource ones. Here, we investigate\nwhether and to what extent malicious actors can be detected in low-resource\nlanguage settings. We discovered that a high number of accounts posting in\nTagalog were suspended as part of Twitter's crackdown on interference\noperations after the 2016 US Presidential election. By combining text embedding\nand transfer learning, our framework can detect, with promising accuracy,\nmalicious users posting in Tagalog without any prior knowledge or training on\nmalicious content in that language. We first learn an embedding model for each\nlanguage, namely a high-resource language (English) and a low-resource one\n(Tagalog), independently. Then, we learn a mapping between the two latent\nspaces to transfer the detection model. We demonstrate that the proposed\napproach significantly outperforms state-of-the-art models, including BERT, and\nyields marked advantages in settings with very limited training data-the norm\nwhen dealing with detecting malicious activity in online platforms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:38:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Haider", "Samar", ""], ["Luceri", "Luca", ""], ["Deb", "Ashok", ""], ["Badawy", "Adam", ""], ["Peng", "Nanyun", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2011.05402", "submitter": "Shruti Rijhwani", "authors": "Shruti Rijhwani, Antonios Anastasopoulos, Graham Neubig", "title": "OCR Post Correction for Endangered Language Texts", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is little to no data available to build natural language processing\nmodels for most endangered languages. However, textual data in these languages\noften exists in formats that are not machine-readable, such as paper books and\nscanned images. In this work, we address the task of extracting text from these\nresources. We create a benchmark dataset of transcriptions for scanned books in\nthree critically endangered languages and present a systematic analysis of how\ngeneral-purpose OCR tools are not robust to the data-scarce setting of\nendangered languages. We develop an OCR post-correction method tailored to ease\ntraining in this data-scarce setting, reducing the recognition error rate by\n34% on average across the three languages.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:21:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rijhwani", "Shruti", ""], ["Anastasopoulos", "Antonios", ""], ["Neubig", "Graham", ""]]}, {"id": "2011.05431", "submitter": "Nikolaos Stylianou", "authors": "Nikolaos Stylianou, Ioannis Vlahavas", "title": "E.T.: Entity-Transformers. Coreference augmented Neural Language Model\n  for richer mention representations via Entity-Transformer blocks", "comments": "10 pages, 4 figures, 5 tables, accepted at CRAC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, the field of Neural Language Modelling has witnessed\nenormous changes, with the development of novel models through the use of\nTransformer architectures. However, even these models struggle to model long\nsequences due to memory constraints and increasing computational complexity.\nCoreference annotations over the training data can provide context far beyond\nthe modelling limitations of such language models. In this paper we present an\nextension over the Transformer-block architecture used in neural language\nmodels, specifically in GPT2, in order to incorporate entity annotations during\ntraining. Our model, GPT2E, extends the Transformer layers architecture of GPT2\nto Entity-Transformers, an architecture designed to handle coreference\ninformation when present. To that end, we achieve richer representations for\nentity mentions, with insignificant training cost. We show the comparative\nmodel performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL\n2012 and LAMBADA datasets as well as the key differences in the entity\nrepresentations and their effects in downstream tasks such as Named Entity\nRecognition. Furthermore, our approach can be adopted by the majority of\nTransformer-based language models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:28:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Stylianou", "Nikolaos", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "2011.05435", "submitter": "Yuxiang Wu", "authors": "Yuxiang Wu, Sebastian Riedel, Pasquale Minervini, Pontus Stenetorp", "title": "Don't Read Too Much into It: Adaptive Computation for Open-Domain\n  Question Answering", "comments": "11 pages, 9 figures, presented in EMNLP 2020 main conference and\n  SustaiNLP 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to Open-Domain Question Answering consist of a light-weight\nretriever that selects a set of candidate passages, and a computationally\nexpensive reader that examines the passages to identify the correct answer.\nPrevious works have shown that as the number of retrieved passages increases,\nso does the performance of the reader. However, they assume all retrieved\npassages are of equal importance and allocate the same amount of computation to\nthem, leading to a substantial increase in computational cost. To reduce this\ncost, we propose the use of adaptive computation to control the computational\nbudget allocated for the passages to be read. We first introduce a technique\noperating on individual passages in isolation which relies on anytime\nprediction and a per-layer estimation of an early exit probability. We then\nintroduce SkylineBuilder, an approach for dynamically deciding on which passage\nto allocate computation at each step, based on a resource allocation policy\ntrained via reinforcement learning. Our results on SQuAD-Open show that\nadaptive computation with global prioritisation improves over several strong\nstatic and adaptive methods, leading to a 4.3x reduction in computation while\nretaining 95% performance of the full model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:37:56 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wu", "Yuxiang", ""], ["Riedel", "Sebastian", ""], ["Minervini", "Pasquale", ""], ["Stenetorp", "Pontus", ""]]}, {"id": "2011.05443", "submitter": "Angela Fan", "authors": "Angela Fan, Claire Gardent", "title": "Multilingual AMR-to-Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating text from structured data is challenging because it requires\nbridging the gap between (i) structure and natural language (NL) and (ii)\nsemantically underspecified input and fully specified NL output. Multilingual\ngeneration brings in an additional challenge: that of generating into languages\nwith varied word order and morphological properties. In this work, we focus on\nAbstract Meaning Representations (AMRs) as structured input, where previous\nresearch has overwhelmingly focused on generating only into English. We\nleverage advances in cross-lingual embeddings, pretraining, and multilingual\nmodels to create multilingual AMR-to-text models that generate in twenty one\ndifferent languages. For eighteen languages, based on automatic metrics, our\nmultilingual models surpass baselines that generate into a single language. We\nanalyse the ability of our multilingual models to accurately capture morphology\nand word order using human evaluation, and find that native speakers judge our\ngenerations to be fluent.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:47:14 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Fan", "Angela", ""], ["Gardent", "Claire", ""]]}, {"id": "2011.05448", "submitter": "Angela Fan", "authors": "Angela Fan, Aleksandra Piktus, Fabio Petroni, Guillaume Wenzek,\n  Marzieh Saeidi, Andreas Vlachos, Antoine Bordes, Sebastian Riedel", "title": "Generating Fact Checking Briefs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact checking at scale is difficult -- while the number of active fact\nchecking websites is growing, it remains too small for the needs of the\ncontemporary media ecosystem. However, despite good intentions, contributions\nfrom volunteers are often error-prone, and thus in practice restricted to claim\ndetection. We investigate how to increase the accuracy and efficiency of fact\nchecking by providing information about the claim before performing the check,\nin the form of natural language briefs. We investigate passage-based briefs,\ncontaining a relevant passage from Wikipedia, entity-centric ones consisting of\nWikipedia pages of mentioned entities, and Question-Answering Briefs, with\nquestions decomposing the claim, and their answers. To produce QABriefs, we\ndevelop QABriefer, a model that generates a set of questions conditioned on the\nclaim, searches the web for evidence, and generates answers. To train its\ncomponents, we introduce QABriefDataset which we collected via crowdsourcing.\nWe show that fact checking with briefs -- in particular QABriefs -- increases\nthe accuracy of crowdworkers by 10% while slightly decreasing the time taken.\nFor volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and\nreduce the time required by around 20%.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 23:02:47 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Fan", "Angela", ""], ["Piktus", "Aleksandra", ""], ["Petroni", "Fabio", ""], ["Wenzek", "Guillaume", ""], ["Saeidi", "Marzieh", ""], ["Vlachos", "Andreas", ""], ["Bordes", "Antoine", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2011.05449", "submitter": "Ahmad Rashid", "authors": "Ahmad Rashid, Alan Do-Omri, Md. Akmal Haidar, Qun Liu and Mehdi\n  Rezagholizadeh", "title": "From Unsupervised Machine Translation To Adversarial Text Generation", "comments": "Accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a self-attention based bilingual adversarial text generator\n(B-GAN) which can learn to generate text from the encoder representation of an\nunsupervised neural machine translation system. B-GAN is able to generate a\ndistributed latent space representation which can be paired with an attention\nbased decoder to generate fluent sentences. When trained on an encoder shared\nbetween two languages and paired with the appropriate decoder, it can generate\nsentences in either language. B-GAN is trained using a combination of\nreconstruction loss for auto-encoder, a cross domain loss for translation and a\nGAN based adversarial loss for text generation. We demonstrate that B-GAN,\ntrained on monolingual corpora only using multiple losses, generates more\nfluent sentences compared to monolingual baselines while effectively using half\nthe number of parameters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 23:03:50 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rashid", "Ahmad", ""], ["Do-Omri", "Alan", ""], ["Haidar", "Md. Akmal", ""], ["Liu", "Qun", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "2011.05457", "submitter": "Zhenpeng Zhou", "authors": "Zhenpeng Zhou, Ahmad Beirami, Paul Crook, Pararth Shah, Rajen Subba,\n  and Alborz Geramifard", "title": "Resource Constrained Dialog Policy Learning via Differentiable Inductive\n  Logic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the needs of resource constrained dialog policy learning, we\nintroduce dialog policy via differentiable inductive logic (DILOG). We explore\nthe tasks of one-shot learning and zero-shot domain transfer with DILOG on\nSimDial and MultiWoZ. Using a single representative dialog from the restaurant\ndomain, we train DILOG on the SimDial dataset and obtain 99+% in-domain test\naccuracy. We also show that the trained DILOG zero-shot transfers to all other\ndomains with 99+% accuracy, proving the suitability of DILOG to slot-filling\ndialogs. We further extend our study to the MultiWoZ dataset achieving 90+%\ninform and success metrics. We also observe that these metrics are not\ncapturing some of the shortcomings of DILOG in terms of false positives,\nprompting us to measure an auxiliary Action F1 score. We show that DILOG is\n100x more data efficient than state-of-the-art neural approaches on MultiWoZ\nwhile achieving similar performance metrics. We conclude with a discussion on\nthe strengths and weaknesses of DILOG.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 23:28:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zhou", "Zhenpeng", ""], ["Beirami", "Ahmad", ""], ["Crook", "Paul", ""], ["Shah", "Pararth", ""], ["Subba", "Rajen", ""], ["Geramifard", "Alborz", ""]]}, {"id": "2011.05463", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "Artificial sound change: Language change and deep convolutional neural\n  networks in iterative learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework for modeling sound change that combines deep\nconvolutional neural networks and iterative learning. Acquisition and\ntransmission of speech across generations is modeled by training generations of\nGenerative Adversarial Networks (Goodfellow et al. arXiv:1406.2661,Donahue et\nal. arXiv:1705.07904) on unannotated raw speech data. The paper argues that\nseveral properties of sound change emerge from the proposed architecture. Four\ngenerations of Generative Adversarial Networks were trained on an allophonic\ndistribution in English where voiceless stops are aspirated word-initially\nbefore stressed vowels except if preceded by [s]. The first generation of\nnetworks is trained on the relevant sequences in human speech from the TIMIT\ndatabase. The subsequent generations are not trained on TIMIT, but on generated\noutputs from the previous generation and thus start learning from each other in\nan iterative learning task. The initial allophonic distribution is\nprogressively being lost with each generation, likely due to pressures from the\nglobal distribution of aspiration in the training data that resembles\nphonological pressures in natural language. The networks show signs of a\ngradual shift in phonetic targets characteristic of a gradual phonetic sound\nchange. At endpoints, the networks' outputs superficially resemble a\nphonological change -- rule loss -- driven by imperfect learning. The model\nfeatures signs of stability, one of the more challenging aspects of\ncomputational models of sound change. The results suggest that the proposed\nGenerative Adversarial models of phonetic and phonological acquisition have the\npotential to yield new insights into the long-standing question of how to model\nlanguage change.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 23:49:09 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2011.05504", "submitter": "Antoine Nzeyimana", "authors": "Antoine Nzeyimana", "title": "Morphological Disambiguation from Stemming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Morphological analysis and disambiguation is an important task and a crucial\npreprocessing step in natural language processing of morphologically rich\nlanguages. Kinyarwanda, a morphologically rich language, currently lacks tools\nfor automated morphological analysis. While linguistically curated finite state\ntools can be easily developed for morphological analysis, the morphological\nrichness of the language allows many ambiguous analyses to be produced,\nrequiring effective disambiguation. In this paper, we propose learning to\nmorphologically disambiguate Kinyarwanda verbal forms from a new stemming\ndataset collected through crowd-sourcing. Using feature engineering and a\nfeed-forward neural network based classifier, we achieve about 89%\nnon-contextualized disambiguation accuracy. Our experiments reveal that\ninflectional properties of stems and morpheme association rules are the most\ndiscriminative features for disambiguation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:44:09 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Nzeyimana", "Antoine", ""]]}, {"id": "2011.05533", "submitter": "Matthew Marge", "authors": "Matthew Marge, Carol Espy-Wilson, Nigel Ward", "title": "Spoken Language Interaction with Robots: Research Issues and\n  Recommendations, Report from the NSF Future Directions Workshop", "comments": "35 pages, 6 figures, Final report from the NSF Future Directions\n  Workshop on Speech for Robotics, held in October 2019, College Park, MD.\n  Workshop website: https://isr.umd.edu/2019-SFRW", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With robotics rapidly advancing, more effective human-robot interaction is\nincreasingly needed to realize the full potential of robots for society. While\nspoken language must be part of the solution, our ability to provide spoken\nlanguage interaction capabilities is still very limited. The National Science\nFoundation accordingly convened a workshop, bringing together speech, language,\nand robotics researchers to discuss what needs to be done. The result is this\nreport, in which we identify key scientific and engineering advances needed.\n  Our recommendations broadly relate to eight general themes. First, meeting\nhuman needs requires addressing new challenges in speech technology and user\nexperience design. Second, this requires better models of the social and\ninteractive aspects of language use. Third, for robustness, robots need\nhigher-bandwidth communication with users and better handling of uncertainty,\nincluding simultaneous consideration of multiple hypotheses and goals. Fourth,\nmore powerful adaptation methods are needed, to enable robots to communicate in\nnew environments, for new tasks, and with diverse user populations, without\nextensive re-engineering or the collection of massive training data. Fifth,\nsince robots are embodied, speech should function together with other\ncommunication modalities, such as gaze, gesture, posture, and motion. Sixth,\nsince robots operate in complex environments, speech components need access to\nrich yet efficient representations of what the robot knows about objects,\nlocations, noise sources, the user, and other humans. Seventh, since robots\noperate in real time, their speech and language processing components must\nalso. Eighth, in addition to more research, we need more work on infrastructure\nand resources, including shareable software modules and internal interfaces,\ninexpensive hardware, baseline systems, and diverse corpora.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 03:45:34 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Marge", "Matthew", ""], ["Espy-Wilson", "Carol", ""], ["Ward", "Nigel", ""]]}, {"id": "2011.05546", "submitter": "Yiren Liu", "authors": "Yiren Liu, Kuan-Ying Lee", "title": "E-commerce Query-based Generation based on User Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of merchandise on e-commerce platforms, users tend\nto refer to reviews of other shoppers to decide which product they should buy.\nHowever, with so many reviews of a product, users often have to spend lots of\ntime browsing through reviews talking about product attributes they do not care\nabout. We want to establish a system that can automatically summarize and\nanswer user's product specific questions.\n  In this study, we propose a novel seq2seq based text generation model to\ngenerate answers to user's question based on reviews posted by previous users.\nGiven a user question and/or target sentiment polarity, we extract aspects of\ninterest and generate an answer that summarizes previous relevant user reviews.\nSpecifically, our model performs attention between input reviews and target\naspects during encoding and is conditioned on both review rating and input\ncontext during decoding. We also incorporate a pre-trained auxiliary rating\nclassifier to improve model performance and accelerate convergence during\ntraining. Experiments using real-world e-commerce dataset show that our model\nachieves improvement in performance compared to previously introduced models.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 04:58:31 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Liu", "Yiren", ""], ["Lee", "Kuan-Ying", ""]]}, {"id": "2011.05551", "submitter": "Jagadeesh Malla Sree Mr", "authors": "Jagadeesh M S, Alphonse P J A", "title": "NIT COVID-19 at WNUT-2020 Task 2: Deep Learning Model RoBERTa for\n  Identify Informative COVID-19 English Tweets", "comments": "5 pages, one figures, conference", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.66", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the model submitted by the NIT_COVID-19 team for\nidentified informative COVID-19 English tweets at WNUT-2020 Task2. This shared\ntask addresses the problem of automatically identifying whether an English\ntweet related to informative (novel coronavirus) or not. These informative\ntweets provide information about recovered, confirmed, suspected, and death\ncases as well as the location or travel history of the cases. The proposed\napproach includes pre-processing techniques and pre-trained RoBERTa with\nsuitable hyperparameters for English coronavirus tweet classification. The\nperformance achieved by the proposed model for shared task WNUT 2020 Task2 is\n89.14% in the F1-score metric.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 05:20:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["S", "Jagadeesh M", ""], ["A", "Alphonse P J", ""]]}, {"id": "2011.05604", "submitter": "Zechuan Hu", "authors": "Zechuan Hu, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "An Investigation of Potential Function Designs for Neural CRF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural linear-chain CRF model is one of the most widely-used approach to\nsequence labeling. In this paper, we investigate a series of increasingly\nexpressive potential functions for neural CRF models, which not only integrate\nthe emission and transition functions, but also explicitly take the\nrepresentations of the contextual words as input. Our extensive experiments\nshow that the decomposed quadrilinear potential function based on the vector\nrepresentations of two neighboring labels and two neighboring words\nconsistently achieves the best performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:32:18 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hu", "Zechuan", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2011.05675", "submitter": "Isanka Rajapaksha", "authors": "Isanka Rajapaksha, Chanika Ruchini Mudalige, Dilini Karunarathna,\n  Nisansa de Silva, Gathika Ratnayaka, and Amal Shehan Perera", "title": "Rule-Based Approach for Party-Based Sentiment Analysis in Legal Opinion\n  Texts", "comments": "2 pages, 1 figure, The 20th International Conference on Advances in\n  ICT for Emerging Regions (ICTer2020)", "journal-ref": null, "doi": "10.1109/ICTer51097.2020.9325435", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A document which elaborates opinions and arguments related to the previous\ncourt cases is known as a legal opinion text. Lawyers and legal officials have\nto spend considerable effort and time to obtain the required information\nmanually from those documents when dealing with new legal cases. Hence, it\nprovides much convenience to those individuals if there is a way to automate\nthe process of extracting information from legal opinion texts. Party-based\nsentiment analysis will play a key role in the automation system by identifying\nopinion values with respect to each legal parties in legal texts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:07:14 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 19:33:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Rajapaksha", "Isanka", ""], ["Mudalige", "Chanika Ruchini", ""], ["Karunarathna", "Dilini", ""], ["de Silva", "Nisansa", ""], ["Ratnayaka", "Gathika", ""], ["Perera", "Amal Shehan", ""]]}, {"id": "2011.05688", "submitter": "Elisa Bassignana", "authors": "Elisa Bassignana, Malvina Nissim and Viviana Patti", "title": "Personal-ITY: A Novel YouTube-based Corpus for Personality Prediction in\n  Italian", "comments": "7 pages, accepted at Seventh Italian Conference on Computational\n  Linguistics (CLiC-it 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel corpus for personality prediction in Italian, containing a\nlarger number of authors and a different genre compared to previously available\nresources. The corpus is built exploiting Distant Supervision, assigning\nMyers-Briggs Type Indicator (MBTI) labels to YouTube comments, and can lend\nitself to a variety of experiments. We report on preliminary experiments on\nPersonal-ITY, which can serve as a baseline for future work, showing that some\ntypes are easier to predict than others, and discussing the perks of\ncross-dataset prediction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:51:07 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Bassignana", "Elisa", ""], ["Nissim", "Malvina", ""], ["Patti", "Viviana", ""]]}, {"id": "2011.05706", "submitter": "Alessandra Teresa Cignarella", "authors": "Alessandra Teresa Cignarella, Valerio Basile, Manuela Sanguinetti,\n  Cristina Bosco, Paolo Rosso and Farah Benamara", "title": "Multilingual Irony Detection with Dependency Syntax and Neural Models", "comments": "long paper accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an in-depth investigation of the effectiveness of\ndependency-based syntactic features on the irony detection task in a\nmultilingual perspective (English, Spanish, French and Italian). It focuses on\nthe contribution from syntactic knowledge, exploiting linguistic resources\nwhere syntax is annotated according to the Universal Dependencies scheme. Three\ndistinct experimental settings are provided. In the first, a variety of\nsyntactic dependency-based features combined with classical machine learning\nclassifiers are explored. In the second scenario, two well-known types of word\nembeddings are trained on parsed data and tested against gold standard\ndatasets. In the third setting, dependency-based syntactic features are\ncombined into the Multilingual BERT architecture. The results suggest that\nfine-grained dependency-based syntactic information is informative for the\ndetection of irony.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:22:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Cignarella", "Alessandra Teresa", ""], ["Basile", "Valerio", ""], ["Sanguinetti", "Manuela", ""], ["Bosco", "Cristina", ""], ["Rosso", "Paolo", ""], ["Benamara", "Farah", ""]]}, {"id": "2011.05707", "submitter": "Goeric Huybrechts", "authors": "Goeric Huybrechts, Thomas Merritt, Giulia Comini, Bartek Perz, Raahil\n  Shah, Jaime Lorenzo-Trueba", "title": "Low-resource expressive text-to-speech using data augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent neural text-to-speech (TTS) systems perform remarkably well,\nthey typically require a substantial amount of recordings from the target\nspeaker reading in the desired speaking style. In this work, we present a novel\n3-step methodology to circumvent the costly operation of recording large\namounts of target data in order to build expressive style voices with as little\nas 15 minutes of such recordings. First, we augment data via voice conversion\nby leveraging recordings in the desired speaking style from other speakers.\nNext, we use that synthetic data on top of the available recordings to train a\nTTS model. Finally, we fine-tune that model to further increase quality. Our\nevaluations show that the proposed changes bring significant improvements over\nnon-augmented models across many perceived aspects of synthesised speech. We\ndemonstrate the proposed approach on 2 styles (newscaster and conversational),\non various speakers, and on both single and multi-speaker models, illustrating\nthe robustness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:22:37 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 20:18:08 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Huybrechts", "Goeric", ""], ["Merritt", "Thomas", ""], ["Comini", "Giulia", ""], ["Perz", "Bartek", ""], ["Shah", "Raahil", ""], ["Lorenzo-Trueba", "Jaime", ""]]}, {"id": "2011.05723", "submitter": "Ming Gong", "authors": "Shining Liang, Linjun Shou, Jian Pei, Ming Gong, Wanli Zuo, Daxin\n  Jiang", "title": "CalibreNet: Calibration Networks for Multilingual Sequence Labeling", "comments": "Long paper in WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lack of training data in low-resource languages presents huge challenges to\nsequence labeling tasks such as named entity recognition (NER) and machine\nreading comprehension (MRC). One major obstacle is the errors on the boundary\nof predicted answers. To tackle this problem, we propose CalibreNet, which\npredicts answers in two steps. In the first step, any existing sequence\nlabeling method can be adopted as a base model to generate an initial answer.\nIn the second step, CalibreNet refines the boundary of the initial answer. To\ntackle the challenge of lack of training data in low-resource languages, we\ndedicatedly develop a novel unsupervised phrase boundary recovery pre-training\ntask to enhance the multilingual boundary detection capability of CalibreNet.\nExperiments on two cross-lingual benchmark datasets show that the proposed\napproach achieves SOTA results on zero-shot cross-lingual NER and MRC tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:59:49 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Liang", "Shining", ""], ["Shou", "Linjun", ""], ["Pei", "Jian", ""], ["Gong", "Ming", ""], ["Zuo", "Wanli", ""], ["Jiang", "Daxin", ""]]}, {"id": "2011.05744", "submitter": "Yitao Cai", "authors": "Yitao Cai, Xiaojun Wan", "title": "IGSQL: Database Schema Interaction Graph Based Neural Model for\n  Context-Dependent Text-to-SQL Generation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Context-dependent text-to-SQL task has drawn much attention in recent years.\nPrevious models on context-dependent text-to-SQL task only concentrate on\nutilizing historical user inputs. In this work, in addition to using encoders\nto capture historical information of user inputs, we propose a database schema\ninteraction graph encoder to utilize historicalal information of database\nschema items. In decoding phase, we introduce a gate mechanism to weigh the\nimportance of different vocabularies and then make the prediction of SQL\ntokens. We evaluate our model on the benchmark SParC and CoSQL datasets, which\nare two large complex context-dependent cross-domain text-to-SQL datasets. Our\nmodel outperforms previous state-of-the-art model by a large margin and\nachieves new state-of-the-art results on the two datasets. The comparison and\nablation results demonstrate the efficacy of our model and the usefulness of\nthe database schema interaction graph encoder.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 12:56:21 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Cai", "Yitao", ""], ["Wan", "Xiaojun", ""]]}, {"id": "2011.05773", "submitter": "Nicholas Micallef", "authors": "Nicholas Micallef, Bing He, Srijan Kumar, Mustaque Ahamad and Nasir\n  Memon", "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "comments": "PrePrint - IEEE BigData 2020. The code and data can be found in\n  http://claws.cc.gatech.edu/covid_counter_misinformation.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 13:48:44 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 04:20:37 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Micallef", "Nicholas", ""], ["He", "Bing", ""], ["Kumar", "Srijan", ""], ["Ahamad", "Mustaque", ""], ["Memon", "Nasir", ""]]}, {"id": "2011.05788", "submitter": "Artem Kramov", "authors": "S.D. Pogorilyy, A.A. Kramov", "title": "Assessment of text coherence based on the cohesion estimation", "comments": "2 pages, conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a graph-based coherence estimation method based on the\ncohesion estimation is suggested. Our method uses a graph-based approach to\nprovide a user with an understanding of the evaluation process. Moreover, it\ncan be applied to different languages, therefore, the effectiveness of this\nmethod is examined on the set of English, Chinese, and Arabic texts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:05:32 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Pogorilyy", "S. D.", ""], ["Kramov", "A. A.", ""]]}, {"id": "2011.05864", "submitter": "Bohan Li", "authors": "Bohan Li and Hao Zhou and Junxian He and Mingxuan Wang and Yiming Yang\n  and Lei Li", "title": "On the Sentence Embeddings from Pre-trained Language Models", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained contextual representations like BERT have achieved great success\nin natural language processing. However, the sentence embeddings from the\npre-trained language models without fine-tuning have been found to poorly\ncapture semantic meaning of sentences. In this paper, we argue that the\nsemantic information in the BERT embeddings is not fully exploited. We first\nreveal the theoretical connection between the masked language model\npre-training objective and the semantic similarity task theoretically, and then\nanalyze the BERT sentence embeddings empirically. We find that BERT always\ninduces a non-smooth anisotropic semantic space of sentences, which harms its\nperformance of semantic similarity. To address this issue, we propose to\ntransform the anisotropic sentence embedding distribution to a smooth and\nisotropic Gaussian distribution through normalizing flows that are learned with\nan unsupervised objective. Experimental results show that our proposed\nBERT-flow method obtains significant performance gains over the\nstate-of-the-art sentence embeddings on a variety of semantic textual\nsimilarity tasks. The code is available at\nhttps://github.com/bohanli/BERT-flow.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:14:57 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Li", "Bohan", ""], ["Zhou", "Hao", ""], ["He", "Junxian", ""], ["Wang", "Mingxuan", ""], ["Yang", "Yiming", ""], ["Li", "Lei", ""]]}, {"id": "2011.05910", "submitter": "Chung Hoon Hong", "authors": "Chung Hoon Hong, Yuan Liang, Sagnik Sinha Roy, Arushi Jain, Vihang\n  Agarwal, Ryan Draves, Zhizhuo Zhou, William Chen, Yujian Liu, Martha Miracky,\n  Lily Ge, Nikola Banovic, David Jurgens", "title": "Audrey: A Personalized Open-Domain Conversational Bot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational Intelligence requires that a person engage on informational,\npersonal and relational levels. Advances in Natural Language Understanding have\nhelped recent chatbots succeed at dialog on the informational level. However,\ncurrent techniques still lag for conversing with humans on a personal level and\nfully relating to them. The University of Michigan's submission to the Alexa\nPrize Grand Challenge 3, Audrey, is an open-domain conversational chat-bot that\naims to engage customers on these levels through interest driven conversations\nguided by customers' personalities and emotions. Audrey is built from\nsocially-aware models such as Emotion Detection and a Personal Understanding\nModule to grasp a deeper understanding of users' interests and desires. Our\narchitecture interacts with customers using a hybrid approach balanced between\nknowledge-driven response generators and context-driven neural response\ngenerators to cater to all three levels of conversations. During the\nsemi-finals period, we achieved an average cumulative rating of 3.25 on a 1-5\nLikert scale.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:02:01 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Hong", "Chung Hoon", ""], ["Liang", "Yuan", ""], ["Roy", "Sagnik Sinha", ""], ["Jain", "Arushi", ""], ["Agarwal", "Vihang", ""], ["Draves", "Ryan", ""], ["Zhou", "Zhizhuo", ""], ["Chen", "William", ""], ["Liu", "Yujian", ""], ["Miracky", "Martha", ""], ["Ge", "Lily", ""], ["Banovic", "Nikola", ""], ["Jurgens", "David", ""]]}, {"id": "2011.05911", "submitter": "Lucy Havens", "authors": "Lucy Havens, Melissa Terras, Benjamin Bach, Beatrice Alex", "title": "Situated Data, Situated Systems: A Methodology to Engage with Power\n  Relations in Natural Language Processing Research", "comments": "Accepted to the 2nd Workshop on Gender Bias in Natural Language\n  Processing at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a bias-aware methodology to engage with power relations in natural\nlanguage processing (NLP) research. NLP research rarely engages with bias in\nsocial contexts, limiting its ability to mitigate bias. While researchers have\nrecommended actions, technical methods, and documentation practices, no\nmethodology exists to integrate critical reflections on bias with technical NLP\nmethods. In this paper, after an extensive and interdisciplinary literature\nreview, we contribute a bias-aware methodology for NLP research. We also\ncontribute a definition of biased text, a discussion of the implications of\nbiased NLP systems, and a case study demonstrating how we are executing the\nbias-aware methodology in research on archival metadata descriptions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:04:55 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Havens", "Lucy", ""], ["Terras", "Melissa", ""], ["Bach", "Benjamin", ""], ["Alex", "Beatrice", ""]]}, {"id": "2011.05932", "submitter": "Luis Espinosa-Anke", "authors": "Jordi Porta-Zamorano and Luis Espinosa-Anke", "title": "Overview of CAPITEL Shared Tasks at IberLEF 2020: Named Entity\n  Recognition and Universal Dependencies Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the results of the CAPITEL-EVAL shared task, held in the context\nof the IberLEF 2020 competition series. CAPITEL-EVAL consisted on two subtasks:\n(1) Named Entity Recognition and Classification and (2) Universal Dependency\nparsing. For both, the source data was a newly annotated corpus, CAPITEL, a\ncollection of Spanish articles in the newswire domain. A total of seven teams\nparticipated in CAPITEL-EVAL, with a total of 13 runs submitted across all\nsubtasks. Data, results and further information about this task can be found at\nsites.google.com/view/capitel2020.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:44:57 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Porta-Zamorano", "Jordi", ""], ["Espinosa-Anke", "Luis", ""]]}, {"id": "2011.05958", "submitter": "Catalin Zorila", "authors": "Jisi Zhang, Catalin Zorila, Rama Doddipatla, Jon Barker", "title": "On End-to-end Multi-channel Time Domain Speech Separation in Reverberant\n  Environments", "comments": "Presented at IEEE ICASSP 2020", "journal-ref": "Proc. ICASSP (2020) 6389-6393", "doi": "10.1109/ICASSP40776.2020.9053833", "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new method for multi-channel time domain speech\nseparation in reverberant environments. A fully-convolutional neural network\nstructure has been used to directly separate speech from multiple microphone\nrecordings, with no need of conventional spatial feature extraction. To reduce\nthe influence of reverberation on spatial feature extraction, a dereverberation\npre-processing method has been applied to further improve the separation\nperformance. A spatialized version of wsj0-2mix dataset has been simulated to\nevaluate the proposed system. Both source separation and speech recognition\nperformance of the separated signals have been evaluated objectively.\nExperiments show that the proposed fully-convolutional network improves the\nsource separation metric and the word error rate (WER) by more than 13% and 50%\nrelative, respectively, over a reference system with conventional features.\nApplying dereverberation as pre-processing to the proposed system can further\nreduce the WER by 29% relative using an acoustic model trained on clean and\nreverberated data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:25:07 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zhang", "Jisi", ""], ["Zorila", "Catalin", ""], ["Doddipatla", "Rama", ""], ["Barker", "Jon", ""]]}, {"id": "2011.05978", "submitter": "Samuel L\\\"aubli", "authors": "Samuel L\\\"aubli, Patrick Simianer, Joern Wuebker, Geza Kovacs, Rico\n  Sennrich, Spence Green", "title": "The Impact of Text Presentation on Translator Performance", "comments": "Accepted for publication in Target", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Widely used computer-aided translation (CAT) tools divide documents into\nsegments such as sentences and arrange them in a side-by-side, spreadsheet-like\nview. We present the first controlled evaluation of these design choices on\ntranslator performance, measuring speed and accuracy in three experimental text\nprocessing tasks. We find significant evidence that sentence-by-sentence\npresentation enables faster text reproduction and within-sentence error\nidentification compared to unsegmented text, and that a top-and-bottom\narrangement of source and target sentences enables faster text reproduction\ncompared to a side-by-side arrangement. For revision, on the other hand, our\nresults suggest that presenting unsegmented text results in the highest\naccuracy and time efficiency. Our findings have direct implications for best\npractices in designing CAT tools.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:50:18 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["L\u00e4ubli", "Samuel", ""], ["Simianer", "Patrick", ""], ["Wuebker", "Joern", ""], ["Kovacs", "Geza", ""], ["Sennrich", "Rico", ""], ["Green", "Spence", ""]]}, {"id": "2011.06056", "submitter": "Karel Bene\\v{s}", "authors": "Karel Bene\\v{s} and Luk\\'a\\v{s} Burget", "title": "Text Augmentation for Language Models in High Error Recognition Scenario", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We examine the effect of data augmentation for training of language models\nfor speech recognition. We compare augmentation based on global error\nstatistics with one based on per-word unigram statistics of ASR errors and\nobserve that it is better to only pay attention the global substitution,\ndeletion and insertion rates. This simple scheme also performs consistently\nbetter than label smoothing and its sampled variants. Additionally, we\ninvestigate into the behavior of perplexity estimated on augmented data, but\nconclude that it gives no better prediction of the final error rate. Our best\naugmentation scheme increases the absolute WER improvement from second-pass\nrescoring from 1.1 % to 1.9 % absolute on the CHiMe-6 challenge.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:21:21 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Bene\u0161", "Karel", ""], ["Burget", "Luk\u00e1\u0161", ""]]}, {"id": "2011.06057", "submitter": "Charlie Welch", "authors": "Charles Welch, Jonathan K. Kummerfeld, Ver\\'onica P\\'erez-Rosas, Rada\n  Mihalcea", "title": "Exploring the Value of Personalized Word Embeddings", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce personalized word embeddings, and examine their\nvalue for language modeling. We compare the performance of our proposed\nprediction model when using personalized versus generic word representations,\nand study how these representations can be leveraged for improved performance.\nWe provide insight into what types of words can be more accurately predicted\nwhen building personalized models. Our results show that a subset of words\nbelonging to specific psycholinguistic categories tend to vary more in their\nrepresentations across users and that combining generic and personalized word\nembeddings yields the best performance, with a 4.7% relative reduction in\nperplexity. Additionally, we show that a language model using personalized word\nembeddings can be effectively used for authorship attribution.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:23:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Welch", "Charles", ""], ["Kummerfeld", "Jonathan K.", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2011.06128", "submitter": "Mohaddeseh Bastan", "authors": "Mohaddeseh Bastan, Mahnaz Koupaee, Youngseo Son, Richard Sicoli, and\n  Niranjan Balasubramanian", "title": "Author's Sentiment Prediction", "comments": "12 pages, 5 figures, Accepted in COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce PerSenT, a dataset of crowd-sourced annotations of the sentiment\nexpressed by the authors towards the main entities in news articles. The\ndataset also includes paragraph-level sentiment annotations to provide more\nfine-grained supervision for the task. Our benchmarks of multiple strong\nbaselines show that this is a difficult classification task. The results also\nsuggest that simply fine-tuning document-level representations from BERT isn't\nadequate for this task. Making paragraph-level decisions and aggregating them\nover the entire document is also ineffective. We present empirical and\nqualitative analyses that illustrate the specific challenges posed by this\ndataset. We release this dataset with 5.3k documents and 38k paragraphs\ncovering 3.2k unique entities as a challenge in entity sentiment analysis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:03:26 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Bastan", "Mohaddeseh", ""], ["Koupaee", "Mahnaz", ""], ["Son", "Youngseo", ""], ["Sicoli", "Richard", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "2011.06132", "submitter": "Xiang Kong", "authors": "Xiang Kong, Zhisong Zhang, Eduard Hovy", "title": "Incorporating a Local Translation Mechanism into Non-autoregressive\n  Translation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a novel local autoregressive translation (LAT)\nmechanism into non-autoregressive translation (NAT) models so as to capture\nlocal dependencies among tar-get outputs. Specifically, for each target\ndecoding position, instead of only one token, we predict a short sequence of\ntokens in an autoregressive way. We further design an efficient merging\nalgorithm to align and merge the out-put pieces into one final output sequence.\nWe integrate LAT into the conditional masked language model (CMLM;\nGhazvininejad et al.,2019) and similarly adopt iterative decoding. Empirical\nresults on five translation tasks show that compared with CMLM, our method\nachieves comparable or better performance with fewer decoding iterations,\nbringing a 2.5xspeedup. Further analysis indicates that our method reduces\nrepeated translations and performs better at longer sentences.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:32:51 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kong", "Xiang", ""], ["Zhang", "Zhisong", ""], ["Hovy", "Eduard", ""]]}, {"id": "2011.06149", "submitter": "Shweta Yadav", "authors": "Shweta Yadav, Jainish Chauhan, Joy Prakash Sain, Krishnaprasad\n  Thirunarayan, Amit Sheth, Jeremiah Schumm", "title": "Identifying Depressive Symptoms from Tweets: Figurative Language Enabled\n  Multitask Learning Framework", "comments": "Accepted for publication in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing studies on using social media for deriving mental health status of\nusers focus on the depression detection task. However, for case management and\nreferral to psychiatrists, healthcare workers require practical and scalable\ndepressive disorder screening and triage system. This study aims to design and\nevaluate a decision support system (DSS) to reliably determine the depressive\ntriage level by capturing fine-grained depressive symptoms expressed in user\ntweets through the emulation of Patient Health Questionnaire-9 (PHQ-9) that is\nroutinely used in clinical practice. The reliable detection of depressive\nsymptoms from tweets is challenging because the 280-character limit on tweets\nincentivizes the use of creative artifacts in the utterances and figurative\nusage contributes to effective expression. We propose a novel BERT based robust\nmulti-task learning framework to accurately identify the depressive symptoms\nusing the auxiliary task of figurative usage detection. Specifically, our\nproposed novel task sharing mechanism, co-task aware attention, enables\nautomatic selection of optimal information across the BERT layers and tasks by\nsoft-sharing of parameters. Our results show that modeling figurative usage can\ndemonstrably improve the model's robustness and reliability for distinguishing\nthe depression symptoms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 01:17:49 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yadav", "Shweta", ""], ["Chauhan", "Jainish", ""], ["Sain", "Joy Prakash", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Sheth", "Amit", ""], ["Schumm", "Jeremiah", ""]]}, {"id": "2011.06153", "submitter": "Aparna Balagopalan", "authors": "Aparna Balagopalan, Jekaterina Novikova", "title": "Augmenting BERT Carefully with Underrepresented Linguistic Features", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuned Bidirectional Encoder Representations from Transformers\n(BERT)-based sequence classification models have proven to be effective for\ndetecting Alzheimer's Disease (AD) from transcripts of human speech. However,\nprevious research shows it is possible to improve BERT's performance on various\ntasks by augmenting the model with additional information. In this work, we use\nprobing tasks as introspection techniques to identify linguistic information\nnot well-represented in various layers of BERT, but important for the AD\ndetection task. We supplement these linguistic features in which\nrepresentations from BERT are found to be insufficient with hand-crafted\nfeatures externally, and show that jointly fine-tuning BERT in combination with\nthese features improves the performance of AD classification by upto 5\\% over\nfine-tuned BERT alone.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 01:32:41 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Novikova", "Jekaterina", ""]]}, {"id": "2011.06174", "submitter": "Canlin Zhang", "authors": "Canlin Zhang, Yannis Katsis, Yoshiki Vazquez-Baeza, Andrew Bartko,\n  Ho-Cheol Kim, Chun-Nan Hsu", "title": "Theoretical Knowledge Graph Reasoning via Ending Anchored Rules", "comments": "We made a mistake when ranking the test triples: Due to the\n  rule-based nature, many triples r(s,t) have zero occurring probabilities. But\n  since we always append the true test triple at the beginning, the true test\n  triple is always ranked at the top. Due to this fact, our performance is\n  severely over-estimated. As a result, we withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering precise and specific rules from knowledge graphs is regarded as\nan essential challenge, which can improve the performances of many downstream\ntasks and even provide new ways to approach some Natural Language Processing\nresearch topics. In this paper, we provide a fundamental theory for knowledge\ngraph reasoning based on the ending anchored rules. Our theory provides precise\nreasons explaining why or why not a triple is correct. Then, we implement our\ntheory by what we call the EARDict model. Results show that our EARDict model\nsignificantly outperforms all the benchmark models on three large datasets of\nknowledge graph completion. Especially, our model achieves a Hits@10 score of\n96.6 percent on WN18RR.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 03:00:20 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 00:59:56 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 02:21:35 GMT"}, {"version": "v4", "created": "Wed, 23 Dec 2020 01:26:26 GMT"}, {"version": "v5", "created": "Wed, 30 Dec 2020 23:40:00 GMT"}, {"version": "v6", "created": "Mon, 18 Jan 2021 18:47:05 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Zhang", "Canlin", ""], ["Katsis", "Yannis", ""], ["Vazquez-Baeza", "Yoshiki", ""], ["Bartko", "Andrew", ""], ["Kim", "Ho-Cheol", ""], ["Hsu", "Chun-Nan", ""]]}, {"id": "2011.06195", "submitter": "Cheng-I Lai", "authors": "Cheng-I Lai, Jin Cao, Sravan Bodapati, Shang-Wen Li", "title": "Towards Semi-Supervised Semantics Understanding from Speech", "comments": "arXiv admin note: text overlap with arXiv:2010.13826", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much recent work on Spoken Language Understanding (SLU) falls short in at\nleast one of three ways: models were trained on oracle text input and neglected\nthe Automatics Speech Recognition (ASR) outputs, models were trained to predict\nonly intents without the slot values, or models were trained on a large amount\nof in-house data. We proposed a clean and general framework to learn semantics\ndirectly from speech with semi-supervision from transcribed speech to address\nthese. Our framework is built upon pretrained end-to-end (E2E) ASR and\nself-supervised language models, such as BERT, and fine-tuned on a limited\namount of target SLU corpus. In parallel, we identified two inadequate settings\nunder which SLU models have been tested: noise-robustness and E2E semantics\nevaluation. We tested the proposed framework under realistic environmental\nnoises and with a new metric, the slots edit F1 score, on two public SLU\ncorpora. Experiments show that our SLU framework with speech as input can\nperform on par with those with oracle text as input in semantics understanding,\nwhile environmental noises are present, and a limited amount of labeled\nsemantics data is available.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:48:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Lai", "Cheng-I", ""], ["Cao", "Jin", ""], ["Bodapati", "Sravan", ""], ["Li", "Shang-Wen", ""]]}, {"id": "2011.06198", "submitter": "Eric Le Ferrand", "authors": "\\'Eric Le Ferrand, Steven Bird, Laurent Besacier", "title": "Enabling Interactive Transcription in an Indigenous Community", "comments": "inproceedings Coling 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel transcription workflow which combines spoken term\ndetection and human-in-the-loop, together with a pilot experiment. This work is\ngrounded in an almost zero-resource scenario where only a few terms have so far\nbeen identified, involving two endangered languages. We show that in the early\nstages of transcription, when the available data is insufficient to train a\nrobust ASR system, it is possible to take advantage of the transcription of a\nsmall number of isolated words in order to bootstrap the transcription of a\nspeech collection.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:41:35 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ferrand", "\u00c9ric Le", ""], ["Bird", "Steven", ""], ["Besacier", "Laurent", ""]]}, {"id": "2011.06226", "submitter": "Sanket Shah", "authors": "Sanket Shah, Satarupa Guha, Simran Khanuja, Sunayana Sitaram", "title": "Cross-lingual and Multilingual Spoken Term Detection for Low-Resource\n  Indian Languages", "comments": "5 pages, 2 figures, 6 tables, 17 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Term Detection (STD) is the task of searching for words or phrases\nwithin audio, given either text or spoken input as a query. In this work, we\nuse state-of-the-art Hindi, Tamil and Telugu ASR systems cross-lingually for\nlexical Spoken Term Detection in ten low-resource Indian languages. Since no\npublicly available dataset exists for Spoken Term Detection in these languages,\nwe create a new dataset using a publicly available TTS dataset. We report a\nstandard metric for STD, Mean Term Weighted Value (MTWV) and show that ASR\nsystems built in languages that are phonetically similar to the target\nlanguages have higher accuracy, however, it is also possible to get high MTWV\nscores for dissimilar languages by using a relaxed phone matching algorithm. We\npropose a technique to bootstrap the Grapheme-to-Phoneme (g2p) mapping between\nall the languages under consideration using publicly available resources. Gains\nare obtained when we combine the output of multiple ASR systems and when we use\nlanguage-specific Language Models. We show that it is possible to perform STD\ncross-lingually in a zero-shot manner without the need for any\nlanguage-specific speech data. We plan to make the STD dataset available for\nother researchers interested in cross-lingual STD.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 06:41:27 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Shah", "Sanket", ""], ["Guha", "Satarupa", ""], ["Khanuja", "Simran", ""], ["Sitaram", "Sunayana", ""]]}, {"id": "2011.06306", "submitter": "Youmna Farag", "authors": "Youmna Farag, Josef Valvoda, Helen Yannakoudakis and Ted Briscoe", "title": "Analyzing Neural Discourse Coherence Models", "comments": null, "journal-ref": "CODI workshop in EMNLP2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we systematically investigate how well current models of\ncoherence can capture aspects of text implicated in discourse organisation. We\ndevise two datasets of various linguistic alterations that undermine coherence\nand test model sensitivity to changes in syntax and semantics. We furthermore\nprobe discourse embedding space and examine the knowledge that is encoded in\nrepresentations of coherence. We hope this study shall provide further insight\ninto how to frame the task and improve models of coherence assessment further.\nFinally, we make our datasets publicly available as a resource for researchers\nto use to test discourse coherence models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:44:41 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Farag", "Youmna", ""], ["Valvoda", "Josef", ""], ["Yannakoudakis", "Helen", ""], ["Briscoe", "Ted", ""]]}, {"id": "2011.06315", "submitter": "Veysel Kocaman Vk", "authors": "Veysel Kocaman and David Talby", "title": "Biomedical Named Entity Recognition at Scale", "comments": "Accepted for presentation and inclusion in CADL 2020 (International\n  Workshop on Computational Aspects of Deep Learning) , organized in\n  conjunction with ICPR 2020, the 25th International Conference on Pattern\n  Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is a widely applicable natural language\nprocessing task and building block of question answering, topic modeling,\ninformation retrieval, etc. In the medical domain, NER plays a crucial role by\nextracting meaningful chunks from clinical notes and reports, which are then\nfed to downstream tasks like assertion status detection, entity resolution,\nrelation extraction, and de-identification. Reimplementing a Bi-LSTM-CNN-Char\ndeep learning architecture on top of Apache Spark, we present a single\ntrainable NER model that obtains new state-of-the-art results on seven public\nbiomedical benchmarks without using heavy contextual embeddings like BERT. This\nincludes improving BC4CHEMD to 93.72% (4.1% gain), Species800 to 80.91% (4.6%\ngain), and JNLPBA to 81.29% (5.2% gain). In addition, this model is freely\navailable within a production-grade code base as part of the open-source Spark\nNLP library; can scale up for training and inference in any Spark cluster; has\nGPU support and libraries for popular programming languages such as Python, R,\nScala and Java; and can be extended to support other human languages with no\ncode changes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:10:17 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kocaman", "Veysel", ""], ["Talby", "David", ""]]}, {"id": "2011.06326", "submitter": "Chanika Ruchini Mudalige", "authors": "Chanika Ruchini Mudalige, Dilini Karunarathna, Isanka Rajapaksha,\n  Nisansa de Silva, Gathika Ratnayaka, Amal Shehan Perera, Ramesh Pathirana", "title": "SigmaLaw-ABSA: Dataset for Aspect-Based Sentiment Analysis in Legal\n  Opinion Texts", "comments": "6 pages, 2 figures, IEEE International Conference on Industrial and\n  Information Systems(ICIIS) 2020", "journal-ref": null, "doi": "10.1109/ICIIS51140.2020.9342650", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-Based Sentiment Analysis (ABSA) has been prominent and ongoing\nresearch over many different domains, but it is not widely discussed in the\nlegal domain. A number of publicly available datasets for a wide range of\ndomains usually fulfill the needs of researchers to perform their studies in\nthe field of ABSA. To the best of our knowledge, there is no publicly available\ndataset for the Aspect (Party) Based Sentiment Analysis for legal opinion\ntexts. Therefore, creating a publicly available dataset for the research of\nABSA for the legal domain can be considered as a task with significant\nimportance. In this study, we introduce a manually annotated legal opinion text\ndataset (SigmaLaw-ABSA) intended towards facilitating researchers for ABSA\ntasks in the legal domain. SigmaLaw-ABSA consists of legal opinion texts in the\nEnglish language which have been annotated by human judges. This study\ndiscusses the sub-tasks of ABSA relevant to the legal domain and how to use the\ndataset to perform them. This paper also describes the statistics of the\ndataset and as a baseline, we present some results on the performance of some\nexisting deep learning based systems on the SigmaLaw-ABSA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:45:47 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Mudalige", "Chanika Ruchini", ""], ["Karunarathna", "Dilini", ""], ["Rajapaksha", "Isanka", ""], ["de Silva", "Nisansa", ""], ["Ratnayaka", "Gathika", ""], ["Perera", "Amal Shehan", ""], ["Pathirana", "Ramesh", ""]]}, {"id": "2011.06380", "submitter": "Gurunath Reddy Madhumani", "authors": "Gurunath Reddy Madhumani, Yi Yu, Florian Harsco\\\"et, Simon Canales,\n  Suhua Tang", "title": "Automatic Neural Lyrics and Melody Composition", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a technique to address the most challenging aspect\nof algorithmic songwriting process, which enables the human community to\ndiscover original lyrics, and melodies suitable for the generated lyrics. The\nproposed songwriting system, Automatic Neural Lyrics and Melody Composition\n(AutoNLMC) is an attempt to make the whole process of songwriting automatic\nusing artificial neural networks. Our lyric to vector (lyric2vec) model trained\non a large set of lyric-melody pairs dataset parsed at syllable, word and\nsentence levels are large scale embedding models enable us to train data driven\nmodel such as recurrent neural networks for popular English songs. AutoNLMC is\na encoder-decoder sequential recurrent neural network model consisting of a\nlyric generator, a lyric encoder and melody decoder trained end-to-end.\nAutoNLMC is designed to generate both lyrics and corresponding melody\nautomatically for an amateur or a person without music knowledge. It can also\ntake lyrics from professional lyric writer to generate matching melodies. The\nqualitative and quantitative evaluation measures revealed that the proposed\nmethod is indeed capable of generating original lyrics and corresponding melody\nfor composing new songs.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:44:01 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Madhumani", "Gurunath Reddy", ""], ["Yu", "Yi", ""], ["Harsco\u00ebt", "Florian", ""], ["Canales", "Simon", ""], ["Tang", "Suhua", ""]]}, {"id": "2011.06382", "submitter": "Arbi Haza Nasution", "authors": "Dian Indriani, Arbi Haza Nasution, Winda Monika and Salhazan Nasution", "title": "Towards A Sentiment Analyzer for Low-Resource Languages", "comments": "Accepted to be published in Proceedings of International Conference\n  on Smart Computing and Cyber Security (SMARTCYBER 2020)", "journal-ref": "Proceedings of International Conference on Smart Computing and\n  Cyber Security: Strategic Foresight, Security Challenges and Innovation\n  (SMARTCYBER 2020)", "doi": "10.1007/978-981-15-7990-5_10", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Twitter is one of the top influenced social media which has a million number\nof active users. It is commonly used for microblogging that allows users to\nshare messages, ideas, thoughts and many more. Thus, millions interaction such\nas short messages or tweets are flowing around among the twitter users\ndiscussing various topics that has been happening world-wide. This research\naims to analyse a sentiment of the users towards a particular trending topic\nthat has been actively and massively discussed at that time. We chose a hashtag\n\\textit{\\#kpujangancurang} that was the trending topic during the Indonesia\npresidential election in 2019. We use the hashtag to obtain a set of data from\nTwitter to analyse and investigate further the positive or the negative\nsentiment of the users from their tweets. This research utilizes rapid miner\ntool to generate the twitter data and comparing Naive Bayes, K-Nearest\nNeighbor, Decision Tree, and Multi-Layer Perceptron classification methods to\nclassify the sentiment of the twitter data. There are overall 200 labeled data\nin this experiment. Overall, Naive Bayes and Multi-Layer Perceptron\nclassification outperformed the other two methods on 11 experiments with\ndifferent size of training-testing data split. The two classifiers are\npotential to be used in creating sentiment analyzer for low-resource languages\nwith small corpus.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:50:00 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Indriani", "Dian", ""], ["Nasution", "Arbi Haza", ""], ["Monika", "Winda", ""], ["Nasution", "Salhazan", ""]]}, {"id": "2011.06395", "submitter": "Ruofeng Wen", "authors": "Ruofeng Wen", "title": "Turn-level Dialog Evaluation with Dialog-level Weak Signals for\n  Bot-Human Hybrid Customer Service Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a machine learning approach that quantifies multiple aspects of\nthe success or values in Customer Service contacts, at anytime during the\ninteraction. Specifically, the value/reward function regarding to the\nturn-level behaviors across human agents, chatbots and other hybrid dialog\nsystems is characterized by the incremental information and confidence gain\nbetween sentences, based on the token-level predictions from a multi-task\nneural network trained with only weak signals in dialog-level\nattributes/states. The resulting model, named Value Profiler, serves as a\ngoal-oriented dialog manager that enhances conversations by regulating\nautomated decisions with its reward and state predictions. It supports both\nreal-time monitoring and scalable offline customer experience evaluation, for\nboth bot- and human-handled contacts. We show how it improves Amazon customer\nservice quality in several applications.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 19:36:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wen", "Ruofeng", ""]]}, {"id": "2011.06457", "submitter": "Youngseo Son", "authors": "Youngseo Son, Sean A. P. Clouston, Roman Kotov, Johannes C.\n  Eichstaedt, Evelyn J. Bromet, Benjamin J. Luft, and H Andrew Schwartz", "title": "World Trade Center responders in their own words: Predicting PTSD\n  symptom trajectories with AI-based language analyses of interviews", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Background: Oral histories from 9/11 responders to the World Trade Center\n(WTC) attacks provide rich narratives about distress and resilience. Artificial\nIntelligence (AI) models promise to detect psychopathology in natural language,\nbut they have been evaluated primarily in non-clinical settings using social\nmedia. This study sought to test the ability of AI-based language assessments\nto predict PTSD symptom trajectories among responders. Methods: Participants\nwere 124 responders whose health was monitored at the Stony Brook WTC Health\nand Wellness Program who completed oral history interviews about their initial\nWTC experiences. PTSD symptom severity was measured longitudinally using the\nPTSD Checklist (PCL) for up to 7 years post-interview. AI-based indicators were\ncomputed for depression, anxiety, neuroticism, and extraversion along with\ndictionary-based measures of linguistic and interpersonal style. Linear\nregression and multilevel models estimated associations of AI indicators with\nconcurrent and subsequent PTSD symptom severity (significance adjusted by false\ndiscovery rate). Results: Cross-sectionally, greater depressive language\n(beta=0.32; p=0.043) and first-person singular usage (beta=0.31; p=0.044) were\nassociated with increased symptom severity. Longitudinally, anxious language\npredicted future worsening in PCL scores (beta=0.31; p=0.031), whereas\nfirst-person plural usage (beta=-0.37; p=0.007) and longer words usage\n(beta=-0.36; p=0.007) predicted improvement. Conclusions: This is the first\nstudy to demonstrate the value of AI in understanding PTSD in a vulnerable\npopulation. Future studies should extend this application to other trauma\nexposures and to other demographic groups, especially under-represented\nminorities.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 15:57:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Son", "Youngseo", ""], ["Clouston", "Sean A. P.", ""], ["Kotov", "Roman", ""], ["Eichstaedt", "Johannes C.", ""], ["Bromet", "Evelyn J.", ""], ["Luft", "Benjamin J.", ""], ["Schwartz", "H Andrew", ""]]}, {"id": "2011.06467", "submitter": "Nilo Pedrazzini", "authors": "Nilo Pedrazzini (University of Oxford)", "title": "Exploiting Cross-Dialectal Gold Syntax for Low-Resource Historical\n  Languages: Towards a Generic Parser for Pre-Modern Slavic", "comments": "Edited by Folgert Karsdorp, Barbara McGillivray, Adina Nerghes &\n  Melvin Wevers. Conference paper (Preprint version). 11 pages. A link to the\n  repository with the datasets used in the paper can be found in the relevant\n  footnotes", "journal-ref": "Proceedings of the Workshop on Computational Humanities Research,\n  18-20 November 2020 (CEUR Workshop Proceedings, Vol. 2723), 237-247", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the possibility of improving the performance of\nspecialized parsers for pre-modern Slavic by training them on data from\ndifferent related varieties. Because of their linguistic heterogeneity,\npre-modern Slavic varieties are treated as low-resource historical languages,\nwhereby cross-dialectal treebank data may be exploited to overcome data\nscarcity and attempt the training of a variety-agnostic parser. Previous\nexperiments on early Slavic dependency parsing are discussed, particularly with\nregard to their ability to tackle different orthographic, regional and\nstylistic features. A generic pre-modern Slavic parser and two specialized\nparsers -- one for East Slavic and one for South Slavic -- are trained using\njPTDP (Nguyen & Verspoor 2018), a neural network model for joint part-of-speech\n(POS) tagging and dependency parsing which had shown promising results on a\nnumber of Universal Dependency (UD) treebanks, including Old Church Slavonic\n(OCS). With these experiments, a new state of the art is obtained for both OCS\n(83.79\\% unlabelled attachment score (UAS) and 78.43\\% labelled attachement\nscore (LAS)) and Old East Slavic (OES) (85.7\\% UAS and 80.16\\% LAS).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:17:59 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Pedrazzini", "Nilo", "", "University of Oxford"]]}, {"id": "2011.06485", "submitter": "Robert Adragna", "authors": "Robert Adragna, Elliot Creager, David Madras, Richard Zemel", "title": "Fairness and Robustness in Invariant Learning: A Case Study in Toxicity\n  Classification", "comments": "12 pages, 5 figures. Appears in the NeurIPS 2020 Workshop on\n  Algorithmic Fairness through the Lens of Causality and Interpretability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robustness is of central importance in machine learning and has given rise to\nthe fields of domain generalization and invariant learning, which are concerned\nwith improving performance on a test distribution distinct from but related to\nthe training distribution. In light of recent work suggesting an intimate\nconnection between fairness and robustness, we investigate whether algorithms\nfrom robust ML can be used to improve the fairness of classifiers that are\ntrained on biased data and tested on unbiased data. We apply Invariant Risk\nMinimization (IRM), a domain generalization algorithm that employs a causal\ndiscovery inspired method to find robust predictors, to the task of fairly\npredicting the toxicity of internet comments. We show that IRM achieves better\nout-of-distribution accuracy and fairness than Empirical Risk Minimization\n(ERM) methods, and analyze both the difficulties that arise when applying IRM\nin practice and the conditions under which IRM will likely be effective in this\nscenario. We hope that this work will inspire further studies of how robust\nmachine learning methods relate to algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:42:14 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 02:21:12 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Adragna", "Robert", ""], ["Creager", "Elliot", ""], ["Madras", "David", ""], ["Zemel", "Richard", ""]]}, {"id": "2011.06486", "submitter": "Chulaka Gunasekara", "authors": "Chulaka Gunasekara, Seokhwan Kim, Luis Fernando D'Haro, Abhinav\n  Rastogi, Yun-Nung Chen, Mihail Eric, Behnam Hedayatnia, Karthik\n  Gopalakrishnan, Yang Liu, Chao-Wei Huang, Dilek Hakkani-T\\\"ur, Jinchao Li, Qi\n  Zhu, Lingxiao Luo, Lars Liden, Kaili Huang, Shahin Shayandeh, Runze Liang,\n  Baolin Peng, Zheng Zhang, Swadheen Shukla, Minlie Huang, Jianfeng Gao, Shikib\n  Mehri, Yulan Feng, Carla Gordon, Seyed Hossein Alavi, David Traum, Maxine\n  Eskenazi, Ahmad Beirami, Eunjoon (EJ) Cho, Paul A. Crook, Ankita De, Alborz\n  Geramifard, Satwik Kottur, Seungwhan Moon, Shivani Poddar, Rajen Subba", "title": "Overview of the Ninth Dialog System Technology Challenge: DSTC9", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces the Ninth Dialog System Technology Challenge (DSTC-9).\nThis edition of the DSTC focuses on applying end-to-end dialog technologies for\nfour distinct tasks in dialog systems, namely, 1. Task-oriented dialog Modeling\nwith unstructured knowledge access, 2. Multi-domain task-oriented dialog, 3.\nInteractive evaluation of dialog, and 4. Situated interactive multi-modal\ndialog. This paper describes the task definition, provided datasets, baselines\nand evaluation set-up for each track. We also summarize the results of the\nsubmitted systems to highlight the overall trends of the state-of-the-art\ntechnologies for the tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:43:10 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Gunasekara", "Chulaka", "", "EJ"], ["Kim", "Seokhwan", "", "EJ"], ["D'Haro", "Luis Fernando", "", "EJ"], ["Rastogi", "Abhinav", "", "EJ"], ["Chen", "Yun-Nung", "", "EJ"], ["Eric", "Mihail", "", "EJ"], ["Hedayatnia", "Behnam", "", "EJ"], ["Gopalakrishnan", "Karthik", "", "EJ"], ["Liu", "Yang", "", "EJ"], ["Huang", "Chao-Wei", "", "EJ"], ["Hakkani-T\u00fcr", "Dilek", "", "EJ"], ["Li", "Jinchao", "", "EJ"], ["Zhu", "Qi", "", "EJ"], ["Luo", "Lingxiao", "", "EJ"], ["Liden", "Lars", "", "EJ"], ["Huang", "Kaili", "", "EJ"], ["Shayandeh", "Shahin", "", "EJ"], ["Liang", "Runze", "", "EJ"], ["Peng", "Baolin", "", "EJ"], ["Zhang", "Zheng", "", "EJ"], ["Shukla", "Swadheen", "", "EJ"], ["Huang", "Minlie", "", "EJ"], ["Gao", "Jianfeng", "", "EJ"], ["Mehri", "Shikib", "", "EJ"], ["Feng", "Yulan", "", "EJ"], ["Gordon", "Carla", "", "EJ"], ["Alavi", "Seyed Hossein", "", "EJ"], ["Traum", "David", "", "EJ"], ["Eskenazi", "Maxine", "", "EJ"], ["Beirami", "Ahmad", "", "EJ"], ["Eunjoon", "", "", "EJ"], ["Cho", "", ""], ["Crook", "Paul A.", ""], ["De", "Ankita", ""], ["Geramifard", "Alborz", ""], ["Kottur", "Satwik", ""], ["Moon", "Seungwhan", ""], ["Poddar", "Shivani", ""], ["Subba", "Rajen", ""]]}, {"id": "2011.06489", "submitter": "Zhuoqiao Hong", "authors": "Zhuoqiao Hong, Colin G. Magdamo, Yi-han Sheu, Prathamesh Mohite, Ayush\n  Noori, Elissa M. Ye, Wendong Ge, Haoqi Sun, Laura Brenner, Gregory Robbins,\n  Shibani Mukerji, Sahar Zafar, Nicole Benson, Lidia Moura, John Hsu, Bradley\n  T. Hyman, Michael B. Westover, Deborah Blacker, Sudeshna Das", "title": "Natural Language Processing to Detect Cognitive Concerns in Electronic\n  Health Records Using Deep Learning", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dementia is under-recognized in the community, under-diagnosed by healthcare\nprofessionals, and under-coded in claims data. Information on cognitive\ndysfunction, however, is often found in unstructured clinician notes within\nmedical records but manual review by experts is time consuming and often prone\nto errors. Automated mining of these notes presents a potential opportunity to\nlabel patients with cognitive concerns who could benefit from an evaluation or\nbe referred to specialist care. In order to identify patients with cognitive\nconcerns in electronic medical records, we applied natural language processing\n(NLP) algorithms and compared model performance to a baseline model that used\nstructured diagnosis codes and medication data only. An attention-based deep\nlearning model outperformed the baseline model and other simpler models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:59:56 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hong", "Zhuoqiao", ""], ["Magdamo", "Colin G.", ""], ["Sheu", "Yi-han", ""], ["Mohite", "Prathamesh", ""], ["Noori", "Ayush", ""], ["Ye", "Elissa M.", ""], ["Ge", "Wendong", ""], ["Sun", "Haoqi", ""], ["Brenner", "Laura", ""], ["Robbins", "Gregory", ""], ["Mukerji", "Shibani", ""], ["Zafar", "Sahar", ""], ["Benson", "Nicole", ""], ["Moura", "Lidia", ""], ["Hsu", "John", ""], ["Hyman", "Bradley T.", ""], ["Westover", "Michael B.", ""], ["Blacker", "Deborah", ""], ["Das", "Sudeshna", ""]]}, {"id": "2011.06504", "submitter": "Kexin Huang", "authors": "Kexin Huang, Sankeerth Garapati, Alexander S. Rich", "title": "An Interpretable End-to-end Fine-tuning Approach for Long Clinical Text", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured clinical text in EHRs contains crucial information for\napplications including decision support, trial matching, and retrospective\nresearch. Recent work has applied BERT-based models to clinical information\nextraction and text classification, given these models' state-of-the-art\nperformance in other NLP domains. However, BERT is difficult to apply to\nclinical notes because it doesn't scale well to long sequences of text. In this\nwork, we propose a novel fine-tuning approach called SnipBERT. Instead of using\nentire notes, SnipBERT identifies crucial snippets and then feeds them into a\ntruncated BERT-based model in a hierarchical manner. Empirically, SnipBERT not\nonly has significant predictive performance gain across three tasks but also\nprovides improved interpretability, as the model can identify key pieces of\ntext that led to its prediction.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:14:32 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Huang", "Kexin", ""], ["Garapati", "Sankeerth", ""], ["Rich", "Alexander S.", ""]]}, {"id": "2011.06523", "submitter": "Danielle Saunders", "authors": "Danielle Saunders, Weston Feely, Bill Byrne", "title": "Inference-only sub-character decomposition improves translation of\n  unseen logographic characters", "comments": "Workshop on Asian Translation (WAT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) on logographic source languages struggles\nwhen translating `unseen' characters, which never appear in the training data.\nOne possible approach to this problem uses sub-character decomposition for\ntraining and test sentences. However, this approach involves complete\nretraining, and its effectiveness for unseen character translation to\nnon-logographic languages has not been fully explored.\n  We investigate existing ideograph-based sub-character decomposition\napproaches for Chinese-to-English and Japanese-to-English NMT, for both\nhigh-resource and low-resource domains. For each language pair and domain we\nconstruct a test set where all source sentences contain at least one unseen\nlogographic character. We find that complete sub-character decomposition often\nharms unseen character translation, and gives inconsistent results generally.\n  We offer a simple alternative based on decomposition before inference for\nunseen characters only. Our approach allows flexible application, achieving\ntranslation adequacy improvements and requiring no additional models or\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:36:22 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Saunders", "Danielle", ""], ["Feely", "Weston", ""], ["Byrne", "Bill", ""]]}, {"id": "2011.06623", "submitter": "Song Feng", "authors": "Song Feng, Hui Wan, Chulaka Gunasekara, Siva Sankalp Patel, Sachindra\n  Joshi, Luis A. Lastras", "title": "doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce doc2dial, a new dataset of goal-oriented dialogues that are\ngrounded in the associated documents. Inspired by how the authors compose\ndocuments for guiding end users, we first construct dialogue flows based on the\ncontent elements that corresponds to higher-level relations across text\nsections as well as lower-level relations between discourse units within a\nsection. Then we present these dialogue flows to crowd contributors to create\nconversational utterances. The dataset includes about 4800 annotated\nconversations with an average of 14 turns that are grounded in over 480\ndocuments from four domains. Compared to the prior document-grounded dialogue\ndatasets, this dataset covers a variety of dialogue scenes in\ninformation-seeking conversations. For evaluating the versatility of the\ndataset, we introduce multiple dialogue modeling tasks and present baseline\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 19:08:44 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:42:12 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Feng", "Song", ""], ["Wan", "Hui", ""], ["Gunasekara", "Chulaka", ""], ["Patel", "Siva Sankalp", ""], ["Joshi", "Sachindra", ""], ["Lastras", "Luis A.", ""]]}, {"id": "2011.06642", "submitter": "Xiangci Li", "authors": "Xiangci Li, Hairong Liu, Liang Huang", "title": "Context-aware Stand-alone Neural Spelling Correction", "comments": "8 pages, 5 tables, 1 figure. Findings of the Association for\n  Computational Linguistics: EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing natural language processing systems are vulnerable to noisy inputs\nresulting from misspellings. On the contrary, humans can easily infer the\ncorresponding correct words from their misspellings and surrounding context.\nInspired by this, we address the stand-alone spelling correction problem, which\nonly corrects the spelling of each token without additional token insertion or\ndeletion, by utilizing both spelling information and global context\nrepresentations. We present a simple yet powerful solution that jointly detects\nand corrects misspellings as a sequence labeling task by fine-turning a\npre-trained language model. Our solution outperforms the previous\nstate-of-the-art result by 12.8% absolute F0.5 score.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 20:34:49 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Li", "Xiangci", ""], ["Liu", "Hairong", ""], ["Huang", "Liang", ""]]}, {"id": "2011.06727", "submitter": "Zanbo Wang", "authors": "Zhiyong He, Zanbo Wang, Wei Wei, Shanshan Feng, Xianling Mao, and\n  Sheng Jiang", "title": "A Survey on Recent Advances in Sequence Labeling from Deep Learning\n  Models", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling (SL) is a fundamental research problem encompassing a\nvariety of tasks, e.g., part-of-speech (POS) tagging, named entity recognition\n(NER), text chunking, etc. Though prevalent and effective in many downstream\napplications (e.g., information retrieval, question answering, and knowledge\ngraph embedding), conventional sequence labeling approaches heavily rely on\nhand-crafted or language-specific features. Recently, deep learning has been\nemployed for sequence labeling tasks due to its powerful capability in\nautomatically learning complex features of instances and effectively yielding\nthe stat-of-the-art performances. In this paper, we aim to present a\ncomprehensive review of existing deep learning-based sequence labeling models,\nwhich consists of three related tasks, e.g., part-of-speech tagging, named\nentity recognition, and text chunking. Then, we systematically present the\nexisting approaches base on a scientific taxonomy, as well as the widely-used\nexperimental datasets and popularly-adopted evaluation metrics in the SL\ndomain. Furthermore, we also present an in-depth analysis of different SL\nmodels on the factors that may affect the performance and future directions in\nthe SL domain.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:29:50 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["He", "Zhiyong", ""], ["Wang", "Zanbo", ""], ["Wei", "Wei", ""], ["Feng", "Shanshan", ""], ["Mao", "Xianling", ""], ["Jiang", "Sheng", ""]]}, {"id": "2011.06737", "submitter": "Yiming Cui", "authors": "Yiming Cui, Ting Liu, Shijin Wang, Guoping Hu", "title": "Unsupervised Explanation Generation for Machine Reading Comprehension", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the blooming of various Pre-trained Language Models (PLMs), Machine\nReading Comprehension (MRC) has embraced significant improvements on various\nbenchmarks and even surpass human performances. However, the existing works\nonly target on the accuracy of the final predictions and neglect the importance\nof the explanations for the prediction, which is a big obstacle when utilizing\nthese models in real-life applications to convince humans. In this paper, we\npropose a self-explainable framework for the machine reading comprehension\ntask. The main idea is that the proposed system tries to use less passage\ninformation and achieve similar results compared to the system that uses the\nwhole passage, while the filtered passage will be used as explanations. We\ncarried out experiments on three multiple-choice MRC datasets, and found that\nthe proposed system could achieve consistent improvements over baseline\nsystems. To evaluate the explainability, we compared our approach with the\ntraditional attention mechanism in human evaluations and found that the\nproposed system has a notable advantage over the latter one.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:58:55 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Cui", "Yiming", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "2011.06754", "submitter": "Morteza Rohanian", "authors": "Morteza Rohanian, Julian Hough", "title": "Re-framing Incremental Deep Language Models for Dialogue Processing with\n  Multi-task Learning", "comments": null, "journal-ref": "The 28th International Conference on Computational Linguistics\n  (COLING 2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a multi-task learning framework to enable the training of one\nuniversal incremental dialogue processing model with four tasks of disfluency\ndetection, language modelling, part-of-speech tagging, and utterance\nsegmentation in a simple deep recurrent setting. We show that these tasks\nprovide positive inductive biases to each other with the optimal contribution\nof each one relying on the severity of the noise from the task. Our live\nmulti-task model outperforms similar individual tasks, delivers competitive\nperformance, and is beneficial for future use in conversational agents in\npsychiatric treatment.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 04:31:51 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Rohanian", "Morteza", ""], ["Hough", "Julian", ""]]}, {"id": "2011.06819", "submitter": "Jaap Jumelet", "authors": "Jaap Jumelet", "title": "diagNNose: A Library for Neural Activation Analysis", "comments": "Accepted to the Third BlackboxNLP Workshop on Analyzing and\n  Interpreting Neural Networks for NLP, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce diagNNose, an open source library for analysing\nthe activations of deep neural networks. diagNNose contains a wide array of\ninterpretability techniques that provide fundamental insights into the inner\nworkings of neural networks. We demonstrate the functionality of diagNNose with\na case study on subject-verb agreement within language models. diagNNose is\navailable at https://github.com/i-machine-think/diagnnose.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:19:48 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Jumelet", "Jaap", ""]]}, {"id": "2011.06844", "submitter": "Xiaoyu Shen", "authors": "Liqiang Wang, Xiaoyu Shen, Gerard de Melo, Gerhard Weikum", "title": "Cross-Domain Learning for Classifying Propaganda in Online Contents", "comments": "TTO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As news and social media exhibit an increasing amount of manipulative\npolarized content, detecting such propaganda has received attention as a new\ntask for content analysis. Prior work has focused on supervised learning with\ntraining data from the same domain. However, as propaganda can be subtle and\nkeeps evolving, manual identification and proper labeling are very demanding.\nAs a consequence, training data is a major bottleneck. In this paper, we tackle\nthis bottleneck and present an approach to leverage cross-domain learning,\nbased on labeled documents and sentences from news and tweets, as well as\npolitical speeches with a clear difference in their degrees of being\npropagandistic. We devise informative features and build various classifiers\nfor propaganda labeling, using cross-domain learning. Our experiments\ndemonstrate the usefulness of this approach, and identify difficulties and\nlimitations in various configurations of sources and targets for the transfer\nstep. We further analyze the influence of various features, and characterize\nsalient indicators of propaganda.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:19:13 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 17:39:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Liqiang", ""], ["Shen", "Xiaoyu", ""], ["de Melo", "Gerard", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2011.06846", "submitter": "Thomas Pellegrini", "authors": "Thomas Pellegrini, Romain Zimmer, Timoth\\'ee Masquelier", "title": "Low-activity supervised convolutional spiking neural networks applied to\n  speech commands recognition", "comments": "Accepted to IEEE Spoken Language Technology Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Neural Networks (DNNs) are the current state-of-the-art models in many\nspeech related tasks. There is a growing interest, though, for more\nbiologically realistic, hardware friendly and energy efficient models, named\nSpiking Neural Networks (SNNs). Recently, it has been shown that SNNs can be\ntrained efficiently, in a supervised manner, using backpropagation with a\nsurrogate gradient trick. In this work, we report speech command (SC)\nrecognition experiments using supervised SNNs. We explored the\nLeaky-Integrate-Fire (LIF) neuron model for this task, and show that a model\ncomprised of stacked dilated convolution spiking layers can reach an error rate\nvery close to standard DNNs on the Google SC v1 dataset: 5.5%, while keeping a\nvery sparse spiking activity, below 5%, thank to a new regularization term. We\nalso show that modeling the leakage of the neuron membrane potential is useful,\nsince the LIF model outperformed its non-leaky model counterpart significantly.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:29:35 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Pellegrini", "Thomas", ""], ["Zimmer", "Romain", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "2011.06854", "submitter": "Jinlan Fu", "authors": "Jinlan Fu, Pengfei Liu, Graham Neubig", "title": "Interpretable Multi-dataset Evaluation for Named Entity Recognition", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the proliferation of models for natural language processing tasks, it is\neven harder to understand the differences between models and their relative\nmerits. Simply looking at differences between holistic metrics such as\naccuracy, BLEU, or F1 does not tell us why or how particular methods perform\ndifferently and how diverse datasets influence the model design choices. In\nthis paper, we present a general methodology for interpretable evaluation for\nthe named entity recognition (NER) task. The proposed evaluation method enables\nus to interpret the differences in models and datasets, as well as the\ninterplay between them, identifying the strengths and weaknesses of current\nsystems. By making our analysis tool available, we make it easy for future\nresearchers to run similar analyses and drive progress in this area:\nhttps://github.com/neulab/InterpretEval.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:53:27 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 04:53:07 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Fu", "Jinlan", ""], ["Liu", "Pengfei", ""], ["Neubig", "Graham", ""]]}, {"id": "2011.06858", "submitter": "Jinlan Fu", "authors": "Jinlan Fu, Pengfei Liu, Qi Zhang, Xuanjing Huang", "title": "RethinkCWS: Is Chinese Word Segmentation a Solved Task?", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of the Chinese Word Segmentation (CWS) systems has gradually\nreached a plateau with the rapid development of deep neural networks,\nespecially the successful use of large pre-trained models. In this paper, we\ntake stock of what we have achieved and rethink what's left in the CWS task.\nMethodologically, we propose a fine-grained evaluation for existing CWS\nsystems, which not only allows us to diagnose the strengths and weaknesses of\nexisting models (under the in-dataset setting), but enables us to quantify the\ndiscrepancy between different criterion and alleviate the negative transfer\nproblem when doing multi-criteria learning. Strategically, despite not aiming\nto propose a novel model in this paper, our comprehensive experiments on eight\nmodels and seven datasets, as well as thorough analysis, could search for some\npromising direction for future research. We make all codes publicly available\nand release an interface that can quickly evaluate and diagnose user's models:\nhttps://github.com/neulab/InterpretEval.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 11:07:08 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 04:48:04 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Fu", "Jinlan", ""], ["Liu", "Pengfei", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2011.06868", "submitter": "Weijia Xu", "authors": "Weijia Xu, Marine Carpuat", "title": "EDITOR: an Edit-Based Transformer with Repositioning for Neural Machine\n  Translation with Soft Lexical Constraints", "comments": "TACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an Edit-Based Transformer with Repositioning (EDITOR), which\nmakes sequence generation flexible by seamlessly allowing users to specify\npreferences in output lexical choice. Building on recent models for\nnon-autoregressive sequence generation (Gu et al., 2019), EDITOR generates new\nsequences by iteratively editing hypotheses. It relies on a novel reposition\noperation designed to disentangle lexical choice from word positioning\ndecisions, while enabling efficient oracles for imitation learning and parallel\nedits at decoding time. Empirically, EDITOR uses soft lexical constraints more\neffectively than the Levenshtein Transformer (Gu et al., 2019) while speeding\nup decoding dramatically compared to constrained beam search (Post and Vilar,\n2018). EDITOR also achieves comparable or better translation quality with\nfaster decoding speed than the Levenshtein Transformer on standard\nRomanian-English, English-German, and English-Japanese machine translation\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 11:47:28 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 22:26:02 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Xu", "Weijia", ""], ["Carpuat", "Marine", ""]]}, {"id": "2011.06874", "submitter": "Ali Mottaghi", "authors": "Ali Mottaghi, Prathusha K Sarma, Xavier Amatriain, Serena Yeung,\n  Anitha Kannan", "title": "Medical symptom recognition from patient text: An active learning\n  approach for long-tailed multilabel distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of medical symptoms recognition from patient text, for\nthe purposes of gathering pertinent information from the patient (known as\nhistory-taking). A typical patient text is often descriptive of the symptoms\nthe patient is experiencing and a single instance of such a text can be\n\"labeled\" with multiple symptoms. This makes learning a medical symptoms\nrecognizer challenging on account of i) the lack of availability of voluminous\nannotated data as well as ii) the large unknown universe of multiple symptoms\nthat a single text can map to. Furthermore, patient text is often characterized\nby a long tail in the data (i.e., some labels/symptoms occur more frequently\nthan others for e.g \"fever\" vs \"hematochezia\"). In this paper, we introduce an\nactive learning method that leverages underlying structure of a continually\nrefined, learned latent space to select the most informative examples to label.\nThis enables the selection of the most informative examples that progressively\nincreases the coverage on the universe of symptoms via the learned model,\ndespite the long tail in data distribution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:26:56 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 23:18:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mottaghi", "Ali", ""], ["Sarma", "Prathusha K", ""], ["Amatriain", "Xavier", ""], ["Yeung", "Serena", ""], ["Kannan", "Anitha", ""]]}, {"id": "2011.06949", "submitter": "Jos\\'e Ignacio Alvarez-Hamelin Phd.", "authors": "Carlos Selmo, Julian F. Martinez, Mariano G. Beir\\'o and J. Ignacio\n  Alvarez-Hamelin", "title": "Learning language variations in news corpora through differential\n  embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is an increasing interest in the NLP community in capturing variations\nin the usage of language, either through time (i.e., semantic drift), across\nregions (as dialects or variants) or in different social contexts (i.e.,\nprofessional or media technolects). Several successful dynamical embeddings\nhave been proposed that can track semantic change through time. Here we show\nthat a model with a central word representation and a slice-dependent\ncontribution can learn word embeddings from different corpora simultaneously.\nThis model is based on a star-like representation of the slices. We apply it to\nThe New York Times and The Guardian newspapers, and we show that it can capture\nboth temporal dynamics in the yearly slices of each corpus, and language\nvariations between US and UK English in a curated multi-source corpus. We\nprovide an extensive evaluation of this methodology.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 14:50:08 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Selmo", "Carlos", ""], ["Martinez", "Julian F.", ""], ["Beir\u00f3", "Mariano G.", ""], ["Alvarez-Hamelin", "J. Ignacio", ""]]}, {"id": "2011.06977", "submitter": "Abdelrahman Abouelenin", "authors": "Ahmad Beltagy, Abdelrahman Wael, Omar ElSherief", "title": "Arabic Dialect Identification Using BERT-Based Domain Adaptation", "comments": "6 pages, 2 figures , WANLP co-located with COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Arabic is one of the most important and growing languages in the world. With\nthe rise of social media platforms such as Twitter, Arabic spoken dialects have\nbecome more in use. In this paper, we describe our approach on the NADI Shared\nTask 1 that requires us to build a system to differentiate between different 21\nArabic dialects, we introduce a deep learning semi-supervised fashion approach\nalong with pre-processing that was reported on NADI shared Task 1 Corpus. Our\nsystem ranks 4th in NADI's shared task competition achieving a 23.09% F1 macro\naverage score with a simple yet efficient approach to differentiating between\n21 Arabic Dialects given tweets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:52:51 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Beltagy", "Ahmad", ""], ["Wael", "Abdelrahman", ""], ["ElSherief", "Omar", ""]]}, {"id": "2011.06993", "submitter": "Stefan Schweter", "authors": "Stefan Schweter, Alan Akbik", "title": "FLERT: Document-Level Features for Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art approaches for named entity recognition (NER)\ntypically consider text at the sentence-level and thus do not model information\nthat crosses sentence boundaries. However, the use of transformer-based models\nfor NER offers natural options for capturing document-level features. In this\npaper, we perform a comparative evaluation of document-level features in the\ntwo standard NER architectures commonly considered in the literature, namely\n\"fine-tuning\" and \"feature-based LSTM-CRF\". We evaluate different\nhyperparameters for document-level features such as context window size and\nenforcing document-locality. We present experiments from which we derive\nrecommendations for how to model document context and present new\nstate-of-the-art scores on several CoNLL-03 benchmark datasets. Our approach is\nintegrated into the Flair framework to facilitate reproduction of our\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:13:59 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 07:15:07 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Schweter", "Stefan", ""], ["Akbik", "Alan", ""]]}, {"id": "2011.07009", "submitter": "Elisa Bassignana", "authors": "Elisa Bassignana, Malvina Nissim and Viviana Patti", "title": "Matching Theory and Data with Personal-ITY: What a Corpus of Italian\n  YouTube Comments Reveals About Personality", "comments": "12 pages, Accepted at PEOPLES 2020 (workshop COLING 2020). arXiv\n  admin note: text overlap with arXiv:2011.05688", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a contribution to personality detection in languages other than English,\nwe rely on distant supervision to create Personal-ITY, a novel corpus of\nYouTube comments in Italian, where authors are labelled with personality\ntraits. The traits are derived from one of the mainstream personality theories\nin psychology research, named MBTI. Using personality prediction experiments,\nwe (i) study the task of personality prediction in itself on our corpus as well\nas on TwiSty, a Twitter dataset also annotated with MBTI labels; (ii) carry out\nan extensive, in-depth analysis of the features used by the classifier, and\nview them specifically under the light of the original theory that we used to\ncreate the corpus in the first place. We observe that no single model is best\nat personality detection, and that while some traits are easier than others to\ndetect, and also to match back to theory, for other, less frequent traits the\npicture is much more blurred.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 12:45:33 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Bassignana", "Elisa", ""], ["Nissim", "Malvina", ""], ["Patti", "Viviana", ""]]}, {"id": "2011.07013", "submitter": "Kian Kenyon-Dean", "authors": "Kian Kenyon-Dean, Edward Newell, Jackie Chi Kit Cheung", "title": "Deconstructing word embedding algorithms", "comments": "EMNLP 2020, 6 pages. arXiv admin note: substantial text overlap with\n  arXiv:1911.13280", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings are reliable feature representations of words used to obtain\nhigh quality results for various NLP applications. Uncontextualized word\nembeddings are used in many NLP tasks today, especially in resource-limited\nsettings where high memory capacity and GPUs are not available. Given the\nhistorical success of word embeddings in NLP, we propose a retrospective on\nsome of the most well-known word embedding algorithms. In this work, we\ndeconstruct Word2vec, GloVe, and others, into a common form, unveiling some of\nthe common conditions that seem to be required for making performant word\nembeddings. We believe that the theoretical findings in this paper can provide\na basis for more informed development of future models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 14:23:35 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Kenyon-Dean", "Kian", ""], ["Newell", "Edward", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "2011.07065", "submitter": "Homayoon Beigi", "authors": "Amith Ananthram, Kailash Karthik Saravanakumar, Jessica Huynh, and\n  Homayoon Beigi", "title": "Multi-Modal Emotion Detection with Transfer Learning", "comments": "11 pages, 7 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": "RTI-20201113-01", "categories": "eess.AS cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated emotion detection in speech is a challenging task due to the\ncomplex interdependence between words and the manner in which they are spoken.\nIt is made more difficult by the available datasets; their small size and\nincompatible labeling idiosyncrasies make it hard to build generalizable\nemotion detection systems. To address these two challenges, we present a\nmulti-modal approach that first transfers learning from related tasks in speech\nand text to produce robust neural embeddings and then uses these embeddings to\ntrain a pLDA classifier that is able to adapt to previously unseen emotions and\ndomains. We begin by training a multilayer TDNN on the task of speaker\nidentification with the VoxCeleb corpora and then fine-tune it on the task of\nemotion identification with the Crema-D corpus. Using this network, we extract\nspeech embeddings for Crema-D from each of its layers, generate and concatenate\ntext embeddings for the accompanying transcripts using a fine-tuned BERT model\nand then train an LDA - pLDA classifier on the resulting dense representations.\nWe exhaustively evaluate the predictive power of every component: the TDNN\nalone, speech embeddings from each of its layers alone, text embeddings alone\nand every combination thereof. Our best variant, trained on only VoxCeleb and\nCrema-D and evaluated on IEMOCAP, achieves an EER of 38.05%. Including a\nportion of IEMOCAP during training produces a 5-fold averaged EER of 25.72%\n(For comparison, 44.71% of the gold-label annotations include at least one\nannotator who disagrees).\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 18:58:59 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ananthram", "Amith", ""], ["Saravanakumar", "Kailash Karthik", ""], ["Huynh", "Jessica", ""], ["Beigi", "Homayoon", ""]]}, {"id": "2011.07109", "submitter": "Helen Yannakoudakis", "authors": "Andrew Caines and Helen Yannakoudakis and Helena Edmondson and Helen\n  Allen and Pascual P\\'erez-Paredes and Bill Byrne and Paula Buttery", "title": "The Teacher-Student Chatroom Corpus", "comments": "NLP4CALL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Teacher-Student Chatroom Corpus (TSCC) is a collection of written\nconversations captured during one-to-one lessons between teachers and learners\nof English. The lessons took place in an online chatroom and therefore involve\nmore interactive, immediate and informal language than might be found in\nasynchronous exchanges such as email correspondence. The fact that the lessons\nwere one-to-one means that the teacher was able to focus exclusively on the\nlinguistic abilities and errors of the student, and to offer personalised\nexercises, scaffolding and correction. The TSCC contains more than one hundred\nlessons between two teachers and eight students, amounting to 13.5K\nconversational turns and 133K words: it is freely available for research use.\nWe describe the corpus design, data collection procedure and annotations added\nto the text. We perform some preliminary descriptive analyses of the data and\nconsider possible uses of the TSCC.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:58:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Caines", "Andrew", ""], ["Yannakoudakis", "Helen", ""], ["Edmondson", "Helena", ""], ["Allen", "Helen", ""], ["P\u00e9rez-Paredes", "Pascual", ""], ["Byrne", "Bill", ""], ["Buttery", "Paula", ""]]}, {"id": "2011.07120", "submitter": "Ching-Feng Yeh", "authors": "Ching-Feng Yeh, Yongqiang Wang, Yangyang Shi, Chunyang Wu, Frank\n  Zhang, Julian Chan, Michael L. Seltzer", "title": "Streaming Attention-Based Models with Augmented Memory for End-to-End\n  Speech Recognition", "comments": "IEEE Spoken Language Technology Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have been gaining popularity recently for their strong\nperformance demonstrated in fields such as machine translation and automatic\nspeech recognition. One major challenge of attention-based models is the need\nof access to the full sequence and the quadratically growing computational cost\nconcerning the sequence length. These characteristics pose challenges,\nespecially for low-latency scenarios, where the system is often required to be\nstreaming. In this paper, we build a compact and streaming speech recognition\nsystem on top of the end-to-end neural transducer architecture with\nattention-based modules augmented with convolution. The proposed system equips\nthe end-to-end models with the streaming capability and reduces the large\nfootprint from the streaming attention-based model using augmented memory. On\nthe LibriSpeech dataset, our proposed system achieves word error rates 2.7% on\ntest-clean and 5.8% on test-other, to our best knowledge the lowest among\nstreaming approaches reported so far.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 00:43:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yeh", "Ching-Feng", ""], ["Wang", "Yongqiang", ""], ["Shi", "Yangyang", ""], ["Wu", "Chunyang", ""], ["Zhang", "Frank", ""], ["Chan", "Julian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "2011.07126", "submitter": "Hoda Eldardiry", "authors": "Jiaying Gong and Hoda Eldardiry", "title": "Zero-shot Learning for Relation Extraction", "comments": "11 pages, 7 figures, submitted to WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing supervised and few-shot learning relation extraction methods\nhave relied on labeled training data. However, in real-world scenarios, there\nexist many relations for which there is no available training data. We address\nthis issue from the perspective of zero-shot learning (ZSL) which is similar to\nthe way humans learn and recognize new concepts with no prior knowledge. We\npropose a zero-shot learning relation extraction (ZSLRE) framework, which\nfocuses on recognizing novel relations that have no corresponding labeled data\navailable for training. Our proposed ZSLRE model aims to recognize new\nrelations based on prototypical networks that are modified to utilize side\n(auxiliary) information. The additional use of side information allows those\nmodified prototype networks to recognize novel relations in addition to\nrecognized previously known relations. We construct side information from\nlabels and their synonyms, hypernyms of name entities, and keywords. We build\nan automatic hypernym extraction framework to help get hypernyms of various\nname entities directly from the web. We demonstrate using extensive experiments\non two public datasets (NYT and FewRel) that our proposed model significantly\noutperforms state-of-the-art methods on supervised learning, few-shot learning,\nand zero-shot learning tasks. Our experimental results also demonstrate the\neffectiveness and robustness of our proposed model in a combination scenario.\nOnce accepted for publication, we will publish ZSLRE's source code and datasets\nto enable reproducibility and encourage further research.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:57:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gong", "Jiaying", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2011.07127", "submitter": "James Ferguson", "authors": "James Ferguson, Matt Gardner, Hannaneh Hajishirzi, Tushar Khot,\n  Pradeep Dasigi", "title": "IIRC: A Dataset of Incomplete Information Reading Comprehension\n  Questions", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Humans often have to read multiple documents to address their information\nneeds. However, most existing reading comprehension (RC) tasks only focus on\nquestions for which the contexts provide all the information required to answer\nthem, thus not evaluating a system's performance at identifying a potential\nlack of sufficient information and locating sources for that information. To\nfill this gap, we present a dataset, IIRC, with more than 13K questions over\nparagraphs from English Wikipedia that provide only partial information to\nanswer them, with the missing information occurring in one or more linked\ndocuments. The questions were written by crowd workers who did not have access\nto any of the linked documents, leading to questions that have little lexical\noverlap with the contexts where the answers appear. This process also gave many\nquestions without answers, and those that require discrete reasoning,\nincreasing the difficulty of the task. We follow recent modeling work on\nvarious reading comprehension datasets to construct a baseline model for this\ndataset, finding that it achieves 31.1% F1 on this task, while estimated human\nperformance is 88.4%. The dataset, code for the baseline system, and a\nleaderboard can be found at https://allennlp.org/iirc.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:59:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ferguson", "James", ""], ["Gardner", "Matt", ""], ["Hajishirzi", "Hannaneh", ""], ["Khot", "Tushar", ""], ["Dasigi", "Pradeep", ""]]}, {"id": "2011.07164", "submitter": "Shruti Bhosale", "authors": "Shruti Bhosale, Kyra Yee, Sergey Edunov, Michael Auli", "title": "Language Models not just for Pre-training: Fast Online Neural Noisy\n  Channel Modeling", "comments": "Accepted at WMT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training models on vast quantities of unlabeled data has emerged as an\neffective approach to improving accuracy on many NLP tasks. On the other hand,\ntraditional machine translation has a long history of leveraging unlabeled data\nthrough noisy channel modeling. The same idea has recently been shown to\nachieve strong improvements for neural machine translation. Unfortunately,\nna\\\"{i}ve noisy channel modeling with modern sequence to sequence models is up\nto an order of magnitude slower than alternatives. We address this issue by\nintroducing efficient approximations to make inference with the noisy channel\napproach as fast as strong ensembles while increasing accuracy. We also show\nthat the noisy channel approach can outperform strong pre-training results by\nachieving a new state of the art on WMT Romanian-English translation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 23:22:28 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bhosale", "Shruti", ""], ["Yee", "Kyra", ""], ["Edunov", "Sergey", ""], ["Auli", "Michael", ""]]}, {"id": "2011.07208", "submitter": "Md Tahmid Rahman Laskar", "authors": "Md Tahmid Rahman Laskar, Enamul Hoque, Jimmy Xiangji Huang", "title": "Utilizing Bidirectional Encoder Representations from Transformers for\n  Answer Selection", "comments": "Accepted to the AMMCS 2019 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training a transformer-based model for the language modeling task in a\nlarge dataset and then fine-tuning it for downstream tasks has been found very\nuseful in recent years. One major advantage of such pre-trained language models\nis that they can effectively absorb the context of each word in a sentence.\nHowever, for tasks such as the answer selection task, the pre-trained language\nmodels have not been extensively used yet. To investigate their effectiveness\nin such tasks, in this paper, we adopt the pre-trained Bidirectional Encoder\nRepresentations from Transformer (BERT) language model and fine-tune it on two\nQuestion Answering (QA) datasets and three Community Question Answering (CQA)\ndatasets for the answer selection task. We find that fine-tuning the BERT model\nfor the answer selection task is very effective and observe a maximum\nimprovement of 13.1% in the QA datasets and 18.7% in the CQA datasets compared\nto the previous state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 03:15:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Laskar", "Md Tahmid Rahman", ""], ["Hoque", "Enamul", ""], ["Huang", "Jimmy Xiangji", ""]]}, {"id": "2011.07247", "submitter": "Severin Laicher", "authors": "Severin Laicher, Gioia Baldissin, Enrique Casta\\~neda, Dominik\n  Schlechtweg, Sabine Schulte im Walde", "title": "CL-IMS @ DIACR-Ita: Volente o Nolente: BERT does not outperform SGNS on\n  Semantic Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the results of our participation in the DIACR-Ita shared task on\nlexical semantic change detection for Italian. We exploit Average Pairwise\nDistance of token-based BERT embeddings between time points and rank 5 (of 8)\nin the official ranking with an accuracy of $.72$. While we tune parameters on\nthe English data set of SemEval-2020 Task 1 and reach high performance, this\ndoes not translate to the Italian DIACR-Ita data set. Our results show that we\ndo not manage to find robust ways to exploit BERT embeddings in lexical\nsemantic change detection.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 09:50:35 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 10:11:03 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Laicher", "Severin", ""], ["Baldissin", "Gioia", ""], ["Casta\u00f1eda", "Enrique", ""], ["Schlechtweg", "Dominik", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "2011.07251", "submitter": "Allen Roush", "authors": "Allen Roush and Arvind Balaji", "title": "DebateSum: A large-scale argument mining and summarization dataset", "comments": "Accepted for oral presentation at the 7th Workshop on Argument Mining\n  (ARGMIN 2020) held at The 28th International Conference on Computational\n  Linguistics (COLING 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior work in Argument Mining frequently alludes to its potential\napplications in automatic debating systems. Despite this focus, almost no\ndatasets or models exist which apply natural language processing techniques to\nproblems found within competitive formal debate. To remedy this, we present the\nDebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with\ncorresponding argument and extractive summaries. DebateSum was made using data\ncompiled by competitors within the National Speech and Debate Association over\na 7-year period. We train several transformer summarization models to benchmark\nsummarization performance on DebateSum. We also introduce a set of fasttext\nword-vectors trained on DebateSum called debate2vec. Finally, we present a\nsearch engine for this dataset which is utilized extensively by members of the\nNational Speech and Debate Association today. The DebateSum search engine is\navailable to the public here: http://www.debate.cards\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 10:06:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Roush", "Allen", ""], ["Balaji", "Arvind", ""]]}, {"id": "2011.07280", "submitter": "Piyumal Demotte", "authors": "Lahiru Senevirathne, Piyumal Demotte, Binod Karunanayake, Udyogi\n  Munasinghe, Surangika Ranathunga", "title": "Sentiment Analysis for Sinhala Language using Deep Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the high impact of the fast-evolving fields of machine learning and\ndeep learning, Natural Language Processing (NLP) tasks have further obtained\ncomprehensive performances for highly resourced languages such as English and\nChinese. However Sinhala, which is an under-resourced language with a rich\nmorphology, has not experienced these advancements. For sentiment analysis,\nthere exists only two previous research with deep learning approaches, which\nfocused only on document-level sentiment analysis for the binary case. They\nexperimented with only three types of deep learning models. In contrast, this\npaper presents a much comprehensive study on the use of standard sequence\nmodels such as RNN, LSTM, Bi-LSTM, as well as more recent state-of-the-art\nmodels such as hierarchical attention hybrid neural networks, and capsule\nnetworks. Classification is done at document-level but with more granularity by\nconsidering POSITIVE, NEGATIVE, NEUTRAL, and CONFLICT classes. A data set of\n15059 Sinhala news comments, annotated with these four classes and a corpus\nconsists of 9.48 million tokens are publicly released. This is the largest\nsentiment annotated data set for Sinhala so far.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 12:02:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Senevirathne", "Lahiru", ""], ["Demotte", "Piyumal", ""], ["Karunanayake", "Binod", ""], ["Munasinghe", "Udyogi", ""], ["Ranathunga", "Surangika", ""]]}, {"id": "2011.07307", "submitter": "Shen Gao", "authors": "Shen Gao, Xiuying Chen, Zhaochun Ren, Dongyan Zhao and Rui Yan", "title": "Meaningful Answer Generation of E-Commerce Question-Answering", "comments": "Accepted By TOIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In e-commerce portals, generating answers for product-related questions has\nbecome a crucial task. In this paper, we focus on the task of product-aware\nanswer generation, which learns to generate an accurate and complete answer\nfrom large-scale unlabeled e-commerce reviews and product attributes. However,\nsafe answer problems pose significant challenges to text generation tasks, and\ne-commerce question-answering task is no exception. To generate more meaningful\nanswers, in this paper, we propose a novel generative neural model, called the\nMeaningful Product Answer Generator (MPAG), which alleviates the safe answer\nproblem by taking product reviews, product attributes, and a prototype answer\ninto consideration. Product reviews and product attributes are used to provide\nmeaningful content, while the prototype answer can yield a more diverse answer\npattern. To this end, we propose a novel answer generator with a review\nreasoning module and a prototype answer reader. Our key idea is to obtain the\ncorrect question-aware information from a large scale collection of reviews and\nlearn how to write a coherent and meaningful answer from an existing prototype\nanswer. To be more specific, we propose a read-and-write memory consisting of\nselective writing units to conduct reasoning among these reviews. We then\nemploy a prototype reader consisting of comprehensive matching to extract the\nanswer skeleton from the prototype answer. Finally, we propose an answer editor\nto generate the final answer by taking the question and the above parts as\ninput. Conducted on a real-world dataset collected from an e-commerce platform,\nextensive experimental results show that our model achieves state-of-the-art\nperformance in terms of both automatic metrics and human evaluations. Human\nevaluation also demonstrates that our model can consistently generate specific\nand proper answers.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 14:05:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gao", "Shen", ""], ["Chen", "Xiuying", ""], ["Ren", "Zhaochun", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2011.07347", "submitter": "Cheng-I Lai", "authors": "Fan-Keng Sun, Cheng-I Lai", "title": "Conditioned Natural Language Generation using only Unconditioned\n  Language Model: An Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transformer-based language models have shown to be very powerful for natural\nlanguage generation (NLG). However, text generation conditioned on some user\ninputs, such as topics or attributes, is non-trivial. Past approach relies on\neither modifying the original LM architecture, re-training the LM on corpora\nwith attribute labels, or having separately trained `guidance models' to guide\ntext generation in decoding. We argued that the above approaches are not\nnecessary, and the original unconditioned LM is sufficient for conditioned NLG.\nWe evaluated our approaches by the samples' fluency and diversity with\nautomated and human evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 17:45:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sun", "Fan-Keng", ""], ["Lai", "Cheng-I", ""]]}, {"id": "2011.07384", "submitter": "Valts Blukis", "authors": "Valts Blukis, Ross A. Knepper, Yoav Artzi", "title": "Few-shot Object Grounding and Mapping for Natural Language Robot\n  Instruction Following", "comments": "4th Conference on Robot Learning (CoRL 2020), Cambridge MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a robot policy to follow natural language\ninstructions that can be easily extended to reason about new objects. We\nintroduce a few-shot language-conditioned object grounding method trained from\naugmented reality data that uses exemplars to identify objects and align them\nto their mentions in instructions. We present a learned map representation that\nencodes object locations and their instructed use, and construct it from our\nfew-shot grounding output. We integrate this mapping approach into an\ninstruction-following policy, thereby allowing it to reason about previously\nunseen objects at test-time by simply adding exemplars. We evaluate on the task\nof learning to map raw observations and instructions to continuous control of a\nphysical quadcopter. Our approach significantly outperforms the prior state of\nthe art in the presence of new objects, even when the prior approach observes\nall objects during training.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 20:35:20 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Blukis", "Valts", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "2011.07389", "submitter": "Marco Del Tredici", "authors": "Marco Del Tredici and Raquel Fern\\'andez", "title": "Words are the Window to the Soul: Language-based User Representations\n  for Fake News Detection", "comments": "9 pages, accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cognitive and social traits of individuals are reflected in language use.\nMoreover, individuals who are prone to spread fake news online often share\ncommon traits. Building on these ideas, we introduce a model that creates\nrepresentations of individuals on social media based only on the language they\nproduce, and use them to detect fake news. We show that language-based user\nrepresentations are beneficial for this task. We also present an extended\nanalysis of the language of fake news spreaders, showing that its main features\nare mostly domain independent and consistent across two English datasets.\nFinally, we exploit the relation between language use and connections in the\nsocial graph to assess the presence of the Echo Chamber effect in our data.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:14:17 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Del Tredici", "Marco", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "2011.07398", "submitter": "Guanyi Chen", "authors": "Guanyi Chen, Kees van Deemter", "title": "Lessons from Computational Modelling of Reference Production in Mandarin\n  and English", "comments": "Long paper accepted at INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Referring expression generation (REG) algorithms offer computational models\nof the production of referring expressions. In earlier work, a corpus of\nreferring expressions (REs) in Mandarin was introduced. In the present paper,\nwe annotate this corpus, evaluate classic REG algorithms on it, and compare the\nresults with earlier results on the evaluation of REG for English referring\nexpressions. Next, we offer an in-depth analysis of the corpus, focusing on\nissues that arise from the grammar of Mandarin. We discuss shortcomings of\nprevious REG evaluations that came to light during our investigation and we\nhighlight some surprising results. Perhaps most strikingly, we found a much\nhigher proportion of under-specified expressions than previous studies had\nsuggested, not just in Mandarin but in English as well.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:55:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chen", "Guanyi", ""], ["van Deemter", "Kees", ""]]}, {"id": "2011.07403", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin, Bashir Shehu Galadanci, Abubakar Isa, Ismaila Idris\n  Sinan", "title": "A Hybrid Approach for Improved Low Resource Neural Machine Translation\n  using Monolingual Data", "comments": "14 pages, 4 figures, 9 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many language pairs are low resource, meaning the amount and/or quality of\navailable parallel data is not sufficient to train a neural machine translation\n(NMT) model which can reach an acceptable standard of accuracy. Many works have\nexplored using the readily available monolingual data in either or both of the\nlanguages to improve the standard of translation models in low, and even high,\nresource languages. One of the most successful of such works is the\nback-translation that utilizes the translations of the target language\nmonolingual data to increase the amount of the training data. The quality of\nthe backward model which is trained on the available parallel data has been\nshown to determine the performance of the back-translation approach. Despite\nthis, only the forward model is improved on the monolingual target data in\nstandard back-translation. A previous study proposed an iterative\nback-translation approach for improving both models over several iterations.\nBut unlike in the traditional back-translation, it relied on both the target\nand source monolingual data. This work, therefore, proposes a novel approach\nthat enables both the backward and forward models to benefit from the\nmonolingual target data through a hybrid of self-learning and back-translation\nrespectively. Experimental results have shown the superiority of the proposed\napproach over the traditional back-translation method on English-German low\nresource neural machine translation. We also proposed an iterative\nself-learning approach that outperforms the iterative back-translation while\nalso relying only on the monolingual target data and require the training of\nless models.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 22:18:45 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 15:44:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""], ["Isa", "Abubakar", ""], ["Sinan", "Ismaila Idris", ""]]}, {"id": "2011.07432", "submitter": "Jiayi Liu", "authors": "Wei Wei, Jiayi Liu, Xianling Mao, Guibin Guo, Feida Zhu, Pan Zhou,\n  Yuchong Hu and Shanshan Feng", "title": "Target Guided Emotion Aware Chat Machine", "comments": "To appear on TOIS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The consistency of a response to a given post at semantic-level and\nemotional-level is essential for a dialogue system to deliver human-like\ninteractions. However, this challenge is not well addressed in the literature,\nsince most of the approaches neglect the emotional information conveyed by a\npost while generating responses. This article addresses this problem by\nproposing a unifed end-to-end neural architecture, which is capable of\nsimultaneously encoding the semantics and the emotions in a post and leverage\ntarget information for generating more intelligent responses with appropriately\nexpressed emotions. Extensive experiments on real-world data demonstrate that\nthe proposed method outperforms the state-of-the-art methods in terms of both\ncontent coherence and emotion appropriateness.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 01:55:37 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 07:36:47 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Wei", "Wei", ""], ["Liu", "Jiayi", ""], ["Mao", "Xianling", ""], ["Guo", "Guibin", ""], ["Zhu", "Feida", ""], ["Zhou", "Pan", ""], ["Hu", "Yuchong", ""], ["Feng", "Shanshan", ""]]}, {"id": "2011.07497", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra", "title": "Generating Negative Commonsense Knowledge", "comments": "Preprint, ongoing work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acquisition of commonsense knowledge is an important open challenge in\nartificial intelligence. In this work-in-progress paper, we study the task of\nautomatically augmenting commonsense knowledge bases (KBs) with novel\nstatements. We show empirically that obtaining meaningful negative samples for\nthe completion task is nontrivial, and propose NegatER, a framework for\ngenerating negative commonsense knowledge, to address this challenge. In our\nevaluation we demonstrate the intrinsic value and extrinsic utility of the\nknowledge generated by NegatER, opening up new avenues for future research in\nthis direction.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:55:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""]]}, {"id": "2011.07593", "submitter": "Paula Czarnowska", "authors": "Paula Czarnowska, Sebastian Ruder, Ryan Cotterell, Ann Copestake", "title": "Morphologically Aware Word-Level Translation", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel morphologically aware probability model for bilingual\nlexicon induction, which jointly models lexeme translation and inflectional\nmorphology in a structured way. Our model exploits the basic linguistic\nintuition that the lexeme is the key lexical unit of meaning, while\ninflectional morphology provides additional syntactic information. This\napproach leads to substantial performance improvements - 19% average\nimprovement in accuracy across 6 language pairs over the state of the art in\nthe supervised setting and 16% in the weakly supervised setting. As another\ncontribution, we highlight issues associated with modern BLI that stem from\nignoring inflectional morphology, and propose three suggestions for improving\nthe task.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 17:54:49 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Czarnowska", "Paula", ""], ["Ruder", "Sebastian", ""], ["Cotterell", "Ryan", ""], ["Copestake", "Ann", ""]]}, {"id": "2011.07605", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "The Challenge of Diacritics in Yoruba Embeddings", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The major contributions of this work include the empirical establishment of a\nbetter performance for Yoruba embeddings from undiacritized (normalized)\ndataset and provision of new analogy sets for evaluation. The Yoruba language,\nbeing a tonal language, utilizes diacritics (tonal marks) in written form. We\nshow that this affects embedding performance by creating embeddings from\nexactly the same Wikipedia dataset but with the second one normalized to be\nundiacritized. We further compare average intrinsic performance with two other\nwork (using analogy test set & WordSim) and we obtain the best performance in\nWordSim and corresponding Spearman correlation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:02:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2011.07635", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Han Guo, Mohit Bansal", "title": "DORB: Dynamically Optimizing Multiple Rewards with Bandits", "comments": "EMNLP 2020 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradients-based reinforcement learning has proven to be a promising\napproach for directly optimizing non-differentiable evaluation metrics for\nlanguage generation tasks. However, optimizing for a specific metric reward\nleads to improvements in mostly that metric only, suggesting that the model is\ngaming the formulation of that metric in a particular way without often\nachieving real qualitative improvements. Hence, it is more beneficial to make\nthe model optimize multiple diverse metric rewards jointly. While appealing,\nthis is challenging because one needs to manually decide the importance and\nscaling weights of these metric rewards. Further, it is important to consider\nusing a dynamic combination and curriculum of metric rewards that flexibly\nchanges over time. Considering the above aspects, in our work, we automate the\noptimization of multiple metric rewards simultaneously via a multi-armed bandit\napproach (DORB), where at each round, the bandit chooses which metric reward to\noptimize next, based on expected arm gains. We use the Exp3 algorithm for\nbandits and formulate two approaches for bandit rewards: (1) Single\nMulti-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit\n(HM-Bandit). We empirically show the effectiveness of our approaches via\nvarious automatic metrics and human evaluation on two important NLG tasks:\nquestion generation and data-to-text generation, including on an unseen-test\ntransfer setup. Finally, we present interpretable analyses of the learned\nbandit curriculum over the optimized rewards.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 21:57:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Guo", "Han", ""], ["Bansal", "Mohit", ""]]}, {"id": "2011.07636", "submitter": "Amanpreet Singh", "authors": "Amanpreet Singh, Niranjan Balasubramanian", "title": "Open4Business(O4B): An Open Access Dataset for Summarizing Business\n  Documents", "comments": "7 pages, 3 figures, accepted in Workshop on Dataset Curation and\n  Security-NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major challenge in fine-tuning deep learning models for automatic\nsummarization is the need for large domain specific datasets. One of the\nbarriers to curating such data from resources like online publications is\nnavigating the license regulations applicable to their re-use, especially for\ncommercial purposes. As a result, despite the availability of several business\njournals there are no large scale datasets for summarizing business documents.\nIn this work, we introduce Open4Business(O4B),a dataset of 17,458 open access\nbusiness articles and their reference summaries. The dataset introduces a new\nchallenge for summarization in the business domain, requiring highly\nabstractive and more concise summaries as compared to other existing datasets.\nAdditionally, we evaluate existing models on it and consequently show that\nmodels trained on O4B and a 7x larger non-open access dataset achieve\ncomparable performance on summarization. We release the dataset, along with the\ncode which can be leveraged to similarly gather data for multiple domains.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 22:00:07 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 21:50:18 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 21:19:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Singh", "Amanpreet", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "2011.07658", "submitter": "Lukun Zheng", "authors": "Chandra Kundu, Lukun Zheng", "title": "Deep multi-modal networks for book genre classification based on its\n  cover", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Book covers are usually the very first impression to its readers and they\noften convey important information about the content of the book. Book genre\nclassification based on its cover would be utterly beneficial to many modern\nretrieval systems, considering that the complete digitization of books is an\nextremely expensive task. At the same time, it is also an extremely challenging\ntask due to the following reasons: First, there exists a wide variety of book\ngenres, many of which are not concretely defined. Second, book covers, as\ngraphic designs, vary in many different ways such as colors, styles, textual\ninformation, etc, even for books of the same genre. Third, book cover designs\nmay vary due to many external factors such as country, culture, target reader\npopulations, etc. With the growing competitiveness in the book industry, the\nbook cover designers and typographers push the cover designs to its limit in\nthe hope of attracting sales. The cover-based book classification systems\nbecome a particularly exciting research topic in recent years. In this paper,\nwe propose a multi-modal deep learning framework to solve this problem. The\ncontribution of this paper is four-fold. First, our method adds an extra\nmodality by extracting texts automatically from the book covers. Second,\nimage-based and text-based, state-of-the-art models are evaluated thoroughly\nfor the task of book cover classification. Third, we develop an efficient and\nsalable multi-modal framework based on the images and texts shown on the covers\nonly. Fourth, a thorough analysis of the experimental results is given and\nfuture works to improve the performance is suggested. The results show that the\nmulti-modal framework significantly outperforms the current state-of-the-art\nimage-based models. However, more efforts and resources are needed for this\nclassification task in order to reach a satisfactory level.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 23:27:43 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kundu", "Chandra", ""], ["Zheng", "Lukun", ""]]}, {"id": "2011.07660", "submitter": "Hyounghun Kim", "authors": "Hyounghun Kim, Abhay Zala, Graham Burri, Hao Tan, Mohit Bansal", "title": "ArraMon: A Joint Navigation-Assembly Instruction Interpretation Task in\n  Dynamic Environments", "comments": "EMNLP Findings 2020 (18 pages; extended to Hindi)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For embodied agents, navigation is an important ability but not an isolated\ngoal. Agents are also expected to perform specific tasks after reaching the\ntarget location, such as picking up objects and assembling them into a\nparticular arrangement. We combine Vision-and-Language Navigation, assembling\nof collected objects, and object referring expression comprehension, to create\na novel joint navigation-and-assembly task, named ArraMon. During this task,\nthe agent (similar to a PokeMON GO player) is asked to find and collect\ndifferent target objects one-by-one by navigating based on natural language\ninstructions in a complex, realistic outdoor environment, but then also ARRAnge\nthe collected objects part-by-part in an egocentric grid-layout environment. To\nsupport this task, we implement a 3D dynamic environment simulator and collect\na dataset (in English; and also extended to Hindi) with human-written\nnavigation and assembling instructions, and the corresponding ground truth\ntrajectories. We also filter the collected instructions via a verification\nstage, leading to a total of 7.7K task instances (30.8K instructions and\npaths). We present results for several baseline models (integrated and biased)\nand metrics (nDTW, CTC, rPOD, and PTC), and the large model-human performance\ngap demonstrates that our task is challenging and presents a wide scope for\nfuture work. Our dataset, simulator, and code are publicly available at:\nhttps://arramonunc.github.io\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 23:30:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kim", "Hyounghun", ""], ["Zala", "Abhay", ""], ["Burri", "Graham", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2011.07661", "submitter": "Luca Parisi", "authors": "Luca Parisi, Renfei Ma, Narrendar RaviChandran and Matteo Lanzillotta", "title": "hyper-sinh: An Accurate and Reliable Function from Shallow to Deep\n  Learning in TensorFlow and Keras", "comments": "19 pages, 6 listings/Python code snippets, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the 'hyper-sinh', a variation of the m-arcsinh activation\nfunction suitable for Deep Learning (DL)-based algorithms for supervised\nlearning, such as Convolutional Neural Networks (CNN). hyper-sinh, developed in\nthe open source Python libraries TensorFlow and Keras, is thus described and\nvalidated as an accurate and reliable activation function for both shallow and\ndeep neural networks. Improvements in accuracy and reliability in image and\ntext classification tasks on five (N = 5) benchmark data sets available from\nKeras are discussed. Experimental results demonstrate the overall competitive\nclassification performance of both shallow and deep neural networks, obtained\nvia this novel function. This function is evaluated with respect to gold\nstandard activation functions, demonstrating its overall competitive accuracy\nand reliability for both image and text classification.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 23:38:59 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Parisi", "Luca", ""], ["Ma", "Renfei", ""], ["RaviChandran", "Narrendar", ""], ["Lanzillotta", "Matteo", ""]]}, {"id": "2011.07670", "submitter": "Arka Mitra", "authors": "Arka Mitra, Harshvardhan Srivastava, Yugam Tiwari", "title": "IIT_kgp at FinCausal 2020, Shared Task 1: Causality Detection using\n  Sentence Embeddings in Financial Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the work that the team submitted to FinCausal 2020 Shared\nTask. This work is associated with the first sub-task of identifying causality\nin sentences. The various models used in the experiments tried to obtain a\nlatent space representation for each of the sentences. Linear regression was\nperformed on these representations to classify whether the sentence is causal\nor not. The experiments have shown BERT (Large) performed the best, giving a F1\nscore of 0.958, in the task of detecting the causality of sentences in\nfinancial texts and reports. The class imbalance was dealt with a modified loss\nfunction to give a better metric score for the evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 00:57:14 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mitra", "Arka", ""], ["Srivastava", "Harshvardhan", ""], ["Tiwari", "Yugam", ""]]}, {"id": "2011.07680", "submitter": "Wenting Xu", "authors": "Wenting Xu, Chang Qi, Zhenghua Xu and Thomas Lukasiewicz", "title": "Reinforced Medical Report Generation with X-Linear Attention and\n  Repetition Penalty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To reduce doctors' workload, deep-learning-based automatic medical report\ngeneration has recently attracted more and more research efforts, where\nattention mechanisms and reinforcement learning are integrated with the classic\nencoder-decoder architecture to enhance the performance of deep models.\nHowever, these state-of-the-art solutions mainly suffer from two shortcomings:\n(i) their attention mechanisms cannot utilize high-order feature interactions,\nand (ii) due to the use of TF-IDF-based reward functions, these methods are\nfragile with generating repeated terms. Therefore, in this work, we propose a\nreinforced medical report generation solution with x-linear attention and\nrepetition penalty mechanisms (ReMRG-XR) to overcome these problems.\nSpecifically, x-linear attention modules are used to explore high-order feature\ninteractions and achieve multi-modal reasoning, while repetition penalty is\nused to apply penalties to repeated terms during the model's training process.\nExtensive experimental studies have been conducted on two public datasets, and\nthe results show that ReMRG-XR greatly outperforms the state-of-the-art\nbaselines in terms of all metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:44:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Xu", "Wenting", ""], ["Qi", "Chang", ""], ["Xu", "Zhenghua", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2011.07743", "submitter": "Yu Gu", "authors": "Yu Gu, Sue Kase, Michelle Vanni, Brian Sadler, Percy Liang, Xifeng\n  Yan, Yu Su", "title": "Beyond I.I.D.: Three Levels of Generalization for Question Answering on\n  Knowledge Bases", "comments": "Accepted to TheWebConf 2021 (previously WWW)", "journal-ref": null, "doi": "10.1145/3442381.3449992", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing studies on question answering on knowledge bases (KBQA) mainly\noperate with the standard i.i.d assumption, i.e., training distribution over\nquestions is the same as the test distribution. However, i.i.d may be neither\nreasonably achievable nor desirable on large-scale KBs because 1) true user\ndistribution is hard to capture and 2) randomly sample training examples from\nthe enormous space would be highly data-inefficient. Instead, we suggest that\nKBQA models should have three levels of built-in generalization: i.i.d,\ncompositional, and zero-shot. To facilitate the development of KBQA models with\nstronger generalization, we construct and release a new large-scale,\nhigh-quality dataset with 64,331 questions, GrailQA, and provide evaluation\nsettings for all three levels of generalization. In addition, we propose a\nnovel BERT-based KBQA model. The combination of our dataset and model enables\nus to thoroughly examine and demonstrate, for the first time, the key role of\npre-trained contextual embeddings like BERT in the generalization of KBQA.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:36:26 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 03:36:38 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 03:13:37 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 18:48:38 GMT"}, {"version": "v5", "created": "Fri, 19 Feb 2021 04:11:23 GMT"}, {"version": "v6", "created": "Mon, 22 Feb 2021 19:04:45 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gu", "Yu", ""], ["Kase", "Sue", ""], ["Vanni", "Michelle", ""], ["Sadler", "Brian", ""], ["Liang", "Percy", ""], ["Yan", "Xifeng", ""], ["Su", "Yu", ""]]}, {"id": "2011.07754", "submitter": "Duc Le", "authors": "Duc Le, Gil Keren, Julian Chan, Jay Mahadeokar, Christian Fuegen,\n  Michael L. Seltzer", "title": "Deep Shallow Fusion for RNN-T Personalization", "comments": "To appear at SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models in general, and Recurrent Neural Network Transducer (RNN-T)\nin particular, have gained significant traction in the automatic speech\nrecognition community in the last few years due to their simplicity,\ncompactness, and excellent performance on generic transcription tasks. However,\nthese models are more challenging to personalize compared to traditional hybrid\nsystems due to the lack of external language models and difficulties in\nrecognizing rare long-tail words, specifically entity names. In this work, we\npresent novel techniques to improve RNN-T's ability to model rare WordPieces,\ninfuse extra information into the encoder, enable the use of alternative\ngraphemic pronunciations, and perform deep fusion with personalized language\nmodels for more robust biasing. We show that these combined techniques result\nin 15.4%-34.5% relative Word Error Rate improvement compared to a strong RNN-T\nbaseline which uses shallow fusion and text-to-speech augmentation. Our work\nhelps push the boundary of RNN-T personalization and close the gap with hybrid\nsystems on use cases where biasing and entity recognition are crucial.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 07:13:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Le", "Duc", ""], ["Keren", "Gil", ""], ["Chan", "Julian", ""], ["Mahadeokar", "Jay", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "2011.07832", "submitter": "Hiroaki Hayashi", "authors": "Hiroaki Hayashi, Prashant Budania, Peng Wang, Chris Ackerson, Raj\n  Neervannan, Graham Neubig", "title": "WikiAsp: A Dataset for Multi-domain Aspect-based Summarization", "comments": "Transaction of the ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based summarization is the task of generating focused summaries based\non specific points of interest. Such summaries aid efficient analysis of text,\nsuch as quickly understanding reviews or opinions from different angles.\nHowever, due to large differences in the type of aspects for different domains\n(e.g., sentiment, product features), the development of previous models has\ntended to be domain-specific. In this paper, we propose WikiAsp, a large-scale\ndataset for multi-domain aspect-based summarization that attempts to spur\nresearch in the direction of open-domain aspect-based summarization.\nSpecifically, we build the dataset using Wikipedia articles from 20 different\ndomains, using the section titles and boundaries of each article as a proxy for\naspect annotation. We propose several straightforward baseline models for this\ntask and conduct experiments on the dataset. Results highlight key challenges\nthat existing summarization models face in this setting, such as proper pronoun\nhandling of quoted sources and consistent explanation of time-sensitive events.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:02:52 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hayashi", "Hiroaki", ""], ["Budania", "Prashant", ""], ["Wang", "Peng", ""], ["Ackerson", "Chris", ""], ["Neervannan", "Raj", ""], ["Neubig", "Graham", ""]]}, {"id": "2011.07868", "submitter": "Kairit Sirts", "authors": "Kairit Sirts and Kairit Peekman", "title": "Evaluating Sentence Segmentation and Word Tokenization Systems on\n  Estonian Web Texts", "comments": "BalticHLT2020", "journal-ref": null, "doi": "10.3233/FAIA200620", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texts obtained from web are noisy and do not necessarily follow the\northographic sentence and word boundary rules. Thus, sentence segmentation and\nword tokenization systems that have been developed on well-formed texts might\nnot perform so well on unedited web texts. In this paper, we first describe the\nmanual annotation of sentence boundaries of an Estonian web dataset and then\npresent the evaluation results of three existing sentence segmentation and word\ntokenization systems on this corpus: EstNLTK, Stanza and UDPipe. While EstNLTK\nobtains the highest performance compared to other systems on sentence\nsegmentation on this dataset, the sentence segmentation performance of Stanza\nand UDPipe remains well below the results obtained on the more well-formed\nEstonian UD test set.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:13:41 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sirts", "Kairit", ""], ["Peekman", "Kairit", ""]]}, {"id": "2011.07916", "submitter": "Jingjing Gong", "authors": "Jingjing Gong, Hang Yan, Yining Zheng, Xipeng Qiu and Xuanjing Huang", "title": "Text Information Aggregation with Centrality Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of natural language processing problems need to encode the text\nsequence as a fix-length vector, which usually involves aggregation process of\ncombining the representations of all the words, such as pooling or\nself-attention. However, these widely used aggregation approaches did not take\nhigher-order relationship among the words into consideration. Hence we propose\na new way of obtaining aggregation weights, called eigen-centrality\nself-attention. More specifically, we build a fully-connected graph for all the\nwords in a sentence, then compute the eigen-centrality as the attention score\nof each word.\n  The explicit modeling of relationships as a graph is able to capture some\nhigher-order dependency among words, which helps us achieve better results in 5\ntext classification tasks and one SNLI task than baseline models such as\npooling, self-attention and dynamic routing. Besides, in order to compute the\ndominant eigenvector of the graph, we adopt power method algorithm to get the\neigen-centrality measure. Moreover, we also derive an iterative approach to get\nthe gradient for the power method process to reduce both memory consumption and\ncomputation requirement.}\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:08:48 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gong", "Jingjing", ""], ["Yan", "Hang", ""], ["Zheng", "Yining", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2011.07933", "submitter": "Muhammad ElNokrashy", "authors": "Muhammad N. ElNokrashy, Amr Hendy, Mohamed Abdelghaffar, Mohamed\n  Afify, Ahmed Tawfik and Hany Hassan Awadalla", "title": "Score Combination for Improved Parallel Corpus Filtering for Low\n  Resource Conditions", "comments": "Accepted at WMT20 (EMNLP 2020 Fifth Conference on Machine\n  Translation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our submission to the WMT20 sentence filtering task. We\ncombine scores from (1) a custom LASER built for each source language, (2) a\nclassifier built to distinguish positive and negative pairs by semantic\nalignment, and (3) the original scores included in the task devkit. For the\nmBART finetuning setup, provided by the organizers, our method shows 7% and 5%\nrelative improvement over baseline, in sacreBLEU score on the test set for\nPashto and Khmer respectively.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:31:33 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["ElNokrashy", "Muhammad N.", ""], ["Hendy", "Amr", ""], ["Abdelghaffar", "Mohamed", ""], ["Afify", "Mohamed", ""], ["Tawfik", "Ahmed", ""], ["Awadalla", "Hany Hassan", ""]]}, {"id": "2011.07956", "submitter": "Dong-Ho Lee", "authors": "Wangchunshu Zhou, Dong-Ho Lee, Ravi Kiran Selvam, Seyeon Lee, Bill\n  Yuchen Lin, Xiang Ren", "title": "Pre-training Text-to-Text Transformers for Concept-centric Common Sense", "comments": "15 pages, 4 figures. Code and Data: https://github.com/INK-USC/CALM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (PTLM) have achieved impressive results in a\nrange of natural language understanding (NLU) and generation (NLG) tasks.\nHowever, current pre-training objectives such as masked token prediction (for\nBERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not\nexplicitly model the relational commonsense knowledge about everyday concepts,\nwhich is crucial to many downstream tasks that need common sense to understand\nor generate. To augment PTLMs with concept-centric commonsense knowledge, in\nthis paper, we propose both generative and contrastive objectives for learning\ncommon sense from the text, and use them as intermediate self-supervised\nlearning tasks for incrementally pre-training PTLMs (before task-specific\nfine-tuning on downstream datasets). Furthermore, we develop a joint\npre-training framework to unify generative and contrastive objectives so that\nthey can mutually reinforce each other. Extensive experimental results show\nthat our method, concept-aware language model (CALM), can pack more commonsense\nknowledge into the parameters of a pre-trained text-to-text transformer without\nrelying on external knowledge graphs, yielding better performance on both NLU\nand NLG tasks. We show that while only incrementally pre-trained on a\nrelatively small corpus for a few steps, CALM outperforms baseline methods by a\nconsistent margin and even comparable with some larger PTLMs, which suggests\nthat CALM can serve as a general, plug-and-play method for improving the\ncommonsense reasoning ability of a PTLM.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 07:00:37 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 04:53:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Lee", "Dong-Ho", ""], ["Selvam", "Ravi Kiran", ""], ["Lee", "Seyeon", ""], ["Lin", "Bill Yuchen", ""], ["Ren", "Xiang", ""]]}, {"id": "2011.07959", "submitter": "Rahul Yedida", "authors": "Rahul Yedida, Saad Mohammad Abrar, Cleber Melo-Filho, Eugene Muratov,\n  Rada Chirkova, Alexander Tropsha", "title": "Text Mining to Identify and Extract Novel Disease Treatments From\n  Unstructured Datasets", "comments": "initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: We aim to learn potential novel cures for diseases from\nunstructured text sources. More specifically, we seek to extract drug-disease\npairs of potential cures to diseases by a simple reasoning over the structure\nof spoken text.\n  Materials and Methods: We use Google Cloud to transcribe podcast episodes of\nan NPR radio show. We then build a pipeline for systematically pre-processing\nthe text to ensure quality input to the core classification model, which feeds\nto a series of post-processing steps for obtaining filtered results. Our\nclassification model itself uses a language model pre-trained on PubMed text.\nThe modular nature of our pipeline allows for ease of future developments in\nthis area by substituting higher quality components at each stage of the\npipeline. As a validation measure, we use ROBOKOP, an engine over a medical\nknowledge graph with only validated pathways, as a ground truth source for\nchecking the existence of the proposed pairs. For the proposed pairs not found\nin ROBOKOP, we provide further verification using Chemotext.\n  Results: We found 30.4% of our proposed pairs in the ROBOKOP database. For\nexample, our model successfully identified that Omeprazole can help treat\nheartburn.We discuss the significance of this result, showing some examples of\nthe proposed pairs.\n  Discussion and Conclusion: The agreement of our results with the existing\nknowledge source indicates a step in the right direction. Given the\nplug-and-play nature of our framework, it is easy to add, remove, or modify\nparts to improve the model as necessary. We discuss the results showing some\nexamples, and note that this is a potentially new line of research that has\nfurther scope to be explored. Although our approach was originally oriented on\nradio podcast transcripts, it is input-agnostic and could be applied to any\nsource of textual data and to any problem of interest.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 19:52:49 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yedida", "Rahul", ""], ["Abrar", "Saad Mohammad", ""], ["Melo-Filho", "Cleber", ""], ["Muratov", "Eugene", ""], ["Chirkova", "Rada", ""], ["Tropsha", "Alexander", ""]]}, {"id": "2011.07960", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Alessandro Sordoni, Siva Reddy, Aaron\n  Courville", "title": "Explicitly Modeling Syntax in Language Models with Incremental Parsing\n  and a Dynamic Oracle", "comments": "12 pages, 10 figures", "journal-ref": "NAACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax is fundamental to our thinking about language. Failing to capture the\nstructure of input language could lead to generalization problems and\nover-parametrization. In the present work, we propose a new syntax-aware\nlanguage model: Syntactic Ordered Memory (SOM). The model explicitly models the\nstructure with an incremental parser and maintains the conditional probability\nsetting of a standard language model (left-to-right). To train the incremental\nparser and avoid exposure bias, we also propose a novel dynamic oracle, so that\nSOM is more robust to wrong parsing decisions. Experiments show that SOM can\nachieve strong results in language modeling, incremental parsing and syntactic\ngeneralization tests, while using fewer parameters than other models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:39:15 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 18:13:41 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Sordoni", "Alessandro", ""], ["Reddy", "Siva", ""], ["Courville", "Aaron", ""]]}, {"id": "2011.07961", "submitter": "Daniel Spokoyny", "authors": "Daniel Spokoyny, Taylor Berg-Kirkpatrick", "title": "An Empirical Investigation of Contextualized Number Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a large scale empirical investigation of contextualized number\nprediction in running text. Specifically, we consider two tasks: (1)masked\nnumber prediction-predicting a missing numerical value within a sentence, and\n(2)numerical anomaly detection-detecting an errorful numeric value within a\nsentence. We experiment with novel combinations of contextual encoders and\noutput distributions over the real number line. Specifically, we introduce a\nsuite of output distribution parameterizations that incorporate latent\nvariables to add expressivity and better fit the natural distribution of\nnumeric values in running text, and combine them with both recurrent and\ntransformer-based encoder architectures. We evaluate these models on two\nnumeric datasets in the financial and scientific domain. Our findings show that\noutput distributions that incorporate discrete latent variables and allow for\nmultiple modes outperform simple flow-based counterparts on all datasets,\nyielding more accurate numerical prediction and anomaly detection. We also show\nthat our models effectively utilize textual con-text and benefit from\ngeneral-purpose unsupervised pretraining.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 23:12:23 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Spokoyny", "Daniel", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2011.07962", "submitter": "William Hui", "authors": "William Hui", "title": "Performance of Transfer Learning Model vs. Traditional Neural Network in\n  Low System Resource Environment", "comments": "5 pages, testing result, feature engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the use of pre-trained model to build neural network based on\ntransfer learning methodology is increasingly popular. These pre-trained models\npresent the benefit of using less computing resources to train model with\nsmaller amount of training data. The rise of state-of-the-art models such as\nBERT, XLNet and GPT boost accuracy and benefit as a base model for transfer\nleanring. However, these models are still too complex and consume many\ncomputing resource to train for transfer learning with low GPU memory. We will\ncompare the performance and cost between lighter transfer learning model and\npurposely built neural network for NLP application of text classification and\nNER model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 08:12:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hui", "William", ""]]}, {"id": "2011.07964", "submitter": "Martin Hole\\v{c}ek", "authors": "Martin Hole\\v{c}ek", "title": "Learning from similarity and information extraction from structured\n  documents", "comments": "17 pages, 9 figures, manuscript for the IJDAR journal special issue\n  for ICDAR conference", "journal-ref": "Hole\\v{c}ek, M. 2021 Learning from similarity and information\n  extraction from structured documents; International Journal on Document\n  Analysis and Recognition (IJDAR) 2021/06/11", "doi": "10.1007/s10032-021-00375-3", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of document processing is gaining recent attention due to the\ngreat potential to reduce manual work through improved methods and hardware.\nNeural networks have been successfully applied before - even though they have\nbeen trained only on relatively small datasets with hundreds of documents so\nfar. To successfully explore deep learning techniques and improve the\ninformation extraction results, a dataset with more than twenty-five thousand\ndocuments has been compiled, anonymized and is published as a part of this\nwork. We will expand our previous work where we proved that convolutions, graph\nconvolutions and self-attention can work together and exploit all the\ninformation present in a structured document. Taking the fully trainable method\none step further, we will now design and examine various approaches to using\nsiamese networks, concepts of similarity, one-shot learning and context/memory\nawareness. The aim is to improve micro F1 of per-word classification on the\nhuge real-world document dataset. The results verify the hypothesis that\ntrainable access to a similar (yet still different) page together with its\nalready known target information improves the information extraction.\nFurthermore, the experiments confirm that all proposed architecture parts are\nall required to beat the previous results. The best model improves the previous\nstate-of-the-art results by an 8.25 gain in F1 score. Qualitative analysis is\nprovided to verify that the new model performs better for all target classes.\nAdditionally, multiple structural observations about the causes of the\nunderperformance of some architectures are revealed. All the source codes,\nparameters and implementation details are published together with the dataset\nin the hope to push the research boundaries since all the techniques used in\nthis work are not problem-specific and can be generalized for other tasks and\ncontexts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:34:52 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 21:36:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hole\u010dek", "Martin", ""]]}, {"id": "2011.07975", "submitter": "Albert Gatt", "authors": "Gaetana Ruggiero, Albert Gatt, Malvina Nissim", "title": "Datasets and Models for Authorship Attribution on Italian Personal\n  Writings", "comments": "Accepted for publication in: 7th Italian Conference on Computational\n  Linguistics (CLIC-IT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing research on Authorship Attribution (AA) focuses on texts for which a\nlot of data is available (e.g novels), mainly in English. We approach AA via\nAuthorship Verification on short Italian texts in two novel datasets, and\nanalyze the interaction between genre, topic, gender and length. Results show\nthat AV is feasible even with little data, but more evidence helps. Gender and\ntopic can be indicative clues, and if not controlled for, they might overtake\nmore specific aspects of personal style.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:11:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ruggiero", "Gaetana", ""], ["Gatt", "Albert", ""], ["Nissim", "Malvina", ""]]}, {"id": "2011.07990", "submitter": "Markus Schr\\\"oder", "authors": "Markus Schr\\\"oder, Christian Jilek, Michael Schulze, Andreas Dengel", "title": "The Person Index Challenge: Extraction of Persons from Messy, Short\n  Texts", "comments": "7 pages, accepted at ICAART 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When persons are mentioned in texts with their first name, last name and/or\nmiddle names, there can be a high variation which of their names are used, how\ntheir names are ordered and if their names are abbreviated. If multiple persons\nare mentioned consecutively in very different ways, especially short texts can\nbe perceived as \"messy\". Once ambiguous names occur, associations to persons\nmay not be inferred correctly. Despite these eventualities, in this paper we\nask how well an unsupervised algorithm can build a person index from short\ntexts. We define a person index as a structured table that distinctly catalogs\nindividuals by their names. First, we give a formal definition of the problem\nand describe a procedure to generate ground truth data for future evaluations.\nTo give a first solution to this challenge, a baseline approach is implemented.\nBy using our proposed evaluation strategy, we test the performance of the\nbaseline and suggest further improvements. For future research the source code\nis publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:36:42 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Schr\u00f6der", "Markus", ""], ["Jilek", "Christian", ""], ["Schulze", "Michael", ""], ["Dengel", "Andreas", ""]]}, {"id": "2011.07997", "submitter": "Jo\\~ao Rodrigues", "authors": "Ant\\'onio Branco, Jo\\~ao Rodrigues, Ma{\\l}gorzata Salawa, Ruben\n  Branco, Chakaveh Saedi", "title": "Comparative Probing of Lexical Semantics Theories for Cognitive\n  Plausibility and Technological Usefulness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Lexical semantics theories differ in advocating that the meaning of words is\nrepresented as an inference graph, a feature mapping or a vector space, thus\nraising the question: is it the case that one of these approaches is superior\nto the others in representing lexical semantics appropriately? Or in its non\nantagonistic counterpart: could there be a unified account of lexical semantics\nwhere these approaches seamlessly emerge as (partial) renderings of (different)\naspects of a core semantic knowledge base?\n  In this paper, we contribute to these research questions with a number of\nexperiments that systematically probe different lexical semantics theories for\ntheir levels of cognitive plausibility and of technological usefulness.\n  The empirical findings obtained from these experiments advance our insight on\nlexical semantics as the feature-based approach emerges as superior to the\nother ones, and arguably also move us closer to finding answers to the research\nquestions above.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:46:08 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Branco", "Ant\u00f3nio", ""], ["Rodrigues", "Jo\u00e3o", ""], ["Salawa", "Ma\u0142gorzata", ""], ["Branco", "Ruben", ""], ["Saedi", "Chakaveh", ""]]}, {"id": "2011.08021", "submitter": "Edward Raff", "authors": "Nisha Pillai, Edward Raff, Francis Ferraro, Cynthia Matuszek", "title": "Sampling Approach Matters: Active Learning for Robotic Language\n  Acquisition", "comments": "To appear in IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordering the selection of training data using active learning can lead to\nimprovements in learning efficiently from smaller corpora. We present an\nexploration of active learning approaches applied to three grounded language\nproblems of varying complexity in order to analyze what methods are suitable\nfor improving data efficiency in learning. We present a method for analyzing\nthe complexity of data in this joint problem space, and report on how\ncharacteristics of the underlying task, along with design decisions such as\nfeature selection and classification model, drive the results. We observe that\nrepresentativeness, along with diversity, is crucial in selecting data samples.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:18:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Pillai", "Nisha", ""], ["Raff", "Edward", ""], ["Ferraro", "Francis", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "2011.08035", "submitter": "Venelin Kovatchev", "authors": "Venelin Kovatchev, Phillip Smith, Mark Lee, Imogen Grumley Traynor,\n  Irene Luque Aguilera and Rory T. Devine", "title": "\"What is on your mind?\" Automated Scoring of Mindreading in Childhood\n  and Early Adolescence", "comments": "Accepted in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present the first work on the automated scoring of\nmindreading ability in middle childhood and early adolescence. We create\nMIND-CA, a new corpus of 11,311 question-answer pairs in English from 1,066\nchildren aged 7 to 14. We perform machine learning experiments and carry out\nextensive quantitative and qualitative evaluation. We obtain promising results,\ndemonstrating the applicability of state-of-the-art NLP solutions to a new\ndomain and task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:41:45 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kovatchev", "Venelin", ""], ["Smith", "Phillip", ""], ["Lee", "Mark", ""], ["Traynor", "Imogen Grumley", ""], ["Aguilera", "Irene Luque", ""], ["Devine", "Rory T.", ""]]}, {"id": "2011.08067", "submitter": "Bishal Santra", "authors": "Bishal Santra, Potnuru Anusha, Pawan Goyal", "title": "Hierarchical Transformer for Task Oriented Dialog Systems", "comments": "v3: Latest camera ready version; 10 pages; Codes:\n  https://github.com/bsantraigi/HIER ,\n  https://github.com/bsantraigi/hier-transformer-pytorch v2: To appear in NAACL\n  2021 (Long Paper) v1: preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for dialog systems have gained much interest because of the\nrecent success of RNN and Transformer based models in tasks like question\nanswering and summarization. Although the task of dialog response generation is\ngenerally seen as a sequence-to-sequence (Seq2Seq) problem, researchers in the\npast have found it challenging to train dialog systems using the standard\nSeq2Seq models. Therefore, to help the model learn meaningful utterance and\nconversation level features, Sordoni et al. (2015b); Serban et al. (2016)\nproposed Hierarchical RNN architecture, which was later adopted by several\nother RNN based dialog systems. With the transformer-based models dominating\nthe seq2seq problems lately, the natural question to ask is the applicability\nof the notion of hierarchy in transformer based dialog systems. In this paper,\nwe propose a generalized framework for Hierarchical Transformer Encoders and\nshow how a standard transformer can be morphed into any hierarchical encoder,\nincluding HRED and HIBERT like models, by using specially designed attention\nmasks and positional encodings. We demonstrate that Hierarchical Encoding helps\nachieve better natural language understanding of the contexts in\ntransformer-based models for task-oriented dialog systems through a wide range\nof experiments.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:08:52 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 15:38:26 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 10:25:13 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Santra", "Bishal", ""], ["Anusha", "Potnuru", ""], ["Goyal", "Pawan", ""]]}, {"id": "2011.08071", "submitter": "Ha Thanh Nguyen", "authors": "Ha-Thanh Nguyen, Hai-Yen Thi Vuong, Phuong Minh Nguyen, Binh Tran\n  Dang, Quan Minh Bui, Sinh Trong Vu, Chau Minh Nguyen, Vu Tran, Ken Satoh,\n  Minh Le Nguyen", "title": "JNLP Team: Deep Learning for Legal Processing in COLIEE 2020", "comments": "Also be published in JURISIN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose deep learning based methods for automatic systems of legal\nretrieval and legal question-answering in COLIEE 2020. These systems are all\ncharacterized by being pre-trained on large amounts of data before being\nfinetuned for the specified tasks. This approach helps to overcome the data\nscarcity and achieve good performance, thus can be useful for tackling related\nproblems in information retrieval, and decision support in the legal domain.\nBesides, the approach can be explored to deal with other domain specific\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:14:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Nguyen", "Ha-Thanh", ""], ["Vuong", "Hai-Yen Thi", ""], ["Nguyen", "Phuong Minh", ""], ["Dang", "Binh Tran", ""], ["Bui", "Quan Minh", ""], ["Vu", "Sinh Trong", ""], ["Nguyen", "Chau Minh", ""], ["Tran", "Vu", ""], ["Satoh", "Ken", ""], ["Nguyen", "Minh Le", ""]]}, {"id": "2011.08072", "submitter": "Swati Padhee", "authors": "Amanuel Alambo, Cori Lohstroh, Erik Madaus, Swati Padhee, Brandy\n  Foster, Tanvi Banerjee, Krishnaprasad Thirunarayan, Michael Raymer", "title": "Topic-Centric Unsupervised Multi-Document Summarization of Scientific\n  and News Articles", "comments": "6 pages, 6 Figures, 8 Tables. Accepted at IEEE Big Data 2020\n  (https://bigdataieee.org/BigData2020/AcceptedPapers.html)", "journal-ref": null, "doi": null, "report-no": "BigD420", "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in natural language processing have enabled automation of a\nwide range of tasks, including machine translation, named entity recognition,\nand sentiment analysis. Automated summarization of documents, or groups of\ndocuments, however, has remained elusive, with many efforts limited to\nextraction of keywords, key phrases, or key sentences. Accurate abstractive\nsummarization has yet to be achieved due to the inherent difficulty of the\nproblem, and limited availability of training data. In this paper, we propose a\ntopic-centric unsupervised multi-document summarization framework to generate\nextractive and abstractive summaries for groups of scientific articles across\n20 Fields of Study (FoS) in Microsoft Academic Graph (MAG) and news articles\nfrom DUC-2004 Task 2. The proposed algorithm generates an abstractive summary\nby developing salient language unit selection and text generation techniques.\nOur approach matches the state-of-the-art when evaluated on automated\nextractive evaluation metrics and performs better for abstractive summarization\non five human evaluation metrics (entailment, coherence, conciseness,\nreadability, and grammar). We achieve a kappa score of 0.68 between two\nco-author linguists who evaluated our results. We plan to publicly share\nMAG-20, a human-validated gold standard dataset of topic-clustered research\narticles and their summaries to promote research in abstractive summarization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:04:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Alambo", "Amanuel", ""], ["Lohstroh", "Cori", ""], ["Madaus", "Erik", ""], ["Padhee", "Swati", ""], ["Foster", "Brandy", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Raymer", "Michael", ""]]}, {"id": "2011.08073", "submitter": "Alexandra Luccioni", "authors": "Alexandra Luccioni, Emily Baylor, Nicolas Duchene", "title": "Analyzing Sustainability Reports Using Natural Language Processing", "comments": null, "journal-ref": "Tackling Climate Change with Machine Learning workshop at NeurIPS\n  2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change is a far-reaching, global phenomenon that will impact many\naspects of our society, including the global stock market\n\\cite{dietz2016climate}. In recent years, companies have increasingly been\naiming to both mitigate their environmental impact and adapt to the changing\nclimate context. This is reported via increasingly exhaustive reports, which\ncover many types of climate risks and exposures under the umbrella of\nEnvironmental, Social, and Governance (ESG). However, given this abundance of\ndata, sustainability analysts are obliged to comb through hundreds of pages of\nreports in order to find relevant information. We leveraged recent progress in\nNatural Language Processing (NLP) to create a custom model, ClimateQA, which\nallows the analysis of financial reports in order to identify climate-relevant\nsections based on a question answering approach. We present this tool and the\nmethodology that we used to develop it in the present article.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 21:22:42 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 17:20:09 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Luccioni", "Alexandra", ""], ["Baylor", "Emily", ""], ["Duchene", "Nicolas", ""]]}, {"id": "2011.08074", "submitter": "Naama Tepper", "authors": "Naama Tepper, Naama Zwerdling, David Naori and Inbal Ronen", "title": "Answer Identification in Collaborative Organizational Group Chat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple unsupervised approach for answer identification in\norganizational group chat. In recent years, organizational group chat is on the\nrise enabling asynchronous text-based collaboration between co-workers in\ndifferent locations and time zones. Finding answers to questions is often\ncritical for work efficiency. However, group chat is characterized by\nintertwined conversations and 'always on' availability, making it hard for\nusers to pinpoint answers to questions they care about in real-time or search\nfor answers in retrospective. In addition, structural and lexical\ncharacteristics differ between chat groups, making it hard to find a 'one model\nfits all' approach. Our Kernel Density Estimation (KDE) based clustering\napproach termed Ans-Chat implicitly learns discussion patterns as a means for\nanswer identification, thus eliminating the need to channel-specific tagging.\nEmpirical evaluation shows that this solution outperforms other approached.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 09:42:54 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Tepper", "Naama", ""], ["Zwerdling", "Naama", ""], ["Naori", "David", ""], ["Ronen", "Inbal", ""]]}, {"id": "2011.08091", "submitter": "Fabrizio Sebastiani", "authors": "Alejandro Moreo and Fabrizio Sebastiani", "title": "Tweet Sentiment Quantification: An Experimental Re-Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment quantification is the task of estimating the relative frequency (or\n\"prevalence\") of sentiment-related classes (such as Positive, Neutral,\nNegative) in a sample of unlabelled texts; this is especially important when\nthese texts are tweets, since most sentiment classification endeavours carried\nout on Twitter data actually have quantification (and not the classification of\nindividual tweets) as their ultimate goal. It is well-known that solving\nquantification via \"classify and count\" (i.e., by classifying all unlabelled\nitems via a standard classifier and counting the items that have been assigned\nto a given class) is suboptimal in terms of accuracy, and that more accurate\nquantification methods exist. In 2016, Gao and Sebastiani carried out a\nsystematic comparison of quantification methods on the task of tweet sentiment\nquantification. In hindsight, we observe that the experimental protocol\nfollowed in that work is flawed, and that its results are thus unreliable. We\nnow re-evaluate those quantification methods on the very same datasets, this\ntime following a now consolidated and much more robust experimental protocol,\nthat involves 5775 as many experiments as run in the original study. Our\nexperimentation yields results dramatically different from those obtained by\nGao and Sebastiani, and thus provide a different, much more solid understanding\nof the relative strengths and weaknesses of different sentiment quantification\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:41:34 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 10:49:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "2011.08092", "submitter": "Niket Tandon", "authors": "Niket Tandon, Keisuke Sakaguchi, Bhavana Dalvi Mishra, Dheeraj\n  Rajagopal, Peter Clark, Michal Guerquin, Kyle Richardson, Eduard Hovy", "title": "A Dataset for Tracking Entities in Open Domain Procedural Text", "comments": "To appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first dataset for tracking state changes in procedural text\nfrom arbitrary domains by using an unrestricted (open) vocabulary. For example,\nin a text describing fog removal using potatoes, a car window may transition\nbetween being foggy, sticky,opaque, and clear. Previous formulations of this\ntask provide the text and entities involved,and ask how those entities change\nfor just a small, pre-defined set of attributes (e.g., location), limiting\ntheir fidelity. Our solution is a new task formulation where given just a\nprocedural text as input, the task is to generate a set of state change\ntuples(entity, at-tribute, before-state, after-state)for each step,where the\nentity, attribute, and state values must be predicted from an open vocabulary.\nUsing crowdsourcing, we create OPENPI1, a high-quality (91.5% coverage as\njudged by humans and completely vetted), and large-scale dataset comprising\n29,928 state changes over 4,050 sentences from 810 procedural real-world\nparagraphs from WikiHow.com. A current state-of-the-art generation model on\nthis task achieves 16.1% F1 based on BLEU metric, leaving enough room for novel\nmodel architectures.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:33:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Tandon", "Niket", ""], ["Sakaguchi", "Keisuke", ""], ["Mishra", "Bhavana Dalvi", ""], ["Rajagopal", "Dheeraj", ""], ["Clark", "Peter", ""], ["Guerquin", "Michal", ""], ["Richardson", "Kyle", ""], ["Hovy", "Eduard", ""]]}, {"id": "2011.08115", "submitter": "Matthew Peters", "authors": "Orion Weller, Nicholas Lourie, Matt Gardner, Matthew E. Peters", "title": "Learning from Task Descriptions", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, machine learning systems solve new tasks by training on thousands\nof examples. In contrast, humans can solve new tasks by reading some\ninstructions, with perhaps an example or two. To take a step toward closing\nthis gap, we introduce a framework for developing NLP systems that solve new\ntasks after reading their descriptions, synthesizing prior work in this area.\nWe instantiate this framework with a new English language dataset, ZEST,\nstructured for task-oriented evaluation on unseen tasks. Formulating task\ndescriptions as questions, we ensure each is general enough to apply to many\npossible inputs, thus comprehensively evaluating a model's ability to solve\neach task. Moreover, the dataset's structure tests specific types of systematic\ngeneralization. We find that the state-of-the-art T5 model achieves a score of\n12% on ZEST, leaving a significant challenge for NLP researchers.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:25:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Weller", "Orion", ""], ["Lourie", "Nicholas", ""], ["Gardner", "Matt", ""], ["Peters", "Matthew E.", ""]]}, {"id": "2011.08238", "submitter": "Edmilson Morais PhD", "authors": "Edmilson Morais, Hong-Kwang J. Kuo, Samuel Thomas, Zoltan Tuske and\n  Brian Kingsbury", "title": "End-to-end spoken language understanding using transformer networks and\n  self-supervised pre-trained features", "comments": "5 pages, 3 tables and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformer networks and self-supervised pre-training have consistently\ndelivered state-of-art results in the field of natural language processing\n(NLP); however, their merits in the field of spoken language understanding\n(SLU) still need further investigation. In this paper we introduce a modular\nEnd-to-End (E2E) SLU transformer network based architecture which allows the\nuse of self-supervised pre-trained acoustic features, pre-trained model\ninitialization and multi-task training. Several SLU experiments for predicting\nintent and entity labels/values using the ATIS dataset are performed. These\nexperiments investigate the interaction of pre-trained model initialization and\nmulti-task training with either traditional filterbank or self-supervised\npre-trained acoustic features. Results show not only that self-supervised\npre-trained acoustic features outperform filterbank features in almost all the\nexperiments, but also that when these features are used in combination with\nmulti-task training, they almost eliminate the necessity of pre-trained model\ninitialization.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:30:52 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Morais", "Edmilson", ""], ["Kuo", "Hong-Kwang J.", ""], ["Thomas", "Samuel", ""], ["Tuske", "Zoltan", ""], ["Kingsbury", "Brian", ""]]}, {"id": "2011.08243", "submitter": "Chien-Wei Lin", "authors": "Chien-Wei Lin, Vincent Auvray, Daniel Elkind, Arijit Biswas, Maryam\n  Fazel-Zarandi, Nehal Belgamwar, Shubhra Chandra, Matt Zhao, Angeliki\n  Metallinou, Tagyoung Chung, Charlie Shucheng Zhu, Suranjit Adhikari, Dilek\n  Hakkani-Tur", "title": "Dialog Simulation with Realistic Variations for Training Goal-Oriented\n  Conversational Systems", "comments": "To be presented at Human in the Loop Dialogue Systems Workshop,\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialog systems enable users to complete specific goals like\nrequesting information about a movie or booking a ticket. Typically the dialog\nsystem pipeline contains multiple ML models, including natural language\nunderstanding, state tracking and action prediction (policy learning). These\nmodels are trained through a combination of supervised or reinforcement\nlearning methods and therefore require collection of labeled domain specific\ndatasets. However, collecting annotated datasets with language and dialog-flow\nvariations is expensive, time-consuming and scales poorly due to human\ninvolvement. In this paper, we propose an approach for automatically creating a\nlarge corpus of annotated dialogs from a few thoroughly annotated sample\ndialogs and the dialog schema. Our approach includes a novel goal-sampling\ntechnique for sampling plausible user goals and a dialog simulation technique\nthat uses heuristic interplay between the user and the system (Alexa), where\nthe user tries to achieve the sampled goal. We validate our approach by\ngenerating data and training three different downstream conversational ML\nmodels. We achieve 18 ? 50% relative accuracy improvements on a held-out test\nset compared to a baseline dialog generation approach that only samples natural\nlanguage and entity value variations from existing catalogs but does not\ngenerate any novel dialog flow variations. We also qualitatively establish that\nthe proposed approach is better than the baseline. Moreover, several different\nconversational experiences have been built using this method, which enables\ncustomers to have a wide variety of conversations with Alexa.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:39:15 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lin", "Chien-Wei", ""], ["Auvray", "Vincent", ""], ["Elkind", "Daniel", ""], ["Biswas", "Arijit", ""], ["Fazel-Zarandi", "Maryam", ""], ["Belgamwar", "Nehal", ""], ["Chandra", "Shubhra", ""], ["Zhao", "Matt", ""], ["Metallinou", "Angeliki", ""], ["Chung", "Tagyoung", ""], ["Zhu", "Charlie Shucheng", ""], ["Adhikari", "Suranjit", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2011.08262", "submitter": "Olga Scrivner", "authors": "Olga Scrivner", "title": "A Probabilistic Approach in Historical Linguistics Word Order Change in\n  Infinitival Clauses: from Latin to Old French", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research offers a new interdisciplinary approach to the field of\nLinguistics by using Computational Linguistics, NLP, Bayesian Statistics and\nSociolinguistics methods. This thesis investigates word order change in\ninfinitival clauses from Object-Verb (OV) to Verb-Object (VO) in the history of\nLatin and Old French. By applying a variationist approach, I examine a\nsynchronic word order variation in each stage of language change, from which I\ninfer the character, periodization and constraints of diachronic variation. I\nalso show that in discourse-configurational languages, such as Latin and Early\nOld French, it is possible to identify pragmatically neutral contexts by using\ninformation structure annotation. I further argue that by mapping pragmatic\ncategories into a syntactic structure, we can detect how word order change\nunfolds. For this investigation, the data are extracted from annotated corpora\nspanning several centuries of Latin and Old French and from additional\nresources created by using computational linguistic methods. The data are then\nfurther codified for various pragmatic, semantic, syntactic and sociolinguistic\nfactors. This study also evaluates previous factors proposed to account for\nword order alternation and change. I show how information structure and\nsyntactic constraints change over time and propose a method that allows\nresearchers to differentiate a stable word order alternation from alternation\nindicating a change. Finally, I present a three-stage probabilistic model of\nword order change, which also conforms to traditional language change patterns.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:30:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Scrivner", "Olga", ""]]}, {"id": "2011.08272", "submitter": "Rajkumar Ramamurthy", "authors": "Rajkumar Ramamurthy, Rafet Sifa and Christian Bauckhage", "title": "NLPGym -- A toolkit for evaluating RL agents on Natural Language\n  Processing Tasks", "comments": "Accepted at Wordplay: When Language Meets Games Workshop @ NeurIPS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has recently shown impressive performance in\ncomplex game AI and robotics tasks. To a large extent, this is thanks to the\navailability of simulated environments such as OpenAI Gym, Atari Learning\nEnvironment, or Malmo which allow agents to learn complex tasks through\ninteraction with virtual environments. While RL is also increasingly applied to\nnatural language processing (NLP), there are no simulated textual environments\navailable for researchers to apply and consistently benchmark RL on NLP tasks.\nWith the work reported here, we therefore release NLPGym, an open-source Python\ntoolkit that provides interactive textual environments for standard NLP tasks\nsuch as sequence tagging, multi-label classification, and question answering.\nWe also present experimental results for 6 tasks using different RL algorithms\nwhich serve as baselines for further research. The toolkit is published at\nhttps://github.com/rajcscw/nlp-gym\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:58:35 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ramamurthy", "Rajkumar", ""], ["Sifa", "Rafet", ""], ["Bauckhage", "Christian", ""]]}, {"id": "2011.08277", "submitter": "Meera Hahn", "authors": "Meera Hahn, Jacob Krantz, Dhruv Batra, Devi Parikh, James M. Rehg,\n  Stefan Lee and Peter Anderson", "title": "Where Are You? Localization from Embodied Dialog", "comments": null, "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Where Are You? (WAY), a dataset of ~6k dialogs in which two humans\n-- an Observer and a Locator -- complete a cooperative localization task. The\nObserver is spawned at random in a 3D environment and can navigate from\nfirst-person views while answering questions from the Locator. The Locator must\nlocalize the Observer in a detailed top-down map by asking questions and giving\ninstructions. Based on this dataset, we define three challenging tasks:\nLocalization from Embodied Dialog or LED (localizing the Observer from dialog\nhistory), Embodied Visual Dialog (modeling the Observer), and Cooperative\nLocalization (modeling both agents). In this paper, we focus on the LED task --\nproviding a strong baseline model with detailed ablations characterizing both\ndataset biases and the importance of various modeling choices. Our best model\nachieves 32.7% success at identifying the Observer's location within 3m in\nunseen buildings, vs. 70.4% for human Locators.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:09:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hahn", "Meera", ""], ["Krantz", "Jacob", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Rehg", "James M.", ""], ["Lee", "Stefan", ""], ["Anderson", "Peter", ""]]}, {"id": "2011.08291", "submitter": "Chujie Zheng", "authors": "Chujie Zheng, Kunpeng Zhang, Harry Jiannan Wang, Ling Fan", "title": "A Two-Phase Approach for Abstractive Podcast Summarization", "comments": "TREC 2020 Podcasts Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Podcast summarization is different from summarization of other data formats,\nsuch as news, patents, and scientific papers in that podcasts are often longer,\nconversational, colloquial, and full of sponsorship and advertising\ninformation, which imposes great challenges for existing models. In this paper,\nwe focus on abstractive podcast summarization and propose a two-phase approach:\nsentence selection and seq2seq learning. Specifically, we first select\nimportant sentences from the noisy long podcast transcripts. The selection is\nbased on sentence similarity to the reference to reduce the redundancy and the\nassociated latent topics to preserve semantics. Then the selected sentences are\nfed into a pre-trained encoder-decoder framework for the summary generation.\nOur approach achieves promising results regarding both ROUGE-based measures and\nhuman evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:31:28 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zheng", "Chujie", ""], ["Zhang", "Kunpeng", ""], ["Wang", "Harry Jiannan", ""], ["Fan", "Ling", ""]]}, {"id": "2011.08298", "submitter": "Peng-Jen Chen", "authors": "Peng-Jen Chen, Ann Lee, Changhan Wang, Naman Goyal, Angela Fan, Mary\n  Williamson, Jiatao Gu", "title": "Facebook AI's WMT20 News Translation Task Submission", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Facebook AI's submission to WMT20 shared news\ntranslation task. We focus on the low resource setting and participate in two\nlanguage pairs, Tamil <-> English and Inuktitut <-> English, where there are\nlimited out-of-domain bitext and monolingual data. We approach the low resource\nproblem using two main strategies, leveraging all available data and adapting\nthe system to the target news domain. We explore techniques that leverage\nbitext and monolingual data from all languages, such as self-supervised model\npretraining, multilingual models, data augmentation, and reranking. To better\nadapt the translation system to the test domain, we explore dataset tagging and\nfine-tuning on in-domain data. We observe that different techniques provide\nvaried improvements based on the available data of the language pair. Based on\nthe finding, we integrate these techniques into one training pipeline. For\nEn->Ta, we explore an unconstrained setup with additional Tamil bitext and\nmonolingual data and show that further improvement can be obtained. On the test\nset, our best submitted systems achieve 21.5 and 13.7 BLEU for Ta->En and\nEn->Ta respectively, and 27.9 and 13.0 for Iu->En and En->Iu respectively.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:49:00 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Chen", "Peng-Jen", ""], ["Lee", "Ann", ""], ["Wang", "Changhan", ""], ["Goyal", "Naman", ""], ["Fan", "Angela", ""], ["Williamson", "Mary", ""], ["Gu", "Jiatao", ""]]}, {"id": "2011.08320", "submitter": "Carla Perez-Almendros", "authors": "Carla P\\'erez-Almendros, Luis Espinosa-Anke and Steven Schockaert", "title": "Don't Patronize Me! An Annotated Dataset with Patronizing and\n  Condescending Language towards Vulnerable Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a new annotated dataset which is aimed at\nsupporting the development of NLP models to identify and categorize language\nthat is patronizing or condescending towards vulnerable communities (e.g.\nrefugees, homeless people, poor families). While the prevalence of such\nlanguage in the general media has long been shown to have harmful effects, it\ndiffers from other types of harmful language, in that it is generally used\nunconsciously and with good intentions. We furthermore believe that the often\nsubtle nature of patronizing and condescending language (PCL) presents an\ninteresting technical challenge for the NLP community. Our analysis of the\nproposed dataset shows that identifying PCL is hard for standard NLP models,\nwith language models such as BERT achieving the best results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:45:03 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["P\u00e9rez-Almendros", "Carla", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "2011.08334", "submitter": "Michael Wessel", "authors": "Michael Wessel, Edgar Kalns, Girish Acharya, Andreas Kathol", "title": "Widening the Dialogue Workflow Modeling Bottleneck in Ontology-Based\n  Personal Assistants", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to dialogue specification for Virtual Personal\nAssistants (VPAs) based on so-called dialogue workflow graphs, with several\ndemonstrated advantages over current ontology-based methods. Our new dialogue\nspecification language (DSL) enables customers to more easily participate in\nthe VPA modeling process due to a user-friendly modeling framework. Resulting\nmodels are also significantly more compact. VPAs can be developed much more\nrapidly. The DSL is a new modeling layer on top of our ontology-based Dialogue\nManagement (DM) framework OntoVPA. We explain the rationale and benefits behind\nthe new language and support our claims with concrete reduced Level-of-Effort\n(LOE) numbers from two recent OntoVPA projects.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 23:32:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wessel", "Michael", ""], ["Kalns", "Edgar", ""], ["Acharya", "Girish", ""], ["Kathol", "Andreas", ""]]}, {"id": "2011.08346", "submitter": "Liu Chen", "authors": "Liu Chen, Meysam Asgari", "title": "Refining Automatic Speech Recognition System for older adults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building a high quality automatic speech recognition (ASR) system with\nlimited training data has been a challenging task particularly for a narrow\ntarget population. Open-sourced ASR systems, trained on sufficient data from\nadults, are susceptible on seniors' speech due to acoustic mismatch between\nadults and seniors. With 12 hours of training data, we attempt to develop an\nASR system for socially isolated seniors (80+ years old) with possible\ncognitive impairments. We experimentally identify that ASR for the adult\npopulation performs poorly on our target population and transfer learning (TL)\ncan boost the system's performance. Standing on the fundamental idea of TL,\ntuning model parameters, we further improve the system by leveraging an\nattention mechanism to utilize the model's intermediate information. Our\napproach achieves 1.58% absolute improvements over the TL model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 00:00:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Chen", "Liu", ""], ["Asgari", "Meysam", ""]]}, {"id": "2011.08469", "submitter": "Yao Zhuoyuan", "authors": "Xiong Wang, Zhuoyuan Yao, Xian Shi, Lei Xie", "title": "Cascade RNN-Transducer: Syllable Based Streaming On-device Mandarin\n  Speech Recognition with a Syllable-to-Character Converter", "comments": "7 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models are favored in automatic speech recognition (ASR) because\nof its simplified system structure and superior performance. Among these\nmodels, recurrent neural network transducer (RNN-T) has achieved significant\nprogress in streaming on-device speech recognition because of its high-accuracy\nand low-latency. RNN-T adopts a prediction network to enhance language\ninformation, but its language modeling ability is limited because it still\nneeds paired speech-text data to train. Further strengthening the language\nmodeling ability through extra text data, such as shallow fusion with an\nexternal language model, only brings a small performance gain. In view of the\nfact that Mandarin Chinese is a character-based language and each character is\npronounced as a tonal syllable, this paper proposes a novel cascade RNN-T\napproach to improve the language modeling ability of RNN-T. Our approach\nfirstly uses an RNN-T to transform acoustic feature into syllable sequence, and\nthen converts the syllable sequence into character sequence through an\nRNN-T-based syllable-to-character converter. Thus a rich text repository can be\neasily used to strengthen the language model ability. By introducing several\nimportant tricks, the cascade RNN-T approach surpasses the character-based\nRNN-T by a large margin on several Mandarin test sets, with much higher\nrecognition quality and similar latency.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:42:47 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wang", "Xiong", ""], ["Yao", "Zhuoyuan", ""], ["Shi", "Xian", ""], ["Xie", "Lei", ""]]}, {"id": "2011.08523", "submitter": "Haoxiang Shi", "authors": "Haoxiang Shi and Cen Wang", "title": "Self-supervised Document Clustering Based on BERT with Data Augment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contrastive learning is a good way to pursue discriminative unsupervised\nlearning, which can inherit advantages and experiences of well-studied deep\nmodels without complexly novel model designing. In this paper, we propose two\nlearning method for document clustering, the one is a partial contrastive\nlearning with unsupervised data augment, and the other is a self-supervised\ncontrastive learning. Both methods achieve state-of-the-art results in\nclustering accuracy when compared to recently proposed unsupervised clustering\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 09:18:47 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 18:46:28 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Shi", "Haoxiang", ""], ["Wang", "Cen", ""]]}, {"id": "2011.08539", "submitter": "Wei Zhu", "authors": "Wei Zhu", "title": "MVP-BERT: Redesigning Vocabularies for Chinese BERT and Multi-Vocab\n  Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the development of pre-trained language models (PLMs) significantly\nraise the performances of various Chinese natural language processing (NLP)\ntasks, the vocabulary for these Chinese PLMs remain to be the one provided by\nGoogle Chinese Bert \\cite{devlin2018bert}, which is based on Chinese\ncharacters. Second, the masked language model pre-training is based on a single\nvocabulary, which limits its downstream task performances. In this work, we\nfirst propose a novel method, \\emph{seg\\_tok}, to form the vocabulary of\nChinese BERT, with the help of Chinese word segmentation (CWS) and subword\ntokenization. Then we propose three versions of multi-vocabulary pretraining\n(MVP) to improve the models expressiveness. Experiments show that: (a) compared\nwith char based vocabulary, \\emph{seg\\_tok} does not only improves the\nperformances of Chinese PLMs on sentence level tasks, it can also improve\nefficiency; (b) MVP improves PLMs' downstream performance, especially it can\nimprove \\emph{seg\\_tok}'s performances on sequence labeling tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:15:36 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zhu", "Wei", ""]]}, {"id": "2011.08543", "submitter": "Thu Nguyen", "authors": "Thu Nguyen, Duy Phung, Minh Hoai, Thien Huu Nguyen", "title": "Structural and Functional Decomposition for Personality Image Captioning\n  in a Communication Game", "comments": "10 pages, EMNLP-Findings 2020", "journal-ref": "EMNLP-Findings 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personality image captioning (PIC) aims to describe an image with a natural\nlanguage caption given a personality trait. In this work, we introduce a novel\nformulation for PIC based on a communication game between a speaker and a\nlistener. The speaker attempts to generate natural language captions while the\nlistener encourages the generated captions to contain discriminative\ninformation about the input images and personality traits. In this way, we\nexpect that the generated captions can be improved to naturally represent the\nimages and express the traits. In addition, we propose to adapt the language\nmodel GPT2 to perform caption generation for PIC. This enables the speaker and\nlistener to benefit from the language encoding capacity of GPT2. Our\nexperiments show that the proposed model achieves the state-of-the-art\nperformance for PIC.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:19:27 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Nguyen", "Thu", ""], ["Phung", "Duy", ""], ["Hoai", "Minh", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "2011.08558", "submitter": "Liping Yuan", "authors": "Liping Yuan, Xiaoqing Zheng, Yi Zhou, Cho-Jui Hsieh, Kai-wei Chang,\n  Xuanjing Huang", "title": "Generating universal language adversarial examples by understanding and\n  enhancing the transferability across neural models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network models are vulnerable to adversarial attacks. In many\ncases, malicious inputs intentionally crafted for one model can fool another\nmodel in the black-box attack setting. However, there is a lack of systematic\nstudies on the transferability of adversarial examples and how to generate\nuniversal adversarial examples. In this paper, we systematically study the\ntransferability of adversarial attacks for text classification models. In\nparticular, we conduct extensive experiments to investigate how various\nfactors, such as network architecture, input format, word embedding, and model\ncapacity, affect the transferability of adversarial attacks. Based on these\nstudies, we then propose universal black-box attack algorithms that can induce\nadversarial examples to attack almost all existing models. These universal\nadversarial examples reflect the defects of the learning process and the bias\nin the training dataset. Finally, we generalize these adversarial examples into\nuniversal word replacement rules that can be used for model diagnostics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:45:05 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 02:05:43 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yuan", "Liping", ""], ["Zheng", "Xiaoqing", ""], ["Zhou", "Yi", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-wei", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2011.08626", "submitter": "Jiwei Li", "authors": "Zijun Sun, Chun Fan, Xiaofei Sun, Yuxian Meng, Fei Wu and Jiwei Li", "title": "Neural Semi-supervised Learning for Text Classification Under\n  Large-Scale Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of semi-supervised learning is to utilize the unlabeled, in-domain\ndataset U to improve models trained on the labeled dataset D. Under the context\nof large-scale language-model (LM) pretraining, how we can make the best use of\nU is poorly understood: is semi-supervised learning still beneficial with the\npresence of large-scale pretraining? should U be used for in-domain LM\npretraining or pseudo-label generation? how should the pseudo-label based\nsemi-supervised model be actually implemented? how different semi-supervised\nstrategies affect performances regarding D of different sizes, U of different\nsizes, etc. In this paper, we conduct comprehensive studies on semi-supervised\nlearning in the task of text classification under the context of large-scale LM\npretraining. Our studies shed important lights on the behavior of\nsemi-supervised learning methods: (1) with the presence of in-domain\npretraining LM on U, open-domain LM pretraining is unnecessary; (2) both the\nin-domain pretraining strategy and the pseudo-label based strategy introduce\nsignificant performance boosts, with the former performing better with larger\nU, the latter performing better with smaller U, and the combination leading to\nthe largest performance boost; (3) self-training (pretraining first on pseudo\nlabels D' and then fine-tuning on D) yields better performances when D is\nsmall, while joint training on the combination of pseudo labels D' and the\noriginal dataset D yields better performances when D is large. Using\nsemi-supervised learning strategies, we are able to achieve a performance of\naround 93.8% accuracy with only 50 training data points on the IMDB dataset,\nand a competitive performance of 96.6% with the full IMDB dataset. Our work\nmarks an initial step in understanding the behavior of semi-supervised learning\nmodels under the context of large-scale pretraining.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:39:05 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 12:43:58 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sun", "Zijun", ""], ["Fan", "Chun", ""], ["Sun", "Xiaofei", ""], ["Meng", "Yuxian", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2011.08678", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Yang Xiao, Jiang Guo, Xiangyu Yue, Jufeng Yang, Ravi\n  Krishna, Pengfei Xu, Kurt Keutzer", "title": "Curriculum CycleGAN for Textual Sentiment Domain Adaptation with\n  Multiple Sources", "comments": "Accepted by WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis of user-generated reviews or comments on products and\nservices in social networks can help enterprises to analyze the feedback from\ncustomers and take corresponding actions for improvement. To mitigate\nlarge-scale annotations on the target domain, domain adaptation (DA) provides\nan alternate solution by learning a transferable model from other labeled\nsource domains. Existing multi-source domain adaptation (MDA) methods either\nfail to extract some discriminative features in the target domain that are\nrelated to sentiment, neglect the correlations of different sources and the\ndistribution difference among different sub-domains even in the same source, or\ncannot reflect the varying optimal weighting during different training stages.\nIn this paper, we propose a novel instance-level MDA framework, named\ncurriculum cycle-consistent generative adversarial network (C-CycleGAN), to\naddress the above issues. Specifically, C-CycleGAN consists of three\ncomponents: (1) pre-trained text encoder which encodes textual input from\ndifferent domains into a continuous representation space, (2) intermediate\ndomain generator with curriculum instance-level adaptation which bridges the\ngap across source and target domains, and (3) task classifier trained on the\nintermediate domain for final sentiment classification. C-CycleGAN transfers\nsource samples at instance-level to an intermediate domain that is closer to\nthe target domain with sentiment semantics preserved and without losing\ndiscriminative features. Further, our dynamic instance-level weighting\nmechanisms can assign the optimal weights to different source samples in each\ntraining stage. We conduct extensive experiments on three benchmark datasets\nand achieve substantial gains over state-of-the-art DA approaches. Our source\ncode is released at: https://github.com/WArushrush/Curriculum-CycleGAN.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:50:55 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 01:22:50 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Zhao", "Sicheng", ""], ["Xiao", "Yang", ""], ["Guo", "Jiang", ""], ["Yue", "Xiangyu", ""], ["Yang", "Jufeng", ""], ["Krishna", "Ravi", ""], ["Xu", "Pengfei", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2011.08755", "submitter": "Bimal Bhattarai", "authors": "Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao", "title": "Measuring the Novelty of Natural Language Text Using the Conjunctive\n  Clauses of a Tsetlin Machine Text Classifier", "comments": "10 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most supervised text classification approaches assume a closed world,\ncounting on all classes being present in the data at training time. This\nassumption can lead to unpredictable behaviour during operation, whenever\nnovel, previously unseen, classes appear. Although deep learning-based methods\nhave recently been used for novelty detection, they are challenging to\ninterpret due to their black-box nature. This paper addresses\n\\emph{interpretable} open-world text classification, where the trained\nclassifier must deal with novel classes during operation. To this end, we\nextend the recently introduced Tsetlin machine (TM) with a novelty scoring\nmechanism. The mechanism uses the conjunctive clauses of the TM to measure to\nwhat degree a text matches the classes covered by the training data. We\ndemonstrate that the clauses provide a succinct interpretable description of\nknown topics, and that our scoring mechanism makes it possible to discern novel\ntopics from the known ones. Empirically, our TM-based approach outperforms\nseven other novelty detection schemes on three out of five datasets, and\nperforms second and third best on the remaining, with the added benefit of an\ninterpretable propositional logic-based representation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:35:21 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bhattarai", "Bimal", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""]]}, {"id": "2011.08772", "submitter": "Zimo Zhou", "authors": "Hongru Wang, Min Li, Zimo Zhou, Gabriel Pui Cheong Fung, Kam-Fai Wong", "title": "KddRES: A Multi-level Knowledge-driven Dialogue Dataset for Restaurant\n  Towards Customized Dialogue System", "comments": "8 pages,2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with CrossWOZ (Chinese) and MultiWOZ (English) dataset which have\ncoarse-grained information, there is no dataset which handle fine-grained and\nhierarchical level information properly. In this paper, we publish a first\nCantonese knowledge-driven Dialogue Dataset for REStaurant (KddRES) in Hong\nKong, which grounds the information in multi-turn conversations to one specific\nrestaurant. Our corpus contains 0.8k conversations which derive from 10\nrestaurants with various styles in different regions. In addition to that, we\ndesigned fine-grained slots and intents to better capture semantic information.\nThe benchmark experiments and data statistic analysis show the diversity and\nrich annotations of our dataset. We believe the publish of KddRES can be a\nnecessary supplement of current dialogue datasets and more suitable and\nvaluable for small and middle enterprises (SMEs) of society, such as build a\ncustomized dialogue system for each restaurant. The corpus and benchmark models\nare publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:57:41 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 11:38:24 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Wang", "Hongru", ""], ["Li", "Min", ""], ["Zhou", "Zimo", ""], ["Fung", "Gabriel Pui Cheong", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "2011.08835", "submitter": "Diwakar Mahajan", "authors": "Diwakar Mahajan, Jennifer J Liang, Ching-Huei Tsou", "title": "Toward Understanding Clinical Context of Medication Change Events in\n  Clinical Narratives", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Understanding medication events in clinical narratives is essential to\nachieving a complete picture of a patient's medication history. While prior\nresearch has explored classification of medication changes from clinical notes,\nstudies to date have not considered the necessary clinical context needed for\ntheir use in real-world applications, such as medication timeline generation\nand medication reconciliation. In this paper, we present the Contextualized\nMedication Event Dataset (CMED), a dataset for capturing relevant context of\nmedication changes documented in clinical notes, which was developed using a\nnovel conceptual framework that organizes context for clinical events into\nvarious orthogonal dimensions. In this process, we define specific contextual\naspects pertinent to medication change events, characterize the dataset, and\nreport the results of preliminary experiments. CMED consists of 9,013\nmedication mentions annotated over 500 clinical notes, and will be released to\nthe community as a shared task in 2021.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:55:00 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 15:08:14 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mahajan", "Diwakar", ""], ["Liang", "Jennifer J", ""], ["Tsou", "Ching-Huei", ""]]}, {"id": "2011.08903", "submitter": "Marieke van Erp", "authors": "Ryan Brate, Paul Groth, Marieke van Erp", "title": "Towards Olfactory Information Extraction from Text: A Case Study on\n  Detecting Smell Experiences in Novels", "comments": "Accepted to The 4th Joint SIGHUM Workshop on Computational\n  Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature\n  (LaTeCH-CLfL 2020). Barcelona, Spain. December 2020./", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Environmental factors determine the smells we perceive, but societal factors\nfactors shape the importance, sentiment and biases we give to them.\nDescriptions of smells in text, or as we call them `smell experiences', offer a\nwindow into these factors, but they must first be identified. To the best of\nour knowledge, no tool exists to extract references to smell experiences from\ntext. In this paper, we present two variations on a semi-supervised approach to\nidentify smell experiences in English literature. The combined set of patterns\nfrom both implementations offer significantly better performance than a\nkeyword-based baseline.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:41:02 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 19:02:16 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Brate", "Ryan", ""], ["Groth", "Paul", ""], ["van Erp", "Marieke", ""]]}, {"id": "2011.08906", "submitter": "Dian Yu", "authors": "Kaihui Liang, Austin Chau, Yu Li, Xueyuan Lu, Dian Yu, Mingyang Zhou,\n  Ishan Jain, Sam Davidson, Josh Arnold, Minh Nguyen, Zhou Yu", "title": "Gunrock 2.0: A User Adaptive Social Conversational System", "comments": "Published in 3rd Proceedings of Alexa Prize (Alexa Prize 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gunrock 2.0 is built on top of Gunrock with an emphasis on user adaptation.\nGunrock 2.0 combines various neural natural language understanding modules,\nincluding named entity detection, linking, and dialog act prediction, to\nimprove user understanding. Its dialog management is a hierarchical model that\nhandles various topics, such as movies, music, and sports. The system-level\ndialog manager can handle question detection, acknowledgment, error handling,\nand additional functions, making downstream modules much easier to design and\nimplement. The dialog manager also adapts its topic selection to accommodate\ndifferent users' profile information, such as inferred gender and personality.\nThe generation model is a mix of templates and neural generation models.\nGunrock 2.0 is able to achieve an average rating of 3.73 at its latest build\nfrom May 29th to June 4th.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:52:32 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 18:47:46 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Liang", "Kaihui", ""], ["Chau", "Austin", ""], ["Li", "Yu", ""], ["Lu", "Xueyuan", ""], ["Yu", "Dian", ""], ["Zhou", "Mingyang", ""], ["Jain", "Ishan", ""], ["Davidson", "Sam", ""], ["Arnold", "Josh", ""], ["Nguyen", "Minh", ""], ["Yu", "Zhou", ""]]}, {"id": "2011.08908", "submitter": "Thai Le", "authors": "Thai Le, Noseong Park, Dongwon Lee", "title": "SIENA: Stochastic Multi-Expert Neural Patcher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network (NN) models that are solely trained to maximize the likelihood\nof an observed dataset are often vulnerable to adversarial attacks. Even though\nseveral methods have been proposed to enhance NN models' adversarial\nrobustness, they often require re-training from scratch. This leads to\nredundant computation, especially in the NLP domain where current\nstate-of-the-art models, such as BERT and ROBERTA, require great time and space\nresources. By borrowing ideas from Software Engineering, we, therefore, first\nintroduce the Neural Patching mechanism to improve adversarial robustness by\n\"patching\" only parts of a NN model. Then, we propose a novel neural patching\nalgorithm, SIENA, that transforms a textual NN model into a stochastic ensemble\nof multi-expert predictors by upgrading and re-training its last layer only.\nSIENA forces adversaries to attack not only one but multiple models that are\nspecialized in diverse sub-sets of features, labels, and instances so that the\nensemble model becomes more robust to adversarial attacks. By conducting\ncomprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and\nROBERTA-based textual models, once patched by SIENA, witness an absolute\nincrease of as much as 20% in accuracy on average under 5 different white and\nblack-box attacks, outperforming 6 defensive baselines across 4 public NLP\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:58:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Le", "Thai", ""], ["Park", "Noseong", ""], ["Lee", "Dongwon", ""]]}, {"id": "2011.08927", "submitter": "Arda Mavi", "authors": "Arda Mavi", "title": "A New Dataset and Proposed Convolutional Neural Network Architecture for\n  Classification of American Sign Language Digits", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to interviews with people who work with speech impaired persons,\nspeech impaired people have difficulties in communicating with other people\naround them who do not know the sign language, and this situation may cause\nthem to isolate themselves from society and lose their sense of independence.\nWith this paper, to increase the quality of life of individuals with\nfacilitating communication between individuals who use sign language and who do\nnot know this language, a new American Sign Language (ASL) digits dataset that\ncan help to create machine learning algorithms which need to large and varied\ndata to be successful created and published as Sign Language Digits Dataset on\nKaggle Datasets web page, a proposal Convolutional Neural Network (CNN)\narchitecture that can get 98% test accuracy on our dataset presented, and\ncompared with the existing popular CNN models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:32:22 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 14:28:09 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Mavi", "Arda", ""]]}, {"id": "2011.08951", "submitter": "Andrew Runge", "authors": "Andrew Runge and Eduard Hovy", "title": "Exploring Neural Entity Representations for Semantic Information", "comments": "9 pages, 1 figure", "journal-ref": "Proceedings of the Third BlackboxNLP Workshop on Analyzing and\n  Interpreting Neural Networks for NLP 2020, p. 204-216", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural methods for embedding entities are typically extrinsically evaluated\non downstream tasks and, more recently, intrinsically using probing tasks.\nDownstream task-based comparisons are often difficult to interpret due to\ndifferences in task structure, while probing task evaluations often look at\nonly a few attributes and models. We address both of these issues by evaluating\na diverse set of eight neural entity embedding methods on a set of simple\nprobing tasks, demonstrating which methods are able to remember words used to\ndescribe entities, learn type, relationship and factual information, and\nidentify how frequently an entity is mentioned. We also compare these methods\nin a unified framework on two entity linking tasks and discuss how they\ngeneralize to different model architectures and datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:21:37 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Runge", "Andrew", ""], ["Hovy", "Eduard", ""]]}, {"id": "2011.08952", "submitter": "Sarah Tymochko", "authors": "Sarah Tymochko, Zachary New, Lucius Bynum, Emilie Purvine, Timothy\n  Doster, Julien Chaput, Tegan Emerson", "title": "Argumentative Topology: Finding Loop(holes) in Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in natural language processing have resulted in increased\ncapabilities with respect to multiple tasks. One of the possible causes of the\nobserved performance gains is the introduction of increasingly sophisticated\ntext representations. While many of the new word embedding techniques can be\nshown to capture particular notions of sentiment or associative structures, we\nexplore the ability of two different word embeddings to uncover or capture the\nnotion of logical shape in text. To this end we present a novel framework that\nwe call Topological Word Embeddings which leverages mathematical techniques in\ndynamical system analysis and data driven shape extraction (i.e. topological\ndata analysis). In this preliminary work we show that using a topological delay\nembedding we are able to capture and extract a different, shape-based notion of\nlogic aimed at answering the question \"Can we find a circle in a circular\nargument?\"\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:23:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tymochko", "Sarah", ""], ["New", "Zachary", ""], ["Bynum", "Lucius", ""], ["Purvine", "Emilie", ""], ["Doster", "Timothy", ""], ["Chaput", "Julien", ""], ["Emerson", "Tegan", ""]]}, {"id": "2011.09031", "submitter": "Tong Guo", "authors": "Tong Guo", "title": "Self-training For Pre-training Language Models", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language model pre-training has proven to be useful in many language\nunderstanding tasks. In this paper, we investigate whether it is still helpful\nto add the self-training method in the pre-training step and the fine-tuning\nstep. Towards this goal, we propose a learning framework that making best use\nof the unlabel data on the low-resource and high-resource labeled dataset. In\nindustry NLP applications, we have large amounts of data produced by users or\ncustomers. Our learning framework is based on this large amounts of unlabel\ndata. First, We use the model fine-tuned on manually labeled dataset to predict\npseudo labels for the user-generated unlabeled data. Then we use the pseudo\nlabels to supervise the task-specific training on the large amounts of\nuser-generated data. We consider this task-specific training step on pseudo\nlabels as a pre-training step for the next fine-tuning step. At last, we\nfine-tune on the manually labeled dataset upon the pre-trained model. In this\nwork, we first empirically show that our method is able to solidly improve the\nperformance by 3.6%, when the manually labeled fine-tuning dataset is\nrelatively small. Then we also show that our method still is able to improve\nthe performance further by 0.2%, when the manually labeled fine-tuning dataset\nis relatively large enough. We argue that our method make the best use of the\nunlabel data, which is superior to either pre-training or self-training alone.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 01:35:01 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 01:43:20 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 00:44:11 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Guo", "Tong", ""]]}, {"id": "2011.09039", "submitter": "Demi Guo", "authors": "Demi Guo, Yoon Kim and Alexander M. Rush", "title": "Sequence-Level Mixed Sample Data Augmentation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite their empirical success, neural networks still have difficulty\ncapturing compositional aspects of natural language. This work proposes a\nsimple data augmentation approach to encourage compositional behavior in neural\nmodels for sequence-to-sequence problems. Our approach, SeqMix, creates new\nsynthetic examples by softly combining input/output sequences from the training\nset. We connect this approach to existing techniques such as SwitchOut and word\ndropout, and show that these techniques are all approximating variants of a\nsingle objective. SeqMix consistently yields approximately 1.0 BLEU improvement\non five different translation datasets over strong Transformer baselines. On\ntasks that require strong compositional generalization such as SCAN and\nsemantic parsing, SeqMix also offers further improvements.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:18:04 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Guo", "Demi", ""], ["Kim", "Yoon", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2011.09044", "submitter": "Markus M\\\"uller", "authors": "Bhuvan Agrawal, Markus M\\\"uller, Martin Radfar, Samridhi Choudhary,\n  Athanasios Mouchtaris, Siegfried Kunzmann", "title": "Tie Your Embeddings Down: Cross-Modal Latent Spaces for End-to-end\n  Spoken Language Understanding", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) spoken language understanding (SLU) systems can infer the\nsemantics of a spoken utterance directly from an audio signal. However,\ntraining an E2E system remains a challenge, largely due to the scarcity of\npaired audio-semantics data. In this paper, we treat an E2E system as a\nmulti-modal model, with audio and text functioning as its two modalities, and\nuse a cross-modal latent space (CMLS) architecture, where a shared latent space\nis learned between the `acoustic' and `text' embeddings. We propose using\ndifferent multi-modal losses to explicitly guide the acoustic embeddings to be\ncloser to the text embeddings, obtained from a semantically powerful\npre-trained BERT model. We train the CMLS model on two publicly available E2E\ndatasets, across different cross-modal losses and show that our proposed\ntriplet loss function achieves the best performance. It achieves a relative\nimprovement of 1.4% and 4% respectively over an E2E model without a cross-modal\nspace and a relative improvement of 0.7% and 1% over a previously published\nCMLS model using $L_2$ loss. The gains are higher for a smaller, more\ncomplicated E2E dataset, demonstrating the efficacy of using an efficient\ncross-modal loss function, especially when there is limited E2E training data\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:32:42 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 16:38:29 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Agrawal", "Bhuvan", ""], ["M\u00fcller", "Markus", ""], ["Radfar", "Martin", ""], ["Choudhary", "Samridhi", ""], ["Mouchtaris", "Athanasios", ""], ["Kunzmann", "Siegfried", ""]]}, {"id": "2011.09046", "submitter": "Bowen Zhang", "authors": "Bowen Zhang, Hexiang Hu, Joonseok Lee, Ming Zhao, Sheide Chammas,\n  Vihan Jain, Eugene Ie, Fei Sha", "title": "A Hierarchical Multi-Modal Encoder for Moment Localization in Video\n  Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying a short segment in a long video that semantically matches a text\nquery is a challenging task that has important application potentials in\nlanguage-based video search, browsing, and navigation. Typical retrieval\nsystems respond to a query with either a whole video or a pre-defined video\nsegment, but it is challenging to localize undefined segments in untrimmed and\nunsegmented videos where exhaustively searching over all possible segments is\nintractable. The outstanding challenge is that the representation of a video\nmust account for different levels of granularity in the temporal domain. To\ntackle this problem, we propose the HierArchical Multi-Modal EncodeR (HAMMER)\nthat encodes a video at both the coarse-grained clip level and the fine-grained\nframe level to extract information at different scales based on multiple\nsubtasks, namely, video retrieval, segment temporal localization, and masked\nlanguage modeling. We conduct extensive experiments to evaluate our model on\nmoment localization in video corpus on ActivityNet Captions and TVR datasets.\nOur approach outperforms the previous methods as well as strong baselines,\nestablishing new state-of-the-art for this task.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:42:36 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 04:11:13 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Zhang", "Bowen", ""], ["Hu", "Hexiang", ""], ["Lee", "Joonseok", ""], ["Zhao", "Ming", ""], ["Chammas", "Sheide", ""], ["Jain", "Vihan", ""], ["Ie", "Eugene", ""], ["Sha", "Fei", ""]]}, {"id": "2011.09140", "submitter": "Tomohide Shibata", "authors": "Shogo Fujita and Tomohide Shibata and Manabu Okumura", "title": "Diverse and Non-redundant Answer Set Extraction on Community QA based on\n  DPPs", "comments": "COLING2020, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In community-based question answering (CQA) platforms, it takes time for a\nuser to get useful information from among many answers. Although one solution\nis an answer ranking method, the user still needs to read through the\ntop-ranked answers carefully. This paper proposes a new task of selecting a\ndiverse and non-redundant answer set rather than ranking the answers. Our\nmethod is based on determinantal point processes (DPPs), and it calculates the\nanswer importance and similarity between answers by using BERT. We built a\ndataset focusing on a Japanese CQA site, and the experiments on this dataset\ndemonstrated that the proposed method outperformed several baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:33:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fujita", "Shogo", ""], ["Shibata", "Tomohide", ""], ["Okumura", "Manabu", ""]]}, {"id": "2011.09159", "submitter": "Ke Shen", "authors": "Mayank Kejriwal and Ke Shen", "title": "Do Fine-tuned Commonsense Language Models Really Generalize?", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, transformer-based methods such as RoBERTa and GPT-3 have led to\nsignificant experimental advances in natural language processing tasks such as\nquestion answering and commonsense reasoning. The latter is typically evaluated\nthrough multiple benchmarks framed as multiple-choice instances of the former.\nAccording to influential leaderboards hosted by the Allen Institute (evaluating\nstate-of-the-art performance on commonsense reasoning benchmarks), models based\non such transformer methods are approaching human-like performance and have\naverage accuracy well over 80% on many benchmarks. Since these are commonsense\nbenchmarks, a model that generalizes on commonsense reasoning should not\nexperience much performance loss across multiple commonsense benchmarks. In\nthis paper, we study the generalization issue in detail by designing and\nconducting a rigorous scientific study. Using five common benchmarks, multiple\ncontrols and statistical analysis, we find clear evidence that fine-tuned\ncommonsense language models still do not generalize well, even with moderate\nchanges to the experimental setup, and may, in fact, be susceptible to dataset\nbias. We also perform selective studies, including qualitative and consistency\nanalyses, to gain deeper insight into the problem.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 08:52:49 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Shen", "Ke", ""]]}, {"id": "2011.09210", "submitter": "Chenyang Lyu", "authors": "Chenyang Lyu, Jennifer Foster, Yvette Graham", "title": "Improving Document-Level Sentiment Analysis with User and Product\n  Context", "comments": "Accepted to COLING 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Past work that improves document-level sentiment analysis by encoding user\nand product information has been limited to considering only the text of the\ncurrent review. We investigate incorporating additional review text available\nat the time of sentiment prediction that may prove meaningful for guiding\nprediction. Firstly, we incorporate all available historical review text\nbelonging to the author of the review in question. Secondly, we investigate the\ninclusion of historical reviews associated with the current product (written by\nother users). We achieve this by explicitly storing representations of reviews\nwritten by the same user and about the same product and force the model to\nmemorize all reviews for one particular user and product. Additionally, we drop\nthe hierarchical architecture used in previous work to enable words in the text\nto directly attend to each other. Experiment results on IMDB, Yelp 2013 and\nYelp 2014 datasets show improvement to state-of-the-art of more than 2\npercentage points in the best case.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 10:59:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Lyu", "Chenyang", ""], ["Foster", "Jennifer", ""], ["Graham", "Yvette", ""]]}, {"id": "2011.09212", "submitter": "Yannick Est\\`eve", "authors": "Manon Macary, Marie Tahon, Yannick Est\\`eve, Anthony Rousseau", "title": "On the use of Self-supervised Pre-trained Acoustic and Linguistic\n  Features for Continuous Speech Emotion Recognition", "comments": "Accepted in IEEE SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-training for feature extraction is an increasingly studied approach to\nget better continuous representations of audio and text content. In the present\nwork, we use wav2vec and camemBERT as self-supervised learned models to\nrepresent our data in order to perform continuous emotion recognition from\nspeech (SER) on AlloSat, a large French emotional database describing the\nsatisfaction dimension, and on the state of the art corpus SEWA focusing on\nvalence, arousal and liking dimensions. To the authors' knowledge, this paper\npresents the first study showing that the joint use of wav2vec and BERT-like\npre-trained features is very relevant to deal with continuous SER task, usually\ncharacterized by a small amount of labeled training data. Evaluated by the\nwell-known concordance correlation coefficient (CCC), our experiments show that\nwe can reach a CCC value of 0.825 instead of 0.592 when using MFCC in\nconjunction with word2vec word embedding on the AlloSat dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 11:10:29 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Macary", "Manon", ""], ["Tahon", "Marie", ""], ["Est\u00e8ve", "Yannick", ""], ["Rousseau", "Anthony", ""]]}, {"id": "2011.09249", "submitter": "Fran\\c{c}ois Hernandez", "authors": "Fran\\c{c}ois Hernandez and Vincent Nguyen", "title": "The Ubiqus English-Inuktitut System for WMT20", "comments": "System Description paper for WMT 2020 English-Inuktitut News\n  Translation Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper describes Ubiqus' submission to the WMT20 English-Inuktitut shared\nnews translation task. Our main system, and only submission, is based on a\nmultilingual approach, jointly training a Transformer model on several\nagglutinative languages. The English-Inuktitut translation task is challenging\nat every step, from data selection, preparation and tokenization to quality\nevaluation down the line. Difficulties emerge both because of the peculiarities\nof the Inuktitut language as well as the low-resource context.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 12:49:17 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Hernandez", "Fran\u00e7ois", ""], ["Nguyen", "Vincent", ""]]}, {"id": "2011.09257", "submitter": "Pablo Pino", "authors": "Pablo Pino, Denis Parra, Pablo Messina, Cecilia Besa, Sergio Uribe", "title": "Inspecting state of the art performance and NLP metrics in image-based\n  medical report generation", "comments": "3 pages, 1 figure, 1 table. Accepted in LatinX in AI workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several deep learning architectures have been proposed over the last years to\ndeal with the problem of generating a written report given an imaging exam as\ninput. Most works evaluate the generated reports using standard Natural\nLanguage Processing (NLP) metrics (e.g. BLEU, ROUGE), reporting significant\nprogress. In this article, we contrast this progress by comparing state of the\nart (SOTA) models against weak baselines. We show that simple and even naive\napproaches yield near SOTA performance on most traditional NLP metrics. We\nconclude that evaluation methods in this task should be further studied towards\ncorrectly measuring clinical accuracy, ideally involving physicians to\ncontribute to this end.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:09:12 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 17:58:40 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pino", "Pablo", ""], ["Parra", "Denis", ""], ["Messina", "Pablo", ""], ["Besa", "Cecilia", ""], ["Uribe", "Sergio", ""]]}, {"id": "2011.09272", "submitter": "Mireia Farr\\'us", "authors": "Mireia Farr\\'us, Joan Codina-Filb\\`a", "title": "Combining Prosodic, Voice Quality and Lexical Features to Automatically\n  Detect Alzheimer's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Alzheimer's Disease (AD) is nowadays the most common form of dementia, and\nits automatic detection can help to identify symptoms at early stages, so that\npreventive actions can be carried out. Moreover, non-intrusive techniques based\non spoken data are crucial for the development of AD automatic detection\nsystems. In this light, this paper is presented as a contribution to the ADReSS\nChallenge, aiming at improving AD automatic detection from spontaneous speech.\nTo this end, recordings from 108 participants, which are age-, gender-, and AD\ncondition-balanced, have been used as training set to perform two different\ntasks: classification into AD/non-AD conditions, and regression over the\nMini-Mental State Examination (MMSE) scores. Both tasks have been performed\nextracting 28 features from speech -- based on prosody and voice quality -- and\n51 features from the transcriptions -- based on lexical and turn-taking\ninformation. Our results achieved up to 87.5 % of classification accuracy using\na Random Forest classifier, and 4.54 of RMSE using a linear regression with\nstochastic gradient descent over the provided test set. This shows promising\nresults in the automatic detection of Alzheimer's Disease through speech and\nlexical features.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:37:27 GMT"}], "update_date": "2020-11-21", "authors_parsed": [["Farr\u00fas", "Mireia", ""], ["Codina-Filb\u00e0", "Joan", ""]]}, {"id": "2011.09289", "submitter": "Alptekin Orbay", "authors": "Alptekin Orbay", "title": "Master Thesis: Neural Sign Language Translation by Learning Tokenization", "comments": "MS Thesis Extension of the Paper with the same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this thesis, we propose a multitask learning based method to improve\nNeural Sign Language Translation (NSLT) consisting of two parts, a tokenization\nlayer and Neural Machine Translation (NMT). The tokenization part focuses on\nhow Sign Language (SL) videos should be represented to be fed into the other\npart. It has not been studied elaborately whereas NMT research has attracted\nseveral researchers contributing enormous advancements. Up to now, there are\ntwo main input tokenization levels, namely frame-level and gloss-level\ntokenization. Glosses are world-like intermediate presentation and unique to\nSLs. Therefore, we aim to develop a generic sign-level tokenization layer so\nthat it is applicable to other domains without further effort. We begin with\ninvestigating current tokenization approaches and explain their weaknesses with\nseveral experiments. To provide a solution, we adapt Transfer Learning,\nMultitask Learning and Unsupervised Domain Adaptation into this research to\nleverage additional supervision. We succeed in enabling knowledge transfer\nbetween SLs and improve translation quality by 5 points in BLEU-4 and 8 points\nin ROUGE scores. Secondly, we show the effects of body parts by extensive\nexperiments in all the tokenization approaches. Apart from these, we adopt\n3D-CNNs to improve efficiency in terms of time and space. Lastly, we discuss\nthe advantages of sign-level tokenization over gloss-level tokenization. To sum\nup, our proposed method eliminates the need for gloss level annotation to\nobtain higher scores by providing additional supervision by utilizing weak\nsupervision sources.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:59:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Orbay", "Alptekin", ""]]}, {"id": "2011.09351", "submitter": "Uwe Aickelin", "authors": "Chaofan Tu, Ruibin Bai, Zheng Lu, Uwe Aickelin, Peiming Ge, Jianshuang\n  Zhao", "title": "Learning Regular Expressions for Interpretable Medical Text\n  Classification Using a Pool-based Simulated Annealing and Word-vector Models", "comments": "9th Multidisciplinary International Conference on Scheduling : Theory\n  and Applications (MISTA 2019) 12-15 December 2019, Ningbo, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a rule-based engine composed of high quality and\ninterpretable regular expressions for medical text classification. The regular\nexpressions are auto generated by a constructive heuristic method and optimized\nusing a Pool-based Simulated Annealing (PSA) approach. Although existing Deep\nNeural Network (DNN) methods present high quality performance in most Natural\nLanguage Processing (NLP) applications, the solutions are regarded as\nuninterpretable black boxes to humans. Therefore, rule-based methods are often\nintroduced when interpretable solutions are needed, especially in the medical\nfield. However, the construction of regular expressions can be extremely\nlabor-intensive for large data sets. This research aims to reduce the manual\nefforts while maintaining high-quality solutions\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 07:20:02 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tu", "Chaofan", ""], ["Bai", "Ruibin", ""], ["Lu", "Zheng", ""], ["Aickelin", "Uwe", ""], ["Ge", "Peiming", ""], ["Zhao", "Jianshuang", ""]]}, {"id": "2011.09378", "submitter": "Nurul Lubis", "authors": "Nurul Lubis, Christian Geishauser, Michael Heck, Hsien-chin Lin, Marco\n  Moresi, Carel van Niekerk and Milica Ga\\v{s}i\\'c", "title": "LAVA: Latent Action Spaces via Variational Auto-encoding for Dialogue\n  Policy Optimization", "comments": "15 pages. To be published as long paper in Proceedings of The 28th\n  International Conference on Computational Linguistics (COLING 2020). Code can\n  be accessed at https://gitlab.cs.uni-duesseldorf.de/general/dsml/lava-public", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) can enable task-oriented dialogue systems to\nsteer the conversation towards successful task completion. In an end-to-end\nsetting, a response can be constructed in a word-level sequential decision\nmaking process with the entire system vocabulary as action space. Policies\ntrained in such a fashion do not require expert-defined action spaces, but they\nhave to deal with large action spaces and long trajectories, making RL\nimpractical. Using the latent space of a variational model as action space\nalleviates this problem. However, current approaches use an uninformed prior\nfor training and optimize the latent distribution solely on the context. It is\ntherefore unclear whether the latent representation truly encodes the\ncharacteristics of different actions. In this paper, we explore three ways of\nleveraging an auxiliary task to shape the latent variable distribution: via\npre-training, to obtain an informed prior, and via multitask learning. We\nchoose response auto-encoding as the auxiliary task, as this captures the\ngenerative factors of dialogue responses while requiring low computational cost\nand neither additional data nor labels. Our approach yields a more\naction-characterized latent representations which support end-to-end dialogue\npolicy optimization and achieves state-of-the-art success rates. These results\nwarrant a more wide-spread use of RL in end-to-end dialogue models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:23:30 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Lubis", "Nurul", ""], ["Geishauser", "Christian", ""], ["Heck", "Michael", ""], ["Lin", "Hsien-chin", ""], ["Moresi", "Marco", ""], ["van Niekerk", "Carel", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "2011.09379", "submitter": "Michael Heck", "authors": "Michael Heck, Carel van Niekerk, Nurul Lubis, Christian Geishauser,\n  Hsien-Chin Lin, Marco Moresi, Milica Ga\\v{s}i\\'c", "title": "Out-of-Task Training for Dialog State Tracking Models", "comments": "8 pages, 2 figures, to be published in Proceedings of the 28th\n  International Conference on Computational Linguistics, Code at\n  https://gitlab.cs.uni-duesseldorf.de/general/dsml/trippy-public", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialog state tracking (DST) suffers from severe data sparsity. While many\nnatural language processing (NLP) tasks benefit from transfer learning and\nmulti-task learning, in dialog these methods are limited by the amount of\navailable data and by the specificity of dialog applications. In this work, we\nsuccessfully utilize non-dialog data from unrelated NLP tasks to train dialog\nstate trackers. This opens the door to the abundance of unrelated NLP corpora\nto mitigate the data sparsity issue inherent to DST.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:23:30 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Heck", "Michael", ""], ["van Niekerk", "Carel", ""], ["Lubis", "Nurul", ""], ["Geishauser", "Christian", ""], ["Lin", "Hsien-Chin", ""], ["Moresi", "Marco", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "2011.09410", "submitter": "Deokgun Park", "authors": "Deokgun Park", "title": "A Definition and a Test for Human-Level Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in many application-specific domains, we do not know\nhow to build a human-level artificial intelligence (HLAI). We conjecture that\nlearning from others' experience with the language is the essential\ncharacteristic that distinguishes human intelligence from the rest. Humans can\nupdate the action-value function with the verbal description as if they\nexperience states, actions, and corresponding rewards sequences firsthand. In\nthis paper, we present a classification of intelligence according to how\nindividual agents learn and propose a definition and a test for HLAI. The main\nidea is that language acquisition without explicit rewards can be a sufficient\ntest for HLAI.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:10:02 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 17:14:29 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 21:54:04 GMT"}, {"version": "v4", "created": "Sat, 17 Jul 2021 21:30:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Park", "Deokgun", ""]]}, {"id": "2011.09413", "submitter": "Milica Gasic", "authors": "Alexander Jakubowski, Milica Ga\\v{s}i\\'c, Marcus Zibrowius", "title": "Topology of Word Embeddings: Singularities Reflect Polysemy", "comments": "Accepted at the 9th Joint Conference on Lexical and Computational\n  Semantics (*SEM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The manifold hypothesis suggests that word vectors live on a submanifold\nwithin their ambient vector space. We argue that we should, more accurately,\nexpect them to live on a pinched manifold: a singular quotient of a manifold\nobtained by identifying some of its points. The identified, singular points\ncorrespond to polysemous words, i.e. words with multiple meanings. Our point of\nview suggests that monosemous and polysemous words can be distinguished based\non the topology of their neighbourhoods. We present two kinds of empirical\nevidence to support this point of view: (1) We introduce a topological measure\nof polysemy based on persistent homology that correlates well with the actual\nnumber of meanings of a word. (2) We propose a simple, topologically motivated\nsolution to the SemEval-2010 task on Word Sense Induction & Disambiguation that\nproduces competitive results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:21:51 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Jakubowski", "Alexander", ""], ["Ga\u0161i\u0107", "Milica", ""], ["Zibrowius", "Marcus", ""]]}, {"id": "2011.09448", "submitter": "Daniel Palomino", "authors": "Daniel Palomino and Jose Ochoa-Luna", "title": "Palomino-Ochoa at SemEval-2020 Task 9: Robust System based on\n  Transformer for Code-Mixed Sentiment Classification", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a transfer learning system to perform a mixed Spanish-English\nsentiment classification task. Our proposal uses the state-of-the-art language\nmodel BERT and embed it within a ULMFiT transfer learning pipeline. This\ncombination allows us to predict the polarity detection of code-mixed\n(English-Spanish) tweets. Thus, among 29 submitted systems, our approach\n(referred to as dplominop) is ranked 4th on the Sentimix Spanglish test set of\nSemEval 2020 Task 9. In fact, our system yields the weighted-F1 score value of\n0.755 which can be easily reproduced -- the source code and implementation\ndetails are made available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:25:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Palomino", "Daniel", ""], ["Ochoa-Luna", "Jose", ""]]}, {"id": "2011.09463", "submitter": "Minghui Qiu", "authors": "Minghui Qiu and Peng Li and Hanjie Pan and Chengyu Wang and Ang Wang\n  and Cen Chen and Yaliang Li and Dehong Gao and Jun Huang and Yong Li and Jun\n  Yang and Deng Cai and Wei Lin", "title": "EasyTransfer -- A Simple and Scalable Deep Transfer Learning Platform\n  for NLP Applications", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The literature has witnessed the success of applying deep Transfer Learning\n(TL) algorithms to many NLP applications, yet it is not easy to build a simple\nand scalable TL toolkit for this purpose. To bridge this gap, the EasyTransfer\nplatform is designed to make it easy to develop deep TL algorithms for NLP\napplications. It is built with rich API abstractions, a scalable architecture\nand comprehensive deep TL algorithms, to make the development of NLP\napplications easier. To be specific, the build-in data and model parallelism\nstrategy shows to be 4x faster than the default distribution strategy of\nTensorflow. EasyTransfer supports the mainstream pre-trained ModelZoo,\nincluding Pre-trained Language Models (PLMs) and multi-modality models. It also\nintegrates various SOTA models for mainstream NLP applications in AppZoo, and\nsupports mainstream TL algorithms as well. The toolkit is convenient for users\nto quickly start model training, evaluation, offline prediction, and online\ndeployment. This system is currently deployed at Alibaba to support a variety\nof business scenarios, including item recommendation, personalized search, and\nconversational question answering. Extensive experiments on real-world datasets\nshow that EasyTransfer is suitable for online production with cutting-edge\nperformance. The source code of EasyTransfer is released at Github\n(https://github.com/alibaba/EasyTransfer).\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:41:27 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 05:45:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Qiu", "Minghui", ""], ["Li", "Peng", ""], ["Pan", "Hanjie", ""], ["Wang", "Chengyu", ""], ["Wang", "Ang", ""], ["Chen", "Cen", ""], ["Li", "Yaliang", ""], ["Gao", "Dehong", ""], ["Huang", "Jun", ""], ["Li", "Yong", ""], ["Yang", "Jun", ""], ["Cai", "Deng", ""], ["Lin", "Wei", ""]]}, {"id": "2011.09553", "submitter": "Yue Feng", "authors": "Yue Feng, Yang Wang, Hang Li", "title": "A Sequence-to-Sequence Approach to Dialogue State Tracking", "comments": "Accepted by ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned with dialogue state tracking (DST) in a task-oriented\ndialogue system. Building a DST module that is highly effective is still a\nchallenging issue, although significant progresses have been made recently.\nThis paper proposes a new approach to dialogue state tracking, referred to as\nSeq2Seq-DU, which formalizes DST as a sequence-to-sequence problem. Seq2Seq-DU\nemploys two BERT-based encoders to respectively encode the utterances in the\ndialogue and the descriptions of schemas, an attender to calculate attentions\nbetween the utterance embeddings and the schema embeddings, and a decoder to\ngenerate pointers to represent the current state of dialogue. Seq2Seq-DU has\nthe following advantages. It can jointly model intents, slots, and slot values;\nit can leverage the rich representations of utterances and schemas based on\nBERT; it can effectively deal with categorical and non-categorical slots, and\nunseen schemas. In addition, Seq2Seq-DU can also be used in the NLU (natural\nlanguage understanding) module of a dialogue system. Experimental results on\nbenchmark datasets in different settings (SGD, MultiWOZ2.2, MultiWOZ2.1,\nWOZ2.0, DSTC2, M2M, SNIPS, and ATIS) show that Seq2Seq-DU outperforms the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 21:42:44 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 02:48:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Feng", "Yue", ""], ["Wang", "Yang", ""], ["Li", "Hang", ""]]}, {"id": "2011.09567", "submitter": "Javier de la Rosa", "authors": "Javier de la Rosa, Salvador Ros, Elena Gonz\\'alez-Blanco", "title": "Predicting metrical patterns in Spanish poetry with language models", "comments": "LXAI Workshop @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we compare automated metrical pattern identification systems\navailable for Spanish against extensive experiments done by fine-tuning\nlanguage models trained on the same task. Despite being initially conceived as\na model suitable for semantic tasks, our results suggest that BERT-based models\nretain enough structural information to perform reasonably well for Spanish\nscansion.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 22:33:09 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["de la Rosa", "Javier", ""], ["Ros", "Salvador", ""], ["Gonz\u00e1lez-Blanco", "Elena", ""]]}, {"id": "2011.09625", "submitter": "John Chen", "authors": "John Chen, Ian Berlot-Attwell, Safwan Hossain, Xindi Wang and Frank\n  Rudzicz", "title": "Exploring Text Specific and Blackbox Fairness Algorithms in Multimodal\n  Clinical NLP", "comments": "Best paper award at 3rd Clinical Natural Language Processing Workshop\n  at EMNLP 2020", "journal-ref": "Proceedings of the 3rd Clinical Natural Language Processing\n  Workshop (2020), pages 301--312", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Clinical machine learning is increasingly multimodal, collected in both\nstructured tabular formats and unstructured forms such as freetext. We propose\na novel task of exploring fairness on a multimodal clinical dataset, adopting\nequalized odds for the downstream medical prediction tasks. To this end, we\ninvestigate a modality-agnostic fairness algorithm - equalized odds post\nprocessing - and compare it to a text-specific fairness algorithm: debiased\nclinical word embeddings. Despite the fact that debiased word embeddings do not\nexplicitly address equalized odds of protected groups, we show that a\ntext-specific approach to fairness may simultaneously achieve a good balance of\nperformance and classical notions of fairness. We hope that our paper inspires\nfuture contributions at the critical intersection of clinical NLP and fairness.\nThe full source code is available here:\nhttps://github.com/johntiger1/multimodal_fairness\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 03:11:24 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 15:54:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chen", "John", ""], ["Berlot-Attwell", "Ian", ""], ["Hossain", "Safwan", ""], ["Wang", "Xindi", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2011.09631", "submitter": "Won Jang", "authors": "Won Jang, Dan Lim, Jaesam Yoon", "title": "Universal MelGAN: A Robust Neural Vocoder for High-Fidelity Waveform\n  Generation in Multiple Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Universal MelGAN, a vocoder that synthesizes high-fidelity speech\nin multiple domains. To preserve sound quality when the MelGAN-based structure\nis trained with a dataset of hundreds of speakers, we added multi-resolution\nspectrogram discriminators to sharpen the spectral resolution of the generated\nwaveforms. This enables the model to generate realistic waveforms of\nmulti-speakers, by alleviating the over-smoothing problem in the high frequency\nband of the large footprint model. Our structure generates signals close to\nground-truth data without reducing the inference speed, by discriminating the\nwaveform and spectrogram during training. The model achieved the best mean\nopinion score (MOS) in most scenarios using ground-truth mel-spectrogram as an\ninput. Especially, it showed superior performance in unseen domains with regard\nof speaker, emotion, and language. Moreover, in a multi-speaker text-to-speech\nscenario using mel-spectrogram generated by a transformer model, it synthesized\nhigh-fidelity speech of 4.22 MOS. These results, achieved without external\ndomain information, highlight the potential of the proposed model as a\nuniversal vocoder.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 03:35:45 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 02:00:12 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Jang", "Won", ""], ["Lim", "Dan", ""], ["Yoon", "Jaesam", ""]]}, {"id": "2011.09658", "submitter": "Xiaoyu Chen", "authors": "Xiaoyu Chen and Rohan Badlani", "title": "Relation Extraction with Contextualized Relation Embedding (CRE)", "comments": "EMNLP 2020 Workshop: Deep Learning Inside Out (DeeLIO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Relation extraction is the task of identifying relation instance between two\nentities given a corpus whereas Knowledge base modeling is the task of\nrepresenting a knowledge base, in terms of relations between entities. This\npaper proposes an architecture for the relation extraction task that integrates\nsemantic information with knowledge base modeling in a novel manner. Existing\napproaches for relation extraction either do not utilize knowledge base\nmodelling or use separately trained KB models for the RE task. We present a\nmodel architecture that internalizes KB modeling in relation extraction. This\nmodel applies a novel approach to encode sentences into contextualized relation\nembeddings, which can then be used together with parameterized entity\nembeddings to score relation instances. The proposed CRE model achieves state\nof the art performance on datasets derived from The New York Times Annotated\nCorpus and FreeBase. The source code has been made available.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 05:19:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chen", "Xiaoyu", ""], ["Badlani", "Rohan", ""]]}, {"id": "2011.09684", "submitter": "Omar Sharif", "authors": "Eftekhar Hossain, Omar Sharif, Mohammed Moshiul Hoque, Iqbal H. Sarker", "title": "SentiLSTM: A Deep Learning Approach for Sentiment Analysis of Restaurant\n  Reviews", "comments": "13 page, will appear in 20th International Conference on Hybrid\n  Intelligent Systems (HIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The amount of textual data generation has increased enormously due to the\neffortless access of the Internet and the evolution of various web 2.0\napplications. These textual data productions resulted because of the people\nexpress their opinion, emotion or sentiment about any product or service in the\nform of tweets, Facebook post or status, blog write up, and reviews. Sentiment\nanalysis deals with the process of computationally identifying and categorizing\nopinions expressed in a piece of text, especially in order to determine whether\nthe writer's attitude toward a particular topic is positive, negative, or\nneutral. The impact of customer review is significant to perceive the customer\nattitude towards a restaurant. Thus, the automatic detection of sentiment from\nreviews is advantageous for the restaurant owners, or service providers and\ncustomers to make their decisions or services more satisfactory. This paper\nproposes, a deep learning-based technique (i.e., BiLSTM) to classify the\nreviews provided by the clients of the restaurant into positive and negative\npolarities. A corpus consists of 8435 reviews is constructed to evaluate the\nproposed technique. In addition, a comparative analysis of the proposed\ntechnique with other machine learning algorithms presented. The results of the\nevaluation on test dataset show that BiLSTM technique produced in the highest\naccuracy of 91.35%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 06:24:42 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Hossain", "Eftekhar", ""], ["Sharif", "Omar", ""], ["Hoque", "Mohammed Moshiul", ""], ["Sarker", "Iqbal H.", ""]]}, {"id": "2011.09708", "submitter": "Yufan Zhao", "authors": "Yufan Zhao, Wei Wu, Can Xu", "title": "Are Pre-trained Language Models Knowledgeable to Ground Open Domain\n  Dialogues?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study knowledge-grounded dialogue generation with pre-trained language\nmodels. Instead of pursuing new state-of-the-art on benchmarks, we try to\nunderstand if the knowledge stored in parameters of the pre-trained models is\nalready enough to ground open domain dialogues, and thus allows us to get rid\nof the dependency on external knowledge sources in generation. Through\nextensive experiments on benchmarks, we find that by fine-tuning with a few\ndialogues containing knowledge, the pre-trained language models can outperform\nthe state-of-the-art model that requires external knowledge in automatic\nevaluation and human judgment, suggesting a positive answer to the question we\nraised.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:22:49 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhao", "Yufan", ""], ["Wu", "Wei", ""], ["Xu", "Can", ""]]}, {"id": "2011.09739", "submitter": "Ruifeng Yuan", "authors": "Ruifeng Yuan, Zili Wang, Wenjie Li", "title": "Fact-level Extractive Summarization with Hierarchical Graph Mask on BERT", "comments": "Accept by Coling2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most current extractive summarization models generate summaries by selecting\nsalient sentences. However, one of the problems with sentence-level extractive\nsummarization is that there exists a gap between the human-written gold summary\nand the oracle sentence labels. In this paper, we propose to extract fact-level\nsemantic units for better extractive summarization. We also introduce a\nhierarchical structure, which incorporates the multi-level of granularities of\nthe textual information into the model. In addition, we incorporate our model\nwith BERT using a hierarchical graph mask. This allows us to combine BERT's\nability in natural language understanding and the structural information\nwithout increasing the scale of the model. Experiments on the CNN/DaliyMail\ndataset show that our model achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:29:51 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Yuan", "Ruifeng", ""], ["Wang", "Zili", ""], ["Li", "Wenjie", ""]]}, {"id": "2011.09754", "submitter": "Soumyadeep Roy", "authors": "Soumyadeep Roy, Shamik Sural, Niyati Chhaya, Anandhavelu Natarajan,\n  Niloy Ganguly", "title": "An Integrated Approach for Improving Brand Consistency of Web Content:\n  Modeling, Analysis and Recommendation", "comments": "25 pages, Accepted for publication at ACM Transactions on the Web\n  (TWEB)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A consumer-dependent (business-to-consumer) organization tends to present\nitself as possessing a set of human qualities, which is termed as the brand\npersonality of the company. The perception is impressed upon the consumer\nthrough the content, be it in the form of advertisement, blogs or magazines,\nproduced by the organization. A consistent brand will generate trust and retain\ncustomers over time as they develop an affinity towards regularity and common\npatterns. However, maintaining a consistent messaging tone for a brand has\nbecome more challenging with the virtual explosion in the amount of content\nwhich needs to be authored and pushed to the Internet to maintain an edge in\nthe era of digital marketing. To understand the depth of the problem, we\ncollect around 300K web page content from around 650 companies. We develop\ntrait-specific classification models by considering the linguistic features of\nthe content. The classifier automatically identifies the web articles which are\nnot consistent with the mission and vision of a company and further helps us to\ndiscover the conditions under which the consistency cannot be maintained. To\naddress the brand inconsistency issue, we then develop a sentence ranking\nsystem that outputs the top three sentences that need to be changed for making\na web article more consistent with the company's brand personality.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:18:47 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 03:09:37 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Roy", "Soumyadeep", ""], ["Sural", "Shamik", ""], ["Chhaya", "Niyati", ""], ["Natarajan", "Anandhavelu", ""], ["Ganguly", "Niloy", ""]]}, {"id": "2011.09767", "submitter": "Sattaya Singkul", "authors": "Sattaya Singkul, Thakorn Chatchaisathaporn, Boontawee Suntisrivaraporn\n  and Kuntpong Woraratpanya", "title": "Deep Residual Local Feature Learning for Speech Emotion Recognition", "comments": "12 pages, 5 figures, submitted for review", "journal-ref": null, "doi": "10.1007/978-3-030-63830-6_21", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Speech Emotion Recognition (SER) is becoming a key role in global business\ntoday to improve service efficiency, like call center services. Recent SERs\nwere based on a deep learning approach. However, the efficiency of deep\nlearning depends on the number of layers, i.e., the deeper layers, the higher\nefficiency. On the other hand, the deeper layers are causes of a vanishing\ngradient problem, a low learning rate, and high time-consuming. Therefore, this\npaper proposed a redesign of existing local feature learning block (LFLB). The\nnew design is called a deep residual local feature learning block\n(DeepResLFLB). DeepResLFLB consists of three cascade blocks: LFLB, residual\nlocal feature learning block (ResLFLB), and multilayer perceptron (MLP). LFLB\nis built for learning local correlations along with extracting hierarchical\ncorrelations; DeepResLFLB can take advantage of repeatedly learning to explain\nmore detail in deeper layers using residual learning for solving vanishing\ngradient and reducing overfitting; and MLP is adopted to find the relationship\nof learning and discover probability for predicted speech emotions and gender\ntypes. Based on two available published datasets: EMODB and RAVDESS, the\nproposed DeepResLFLB can significantly improve performance when evaluated by\nstandard metrics: accuracy, precision, recall, and F1-score.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 11:04:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Singkul", "Sattaya", ""], ["Chatchaisathaporn", "Thakorn", ""], ["Suntisrivaraporn", "Boontawee", ""], ["Woraratpanya", "Kuntpong", ""]]}, {"id": "2011.09804", "submitter": "Manuel Sam Ribeiro", "authors": "Manuel Sam Ribeiro, Jennifer Sanger, Jing-Xuan Zhang, Aciel Eshky,\n  Alan Wrench, Korin Richmond, Steve Renals", "title": "TaL: a synchronised multi-speaker corpus of ultrasound tongue imaging,\n  audio, and lip videos", "comments": "8 pages, 4 figures, Accepted to SLT2021, IEEE Spoken Language\n  Technology Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.SD eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Tongue and Lips corpus (TaL), a multi-speaker corpus of audio,\nultrasound tongue imaging, and lip videos. TaL consists of two parts: TaL1 is a\nset of six recording sessions of one professional voice talent, a male native\nspeaker of English; TaL80 is a set of recording sessions of 81 native speakers\nof English without voice talent experience. Overall, the corpus contains 24\nhours of parallel ultrasound, video, and audio data, of which approximately\n13.5 hours are speech. This paper describes the corpus and presents benchmark\nresults for the tasks of speech recognition, speech synthesis\n(articulatory-to-acoustic mapping), and automatic synchronisation of ultrasound\nto audio. The TaL corpus is publicly available under the CC BY-NC 4.0 license.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:11:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ribeiro", "Manuel Sam", ""], ["Sanger", "Jennifer", ""], ["Zhang", "Jing-Xuan", ""], ["Eshky", "Aciel", ""], ["Wrench", "Alan", ""], ["Richmond", "Korin", ""], ["Renals", "Steve", ""]]}, {"id": "2011.09817", "submitter": "Tatiana Batura", "authors": "Elena Bruches, Alexey Pauls, Tatiana Batura, Vladimir Isachenko", "title": "Entity Recognition and Relation Extraction from Scientific and Technical\n  Texts in Russian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is devoted to the study of methods for information extraction\n(entity recognition and relation classification) from scientific texts on\ninformation technology. Scientific publications provide valuable information\ninto cutting-edge scientific advances, but efficient processing of increasing\namounts of data is a time-consuming task. In this paper, several modifications\nof methods for the Russian language are proposed. It also includes the results\nof experiments comparing a keyword extraction method, vocabulary method, and\nsome methods based on neural networks. Text collections for these tasks exist\nfor the English language and are actively used by the scientific community, but\nat present, such datasets in Russian are not publicly available. In this paper,\nwe present a corpus of scientific texts in Russian, RuSERRC. This dataset\nconsists of 1600 unlabeled documents and 80 labeled with entities and semantic\nrelations (6 relation types were considered). The dataset and models are\navailable at https://github.com/iis-research-team. We hope they can be useful\nfor research purposes and development of information extraction systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:40:03 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 02:48:25 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 08:21:42 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Bruches", "Elena", ""], ["Pauls", "Alexey", ""], ["Batura", "Tatiana", ""], ["Isachenko", "Vladimir", ""]]}, {"id": "2011.09825", "submitter": "Petr Marek", "authors": "Petr Lorenc, Petr Marek, Jan Pichl, Jakub Konr\\'ad and Jan\n  \\v{S}ediv\\'y", "title": "Do We Need Online NLU Tools?", "comments": "8 pages, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intent recognition is an essential algorithm of any conversational AI\napplication. It is responsible for the classification of an input message into\nmeaningful classes. In many bot development platforms, we can configure the NLU\npipeline. Several intent recognition services are currently available as an\nAPI, or we choose from many open-source alternatives. However, there is no\ncomparison of intent recognition services and open-source algorithms. Many\nfactors make the selection of the right approach to the intent recognition\nchallenging in practice. In this paper, we suggest criteria to choose the best\nintent recognition algorithm for an application. We present a dataset for\nevaluation. Finally, we compare selected public NLU services with selected\nopen-source algorithms for intent recognition.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:58:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lorenc", "Petr", ""], ["Marek", "Petr", ""], ["Pichl", "Jan", ""], ["Konr\u00e1d", "Jakub", ""], ["\u0160ediv\u00fd", "Jan", ""]]}, {"id": "2011.09846", "submitter": "Ben Saunders", "authors": "Ben Saunders, Necati Cihan Camgoz, Richard Bowden", "title": "Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign\n  Language Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be truly understandable and accepted by Deaf communities, an automatic\nSign Language Production (SLP) system must generate a photo-realistic signer.\nPrior approaches based on graphical avatars have proven unpopular, whereas\nrecent neural SLP works that produce skeleton pose sequences have been shown to\nbe not understandable to Deaf viewers.\n  In this paper, we propose SignGAN, the first SLP model to produce\nphoto-realistic continuous sign language videos directly from spoken language.\nWe employ a transformer architecture with a Mixture Density Network (MDN)\nformulation to handle the translation from spoken language to skeletal pose. A\npose-conditioned human synthesis model is then introduced to generate a\nphoto-realistic sign language video from the skeletal pose sequence. This\nallows the photo-realistic production of sign videos directly translated from\nwritten text.\n  We further propose a novel keypoint-based loss function, which significantly\nimproves the quality of synthesized hand images, operating in the keypoint\nspace to avoid issues caused by motion blur. In addition, we introduce a method\nfor controllable video generation, enabling training on large, diverse sign\nlanguage datasets and providing the ability to control the signer appearance at\ninference.\n  Using a dataset of eight different sign language interpreters extracted from\nbroadcast footage, we show that SignGAN significantly outperforms all baseline\nmethods for quantitative metrics and human perceptual studies.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:31:06 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 10:16:24 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 13:31:28 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 19:00:34 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Saunders", "Ben", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2011.09866", "submitter": "Vanja Dosko\\v{c}", "authors": "Julian Berger, Maximilian B\\\"other, Vanja Dosko\\v{c}, Jonathan Gadea\n  Harder, Nicolas Klodt, Timo K\\\"otzing, Winfried L\\\"otzsch, Jannik Peters,\n  Leon Schiller, Lars Seifert, Armin Wells, Simon Wietheger", "title": "Learning Languages with Decidable Hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In language learning in the limit, the most common type of hypothesis is to\ngive an enumerator for a language. This so-called $W$-index allows for naming\narbitrary computably enumerable languages, with the drawback that even the\nmembership problem is undecidable. In this paper we use a different system\nwhich allows for naming arbitrary decidable languages, namely programs for\ncharacteristic functions (called $C$-indices). These indices have the drawback\nthat it is now not decidable whether a given hypothesis is even a legal\n$C$-index.\n  In this first analysis of learning with $C$-indices, we give a structured\naccount of the learning power of various restrictions employing $C$-indices,\nalso when compared with $W$-indices. We establish a hierarchy of learning power\ndepending on whether $C$-indices are required (a) on all outputs; (b) only on\noutputs relevant for the class to be learned and (c) only in the limit as\nfinal, correct hypotheses. Furthermore, all these settings are weaker than\nlearning with $W$-indices (even when restricted to classes of computable\nlanguages). We analyze all these questions also in relation to the mode of data\npresentation.\n  Finally, we also ask about the relation of semantic versus syntactic\nconvergence and derive the map of pairwise relations for these two kinds of\nconvergence coupled with various forms of data presentation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:27:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Berger", "Julian", ""], ["B\u00f6ther", "Maximilian", ""], ["Dosko\u010d", "Vanja", ""], ["Harder", "Jonathan Gadea", ""], ["Klodt", "Nicolas", ""], ["K\u00f6tzing", "Timo", ""], ["L\u00f6tzsch", "Winfried", ""], ["Peters", "Jannik", ""], ["Schiller", "Leon", ""], ["Seifert", "Lars", ""], ["Wells", "Armin", ""], ["Wietheger", "Simon", ""]]}, {"id": "2011.09867", "submitter": "Hanshuang Tong", "authors": "Hanshuang Tong, Yun Zhou and Zhen Wang", "title": "Exercise Hierarchical Feature Enhanced Knowledge Tracing", "comments": "5 pages, 4 figures, Accepted by AIED 2020. In the 21st International\n  Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-52240-7_59", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing is a fundamental task in the computer-aid educational\nsystem. In this paper, we propose a hierarchical exercise feature enhanced\nknowledge tracing framework, which could enhance the ability of knowledge\ntracing by incorporating knowledge distribution, semantic features, and\ndifficulty features from exercise text. Extensive experiments show the high\nperformance of our framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:16:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tong", "Hanshuang", ""], ["Zhou", "Yun", ""], ["Wang", "Zhen", ""]]}, {"id": "2011.09954", "submitter": "Hui Chen", "authors": "Hui Chen, Deepanway Ghosal, Navonil Majumder, Amir Hussain, Soujanya\n  Poria", "title": "Persuasive Dialogue Understanding: the Baselines and Negative Results", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persuasion aims at forming one's opinion and action via a series of\npersuasive messages containing persuader's strategies. Due to its potential\napplication in persuasive dialogue systems, the task of persuasive strategy\nrecognition has gained much attention lately. Previous methods on user intent\nrecognition in dialogue systems adopt recurrent neural network (RNN) or\nconvolutional neural network (CNN) to model context in conversational history,\nneglecting the tactic history and intra-speaker relation. In this paper, we\ndemonstrate the limitations of a Transformer-based approach coupled with\nConditional Random Field (CRF) for the task of persuasive strategy recognition.\nIn this model, we leverage inter- and intra-speaker contextual semantic\nfeatures, as well as label dependencies to improve the recognition. Despite\nextensive hyper-parameter optimizations, this architecture fails to outperform\nthe baseline methods. We observe two negative results. Firstly, CRF cannot\ncapture persuasive label dependencies, possibly as strategies in persuasive\ndialogues do not follow any strict grammar or rules as the cases in Named\nEntity Recognition (NER) or part-of-speech (POS) tagging. Secondly, the\nTransformer encoder trained from scratch is less capable of capturing\nsequential information in persuasive dialogues than Long Short-Term Memory\n(LSTM). We attribute this to the reason that the vanilla Transformer encoder\ndoes not efficiently consider relative position information of sequence\nelements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 16:52:43 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 18:27:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Hui", ""], ["Ghosal", "Deepanway", ""], ["Majumder", "Navonil", ""], ["Hussain", "Amir", ""], ["Poria", "Soujanya", ""]]}, {"id": "2011.10106", "submitter": "Firoj Alam", "authors": "Md. Arid Hasan, Jannatul Tajrin, Shammur Absar Chowdhury, Firoj Alam", "title": "Sentiment Classification in Bangla Textual Content: A Comparative Study", "comments": "Accepted at ICCIT-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 21:06:28 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Hasan", "Md. Arid", ""], ["Tajrin", "Jannatul", ""], ["Chowdhury", "Shammur Absar", ""], ["Alam", "Firoj", ""]]}, {"id": "2011.10132", "submitter": "Sally Sisi Qu", "authors": "Sisi Qu, Mattia Soldan, Mengmeng Xu, Jesper Tegner, Bernard Ghanem", "title": "VLG-Net: Video-Language Graph Matching Network for Video Grounding", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding language queries in videos aims at identifying the time interval\n(or moment) semantically relevant to a language query. The solution to this\nchallenging task demands the understanding of videos' and queries' semantic\ncontent and the fine-grained reasoning about their multi-modal interactions.\nOur key idea is to recast this challenge into an algorithmic graph matching\nproblem. Fueled by recent advances in Graph Neural Networks, we propose to\nleverage Graph Convolutional Networks to model video and textual information as\nwell as their semantic alignment. To enable the mutual exchange of information\nacross the domains, we design a novel Video-Language Graph Matching Network\n(VLG-Net) to match video and query graphs. Core ingredients include\nrepresentation graphs, built on top of video snippets and query tokens\nseparately, which are used for modeling the intra-modality relationships. A\nGraph Matching layer is adopted for cross-modal context modeling and\nmulti-modal fusion. Finally, moment candidates are created using masked moment\nattention pooling by fusing the moment's enriched snippet features. We\ndemonstrate superior performance over state-of-the-art grounding methods on\nthree widely used datasets for temporal localization of moments in videos with\nnatural language queries: ActivityNet-Captions, TACoS, and DiDeMo.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 22:32:03 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Qu", "Sisi", ""], ["Soldan", "Mattia", ""], ["Xu", "Mengmeng", ""], ["Tegner", "Jesper", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2011.10208", "submitter": "Eric Nichols", "authors": "Eric Nichols and Leo Gao and Randy Gomez", "title": "Collaborative Storytelling with Large-scale Neural Language Models", "comments": "To appear in Proceedings of the 13th Annual ACM SIGGRAPH Conference\n  on Motion, Interaction and Games (MIG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Storytelling plays a central role in human socializing and entertainment.\nHowever, much of the research on automatic storytelling generation assumes that\nstories will be generated by an agent without any human interaction. In this\npaper, we introduce the task of collaborative storytelling, where an artificial\nintelligence agent and a person collaborate to create a unique story by taking\nturns adding to it. We present a collaborative storytelling system which works\nwith a human storyteller to create a story by generating new utterances based\non the story so far. We constructed the storytelling system by tuning a\npublicly-available large scale language model on a dataset of writing prompts\nand their accompanying fictional works. We identify generating sufficiently\nhuman-like utterances to be an important technical issue and propose a\nsample-and-rank approach to improve utterance quality. Quantitative evaluation\nshows that our approach outperforms a baseline, and we present qualitative\nevaluation of our system's capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:36:54 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Nichols", "Eric", ""], ["Gao", "Leo", ""], ["Gomez", "Randy", ""]]}, {"id": "2011.10216", "submitter": "Joel Jang", "authors": "Joel Jang, Yoonjeon Kim, Kyoungho Choi, Sungho Suh", "title": "Sequential Targeting: an incremental learning approach for data\n  imbalance in text classification", "comments": "9 pages, 7 figures, submitted to the journal of Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification tasks require a balanced distribution of data to ensure the\nlearner to be trained to generalize over all classes. In real-world datasets,\nhowever, the number of instances vary substantially among classes. This\ntypically leads to a learner that promotes bias towards the majority group due\nto its dominating property. Therefore, methods to handle imbalanced datasets\nare crucial for alleviating distributional skews and fully utilizing the\nunder-represented data, especially in text classification. While addressing the\nimbalance in text data, most methods utilize sampling methods on the numerical\nrepresentation of the data, which limits its efficiency on how effective the\nrepresentation is. We propose a novel training method, Sequential\nTargeting(ST), independent of the effectiveness of the representation method,\nwhich enforces an incremental learning setting by splitting the data into\nmutually exclusive subsets and training the learner adaptively. To address\nproblems that arise within incremental learning, we apply elastic weight\nconsolidation. We demonstrate the effectiveness of our method through\nexperiments on simulated benchmark datasets (IMDB) and data collected from\nNAVER.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:54:00 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 02:33:08 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jang", "Joel", ""], ["Kim", "Yoonjeon", ""], ["Choi", "Kyoungho", ""], ["Suh", "Sungho", ""]]}, {"id": "2011.10280", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Rupak Sarkar, Ashiqur R. KhudaBukhsh", "title": "Are Chess Discussions Racist? An Adversarial Hate Speech Data Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On June 28, 2020, while presenting a chess podcast on Grandmaster Hikaru\nNakamura, Antonio Radi\\'c's YouTube handle got blocked because it contained\n\"harmful and dangerous\" content. YouTube did not give further specific reason,\nand the channel got reinstated within 24 hours. However, Radi\\'c speculated\nthat given the current political situation, a referral to \"black against\nwhite\", albeit in the context of chess, earned him this temporary ban. In this\npaper, via a substantial corpus of 681,995 comments, on 8,818 YouTube videos\nhosted by five highly popular chess-focused YouTube channels, we ask the\nfollowing research question: \\emph{how robust are off-the-shelf hate-speech\nclassifiers to out-of-domain adversarial examples?} We release a data set of\n1,000 annotated comments where existing hate speech classifiers misclassified\nbenign chess discussions as hate speech. We conclude with an intriguing analogy\nresult on racial bias with our findings pointing out to the broader challenge\nof color polysemy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:50:06 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sarkar", "Rupak", ""], ["KhudaBukhsh", "Ashiqur R.", ""]]}, {"id": "2011.10285", "submitter": "Harshil Shah", "authors": "Harshil Shah and Julien Fauqueur", "title": "Learning Informative Representations of Biomedical Relations with Latent\n  Variable Models", "comments": "SustaiNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting biomedical relations from large corpora of scientific documents is\na challenging natural language processing task. Existing approaches usually\nfocus on identifying a relation either in a single sentence (mention-level) or\nacross an entire corpus (pair-level). In both cases, recent methods have\nachieved strong results by learning a point estimate to represent the relation;\nthis is then used as the input to a relation classifier. However, the relation\nexpressed in text between a pair of biomedical entities is often more complex\nthan can be captured by a point estimate. To address this issue, we propose a\nlatent variable model with an arbitrarily flexible distribution to represent\nthe relation between an entity pair. Additionally, our model provides a unified\narchitecture for both mention-level and pair-level relation extraction. We\ndemonstrate that our model achieves results competitive with strong baselines\nfor both tasks while having fewer parameters and being significantly faster to\ntrain. We make our code publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:56:31 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Shah", "Harshil", ""], ["Fauqueur", "Julien", ""]]}, {"id": "2011.10337", "submitter": "Shivam Pal", "authors": "Shivam Pal, Vipul Arora, Pawan Goyal", "title": "Finding Prerequisite Relations between Concepts using Textbook", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prerequisite is anything that you need to know or understand first before\nattempting to learn or understand something new. In the current work, we\npresent a method of finding prerequisite relations between concepts using\nrelated textbooks. Previous researchers have focused on finding these relations\nusing Wikipedia link structure through unsupervised and supervised learning\napproaches. In the current work, we have proposed two methods, one is\nstatistical method and another is learning-based method. We mine the rich and\nstructured knowledge available in the textbooks to find the content for those\nconcepts and the order in which they are discussed. Using this information,\nproposed statistical method estimates explicit as well as implicit prerequisite\nrelations between concepts. During experiments, we have found performance of\nproposed statistical method is better than the popular RefD method, which uses\nWikipedia link structure. And proposed learning-based method has shown a\nsignificant increase in the efficiency of supervised learning method when\ncompared with graph and text-based learning-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:58:31 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Pal", "Shivam", ""], ["Arora", "Vipul", ""], ["Goyal", "Pawan", ""]]}, {"id": "2011.10358", "submitter": "Dinesh Kumar Vishwakarma Dr", "authors": "Ashima Yadav, Dinesh Kumar Vishwakarma", "title": "A Deep Language-independent Network to analyze the impact of COVID-19 on\n  the World via Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Towards the end of 2019, Wuhan experienced an outbreak of novel coronavirus,\nwhich soon spread all over the world, resulting in a deadly pandemic that\ninfected millions of people around the globe. The government and public health\nagencies followed many strategies to counter the fatal virus. However, the\nvirus severely affected the social and economic lives of the people. In this\npaper, we extract and study the opinion of people from the top five worst\naffected countries by the virus, namely USA, Brazil, India, Russia, and South\nAfrica. We propose a deep language-independent Multilevel Attention-based\nConv-BiGRU network (MACBiG-Net), which includes embedding layer, word-level\nencoded attention, and sentence-level encoded attention mechanism to extract\nthe positive, negative, and neutral sentiments. The embedding layer encodes the\nsentence sequence into a real-valued vector. The word-level and sentence-level\nencoding is performed by a 1D Conv-BiGRU based mechanism, followed by\nword-level and sentence-level attention, respectively. We further develop a\nCOVID-19 Sentiment Dataset by crawling the tweets from Twitter. Extensive\nexperiments on our proposed dataset demonstrate the effectiveness of the\nproposed MACBiG-Net. Also, attention-weights visualization and in-depth results\nanalysis shows that the proposed network has effectively captured the\nsentiments of the people.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 11:59:16 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Yadav", "Ashima", ""], ["Vishwakarma", "Dinesh Kumar", ""]]}, {"id": "2011.10361", "submitter": "Kathleen Siminyu", "authors": "Kathleen Siminyu, Laura Martinus, Vukosi Marivate", "title": "1st AfricaNLP Workshop Proceedings, 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proceedings of the 1st AfricaNLP Workshop held on 26th April alongside ICLR\n2020, Virtual Conference, Formerly Addis Ababa Ethiopia.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:03:41 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Siminyu", "Kathleen", ""], ["Martinus", "Laura", ""], ["Marivate", "Vukosi", ""]]}, {"id": "2011.10364", "submitter": "Mohamadreza Faridghasemnia", "authors": "Mohamadreza Faridghasemnia, Daniele Nardi, Alessandro Saffiotti", "title": "Towards Abstract Relational Learning in Human Robot Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have a rich representation of the entities in their environment.\nEntities are described by their attributes, and entities that share attributes\nare often semantically related. For example, if two books have \"Natural\nLanguage Processing\" as the value of their `title' attribute, we can expect\nthat their `topic' attribute will also be equal, namely, \"NLP\". Humans tend to\ngeneralize such observations, and infer sufficient conditions under which the\n`topic' attribute of any entity is \"NLP\". If robots need to interact\nsuccessfully with humans, they need to represent entities, attributes, and\ngeneralizations in a similar way. This ends in a contextualized cognitive agent\nthat can adapt its understanding, where context provides sufficient conditions\nfor a correct understanding. In this work, we address the problem of how to\nobtain these representations through human-robot interaction. We integrate\nvisual perception and natural language input to incrementally build a semantic\nmodel of the world, and then use inductive reasoning to infer logical rules\nthat capture generic semantic relations, true in this model. These relations\ncan be used to enrich the human-robot interaction, to populate a knowledge base\nwith inferred facts, or to remove uncertainty in the robot's sensory inputs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:06:46 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Faridghasemnia", "Mohamadreza", ""], ["Nardi", "Daniele", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "2011.10369", "submitter": "Fanchao Qi", "authors": "Fanchao Qi, Yangyi Chen, Mukai Li, Zhiyuan Liu, Maosong Sun", "title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attacks, which are a kind of emergent training-time threat to deep\nneural networks (DNNS). They can manipulate the output of DNNs and posses high\ninsidiousness. In the field of natural language processing, some attack methods\nhave been proposed and achieve very high attack success rates on multiple\npopular models. Nevertheless, the studies on defending textual backdoor defense\nare little conducted. In this paper, we propose a simple and effective textual\nbackdoor defense named ONION, which is based on outlier word detection and\nmight be the first method that can handle all the attack situations.\nExperiments demonstrate the effectiveness of our model when blocking two latest\nbackdoor attack methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:17:21 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Qi", "Fanchao", ""], ["Chen", "Yangyi", ""], ["Li", "Mukai", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "2011.10426", "submitter": "Quoc Hung Ngo", "authors": "Quoc Thai Nguyen, Thoai Linh Nguyen, Ngoc Hoang Luong, and Quoc Hung\n  Ngo", "title": "Fine-Tuning BERT for Sentiment Analysis of Vietnamese Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis is an important task in the field ofNature Language\nProcessing (NLP), in which users' feedbackdata on a specific issue are\nevaluated and analyzed. Manydeep learning models have been proposed to tackle\nthis task, including the recently-introduced Bidirectional Encoder\nRep-resentations from Transformers (BERT) model. In this paper,we experiment\nwith two BERT fine-tuning methods for thesentiment analysis task on datasets of\nVietnamese reviews: 1) a method that uses only the [CLS] token as the input for\nanattached feed-forward neural network, and 2) another methodin which all BERT\noutput vectors are used as the input forclassification. Experimental results on\ntwo datasets show thatmodels using BERT slightly outperform other models\nusingGloVe and FastText. Also, regarding the datasets employed inthis study,\nour proposed BERT fine-tuning method produces amodel with better performance\nthan the original BERT fine-tuning method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 14:45:46 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Nguyen", "Quoc Thai", ""], ["Nguyen", "Thoai Linh", ""], ["Luong", "Ngoc Hoang", ""], ["Ngo", "Quoc Hung", ""]]}, {"id": "2011.10428", "submitter": "Simon Hengchen", "authors": "Jani Marjanen, Elaine Zosa, Simon Hengchen, Lidia Pivovarova, Mikko\n  Tolonen", "title": "Topic modelling discourse dynamics in historical newspapers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper addresses methodological issues in diachronic data analysis for\nhistorical research. We apply two families of topic models (LDA and DTM) on a\nrelatively large set of historical newspapers, with the aim of capturing and\nunderstanding discourse dynamics. Our case study focuses on newspapers and\nperiodicals published in Finland between 1854 and 1917, but our method can\neasily be transposed to any diachronic data. Our main contributions are a) a\ncombined sampling, training and inference procedure for applying topic models\nto huge and imbalanced diachronic text collections; b) a discussion on the\ndifferences between two topic models for this type of data; c) quantifying\ntopic prominence for a period and thus a generalization of document-wise topic\nassignment to a discourse level; and d) a discussion of the role of humanistic\ninterpretation with regard to analysing discourse dynamics through topic\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 14:51:07 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Marjanen", "Jani", ""], ["Zosa", "Elaine", ""], ["Hengchen", "Simon", ""], ["Pivovarova", "Lidia", ""], ["Tolonen", "Mikko", ""]]}, {"id": "2011.10456", "submitter": "Noemi Mauro", "authors": "Noemi Mauro and Liliana Ardissono and Giovanna Petrone", "title": "User and Item-aware Estimation of Review Helpfulness", "comments": null, "journal-ref": "Information Processing & Management, Volume 58, Issue 1, 2021.\n  ISSN 0306-4573", "doi": "10.1016/j.ipm.2020.102434", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In online review sites, the analysis of user feedback for assessing its\nhelpfulness for decision-making is usually carried out by locally studying the\nproperties of individual reviews. However, global properties should be\nconsidered as well to precisely evaluate the quality of user feedback. In this\npaper we investigate the role of deviations in the properties of reviews as\nhelpfulness determinants with the intuition that \"out of the core\" feedback\nhelps item evaluation. We propose a novel helpfulness estimation model that\nextends previous ones with the analysis of deviations in rating, length and\npolarity with respect to the reviews written by the same person, or concerning\nthe same item. A regression analysis carried out on two large datasets of\nreviews extracted from Yelp social network shows that user-based deviations in\nreview length and rating clearly influence perceived helpfulness. Moreover, an\nexperiment on the same datasets shows that the integration of our helpfulness\nestimation model improves the performance of a collaborative recommender system\nby enhancing the selection of high-quality data for rating estimation. Our\nmodel is thus an effective tool to select relevant user feedback for\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:35:56 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Mauro", "Noemi", ""], ["Ardissono", "Liliana", ""], ["Petrone", "Giovanna", ""]]}, {"id": "2011.10492", "submitter": "Thai Le", "authors": "Thai Le, Noseong Park, Dongwon Lee", "title": "A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal\n  Trigger's Adversarial Attacks", "comments": "Accepted to the 59th Annual Meeting of the Association for\n  Computational Linguistics (ACL) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Universal Trigger (UniTrigger) is a recently-proposed powerful\nadversarial textual attack method. Utilizing a learning-based mechanism,\nUniTrigger generates a fixed phrase that, when added to any benign inputs, can\ndrop the prediction accuracy of a textual neural network (NN) model to near\nzero on a target class. To defend against this attack that can cause\nsignificant harm, in this paper, we borrow the \"honeypot\" concept from the\ncybersecurity community and propose DARCY, a honeypot-based defense framework\nagainst UniTrigger. DARCY greedily searches and injects multiple trapdoors into\nan NN model to \"bait and catch\" potential attacks. Through comprehensive\nexperiments across four public datasets, we show that DARCY detects\nUniTrigger's adversarial attacks with up to 99% TPR and less than 2% FPR in\nmost cases, while maintaining the prediction accuracy (in F1) for clean inputs\nwithin a 1% margin. We also demonstrate that DARCY with multiple trapdoors is\nalso robust to a diverse set of attack scenarios with attackers' varying levels\nof knowledge and skills. Source code will be released upon the acceptance of\nthis paper.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:38:28 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:14:53 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 20:53:25 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Le", "Thai", ""], ["Park", "Noseong", ""], ["Lee", "Dongwon", ""]]}, {"id": "2011.10647", "submitter": "Krunal Shah", "authors": "Krunal Shah, Nitish Gupta, Dan Roth", "title": "What do we expect from Multiple-choice QA Systems?", "comments": "Findings of EMNLP 2020", "journal-ref": "Findings of the Association for Computational Linguistics: EMNLP\n  2020 pg. 3547-3553", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of machine learning systems on various QA datasets could\nbe interpreted as a significant improvement in models' language understanding\nabilities. However, using various perturbations, multiple recent works have\nshown that good performance on a dataset might not indicate performance that\ncorrelates well with human's expectations from models that \"understand\"\nlanguage. In this work we consider a top performing model on several Multiple\nChoice Question Answering (MCQA) datasets, and evaluate it against a set of\nexpectations one might have from such a model, using a series of\nzero-information perturbations of the model's inputs. Our results show that the\nmodel clearly falls short of our expectations, and motivates a modified\ntraining approach that forces the model to better attend to the inputs. We show\nthat the new training paradigm leads to a model that performs on par with the\noriginal model while better satisfying our expectations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:27:10 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shah", "Krunal", ""], ["Gupta", "Nitish", ""], ["Roth", "Dan", ""]]}, {"id": "2011.10652", "submitter": "Aparna Khare", "authors": "Aparna Khare, Srinivas Parthasarathy, Shiva Sundaram", "title": "Self-Supervised learning with cross-modal transformers for emotion\n  recognition", "comments": "To appear in SLT2020", "journal-ref": null, "doi": "10.1109/SLT48900.2021.9383618", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition is a challenging task due to limited availability of\nin-the-wild labeled datasets. Self-supervised learning has shown improvements\non tasks with limited labeled datasets in domains like speech and natural\nlanguage. Models such as BERT learn to incorporate context in word embeddings,\nwhich translates to improved performance in downstream tasks like question\nanswering. In this work, we extend self-supervised training to multi-modal\napplications. We learn multi-modal representations using a transformer trained\non the masked language modeling task with audio, visual and text features. This\nmodel is fine-tuned on the downstream task of emotion recognition. Our results\non the CMU-MOSEI dataset show that this pre-training technique can improve the\nemotion recognition performance by up to 3% compared to the baseline.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:38:34 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Khare", "Aparna", ""], ["Parthasarathy", "Srinivas", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2011.10683", "submitter": "Vrindavan Harrison", "authors": "Vrindavan Harrison, Juraj Juraska, Wen Cui, Lena Reed, Kevin K.\n  Bowden, Jiaqi Wu, Brian Schwarzmann, Abteen Ebrahimi, Rishi Rajasekaran,\n  Nikhil Varghese, Max Wechsler-Azen, Steve Whittaker, Jeffrey Flanigan, and\n  Marilyn Walker", "title": "Athena: Constructing Dialogues Dynamically with Discourse Constraints", "comments": "3rd Proceedings of Alexa Prize (Alexa Prize 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes Athena, a dialogue system for spoken conversation on\npopular topics and current events. We develop a flexible topic-agnostic\napproach to dialogue management that dynamically configures dialogue based on\ngeneral principles of entity and topic coherence. Athena's dialogue manager\nuses a contract-based method where discourse constraints are dispatched to\nclusters of response generators. This allows Athena to procure responses from\ndynamic sources, such as knowledge graph traversals and feature-based\non-the-fly response retrieval methods. After describing the dialogue system\narchitecture, we perform an analysis of conversations that Athena participated\nin during the 2019 Alexa Prize Competition. We conclude with a report on\nseveral user studies we carried out to better understand how individual user\ncharacteristics affect system ratings.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:28:34 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Harrison", "Vrindavan", ""], ["Juraska", "Juraj", ""], ["Cui", "Wen", ""], ["Reed", "Lena", ""], ["Bowden", "Kevin K.", ""], ["Wu", "Jiaqi", ""], ["Schwarzmann", "Brian", ""], ["Ebrahimi", "Abteen", ""], ["Rajasekaran", "Rishi", ""], ["Varghese", "Nikhil", ""], ["Wechsler-Azen", "Max", ""], ["Whittaker", "Steve", ""], ["Flanigan", "Jeffrey", ""], ["Walker", "Marilyn", ""]]}, {"id": "2011.10704", "submitter": "Weixin Liang", "authors": "Weixin Liang, James Zou", "title": "Neural Group Testing to Accelerate Deep Learning", "comments": "ISIT 2021. Code & data available at\n  https://github.com/Weixin-Liang/NeuralGroupTesting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have made the use of large, deep neural\nnetworks with tens of millions of parameters. The sheer size of these networks\nimposes a challenging computational burden during inference. Existing work\nfocuses primarily on accelerating each forward pass of a neural network.\nInspired by the group testing strategy for efficient disease testing, we\npropose neural group testing, which accelerates by testing a group of samples\nin one forward pass. Groups of samples that test negative are ruled out. If a\ngroup tests positive, samples in that group are then retested adaptively. A key\nchallenge of neural group testing is to modify a deep neural network so that it\ncould test multiple samples in one forward pass. We propose three designs to\nachieve this without introducing any new parameters and evaluate their\nperformances. We applied neural group testing in an image moderation task to\ndetect rare but inappropriate images. We found that neural group testing can\ngroup up to 16 images in one forward pass and reduce the overall computation\ncost by over 73% while improving detection performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 02:23:54 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 23:03:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Liang", "Weixin", ""], ["Zou", "James", ""]]}, {"id": "2011.10731", "submitter": "Weixin Liang", "authors": "Weixin Liang, Feiyang Niu, Aishwarya Reganti, Govind Thattai, Gokhan\n  Tur", "title": "LRTA: A Transparent Neural-Symbolic Reasoning Framework with Modular\n  Supervision for Visual Question Answering", "comments": "NeurIPS KR2ML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant approach to visual question answering (VQA) relies on\nencoding the image and question with a \"black-box\" neural encoder and decoding\na single token as the answer like \"yes\" or \"no\". Despite this approach's strong\nquantitative results, it struggles to come up with intuitive, human-readable\nforms of justification for the prediction process. To address this\ninsufficiency, we reformulate VQA as a full answer generation task, which\nrequires the model to justify its predictions in natural language. We propose\nLRTA [Look, Read, Think, Answer], a transparent neural-symbolic reasoning\nframework for visual question answering that solves the problem step-by-step\nlike humans and provides human-readable form of justification at each step.\nSpecifically, LRTA learns to first convert an image into a scene graph and\nparse a question into multiple reasoning instructions. It then executes the\nreasoning instructions one at a time by traversing the scene graph using a\nrecurrent neural-symbolic execution module. Finally, it generates a full answer\nto the given question with natural language justifications. Our experiments on\nGQA dataset show that LRTA outperforms the state-of-the-art model by a large\nmargin (43.1% v.s. 28.0%) on the full answer generation task. We also create a\nperturbed GQA test set by removing linguistic cues (attributes and relations)\nin the questions for analyzing whether a model is having a smart guess with\nsuperficial data correlations. We show that LRTA makes a step towards truly\nunderstanding the question while the state-of-the-art model tends to learn\nsuperficial correlations from the training data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 06:39:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liang", "Weixin", ""], ["Niu", "Feiyang", ""], ["Reganti", "Aishwarya", ""], ["Thattai", "Govind", ""], ["Tur", "Gokhan", ""]]}, {"id": "2011.10819", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek and Zden\\v{e}k Kasner", "title": "Evaluating Semantic Accuracy of Data-to-Text Generation with Natural\n  Language Inference", "comments": "Accepted as a short paper for INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in evaluating data-to-text (D2T) generation is measuring\nthe semantic accuracy of the generated text, i.e. checking if the output text\ncontains all and only facts supported by the input data. We propose a new\nmetric for evaluating the semantic accuracy of D2T generation based on a neural\nmodel pretrained for natural language inference (NLI). We use the NLI model to\ncheck textual entailment between the input data and the output text in both\ndirections, allowing us to reveal omissions or hallucinations. Input data are\nconverted to text for NLI using trivial templates. Our experiments on two\nrecent D2T datasets show that our metric can achieve high accuracy in\nidentifying erroneous system outputs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 16:37:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Kasner", "Zden\u011bk", ""]]}, {"id": "2011.10832", "submitter": "Victor Makarenkov", "authors": "Victor Makarenkov and Yael Segalovitz", "title": "Sensing Ambiguity in Henry James' \"The Turn of the Screw\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fields such as the philosophy of language, continental philosophy, and\nliterary studies have long established that human language is, at its essence,\nambiguous and that this quality, although challenging to communication,\nenriches language and points to the complexity of human thought. On the other\nhand, in the NLP field there have been ongoing efforts aimed at disambiguation\nfor various downstream tasks. This work brings together computational text\nanalysis and literary analysis to demonstrate the extent to which ambiguity in\ncertain texts plays a key role in shaping meaning and thus requires analysis\nrather than elimination. We revisit the discussion, well known in the\nhumanities, about the role ambiguity plays in Henry James' 19th century\nnovella, The Turn of the Screw. We model each of the novella's two competing\ninterpretations as a topic and computationally demonstrate that the duality\nbetween them exists consistently throughout the work and shapes, rather than\nobscures, its meaning. We also demonstrate that cosine similarity and word\nmover's distance are sensitive enough to detect ambiguity in its most subtle\nliterary form, despite doubts to the contrary raised by literary scholars. Our\nanalysis is built on topic word lists and word embeddings from various sources.\nWe first claim, and then empirically show, the interdependence between\ncomputational analysis and close reading performed by a human expert.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 17:53:41 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Makarenkov", "Victor", ""], ["Segalovitz", "Yael", ""]]}, {"id": "2011.10896", "submitter": "Masudul Quraishi", "authors": "Michael Riera, Erfan Bank Tavakoli, Masudul Hassan Quraishi, Fengbo\n  Ren", "title": "HALO 1.0: A Hardware-agnostic Accelerator Orchestration Framework for\n  Enabling Hardware-agnostic Programming with True Performance Portability for\n  Heterogeneous HPC", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents HALO 1.0, an open-ended extensible multi-agent software\nframework that implements a set of proposed hardware-agnostic accelerator\norchestration (HALO) principles. HALO implements a novel compute-centric\nmessage passing interface (C^2MPI) specification for enabling the\nperformance-portable execution of a hardware-agnostic host application across\nheterogeneous accelerators. The experiment results of evaluating eight widely\nused HPC subroutines based on Intel Xeon E5-2620 CPUs, Intel Arria 10 GX FPGAs,\nand NVIDIA GeForce RTX 2080 Ti GPUs show that HALO 1.0 allows for a unified\ncontrol flow for host programs to run across all the computing devices with a\nconsistently top performance portability score, which is up to five orders of\nmagnitude higher than the OpenCL-based solution.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 00:25:55 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 04:27:01 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 00:56:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Riera", "Michael", ""], ["Tavakoli", "Erfan Bank", ""], ["Quraishi", "Masudul Hassan", ""], ["Ren", "Fengbo", ""]]}, {"id": "2011.10916", "submitter": "Kunjal Panchal", "authors": "Kunjal Panchal", "title": "Hierachical Delta-Attention Method for Multimodal Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In vision and linguistics; the main input modalities are facial expressions,\nspeech patterns, and the words uttered. The issue with analysis of any one mode\nof expression (Visual, Verbal or Vocal) is that lot of contextual information\ncan get lost. This asks researchers to inspect multiple modalities to get a\nthorough understanding of the cross-modal dependencies and temporal context of\nthe situation to analyze the expression. This work attempts at preserving the\nlong-range dependencies within and across different modalities, which would be\nbottle-necked by the use of recurrent networks and adds the concept of\ndelta-attention to focus on local differences per modality to capture the\nidiosyncrasy of different people. We explore a cross-attention fusion technique\nto get the global view of the emotion expressed through these\ndelta-self-attended modalities, in order to fuse all the local nuances and\nglobal context together. The addition of attention is new to the multi-modal\nfusion field and currently being scrutinized for on what stage the attention\nmechanism should be used, this work achieves competitive accuracy for overall\nand per-class classification which is close to the current state-of-the-art\nwith almost half number of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 02:45:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Panchal", "Kunjal", ""]]}, {"id": "2011.11074", "submitter": "Simon Gabay", "authors": "Simon Gabay (UNIGE), Thibault Cl\\'erice (ENC), Jean-Baptiste Camps\n  (ENC), Jean-Baptiste Tanguy (SU), Matthias Gille-Levenson (ENS Lyon)", "title": "Standardizing linguistic data: method and tools for annotating\n  (pre-orthographic) French", "comments": null, "journal-ref": "Proceedings of the 2nd International Digital Tools & Uses Congress\n  (DTUC '20), Oct 2020, Hammamet, Tunisia", "doi": "10.1145/3423603.3423996", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of big corpora of various periods, it becomes crucial to\nstandardise linguistic annotation (e.g. lemmas, POS tags, morphological\nannotation) to increase the interoperability of the data produced, despite\ndiachronic variations. In the present paper, we describe both methodologically\n(by proposing annotation principles) and technically (by creating the required\ntraining data and the relevant models) the production of a linguistic tagger\nfor (early) modern French (16-18th c.), taking as much as possible into account\nalready existing standards for contemporary and, especially, medieval French.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:39:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Gabay", "Simon", "", "UNIGE"], ["Cl\u00e9rice", "Thibault", "", "ENC"], ["Camps", "Jean-Baptiste", "", "ENC"], ["Tanguy", "Jean-Baptiste", "", "SU"], ["Gille-Levenson", "Matthias", "", "ENS Lyon"]]}, {"id": "2011.11090", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Alexandre Rochette and Timothy J. Hazen", "title": "Cross-Domain Generalization Through Memorization: A Study of Nearest\n  Neighbors in Neural Duplicate Question Detection", "comments": "7 pages, initial results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Duplicate question detection (DQD) is important to increase efficiency of\ncommunity and automatic question answering systems. Unfortunately, gathering\nsupervised data in a domain is time-consuming and expensive, and our ability to\nleverage annotations across domains is minimal. In this work, we leverage\nneural representations and study nearest neighbors for cross-domain\ngeneralization in DQD. We first encode question pairs of the source and target\ndomain in a rich representation space and then using a k-nearest neighbour\nretrieval-based method, we aggregate the neighbors' labels and distances to\nrank pairs. We observe robust performance of this method in different\ncross-domain scenarios of StackExchange, Spring and Quora datasets,\noutperforming cross-entropy classification in multiple cases.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 19:19:33 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Rochette", "Alexandre", ""], ["Hazen", "Timothy J.", ""]]}, {"id": "2011.11115", "submitter": "Haemanth Santhi Ponnusamy", "authors": "Haemanth Santhi Ponnusamy, Detmar Meurers", "title": "Employing distributional semantics to organize task-focused vocabulary\n  learning", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can a learner systematically prepare for reading a book they are\ninterested in? In this paper,we explore how computational linguistic methods\nsuch as distributional semantics, morphological clustering, and exercise\ngeneration can be combined with graph-based learner models to answer this\nquestion both conceptually and in practice. Based on the highly structured\nlearner model and concepts from network analysis, the learner is guided to\nefficiently explore the targeted lexical space. They practice using multi-gap\nlearning activities generated from the book focused on words that are central\nto the targeted lexical space. As such the approach offers a unique combination\nof computational linguistic methods with concepts from network analysis and the\ntutoring system domain to support learners in achieving their individual,\nreading task-based learning goals.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 21:51:19 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ponnusamy", "Haemanth Santhi", ""], ["Meurers", "Detmar", ""]]}, {"id": "2011.11263", "submitter": "Raviraj Joshi", "authors": "Ramchandra Joshi, Raviraj Joshi", "title": "Evaluating Input Representation for Language Identification in\n  Hindi-English Code Mixed Text", "comments": "Accepted at ICDSMLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) techniques have become mainstream in the\nrecent decade. Most of these advances are attributed to the processing of a\nsingle language. More recently, with the extensive growth of social media\nplatforms focus has shifted to code-mixed text. The code-mixed text comprises\ntext written in more than one language. People naturally tend to combine local\nlanguage with global languages like English. To process such texts, current NLP\ntechniques are not sufficient. As a first step, the text is processed to\nidentify the language of the words in the text. In this work, we focus on\nlanguage identification in code-mixed sentences for Hindi-English mixed text.\nThe task of language identification is formulated as a token classification\ntask. In the supervised setting, each word in the sentence has an associated\nlanguage label. We evaluate different deep learning models and input\nrepresentation combinations for this task. Mainly, character, sub-word, and\nword embeddings are considered in combination with CNN and LSTM based models.\nWe show that sub-word representation along with the LSTM model gives the best\nresults. In general sub-word representations perform significantly better than\nother input representations. We report the best accuracy of 94.52% using a\nsingle layer LSTM model on the standard SAIL ICON 2017 test set.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:08:09 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 13:22:04 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Joshi", "Ramchandra", ""], ["Joshi", "Raviraj", ""]]}, {"id": "2011.11387", "submitter": "Prakamya Mishra", "authors": "Prakamya Mishra", "title": "STEPs-RL: Speech-Text Entanglement for Phonetically Sound Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel multi-modal deep neural network\narchitecture that uses speech and text entanglement for learning phonetically\nsound spoken-word representations. STEPs-RL is trained in a supervised manner\nto predict the phonetic sequence of a target spoken-word using its contextual\nspoken word's speech and text, such that the model encodes its meaningful\nlatent representations. Unlike existing work, we have used text along with\nspeech for auditory representation learning to capture semantical and\nsyntactical information along with the acoustic and temporal information. The\nlatent representations produced by our model were not only able to predict the\ntarget phonetic sequences with an accuracy of 89.47% but were also able to\nachieve competitive results to textual word representation models, Word2Vec &\nFastText (trained on textual transcripts), when evaluated on four widely used\nword similarity benchmark datasets. In addition, investigation of the generated\nvector space also demonstrated the capability of the proposed model to capture\nthe phonetic structure of the spoken-words. To the best of our knowledge, none\nof the existing works use speech and text entanglement for learning spoken-word\nrepresentation, which makes this work first of its kind.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 13:29:16 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Mishra", "Prakamya", ""]]}, {"id": "2011.11400", "submitter": "Feng Qi", "authors": "Feng Qi", "title": "Language guided machine action", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Here we build a hierarchical modular network called Language guided machine\naction (LGMA), whose modules process information stream mimicking human\ncortical network that allows to achieve multiple general tasks such as language\nguided action, intention decomposition and mental simulation before action\nexecution etc. LGMA contains 3 main systems: (1) primary sensory system that\nmultimodal sensory information of vision, language and sensorimotor. (2)\nassociation system involves and Broca modules to comprehend and synthesize\nlanguage, BA14/40 module to translate between sensorimotor and language,\nmidTemporal module to convert between language and vision, and superior\nparietal lobe to integrate attended visual object and arm state into cognitive\nmap for future spatial actions. Pre-supplementary motor area (pre-SMA) can\nconverts high level intention into sequential atomic actions, while SMA can\nintegrate these atomic actions, current arm and attended object state into\nsensorimotor vector to apply corresponding torques on arm via pre-motor and\nprimary motor of arm to achieve the intention. The high-level executive system\ncontains PFC that does explicit inference and guide voluntary action based on\nlanguage, while BG is the habitual action control center.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 13:49:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Qi", "Feng", ""]]}, {"id": "2011.11436", "submitter": "Jenni Raitoharju", "authors": "Mohammad Soltanian and Junaid Malik and Jenni Raitoharju and\n  Alexandros Iosifidis and Serkan Kiranyaz and Moncef Gabbouj", "title": "Speech Command Recognition in Computationally Constrained Environments\n  with a Quadratic Self-organized Operational Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic classification of speech commands has revolutionized human computer\ninteractions in robotic applications. However, employed recognition models\nusually follow the methodology of deep learning with complicated networks which\nare memory and energy hungry. So, there is a need to either squeeze these\ncomplicated models or use more efficient light-weight models in order to be\nable to implement the resulting classifiers on embedded devices. In this paper,\nwe pick the second approach and propose a network layer to enhance the speech\ncommand recognition capability of a lightweight network and demonstrate the\nresult via experiments. The employed method borrows the ideas of Taylor\nexpansion and quadratic forms to construct a better representation of features\nin both input and hidden layers. This richer representation results in\nrecognition accuracy improvement as shown by extensive experiments on Google\nspeech commands (GSC) and synthetic speech commands (SSC) datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 14:40:18 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 18:28:13 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Soltanian", "Mohammad", ""], ["Malik", "Junaid", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2011.11465", "submitter": "Prakamya Mishra", "authors": "Prakamya Mishra, Saroj Kaushik and Kuntal Dey", "title": "Bi-ISCA: Bidirectional Inter-Sentence Contextual Attention Mechanism for\n  Detecting Sarcasm in User Generated Noisy Short Text", "comments": "Paper under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online comments on social media platforms are hateful, humorous, or\nsarcastic. The sarcastic nature of these comments (especially the short ones)\nalters their actual implied sentiments, which leads to misinterpretations by\nthe existing sentiment analysis models. A lot of research has already been done\nto detect sarcasm in the text using user-based, topical, and conversational\ninformation but not much work has been done to use inter-sentence contextual\ninformation for detecting the same. This paper proposes a new state-of-the-art\ndeep learning architecture that uses a novel Bidirectional Inter-Sentence\nContextual Attention mechanism (Bi-ISCA) to capture inter-sentence dependencies\nfor detecting sarcasm in the user-generated short text using only the\nconversational context. The proposed deep learning model demonstrates the\ncapability to capture explicit, implicit, and contextual incongruous words &\nphrases responsible for invoking sarcasm. Bi-ISCA generates state-of-the-art\nresults on two widely used benchmark datasets for the sarcasm detection task\n(Reddit and Twitter). To the best of our knowledge, none of the existing\nstate-of-the-art models use an inter-sentence contextual attention mechanism to\ndetect sarcasm in the user-generated short text using only conversational\ncontext.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:24:27 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 07:22:48 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 17:36:02 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Mishra", "Prakamya", ""], ["Kaushik", "Saroj", ""], ["Dey", "Kuntal", ""]]}, {"id": "2011.11499", "submitter": "Juntao Li", "authors": "Juntao Li, Ruidan He, Hai Ye, Hwee Tou Ng, Lidong Bing, Rui Yan", "title": "Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language\n  Model", "comments": null, "journal-ref": "IJCAI-PRICAI2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research indicates that pretraining cross-lingual language models on\nlarge-scale unlabeled texts yields significant performance improvements over\nvarious cross-lingual and low-resource tasks. Through training on one hundred\nlanguages and terabytes of texts, cross-lingual language models have proven to\nbe effective in leveraging high-resource languages to enhance low-resource\nlanguage processing and outperform monolingual models. In this paper, we\nfurther investigate the cross-lingual and cross-domain (CLCD) setting when a\npretrained cross-lingual language model needs to adapt to new domains.\nSpecifically, we propose a novel unsupervised feature decomposition method that\ncan automatically extract domain-specific features and domain-invariant\nfeatures from the entangled pretrained cross-lingual representations, given\nunlabeled raw texts in the source language. Our proposed model leverages mutual\ninformation estimation to decompose the representations computed by a\ncross-lingual model into domain-invariant and domain-specific parts.\nExperimental results show that our proposed method achieves significant\nperformance improvements over the state-of-the-art pretrained cross-lingual\nlanguage model in the CLCD setting. The source code of this paper is publicly\navailable at https://github.com/lijuntaopku/UFD.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:00:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Juntao", ""], ["He", "Ruidan", ""], ["Ye", "Hai", ""], ["Ng", "Hwee Tou", ""], ["Bing", "Lidong", ""], ["Yan", "Rui", ""]]}, {"id": "2011.11523", "submitter": "Neeraj Vashistha", "authors": "Neeraj Vashistha, Arkaitz Zubiaga, Shanky Sharma", "title": "An Online Multilingual Hate speech Recognition System", "comments": "11 pages, 5 figures, appear in Special Issue \"Natural Language\n  Processing for Social Media\" on MDPI Information 2021, 12(1), 5", "journal-ref": "Information 12, no. 1: 5 (2021)", "doi": "10.3390/info12010005", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exponential increase in the use of the Internet and social media over the\nlast two decades has changed human interaction. This has led to many positive\noutcomes, but at the same time it has brought risks and harms. While the volume\nof harmful content online, such as hate speech, is not manageable by humans,\ninterest in the academic community to investigate automated means for hate\nspeech detection has increased. In this study, we analyse six publicly\navailable datasets by combining them into a single homogeneous dataset and\nclassify them into three classes, abusive, hateful or neither. We create a\nbaseline model and we improve model performance scores using various\noptimisation techniques. After attaining a competitive performance score, we\ncreate a tool which identifies and scores a page with effective metric in\nnear-real time and uses the same as feedback to re-train our model. We prove\nthe competitive performance of our multilingual model on two langauges, English\nand Hindi, leading to comparable or superior performance to most monolingual\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:33:48 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 04:29:29 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 18:08:11 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Vashistha", "Neeraj", ""], ["Zubiaga", "Arkaitz", ""], ["Sharma", "Shanky", ""]]}, {"id": "2011.11536", "submitter": "Irina Nikishina", "authors": "Irina Nikishina, Alexander Panchenko, Varvara Logacheva, Natalia\n  Loukachevitch", "title": "Studying Taxonomy Enrichment on Diachronic WordNet Versions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ontologies, taxonomies, and thesauri are used in many NLP tasks. However,\nmost studies are focused on the creation of these lexical resources rather than\nthe maintenance of the existing ones. Thus, we address the problem of taxonomy\nenrichment. We explore the possibilities of taxonomy extension in a\nresource-poor setting and present methods which are applicable to a large\nnumber of languages. We create novel English and Russian datasets for training\nand evaluating taxonomy enrichment models and describe a technique of creating\nsuch datasets for other languages.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:49:37 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Nikishina", "Irina", ""], ["Panchenko", "Alexander", ""], ["Logacheva", "Varvara", ""], ["Loukachevitch", "Natalia", ""]]}, {"id": "2011.11551", "submitter": "Johannes De Smedt", "authors": "Boudewijn van Dongen, Johannes De Smedt, Claudio Di Ciccio, Jan\n  Mendling", "title": "Conformance Checking of Mixed-paradigm Process Models", "comments": "Accepted for publication in Information Systems", "journal-ref": null, "doi": "10.1016/j.is.2020.101685", "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed-paradigm process models integrate strengths of procedural and\ndeclarative representations like Petri nets and Declare. They are specifically\ninteresting for process mining because they allow capturing complex behaviour\nin a compact way. A key research challenge for the proliferation of\nmixed-paradigm models for process mining is the lack of corresponding\nconformance checking techniques. In this paper, we address this problem by\ndevising the first approach that works with intertwined state spaces of\nmixed-paradigm models. More specifically, our approach uses an alignment-based\nreplay to explore the state space and compute trace fitness in a procedural\nway. In every state, the declarative constraints are separately updated, such\nthat violations disable the corresponding activities. Our technique provides\nfor an efficient replay towards an optimal alignment by respecting all\northogonal Declare constraints. We have implemented our technique in ProM and\ndemonstrate its performance in an evaluation with real-world event logs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:04:33 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["van Dongen", "Boudewijn", ""], ["De Smedt", "Johannes", ""], ["Di Ciccio", "Claudio", ""], ["Mendling", "Jan", ""]]}, {"id": "2011.11588", "submitter": "Maureen de Seyssel", "authors": "Tu Anh Nguyen, Maureen de Seyssel, Patricia Roz\\'e, Morgane Rivi\\`ere,\n  Evgeny Kharitonov, Alexei Baevski, Ewan Dunbar, Emmanuel Dupoux", "title": "The Zero Resource Speech Benchmark 2021: Metrics and baselines for\n  unsupervised spoken language modeling", "comments": "14 pages, including references and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new unsupervised task, spoken language modeling: the learning\nof linguistic representations from raw audio signals without any labels, along\nwith the Zero Resource Speech Benchmark 2021: a suite of 4 black-box, zero-shot\nmetrics probing for the quality of the learned models at 4 linguistic levels:\nphonetics, lexicon, syntax and semantics. We present the results and analyses\nof a composite baseline made of the concatenation of three unsupervised\nsystems: self-supervised contrastive representation learning (CPC), clustering\n(k-means) and language modeling (LSTM or BERT). The language models learn on\nthe basis of the pseudo-text derived from clustering the learned\nrepresentations. This simple pipeline shows better than chance performance on\nall four metrics, demonstrating the feasibility of spoken language modeling\nfrom raw speech. It also yields worse performance compared to text-based\n'topline' systems trained on the same data, delineating the space to be\nexplored by more sophisticated end-to-end models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:01:37 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 15:53:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Nguyen", "Tu Anh", ""], ["de Seyssel", "Maureen", ""], ["Roz\u00e9", "Patricia", ""], ["Rivi\u00e8re", "Morgane", ""], ["Kharitonov", "Evgeny", ""], ["Baevski", "Alexei", ""], ["Dunbar", "Ewan", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2011.11603", "submitter": "Zhonghao Wang", "authors": "Zhonghao Wang, Mo Yu, Kai Wang, Jinjun Xiong, Wen-mei Hwu, Mark\n  Hasegawa-Johnson, Humphrey Shi", "title": "Interpretable Visual Reasoning via Induced Symbolic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of concept induction in visual reasoning, i.e.,\nidentifying concepts and their hierarchical relationships from question-answer\npairs associated with images; and achieve an interpretable model via working on\nthe induced symbolic concept space. To this end, we first design a new\nframework named object-centric compositional attention model (OCCAM) to perform\nthe visual reasoning task with object-level visual features. Then, we come up\nwith a method to induce concepts of objects and relations using clues from the\nattention patterns between objects' visual features and question words.\nFinally, we achieve a higher level of interpretability by imposing OCCAM on the\nobjects represented in the induced symbolic concept space. Experiments on the\nCLEVR dataset demonstrate: 1) our OCCAM achieves a new state of the art without\nhuman-annotated functional programs; 2) our induced concepts are both accurate\nand sufficient as OCCAM achieves an on-par performance on objects represented\neither in visual features or in the induced symbolic concept space.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:21:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Zhonghao", ""], ["Yu", "Mo", ""], ["Wang", "Kai", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""], ["Hasegawa-Johnson", "Mark", ""], ["Shi", "Humphrey", ""]]}, {"id": "2011.11671", "submitter": "Ilya Sklyar", "authors": "Ilya Sklyar, Anna Piunova, Yulan Liu", "title": "Streaming Multi-speaker ASR with RNN-T", "comments": "Accepted at ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows end-to-end ASR systems can recognize overlapped speech\nfrom multiple speakers. However, all published works have assumed no latency\nconstraints during inference, which does not hold for most voice assistant\ninteractions. This work focuses on multi-speaker speech recognition based on a\nrecurrent neural network transducer (RNN-T) that has been shown to provide high\nrecognition accuracy at a low latency online recognition regime. We investigate\ntwo approaches to multi-speaker model training of the RNN-T: deterministic\noutput-target assignment and permutation invariant training. We show that\nguiding separation with speaker order labels in the former case enhances the\nhigh-level speaker tracking capability of RNN-T. Apart from that, with\nmultistyle training on single- and multi-speaker utterances, the resulting\nmodels gain robustness against ambiguous numbers of speakers during inference.\nOur best model achieves a WER of 10.2% on simulated 2-speaker LibriSpeech data,\nwhich is competitive with the previously reported state-of-the-art nonstreaming\nmodel (10.3%), while the proposed model could be directly applied for streaming\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:10:40 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 16:42:51 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Sklyar", "Ilya", ""], ["Piunova", "Anna", ""], ["Liu", "Yulan", ""]]}, {"id": "2011.11673", "submitter": "Muktabh Mayank Srivastava", "authors": "Natesh Reddy, Pranaydeep Singh, Muktabh Mayank Srivastava", "title": "Does BERT Understand Sentiment? Leveraging Comparisons Between\n  Contextual and Non-Contextual Embeddings to Improve Aspect-Based Sentiment\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When performing Polarity Detection for different words in a sentence, we need\nto look at the words around to understand the sentiment. Massively pretrained\nlanguage models like BERT can encode not only just the words in a document but\nalso the context around the words along with them. This begs the questions,\n\"Does a pretrain language model also automatically encode sentiment information\nabout each word?\" and \"Can it be used to infer polarity towards different\naspects?\". In this work we try to answer this question by showing that training\na comparison of a contextual embedding from BERT and a generic word embedding\ncan be used to infer sentiment. We also show that if we finetune a subset of\nweights the model built on comparison of BERT and generic word embedding, it\ncan get state of the art results for Polarity Detection in Aspect Based\nSentiment Classification datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:12:31 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Reddy", "Natesh", ""], ["Singh", "Pranaydeep", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "2011.11712", "submitter": "Jernej Vivod", "authors": "Jernej Vivod", "title": "Using Machine Learning and Natural Language Processing Techniques to\n  Analyze and Support Moderation of Student Book Discussions", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing adoption of technology to augment or even replace traditional\nface-to-face learning has led to the development of a myriad of tools and\nplatforms aimed at engaging the students and facilitating the teacher's ability\nto present new information. The IMapBook project aims at improving the literacy\nand reading comprehension skills of elementary school-aged children by\npresenting them with interactive e-books and letting them take part in\nmoderated book discussions. This study aims to develop and illustrate a machine\nlearning-based approach to message classification that could be used to\nautomatically notify the discussion moderator of a possible need for an\nintervention and also to collect other useful information about the ongoing\ndiscussion. We aim to predict whether a message posted in the discussion is\nrelevant to the discussed book, whether the message is a statement, a question,\nor an answer, and in which broad category it can be classified. We\nincrementally enrich our used feature subsets and compare them using standard\nclassification algorithms as well as the novel Feature stacking method. We use\nstandard classification performance metrics as well as the Bayesian correlated\nt-test to show that the use of described methods in discussion moderation is\nfeasible. Moving forward, we seek to attain better performance by focusing on\nextracting more of the significant information found in the strong temporal\ninterdependence of the messages.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:33:09 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Vivod", "Jernej", ""]]}, {"id": "2011.11715", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Linda Liu, Ankur Gandhe, Yile Gu, Anirudh Raju,\n  Denis Filimonov, Ivan Bulyko", "title": "Multi-task Language Modeling for Improving Speech Recognition of Rare\n  Words", "comments": "Preprint. Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end automatic speech recognition (ASR) systems are increasingly\npopular due to their relative architectural simplicity and competitive\nperformance. However, even though the average accuracy of these systems may be\nhigh, the performance on rare content words often lags behind hybrid ASR\nsystems. To address this problem, second-pass rescoring is often applied\nleveraging upon language modeling. In this paper, we propose a second-pass\nsystem with multi-task learning, utilizing semantic targets (such as intent and\nslot prediction) to improve speech recognition performance. We show that our\nrescoring model trained with these additional tasks outperforms the baseline\nrescoring model, trained with only the language modeling task, by 1.4% on a\ngeneral test and by 2.6% on a rare word test set in terms of word-error-rate\nrelative (WERR).\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:40:44 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 03:12:54 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 20:31:00 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Liu", "Linda", ""], ["Gandhe", "Ankur", ""], ["Gu", "Yile", ""], ["Raju", "Anirudh", ""], ["Filimonov", "Denis", ""], ["Bulyko", "Ivan", ""]]}, {"id": "2011.11760", "submitter": "Gabriel Huang", "authors": "Gabriel Huang, Bo Pang, Zhenhai Zhu, Clara Rivera, Radu Soricut", "title": "Multimodal Pretraining for Dense Video Captioning", "comments": "AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning specific hands-on skills such as cooking, car maintenance, and home\nrepairs increasingly happens via instructional videos. The user experience with\nsuch videos is known to be improved by meta-information such as time-stamped\nannotations for the main steps involved. Generating such annotations\nautomatically is challenging, and we describe here two relevant contributions.\nFirst, we construct and release a new dense video captioning dataset, Video\nTimeline Tags (ViTT), featuring a variety of instructional videos together with\ntime-stamped annotations. Second, we explore several multimodal\nsequence-to-sequence pretraining strategies that leverage large unsupervised\ndatasets of videos and caption-like texts. We pretrain and subsequently\nfinetune dense video captioning models using both YouCook2 and ViTT. We show\nthat such models generalize well and are robust over a wide variety of\ninstructional videos.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:49:14 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huang", "Gabriel", ""], ["Pang", "Bo", ""], ["Zhu", "Zhenhai", ""], ["Rivera", "Clara", ""], ["Soricut", "Radu", ""]]}, {"id": "2011.11773", "submitter": "Felipe Godoy", "authors": "Felipe Godoy", "title": "Advancing Humor-Focused Sentiment Analysis through Improved\n  Contextualized Embeddings and Model Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humor is a natural and fundamental component of human interactions. When\ncorrectly applied, humor allows us to express thoughts and feelings\nconveniently and effectively, increasing interpersonal affection, likeability,\nand trust. However, understanding the use of humor is a computationally\nchallenging task from the perspective of humor-aware language processing\nmodels. As language models become ubiquitous through virtual-assistants and IOT\ndevices, the need to develop humor-aware models rises exponentially. To further\nimprove the state-of-the-art capacity to perform this particular\nsentiment-analysis task we must explore models that incorporate contextualized\nand nonverbal elements in their design. Ideally, we seek architectures\naccepting non-verbal elements as additional embedded inputs to the model,\nalongside the original sentence-embedded input. This survey thus analyses the\ncurrent state of research in techniques for improved contextualized embedding\nincorporating nonverbal information, as well as newly proposed deep\narchitectures to improve context retention on top of popular word-embeddings\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 22:30:32 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Godoy", "Felipe", ""]]}, {"id": "2011.11807", "submitter": "Yushi Hu", "authors": "Yushi Hu, Shane Settle, and Karen Livescu", "title": "Acoustic span embeddings for multilingual query-by-example search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query-by-example (QbE) speech search is the task of matching spoken queries\nto utterances within a search collection. In low- or zero-resource settings,\nQbE search is often addressed with approaches based on dynamic time warping\n(DTW). Recent work has found that methods based on acoustic word embeddings\n(AWEs) can improve both performance and search speed. However, prior work on\nAWE-based QbE has primarily focused on English data and with single-word\nqueries. In this work, we generalize AWE training to spans of words, producing\nacoustic span embeddings (ASE), and explore the application of ASE to QbE with\narbitrary-length queries in multiple unseen languages. We consider the commonly\nused setting where we have access to labeled data in other languages (in our\ncase, several low-resource languages) distinct from the unseen test languages.\nWe evaluate our approach on the QUESST 2015 QbE tasks, finding that\nmultilingual ASE-based search is much faster than DTW-based search and\noutperforms the best previously published results on this task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:28:22 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Hu", "Yushi", ""], ["Settle", "Shane", ""], ["Livescu", "Karen", ""]]}, {"id": "2011.11851", "submitter": "Woohwan Jung", "authors": "Woohwan Jung and Kyuseok Shim", "title": "Dual Supervision Framework for Relation Extraction with Distant\n  Supervision and Human Annotation", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) has been extensively studied due to its importance\nin real-world applications such as knowledge base construction and question\nanswering. Most of the existing works train the models on either distantly\nsupervised data or human-annotated data. To take advantage of the high accuracy\nof human annotation and the cheap cost of distant supervision, we propose the\ndual supervision framework which effectively utilizes both types of data.\nHowever, simply combining the two types of data to train a RE model may\ndecrease the prediction accuracy since distant supervision has labeling bias.\nWe employ two separate prediction networks HA-Net and DS-Net to predict the\nlabels by human annotation and distant supervision, respectively, to prevent\nthe degradation of accuracy by the incorrect labeling of distant supervision.\nFurthermore, we propose an additional loss term called disagreement penalty to\nenable HA-Net to learn from distantly supervised labels. In addition, we\nexploit additional networks to adaptively assess the labeling bias by\nconsidering contextual information. Our performance study on sentence-level and\ndocument-level REs confirms the effectiveness of the dual supervision\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:35:24 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Jung", "Woohwan", ""], ["Shim", "Kyuseok", ""]]}, {"id": "2011.11855", "submitter": "Sihyeon Jo", "authors": "Sihyeon Jo, Donghwi Jung, Keonwoo Kim, Eun Gyo Joung, Giulia Nespoli,\n  Seungryong Yoo, Minseob So, Seung-Woo Seo, and Seong-Woo Kim", "title": "A Robotic Dating Coaching System Leveraging Online Communities Posts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can a robot be a personal dating coach? Even with the increasing amount of\nconversational data on the internet, the implementation of conversational\nrobots remains a challenge. In particular, a detailed and professional\ncounseling log is expensive and not publicly accessible. In this paper, we\ndevelop a robot dating coaching system leveraging corpus from online\ncommunities. We examine people's perceptions of the dating coaching robot with\na dialogue module. 97 participants joined to have a conversation with the\nrobot, and 30 of them evaluated the robot. The results indicate that\nparticipants thought the robot could become a dating coach while considering\nthe robot is entertaining rather than helpful.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:46:02 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Jo", "Sihyeon", ""], ["Jung", "Donghwi", ""], ["Kim", "Keonwoo", ""], ["Joung", "Eun Gyo", ""], ["Nespoli", "Giulia", ""], ["Yoo", "Seungryong", ""], ["So", "Minseob", ""], ["Seo", "Seung-Woo", ""], ["Kim", "Seong-Woo", ""]]}, {"id": "2011.11928", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Yu Yan, Yeyun Gong, Weizhen Qi, Hang Zhang, Jian Jiao,\n  Weizhu Chen, Jie Fu, Linjun Shou, Ming Gong, Pengcheng Wang, Jiusheng Chen,\n  Daxin Jiang, Jiancheng Lv, Ruofei Zhang, Winnie Wu, Ming Zhou, Nan Duan", "title": "GLGE: A New General Language Generation Evaluation Benchmark", "comments": "Findings of Association for Computational Linguistics. ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-task benchmarks such as GLUE and SuperGLUE have driven great progress\nof pretraining and transfer learning in Natural Language Processing (NLP).\nThese benchmarks mostly focus on a range of Natural Language Understanding\n(NLU) tasks, without considering the Natural Language Generation (NLG) models.\nIn this paper, we present the General Language Generation Evaluation (GLGE), a\nnew multi-task benchmark for evaluating the generalization capabilities of NLG\nmodels across eight language generation tasks. For each task, we continue to\ndesign three subtasks in terms of task difficulty (GLGE-Easy, GLGE-Medium, and\nGLGE-Hard). This introduces 24 subtasks to comprehensively compare model\nperformance. To encourage research on pretraining and transfer learning on NLG\nmodels, we make GLGE publicly available and build a leaderboard with strong\nbaselines including MASS, BART, and ProphetNet (The source code and dataset are\npublicly available at https://github.com/microsoft/glge).\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 06:59:45 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 11:54:23 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 08:01:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liu", "Dayiheng", ""], ["Yan", "Yu", ""], ["Gong", "Yeyun", ""], ["Qi", "Weizhen", ""], ["Zhang", "Hang", ""], ["Jiao", "Jian", ""], ["Chen", "Weizhu", ""], ["Fu", "Jie", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Wang", "Pengcheng", ""], ["Chen", "Jiusheng", ""], ["Jiang", "Daxin", ""], ["Lv", "Jiancheng", ""], ["Zhang", "Ruofei", ""], ["Wu", "Winnie", ""], ["Zhou", "Ming", ""], ["Duan", "Nan", ""]]}, {"id": "2011.12014", "submitter": "Maximilian Splieth\\\"over", "authors": "Maximilian Splieth\\\"over, Henning Wachsmuth", "title": "Argument from Old Man's View: Assessing Social Bias in Argumentation", "comments": "Accepted at the 7th Workshop on Argument Mining 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social bias in language - towards genders, ethnicities, ages, and other\nsocial groups - poses a problem with ethical impact for many NLP applications.\nRecent research has shown that machine learning models trained on respective\ndata may not only adopt, but even amplify the bias. So far, however, little\nattention has been paid to bias in computational argumentation. In this paper,\nwe study the existence of social biases in large English debate portals. In\nparticular, we train word embedding models on portal-specific corpora and\nsystematically evaluate their bias using WEAT, an existing metric to measure\nbias in word embeddings. In a word co-occurrence analysis, we then investigate\ncauses of bias. The results suggest that all tested debate corpora contain\nunbalanced and biased data, mostly in favor of male people with\nEuropean-American names. Our empirical insights contribute towards an\nunderstanding of bias in argumentative data sources.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 10:39:44 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Splieth\u00f6ver", "Maximilian", ""], ["Wachsmuth", "Henning", ""]]}, {"id": "2011.12073", "submitter": "Michael Lepori Jr.", "authors": "Michael A. Lepori, R. Thomas McCoy", "title": "Picking BERT's Brain: Probing for Linguistic Dependencies in\n  Contextualized Embeddings Using Representational Similarity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the name implies, contextualized representations of language are typically\nmotivated by their ability to encode context. Which aspects of context are\ncaptured by such representations? We introduce an approach to address this\nquestion using Representational Similarity Analysis (RSA). As case studies, we\ninvestigate the degree to which a verb embedding encodes the verb's subject, a\npronoun embedding encodes the pronoun's antecedent, and a full-sentence\nrepresentation encodes the sentence's head word (as determined by a dependency\nparse). In all cases, we show that BERT's contextualized embeddings reflect the\nlinguistic dependency being studied, and that BERT encodes these dependencies\nto a greater degree than it encodes less linguistically-salient controls. These\nresults demonstrate the ability of our approach to adjudicate between\nhypotheses about which aspects of context are encoded in representations of\nlanguage.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:19:06 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Lepori", "Michael A.", ""], ["McCoy", "R. Thomas", ""]]}, {"id": "2011.12075", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Alejandro Sobrino and Eduardo C. Garrido-Merchan and Cristina Puente", "title": "Fuzzy Stochastic Timed Petri Nets for Causal properties representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagery is frequently used to model, represent and communicate knowledge. In\nparticular, graphs are one of the most powerful tools, being able to represent\nrelations between objects. Causal relations are frequently represented by\ndirected graphs, with nodes denoting causes and links denoting causal\ninfluence. A causal graph is a skeletal picture, showing causal associations\nand impact between entities. Common methods used for graphically representing\ncausal scenarios are neurons, truth tables, causal Bayesian networks, cognitive\nmaps and Petri Nets. Causality is often defined in terms of precedence (the\ncause precedes the effect), concurrency (often, an effect is provoked\nsimultaneously by two or more causes), circularity (a cause provokes the effect\nand the effect reinforces the cause) and imprecision (the presence of the cause\nfavors the effect, but not necessarily causes it). We will show that, even\nthough the traditional graphical models are able to represent separately some\nof the properties aforementioned, they fail trying to illustrate indistinctly\nall of them. To approach that gap, we will introduce Fuzzy Stochastic Timed\nPetri Nets as a graphical tool able to represent time, co-occurrence, looping\nand imprecision in causal flow.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:22:34 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Sobrino", "Alejandro", ""], ["Garrido-Merchan", "Eduardo C.", ""], ["Puente", "Cristina", ""]]}, {"id": "2011.12081", "submitter": "Brandon Bennett Dr", "authors": "Suk Joon Hong, Brandon Bennett", "title": "Tackling Domain-Specific Winograd Schemas with Knowledge-Based Reasoning\n  and Machine Learning", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Winograd Schema Challenge (WSC) is a common-sense reasoning task that\nrequires background knowledge. In this paper, we contribute to tackling WSC in\nfour ways. Firstly, we suggest a keyword method to define a restricted domain\nwhere distinctive high-level semantic patterns can be found. A thanking domain\nwas defined by key-words, and the data set in this domain is used in our\nexperiments. Secondly, we develop a high-level knowledge-based reasoning method\nusing semantic roles which is based on the method of Sharma [2019]. Thirdly, we\npropose an ensemble method to combine knowledge-based reasoning and machine\nlearning which shows the best performance in our experiments. As a machine\nlearning method, we used Bidirectional Encoder Representations from\nTransformers (BERT) [Kocijan et al., 2019]. Lastly, in terms of evaluation, we\nsuggest a \"robust\" accuracy measurement by modifying that of Trichelair et al.\n[2018]. As with their switching method, we evaluate a model by considering its\nperformance on trivial variants of each sentence in the test set.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:34:38 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Hong", "Suk Joon", ""], ["Bennett", "Brandon", ""]]}, {"id": "2011.12086", "submitter": "Michael Lepori Jr.", "authors": "Michael A. Lepori", "title": "Unequal Representations: Analyzing Intersectional Biases in Word\n  Embeddings Using Representational Similarity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach for detecting human-like social biases in word\nembeddings using representational similarity analysis. Specifically, we probe\ncontextualized and non-contextualized embeddings for evidence of intersectional\nbiases against Black women. We show that these embeddings represent Black women\nas simultaneously less feminine than White women, and less Black than Black\nmen. This finding aligns with intersectionality theory, which argues that\nmultiple identity categories (such as race or sex) layer on top of each other\nin order to create unique modes of discrimination that are not shared by any\nindividual category.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:45:14 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Lepori", "Michael A.", ""]]}, {"id": "2011.12096", "submitter": "Diego Kozlowski", "authors": "Diego Kozlowski, Gabriela Lozano, Carla M. Felcher, Fernando Gonzalez\n  and Edgar Altszyler", "title": "Gender bias in magazines oriented to men and women: a computational\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cultural products are a source to acquire individual values and behaviours.\nTherefore, the differences in the content of the magazines aimed specifically\nat women or men are a means to create and reproduce gender stereotypes. In this\nstudy, we compare the content of a women-oriented magazine with that of a\nmen-oriented one, both produced by the same editorial group, over a decade\n(2008-2018). With Topic Modelling techniques we identify the main themes\ndiscussed in the magazines and quantify how much the presence of these topics\ndiffers between magazines over time. Then, we performed a word-frequency\nanalysis to validate this methodology and extend the analysis to other subjects\nthat did not emerge automatically. Our results show that the frequency of\nappearance of the topics Family, Business and Women as sex objects, present an\ninitial bias that tends to disappear over time. Conversely, in Fashion and\nScience topics, the initial differences between both magazines are maintained.\nBesides, we show that in 2012, the content associated with horoscope increased\nin the women-oriented magazine, generating a new gap that remained open over\ntime. Also, we show a strong increase in the use of words associated with\nfeminism since 2015 and specifically the word abortion in 2018. Overall, these\ncomputational tools allowed us to analyse more than 24,000 articles. Up to our\nknowledge, this is the first study to compare magazines in such a large\ndataset, a task that would have been prohibitive using manual content analysis\nmethodologies.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:02:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kozlowski", "Diego", ""], ["Lozano", "Gabriela", ""], ["Felcher", "Carla M.", ""], ["Gonzalez", "Fernando", ""], ["Altszyler", "Edgar", ""]]}, {"id": "2011.12165", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Christopher Brix and Hermann Ney", "title": "Two-Way Neural Machine Translation: A Proof of Concept for Bidirectional\n  Translation Modeling using a Two-Dimensional Grid", "comments": "6 pages, accepted at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural translation models have proven to be effective in capturing sufficient\ninformation from a source sentence and generating a high-quality target\nsentence. However, it is not easy to get the best effect for bidirectional\ntranslation, i.e., both source-to-target and target-to-source translation using\na single model. If we exclude some pioneering attempts, such as multilingual\nsystems, all other bidirectional translation approaches are required to train\ntwo individual models. This paper proposes to build a single end-to-end\nbidirectional translation model using a two-dimensional grid, where the\nleft-to-right decoding generates source-to-target, and the bottom-to-up\ndecoding creates target-to-source output. Instead of training two models\nindependently, our approach encourages a single network to jointly learn to\ntranslate in both directions. Experiments on the WMT 2018\nGerman$\\leftrightarrow$English and Turkish$\\leftrightarrow$English translation\ntasks show that the proposed model is capable of generating a good translation\nquality and has sufficient potential to direct the research.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:42:32 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bahar", "Parnia", ""], ["Brix", "Christopher", ""], ["Ney", "Hermann", ""]]}, {"id": "2011.12167", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Tobias Bieschke, Ralf Schl\\\"uter and Hermann Ney", "title": "Tight Integrated End-to-End Training for Cascaded Speech Translation", "comments": "8 pages, accepted at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A cascaded speech translation model relies on discrete and non-differentiable\ntranscription, which provides a supervision signal from the source side and\nhelps the transformation between source speech and target text. Such modeling\nsuffers from error propagation between ASR and MT models. Direct speech\ntranslation is an alternative method to avoid error propagation; however, its\nperformance is often behind the cascade system. To use an intermediate\nrepresentation and preserve the end-to-end trainability, previous studies have\nproposed using two-stage models by passing the hidden vectors of the recognizer\ninto the decoder of the MT model and ignoring the MT encoder. This work\nexplores the feasibility of collapsing the entire cascade components into a\nsingle end-to-end trainable model by optimizing all parameters of ASR and MT\nmodels jointly without ignoring any learned parameters. It is a tightly\nintegrated method that passes renormalized source word posterior distributions\nas a soft decision instead of one-hot vectors and enables backpropagation.\nTherefore, it provides both transcriptions and translations and achieves strong\nconsistency between them. Our experiments on four tasks with different data\nscenarios show that the model outperforms cascade models up to 1.8% in BLEU and\n2.0% in TER and is superior compared to direct models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:43:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bahar", "Parnia", ""], ["Bieschke", "Tobias", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2011.12170", "submitter": "Vladislav Mikhailov", "authors": "Vladislav Mikhailov and Tatiana Shavrina", "title": "Domain-Transferable Method for Named Entity Recognition Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) is a fundamental task in the fields of natural\nlanguage processing and information extraction. NER has been widely used as a\nstandalone tool or an essential component in a variety of applications such as\nquestion answering, dialogue assistants and knowledge graphs development.\nHowever, training reliable NER models requires a large amount of labelled data\nwhich is expensive to obtain, particularly in specialized domains. This paper\ndescribes a method to learn a domain-specific NER model for an arbitrary set of\nnamed entities when domain-specific supervision is not available. We assume\nthat the supervision can be obtained with no human effort, and neural models\ncan learn from each other. The code, data and models are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:45:52 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mikhailov", "Vladislav", ""], ["Shavrina", "Tatiana", ""]]}, {"id": "2011.12183", "submitter": "Nicolas Garneau", "authors": "David Beauchemin, Nicolas Garneau, Eve Gaumond, Pierre-Luc D\\'eziel,\n  Richard Khoury, Luc Lamontagne", "title": "Generating Intelligible Plumitifs Descriptions: Use Case Application\n  with Ethical Considerations", "comments": "INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Plumitifs (dockets) were initially a tool for law clerks. Nowadays, they are\nused as summaries presenting all the steps of a judicial case. Information\nconcerning parties' identity, jurisdiction in charge of administering the case,\nand some information relating to the nature and the course of the preceding are\navailable through plumitifs. They are publicly accessible but barely\nunderstandable; they are written using abbreviations and referring to\nprovisions from the Criminal Code of Canada, which makes them hard to reason\nabout. In this paper, we propose a simple yet efficient multi-source language\ngeneration architecture that leverages both the plumitif and the Criminal\nCode's content to generate intelligible plumitifs descriptions. It goes without\nsaying that ethical considerations rise with these sensitive documents made\nreadable and available at scale, legitimate concerns that we address in this\npaper.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 16:02:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Beauchemin", "David", ""], ["Garneau", "Nicolas", ""], ["Gaumond", "Eve", ""], ["D\u00e9ziel", "Pierre-Luc", ""], ["Khoury", "Richard", ""], ["Lamontagne", "Luc", ""]]}, {"id": "2011.12184", "submitter": "Yekun Chai", "authors": "Yekun Chai, Haidong Zhang, Shuo Jin", "title": "Neural Text Classification by Jointly Learning to Cluster and Align", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional text clustering delivers semantically informative\nrepresentations and captures the relevance between each word and semantic\nclustering centroids. We extend the neural text clustering approach to text\nclassification tasks by inducing cluster centers via a latent variable model\nand interacting with distributional word embeddings, to enrich the\nrepresentation of tokens and measure the relatedness between tokens and each\nlearnable cluster centroid. The proposed method jointly learns word clustering\ncentroids and clustering-token alignments, achieving the state of the art\nresults on multiple benchmark datasets and proving that the proposed\ncluster-token alignment mechanism is indeed favorable to text classification.\nNotably, our qualitative analysis has conspicuously illustrated that text\nrepresentations learned by the proposed model are in accord well with our\nintuition.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 16:07:18 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Chai", "Yekun", ""], ["Zhang", "Haidong", ""], ["Jin", "Shuo", ""]]}, {"id": "2011.12249", "submitter": "Michael Bugert", "authors": "Michael Bugert and Nils Reimers and Iryna Gurevych", "title": "Generalizing Cross-Document Event Coreference Resolution Across Multiple\n  Corpora", "comments": "Accepted at CL Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cross-document event coreference resolution (CDCR) is an NLP task in which\nmentions of events need to be identified and clustered throughout a collection\nof documents. CDCR aims to benefit downstream multi-document applications, but\ndespite recent progress on corpora and system development, downstream\nimprovements from applying CDCR have not been shown yet. We make the\nobservation that every CDCR system to date was developed, trained, and tested\nonly on a single respective corpus. This raises strong concerns on their\ngeneralizability -- a must-have for downstream applications where the magnitude\nof domains or event mentions is likely to exceed those found in a curated\ncorpus. To investigate this assumption, we define a uniform evaluation setup\ninvolving three CDCR corpora: ECB+, the Gun Violence Corpus and the Football\nCoreference Corpus (which we reannotate on token level to make our analysis\npossible). We compare a corpus-independent, feature-based system against a\nrecent neural system developed for ECB+. Whilst being inferior in absolute\nnumbers, the feature-based system shows more consistent performance across all\ncorpora whereas the neural system is hit-and-miss. Via model introspection, we\nfind that the importance of event actions, event time, etc. for resolving\ncoreference in practice varies greatly between the corpora. Additional analysis\nshows that several systems overfit on the structure of the ECB+ corpus. We\nconclude with recommendations on how to achieve generally applicable CDCR\nsystems in the future -- the most important being that evaluation on multiple\nCDCR corpora is strongly necessary. To facilitate future research, we release\nour dataset, annotation guidelines, and system implementation to the public.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:45:03 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 18:06:08 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Bugert", "Michael", ""], ["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2011.12265", "submitter": "Yingxue Fu", "authors": "Yingxue Fu and Elaine Ui Dhonnchadha", "title": "A Pattern-mining Driven Study on Differences of Newspapers in Expressing\n  Temporal Information", "comments": "19 pages", "journal-ref": "David C. Wyld et al. (Eds): NLP, JSE, MLTEC, DMS, NeTIOT, ITCS,\n  SIP, CST, ARIA - 2020 pp. 111-129, 2020. CS & IT - CSCP 2020", "doi": "10.5121/csit.2020.101409", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper studies the differences between different types of newspapers in\nexpressing temporal information, which is a topic that has not received much\nattention. Techniques from the fields of temporal processing and pattern mining\nare employed to investigate this topic. First, a corpus annotated with temporal\ninformation is created by the author. Then, sequences of temporal information\ntags mixed with part-of-speech tags are extracted from the corpus. The TKS\nalgorithm is used to mine skip-gram patterns from the sequences. With these\npatterns, the signatures of the four newspapers are obtained. In order to make\nthe signatures uniquely characterize the newspapers, we revise the signatures\nby removing reference patterns. Through examining the number of patterns in the\nsignatures and revised signatures, the proportion of patterns containing\ntemporal information tags and the specific patterns containing temporal\ninformation tags, it is found that newspapers differ in ways of expressing\ntemporal information.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 18:20:24 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Fu", "Yingxue", ""], ["Dhonnchadha", "Elaine Ui", ""]]}, {"id": "2011.12334", "submitter": "Nan Jiang", "authors": "Maosen Zhang, Nan Jiang, Lei Li, and Yexiang Xue", "title": "Language Generation via Combinatorial Constraint Satisfaction: A Tree\n  Search Enhanced Monte-Carlo Approach", "comments": "Findings of the Association for Computational Linguistics: EMNLP\n  2020, pages 1286-1298. November 16 - 20, 2020. 2020 Association for\n  Computational Linguistics", "journal-ref": "Findings of the Association for Computational Linguistics: EMNLP\n  2020, pages 1286-1298. November 16 - 20, 2020. 2020 Association for\n  Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating natural language under complex constraints is a principled\nformulation towards controllable text generation. We present a framework to\nallow specification of combinatorial constraints for sentence generation. We\npropose TSMH, an efficient method to generate high likelihood sentences with\nrespect to a pre-trained language model while satisfying the constraints. Our\napproach is highly flexible, requires no task-specific training, and leverages\nefficient constraint satisfaction solving techniques. To better handle the\ncombinatorial constraints, a tree search algorithm is embedded into the\nproposal process of the Markov chain Monte Carlo (MCMC) to explore candidates\nthat satisfy more constraints. Compared to existing MCMC approaches, our\nsampling approach has a better mixing performance. Experiments show that TSMH\nachieves consistent and significant improvement on multiple language generation\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:21:00 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 00:15:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhang", "Maosen", ""], ["Jiang", "Nan", ""], ["Li", "Lei", ""], ["Xue", "Yexiang", ""]]}, {"id": "2011.12349", "submitter": "Batuhan Bardak", "authors": "Batuhan Bardak and Mehmet Tan", "title": "Improving Clinical Outcome Predictions Using Convolution over Medical\n  Entities with Multimodal Learning", "comments": "21 pages, 2 figures, Submitted to Elsevier (Artificial Intelligence\n  in Medicine)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early prediction of mortality and length of stay(LOS) of a patient is vital\nfor saving a patient's life and management of hospital resources. Availability\nof electronic health records(EHR) makes a huge impact on the healthcare domain\nand there has seen several works on predicting clinical problems. However, many\nstudies did not benefit from the clinical notes because of the sparse, and high\ndimensional nature. In this work, we extract medical entities from clinical\nnotes and use them as additional features besides time-series features to\nimprove our predictions. We propose a convolution based multimodal\narchitecture, which not only learns effectively combining medical entities and\ntime-series ICU signals of patients, but also allows us to compare the effect\nof different embedding techniques such as Word2vec, FastText on medical\nentities. In the experiments, our proposed method robustly outperforms all\nother baseline models including different multimodal architectures for all\nclinical tasks. The code for the proposed method is available at\nhttps://github.com/tanlab/ConvolutionMedicalNer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:08:39 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 09:40:41 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bardak", "Batuhan", ""], ["Tan", "Mehmet", ""]]}, {"id": "2011.12380", "submitter": "Walid Hafiane", "authors": "Walid Hafiane, Joel Legrand, Yannick Toussaint and Adrien Coulet", "title": "Experiments on transfer learning architectures for biomedical relation\n  extraction", "comments": "12 pages, 2 figures,Extraction et Gestion des Connaissances (EGC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relation extraction (RE) consists in identifying and structuring\nautomatically relations of interest from texts. Recently, BERT improved the top\nperformances for several NLP tasks, including RE. However, the best way to use\nBERT, within a machine learning architecture, and within a transfer learning\nstrategy is still an open question since it is highly dependent on each\nspecific task and domain. Here, we explore various BERT-based architectures and\ntransfer learning strategies (i.e., frozen or fine-tuned) for the task of\nbiomedical RE on two corpora. Among tested architectures and strategies, our\n*BERT-segMCNN with finetuning reaches performances higher than the\nstate-of-the-art on the two corpora (1.73 % and 32.77 % absolute improvement on\nChemProt and PGxCorpus corpora respectively). More generally, our experiments\nillustrate the expected interest of fine-tuning with BERT, but also the\nunexplored advantage of using structural information (with sentence\nsegmentation), in addition to the context classically leveraged by BERT.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:56:47 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Hafiane", "Walid", ""], ["Legrand", "Joel", ""], ["Toussaint", "Yannick", ""], ["Coulet", "Adrien", ""]]}, {"id": "2011.12432", "submitter": "Matej Klemen", "authors": "Matej Klemen, Luka Krsnik, Marko Robnik-\\v{S}ikonja", "title": "Enhancing deep neural networks with morphological information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Currently, deep learning approaches are superior in natural language\nprocessing due to their ability to extract informative features and patterns\nfrom languages. Two most successful neural architectures are LSTM and\ntransformers, the latter mostly used in the form of large pretrained language\nmodels such as BERT. While cross-lingual approaches are on the rise, a vast\nmajority of current natural language processing techniques is designed and\napplied to English, and less-resourced languages are lagging behind. In\nmorphologically rich languages, plenty of information is conveyed through\nchanges in morphology, e.g., through different prefixes and suffixes modifying\nstems of words. The existing neural approaches do not explicitly use the\ninformation on word morphology. We analyze the effect of adding morphological\nfeatures to LSTM and BERT models. We use three tasks available in many\nless-resourced languages: named entity recognition (NER), dependency parsing\n(DP), and comment filtering (CF). We construct sensible baselines involving\nLSTM and BERT models, which we adjust by adding additional input in the form of\npart of speech (POS) tags and universal features. We compare the obtained\nmodels across subsets of eight languages. Our results suggest that adding\nmorphological features has mixed effects depending on the quality of features\nand the task. The features improve the performance of LSTM-based models on the\nNER and DP tasks, while they do not benefit the performance on the CF task. For\nBERT-based models, the added morphological features only improve the\nperformance on DP when they are of high quality, while they do not show any\npractical improvement when they are predicted. As in NER and CF datasets\nmanually checked features are not available, we only experiment with the\npredicted morphological features and find that they do not cause any practical\nimprovement in performance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:35:44 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Klemen", "Matej", ""], ["Krsnik", "Luka", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "2011.12465", "submitter": "Sunipa Dev", "authors": "Sunipa Dev", "title": "The Geometry of Distributed Representations for Better Alignment,\n  Attenuated Bias, and Improved Interpretability", "comments": "PhD thesis, University of Utah (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional representations for words, text, images, knowledge graphs\nand other structured data are commonly used in different paradigms of machine\nlearning and data mining. These representations have different degrees of\ninterpretability, with efficient distributed representations coming at the cost\nof the loss of feature to dimension mapping. This implies that there is\nobfuscation in the way concepts are captured in these embedding spaces. Its\neffects are seen in many representations and tasks, one particularly\nproblematic one being in language representations where the societal biases,\nlearned from underlying data, are captured and occluded in unknown dimensions\nand subspaces. As a result, invalid associations (such as different races and\ntheir association with a polar notion of good versus bad) are made and\npropagated by the representations, leading to unfair outcomes in different\ntasks where they are used. This work addresses some of these problems\npertaining to the transparency and interpretability of such representations. A\nprimary focus is the detection, quantification, and mitigation of socially\nbiased associations in language representation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:04:11 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Dev", "Sunipa", ""]]}, {"id": "2011.12536", "submitter": "Achintya Sarkar", "authors": "Achintya kr. Sarkar, Zheng-Hua Tan (Senior Member, IEEE)", "title": "Vocal Tract Length Perturbation for Text-Dependent Speaker Verification\n  with Autoregressive Prediction Coding", "comments": "Copyright (c) 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE Signal Processing Letters, vol. 28, pp. 364-368, 2021", "doi": "10.1109/LSP.2021.3055180", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we propose a vocal tract length (VTL) perturbation method for\ntext-dependent speaker verification (TD-SV), in which a set of TD-SV systems\nare trained, one for each VTL factor, and score-level fusion is applied to make\na final decision. Next, we explore the bottleneck (BN) feature extracted by\ntraining deep neural networks with a self-supervised objective, autoregressive\npredictive coding (APC), for TD-SV and compare it with the well-studied\nspeaker-discriminant BN feature. The proposed VTL method is then applied to APC\nand speaker-discriminant BN features. In the end, we combine the VTL\nperturbation systems trained on MFCC and the two BN features in the score\ndomain. Experiments are performed on the RedDots challenge 2016 database of\nTD-SV using short utterances with Gaussian mixture model-universal background\nmodel and i-vector techniques. Results show the proposed methods significantly\noutperform the baselines.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:11:06 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 18:57:26 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Sarkar", "Achintya kr.", "", "Senior Member, IEEE"], ["Tan", "Zheng-Hua", "", "Senior Member, IEEE"]]}, {"id": "2011.12631", "submitter": "Kareem Darwish", "authors": "Kareem Darwish and Nizar Habash and Mourad Abbas and Hend Al-Khalifa\n  and Huseein T. Al-Natsheh and Samhaa R. El-Beltagy and Houda Bouamor and\n  Karim Bouzoubaa and Violetta Cavalli-Sforza and Wassim El-Hajj and Mustafa\n  Jarrar and Hamdy Mubarak", "title": "A Panoramic Survey of Natural Language Processing in the Arab World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The term natural language refers to any system of symbolic communication\n(spoken, signed or written) without intentional human planning and design. This\ndistinguishes natural languages such as Arabic and Japanese from artificially\nconstructed languages such as Esperanto or Python. Natural language processing\n(NLP) is the sub-field of artificial intelligence (AI) focused on modeling\nnatural languages to build applications such as speech recognition and\nsynthesis, machine translation, optical character recognition (OCR), sentiment\nanalysis (SA), question answering, dialogue systems, etc. NLP is a highly\ninterdisciplinary field with connections to computer science, linguistics,\ncognitive science, psychology, mathematics and others. Some of the earliest AI\napplications were in NLP (e.g., machine translation); and the last decade\n(2010-2020) in particular has witnessed an incredible increase in quality,\nmatched with a rise in public awareness, use, and expectations of what may have\nseemed like science fiction in the past. NLP researchers pride themselves on\ndeveloping language independent models and tools that can be applied to all\nhuman languages, e.g. machine translation systems can be built for a variety of\nlanguages using the same basic mechanisms and models. However, the reality is\nthat some languages do get more attention (e.g., English and Chinese) than\nothers (e.g., Hindi and Swahili). Arabic, the primary language of the Arab\nworld and the religious language of millions of non-Arab Muslims is somewhere\nin the middle of this continuum. Though Arabic NLP has many challenges, it has\nseen many successes and developments. Next we discuss Arabic's main challenges\nas a necessary background, and we present a brief history of Arabic NLP. We\nthen survey a number of its research areas, and close with a critical\ndiscussion of the future of Arabic NLP.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:45:38 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 06:38:36 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Darwish", "Kareem", ""], ["Habash", "Nizar", ""], ["Abbas", "Mourad", ""], ["Al-Khalifa", "Hend", ""], ["Al-Natsheh", "Huseein T.", ""], ["El-Beltagy", "Samhaa R.", ""], ["Bouamor", "Houda", ""], ["Bouzoubaa", "Karim", ""], ["Cavalli-Sforza", "Violetta", ""], ["El-Hajj", "Wassim", ""], ["Jarrar", "Mustafa", ""], ["Mubarak", "Hamdy", ""]]}, {"id": "2011.12649", "submitter": "Martijn Bartelds", "authors": "Martijn Bartelds, Wietse de Vries, Faraz Sanal, Caitlin Richter, Mark\n  Liberman, Martijn Wieling", "title": "Neural Representations for Modeling Variation in English Speech", "comments": "Submitted to Journal of Phonetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variation in speech is often represented and investigated using phonetic\ntranscriptions, but transcribing speech is time-consuming and error prone. To\ncreate reliable representations of speech independent from phonetic\ntranscriptions, we investigate the extraction of acoustic embeddings from\nseveral self-supervised neural models. We use these representations to compute\nword-based pronunciation differences between non-native and native speakers of\nEnglish, and evaluate these differences by comparing them with human\nnative-likeness judgments. We show that Transformer-based speech\nrepresentations lead to significant performance gains over the use of phonetic\ntranscriptions, and find that feature-based use of Transformer models is most\neffective with one or more middle layers instead of the final layer. We also\ndemonstrate that these neural speech representations not only capture segmental\ndifferences, but also intonational and durational differences that cannot be\nrepresented by a set of discrete symbols used in phonetic transcriptions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:19:12 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Bartelds", "Martijn", ""], ["de Vries", "Wietse", ""], ["Sanal", "Faraz", ""], ["Richter", "Caitlin", ""], ["Liberman", "Mark", ""], ["Wieling", "Martijn", ""]]}, {"id": "2011.12662", "submitter": "Jie Ma", "authors": "Jie Ma, Jun Liu, Junjun Li, Qinghua Zheng, Qingyu Yin, Jianlong Zhou,\n  Yi Huang", "title": "XTQA: Span-Level Explanations of the Textbook Question Answering", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Textbook Question Answering (TQA) is a task that one should answer a\ndiagram/non-diagram question given a large multi-modal context consisting of\nabundant essays and diagrams. We argue that the explainability of this task\nshould place students as a key aspect to be considered. To address this issue,\nwe devise a novel architecture towards span-level eXplanations of the TQA\n(XTQA) based on our proposed coarse-to-fine grained algorithm, which can\nprovide not only the answers but also the span-level evidences to choose them\nfor students. This algorithm first coarsely chooses top $M$ paragraphs relevant\nto questions using the TF-IDF method, and then chooses top $K$ evidence spans\nfinely from all candidate spans within these paragraphs by computing the\ninformation gain of each span to questions. Experimental results shows that\nXTQA significantly improves the state-of-the-art performance compared with\nbaselines. The source code is available at\nhttps://github.com/keep-smile-001/opentqa\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:44:12 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 06:23:45 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 01:13:44 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ma", "Jie", ""], ["Liu", "Jun", ""], ["Li", "Junjun", ""], ["Zheng", "Qinghua", ""], ["Yin", "Qingyu", ""], ["Zhou", "Jianlong", ""], ["Huang", "Yi", ""]]}, {"id": "2011.12771", "submitter": "Haojie Pan", "authors": "Haojie Pan, Cen Chen, Minghui Qiu, Liu Yang, Feng Ji, Jun Huang,\n  Haiqing Chen", "title": "Learning to Expand: Reinforced Pseudo-relevance Feedback Selection for\n  Information-seeking Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intelligent personal assistant systems for information-seeking conversations\nare increasingly popular in real-world applications, especially for e-commerce\ncompanies. With the development of research in such conversation systems, the\npseudo-relevance feedback (PRF) has demonstrated its effectiveness in\nincorporating relevance signals from external documents. However, the existing\nstudies are either based on heuristic rules or require heavy manual labeling.\nIn this work, we treat the PRF selection as a learning task and proposed a\nreinforced learning based method that can be trained in an end-to-end manner\nwithout any human annotations. More specifically, we proposed a reinforced\nselector to extract useful PRF terms to enhance response candidates and a BERT\nbased response ranker to rank the PRF-enhanced responses. The performance of\nthe ranker serves as rewards to guide the selector to extract useful PRF terms,\nand thus boost the task performance. Extensive experiments on both standard\nbenchmark and commercial datasets show the superiority of our reinforced PRF\nterm selector compared with other potential soft or hard selection methods.\nBoth qualitative case studies and quantitative analysis show that our model can\nnot only select meaningful PRF terms to expand response candidates but also\nachieve the best results compared with all the baseline methods on a variety of\nevaluation metrics. We have also deployed our method on online production in an\ne-commerce company, which shows a significant improvement over the existing\nonline ranking system.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 14:33:18 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Pan", "Haojie", ""], ["Chen", "Cen", ""], ["Qiu", "Minghui", ""], ["Yang", "Liu", ""], ["Ji", "Feng", ""], ["Huang", "Jun", ""], ["Chen", "Haiqing", ""]]}, {"id": "2011.13087", "submitter": "Alicia Y. Tsai", "authors": "Alicia Y. Tsai and Selim Gunay and Minjune Hwang and Pengyuan Zhai and\n  Chenglong Li and Laurent El Ghaoui and Khalid M. Mosalam", "title": "Text Analytics for Resilience-Enabled Extreme Events Reconnaissance", "comments": "Published at NeurIPS 2020 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response (AI+HADR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hazard reconnaissance for natural disasters (e.g., earthquakes) is\nimportant for understanding the performance of the built environment, speeding\nup the recovery, enhancing resilience and making informed decisions related to\ncurrent and future hazards. Natural language processing (NLP) is used in this\nstudy for the purposes of increasing the accuracy and efficiency of natural\nhazard reconnaissance through automation. The study particularly focuses on (1)\nautomated data (news and social media) collection hosted by the Pacific\nEarthquake Engineering Research (PEER) Center server, (2) automatic generation\nof reconnaissance reports, and (3) use of social media to extract post-hazard\ninformation such as the recovery time. Obtained results are encouraging for\nfurther development and wider usage of various NLP methods in natural hazard\nreconnaissance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 01:43:29 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:07:20 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Tsai", "Alicia Y.", ""], ["Gunay", "Selim", ""], ["Hwang", "Minjune", ""], ["Zhai", "Pengyuan", ""], ["Li", "Chenglong", ""], ["Ghaoui", "Laurent El", ""], ["Mosalam", "Khalid M.", ""]]}, {"id": "2011.13100", "submitter": "Zhaopeng Qiu", "authors": "Zhaopeng Qiu, Xian Wu, Wei Fan", "title": "Automatic Distractor Generation for Multiple Choice Questions in\n  Standard Tests", "comments": "accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To assess the knowledge proficiency of a learner, multiple choice question is\nan efficient and widespread form in standard tests. However, the composition of\nthe multiple choice question, especially the construction of distractors is\nquite challenging. The distractors are required to both incorrect and plausible\nenough to confuse the learners who did not master the knowledge. Currently, the\ndistractors are generated by domain experts which are both expensive and\ntime-consuming. This urges the emergence of automatic distractor generation,\nwhich can benefit various standard tests in a wide range of domains. In this\npaper, we propose a question and answer guided distractor generation (EDGE)\nframework to automate distractor generation. EDGE consists of three major\nmodules: (1) the Reforming Question Module and the Reforming Passage Module\napply gate layers to guarantee the inherent incorrectness of the generated\ndistractors; (2) the Distractor Generator Module applies attention mechanism to\ncontrol the level of plausibility. Experimental results on a large-scale public\ndataset demonstrate that our model significantly outperforms existing models\nand achieves a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:58:24 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Qiu", "Zhaopeng", ""], ["Wu", "Xian", ""], ["Fan", "Wei", ""]]}, {"id": "2011.13115", "submitter": "Farhad Moghimifar", "authors": "Farhad Moghimifar, Afshin Rahimi, Mahsa Baktashmotlagh, Xue Li", "title": "Learning Causal Bayesian Networks from Text", "comments": "ALTA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal relationships form the basis for reasoning and decision-making in\nArtificial Intelligence systems. To exploit the large volume of textual data\navailable today, the automatic discovery of causal relationships from text has\nemerged as a significant challenge in recent years. Existing approaches in this\nrealm are limited to the extraction of low-level relations among individual\nevents. To overcome the limitations of the existing approaches, in this paper,\nwe propose a method for automatic inference of causal relationships from human\nwritten language at conceptual level. To this end, we leverage the\ncharacteristics of hierarchy of concepts and linguistic variables created from\ntext, and represent the extracted causal relationships in the form of a Causal\nBayesian Network. Our experiments demonstrate superiority of our approach over\nthe existing approaches in inferring complex causal reasoning from the text.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 03:57:56 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Moghimifar", "Farhad", ""], ["Rahimi", "Afshin", ""], ["Baktashmotlagh", "Mahsa", ""], ["Li", "Xue", ""]]}, {"id": "2011.13137", "submitter": "Yifan Gao", "authors": "Yifan Gao, Henghui Zhu, Patrick Ng, Cicero Nogueira dos Santos, Zhiguo\n  Wang, Feng Nan, Dejiao Zhang, Ramesh Nallapati, Andrew O. Arnold, Bing Xiang", "title": "Answering Ambiguous Questions through Generative Evidence Fusion and\n  Round-Trip Prediction", "comments": "ACL 2021 main conference, 14 pages, 7 figures. Code will be released\n  at https://github.com/amzn/refuel-open-domain-qa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In open-domain question answering, questions are highly likely to be\nambiguous because users may not know the scope of relevant topics when\nformulating them. Therefore, a system needs to find possible interpretations of\nthe question, and predict one or multiple plausible answers. When multiple\nplausible answers are found, the system should rewrite the question for each\nanswer to resolve the ambiguity. In this paper, we present a model that\naggregates and combines evidence from multiple passages to adaptively predict a\nsingle answer or a set of question-answer pairs for ambiguous questions. In\naddition, we propose a novel round-trip prediction approach to iteratively\ngenerate additional interpretations that our model fails to find in the first\npass, and then verify and filter out the incorrect question-answer pairs to\narrive at the final disambiguated output. Our model, named Refuel, achieves a\nnew state-of-the-art performance on the AmbigQA dataset, and shows competitive\nperformance on NQ-Open and TriviaQA. The proposed round-trip prediction is a\nmodel-agnostic general approach for answering ambiguous open-domain questions,\nwhich improves our Refuel as well as several baseline models. We release source\ncode for our models and experiments at\nhttps://github.com/amzn/refuel-open-domain-qa.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 05:48:55 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 07:07:19 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gao", "Yifan", ""], ["Zhu", "Henghui", ""], ["Ng", "Patrick", ""], ["Santos", "Cicero Nogueira dos", ""], ["Wang", "Zhiguo", ""], ["Nan", "Feng", ""], ["Zhang", "Dejiao", ""], ["Nallapati", "Ramesh", ""], ["Arnold", "Andrew O.", ""], ["Xiang", "Bing", ""]]}, {"id": "2011.13148", "submitter": "Liang Lu", "authors": "Liang Lu, Naoyuki Kanda, Jinyu Li, Yifan Gong", "title": "Streaming end-to-end multi-talker speech recognition", "comments": "5 pages, 3 figures. Accepted to IEEE Signal Processing Letters 2021", "journal-ref": null, "doi": "10.1109/LSP.2021.3070817", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end multi-talker speech recognition is an emerging research trend in\nthe speech community due to its vast potential in applications such as\nconversation and meeting transcriptions. To the best of our knowledge, all\nexisting research works are constrained in the offline scenario. In this work,\nwe propose the Streaming Unmixing and Recognition Transducer (SURT) for\nend-to-end multi-talker speech recognition. Our model employs the Recurrent\nNeural Network Transducer (RNN-T) as the backbone that can meet various latency\nconstraints. We study two different model architectures that are based on a\nspeaker-differentiator encoder and a mask encoder respectively. To train this\nmodel, we investigate the widely used Permutation Invariant Training (PIT)\napproach and the Heuristic Error Assignment Training (HEAT) approach. Based on\nexperiments on the publicly available LibriSpeechMix dataset, we show that HEAT\ncan achieve better accuracy compared with PIT, and the SURT model with 150\nmilliseconds algorithmic latency constraint compares favorably with the offline\nsequence-to-sequence based baseline model in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 06:28:04 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 19:56:02 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lu", "Liang", ""], ["Kanda", "Naoyuki", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2011.13187", "submitter": "Ramon Ruiz-Dolz", "authors": "Ramon Ruiz-Dolz, Stella Heras, Jose Alemany, Ana Garc\\'ia-Fornes", "title": "Transformer-Based Models for Automatic Identification of Argument\n  Relations: A Cross-Domain Evaluation", "comments": "\\c{opyright} 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/MIS.2021.3073993", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Argument Mining is defined as the task of automatically identifying and\nextracting argumentative components (e.g., premises, claims, etc.) and\ndetecting the existing relations among them (i.e., support, attack, rephrase,\nno relation). One of the main issues when approaching this problem is the lack\nof data, and the size of the publicly available corpora. In this work, we use\nthe recently annotated US2016 debate corpus. US2016 is the largest existing\nargument annotated corpus, which allows exploring the benefits of the most\nrecent advances in Natural Language Processing in a complex domain like\nArgument (relation) Mining. We present an exhaustive analysis of the behavior\nof transformer-based models (i.e., BERT, XLNET, RoBERTa, DistilBERT and ALBERT)\nwhen predicting argument relations. Finally, we evaluate the models in five\ndifferent domains, with the objective of finding the less domain dependent\nmodel. We obtain a macro F1-score of 0.70 with the US2016 evaluation corpus,\nand a macro F1-score of 0.61 with the Moral Maze cross-domain corpus.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:04:07 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 11:47:55 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Ruiz-Dolz", "Ramon", ""], ["Heras", "Stella", ""], ["Alemany", "Jose", ""], ["Garc\u00eda-Fornes", "Ana", ""]]}, {"id": "2011.13200", "submitter": "Sourav Dutta", "authors": "Silviu Oprea and Sourav Dutta and Haytham Assem", "title": "Unsupervised Word Translation Pairing using Refinement based Point Set\n  Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-lingual alignment of word embeddings play an important role in\nknowledge transfer across languages, for improving machine translation and\nother multi-lingual applications. Current unsupervised approaches rely on\nsimilarities in geometric structure of word embedding spaces across languages,\nto learn structure-preserving linear transformations using adversarial networks\nand refinement strategies. However, such techniques, in practice, tend to\nsuffer from instability and convergence issues, requiring tedious fine-tuning\nfor precise parameter setting. This paper proposes BioSpere, a novel framework\nfor unsupervised mapping of bi-lingual word embeddings onto a shared vector\nspace, by combining adversarial initialization and refinement procedure with\npoint set registration algorithm used in image processing. We show that our\nframework alleviates the shortcomings of existing methodologies, and is\nrelatively invariant to variable adversarial learning performance, depicting\nrobustness in terms of parameter choices and training losses. Experimental\nevaluation on parallel dictionary induction task demonstrates state-of-the-art\nresults for our framework on diverse language pairs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:51:29 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Oprea", "Silviu", ""], ["Dutta", "Sourav", ""], ["Assem", "Haytham", ""]]}, {"id": "2011.13205", "submitter": "Emanuele Bastianelli", "authors": "Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski, Verena Rieser", "title": "SLURP: A Spoken Language Understanding Resource Package", "comments": "Published at the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoken Language Understanding infers semantic meaning directly from audio\ndata, and thus promises to reduce error propagation and misunderstandings in\nend-user applications. However, publicly available SLU resources are limited.\nIn this paper, we release SLURP, a new SLU package containing the following:\n(1) A new challenging dataset in English spanning 18 domains, which is\nsubstantially bigger and linguistically more diverse than existing datasets;\n(2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A\nnew transparent metric for entity labelling which enables a detailed error\nanalysis for identifying potential areas of improvement. SLURP is available at\nhttps: //github.com/pswietojanski/slurp.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:58:20 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bastianelli", "Emanuele", ""], ["Vanzo", "Andrea", ""], ["Swietojanski", "Pawel", ""], ["Rieser", "Verena", ""]]}, {"id": "2011.13210", "submitter": "Emanuele Bastianelli", "authors": "Emanuele Bastianelli, Andrea Vanzo, Oliver Lemon", "title": "Encoding Syntactic Constituency Paths for Frame-Semantic Parsing with\n  Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of integrating syntactic information from constituency\ntrees into a neural model in Frame-semantic parsing sub-tasks, namely Target\nIdentification (TI), FrameIdentification (FI), and Semantic Role Labeling\n(SRL). We use a Graph Convolutional Network to learn specific representations\nof constituents, such that each constituent is profiled as the production\ngrammar rule it corresponds to. We leverage these representations to build\nsyntactic features for each word in a sentence, computed as the sum of all the\nconstituents on the path between a word and a task-specific node in the tree,\ne.g. the target predicate for SRL. Our approach improves state-of-the-art\nresults on the TI and SRL of ~1%and~3.5% points, respectively (+2.5% additional\npoints are gained with BERT as input), when tested on FrameNet 1.5, while\nyielding comparable results on the CoNLL05 dataset to other syntax-aware\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:10:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bastianelli", "Emanuele", ""], ["Vanzo", "Andrea", ""], ["Lemon", "Oliver", ""]]}, {"id": "2011.13220", "submitter": "Jihyeon Roh", "authors": "Jihyeon Roh, Sang-Hoon Oh, Soo-Young Lee", "title": "Unigram-Normalized Perplexity as a Language Model Performance Measure\n  with Different Vocabulary Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Perplexity is a widely used performance metric for language models,\nthe values are highly dependent upon the number of words in the corpus and is\nuseful to compare performance of the same corpus only. In this paper, we\npropose a new metric that can be used to evaluate language model performance\nwith different vocabulary sizes. The proposed unigram-normalized Perplexity\nactually presents the performance improvement of the language models from that\nof simple unigram model, and is robust on the vocabulary size. Both theoretical\nanalysis and computational experiments are reported.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:39:03 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Roh", "Jihyeon", ""], ["Oh", "Sang-Hoon", ""], ["Lee", "Soo-Young", ""]]}, {"id": "2011.13231", "submitter": "Jesse Gioannini", "authors": "Haotian Zhu, Denise Mak, Jesse Gioannini, Fei Xia", "title": "NLPStatTest: A Toolkit for Comparing NLP System Performance", "comments": "Will appear in AACL-IJCNLP 2020", "journal-ref": "Proceedings of the 1st Conference of the Asia-Pacific Chapter of\n  the Association for Computational Linguistics and the 10th International\n  Joint Conference on Natural Language Processing: System Demonstrations (2020)\n  40-46", "doi": null, "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical significance testing centered on p-values is commonly used to\ncompare NLP system performance, but p-values alone are insufficient because\nstatistical significance differs from practical significance. The latter can be\nmeasured by estimating effect size. In this paper, we propose a three-stage\nprocedure for comparing NLP system performance and provide a toolkit,\nNLPStatTest, that automates the process. Users can upload NLP system evaluation\nscores and the toolkit will analyze these scores, run appropriate significance\ntests, estimate effect size, and conduct power analysis to estimate Type II\nerror. The toolkit provides a convenient and systematic way to compare NLP\nsystem performance that goes beyond statistical significance testing\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:59:23 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhu", "Haotian", ""], ["Mak", "Denise", ""], ["Gioannini", "Jesse", ""], ["Xia", "Fei", ""]]}, {"id": "2011.13238", "submitter": "Alvi Md Ishmam", "authors": "Alvi Md Ishmam", "title": "Towards Interpretable Multilingual Detection of Hate Speech against\n  Immigrants and Women in Twitter at SemEval-2019 Task 5", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  his paper describes our techniques to detect hate speech against women and\nimmigrants on Twitter in multilingual contexts, particularly in English and\nSpanish. The challenge was designed by SemEval-2019 Task 5, where the\nparticipants need to design algorithms to detect hate speech in English and\nSpanish language with a given target (e.g., women or immigrants). Here, we have\ndeveloped two deep neural networks (Bidirectional Gated Recurrent Unit (GRU),\nCharacter-level Convolutional Neural Network (CNN)), and one machine learning\nmodel by exploiting the linguistic features. Our proposed model obtained 57 and\n75 F1 scores for Task A in English and Spanish language respectively. For Task\nB, the F1 scores are 67 for English and 75.33 for Spanish. In the case of task\nA (Spanish) and task B (both English and Spanish), the F1 scores are improved\nby 2, 10, and 5 points respectively. Besides, we present visually interpretable\nmodels that can address the generalizability issues of the custom-designed\nmachine learning architecture by investigating the annotated dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 11:11:44 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ishmam", "Alvi Md", ""]]}, {"id": "2011.13253", "submitter": "Sundeep Teki", "authors": "Rutvik Vijjali, Prathyush Potluri, Siddharth Kumar, Sundeep Teki", "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 11:50:45 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Vijjali", "Rutvik", ""], ["Potluri", "Prathyush", ""], ["Kumar", "Siddharth", ""], ["Teki", "Sundeep", ""]]}, {"id": "2011.13284", "submitter": "Catherine Kobus", "authors": "Alexandre Arnold and G\\'erard Dupont and F\\'elix Furger and Catherine\n  Kobus and Fran\\c{c}ois Lancelot", "title": "A question-answering system for aircraft pilots' documentation", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The aerospace industry relies on massive collections of complex and technical\ndocuments covering system descriptions, manuals or procedures. This paper\npresents a question answering (QA) system that would help aircraft pilots\naccess information in this documentation by naturally interacting with the\nsystem and asking questions in natural language. After describing each module\nof the dialog system, we present a multi-task based approach for the QA module\nwhich enables performance improvement on a Flight Crew Operating Manual (FCOM)\ndataset. A method to combine scores from the retriever and the QA modules is\nalso presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 13:33:47 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Arnold", "Alexandre", ""], ["Dupont", "G\u00e9rard", ""], ["Furger", "F\u00e9lix", ""], ["Kobus", "Catherine", ""], ["Lancelot", "Fran\u00e7ois", ""]]}, {"id": "2011.13354", "submitter": "Aditya Kalyanpur", "authors": "Aditya Kalyanpur, Tom Breloff, David Ferrucci, Adam Lally, John Jantos", "title": "Braid: Weaving Symbolic and Neural Knowledge into Coherent Logical\n  Explanations", "comments": "Description of Braid's design/algorithms + Appendix on Story Cloze\n  evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional symbolic reasoning engines, while attractive for their precision\nand explicability, have a few major drawbacks: the use of brittle inference\nprocedures that rely on exact matching (unification) of logical terms, an\ninability to deal with uncertainty, and the need for a precompiled rule-base of\nknowledge (the \"knowledge acquisition\" problem). These issues are particularly\nsevere for the Natural Language Understanding (NLU) task, where we often use\nimplicit background knowledge to understand and reason about text, resort to\nfuzzy alignment of concepts and relations during reasoning, and constantly deal\nwith ambiguity in representations. To address these issues, we devise a novel\nFOL-based reasoner, called Braid, that supports probabilistic rules, and uses\nthe notion of custom unification functions and dynamic rule generation to\novercome the brittle matching and knowledge-gap problem prevalent in\ntraditional reasoners. In this paper, we describe the reasoning algorithms used\nin Braid-BC (the backchaining component of Braid), and their implementation in\na distributed task-based framework that builds proof/explanation graphs for an\ninput query in a scalable manner. We use a simple QA example from a children's\nstory to motivate Braid-BC's design and explain how the various components work\ntogether to produce a coherent logical explanation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 15:36:06 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 04:44:00 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 17:40:52 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Kalyanpur", "Aditya", ""], ["Breloff", "Tom", ""], ["Ferrucci", "David", ""], ["Lally", "Adam", ""], ["Jantos", "John", ""]]}, {"id": "2011.13384", "submitter": "Shuchin Aeron", "authors": "Ruijie Jiang, Julia Gouvea, David Hammer, Eric Miller, Shuchin Aeron", "title": "Automatic coding of students' writing via Contrastive Representation\n  Learning in the Wasserstein space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative analysis of verbal data is of central importance in the learning\nsciences. It is labor-intensive and time-consuming, however, which limits the\namount of data researchers can include in studies. This work is a step towards\nbuilding a statistical machine learning (ML) method for achieving an automated\nsupport for qualitative analyses of students' writing, here specifically in\nscore laboratory reports in introductory biology for sophistication of\nargumentation and reasoning. We start with a set of lab reports from an\nundergraduate biology course, scored by a four-level scheme that considers the\ncomplexity of argument structure, the scope of evidence, and the care and\nnuance of conclusions. Using this set of labeled data, we show that a popular\nnatural language modeling processing pipeline, namely vector representation of\nwords, a.k.a word embeddings, followed by Long Short Term Memory (LSTM) model\nfor capturing language generation as a state-space model, is able to\nquantitatively capture the scoring, with a high Quadratic Weighted Kappa (QWK)\nprediction score, when trained in via a novel contrastive learning set-up. We\nshow that the ML algorithm approached the inter-rater reliability of human\nanalysis. Ultimately, we conclude, that machine learning (ML) for natural\nlanguage processing (NLP) holds promise for assisting learning sciences\nresearchers in conducting qualitative studies at much larger scales than is\ncurrently possible.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:52:48 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 17:01:35 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jiang", "Ruijie", ""], ["Gouvea", "Julia", ""], ["Hammer", "David", ""], ["Miller", "Eric", ""], ["Aeron", "Shuchin", ""]]}, {"id": "2011.13439", "submitter": "Niko Moritz", "authors": "Sameer Khurana, Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Unsupervised Domain Adaptation for Speech Recognition via Uncertainty\n  Driven Self-Training", "comments": "ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition (ASR) systems typically\ndegrades significantly when the training and test data domains are mismatched.\nIn this paper, we show that self-training (ST) combined with an\nuncertainty-based pseudo-label filtering approach can be effectively used for\ndomain adaptation. We propose DUST, a dropout-based uncertainty-driven\nself-training technique which uses agreement between multiple predictions of an\nASR system obtained for different dropout settings to measure the model's\nuncertainty about its prediction. DUST excludes pseudo-labeled data with high\nuncertainties from the training, which leads to substantially improved ASR\nresults compared to ST without filtering, and accelerates the training time due\nto a reduced training data set. Domain adaptation experiments using WSJ as a\nsource domain and TED-LIUM 3 as well as SWITCHBOARD as the target domains show\nthat up to 80% of the performance of a system trained on ground-truth data can\nbe recovered.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 18:51:26 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:00:46 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Khurana", "Sameer", ""], ["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2011.13470", "submitter": "Tuan Manh Lai", "authors": "Nham Le, Tuan Lai, Trung Bui and Doo Soon Kim", "title": "AutoNLU: An On-demand Cloud-based Natural Language Understanding System\n  for Enterprises", "comments": "Accepted to AACL 2020 (Demo)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the renaissance of deep learning, neural networks have achieved\npromising results on many natural language understanding (NLU) tasks. Even\nthough the source codes of many neural network models are publicly available,\nthere is still a large gap from open-sourced models to solving real-world\nproblems in enterprises. Therefore, to fill this gap, we introduce AutoNLU, an\non-demand cloud-based system with an easy-to-use interface that covers all\ncommon use-cases and steps in developing an NLU model. AutoNLU has supported\nmany product teams within Adobe with different use-cases and datasets, quickly\ndelivering them working models. To demonstrate the effectiveness of AutoNLU, we\npresent two case studies. i) We build a practical NLU model for handling\nvarious image-editing requests in Photoshop. ii) We build powerful keyphrase\nextraction models that achieve state-of-the-art results on two public\nbenchmarks. In both cases, end users only need to write a small amount of code\nto convert their datasets into a common format used by AutoNLU.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 20:51:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Le", "Nham", ""], ["Lai", "Tuan", ""], ["Bui", "Trung", ""], ["Kim", "Doo Soon", ""]]}, {"id": "2011.13477", "submitter": "Nicholas Roberts", "authors": "Nicholas Roberts, Davis Liang, Graham Neubig, Zachary C. Lipton", "title": "Decoding and Diversity in Machine Translation", "comments": "Presented at the Resistance AI Workshop, 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) systems are typically evaluated using\nautomated metrics that assess the agreement between generated translations and\nground truth candidates. To improve systems with respect to these metrics, NLP\nresearchers employ a variety of heuristic techniques, including searching for\nthe conditional mode (vs. sampling) and incorporating various training\nheuristics (e.g., label smoothing). While search strategies significantly\nimprove BLEU score, they yield deterministic outputs that lack the diversity of\nhuman translations. Moreover, search tends to bias the distribution of\ntranslated gender pronouns. This makes human-level BLEU a misleading benchmark\nin that modern MT systems cannot approach human-level BLEU while simultaneously\nmaintaining human-level translation diversity. In this paper, we characterize\ndistributional differences between generated and real translations, examining\nthe cost in diversity paid for the BLEU scores enjoyed by NMT. Moreover, our\nstudy implicates search as a salient source of known bias when translating\ngender pronouns.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 21:09:38 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Roberts", "Nicholas", ""], ["Liang", "Davis", ""], ["Neubig", "Graham", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.13527", "submitter": "Chun-Hsing Lin", "authors": "Chun-Hsing Lin, Siang-Ruei Wu, Hung-Yi Lee, Yun-Nung Chen", "title": "TaylorGAN: Neighbor-Augmented Policy Update for Sample-Efficient Natural\n  Language Generation", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score function-based natural language generation (NLG) approaches such as\nREINFORCE, in general, suffer from low sample efficiency and training\ninstability problems. This is mainly due to the non-differentiable nature of\nthe discrete space sampling and thus these methods have to treat the\ndiscriminator as a black box and ignore the gradient information. To improve\nthe sample efficiency and reduce the variance of REINFORCE, we propose a novel\napproach, TaylorGAN, which augments the gradient estimation by off-policy\nupdate and the first-order Taylor expansion. This approach enables us to train\nNLG models from scratch with smaller batch size -- without maximum likelihood\npre-training, and outperforms existing GAN-based methods on multiple metrics of\nquality and diversity. The source code and data are available at\nhttps://github.com/MiuLab/TaylorGAN\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 02:26:15 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Lin", "Chun-Hsing", ""], ["Wu", "Siang-Ruei", ""], ["Lee", "Hung-Yi", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2011.13534", "submitter": "Nishant Subramani", "authors": "Nishant Subramani and Alexandre Matton and Malcolm Greaves and Adrian\n  Lam", "title": "A Survey of Deep Learning Approaches for OCR and Document Understanding", "comments": "Accepted to the ML-RSA Workshop at NeurIPS2020. 15 pages (10 +\n  References)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Documents are a core part of many businesses in many fields such as law,\nfinance, and technology among others. Automatic understanding of documents such\nas invoices, contracts, and resumes is lucrative, opening up many new avenues\nof business. The fields of natural language processing and computer vision have\nseen tremendous progress through the development of deep learning such that\nthese methods have started to become infused in contemporary document\nunderstanding systems. In this survey paper, we review different techniques for\ndocument understanding for documents written in English and consolidate\nmethodologies present in literature to act as a jumping-off point for\nresearchers exploring this area.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 03:05:59 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 23:48:39 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Subramani", "Nishant", ""], ["Matton", "Alexandre", ""], ["Greaves", "Malcolm", ""], ["Lam", "Adrian", ""]]}, {"id": "2011.13549", "submitter": "Farhad Moghimifar", "authors": "Farhad Moghimifar, Gholamreza Haffari, Mahsa Baktashmotlagh", "title": "Domain Adaptative Causality Encoder", "comments": "ALTA2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches which are mainly based on the extraction of low-level\nrelations among individual events are limited by the shortage of publicly\navailable labelled data. Therefore, the resulting models perform poorly when\napplied to a distributionally different domain for which labelled data did not\nexist at the time of training. To overcome this limitation, in this paper, we\nleverage the characteristics of dependency trees and adversarial learning to\naddress the tasks of adaptive causality identification and localisation. The\nterm adaptive is used since the training and test data come from two\ndistributionally different datasets, which to the best of our knowledge, this\nwork is the first to address. Moreover, we present a new causality dataset,\nnamely MedCaus, which integrates all types of causality in the text. Our\nexperiments on four different benchmark causality datasets demonstrate the\nsuperiority of our approach over the existing baselines, by up to 7%\nimprovement, on the tasks of identification and localisation of the causal\nrelations from the text.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 04:14:55 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Moghimifar", "Farhad", ""], ["Haffari", "Gholamreza", ""], ["Baktashmotlagh", "Mahsa", ""]]}, {"id": "2011.13565", "submitter": "Yuanhao Shen", "authors": "Yuanhao Shen and Jungang Han", "title": "Joint Extraction of Entity and Relation with Information Redundancy\n  Elimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To solve the problem of redundant information and overlapping relations of\nthe entity and relation extraction model, we propose a joint extraction model.\nThis model can directly extract multiple pairs of related entities without\ngenerating unrelated redundant information. We also propose a recurrent neural\nnetwork named Encoder-LSTM that enhances the ability of recurrent units to\nmodel sentences. Specifically, the joint model includes three sub-modules: the\nNamed Entity Recognition sub-module consisted of a pre-trained language model\nand an LSTM decoder layer, the Entity Pair Extraction sub-module which uses\nEncoder-LSTM network to model the order relationship between related entity\npairs, and the Relation Classification sub-module including Attention\nmechanism. We conducted experiments on the public datasets ADE and CoNLL04 to\nevaluate the effectiveness of our model. The results show that the proposed\nmodel achieves good performance in the task of entity and relation extraction\nand can greatly reduce the amount of redundant information.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 05:47:26 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Shen", "Yuanhao", ""], ["Han", "Jungang", ""]]}, {"id": "2011.13570", "submitter": "Yekyung Kim", "authors": "Yekyung Kim", "title": "Deep Active Learning for Sequence Labeling Based on Diversity and\n  Uncertainty in Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies have investigated active learning (AL) for natural\nlanguage processing tasks to alleviate data dependency. However, for query\nselection, most of these studies mainly rely on uncertainty-based sampling,\nwhich generally does not exploit the structural information of the unlabeled\ndata. This leads to a sampling bias in the batch active learning setting, which\nselects several samples at once. In this work, we demonstrate that the amount\nof labeled training data can be reduced using active learning when it\nincorporates both uncertainty and diversity in the sequence labeling task. We\nexamined the effects of our sequence-based approach by selecting weighted\ndiverse in the gradient embedding approach across multiple tasks, datasets,\nmodels, and consistently outperform classic uncertainty-based sampling and\ndiversity-based sampling.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 06:03:27 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kim", "Yekyung", ""]]}, {"id": "2011.13573", "submitter": "Xiongtao Cui", "authors": "Xiongtao Cui and Jungang Han", "title": "Chinese Medical Question Answer Matching Based on Interactive Sentence\n  Representation Learning", "comments": null, "journal-ref": "pp. 93-109, 2020. CS & IT - CSCP 2020", "doi": "10.5121/csit.2020.101408", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chinese medical question-answer matching is more challenging than the\nopen-domain question answer matching in English. Even though the deep learning\nmethod has performed well in improving the performance of question answer\nmatching, these methods only focus on the semantic information inside\nsentences, while ignoring the semantic association between questions and\nanswers, thus resulting in performance deficits. In this paper, we design a\nseries of interactive sentence representation learning models to tackle this\nproblem. To better adapt to Chinese medical question-answer matching and take\nthe advantages of different neural network structures, we propose the Crossed\nBERT network to extract the deep semantic information inside the sentence and\nthe semantic association between question and answer, and then combine with the\nmulti-scale CNNs network or BiGRU network to take the advantage of different\nstructure of neural networks to learn more semantic features into the sentence\nrepresentation. The experiments on the cMedQA V2.0 and cMedQA V1.0 dataset show\nthat our model significantly outperforms all the existing state-of-the-art\nmodels of Chinese medical question answer matching.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 06:13:56 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cui", "Xiongtao", ""], ["Han", "Jungang", ""]]}, {"id": "2011.13574", "submitter": "Jun Kuang", "authors": "Yixin Cao, Jun Kuang, Ming Gao, Aoying Zhou, Yonggang Wen, Tat-Seng\n  Chua", "title": "Learning Relation Prototype from Unlabeled Texts for Long-tail Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relation Extraction (RE) is a vital step to complete Knowledge Graph (KG) by\nextracting entity relations from texts.However, it usually suffers from the\nlong-tail issue. The training data mainly concentrates on a few types of\nrelations, leading to the lackof sufficient annotations for the remaining types\nof relations. In this paper, we propose a general approach to learn relation\nprototypesfrom unlabeled texts, to facilitate the long-tail relation extraction\nby transferring knowledge from the relation types with sufficient trainingdata.\nWe learn relation prototypes as an implicit factor between entities, which\nreflects the meanings of relations as well as theirproximities for transfer\nlearning. Specifically, we construct a co-occurrence graph from texts, and\ncapture both first-order andsecond-order entity proximities for embedding\nlearning. Based on this, we further optimize the distance from entity pairs\ntocorresponding prototypes, which can be easily adapted to almost arbitrary RE\nframeworks. Thus, the learning of infrequent or evenunseen relation types will\nbenefit from semantically proximate relations through pairs of entities and\nlarge-scale textual information.We have conducted extensive experiments on two\npublicly available datasets: New York Times and Google Distant\nSupervision.Compared with eight state-of-the-art baselines, our proposed model\nachieves significant improvements (4.1% F1 on average). Furtherresults on\nlong-tail relations demonstrate the effectiveness of the learned relation\nprototypes. We further conduct an ablation study toinvestigate the impacts of\nvarying components, and apply it to four basic relation extraction models to\nverify the generalization ability.Finally, we analyze several example cases to\ngive intuitive impressions as qualitative analysis. Our codes will be released\nlater.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 06:21:12 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cao", "Yixin", ""], ["Kuang", "Jun", ""], ["Gao", "Ming", ""], ["Zhou", "Aoying", ""], ["Wen", "Yonggang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2011.13633", "submitter": "Shengnan Wang", "authors": "Cheng Yang, Shengnan Wang, Yuechuan Li, Chao Yang, Ming Yan, Jingqiao\n  Zhang, Fangquan Lin", "title": "CoRe: An Efficient Coarse-refined Training Framework for BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, BERT has made significant breakthroughs on many natural\nlanguage processing tasks and attracted great attentions. Despite its accuracy\ngains, the BERT model generally involves a huge number of parameters and needs\nto be trained on massive datasets, so training such a model is computationally\nvery challenging and time-consuming. Hence, training efficiency should be a\ncritical issue. In this paper, we propose a novel coarse-refined training\nframework named CoRe to speed up the training of BERT. Specifically, we\ndecompose the training process of BERT into two phases. In the first phase, by\nintroducing fast attention mechanism and decomposing the large parameters in\nthe feed-forward network sub-layer, we construct a relaxed BERT model which has\nmuch less parameters and much lower model complexity than the original BERT, so\nthe relaxed model can be quickly trained. In the second phase, we transform the\ntrained relaxed BERT model into the original BERT and further retrain the\nmodel. Thanks to the desired initialization provided by the relaxed model, the\nretraining phase requires much less training steps, compared with training an\noriginal BERT model from scratch with a random initialization. Experimental\nresults show that the proposed CoRe framework can greatly reduce the training\ntime without reducing the performance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 09:49:37 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 03:39:00 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Yang", "Cheng", ""], ["Wang", "Shengnan", ""], ["Li", "Yuechuan", ""], ["Yang", "Chao", ""], ["Yan", "Ming", ""], ["Zhang", "Jingqiao", ""], ["Lin", "Fangquan", ""]]}, {"id": "2011.13635", "submitter": "Shengnan Wang", "authors": "Cheng Yang, Shengnan Wang, Chao Yang, Yuechuan Li, Ru He, Jingqiao\n  Zhang", "title": "Progressively Stacking 2.0: A Multi-stage Layerwise Training Method for\n  BERT Training Speedup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-trained language models, such as BERT, have achieved significant accuracy\ngain in many natural language processing tasks. Despite its effectiveness, the\nhuge number of parameters makes training a BERT model computationally very\nchallenging. In this paper, we propose an efficient multi-stage layerwise\ntraining (MSLT) approach to reduce the training time of BERT. We decompose the\nwhole training process into several stages. The training is started from a\nsmall model with only a few encoder layers and we gradually increase the depth\nof the model by adding new encoder layers. At each stage, we only train the top\n(near the output layer) few encoder layers which are newly added. The\nparameters of the other layers which have been trained in the previous stages\nwill not be updated in the current stage. In BERT training, the backward\ncomputation is much more time-consuming than the forward computation,\nespecially in the distributed training setting in which the backward\ncomputation time further includes the communication time for gradient\nsynchronization. In the proposed training strategy, only top few layers\nparticipate in backward computation, while most layers only participate in\nforward computation. Hence both the computation and communication efficiencies\nare greatly improved. Experimental results show that the proposed method can\nachieve more than 110% training speedup without significant performance\ndegradation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 10:00:22 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Yang", "Cheng", ""], ["Wang", "Shengnan", ""], ["Yang", "Chao", ""], ["Li", "Yuechuan", ""], ["He", "Ru", ""], ["Zhang", "Jingqiao", ""]]}, {"id": "2011.13647", "submitter": "Kanjirangat Vani", "authors": "Simone Mellace, K Vani, Alessandro Antonucci", "title": "Relation Clustering in Narrative Knowledge Graphs", "comments": "Accepted for AI4Narratives Workshop at 29th International Joint\n  Conference on Artificial Intelligence and the 17th Pacific Rim International\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When coping with literary texts such as novels or short stories, the\nextraction of structured information in the form of a knowledge graph might be\nhindered by the huge number of possible relations between the entities\ncorresponding to the characters in the novel and the consequent hurdles in\ngathering supervised information about them. Such issue is addressed here as an\nunsupervised task empowered by transformers: relational sentences in the\noriginal text are embedded (with SBERT) and clustered in order to merge\ntogether semantically similar relations. All the sentences in the same cluster\nare finally summarized (with BART) and a descriptive label extracted from the\nsummary. Preliminary tests show that such clustering might successfully detect\nsimilar relations, and provide a valuable preprocessing for semi-supervised\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 10:43:04 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Mellace", "Simone", ""], ["Vani", "K", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "2011.13662", "submitter": "Fajri Koto", "authors": "Fajri Koto and Timothy Baldwin and Jey Han Lau", "title": "FFCI: A Framework for Interpretable Automatic Evaluation of\n  Summarization", "comments": "Under review for the Journal of Artificial Intelligence Research\n  (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose FFCI, a framework for fine-grained summarization\nevaluation that comprises four elements: faithfulness (degree of factual\nconsistency with the source), focus (precision of summary content relative to\nthe reference), coverage (recall of summary content relative to the reference),\nand inter-sentential coherence (document fluency between adjacent sentences).\nWe construct a novel dataset for focus, coverage, and inter-sentential\ncoherence, and develop automatic methods for evaluating each of the four\ndimensions of FFCI based on cross-comparison of evaluation metrics and\nmodel-based evaluation methods, including question answering (QA) approaches,\nSTS, next-sentence prediction (NSP), and scores derived from 19 pre-trained\nlanguage models. We then apply the developed metrics in evaluating a broad\nrange of summarization models across two datasets, with some surprising\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 10:57:18 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 08:37:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Koto", "Fajri", ""], ["Baldwin", "Timothy", ""], ["Lau", "Jey Han", ""]]}, {"id": "2011.13741", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul, Puranjay Mohan, Stuti Sehgal", "title": "Rethinking Generalization in American Sign Language Prediction for Edge\n  Devices with Extremely Low Memory Footprint", "comments": "6 pages, Published in IEEE RAICS 2020, see https://raics.in", "journal-ref": "2020 IEEE Recent Advances in Intelligent Computational Systems\n  (RAICS), 2020, pp. 147-152", "doi": "10.1109/RAICS51191.2020.9332480", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the boom in technical compute in the last few years, the world has\nseen massive advances in artificially intelligent systems solving diverse\nreal-world problems. But a major roadblock in the ubiquitous acceptance of\nthese models is their enormous computational complexity and memory footprint.\nHence efficient architectures and training techniques are required for\ndeployment on extremely low resource inference endpoints. This paper proposes\nan architecture for detection of alphabets in American Sign Language on an ARM\nCortex-M7 microcontroller having just 496 KB of framebuffer RAM. Leveraging\nparameter quantization is a common technique that might cause varying drops in\ntest accuracy. This paper proposes using interpolation as augmentation amongst\nother techniques as an efficient method of reducing this drop, which also helps\nthe model generalize well to previously unseen noisy data. The proposed model\nis about 185 KB post-quantization and inference speed is 20 frames per second.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 14:05:42 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 10:24:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Paul", "Aditya Jyoti", ""], ["Mohan", "Puranjay", ""], ["Sehgal", "Stuti", ""]]}, {"id": "2011.13978", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis and Eric Fosler-Lussier", "title": "Automated Coding of Under-Studied Medical Concept Domains: Linking\n  Physical Activity Reports to the International Classification of Functioning,\n  Disability, and Health", "comments": "Updated final version, published in Frontiers in Digital Health,\n  https://doi.org/10.3389/fdgth.2021.620828. 34 pages (23 text + 11\n  references); 9 figures, 2 tables", "journal-ref": "Frontiers in Digital Health, 3:620828 (2021)", "doi": "10.3389/fdgth.2021.620828", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking clinical narratives to standardized vocabularies and coding systems\nis a key component of unlocking the information in medical text for analysis.\nHowever, many domains of medical concepts lack well-developed terminologies\nthat can support effective coding of medical text. We present a framework for\ndeveloping natural language processing (NLP) technologies for automated coding\nof under-studied types of medical information, and demonstrate its\napplicability via a case study on physical mobility function. Mobility is a\ncomponent of many health measures, from post-acute care and surgical outcomes\nto chronic frailty and disability, and is coded in the International\nClassification of Functioning, Disability, and Health (ICF). However, mobility\nand other types of functional activity remain under-studied in medical\ninformatics, and neither the ICF nor commonly-used medical terminologies\ncapture functional status terminology in practice. We investigated two\ndata-driven paradigms, classification and candidate selection, to link\nnarrative observations of mobility to standardized ICF codes, using a dataset\nof clinical narratives from physical therapy encounters. Recent advances in\nlanguage modeling and word embedding were used as features for established\nmachine learning models and a novel deep learning approach, achieving a macro\nF-1 score of 84% on linking mobility activity reports to ICF codes. Both\nclassification and candidate selection approaches present distinct strengths\nfor automated coding in under-studied domains, and we highlight that the\ncombination of (i) a small annotated data set; (ii) expert definitions of codes\nof interest; and (iii) a representative text corpus is sufficient to produce\nhigh-performing automated coding systems. This study has implications for the\nongoing growth of NLP tools for a variety of specialized applications in\nclinical care and research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 20:02:59 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 18:05:55 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "2011.14037", "submitter": "Jussi Karlgren", "authors": "Jussi Karlgren, Renee Li, Eva M Meyersson Milgrom", "title": "Text Mining for Processing Interview Data in Computational Social\n  Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We use commercially available text analysis technology to process interview\ntext data from a computational social science study. We find that topical\nclustering and terminological enrichment provide for convenient exploration and\nquantification of the responses. This makes it possible to generate and test\nhypotheses and to compare textual and non-textual variables, and saves analyst\neffort. We encourage studies in social science to use text analysis, especially\nfor exploratory open-ended studies. We discuss how replicability requirements\nare met by text analysis technology. We note that the most recent learning\nmodels are not designed with transparency in mind, and that research requires a\nmodel to be editable and its decisions to be explainable. The tools available\ntoday, such as the one used in the present study, are not built for processing\ninterview texts. While many of the variables under consideration are\nquantifiable using lexical statistics, we find that some interesting and\npotentially valuable features are difficult or impossible to automatise\nreliably at present. We note that there are some potentially interesting\napplications for traditional natural language processing mechanisms such as\nnamed entity recognition and anaphora resolution in this application area. We\nconclude with a suggestion for language technologists to investigate the\nchallenge of processing interview data comprehensively, especially the\ninterplay between question and response, and we encourage social science\nresearchers not to hesitate to use text analysis tools, especially for the\nexploratory phase of processing interview data.?\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:44:35 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Karlgren", "Jussi", ""], ["Li", "Renee", ""], ["Milgrom", "Eva M Meyersson", ""]]}, {"id": "2011.14039", "submitter": "Samuel Stevens", "authors": "Samuel Stevens and Yu Su", "title": "Understanding How BERT Learns to Identify Edits", "comments": "8 pages, 11 figures. A work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained transformer language models such as BERT are ubiquitous in NLP\nresearch, leading to work on understanding how and why these models work.\nAttention mechanisms have been proposed as a means of interpretability with\nvarying conclusions. We propose applying BERT-based models to a sequence\nclassification task and using the data set's labeling schema to measure each\nmodel's interpretability. We find that classification performance scores do not\nalways correlate with interpretability. Despite this, BERT's attention weights\nare interpretable for over 70% of examples.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:46:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Stevens", "Samuel", ""], ["Su", "Yu", ""]]}, {"id": "2011.14062", "submitter": "Man-Ling Sung", "authors": "Man-Ling Sung, Tan Lee", "title": "Unsupervised Spoken Term Discovery Based on Re-clustering of\n  Hypothesized Speech Segments with Siamese and Triplet Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoken term discovery from untranscribed speech audio could be achieved via a\ntwo-stage process. In the first stage, the unlabelled speech is decoded into a\nsequence of subword units that are learned and modelled in an unsupervised\nmanner. In the second stage, partial sequence matching and clustering are\nperformed on the decoded subword sequences, resulting in a set of discovered\nwords or phrases. A limitation of this approach is that the results of subword\ndecoding could be erroneous, and the errors would impact the subsequent steps.\nWhile Siamese/Triplet network is one approach to learn segment representations\nthat can improve the discovery process, the challenge in spoken term discovery\nunder a complete unsupervised scenario is that training examples are\nunavailable. In this paper, we propose to generate training examples from\ninitial hypothesized sequence clusters. The Siamese/Triplet network is trained\non the hypothesized examples to measure the similarity between two speech\nsegments and hereby perform re-clustering of all hypothesized subword sequences\nto achieve spoken term discovery. Experimental results show that the proposed\napproach is effective in obtaining training examples for Siamese and Triplet\nnetworks, improving the efficacy of spoken term discovery as compared with the\noriginal two-stage method.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 03:52:38 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 21:06:44 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Sung", "Man-Ling", ""], ["Lee", "Tan", ""]]}, {"id": "2011.14084", "submitter": "Ke Shen", "authors": "Ke Shen and Mayank Kejriwal", "title": "A Data-Driven Study of Commonsense Knowledge using the ConceptNet\n  Knowledge Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Acquiring commonsense knowledge and reasoning is recognized as an important\nfrontier in achieving general Artificial Intelligence (AI). Recent research in\nthe Natural Language Processing (NLP) community has demonstrated significant\nprogress in this problem setting. Despite this progress, which is mainly on\nmultiple-choice question answering tasks in limited settings, there is still a\nlack of understanding (especially at scale) of the nature of commonsense\nknowledge itself. In this paper, we propose and conduct a systematic study to\nenable a deeper understanding of commonsense knowledge by doing an empirical\nand structural analysis of the ConceptNet knowledge base. ConceptNet is a\nfreely available knowledge base containing millions of commonsense assertions\npresented in natural language. Detailed experimental results on three carefully\ndesigned research questions, using state-of-the-art unsupervised graph\nrepresentation learning ('embedding') and clustering techniques, reveal deep\nsubstructures in ConceptNet relations, allowing us to make data-driven and\ncomputational claims about the meaning of phenomena such as 'context' that are\ntraditionally discussed only in qualitative terms. Furthermore, our methodology\nprovides a case study in how to use data-science and computational\nmethodologies for understanding the nature of an everyday (yet complex)\npsychological phenomenon that is an essential feature of human intelligence.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 08:08:25 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 07:21:20 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Shen", "Ke", ""], ["Kejriwal", "Mayank", ""]]}, {"id": "2011.14190", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas, Jan Buts, James Hadley, Andy Way", "title": "Using Multiple Subwords to Improve English-Esperanto Automated Literary\n  Translation Quality", "comments": null, "journal-ref": "The 3rd Workshop on Technologies for MT of Low Resource Languages\n  (LoResMT 2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building Machine Translation (MT) systems for low-resource languages remains\nchallenging. For many language pairs, parallel data are not widely available,\nand in such cases MT models do not achieve results comparable to those seen\nwith high-resource languages.\n  When data are scarce, it is of paramount importance to make optimal use of\nthe limited material available. To that end, in this paper we propose employing\nthe same parallel sentences multiple times, only changing the way the words are\nsplit each time. For this purpose we use several Byte Pair Encoding models,\nwith various merge operations used in their configuration.\n  In our experiments, we use this technique to expand the available data and\nimprove an MT system involving a low-resource language pair, namely\nEnglish-Esperanto.\n  As an additional contribution, we made available a set of English-Esperanto\nparallel data in the literary domain.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:44:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Poncelas", "Alberto", ""], ["Buts", "Jan", ""], ["Hadley", "James", ""], ["Way", "Andy", ""]]}, {"id": "2011.14203", "submitter": "Thierry Tambe", "authors": "Thierry Tambe, Coleman Hooper, Lillian Pentecost, Tianyu Jia, En-Yu\n  Yang, Marco Donato, Victor Sanh, Paul Whatmough, Alexander M. Rush, David\n  Brooks and Gu-Yeon Wei", "title": "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware\n  Multi-Task NLP Inference", "comments": "12 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based language models such as BERT provide significant accuracy\nimprovement for a multitude of natural language processing (NLP) tasks.\nHowever, their hefty computational and memory demands make them challenging to\ndeploy to resource-constrained edge platforms with strict latency requirements.\nWe present EdgeBERT, an in-depth algorithm-hardware co-design for latency-aware\nenergy optimization for multi-task NLP. EdgeBERT employs entropy-based early\nexit predication in order to perform dynamic voltage-frequency scaling (DVFS),\nat a sentence granularity, for minimal energy consumption while adhering to a\nprescribed target latency. Computation and memory footprint overheads are\nfurther alleviated by employing a calibrated combination of adaptive attention\nspan, selective network pruning, and floating-point quantization. Furthermore,\nin order to maximize the synergistic benefits of these algorithms in always-on\nand intermediate edge computing settings, we specialize a 12nm scalable\nhardware accelerator system, integrating a fast-switching low-dropout voltage\nregulator (LDO), an all-digital phase-locked loop (ADPLL), as well as,\nhigh-density embedded non-volatile memories (eNVMs) wherein the sparse\nfloating-point bit encodings of the shared multi-task parameters are carefully\nstored. Altogether, latency-aware multi-task NLP inference acceleration on the\nEdgeBERT hardware system generates up to 7x, 2.5x, and 53x lower energy\ncompared to the conventional inference without early stopping, the\nlatency-unbounded early exit approach, and CUDA adaptations on an Nvidia Jetson\nTegra X2 mobile GPU, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 19:21:47 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 03:03:49 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 04:02:59 GMT"}, {"version": "v4", "created": "Sat, 17 Apr 2021 22:11:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Tambe", "Thierry", ""], ["Hooper", "Coleman", ""], ["Pentecost", "Lillian", ""], ["Jia", "Tianyu", ""], ["Yang", "En-Yu", ""], ["Donato", "Marco", ""], ["Sanh", "Victor", ""], ["Whatmough", "Paul", ""], ["Rush", "Alexander M.", ""], ["Brooks", "David", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "2011.14244", "submitter": "Yao Fu", "authors": "Yao Fu, Chuanqi Tan, Bin Bi, Mosha Chen, Yansong Feng, Alexander M.\n  Rush", "title": "Latent Template Induction with Gumbel-CRFs", "comments": "NeurIPS 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to control the structure of sentences is a challenging problem in\ntext generation. Existing work either relies on simple deterministic approaches\nor RL-based hard structures. We explore the use of structured variational\nautoencoders to infer latent templates for sentence generation using a soft,\ncontinuous relaxation in order to utilize reparameterization for training.\nSpecifically, we propose a Gumbel-CRF, a continuous relaxation of the CRF\nsampling algorithm using a relaxed Forward-Filtering Backward-Sampling (FFBS)\napproach. As a reparameterized gradient estimator, the Gumbel-CRF gives more\nstable gradients than score-function based estimators. As a structured\ninference network, we show that it learns interpretable templates during\ntraining, which allows us to control the decoder during testing. We demonstrate\nthe effectiveness of our methods with experiments on data-to-text generation\nand unsupervised paraphrase generation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 01:00:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Fu", "Yao", ""], ["Tan", "Chuanqi", ""], ["Bi", "Bin", ""], ["Chen", "Mosha", ""], ["Feng", "Yansong", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2011.14277", "submitter": "Zhiruo Wang", "authors": "Zhiruo Wang, Renfen Hu", "title": "Intrinsic Knowledge Evaluation on Chinese Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent NLP tasks have benefited a lot from pre-trained language models (LM)\nsince they are able to encode knowledge of various aspects. However, current LM\nevaluations focus on downstream performance, hence lack to comprehensively\ninspect in which aspect and to what extent have they encoded knowledge. This\npaper addresses both queries by proposing four tasks on syntactic, semantic,\ncommonsense, and factual knowledge, aggregating to a total of $39,308$\nquestions covering both linguistic and world knowledge in Chinese. Throughout\nexperiments, our probes and knowledge data prove to be a reliable benchmark for\nevaluating pre-trained Chinese LMs. Our work is publicly available at\nhttps://github.com/ZhiruoWang/ChnEval.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:34:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Zhiruo", ""], ["Hu", "Renfen", ""]]}, {"id": "2011.14280", "submitter": "Hrithwik Shalu", "authors": "Sudhir Kumar Suman, Hrithwik Shalu, Lakshya A Agrawal, Archit Agrawal,\n  Juned Kadiwala", "title": "A Novel Sentiment Analysis Engine for Preliminary Depression Status\n  Estimation on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text sentiment analysis for preliminary depression status estimation of users\non social media is a widely exercised and feasible method, However, the immense\nvariety of users accessing the social media websites and their ample mix of\nvocabularies makes it difficult for commonly applied deep learning-based\nclassifiers to perform. To add to the situation, the lack of adaptability of\ntraditional supervised machine learning could hurt at many levels. We propose a\ncloud-based smartphone application, with a deep learning-based backend to\nprimarily perform depression detection on Twitter social media. The backend\nmodel consists of a RoBERTa based siamese sentence classifier that compares a\ngiven tweet (Query) with a labeled set of tweets with known sentiment (\nStandard Corpus ). The standard corpus is varied over time with expert opinion\nso as to improve the model's reliability. A psychologist ( with the patient's\npermission ) could leverage the application to assess the patient's depression\nstatus prior to counseling, which provides better insight into the mental\nhealth status of a patient. In addition, to the same, the psychologist could be\nreferred to cases of similar characteristics, which could in turn help in more\neffective treatment. We evaluate our backend model after fine-tuning it on a\npublicly available dataset. The find tuned model is made to predict depression\non a large set of tweet samples with random noise factors. The model achieved\npinnacle results, with a testing accuracy of 87.23% and an AUC of 0.8621.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:42:53 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Suman", "Sudhir Kumar", ""], ["Shalu", "Hrithwik", ""], ["Agrawal", "Lakshya A", ""], ["Agrawal", "Archit", ""], ["Kadiwala", "Juned", ""]]}, {"id": "2011.14293", "submitter": "Meiqi Guo", "authors": "Meiqi Guo, Rebecca Hwa, Yu-Ru Lin, Wen-Ting Chung", "title": "Inflating Topic Relevance with Ideology: A Case Study of Political\n  Ideology Bias in Social Topic Detection Models", "comments": "To appear in The Proceedings of The 28th International Conference on\n  Computational Linguistics (COLING-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the impact of political ideology biases in training data.\nThrough a set of comparison studies, we examine the propagation of biases in\nseveral widely-used NLP models and its effect on the overall retrieval\naccuracy. Our work highlights the susceptibility of large, complex models to\npropagating the biases from human-selected input, which may lead to a\ndeterioration of retrieval accuracy, and the importance of controlling for\nthese biases. Finally, as a way to mitigate the bias, we propose to learn a\ntext representation that is invariant to political ideology while still judging\ntopic relevance.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 05:54:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Guo", "Meiqi", ""], ["Hwa", "Rebecca", ""], ["Lin", "Yu-Ru", ""], ["Chung", "Wen-Ting", ""]]}, {"id": "2011.14326", "submitter": "Roland Molontay", "authors": "Kate Barnes, Tiernon Riesenmy, Minh Duc Trinh, Eli Lleshi, N\\'ora\n  Balogh, Roland Molontay", "title": "Dank or Not? -- Analyzing and Predicting the Popularity of Memes on\n  Reddit", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": "10.1007/s41109-021-00358-7", "report-no": null, "categories": "cs.SI cs.CL cs.CV cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet memes have become an increasingly pervasive form of contemporary\nsocial communication that attracted a lot of research interest recently. In\nthis paper, we analyze the data of 129,326 memes collected from Reddit in the\nmiddle of March, 2020, when the most serious coronavirus restrictions were\nbeing introduced around the world. This article not only provides a looking\nglass into the thoughts of Internet users during the COVID-19 pandemic but we\nalso perform a content-based predictive analysis of what makes a meme go viral.\nUsing machine learning methods, we also study what incremental predictive power\nimage related attributes have over textual attributes on meme popularity. We\nfind that the success of a meme can be predicted based on its content alone\nmoderately well, our best performing machine learning model predicts viral\nmemes with AUC=0.68. We also find that both image related and textual\nattributes have significant incremental predictive power over each other.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 09:57:17 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 08:31:42 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Barnes", "Kate", ""], ["Riesenmy", "Tiernon", ""], ["Trinh", "Minh Duc", ""], ["Lleshi", "Eli", ""], ["Balogh", "N\u00f3ra", ""], ["Molontay", "Roland", ""]]}, {"id": "2011.14330", "submitter": "Yanping Chen", "authors": "Yanping Chen, Lefei Wu, Liyuan Deng, Yongbin Qing, Ruizhang Huang,\n  Qinghua Zheng, Ping Chen", "title": "A Boundary Regression Model for Nested Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing named entities (NEs) is commonly conducted as a classification\nproblem that predicts a class tag for an NE candidate in a sentence. In shallow\nstructures, categorized features are weighted to support the prediction. Recent\ndevelopments in neural networks have adopted deep structures that map\ncategorized features into continuous representations. This approach unfolds a\ndense space saturated with high-order abstract semantic information, where the\nprediction is based on distributed feature representations. In this paper, the\nregression operation is introduced to locate NEs in a sentence. In this\napproach, a deep network is first designed to transform an input sentence into\nrecurrent feature maps. Bounding boxes are generated from the feature maps,\nwhere a box is an abstract representation of an NE candidate. In addition to\nthe class tag, each bounding box has two parameters denoting the start position\nand the length of an NE candidate. In the training process, the location offset\nbetween a bounding box and a true NE are learned to minimize the location loss.\nBased on this motivation, a multiobjective learning framework is designed to\nsimultaneously locate entities and predict the class probability. By sharing\nparameters for locating and predicting, the framework can take full advantage\nof annotated data and enable more potent nonlinear function approximators to\nenhance model discriminability. Experiments demonstrate state-of-the-art\nperformance for nested named entities\\footnote{Our codes will be available at:\n\\url{https://github.com/wuyuefei3/BR}}.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 10:04:38 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 22:09:22 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Yanping", ""], ["Wu", "Lefei", ""], ["Deng", "Liyuan", ""], ["Qing", "Yongbin", ""], ["Huang", "Ruizhang", ""], ["Zheng", "Qinghua", ""], ["Chen", "Ping", ""]]}, {"id": "2011.14344", "submitter": "Tien Cuong Bui", "authors": "Tien-Cuong Bui, Van-Duc Le, Hai-Thien To and Sang Kyun Cha", "title": "Generative Pre-training for Paraphrase Generation by Representing and\n  Predicting Spans in Exemplars", "comments": "8 pages, 4 figures, Accepted to IEEE International Conference on Big\n  Data and Smart Computing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Paraphrase generation is a long-standing problem and serves an essential role\nin many natural language processing problems. Despite some encouraging results,\nrecent methods either confront the problem of favoring generic utterance or\nneed to retrain the model from scratch for each new dataset. This paper\npresents a novel approach to paraphrasing sentences, extended from the GPT-2\nmodel. We develop a template masking technique, named first-order masking, to\nmasked out irrelevant words in exemplars utilizing POS taggers. So that, the\nparaphrasing task is changed to predicting spans in masked templates. Our\nproposed approach outperforms competitive baselines, especially in the semantic\npreservation aspect. To prevent the model from being biased towards a given\ntemplate, we introduce a technique, referred to as second-order masking, which\nutilizes Bernoulli distribution to control the visibility of the\nfirst-order-masked template's tokens. Moreover, this technique allows the model\nto provide various paraphrased sentences in testing by adjusting the\nsecond-order-masking level. For scale-up objectives, we compare the performance\nof two alternatives template-selection methods, which shows that they were\nequivalent in preserving semantic information.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 11:36:13 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bui", "Tien-Cuong", ""], ["Le", "Van-Duc", ""], ["To", "Hai-Thien", ""], ["Cha", "Sang Kyun", ""]]}, {"id": "2011.14459", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Ranit Aharonov, Siddhartha Brahma, Huaiyu Zhu, Yunyao Li", "title": "Improved Semantic Role Labeling using Parameterized Neighborhood Memory\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural models achieve some of the best results for semantic role\nlabeling. Inspired by instance-based learning that utilizes nearest neighbors\nto handle low-frequency context-specific training samples, we investigate the\nuse of memory adaptation techniques in deep neural models. We propose a\nparameterized neighborhood memory adaptive (PNMA) method that uses a\nparameterized representation of the nearest neighbors of tokens in a memory of\nactivations and makes predictions based on the most similar samples in the\ntraining data. We empirically show that PNMA consistently improves the SRL\nperformance of the base model irrespective of types of word embeddings. Coupled\nwith contextualized word embeddings derived from BERT, PNMA improves over\nexisting models for both span and dependency semantic parsing datasets,\nespecially on out-of-domain text, reaching F1 scores of 80.2, and 84.97 on\nCoNLL2005, and CoNLL2009 datasets, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 22:51:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jindal", "Ishan", ""], ["Aharonov", "Ranit", ""], ["Brahma", "Siddhartha", ""], ["Zhu", "Huaiyu", ""], ["Li", "Yunyao", ""]]}, {"id": "2011.14489", "submitter": "Saliha Murado\\u{g}lu", "authors": "Saliha Murado\\u{g}lu, Nicholas Evans, Ekaterina Vylomova", "title": "Modelling Verbal Morphology in Nen", "comments": "ALTA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nen verbal morphology is remarkably complex; a transitive verb can take up to\n1,740 unique forms. The combined effect of having a large combinatoric space\nand a low-resource setting amplifies the need for NLP tools. Nen morphology\nutilises distributed exponence - a non-trivial means of mapping form to\nmeaning. In this paper, we attempt to model Nen verbal morphology using\nstate-of-the-art machine learning models for morphological reinflection. We\nexplore and categorise the types of errors these systems generate. Our results\nshow sensitivity to training data composition; different distributions of verb\ntype yield different accuracies (patterning with E-complexity). We also\ndemonstrate the types of patterns that can be inferred from the training data\nthrough the case study of syncretism.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:22:05 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 23:08:01 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Murado\u011flu", "Saliha", ""], ["Evans", "Nicholas", ""], ["Vylomova", "Ekaterina", ""]]}, {"id": "2011.14496", "submitter": "Yikai Wang", "authors": "Yikai Wang and Weijian Li", "title": "Blind signal decomposition of various word embeddings based on join and\n  individual variance explained", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, natural language processing (NLP) has become one of the most\nimportant areas with various applications in human's life. As the most\nfundamental task, the field of word embedding still requires more attention and\nresearch. Currently, existing works about word embedding are focusing on\nproposing novel embedding algorithms and dimension reduction techniques on\nwell-trained word embeddings. In this paper, we propose to use a novel joint\nsignal separation method - JIVE to jointly decompose various trained word\nembeddings into joint and individual components. Through this decomposition\nframework, we can easily investigate the similarity and difference among\ndifferent word embeddings. We conducted extensive empirical study on word2vec,\nFastText and GLoVE trained on different corpus and with different dimensions.\nWe compared the performance of different decomposed components based on\nsentiment analysis on Twitter and Stanford sentiment treebank. We found that by\nmapping different word embeddings into the joint component, sentiment\nperformance can be greatly improved for the original word embeddings with lower\nperformance. Moreover, we found that by concatenating different components\ntogether, the same model can achieve better performance. These findings provide\ngreat insights into the word embeddings and our work offer a new of generating\nword embeddings by fusing.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:36:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Yikai", ""], ["Li", "Weijian", ""]]}, {"id": "2011.14608", "submitter": "Chen Xu", "authors": "Chen Xu, Bojie Hu, Yufan Jiang, Kai Feng, Zeyang Wang, Shen Huang, Qi\n  Ju, Tong Xiao, Jingbo Zhu", "title": "Dynamic Curriculum Learning for Low-Resource Neural Machine Translation", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large amounts of data has made neural machine translation (NMT) a big success\nin recent years. But it is still a challenge if we train these models on\nsmall-scale corpora. In this case, the way of using data appears to be more\nimportant. Here, we investigate the effective use of training data for\nlow-resource NMT. In particular, we propose a dynamic curriculum learning (DCL)\nmethod to reorder training samples in training. Unlike previous work, we do not\nuse a static scoring function for reordering. Instead, the order of training\nsamples is dynamically determined in two ways - loss decline and model\ncompetence. This eases training by highlighting easy samples that the current\nmodel has enough competence to learn. We test our DCL method in a\nTransformer-based system. Experimental results show that DCL outperforms\nseveral strong baselines on three low-resource machine translation benchmarks\nand different sized data of WMT' 16 En-De.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:13:41 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Xu", "Chen", ""], ["Hu", "Bojie", ""], ["Jiang", "Yufan", ""], ["Feng", "Kai", ""], ["Wang", "Zeyang", ""], ["Huang", "Shen", ""], ["Ju", "Qi", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2011.14618", "submitter": "Kavita Vaishnaw", "authors": "Heer Ambavi (1), Kavita Vaishnaw (1), Udit Vyas (1), Abhisht Tiwari\n  (1) and Mayank Singh (1) ((1) Indian Institute of Technology Gandhinagar)", "title": "CovidExplorer: A Multi-faceted AI-based Search and Visualization Engine\n  for COVID-19 Information", "comments": "4 pages, 7 figures, The associated system can be accessed at\n  http://covidexplorer.in, To be published in the Proceedings of the 29th ACM\n  International Conference on Information and Knowledge Management (CIKM '20)\n  (October 19-23, 2020)(Virtual Event, Ireland)", "journal-ref": null, "doi": "10.1145/3340531.3417428", "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The entire world is engulfed in the fight against the COVID-19 pandemic,\nleading to a significant surge in research experiments, government policies,\nand social media discussions. A multi-modal information access and data\nvisualization platform can play a critical role in supporting research aimed at\nunderstanding and developing preventive measures for the pandemic. In this\npaper, we present a multi-faceted AI-based search and visualization engine,\nCovidExplorer. Our system aims to help researchers understand current\nstate-of-the-art COVID-19 research, identify research articles relevant to\ntheir domain, and visualize real-time trends and statistics of COVID-19 cases.\nIn contrast to other existing systems, CovidExplorer also brings in\nIndia-specific topical discussions on social media to study different aspects\nof COVID-19. The system, demo video, and the datasets are available at\nhttp://covidexplorer.in.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:42:13 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ambavi", "Heer", "", "Indian Institute of Technology Gandhinagar"], ["Vaishnaw", "Kavita", "", "Indian Institute of Technology Gandhinagar"], ["Vyas", "Udit", "", "Indian Institute of Technology Gandhinagar"], ["Tiwari", "Abhisht", "", "Indian Institute of Technology Gandhinagar"], ["Singh", "Mayank", "", "Indian Institute of Technology Gandhinagar"]]}, {"id": "2011.14678", "submitter": "Pavel P\\v{r}ib\\'a\\v{n}", "authors": "Ond\\v{r}ej Pra\\v{z}\\'ak, Pavel P\\v{r}ib\\'a\\v{n}, and Stephen Taylor", "title": "UWB @ DIACR-Ita: Lexical Semantic Change Detection with CCA and\n  Orthogonal Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our method for detection of lexical semantic\nchange (i.e., word sense changes over time) for the DIACR-Ita shared task,\nwhere we ranked $1^{st}$. We examine semantic differences between specific\nwords in two Italian corpora, chosen from different time periods. Our method is\nfully unsupervised and language independent. It consists of preparing a\nsemantic vector space for each corpus, earlier and later. Then we compute a\nlinear transformation between earlier and later spaces, using CCA and\nOrthogonal Transformation. Finally, we measure the cosines between the\ntransformed vectors.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:41:50 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Pra\u017e\u00e1k", "Ond\u0159ej", ""], ["P\u0159ib\u00e1\u0148", "Pavel", ""], ["Taylor", "Stephen", ""]]}, {"id": "2011.14752", "submitter": "Thoudam Doren Singh", "authors": "Alok Singh, Thoudam Doren Singh, Sivaji Bandyopadhyay", "title": "A Comprehensive Review on Recent Methods and Challenges of Video\n  Description", "comments": "Paper of 35 pages submitted to ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video description involves the generation of the natural language description\nof actions, events, and objects in the video. There are various applications of\nvideo description by filling the gap between languages and vision for visually\nimpaired people, generating automatic title suggestion based on content,\nbrowsing of the video based on the content and video-guided machine translation\n[86] etc.In the past decade, several works had been done in this field in terms\nof approaches/methods for video description, evaluation metrics,and datasets.\nFor analyzing the progress in the video description task, a comprehensive\nsurvey is needed that covers all the phases of video description approaches\nwith a special focus on recent deep learning approaches. In this work, we\nreport a comprehensive survey on the phases of video description approaches,\nthe dataset for video description, evaluation metrics, open competitions for\nmotivating the research on the video description, open challenges in this\nfield, and future research directions. In this survey, we cover the\nstate-of-the-art approaches proposed for each and every dataset with their pros\nand cons. For the growth of this research domain,the availability of numerous\nbenchmark dataset is a basic need. Further, we categorize all the dataset into\ntwo classes: open domain dataset and domain-specific dataset. From our survey,\nwe observe that the work in this field is in fast-paced development since the\ntask of video description falls in the intersection of computer vision and\nnatural language processing. But still, the work in the video description is\nfar from saturation stage due to various challenges like the redundancy due to\nsimilar frames which affect the quality of visual features, the availability of\ndataset containing more diverse content and availability of an effective\nevaluation metric.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:08:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Singh", "Alok", ""], ["Singh", "Thoudam Doren", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "2011.14874", "submitter": "Yanyang Li", "authors": "Yanyang Li, Yingfeng Luo, Ye Lin, Quan Du, Huizhen Wang, Shujian\n  Huang, Tong Xiao, Jingbo Zhu", "title": "A Simple and Effective Approach to Robust Unsupervised Bilingual\n  Dictionary Induction", "comments": "Accepted by COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Bilingual Dictionary Induction methods based on the\ninitialization and the self-learning have achieved great success in similar\nlanguage pairs, e.g., English-Spanish. But they still fail and have an accuracy\nof 0% in many distant language pairs, e.g., English-Japanese. In this work, we\nshow that this failure results from the gap between the actual initialization\nperformance and the minimum initialization performance for the self-learning to\nsucceed. We propose Iterative Dimension Reduction to bridge this gap. Our\nexperiments show that this simple method does not hamper the performance of\nsimilar language pairs and achieves an accuracy of 13.64~55.53% between English\nand four distant languages, i.e., Chinese, Japanese, Vietnamese and Thai.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:11:51 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Li", "Yanyang", ""], ["Luo", "Yingfeng", ""], ["Lin", "Ye", ""], ["Du", "Quan", ""], ["Wang", "Huizhen", ""], ["Huang", "Shujian", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2011.14901", "submitter": "Annika Lindh", "authors": "Annika Lindh, Robert J. Ross, John D. Kelleher", "title": "Language-Driven Region Pointer Advancement for Controllable Image\n  Captioning", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Controllable Image Captioning is a recent sub-field in the multi-modal task\nof Image Captioning wherein constraints are placed on which regions in an image\nshould be described in the generated natural language caption. This puts a\nstronger focus on producing more detailed descriptions, and opens the door for\nmore end-user control over results. A vital component of the Controllable Image\nCaptioning architecture is the mechanism that decides the timing of attending\nto each region through the advancement of a region pointer. In this paper, we\npropose a novel method for predicting the timing of region pointer advancement\nby treating the advancement step as a natural part of the language structure\nvia a NEXT-token, motivated by a strong correlation to the sentence structure\nin the training data. We find that our timing agrees with the ground-truth\ntiming in the Flickr30k Entities test data with a precision of 86.55% and a\nrecall of 97.92%. Our model implementing this technique improves the\nstate-of-the-art on standard captioning metrics while additionally\ndemonstrating a considerably larger effective vocabulary size.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:34:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lindh", "Annika", ""], ["Ross", "Robert J.", ""], ["Kelleher", "John D.", ""]]}, {"id": "2011.14979", "submitter": "Antonio Toral", "authors": "Antonio Toral, Antoni Oliver, Pau Ribas Ballest\\'in", "title": "Machine Translation of Novels in the Age of Transformer", "comments": "Chapter published in the book Maschinelle \\\"Ubersetzung f\\\"ur\n  \\\"Ubersetzungsprofis (pp. 276-295). J\\\"org Porsiel (Ed.), BD\\\"U Fachverlag,\n  2020. ISBN 978-3-946702-09-2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we build a machine translation (MT) system tailored to the\nliterary domain, specifically to novels, based on the state-of-the-art\narchitecture in neural MT (NMT), the Transformer (Vaswani et al., 2017), for\nthe translation direction English-to-Catalan. Subsequently, we assess to what\nextent such a system can be useful by evaluating its translations, by comparing\nthis MT system against three other systems (two domain-specific systems under\nthe recurrent and phrase-based paradigms and a popular generic on-line system)\non three evaluations. The first evaluation is automatic and uses the\nmost-widely used automatic evaluation metric, BLEU. The two remaining\nevaluations are manual and they assess, respectively, preference and amount of\npost-editing required to make the translation error-free. As expected, the\ndomain-specific Transformer-based system outperformed the three other systems\nin all the three evaluations conducted, in all cases by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:51:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Toral", "Antonio", ""], ["Oliver", "Antoni", ""], ["Ballest\u00edn", "Pau Ribas", ""]]}, {"id": "2011.15023", "submitter": "Siddharth Dalmia", "authors": "Siddharth Dalmia, Yuzong Liu, Srikanth Ronanki, Katrin Kirchhoff", "title": "Transformer-Transducers for Code-Switched Speech Recognition", "comments": "Accepted at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in a world where 60% of the population can speak two or more\nlanguages fluently. Members of these communities constantly switch between\nlanguages when having a conversation. As automatic speech recognition (ASR)\nsystems are being deployed to the real-world, there is a need for practical\nsystems that can handle multiple languages both within an utterance or across\nutterances. In this paper, we present an end-to-end ASR system using a\ntransformer-transducer model architecture for code-switched speech recognition.\nWe propose three modifications over the vanilla model in order to handle\nvarious aspects of code-switching. First, we introduce two auxiliary loss\nfunctions to handle the low-resource scenario of code-switching. Second, we\npropose a novel mask-based training strategy with language ID information to\nimprove the label encoder training towards intra-sentential code-switching.\nFinally, we propose a multi-label/multi-audio encoder structure to leverage the\nvast monolingual speech corpora towards code-switching. We demonstrate the\nefficacy of our proposed approaches on the SEAME dataset, a public\nMandarin-English code-switching corpus, achieving a mixed error rate of 18.5%\nand 26.3% on test_man and test_sge sets respectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:27:41 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 02:46:51 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dalmia", "Siddharth", ""], ["Liu", "Yuzong", ""], ["Ronanki", "Srikanth", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "2011.15038", "submitter": "Rafi Trad", "authors": "Rafi Trad, Myra Spiliopoulou", "title": "A Framework for Authorial Clustering of Shorter Texts in Latent Semantic\n  Spaces", "comments": "8 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Authorial clustering involves the grouping of documents written by the same\nauthor or team of authors without any prior positive examples of an author's\nwriting style or thematic preferences. For authorial clustering on shorter\ntexts (paragraph-length texts that are typically shorter than conventional\ndocuments), the document representation is particularly important: very\nhigh-dimensional feature spaces lead to data sparsity and suffer from serious\nconsequences like the curse of dimensionality, while feature selection may lead\nto information loss. We propose a high-level framework which utilizes a compact\ndata representation in a latent feature space derived with non-parametric topic\nmodeling. Authorial clusters are identified thereafter in two scenarios: (a)\nfully unsupervised and (b) semi-supervised where a small number of shorter\ntexts are known to belong to the same author (must-link constraints) or not\n(cannot-link constraints). We report on experiments with 120 collections in\nthree languages and two genres and show that the topic-based latent feature\nspace provides a promising level of performance while reducing the\ndimensionality by a factor of 1500 compared to state-of-the-arts. We also\ndemonstrate that, while prior knowledge on the precise number of authors (i.e.\nauthorial clusters) does not contribute much to additional quality, little\nknowledge on constraints in authorial clusters memberships leads to clear\nperformance improvements in front of this difficult task. Thorough\nexperimentation with standard metrics indicates that there still remains an\nample room for improvement for authorial clustering, especially with shorter\ntexts\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:39:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Trad", "Rafi", ""], ["Spiliopoulou", "Myra", ""]]}, {"id": "2011.15124", "submitter": "Emanuele Bugliarello", "authors": "Emanuele Bugliarello, Ryan Cotterell, Naoaki Okazaki, Desmond Elliott", "title": "Multimodal Pretraining Unmasked: A Meta-Analysis and a Unified Framework\n  of Vision-and-Language BERTs", "comments": "To appear in TACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pretraining and task-specific fine-tuning is now the standard\nmethodology for many tasks in computer vision and natural language processing.\nRecently, a multitude of methods have been proposed for pretraining vision and\nlanguage BERTs to tackle challenges at the intersection of these two key areas\nof AI. These models can be categorised into either single-stream or dual-stream\nencoders. We study the differences between these two categories, and show how\nthey can be unified under a single theoretical framework. We then conduct\ncontrolled experiments to discern the empirical differences between five V&L\nBERTs. Our experiments show that training data and hyperparameters are\nresponsible for most of the differences between the reported results, but they\nalso reveal that the embedding layer plays a crucial role in these massive\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:55:24 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 23:37:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Bugliarello", "Emanuele", ""], ["Cotterell", "Ryan", ""], ["Okazaki", "Naoaki", ""], ["Elliott", "Desmond", ""]]}]