[{"id": "1205.0627", "submitter": "Yann Ponty", "authors": "Yann Ponty (LIX, INRIA Saclay - Ile de France)", "title": "Rule-weighted and terminal-weighted context-free grammars have identical\n  expressivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two formalisms, both based on context-free grammars, have recently been\nproposed as a basis for a non-uniform random generation of combinatorial\nobjects. The former, introduced by Denise et al, associates weights with\nletters, while the latter, recently explored by Weinberg et al in the context\nof random generation, associates weights to transitions. In this short note, we\nuse a simple modification of the Greibach Normal Form transformation algorithm,\ndue to Blum and Koch, to show the equivalent expressivities, in term of their\ninduced distributions, of these two formalisms.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 06:49:59 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["Ponty", "Yann", "", "LIX, INRIA Saclay - Ile de France"]]}, {"id": "1205.1564", "submitter": "Wentian Li", "authors": "Wentian Li", "title": "Characterizing Ranked Chinese Syllable-to-Character Mapping Spectrum: A\n  Bridge Between the Spoken and Written Chinese Language", "comments": "15 pages, 4 figures", "journal-ref": "Journal of Quantitative Linguistics, 20, 153-167 (2013)", "doi": "10.1080/09296174.2013.773140", "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important aspect of the relationship between spoken and written Chinese\nis the ranked syllable-to-character mapping spectrum, which is the ranked list\nof syllables by the number of characters that map to the syllable. Previously,\nthis spectrum is analyzed for more than 400 syllables without distinguishing\nthe four intonations. In the current study, the spectrum with 1280 toned\nsyllables is analyzed by logarithmic function, Beta rank function, and\npiecewise logarithmic function. Out of the three fitting functions, the\ntwo-piece logarithmic function fits the data the best, both by the smallest sum\nof squared errors (SSE) and by the lowest Akaike information criterion (AIC)\nvalue. The Beta rank function is the close second. By sampling from a Poisson\ndistribution whose parameter value is chosen from the observed data, we\nempirically estimate the $p$-value for testing the\ntwo-piece-logarithmic-function being better than the Beta rank function\nhypothesis, to be 0.16. For practical purposes, the piecewise logarithmic\nfunction and the Beta rank function can be considered a tie.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 00:29:48 GMT"}], "update_date": "2013-08-29", "authors_parsed": [["Li", "Wentian", ""]]}, {"id": "1205.1603", "submitter": "Win Win  Thant", "authors": "Win Win Thant, Tin Myat Htwe and Ni Lar Thein", "title": "Parsing of Myanmar sentences with function tagging", "comments": "18 pages, 8 figures, 10 tables. arXiv admin note: substantial text\n  overlap with arXiv:1203.1685, and with arXiv:0912.1820 by other authors\n  without attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the use of Naive Bayes to address the task of assigning\nfunction tags and context free grammar (CFG) to parse Myanmar sentences. Part\nof the challenge of statistical function tagging for Myanmar sentences comes\nfrom the fact that Myanmar has free-phrase-order and a complex morphological\nsystem. Function tagging is a pre-processing step for parsing. In the task of\nfunction tagging, we use the functional annotated corpus and tag Myanmar\nsentences with correct segmentation, POS (part-of-speech) tagging and chunking\ninformation. We propose Myanmar grammar rules and apply context free grammar\n(CFG) to find out the parse tree of function tagged Myanmar sentences.\nExperiments show that our analysis achieves a good result with parsing of\nsimple sentences and three types of complex sentences.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 07:01:40 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Thant", "Win Win", ""], ["Htwe", "Tin Myat", ""], ["Thein", "Ni Lar", ""]]}, {"id": "1205.1639", "submitter": "Sajilal Divakaran", "authors": "Sajilal Divakaran", "title": "Spectral Analysis of Projection Histogram for Enhancing Close matching\n  character Recognition in Malayalam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success rates of Optical Character Recognition (OCR) systems for printed\nMalayalam documents is quite impressive with the state of the art accuracy\nlevels in the range of 85-95% for various. However for real applications,\nfurther enhancement of this accuracy levels are required. One of the bottle\nnecks in further enhancement of the accuracy is identified as close-matching\ncharacters. In this paper, we delineate the close matching characters in\nMalayalam and report the development of a specialised classifier for these\nclose-matching characters. The output of a state of the art of OCR is taken and\ncharacters falling into the close-matching character set is further fed into\nthis specialised classifier for enhancing the accuracy. The classifier is based\non support vector machine algorithm and uses feature vectors derived out of\nspectral coefficients of projection histogram signals of close-matching\ncharacters.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 09:25:14 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Divakaran", "Sajilal", ""]]}, {"id": "1205.1794", "submitter": "Behrouz Abdolali", "authors": "Behrouz Abdolali and Hossein Sameti", "title": "A Novel Method For Speech Segmentation Based On Speakers'\n  Characteristics", "comments": "14 pages, 8 figures", "journal-ref": "B. Abdolali, H. Sameti \"A Novel Method for Speech Segmentation\n  based on Speakers' Specifications\", Signal & Image Processing: An\n  International Journal (SIPIJ) Vol.3, No.2, pp. 65-78, April 2012", "doi": "10.5121/sipij.2012.3205", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech Segmentation is the process change point detection for partitioning an\ninput audio stream into regions each of which corresponds to only one audio\nsource or one speaker. One application of this system is in Speaker Diarization\nsystems. There are several methods for speaker segmentation; however, most of\nthe Speaker Diarization Systems use BIC-based Segmentation methods. The main\ngoal of this paper is to propose a new method for speaker segmentation with\nhigher speed than the current methods - e.g. BIC - and acceptable accuracy. Our\nproposed method is based on the pitch frequency of the speech. The accuracy of\nthis method is similar to the accuracy of common speaker segmentation methods.\nHowever, its computation cost is much less than theirs. We show that our method\nis about 2.4 times faster than the BIC-based method, while the average accuracy\nof pitch-based method is slightly higher than that of the BIC-based method.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 19:54:13 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Abdolali", "Behrouz", ""], ["Sameti", "Hossein", ""]]}, {"id": "1205.1975", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Paola Flocchini, Emmanuel Godard, Nicola Santoro,\n  Masafumi Yamashita", "title": "Expressivity of Time-Varying Graphs and the Power of Waiting in Dynamic\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In infrastructure-less highly dynamic networks, computing and performing even\nbasic tasks (such as routing and broadcasting) is a very challenging activity\ndue to the fact that connectivity does not necessarily hold, and the network\nmay actually be disconnected at every time instant. Clearly the task of\ndesigning protocols for these networks is less difficult if the environment\nallows waiting (i.e., it provides the nodes with store-carry-forward-like\nmechanisms such as local buffering) than if waiting is not feasible. No\nquantitative corroborations of this fact exist (e.g., no answer to the\nquestion: how much easier?). In this paper, we consider these qualitative\nquestions about dynamic networks, modeled as time-varying (or evolving) graphs,\nwhere edges exist only at some times.\n  We examine the difficulty of the environment in terms of the expressivity of\nthe corresponding time-varying graph; that is in terms of the language\ngenerated by the feasible journeys in the graph. We prove that the set of\nlanguages $L_{nowait}$ when no waiting is allowed contains all computable\nlanguages. On the other end, using algebraic properties of quasi-orders, we\nprove that $L_{wait}$ is just the family of regular languages. In other words,\nwe prove that, when waiting is no longer forbidden, the power of the accepting\nautomaton (difficulty of the environment) drops drastically from being as\npowerful as a Turing machine, to becoming that of a Finite-State machine. This\n(perhaps surprisingly large) gap is a measure of the computational power of\nwaiting.\n  We also study bounded waiting; that is when waiting is allowed at a node only\nfor at most $d$ time units. We prove the negative result that $L_{wait[d]} =\nL_{nowait}$; that is, the expressivity decreases only if the waiting is finite\nbut unpredictable (i.e., under the control of the protocol designer and not of\nthe environment).\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 13:19:46 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Flocchini", "Paola", ""], ["Godard", "Emmanuel", ""], ["Santoro", "Nicola", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1205.2657", "submitter": "Jordan Boyd-Graber", "authors": "Jordan Boyd-Graber, David Blei", "title": "Multilingual Topic Models for Unaligned Text", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-75-82", "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the multilingual topic model for unaligned text (MuTo), a\nprobabilistic model of text that is designed to analyze corpora composed of\ndocuments in two languages. From these documents, MuTo uses stochastic EM to\nsimultaneously discover both a matching between the languages and multilingual\nlatent topics. We demonstrate that MuTo is able to find shared topics on\nreal-world multilingual corpora, successfully pairing related documents across\nlanguages. MuTo provides a new framework for creating multilingual topic models\nwithout needing carefully curated parallel corpora and allows applications\nbuilt using the topic model formalism to be applied to a much wider class of\ncorpora.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:53:11 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Boyd-Graber", "Jordan", ""], ["Blei", "David", ""]]}, {"id": "1205.3183", "submitter": "Luis Quesada", "authors": "Luis Quesada, Fernando Berzal, Francisco J. Cortijo", "title": "A Model-Driven Probabilistic Parser Generator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing probabilistic scanners and parsers impose hard constraints on the\nway lexical and syntactic ambiguities can be resolved. Furthermore, traditional\ngrammar-based parsing tools are limited in the mechanisms they allow for taking\ncontext into account. In this paper, we propose a model-driven tool that allows\nfor statistical language models with arbitrary probability estimators. Our work\non model-driven probabilistic parsing is built on top of ModelCC, a model-based\nparser generator, and enables the probabilistic interpretation and resolution\nof anaphoric, cataphoric, and recursive references in the disambiguation of\nabstract syntax graphs. In order to prove the expression power of ModelCC, we\ndescribe the design of a general-purpose natural language parser.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 20:12:06 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Quesada", "Luis", ""], ["Berzal", "Fernando", ""], ["Cortijo", "Francisco J.", ""]]}, {"id": "1205.3316", "submitter": "Naim Terbeh", "authors": "Naim Terbeh and Mounir Zrigui", "title": "Arabic Language Learning Assisted by Computer, based on Automatic Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work consists of creating a system of the Computer Assisted Language\nLearning (CALL) based on a system of Automatic Speech Recognition (ASR) for the\nArabic language using the tool CMU Sphinx3 [1], based on the approach of HMM.\nTo this work, we have constructed a corpus of six hours of speech recordings\nwith a number of nine speakers. we find in the robustness to noise a grounds\nfor the choice of the HMM approach [2]. the results achieved are encouraging\nsince our corpus is made by only nine speakers, but they are always reasons\nthat open the door for other improvement works.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2012 10:34:05 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Terbeh", "Naim", ""], ["Zrigui", "Mounir", ""]]}, {"id": "1205.4298", "submitter": "Yoav Goldberg", "authors": "Yoav Goldberg", "title": "Task-specific Word-Clustering for Part-of-Speech Tagging", "comments": "Rejected from ACL 2012 Short Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the use of cluster features became ubiquitous in core NLP tasks, most\ncluster features in NLP are based on distributional similarity. We propose a\nnew type of clustering criteria, specific to the task of part-of-speech\ntagging. Instead of distributional similarity, these clusters are based on the\nbeha vior of a baseline tagger when applied to a large corpus. These cluster\nfeatures provide similar gains in accuracy to those achieved by\ndistributional-similarity derived clusters. Using both types of cluster\nfeatures together further improve tagging accuracies. We show that the method\nis effective for both the in-domain and out-of-domain scenarios for English,\nand for French, German and Italian. The effect is larger for out-of-domain\ntext.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 05:04:31 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Goldberg", "Yoav", ""]]}, {"id": "1205.4324", "submitter": "P\\'adraig Mac Carron", "authors": "P\\'adraig Mac Carron and Ralph Kenna", "title": "Universal Properties of Mythological Networks", "comments": "6 pages, 3 figures, 2 tables. Updated to incorporate corrections from\n  EPL acceptance process", "journal-ref": "EPL 99 (2012) 28002", "doi": "10.1209/0295-5075/99/28002", "report-no": null, "categories": "physics.soc-ph cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As in statistical physics, the concept of universality plays an important,\nalbeit qualitative, role in the field of comparative mythology. Here we apply\nstatistical mechanical tools to analyse the networks underlying three iconic\nmythological narratives with a view to identifying common and distinguishing\nquantitative features. Of the three narratives, an Anglo-Saxon and a Greek text\nare mostly believed by antiquarians to be partly historically based while the\nthird, an Irish epic, is often considered to be fictional. Here we show that\nnetwork analysis is able to discriminate real from imaginary social networks\nand place mythological narratives on the spectrum between them. Moreover, the\nperceived artificiality of the Irish narrative can be traced back to anomalous\nfeatures associated with six characters. Considering these as amalgams of\nseveral entities or proxies, renders the plausibility of the Irish text\ncomparable to the others from a network-theoretic point of view.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2012 13:09:32 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2012 11:53:40 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Mac Carron", "P\u00e1draig", ""], ["Kenna", "Ralph", ""]]}, {"id": "1205.4387", "submitter": "Yoav Goldberg", "authors": "Yoav Goldberg, Michael Elhadad", "title": "Precision-biased Parsing and High-Quality Parse Selection", "comments": "Rejected from EMNLP 2012 (among others)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce precision-biased parsing: a parsing task which favors precision\nover recall by allowing the parser to abstain from decisions deemed uncertain.\nWe focus on dependency-parsing and present an ensemble method which is capable\nof assigning parents to 84% of the text tokens while being over 96% accurate on\nthese tokens. We use the precision-biased parsing task to solve the related\nhigh-quality parse-selection task: finding a subset of high-quality (accurate)\ntrees in a large collection of parsed text. We present a method for choosing\nover a third of the input trees while keeping unlabeled dependency parsing\naccuracy of 97% on these trees. We also present a method which is not based on\nan ensemble but rather on directly predicting the risk associated with\nindividual parser decisions. In addition to its efficiency, this method\ndemonstrates that a parsing system can provide reasonable estimates of\nconfidence in its predictions without relying on ensembles or aggregate corpus\ncounts.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 06:36:19 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Goldberg", "Yoav", ""], ["Elhadad", "Michael", ""]]}, {"id": "1205.5407", "submitter": "Deniz Yuret", "authors": "Deniz Yuret", "title": "FASTSUBS: An Efficient and Exact Procedure for Finding the Most Likely\n  Lexical Substitutes Based on an N-gram Language Model", "comments": "4 pages, 1 figure, to appear in IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2012.2215587", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical substitutes have found use in areas such as paraphrasing, text\nsimplification, machine translation, word sense disambiguation, and part of\nspeech induction. However the computational complexity of accurately\nidentifying the most likely substitutes for a word has made large scale\nexperiments difficult. In this paper I introduce a new search algorithm,\nFASTSUBS, that is guaranteed to find the K most likely lexical substitutes for\na given word in a sentence based on an n-gram language model. The computation\nis sub-linear in both K and the vocabulary size V. An implementation of the\nalgorithm and a dataset with the top 100 substitutes of each token in the WSJ\nsection of the Penn Treebank are available at http://goo.gl/jzKH0.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 11:53:41 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2012 07:54:47 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Yuret", "Deniz", ""]]}, {"id": "1205.6396", "submitter": "Murphy Choy", "authors": "Murphy Choy", "title": "Effective Listings of Function Stop words for Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many words in documents recur very frequently but are essentially meaningless\nas they are used to join words together in a sentence. It is commonly\nunderstood that stop words do not contribute to the context or content of\ntextual documents. Due to their high frequency of occurrence, their presence in\ntext mining presents an obstacle to the understanding of the content in the\ndocuments. To eliminate the bias effects, most text mining software or\napproaches make use of stop words list to identify and remove those words.\nHowever, the development of such top words list is difficult and inconsistent\nbetween textual sources. This problem is further aggravated by sources such as\nTwitter which are highly repetitive or similar in nature. In this paper, we\nwill be examining the original work using term frequency, inverse document\nfrequency and term adjacency for developing a stop words list for the Twitter\ndata source. We propose a new technique using combinatorial values as an\nalternative measure to effectively list out stop words.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 15:37:46 GMT"}], "update_date": "2012-05-30", "authors_parsed": [["Choy", "Murphy", ""]]}, {"id": "1205.6832", "submitter": "Michael Zock", "authors": "Ga\\\"elle Lortal (TRT), Brigitte Grau (LIMSI), Michael Zock (LIF)", "title": "Syst\\`eme d'aide \\`a l'acc\\`es lexical : trouver le mot qu'on a sur le\n  bout de la langue", "comments": "TALN, Fez : Maroc (2004)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the Tip of the Tongue phenomenon (TOT) provides valuable clues\nand insights concerning the organisation of the mental lexicon (meaning, number\nof syllables, relation with other words, etc.). This paper describes a tool\nbased on psycho-linguistic observations concerning the TOT phenomenon. We've\nbuilt it to enable a speaker/writer to find the word he is looking for, word he\nmay know, but which he is unable to access in time. We try to simulate the TOT\nphenomenon by creating a situation where the system knows the target word, yet\nis unable to access it. In order to find the target word we make use of the\nparadigmatic and syntagmatic associations stored in the linguistic databases.\nOur experiment allows the following conclusion: a tool like SVETLAN, capable to\nstructure (automatically) a dictionary by domains can be used sucessfully to\nhelp the speaker/writer to find the word he is looking for, if it is combined\nwith a database rich in terms of paradigmatic links like EuroWordNet.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 17:33:47 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Lortal", "Ga\u00eblle", "", "TRT"], ["Grau", "Brigitte", "", "LIMSI"], ["Zock", "Michael", "", "LIF"]]}]