[{"id": "1712.00044", "submitter": "Hussam Hamdan", "authors": "Hussam Hamdan, Jean-Gabriel Ganascia", "title": "Graph Centrality Measures for Boosting Popularity-Based Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Entity Linking systems use collective graph-based methods to\ndisambiguate the entity mentions within a document. Most of them have focused\non graph construction and initial weighting of the candidate entities, less\nattention has been devoted to compare the graph ranking algorithms. In this\nwork, we focus on the graph-based ranking algorithms, therefore we propose to\napply five centrality measures: Degree, HITS, PageRank, Betweenness and\nCloseness. A disambiguation graph of candidate entities is constructed for each\ndocument using the popularity method, then centrality measures are applied to\nchoose the most relevant candidate to boost the results of entity popularity\nmethod. We investigate the effectiveness of each centrality measure on the\nperformance across different domains and datasets. Our experiments show that a\nsimple and fast centrality measure such as Degree centrality can outperform\nother more time-consuming measures.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 19:39:23 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Hamdan", "Hussam", ""], ["Ganascia", "Jean-Gabriel", ""]]}, {"id": "1712.00069", "submitter": "Chlo\\'e Pou-Prom", "authors": "Zeinab Noorian, Chlo\\'e Pou-Prom, Frank Rudzicz", "title": "On the importance of normative data in speech-based assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data sets for identifying Alzheimer's disease (AD) are often relatively\nsparse, which limits their ability to train generalizable models. Here, we\naugment such a data set, DementiaBank, with each of two normative data sets,\nthe Wisconsin Longitudinal Study and Talk2Me, each of which employs a\nspeech-based picture-description assessment. Through minority class\noversampling with ADASYN, we outperform state-of-the-art results in binary\nclassification of people with and without AD in DementiaBank. This work\nhighlights the effectiveness of combining sparse and difficult-to-acquire\npatient data with relatively large and easily accessible normative datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 20:36:50 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Noorian", "Zeinab", ""], ["Pou-Prom", "Chlo\u00e9", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1712.00170", "submitter": "Heng Wang", "authors": "Heng Wang, Zengchang Qin, Tao Wan", "title": "Text Generation Based on Generative Adversarial Nets with Latent\n  Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a model using generative adversarial net (GAN) to\ngenerate realistic text. Instead of using standard GAN, we combine variational\nautoencoder (VAE) with generative adversarial net. The use of high-level latent\nrandom variables is helpful to learn the data distribution and solve the\nproblem that generative adversarial net always emits the similar data. We\npropose the VGAN model where the generative model is composed of recurrent\nneural network and VAE. The discriminative model is a convolutional neural\nnetwork. We train the model via policy gradient. We apply the proposed model to\nthe task of text generation and compare it to other recent neural network based\nmodels, such as recurrent neural network language model and SeqGAN. We evaluate\nthe performance of the model by calculating negative log-likelihood and the\nBLEU score. We conduct experiments on three benchmark datasets, and results\nshow that our model outperforms other previous models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 03:14:51 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 12:27:23 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Wang", "Heng", ""], ["Qin", "Zengchang", ""], ["Wan", "Tao", ""]]}, {"id": "1712.00334", "submitter": "Fabio Paolizzo", "authors": "Fabio Paolizzo", "title": "Enabling Embodied Analogies in Intelligent Music Systems", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present methodology is aimed at cross-modal machine learning and uses\nmultidisciplinary tools and methods drawn from a broad range of areas and\ndisciplines, including music, systematic musicology, dance, motion capture,\nhuman-computer interaction, computational linguistics and audio signal\nprocessing. Main tasks include: (1) adapting wisdom-of-the-crowd approaches to\nembodiment in music and dance performance to create a dataset of music and\nmusic lyrics that covers a variety of emotions, (2) applying\naudio/language-informed machine learning techniques to that dataset to identify\nautomatically the emotional content of the music and the lyrics, and (3)\nintegrating motion capture data from a Vicon system and dancers performing on\nthat music.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 08:27:08 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Paolizzo", "Fabio", ""]]}, {"id": "1712.00377", "submitter": "Aishwarya Agrawal", "authors": "Aishwarya Agrawal, Dhruv Batra, Devi Parikh, Aniruddha Kembhavi", "title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering", "comments": "15 pages, 10 figures. To appear in IEEE Conference on Computer Vision\n  and Pattern Recognition (CVPR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:48:50 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 15:32:06 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Agrawal", "Aishwarya", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "1712.00489", "submitter": "Abhinav Gupta", "authors": "Abhinav Gupta, Yajie Miao, Leonardo Neves, Florian Metze", "title": "Visual Features for Context-Aware Speech Recognition", "comments": "5 pages and 3 figures", "journal-ref": "IEEE Xplore (ICASSP) (2017) 5020-5024", "doi": "10.1109/ICASSP.2017.7953112", "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic transcriptions of consumer-generated multi-media content such as\n\"Youtube\" videos still exhibit high word error rates. Such data typically\noccupies a very broad domain, has been recorded in challenging conditions, with\ncheap hardware and a focus on the visual modality, and may have been\npost-processed or edited. In this paper, we extend our earlier work on adapting\nthe acoustic model of a DNN-based speech recognition system to an RNN language\nmodel and show how both can be adapted to the objects and scenes that can be\nautomatically detected in the video. We are working on a corpus of \"how-to\"\nvideos from the web, and the idea is that an object that can be seen (\"car\"),\nor a scene that is being detected (\"kitchen\") can be used to condition both\nmodels on the \"context\" of the recording, thereby reducing perplexity and\nimproving transcription. We achieve good improvements in both cases and compare\nand analyze the respective reductions in word error rate. We expect that our\nresults can be used for any type of speech processing in which \"context\"\ninformation is available, for example in robotics, man-machine interaction, or\nwhen indexing large audio-visual archives, and should ultimately help to bring\ntogether the \"video-to-text\" and \"speech-to-text\" communities.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 20:56:31 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Gupta", "Abhinav", ""], ["Miao", "Yajie", ""], ["Neves", "Leonardo", ""], ["Metze", "Florian", ""]]}, {"id": "1712.00609", "submitter": "Kang Min Yoo", "authors": "Kang Min Yoo, Youhyun Shin, Sang-goo Lee", "title": "Improving Visually Grounded Sentence Representations with Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence representation models trained only on language could potentially\nsuffer from the grounding problem. Recent work has shown promising results in\nimproving the qualities of sentence representations by jointly training them\nwith associated image features. However, the grounding capability is limited\ndue to distant connection between input sentences and image features by the\ndesign of the architecture. In order to further close the gap, we propose\napplying self-attention mechanism to the sentence encoder to deepen the\ngrounding effect. Our results on transfer tasks show that self-attentive\nencoders are better for visual grounding, as they exploit specific words with\nstrong visual associations.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 14:14:50 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Yoo", "Kang Min", ""], ["Shin", "Youhyun", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1712.00725", "submitter": "Abhinav Gupta", "authors": "Laura Graesser, Abhinav Gupta, Lakshay Sharma, Evelina Bakhturina", "title": "Sentiment Classification using Images and Label Embeddings", "comments": "13 pages, 3 figures, 9 tables. Technical report for Statistical\n  Natural Language Processing Project (NYU CS - Fall 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project we analysed how much semantic information images carry, and\nhow much value image data can add to sentiment analysis of the text associated\nwith the images. To better understand the contribution from images, we compared\nmodels which only made use of image data, models which only made use of text\ndata, and models which combined both data types. We also analysed if this\napproach could help sentiment classifiers generalize to unknown sentiments.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 07:20:15 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Graesser", "Laura", ""], ["Gupta", "Abhinav", ""], ["Sharma", "Lakshay", ""], ["Bakhturina", "Evelina", ""]]}, {"id": "1712.00733", "submitter": "Guohao Li", "authors": "Guohao Li, Hang Su, Wenwu Zhu", "title": "Incorporating External Knowledge to Answer Open-Domain Visual Questions\n  with Dynamic Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) has attracted much attention since it offers\ninsight into the relationships between the multi-modal analysis of images and\nnatural language. Most of the current algorithms are incapable of answering\nopen-domain questions that require to perform reasoning beyond the image\ncontents. To address this issue, we propose a novel framework which endows the\nmodel capabilities in answering more complex questions by leveraging massive\nexternal knowledge with dynamic memory networks. Specifically, the questions\nalong with the corresponding images trigger a process to retrieve the relevant\ninformation in external knowledge bases, which are embedded into a continuous\nvector space by preserving the entity-relation structures. Afterwards, we\nemploy dynamic memory networks to attend to the large body of facts in the\nknowledge graph and images, and then perform reasoning over these facts to\ngenerate corresponding answers. Extensive experiments demonstrate that our\nmodel not only achieves the state-of-the-art performance in the visual question\nanswering task, but can also answer open-domain questions effectively by\nleveraging the external knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 08:41:35 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Li", "Guohao", ""], ["Su", "Hang", ""], ["Zhu", "Wenwu", ""]]}, {"id": "1712.00991", "submitter": "Sachin Pawar", "authors": "Girish Keshav Palshikar, Sachin Pawar, Saheb Chourasia, Nitin\n  Ramrakhiyani", "title": "Mining Supervisor Evaluation and Peer Feedback in Performance Appraisals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance appraisal (PA) is an important HR process to periodically measure\nand evaluate every employee's performance vis-a-vis the goals established by\nthe organization. A PA process involves purposeful multi-step multi-modal\ncommunication between employees, their supervisors and their peers, such as\nself-appraisal, supervisor assessment and peer feedback. Analysis of the\nstructured data and text produced in PA is crucial for measuring the quality of\nappraisals and tracking actual improvements. In this paper, we apply text\nmining techniques to produce insights from PA text. First, we perform sentence\nclassification to identify strengths, weaknesses and suggestions of\nimprovements found in the supervisor assessments and then use clustering to\ndiscover broad categories among them. Next we use multi-class multi-label\nclassification techniques to match supervisor assessments to predefined broad\nperspectives on performance. Finally, we propose a short-text summarization\ntechnique to produce a summary of peer feedback comments for a given employee\nand compare it with manual summaries. All techniques are illustrated using a\nreal-life dataset of supervisor assessment and peer feedback text produced\nduring the PA of 4528 employees in a large multi-national IT company.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 10:30:18 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Palshikar", "Girish Keshav", ""], ["Pawar", "Sachin", ""], ["Chourasia", "Saheb", ""], ["Ramrakhiyani", "Nitin", ""]]}, {"id": "1712.01097", "submitter": "Thomas Kollar", "authors": "Thomas Kollar, Stefanie Tellex, Matthew Walter, Albert Huang, Abraham\n  Bachrach, Sachi Hemachandra, Emma Brunskill, Ashis Banerjee, Deb Roy, Seth\n  Teller and Nicholas Roy", "title": "Generalized Grounding Graphs: A Probabilistic Framework for\n  Understanding Grounded Commands", "comments": "Submitted to the Journal of Artificial Intelligence Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many task domains require robots to interpret and act upon natural language\ncommands which are given by people and which refer to the robot's physical\nsurroundings. Such interpretation is known variously as the symbol grounding\nproblem, grounded semantics and grounded language acquisition. This problem is\nchallenging because people employ diverse vocabulary and grammar, and because\nrobots have substantial uncertainty about the nature and contents of their\nsurroundings, making it difficult to associate the constitutive language\nelements (principally noun phrases and spatial relations) of the command text\nto elements of those surroundings. Symbolic models capture linguistic structure\nbut have not scaled successfully to handle the diverse language produced by\nuntrained users. Existing statistical approaches can better handle diversity,\nbut have not to date modeled complex linguistic structure, limiting achievable\naccuracy. Recent hybrid approaches have addressed limitations in scaling and\ncomplexity, but have not effectively associated linguistic and perceptual\nfeatures. Our framework, called Generalized Grounding Graphs (G^3), addresses\nthese issues by defining a probabilistic graphical model dynamically according\nto the linguistic parse structure of a natural language command. This approach\nscales effectively, handles linguistic diversity, and enables the system to\nassociate parts of a command with the specific objects, places, and events in\nthe external world to which they refer. We show that robots can learn word\nmeanings and use those learned meanings to robustly follow natural language\ncommands produced by untrained users. We demonstrate our approach for both\nmobility commands and mobile manipulation commands involving a variety of\nsemi-autonomous robotic platforms, including a wheelchair, a micro-air vehicle,\na forklift, and the Willow Garage PR2.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 21:20:51 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kollar", "Thomas", ""], ["Tellex", "Stefanie", ""], ["Walter", "Matthew", ""], ["Huang", "Albert", ""], ["Bachrach", "Abraham", ""], ["Hemachandra", "Sachi", ""], ["Brunskill", "Emma", ""], ["Banerjee", "Ashis", ""], ["Roy", "Deb", ""], ["Teller", "Seth", ""], ["Roy", "Nicholas", ""]]}, {"id": "1712.01213", "submitter": "Zulfat Miftakhutdinov", "authors": "Elena Tutubalina, Zulfat Miftahutdinov", "title": "An Encoder-Decoder Model for ICD-10 Coding of Death Certificates", "comments": null, "journal-ref": "KFU at CLEF eHealth 2017 Task 1: ICD-10 Coding of English Death\n  Certificates with Recurrent Neural Networks, CEUR Workshop Proceedings, Vol\n  1866, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction from textual documents such as hospital records and\nhealthrelated user discussions has become a topic of intense interest. The task\nof medical concept coding is to map a variable length text to medical concepts\nand corresponding classification codes in some external system or ontology. In\nthis work, we utilize recurrent neural networks to automatically assign ICD-10\ncodes to fragments of death certificates written in English. We develop\nend-to-end neural architectures directly tailored to the task, including basic\nencoder-decoder architecture for statistical translation. In order to\nincorporate prior knowledge, we concatenate cosine similarities vector among\nthe text and dictionary entry to the encoded state. Being applied to a standard\nbenchmark from CLEF eHealth 2017 challenge, our model achieved F-measure of\n85.01% on a full test set with significant improvement as compared to the\naverage score of 62.2% for all official participants approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 17:39:51 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Tutubalina", "Elena", ""], ["Miftahutdinov", "Zulfat", ""]]}, {"id": "1712.01238", "submitter": "Ishan Misra", "authors": "Ishan Misra, Ross Girshick, Rob Fergus, Martial Hebert, Abhinav Gupta,\n  Laurens van der Maaten", "title": "Learning by Asking Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an interactive learning framework for the development and\ntesting of intelligent visual systems, called learning-by-asking (LBA). We\nexplore LBA in context of the Visual Question Answering (VQA) task. LBA differs\nfrom standard VQA training in that most questions are not observed during\ntraining time, and the learner must ask questions it wants answers to. Thus,\nLBA more closely mimics natural learning and has the potential to be more\ndata-efficient than the traditional VQA setting. We present a model that\nperforms LBA on the CLEVR dataset, and show that it automatically discovers an\neasy-to-hard curriculum when learning interactively from an oracle. Our LBA\ngenerated data consistently matches or outperforms the CLEVR train data and is\nmore sample efficient. We also show that our model asks questions that\ngeneralize to state-of-the-art VQA models and to novel test time distributions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:23:19 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Misra", "Ishan", ""], ["Girshick", "Ross", ""], ["Fergus", "Rob", ""], ["Hebert", "Martial", ""], ["Gupta", "Abhinav", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1712.01329", "submitter": "Dana Kianfar", "authors": "Mircea Mironenco, Dana Kianfar, Ke Tran, Evangelos Kanoulas,\n  Efstratios Gavves", "title": "Examining Cooperation in Visual Dialog Models", "comments": "9 pages, 5 figures, 2 tables, code at\n  http://github.com/danakianfar/Examining-Cooperation-in-VDM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a blackbox intervention method for visual dialog\nmodels, with the aim of assessing the contribution of individual linguistic or\nvisual components. Concretely, we conduct structured or randomized\ninterventions that aim to impair an individual component of the model, and\nobserve changes in task performance. We reproduce a state-of-the-art visual\ndialog model and demonstrate that our methodology yields surprising insights,\nnamely that both dialog and image information have minimal contributions to\ntask performance. The intervention method presented here can be applied as a\nsanity check for the strength and robustness of each component in visual dialog\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 20:16:52 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Mironenco", "Mircea", ""], ["Kianfar", "Dana", ""], ["Tran", "Ke", ""], ["Kanoulas", "Evangelos", ""], ["Gavves", "Efstratios", ""]]}, {"id": "1712.01411", "submitter": "Ian Stewart", "authors": "Ian Stewart and Stevie Chancellor and Munmun De Choudhury and Jacob\n  Eisenstein", "title": "#anorexia, #anarexia, #anarexyia: Characterizing Online Community\n  Practices with Orthographic Variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinctive linguistic practices help communities build solidarity and\ndifferentiate themselves from outsiders. In an online community, one such\npractice is variation in orthography, which includes spelling, punctuation, and\ncapitalization. Using a dataset of over two million Instagram posts, we\ninvestigate orthographic variation in a community that shares pro-eating\ndisorder (pro-ED) content. We find that not only does orthographic variation\ngrow more frequent over time, it also becomes more profound or deep, with\nvariants becoming increasingly distant from the original: as, for example,\n#anarexyia is more distant than #anarexia from the original spelling #anorexia.\nThese changes are driven by newcomers, who adopt the most extreme linguistic\npractices as they enter the community. Moreover, this behavior correlates with\nengagement: the newcomers who adopt deeper orthographic variants tend to remain\nactive for longer in the community, and the posts that contain deeper variation\nreceive more positive feedback in the form of \"likes.\" Previous work has linked\ncommunity membership change with language change, and our work casts this\nconnection in a new light, with newcomers driving an evolving practice, rather\nthan adapting to it. We also demonstrate the utility of orthographic variation\nas a new lens to study sociolinguistic change in online communities,\nparticularly when the change results from an exogenous force such as a content\nban.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 23:27:11 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Stewart", "Ian", ""], ["Chancellor", "Stevie", ""], ["De Choudhury", "Munmun", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1712.01455", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Xuchao Zhang, Arnold P. Boedihardjo, Jing Dai and\n  Chang-Tien Lu", "title": "Multimodal Storytelling via Generative Adversarial Imitation Learning", "comments": "IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving event storylines is an effective summarization method to succinctly\norganize extensive information, which can significantly alleviate the pain of\ninformation overload. The critical challenge is the lack of widely recognized\ndefinition of storyline metric. Prior studies have developed various approaches\nbased on different assumptions about users' interests. These works can extract\ninteresting patterns, but their assumptions do not guarantee that the derived\npatterns will match users' preference. On the other hand, their exclusiveness\nof single modality source misses cross-modality information. This paper\nproposes a method, multimodal imitation learning via generative adversarial\nnetworks(MIL-GAN), to directly model users' interests as reflected by various\ndata. In particular, the proposed model addresses the critical challenge by\nimitating users' demonstrated storylines. Our proposed model is designed to\nlearn the reward patterns given user-provided storylines and then applies the\nlearned policy to unseen data. The proposed approach is demonstrated to be\ncapable of acquiring the user's implicit intent and outperforming competing\nmethods by a substantial margin with a user study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:51:35 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Chen", "Zhiqian", ""], ["Zhang", "Xuchao", ""], ["Boedihardjo", "Arnold P.", ""], ["Dai", "Jing", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1712.01460", "submitter": "Hassan Kane", "authors": "Willie Boag and Hassan Kan\\'e", "title": "AWE-CM Vectors: Augmenting Word Embeddings with a Clinical Metathesaurus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, word embeddings have been surprisingly effective at\ncapturing intuitive characteristics of the words they represent. These vectors\nachieve the best results when training corpora are extremely large, sometimes\nbillions of words. Clinical natural language processing datasets, however, tend\nto be much smaller. Even the largest publicly-available dataset of medical\nnotes is three orders of magnitude smaller than the dataset of the oft-used\n\"Google News\" word vectors. In order to make up for limited training data\nsizes, we encode expert domain knowledge into our embeddings. Building on a\nprevious extension of word2vec, we show that generalizing the notion of a\nword's \"context\" to include arbitrary features creates an avenue for encoding\ndomain knowledge into word embeddings. We show that the word vectors produced\nby this method outperform their text-only counterparts across the board in\ncorrelation with clinical experts.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 03:11:07 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Boag", "Willie", ""], ["Kan\u00e9", "Hassan", ""]]}, {"id": "1712.01476", "submitter": "J\\'ulio Hoffimann", "authors": "J\\'ulio Hoffimann, Youli Mao, Avinash Wesley and Aimee Taylor", "title": "Sequence Mining and Pattern Analysis in Drilling Reports with Deep\n  Natural Language Processing", "comments": "7 pages, 14 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drilling activities in the oil and gas industry have been reported over\ndecades for thousands of wells on a daily basis, yet the analysis of this text\nat large-scale for information retrieval, sequence mining, and pattern analysis\nis very challenging. Drilling reports contain interpretations written by\ndrillers from noting measurements in downhole sensors and surface equipment,\nand can be used for operation optimization and accident mitigation. In this\ninitial work, a methodology is proposed for automatic classification of\nsentences written in drilling reports into three relevant labels (EVENT,\nSYMPTOM and ACTION) for hundreds of wells in an actual field. Some of the main\nchallenges in the text corpus were overcome, which include the high frequency\nof technical symbols, mistyping/abbreviation of technical terms, and the\npresence of incomplete sentences in the drilling reports. We obtain\nstate-of-the-art classification accuracy within this technical language and\nillustrate advanced queries enabled by the tool.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 04:49:58 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Hoffimann", "J\u00falio", ""], ["Mao", "Youli", ""], ["Wesley", "Avinash", ""], ["Taylor", "Aimee", ""]]}, {"id": "1712.01562", "submitter": "Ritvik Shrivastava", "authors": "Kuntal Dey, Ritvik Shrivastava, Saroj Kaushik and L. Venkata\n  Subramaniam", "title": "EmTaggeR: A Word Embedding Based Novel Method for Hashtag Recommendation\n  on Twitter", "comments": "Accepted at the IEEE International Conference on Data Mining (ICDM)\n  2017 ACUMEN Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hashtag recommendation problem addresses recommending (suggesting) one or\nmore hashtags to explicitly tag a post made on a given social network platform,\nbased upon the content and context of the post. In this work, we propose a\nnovel methodology for hashtag recommendation for microblog posts, specifically\nTwitter. The methodology, EmTaggeR, is built upon a training-testing framework\nthat builds on the top of the concept of word embedding. The training phase\ncomprises of learning word vectors associated with each hashtag, and deriving a\nword embedding for each hashtag. We provide two training procedures, one in\nwhich each hashtag is trained with a separate word embedding model applicable\nin the context of that hashtag, and another in which each hashtag obtains its\nembedding from a global context. The testing phase constitutes computing the\naverage word embedding of the test post, and finding the similarity of this\nembedding with the known embeddings of the hashtags. The tweets that contain\nthe most-similar hashtag are extracted, and all the hashtags that appear in\nthese tweets are ranked in terms of embedding similarity scores. The top-K\nhashtags that appear in this ranked list, are recommended for the given test\npost. Our system produces F1 score of 50.83%, improving over the LDA baseline\nby around 6.53 times, outperforming the best-performing system known in the\nliterature that provides a lift of 6.42 times. EmTaggeR is a fast, scalable and\nlightweight system, which makes it practical to deploy in real-life\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 10:29:14 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Dey", "Kuntal", ""], ["Shrivastava", "Ritvik", ""], ["Kaushik", "Saroj", ""], ["Subramaniam", "L. Venkata", ""]]}, {"id": "1712.01586", "submitter": "Zhixing Tan", "authors": "Zhixing Tan, Mingxuan Wang, Jun Xie, Yidong Chen, Xiaodong Shi", "title": "Deep Semantic Role Labeling with Self-Attention", "comments": "Accepted by AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Role Labeling (SRL) is believed to be a crucial step towards natural\nlanguage understanding and has been widely studied. Recent years, end-to-end\nSRL with recurrent neural networks (RNN) has gained increasing attention.\nHowever, it remains a major challenge for RNNs to handle structural information\nand long range dependencies. In this paper, we present a simple and effective\narchitecture for SRL which aims to address these problems. Our model is based\non self-attention which can directly capture the relationships between two\ntokens regardless of their distance. Our single model achieves F$_1=83.4$ on\nthe CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared task\ndataset, which outperforms the previous state-of-the-art results by $1.8$ and\n$1.0$ F$_1$ score respectively. Besides, our model is computationally\nefficient, and the parsing speed is 50K tokens per second on a single Titan X\nGPU.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 11:48:51 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Tan", "Zhixing", ""], ["Wang", "Mingxuan", ""], ["Xie", "Jun", ""], ["Chen", "Yidong", ""], ["Shi", "Xiaodong", ""]]}, {"id": "1712.01719", "submitter": "Matilde Marcolli", "authors": "Kevin Shu, Andrew Ortegaray, Robert Berwick, Matilde Marcolli", "title": "Phylogenetics of Indo-European Language families via an\n  Algebro-Geometric Analysis of their Syntactic Structures", "comments": "57 pages, LaTeX; v2: some corrections and more details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Phylogenetic Algebraic Geometry, we analyze computationally the\nphylogenetic tree of subfamilies of the Indo-European language family, using\ndata of syntactic structures. The two main sources of syntactic data are the\nSSWL database and Longobardi's recent data of syntactic parameters. We compute\nphylogenetic invariants and likelihood functions for two sets of Germanic\nlanguages, a set of Romance languages, a set of Slavic languages and a set of\nearly Indo-European languages, and we compare the results with what is known\nthrough historical linguistics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 15:55:27 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 22:24:47 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Shu", "Kevin", ""], ["Ortegaray", "Andrew", ""], ["Berwick", "Robert", ""], ["Marcolli", "Matilde", ""]]}, {"id": "1712.01741", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko and Saif M. Mohammad", "title": "Capturing Reliable Fine-Grained Sentiment Associations by Crowdsourcing\n  and Best-Worst Scaling", "comments": "In Proceedings of the 15th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL), San Diego, California, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to word-sentiment associations is useful for many applications,\nincluding sentiment analysis, stance detection, and linguistic analysis.\nHowever, manually assigning fine-grained sentiment association scores to words\nhas many challenges with respect to keeping annotations consistent. We apply\nthe annotation technique of Best-Worst Scaling to obtain real-valued sentiment\nassociation scores for words and phrases in three different domains: general\nEnglish, English Twitter, and Arabic Twitter. We show that on all three domains\nthe ranking of words by sentiment remains remarkably consistent even when the\nannotation process is repeated with a different set of annotators. We also, for\nthe first time, determine the minimum difference in sentiment association that\nis perceptible to native speakers of a language.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 16:28:37 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1712.01765", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko and Saif M. Mohammad", "title": "Best-Worst Scaling More Reliable than Rating Scales: A Case Study on\n  Sentiment Intensity Annotation", "comments": "In Proceedings of the Annual Meeting of the Association for\n  Computational Linguistics (ACL), Vancouver, Canada, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rating scales are a widely used method for data annotation; however, they\npresent several challenges, such as difficulty in maintaining inter- and\nintra-annotator consistency. Best-worst scaling (BWS) is an alternative method\nof annotation that is claimed to produce high-quality annotations while keeping\nthe required number of annotations similar to that of rating scales. However,\nthe veracity of this claim has never been systematically established. Here for\nthe first time, we set up an experiment that directly compares the rating scale\nmethod with BWS. We show that with the same total number of annotations, BWS\nproduces significantly more reliable results than the rating scale.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 17:13:48 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1712.01769", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu, Tara N. Sainath, Yonghui Wu, Rohit Prabhavalkar,\n  Patrick Nguyen, Zhifeng Chen, Anjuli Kannan, Ron J. Weiss, Kanishka Rao,\n  Ekaterina Gonina, Navdeep Jaitly, Bo Li, Jan Chorowski, Michiel Bacchiani", "title": "State-of-the-art Speech Recognition With Sequence-to-Sequence Models", "comments": "ICASSP camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder architectures such as Listen, Attend, and\nSpell (LAS), subsume the acoustic, pronunciation and language model components\nof a traditional automatic speech recognition (ASR) system into a single neural\nnetwork. In previous work, we have shown that such architectures are comparable\nto state-of-theart ASR systems on dictation tasks, but it was not clear if such\narchitectures would be practical for more challenging tasks such as voice\nsearch. In this work, we explore a variety of structural and optimization\nimprovements to our LAS model which significantly improve performance. On the\nstructural side, we show that word piece models can be used instead of\ngraphemes. We also introduce a multi-head attention architecture, which offers\nimprovements over the commonly-used single-head attention. On the optimization\nside, we explore synchronous training, scheduled sampling, label smoothing, and\nminimum word error rate optimization, which are all shown to improve accuracy.\nWe present results with a unidirectional LSTM encoder for streaming\nrecognition. On a 12, 500 hour voice search task, we find that the proposed\nchanges improve the WER from 9.2% to 5.6%, while the best conventional system\nachieves 6.7%; on a dictation task our model achieves a WER of 4.1% compared to\n5% for the conventional system.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 17:24:05 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 23:25:23 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 18:41:01 GMT"}, {"version": "v4", "created": "Fri, 22 Dec 2017 22:55:44 GMT"}, {"version": "v5", "created": "Thu, 18 Jan 2018 18:25:33 GMT"}, {"version": "v6", "created": "Fri, 23 Feb 2018 18:44:30 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Sainath", "Tara N.", ""], ["Wu", "Yonghui", ""], ["Prabhavalkar", "Rohit", ""], ["Nguyen", "Patrick", ""], ["Chen", "Zhifeng", ""], ["Kannan", "Anjuli", ""], ["Weiss", "Ron J.", ""], ["Rao", "Kanishka", ""], ["Gonina", "Ekaterina", ""], ["Jaitly", "Navdeep", ""], ["Li", "Bo", ""], ["Chorowski", "Jan", ""], ["Bacchiani", "Michiel", ""]]}, {"id": "1712.01794", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko and Saif M. Mohammad", "title": "The Effect of Negators, Modals, and Degree Adverbs on Sentiment\n  Composition", "comments": "In Proceedings of the 7th Workshop on Computational Approaches to\n  Subjectivity, Sentiment and Social Media Analysis (WASSA), San Diego,\n  California, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negators, modals, and degree adverbs can significantly affect the sentiment\nof the words they modify. Often, their impact is modeled with simple\nheuristics; although, recent work has shown that such heuristics do not capture\nthe true sentiment of multi-word phrases. We created a dataset of phrases that\ninclude various negators, modals, and degree adverbs, as well as their\ncombinations. Both the phrases and their constituent content words were\nannotated with real-valued scores of sentiment association. Using phrasal terms\nin the created dataset, we analyze the impact of individual modifiers and the\naverage effect of the groups of modifiers on overall sentiment. We find that\nthe effect of modifiers varies substantially among the members of the same\ngroup. Furthermore, each individual modifier can affect sentiment words in\ndifferent ways. Therefore, solutions based on statistical learning seem more\npromising than fixed hand-crafted rules on the task of automatic sentiment\nprediction.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:17:43 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1712.01797", "submitter": "Avirup Sil", "authors": "Avirup Sil and Radu Florian", "title": "One for All: Towards Language Independent Named Entity Linking", "comments": "Association for Computational Linguistics (ACL), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking (EL) is the task of disambiguating mentions in text by\nassociating them with entries in a predefined database of mentions (persons,\norganizations, etc). Most previous EL research has focused mainly on one\nlanguage, English, with less attention being paid to other languages, such as\nSpanish or Chinese. In this paper, we introduce LIEL, a Language Independent\nEntity Linking system, which provides an EL framework which, once trained on\none language, works remarkably well on a number of different languages without\nchange. LIEL makes a joint global prediction over the entire document,\nemploying a discriminative reranking framework with many domain and\nlanguage-independent feature functions. Experiments on numerous benchmark\ndatasets, show that the proposed system, once trained on one language, English,\noutperforms several state-of-the-art systems in English (by 4 points) and the\ntrained model also works very well on Spanish (14 points better than a\ncompetitor system), demonstrating the viability of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:21:24 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Sil", "Avirup", ""], ["Florian", "Radu", ""]]}, {"id": "1712.01807", "submitter": "Chung-Cheng Chiu", "authors": "Tara N. Sainath, Chung-Cheng Chiu, Rohit Prabhavalkar, Anjuli Kannan,\n  Yonghui Wu, Patrick Nguyen, Zhifeng Chen", "title": "Improving the Performance of Online Neural Transducer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a sequence-to-sequence model which can operate in an online fashion is\nimportant for streaming applications such as Voice Search. Neural transducer is\na streaming sequence-to-sequence model, but has shown a significant degradation\nin performance compared to non-streaming models such as Listen, Attend and\nSpell (LAS). In this paper, we present various improvements to NT.\nSpecifically, we look at increasing the window over which NT computes\nattention, mainly by looking backwards in time so the model still remains\nonline. In addition, we explore initializing a NT model from a LAS-trained\nmodel so that it is guided with a better alignment. Finally, we explore\nincluding stronger language models such as using wordpiece models, and applying\nan external LM during the beam search. On a Voice Search task, we find with\nthese improvements we can get NT to match the performance of LAS.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:34:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Sainath", "Tara N.", ""], ["Chiu", "Chung-Cheng", ""], ["Prabhavalkar", "Rohit", ""], ["Kannan", "Anjuli", ""], ["Wu", "Yonghui", ""], ["Nguyen", "Patrick", ""], ["Chen", "Zhifeng", ""]]}, {"id": "1712.01813", "submitter": "Avirup Sil", "authors": "Avirup Sil and Gourab Kundu and Radu Florian and Wael Hamza", "title": "Neural Cross-Lingual Entity Linking", "comments": "Association for the Advancement of Artificial Intelligence (AAAI),\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in Entity Linking (EL) is making effective use of\ncontextual information to disambiguate mentions to Wikipedia that might refer\nto different entities in different contexts. The problem exacerbates with\ncross-lingual EL which involves linking mentions written in non-English\ndocuments to entries in the English Wikipedia: to compare textual clues across\nlanguages we need to compute similarity between textual fragments across\nlanguages. In this paper, we propose a neural EL model that trains fine-grained\nsimilarities and dissimilarities between the query and candidate document from\nmultiple perspectives, combined with convolution and tensor networks. Further,\nwe show that this English-trained system can be applied, in zero-shot learning,\nto other languages by making surprisingly effective use of multi-lingual\nembeddings. The proposed system has strong empirical evidence yielding\nstate-of-the-art results in English as well as cross-lingual: Spanish and\nChinese TAC 2015 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:43:57 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Sil", "Avirup", ""], ["Kundu", "Gourab", ""], ["Florian", "Radu", ""], ["Hamza", "Wael", ""]]}, {"id": "1712.01818", "submitter": "Chung-Cheng Chiu", "authors": "Rohit Prabhavalkar, Tara N. Sainath, Yonghui Wu, Patrick Nguyen,\n  Zhifeng Chen, Chung-Cheng Chiu, Anjuli Kannan", "title": "Minimum Word Error Rate Training for Attention-based\n  Sequence-to-Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models, such as attention-based models in automatic\nspeech recognition (ASR), are typically trained to optimize the cross-entropy\ncriterion which corresponds to improving the log-likelihood of the data.\nHowever, system performance is usually measured in terms of word error rate\n(WER), not log-likelihood. Traditional ASR systems benefit from discriminative\nsequence training which optimizes criteria such as the state-level minimum\nBayes risk (sMBR) which are more closely related to WER. In the present work,\nwe explore techniques to train attention-based models to directly minimize\nexpected word error rate. We consider two loss functions which approximate the\nexpected number of word errors: either by sampling from the model, or by using\nN-best lists of decoded hypotheses, which we find to be more effective than the\nsampling-based method. In experimental evaluations, we find that the proposed\ntraining procedure improves performance by up to 8.2% relative to the baseline\nsystem. This allows us to train grapheme-based, uni-directional attention-based\nmodels which match the performance of a traditional, state-of-the-art,\ndiscriminative sequence-trained system on a mobile voice-search task.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:52:18 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Prabhavalkar", "Rohit", ""], ["Sainath", "Tara N.", ""], ["Wu", "Yonghui", ""], ["Nguyen", "Patrick", ""], ["Chen", "Zhifeng", ""], ["Chiu", "Chung-Cheng", ""], ["Kannan", "Anjuli", ""]]}, {"id": "1712.01821", "submitter": "Mercedes Garc\\'ia-Mart\\'inez", "authors": "Mercedes Garc\\'ia-Mart\\'inez and Lo\\\"ic Barrault and Fethi Bougares", "title": "Neural Machine Translation by Generating Multiple Linguistic Factors", "comments": "11 pages, 3 figues, SLSP conference", "journal-ref": null, "doi": "10.1007/978-3-319-68456-7_2", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factored neural machine translation (FNMT) is founded on the idea of using\nthe morphological and grammatical decomposition of the words (factors) at the\noutput side of the neural network. This architecture addresses two well-known\nproblems occurring in MT, namely the size of target language vocabulary and the\nnumber of unknown tokens produced in the translation. FNMT system is designed\nto manage larger vocabulary and reduce the training time (for systems with\nequivalent target language vocabulary size). Moreover, we can produce\ngrammatically correct words that are not part of the vocabulary. FNMT model is\nevaluated on IWSLT'15 English to French task and compared to the baseline\nword-based and BPE-based NMT systems. Promising qualitative and quantitative\nresults (in terms of BLEU and METEOR) are reported.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:53:49 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Barrault", "Lo\u00efc", ""], ["Bougares", "Fethi", ""]]}, {"id": "1712.01864", "submitter": "Chung-Cheng Chiu", "authors": "Tara N. Sainath, Rohit Prabhavalkar, Shankar Kumar, Seungji Lee,\n  Anjuli Kannan, David Rybach, Vlad Schogol, Patrick Nguyen, Bo Li, Yonghui Wu,\n  Zhifeng Chen, Chung-Cheng Chiu", "title": "No Need for a Lexicon? Evaluating the Value of the Pronunciation Lexica\n  in End-to-End Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, context-dependent phonemes have been the dominant sub-word unit\nfor conventional acoustic modeling systems. This status quo has begun to be\nchallenged recently by end-to-end models which seek to combine acoustic,\npronunciation, and language model components into a single neural network. Such\nsystems, which typically predict graphemes or words, simplify the recognition\nprocess since they remove the need for a separate expert-curated pronunciation\nlexicon to map from phoneme-based units to words. However, there has been\nlittle previous work comparing phoneme-based versus grapheme-based sub-word\nunits in the end-to-end modeling framework, to determine whether the gains from\nsuch approaches are primarily due to the new probabilistic model, or from the\njoint learning of the various components with grapheme-based units.\n  In this work, we conduct detailed experiments which are aimed at quantifying\nthe value of phoneme-based pronunciation lexica in the context of end-to-end\nmodels. We examine phoneme-based end-to-end models, which are contrasted\nagainst grapheme-based ones on a large vocabulary English Voice-search task,\nwhere we find that graphemes do indeed outperform phonemes. We also compare\ngrapheme and phoneme-based approaches on a multi-dialect English task, which\nonce again confirm the superiority of graphemes, greatly simplifying the system\nfor recognizing multiple dialects.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 19:02:28 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Sainath", "Tara N.", ""], ["Prabhavalkar", "Rohit", ""], ["Kumar", "Shankar", ""], ["Lee", "Seungji", ""], ["Kannan", "Anjuli", ""], ["Rybach", "David", ""], ["Schogol", "Vlad", ""], ["Nguyen", "Patrick", ""], ["Li", "Bo", ""], ["Wu", "Yonghui", ""], ["Chen", "Zhifeng", ""], ["Chiu", "Chung-Cheng", ""]]}, {"id": "1712.01969", "submitter": "Jimmy Lin", "authors": "Salman Mohammed, Peng Shi, Jimmy Lin", "title": "Strong Baselines for Simple Question Answering over Knowledge Graphs\n  with and without Neural Networks", "comments": "Published in NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of question answering over knowledge graphs, focusing\non simple questions that can be answered by the lookup of a single fact.\nAdopting a straightforward decomposition of the problem into entity detection,\nentity linking, relation prediction, and evidence combination, we explore\nsimple yet strong baselines. On the popular SimpleQuestions dataset, we find\nthat basic LSTMs and GRUs plus a few heuristics yield accuracies that approach\nthe state of the art, and techniques that do not use neural networks also\nperform reasonably well. These results show that gains from sophisticated deep\nlearning techniques proposed in the literature are quite modest and that some\nprevious models exhibit unnecessary complexity.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 23:38:00 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 19:40:19 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Mohammed", "Salman", ""], ["Shi", "Peng", ""], ["Lin", "Jimmy", ""]]}, {"id": "1712.01996", "submitter": "Anjuli Kannan", "authors": "Anjuli Kannan, Yonghui Wu, Patrick Nguyen, Tara N. Sainath, Zhifeng\n  Chen, Rohit Prabhavalkar", "title": "An analysis of incorporating an external language model into a\n  sequence-to-sequence model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models for automatic speech recognition\njointly train an acoustic model, language model, and alignment mechanism. Thus,\nthe language model component is only trained on transcribed audio-text pairs.\nThis leads to the use of shallow fusion with an external language model at\ninference time. Shallow fusion refers to log-linear interpolation with a\nseparately trained language model at each step of the beam search. In this\nwork, we investigate the behavior of shallow fusion across a range of\nconditions: different types of language models, different decoding units, and\ndifferent tasks. On Google Voice Search, we demonstrate that the use of shallow\nfusion with a neural LM with wordpieces yields a 9.1% relative word error rate\nreduction (WERR) over our competitive attention-based sequence-to-sequence\nmodel, obviating the need for second-pass rescoring.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 01:30:54 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Kannan", "Anjuli", ""], ["Wu", "Yonghui", ""], ["Nguyen", "Patrick", ""], ["Sainath", "Tara N.", ""], ["Chen", "Zhifeng", ""], ["Prabhavalkar", "Rohit", ""]]}, {"id": "1712.02016", "submitter": "Hu Xu", "authors": "Hu Xu and Sihong Xie and Lei Shu and Philip S. Yu", "title": "Dual Attention Network for Product Compatibility and Function\n  Satisfiability Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product compatibility and their functionality are of utmost importance to\ncustomers when they purchase products, and to sellers and manufacturers when\nthey sell products. Due to the huge number of products available online, it is\ninfeasible to enumerate and test the compatibility and functionality of every\nproduct. In this paper, we address two closely related problems: product\ncompatibility analysis and function satisfiability analysis, where the second\nproblem is a generalization of the first problem (e.g., whether a product works\nwith another product can be considered as a special function). We first\nidentify a novel question and answering corpus that is up-to-date regarding\nproduct compatibility and functionality information. To allow automatic\ndiscovery product compatibility and functionality, we then propose a deep\nlearning model called Dual Attention Network (DAN). Given a QA pair for a\nto-be-purchased product, DAN learns to 1) discover complementary products (or\nfunctions), and 2) accurately predict the actual compatibility (or\nsatisfiability) of the discovered products (or functions). The challenges\naddressed by the model include the briefness of QAs, linguistic patterns\nindicating compatibility, and the appropriate fusion of questions and answers.\nWe conduct experiments to quantitatively and qualitatively show that the\nidentified products and functions have both high coverage and accuracy,\ncompared with a wide spectrum of baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 03:11:51 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Xu", "Hu", ""], ["Xie", "Sihong", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1712.02034", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Nathan O. Hodas, Charles Siegel, Abhinav Vishnu", "title": "SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties", "comments": "Submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 04:29:28 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 13:50:32 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Goh", "Garrett B.", ""], ["Hodas", "Nathan O.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""]]}, {"id": "1712.02047", "submitter": "Jinbae Im", "authors": "Jinbae Im and Sungzoon Cho", "title": "Distance-based Self-Attention Network for Natural Language Inference", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism has been used as an ancillary means to help RNN or CNN.\nHowever, the Transformer (Vaswani et al., 2017) recently recorded the\nstate-of-the-art performance in machine translation with a dramatic reduction\nin training time by solely using attention. Motivated by the Transformer,\nDirectional Self Attention Network (Shen et al., 2017), a fully attention-based\nsentence encoder, was proposed. It showed good performance with various data by\nusing forward and backward directional information in a sentence. But in their\nstudy, not considered at all was the distance between words, an important\nfeature when learning the local dependency to help understand the context of\ninput text. We propose Distance-based Self-Attention Network, which considers\nthe word distance by using a simple distance mask in order to model the local\ndependency without losing the ability of modeling global dependency which\nattention has inherent. Our model shows good performance with NLI data, and it\nrecords the new state-of-the-art result with SNLI data. Additionally, we show\nthat our model has a strength in long sentences or documents.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 05:38:29 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Im", "Jinbae", ""], ["Cho", "Sungzoon", ""]]}, {"id": "1712.02109", "submitter": "Hao Xiong", "authors": "Hao Xiong, Zhongjun He, Xiaoguang Hu and Hua Wu", "title": "Multi-channel Encoder for Neural Machine Translation", "comments": "Accepted by AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based Encoder-Decoder has the effective architecture for neural\nmachine translation (NMT), which typically relies on recurrent neural networks\n(RNN) to build the blocks that will be lately called by attentive reader during\nthe decoding process. This design of encoder yields relatively uniform\ncomposition on source sentence, despite the gating mechanism employed in\nencoding RNN. On the other hand, we often hope the decoder to take pieces of\nsource sentence at varying levels suiting its own linguistic structure: for\nexample, we may want to take the entity name in its raw form while taking an\nidiom as a perfectly composed unit. Motivated by this demand, we propose\nMulti-channel Encoder (MCE), which enhances encoding components with different\nlevels of composition. More specifically, in addition to the hidden state of\nencoding RNN, MCE takes 1) the original word embedding for raw encoding with no\ncomposition, and 2) a particular design of external memory in Neural Turing\nMachine (NTM) for more complex composition, while all three encoding strategies\nare properly blended during decoding. Empirical study on Chinese-English\ntranslation shows that our model can improve by 6.52 BLEU points upon a strong\nopen source NMT system: DL4MT1. On the WMT14 English- French task, our single\nshallow system achieves BLEU=38.8, comparable with the state-of-the-art deep\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 09:59:43 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Xiong", "Hao", ""], ["He", "Zhongjun", ""], ["Hu", "Xiaoguang", ""], ["Wu", "Hua", ""]]}, {"id": "1712.02121", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen, Tu Dinh Nguyen, Dat Quoc Nguyen, Dinh Phung", "title": "A Novel Embedding Model for Knowledge Base Completion Based on\n  Convolutional Neural Network", "comments": "In Proceedings of NAACL-HLT 2018, to appear", "journal-ref": null, "doi": "10.18653/v1/N18-2053", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel embedding model, named ConvKB, for\nknowledge base completion. Our model ConvKB advances state-of-the-art models by\nemploying a convolutional neural network, so that it can capture global\nrelationships and transitional characteristics between entities and relations\nin knowledge bases. In ConvKB, each triple (head entity, relation, tail entity)\nis represented as a 3-column matrix where each column vector represents a\ntriple element. This 3-column matrix is then fed to a convolution layer where\nmultiple filters are operated on the matrix to generate different feature maps.\nThese feature maps are then concatenated into a single feature vector\nrepresenting the input triple. The feature vector is multiplied with a weight\nvector via a dot product to return a score. This score is then used to predict\nwhether the triple is valid or not. Experiments show that ConvKB achieves\nbetter link prediction performance than previous state-of-the-art embedding\nmodels on two benchmark datasets WN18RR and FB15k-237.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 10:41:47 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 07:45:20 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Nguyen", "Dat Quoc", ""], ["Phung", "Dinh", ""]]}, {"id": "1712.02186", "submitter": "Hu Xu", "authors": "Hu Xu, Sihong Xie, Lei Shu, Philip S. Yu", "title": "Product Function Need Recognition via Semi-supervised Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functionality is of utmost importance to customers when they purchase\nproducts. However, it is unclear to customers whether a product can really\nsatisfy their needs on functions. Further, missing functions may be\nintentionally hidden by the manufacturers or the sellers. As a result, a\ncustomer needs to spend a fair amount of time before purchasing or just\npurchase the product on his/her own risk. In this paper, we first identify a\nnovel QA corpus that is dense on product functionality information\n\\footnote{The annotated corpus can be found at\n\\url{https://www.cs.uic.edu/~hxu/}.}. We then design a neural network called\nSemi-supervised Attention Network (SAN) to discover product functions from\nquestions. This model leverages unlabeled data as contextual information to\nperform semi-supervised sequence labeling. We conduct experiments to show that\nthe extracted function have both high coverage and accuracy, compared with a\nwide spectrum of baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 13:48:57 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Xu", "Hu", ""], ["Xie", "Sihong", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1712.02223", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga, Elena Kochkina, Maria Liakata, Rob Procter, Michal\n  Lukasik, Kalina Bontcheva, Trevor Cohn, Isabelle Augenstein", "title": "Discourse-Aware Rumour Stance Classification in Social Media Using\n  Sequential Classifiers", "comments": null, "journal-ref": "Information Processing & Management, Volume 54, Issue 2, March\n  2018, Pages 273-290", "doi": "10.1016/j.ipm.2017.11.009", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rumour stance classification, defined as classifying the stance of specific\nsocial media posts into one of supporting, denying, querying or commenting on\nan earlier post, is becoming of increasing interest to researchers. While most\nprevious work has focused on using individual tweets as classifier inputs, here\nwe report on the performance of sequential classifiers that exploit the\ndiscourse features inherent in social media interactions or 'conversational\nthreads'. Testing the effectiveness of four sequential classifiers -- Hawkes\nProcesses, Linear-Chain Conditional Random Fields (Linear CRF), Tree-Structured\nConditional Random Fields (Tree CRF) and Long Short Term Memory networks (LSTM)\n-- on eight datasets associated with breaking news stories, and looking at\ndifferent types of local and contextual features, our work sheds new light on\nthe development of accurate stance classifiers. We show that sequential\nclassifiers that exploit the use of discourse properties in social media\nconversations while using only local features, outperform non-sequential\nclassifiers. Furthermore, we show that LSTM using a reduced set of features can\noutperform the other sequential classifiers; this performance is consistent\nacross datasets and across types of stances. To conclude, our work also\nanalyses the different features under study, identifying those that best help\ncharacterise and distinguish between stances, such as supporting tweets being\nmore likely to be accompanied by evidence than denying tweets. We also set\nforth a number of directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 15:15:21 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Zubiaga", "Arkaitz", ""], ["Kochkina", "Elena", ""], ["Liakata", "Maria", ""], ["Procter", "Rob", ""], ["Lukasik", "Michal", ""], ["Bontcheva", "Kalina", ""], ["Cohn", "Trevor", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1712.02250", "submitter": "Lili Mou", "authors": "Bolin Wei, Shuai Lu, Lili Mou, Hao Zhou, Pascal Poupart, Ge Li, Zhi\n  Jin", "title": "Why Do Neural Dialog Systems Generate Short and Meaningless Replies? A\n  Comparison between Dialog and Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the question: Why do neural dialog systems generate\nshort and meaningless replies? We conjecture that, in a dialog system, an\nutterance may have multiple equally plausible replies, causing the deficiency\nof neural networks in the dialog application. We propose a systematic way to\nmimic the dialog scenario in a machine translation system, and manage to\nreproduce the phenomenon of generating short and less meaningful sentences in\nthe translation setting, showing evidence of our conjecture.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 16:00:45 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Wei", "Bolin", ""], ["Lu", "Shuai", ""], ["Mou", "Lili", ""], ["Zhou", "Hao", ""], ["Poupart", "Pascal", ""], ["Li", "Ge", ""], ["Jin", "Zhi", ""]]}, {"id": "1712.02259", "submitter": "Nicolas Bousquet", "authors": "Nicolas Thiebaut, Antoine Simoulin, Karl Neuberger, Issam Ibnouhsein,\n  Nicolas Bousquet, Nathalie Reix, S\\'ebastien Moli\\`ere, Carole Mathelin", "title": "An innovative solution for breast cancer textual big data analysis", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of stored information in hospitals now allows for the\nexploitation of medical data in text format, as electronic health records\n(EHRs), initially gathered for other purposes than epidemiology. Manual search\nand analysis operations on such data become tedious. In recent years, the use\nof natural language processing (NLP) tools was highlighted to automatize the\nextraction of information contained in EHRs, structure it and perform\nstatistical analysis on this structured information. The main difficulties with\nthe existing approaches is the requirement of synonyms or ontology\ndictionaries, that are mostly available in English only and do not include\nlocal or custom notations. In this work, a team composed of oncologists as\ndomain experts and data scientists develop a custom NLP-based system to process\nand structure textual clinical reports of patients suffering from breast\ncancer. The tool relies on the combination of standard text mining techniques\nand an advanced synonym detection method. It allows for a global analysis by\nretrieval of indicators such as medical history, tumor characteristics,\ntherapeutic responses, recurrences and prognosis. The versatility of the method\nallows to obtain easily new indicators, thus opening up the way for\nretrospective studies with a substantial reduction of the amount of manual\nwork. With no need for biomedical annotators or pre-defined ontologies, this\nlanguage-agnostic method reached an good extraction accuracy for several\nconcepts of interest, according to a comparison with a manually structured\nfile, without requiring any existing corpus with local or new notations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 16:18:31 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Thiebaut", "Nicolas", ""], ["Simoulin", "Antoine", ""], ["Neuberger", "Karl", ""], ["Ibnouhsein", "Issam", ""], ["Bousquet", "Nicolas", ""], ["Reix", "Nathalie", ""], ["Moli\u00e8re", "S\u00e9bastien", ""], ["Mathelin", "Carole", ""]]}, {"id": "1712.02480", "submitter": "Paul Reisert", "authors": "Paul Reisert and Naoya Inoue and Naoaki Okazaki and Kentaro Inui", "title": "A Corpus of Deep Argumentative Structures as an Explanation to\n  Argumentative Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compose a new task for deep argumentative structure\nanalysis that goes beyond shallow discourse structure analysis. The idea is\nthat argumentative relations can reasonably be represented with a small set of\npredefined patterns. For example, using value judgment and bipolar causality,\nwe can explain a support relation between two argumentative segments as\nfollows: Segment 1 states that something is good, and Segment 2 states that it\nis good because it promotes something good when it happens. We are motivated by\nthe following questions: (i) how do we formulate the task?, (ii) can a\nreasonable pattern set be created?, and (iii) do the patterns work? To examine\nthe task feasibility, we conduct a three-stage, detailed annotation study using\n357 argumentative relations from the argumentative microtext corpus, a small,\nbut highly reliable corpus. We report the coverage of explanations captured by\nour patterns on a test set composed of 270 relations. Our coverage result of\n74.6% indicates that argumentative relations can reasonably be explained by our\nsmall pattern set. Our agreement result of 85.9% shows that a reasonable\ninter-annotator agreement can be achieved. To assist with future work in\ncomputational argumentation, the annotated corpus is made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 03:17:51 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Reisert", "Paul", ""], ["Inoue", "Naoya", ""], ["Okazaki", "Naoaki", ""], ["Inui", "Kentaro", ""]]}, {"id": "1712.02555", "submitter": "Han Xiao", "authors": "Han Xiao, Yidong Chen, Xiaodong Shi", "title": "Hungarian Layer: Logics Empowered Neural Architecture", "comments": "This is the draft submitting to ICML 2018. You could expect the final\n  version, which is more perfect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture is a purely numeric framework, which fits the data as a\ncontinuous function. However, lacking of logic flow (e.g. \\textit{if, for,\nwhile}), traditional algorithms (e.g. \\textit{Hungarian algorithm, A$^*$\nsearching, decision tress algorithm}) could not be embedded into this paradigm,\nwhich limits the theories and applications. In this paper, we reform the\ncalculus graph as a dynamic process, which is guided by logic flow. Within our\nnovel methodology, traditional algorithms could empower numerical neural\nnetwork. Specifically, regarding the subject of sentence matching, we\nreformulate this issue as the form of task-assignment, which is solved by\nHungarian algorithm. First, our model applies BiLSTM to parse the sentences.\nThen Hungarian layer aligns the matching positions. Last, we transform the\nmatching results for soft-max regression by another BiLSTM. Extensive\nexperiments show that our model outperforms other state-of-the-art baselines\nsubstantially.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 10:02:56 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 10:41:18 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 07:56:28 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Xiao", "Han", ""], ["Chen", "Yidong", ""], ["Shi", "Xiaodong", ""]]}, {"id": "1712.02767", "submitter": "Sachin Pawar", "authors": "Sachin Pawar, Nitin Ramrakhiyani, Swapnil Hingmire and Girish K.\n  Palshikar", "title": "Topics and Label Propagation: Best of Both Worlds for Weakly Supervised\n  Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Label Propagation based algorithm for weakly supervised text\nclassification. We construct a graph where each document is represented by a\nnode and edge weights represent similarities among the documents. Additionally,\nwe discover underlying topics using Latent Dirichlet Allocation (LDA) and\nenrich the document graph by including the topics in the form of additional\nnodes. The edge weights between a topic and a text document represent level of\n\"affinity\" between them. Our approach does not require document level\nlabelling, instead it expects manual labels only for topic nodes. This\nsignificantly minimizes the level of supervision needed as only a few topics\nare observed to be enough for achieving sufficiently high accuracy. The Label\nPropagation Algorithm is employed on this enriched graph to propagate labels\namong the nodes. Our approach combines the advantages of Label Propagation\n(through document-document similarities) and Topic Modelling (for minimal but\nsmart supervision). We demonstrate the effectiveness of our approach on various\ndatasets and compare with state-of-the-art weakly supervised text\nclassification approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 06:05:21 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Pawar", "Sachin", ""], ["Ramrakhiyani", "Nitin", ""], ["Hingmire", "Swapnil", ""], ["Palshikar", "Girish K.", ""]]}, {"id": "1712.02768", "submitter": "Dimitris Konomis", "authors": "Christy Li, Dimitris Konomis, Graham Neubig, Pengtao Xie, Carol Cheng,\n  Eric Xing", "title": "Convolutional Neural Networks for Medical Diagnosis from Admission Notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\textbf{Objective}$ Develop an automatic diagnostic system which only uses\ntextual admission information from Electronic Health Records (EHRs) and assist\nclinicians with a timely and statistically proved decision tool. The hope is\nthat the tool can be used to reduce mis-diagnosis.\n  $\\textbf{Materials and Methods}$ We use the real-world clinical notes from\nMIMIC-III, a freely available dataset consisting of clinical data of more than\nforty thousand patients who stayed in intensive care units of the Beth Israel\nDeaconess Medical Center between 2001 and 2012. We proposed a Convolutional\nNeural Network model to learn semantic features from unstructured textual input\nand automatically predict primary discharge diagnosis.\n  $\\textbf{Results}$ The proposed model achieved an overall 96.11% accuracy and\n80.48% weighted F1 score values on 10 most frequent disease classes,\nsignificantly outperforming four strong baseline models by at least 12.7% in\nweighted F1 score.\n  $\\textbf{Discussion}$ Experimental results imply that the CNN model is\nsuitable for supporting diagnosis decision making in the presence of complex,\nnoisy and unstructured clinical data while at the same time using fewer layers\nand parameters that other traditional Deep Network models.\n  $\\textbf{Conclusion}$ Our model demonstrated capability of representing\ncomplex medical meaningful features from unstructured clinical notes and\nprediction power for commonly misdiagnosed frequent diseases. It can use easily\nadopted in clinical setting to provide timely and statistically proved decision\nsupport.\n  $\\textbf{Keywords}$ Convolutional neural network, text classification,\ndischarge diagnosis prediction, admission information from EHRs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 08:39:29 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Li", "Christy", ""], ["Konomis", "Dimitris", ""], ["Neubig", "Graham", ""], ["Xie", "Pengtao", ""], ["Cheng", "Carol", ""], ["Xing", "Eric", ""]]}, {"id": "1712.02820", "submitter": "Heri Ramampiaro", "authors": "Basant Agarwal, Heri Ramampiaro, Helge Langseth, Massimiliano Ruocco", "title": "A Deep Network Model for Paraphrase Detection in Short Text Messages", "comments": null, "journal-ref": "B Agarwal, H. Ramampiaro, H Langseth, M Ruocco, (2018), \"A Deep\n  Network Model for Paraphrase Detection in Short Text Messages\". In\n  Information Processing & Management Journal (IPM), 54(6), pp. 922-937.\n  Elsevier", "doi": "10.1016/j.ipm.2018.06.005", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with paraphrase detection. The ability to detect\nsimilar sentences written in natural language is crucial for several\napplications, such as text mining, text summarization, plagiarism detection,\nauthorship authentication and question answering. Given two sentences, the\nobjective is to detect whether they are semantically identical. An important\ninsight from this work is that existing paraphrase systems perform well when\napplied on clean texts, but they do not necessarily deliver good performance\nagainst noisy texts. Challenges with paraphrase detection on user generated\nshort texts, such as Twitter, include language irregularity and noise. To cope\nwith these challenges, we propose a novel deep neural network-based approach\nthat relies on coarse-grained sentence modeling using a convolutional neural\nnetwork and a long short-term memory model, combined with a specific\nfine-grained word-level similarity matching model. Our experimental results\nshow that the proposed approach outperforms existing state-of-the-art\napproaches on user-generated noisy social media data, such as Twitter texts,\nand achieves highly competitive performance on a cleaner corpus.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 19:10:45 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Agarwal", "Basant", ""], ["Ramampiaro", "Heri", ""], ["Langseth", "Helge", ""], ["Ruocco", "Massimiliano", ""]]}, {"id": "1712.02838", "submitter": "Li Zhou", "authors": "Li Zhou, Kevin Small, Oleg Rokhlenko, Charles Elkan", "title": "End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy\n  Gradient", "comments": "Workshop on Conversational AI, NIPS 2017, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a goal-oriented dialog policy is generally performed offline with\nsupervised learning algorithms or online with reinforcement learning (RL).\nAdditionally, as companies accumulate massive quantities of dialog transcripts\nbetween customers and trained human agents, encoder-decoder methods have gained\npopularity as agent utterances can be directly treated as supervision without\nthe need for utterance-level annotations. However, one potential drawback of\nsuch approaches is that they myopically generate the next agent utterance\nwithout regard for dialog-level considerations. To resolve this concern, this\npaper describes an offline RL method for learning from unannotated corpora that\ncan optimize a goal-oriented policy at both the utterance and dialog level. We\nintroduce a novel reward function and use both on-policy and off-policy policy\ngradient to learn a policy offline without requiring online user interaction or\nan explicit state space definition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 19:52:50 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""], ["Rokhlenko", "Oleg", ""], ["Elkan", "Charles", ""]]}, {"id": "1712.02856", "submitter": "Han He", "authors": "Han He, Lei Wu, Hua Yan, Zhimin Gao, Yi Feng, George Townsend", "title": "Effective Neural Solution for Multi-Criteria Word Segmentation", "comments": "2nd International Conference on Smart Computing & Informatics\n  (SCI-2018), Springer Smart Innovation Systems and Technologies Book Series,\n  Springer-Verlag, Accepted & Forthcoming, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple yet elegant solution to train a single joint model on\nmulti-criteria corpora for Chinese Word Segmentation (CWS). Our novel design\nrequires no private layers in model architecture, instead, introduces two\nartificial tokens at the beginning and ending of input sentence to specify the\nrequired target criteria. The rest of the model including Long Short-Term\nMemory (LSTM) layer and Conditional Random Fields (CRFs) layer remains\nunchanged and is shared across all datasets, keeping the size of parameter\ncollection minimal and constant. On Bakeoff 2005 and Bakeoff 2008 datasets, our\ninnovative design has surpassed both single-criterion and multi-criteria\nstate-of-the-art learning results. To the best knowledge, our design is the\nfirst one that has achieved the latest high performance on such large scale\ndatasets. Source codes and corpora of this paper are available on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 20:48:15 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 12:24:33 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["He", "Han", ""], ["Wu", "Lei", ""], ["Yan", "Hua", ""], ["Gao", "Zhimin", ""], ["Feng", "Yi", ""], ["Townsend", "George", ""]]}, {"id": "1712.02896", "submitter": "Eric Chu", "authors": "Eric Chu and Deb Roy", "title": "Audio-Visual Sentiment Analysis for Learning Emotional Arcs in Movies", "comments": "Data Mining (ICDM), 2017 IEEE 17th International Conference on", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stories can have tremendous power -- not only useful for entertainment, they\ncan activate our interests and mobilize our actions. The degree to which a\nstory resonates with its audience may be in part reflected in the emotional\njourney it takes the audience upon. In this paper, we use machine learning\nmethods to construct emotional arcs in movies, calculate families of arcs, and\ndemonstrate the ability for certain arcs to predict audience engagement. The\nsystem is applied to Hollywood films and high quality shorts found on the web.\nWe begin by using deep convolutional neural networks for audio and visual\nsentiment analysis. These models are trained on both new and existing\nlarge-scale datasets, after which they can be used to compute separate audio\nand visual emotional arcs. We then crowdsource annotations for 30-second video\nclips extracted from highs and lows in the arcs in order to assess the\nmicro-level precision of the system, with precision measured in terms of\nagreement in polarity between the system's predictions and annotators' ratings.\nThese annotations are also used to combine the audio and visual predictions.\nNext, we look at macro-level characterizations of movies by investigating\nwhether there exist `universal shapes' of emotional arcs. In particular, we\ndevelop a clustering approach to discover distinct classes of emotional arcs.\nFinally, we show on a sample corpus of short web videos that certain emotional\narcs are statistically significant predictors of the number of comments a video\nreceives. These results suggest that the emotional arcs learned by our approach\nsuccessfully represent macroscopic aspects of a video story that drive audience\nengagement. Such machine understanding could be used to predict audience\nreactions to video stories, ultimately improving our ability as storytellers to\ncommunicate with each other.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 00:27:08 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Chu", "Eric", ""], ["Roy", "Deb", ""]]}, {"id": "1712.02959", "submitter": "Mehreen Alam", "authors": "Mehreen Alam, Sibt ul Hussain", "title": "Sequence to Sequence Networks for Roman-Urdu to Urdu Transliteration", "comments": "20th International Multitopic Conference (INMIC 17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation models have replaced the conventional phrase based\nstatistical translation methods since the former takes a generic, scalable,\ndata-driven approach rather than relying on manual, hand-crafted features. The\nneural machine translation system is based on one neural network that is\ncomposed of two parts, one that is responsible for input language sentence and\nother part that handles the desired output language sentence. This model based\non encoder-decoder architecture also takes as input the distributed\nrepresentations of the source language which enriches the learnt dependencies\nand gives a warm start to the network. In this work, we transform Roman-Urdu to\nUrdu transliteration into sequence to sequence learning problem. To this end,\nwe make the following contributions. We create the first ever parallel corpora\nof Roman-Urdu to Urdu, create the first ever distributed representation of\nRoman-Urdu and present the first neural machine translation model that\ntransliterates text from Roman-Urdu to Urdu language. Our model has achieved\nthe state-of-the-art results using BLEU as the evaluation metric. Precisely,\nour model is able to correctly predict sentences up to length 10 while\nachieving BLEU score of 48.6 on the test set. We are hopeful that our model and\nour results shall serve as the baseline for further work in the domain of\nneural machine translation for Roman-Urdu to Urdu using distributed\nrepresentation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 06:36:54 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Alam", "Mehreen", ""], ["Hussain", "Sibt ul", ""]]}, {"id": "1712.03086", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Jiayuan Ding, Runqi Shao, Anoop Kumar, Pedro Szekely", "title": "FlagIt: A System for Minimally Supervised Human Trafficking Indicator\n  Mining", "comments": "6 pages, published in Workshop on Learning with Limited Labeled Data\n  co-held with NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe and study the indicator mining problem in the\nonline sex advertising domain. We present an in-development system, FlagIt\n(Flexible and adaptive generation of Indicators from text), which combines the\nbenefits of both a lightweight expert system and classical semi-supervision\n(heuristic re-labeling) with recently released state-of-the-art unsupervised\ntext embeddings to tag millions of sentences with indicators that are highly\ncorrelated with human trafficking. The FlagIt technology stack is open source.\nOn preliminary evaluations involving five indicators, FlagIt illustrates\npromising performance compared to several alternatives. The system is being\nactively developed, refined and integrated into a domain-specific search system\nused by over 200 law enforcement agencies to combat human trafficking, and is\nbeing aggressively extended to mine at least six more indicators with minimal\nprogramming effort. FlagIt is a good example of a system that operates in\nlimited label settings, and that requires creative combinations of established\nmachine learning techniques to produce outputs that could be used by real-world\nnon-technical analysts.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:15:48 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Ding", "Jiayuan", ""], ["Shao", "Runqi", ""], ["Kumar", "Anoop", ""], ["Szekely", "Pedro", ""]]}, {"id": "1712.03133", "submitter": "Kartik Audhkhasi", "authors": "Kartik Audhkhasi, Brian Kingsbury, Bhuvana Ramabhadran, George Saon,\n  Michael Picheny", "title": "Building competitive direct acoustics-to-word models for English\n  conversational speech recognition", "comments": "Submitted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct acoustics-to-word (A2W) models in the end-to-end paradigm have\nreceived increasing attention compared to conventional sub-word based automatic\nspeech recognition models using phones, characters, or context-dependent hidden\nMarkov model states. This is because A2W models recognize words from speech\nwithout any decoder, pronunciation lexicon, or externally-trained language\nmodel, making training and decoding with such models simple. Prior work has\nshown that A2W models require orders of magnitude more training data in order\nto perform comparably to conventional models. Our work also showed this\naccuracy gap when using the English Switchboard-Fisher data set. This paper\ndescribes a recipe to train an A2W model that closes this gap and is at-par\nwith state-of-the-art sub-word based models. We achieve a word error rate of\n8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder\nor language model. We find that model initialization, training data order, and\nregularization have the most impact on the A2W model performance. Next, we\npresent a joint word-character A2W model that learns to first spell the word\nand then recognize it. This model provides a rich output to the user instead of\nsimple word hypotheses, making it especially useful in the case of words unseen\nor rarely-seen during training.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:43:21 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Audhkhasi", "Kartik", ""], ["Kingsbury", "Brian", ""], ["Ramabhadran", "Bhuvana", ""], ["Saon", "George", ""], ["Picheny", "Michael", ""]]}, {"id": "1712.03199", "submitter": "Sekou Remy", "authors": "Victor Akinwande, Sekou L. Remy", "title": "Characterizing the hyper-parameter space of LSTM language models for\n  mixed context applications", "comments": "4 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying state of the art deep learning models to novel real world datasets\ngives a practical evaluation of the generalizability of these models. Of\nimportance in this process is how sensitive the hyper parameters of such models\nare to novel datasets as this would affect the reproducibility of a model. We\npresent work to characterize the hyper parameter space of an LSTM for language\nmodeling on a code-mixed corpus. We observe that the evaluated model shows\nminimal sensitivity to our novel dataset bar a few hyper parameters.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 17:52:32 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Akinwande", "Victor", ""], ["Remy", "Sekou L.", ""]]}, {"id": "1712.03249", "submitter": "Tobias Moers", "authors": "Florian Krebs, Bruno Lubascher, Tobias Moers, Pieter Schaap, Gerasimos\n  Spanakis", "title": "Social Emotion Mining Techniques for Facebook Posts Reaction Prediction", "comments": "10 pages, 13 figures and accepted at ICAART 2018. (Dataset:\n  https://github.com/jerryspan/FacebookR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of February 2016 Facebook allows users to express their experienced\nemotions about a post by using five so-called `reactions'. This research paper\nproposes and evaluates alternative methods for predicting these reactions to\nuser posts on public pages of firms/companies (like supermarket chains). For\nthis purpose, we collected posts (and their reactions) from Facebook pages of\nlarge supermarket chains and constructed a dataset which is available for other\nresearches. In order to predict the distribution of reactions of a new post,\nneural network architectures (convolutional and recurrent neural networks) were\ntested using pretrained word embeddings. Results of the neural networks were\nimproved by introducing a bootstrapping approach for sentiment and emotion\nmining on the comments for each post. The final model (a combination of neural\nnetwork and a baseline emotion miner) is able to predict the reaction\ndistribution on Facebook posts with a mean squared error (or misclassification\nrate) of 0.135.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 19:05:50 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Krebs", "Florian", ""], ["Lubascher", "Bruno", ""], ["Moers", "Tobias", ""], ["Schaap", "Pieter", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1712.03376", "submitter": "Jacopo Urbani", "authors": "Minh Le, Marten Postma, Jacopo Urbani", "title": "Word Sense Disambiguation with LSTM: Do We Really Need 100 Billion\n  Words?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recently, Yuan et al. (2016) have shown the effectiveness of using Long\nShort-Term Memory (LSTM) for performing Word Sense Disambiguation (WSD). Their\nproposed technique outperformed the previous state-of-the-art with several\nbenchmarks, but neither the training data nor the source code was released.\nThis paper presents the results of a reproduction study of this technique using\nonly openly available datasets (GigaWord, SemCore, OMSTI) and software\n(TensorFlow). From them, it emerged that state-of-the-art results can be\nobtained with much less data than hinted by Yuan et al. All code and trained\nmodels are made freely available.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 10:47:19 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 10:24:08 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Le", "Minh", ""], ["Postma", "Marten", ""], ["Urbani", "Jacopo", ""]]}, {"id": "1712.03430", "submitter": "Sharmistha Dey Ms", "authors": "Sharmistha Dey", "title": "Aspect Extraction and Sentiment Classification of Mobile Apps using\n  App-Store Reviews", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding of customer sentiment can be useful for product development. On\ntop of that if the priorities for the development order can be known, then\ndevelopment procedure become simpler. This work has tried to address this issue\nin the mobile app domain. Along with aspect and opinion extraction this work\nhas also categorized the extracted aspects ac-cording to their importance. This\ncan help developers to focus their time and energy at the right place.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 20:06:52 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Dey", "Sharmistha", ""]]}, {"id": "1712.03449", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and St\\'ephane Dupont", "title": "Modulating and attending the source image during encoding improves\n  Multimodal Translation", "comments": "Accepted at NIPS Workshop", "journal-ref": "Visually-Grounded Interaction and Language, NIPS 2017 Workshop", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new and fully end-to-end approach for multimodal translation\nwhere the source text encoder modulates the entire visual input processing\nusing conditional batch normalization, in order to compute the most informative\nimage features for our task. Additionally, we propose a new attention mechanism\nderived from this original idea, where the attention model for the visual input\nis conditioned on the source text encoder representations. In the paper, we\ndetail our models as well as the image analysis pipeline. Finally, we report\nexperimental results. They are, as far as we know, the new state of the art on\nthree different test sets.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 23:17:22 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1712.03463", "submitter": "Yonatan Bisk", "authors": "Yonatan Bisk, Kevin J. Shih, Yejin Choi, Daniel Marcu", "title": "Learning Interpretable Spatial Operations in a Rich 3D Blocks World", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of mapping natural language instructions\nto complex spatial actions in a 3D blocks world. We first introduce a new\ndataset that pairs complex 3D spatial operations to rich natural language\ndescriptions that require complex spatial and pragmatic interpretations such as\n\"mirroring\", \"twisting\", and \"balancing\". This dataset, built on the simulation\nenvironment of Bisk, Yuret, and Marcu (2016), attains language that is\nsignificantly richer and more complex, while also doubling the size of the\noriginal dataset in the 2D environment with 100 new world configurations and\n250,000 tokens. In addition, we propose a new neural architecture that achieves\ncompetitive results while automatically discovering an inventory of\ninterpretable spatial operations (Figure 5)\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 00:55:16 GMT"}, {"version": "v2", "created": "Sun, 24 Dec 2017 20:21:46 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Bisk", "Yonatan", ""], ["Shih", "Kevin J.", ""], ["Choi", "Yejin", ""], ["Marcu", "Daniel", ""]]}, {"id": "1712.03512", "submitter": "Vladimir Bochkarev", "authors": "Inna A. Belashova and Vladimir V. Bochkarev", "title": "Comparative analysis of criteria for filtering time series of word usage\n  frequencies", "comments": "10 pages, 4 figures. This report was presented at ITISE 2017\n  (International work-conference on Time Series), September 18-20th 2017,\n  Granada, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method of nonlinear wavelet thresholding of time\nseries. The Ramachandran-Ranganathan runs test is used to assess the quality of\napproximation. To minimize the objective function, it is proposed to use\ngenetic algorithms - one of the stochastic optimization methods. The suggested\nmethod is tested both on the model series and on the word frequency series\nusing the Google Books Ngram data. It is shown that method of filtering which\nuses the runs criterion shows significantly better results compared with the\nstandard wavelet thresholding. The method can be used when quality of filtering\nis of primary importance but not the speed of calculations.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 12:04:19 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Belashova", "Inna A.", ""], ["Bochkarev", "Vladimir V.", ""]]}, {"id": "1712.03538", "submitter": "Adrian Benton", "authors": "Adrian Benton, Margaret Mitchell, Dirk Hovy", "title": "Multi-Task Learning for Mental Health using Social Media Text", "comments": null, "journal-ref": "Proceedings of the 15th Conference of the EACL (2017) 152-162", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce initial groundwork for estimating suicide risk and mental health\nin a deep learning framework. By modeling multiple conditions, the system\nlearns to make predictions about suicide risk and mental health at a low false\npositive rate. Conditions are modeled as tasks in a multi-task learning (MTL)\nframework, with gender prediction as an additional auxiliary task. We\ndemonstrate the effectiveness of multi-task learning by comparison to a\nwell-tuned single-task baseline with the same number of parameters. Our best\nMTL model predicts potential suicide attempt, as well as the presence of\natypical mental health, with AUC > 0.8. We also find additional large\nimprovements using multi-task learning on mental health tasks with limited\ntraining data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 14:27:26 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Benton", "Adrian", ""], ["Mitchell", "Margaret", ""], ["Hovy", "Dirk", ""]]}, {"id": "1712.03547", "submitter": "Chandrahas Dewangan", "authors": "Chandrahas and Tathagata Sengupta and Cibi Pragadeesh and Partha\n  Pratim Talukdar", "title": "Inducing Interpretability in Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inducing interpretability in KG embeddings.\nSpecifically, we explore the Universal Schema (Riedel et al., 2013) and propose\na method to induce interpretability. There have been many vector space models\nproposed for the problem, however, most of these methods don't address the\ninterpretability (semantics) of individual dimensions. In this work, we study\nthis problem and propose a method for inducing interpretability in KG\nembeddings using entity co-occurrence statistics. The proposed method\nsignificantly improves the interpretability, while maintaining comparable\nperformance in other KG tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 15:02:05 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Chandrahas", "", ""], ["Sengupta", "Tathagata", ""], ["Pragadeesh", "Cibi", ""], ["Talukdar", "Partha Pratim", ""]]}, {"id": "1712.03556", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Yelong Shen, Kevin Duh and Jianfeng Gao", "title": "Stochastic Answer Networks for Machine Reading Comprehension", "comments": "11 pages, 5 figures, Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet robust stochastic answer network (SAN) that simulates\nmulti-step reasoning in machine reading comprehension. Compared to previous\nwork such as ReasoNet which used reinforcement learning to determine the number\nof steps, the unique feature is the use of a kind of stochastic prediction\ndropout on the answer module (final layer) of the neural network during the\ntraining. We show that this simple trick improves robustness and achieves\nresults competitive to the state-of-the-art on the Stanford Question Answering\nDataset (SQuAD), the Adversarial SQuAD, and the Microsoft MAchine Reading\nCOmprehension Dataset (MS MARCO).\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 16:28:33 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 05:51:47 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Liu", "Xiaodong", ""], ["Shen", "Yelong", ""], ["Duh", "Kevin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1712.03609", "submitter": "Shimi Salant", "authors": "Shimi Salant, Jonathan Berant", "title": "Contextualized Word Representations for Reading Comprehension", "comments": "6 pages, 1 figure, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading a document and extracting an answer to a question about its content\nhas attracted substantial attention recently. While most work has focused on\nthe interaction between the question and the document, in this work we evaluate\nthe importance of context when the question and document are processed\nindependently. We take a standard neural architecture for this task, and show\nthat by providing rich contextualized word representations from a large\npre-trained language model as well as allowing the model to choose between\ncontext-dependent and context-independent word representations, we can obtain\ndramatic improvements and reach performance comparable to state-of-the-art on\nthe competitive SQuAD dataset.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 23:16:02 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 22:13:12 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 20:25:15 GMT"}, {"version": "v4", "created": "Tue, 4 Sep 2018 08:20:26 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Salant", "Shimi", ""], ["Berant", "Jonathan", ""]]}, {"id": "1712.03645", "submitter": "Kumiko Tanaka-Ishii", "authors": "Kumiko Tanaka-Ishii", "title": "Long-Range Correlation Underlying Childhood Language and Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-range correlation, a property of time series exhibiting long-term\nmemory, is mainly studied in the statistical physics domain and has been\nreported to exist in natural language. Using a state-of-the-art method for such\nanalysis, long-range correlation is first shown to occur in long CHILDES data\nsets. To understand why, Bayesian generative models of language, originally\nproposed in the cognitive scientific domain, are investigated. Among\nrepresentative models, the Simon model was found to exhibit surprisingly good\nlong-range correlation, but not the Pitman-Yor model. Since the Simon model is\nknown not to correctly reflect the vocabulary growth of natural language, a\nsimple new model is devised as a conjunct of the Simon and Pitman-Yor models,\nsuch that long-range correlation holds with a correct vocabulary growth rate.\nThe investigation overall suggests that uniform sampling is one cause of\nlong-range correlation and could thus have a relation with actual linguistic\nprocesses.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 04:48:43 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Tanaka-Ishii", "Kumiko", ""]]}, {"id": "1712.03665", "submitter": "Ying Zeng", "authors": "Ying Zeng, Yansong Feng, Rong Ma, Zheng Wang, Rui Yan, Chongde Shi,\n  Dongyan Zhao", "title": "Scale Up Event Extraction Learning via Automatic Training Data\n  Generation", "comments": "8 pages, accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of event extraction has long been investigated in a supervised\nlearning paradigm, which is bound by the number and the quality of the training\ninstances. Existing training data must be manually generated through a\ncombination of expert domain knowledge and extensive human involvement.\nHowever, due to drastic efforts required in annotating text, the resultant\ndatasets are usually small, which severally affects the quality of the learned\nmodel, making it hard to generalize. Our work develops an automatic approach\nfor generating training data for event extraction. Our approach allows us to\nscale up event extraction training instances from thousands to hundreds of\nthousands, and it does this at a much lower cost than a manual approach. We\nachieve this by employing distant supervision to automatically create event\nannotations from unlabelled text using existing structured knowledge bases or\ntables.We then develop a neural network model with post inference to transfer\nthe knowledge extracted from structured knowledge bases to automatically\nannotate typed events with corresponding arguments in text.We evaluate our\napproach by using the knowledge extracted from Freebase to label texts from\nWikipedia articles. Experimental results show that our approach can generate a\nlarge number of high quality training instances. We show that this large volume\nof training data not only leads to a better event extractor, but also allows us\nto detect multiple typed events.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 07:41:28 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Zeng", "Ying", ""], ["Feng", "Yansong", ""], ["Ma", "Rong", ""], ["Wang", "Zheng", ""], ["Yan", "Rui", ""], ["Shi", "Chongde", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1712.03897", "submitter": "Kenneth Leidal", "authors": "Kenneth Leidal, David Harwath, and James Glass", "title": "Learning Modality-Invariant Representations for Speech and Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the unsupervised learning of a semantic embedding\nspace for co-occurring sensory inputs. Specifically, we focus on the task of\nlearning a semantic vector space for both spoken and handwritten digits using\nthe TIDIGITs and MNIST datasets. Current techniques encode image and\naudio/textual inputs directly to semantic embeddings. In contrast, our\ntechnique maps an input to the mean and log variance vectors of a diagonal\nGaussian from which sample semantic embeddings are drawn. In addition to\nencouraging semantic similarity between co-occurring inputs,our loss function\nincludes a regularization term borrowed from variational autoencoders (VAEs)\nwhich drives the posterior distributions over embeddings to be unit Gaussian.\nWe can use this regularization term to filter out modality information while\npreserving semantic information. We speculate this technique may be more\nbroadly applicable to other areas of cross-modality/domain information\nretrieval and transfer learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:18:34 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Leidal", "Kenneth", ""], ["Harwath", "David", ""], ["Glass", "James", ""]]}, {"id": "1712.03903", "submitter": "Dan Liu", "authors": "Dan Liu, Ching Yee Suen, Olga Ormandjieva", "title": "A Novel Way of Identifying Cyber Predators", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks with Long Short-Term Memory cell (LSTM-RNN) have\nimpressive ability in sequence data processing, particularly for language model\nbuilding and text classification. This research proposes the combination of\nsentiment analysis, new approach of sentence vectors and LSTM-RNN as a novel\nway for Sexual Predator Identification (SPI). LSTM-RNN language model is\napplied to generate sentence vectors which are the last hidden states in the\nlanguage model. Sentence vectors are fed into another LSTM-RNN classifier, so\nas to capture suspicious conversations. Hidden state enables to generate\nvectors for sentences never seen before. Fasttext is used to filter the\ncontents of conversations and generate a sentiment score so as to identify\npotential predators. The experiment achieves a record-breaking accuracy and\nprecision of 100% with recall of 81.10%, exceeding the top-ranked result in the\nSPI competition.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:24:13 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Liu", "Dan", ""], ["Suen", "Ching Yee", ""], ["Ormandjieva", "Olga", ""]]}, {"id": "1712.03935", "submitter": "Gaurav Bhatt", "authors": "Gaurav Bhatt, Aman Sharma, Shivam Sharma, Ankush Nagpal,\n  Balasubramanian Raman, and Ankush Mittal", "title": "On the Benefit of Combining Neural, Statistical and External Features\n  for Fake News Identification", "comments": "Source code available at - www.deeplearn-ai.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the veracity of a news article is an interesting problem while\nautomating this process can be a challenging task. Detection of a news article\nas fake is still an open question as it is contingent on many factors which the\ncurrent state-of-the-art models fail to incorporate. In this paper, we explore\na subtask to fake news identification, and that is stance detection. Given a\nnews article, the task is to determine the relevance of the body and its claim.\nWe present a novel idea that combines the neural, statistical and external\nfeatures to provide an efficient solution to this problem. We compute the\nneural embedding from the deep recurrent model, statistical features from the\nweighted n-gram bag-of-words model and handcrafted external features with the\nhelp of feature engineering heuristics. Finally, using deep neural layer all\nthe features are combined, thereby classifying the headline-body news pair as\nagree, disagree, discuss, or unrelated. We compare our proposed technique with\nthe current state-of-the-art models on the fake news challenge dataset. Through\nextensive experiments, we find that the proposed model outperforms all the\nstate-of-the-art techniques including the submissions to the fake news\nchallenge.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:32:11 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Bhatt", "Gaurav", ""], ["Sharma", "Aman", ""], ["Sharma", "Shivam", ""], ["Nagpal", "Ankush", ""], ["Raman", "Balasubramanian", ""], ["Mittal", "Ankush", ""]]}, {"id": "1712.04034", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Shang-Wen Li, Jin Cao, Jared Casale, Peter\n  Henderson, David Whitney, Alborz Geramifard", "title": "Learning Robust Dialog Policies in Noisy Environments", "comments": "1st Workshop on Conversational AI at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern virtual personal assistants provide a convenient interface for\ncompleting daily tasks via voice commands. An important consideration for these\nassistants is the ability to recover from automatic speech recognition (ASR)\nand natural language understanding (NLU) errors. In this paper, we focus on\nlearning robust dialog policies to recover from these errors. To this end, we\ndevelop a user simulator which interacts with the assistant through voice\ncommands in realistic scenarios with noisy audio, and use it to learn dialog\npolicies through deep reinforcement learning. We show that dialogs generated by\nour simulator are indistinguishable from human generated dialogs, as determined\nby human evaluators. Furthermore, preliminary experimental results show that\nthe learned policies in noisy environments achieve the same execution success\nrate with fewer dialog turns compared to fixed rule-based policies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 21:22:01 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Li", "Shang-Wen", ""], ["Cao", "Jin", ""], ["Casale", "Jared", ""], ["Henderson", "Peter", ""], ["Whitney", "David", ""], ["Geramifard", "Alborz", ""]]}, {"id": "1712.04046", "submitter": "Jason Poulos", "authors": "Jason Poulos and Rafael Valle", "title": "Character-Based Handwritten Text Transcription with Attention Networks", "comments": null, "journal-ref": null, "doi": "10.1007/s00521-021-05813-1", "report-no": null, "categories": "cs.CV cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper approaches the task of handwritten text recognition (HTR) with\nattentional encoder-decoder networks trained on sequences of characters, rather\nthan words. We experiment on lines of text from popular handwriting datasets\nand compare different activation functions for the attention mechanism used for\naligning image pixels and target characters. We find that softmax attention\nfocuses heavily on individual characters, while sigmoid attention focuses on\nmultiple characters at each step of the decoding. When the sequence alignment\nis one-to-one, softmax attention is able to learn a more precise alignment at\neach step of the decoding, whereas the alignment generated by sigmoid attention\nis much less precise. When a linear function is used to obtain attention\nweights, the model predicts a character by looking at the entire sequence of\ncharacters and performs poorly because it lacks a precise alignment between the\nsource and target. Future research may explore HTR in natural scene images,\nsince the model is capable of transcribing handwritten text without the need\nfor producing segmentations or bounding boxes of text in images.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 21:57:03 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 19:33:31 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 17:00:03 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Poulos", "Jason", ""], ["Valle", "Rafael", ""]]}, {"id": "1712.04048", "submitter": "Hao Zhang", "authors": "Hao Zhang, Shizhen Xu, Graham Neubig, Wei Dai, Qirong Ho, Guangwen\n  Yang, Eric P. Xing", "title": "Cavs: A Vertex-centric Programming Interface for Dynamic Neural Networks", "comments": "Short versions of this paper were presented at AISys workshop@SOSP\n  2017 and MLSys workshop@NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning (DL) models have moved beyond static network\narchitectures to dynamic ones, handling data where the network structure\nchanges every example, such as sequences of variable lengths, trees, and\ngraphs. Existing dataflow-based programming models for DL---both static and\ndynamic declaration---either cannot readily express these dynamic models, or\nare inefficient due to repeated dataflow graph construction and processing, and\ndifficulties in batched execution. We present Cavs, a vertex-centric\nprogramming interface and optimized system implementation for dynamic DL\nmodels. Cavs represents dynamic network structure as a static vertex function\n$\\mathcal{F}$ and a dynamic instance-specific graph $\\mathcal{G}$, and performs\nbackpropagation by scheduling the execution of $\\mathcal{F}$ following the\ndependencies in $\\mathcal{G}$. Cavs bypasses expensive graph construction and\npreprocessing overhead, allows for the use of static graph optimization\ntechniques on pre-defined operations in $\\mathcal{F}$, and naturally exposes\nbatched execution opportunities over different graphs. Experiments comparing\nCavs to two state-of-the-art frameworks for dynamic NNs (TensorFlow Fold and\nDyNet) demonstrate the efficacy of this approach: Cavs achieves a near one\norder of magnitude speedup on training of various dynamic NN architectures, and\nablations demonstrate the contribution of our proposed batching and memory\nmanagement strategies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 22:04:39 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Zhang", "Hao", ""], ["Xu", "Shizhen", ""], ["Neubig", "Graham", ""], ["Dai", "Wei", ""], ["Ho", "Qirong", ""], ["Yang", "Guangwen", ""], ["Xing", "Eric P.", ""]]}, {"id": "1712.04116", "submitter": "Peixian Chen", "authors": "Peixian Chen, Zhourong Chen and Nevin L. Zhang", "title": "A Novel Document Generation Process for Topic Detection based on\n  Hierarchical Latent Tree Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel document generation process based on hierarchical latent\ntree models (HLTMs) learned from data. An HLTM has a layer of observed word\nvariables at the bottom and multiple layers of latent variables on top. For\neach document, we first sample values for the latent variables layer by layer\nvia logic sampling, then draw relative frequencies for the words conditioned on\nthe values of the latent variables, and finally generate words for the document\nusing the relative word frequencies. The motivation for the work is to take\nword counts into consideration with HLTMs. In comparison with LDA-based\nhierarchical document generation processes, the new process achieves\ndrastically better model fit with much fewer parameters. It also yields more\nmeaningful topics and topic hierarchies. It is the new state-of-the-art for the\nhierarchical topic detection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 04:07:10 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 02:46:02 GMT"}, {"version": "v3", "created": "Fri, 28 Jun 2019 03:15:45 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Chen", "Peixian", ""], ["Chen", "Zhourong", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1712.04158", "submitter": "Xihu Zhang", "authors": "Xihu Zhang, Chu Wei and Hai Zhao", "title": "Tracing a Loose Wordhood for Chinese Input Method Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese input methods are used to convert pinyin sequence or other Latin\nencoding systems into Chinese character sentences. For more effective\npinyin-to-character conversion, typical Input Method Engines (IMEs) rely on a\npredefined vocabulary that demands manually maintenance on schedule. For the\npurpose of removing the inconvenient vocabulary setting, this work focuses on\nautomatic wordhood acquisition by fully considering that Chinese inputting is a\nfree human-computer interaction procedure. Instead of strictly defining words,\na loose word likelihood is introduced for measuring how likely a character\nsequence can be a user-recognized word with respect to using IME. Then an\nonline algorithm is proposed to adjust the word likelihood or generate new\nwords by comparing user true choice for inputting and the algorithm prediction.\nThe experimental results show that the proposed solution can agilely adapt to\ndiverse typings and demonstrate performance approaching highly-optimized IME\nwith fixed vocabulary.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:03:17 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Zhang", "Xihu", ""], ["Wei", "Chu", ""], ["Zhao", "Hai", ""]]}, {"id": "1712.04313", "submitter": "Laurent Besacier", "authors": "Ewan Dunbar, Xuan Nga Cao, Juan Benjumea, Julien Karadayi, Mathieu\n  Bernard, Laurent Besacier, Xavier Anguera, Emmanuel Dupoux", "title": "The Zero Resource Speech Challenge 2017", "comments": "IEEE ASRU (Automatic Speech Recognition and Understanding) 2017.\n  Okinawa, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe a new challenge aimed at discovering subword and word units from\nraw speech. This challenge is the followup to the Zero Resource Speech\nChallenge 2015. It aims at constructing systems that generalize across\nlanguages and adapt to new speakers. The design features and evaluation metrics\nof the challenge are presented and the results of seventeen models are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:36:15 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Dunbar", "Ewan", ""], ["Cao", "Xuan Nga", ""], ["Benjumea", "Juan", ""], ["Karadayi", "Julien", ""], ["Bernard", "Mathieu", ""], ["Besacier", "Laurent", ""], ["Anguera", "Xavier", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1712.04314", "submitter": "Yuri G. Gordienko", "authors": "Serhii Hamotskyi, Sergii Stirenko, Yuri Gordienko, Anis Rojbi", "title": "Generating and Estimating Nonverbal Alphabets for Situated and\n  Multimodal Communications", "comments": "5 pages, 5 figures", "journal-ref": "International Journal of Systems Applications Engineering and\n  Development, 11, 232-236 (2017)", "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the formalized approach for generating and\nestimating symbols (and alphabets), which can be communicated by the wide range\nof non-verbal means based on specific user requirements (medium, priorities,\ntype of information that needs to be conveyed). The short characterization of\nbasic terms and parameters of such symbols (and alphabets) with approaches to\ngenerate them are given. Then the framework, experimental setup, and some\nmachine learning methods to estimate usefulness and effectiveness of the\nnonverbal alphabets and systems are presented. The previous results demonstrate\nthat usage of multimodal data sources (like wearable accelerometer, heart\nmonitor, muscle movements sensors, braincomputer interface) along with machine\nlearning approaches can provide the deeper understanding of the usefulness and\neffectiveness of such alphabets and systems for nonverbal and situated\ncommunication. The symbols (and alphabets) generated and estimated by such\nmethods may be useful in various applications: from synthetic languages and\nconstructed scripts to multimodal nonverbal and situated interaction between\npeople and artificial intelligence systems through Human-Computer Interfaces,\nsuch as mouse gestures, touchpads, body gestures, eyetracking cameras,\nwearables, and brain-computing interfaces, especially in applications for\nelderly care and people with disabilities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:38:34 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Hamotskyi", "Serhii", ""], ["Stirenko", "Sergii", ""], ["Gordienko", "Yuri", ""], ["Rojbi", "Anis", ""]]}, {"id": "1712.04708", "submitter": "Maksim Kretov", "authors": "Vlad Zhukov and Eugene Golikov and Maksim Kretov", "title": "Differentiable lower bound for expected BLEU score", "comments": "Presented at NIPS 2017 Workshop on Conversational AI: Today's\n  Practice and Tomorrow's Potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing tasks performance of the models is often\nmeasured with some non-differentiable metric, such as BLEU score. To use\nefficient gradient-based methods for optimization, it is a common workaround to\noptimize some surrogate loss function. This approach is effective if\noptimization of such loss also results in improving target metric. The\ncorresponding problem is referred to as loss-evaluation mismatch. In the\npresent work we propose a method for calculation of differentiable lower bound\nof expected BLEU score that does not involve computationally expensive sampling\nprocedure such as the one required when using REINFORCE rule from reinforcement\nlearning (RL) framework.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 11:17:37 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 11:28:57 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 08:55:07 GMT"}, {"version": "v4", "created": "Thu, 23 Aug 2018 12:37:42 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhukov", "Vlad", ""], ["Golikov", "Eugene", ""], ["Kretov", "Maksim", ""]]}, {"id": "1712.04753", "submitter": "Karttikeya Mangalam", "authors": "Karttikeya Mangalam, Tanaya Guha", "title": "Learning Spontaneity to Improve Emotion Recognition In Speech", "comments": "Accepted at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.HC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect and usefulness of spontaneity (i.e. whether a given\nspeech is spontaneous or not) in speech in the context of emotion recognition.\nWe hypothesize that emotional content in speech is interrelated with its\nspontaneity, and use spontaneity classification as an auxiliary task to the\nproblem of emotion recognition. We propose two supervised learning settings\nthat utilize spontaneity to improve speech emotion recognition: a hierarchical\nmodel that performs spontaneity detection before performing emotion\nrecognition, and a multitask learning model that jointly learns to recognize\nboth spontaneity and emotion. Through various experiments on the well known\nIEMOCAP database, we show that by using spontaneity detection as an additional\ntask, significant improvement can be achieved over emotion recognition systems\nthat are unaware of spontaneity. We achieve state-of-the-art emotion\nrecognition accuracy (4-class, 69.1%) on the IEMOCAP database outperforming\nseveral relevant and competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:30:27 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 01:15:38 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 18:58:29 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Mangalam", "Karttikeya", ""], ["Guha", "Tanaya", ""]]}, {"id": "1712.04762", "submitter": "Himank Yadav", "authors": "Himank Yadav, Juliang Li", "title": "Social Media Writing Style Fingerprint", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our approach for computer-aided social media text authorship\nattribution based on recent advances in short text authorship verification. We\nuse various natural language techniques to create word-level and\ncharacter-level models that act as hidden layers to simulate a simple neural\nnetwork. The choice of word-level and character-level models in each layer was\ninformed through validation performance. The output layer of our system uses an\nunweighted majority vote vector to arrive at a conclusion. We also considered\nwriting bias in social media posts while collecting our training dataset to\nincrease system robustness. Our system achieved a precision, recall, and\nF-measure of 0.82, 0.926 and 0.869 respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 20:03:22 GMT"}, {"version": "v2", "created": "Sat, 16 Dec 2017 12:03:18 GMT"}, {"version": "v3", "created": "Tue, 26 Dec 2017 15:53:42 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Yadav", "Himank", ""], ["Li", "Juliang", ""]]}, {"id": "1712.04787", "submitter": "Ingmar Steiner", "authors": "Ingmar Steiner, S\\'ebastien Le Maguer", "title": "Creating New Language and Voice Components for the Updated MaryTTS\n  Text-to-Speech Synthesis Platform", "comments": null, "journal-ref": "Proc. LREC 11 (2018) 3171-3175", "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a new workflow to create components for the MaryTTS text-to-speech\nsynthesis platform, which is popular with researchers and developers, extending\nit to support new languages and custom synthetic voices. This workflow replaces\nthe previous toolkit with an efficient, flexible process that leverages modern\nbuild automation and cloud-hosted infrastructure. Moreover, it is compatible\nwith the updated MaryTTS architecture, enabling new features and\nstate-of-the-art paradigms such as synthesis based on deep neural networks\n(DNNs). Like MaryTTS itself, the new tools are free, open source software\n(FOSS), and promote the use of open data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 14:29:09 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 09:23:11 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Steiner", "Ingmar", ""], ["Maguer", "S\u00e9bastien Le", ""]]}, {"id": "1712.04798", "submitter": "Ingmar Steiner", "authors": "Arif Khan, Ingmar Steiner, Yusuke Sugano, Andreas Bulling, Ross\n  Macdonald", "title": "A Multimodal Corpus of Expert Gaze and Behavior during Phonetic\n  Segmentation Tasks", "comments": null, "journal-ref": "Proc. LREC 11 (2018) 4277-4281", "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Phonetic segmentation is the process of splitting speech into distinct\nphonetic units. Human experts routinely perform this task manually by analyzing\nauditory and visual cues using analysis software, which is an extremely\ntime-consuming process. Methods exist for automatic segmentation, but these are\nnot always accurate enough. In order to improve automatic segmentation, we need\nto model it as close to the manual segmentation as possible. This corpus is an\neffort to capture the human segmentation behavior by recording experts\nperforming a segmentation task. We believe that this data will enable us to\nhighlight the important aspects of manual segmentation, which can be used in\nautomatic segmentation to improve its accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 14:45:29 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 14:57:09 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 07:22:56 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Khan", "Arif", ""], ["Steiner", "Ingmar", ""], ["Sugano", "Yusuke", ""], ["Bulling", "Andreas", ""], ["Macdonald", "Ross", ""]]}, {"id": "1712.04853", "submitter": "Sariya Karimova", "authors": "Sariya Karimova, Patrick Simianer and Stefan Riezler (Heidelberg\n  University)", "title": "A User-Study on Online Adaptation of Neural Machine Translation to Human\n  Post-Edits", "comments": "Accepted at Machine Translation Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advantages of neural machine translation (NMT) have been extensively\nvalidated for offline translation of several language pairs for different\ndomains of spoken and written language. However, research on interactive\nlearning of NMT by adaptation to human post-edits has so far been confined to\nsimulation experiments. We present the first user study on online adaptation of\nNMT to user post-edits in the domain of patent translation. Our study involves\n29 human subjects (translation students) whose post-editing effort and\ntranslation quality were measured on about 4,500 interactions of a human\npost-editor and a machine translation system integrating an online adaptive\nlearning algorithm. Our experimental results show a significant reduction of\nhuman post-editing effort due to online adaptation in NMT according to several\nevaluation metrics, including hTER, hBLEU, and KSMR. Furthermore, we found\nsignificant improvements in BLEU/TER between NMT outputs and professional\ntranslations in granted patents, providing further evidence for the advantages\nof online adaptive NMT in an interactive setup.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 16:41:08 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 15:08:40 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 12:32:29 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Karimova", "Sariya", "", "Heidelberg\n  University"], ["Simianer", "Patrick", "", "Heidelberg\n  University"], ["Riezler", "Stefan", "", "Heidelberg\n  University"]]}, {"id": "1712.05128", "submitter": "Alexandre Rademaker", "authors": "Pedro Delfino and Bruno Cuconato and Edward Hermann Haeusler and\n  Alexandre Rademaker", "title": "Passing the Brazilian OAB Exam: data preparation and some experiments", "comments": "Extended version of the paper published in the Proceedings of JURIX\n  2017 (http://ebooks.iospress.nl/ISBN/978-1-61499-838-9)", "journal-ref": "Legal Knowledge and Information Systems 302 (2017) 89-94", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In Brazil, all legal professionals must demonstrate their knowledge of the\nlaw and its application by passing the OAB exams, the national bar exams. The\nOAB exams therefore provide an excellent benchmark for the performance of legal\ninformation systems since passing the exam would arguably signal that the\nsystem has acquired capacity of legal reasoning comparable to that of a human\nlawyer. This article describes the construction of a new data set and some\npreliminary experiments on it, treating the problem of finding the\njustification for the answers to questions. The results provide a baseline\nperformance measure against which to evaluate future improvements. We discuss\nthe reasons to the poor performance and propose next steps.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 08:40:10 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Delfino", "Pedro", ""], ["Cuconato", "Bruno", ""], ["Haeusler", "Edward Hermann", ""], ["Rademaker", "Alexandre", ""]]}, {"id": "1712.05181", "submitter": "Nick Pawlowski", "authors": "Tom Bocklisch, Joey Faulkner, Nick Pawlowski, Alan Nichol", "title": "Rasa: Open Source Language Understanding and Dialogue Management", "comments": "Presented at NIPS Workshop on Conversational AI, Code at\n  https://github.com/RasaHQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source\npython libraries for building conversational software. Their purpose is to make\nmachine-learning based dialogue management and language understanding\naccessible to non-specialist software developers. In terms of design\nphilosophy, we aim for ease of use, and bootstrapping from minimal (or no)\ninitial training data. Both packages are extensively documented and ship with a\ncomprehensive suite of tests. The code is available at\nhttps://github.com/RasaHQ/\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 11:37:18 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 09:33:11 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Bocklisch", "Tom", ""], ["Faulkner", "Joey", ""], ["Pawlowski", "Nick", ""], ["Nichol", "Alan", ""]]}, {"id": "1712.05191", "submitter": "Sachin Pawar", "authors": "Sachin Pawar, Girish K. Palshikar, Pushpak Bhattacharyya", "title": "Relation Extraction : A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the Internet, large amount of digital text is generated\neveryday in the form of news articles, research publications, blogs, question\nanswering forums and social media. It is important to develop techniques for\nextracting information automatically from these documents, as lot of important\ninformation is hidden within them. This extracted information can be used to\nimprove access and management of knowledge hidden in large text corpora.\nSeveral applications such as Question Answering, Information Retrieval would\nbenefit from this information. Entities like persons and organizations, form\nthe most basic unit of the information. Occurrences of entities in a sentence\nare often linked through well-defined relations; e.g., occurrences of person\nand organization in a sentence may be linked through relations such as employed\nat. The task of Relation Extraction (RE) is to identify such relations\nautomatically. In this paper, we survey several important supervised,\nsemi-supervised and unsupervised RE techniques. We also cover the paradigms of\nOpen Information Extraction (OIE) and Distant Supervision. Finally, we describe\nsome of the recent trends in the RE techniques and possible future research\ndirections. This survey would be useful for three kinds of readers - i)\nNewcomers in the field who want to quickly learn about RE; ii) Researchers who\nwant to know how the various RE techniques evolved over time and what are\npossible future research directions and iii) Practitioners who just need to\nknow which RE technique works best in various settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:04:10 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Pawar", "Sachin", ""], ["Palshikar", "Girish K.", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1712.05382", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu and Colin Raffel", "title": "Monotonic Chunkwise Attention", "comments": "ICLR camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models with soft attention have been successfully\napplied to a wide variety of problems, but their decoding process incurs a\nquadratic time and space cost and is inapplicable to real-time sequence\ntransduction. To address these issues, we propose Monotonic Chunkwise Attention\n(MoChA), which adaptively splits the input sequence into small chunks over\nwhich soft attention is computed. We show that models utilizing MoChA can be\ntrained efficiently with standard backpropagation while allowing online and\nlinear-time decoding at test time. When applied to online speech recognition,\nwe obtain state-of-the-art results and match the performance of a model using\nan offline soft attention mechanism. In document summarization experiments\nwhere we do not expect monotonic alignments, we show significantly improved\nperformance compared to a baseline monotonic attention-based model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 18:29:42 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 01:35:36 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Raffel", "Colin", ""]]}, {"id": "1712.05403", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "Learning to Attend via Word-Aspect Associative Fusion for Aspect-based\n  Sentiment Analysis", "comments": "Accepted to AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) tries to predict the polarity of a\ngiven document with respect to a given aspect entity. While neural network\narchitectures have been successful in predicting the overall polarity of\nsentences, aspect-specific sentiment analysis still remains as an open problem.\nIn this paper, we propose a novel method for integrating aspect information\ninto the neural model. More specifically, we incorporate aspect information\ninto the neural model by modeling word-aspect relationships. Our novel model,\n\\textit{Aspect Fusion LSTM} (AF-LSTM) learns to attend based on associative\nrelationships between sentence words and aspect which allows our model to\nadaptively focus on the correct words given an aspect term. This ameliorates\nthe flaws of other state-of-the-art models that utilize naive concatenations to\nmodel word-aspect similarity. Instead, our model adopts circular convolution\nand circular correlation to model the similarity between aspect and words and\nelegantly incorporates this within a differentiable neural attention framework.\nFinally, our model is end-to-end differentiable and highly related to\nconvolution-correlation (holographic like) memories. Our proposed neural model\nachieves state-of-the-art performance on benchmark datasets, outperforming\nATAE-LSTM by $4\\%-5\\%$ on average across multiple datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:46:44 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1712.05483", "submitter": "Alexander Rosenberg Johansen", "authors": "Alexander Rosenberg Johansen and Richard Socher", "title": "Learning when to skim and when to read", "comments": "8 pages (4 article, 1 references, 3 appendix), 11 figures, 3 tables,\n  published at ACL2017 workshop Repl4NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent advances in deep learning for natural language processing have\ncome at increasing computational cost, but the power of these state-of-the-art\nmodels is not needed for every example in a dataset. We demonstrate two\napproaches to reducing unnecessary computation in cases where a fast but weak\nbaseline classier and a stronger, slower model are both available. Applying an\nAUC-based metric to the task of sentiment classification, we find significant\nefficiency gains with both a probability-threshold method for reducing\ncomputational cost and one that uses a secondary decision network.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 00:12:47 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Johansen", "Alexander Rosenberg", ""], ["Socher", "Richard", ""]]}, {"id": "1712.05558", "submitter": "Nikita Kitaev", "authors": "Jin-Hwa Kim, Nikita Kitaev, Xinlei Chen, Marcus Rohrbach, Byoung-Tak\n  Zhang, Yuandong Tian, Dhruv Batra, Devi Parikh", "title": "CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven\n  Communication", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a goal-driven collaborative task that combines\nlanguage, perception, and action. Specifically, we develop a Collaborative\nimage-Drawing game between two agents, called CoDraw. Our game is grounded in a\nvirtual world that contains movable clip art objects. The game involves two\nplayers: a Teller and a Drawer. The Teller sees an abstract scene containing\nmultiple clip art pieces in a semantically meaningful configuration, while the\nDrawer tries to reconstruct the scene on an empty canvas using available clip\nart pieces. The two players communicate with each other using natural language.\nWe collect the CoDraw dataset of ~10K dialogs consisting of ~138K messages\nexchanged between human players. We define protocols and metrics to evaluate\nlearned agents in this testbed, highlighting the need for a novel \"crosstalk\"\nevaluation condition which pairs agents trained independently on disjoint\nsubsets of the training data. We present models for our task and benchmark them\nusing both fully automated evaluation and by having them play the game live\nwith humans.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 06:38:15 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 08:00:14 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:01:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Kitaev", "Nikita", ""], ["Chen", "Xinlei", ""], ["Rohrbach", "Marcus", ""], ["Zhang", "Byoung-Tak", ""], ["Tian", "Yuandong", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1712.05608", "submitter": "Sri Harsha Dumpala Mr", "authors": "Sri Harsha Dumpala, Rupayan Chakraborty, Sunil Kumar Kopparapu", "title": "A Novel Approach for Effective Learning in Low Resourced Scenarios", "comments": "Presented at NIPS 2017 Machine Learning for Audio Signal Processing\n  (ML4Audio) Workshop, Dec. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based discriminative methods, being the state-of-the-art\nmachine learning techniques, are ill-suited for learning from lower amounts of\ndata. In this paper, we propose a novel framework, called simultaneous two\nsample learning (s2sL), to effectively learn the class discriminative\ncharacteristics, even from very low amount of data. In s2sL, more than one\nsample (here, two samples) are simultaneously considered to both, train and\ntest the classifier. We demonstrate our approach for speech/music\ndiscrimination and emotion classification through experiments. Further, we also\nshow the effectiveness of s2sL approach for classification in low-resource\nscenario, and for imbalanced data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 10:33:57 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Dumpala", "Sri Harsha", ""], ["Chakraborty", "Rupayan", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1712.05626", "submitter": "Denis Fedorenko", "authors": "Denis Fedorenko, Nikita Smetanin, Artem Rodichev", "title": "Avoiding Echo-Responses in a Retrieval-Based Conversation System", "comments": null, "journal-ref": "In: Artificial Intelligence and Natural Language. AINL 2018. Vol\n  930. Springer", "doi": "10.1007/978-3-030-01204-5_9", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieval-based conversation systems generally tend to highly rank responses\nthat are semantically similar or even identical to the given conversation\ncontext. While the system's goal is to find the most appropriate response,\nrather than the most semantically similar one, this tendency results in\nlow-quality responses. We refer to this challenge as the echoing problem. To\nmitigate this problem, we utilize a hard negative mining approach at the\ntraining stage. The evaluation shows that the resulting model reduces echoing\nand achieves better results in terms of Average Precision and Recall@N metrics,\ncompared to the models trained without the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 11:32:29 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 10:42:57 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Fedorenko", "Denis", ""], ["Smetanin", "Nikita", ""], ["Rodichev", "Artem", ""]]}, {"id": "1712.05690", "submitter": "Tobias Domhan", "authors": "Felix Hieber, Tobias Domhan, Michael Denkowski, David Vilar, Artem\n  Sokolov, Ann Clifton, Matt Post", "title": "Sockeye: A Toolkit for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Sockeye (version 1.12), an open-source sequence-to-sequence\ntoolkit for Neural Machine Translation (NMT). Sockeye is a production-ready\nframework for training and applying models as well as an experimental platform\nfor researchers. Written in Python and built on MXNet, the toolkit offers\nscalable training and inference for the three most prominent encoder-decoder\narchitectures: attentional recurrent neural networks, self-attentional\ntransformers, and fully convolutional networks. Sockeye also supports a wide\nrange of optimizers, normalization and regularization techniques, and inference\nimprovements from current NMT literature. Users can easily run standard\ntraining recipes, explore different model settings, and incorporate new ideas.\nIn this paper, we highlight Sockeye's features and benchmark it against other\nNMT toolkits on two language arcs from the 2017 Conference on Machine\nTranslation (WMT): English-German and Latvian-English. We report competitive\nBLEU scores across all three architectures, including an overall best score for\nSockeye's transformer implementation. To facilitate further comparison, we\nrelease all system outputs and training scripts used in our experiments. The\nSockeye toolkit is free software released under the Apache 2.0 license.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 14:44:28 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 13:29:31 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Hieber", "Felix", ""], ["Domhan", "Tobias", ""], ["Denkowski", "Michael", ""], ["Vilar", "David", ""], ["Sokolov", "Artem", ""], ["Clifton", "Ann", ""], ["Post", "Matt", ""]]}, {"id": "1712.05785", "submitter": "Xingyou Song", "authors": "Jordan Prosky, Xingyou Song, Andrew Tan, Michael Zhao", "title": "Sentiment Predictability for Stocks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present our findings and experiments for stock-market\nprediction using various textual sentiment analysis tools, such as mood\nanalysis and event extraction, as well as prediction models, such as LSTMs and\nspecific convolutional architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 18:41:53 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 20:24:40 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Prosky", "Jordan", ""], ["Song", "Xingyou", ""], ["Tan", "Andrew", ""], ["Zhao", "Michael", ""]]}, {"id": "1712.05846", "submitter": "Denis Yarats", "authors": "Denis Yarats, Mike Lewis", "title": "Hierarchical Text Generation and Planning for Strategic Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models for goal-orientated dialogue are challenging to train,\nbecause linguistic and strategic aspects are entangled in latent state vectors.\nWe introduce an approach to learning representations of messages in dialogues\nby maximizing the likelihood of subsequent sentences and actions, which\ndecouples the semantics of the dialogue utterance from its linguistic\nrealization. We then use these latent sentence representations for hierarchical\nlanguage generation, planning and reinforcement learning. Experiments show that\nour approach increases the end-task reward achieved by the model, improves the\neffectiveness of long-term planning using rollouts, and allows self-play\nreinforcement learning to improve decision making without diverging from human\nlanguage. Our hierarchical latent-variable model outperforms previous work both\nlinguistically and strategically.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 21:33:07 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 21:15:01 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Yarats", "Denis", ""], ["Lewis", "Mike", ""]]}, {"id": "1712.05884", "submitter": "Jonathan Shen", "authors": "Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep\n  Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan,\n  Rif A. Saurous, Yannis Agiomyrgiannakis, Yonghui Wu", "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram\n  Predictions", "comments": "Accepted to ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Tacotron 2, a neural network architecture for speech\nsynthesis directly from text. The system is composed of a recurrent\nsequence-to-sequence feature prediction network that maps character embeddings\nto mel-scale spectrograms, followed by a modified WaveNet model acting as a\nvocoder to synthesize timedomain waveforms from those spectrograms. Our model\nachieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for\nprofessionally recorded speech. To validate our design choices, we present\nablation studies of key components of our system and evaluate the impact of\nusing mel spectrograms as the input to WaveNet instead of linguistic, duration,\nand $F_0$ features. We further demonstrate that using a compact acoustic\nintermediate representation enables significant simplification of the WaveNet\narchitecture.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 00:51:40 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 01:28:23 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Shen", "Jonathan", ""], ["Pang", "Ruoming", ""], ["Weiss", "Ron J.", ""], ["Schuster", "Mike", ""], ["Jaitly", "Navdeep", ""], ["Yang", "Zongheng", ""], ["Chen", "Zhifeng", ""], ["Zhang", "Yu", ""], ["Wang", "Yuxuan", ""], ["Skerry-Ryan", "RJ", ""], ["Saurous", "Rif A.", ""], ["Agiomyrgiannakis", "Yannis", ""], ["Wu", "Yonghui", ""]]}, {"id": "1712.05898", "submitter": "Yifan Peng", "authors": "Yifan Peng and Xiaosong Wang and Le Lu and Mohammadhadi Bagheri and\n  Ronald Summers and Zhiyong Lu", "title": "NegBio: a high-performance tool for negation and uncertainty detection\n  in radiology reports", "comments": "Final version. Accepted for publication in AMIA 2018 Informatics\n  Summit. 9 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative and uncertain medical findings are frequent in radiology reports,\nbut discriminating them from positive findings remains challenging for\ninformation extraction. Here, we propose a new algorithm, NegBio, to detect\nnegative and uncertain findings in radiology reports. Unlike previous\nrule-based methods, NegBio utilizes patterns on universal dependencies to\nidentify the scope of triggers that are indicative of negation or uncertainty.\nWe evaluated NegBio on four datasets, including two public benchmarking corpora\nof radiology reports, a new radiology corpus that we annotated for this work,\nand a public corpus of general clinical texts. Evaluation on these datasets\ndemonstrates that NegBio is highly accurate for detecting negative and\nuncertain findings and compares favorably to a widely-used state-of-the-art\nsystem NegEx (an average of 9.5% improvement in precision and 5.1% in\nF1-score).\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 03:43:42 GMT"}, {"version": "v2", "created": "Wed, 27 Dec 2017 03:44:03 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Peng", "Yifan", ""], ["Wang", "Xiaosong", ""], ["Lu", "Le", ""], ["Bagheri", "Mohammadhadi", ""], ["Summers", "Ronald", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1712.05972", "submitter": "Muktabh Mayank Srivastava", "authors": "Pushpankar Kumar Pushp, Muktabh Mayank Srivastava", "title": "Train Once, Test Anywhere: Zero-Shot Learning for Text Classification", "comments": "v2 - fixed a citation error, unchanged from v1 otherwise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Zero-shot Learners are models capable of predicting unseen classes. In this\nwork, we propose a Zero-shot Learning approach for text categorization. Our\nmethod involves training model on a large corpus of sentences to learn the\nrelationship between a sentence and embedding of sentence's tags. Learning such\nrelationship makes the model generalize to unseen sentences, tags, and even new\ndatasets provided they can be put into same embedding space. The model learns\nto predict whether a given sentence is related to a tag or not; unlike other\nclassifiers that learn to classify the sentence as one of the possible classes.\nWe propose three different neural networks for the task and report their\naccuracy on the test set of the dataset used for training them as well as two\nother standard datasets for which no retraining was done. We show that our\nmodels generalize well across new unseen classes in both cases. Although the\nmodels do not achieve the accuracy level of the state of the art supervised\nmodels, yet it evidently is a step forward towards general intelligence in\nnatural language processing.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 15:17:07 GMT"}, {"version": "v2", "created": "Sat, 23 Dec 2017 20:05:03 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Pushp", "Pushpankar Kumar", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "1712.05997", "submitter": "Amir Karami", "authors": "Amir Karami", "title": "Taming Wild High Dimensional Text Data with a Fuzzy Lash", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bag of words (BOW) represents a corpus in a matrix whose elements are the\nfrequency of words. However, each row in the matrix is a very high-dimensional\nsparse vector. Dimension reduction (DR) is a popular method to address sparsity\nand high-dimensionality issues. Among different strategies to develop DR\nmethod, Unsupervised Feature Transformation (UFT) is a popular strategy to map\nall words on a new basis to represent BOW. The recent increase of text data and\nits challenges imply that DR area still needs new perspectives. Although a wide\nrange of methods based on the UFT strategy has been developed, the fuzzy\napproach has not been considered for DR based on this strategy. This research\ninvestigates the application of fuzzy clustering as a DR method based on the\nUFT strategy to collapse BOW matrix to provide a lower-dimensional\nrepresentation of documents instead of the words in a corpus. The quantitative\nevaluation shows that fuzzy clustering produces superior performance and\nfeatures to Principal Components Analysis (PCA) and Singular Value\nDecomposition (SVD), two popular DR methods based on the UFT strategy.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 17:57:57 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Karami", "Amir", ""]]}, {"id": "1712.05999", "submitter": "Miguel Molina-Solana", "authors": "Julio Amador and Axel Oehmichen and Miguel Molina-Solana", "title": "Characterizing Political Fake News in Twitter by its Meta-Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a preliminary approach towards characterizing political\nfake news on Twitter through the analysis of their meta-data. In particular, we\nfocus on more than 1.5M tweets collected on the day of the election of Donald\nTrump as 45th president of the United States of America. We use the meta-data\nembedded within those tweets in order to look for differences between tweets\ncontaining fake news and tweets not containing them. Specifically, we perform\nour analysis only on tweets that went viral, by studying proxies for users'\nexposure to the tweets, by characterizing accounts spreading fake news, and by\nlooking at their polarization. We found significant differences on the\ndistribution of followers, the number of URLs on tweets, and the verification\nof the users.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 18:07:58 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Amador", "Julio", ""], ["Oehmichen", "Axel", ""], ["Molina-Solana", "Miguel", ""]]}, {"id": "1712.06074", "submitter": "Xiao-Yong Yan", "authors": "Xiaoyong Yan, Seong-Gyu Yang, Beom Jun Kim and Petter Minnhagen", "title": "Benford's Law and First Letter of Word", "comments": "10 pages, 11 figures", "journal-ref": "Physica A 512, 305-315 (2018)", "doi": "10.1016/j.physa.2018.08.133", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A universal First-Letter Law (FLL) is derived and described. It predicts the\npercentages of first letters for words in novels. The FLL is akin to Benford's\nlaw (BL) of first digits, which predicts the percentages of first digits in a\ndata collection of numbers. Both are universal in the sense that FLL only\ndepends on the numbers of letters in the alphabet, whereas BL only depends on\nthe number of digits in the base of the number system. The existence of these\ntypes of universal laws appears counter-intuitive. Nonetheless both describe\ndata very well. Relations to some earlier works are given. FLL predicts that an\nEnglish author on the average starts about 16 out of 100 words with the English\nletter `t'. This is corroborated by data, yet an author can freely write\nanything. Fuller implications and the applicability of FLL remain for the\nfuture.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 08:53:13 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Yan", "Xiaoyong", ""], ["Yang", "Seong-Gyu", ""], ["Kim", "Beom Jun", ""], ["Minnhagen", "Petter", ""]]}, {"id": "1712.06086", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli", "title": "Deep Learning for Distant Speech Recognition", "comments": "PhD Thesis Unitn, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is an emerging technology that is considered one of the most\npromising directions for reaching higher levels of artificial intelligence.\nAmong the other achievements, building computers that understand speech\nrepresents a crucial leap towards intelligent machines. Despite the great\nefforts of the past decades, however, a natural and robust human-machine speech\ninteraction still appears to be out of reach, especially when users interact\nwith a distant microphone in noisy and reverberant environments. The latter\ndisturbances severely hamper the intelligibility of a speech signal, making\nDistant Speech Recognition (DSR) one of the major open challenges in the field.\n  This thesis addresses the latter scenario and proposes some novel techniques,\narchitectures, and algorithms to improve the robustness of distant-talking\nacoustic models. We first elaborate on methodologies for realistic data\ncontamination, with a particular emphasis on DNN training with simulated data.\nWe then investigate on approaches for better exploiting speech contexts,\nproposing some original methodologies for both feed-forward and recurrent\nneural networks. Lastly, inspired by the idea that cooperation across different\nDNNs could be the key for counteracting the harmful effects of noise and\nreverberation, we propose a novel deep learning paradigm called network of deep\nneural networks. The analysis of the original concepts were based on extensive\nexperimental validations conducted on both real and simulated data, considering\ndifferent corpora, microphone configurations, environments, noisy conditions,\nand ASR tasks.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 10:29:15 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Ravanelli", "Mirco", ""]]}, {"id": "1712.06100", "submitter": "Mikael K{\\aa}geb\\\"ack", "authors": "Johan Hasselqvist, Niklas Helmertz, Mikael K{\\aa}geb\\\"ack", "title": "Query-Based Abstractive Summarization Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a model for generating summaries of text documents\nwith respect to a query. This is known as query-based summarization. We adapt\nan existing dataset of news article summaries for the task and train a\npointer-generator model using this dataset. The generated summaries are\nevaluated by measuring similarity to reference summaries. Our results show that\na neural network summarization model, similar to existing neural network models\nfor abstractive summarization, can be constructed to make use of queries to\nproduce targeted summaries.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 12:42:51 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Hasselqvist", "Johan", ""], ["Helmertz", "Niklas", ""], ["K\u00e5geb\u00e4ck", "Mikael", ""]]}, {"id": "1712.06163", "submitter": "Andrew Reagan", "authors": "Andrew J. Reagan", "title": "Towards a science of human stories: using sentiment analysis and\n  emotional arcs to understand the building blocks of complex social systems", "comments": "286 pages, PhD dissertation, University of Vermont (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the growing assortment of sentiment measuring instruments, it is\nimperative to understand which aspects of sentiment dictionaries contribute to\nboth their classification accuracy and their ability to provide richer\nunderstanding of texts. Here, we perform detailed, quantitative tests and\nqualitative assessments of 6 dictionary-based methods applied, and briefly\nexamine a further 20 methods. We show that while inappropriate for sentences,\ndictionary-based methods are generally robust in their classification accuracy\nfor longer texts.\n  Stories often following distinct emotional trajectories, forming patterns\nthat are meaningful to us. By classifying the emotional arcs for a filtered\nsubset of 4,803 stories from Project Gutenberg's fiction collection, we find a\nset of six core trajectories which form the building blocks of complex\nnarratives. Of profound scientific interest will be the degree to which we can\neventually understand the full landscape of human stories, and data driven\napproaches will play a crucial role.\n  Finally, we utilize web-scale data from Twitter to study the limits of what\nsocial data can tell us about public health, mental illness, discourse around\nthe protest movement of #BlackLivesMatter, discourse around climate change, and\nhidden networks. We conclude with a review of published works in complex\nsystems that separately analyze charitable donations, the happiness of words in\n10 languages, 100 years of daily temperature data across the United States, and\nAustralian Rules Football games.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 19:33:36 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Reagan", "Andrew J.", ""]]}, {"id": "1712.06204", "submitter": "Yuting Chen", "authors": "Yuting Chen, Joseph Wang, Yannan Bai, Gregory Casta\\~n\\'on, and\n  Venkatesh Saligrama", "title": "Probabilistic Semantic Retrieval for Surveillance Videos with Activity\n  Graphs", "comments": "1520-9210 (c) 2018 IEEE. This paper has been accepted by IEEE\n  Transactions on Multimedia. Print ISSN: 1520-9210. Online ISSN: 1941-0077.\n  Preprint link is https://ieeexplore.ieee.org/document/8438958/", "journal-ref": null, "doi": "10.1109/TMM.2018.2865860", "report-no": null, "categories": "cs.MM cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for finding complex activities matching\nuser-described queries in cluttered surveillance videos. The wide diversity of\nqueries coupled with unavailability of annotated activity data limits our\nability to train activity models. To bridge the semantic gap we propose to let\nusers describe an activity as a semantic graph with object attributes and\ninter-object relationships associated with nodes and edges, respectively. We\nlearn node/edge-level visual predictors during training and, at test-time,\npropose to retrieve activity by identifying likely locations that match the\nsemantic graph. We formulate a novel CRF based probabilistic activity\nlocalization objective that accounts for mis-detections, mis-classifications\nand track-losses, and outputs a likelihood score for a candidate grounded\nlocation of the query in the video. We seek groundings that maximize overall\nprecision and recall. To handle the combinatorial search over all\nhigh-probability groundings, we propose a highest precision subgraph matching\nalgorithm. Our method outperforms existing retrieval methods on benchmarked\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 23:11:28 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 02:03:27 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Chen", "Yuting", ""], ["Wang", "Joseph", ""], ["Bai", "Yannan", ""], ["Casta\u00f1\u00f3n", "Gregory", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1712.06273", "submitter": "Alexander Erdmann", "authors": "Alexander Erdmann, Nizar Habash, Dima Taji, Houda Bouamor", "title": "Low Resourced Machine Translation via Morpho-syntactic Modeling: The\n  Case of Dialectal Arabic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the second ever evaluated Arabic dialect-to-dialect machine\ntranslation effort, and the first to leverage external resources beyond a small\nparallel corpus. The subject has not previously received serious attention due\nto lack of naturally occurring parallel data; yet its importance is evidenced\nby dialectal Arabic's wide usage and breadth of inter-dialect variation,\ncomparable to that of Romance languages. Our results suggest that modeling\nmorphology and syntax significantly improves dialect-to-dialect translation,\nthough optimizing such data-sparse models requires consideration of the\nlinguistic differences between dialects and the nature of available data and\nresources. On a single-reference blind test set where untranslated input scores\n6.5 BLEU and a model trained only on parallel data reaches 14.6, pivot\ntechniques and morphosyntactic modeling significantly improve performance to\n17.5.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 07:04:10 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Erdmann", "Alexander", ""], ["Habash", "Nizar", ""], ["Taji", "Dima", ""], ["Bouamor", "Houda", ""]]}, {"id": "1712.06289", "submitter": "Yi Zhang", "authors": "Yi Zhang, Xu Sun", "title": "A Chinese Dataset with Negative Full Forms for General Abbreviation\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abbreviation is a common phenomenon across languages, especially in Chinese.\nIn most cases, if an expression can be abbreviated, its abbreviation is used\nmore often than its fully expanded forms, since people tend to convey\ninformation in a most concise way. For various language processing tasks,\nabbreviation is an obstacle to improving the performance, as the textual form\nof an abbreviation does not express useful information, unless it's expanded to\nthe full form. Abbreviation prediction means associating the fully expanded\nforms with their abbreviations. However, due to the deficiency in the\nabbreviation corpora, such a task is limited in current studies, especially\nconsidering general abbreviation prediction should also include those full form\nexpressions that do not have valid abbreviations, namely the negative full\nforms (NFFs). Corpora incorporating negative full forms for general\nabbreviation prediction are few in number. In order to promote the research in\nthis area, we build a dataset for general Chinese abbreviation prediction,\nwhich needs a few preprocessing steps, and evaluate several different models on\nthe built dataset. The dataset is available at\nhttps://github.com/lancopku/Chinese-abbreviation-dataset\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 08:24:12 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Zhang", "Yi", ""], ["Sun", "Xu", ""]]}, {"id": "1712.06414", "submitter": "Misha Teplitskiy", "authors": "Feng Shi, Misha Teplitskiy, Eamon Duede, James Evans", "title": "The Wisdom of Polarized Crowds", "comments": null, "journal-ref": "Nature Human Behavior. 2019", "doi": "10.1038/s41562-019-0541-6", "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one's echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia's\nPolitical, Social Issues, and Science articles. We measure editors' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia's Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article \"talk\npages\" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 21:40:29 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Shi", "Feng", ""], ["Teplitskiy", "Misha", ""], ["Duede", "Eamon", ""], ["Evans", "James", ""]]}, {"id": "1712.06427", "submitter": "Marcos Zampieri", "authors": "Shervin Malmasi, Marcos Zampieri", "title": "Detecting Hate Speech in Social Media", "comments": "Proceedings of Recent Advances in Natural Language Processing\n  (RANLP). pp. 467-472. Varna, Bulgaria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine methods to detect hate speech in social media, while\ndistinguishing this from general profanity. We aim to establish lexical\nbaselines for this task by applying supervised classification methods using a\nrecently released dataset annotated for this purpose. As features, our system\nuses character n-grams, word n-grams and word skip-grams. We obtain results of\n78% accuracy in identifying posts across three classes. Results demonstrate\nthat the main challenge lies in discriminating profanity and hate speech from\neach other. A number of directions for future work are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 14:39:57 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 19:08:16 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Malmasi", "Shervin", ""], ["Zampieri", "Marcos", ""]]}, {"id": "1712.06674", "submitter": "Erfan Rahmani", "authors": "Siamak Sarmady and Erfan Rahmani", "title": "word representation or word embedding in Persian text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text processing is one of the sub-branches of natural language processing.\nRecently, the use of machine learning and neural networks methods has been\ngiven greater consideration. For this reason, the representation of words has\nbecome very important. This article is about word representation or converting\nwords into vectors in Persian text. In this research GloVe, CBOW and skip-gram\nmethods are updated to produce embedded vectors for Persian words. In order to\ntrain a neural networks, Bijankhan corpus, Hamshahri corpus and UPEC corpus\nhave been compound and used. Finally, we have 342,362 words that obtained\nvectors in all three models for this words. These vectors have many usage for\nPersian natural language processing.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 21:06:42 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Sarmady", "Siamak", ""], ["Rahmani", "Erfan", ""]]}, {"id": "1712.06682", "submitter": "Jason Xie", "authors": "Jason Xie, Tingwen Bao", "title": "Synthesizing Novel Pairs of Image and Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating novel pairs of image and text is a problem that combines computer\nvision and natural language processing. In this paper, we present strategies\nfor generating novel image and caption pairs based on existing captioning\ndatasets. The model takes advantage of recent advances in generative\nadversarial networks and sequence-to-sequence modeling. We make generalizations\nto generate paired samples from multiple domains. Furthermore, we study cycles\n-- generating from image to text then back to image and vise versa, as well as\nits connection with autoencoders.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 21:25:37 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Xie", "Jason", ""], ["Bao", "Tingwen", ""]]}, {"id": "1712.06704", "submitter": "Kriste Krstovski", "authors": "Kriste Krstovski, Michael J. Kurtz, David A. Smith and Alberto\n  Accomazzi", "title": "Multilingual Topic Models", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific publications have evolved several features for mitigating\nvocabulary mismatch when indexing, retrieving, and computing similarity between\narticles. These mitigation strategies range from simply focusing on high-value\narticle sections, such as titles and abstracts, to assigning keywords, often\nfrom controlled vocabularies, either manually or through automatic annotation.\nVarious document representation schemes possess different cost-benefit\ntradeoffs. In this paper, we propose to model different representations of the\nsame article as translations of each other, all generated from a common latent\nrepresentation in a multilingual topic model. We start with a methodological\noverview on latent variable models for parallel document representations that\ncould be used across many information science tasks. We then show how solving\nthe inference problem of mapping diverse representations into a shared topic\nspace allows us to evaluate representations based on how topically similar they\nare to the original article. In addition, our proposed approach provides means\nto discover where different concept vocabularies require improvement.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 22:45:20 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Krstovski", "Kriste", ""], ["Kurtz", "Michael J.", ""], ["Smith", "David A.", ""], ["Accomazzi", "Alberto", ""]]}, {"id": "1712.06751", "submitter": "Javid Ebrahimi", "authors": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou", "title": "HotFlip: White-Box Adversarial Examples for Text Classification", "comments": null, "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient method to generate white-box adversarial examples to\ntrick a character-level neural classifier. We find that only a few\nmanipulations are needed to greatly decrease the accuracy. Our method relies on\nan atomic flip operation, which swaps one token for another, based on the\ngradients of the one-hot input vectors. Due to efficiency of our method, we can\nperform adversarial training which makes the model more robust to attacks at\ntest time. With the use of a few semantics-preserving constraints, we\ndemonstrate that HotFlip can be adapted to attack a word-level classifier as\nwell.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 02:15:19 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 16:43:45 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Ebrahimi", "Javid", ""], ["Rao", "Anyi", ""], ["Lowd", "Daniel", ""], ["Dou", "Dejing", ""]]}, {"id": "1712.06855", "submitter": "Thomas Zenkel", "authors": "Thomas Zenkel, Ramon Sanabria, Florian Metze, Alex Waibel", "title": "Subword and Crossword Units for CTC Acoustic Models", "comments": "Current version accepted at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach to create an unit set for CTC based\nspeech recognition systems. By using Byte Pair Encoding we learn an unit set of\nan arbitrary size on a given training text. In contrast to using characters or\nwords as units this allows us to find a good trade-off between the size of our\nunit set and the available training data. We evaluate both Crossword units,\nthat may span multiple word, and Subword units. By combining this approach with\ndecoding methods using a separate language model we are able to achieve state\nof the art results for grapheme based CTC systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 10:29:28 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 12:55:36 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Zenkel", "Thomas", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""], ["Waibel", "Alex", ""]]}, {"id": "1712.06880", "submitter": "Karni Gilon", "authors": "Karni Gilon, Felicia Y Ng, Joel Chan, Hila Lifshitz Assaf, Aniket\n  Kittur, Dafna Shahaf", "title": "Analogy Mining for Specific Design Needs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding analogical inspirations in distant domains is a powerful way of\nsolving problems. However, as the number of inspirations that could be matched\nand the dimensions on which that matching could occur grow, it becomes\nchallenging for designers to find inspirations relevant to their needs.\nFurthermore, designers are often interested in exploring specific aspects of a\nproduct-- for example, one designer might be interested in improving the\nbrewing capability of an outdoor coffee maker, while another might wish to\noptimize for portability. In this paper we introduce a novel system for\ntargeting analogical search for specific needs. Specifically, we contribute a\nnovel analogical search engine for expressing and abstracting specific design\nneeds that returns more distant yet relevant inspirations than alternate\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 11:47:53 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Gilon", "Karni", ""], ["Ng", "Felicia Y", ""], ["Chan", "Joel", ""], ["Assaf", "Hila Lifshitz", ""], ["Kittur", "Aniket", ""], ["Shahaf", "Dafna", ""]]}, {"id": "1712.06961", "submitter": "Hanan Aldarmaki", "authors": "Hanan Aldarmaki, Mahesh Mohan and Mona Diab", "title": "Unsupervised Word Mapping Using Structural Similarities in Monolingual\n  Embeddings", "comments": "10 pages, 8 figures; will appear in Transactions of the Association\n  for Computational Linguistics (TACL)", "journal-ref": "TACL 6 (2018) 185-196", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing methods for automatic bilingual dictionary induction rely on\nprior alignments between the source and target languages, such as parallel\ncorpora or seed dictionaries. For many language pairs, such supervised\nalignments are not readily available. We propose an unsupervised approach for\nlearning a bilingual dictionary for a pair of languages given their\nindependently-learned monolingual word embeddings. The proposed method exploits\nlocal and global structures in monolingual vector spaces to align them such\nthat similar words are mapped to each other. We show empirically that the\nperformance of bilingual correspondents learned using our proposed unsupervised\nmethod is comparable to that of using supervised bilingual correspondents from\na seed dictionary.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 14:52:47 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 18:54:13 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Aldarmaki", "Hanan", ""], ["Mohan", "Mahesh", ""], ["Diab", "Mona", ""]]}, {"id": "1712.06994", "submitter": "Maryam Zare", "authors": "Maryam Zare, Shaurya Rohatgi", "title": "DeepNorm-A Deep Learning Approach to Text Normalization", "comments": "arXiv admin note: text overlap with arXiv:1611.00068 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an simple yet sophisticated approach to the challenge by\nSproat and Jaitly (2016)- given a large corpus of written text aligned to its\nnormalized spoken form, train an RNN to learn the correct normalization\nfunction. Text normalization for a token seems very straightforward without\nit's context. But given the context of the used token and then normalizing\nbecomes tricky for some classes. We present a novel approach in which the\nprediction of our classification algorithm is used by our sequence to sequence\nmodel to predict the normalized text of the input token. Our approach takes\nvery less time to learn and perform well unlike what has been reported by\nGoogle (5 days on their GPU cluster). We have achieved an accuracy of 97.62\nwhich is impressive given the resources we use. Our approach is using the best\nof both worlds, gradient boosting - state of the art in most classification\ntasks and sequence to sequence learning - state of the art in machine\ntranslation. We present our experiments and report results with various\nparameter settings.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 18:31:26 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Zare", "Maryam", ""], ["Rohatgi", "Shaurya", ""]]}, {"id": "1712.07004", "submitter": "Rasoul Kaljahi", "authors": "Rasoul Kaljahi, Jennifer Foster", "title": "Any-gram Kernels for Sentence Classification: A Sentiment Analysis Case\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any-gram kernels are a flexible and efficient way to employ bag-of-n-gram\nfeatures when learning from textual data. They are also compatible with the use\nof word embeddings so that word similarities can be accounted for. While the\noriginal any-gram kernels are implemented on top of tree kernels, we propose a\nnew approach which is independent of tree kernels and is more efficient. We\nalso propose a more effective way to make use of word embeddings than the\noriginal any-gram formulation. When applied to the task of sentiment\nclassification, our new formulation achieves significantly better performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 15:47:00 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Kaljahi", "Rasoul", ""], ["Foster", "Jennifer", ""]]}, {"id": "1712.07040", "submitter": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y", "authors": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Jonathan Schwarz, Phil Blunsom, Chris Dyer,\n  Karl Moritz Hermann, G\\'abor Melis, Edward Grefenstette", "title": "The NarrativeQA Reading Comprehension Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension (RC)---in contrast to information retrieval---requires\nintegrating information and reasoning about events, entities, and their\nrelations across a full document. Question answering is conventionally used to\nassess RC ability, in both artificial agents and children learning to read.\nHowever, existing RC datasets and tasks are dominated by questions that can be\nsolved by selecting answers using superficial information (e.g., local context\nsimilarity or global term frequency); they thus fail to test for the essential\nintegrative aspect of RC. To encourage progress on deeper comprehension of\nlanguage, we present a new dataset and set of tasks in which the reader must\nanswer questions about stories by reading entire books or movie scripts. These\ntasks are designed so that successfully answering their questions requires\nunderstanding the underlying narrative rather than relying on shallow pattern\nmatching or salience. We show that although humans solve the tasks easily,\nstandard RC models struggle on the tasks presented here. We provide an analysis\nof the dataset and the challenges it presents.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 16:48:05 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Schwarz", "Jonathan", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Hermann", "Karl Moritz", ""], ["Melis", "G\u00e1bor", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1712.07101", "submitter": "Yingbo Zhou", "authors": "Yingbo Zhou, Caiming Xiong, Richard Socher", "title": "Improving End-to-End Speech Recognition with Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist temporal classification (CTC) is widely used for maximum\nlikelihood learning in end-to-end speech recognition models. However, there is\nusually a disparity between the negative maximum likelihood and the performance\nmetric used in speech recognition, e.g., word error rate (WER). This results in\na mismatch between the objective function and metric during training. We show\nthat the above problem can be mitigated by jointly training with maximum\nlikelihood and policy gradient. In particular, with policy learning we are able\nto directly optimize on the (otherwise non-differentiable) performance metric.\nWe show that joint training improves relative performance by 4% to 13% for our\nend-to-end model as compared to the same model learned through maximum\nlikelihood. The model achieves 5.53% WER on Wall Street Journal dataset, and\n5.42% and 14.70% on Librispeech test-clean and test-other set, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:39:50 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Zhou", "Yingbo", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07108", "submitter": "Yingbo Zhou", "authors": "Yingbo Zhou, Caiming Xiong, Richard Socher", "title": "Improved Regularization Techniques for End-to-End Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is important for end-to-end speech models, since the models\nare highly flexible and easy to overfit. Data augmentation and dropout has been\nimportant for improving end-to-end models in other domains. However, they are\nrelatively under explored for end-to-end speech models. Therefore, we\ninvestigate the effectiveness of both methods for end-to-end trainable, deep\nspeech recognition models. We augment audio data through random perturbations\nof tempo, pitch, volume, temporal alignment, and adding random noise.We further\ninvestigate the effect of dropout when applied to the inputs of all layers of\nthe network. We show that the combination of data augmentation and dropout give\na relative performance improvement on both Wall Street Journal (WSJ) and\nLibriSpeech dataset of over 20%. Our model performance is also competitive with\nother end-to-end speech models on both datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:45:25 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Zhou", "Yingbo", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07199", "submitter": "Rajesh Bordawekar", "authors": "Rajesh Bordawekar and Bortik Bandyopadhyay and Oded Shmueli", "title": "Cognitive Database: A Step towards Endowing Relational Databases with\n  Artificial Intelligence Capabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Cognitive Databases, an approach for transparently enabling\nArtificial Intelligence (AI) capabilities in relational databases. A novel\naspect of our design is to first view the structured data source as meaningful\nunstructured text, and then use the text to build an unsupervised neural\nnetwork model using a Natural Language Processing (NLP) technique called word\nembedding. This model captures the hidden inter-/intra-column relationships\nbetween database tokens of different types. For each database token, the model\nincludes a vector that encodes contextual semantic relationships. We seamlessly\nintegrate the word embedding model into existing SQL query infrastructure and\nuse it to enable a new class of SQL-based analytics queries called cognitive\nintelligence (CI) queries. CI queries use the model vectors to enable complex\nqueries such as semantic matching, inductive reasoning queries such as\nanalogies, predictive queries using entities not present in a database, and,\nmore generally, using knowledge from external sources. We demonstrate unique\ncapabilities of Cognitive Databases using an Apache Spark based prototype to\nexecute inductive reasoning CI queries over a multi-modal database containing\ntext and images. We believe our first-of-a-kind system exemplifies using AI\nfunctionality to endow relational databases with capabilities that were\npreviously very hard to realize in practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:49:26 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Bordawekar", "Rajesh", ""], ["Bandyopadhyay", "Bortik", ""], ["Shmueli", "Oded", ""]]}, {"id": "1712.07229", "submitter": "Tom Kenter", "authors": "Tom Kenter, Maarten de Rijke", "title": "Attentive Memory Networks: Efficient Machine Reading for Conversational\n  Search", "comments": null, "journal-ref": "Proceedings of 1st International Workshop on Conversational\n  Approaches to Information Retrieval, Tokyo, Japan, August 11, 2017 (CAIR'17)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in conversational systems have changed the search paradigm.\nTraditionally, a user poses a query to a search engine that returns an answer\nbased on its index, possibly leveraging external knowledge bases and\nconditioning the response on earlier interactions in the search session. In a\nnatural conversation, there is an additional source of information to take into\naccount: utterances produced earlier in a conversation can also be referred to\nand a conversational IR system has to keep track of information conveyed by the\nuser during the conversation, even if it is implicit.\n  We argue that the process of building a representation of the conversation\ncan be framed as a machine reading task, where an automated system is presented\nwith a number of statements about which it should answer questions. The\nquestions should be answered solely by referring to the statements provided,\nwithout consulting external knowledge. The time is right for the information\nretrieval community to embrace this task, both as a stand-alone task and\nintegrated in a broader conversational search setting.\n  In this paper, we focus on machine reading as a stand-alone task and present\nthe Attentive Memory Network (AMN), an end-to-end trainable machine reading\nalgorithm. Its key contribution is in efficiency, achieved by having an\nhierarchical input encoder, iterating over the input only once. Speed is an\nimportant requirement in the setting of conversational search, as gaps between\nconversational turns have a detrimental effect on naturalness. On 20 datasets\ncommonly used for evaluating machine reading algorithms we show that the AMN\nachieves performance comparable to the state-of-the-art models, while using\nconsiderably fewer computations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 21:43:59 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Kenter", "Tom", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1712.07316", "submitter": "Stephen Merity", "authors": "Martin Schrimpf, Stephen Merity, James Bradbury, Richard Socher", "title": "A Flexible Approach to Automated RNN Architecture Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of designing neural architectures requires expert knowledge and\nextensive trial and error. While automated architecture search may simplify\nthese requirements, the recurrent neural network (RNN) architectures generated\nby existing methods are limited in both flexibility and components. We propose\na domain-specific language (DSL) for use in automated architecture search which\ncan produce novel RNNs of arbitrary depth and width. The DSL is flexible enough\nto define standard architectures such as the Gated Recurrent Unit and Long\nShort Term Memory and allows the introduction of non-standard RNN components\nsuch as trigonometric curves and layer normalization. Using two different\ncandidate generation techniques, random search with a ranking function and\nreinforcement learning, we explore the novel architectures produced by the RNN\nDSL for language modeling and machine translation domains. The resulting\narchitectures do not follow human intuition yet perform well on their targeted\ntasks, suggesting the space of usable RNN architectures is far larger than\npreviously assumed.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 04:20:40 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Schrimpf", "Martin", ""], ["Merity", "Stephen", ""], ["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07473", "submitter": "Mikhail Kudinov", "authors": "Vadim Popov, Mikhail Kudinov, Irina Piontkovskaya, Petr Vytovtov and\n  Alex Nevidomsky", "title": "Differentially Private Distributed Learning for Language Modeling Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the big challenges in machine learning applications is that training\ndata can be different from the real-world data faced by the algorithm. In\nlanguage modeling, users' language (e.g. in private messaging) could change in\na year and be completely different from what we observe in publicly available\ndata. At the same time, public data can be used for obtaining general knowledge\n(i.e. general model of English). We study approaches to distributed fine-tuning\nof a general model on user private data with the additional requirements of\nmaintaining the quality on the general data and minimization of communication\ncosts. We propose a novel technique that significantly improves prediction\nquality on users' language compared to a general model and outperforms gradient\ncompression methods in terms of communication efficiency. The proposed\nprocedure is fast and leads to an almost 70% perplexity reduction and 8.7\npercentage point improvement in keystroke saving rate on informal English\ntexts. We also show that the range of tasks our approach is applicable to is\nnot limited by language modeling only. Finally, we propose an experimental\nframework for evaluating differential privacy of distributed training of\nlanguage models and show that our approach has good privacy guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 13:28:13 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 14:10:05 GMT"}, {"version": "v3", "created": "Tue, 6 Mar 2018 13:10:31 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Popov", "Vadim", ""], ["Kudinov", "Mikhail", ""], ["Piontkovskaya", "Irina", ""], ["Vytovtov", "Petr", ""], ["Nevidomsky", "Alex", ""]]}, {"id": "1712.07512", "submitter": "Anil Kumar Singh", "authors": "Anil Kumar Singh and Akhilesh Sudhakar", "title": "Ethical Questions in NLP Research: The (Mis)-Use of Forensic Linguistics", "comments": "4 pages, submitted to AIES-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideas from forensic linguistics are now being used frequently in Natural\nLanguage Processing (NLP), using machine learning techniques. While the role of\nforensic linguistics was more benign earlier, it is now being used for purposes\nwhich are questionable. Certain methods from forensic linguistics are employed,\nwithout considering their scientific limitations and ethical concerns. While we\ntake the specific case of forensic linguistics as an example of such trends in\nNLP and machine learning, the issue is a larger one and present in many other\nscientific and data-driven domains. We suggest that such trends indicate that\nsome of the applied sciences are exceeding their legal and scientific briefs.\nWe highlight how carelessly implemented practices are serving to short-circuit\nthe due processes of law as well breach ethical codes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 15:03:04 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Singh", "Anil Kumar", ""], ["Sudhakar", "Akhilesh", ""]]}, {"id": "1712.07558", "submitter": "Amanda Cercas Curry", "authors": "Ioannis Papaioannou, Amanda Cercas Curry, Jose L. Part, Igor\n  Shalyminov, Xinnuo Xu, Yanchao Yu, Ond\\v{r}ej Du\\v{s}ek, Verena Rieser and\n  Oliver Lemon", "title": "An Ensemble Model with Ranking for Social Dialogue", "comments": "NIPS 2017 Workshop on Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain social dialogue is one of the long-standing goals of Artificial\nIntelligence. This year, the Amazon Alexa Prize challenge was announced for the\nfirst time, where real customers get to rate systems developed by leading\nuniversities worldwide. The aim of the challenge is to converse \"coherently and\nengagingly with humans on popular topics for 20 minutes\". We describe our Alexa\nPrize system (called 'Alana') consisting of an ensemble of bots, combining\nrule-based and machine learning systems, and using a contextual ranking\nmechanism to choose a system response. The ranker was trained on real user\nfeedback received during the competition, where we address the problem of how\nto train on the noisy and sparse feedback obtained during the competition.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 16:28:48 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Papaioannou", "Ioannis", ""], ["Curry", "Amanda Cercas", ""], ["Part", "Jose L.", ""], ["Shalyminov", "Igor", ""], ["Xu", "Xinnuo", ""], ["Yu", "Yanchao", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Rieser", "Verena", ""], ["Lemon", "Oliver", ""]]}, {"id": "1712.07745", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Bing Liu", "title": "Context-aware Path Ranking for Knowledge Base Completion", "comments": null, "journal-ref": "Published in IJCAI 2017", "doi": "10.24963/ijcai.2017/166", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base (KB) completion aims to infer missing facts from existing ones\nin a KB. Among various approaches, path ranking (PR) algorithms have received\nincreasing attention in recent years. PR algorithms enumerate paths between\nentity pairs in a KB and use those paths as features to train a model for\nmissing fact prediction. Due to their good performances and high model\ninterpretability, several methods have been proposed. However, most existing\nmethods suffer from scalability (high RAM consumption) and feature explosion\n(trains on an exponentially large number of features) problems. This paper\nproposes a Context-aware Path Ranking (C-PR) algorithm to solve these problems\nby introducing a selective path exploration strategy. C-PR learns global\nsemantics of entities in the KB using word embedding and leverages the\nknowledge of entity semantics to enumerate contextually relevant paths using\nbidirectional random walk. Experimental results on three large KBs show that\nthe path features (fewer in number) discovered by C-PR not only improve\npredictive performance but also are more interpretable than existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 23:10:21 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""]]}, {"id": "1712.07794", "submitter": "Roger Dean Dr", "authors": "Roger T. Dean and Hazel Smith", "title": "The Character Thinks Ahead: creative writing with deep learning nets and\n  its stylistic assessment", "comments": "A 2 page paper in press in Leonardo Vol 51, 2018. Yet to be\n  copy-edited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how to control outputs from deep learning models of text corpora\nso as to create contemporary poetic works. We assess whether these controls are\nsuccessful in the immediate sense of creating stylo- metric distinctiveness.\nThe specific context is our piece The Character Thinks Ahead (2016/17); the\npotential applications are broad.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 05:16:51 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Dean", "Roger T.", ""], ["Smith", "Hazel", ""]]}, {"id": "1712.08207", "submitter": "Hareesh Bahuleyan", "authors": "Hareesh Bahuleyan, Lili Mou, Olga Vechtomova, Pascal Poupart", "title": "Variational Attention for Sequence-to-Sequence Models", "comments": "In Proceedings of COLING 2018. Also accepted by TADGM Workshop@ICML\n  2018 for presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The variational encoder-decoder (VED) encodes source information as a set of\nrandom variables using a neural network, which in turn is decoded into target\ndata using another neural network. In natural language processing,\nsequence-to-sequence (Seq2Seq) models typically serve as encoder-decoder\nnetworks. When combined with a traditional (deterministic) attention mechanism,\nthe variational latent space may be bypassed by the attention model, and thus\nbecomes ineffective. In this paper, we propose a variational attention\nmechanism for VED, where the attention vector is also modeled as Gaussian\ndistributed random variables. Results on two experiments show that, without\nloss of quality, our proposed method alleviates the bypassing phenomenon as it\nincreases the diversity of generated sentences.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 20:47:27 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 15:36:27 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 19:44:23 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Bahuleyan", "Hareesh", ""], ["Mou", "Lili", ""], ["Vechtomova", "Olga", ""], ["Poupart", "Pascal", ""]]}, {"id": "1712.08291", "submitter": "Vivek Kulkarni", "authors": "Vivek Kulkarni and William Yang Wang", "title": "TFW, DamnGina, Juvie, and Hotsie-Totsie: On the Linguistic and Social\n  Aspects of Internet Slang", "comments": "10 pages, 11 figures,4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slang is ubiquitous on the Internet. The emergence of new social contexts\nlike micro-blogs, question-answering forums, and social networks has enabled\nslang and non-standard expressions to abound on the web. Despite this, slang\nhas been traditionally viewed as a form of non-standard language -- a form of\nlanguage that is not the focus of linguistic analysis and has largely been\nneglected. In this work, we use UrbanDictionary to conduct the first\nlarge-scale linguistic analysis of slang and its social aspects on the Internet\nto yield insights into this variety of language that is increasingly used all\nover the world online.\n  We begin by computationally analyzing the phonological, morphological and\nsyntactic properties of slang. We then study linguistic patterns in four\nspecific categories of slang namely alphabetisms, blends, clippings, and\nreduplicatives. Our analysis reveals that slang demonstrates extra-grammatical\nrules of phonological and morphological formation that markedly distinguish it\nfrom the standard form shedding insight into its generative patterns. Next, we\nanalyze the social aspects of slang by studying subject restriction and\nstereotyping in slang usage. Analyzing tens of thousands of such slang words\nreveals that the majority of slang on the Internet belongs to two major\ncategories: sex and drugs. We also noted that not only is slang usage not\nimmune to prevalent social biases and prejudices but also reflects such biases\nand stereotypes more intensely than the standard variety.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 03:21:05 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Kulkarni", "Vivek", ""], ["Wang", "William Yang", ""]]}, {"id": "1712.08302", "submitter": "Shun Kiyono", "authors": "Shun Kiyono, Sho Takase, Jun Suzuki, Naoaki Okazaki, Kentaro Inui,\n  Masaaki Nagata", "title": "Source-side Prediction for Neural Headline Generation", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder model is widely used in natural language generation\ntasks. However, the model sometimes suffers from repeated redundant generation,\nmisses important phrases, and includes irrelevant entities. Toward solving\nthese problems we propose a novel source-side token prediction module. Our\nmethod jointly estimates the probability distributions over source and target\nvocabularies to capture a correspondence between source and target tokens. The\nexperiments show that the proposed model outperforms the current\nstate-of-the-art method in the headline generation task. Additionally, we show\nthat our method has an ability to learn a reasonable token-wise correspondence\nwithout knowing any true alignments.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 04:36:07 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Kiyono", "Shun", ""], ["Takase", "Sho", ""], ["Suzuki", "Jun", ""], ["Okazaki", "Naoaki", ""], ["Inui", "Kentaro", ""], ["Nagata", "Masaaki", ""]]}, {"id": "1712.08349", "submitter": "Leon Derczynski", "authors": "Leon Derczynski and Matthew Rowe", "title": "Tracking the Diffusion of Named Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing studies of how information diffuses across social networks have thus\nfar concentrated on analysing and recovering the spread of deterministic\ninnovations such as URLs, hashtags, and group membership. However investigating\nhow mentions of real-world entities appear and spread has yet to be explored,\nlargely due to the computationally intractable nature of performing large-scale\nentity extraction. In this paper we present, to the best of our knowledge, one\nof the first pieces of work to closely examine the diffusion of named entities\non social media, using Reddit as our case study platform. We first investigate\nhow named entities can be accurately recognised and extracted from discussion\nposts. We then use these extracted entities to study the patterns of entity\ncascades and how the probability of a user adopting an entity (i.e. mentioning\nit) is associated with exposures to the entity. We put these pieces together by\npresenting a parallelised diffusion model that can forecast the probability of\nentity adoption, finding that the influence of adoption between users can be\ncharacterised by their prior interactions -- as opposed to whether the users\npropagated entity-adoptions beforehand. Our findings have important\nimplications for researchers studying influence and language, and for community\nanalysts who wish to understand entity-level influence dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 09:01:00 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 14:45:25 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Derczynski", "Leon", ""], ["Rowe", "Matthew", ""]]}, {"id": "1712.08439", "submitter": "Jakub Dutkiewicz", "authors": "Jakub Dutkiewicz and Czes{\\l}aw J\\k{e}drzejek", "title": "Novel Ranking-Based Lexical Similarity Measure for Word Embedding", "comments": "7 pages; 1 page of references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional semantics models derive word space from linguistic items in\ncontext. Meaning is obtained by defining a distance measure between vectors\ncorresponding to lexical entities. Such vectors present several problems. In\nthis paper we provide a guideline for post process improvements to the baseline\nvectors. We focus on refining the similarity aspect, address imperfections of\nthe model by applying the hubness reduction method, implementing relational\nknowledge into the model, and providing a new ranking similarity definition\nthat give maximum weight to the top 1 component value. This feature ranking is\nsimilar to the one used in information retrieval. All these enrichments\noutperform current literature results for joint ESL and TOEF sets comparison.\nSince single word embedding is a basic element of any semantic task one can\nexpect a significant improvement of results for these tasks. Moreover, our\nimproved method of text processing can be translated to continuous distributed\nrepresentation of biological sequences for deep proteomics and genomics.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 13:40:41 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Dutkiewicz", "Jakub", ""], ["J\u0119drzejek", "Czes\u0142aw", ""]]}, {"id": "1712.08636", "submitter": "Yunhao Jiao", "authors": "Yunhao Jiao, Cheng Li, Fei Wu, Qiaozhu Mei", "title": "Find the Conversation Killers: a Predictive Study of Thread-ending Posts", "comments": "Accepted by WWW 2018 (The Web Conference, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to improve the quality of conversations in online communities has\nattracted considerable attention recently. Having engaged, urbane, and reactive\nonline conversations has a critical effect on the social life of Internet\nusers. In this study, we are particularly interested in identifying a post in a\nmulti-party conversation that is unlikely to be further replied to, which\ntherefore kills that thread of the conversation. For this purpose, we propose a\ndeep learning model called the ConverNet. ConverNet is attractive due to its\ncapability of modeling the internal structure of a long conversation and its\nappropriate encoding of the contextual information of the conversation, through\neffective integration of attention mechanisms. Empirical experiments on\nreal-world datasets demonstrate the effectiveness of the proposal model. For\nthe widely concerned topic, our analysis also offers implications for improving\nthe quality and user experience of online conversations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 19:58:01 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jiao", "Yunhao", ""], ["Li", "Cheng", ""], ["Wu", "Fei", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1712.08647", "submitter": "Taha Yasseri", "authors": "Dong Nguyen and Barbara McGillivray and Taha Yasseri", "title": "Emo, Love, and God: Making Sense of Urban Dictionary, a Crowd-Sourced\n  Online Dictionary", "comments": "Accepted, to appear in Royal Society Open Science. Data available\n  upon request", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet facilitates large-scale collaborative projects and the emergence\nof Web 2.0 platforms, where producers and consumers of content unify, has\ndrastically changed the information market. On the one hand, the promise of the\n\"wisdom of the crowd\" has inspired successful projects such as Wikipedia, which\nhas become the primary source of crowd-based information in many languages. On\nthe other hand, the decentralized and often un-monitored environment of such\nprojects may make them susceptible to low quality content. In this work, we\nfocus on Urban Dictionary, a crowd-sourced online dictionary. We combine\ncomputational methods with qualitative annotation and shed light on the overall\nfeatures of Urban Dictionary in terms of growth, coverage and types of content.\nWe measure a high presence of opinion-focused entries, as opposed to the\nmeaning-focused entries that we expect from traditional dictionaries.\nFurthermore, Urban Dictionary covers many informal, unfamiliar words as well as\nproper nouns. Urban Dictionary also contains offensive content, but highly\noffensive content tends to receive lower scores through the dictionary's voting\nsystem. The low threshold to include new material in Urban Dictionary enables\nquick recording of new words and new meanings, but the resulting heterogeneous\ncontent can pose challenges in using Urban Dictionary as a source to study\nlanguage innovation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 20:27:11 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 13:52:54 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Nguyen", "Dong", ""], ["McGillivray", "Barbara", ""], ["Yasseri", "Taha", ""]]}, {"id": "1712.08697", "submitter": "Alexander Trott", "authors": "Alexander Trott, Caiming Xiong, Richard Socher", "title": "Interpretable Counting for Visual Question Answering", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions that require counting a variety of objects in images remain a major\nchallenge in visual question answering (VQA). The most common approaches to VQA\ninvolve either classifying answers based on fixed length representations of\nboth the image and question or summing fractional counts estimated from each\nsection of the image. In contrast, we treat counting as a sequential decision\nprocess and force our model to make discrete choices of what to count.\nSpecifically, the model sequentially selects from detected objects and learns\ninteractions between objects that influence subsequent selections. A\ndistinction of our approach is its intuitive and interpretable output, as\ndiscrete counts are automatically grounded in the image. Furthermore, our\nmethod outperforms the state of the art architecture for VQA on multiple\nmetrics that evaluate counting.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 01:44:45 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:00:43 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Trott", "Alexander", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1712.08793", "submitter": "Adriana Guevara-Rukoz", "authors": "Adriana Guevara-Rukoz, Alejandrina Cristia, Bogdan Ludusan, Roland\n  Thiolli\\`ere, Andrew Martin, Reiko Mazuka, Emmanuel Dupoux", "title": "Are words easier to learn from infant- than adult-directed speech? A\n  quantitative corpus-based investigation", "comments": "Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether infant-directed speech (IDS) could facilitate word\nform learning when compared to adult-directed speech (ADS). To study this, we\nexamine the distribution of word forms at two levels, acoustic and\nphonological, using a large database of spontaneous speech in Japanese. At the\nacoustic level we show that, as has been documented before for phonemes, the\nrealizations of words are more variable and less discriminable in IDS than in\nADS. At the phonological level, we find an effect in the opposite direction:\nthe IDS lexicon contains more distinctive words (such as onomatopoeias) than\nthe ADS counterpart. Combining the acoustic and phonological metrics together\nin a global discriminability score reveals that the bigger separation of\nlexical categories in the phonological space does not compensate for the\nopposite effect observed at the acoustic level. As a result, IDS word forms are\nstill globally less discriminable than ADS word forms, even though the effect\nis numerically small. We discuss the implication of these findings for the view\nthat the functional role of IDS is to improve language learnability.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 15:55:54 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Guevara-Rukoz", "Adriana", ""], ["Cristia", "Alejandrina", ""], ["Ludusan", "Bogdan", ""], ["Thiolli\u00e8re", "Roland", ""], ["Martin", "Andrew", ""], ["Mazuka", "Reiko", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1712.08819", "submitter": "Alexander Panchenko", "authors": "Chris Biemann, Stefano Faralli, Alexander Panchenko, Simone Paolo\n  Ponzetto", "title": "A Framework for Enriching Lexical Semantic Resources with Distributional\n  Semantics", "comments": "Accepted for publication in the journal of Natural Language\n  Engineering, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to combining distributional semantic representations\ninduced from text corpora with manually constructed lexical-semantic networks.\nWhile both kinds of semantic resources are available with high lexical\ncoverage, our aligned resource combines the domain specificity and availability\nof contextual information from distributional models with the conciseness and\nhigh quality of manually crafted lexical networks. We start with a\ndistributional representation of induced senses of vocabulary terms, which are\naccompanied with rich context information given by related lexical items. We\nthen automatically disambiguate such representations to obtain a full-fledged\nproto-conceptualization, i.e. a typed graph of induced word senses. In a final\nstep, this proto-conceptualization is aligned to a lexical ontology, resulting\nin a hybrid aligned resource. Moreover, unmapped induced senses are associated\nwith a semantic type in order to connect them to the core resource. Manual\nevaluations against ground-truth judgments for different stages of our method\nas well as an extrinsic evaluation on a knowledge-based Word Sense\nDisambiguation benchmark all indicate the high quality of the new hybrid\nresource. Additionally, we show the benefits of enriching top-down lexical\nknowledge resources with bottom-up distributional information from text for\naddressing high-end knowledge acquisition tasks such as cleaning hypernym\ngraphs and learning taxonomies from scratch.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 18:46:58 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Biemann", "Chris", ""], ["Faralli", "Stefano", ""], ["Panchenko", "Alexander", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1712.08841", "submitter": "Han He", "authors": "Han He, Lei Wu, Xiaokun Yang, Hua Yan, Zhimin Gao, Yi Feng, George\n  Townsend", "title": "Dual Long Short-Term Memory Networks for Sub-Character Representation\n  Learning", "comments": "Accepted & forthcoming at ITNG-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characters have commonly been regarded as the minimal processing unit in\nNatural Language Processing (NLP). But many non-latin languages have\nhieroglyphic writing systems, involving a big alphabet with thousands or\nmillions of characters. Each character is composed of even smaller parts, which\nare often ignored by the previous work. In this paper, we propose a novel\narchitecture employing two stacked Long Short-Term Memory Networks (LSTMs) to\nlearn sub-character level representation and capture deeper level of semantic\nmeanings. To build a concrete study and substantiate the efficiency of our\nneural architecture, we take Chinese Word Segmentation as a research case\nexample. Among those languages, Chinese is a typical case, for which every\ncharacter contains several components called radicals. Our networks employ a\nshared radical level embedding to solve both Simplified and Traditional Chinese\nWord Segmentation, without extra Traditional to Simplified Chinese conversion,\nin such a highly end-to-end way the word segmentation can be significantly\nsimplified compared to the previous work. Radical level embeddings can also\ncapture deeper semantic meaning below character level and improve the system\nperformance of learning. By tying radical and character embeddings together,\nthe parameter count is reduced whereas semantic knowledge is shared and\ntransferred between two levels, boosting the performance largely. On 3 out of 4\nBakeoff 2005 datasets, our method surpassed state-of-the-art results by up to\n0.4%. Our results are reproducible, source codes and corpora are available on\nGitHub.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 21:12:23 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 12:09:09 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["He", "Han", ""], ["Wu", "Lei", ""], ["Yang", "Xiaokun", ""], ["Yan", "Hua", ""], ["Gao", "Zhimin", ""], ["Feng", "Yi", ""], ["Townsend", "George", ""]]}, {"id": "1712.08862", "submitter": "Shiliang Sun", "authors": "Feng Jin, Shiliang Sun", "title": "Neural Network Multitask Learning for Traffic Flow Forecasting", "comments": null, "journal-ref": "Proceedings of the International Joint Conference on Neural\n  Networks (IJCNN), 2008. pp. 1898-1902", "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neural network approaches for traffic flow forecasting are\nusually single task learning (STL) models, which do not take advantage of the\ninformation provided by related tasks. In contrast to STL, multitask learning\n(MTL) has the potential to improve generalization by transferring information\nin training signals of extra tasks. In this paper, MTL based neural networks\nare used for traffic flow forecasting. For neural network MTL, a\nbackpropagation (BP) network is constructed by incorporating traffic flows at\nseveral contiguous time instants into an output layer. Nodes in the output\nlayer can be seen as outputs of different but closely related STL tasks.\nComprehensive experiments on urban vehicular traffic flow data and comparisons\nwith STL show that MTL in BP neural networks is a promising and effective\napproach for traffic flow forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 00:27:09 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jin", "Feng", ""], ["Sun", "Shiliang", ""]]}, {"id": "1712.08917", "submitter": "Henrico Brum", "authors": "Henrico Bertini Brum, Maria das Gra\\c{c}as Volpe Nunes", "title": "Building a Sentiment Corpus of Tweets in Brazilian Portuguese", "comments": "Accepted for publication in 11th International Conference on Language\n  Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large amount of data available in social media, forums and websites\nmotivates researches in several areas of Natural Language Processing, such as\nsentiment analysis. The popularity of the area due to its subjective and\nsemantic characteristics motivates research on novel methods and approaches for\nclassification. Hence, there is a high demand for datasets on different domains\nand different languages. This paper introduces TweetSentBR, a sentiment corpora\nfor Brazilian Portuguese manually annotated with 15.000 sentences on TV show\ndomain. The sentences were labeled in three classes (positive, neutral and\nnegative) by seven annotators, following literature guidelines for ensuring\nreliability on the annotation. We also ran baseline experiments on polarity\nclassification using three machine learning methods, reaching 80.99% on\nF-Measure and 82.06% on accuracy in binary classification, and 59.85% F-Measure\nand 64.62% on accuracy on three point classification.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 13:23:58 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Brum", "Henrico Bertini", ""], ["Nunes", "Maria das Gra\u00e7as Volpe", ""]]}, {"id": "1712.08933", "submitter": "Ivandre Paraboni", "authors": "Danillo da Silva Rocha and Alex Gwo Jen Lan and Ivandre Paraboni", "title": "Semi-automatic definite description annotation: a first report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies in Referring Expression Generation (REG) often make use of corpora of\ndefinite descriptions produced by human subjects in controlled experiments.\nExperiments of this kind, which are essential for the study of reference\nphenomena and many others, may however include a considerable amount of noise.\nHuman subjects may easily lack attention, or may simply misunderstand the task\nat hand and, as a result, the elicited data may include large proportions of\nambiguous or ill-formed descriptions. In addition to that, REG corpora are\nusually collected for the study of semantics-related phenomena, and it is often\nthe case that the elicited descriptions (and their input contexts) need to be\nannotated with their corresponding semantic properties. This, as in many other\nfields, may require considerable time and skilled annotators. As a means to\ntackle both kinds of difficulties - poor data quality and high annotation costs\n- this work discusses a semi-automatic method for the annotation of definite\ndescriptions produced by human subjects in REG data collection experiments. The\nmethod makes use of simple rules to establish associations between words and\nmeanings, and is intended to facilitate the design of experiments that produce\nREG corpora.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 14:54:22 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Rocha", "Danillo da Silva", ""], ["Lan", "Alex Gwo Jen", ""], ["Paraboni", "Ivandre", ""]]}, {"id": "1712.08941", "submitter": "Fabio Crestani Prof.", "authors": "Kasturi Dewi Varathan and Anastasia Giachanou and Fabio Crestani", "title": "Comparative Opinion Mining: A Review", "comments": null, "journal-ref": "Journal of the Association for Information Science and Technology,\n  68(4), 2017", "doi": "10.1002/asi.23716", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion mining refers to the use of natural language processing, text\nanalysis and computational linguistics to identify and extract subjective\ninformation in textual material. Opinion mining, also known as sentiment\nanalysis, has received a lot of attention in recent times, as it provides a\nnumber of tools to analyse the public opinion on a number of different topics.\nComparative opinion mining is a subfield of opinion mining that deals with\nidentifying and extracting information that is expressed in a comparative form\n(e.g.~\"paper X is better than the Y\"). Comparative opinion mining plays a very\nimportant role when ones tries to evaluate something, as it provides a\nreference point for the comparison. This paper provides a review of the area of\ncomparative opinion mining. It is the first review that cover specifically this\ntopic as all previous reviews dealt mostly with general opinion mining. This\nsurvey covers comparative opinion mining from two different angles. One from\nperspective of techniques and the other from perspective of comparative opinion\nelements. It also incorporates preprocessing tools as well as dataset that were\nused by the past researchers that can be useful to the future researchers in\nthe field of comparative opinion mining.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 16:16:07 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Varathan", "Kasturi Dewi", ""], ["Giachanou", "Anastasia", ""], ["Crestani", "Fabio", ""]]}, {"id": "1712.08992", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Preethi Jyothi, Sriram Ganapathy", "title": "Leveraging Native Language Speech for Accent Identification using Deep\n  Siamese Networks", "comments": "Published in ASRU 2017", "journal-ref": null, "doi": "10.1109/ASRU.2017.8268994", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic accent identification is important for several\napplications like speaker profiling and recognition as well as for improving\nspeech recognition systems. The accented nature of speech can be primarily\nattributed to the influence of the speaker's native language on the given\nspeech recording. In this paper, we propose a novel accent identification\nsystem whose training exploits speech in native languages along with the\naccented speech. Specifically, we develop a deep Siamese network-based model\nwhich learns the association between accented speech recordings and the native\nlanguage speech recordings. The Siamese networks are trained with i-vector\nfeatures extracted from the speech recordings using either an unsupervised\nGaussian mixture model (GMM) or a supervised deep neural network (DNN) model.\nWe perform several accent identification experiments using the CSLU Foreign\nAccented English (FAE) corpus. In these experiments, our proposed approach\nusing deep Siamese networks yield significant relative performance improvements\nof 15.4 percent on a 10-class accent identification task, over a baseline\nDNN-based classification system that uses GMM i-vectors. Furthermore, we\npresent a detailed error analysis of the proposed accent identification system.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 02:28:32 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:48:58 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Siddhant", "Aditya", ""], ["Jyothi", "Preethi", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "1712.09127", "submitter": "Baiyang Wang", "authors": "Baiyang Wang, Diego Klabjan", "title": "Generative Adversarial Nets for Multiple Text Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial nets (GANs) have been successfully applied to the\nartificial generation of image data. In terms of text data, much has been done\non the artificial generation of natural language from a single corpus. We\nconsider multiple text corpora as the input data, for which there can be two\napplications of GANs: (1) the creation of consistent cross-corpus word\nembeddings given different word embeddings per corpus; (2) the generation of\nrobust bag-of-words document embeddings for each corpora. We demonstrate our\nGAN models on real-world text data sets from different corpora, and show that\nembeddings from both models lead to improvements in supervised learning\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 20:16:07 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Wang", "Baiyang", ""], ["Klabjan", "Diego", ""]]}, {"id": "1712.09185", "submitter": "Chu-Cheng Lin", "authors": "Chu-Cheng Lin, Dongyeop Kang, Michael Gamon, Madian Khabsa, Ahmed\n  Hassan Awadallah, Patrick Pantel", "title": "Actionable Email Intent Modeling with Reparametrized RNNs", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emails in the workplace are often intentional calls to action for its\nrecipients. We propose to annotate these emails for what action its recipient\nwill take. We argue that our approach of action-based annotation is more\nscalable and theory-agnostic than traditional speech-act-based email intent\nannotation, while still carrying important semantic and pragmatic information.\nWe show that our action-based annotation scheme achieves good inter-annotator\nagreement. We also show that we can leverage threaded messages from other\ndomains, which exhibit comparable intents in their conversation, with domain\nadaptive RAINBOW (Recurrently AttentIve Neural Bag-Of-Words). On a collection\nof datasets consisting of IRC, Reddit, and email, our reparametrized RNNs\noutperform common multitask/multidomain approaches on several speech act\nrelated tasks. We also experiment with a minimally supervised scenario of email\nrecipient action classification, and find the reparametrized RNNs learn a\nuseful representation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 06:02:36 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Lin", "Chu-Cheng", ""], ["Kang", "Dongyeop", ""], ["Gamon", "Michael", ""], ["Khabsa", "Madian", ""], ["Awadallah", "Ahmed Hassan", ""], ["Pantel", "Patrick", ""]]}, {"id": "1712.09359", "submitter": "Renato Fabbri", "authors": "Renato Fabbri", "title": "Basic concepts and tools for the Toki Pona minimal and constructed\n  language: description of the language and main issues; analysis of the\n  vocabulary; text synthesis and syntax highlighting; Wordnet synsets", "comments": "Python and Vim scripts in this repository:\n  https://github.com/ttm/prv/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A minimal constructed language (conlang) is useful for experiments and\ncomfortable for making tools. The Toki Pona (TP) conlang is minimal both in the\nvocabulary (with only 14 letters and 124 lemmas) and in the (about) 10 syntax\nrules. The language is useful for being a used and somewhat established minimal\nconlang with at least hundreds of fluent speakers. This article exposes current\nconcepts and resources for TP, and makes available Python (and Vim) scripted\nroutines for the analysis of the language, synthesis of texts, syntax\nhighlighting schemes, and the achievement of a preliminary TP Wordnet. Focus is\non the analysis of the basic vocabulary, as corpus analyses were found. The\nsynthesis is based on sentence templates, relates to context by keeping track\nof used words, and renders larger texts by using a fixed number of phonemes\n(e.g. for poems) and number of sentences, words and letters (e.g. for\nparagraphs). Syntax highlighting reflects morphosyntactic classes given in the\nofficial dictionary and different solutions are described and implemented in\nthe well-established Vim text editor. The tentative TP Wordnet is made\navailable in three patterns of relations between synsets and word lemmas. In\nsummary, this text holds potentially novel conceptualizations about, and tools\nand results in analyzing, synthesizing and syntax highlighting the TP language.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 18:43:32 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 14:10:05 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 00:18:33 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Fabbri", "Renato", ""]]}, {"id": "1712.09391", "submitter": "Subhro Roy", "authors": "Subhro Roy and Dan Roth", "title": "Mapping to Declarative Knowledge for Word Problem Solving", "comments": "Accepted at TACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Math word problems form a natural abstraction to a range of quantitative\nreasoning problems, such as understanding financial news, sports results, and\ncasualties of war. Solving such problems requires the understanding of several\nmathematical concepts such as dimensional analysis, subset relationships, etc.\nIn this paper, we develop declarative rules which govern the translation of\nnatural language description of these concepts to math expressions. We then\npresent a framework for incorporating such declarative knowledge into word\nproblem solving. Our method learns to map arithmetic word problem text to math\nexpressions, by learning to select the relevant declarative knowledge for each\noperation of the solution expression. This provides a way to handle multiple\nconcepts in the same problem while, at the same time, support interpretability\nof the answer expression. Our method models the mapping to declarative\nknowledge as a latent variable, thus removing the need for expensive\nannotations. Experimental evaluation suggests that our domain knowledge based\nsolver outperforms all other systems, and that it generalizes better in the\nrealistic case where the training data it is exposed to is biased in a\ndifferent way than the test data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 20:21:09 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Roy", "Subhro", ""], ["Roth", "Dan", ""]]}, {"id": "1712.09405", "submitter": "Tomas Mikolov", "authors": "Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch,\n  Armand Joulin", "title": "Advances in Pre-Training Distributed Word Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Natural Language Processing applications nowadays rely on pre-trained\nword representations estimated from large text corpora such as news\ncollections, Wikipedia and Web Crawl. In this paper, we show how to train\nhigh-quality word vector representations by using a combination of known tricks\nthat are however rarely used together. The main result of our work is the new\nset of publicly available pre-trained models that outperform the current state\nof the art by a large margin on a number of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 21:00:04 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Mikolov", "Tomas", ""], ["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Puhrsch", "Christian", ""], ["Joulin", "Armand", ""]]}, {"id": "1712.09444", "submitter": "Ronan Collobert", "authors": "Vitaliy Liptchinsky, Gabriel Synnaeve, Ronan Collobert", "title": "Letter-Based Speech Recognition with Gated ConvNets", "comments": "13 pages.arXiv admin note: text overlap with arXiv:1609.03193", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent literature, \"end-to-end\" speech systems often refer to\nletter-based acoustic models trained in a sequence-to-sequence manner, either\nvia a recurrent model or via a structured output learning approach (such as\nCTC). In contrast to traditional phone (or senone)-based approaches, these\n\"end-to-end'' approaches alleviate the need of word pronunciation modeling, and\ndo not require a \"forced alignment\" step at training time. Phone-based\napproaches remain however state of the art on classical benchmarks. In this\npaper, we propose a letter-based speech recognition system, leveraging a\nConvNet acoustic model. Key ingredients of the ConvNet are Gated Linear Units\nand high dropout. The ConvNet is trained to map audio sequences to their\ncorresponding letter transcriptions, either via a classical CTC approach, or\nvia a recent variant called ASG. Coupled with a simple decoder at inference\ntime, our system matches the best existing letter-based systems on WSJ (in word\nerror rate), and shows near state of the art performance on LibriSpeech.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 17:42:15 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 01:19:21 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Liptchinsky", "Vitaliy", ""], ["Synnaeve", "Gabriel", ""], ["Collobert", "Ronan", ""]]}, {"id": "1712.09509", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Gehui Shen, Zhihong Deng", "title": "A Gap-Based Framework for Chinese Word Segmentation via Very Deep\n  Convolutional Networks", "comments": "Under review as a conference paper at ACL 2018; 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous approaches to Chinese word segmentation can be roughly\nclassified into character-based and word-based methods. The former regards this\ntask as a sequence-labeling problem, while the latter directly segments\ncharacter sequence into words. However, if we consider segmenting a given\nsentence, the most intuitive idea is to predict whether to segment for each gap\nbetween two consecutive characters, which in comparison makes previous\napproaches seem too complex. Therefore, in this paper, we propose a gap-based\nframework to implement this intuitive idea. Moreover, very deep convolutional\nneural networks, namely, ResNets and DenseNets, are exploited in our\nexperiments. Results show that our approach outperforms the best\ncharacter-based and word-based methods on 5 benchmarks, without any further\npost-processing module (e.g. Conditional Random Fields) nor beam search.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 06:44:02 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Sun", "Zhiqing", ""], ["Shen", "Gehui", ""], ["Deng", "Zhihong", ""]]}, {"id": "1712.09518", "submitter": "Usman Zafar Mr", "authors": "Salman Ahmad Ansari, Usman Zafar and Asim Karim", "title": "Improving Text Normalization by Optimizing Nearest Neighbor Matching", "comments": "A short paper which outlines an approach for text normalization ( 4\n  pages long with 1 additional page for references )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text normalization is an essential task in the processing and analysis of\nsocial media that is dominated with informal writing. It aims to map informal\nwords to their intended standard forms. Previously proposed text normalization\napproaches typically require manual selection of parameters for improved\nperformance. In this paper, we present an automatic optimizationbased nearest\nneighbor matching approach for text normalization. This approach is motivated\nby the observation that text normalization is essentially a matching problem\nand nearest neighbor matching with an adaptive similarity function is the most\ndirect procedure for it. Our similarity function incorporates weighted\ncontributions of contextual, string, and phonetic similarity, and the nearest\nneighbor matching involves a minimum similarity threshold. These four\nparameters are tuned efficiently using grid search. We evaluate the performance\nof our approach on two benchmark datasets. The results demonstrate that\nparameter tuning on small sized labeled datasets produce state-of-the-art text\nnormalization performances. Thus, this approach allows practically easy\nconstruction of evolving domain-specific normalization lexicons\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 08:02:26 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Ansari", "Salman Ahmad", ""], ["Zafar", "Usman", ""], ["Karim", "Asim", ""]]}, {"id": "1712.09662", "submitter": "Qiming Chen", "authors": "Qiming Chen, Ren Wu", "title": "CNN Is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Convolution Neural Network (CNN) has demonstrated the unique advantage in\naudio, image and text learning; recently it has also challenged Recurrent\nNeural Networks (RNNs) with long short-term memory cells (LSTM) in\nsequence-to-sequence learning, since the computations involved in CNN are\neasily parallelizable whereas those involved in RNN are mostly sequential,\nleading to a performance bottleneck. However, unlike RNN, the native CNN lacks\nthe history sensitivity required for sequence transformation; therefore\nenhancing the sequential order awareness, or position-sensitivity, becomes the\nkey to make CNN the general deep learning model. In this work we introduce an\nextended CNN model with strengthen position-sensitivity, called PoseNet. A\nnotable feature of PoseNet is the asymmetric treatment of position information\nin the encoder and the decoder. Experiments shows that PoseNet allows us to\nimprove the accuracy of CNN based sequence-to-sequence learning significantly,\nachieving around 33-36 BLEU scores on the WMT 2014 English-to-German\ntranslation task, and around 44-46 BLEU scores on the English-to-French\ntranslation task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 19:49:09 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Chen", "Qiming", ""], ["Wu", "Ren", ""]]}, {"id": "1712.09687", "submitter": "Tim Rockt\\\"aschel", "authors": "Tim Rockt\\\"aschel", "title": "Combining Representation Learning with Logic for Language Processing", "comments": "PhD Thesis, University College London, Submitted and accepted in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art in many natural language processing and\nautomated knowledge base completion tasks is held by representation learning\nmethods which learn distributed vector representations of symbols via\ngradient-based optimization. They require little or no hand-crafted features,\nthus avoiding the need for most preprocessing steps and task-specific\nassumptions. However, in many cases representation learning requires a large\namount of annotated training data to generalize well to unseen data. Such\nlabeled training data is provided by human annotators who often use formal\nlogic as the language for specifying annotations. This thesis investigates\ndifferent combinations of representation learning methods with logic for\nreducing the need for annotated training data, and for improving\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 21:09:36 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1712.09783", "submitter": "Wenlin Wang", "authors": "Wenlin Wang, Zhe Gan, Wenqi Wang, Dinghan Shen, Jiaji Huang, Wei Ping,\n  Sanjeev Satheesh, Lawrence Carin", "title": "Topic Compositional Neural Language Model", "comments": "To appear in AISTATS 2018, updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a Topic Compositional Neural Language Model (TCNLM), a novel\nmethod designed to simultaneously capture both the global semantic meaning and\nthe local word ordering structure in a document. The TCNLM learns the global\nsemantic coherence of a document via a neural topic model, and the probability\nof each learned latent topic is further used to build a Mixture-of-Experts\n(MoE) language model, where each expert (corresponding to one topic) is a\nrecurrent neural network (RNN) that accounts for learning the local structure\nof a word sequence. In order to train the MoE model efficiently, a matrix\nfactorization method is applied, by extending each weight matrix of the RNN to\nbe an ensemble of topic-dependent weight matrices. The degree to which each\nmember of the ensemble is used is tied to the document-dependent probability of\nthe corresponding topics. Experimental results on several corpora show that the\nproposed approach outperforms both a pure RNN-based model and other\ntopic-guided language models. Further, our model yields sensible topics, and\nalso has the capacity to generate meaningful sentences conditioned on given\ntopics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 08:05:48 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 13:50:32 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 17:33:53 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Wang", "Wenlin", ""], ["Gan", "Zhe", ""], ["Wang", "Wenqi", ""], ["Shen", "Dinghan", ""], ["Huang", "Jiaji", ""], ["Ping", "Wei", ""], ["Satheesh", "Sanjeev", ""], ["Carin", "Lawrence", ""]]}, {"id": "1712.09827", "submitter": "Mark Last", "authors": "Guy Danon and Mark Last", "title": "A Syntactic Approach to Domain-Specific Automatic Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factoid questions are questions that require short fact-based answers.\nAutomatic generation (AQG) of factoid questions from a given text can\ncontribute to educational activities, interactive question answering systems,\nsearch engines, and other applications. The goal of our research is to generate\nfactoid source-question-answer triplets based on a specific domain. We propose\na four-component pipeline, which obtains as input a training corpus of\ndomain-specific documents, along with a set of declarative sentences from the\nsame domain, and generates as output a set of factoid questions that refer to\nthe source sentences but are slightly different from them, so that a\nquestion-answering system or a person can be asked a question that requires a\ndeeper understanding and knowledge than a simple word-matching. Contrary to\nexisting domain-specific AQG systems that utilize the template-based approach\nto question generation, we propose to transform each source sentence into a set\nof questions by applying a series of domain-independent rules (a\nsyntactic-based approach). Our pipeline was evaluated in the domain of cyber\nsecurity using a series of experiments on each component of the pipeline\nseparately and on the end-to-end system. The proposed approach generated a\nhigher percentage of acceptable questions than a prior state-of-the-art AQG\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 11:15:30 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Danon", "Guy", ""], ["Last", "Mark", ""]]}, {"id": "1712.09929", "submitter": "Karan Grewal", "authors": "Karan Grewal, Khai N. Truong", "title": "On the Challenges of Detecting Rude Conversational Behaviour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we aim to identify moments of rudeness between two\nindividuals. In particular, we segment all occurrences of rudeness in\nconversations into three broad, distinct categories and try to identify each.\nWe show how machine learning algorithms can be used to identify rudeness based\non acoustic and semantic signals extracted from conversations. Furthermore, we\nmake note of our shortcomings in this task and highlight what makes this\nproblem inherently difficult. Finally, we provide next steps which are needed\nto ensure further success in identifying rudeness in conversations.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 16:49:40 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Grewal", "Karan", ""], ["Truong", "Khai N.", ""]]}, {"id": "1712.09943", "submitter": "Sungjin Lee", "authors": "Sungjin Lee", "title": "Toward Continual Learning for Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While end-to-end neural conversation models have led to promising advances in\nreducing hand-crafted features and errors induced by the traditional complex\nsystem architecture, they typically require an enormous amount of data due to\nthe lack of modularity. Previous studies adopted a hybrid approach with\nknowledge-based components either to abstract out domain-specific information\nor to augment data to cover more diverse patterns. On the contrary, we propose\nto directly address the problem using recent developments in the space of\ncontinual learning for neural models. Specifically, we adopt a\ndomain-independent neural conversational model and introduce a novel neural\ncontinual learning algorithm that allows a conversational agent to accumulate\nskills across different tasks in a data-efficient way. To the best of our\nknowledge, this is the first work that applies continual learning to\nconversation systems. We verified the efficacy of our method through a\nconversational skill transfer from either synthetic dialogs or human-human\ndialogs to human-computer conversations in a customer support domain.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 17:21:42 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 19:19:52 GMT"}, {"version": "v3", "created": "Tue, 9 Jan 2018 17:53:37 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Lee", "Sungjin", ""]]}, {"id": "1712.10054", "submitter": "Edgar Altszyler", "authors": "Edgar Altszyler, Mariano Sigman and Diego Fernandez Slezak", "title": "Corpus specificity in LSA and Word2vec: the role of out-of-domain\n  documents", "comments": null, "journal-ref": "Proceedings of the 3rd Workshop on Representation Learning for\n  NLP, pages 1-10, 2018, ACL", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Semantic Analysis (LSA) and Word2vec are some of the most widely used\nword embeddings. Despite the popularity of these techniques, the precise\nmechanisms by which they acquire new semantic relations between words remain\nunclear. In the present article we investigate whether LSA and Word2vec\ncapacity to identify relevant semantic dimensions increases with size of\ncorpus. One intuitive hypothesis is that the capacity to identify relevant\ndimensions should increase as the amount of data increases. However, if corpus\nsize grow in topics which are not specific to the domain of interest, signal to\nnoise ratio may weaken. Here we set to examine and distinguish these\nalternative hypothesis. To investigate the effect of corpus specificity and\nsize in word-embeddings we study two ways for progressive elimination of\ndocuments: the elimination of random documents vs. the elimination of documents\nunrelated to a specific task. We show that Word2vec can take advantage of all\nthe documents, obtaining its best performance when it is trained with the whole\ncorpus. On the contrary, the specialization (removal of out-of-domain\ndocuments) of the training corpus, accompanied by a decrease of dimensionality,\ncan increase LSA word-representation quality while speeding up the processing\ntime. Furthermore, we show that the specialization without the decrease in LSA\ndimensionality can produce a strong performance reduction in specific tasks.\nFrom a cognitive-modeling point of view, we point out that LSA's word-knowledge\nacquisitions may not be efficiently exploiting higher-order co-occurrences and\nglobal relations, whereas Word2vec does.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:56:16 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Altszyler", "Edgar", ""], ["Sigman", "Mariano", ""], ["Slezak", "Diego Fernandez", ""]]}, {"id": "1712.10066", "submitter": "Mikael K{\\aa}geb\\\"ack", "authors": "Maria Larsson, Amanda Nilsson, Mikael K{\\aa}geb\\\"ack", "title": "Disentangled Representations for Manipulation of Sentiment in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to change arbitrary aspects of a text while leaving the core\nmessage intact could have a strong impact in fields like marketing and politics\nby enabling e.g. automatic optimization of message impact and personalized\nlanguage adapted to the receiver's profile. In this paper we take a first step\ntowards such a system by presenting an algorithm that can manipulate the\nsentiment of a text while preserving its semantics using disentangled\nrepresentations. Validation is performed by examining trajectories in embedding\nspace and analyzing transformed sentences for semantic preservation while\nexpression of desired sentiment shift.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 11:18:35 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Larsson", "Maria", ""], ["Nilsson", "Amanda", ""], ["K\u00e5geb\u00e4ck", "Mikael", ""]]}, {"id": "1712.10190", "submitter": "Victor Thompson Vt", "authors": "Victor Thompson", "title": "Detecting Cross-Lingual Plagiarism Using Simulated Word Embeddings", "comments": "This is a mildly edited version that is currently undergoing review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual plagiarism (CLP) occurs when texts written in one language are\ntranslated into a different language and used without acknowledging the\noriginal sources. One of the most common methods for detecting CLP requires\nonline machine translators (such as Google or Microsoft translate) which are\nnot always available, and given that plagiarism detection typically involves\nlarge document comparison, the amount of translations required would overwhelm\nan online machine translator, especially when detecting plagiarism over the\nweb. In addition, when translated texts are replaced with their synonyms, using\nonline machine translators to detect CLP would result in poor performance. This\npaper addresses the problem of cross-lingual plagiarism detection (CLPD) by\nproposing a model that uses simulated word embeddings to reproduce the\npredictions of an online machine translator (Google translate) when detecting\nCLP. The simulated embeddings comprise of translated words in different\nlanguages mapped in a common space, and replicated to increase the prediction\nprobability of retrieving the translations of a word (and their synonyms) from\nthe model. Unlike most existing models, the proposed model does not require\nparallel corpora, and accommodates multiple languages (multi-lingual). We\ndemonstrated the effectiveness of the proposed model in detecting CLP in\nstandard datasets that contain CLP cases, and evaluated its performance against\na state-of-the-art baseline that relies on online machine translator (T+MA\nmodel). Evaluation results revealed that the proposed model is not only\neffective in detecting CLP, it outperformed the baseline. The results indicate\nthat CLP could be detected with state-of-the-art performances by leveraging the\nprediction accuracy of an internet translator with word embeddings, without\nrelying on internet translators.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 11:46:13 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 14:59:22 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Thompson", "Victor", ""]]}, {"id": "1712.10224", "submitter": "Abhinav Rastogi", "authors": "Abhinav Rastogi, Dilek Hakkani-Tur, Larry Heck", "title": "Scalable Multi-Domain Dialogue State Tracking", "comments": "Published at ASRU-17. New version has updated results in Tables 1, 2\n  and 3 corresponding to the datasets released on\n  github.com/google-research-datasets/simulated-dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dialogue state tracking (DST) is a key component of task-oriented dialogue\nsystems. DST estimates the user's goal at each user turn given the interaction\nuntil then. State of the art approaches for state tracking rely on deep\nlearning methods, and represent dialogue state as a distribution over all\npossible slot values for each slot present in the ontology. Such a\nrepresentation is not scalable when the set of possible values are unbounded\n(e.g., date, time or location) or dynamic (e.g., movies or usernames).\nFurthermore, training of such models requires labeled data, where each user\nturn is annotated with the dialogue state, which makes building models for new\ndomains challenging. In this paper, we present a scalable multi-domain deep\nlearning based approach for DST. We introduce a novel framework for state\ntracking which is independent of the slot value set, and represent the dialogue\nstate as a distribution over a set of values of interest (candidate set)\nderived from the dialogue history or knowledge. Restricting these candidate\nsets to be bounded in size addresses the problem of slot-scalability.\nFurthermore, by leveraging the slot-independent architecture and transfer\nlearning, we show that our proposed approach facilitates quick adaptation to\nnew domains.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 13:34:46 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 17:43:48 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Rastogi", "Abhinav", ""], ["Hakkani-Tur", "Dilek", ""], ["Heck", "Larry", ""]]}, {"id": "1712.10309", "submitter": "Victor Thompson Vt", "authors": "Victor Thompson", "title": "Methods for Detecting Paraphrase Plagiarism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrase plagiarism is one of the difficult challenges facing plagiarism\ndetection systems. Paraphrasing occur when texts are lexically or syntactically\naltered to look different, but retain their original meaning. Most plagiarism\ndetection systems (many of which are commercial based) are designed to detect\nword co-occurrences and light modifications, but are unable to detect severe\nsemantic and structural alterations such as what is seen in many academic\ndocuments. Hence many paraphrase plagiarism cases go undetected. In this paper,\nwe approached the problem of paraphrase plagiarism by proposing methods for\ndetecting the most common techniques (phenomena) used in paraphrasing texts\n(namely; lexical substitution, insertion/deletion and word and phrase\nreordering), and combined the methods into a paraphrase detection model. We\nevaluated our proposed methods and model on collections containing paraphrase\ntexts. Experimental results show significant improvement in performance when\nthe methods were combined (the proposed model) as opposed to running them\nindividually. The results also show that the proposed paraphrase detection\nmodel outperformed a standard baseline (based on greedy string tilling), and\nprevious studies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 18:53:12 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Thompson", "Victor", ""]]}]