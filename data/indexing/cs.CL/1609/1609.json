[{"id": "1609.00070", "submitter": "Arun Tejasvi Chaganty", "authors": "Arun Tejasvi Chaganty and Percy Liang", "title": "How Much is 131 Million Dollars? Putting Numbers in Perspective with\n  Compositional Descriptions", "comments": null, "journal-ref": "ACL (2016), 578-587", "doi": "10.18653/v1/P16-1055", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  How much is 131 million US dollars? To help readers put such numbers in\ncontext, we propose a new task of automatically generating short descriptions\nknown as perspectives, e.g. \"$131 million is about the cost to employ everyone\nin Texas over a lunch period\". First, we collect a dataset of numeric mentions\nin news articles, where each mention is labeled with a set of rated\nperspectives. We then propose a system to generate these descriptions\nconsisting of two steps: formula construction and description generation. In\nconstruction, we compose formulae from numeric facts in a knowledge base and\nrank the resulting formulas based on familiarity, numeric proximity and\nsemantic compatibility. In generation, we convert a formula into natural\nlanguage using a sequence-to-sequence recurrent neural network. Our system\nobtains a 15.2% F1 improvement over a non-compositional baseline at formula\nconstruction and a 12.5 BLEU point improvement over a baseline description\ngeneration.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 00:20:41 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Chaganty", "Arun Tejasvi", ""], ["Liang", "Percy", ""]]}, {"id": "1609.00081", "submitter": "Tanmoy Chakraborty", "authors": "Tanmoy Chakraborty and Ramasuri Narayanam", "title": "All Fingers are not Equal: Intensity of References in Scientific\n  Articles", "comments": "11 pages, 4 figures, 4 tables, Conference on Empirical Methods in\n  Natural Language Processing (EMNLP 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research accomplishment is usually measured by considering all citations with\nequal importance, thus ignoring the wide variety of purposes an article is\nbeing cited for. Here, we posit that measuring the intensity of a reference is\ncrucial not only to perceive better understanding of research endeavor, but\nalso to improve the quality of citation-based applications. To this end, we\ncollect a rich annotated dataset with references labeled by the intensity, and\npropose a novel graph-based semi-supervised model, GraLap to label the\nintensity of references. Experiments with AAN datasets show a significant\nimprovement compared to the baselines to achieve the true labels of the\nreferences (46% better correlation). Finally, we provide four applications to\ndemonstrate how the knowledge of reference intensity leads to design better\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 01:34:56 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Chakraborty", "Tanmoy", ""], ["Narayanam", "Ramasuri", ""]]}, {"id": "1609.00425", "submitter": "Ethan Fast", "authors": "Ethan Fast and Eric Horvitz", "title": "Identifying Dogmatism in Social Media: Signals and Models", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore linguistic and behavioral features of dogmatism in social media\nand construct statistical models that can identify dogmatic comments. Our model\nis based on a corpus of Reddit posts, collected across a diverse set of\nconversational topics and annotated via paid crowdsourcing. We operationalize\nkey aspects of dogmatism described by existing psychology theories (such as\nover-confidence), finding they have predictive power. We also find evidence for\nnew signals of dogmatism, such as the tendency of dogmatic posts to refrain\nfrom signaling cognitive processes. When we use our predictive model to analyze\nmillions of other Reddit posts, we find evidence that suggests dogmatism is a\ndeeper personality trait, present for dogmatic users across many different\ndomains, and that users who engage on dogmatic comments tend to show increases\nin dogmatic posts themselves.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 23:29:57 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Fast", "Ethan", ""], ["Horvitz", "Eric", ""]]}, {"id": "1609.00435", "submitter": "David Jurgens", "authors": "David Jurgens, Srijan Kumar, Raine Hoover, Dan McFarland, Dan Jurafsky", "title": "Citation Classification for Behavioral Analysis of a Scientific Field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citations are an important indicator of the state of a scientific field,\nreflecting how authors frame their work, and influencing uptake by future\nscholars. However, our understanding of citation behavior has been limited to\nsmall-scale manual citation analysis. We perform the largest behavioral study\nof citations to date, analyzing how citations are both framed and taken up by\nscholars in one entire field: natural language processing. We introduce a new\ndataset of nearly 2,000 citations annotated for function and centrality, and\nuse it to develop a state-of-the-art classifier and label the entire ACL\nReference Corpus. We then study how citations are framed by authors and use\nboth papers and online traces to track how citations are followed by readers.\nWe demonstrate that authors are sensitive to discourse structure and\npublication venue when citing, that online readers follow temporal links to\nprevious and future work rather than methodological links, and that how a paper\ncites related work is predictive of its citation count. Finally, we use changes\nin citation roles to show that the field of NLP is undergoing a significant\nincrease in consensus.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 00:40:15 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Jurgens", "David", ""], ["Kumar", "Srijan", ""], ["Hoover", "Raine", ""], ["McFarland", "Dan", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1609.00464", "submitter": "Trey Grainger", "authors": "Trey Grainger, Khalifeh AlJadda, Mohammed Korayem, Andries Smith", "title": "The Semantic Knowledge Graph: A compact, auto-generated model for\n  real-time traversal and ranking of any relationship within a domain", "comments": "Accepted for publication in 2016 IEEE 3rd International Conference on\n  Data Science and Advanced Analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new kind of knowledge representation and mining system\nwhich we are calling the Semantic Knowledge Graph. At its heart, the Semantic\nKnowledge Graph leverages an inverted index, along with a complementary\nuninverted index, to represent nodes (terms) and edges (the documents within\nintersecting postings lists for multiple terms/nodes). This provides a layer of\nindirection between each pair of nodes and their corresponding edge, enabling\nedges to materialize dynamically from underlying corpus statistics. As a\nresult, any combination of nodes can have edges to any other nodes materialize\nand be scored to reveal latent relationships between the nodes. This provides\nnumerous benefits: the knowledge graph can be built automatically from a\nreal-world corpus of data, new nodes - along with their combined edges - can be\ninstantly materialized from any arbitrary combination of preexisting nodes\n(using set operations), and a full model of the semantic relationships between\nall entities within a domain can be represented and dynamically traversed using\na highly compact representation of the graph. Such a system has widespread\napplications in areas as diverse as knowledge modeling and reasoning, natural\nlanguage processing, anomaly detection, data cleansing, semantic search,\nanalytics, data classification, root cause analysis, and recommendations\nsystems. The main contribution of this paper is the introduction of a novel\nsystem - the Semantic Knowledge Graph - which is able to dynamically discover\nand score interesting relationships between any arbitrary combination of\nentities (words, phrases, or extracted concepts) through dynamically\nmaterializing nodes and edges from a compact graphical representation built\nautomatically from a corpus of data representative of a knowledge domain.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 04:26:54 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 15:06:45 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Grainger", "Trey", ""], ["AlJadda", "Khalifeh", ""], ["Korayem", "Mohammed", ""], ["Smith", "Andries", ""]]}, {"id": "1609.00514", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Hosein Azarbonyad, Jaap Kamps, Maarten Marx", "title": "On Horizontal and Vertical Separation in Hierarchical Text\n  Classification", "comments": "Full paper (10 pages) accepted for publication in proceedings of ACM\n  SIGIR International Conference on the Theory of Information Retrieval\n  (ICTIR'16)", "journal-ref": null, "doi": "10.1145/2970398.2970408", "report-no": null, "categories": "cs.IR cs.CL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchy is a common and effective way of organizing data and representing\ntheir relationships at different levels of abstraction. However, hierarchical\ndata dependencies cause difficulties in the estimation of \"separable\" models\nthat can distinguish between the entities in the hierarchy. Extracting\nseparable models of hierarchical entities requires us to take their relative\nposition into account and to consider the different types of dependencies in\nthe hierarchy. In this paper, we present an investigation of the effect of\nseparability in text-based entity classification and argue that in hierarchical\nclassification, a separation property should be established between entities\nnot only in the same layer, but also in different layers. Our main findings are\nthe followings. First, we analyse the importance of separability on the data\nrepresentation in the task of classification and based on that, we introduce a\n\"Strong Separation Principle\" for optimizing expected effectiveness of\nclassifiers decision based on separation property. Second, we present\nHierarchical Significant Words Language Models (HSWLM) which capture all, and\nonly, the essential features of hierarchical entities according to their\nrelative position in the hierarchy resulting in horizontally and vertically\nseparable models. Third, we validate our claims on real-world data and\ndemonstrate that how HSWLM improves the accuracy of classification and how it\nprovides transferable models over time. Although discussions in this paper\nfocus on the classification problem, the models are applicable to any\ninformation access tasks on data that has, or can be mapped to, a hierarchical\nstructure.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 09:21:33 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Azarbonyad", "Hosein", ""], ["Kamps", "Jaap", ""], ["Marx", "Maarten", ""]]}, {"id": "1609.00559", "submitter": "Ted Pedersen", "authors": "Bridget T. McInnes and Ted Pedersen", "title": "Improving Correlation with Human Judgments by Integrating Semantic\n  Similarity with Second--Order Vectors", "comments": "10 pages, Appears in the Proceedings of the 16th Workshop on\n  Biomedical Natural Language Processing (BioNLP-2017), August 2017, Vancouver,\n  BC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector space methods that measure semantic similarity and relatedness often\nrely on distributional information such as co--occurrence frequencies or\nstatistical measures of association to weight the importance of particular\nco--occurrences. In this paper, we extend these methods by incorporating a\nmeasure of semantic similarity based on a human curated taxonomy into a\nsecond--order vector representation. This results in a measure of semantic\nrelatedness that combines both the contextual information available in a\ncorpus--based vector space representation with the semantic knowledge found in\na biomedical ontology. Our results show that incorporating semantic similarity\ninto a second order co--occurrence matrices improves correlation with human\njudgments for both similarity and relatedness, and that our method compares\nfavorably to various different word embedding methods that have recently been\nevaluated on the same reference standards we have used.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 11:44:17 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 00:23:06 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["McInnes", "Bridget T.", ""], ["Pedersen", "Ted", ""]]}, {"id": "1609.00565", "submitter": "Lingxun Meng", "authors": "Lingxun Meng, Yan Li, Mengyi Liu and Peng Shu", "title": "Skipping Word: A Character-Sequential Representation based Framework for\n  Question Answering", "comments": "to be accepted as CIKM2016 short paper", "journal-ref": null, "doi": "10.1145/2983323.2983861", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works using artificial neural networks based on word distributed\nrepresentation greatly boost the performance of various natural language\nlearning tasks, especially question answering. Though, they also carry along\nwith some attendant problems, such as corpus selection for embedding learning,\ndictionary transformation for different learning tasks, etc. In this paper, we\npropose to straightforwardly model sentences by means of character sequences,\nand then utilize convolutional neural networks to integrate character embedding\nlearning together with point-wise answer selection training. Compared with deep\nmodels pre-trained on word embedding (WE) strategy, our character-sequential\nrepresentation (CSR) based method shows a much simpler procedure and more\nstable performance across different benchmarks. Extensive experiments on two\nbenchmark answer selection datasets exhibit the competitive performance\ncompared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 11:57:46 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Meng", "Lingxun", ""], ["Li", "Yan", ""], ["Liu", "Mengyi", ""], ["Shu", "Peng", ""]]}, {"id": "1609.00626", "submitter": "Shinichi Nakajima", "authors": "Shinichi Nakajima, Sebastian Krause, Dirk Weissenborn, Sven Schmeier,\n  Nico Goernitz, Feiyu Xu", "title": "SynsetRank: Degree-adjusted Random Walk for Relation Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In relation extraction, a key process is to obtain good detectors that find\nrelevant sentences describing the target relation. To minimize the necessity of\nlabeled data for refining detectors, previous work successfully made use of\nBabelNet, a semantic graph structure expressing relationships between synsets,\nas side information or prior knowledge. The goal of this paper is to enhance\nthe use of graph structure in the framework of random walk with a few\nadjustable parameters. Actually, a straightforward application of random walk\ndegrades the performance even after parameter optimization. With the insight\nfrom this unsuccessful trial, we propose SynsetRank, which adjusts the initial\nprobability so that high degree nodes influence the neighbors as strong as low\ndegree nodes. In our experiment on 13 relations in the FB15K-237 dataset,\nSynsetRank significantly outperforms baselines and the plain random walk\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 14:42:18 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2016 22:46:29 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Nakajima", "Shinichi", ""], ["Krause", "Sebastian", ""], ["Weissenborn", "Dirk", ""], ["Schmeier", "Sven", ""], ["Goernitz", "Nico", ""], ["Xu", "Feiyu", ""]]}, {"id": "1609.00718", "submitter": "Rie Johnson", "authors": "Rie Johnson and Tong Zhang", "title": "Convolutional Neural Networks for Text Categorization: Shallow\n  Word-level vs. Deep Character-level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the performances of shallow word-level convolutional\nneural networks (CNN), our earlier work (2015), on the eight datasets with\nrelatively large training data that were used for testing the very deep\ncharacter-level CNN in Conneau et al. (2016). Our findings are as follows. The\nshallow word-level CNNs achieve better error rates than the error rates\nreported in Conneau et al., though the results should be interpreted with some\nconsideration due to the unique pre-processing of Conneau et al. The shallow\nword-level CNN uses more parameters and therefore requires more storage than\nthe deep character-level CNN; however, the shallow word-level CNN computes much\nfaster.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2016 15:43:27 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Johnson", "Rie", ""], ["Zhang", "Tong", ""]]}, {"id": "1609.00777", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen,\n  Faisal Ahmed, Li Deng", "title": "Towards End-to-End Reinforcement Learning of Dialogue Agents for\n  Information Access", "comments": "Accepted at ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes KB-InfoBot -- a multi-turn dialogue agent which helps\nusers search Knowledge Bases (KBs) without composing complicated queries. Such\ngoal-oriented dialogue agents typically need to interact with an external\ndatabase to access real-world knowledge. Previous systems achieved this by\nissuing a symbolic query to the KB to retrieve entries based on their\nattributes. However, such symbolic operations break the differentiability of\nthe system and prevent end-to-end training of neural dialogue agents. In this\npaper, we address this limitation by replacing symbolic queries with an induced\n\"soft\" posterior distribution over the KB that indicates which entities the\nuser is interested in. Integrating the soft retrieval process with a\nreinforcement learner leads to higher task success rate and reward in both\nsimulations and against real users. We also present a fully neural end-to-end\nagent, trained entirely from user feedback, and discuss its application towards\npersonalized dialogue agents. The source code is available at\nhttps://github.com/MiuLab/KB-InfoBot.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 01:02:51 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 21:39:31 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 17:26:35 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Li", "Lihong", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Chen", "Yun-Nung", ""], ["Ahmed", "Faisal", ""], ["Deng", "Li", ""]]}, {"id": "1609.00799", "submitter": "Minh-Tien Nguyen", "authors": "Danilo S. Carvalho, Minh-Tien Nguyen, Tran Xuan Chien and Minh Le\n  Nguyen", "title": "Lexical-Morphological Modeling for Legal Text Analysis", "comments": "16 pages, 5 figures, Lecture notes in computer science: New Frontiers\n  in Artificial Intelligence, 2016/03", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the Competition on Legal Information Extraction/Entailment\n(COLIEE), we propose a method comprising the necessary steps for finding\nrelevant documents to a legal question and deciding on textual entailment\nevidence to provide a correct answer. The proposed method is based on the\ncombination of several lexical and morphological characteristics, to build a\nlanguage model and a set of features for Machine Learning algorithms. We\nprovide a detailed study on the proposed method performance and failure cases,\nindicating that it is competitive with state-of-the-art approaches on Legal\nInformation Retrieval and Question Answering, while not needing extensive\ntraining data nor depending on expert produced knowledge. The proposed method\nachieved significant results in the competition, indicating a substantial level\nof adequacy for the tasks addressed.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 07:24:08 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Carvalho", "Danilo S.", ""], ["Nguyen", "Minh-Tien", ""], ["Chien", "Tran Xuan", ""], ["Nguyen", "Minh Le", ""]]}, {"id": "1609.01188", "submitter": "Fahad Al-Obaidli", "authors": "Fahad Al-Obaidli, Stephen Cox, Preslav Nakov", "title": "Bi-Text Alignment of Movie Subtitles for Spoken English-Arabic\n  Statistical Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe efforts towards getting better resources for English-Arabic\nmachine translation of spoken text. In particular, we look at movie subtitles\nas a unique, rich resource, as subtitles in one language often get translated\ninto other languages. Movie subtitles are not new as a resource and have been\nexplored in previous research; however, here we create a much larger bi-text\n(the biggest to date), and we further generate better quality alignment for it.\nGiven the subtitles for the same movie in different languages, a key problem is\nhow to align them at the fragment level. Typically, this is done using\nlength-based alignment, but for movie subtitles, there is also time\ninformation. Here we exploit this information to develop an original algorithm\nthat outperforms the current best subtitle alignment tool, subalign. The\nevaluation results show that adding our bi-text to the IWSLT training bi-text\nyields an improvement of over two BLEU points absolute.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 14:55:31 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Al-Obaidli", "Fahad", ""], ["Cox", "Stephen", ""], ["Nakov", "Preslav", ""]]}, {"id": "1609.01235", "submitter": "Oren Melamud", "authors": "Oren Melamud, Ido Dagan, Jacob Goldberger", "title": "PMI Matrix Approximations with Applications to Neural Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The negative sampling (NEG) objective function, used in word2vec, is a\nsimplification of the Noise Contrastive Estimation (NCE) method. NEG was found\nto be highly effective in learning continuous word representations. However,\nunlike NCE, it was considered inapplicable for the purpose of learning the\nparameters of a language model. In this study, we refute this assertion by\nproviding a principled derivation for NEG-based language modeling, founded on a\nnovel analysis of a low-dimensional approximation of the matrix of pointwise\nmutual information between the contexts and the predicted words. The obtained\nlanguage modeling is closely related to NCE language models but is based on a\nsimplified objective function. We thus provide a unified formulation for two\nmain language processing tasks, namely word embedding and language modeling,\nbased on the NEG objective function. Experimental results on two popular\nlanguage modeling benchmarks show comparable perplexity results, with a small\nadvantage to NEG over NCE.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 17:47:49 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Melamud", "Oren", ""], ["Dagan", "Ido", ""], ["Goldberger", "Jacob", ""]]}, {"id": "1609.01454", "submitter": "Bing Liu", "authors": "Bing Liu, Ian Lane", "title": "Attention-Based Recurrent Neural Network Models for Joint Intent\n  Detection and Slot Filling", "comments": "Accepted at Interspeech 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder neural network models have recently shown\npromising results in machine translation and speech recognition. In this work,\nwe propose an attention-based neural network model for joint intent detection\nand slot filling, both of which are critical steps for many speech\nunderstanding and dialog systems. Unlike in machine translation and speech\nrecognition, alignment is explicit in slot filling. We explore different\nstrategies in incorporating this alignment information to the encoder-decoder\nframework. Learning from the attention mechanism in encoder-decoder model, we\nfurther propose introducing attention to the alignment-based RNN models. Such\nattentions provide additional information to the intent classification and slot\nlabel prediction. Our independent task models achieve state-of-the-art intent\ndetection error rate and slot filling F1 score on the benchmark ATIS task. Our\njoint training model further obtains 0.56% absolute (23.8% relative) error\nreduction on intent detection and 0.23% absolute gain on slot filling over the\nindependent task models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 09:29:12 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Liu", "Bing", ""], ["Lane", "Ian", ""]]}, {"id": "1609.01462", "submitter": "Bing Liu", "authors": "Bing Liu, Ian Lane", "title": "Joint Online Spoken Language Understanding and Language Modeling with\n  Recurrent Neural Networks", "comments": "Accepted at SIGDIAL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker intent detection and semantic slot filling are two critical tasks in\nspoken language understanding (SLU) for dialogue systems. In this paper, we\ndescribe a recurrent neural network (RNN) model that jointly performs intent\ndetection, slot filling, and language modeling. The neural network model keeps\nupdating the intent estimation as word in the transcribed utterance arrives and\nuses it as contextual features in the joint model. Evaluation of the language\nmodel and online SLU model is made on the ATIS benchmarking data set. On\nlanguage modeling task, our joint model achieves 11.8% relative reduction on\nperplexity comparing to the independent training language model. On SLU tasks,\nour joint model outperforms the independent task training model by 22.3% on\nintent detection error rate, with slight degradation on slot filling F1 score.\nThe joint model also shows advantageous performance in the realistic ASR\nsettings with noisy speech input.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 09:45:51 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Liu", "Bing", ""], ["Lane", "Ian", ""]]}, {"id": "1609.01574", "submitter": "Siddhartha Jonnalagadda", "authors": "Prakash Reddy Putta, John J. Dzak III, Siddhartha R. Jonnalagadda", "title": "Automatically extracting, ranking and visually summarizing the\n  treatments for a disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinicians are expected to have up-to-date and broad knowledge of disease\ntreatment options for a patient. Online health knowledge resources contain a\nwealth of information. However, because of the time investment needed to\ndisseminate and rank pertinent information, there is a need to summarize the\ninformation in a more concise format. Our aim of the study is to provide\nclinicians with a concise overview of popular treatments for a given disease\nusing information automatically computed from Medline abstracts. We analyzed\nthe treatments of two disorders - Atrial Fibrillation and Congestive Heart\nFailure. We calculated the precision, recall, and f-scores of our two ranking\nmethods to measure the accuracy of the results. For Atrial Fibrillation\ndisorder, maximum f-score for the New Treatments weighing method is 0.611,\nwhich occurs at 60 treatments. For Congestive Heart Failure disorder, maximum\nf-score for the New Treatments weighing method is 0.503, which occurs at 80\ntreatments.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 14:30:18 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Putta", "Prakash Reddy", ""], ["Dzak", "John J.", "III"], ["Jonnalagadda", "Siddhartha R.", ""]]}, {"id": "1609.01580", "submitter": "Siddhartha Jonnalagadda", "authors": "Shu Dong, R Kannan Mutharasan, Siddhartha Jonnalagadda", "title": "Using Natural Language Processing to Screen Patients with Active Heart\n  Failure: An Exploration for Hospital-wide Surveillance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed two different approaches, a rule-based approach\nand a machine-learning based approach, to identify active heart failure cases\nautomatically by analyzing electronic health records (EHR). For the rule-based\napproach, we extracted cardiovascular data elements from clinical notes and\nmatched patients to different colors according their heart failure condition by\nusing rules provided by experts in heart failure. It achieved 69.4% accuracy\nand 0.729 F1-Score. For the machine learning approach, with bigram of clinical\nnotes as features, we tried four different models while SVM with linear kernel\nachieved the best performance with 87.5% accuracy and 0.86 F1-Score. Also, from\nthe classification comparison between the four different models, we believe\nthat linear models fit better for this problem. Once we combine the\nmachine-learning and rule-based algorithms, we will enable hospital-wide\nsurveillance of active heart failure through increased accuracy and\ninterpretability of the outputs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 14:46:41 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Dong", "Shu", ""], ["Mutharasan", "R Kannan", ""], ["Jonnalagadda", "Siddhartha", ""]]}, {"id": "1609.01586", "submitter": "Siddhartha Jonnalagadda", "authors": "Ravi Garg, Shu Dong, Sanjiv Shah, Siddhartha R Jonnalagadda", "title": "A Bootstrap Machine Learning Approach to Identify Rare Disease Patients\n  from Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare diseases are very difficult to identify among large number of other\npossible diagnoses. Better availability of patient data and improvement in\nmachine learning algorithms empower us to tackle this problem computationally.\nIn this paper, we target one such rare disease - cardiac amyloidosis. We aim to\nautomate the process of identifying potential cardiac amyloidosis patients with\nthe help of machine learning algorithms and also learn most predictive factors.\nWith the help of experienced cardiologists, we prepared a gold standard with 73\npositive (cardiac amyloidosis) and 197 negative instances. We achieved high\naverage cross-validation F1 score of 0.98 using an ensemble machine learning\nclassifier. Some of the predictive variables were: Age and Diagnosis of cardiac\narrest, chest pain, congestive heart failure, hypertension, prim open angle\nglaucoma, and shoulder arthritis. Further studies are needed to validate the\naccuracy of the system across an entire health system and its generalizability\nfor other diseases.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 14:54:58 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Garg", "Ravi", ""], ["Dong", "Shu", ""], ["Shah", "Sanjiv", ""], ["Jonnalagadda", "Siddhartha R", ""]]}, {"id": "1609.01592", "submitter": "Siddhartha Jonnalagadda", "authors": "Ravi P Garg, Kalpana Raja, Siddhartha R Jonnalagadda", "title": "CRTS: A type system for representing clinical recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Clinical guidelines and recommendations are the driving wheels of\nthe evidence-based medicine (EBM) paradigm, but these are available primarily\nas unstructured text and are generally highly heterogeneous in nature. This\nsignificantly reduces the dissemination and automatic application of these\nrecommendations at the point of care. A comprehensive structured representation\nof these recommendations is highly beneficial in this regard. Objective: The\nobjective of this paper to present Clinical Recommendation Type System (CRTS),\na common type system that can effectively represent a clinical recommendation\nin a structured form. Methods: CRTS is built by analyzing 125 recommendations\nand 195 research articles corresponding to 6 different diseases available from\nUpToDate, a publicly available clinical knowledge system, and from the National\nGuideline Clearinghouse, a public resource for evidence-based clinical practice\nguidelines. Results: We show that CRTS not only covers the recommendations but\nalso is flexible to be extended to represent information from primary\nliterature. We also describe how our developed type system can be applied for\nclinical decision support, medical knowledge summarization, and citation\nretrieval. Conclusion: We showed that our proposed type system is precise and\ncomprehensive in representing a large sample of recommendations available for\nvarious disorders. CRTS can now be used to build interoperable information\nextraction systems that automatically extract clinical recommendations and\nrelated data elements from clinical evidence resources, guidelines, systematic\nreviews and primary publications.\n  Keywords: guidelines and recommendations, type system, clinical decision\nsupport, evidence-based medicine, information storage and retrieval\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 15:02:03 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Garg", "Ravi P", ""], ["Raja", "Kalpana", ""], ["Jonnalagadda", "Siddhartha R", ""]]}, {"id": "1609.01594", "submitter": "Siddhartha Jonnalagadda", "authors": "Abhishek Kalyan Adupa, Ravi Prakash Garg, Jessica Corona-Cox, Sanjiv.\n  J. Shah, Siddhartha R. Jonnalagadda", "title": "An Information Extraction Approach to Prescreen Heart Failure Patients\n  for Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the large amount of time spent screening, identifying, and\nrecruiting patients into clinical trials, we need prescreening systems that are\nable to automate the data extraction and decision-making tasks that are\ntypically relegated to clinical research study coordinators. However, a major\nobstacle is the vast amount of patient data available as unstructured free-form\ntext in electronic health records. Here we propose an information\nextraction-based approach that first automatically converts unstructured text\ninto a structured form. The structured data are then compared against a list of\neligibility criteria using a rule-based system to determine which patients\nqualify for enrollment in a heart failure clinical trial. We show that we can\nachieve highly accurate results, with recall and precision values of 0.95 and\n0.86, respectively. Our system allowed us to significantly reduce the time\nneeded for prescreening patients from a few weeks to a few minutes. Our\nopen-source information extraction modules are available for researchers and\ncould be tested and validated in other cardiovascular trials. An approach such\nas the one we demonstrate here may decrease costs and expedite clinical trials,\nand could enhance the reproducibility of trials across institutions and\npopulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 15:05:25 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Adupa", "Abhishek Kalyan", ""], ["Garg", "Ravi Prakash", ""], ["Corona-Cox", "Jessica", ""], ["Shah", "Sanjiv. J.", ""], ["Jonnalagadda", "Siddhartha R.", ""]]}, {"id": "1609.01597", "submitter": "Siddhartha Jonnalagadda", "authors": "Kalpana Raja, Andrew J Sauer, Ravi P Garg, Melanie R Klerer,\n  Siddhartha R Jonnalagadda", "title": "A Hybrid Citation Retrieval Algorithm for Evidence-based Clinical\n  Knowledge Summarization: Combining Concept Extraction, Vector Similarity and\n  Query Expansion for High Precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel information retrieval methods to identify citations relevant to a\nclinical topic can overcome the knowledge gap existing between the primary\nliterature (MEDLINE) and online clinical knowledge resources such as UpToDate.\nSearching the MEDLINE database directly or with query expansion methods returns\na large number of citations that are not relevant to the query. The current\nstudy presents a citation retrieval system that retrieves citations for\nevidence-based clinical knowledge summarization. This approach combines query\nexpansion, concept-based screening algorithm, and concept-based vector\nsimilarity. We also propose an information extraction framework for automated\nconcept (Population, Intervention, Comparison, and Disease) extraction. We\nevaluated our proposed system on all topics (as queries) available from\nUpToDate for two diseases, heart failure (HF) and atrial fibrillation (AFib).\nThe system achieved an overall F-score of 41.2% on HF topics and 42.4% on AFib\ntopics on a gold standard of citations available in UpToDate. This is\nsignificantly high when compared to a query-expansion based baseline (F-score\nof 1.3% on HF and 2.2% on AFib) and a system that uses query expansion with\ndisease hyponyms and journal names, concept-based screening, and term-based\nvector similarity system (F-score of 37.5% on HF and 39.5% on AFib). Evaluating\nthe system with top K relevant citations, where K is the number of citations in\nthe gold standard achieved a much higher overall F-score of 69.9% on HF topics\nand 75.1% on AFib topics. In addition, the system retrieved up to 18 new\nrelevant citations per topic when tested on ten HF and six AFib clinical\ntopics.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 15:10:39 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Raja", "Kalpana", ""], ["Sauer", "Andrew J", ""], ["Garg", "Ravi P", ""], ["Klerer", "Melanie R", ""], ["Jonnalagadda", "Siddhartha R", ""]]}, {"id": "1609.01926", "submitter": "Giovanni Carmantini", "authors": "Giovanni Sirio Carmantini, Peter beim Graben, Mathieu Desroches,\n  Serafim Rodrigues", "title": "A modular architecture for transparent computation in Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2016.09.001", "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.FL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation is classically studied in terms of automata, formal languages and\nalgorithms; yet, the relation between neural dynamics and symbolic\nrepresentations and operations is still unclear in traditional eliminative\nconnectionism. Therefore, we suggest a unique perspective on this central\nissue, to which we would like to refer as to transparent connectionism, by\nproposing accounts of how symbolic computation can be implemented in neural\nsubstrates. In this study we first introduce a new model of dynamics on a\nsymbolic space, the versatile shift, showing that it supports the real-time\nsimulation of a range of automata. We then show that the Goedelization of\nversatile shifts defines nonlinear dynamical automata, dynamical systems\nevolving on a vectorial space. Finally, we present a mapping between nonlinear\ndynamical automata and recurrent artificial neural networks. The mapping\ndefines an architecture characterized by its granular modularity, where data,\nsymbolic operations and their control are not only distinguishable in\nactivation space, but also spatially localizable in the network itself, while\nmaintaining a distributed encoding of symbolic representations. The resulting\nnetworks simulate automata in real-time and are programmed directly, in absence\nof network training. To discuss the unique characteristics of the architecture\nand their consequences, we present two examples: i) the design of a Central\nPattern Generator from a finite-state locomotive controller, and ii) the\ncreation of a network simulating a system of interactive automata that supports\nthe parsing of garden-path sentences as investigated in psycholinguistics\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 10:44:28 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Carmantini", "Giovanni Sirio", ""], ["Graben", "Peter beim", ""], ["Desroches", "Mathieu", ""], ["Rodrigues", "Serafim", ""]]}, {"id": "1609.01933", "submitter": "Ruixi Lin", "authors": "Hua Feng and Ruixi Lin", "title": "Sentiment Classification of Food Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis of reviews is a popular task in natural language\nprocessing. In this work, the goal is to predict the score of food reviews on a\nscale of 1 to 5 with two recurrent neural networks that are carefully tuned. As\nfor baseline, we train a simple RNN for classification. Then we extend the\nbaseline to GRU. In addition, we present two different methods to deal with\nhighly skewed data, which is a common problem for reviews. Models are evaluated\nusing accuracies.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 10:59:58 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Feng", "Hua", ""], ["Lin", "Ruixi", ""]]}, {"id": "1609.01962", "submitter": "Arkaitz Zubiaga", "authors": "Michal Lukasik, Kalina Bontcheva, Trevor Cohn, Arkaitz Zubiaga, Maria\n  Liakata, Rob Procter", "title": "Using Gaussian Processes for Rumour Stance Classification in Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media tend to be rife with rumours while new reports are released\npiecemeal during breaking news. Interestingly, one can mine multiple reactions\nexpressed by social media users in those situations, exploring their stance\ntowards rumours, ultimately enabling the flagging of highly disputed rumours as\nbeing potentially false. In this work, we set out to develop an automated,\nsupervised classifier that uses multi-task learning to classify the stance\nexpressed in each individual tweet in a rumourous conversation as either\nsupporting, denying or questioning the rumour. Using a classifier based on\nGaussian Processes, and exploring its effectiveness on two datasets with very\ndifferent characteristics and varying distributions of stances, we show that\nour approach consistently outperforms competitive baseline classifiers. Our\nclassifier is especially effective in estimating the distribution of different\ntypes of stance associated with a given rumour, which we set forth as a desired\ncharacteristic for a rumour-tracking system that will warn both ordinary users\nof Twitter and professional news practitioners when a rumour is being rebutted.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 12:33:02 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Lukasik", "Michal", ""], ["Bontcheva", "Kalina", ""], ["Cohn", "Trevor", ""], ["Zubiaga", "Arkaitz", ""], ["Liakata", "Maria", ""], ["Procter", "Rob", ""]]}, {"id": "1609.02043", "submitter": "Shirish Karande", "authors": "Purushotam Radadia, Shirish Karande", "title": "Feasibility of Post-Editing Speech Transcriptions with a Mismatched\n  Crowd", "comments": "HCOMP 2016 Works-in-Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manual correction of speech transcription can involve a selection from\nplausible transcriptions. Recent work has shown the feasibility of employing a\nmismatched crowd for speech transcription. However, it is yet to be established\nwhether a mismatched worker has sufficiently fine-granular speech perception to\nchoose among the phonetically proximate options that are likely to be generated\nfrom the trellis of an ASRU. Hence, we consider five languages, Arabic, German,\nHindi, Russian and Spanish. For each we generate synthetic, phonetically\nproximate, options which emulate post-editing scenarios of varying difficulty.\nWe consistently observe non-trivial crowd ability to choose among fine-granular\noptions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 16:05:20 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Radadia", "Purushotam", ""], ["Karande", "Shirish", ""]]}, {"id": "1609.02075", "submitter": "Jacob Eisenstein", "authors": "Rahul Goel, Sandeep Soni, Naman Goyal, John Paparrizos, Hanna Wallach,\n  Fernando Diaz, Jacob Eisenstein", "title": "The Social Dynamics of Language Change in Online Networks", "comments": "This paper appears in the Proceedings of the International Conference\n  on Social Informatics (SocInfo16). The final publication is available at\n  springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language change is a complex social phenomenon, revealing pathways of\ncommunication and sociocultural influence. But, while language change has long\nbeen a topic of study in sociolinguistics, traditional linguistic research\nmethods rely on circumstantial evidence, estimating the direction of change\nfrom differences between older and younger speakers. In this paper, we use a\ndata set of several million Twitter users to track language changes in\nprogress. First, we show that language change can be viewed as a form of social\ninfluence: we observe complex contagion for phonetic spellings and \"netspeak\"\nabbreviations (e.g., lol), but not for older dialect markers from spoken\nlanguage. Next, we test whether specific types of social network connections\nare more influential than others, using a parametric Hawkes process model. We\nfind that tie strength plays an important role: densely embedded social ties\nare significantly better conduits of linguistic influence. Geographic locality\nappears to play a more limited role: we find relatively little evidence to\nsupport the hypothesis that individuals are more influenced by geographically\nlocal social ties, even in their usage of geographical dialect markers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 17:09:10 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Goel", "Rahul", ""], ["Soni", "Sandeep", ""], ["Goyal", "Naman", ""], ["Paparrizos", "John", ""], ["Wallach", "Hanna", ""], ["Diaz", "Fernando", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1609.02082", "submitter": "Christian Huemmer M.Sc.", "authors": "Christian Huemmer, Ram\\'on Fern\\'andez Astudillo and Walter Kellermann", "title": "An improved uncertainty decoding scheme with weighted samples for\n  DNN-HMM hybrid systems", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we advance a recently-proposed uncertainty decoding scheme for\nDNN-HMM (deep neural network - hidden Markov model) hybrid systems. This\nnumerical sampling concept averages DNN outputs produced by a finite set of\nfeature samples (drawn from a probabilistic distortion model) to approximate\nthe posterior likelihoods of the context-dependent HMM states. As main\ninnovation, we propose a weighted DNN-output averaging based on a minimum\nclassification error criterion and apply it to a probabilistic distortion model\nfor spatial diffuseness features. The experimental evaluation is performed on\nthe 8-channel REVERB Challenge task using a DNN-HMM hybrid system with\nmultichannel front-end signal enhancement. We show that the recognition\naccuracy of the DNN-HMM hybrid system improves by incorporating uncertainty\ndecoding based on random sampling and that the proposed weighted DNN-output\naveraging further reduces the word error rate scores.\n", "versions": [{"version": "v1", "created": "Thu, 4 Aug 2016 10:11:24 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Huemmer", "Christian", ""], ["Astudillo", "Ram\u00f3n Fern\u00e1ndez", ""], ["Kellermann", "Walter", ""]]}, {"id": "1609.02116", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, David Belanger, Andrew McCallum", "title": "Ask the GRU: Multi-Task Learning for Deep Text Recommendations", "comments": "8 pages", "journal-ref": null, "doi": "10.1145/2959100.2959180", "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a variety of application domains the content to be recommended to users is\nassociated with text. This includes research papers, movies with associated\nplot summaries, news articles, blog posts, etc. Recommendation approaches based\non latent factor models can be extended naturally to leverage text by employing\nan explicit mapping from text to factors. This enables recommendations for new,\nunseen content, and may generalize better, since the factors for all items are\nproduced by a compactly-parametrized model. Previous work has used topic models\nor averages of word embeddings for this mapping. In this paper we present a\nmethod leveraging deep recurrent neural networks to encode the text sequence\ninto a latent vector, specifically gated recurrent units (GRUs) trained\nend-to-end on the collaborative filtering task. For the task of scientific\npaper recommendation, this yields models with significantly higher accuracy. In\ncold-start scenarios, we beat the previous state-of-the-art, all of which\nignore word order. Performance is further improved by multi-task learning,\nwhere the text encoder network is trained for a combination of content\nrecommendation and item metadata prediction. This regularizes the collaborative\nfiltering model, ameliorating the problem of sparsity of the observed rating\nmatrix.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 19:05:42 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 19:27:19 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Bansal", "Trapit", ""], ["Belanger", "David", ""], ["McCallum", "Andrew", ""]]}, {"id": "1609.02549", "submitter": "Junjie Hu", "authors": "Junjie Hu, Jean Oh, Anatole Gershman", "title": "Learning Lexical Entries for Robotic Commands using Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic commands in natural language usually contain various spatial\ndescriptions that are semantically similar but syntactically different. Mapping\nsuch syntactic variants into semantic concepts that can be understood by robots\nis challenging due to the high flexibility of natural language expressions. To\ntackle this problem, we collect robotic commands for navigation and\nmanipulation tasks using crowdsourcing. We further define a robot language and\nuse a generative machine translation model to translate robotic commands from\nnatural language to robot language. The main purpose of this paper is to\nsimulate the interaction process between human and robots using crowdsourcing\nplatforms, and investigate the possibility of translating natural language to\nrobot language with paraphrases.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 19:51:47 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 17:29:27 GMT"}, {"version": "v3", "created": "Tue, 1 Nov 2016 15:21:43 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Hu", "Junjie", ""], ["Oh", "Jean", ""], ["Gershman", "Anatole", ""]]}, {"id": "1609.02727", "submitter": "Vlad Sandulescu", "authors": "Vlad Sandulescu, Martin Ester", "title": "Detecting Singleton Review Spammers Using Semantic Similarity", "comments": "6 pages, WWW 2015", "journal-ref": "WWW '15 Companion Proceedings of the 24th International Conference\n  on World Wide Web, 2015, p.971-976", "doi": "10.1145/2740908.2742570", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews have increasingly become a very important resource for\nconsumers when making purchases. Though it is becoming more and more difficult\nfor people to make well-informed buying decisions without being deceived by\nfake reviews. Prior works on the opinion spam problem mostly considered\nclassifying fake reviews using behavioral user patterns. They focused on\nprolific users who write more than a couple of reviews, discarding one-time\nreviewers. The number of singleton reviewers however is expected to be high for\nmany review websites. While behavioral patterns are effective when dealing with\nelite users, for one-time reviewers, the review text needs to be exploited. In\nthis paper we tackle the problem of detecting fake reviews written by the same\nperson using multiple names, posting each review under a different name. We\npropose two methods to detect similar reviews and show the results generally\noutperform the vectorial similarity measures used in prior works. The first\nmethod extends the semantic similarity between words to the reviews level. The\nsecond method is based on topic modeling and exploits the similarity of the\nreviews topic distributions using two models: bag-of-words and\nbag-of-opinion-phrases. The experiments were conducted on reviews from three\ndifferent datasets: Yelp (57K reviews), Trustpilot (9K reviews) and Ott dataset\n(800 reviews).\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 09:58:45 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Sandulescu", "Vlad", ""], ["Ester", "Martin", ""]]}, {"id": "1609.02745", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Parsa Ghaffari, and John G. Breslin", "title": "A Hierarchical Model of Reviews for Aspect-based Sentiment Analysis", "comments": "To be published at EMNLP 2016, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion mining from customer reviews has become pervasive in recent years.\nSentences in reviews, however, are usually classified independently, even\nthough they form part of a review's argumentative structure. Intuitively,\nsentences in a review build and elaborate upon each other; knowledge of the\nreview structure and sentential context should thus inform the classification\nof each sentence. We demonstrate this hypothesis for the task of aspect-based\nsentiment analysis by modeling the interdependencies of sentences in a review\nwith a hierarchical bidirectional LSTM. We show that the hierarchical model\noutperforms two non-hierarchical baselines, obtains results competitive with\nthe state-of-the-art, and outperforms the state-of-the-art on five\nmultilingual, multi-domain datasets without any hand-engineered features or\nexternal resources.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 11:16:15 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Ruder", "Sebastian", ""], ["Ghaffari", "Parsa", ""], ["Breslin", "John G.", ""]]}, {"id": "1609.02746", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Parsa Ghaffari, and John G. Breslin", "title": "INSIGHT-1 at SemEval-2016 Task 4: Convolutional Neural Networks for\n  Sentiment Classification and Quantification", "comments": "Published in Proceedings of SemEval-2016, 5 pages", "journal-ref": "Proceedings of SemEval (2016): 178-182", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our deep learning-based approach to sentiment analysis\nin Twitter as part of SemEval-2016 Task 4. We use a convolutional neural\nnetwork to determine sentiment and participate in all subtasks, i.e. two-point,\nthree-point, and five-point scale sentiment classification and two-point and\nfive-point scale sentiment quantification. We achieve competitive results for\ntwo-point scale sentiment classification and quantification, ranking fifth and\na close fourth (third and second by alternative metrics) respectively despite\nusing only pre-trained embeddings that contain no sentiment information. We\nachieve good performance on three-point scale sentiment classification, ranking\neighth out of 35, while performing poorly on five-point scale sentiment\nclassification and quantification. An error analysis reveals that this is due\nto low expressiveness of the model to capture negative sentiment as well as an\ninability to take into account ordinal information. We propose improvements in\norder to address these and other issues.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 11:16:56 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Ruder", "Sebastian", ""], ["Ghaffari", "Parsa", ""], ["Breslin", "John G.", ""]]}, {"id": "1609.02748", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Parsa Ghaffari, and John G. Breslin", "title": "INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual\n  Aspect-based Sentiment Analysis", "comments": "Published in Proceedings of SemEval-2016, 7 pages", "journal-ref": "Proceedings of SemEval (2016): 330-336", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our deep learning-based approach to multilingual\naspect-based sentiment analysis as part of SemEval 2016 Task 5. We use a\nconvolutional neural network (CNN) for both aspect extraction and aspect-based\nsentiment analysis. We cast aspect extraction as a multi-label classification\nproblem, outputting probabilities over aspects parameterized by a threshold. To\ndetermine the sentiment towards an aspect, we concatenate an aspect vector with\nevery word embedding and apply a convolution over it. Our constrained system\n(unconstrained for English) achieves competitive results across all languages\nand domains, placing first or second in 5 and 7 out of 11 language-domain pairs\nfor aspect category detection (slot 1) and sentiment polarity (slot 3)\nrespectively, thereby demonstrating the viability of a deep learning-based\napproach for multilingual aspect-based sentiment analysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 11:23:51 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 10:04:18 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Ruder", "Sebastian", ""], ["Ghaffari", "Parsa", ""], ["Breslin", "John G.", ""]]}, {"id": "1609.02809", "submitter": "Edward Dixon Mr", "authors": "Alexei Bastidas, Edward Dixon, Chris Loo, John Ryan", "title": "Harassment detection: a benchmark on the #HackHarassment dataset", "comments": "Accepted to the Collaborative European Research Conference 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online harassment has been a problem to a greater or lesser extent since the\nearly days of the internet. Previous work has applied anti-spam techniques like\nmachine-learning based text classification (Reynolds, 2011) to detecting\nharassing messages. However, existing public datasets are limited in size, with\nlabels of varying quality. The #HackHarassment initiative (an alliance of 1\ntech companies and NGOs devoted to fighting bullying on the internet) has begun\nto address this issue by creating a new dataset superior to its predecssors in\nterms of both size and quality. As we (#HackHarassment) complete further rounds\nof labelling, later iterations of this dataset will increase the available\nsamples by at least an order of magnitude, enabling corresponding improvements\nin the quality of machine learning models for harassment detection. In this\npaper, we introduce the first models built on the #HackHarassment dataset v1.0\n(a new open dataset, which we are delighted to share with any interested\nresearcherss) as a benchmark for future research.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 14:23:02 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Bastidas", "Alexei", ""], ["Dixon", "Edward", ""], ["Loo", "Chris", ""], ["Ryan", "John", ""]]}, {"id": "1609.02846", "submitter": "Milica Gasic", "authors": "Milica Gasic, Nikola Mrksic, Lina M. Rojas-Barahona, Pei-Hao Su,\n  Stefan Ultes, David Vandyke, Tsung-Hsien Wen and Steve Young", "title": "Dialogue manager domain adaptation using Gaussian process reinforcement\n  learning", "comments": "accepted for publication in Computer Speech and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken dialogue systems allow humans to interact with machines using natural\nspeech. As such, they have many benefits. By using speech as the primary\ncommunication medium, a computer interface can facilitate swift, human-like\nacquisition of information. In recent years, speech interfaces have become ever\nmore popular, as is evident from the rise of personal assistants such as Siri,\nGoogle Now, Cortana and Amazon Alexa. Recently, data-driven machine learning\nmethods have been applied to dialogue modelling and the results achieved for\nlimited-domain applications are comparable to or outperform traditional\napproaches. Methods based on Gaussian processes are particularly effective as\nthey enable good models to be estimated from limited training data.\nFurthermore, they provide an explicit estimate of the uncertainty which is\nparticularly useful for reinforcement learning. This article explores the\nadditional steps that are necessary to extend these methods to model multiple\ndialogue domains. We show that Gaussian process reinforcement learning is an\nelegant framework that naturally supports a range of methods, including prior\nknowledge, Bayesian committee machines and multi-agent learning, for\nfacilitating extensible and adaptable dialogue systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 16:02:57 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Gasic", "Milica", ""], ["Mrksic", "Nikola", ""], ["Rojas-Barahona", "Lina M.", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Vandyke", "David", ""], ["Wen", "Tsung-Hsien", ""], ["Young", "Steve", ""]]}, {"id": "1609.02960", "submitter": "Nizar Habash", "authors": "Salam Khalifa, Nizar Habash, Dana Abdulrahim, Sara Hassan", "title": "A Large Scale Corpus of Gulf Arabic", "comments": "Language Resources and Evaluation Conference 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Arabic natural language processing tools and resources are developed to\nserve Modern Standard Arabic (MSA), which is the official written language in\nthe Arab World. Some Dialectal Arabic varieties, notably Egyptian Arabic, have\nreceived some attention lately and have a growing collection of resources that\ninclude annotated corpora and morphological analyzers and taggers. Gulf Arabic,\nhowever, lags behind in that respect. In this paper, we present the Gumar\nCorpus, a large-scale corpus of Gulf Arabic consisting of 110 million words\nfrom 1,200 forum novels. We annotate the corpus for sub-dialect information at\nthe document level. We also present results of a preliminary study in the\nmorphological annotation of Gulf Arabic which includes developing guidelines\nfor a conventional orthography. The text of the corpus is publicly browsable\nthrough a web interface we developed for it.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 22:22:53 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Khalifa", "Salam", ""], ["Habash", "Nizar", ""], ["Abdulrahim", "Dana", ""], ["Hassan", "Sara", ""]]}, {"id": "1609.03148", "submitter": "Diego Krivochen", "authors": "Diego Gabriel Krivochen", "title": "Divide and...conquer? On the limits of algorithmic approaches to\n  syntactic semantic structure", "comments": "Ms. 36 pages", "journal-ref": "Czech and Slovak Linguistic Review 1(2016)", "doi": "10.13140/RG.2.2.25292.82565", "report-no": null, "categories": "cs.CL cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In computer science, divide and conquer (D&C) is an algorithm design paradigm\nbased on multi-branched recursion. A D&C algorithm works by recursively and\nmonotonically breaking down a problem into sub problems of the same (or a\nrelated) type, until these become simple enough to be solved directly. The\nsolutions to the sub problems are then combined to give a solution to the\noriginal problem. The present work identifies D&C algorithms assumed within\ncontemporary syntactic theory, and discusses the limits of their applicability\nin the realms of the syntax semantics and syntax morphophonology interfaces. We\nwill propose that D&C algorithms, while valid for some processes, fall short on\nflexibility given a mixed approach to the structure of linguistic phrase\nmarkers. Arguments in favour of a computationally mixed approach to linguistic\nstructure will be presented as an alternative that offers advantages to uniform\nD&C approaches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 10:20:48 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Krivochen", "Diego Gabriel", ""]]}, {"id": "1609.03193", "submitter": "Gabriel Synnaeve", "authors": "Ronan Collobert, Christian Puhrsch, Gabriel Synnaeve", "title": "Wav2Letter: an End-to-End ConvNet-based Speech Recognition System", "comments": "8 pages, 4 figures (7 plots/schemas), 2 tables (4 tabulars)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple end-to-end model for speech recognition,\ncombining a convolutional network based acoustic model and a graph decoding. It\nis trained to output letters, with transcribed speech, without the need for\nforce alignment of phonemes. We introduce an automatic segmentation criterion\nfor training from sequence annotation without alignment that is on par with CTC\nwhile being simpler. We show competitive results in word error rate on the\nLibrispeech corpus with MFCC features, and promising results from raw waveform.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 18:56:53 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 02:49:05 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Collobert", "Ronan", ""], ["Puhrsch", "Christian", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "1609.03204", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Sergiu Nisioi, Noam Ordan, Shuly Wintner", "title": "On the Similarities Between Native, Non-native and Translated Texts", "comments": "ACL2016, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational analysis of three language varieties: native,\nadvanced non-native, and translation. Our goal is to investigate the\nsimilarities and differences between non-native language productions and\ntranslations, contrasting both with native language. Using a collection of\ncomputational methods we establish three main results: (1) the three types of\ntexts are easily distinguishable; (2) non-native language and translations are\ncloser to each other than each of them is to native language; and (3) some of\nthese characteristics depend on the source or native language, while others do\nnot, reflecting, perhaps, unified principles that similarly affect translations\nand non-native language.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 19:51:46 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Rabinovich", "Ella", ""], ["Nisioi", "Sergiu", ""], ["Ordan", "Noam", ""], ["Wintner", "Shuly", ""]]}, {"id": "1609.03205", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich and Shuly Wintner", "title": "Unsupervised Identification of Translationese", "comments": "TACL2015, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translated texts are distinctively different from original ones, to the\nextent that supervised text classification methods can distinguish between them\nwith high accuracy. These differences were proven useful for statistical\nmachine translation. However, it has been suggested that the accuracy of\ntranslation detection deteriorates when the classifier is evaluated outside the\ndomain it was trained on. We show that this is indeed the case, in a variety of\nevaluation scenarios. We then show that unsupervised classification is highly\naccurate on this task. We suggest a method for determining the correct labels\nof the clustering outcomes, and then use the labels for voting, improving the\naccuracy even further. Moreover, we suggest a simple method for clustering in\nthe challenging case of mixed-domain datasets, in spite of the dominance of\ndomain-related features over translation-related ones. The result is an\neffective, fully-unsupervised method for distinguishing between original and\ntranslated texts that can be applied to new domains with reasonable accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 19:52:28 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Rabinovich", "Ella", ""], ["Wintner", "Shuly", ""]]}, {"id": "1609.03207", "submitter": "Massimo Stella", "authors": "Massimo Stella, Nicole M. Beckage and Markus Brede", "title": "Multiplex lexical networks reveal patterns in early word acquisition in\n  children", "comments": "11 pages, 3 figures and 1 table. This paper was published on\n  Scientific Reports: https://www.nature.com/articles/srep46730", "journal-ref": "Scientific Reports 7, Article number: 46730 (2017)", "doi": "10.1038/srep46730", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network models of language have provided a way of linking cognitive processes\nto the structure and connectivity of language. However, one shortcoming of\ncurrent approaches is focusing on only one type of linguistic relationship at a\ntime, missing the complex multi-relational nature of language. In this work, we\novercome this limitation by modelling the mental lexicon of English-speaking\ntoddlers as a multiplex lexical network, i.e. a multi-layered network where\nN=529 words/nodes are connected according to four types of relationships: (i)\nfree associations, (ii) feature sharing, (iii) co-occurrence, and (iv)\nphonological similarity. We provide analysis of the topology of the resulting\nmultiplex and then proceed to evaluate single layers as well as the full\nmultiplex structure on their ability to predict empirically observed age of\nacquisition data of English speaking toddlers. We find that the emerging\nmultiplex network topology is an important proxy of the cognitive processes of\nacquisition, capable of capturing emergent lexicon structure. In fact, we show\nthat the multiplex topology is fundamentally more powerful than individual\nlayers in predicting the ordering with which words are acquired. Furthermore,\nmultiplex analysis allows for a quantification of distinct phases of lexical\nacquisition in early learners: while initially all the multiplex layers\ncontribute to word learning, after about month 23 free associations take the\nlead in driving word acquisition.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 19:59:18 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 22:45:02 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Stella", "Massimo", ""], ["Beckage", "Nicole M.", ""], ["Brede", "Markus", ""]]}, {"id": "1609.03286", "submitter": "Yun-Nung Chen", "authors": "Yun-Nung Chen, Dilek Hakkani-Tur, Gokhan Tur, Asli Celikyilmaz,\n  Jianfeng Gao, Li Deng", "title": "Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) is a core component of a spoken dialogue\nsystem. Recently recurrent neural networks (RNN) obtained strong results on NLU\ndue to their superior ability of preserving sequential information over time.\nTraditionally, the NLU module tags semantic slots for utterances considering\ntheir flat structures, as the underlying RNN structure is a linear chain.\nHowever, natural language exhibits linguistic properties that provide rich,\nstructured information for better understanding. This paper introduces a novel\nmodel, knowledge-guided structural attention networks (K-SAN), a generalization\nof RNN to additionally incorporate non-flat network topologies guided by prior\nknowledge. There are two characteristics: 1) important substructures can be\ncaptured from small training data, allowing the model to generalize to\npreviously unseen test data; 2) the model automatically figures out the salient\nsubstructures that are essential to predict the semantic tags of the given\nsentences, so that the understanding performance can be improved. The\nexperiments on the benchmark Air Travel Information System (ATIS) data show\nthat the proposed K-SAN architecture can effectively extract salient knowledge\nfrom substructures with an attention mechanism, and outperform the performance\nof the state-of-the-art neural network based frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 07:29:59 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Chen", "Yun-Nung", ""], ["Hakkani-Tur", "Dilek", ""], ["Tur", "Gokhan", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1609.03357", "submitter": "Anna Jordanous", "authors": "Anna Jordanous and Bill Keller", "title": "Modelling Creativity: Identifying Key Components through a Corpus-Based\n  Approach", "comments": "Submitted to PLOS ONE; currently under review. Figures not included", "journal-ref": null, "doi": "10.1371/journal.pone.0162959", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity is a complex, multi-faceted concept encompassing a variety of\nrelated aspects, abilities, properties and behaviours. If we wish to study\ncreativity scientifically, then a tractable and well-articulated model of\ncreativity is required. Such a model would be of great value to researchers\ninvestigating the nature of creativity and in particular, those concerned with\nthe evaluation of creative practice. This paper describes a unique approach to\ndeveloping a suitable model of how creative behaviour emerges that is based on\nthe words people use to describe the concept. Using techniques from the field\nof statistical natural language processing, we identify a collection of\nfourteen key components of creativity through an analysis of a corpus of\nacademic papers on the topic. Words are identified which appear significantly\noften in connection with discussions of the concept. Using a measure of lexical\nsimilarity to help cluster these words, a number of distinct themes emerge,\nwhich collectively contribute to a comprehensive and multi-perspective model of\ncreativity. The components provide an ontology of creativity: a set of building\nblocks which can be used to model creative practice in a variety of domains.\nThe components have been employed in two case studies to evaluate the\ncreativity of computational systems and have proven useful in articulating\nachievements of this work and directions for further research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 11:58:59 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Jordanous", "Anna", ""], ["Keller", "Bill", ""]]}, {"id": "1609.03376", "submitter": "Nizar Habash", "authors": "Ahmed El Kholy and Nizar Habash", "title": "Morphological Constraints for Phrase Pivot Statistical Machine\n  Translation", "comments": "13 pages; Proceedings of MT Summit XV, vol.1: MT Researchers' Track;\n  Miami, Oct 30 - Nov 3, 2015", "journal-ref": "Proceedings of MT Summit XV. Miami. pp 104-116 (2015)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of parallel data for many language pairs is an important challenge\nto statistical machine translation (SMT). One common solution is to pivot\nthrough a third language for which there exist parallel corpora with the source\nand target languages. Although pivoting is a robust technique, it introduces\nsome low quality translations especially when a poor morphology language is\nused as the pivot between rich morphology languages. In this paper, we examine\nthe use of synchronous morphology constraint features to improve the quality of\nphrase pivot SMT. We compare hand-crafted constraints to those learned from\nlimited parallel data between source and target languages. The learned\nmorphology constraints are based on projected align- ments between the source\nand target phrases in the pivot phrase table. We show positive results on\nHebrew-Arabic SMT (pivoting on English). We get 1.5 BLEU points over a phrase\npivot baseline and 0.8 BLEU points over a system combination baseline with a\ndirect model built from parallel data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 12:52:37 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Kholy", "Ahmed El", ""], ["Habash", "Nizar", ""]]}, {"id": "1609.03441", "submitter": "Micha{\\l} Zapotoczny", "authors": "Jan Chorowski, Micha{\\l} Zapotoczny, Pawe{\\l} Rychlikowski", "title": "Read, Tag, and Parse All at Once, or Fully-neural Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dependency parser implemented as a single deep neural network\nthat reads orthographic representations of words and directly generates\ndependencies and their labels. Unlike typical approaches to parsing, the model\ndoesn't require part-of-speech (POS) tagging of the sentences. With proper\nregularization and additional supervision achieved with multitask learning we\nreach state-of-the-art performance on Slavic languages from the Universal\nDependencies treebank: with no linguistic features other than characters, our\nparser is as accurate as a transition- based system trained on perfect POS\ntags.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 15:16:43 GMT"}, {"version": "v2", "created": "Mon, 5 Jun 2017 18:46:40 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Chorowski", "Jan", ""], ["Zapotoczny", "Micha\u0142", ""], ["Rychlikowski", "Pawe\u0142", ""]]}, {"id": "1609.03528", "submitter": "Andreas Stolcke", "authors": "W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu\n  and G. Zweig", "title": "The Microsoft 2016 Conversational Speech Recognition System", "comments": null, "journal-ref": "Proc. IEEE ICASSP, 2017", "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Microsoft's conversational speech recognition system, in which we\ncombine recent developments in neural-network-based acoustic and language\nmodeling to advance the state of the art on the Switchboard recognition task.\nInspired by machine learning ensemble techniques, the system uses a range of\nconvolutional and recurrent neural networks. I-vector modeling and lattice-free\nMMI training provide significant gains for all acoustic model architectures.\nLanguage model rescoring with multiple forward and backward running RNNLMs, and\nword posterior-based system combination provide a 20% boost. The best single\nsystem uses a ResNet architecture acoustic model with RNNLM rescoring, and\nachieves a word error rate of 6.9% on the NIST 2000 Switchboard task. The\ncombined system has an error rate of 6.2%, representing an improvement over\npreviously reported results on this benchmark task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 18:59:29 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 08:27:28 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Xiong", "W.", ""], ["Droppo", "J.", ""], ["Huang", "X.", ""], ["Seide", "F.", ""], ["Seltzer", "M.", ""], ["Stolcke", "A.", ""], ["Yu", "D.", ""], ["Zweig", "G.", ""]]}, {"id": "1609.03632", "submitter": "Bishan Yang", "authors": "Bishan Yang and Tom Mitchell", "title": "Joint Extraction of Events and Entities within a Document Context", "comments": "11 pages, 2 figures, published at NAACL 2016", "journal-ref": "Proceedings of NAACL-HLT 2016, pages 289-299", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events and entities are closely related; entities are often actors or\nparticipants in events and events without entities are uncommon. The\ninterpretation of events and entities is highly contextually dependent.\nExisting work in information extraction typically models events separately from\nentities, and performs inference at the sentence level, ignoring the rest of\nthe document. In this paper, we propose a novel approach that models the\ndependencies among variables of events, entities, and their relations, and\nperforms joint inference of these variables across a document. The goal is to\nenable access to document-level contextual information and facilitate\ncontext-aware predictions. We demonstrate that our approach substantially\noutperforms the state-of-the-art methods for event extraction as well as a\nstrong baseline for entity extraction.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 23:27:37 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1609.03663", "submitter": "Tong Wang", "authors": "Tong Wang, Ping Chen, Kevin Amaral, Jipeng Qiang", "title": "An Experimental Study of LSTM Encoder-Decoder Model for Text\n  Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text simplification (TS) aims to reduce the lexical and structural complexity\nof a text, while still retaining the semantic meaning. Current automatic TS\ntechniques are limited to either lexical-level applications or manually\ndefining a large amount of rules. Since deep neural networks are powerful\nmodels that have achieved excellent performance over many difficult tasks, in\nthis paper, we propose to use the Long Short-Term Memory (LSTM) Encoder-Decoder\nmodel for sentence level TS, which makes minimal assumptions about word\nsequence. We conduct preliminary experiments to find that the model is able to\nlearn operation rules such as reversing, sorting and replacing from sequence\npairs, which shows that the model may potentially discover and apply rules such\nas modifying sentence structure, substituting words, and removing words for TS.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 03:02:32 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Wang", "Tong", ""], ["Chen", "Ping", ""], ["Amaral", "Kevin", ""], ["Qiang", "Jipeng", ""]]}, {"id": "1609.03777", "submitter": "Kyuyeon Hwang", "authors": "Kyuyeon Hwang, Wonyong Sung", "title": "Character-Level Language Modeling with Hierarchical Recurrent Neural\n  Networks", "comments": "Submitted to NIPS 2016 on May 20, 2016 (v1), accepted to ICASSP 2017\n  (v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network (RNN) based character-level language models (CLMs)\nare extremely useful for modeling out-of-vocabulary words by nature. However,\ntheir performance is generally much worse than the word-level language models\n(WLMs), since CLMs need to consider longer history of tokens to properly\npredict the next one. We address this problem by proposing hierarchical RNN\narchitectures, which consist of multiple modules with different timescales.\nDespite the multi-timescale structures, the input and output layers operate\nwith the character-level clock, which allows the existing RNN CLM training\napproaches to be directly applicable without any modifications. Our CLM models\nshow better perplexity than Kneser-Ney (KN) 5-gram WLMs on the One Billion Word\nBenchmark with only 2% of parameters. Also, we present real-time\ncharacter-level end-to-end speech recognition examples on the Wall Street\nJournal (WSJ) corpus, where replacing traditional mono-clock RNN CLMs with the\nproposed models results in better recognition accuracies even though the number\nof parameters are reduced to 30%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 11:41:48 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 13:49:41 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Hwang", "Kyuyeon", ""], ["Sung", "Wonyong", ""]]}, {"id": "1609.03976", "submitter": "Ozan \\c{C}a\\u{g}layan", "authors": "Ozan Caglayan, Lo\\\"ic Barrault, Fethi Bougares", "title": "Multimodal Attention for Neural Machine Translation", "comments": "10 pages, under review COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The attention mechanism is an important part of the neural machine\ntranslation (NMT) where it was reported to produce richer source representation\ncompared to fixed-length encoding sequence-to-sequence models. Recently, the\neffectiveness of attention has also been explored in the context of image\ncaptioning. In this work, we assess the feasibility of a multimodal attention\nmechanism that simultaneously focus over an image and its natural language\ndescription for generating a description in another language. We train several\nvariants of our proposed attention mechanism on the Multi30k multilingual image\ncaptioning dataset. We show that a dedicated attention for each modality\nachieves up to 1.6 points in BLEU and METEOR compared to a textual NMT\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 18:46:03 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Caglayan", "Ozan", ""], ["Barrault", "Lo\u00efc", ""], ["Bougares", "Fethi", ""]]}, {"id": "1609.04186", "submitter": "Lemao Liu", "authors": "Lemao Liu, Masao Utiyama, Andrew Finch and Eiichiro Sumita", "title": "Neural Machine Translation with Supervised Attention", "comments": "This paper was submitted into COLING2016 on July 10, and it is under\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention mechanisim is appealing for neural machine translation, since\nit is able to dynam- ically encode a source sentence by generating a alignment\nbetween a target word and source words. Unfortunately, it has been proved to be\nworse than conventional alignment models in aligment accuracy. In this paper,\nwe analyze and explain this issue from the point view of re- ordering, and\npropose a supervised attention which is learned with guidance from conventional\nalignment models. Experiments on two Chinese-to-English translation tasks show\nthat the super- vised attention mechanism yields better alignments leading to\nsubstantial gains over the standard attention based NMT.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 09:31:40 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Liu", "Lemao", ""], ["Utiyama", "Masao", ""], ["Finch", "Andrew", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1609.04253", "submitter": "Amir H. Jadidinejad", "authors": "Amir H. Jadidinejad", "title": "Neural Machine Transliteration: Preliminary Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine transliteration is the process of automatically transforming the\nscript of a word from a source language to a target language, while preserving\npronunciation. Sequence to sequence learning has recently emerged as a new\nparadigm in supervised learning. In this paper a character-based\nencoder-decoder model has been proposed that consists of two Recurrent Neural\nNetworks. The encoder is a Bidirectional recurrent neural network that encodes\na sequence of symbols into a fixed-length vector representation, and the\ndecoder generates the target sequence using an attention-based recurrent neural\nnetwork. The encoder, the decoder and the attention mechanism are jointly\ntrained to maximize the conditional probability of a target sequence given a\nsource sequence. Our experiments on different datasets show that the proposed\nencoder-decoder model is able to achieve significantly higher transliteration\nquality over traditional statistical models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 13:12:12 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Jadidinejad", "Amir H.", ""]]}, {"id": "1609.04309", "submitter": "Edouard Grave", "authors": "Edouard Grave, Armand Joulin, Moustapha Ciss\\'e, David Grangier,\n  Herv\\'e J\\'egou", "title": "Efficient softmax approximation for GPUs", "comments": "Accepted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approximate strategy to efficiently train neural network based\nlanguage models over very large vocabularies. Our approach, called adaptive\nsoftmax, circumvents the linear dependency on the vocabulary size by exploiting\nthe unbalanced word distribution to form clusters that explicitly minimize the\nexpectation of computation time. Our approach further reduces the computational\ntime by exploiting the specificities of modern architectures and matrix-matrix\nvector operations, making it particularly suited for graphical processing\nunits. Our experiments carried out on standard benchmarks, such as EuroParl and\nOne Billion Word, show that our approach brings a large gain in efficiency over\nstandard approximations while achieving an accuracy close to that of the full\nsoftmax. The code of our method is available at\nhttps://github.com/facebookresearch/adaptive-softmax.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 15:15:08 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 21:42:39 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 16:33:04 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Ciss\u00e9", "Moustapha", ""], ["Grangier", "David", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1609.04325", "submitter": "Stephen Mayhew", "authors": "Stephen Mayhew, Christos Christodoulopoulos, Dan Roth", "title": "Transliteration in Any Language with Surrogate Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for transliteration generation that can produce\ntransliterations in every language. Where previous results are only as\nmultilingual as Wikipedia, we show how to use training data from Wikipedia as\nsurrogate training for any language. Thus, the problem becomes one of ranking\nWikipedia languages in order of suitability with respect to a target language.\nWe introduce several task-specific methods for ranking languages, and show that\nour approach is comparable to the oracle ceiling, and even outperforms it in\nsome cases.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 15:58:55 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Mayhew", "Stephen", ""], ["Christodoulopoulos", "Christos", ""], ["Roth", "Dan", ""]]}, {"id": "1609.04417", "submitter": "Peng Dai", "authors": "Peng Dai, Xue Teng, Frank Rudzicz, Ing Yann Soon", "title": "An Adaptive Psychoacoustic Model for Automatic Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compared with automatic speech recognition (ASR), the human auditory system\nis more adept at handling noise-adverse situations, including environmental\nnoise and channel distortion. To mimic this adeptness, auditory models have\nbeen widely incorporated in ASR systems to improve their robustness. This paper\nproposes a novel auditory model which incorporates psychoacoustics and\notoacoustic emissions (OAEs) into ASR. In particular, we successfully implement\nthe frequency-dependent property of psychoacoustic models and effectively\nimprove resulting system performance. We also present a novel double-transform\nspectrum-analysis technique, which can qualitatively predict ASR performance\nfor different noise types. Detailed theoretical analysis is provided to show\nthe effectiveness of the proposed algorithm. Experiments are carried out on the\nAURORA2 database and show that the word recognition rate using our proposed\nfeature extraction method is significantly increased over the baseline. Given\nmodels trained with clean speech, our proposed method achieves up to 85.39%\nword recognition accuracy on noisy data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 20:02:42 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Dai", "Peng", ""], ["Teng", "Xue", ""], ["Rudzicz", "Frank", ""], ["Soon", "Ing Yann", ""]]}, {"id": "1609.04621", "submitter": "Mercedes Garc\\'ia Mart\\'inez", "authors": "Mercedes Garc\\'ia-Mart\\'inez, Lo\\\"ic Barrault and Fethi Bougares", "title": "Factored Neural Machine Translation", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach for neural machine translation (NMT) using the\nmorphological and grammatical decomposition of the words (factors) in the\noutput side of the neural network. This architecture addresses two main\nproblems occurring in MT, namely dealing with a large target language\nvocabulary and the out of vocabulary (OOV) words. By the means of factors, we\nare able to handle larger vocabulary and reduce the training time (for systems\nwith equivalent target language vocabulary size). In addition, we can produce\nnew words that are not in the vocabulary. We use a morphological analyser to\nget a factored representation of each word (lemmas, Part of Speech tag, tense,\nperson, gender and number). We have extended the NMT approach with attention\nmechanism in order to have two different outputs, one for the lemmas and the\nother for the rest of the factors. The final translation is built using some\n\\textit{a priori} linguistic information. We compare our extension with a\nword-based NMT system. The experiments, performed on the IWSLT'15 dataset\ntranslating from English to French, show that while the performance do not\nalways increase, the system can manage a much larger vocabulary and\nconsistently reduce the OOV rate. We observe up to 2% BLEU point improvement in\na simulated out of domain translation setup.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 13:15:01 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Barrault", "Lo\u00efc", ""], ["Bougares", "Fethi", ""]]}, {"id": "1609.04628", "submitter": "Rocco Tripodi", "authors": "Rocco Tripodi, Sebastiano Vascon, Marcello Pelillo", "title": "Context Aware Nonnegative Matrix Factorization Clustering", "comments": "6 pages, 3 figures. Full paper accepted to International Conference\n  on Pattern Recognition ICPR 2016, Canc\\'un, Mexico", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a method to refine the clustering results obtained\nwith the nonnegative matrix factorization (NMF) technique, imposing consistency\nconstraints on the final labeling of the data. The research community focused\nits effort on the initialization and on the optimization part of this method,\nwithout paying attention to the final cluster assignments. We propose a game\ntheoretic framework in which each object to be clustered is represented as a\nplayer, which has to choose its cluster membership. The information obtained\nwith NMF is used to initialize the strategy space of the players and a weighted\ngraph is used to model the interactions among the players. These interactions\nallow the players to choose a cluster which is coherent with the clusters\nchosen by similar players, a property which is not guaranteed by NMF, since it\nproduces a soft clustering of the data. The results on common benchmarks show\nthat our model is able to improve the performances of many NMF formulations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 13:23:43 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Tripodi", "Rocco", ""], ["Vascon", "Sebastiano", ""], ["Pelillo", "Marcello", ""]]}, {"id": "1609.04779", "submitter": "Trang Tran", "authors": "Trang Tran and Mari Ostendorf", "title": "Characterizing the Language of Online Communities and its Relation to\n  Community Reception", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates style and topic aspects of language in online\ncommunities: looking at both utility as an identifier of the community and\ncorrelation with community reception of content. Style is characterized using a\nhybrid word and part-of-speech tag n-gram language model, while topic is\nrepresented using Latent Dirichlet Allocation. Experiments with several Reddit\nforums show that style is a better indicator of community identity than topic,\neven for communities organized around specific topics. Further, there is a\npositive correlation between the community reception to a contribution and the\nstyle similarity to that community, but not so for topic similarity.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 19:07:17 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Tran", "Trang", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1609.04873", "submitter": "Chris Quirk", "authors": "Chris Quirk and Hoifung Poon", "title": "Distant Supervision for Relation Extraction beyond the Sentence Boundary", "comments": "Presented at EACL 2017; 9 pages (12 pages including references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing demand for structured knowledge has led to great interest in\nrelation extraction, especially in cases with limited supervision. However,\nexisting distance supervision approaches only extract relations expressed in\nsingle sentences. In general, cross-sentence relation extraction is\nunder-explored, even in the supervised-learning setting. In this paper, we\npropose the first approach for applying distant supervision to cross- sentence\nrelation extraction. At the core of our approach is a graph representation that\ncan incorporate both standard dependencies and discourse relations, thus\nproviding a unifying way to model relations within and across sentences. We\nextract features from multiple paths in this graph, increasing accuracy and\nrobustness when confronted with linguistic variation and analysis error.\nExperiments on an important extraction task for precision medicine show that\nour approach can learn an accurate cross-sentence extractor, using only a small\nexisting knowledge base and unlabeled text from biomedical research articles.\nCompared to the existing distant supervision paradigm, our approach extracted\ntwice as many relations at similar precision, thus demonstrating the prevalence\nof cross-sentence relations and the promise of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 22:01:26 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 04:42:20 GMT"}, {"version": "v3", "created": "Mon, 14 Aug 2017 23:54:49 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Quirk", "Chris", ""], ["Poon", "Hoifung", ""]]}, {"id": "1609.04904", "submitter": "Ethan Fast", "authors": "Ethan Fast and Eric Horvitz", "title": "Long-Term Trends in the Public Perception of Artificial Intelligence", "comments": "In AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyses of text corpora over time can reveal trends in beliefs, interest,\nand sentiment about a topic. We focus on views expressed about artificial\nintelligence (AI) in the New York Times over a 30-year period. General\ninterest, awareness, and discussion about AI has waxed and waned since the\nfield was founded in 1956. We present a set of measures that captures levels of\nengagement, measures of pessimism and optimism, the prevalence of specific\nhopes and concerns, and topics that are linked to discussions about AI over\ndecades. We find that discussion of AI has increased sharply since 2009, and\nthat these discussions have been consistently more optimistic than pessimistic.\nHowever, when we examine specific concerns, we find that worries of loss of\ncontrol of AI, ethical concerns for AI, and the negative impact of AI on work\nhave grown in recent years. We also find that hopes for AI in healthcare and\neducation have increased over time.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 03:45:15 GMT"}, {"version": "v2", "created": "Fri, 2 Dec 2016 17:18:42 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Fast", "Ethan", ""], ["Horvitz", "Eric", ""]]}, {"id": "1609.04909", "submitter": "Shourya Roy", "authors": "Shourya Roy, Himanshu S. Bhatt, Y. Narahari", "title": "An Iterative Transfer Learning Based Ensemble Technique for Automatic\n  Short Answer Grading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic short answer grading (ASAG) techniques are designed to\nautomatically assess short answers to questions in natural language, having a\nlength of a few words to a few sentences. Supervised ASAG techniques have been\ndemonstrated to be effective but suffer from a couple of key practical\nlimitations. They are greatly reliant on instructor provided model answers and\nneed labeled training data in the form of graded student answers for every\nassessment task. To overcome these, in this paper, we introduce an ASAG\ntechnique with two novel features. We propose an iterative technique on an\nensemble of (a) a text classifier of student answers and (b) a classifier using\nnumeric features derived from various similarity measures with respect to model\nanswers. Second, we employ canonical correlation analysis based transfer\nlearning on a common feature representation to build the classifier ensemble\nfor questions having no labelled data. The proposed technique handsomely beats\nall winning supervised entries on the SCIENTSBANK dataset from the Student\nResponse Analysis task of SemEval 2013. Additionally, we demonstrate\ngeneralizability and benefits of the proposed technique through evaluation on\nmultiple ASAG datasets from different subject topics and standards.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 04:58:54 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 01:28:17 GMT"}, {"version": "v3", "created": "Mon, 21 Nov 2016 13:44:09 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Roy", "Shourya", ""], ["Bhatt", "Himanshu S.", ""], ["Narahari", "Y.", ""]]}, {"id": "1609.04938", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Anssi Kanervisto, Jeffrey Ling, Alexander M. Rush", "title": "Image-to-Markup Generation with Coarse-to-Fine Attention", "comments": "Accepted by ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural encoder-decoder model to convert images into\npresentational markup based on a scalable coarse-to-fine attention mechanism.\nOur method is evaluated in the context of image-to-LaTeX generation, and we\nintroduce a new dataset of real-world rendered mathematical expressions paired\nwith LaTeX markup. We show that unlike neural OCR techniques using CTC-based\nmodels, attention-based approaches can tackle this non-standard OCR task. Our\napproach outperforms classical mathematical OCR systems by a large margin on\nin-domain rendered data, and, with pretraining, also performs well on\nout-of-domain handwritten data. To reduce the inference complexity associated\nwith the attention-based approaches, we introduce a new coarse-to-fine\nattention layer that selects a support region before applying attention.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 08:14:50 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 22:48:53 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Deng", "Yuntian", ""], ["Kanervisto", "Anssi", ""], ["Ling", "Jeffrey", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1609.05104", "submitter": "Tirupattur Ananthapadmanabha Dr", "authors": "T.V. Ananthapadmanabha and A.G. Ramakrishnan", "title": "Intrinsic normalization and extrinsic denormalization of formant data of\n  vowels", "comments": "18 pages, 8 figures. Title has been revised. Appendix has been added\n  to include more figures and to clarify 'hypothesize-test' procedure, JASA-EL,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a known speaker-intrinsic normalization procedure, formant data are\nscaled by the reciprocal of the geometric mean of the first three formant\nfrequencies. This reduces the influence of the talker but results in a\ndistorted vowel space. The proposed speaker-extrinsic procedure re-scales the\nnormalized values by the mean formant values of vowels. When tested on the\nformant data of vowels published by Peterson and Barney, the combined approach\nleads to well separated clusters by reducing the spread due to talkers. The\nproposed procedure performs better than two top-ranked normalization procedures\nbased on the accuracy of vowel classification as the objective measure.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 15:20:32 GMT"}, {"version": "v2", "created": "Sat, 10 Dec 2016 10:20:01 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Ananthapadmanabha", "T. V.", ""], ["Ramakrishnan", "A. G.", ""]]}, {"id": "1609.05180", "submitter": "Shuhan Wang", "authors": "Shuhan Wang, Erik Andersen", "title": "Grammatical Templates: Improving Text Difficulty Evaluation for Language\n  Learners", "comments": null, "journal-ref": "The 26th International Conference on Computational Linguistics\n  (COLING), 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language students are most engaged while reading texts at an appropriate\ndifficulty level. However, existing methods of evaluating text difficulty focus\nmainly on vocabulary and do not prioritize grammatical features, hence they do\nnot work well for language learners with limited knowledge of grammar. In this\npaper, we introduce grammatical templates, the expert-identified units of\ngrammar that students learn from class, as an important feature of text\ndifficulty evaluation. Experimental classification results show that\ngrammatical template features significantly improve text difficulty prediction\naccuracy over baseline readability features by 7.4%. Moreover, we build a\nsimple and human-understandable text difficulty evaluation approach with 87.7%\naccuracy, using only 5 grammatical template features.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 19:12:30 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 22:04:47 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Wang", "Shuhan", ""], ["Andersen", "Erik", ""]]}, {"id": "1609.05234", "submitter": "Tzu Hsiang Lin", "authors": "Yen-Chen Wu, Tzu-Hsiang Lin, Yang-De Chen, Hung-Yi Lee, Lin-Shan Lee", "title": "Interactive Spoken Content Retrieval by Deep Reinforcement Learning", "comments": "Accepted conference paper: \"The Annual Conference of the\n  International Speech Communication Association (Interspeech), 2016\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-machine interaction is important for spoken content retrieval. For text\ncontent retrieval, the user can easily scan through and select on a list of\nretrieved item. This is impossible for spoken content retrieval, because the\nretrieved items are difficult to show on screen. Besides, due to the high\ndegree of uncertainty for speech recognition, the retrieval results can be very\nnoisy. One way to counter such difficulties is through user-machine\ninteraction. The machine can take different actions to interact with the user\nto obtain better retrieval results before showing to the user. The suitable\nactions depend on the retrieval status, for example requesting for extra\ninformation from the user, returning a list of topics for user to select, etc.\nIn our previous work, some hand-crafted states estimated from the present\nretrieval results are used to determine the proper actions. In this paper, we\npropose to use Deep-Q-Learning techniques instead to determine the machine\nactions for interactive spoken content retrieval. Deep-Q-Learning bypasses the\nneed for estimation of the hand-crafted states, and directly determine the best\naction base on the present retrieval status even without any human knowledge.\nIt is shown to achieve significantly better performance compared with the\nprevious hand-crafted states.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 20:56:22 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Wu", "Yen-Chen", ""], ["Lin", "Tzu-Hsiang", ""], ["Chen", "Yang-De", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-Shan", ""]]}, {"id": "1609.05244", "submitter": "Haohan Wang", "authors": "Haohan Wang, Aaksha Meghawat, Louis-Philippe Morency and Eric P. Xing", "title": "Select-Additive Learning: Improving Generalization in Multimodal\n  Sentiment Analysis", "comments": "Supplementary files at:\n  http://www.cs.cmu.edu/~haohanw/document/sal_supp.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sentiment analysis is drawing an increasing amount of attention\nthese days. It enables mining of opinions in video reviews which are now\navailable aplenty on online platforms. However, multimodal sentiment analysis\nhas only a few high-quality data sets annotated for training machine learning\nalgorithms. These limited resources restrict the generalizability of models,\nwhere, for example, the unique characteristics of a few speakers (e.g., wearing\nglasses) may become a confounding factor for the sentiment classification task.\nIn this paper, we propose a Select-Additive Learning (SAL) procedure that\nimproves the generalizability of trained neural networks for multimodal\nsentiment analysis. In our experiments, we show that our SAL approach improves\nprediction accuracy significantly in all three modalities (verbal, acoustic,\nvisual), as well as in their fusion. Our results show that SAL, even when\ntrained on one dataset, achieves good generalization across two new test\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 21:33:42 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 21:38:40 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Wang", "Haohan", ""], ["Meghawat", "Aaksha", ""], ["Morency", "Louis-Philippe", ""], ["Xing", "Eric P.", ""]]}, {"id": "1609.05511", "submitter": "Dafydd Gibbon", "authors": "Dafydd Gibbon and Sascha Griffiths", "title": "Multilinear Grammar: Ranks and Interpretations", "comments": "45 pages, 10 figures. In press, journal Open Linguistics (de Gruyter\n  Open), proofread and corrected version", "journal-ref": "Open Linguistics 2017, 3(1): 265-307", "doi": "10.1515/opli-2017-0014", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilinear Grammar provides a framework for integrating the many different\nsyntagmatic structures of language into a coherent semiotically based Rank\nInterpretation Architecture, with default linear grammars at each rank. The\narchitecture defines a Sui Generis Condition on ranks, from discourse through\nutterance and phrasal structures to the word, with its sub-ranks of morphology\nand phonology. Each rank has unique structures and its own semantic-pragmatic\nand prosodic-phonetic interpretation models. Default computational models for\neach rank are proposed, based on a Procedural Plausibility Condition:\nincremental processing in linear time with finite working memory. We suggest\nthat the Rank Interpretation Architecture and its multilinear properties\nprovide systematic design features of human languages, contrasting with\nunordered lists of key properties or single structural properties at one rank,\nsuch as recursion, which have previously been been put forward as language\ndesign features. The framework provides a realistic background for the gradual\ndevelopment of complexity in the phylogeny and ontogeny of language, and\nclarifies a range of challenges for the evaluation of realistic linguistic\ntheories and applications. The empirical objective of the paper is to\ndemonstrate unique multilinear properties at each rank and thereby motivate the\nMultilinear Grammar and Rank Interpretation Architecture framework as a\ncoherent approach to capturing the complexity of human languages in the\nsimplest possible way.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 16:29:20 GMT"}, {"version": "v2", "created": "Sun, 9 Oct 2016 14:07:26 GMT"}, {"version": "v3", "created": "Tue, 11 Oct 2016 13:14:19 GMT"}, {"version": "v4", "created": "Mon, 10 Jul 2017 23:00:53 GMT"}, {"version": "v5", "created": "Sun, 27 Aug 2017 21:29:55 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Gibbon", "Dafydd", ""], ["Griffiths", "Sascha", ""]]}, {"id": "1609.05600", "submitter": "Damien Teney", "authors": "Damien Teney, Lingqiao Liu, Anton van den Hengel", "title": "Graph-Structured Representations for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to improve visual question answering (VQA) with\nstructured representations of both scene contents and questions. A key\nchallenge in VQA is to require joint reasoning over the visual and text\ndomains. The predominant CNN/LSTM-based approach to VQA is limited by\nmonolithic vector representations that largely ignore structure in the scene\nand in the form of the question. CNN feature vectors cannot effectively capture\nsituations as simple as multiple object instances, and LSTMs process questions\nas series of words, which does not reflect the true complexity of language\nstructure. We instead propose to build graphs over the scene objects and over\nthe question words, and we describe a deep neural network that exploits the\nstructure in these representations. This shows significant benefit over the\nsequential processing of LSTMs. The overall efficacy of our approach is\ndemonstrated by significant improvements over the state-of-the-art, from 71.2%\nto 74.4% in accuracy on the \"abstract scenes\" multiple-choice benchmark, and\nfrom 34.7% to 39.1% in accuracy over pairs of \"balanced\" scenes, i.e. images\nwith fine-grained differences and opposite yes/no answers to a same question.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 05:21:36 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 04:26:26 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Teney", "Damien", ""], ["Liu", "Lingqiao", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1609.05625", "submitter": "Ahmed Ali", "authors": "Ahmed Ali, Peter Bell, James Glass, Yacine Messaoui, Hamdy Mubarak,\n  Steve Renals, Yifan Zhang", "title": "The MGB-2 Challenge: Arabic Multi-Dialect Broadcast Media Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Arabic Multi-Genre Broadcast (MGB-2) Challenge for\nSLT-2016. Unlike last year's English MGB Challenge, which focused on\nrecognition of diverse TV genres, this year, the challenge has an emphasis on\nhandling the diversity in dialect in Arabic speech. Audio data comes from 19\ndistinct programmes from the Aljazeera Arabic TV channel between March 2005 and\nDecember 2015. Programmes are split into three groups: conversations,\ninterviews, and reports. A total of 1,200 hours have been released with lightly\nsupervised transcriptions for the acoustic modelling. For language modelling,\nwe made available over 110M words crawled from Aljazeera Arabic website\nAljazeera.net for a 10 year duration 2000-2011. Two lexicons have been\nprovided, one phoneme based and one grapheme based. Finally, two tasks were\nproposed for this year's challenge: standard speech transcription, and word\nalignment. This paper describes the task data and evaluation process used in\nthe MGB challenge, and summarises the results obtained.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 07:57:35 GMT"}, {"version": "v2", "created": "Sun, 14 May 2017 13:32:12 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 12:44:47 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ali", "Ahmed", ""], ["Bell", "Peter", ""], ["Glass", "James", ""], ["Messaoui", "Yacine", ""], ["Mubarak", "Hamdy", ""], ["Renals", "Steve", ""], ["Zhang", "Yifan", ""]]}, {"id": "1609.05650", "submitter": "Ahmed Ali Dr.", "authors": "Sameer Khurana, Ahmed Ali, Steve Renals", "title": "Multi-view Dimensionality Reduction for Dialect Identification of Arabic\n  Broadcast Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new Vector Space Model (VSM) of speech utterances\nfor the task of spoken dialect identification. Generally, DID systems are built\nusing two sets of features that are extracted from speech utterances; acoustic\nand phonetic. The acoustic and phonetic features are used to form vector\nrepresentations of speech utterances in an attempt to encode information about\nthe spoken dialects. The Phonotactic and Acoustic VSMs, thus formed, are used\nfor the task of DID. The aim of this paper is to construct a single VSM that\nencodes information about spoken dialects from both the Phonotactic and\nAcoustic VSMs. Given the two views of the data, we make use of a well known\nmulti-view dimensionality reduction technique known as Canonical Correlation\nAnalysis (CCA), to form a single vector representation for each speech\nutterance that encodes dialect specific discriminative information from both\nthe phonetic and acoustic representations. We refer to this approach as feature\nspace combination approach and show that our CCA based feature vector\nrepresentation performs better on the Arabic DID task than the phonetic and\nacoustic feature representations used alone. We also present the feature space\ncombination approach as a viable alternative to the model based combination\napproach, where two DID systems are built using the two VSMs (Phonotactic and\nAcoustic) and the final prediction score is the output score combination from\nthe two systems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 09:44:54 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Khurana", "Sameer", ""], ["Ali", "Ahmed", ""], ["Renals", "Steve", ""]]}, {"id": "1609.05935", "submitter": "Andreas Stolcke", "authors": "G. Zweig, C. Yu, J. Droppo and A. Stolcke", "title": "Advances in All-Neural Speech Recognition", "comments": null, "journal-ref": "Proc. IEEE ICASSP, 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper advances the design of CTC-based all-neural (or end-to-end) speech\nrecognizers. We propose a novel symbol inventory, and a novel iterated-CTC\nmethod in which a second system is used to transform a noisy initial output\ninto a cleaner version. We present a number of stabilization and initialization\nmethods we have found useful in training these networks. We evaluate our system\non the commonly used NIST 2000 conversational telephony test set, and\nsignificantly exceed the previously published performance of similar systems,\nboth with and without the use of an external language model and decoding\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 20:52:44 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 08:30:10 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Zweig", "G.", ""], ["Yu", "C.", ""], ["Droppo", "J.", ""], ["Stolcke", "A.", ""]]}, {"id": "1609.06038", "submitter": "Qian Chen", "authors": "Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, Diana Inkpen", "title": "Enhanced LSTM for Natural Language Inference", "comments": "ACL 2017", "journal-ref": null, "doi": "10.18653/v1/P17-1152", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning and inference are central to human and artificial intelligence.\nModeling inference in human language is very challenging. With the availability\nof large annotated data (Bowman et al., 2015), it has recently become feasible\nto train neural network based inference models, which have shown to be very\neffective. In this paper, we present a new state-of-the-art result, achieving\nthe accuracy of 88.6% on the Stanford Natural Language Inference Dataset.\nUnlike the previous top models that use very complicated network architectures,\nwe first demonstrate that carefully designing sequential inference models based\non chain LSTMs can outperform all previous models. Based on this, we further\nshow that by explicitly considering recursive architectures in both local\ninference modeling and inference composition, we achieve additional\nimprovement. Particularly, incorporating syntactic parsing information\ncontributes to our best result---it further improves the performance even when\nadded to the already very strong model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 06:59:31 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 03:34:41 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 17:37:13 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chen", "Qian", ""], ["Zhu", "Xiaodan", ""], ["Ling", "Zhenhua", ""], ["Wei", "Si", ""], ["Jiang", "Hui", ""], ["Inkpen", "Diana", ""]]}, {"id": "1609.06049", "submitter": "Laurent Besacier", "authors": "Ngoc-Tien Le, Benjamin Lecouteux, Laurent Besacier", "title": "Automatic Quality Assessment for Speech Translation Using Joint ASR and\n  MT Features", "comments": "submitted to MT Journal (special issue on spoken language\n  translation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses automatic quality assessment of spoken language\ntranslation (SLT). This relatively new task is defined and formalized as a\nsequence labeling problem where each word in the SLT hypothesis is tagged as\ngood or bad according to a large feature set. We propose several word\nconfidence estimators (WCE) based on our automatic evaluation of transcription\n(ASR) quality, translation (MT) quality, or both (combined ASR+MT). This\nresearch work is possible because we built a specific corpus which contains\n6.7k utterances for which a quintuplet containing: ASR output, verbatim\ntranscript, text translation, speech translation and post-edition of\ntranslation is built. The conclusion of our multiple experiments using joint\nASR and MT features for WCE is that MT features remain the most influent while\nASR feature can bring interesting complementary information. Our robust quality\nestimators for SLT can be used for re-scoring speech translation graphs or for\nproviding feedback to the user in interactive speech translation or\ncomputer-assisted speech-to-text scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 08:04:33 GMT"}], "update_date": "2016-10-02", "authors_parsed": [["Le", "Ngoc-Tien", ""], ["Lecouteux", "Benjamin", ""], ["Besacier", "Laurent", ""]]}, {"id": "1609.06082", "submitter": "Yitong Li", "authors": "Yitong Li and Trevor Cohn and Timothy Baldwin", "title": "Learning Robust Representations of Text", "comments": "5 pages with 2 pages reference, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved remarkable results across many language\nprocessing tasks, however these methods are highly sensitive to noise and\nadversarial attacks. We present a regularization based method for limiting\nnetwork sensitivity to its inputs, inspired by ideas from computer vision, thus\nlearning models that are more robust. Empirical evaluation over a range of\nsentiment datasets with a convolutional neural network shows that, compared to\na baseline model and the dropout method, our method achieves superior\nperformance over noisy inputs and out-of-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 10:23:47 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Li", "Yitong", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1609.06127", "submitter": "Diana Al Jlailaty", "authors": "Diana Jlailaty and Daniela Grigori and Khalid Belhajjame", "title": "A framework for mining process models from emails logs", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its wide use in personal, but most importantly, professional contexts,\nemail represents a valuable source of information that can be harvested for\nunderstanding, reengineering and repurposing undocumented business processes of\ncompanies and institutions. Towards this aim, a few researchers investigated\nthe problem of extracting process oriented information from email logs in order\nto take benefit of the many available process mining techniques and tools. In\nthis paper we go further in this direction, by proposing a new method for\nmining process models from email logs that leverage unsupervised machine\nlearning techniques with little human involvement. Moreover, our method allows\nto semi-automatically label emails with activity names, that can be used for\nactivity recognition in new incoming emails. A use case demonstrates the\nusefulness of the proposed solution using a modest in size, yet real-world,\ndataset containing emails that belong to two different process models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 12:29:15 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Jlailaty", "Diana", ""], ["Grigori", "Daniela", ""], ["Belhajjame", "Khalid", ""]]}, {"id": "1609.06204", "submitter": "Alessio Palmero Aprosio", "authors": "Alessio Palmero Aprosio and Giovanni Moretti", "title": "Italy goes to Stanford: a collection of CoreNLP modules for Italian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this we paper present Tint, an easy-to-use set of fast, accurate and\nextendable Natural Language Processing modules for Italian. It is based on\nStanford CoreNLP and is freely available as a standalone software or a library\nthat can be integrated in an existing project.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 14:53:05 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 08:33:33 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Aprosio", "Alessio Palmero", ""], ["Moretti", "Giovanni", ""]]}, {"id": "1609.06239", "submitter": "John Beieler", "authors": "John Beieler", "title": "Generating Politically-Relevant Event Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generated political event data is an important part of the\nsocial science data ecosystem. The approaches for generating this data, though,\nhave remained largely the same for two decades. During this time, the field of\ncomputational linguistics has progressed tremendously. This paper presents an\noverview of political event data, including methods and ontologies, and a set\nof experiments to determine the applicability of deep neural networks to the\nextraction of political events from news text.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 16:19:54 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Beieler", "John", ""]]}, {"id": "1609.06268", "submitter": "Faizan Javed", "authors": "Yun Zhu, Faizan Javed, Ozgur Ozturk", "title": "Semantic Similarity Strategies for Job Title Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic and accurate classification of items enables numerous downstream\napplications in many domains. These applications can range from faceted\nbrowsing of items to product recommendations and big data analytics. In the\nonline recruitment domain, we refer to classifying job ads to pre-defined or\ncustom occupation categories as job title classification. A large-scale job\ntitle classification system can power various downstream applications such as\nsemantic search, job recommendations and labor market analytics. In this paper,\nwe discuss experiments conducted to improve our in-house job title\nclassification system. The classification component of the system is composed\nof a two-stage coarse and fine level classifier cascade that classifies input\ntext such as job title and/or job ads to one of the thousands of job titles in\nour taxonomy. To improve classification accuracy and effectiveness, we\nexperiment with various semantic representation strategies such as average W2V\nvectors and document similarity measures such as Word Movers Distance (WMD).\nOur initial results show an overall improvement in accuracy of Carotene[1].\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 17:54:47 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Zhu", "Yun", ""], ["Javed", "Faizan", ""], ["Ozturk", "Ozgur", ""]]}, {"id": "1609.06380", "submitter": "Yang Liu", "authors": "Yang Liu and Sujian Li", "title": "Recognizing Implicit Discourse Relations via Repeated Reading: Neural\n  Networks with Multi-Level Attention", "comments": "Accepted as long paper at EMNLP2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing implicit discourse relations is a challenging but important task\nin the field of Natural Language Processing. For such a complex text processing\ntask, different from previous studies, we argue that it is necessary to\nrepeatedly read the arguments and dynamically exploit the efficient features\nuseful for recognizing discourse relations. To mimic the repeated reading\nstrategy, we propose the neural networks with multi-level attention (NNMA),\ncombining the attention mechanism and external memories to gradually fix the\nattention on some specific words helpful to judging the discourse relations.\nExperiments on the PDTB dataset show that our proposed method achieves the\nstate-of-art results. The visualization of the attention weights also\nillustrates the progress that our model observes the arguments on each level\nand progressively locates the important words.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 22:59:19 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Liu", "Yang", ""], ["Li", "Sujian", ""]]}, {"id": "1609.06404", "submitter": "Suwon Shon", "authors": "Suwon Shon, Seongkyu Mun, John H.L. Hansen, Hanseok Ko", "title": "KU-ISPL Language Recognition System for NIST 2015 i-Vector Machine\n  Learning Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In language recognition, the task of rejecting/differentiating closely spaced\nversus acoustically far spaced languages remains a major challenge. For\nconfusable closely spaced languages, the system needs longer input test\nduration material to obtain sufficient information to distinguish between\nlanguages. Alternatively, if languages are distinct and not\nacoustically/linguistically similar to others, duration is not a sufficient\nremedy. The solution proposed here is to explore duration distribution analysis\nfor near/far languages based on the Language Recognition i-Vector Machine\nLearning Challenge 2015 (LRiMLC15) database. Using this knowledge, we propose a\nlikelihood ratio based fusion approach that leveraged both score and duration\ninformation. The experimental results show that the use of duration and score\nfusion improves language recognition performance by 5% relative in LRiMLC15\ncost.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 02:14:23 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Shon", "Suwon", ""], ["Mun", "Seongkyu", ""], ["Hansen", "John H. L.", ""], ["Ko", "Hanseok", ""]]}, {"id": "1609.06490", "submitter": "Xiaoqing Li Xiaoqing Li", "authors": "Xiaoqing Li, Jiajun Zhang and Chengqing Zong", "title": "One Sentence One Model for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) becomes a new state-of-the-art and achieves\npromising translation results using a simple encoder-decoder neural network.\nThis neural network is trained once on the parallel corpus and the fixed\nnetwork is used to translate all the test sentences. We argue that the general\nfixed network cannot best fit the specific test sentences. In this paper, we\npropose the dynamic NMT which learns a general network as usual, and then\nfine-tunes the network for each test sentence. The fine-tune work is done on a\nsmall set of the bilingual training data that is obtained through similarity\nsearch according to the test sentence. Extensive experiments demonstrate that\nthis method can significantly improve the translation performance, especially\nwhen highly similar sentences are available.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 10:28:57 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Li", "Xiaoqing", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1609.06492", "submitter": "Alessia Amelio Dr.", "authors": "Darko Brodic, Alessia Amelio, Zoran N. Milivojevic, Milena Jevtic", "title": "Document Image Coding and Clustering for Script Discrimination", "comments": "8 pages, 4 figures, 2 tables", "journal-ref": "ICIC Express Letters Vol. 10 n. 7 July 2016 pp. 1561-1566", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 10:52:03 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Brodic", "Darko", ""], ["Amelio", "Alessia", ""], ["Milivojevic", "Zoran N.", ""], ["Jevtic", "Milena", ""]]}, {"id": "1609.06530", "submitter": "Sameer Bansal", "authors": "Sameer Bansal, Herman Kamper, Sharon Goldwater, Adam Lopez", "title": "Weakly supervised spoken term discovery using cross-lingual side\n  information", "comments": "5 pages, 4 figures, submitted for ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on unsupervised term discovery (UTD) aims to identify and cluster\nrepeated word-like units from audio alone. These systems are promising for some\nvery low-resource languages where transcribed audio is unavailable, or where no\nwritten form of the language exists. However, in some cases it may still be\nfeasible (e.g., through crowdsourcing) to obtain (possibly noisy) text\ntranslations of the audio. If so, this information could be used as a source of\nside information to improve UTD. Here, we present a simple method for rescoring\nthe output of a UTD system using text translations, and test it on a corpus of\nSpanish audio with English translations. We show that it greatly improves the\naverage precision of the results over a wide range of system configurations and\ndata preprocessing methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 12:43:53 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Bansal", "Sameer", ""], ["Kamper", "Herman", ""], ["Goldwater", "Sharon", ""], ["Lopez", "Adam", ""]]}, {"id": "1609.06577", "submitter": "Fabio Del Vigna", "authors": "Fabio Del Vigna, Marinella Petrocchi, Alessandro Tommasi, Cesare\n  Zavattari, Maurizio Tesconi", "title": "Semi-supervised knowledge extraction for detection of drugs and their\n  effects", "comments": "14 pages excluding references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New Psychoactive Substances (NPS) are drugs that lay in a grey area of\nlegislation, since they are not internationally and officially banned, possibly\nleading to their not prosecutable trade. The exacerbation of the phenomenon is\nthat NPS can be easily sold and bought online. Here, we consider large corpora\nof textual posts, published on online forums specialized on drug discussions,\nplus a small set of known substances and associated effects, which we call\nseeds. We propose a semi-supervised approach to knowledge extraction, applied\nto the detection of drugs (comprising NPS) and effects from the corpora under\ninvestigation. Based on the very small set of initial seeds, the work\nhighlights how a contrastive approach and context deduction are effective in\ndetecting substances and effects from the corpora. Our promising results, which\nfeature a F1 score close to 0.9, pave the way for shortening the detection time\nof new psychoactive substances, once these are discussed and advertised on the\nInternet.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 14:24:44 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Del Vigna", "Fabio", ""], ["Petrocchi", "Marinella", ""], ["Tommasi", "Alessandro", ""], ["Zavattari", "Cesare", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1609.06578", "submitter": "Kar Wai Lim", "authors": "Kar Wai Lim, Wray Buntine", "title": "Twitter Opinion Topic Model: Extracting Product Opinions from Tweets by\n  Leveraging Hashtags and Sentiment Lexicon", "comments": "CIKM paper", "journal-ref": "Proceedings of the 23rd ACM International Conference on\n  Information and Knowledge Management (CIKM), pp. 1319-1328. ACM. 2014", "doi": "10.1145/2661829.2662005", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based opinion mining is widely applied to review data to aggregate or\nsummarize opinions of a product, and the current state-of-the-art is achieved\nwith Latent Dirichlet Allocation (LDA)-based model. Although social media data\nlike tweets are laden with opinions, their \"dirty\" nature (as natural language)\nhas discouraged researchers from applying LDA-based opinion model for product\nreview mining. Tweets are often informal, unstructured and lacking labeled data\nsuch as categories and ratings, making it challenging for product opinion\nmining. In this paper, we propose an LDA-based opinion model named Twitter\nOpinion Topic Model (TOTM) for opinion mining and sentiment analysis. TOTM\nleverages hashtags, mentions, emoticons and strong sentiment words that are\npresent in tweets in its discovery process. It improves opinion prediction by\nmodeling the target-opinion interaction directly, thus discovering target\nspecific opinion words, neglected in existing approaches. Moreover, we propose\na new formulation of incorporating sentiment prior information into a topic\nmodel, by utilizing an existing public sentiment lexicon. This is novel in that\nit learns and updates with the data. We conduct experiments on 9 million tweets\non electronic products, and demonstrate the improved performance of TOTM in\nboth quantitative evaluations and qualitative analysis. We show that\naspect-based opinion analysis on massive volume of tweets provides useful\nopinions on products.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 14:25:23 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Lim", "Kar Wai", ""], ["Buntine", "Wray", ""]]}, {"id": "1609.06616", "submitter": "John J Nay", "authors": "John J. Nay", "title": "Gov2Vec: Learning Distributed Representations of Institutions and Their\n  Legal Text", "comments": "Forthcoming paper in the 2016 Proceedings of the Conference on\n  Empirical Methods in Natural Language Processing Workshop on Natural Language\n  Processing and Computational Social Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare policy differences across institutions by embedding\nrepresentations of the entire legal corpus of each institution and the\nvocabulary shared across all corpora into a continuous vector space. We apply\nour method, Gov2Vec, to Supreme Court opinions, Presidential actions, and\nofficial summaries of Congressional bills. The model discerns meaningful\ndifferences between government branches. We also learn representations for more\nfine-grained word sources: individual Presidents and (2-year) Congresses. The\nsimilarities between learned representations of Congresses over time and\nsitting Presidents are negatively correlated with the bill veto rate, and the\ntemporal ordering of Presidents and Congresses was implicitly learned from only\ntext. With the resulting vectors we answer questions such as: how does Obama\nand the 113th House differ in addressing climate change and how does this vary\nfrom environmental or economic perspectives? Our work illustrates\nvector-arithmetic-based investigations of complex relationships between word\nsources based on their texts. We are extending this to create a more\ncomprehensive legal semantic map.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 16:09:12 GMT"}, {"version": "v2", "created": "Sun, 25 Sep 2016 22:20:12 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Nay", "John J.", ""]]}, {"id": "1609.06649", "submitter": "Ke Wu", "authors": "Ke Wu, Kyle Gorman, and Richard Sproat", "title": "Minimally Supervised Written-to-Spoken Text Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In speech-applications such as text-to-speech (TTS) or automatic speech\nrecognition (ASR), \\emph{text normalization} refers to the task of converting\nfrom a \\emph{written} representation into a representation of how the text is\nto be \\emph{spoken}. In all real-world speech applications, the text\nnormalization engine is developed---in large part---by hand. For example, a\nhand-built grammar may be used to enumerate the possible ways of saying a given\ntoken in a given language, and a statistical model used to select the most\nappropriate pronunciation in context. In this study we examine the tradeoffs\nassociated with using more or less language-specific domain knowledge in a text\nnormalization engine. In the most data-rich scenario, we have access to a\ncarefully constructed hand-built normalization grammar that for any given token\nwill produce a set of all possible verbalizations for that token. We also\nassume a corpus of aligned written-spoken utterances, from which we can train a\nranking model that selects the appropriate verbalization for the given context.\nAs a substitute for the carefully constructed grammar, we also consider a\nscenario with a language-universal normalization \\emph{covering grammar}, where\nthe developer merely needs to provide a set of lexical items particular to the\nlanguage. As a substitute for the aligned corpus, we also consider a scenario\nwhere one only has the spoken side, and the corresponding written side is\n\"hallucinated\" by composing the spoken side with the inverted normalization\ngrammar. We investigate the accuracy of a text normalization engine under each\nof these scenarios. We report the results of experiments on English and\nRussian.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 17:51:11 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Wu", "Ke", ""], ["Gorman", "Kyle", ""], ["Sproat", "Richard", ""]]}, {"id": "1609.06657", "submitter": "Andrew Shin", "authors": "Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada", "title": "The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question\n  Answering (FSVQA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) task has showcased a new stage of interaction\nbetween language and vision, two of the most pivotal components of artificial\nintelligence. However, it has mostly focused on generating short and repetitive\nanswers, mostly single words, which fall short of rich linguistic capabilities\nof humans. We introduce Full-Sentence Visual Question Answering (FSVQA)\ndataset, consisting of nearly 1 million pairs of questions and full-sentence\nanswers for images, built by applying a number of rule-based natural language\nprocessing techniques to original VQA dataset and captions in the MS COCO\ndataset. This poses many additional complexities to conventional VQA task, and\nwe provide a baseline for approaching and evaluating the task, on top of which\nwe invite the research community to build further improvements.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 18:12:04 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Shin", "Andrew", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1609.06686", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Parsa Ghaffari, John G. Breslin", "title": "Character-level and Multi-channel Convolutional Neural Networks for\n  Large-scale Authorship Attribution", "comments": "9 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have demonstrated superior capability\nfor extracting information from raw signals in computer vision. Recently,\ncharacter-level and multi-channel CNNs have exhibited excellent performance for\nsentence classification tasks. We apply CNNs to large-scale authorship\nattribution, which aims to determine an unknown text's author among many\ncandidate authors, motivated by their ability to process character-level\nsignals and to differentiate between a large number of classes, while making\nfast predictions in comparison to state-of-the-art approaches. We extensively\nevaluate CNN-based approaches that leverage word and character channels and\ncompare them against state-of-the-art methods for a large range of author\nnumbers, shedding new light on traditional approaches. We show that\ncharacter-level CNNs outperform the state-of-the-art on four out of five\ndatasets in different domains. Additionally, we present the first application\nof authorship attribution to reddit.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 19:08:15 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Ruder", "Sebastian", ""], ["Ghaffari", "Parsa", ""], ["Breslin", "John G.", ""]]}, {"id": "1609.06773", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Takaaki Hori, Shinji Watanabe", "title": "Joint CTC-Attention based End-to-End Speech Recognition using Multi-task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an increasing interest in end-to-end speech\nrecognition that directly transcribes speech to text without any predefined\nalignments. One approach is the attention-based encoder-decoder framework that\nlearns a mapping between variable-length input and output sequences in one step\nusing a purely data-driven method. The attention model has often been shown to\nimprove the performance over another end-to-end approach, the Connectionist\nTemporal Classification (CTC), mainly because it explicitly uses the history of\nthe target character without any conditional independence assumptions. However,\nwe observed that the performance of the attention has shown poor results in\nnoisy condition and is hard to learn in the initial training stage with long\ninput sequences. This is because the attention model is too flexible to predict\nproper alignments in such cases due to the lack of left-to-right constraints as\nused in CTC. This paper presents a novel method for end-to-end speech\nrecognition to improve robustness and achieve fast convergence by using a joint\nCTC-attention model within the multi-task learning framework, thereby\nmitigating the alignment issue. An experiment on the WSJ and CHiME-4 tasks\ndemonstrates its advantages over both the CTC and attention-based\nencoder-decoder baselines, showing 5.4-14.6% relative improvements in Character\nError Rate (CER).\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 22:48:53 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 21:00:01 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Kim", "Suyoun", ""], ["Hori", "Takaaki", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1609.06783", "submitter": "Kar Wai Lim", "authors": "Kar Wai Lim, Wray Buntine, Changyou Chen, Lan Du", "title": "Nonparametric Bayesian Topic Modelling with the Hierarchical Pitman-Yor\n  Processes", "comments": "Preprint for International Journal of Approximate Reasoning", "journal-ref": "International Journal of Approximate Reasoning, Volume 78, pp.\n  172-191. Elsevier. 2016", "doi": "10.1016/j.ijar.2016.07.007", "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dirichlet process and its extension, the Pitman-Yor process, are\nstochastic processes that take probability distributions as a parameter. These\nprocesses can be stacked up to form a hierarchical nonparametric Bayesian\nmodel. In this article, we present efficient methods for the use of these\nprocesses in this hierarchical context, and apply them to latent variable\nmodels for text analytics. In particular, we propose a general framework for\ndesigning these Bayesian models, which are called topic models in the computer\nscience community. We then propose a specific nonparametric Bayesian topic\nmodel for modelling text from social media. We focus on tweets (posts on\nTwitter) in this article due to their ease of access. We find that our\nnonparametric model performs better than existing parametric models in both\ngoodness of fit and real world applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 00:10:16 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Lim", "Kar Wai", ""], ["Buntine", "Wray", ""], ["Chen", "Changyou", ""], ["Du", "Lan", ""]]}, {"id": "1609.06791", "submitter": "Kar Wai Lim", "authors": "Kar Wai Lim, Changyou Chen, Wray Buntine", "title": "Twitter-Network Topic Model: A Full Bayesian Treatment for Social\n  Network and Text Modeling", "comments": "NIPS workshop paper", "journal-ref": "NIPS 2013 Topic Models: Computation, Application, and Evaluation,\n  pp. 1-5. Google Sites. 2013", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter data is extremely noisy -- each tweet is short, unstructured and with\ninformal language, a challenge for current topic modeling. On the other hand,\ntweets are accompanied by extra information such as authorship, hashtags and\nthe user-follower network. Exploiting this additional information, we propose\nthe Twitter-Network (TN) topic model to jointly model the text and the social\nnetwork in a full Bayesian nonparametric way. The TN topic model employs the\nhierarchical Poisson-Dirichlet processes (PDP) for text modeling and a Gaussian\nprocess random function model for social network modeling. We show that the TN\ntopic model significantly outperforms several existing nonparametric models due\nto its flexibility. Moreover, the TN topic model enables additional informative\ninference such as authors' interests, hashtag analysis, as well as leading to\nfurther applications such as author recommendation, automatic topic labeling\nand hashtag suggestion. Note our general inference framework can readily be\napplied to other topic models with embedded PDP nodes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 01:08:31 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Lim", "Kar Wai", ""], ["Chen", "Changyou", ""], ["Buntine", "Wray", ""]]}, {"id": "1609.07028", "submitter": "Ruobing Xie", "authors": "Ruobing Xie, Zhiyuan Liu, Huanbo Luan, Maosong Sun", "title": "Image-embodied Knowledge Representation Learning", "comments": "7 pages; Accepted by IJCAI-2017", "journal-ref": "IJCAI-2017", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity images could provide significant visual information for knowledge\nrepresentation learning. Most conventional methods learn knowledge\nrepresentations merely from structured triples, ignoring rich visual\ninformation extracted from entity images. In this paper, we propose a novel\nImage-embodied Knowledge Representation Learning model (IKRL), where knowledge\nrepresentations are learned with both triple facts and images. More\nspecifically, we first construct representations for all images of an entity\nwith a neural image encoder. These image representations are then integrated\ninto an aggregated image-based representation via an attention-based method. We\nevaluate our IKRL models on knowledge graph completion and triple\nclassification. Experimental results demonstrate that our models outperform all\nbaselines on both tasks, which indicates the significance of visual information\nfor knowledge representations and the capability of our models in learning\nknowledge representations with images.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 15:37:45 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 08:14:27 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Xie", "Ruobing", ""], ["Liu", "Zhiyuan", ""], ["Luan", "Huanbo", ""], ["Sun", "Maosong", ""]]}, {"id": "1609.07033", "submitter": "Siddhartha Banerjee Siddhartha Banerjee", "authors": "Siddhartha Banerjee, Prasenjit Mitra and Kazunari Sugiyama", "title": "Generating Abstractive Summaries from Meeting Transcripts", "comments": "10 pages, Proceedings of the 2015 ACM Symposium on Document\n  Engineering, DocEng' 2015", "journal-ref": null, "doi": "10.1145/2682571.2797061", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summaries of meetings are very important as they convey the essential content\nof discussions in a concise form. Generally, it is time consuming to read and\nunderstand the whole documents. Therefore, summaries play an important role as\nthe readers are interested in only the important context of discussions. In\nthis work, we address the task of meeting document summarization. Automatic\nsummarization systems on meeting conversations developed so far have been\nprimarily extractive, resulting in unacceptable summaries that are hard to\nread. The extracted utterances contain disfluencies that affect the quality of\nthe extractive summaries. To make summaries much more readable, we propose an\napproach to generating abstractive summaries by fusing important content from\nseveral utterances. We first separate meeting transcripts into various topic\nsegments, and then identify the important utterances in each segment using a\nsupervised learning approach. The important utterances are then combined\ntogether to generate a one-sentence summary. In the text generation step, the\ndependency parses of the utterances in each segment are combined together to\ncreate a directed graph. The most informative and well-formed sub-graph\nobtained by integer linear programming (ILP) is selected to generate a\none-sentence summary for each topic segment. The ILP formulation reduces\ndisfluencies by leveraging grammatical relations that are more prominent in\nnon-conversational style of text, and therefore generates summaries that is\ncomparable to human-written abstractive summaries. Experimental results show\nthat our method can generate more informative summaries than the baselines. In\naddition, readability assessments by human judges as well as log-likelihood\nestimates obtained from the dependency parser show that our generated summaries\nare significantly readable and well-formed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 15:50:50 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Banerjee", "Siddhartha", ""], ["Mitra", "Prasenjit", ""], ["Sugiyama", "Kazunari", ""]]}, {"id": "1609.07034", "submitter": "Siddhartha Banerjee Siddhartha Banerjee", "authors": "Siddhartha Banerjee, Prasenjit Mitra and Kazunari Sugiyama", "title": "Multi-document abstractive summarization using ILP based multi-sentence\n  compression", "comments": "IJCAI'15 Proceedings of the 24th International Conference on\n  Artificial Intelligence, Pages 1208-1214, AAAI Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization is an ideal form of summarization since it can\nsynthesize information from multiple documents to create concise informative\nsummaries. In this work, we aim at developing an abstractive summarizer. First,\nour proposed approach identifies the most important document in the\nmulti-document set. The sentences in the most important document are aligned to\nsentences in other documents to generate clusters of similar sentences. Second,\nwe generate K-shortest paths from the sentences in each cluster using a\nword-graph structure. Finally, we select sentences from the set of shortest\npaths generated from all the clusters employing a novel integer linear\nprogramming (ILP) model with the objective of maximizing information content\nand readability of the final summary. Our ILP model represents the shortest\npaths as binary variables and considers the length of the path, information\nscore and linguistic quality score in the objective function. Experimental\nresults on the DUC 2004 and 2005 multi-document summarization datasets show\nthat our proposed approach outperforms all the baselines and state-of-the-art\nextractive summarizers as measured by the ROUGE scores. Our method also\noutperforms a recent abstractive summarization technique. In manual evaluation,\nour approach also achieves promising results on informativeness and\nreadability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 15:51:43 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Banerjee", "Siddhartha", ""], ["Mitra", "Prasenjit", ""], ["Sugiyama", "Kazunari", ""]]}, {"id": "1609.07035", "submitter": "Siddhartha Banerjee Siddhartha Banerjee", "authors": "Siddhartha Banerjee, Prasenjit Mitra and Kazunari Sugiyama", "title": "Abstractive Meeting Summarization UsingDependency Graph Fusion", "comments": "WWW '15 Companion Proceedings of the 24th International Conference on\n  World Wide Web, Pages 5-6. arXiv admin note: substantial text overlap with\n  arXiv:1609.07033", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarization techniques on meeting conversations developed so far\nhave been primarily extractive, resulting in poor summaries. To improve this,\nwe propose an approach to generate abstractive summaries by fusing important\ncontent from several utterances. Any meeting is generally comprised of several\ndiscussion topic segments. For each topic segment within a meeting\nconversation, we aim to generate a one sentence summary from the most important\nutterances using an integer linear programming-based sentence fusion approach.\nExperimental results show that our method can generate more informative\nsummaries than the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 15:53:04 GMT"}], "update_date": "2016-09-25", "authors_parsed": [["Banerjee", "Siddhartha", ""], ["Mitra", "Prasenjit", ""], ["Sugiyama", "Kazunari", ""]]}, {"id": "1609.07053", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva and Barbara Plank and Johan Bos", "title": "Semantic Tagging with Deep Residual Networks", "comments": "COLING 2016, camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel semantic tagging task, sem-tagging, tailored for the\npurpose of multilingual semantic parsing, and present the first tagger using\ndeep residual networks (ResNets). Our tagger uses both word and character\nrepresentations and includes a novel residual bypass architecture. We evaluate\nthe tagset both intrinsically on the new task of semantic tagging, as well as\non Part-of-Speech (POS) tagging. Our system, consisting of a ResNet and an\nauxiliary loss function predicting our semantic tags, significantly outperforms\nprior results on English Universal Dependencies POS tagging (95.71% accuracy on\nUD v1.2 and 95.67% accuracy on UD v1.3).\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 16:34:00 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 18:33:13 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Bjerva", "Johannes", ""], ["Plank", "Barbara", ""], ["Bos", "Johan", ""]]}, {"id": "1609.07075", "submitter": "Jiawei Wu", "authors": "Jiawei Wu, Ruobing Xie, Zhiyuan Liu, Maosong Sun", "title": "Knowledge Representation via Joint Learning of Sequential Text and\n  Knowledge Graphs", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual information is considered as significant supplement to knowledge\nrepresentation learning (KRL). There are two main challenges for constructing\nknowledge representations from plain texts: (1) How to take full advantages of\nsequential contexts of entities in plain texts for KRL. (2) How to dynamically\nselect those informative sentences of the corresponding entities for KRL. In\nthis paper, we propose the Sequential Text-embodied Knowledge Representation\nLearning to build knowledge representations from multiple sentences. Given each\nreference sentence of an entity, we first utilize recurrent neural network with\npooling or long short-term memory network to encode the semantic information of\nthe sentence with respect to the entity. Then we further design an attention\nmodel to measure the informativeness of each sentence, and build text-based\nrepresentations of entities. We evaluate our method on two tasks, including\ntriple classification and link prediction. Experimental results demonstrate\nthat our method outperforms other baselines on both tasks, which indicates that\nour method is capable of selecting informative sentences and encoding the\ntextual information well into knowledge representations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 17:16:43 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Wu", "Jiawei", ""], ["Xie", "Ruobing", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1609.07197", "submitter": "Shyam Upadhyay", "authors": "Shyam Upadhyay and Ming-Wei Chang", "title": "Annotating Derivations: A New Evaluation Strategy and Dataset for\n  Algebra Word Problems", "comments": "EACL 2017 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new evaluation for automatic solvers for algebra word problems,\nwhich can identify mistakes that existing evaluations overlook. Our proposal is\nto evaluate such solvers using derivations, which reflect how an equation\nsystem was constructed from the word problem. To accomplish this, we develop an\nalgorithm for checking the equivalence between two derivations, and show how\nderivation an- notations can be semi-automatically added to existing datasets.\nTo make our experiments more comprehensive, we include the derivation\nannotation for DRAW-1K, a new dataset containing 1000 general algebra word\nproblems. In our experiments, we found that the annotated derivations enable a\nmore accurate evaluation of automatic solvers than previously used metrics. We\nrelease derivation annotations for over 2300 algebra word problems for future\nevaluations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 00:38:59 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 20:05:38 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Upadhyay", "Shyam", ""], ["Chang", "Ming-Wei", ""]]}, {"id": "1609.07222", "submitter": "Pengfei Liu", "authors": "Pengfei Liu and Xipeng Qiu and Xuanjing Huang", "title": "Deep Multi-Task Learning with Shared Memory", "comments": "accepted by emnlp2016. arXiv admin note: text overlap with\n  arXiv:1605.05101", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based models have achieved impressive results on various\nspecific tasks. However, in previous works, most models are learned separately\nbased on single-task supervised objectives, which often suffer from\ninsufficient training data. In this paper, we propose two deep architectures\nwhich can be trained jointly on multiple related tasks. More specifically, we\naugment neural model with an external memory, which is shared by several tasks.\nExperiments on two groups of text classification tasks show that our proposed\narchitectures can improve the performance of a task with the help of other\nrelated tasks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 03:35:27 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Liu", "Pengfei", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1609.07245", "submitter": "Xiaodong Zhuang", "authors": "Xiaodong Zhuang", "title": "A New Statistic Feature of the Short-Time Amplitude Spectrum Values for\n  Human's Unvoiced Pronunciation", "comments": "5 pages, 4 figures, original work", "journal-ref": "WSEAS Transactions on Signal Processing, Volume 12, pp. 265-269,\n  2016", "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new statistic feature of the discrete short-time amplitude\nspectrum is discovered by experiments for the signals of unvoiced\npronunciation. For the random-varying short-time spectrum, this feature reveals\nthe relationship between the amplitude's average and its standard for every\nfrequency component. On the other hand, the association between the amplitude\ndistributions for different frequency components is also studied. A new model\nrepresenting such association is inspired by the normalized histogram of\namplitude. By mathematical analysis, the new statistic feature discovered is\nproved to be necessary evidence which supports the proposed model, and also can\nbe direct evidence for the widely used hypothesis of \"identical distribution of\namplitude for all frequencies\".\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 07:03:32 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 08:57:51 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Zhuang", "Xiaodong", ""]]}, {"id": "1609.07317", "submitter": "Yishu Miao", "authors": "Yishu Miao and Phil Blunsom", "title": "Language as a Latent Variable: Discrete Generative Models for Sentence\n  Compression", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore deep generative models of text in which the latent\nrepresentation of a document is itself drawn from a discrete language model\ndistribution. We formulate a variational auto-encoder for inference in this\nmodel and apply it to the task of compressing sentences. In this application\nthe generative model first draws a latent summary sentence from a background\nlanguage model, and then subsequently draws the observed sentence conditioned\non this latent summary. In our empirical evaluation we show that generative\nformulations of both abstractive and extractive compression yield\nstate-of-the-art results when trained on a large amount of supervised data.\nFurther, we explore semi-supervised compression scenarios where we show that it\nis possible to achieve performance competitive with previously proposed\nsupervised models while training on a fraction of the supervised data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 11:25:41 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 00:21:00 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Miao", "Yishu", ""], ["Blunsom", "Phil", ""]]}, {"id": "1609.07451", "submitter": "Linfeng Song", "authors": "Linfeng Song, Yue Zhang, Xiaochang Peng, Zhiguo Wang and Daniel Gildea", "title": "AMR-to-text generation as a Traveling Salesman Problem", "comments": "accepted by EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of AMR-to-text generation is to generate grammatical text that\nsustains the semantic meaning for a given AMR graph. We at- tack the task by\nfirst partitioning the AMR graph into smaller fragments, and then generating\nthe translation for each fragment, before finally deciding the order by solving\nan asymmetric generalized traveling salesman problem (AGTSP). A Maximum Entropy\nclassifier is trained to estimate the traveling costs, and a TSP solver is used\nto find the optimized solution. The final model reports a BLEU score of 22.44\non the SemEval-2016 Task8 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 18:12:12 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Song", "Linfeng", ""], ["Zhang", "Yue", ""], ["Peng", "Xiaochang", ""], ["Wang", "Zhiguo", ""], ["Gildea", "Daniel", ""]]}, {"id": "1609.07479", "submitter": "Wenyuan Zeng", "authors": "Wenyuan Zeng, Yankai Lin, Zhiyuan Liu, Maosong Sun", "title": "Incorporating Relation Paths in Neural Relation Extraction", "comments": "Proceedings of EMNLP 2017. Code and dataset available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distantly supervised relation extraction has been widely used to find novel\nrelational facts from plain text. To predict the relation between a pair of two\ntarget entities, existing methods solely rely on those direct sentences\ncontaining both entities. In fact, there are also many sentences containing\nonly one of the target entities, which provide rich and useful information for\nrelation extraction. To address this issue, we build inference chains between\ntwo target entities via intermediate entities, and propose a path-based neural\nrelation extraction model to encode the relational semantics from both direct\nsentences and inference chains. Experimental results on real-world datasets\nshow that, our model can make full use of those sentences containing only one\ntarget entity, and achieves significant and consistent improvements on relation\nextraction as compared with baselines. The source code of this paper can be\nobtained from https: //github.com/thunlp/PathNRE.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 19:59:51 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 08:56:42 GMT"}, {"version": "v3", "created": "Wed, 13 Sep 2017 19:30:06 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Zeng", "Wenyuan", ""], ["Lin", "Yankai", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1609.07498", "submitter": "Maryam Najafian Dr", "authors": "Saeid Safavi, Maryam Najafian, Abualsoud Hanani, Martin J Russell,\n  Peter Jancovic, Michael J Carey", "title": "Speaker Recognition for Children's Speech", "comments": "INTERSPEECH 2012, Pages 1836-1839", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents results on Speaker Recognition (SR) for children's\nspeech, using the OGI Kids corpus and GMM-UBM and GMM-SVM SR systems. Regions\nof the spectrum containing important speaker information for children are\nidentified by conducting SR experiments over 21 frequency bands. As for adults,\nthe spectrum can be split into four regions, with the first (containing primary\nvocal tract resonance information) and third (corresponding to high frequency\nspeech sounds) being most useful for SR. However, the frequencies at which\nthese regions occur are from 11% to 38% higher for children. It is also noted\nthat subband SR rates are lower for younger children. Finally results are\npresented of SR experiments to identify a child in a class (30 children,\nsimilar age) and school (288 children, varying ages). Class performance depends\non age, with accuracy varying from 90% for young children to 99% for older\nchildren. The identification rate achieved for a child in a school is 81%.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 20:03:14 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Safavi", "Saeid", ""], ["Najafian", "Maryam", ""], ["Hanani", "Abualsoud", ""], ["Russell", "Martin J", ""], ["Jancovic", "Peter", ""], ["Carey", "Michael J", ""]]}, {"id": "1609.07561", "submitter": "Adhiguna Kuncoro", "authors": "Adhiguna Kuncoro, Miguel Ballesteros, Lingpeng Kong, Chris Dyer, Noah\n  A. Smith", "title": "Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser", "comments": "10 pages. To appear at EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two first-order graph-based dependency parsers achieving a new\nstate of the art. The first is a consensus parser built from an ensemble of\nindependently trained greedy LSTM transition-based parsers with different\nrandom initializations. We cast this approach as minimum Bayes risk decoding\n(under the Hamming cost) and argue that weaker consensus within the ensemble is\na useful signal of difficulty or ambiguity. The second parser is a\n\"distillation\" of the ensemble into a single model. We train the distillation\nparser using a structured hinge loss objective with a novel cost that\nincorporates ensemble uncertainty estimates for each possible attachment,\nthereby avoiding the intractable cross-entropy computations required by\napplying standard distillation objectives to problems with structured outputs.\nThe first-order distillation parser matches or surpasses the state of the art\non English, Chinese, and German.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 02:58:26 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Kuncoro", "Adhiguna", ""], ["Ballesteros", "Miguel", ""], ["Kong", "Lingpeng", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""]]}, {"id": "1609.07568", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, James Glass", "title": "A Character-level Convolutional Neural Network for Distinguishing\n  Similar Languages and Dialects", "comments": "DSL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating between closely-related language varieties is considered a\nchallenging and important task. This paper describes our submission to the DSL\n2016 shared-task, which included two sub-tasks: one on discriminating similar\nlanguages and one on identifying Arabic dialects. We developed a\ncharacter-level neural network for this task. Given a sequence of characters,\nour model embeds each character in vector space, runs the sequence through\nmultiple convolutions with different filter widths, and pools the convolutional\nrepresentations to obtain a hidden vector representation of the text that is\nused for predicting the language or dialect. We primarily focused on the Arabic\ndialect identification task and obtained an F1 score of 0.4834, ranking 6th out\nof 18 participants. We also analyze errors made by our system on the Arabic\ndata in some detail, and point to challenges such an approach is faced with.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 04:02:13 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Glass", "James", ""]]}, {"id": "1609.07585", "submitter": "Raghav Chalapathy", "authors": "Raghavendra Chalapathy, Ehsan Zare Borzeshi, Massimo Piccardi", "title": "An Investigation of Recurrent Neural Architectures for Drug Name\n  Recognition", "comments": "Accepted for Oral Presentation at LOUHI 2016 : EMNLP 2016 Workshop -\n  The Seventh International Workshop on Health Text Mining and Information\n  Analysis (LOUHI 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug name recognition (DNR) is an essential step in the Pharmacovigilance\n(PV) pipeline. DNR aims to find drug name mentions in unstructured biomedical\ntexts and classify them into predefined categories. State-of-the-art DNR\napproaches heavily rely on hand crafted features and domain specific resources\nwhich are difficult to collect and tune. For this reason, this paper\ninvestigates the effectiveness of contemporary recurrent neural architectures -\nthe Elman and Jordan networks and the bidirectional LSTM with CRF decoding - at\nperforming DNR straight from the text. The experimental results achieved on the\nauthoritative SemEval-2013 Task 9.1 benchmarks show that the bidirectional\nLSTM-CRF ranks closely to highly-dedicated, hand-crafted systems.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 08:45:17 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Chalapathy", "Raghavendra", ""], ["Borzeshi", "Ehsan Zare", ""], ["Piccardi", "Massimo", ""]]}, {"id": "1609.07680", "submitter": "Haitao Liu", "authors": "Shuiyuan Yu, Junying Liang, Haitao Liu", "title": "Existence of Hierarchies and Human's Pursuit of Top Hierarchy Lead to\n  Power Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power law is ubiquitous in natural and social phenomena, and is\nconsidered as a universal relationship between the frequency and its rank for\ndiverse social systems. However, a general model is still lacking to interpret\nwhy these seemingly unrelated systems share great similarity. Through a\ndetailed analysis of natural language texts and simulation experiments based on\nthe proposed 'Hierarchical Selection Model', we found that the existence of\nhierarchies and human's pursuit of top hierarchy lead to the power law.\nFurther, the power law is a statistical and emergent performance of\nhierarchies, and it is the universality of hierarchies that contributes to the\nubiquity of the power law.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 23:22:50 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Yu", "Shuiyuan", ""], ["Liang", "Junying", ""], ["Liu", "Haitao", ""]]}, {"id": "1609.07681", "submitter": "Haitao Liu", "authors": "Shuiyuan Yu, Jin Cong, Junying Liang, Haitao Liu", "title": "The distribution of information content in English sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence is a basic linguistic unit, however, little is known about how\ninformation content is distributed across different positions of a sentence.\nBased on authentic language data of English, the present study calculated the\nentropy and other entropy-related statistics for different sentence positions.\nThe statistics indicate a three-step staircase-shaped distribution pattern,\nwith entropy in the initial position lower than the medial positions (positions\nother than the initial and final), the medial positions lower than the final\nposition and the medial positions showing no significant difference. The\nresults suggest that: (1) the hypotheses of Constant Entropy Rate and Uniform\nInformation Density do not hold for the sentence-medial positions; (2) the\ncontext of a word in a sentence should not be simply defined as all the words\npreceding it in the same sentence; and (3) the contextual information content\nin a sentence does not accumulate incrementally but follows a pattern of \"the\nwhole is greater than the sum of parts\".\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 23:36:31 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Yu", "Shuiyuan", ""], ["Cong", "Jin", ""], ["Liang", "Junying", ""], ["Liu", "Haitao", ""]]}, {"id": "1609.07701", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, James Glass", "title": "Large-Scale Machine Translation between Arabic and Hebrew: Available\n  Corpora and Initial Results", "comments": "SeMaT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation between Arabic and Hebrew has so far been limited by a\nlack of parallel corpora, despite the political and cultural importance of this\nlanguage pair. Previous work relied on manually-crafted grammars or pivoting\nvia English, both of which are unsatisfactory for building a scalable and\naccurate MT system. In this work, we compare standard phrase-based and neural\nsystems on Arabic-Hebrew translation. We experiment with tokenization by\nexternal tools and sub-word modeling by character-level neural models, and show\nthat both methods lead to improved translation performance, with a small\nadvantage to the neural models.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 05:07:55 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Glass", "James", ""]]}, {"id": "1609.07730", "submitter": "Jinsong Su", "authors": "Jinsong Su, Zhixing Tan, Deyi Xiong, Rongrong Ji, Xiaodong Shi, Yang\n  Liu", "title": "Lattice-Based Recurrent Neural Network Encoders for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) heavily relies on word-level modelling to\nlearn semantic representations of input sentences. However, for languages\nwithout natural word delimiters (e.g., Chinese) where input sentences have to\nbe tokenized first, conventional NMT is confronted with two issues: 1) it is\ndifficult to find an optimal tokenization granularity for source sentence\nmodelling, and 2) errors in 1-best tokenizations may propagate to the encoder\nof NMT. To handle these issues, we propose word-lattice based Recurrent Neural\nNetwork (RNN) encoders for NMT, which generalize the standard RNN to word\nlattice topology. The proposed encoders take as input a word lattice that\ncompactly encodes multiple tokenizations, and learn to generate new hidden\nstates from arbitrarily many inputs and hidden states in preceding time steps.\nAs such, the word-lattice based encoders not only alleviate the negative impact\nof tokenization errors but also are more expressive and flexible to embed input\nsentences. Experiment results on Chinese-English translation demonstrate the\nsuperiorities of the proposed encoders over the conventional encoder.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 10:59:01 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 13:03:42 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Su", "Jinsong", ""], ["Tan", "Zhixing", ""], ["Xiong", "Deyi", ""], ["Ji", "Rongrong", ""], ["Shi", "Xiaodong", ""], ["Liu", "Yang", ""]]}, {"id": "1609.07756", "submitter": "Lilach Edelstein", "authors": "Lilach Edelstein and Roi Reichart", "title": "A Factorized Model for Transitive Verbs in Compositional Distributional\n  Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a factorized compositional distributional semantics model for the\nrepresentation of transitive verb constructions. Our model first produces\n(subject, verb) and (verb, object) vector representations based on the\nsimilarity of the nouns in the construction to each of the nouns in the\nvocabulary and the tendency of these nouns to take the subject and object roles\nof the verb. These vectors are then combined into a final (subject,verb,object)\nrepresentation through simple vector operations. On two established tasks for\nthe transitive verb construction our model outperforms recent previous work.\n", "versions": [{"version": "v1", "created": "Sun, 25 Sep 2016 15:10:16 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Edelstein", "Lilach", ""], ["Reichart", "Roi", ""]]}, {"id": "1609.07843", "submitter": "Richard Socher", "authors": "Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher", "title": "Pointer Sentinel Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural network sequence models with softmax classifiers have achieved\ntheir best language modeling performance only with very large hidden states and\nlarge vocabularies. Even then they struggle to predict rare or unseen words\neven if the context makes the prediction unambiguous. We introduce the pointer\nsentinel mixture architecture for neural sequence models which has the ability\nto either reproduce a word from the recent context or produce a word from a\nstandard softmax classifier. Our pointer sentinel-LSTM model achieves state of\nthe art language modeling performance on the Penn Treebank (70.9 perplexity)\nwhile using far fewer parameters than a standard softmax LSTM. In order to\nevaluate how well language models can exploit longer contexts and deal with\nmore realistic vocabularies and larger corpora we also introduce the freely\navailable WikiText corpus.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 04:06:13 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Merity", "Stephen", ""], ["Xiong", "Caiming", ""], ["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1609.07876", "submitter": "Taehwan Kim", "authors": "Taehwan Kim, Jonathan Keane, Weiran Wang, Hao Tang, Jason Riggle,\n  Gregory Shakhnarovich, Diane Brentari, Karen Livescu", "title": "Lexicon-Free Fingerspelling Recognition from Video: Data, Models, and\n  Signer Adaptation", "comments": "arXiv admin note: substantial text overlap with arXiv:1608.08339", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recognizing video sequences of fingerspelled letters\nin American Sign Language (ASL). Fingerspelling comprises a significant but\nrelatively understudied part of ASL. Recognizing fingerspelling is challenging\nfor a number of reasons: It involves quick, small motions that are often highly\ncoarticulated; it exhibits significant variation between signers; and there has\nbeen a dearth of continuous fingerspelling data collected. In this work we\ncollect and annotate a new data set of continuous fingerspelling videos,\ncompare several types of recognizers, and explore the problem of signer\nvariation. Our best-performing models are segmental (semi-Markov) conditional\nrandom fields using deep neural network-based features. In the signer-dependent\nsetting, our recognizers achieve up to about 92% letter accuracy. The\nmulti-signer setting is much more challenging, but with neural network\nadaptation we achieve up to 83% letter accuracies in this setting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 07:34:24 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Kim", "Taehwan", ""], ["Keane", "Jonathan", ""], ["Wang", "Weiran", ""], ["Tang", "Hao", ""], ["Riggle", "Jason", ""], ["Shakhnarovich", "Gregory", ""], ["Brentari", "Diane", ""], ["Livescu", "Karen", ""]]}, {"id": "1609.08075", "submitter": "Yi Yang", "authors": "Yi Yang and Ming-Wei Chang", "title": "S-MART: Novel Tree-based Structured Learning Algorithms Applied to Tweet\n  Entity Linking", "comments": "Appeared in ACL 2015 proceedings. This is an updated version. More\n  details available in the pdf file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear models recently receive a lot of attention as people are starting\nto discover the power of statistical and embedding features. However,\ntree-based models are seldom studied in the context of structured learning\ndespite their recent success on various classification and ranking tasks. In\nthis paper, we propose S-MART, a tree-based structured learning framework based\non multiple additive regression trees. S-MART is especially suitable for\nhandling tasks with dense features, and can be used to learn many different\nstructures under various loss functions.\n  We apply S-MART to the task of tweet entity linking --- a core component of\ntweet information extraction, which aims to identify and link name mentions to\nentities in a knowledge base. A novel inference algorithm is proposed to handle\nthe special structure of the task. The experimental results show that S-MART\nsignificantly outperforms state-of-the-art tweet entity linking systems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:01:03 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Yang", "Yi", ""], ["Chang", "Ming-Wei", ""]]}, {"id": "1609.08084", "submitter": "Yi Yang", "authors": "Yi Yang, Ming-Wei Chang, Jacob Eisenstein", "title": "Toward Socially-Infused Information Extraction: Embedding Authors,\n  Mentions, and Entities", "comments": "Accepted to EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of identifying mentions of entities in text, and\nlinking them to entries in a knowledge base. This task is especially difficult\nin microblogs, as there is little additional text to provide disambiguating\ncontext; rather, authors rely on an implicit common ground of shared knowledge\nwith their readers. In this paper, we attempt to capture some of this implicit\ncontext by exploiting the social network structure in microblogs. We build on\nthe theory of homophily, which implies that socially linked individuals share\ninterests, and are therefore likely to mention the same sorts of entities. We\nimplement this idea by encoding authors, mentions, and entities in a continuous\nvector space, which is constructed so that socially-connected authors have\nsimilar vector representations. These vectors are incorporated into a neural\nstructured prediction model, which captures structural constraints that are\ninherent in the entity linking task. Together, these design decisions yield F1\nimprovements of 1%-5% on benchmark datasets, as compared to the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:19:07 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Yang", "Yi", ""], ["Chang", "Ming-Wei", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1609.08097", "submitter": "Rebecca Sharp", "authors": "Rebecca Sharp, Mihai Surdeanu, Peter Jansen, Peter Clark, and Michael\n  Hammond", "title": "Creating Causal Embeddings for Question Answering with Minimal\n  Supervision", "comments": "To appear in EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common model for question answering (QA) is that a good answer is one that\nis closely related to the question, where relatedness is often determined using\ngeneral-purpose lexical models such as word embeddings. We argue that a better\napproach is to look for answers that are related to the question in a relevant\nway, according to the information need of the question, which may be determined\nthrough task-specific embeddings. With causality as a use case, we implement\nthis insight in three steps. First, we generate causal embeddings\ncost-effectively by bootstrapping cause-effect pairs extracted from free text\nusing a small set of seed patterns. Second, we train dedicated embeddings over\nthis data, by using task-specific contexts, i.e., the context of a cause is its\neffect. Finally, we extend a state-of-the-art reranking approach for QA to\nincorporate these causal embeddings. We evaluate the causal embedding models\nboth directly with a casual implication task, and indirectly, in a downstream\ncausal QA task using data from Yahoo! Answers. We show that explicitly modeling\ncausality improves performance in both tasks. In the QA task our best model\nachieves 37.3% P@1, significantly outperforming a strong baseline by 7.7%\n(relative).\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:50:15 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Sharp", "Rebecca", ""], ["Surdeanu", "Mihai", ""], ["Jansen", "Peter", ""], ["Clark", "Peter", ""], ["Hammond", "Michael", ""]]}, {"id": "1609.08139", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos, David Chiang, Long Duong", "title": "An Unsupervised Probability Model for Speech-to-Translation Alignment of\n  Low-Resource Languages", "comments": "accepted at EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many low-resource languages, spoken language resources are more likely to\nbe annotated with translations than with transcriptions. Translated speech data\nis potentially valuable for documenting endangered languages or for training\nspeech translation systems. A first step towards making use of such data would\nbe to automatically align spoken words with their translations. We present a\nmodel that combines Dyer et al.'s reparameterization of IBM Model 2\n(fast-align) and k-means clustering using Dynamic Time Warping as a distance\nmetric. The two components are trained jointly using expectation-maximization.\nIn an extremely low-resource scenario, our model performs significantly better\nthan both a neural model and a strong baseline.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 19:50:59 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Chiang", "David", ""], ["Duong", "Long", ""]]}, {"id": "1609.08144", "submitter": "Mike Schuster", "authors": "Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,\n  Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff\n  Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, {\\L}ukasz Kaiser,\n  Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens,\n  George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason\n  Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, Jeffrey\n  Dean", "title": "Google's Neural Machine Translation System: Bridging the Gap between\n  Human and Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) is an end-to-end learning approach for\nautomated translation, with the potential to overcome many of the weaknesses of\nconventional phrase-based translation systems. Unfortunately, NMT systems are\nknown to be computationally expensive both in training and in translation\ninference. Also, most NMT systems have difficulty with rare words. These issues\nhave hindered NMT's use in practical deployments and services, where both\naccuracy and speed are essential. In this work, we present GNMT, Google's\nNeural Machine Translation system, which attempts to address many of these\nissues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder\nlayers using attention and residual connections. To improve parallelism and\ntherefore decrease training time, our attention mechanism connects the bottom\nlayer of the decoder to the top layer of the encoder. To accelerate the final\ntranslation speed, we employ low-precision arithmetic during inference\ncomputations. To improve handling of rare words, we divide words into a limited\nset of common sub-word units (\"wordpieces\") for both input and output. This\nmethod provides a good balance between the flexibility of \"character\"-delimited\nmodels and the efficiency of \"word\"-delimited models, naturally handles\ntranslation of rare words, and ultimately improves the overall accuracy of the\nsystem. Our beam search technique employs a length-normalization procedure and\nuses a coverage penalty, which encourages generation of an output sentence that\nis most likely to cover all the words in the source sentence. On the WMT'14\nEnglish-to-French and English-to-German benchmarks, GNMT achieves competitive\nresults to state-of-the-art. Using a human side-by-side evaluation on a set of\nisolated simple sentences, it reduces translation errors by an average of 60%\ncompared to Google's phrase-based production system.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 19:59:55 GMT"}, {"version": "v2", "created": "Sat, 8 Oct 2016 19:10:41 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Wu", "Yonghui", ""], ["Schuster", "Mike", ""], ["Chen", "Zhifeng", ""], ["Le", "Quoc V.", ""], ["Norouzi", "Mohammad", ""], ["Macherey", "Wolfgang", ""], ["Krikun", "Maxim", ""], ["Cao", "Yuan", ""], ["Gao", "Qin", ""], ["Macherey", "Klaus", ""], ["Klingner", "Jeff", ""], ["Shah", "Apurva", ""], ["Johnson", "Melvin", ""], ["Liu", "Xiaobing", ""], ["Kaiser", "\u0141ukasz", ""], ["Gouws", "Stephan", ""], ["Kato", "Yoshikiyo", ""], ["Kudo", "Taku", ""], ["Kazawa", "Hideto", ""], ["Stevens", "Keith", ""], ["Kurian", "George", ""], ["Patil", "Nishant", ""], ["Wang", "Wei", ""], ["Young", "Cliff", ""], ["Smith", "Jason", ""], ["Riesa", "Jason", ""], ["Rudnick", "Alex", ""], ["Vinyals", "Oriol", ""], ["Corrado", "Greg", ""], ["Hughes", "Macduff", ""], ["Dean", "Jeffrey", ""]]}, {"id": "1609.08194", "submitter": "Lei Yu", "authors": "Lei Yu, Jan Buys and Phil Blunsom", "title": "Online Segment to Segment Neural Transduction", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online neural sequence to sequence model that learns to\nalternate between encoding and decoding segments of the input as it is read. By\nindependently tracking the encoding and decoding representations our algorithm\npermits exact polynomial marginalization of the latent segmentation during\ntraining, and during decoding beam search is employed to find the best\nalignment path together with the predicted output sequence. Our model tackles\nthe bottleneck of vanilla encoder-decoders that have to read and memorize the\nentire input sequence in their fixed-length hidden states before producing any\noutput. It is different from previous attentive models in that, instead of\ntreating the attention weights as output of a deterministic function, our model\nassigns attention weights to a sequential latent variable which can be\nmarginalized out and permits online generation. Experiments on abstractive\nsentence summarization and morphological inflection show significant\nperformance gains over the baseline encoder-decoders.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 21:13:49 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Yu", "Lei", ""], ["Buys", "Jan", ""], ["Blunsom", "Phil", ""]]}, {"id": "1609.08210", "submitter": "Ferhan Ture", "authors": "Ferhan Ture and Elizabeth Boschee", "title": "Learning to Translate for Multilingual Question Answering", "comments": "12 pages. To appear in EMNLP'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multilingual question answering, either the question needs to be\ntranslated into the document language, or vice versa. In addition to direction,\nthere are multiple methods to perform the translation, four of which we explore\nin this paper: word-based, 10-best, context-based, and grammar-based. We build\na feature for each combination of translation direction and method, and train a\nmodel that learns optimal feature weights. On a large forum dataset consisting\nof posts in English, Arabic, and Chinese, our novel learn-to-translate approach\nwas more effective than a strong baseline (p<0.05): translating all text into\nEnglish, then training a classifier based only on English (original or\ntranslated) text.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 22:12:50 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Ture", "Ferhan", ""], ["Boschee", "Elizabeth", ""]]}, {"id": "1609.08237", "submitter": "Tao Ge", "authors": "Tao Ge, Qing Dou, Xiaoman Pan, Heng Ji, Lei Cui, Baobao Chang, Zhifang\n  Sui, Ming Zhou", "title": "Aligning Coordinated Text Streams through Burst Information Network\n  Construction and Decipherment", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aligning coordinated text streams from multiple sources and multiple\nlanguages has opened many new research venues on cross-lingual knowledge\ndiscovery. In this paper we aim to advance state-of-the-art by: (1). extending\ncoarse-grained topic-level knowledge mining to fine-grained information units\nsuch as entities and events; (2). following a novel\nData-to-Network-to-Knowledge (D2N2K) paradigm to construct and utilize network\nstructures to capture and propagate reliable evidence. We introduce a novel\nBurst Information Network (BINet) representation that can display the most\nimportant information and illustrate the connections among bursty entities,\nevents and keywords in the corpus. We propose an effective approach to\nconstruct and decipher BINets, incorporating novel criteria based on\nmulti-dimensional clues from pronunciation, translation, burst, neighbor and\ngraph topological structure. The experimental results on Chinese and English\ncoordinated text streams show that our approach can accurately decipher the\nnodes with high confidence in the BINets and that the algorithm can be\nefficiently run in parallel, which makes it possible to apply it to huge\namounts of streaming data for never-ending language and information\ndecipherment.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 01:19:41 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Ge", "Tao", ""], ["Dou", "Qing", ""], ["Pan", "Xiaoman", ""], ["Ji", "Heng", ""], ["Cui", "Lei", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""], ["Zhou", "Ming", ""]]}, {"id": "1609.08293", "submitter": "Magnus Sahlgren", "authors": "Magnus Sahlgren and Alessandro Lenci", "title": "The Effects of Data Size and Frequency Range on Distributional Semantic\n  Models", "comments": "Accepted at EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effects of data size and frequency range on\ndistributional semantic models. We compare the performance of a number of\nrepresentative models for several test settings over data of varying sizes, and\nover test items of various frequency. Our results show that neural\nnetwork-based models underperform when the data is small, and that the most\nreliable model over data of varying sizes and frequency ranges is the inverted\nfactorized model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 07:38:29 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Sahlgren", "Magnus", ""], ["Lenci", "Alessandro", ""]]}, {"id": "1609.08337", "submitter": "Zhiyuan Tang", "authors": "Zhiyuan Tang, Lantian Li and Dong Wang", "title": "Multi-task Recurrent Model for True Multilingual Speech Recognition", "comments": "APSIPA 2016. arXiv admin note: text overlap with arXiv:1603.09643", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on multilingual speech recognition remains attractive yet\nchallenging. Recent studies focus on learning shared structures under the\nmulti-task paradigm, in particular a feature sharing structure. This approach\nhas been found effective to improve performance on each individual language.\nHowever, this approach is only useful when the deployed system supports just\none language. In a true multilingual scenario where multiple languages are\nallowed, performance will be significantly reduced due to the competition among\nlanguages in the decoding space. This paper presents a multi-task recurrent\nmodel that involves a multilingual speech recognition (ASR) component and a\nlanguage recognition (LR) component, and the ASR component is informed of the\nlanguage information by the LR component, leading to a language-aware\nrecognition. We tested the approach on an English-Chinese bilingual recognition\ntask. The results show that the proposed multi-task recurrent model can improve\nperformance of multilingual recognition systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 09:56:09 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Tang", "Zhiyuan", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""]]}, {"id": "1609.08359", "submitter": "Isabelle Augenstein", "authors": "Ben Eisner, Tim Rockt\\\"aschel, Isabelle Augenstein, Matko Bo\\v{s}njak,\n  Sebastian Riedel", "title": "emoji2vec: Learning Emoji Representations from their Description", "comments": "7 pages, 4 figures, 1 table, In Proceedings of the 4th International\n  Workshop on Natural Language Processing for Social Media at EMNLP 2016\n  (SocialNLP at EMNLP 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current natural language processing applications for social media rely\non representation learning and utilize pre-trained word embeddings. There\ncurrently exist several publicly-available, pre-trained sets of word\nembeddings, but they contain few or no emoji representations even as emoji\nusage in social media has increased. In this paper we release emoji2vec,\npre-trained embeddings for all Unicode emoji which are learned from their\ndescription in the Unicode emoji standard. The resulting emoji embeddings can\nbe readily used in downstream social natural language processing applications\nalongside word2vec. We demonstrate, for the downstream task of sentiment\nanalysis, that emoji embeddings learned from short descriptions outperforms a\nskip-gram model trained on a large collection of tweets, while avoiding the\nneed for contexts in which emoji need to appear frequently in order to estimate\na representation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 11:32:25 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 22:43:46 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Eisner", "Ben", ""], ["Rockt\u00e4schel", "Tim", ""], ["Augenstein", "Isabelle", ""], ["Bo\u0161njak", "Matko", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1609.08389", "submitter": "Lena Dankin", "authors": "Orna Almogi (UHH), Lena Dankin (TAU-CS), Nachum Dershowitz (TAU-CS),\n  Lior Wolf (TAU-CS)", "title": "A Hackathon for Classical Tibetan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the course of a hackathon dedicated to the development of\nlinguistic tools for Tibetan Buddhist studies. Over a period of five days, a\ngroup of seventeen scholars, scientists, and students developed and compared\nalgorithms for intertextual alignment and text classification, along with some\nbasic language tools, including a stemmer and word segmenter.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 12:55:10 GMT"}, {"version": "v2", "created": "Mon, 31 Dec 2018 11:44:47 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Almogi", "Orna", "", "UHH"], ["Dankin", "Lena", "", "TAU-CS"], ["Dershowitz", "Nachum", "", "TAU-CS"], ["Wolf", "Lior", "", "TAU-CS"]]}, {"id": "1609.08409", "submitter": "Giovanni Montana", "authors": "Savelie Cornegruta, Robert Bakewell, Samuel Withey, Giovanni Montana", "title": "Modelling Radiological Language with Bidirectional Long Short-Term\n  Memory Networks", "comments": "LOUHI 2016 conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need to automate medical information extraction from\nfree-text radiological reports, we present a bi-directional long short-term\nmemory (BiLSTM) neural network architecture for modelling radiological\nlanguage. The model has been used to address two NLP tasks: medical\nnamed-entity recognition (NER) and negation detection. We investigate whether\nlearning several types of word embeddings improves BiLSTM's performance on\nthose tasks. Using a large dataset of chest x-ray reports, we compare the\nproposed model to a baseline dictionary-based NER system and a negation\ndetection system that leverages the hand-crafted rules of the NegEx algorithm\nand the grammatical relations obtained from the Stanford Dependency Parser.\nCompared to these more traditional rule-based systems, we argue that BiLSTM\noffers a strong alternative for both our tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:25:10 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Cornegruta", "Savelie", ""], ["Bakewell", "Robert", ""], ["Withey", "Samuel", ""], ["Montana", "Giovanni", ""]]}, {"id": "1609.08412", "submitter": "Zhiyuan Tang", "authors": "Dong Wang, Zhiyuan Tang, Difei Tang and Qing Chen", "title": "OC16-CE80: A Chinese-English Mixlingual Database and A Speech\n  Recognition Baseline", "comments": "O-COCOSDA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the OC16-CE80 Chinese-English mixlingual speech database which was\nreleased as a main resource for training, development and test for the\nChinese-English mixlingual speech recognition (MixASR-CHEN) challenge on\nO-COCOSDA 2016. This database consists of 80 hours of speech signals recorded\nfrom more than 1,400 speakers, where the utterances are in Chinese but each\ninvolves one or several English words. Based on the database and another two\nfree data resources (THCHS30 and the CMU dictionary), a speech recognition\n(ASR) baseline was constructed with the deep neural network-hidden Markov model\n(DNN-HMM) hybrid system. We then report the baseline results following the\nMixASR-CHEN evaluation rules and demonstrate that OC16-CE80 is a reasonable\ndata resource for mixlingual research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:25:51 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Wang", "Dong", ""], ["Tang", "Zhiyuan", ""], ["Tang", "Difei", ""], ["Chen", "Qing", ""]]}, {"id": "1609.08433", "submitter": "Lantian Li Mr.", "authors": "Chenghui Zhao, Lantian Li, Dong Wang, April Pu", "title": "Local Training for PLDA in Speaker Verification", "comments": "O-COCOSDA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLDA is a popular normalization approach for the i-vector model, and it has\ndelivered state-of-the-art performance in speaker verification. However, PLDA\ntraining requires a large amount of labeled development data, which is highly\nexpensive in most cases. A possible approach to mitigate the problem is various\nunsupervised adaptation methods, which use unlabeled data to adapt the PLDA\nscattering matrices to the target domain.\n  In this paper, we present a new `local training' approach that utilizes\ninaccurate but much cheaper local labels to train the PLDA model. These local\nlabels discriminate speakers within a single conversion only, and so are much\neasier to obtain compared to the normal `global labels'. Our experiments show\nthat the proposed approach can deliver significant performance improvement,\nparticularly with limited globally-labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:37:13 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Zhao", "Chenghui", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Pu", "April", ""]]}, {"id": "1609.08441", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Yixiang Chen, Dong Wang, Chenghui Zhao", "title": "Weakly Supervised PLDA Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLDA is a popular normalization approach for the i-vector model, and it has\ndelivered state-of-the-art performance in speaker verification. However, PLDA\ntraining requires a large amount of labelled development data, which is highly\nexpensive in most cases. We present a cheap PLDA training approach, which\nassumes that speakers in the same session can be easily separated, and speakers\nin different sessions are simply different. This results in `weak labels' which\nare not fully accurate but cheap, leading to a weak PLDA training.\n  Our experimental results on real-life large-scale telephony customer service\nachieves demonstrated that the weak training can offer good performance when\nhuman-labelled data are limited. More interestingly, the weak training can be\nemployed as a discriminative adaptation approach, which is more efficient than\nthe prevailing unsupervised method when human-labelled data are insufficient.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:46:55 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 10:19:15 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Li", "Lantian", ""], ["Chen", "Yixiang", ""], ["Wang", "Dong", ""], ["Zhao", "Chenghui", ""]]}, {"id": "1609.08442", "submitter": "Lantian Li Mr.", "authors": "Lantian Li, Zhiyuan Tang, Dong Wang, Andrew Abel, Yang Feng, Shiyue\n  Zhang", "title": "Collaborative Learning for Language and Speaker Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a unified model to perform language and speaker\nrecognition simultaneously and altogether. The model is based on a multi-task\nrecurrent neural network where the output of one task is fed as the input of\nthe other, leading to a collaborative learning framework that can improve both\nlanguage and speaker recognition by borrowing information from each other. Our\nexperiments demonstrated that the multi-task model outperforms the\ntask-specific models on both tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:48:01 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 09:56:54 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Li", "Lantian", ""], ["Tang", "Zhiyuan", ""], ["Wang", "Dong", ""], ["Abel", "Andrew", ""], ["Feng", "Yang", ""], ["Zhang", "Shiyue", ""]]}, {"id": "1609.08445", "submitter": "Lantian Li Mr.", "authors": "Dong Wang, Lantian Li, Difei Tang, Qing Chen", "title": "AP16-OL7: A Multilingual Database for Oriental Languages and A Language\n  Recognition Baseline", "comments": "APSIPA ASC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the AP16-OL7 database which was released as the training and test\ndata for the oriental language recognition (OLR) challenge on APSIPA 2016.\nBased on the database, a baseline system was constructed on the basis of the\ni-vector model. We report the baseline results evaluated in various metrics\ndefined by the AP16-OLR evaluation plan and demonstrate that AP16-OL7 is a\nreasonable data resource for multilingual research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 13:50:13 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Wang", "Dong", ""], ["Li", "Lantian", ""], ["Tang", "Difei", ""], ["Chen", "Qing", ""]]}, {"id": "1609.08492", "submitter": "Miguel Rodrigues", "authors": "Miguel J. Rodrigues, Miguel Fal\\'e, Andre Lamurias, and Francisco M.\n  Couto", "title": "WS4A: a Biomedical Question and Answering System based on public Web\n  Services and Ontologies", "comments": "7 pages, 1 figure, 1 table, accepted as poster at BioASQ '16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system, dubbed WS4A (Web Services for All), that\nparticipated in the fourth edition of the BioASQ challenge (2016). We used WS4A\nto perform the Question and Answering (QA) task 4b, which consisted on the\nretrieval of relevant concepts, documents, snippets, RDF triples, exact answers\nand ideal answers for each given question. The novelty in our approach consists\non the maximum exploitation of existing web services in each step of WS4A, such\nas the annotation of text, and the retrieval of metadata for each annotation.\nThe information retrieved included concept identifiers, ontologies, ancestors,\nand most importantly, PubMed identifiers. The paper describes the WS4A pipeline\nand also presents the precision, recall and f-measure values obtained in task\n4b. Our system achieved two second places in two subtasks on one of the five\nbatches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 15:14:04 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 12:12:15 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Rodrigues", "Miguel J.", ""], ["Fal\u00e9", "Miguel", ""], ["Lamurias", "Andre", ""], ["Couto", "Francisco M.", ""]]}, {"id": "1609.08496", "submitter": "Jipeng Qiang", "authors": "Jipeng Qiang, Ping Chen, Tong Wang, Xindong Wu", "title": "Topic Modeling over Short Texts by Incorporating Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring topics from the overwhelming amount of short texts becomes a\ncritical but challenging task for many content analysis tasks, such as content\ncharactering, user interest profiling, and emerging topic detecting. Existing\nmethods such as probabilistic latent semantic analysis (PLSA) and latent\nDirichlet allocation (LDA) cannot solve this prob- lem very well since only\nvery limited word co-occurrence information is available in short texts. This\npaper studies how to incorporate the external word correlation knowledge into\nshort texts to improve the coherence of topic modeling. Based on recent results\nin word embeddings that learn se- mantically representations for words from a\nlarge corpus, we introduce a novel method, Embedding-based Topic Model (ETM),\nto learn latent topics from short texts. ETM not only solves the problem of\nvery limited word co-occurrence information by aggregating short texts into\nlong pseudo- texts, but also utilizes a Markov Random Field regularized model\nthat gives correlated words a better chance to be put into the same topic. The\nexperiments on real-world datasets validate the effectiveness of our model\ncomparing with the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 15:26:07 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Qiang", "Jipeng", ""], ["Chen", "Ping", ""], ["Wang", "Tong", ""], ["Wu", "Xindong", ""]]}, {"id": "1609.08667", "submitter": "Kevin Clark", "authors": "Kevin Clark and Christopher D. Manning", "title": "Deep Reinforcement Learning for Mention-Ranking Coreference Models", "comments": "To appear in EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference resolution systems are typically trained with heuristic loss\nfunctions that require careful tuning. In this paper we instead apply\nreinforcement learning to directly optimize a neural mention-ranking model for\ncoreference evaluation metrics. We experiment with two approaches: the\nREINFORCE policy gradient algorithm and a reward-rescaled max-margin objective.\nWe find the latter to be more effective, resulting in significant improvements\nover the current state-of-the-art on the English and Chinese portions of the\nCoNLL 2012 Shared Task.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 21:00:26 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 21:58:34 GMT"}, {"version": "v3", "created": "Mon, 31 Oct 2016 20:30:15 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Clark", "Kevin", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1609.08703", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee", "title": "Optimizing Neural Network Hyperparameters with Gaussian Processes for\n  Dialog Act Classification", "comments": "Accepted as a conference paper at IEEE SLT 2016. The two authors\n  contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems based on artificial neural networks (ANNs) have achieved\nstate-of-the-art results in many natural language processing tasks. Although\nANNs do not require manually engineered features, ANNs have many\nhyperparameters to be optimized. The choice of hyperparameters significantly\nimpacts models' performances. However, the ANN hyperparameters are typically\nchosen by manual, grid, or random search, which either requires expert\nexperiences or is computationally expensive. Recent approaches based on\nBayesian optimization using Gaussian processes (GPs) is a more systematic way\nto automatically pinpoint optimal or near-optimal machine learning\nhyperparameters. Using a previously published ANN model yielding\nstate-of-the-art results for dialog act classification, we demonstrate that\noptimizing hyperparameters using GP further improves the results, and reduces\nthe computational time by a factor of 4 compared to a random search. Therefore\nit is a useful technique for tuning ANN models to yield the best performances\nfor natural language processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 23:10:42 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""]]}, {"id": "1609.08777", "submitter": "Kazuya Kawakami", "authors": "Kazuya Kawakami\u007f, Chris Dyer\u007f, Bryan R. Routledge, Noah A. Smith", "title": "Character Sequence Models for ColorfulWords", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural network architecture to predict a point in color space\nfrom the sequence of characters in the color's name. Using large scale\ncolor--name pairs obtained from an online color design forum, we evaluate our\nmodel on a \"color Turing test\" and find that, given a name, the colors\npredicted by our model are preferred by annotators to color names created by\nhumans. Our datasets and demo system are available online at colorlab.us.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:41:18 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 16:08:36 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Kawakami\u007f", "Kazuya", ""], ["Dyer\u007f", "Chris", ""], ["Routledge", "Bryan R.", ""], ["Smith", "Noah A.", ""]]}, {"id": "1609.08779", "submitter": "Desmond Upton Patton", "authors": "Desmond Upton Patton (Columbia University), Kathleen McKeown (Columbia\n  University), Owen Rambow (Columbia University), Jamie Macbeth (Columbia\n  University)", "title": "Using Natural Language Processing and Qualitative Analysis to Intervene\n  in Gang Violence: A Collaboration Between Social Work Researchers and Data\n  Scientists", "comments": "Presented at the Data For Good Exchange 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The U.S. has the highest rate of firearm-related deaths when compared to\nother industrialized countries. Violence particularly affects low-income, urban\nneighborhoods in cities like Chicago, which saw a 40% increase in firearm\nviolence from 2014 to 2015 to more than 3,000 shooting victims. While recent\nstudies have found that urban, gang-involved individuals curate a unique and\ncomplex communication style within and between social media platforms,\norganizations focused on reducing gang violence are struggling to keep up with\nthe growing complexity of social media platforms and the sheer volume of data\nthey present. In this paper, describe the Digital Urban Violence Analysis\nApproach (DUVVA), a collaborative qualitative analysis method used in a\ncollaboration between data scientists and social work researchers to develop a\nsuite of systems for decoding the high- stress language of urban, gang-involved\nyouth. Our approach leverages principles of grounded theory when analyzing\napproximately 800 tweets posted by Chicago gang members and participation of\nyouth from Chicago neighborhoods to create a language resource for natural\nlanguage processing (NLP) methods. In uncovering the unique language and\ncommunication style, we developed automated tools with the potential to detect\naggressive language on social media and aid individuals and groups in\nperforming violence prevention and interruption.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 05:44:10 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Patton", "Desmond Upton", "", "Columbia University"], ["McKeown", "Kathleen", "", "Columbia\n  University"], ["Rambow", "Owen", "", "Columbia University"], ["Macbeth", "Jamie", "", "Columbia\n  University"]]}, {"id": "1609.08789", "submitter": "Zhiyuan Tang", "authors": "Zhiyuan Tang, Ying Shi, Dong Wang, Yang Feng and Shiyue Zhang", "title": "Memory Visualization for Gated Recurrent Neural Networks in Speech\n  Recognition", "comments": "ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown clear superiority in sequence\nmodeling, particularly the ones with gated units, such as long short-term\nmemory (LSTM) and gated recurrent unit (GRU). However, the dynamic properties\nbehind the remarkable performance remain unclear in many applications, e.g.,\nautomatic speech recognition (ASR). This paper employs visualization techniques\nto study the behavior of LSTM and GRU when performing speech recognition tasks.\nOur experiments show some interesting patterns in the gated memory, and some of\nthem have inspired simple yet effective modifications on the network structure.\nWe report two of such modifications: (1) lazy cell update in LSTM, and (2)\nshortcut connections for residual learning. Both modifications lead to more\ncomprehensible and powerful networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 06:26:16 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2016 09:25:14 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 02:07:34 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Tang", "Zhiyuan", ""], ["Shi", "Ying", ""], ["Wang", "Dong", ""], ["Feng", "Yang", ""], ["Zhang", "Shiyue", ""]]}, {"id": "1609.08810", "submitter": "Hagar Loeub", "authors": "Hagar Loeub and Roi Reichart", "title": "Effective Combination of Language and Vision Through Model Composition\n  and the R-CCA Method", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of integrating textual and visual information in\nvector space models for word meaning representation. We first present the\nResidual CCA (R-CCA) method, that complements the standard CCA method by\nrepresenting, for each modality, the difference between the original signal and\nthe signal projected to the shared, max correlation, space. We then show that\nconstructing visual and textual representations and then post-processing them\nthrough composition of common modeling motifs such as PCA, CCA, R-CCA and\nlinear interpolation (a.k.a sequential modeling) yields high quality models. On\nfive standard semantic benchmarks our sequential models outperform recent\nmultimodal representation learning alternatives, including ones that rely on\njoint representation learning. For two of these benchmarks our R-CCA method is\npart of the Best configuration our algorithm yields.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 08:11:28 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 09:59:50 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Loeub", "Hagar", ""], ["Reichart", "Roi", ""]]}, {"id": "1609.08824", "submitter": "Subhro Roy", "authors": "Subhro Roy, Shyam Upadhyay, Dan Roth", "title": "Equation Parsing: Mapping Sentences to Grounded Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying mathematical relations expressed in text is essential to\nunderstanding a broad range of natural language text from election reports, to\nfinancial news, to sport commentaries to mathematical word problems. This paper\nfocuses on identifying and understanding mathematical relations described\nwithin a single sentence. We introduce the problem of Equation Parsing -- given\na sentence, identify noun phrases which represent variables, and generate the\nmathematical equation expressing the relation described in the sentence. We\nintroduce the notion of projective equation parsing and provide an efficient\nalgorithm to parse text to projective equations. Our system makes use of a high\nprecision lexicon of mathematical expressions and a pipeline of structured\npredictors, and generates correct equations in $70\\%$ of the cases. In $60\\%$\nof the time, it also identifies the correct noun phrase $\\rightarrow$ variables\nmapping, significantly outperforming baselines. We also release a new annotated\ndataset for task evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 08:54:05 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Roy", "Subhro", ""], ["Upadhyay", "Shyam", ""], ["Roth", "Dan", ""]]}, {"id": "1609.08843", "submitter": "Jiaming Xu", "authors": "Jiaming Xu, Jing Shi, Yiqun Yao, Suncong Zheng, Bo Xu, Bo Xu", "title": "Hierarchical Memory Networks for Answer Selection on Unknown Words", "comments": "10 pages, to appear in COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, end-to-end memory networks have shown promising results on Question\nAnswering task, which encode the past facts into an explicit memory and perform\nreasoning ability by making multiple computational steps on the memory.\nHowever, memory networks conduct the reasoning on sentence-level memory to\noutput coarse semantic vectors and do not further take any attention mechanism\nto focus on words, which may lead to the model lose some detail information,\nespecially when the answers are rare or unknown words. In this paper, we\npropose a novel Hierarchical Memory Networks, dubbed HMN. First, we encode the\npast facts into sentence-level memory and word-level memory respectively. Then,\n(k)-max pooling is exploited following reasoning module on the sentence-level\nmemory to sample the (k) most relevant sentences to a question and feed these\nsentences into attention mechanism on the word-level memory to focus the words\nin the selected sentences. Finally, the prediction is jointly learned over the\noutputs of the sentence-level reasoning module and the word-level attention\nmechanism. The experimental results demonstrate that our approach successfully\nconducts answer selection on unknown words and achieves a better performance\nthan memory networks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 10:03:05 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Xu", "Jiaming", ""], ["Shi", "Jing", ""], ["Yao", "Yiqun", ""], ["Zheng", "Suncong", ""], ["Xu", "Bo", ""], ["Xu", "Bo", ""]]}, {"id": "1609.09004", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva", "title": "Byte-based Language Identification with Deep Convolutional Networks", "comments": "7 pages. Adapted reviewer comments. arXiv admin note: text overlap\n  with arXiv:1609.07053", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report on our system for the shared task on discriminating between similar\nlanguages (DSL 2016). The system uses only byte representations in a deep\nresidual network (ResNet). The system, named ResIdent, is trained only on the\ndata released with the task (closed training). We obtain 84.88% accuracy on\nsubtask A, 68.80% accuracy on subtask B1, and 69.80% accuracy on subtask B2. A\nlarge difference in accuracy on development data can be observed with\nrelatively minor changes in our network's architecture and hyperparameters. We\ntherefore expect fine-tuning of these parameters to yield higher accuracies.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 16:51:56 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 15:28:29 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Bjerva", "Johannes", ""]]}, {"id": "1609.09007", "submitter": "Ke Tran", "authors": "Ke Tran, Yonatan Bisk, Ashish Vaswani, Daniel Marcu, Kevin Knight", "title": "Unsupervised Neural Hidden Markov Models", "comments": "accepted at EMNLP 2016, Workshop on Structured Prediction for NLP.\n  Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present the first results for neuralizing an Unsupervised\nHidden Markov Model. We evaluate our approach on tag in- duction. Our approach\noutperforms existing generative models and is competitive with the\nstate-of-the-art though with a simpler model easily extended to include\nadditional context.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 16:55:52 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Tran", "Ke", ""], ["Bisk", "Yonatan", ""], ["Vaswani", "Ashish", ""], ["Marcu", "Daniel", ""], ["Knight", "Kevin", ""]]}, {"id": "1609.09019", "submitter": "Ekaterina Shutova", "authors": "Ekaterina Shutova and Patricia Lichtenstein", "title": "Psychologically Motivated Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing techniques are increasingly applied to identify\nsocial trends and predict behavior based on large text collections. Existing\nmethods typically rely on surface lexical and syntactic information. Yet,\nresearch in psychology shows that patterns of human conceptualisation, such as\nmetaphorical framing, are reliable predictors of human expectations and\ndecisions. In this paper, we present a method to learn patterns of metaphorical\nframing from large text collections, using statistical techniques. We apply the\nmethod to data in three different languages and evaluate the identified\npatterns, demonstrating their psychological validity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 17:58:23 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Shutova", "Ekaterina", ""], ["Lichtenstein", "Patricia", ""]]}, {"id": "1609.09028", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga, Elena Kochkina, Maria Liakata, Rob Procter, Michal\n  Lukasik", "title": "Stance Classification in Rumours as a Sequential Task Exploiting the\n  Tree Structure of Social Media Conversations", "comments": "COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rumour stance classification, the task that determines if each tweet in a\ncollection discussing a rumour is supporting, denying, questioning or simply\ncommenting on the rumour, has been attracting substantial interest. Here we\nintroduce a novel approach that makes use of the sequence of transitions\nobserved in tree-structured conversation threads in Twitter. The conversation\nthreads are formed by harvesting users' replies to one another, which results\nin a nested tree-like structure. Previous work addressing the stance\nclassification task has treated each tweet as a separate unit. Here we analyse\ntweets by virtue of their position in a sequence and test two sequential\nclassifiers, Linear-Chain CRF and Tree CRF, each of which makes different\nassumptions about the conversational structure. We experiment with eight\nTwitter datasets, collected during breaking news, and show that exploiting the\nsequential structure of Twitter conversations achieves significant improvements\nover the non-sequential methods. Our work is the first to model Twitter\nconversations as a tree structure in this manner, introducing a novel way of\ntackling NLP tasks on Twitter conversations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 18:24:12 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2016 11:54:36 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Zubiaga", "Arkaitz", ""], ["Kochkina", "Elena", ""], ["Liakata", "Maria", ""], ["Procter", "Rob", ""], ["Lukasik", "Michal", ""]]}, {"id": "1609.09171", "submitter": "Lei Shen", "authors": "Lei Shen, Junlin Zhang", "title": "Empirical Evaluation of RNN Architectures on Sentence Classification\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks have achieved state-of-the-art results for many\nproblems in NLP and two most popular RNN architectures are Tail Model and\nPooling Model. In this paper, a hybrid architecture is proposed and we present\nthe first empirical study using LSTMs to compare performance of the three RNN\nstructures on sentence classification task. Experimental results show that the\nMax Pooling Model or Hybrid Max Pooling Model achieves the best performance on\nmost datasets, while Tail Model does not outperform other models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 01:53:08 GMT"}, {"version": "v2", "created": "Sat, 8 Oct 2016 15:16:57 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Shen", "Lei", ""], ["Zhang", "Junlin", ""]]}, {"id": "1609.09188", "submitter": "Leonard K.M. Poon", "authors": "Leonard K.M. Poon and Nevin L. Zhang", "title": "Topic Browsing for Research Papers with Hierarchical Latent Tree\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic researchers often need to face with a large collection of research\npapers in the literature. This problem may be even worse for postgraduate\nstudents who are new to a field and may not know where to start. To address\nthis problem, we have developed an online catalog of research papers where the\npapers have been automatically categorized by a topic model. The catalog\ncontains 7719 papers from the proceedings of two artificial intelligence\nconferences from 2000 to 2015. Rather than the commonly used Latent Dirichlet\nAllocation, we use a recently proposed method called hierarchical latent tree\nanalysis for topic modeling. The resulting topic model contains a hierarchy of\ntopics so that users can browse the topics from the top level to the bottom\nlevel. The topic model contains a manageable number of general topics at the\ntop level and allows thousands of fine-grained topics at the bottom level. It\nalso can detect topics that have emerged recently.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 03:22:01 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Poon", "Leonard K. M.", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1609.09189", "submitter": "Shaonan Wang", "authors": "Shaonan Wang, Jiajun Zhang and Chengqing Zong", "title": "Learning Sentence Representation with Guidance of Human Attention", "comments": "accepted to IJCAI2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, much progress has been made in learning general-purpose sentence\nrepresentations that can be used across domains. However, most of the existing\nmodels typically treat each word in a sentence equally. In contrast, extensive\nstudies have proven that human read sentences efficiently by making a sequence\nof fixation and saccades. This motivates us to improve sentence representations\nby assigning different weights to the vectors of the component words, which can\nbe treated as an attention mechanism on single sentences. To that end, we\npropose two novel attention models, in which the attention weights are derived\nusing significant predictors of human reading time, i.e., Surprisal, POS tags\nand CCG supertags. The extensive experiments demonstrate that the proposed\nmethods significantly improve upon the state-of-the-art sentence representation\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 03:26:53 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 10:48:01 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Wang", "Shaonan", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1609.09247", "submitter": "Yue Zhang", "authors": "Zhenghua Li, Yue Zhang, Jiayuan Chao, Min Zhang", "title": "Training Dependency Parsers with Partial Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, these has been a surge on studying how to obtain partially\nannotated data for model supervision. However, there still lacks a systematic\nstudy on how to train statistical models with partial annotation (PA). Taking\ndependency parsing as our case study, this paper describes and compares two\nstraightforward approaches for three mainstream dependency parsers. The first\napproach is previously proposed to directly train a log-linear graph-based\nparser (LLGPar) with PA based on a forest-based objective. This work for the\nfirst time proposes the second approach to directly training a linear\ngraph-based parse (LGPar) and a linear transition-based parser (LTPar) with PA\nbased on the idea of constrained decoding. We conduct extensive experiments on\nPenn Treebank under three different settings for simulating PA, i.e., random\ndependencies, most uncertain dependencies, and dependencies with divergent\noutputs from the three parsers. The results show that LLGPar is most effective\nin learning from PA and LTPar lags behind the graph-based counterparts by large\nmargin. Moreover, LGPar and LTPar can achieve best performance by using LLGPar\nto complete PA into full annotation (FA).\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 08:12:14 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Li", "Zhenghua", ""], ["Zhang", "Yue", ""], ["Chao", "Jiayuan", ""], ["Zhang", "Min", ""]]}, {"id": "1609.09315", "submitter": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y", "authors": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y and G\\'abor Melis and Edward Grefenstette\n  and Chris Dyer and Wang Ling and Phil Blunsom and Karl Moritz Hermann", "title": "Semantic Parsing with Semi-Supervised Sequential Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel semi-supervised approach for sequence transduction and\napply it to semantic parsing. The unsupervised component is based on a\ngenerative model in which latent sentences generate the unpaired logical forms.\nWe apply this method to a number of semantic parsing tasks focusing on domains\nwith limited access to labelled training data and extend those datasets with\nsynthetically generated logical forms.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 12:20:13 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Melis", "G\u00e1bor", ""], ["Grefenstette", "Edward", ""], ["Dyer", "Chris", ""], ["Ling", "Wang", ""], ["Blunsom", "Phil", ""], ["Hermann", "Karl Moritz", ""]]}, {"id": "1609.09382", "submitter": "Laurent Besacier", "authors": "Othman Zennaki and Nasredine Semmar and Laurent Besacier", "title": "Inducing Multilingual Text Analysis Tools Using Bidirectional Recurrent\n  Neural Networks", "comments": "accepted to COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on the rapid development of linguistic annotation tools for\nresource-poor languages. We experiment several cross-lingual annotation\nprojection methods using Recurrent Neural Networks (RNN) models. The\ndistinctive feature of our approach is that our multilingual word\nrepresentation requires only a parallel corpus between the source and target\nlanguage. More precisely, our method has the following characteristics: (a) it\ndoes not use word alignment information, (b) it does not assume any knowledge\nabout foreign languages, which makes it applicable to a wide range of\nresource-poor languages, (c) it provides truly multilingual taggers. We\ninvestigate both uni- and bi-directional RNN models and propose a method to\ninclude external information (for instance low level information from POS) in\nthe RNN to train higher level taggers (for instance, super sense taggers). We\ndemonstrate the validity and genericity of our model by using parallel corpora\n(obtained by manual or automatic translation). Our experiments are conducted to\ninduce cross-lingual POS and super sense taggers.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 15:19:13 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Zennaki", "Othman", ""], ["Semmar", "Nasredine", ""], ["Besacier", "Laurent", ""]]}, {"id": "1609.09405", "submitter": "Siva Reddy", "authors": "Yonatan Bisk, Siva Reddy, John Blitzer, Julia Hockenmaier, Mark\n  Steedman", "title": "Evaluating Induced CCG Parsers on Grounded Semantic Parsing", "comments": "EMNLP 2016, Table 2 erratum, Code and Freebase Semantic Parsing data\n  URL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We compare the effectiveness of four different syntactic CCG parsers for a\nsemantic slot-filling task to explore how much syntactic supervision is\nrequired for downstream semantic analysis. This extrinsic, task-based\nevaluation provides a unique window to explore the strengths and weaknesses of\nsemantics captured by unsupervised grammar induction systems. We release a new\nFreebase semantic parsing dataset called SPADES (Semantic PArsing of\nDEclarative Sentences) containing 93K cloze-style questions paired with\nanswers. We evaluate all our models on this dataset. Our code and data are\navailable at https://github.com/sivareddyg/graph-parser.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 16:09:29 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 16:25:39 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Bisk", "Yonatan", ""], ["Reddy", "Siva", ""], ["Blitzer", "John", ""], ["Hockenmaier", "Julia", ""], ["Steedman", "Mark", ""]]}, {"id": "1609.09552", "submitter": "Yuta Kikuchi", "authors": "Yuta Kikuchi, Graham Neubig, Ryohei Sasano, Hiroya Takamura and Manabu\n  Okumura", "title": "Controlling Output Length in Neural Encoder-Decoders", "comments": "11 pages. To appear in EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural encoder-decoder models have shown great success in many sequence\ngeneration tasks. However, previous work has not investigated situations in\nwhich we would like to control the length of encoder-decoder outputs. This\ncapability is crucial for applications such as text summarization, in which we\nhave to generate concise summaries with a desired length. In this paper, we\npropose methods for controlling the output sequence length for neural\nencoder-decoder models: two decoding-based methods and two learning-based\nmethods. Results show that our learning-based methods have the capability to\ncontrol length without degrading summary quality in a summarization task.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 00:01:27 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Kikuchi", "Yuta", ""], ["Neubig", "Graham", ""], ["Sasano", "Ryohei", ""], ["Takamura", "Hiroya", ""], ["Okumura", "Manabu", ""]]}, {"id": "1609.09580", "submitter": "Michael Spranger", "authors": "Michael Spranger and Katrien Beuls", "title": "Referential Uncertainty and Word Learning in High-dimensional,\n  Continuous Meaning Spaces", "comments": "Published as Spranger, M. and Beuls, K. (2016). Referential\n  uncertainty and word learning in high-dimensional, continuous meaning spaces.\n  In Hafner, V. and Pitti, A., editors, Development and Learning and Epigenetic\n  Robotics (ICDL-Epirob), 2016 Joint IEEE International Conferences on, 2016.\n  IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses lexicon word learning in high-dimensional meaning spaces\nfrom the viewpoint of referential uncertainty. We investigate various\nstate-of-the-art Machine Learning algorithms and discuss the impact of scaling,\nrepresentation and meaning space structure. We demonstrate that current Machine\nLearning techniques successfully deal with high-dimensional meaning spaces. In\nparticular, we show that exponentially increasing dimensions linearly impact\nlearner performance and that referential uncertainty from word sensitivity has\nno impact.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 03:20:52 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Spranger", "Michael", ""], ["Beuls", "Katrien", ""]]}]