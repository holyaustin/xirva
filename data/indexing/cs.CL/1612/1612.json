[{"id": "1612.00148", "submitter": "Vivek Kulkarni", "authors": "Vivek Kulkarni, Yashar Mehdad, Troy Chevalier", "title": "Domain Adaptation for Named Entity Recognition in Online Media with Word\n  Embeddings", "comments": "12 pages, 3 figures, 8 tables arxiv preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content on the Internet is heterogeneous and arises from various domains like\nNews, Entertainment, Finance and Technology. Understanding such content\nrequires identifying named entities (persons, places and organizations) as one\nof the key steps. Traditionally Named Entity Recognition (NER) systems have\nbeen built using available annotated datasets (like CoNLL, MUC) and demonstrate\nexcellent performance. However, these models fail to generalize onto other\ndomains like Sports and Finance where conventions and language use can differ\nsignificantly. Furthermore, several domains do not have large amounts of\nannotated labeled data for training robust Named Entity Recognition models. A\nkey step towards this challenge is to adapt models learned on domains where\nlarge amounts of annotated training data are available to domains with scarce\nannotated data.\n  In this paper, we propose methods to effectively adapt models learned on one\ndomain onto other domains using distributed word representations. First we\nanalyze the linguistic variation present across domains to identify key\nlinguistic insights that can boost performance across domains. We propose\nmethods to capture domain specific semantics of word usage in addition to\nglobal semantics. We then demonstrate how to effectively use such domain\nspecific knowledge to learn NER models that outperform previous baselines in\nthe domain adaptation setting.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 05:08:53 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Kulkarni", "Vivek", ""], ["Mehdad", "Yashar", ""], ["Chevalier", "Troy", ""]]}, {"id": "1612.00227", "submitter": "Loris Bozzato", "authors": "Stefano Borgo, Loris Bozzato, Alessio Palmero Aprosio, Marco Rospocher\n  and Luciano Serafini", "title": "On Coreferring Text-extracted Event Descriptions with the aid of\n  Ontological Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems for automatic extraction of semantic information about events from\nlarge textual resources are now available: these tools are capable to generate\nRDF datasets about text extracted events and this knowledge can be used to\nreason over the recognized events. On the other hand, text based tasks for\nevent recognition, as for example event coreference (i.e. recognizing whether\ntwo textual descriptions refer to the same event), do not take into account\nontological information of the extracted events in their process. In this\npaper, we propose a method to derive event coreference on text extracted event\ndata using semantic based rule reasoning. We demonstrate our method considering\na limited (yet representative) set of event types: we introduce a formal\nanalysis on their ontological properties and, on the base of this, we define a\nset of coreference criteria. We then implement these criteria as RDF-based\nreasoning rules to be applied on text extracted event data. We evaluate the\neffectiveness of our approach over a standard coreference benchmark dataset.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 12:58:02 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Borgo", "Stefano", ""], ["Bozzato", "Loris", ""], ["Aprosio", "Alessio Palmero", ""], ["Rospocher", "Marco", ""], ["Serafini", "Luciano", ""]]}, {"id": "1612.00246", "submitter": "Lahari Poddar", "authors": "Lahari Poddar", "title": "Multilingual Multiword Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The project aims to provide a semi-supervised approach to identify Multiword\nExpressions in a multilingual context consisting of English and most of the\nmajor Indian languages. Multiword expressions are a group of words which refers\nto some conventional or regional way of saying things. If they are literally\ntranslated from one language to another the expression will lose its inherent\nmeaning.\n  To automatically extract multiword expressions from a corpus, an extraction\npipeline have been constructed which consist of a combination of rule based and\nstatistical approaches. There are several types of multiword expressions which\ndiffer from each other widely by construction. We employ different methods to\ndetect different types of multiword expressions. Given a POS tagged corpus in\nEnglish or any Indian language the system initially applies some regular\nexpression filters to narrow down the search space to certain patterns (like,\nreduplication, partial reduplication, compound nouns, compound verbs, conjunct\nverbs etc.). The word sequences matching the required pattern are subjected to\na series of linguistic tests which include verb filtering, named entity\nfiltering and hyphenation filtering test to exclude false positives. The\ncandidates are then checked for semantic relationships among themselves (using\nWordnet). In order to detect partial reduplication we make use of Wordnet as a\nlexical database as well as a tool for lemmatising. We detect complex\npredicates by investigating the features of the constituent words. Statistical\nmethods are applied to detect collocations. Finally, lexicographers examine the\nlist of automatically extracted candidates to validate whether they are true\nmultiword expressions or not and add them to the multiword dictionary\naccordingly.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 14:01:00 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Poddar", "Lahari", ""]]}, {"id": "1612.00347", "submitter": "Arash Eshghi", "authors": "Dimitrios Kalatzis, Arash Eshghi, Oliver Lemon", "title": "Bootstrapping incremental dialogue systems: using linguistic knowledge\n  to learn from minimal data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for inducing new dialogue systems from very small amounts\nof unannotated dialogue data, showing how word-level exploration using\nReinforcement Learning (RL), combined with an incremental and semantic grammar\n- Dynamic Syntax (DS) - allows systems to discover, generate, and understand\nmany new dialogue variants. The method avoids the use of expensive and\ntime-consuming dialogue act annotations, and supports more natural\n(incremental) dialogues than turn-based systems. Here, language generation and\ndialogue management are treated as a joint decision/optimisation problem, and\nthe MDP model for RL is constructed automatically. With an implemented system,\nwe show that this method enables a wide range of dialogue variations to be\nautomatically captured, even when the system is trained from only a single\ndialogue. The variants include question-answer pairs, over- and\nunder-answering, self- and other-corrections, clarification interaction,\nsplit-utterances, and ellipsis. This generalisation property results from the\nstructural knowledge and constraints present within the DS grammar, and\nhighlights some limitations of recent systems built using machine learning\ntechniques only.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 16:49:04 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Kalatzis", "Dimitrios", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1612.00370", "submitter": "Siqi Liu", "authors": "Siqi Liu, Zhenhai Zhu, Ning Ye, Sergio Guadarrama, Kevin Murphy", "title": "Improved Image Captioning via Policy Gradient optimization of SPIDEr", "comments": "Accepted at ICCV 2017", "journal-ref": null, "doi": "10.1109/ICCV.2017.100", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current image captioning methods are usually trained via (penalized) maximum\nlikelihood estimation. However, the log-likelihood score of a caption does not\ncorrelate well with human assessments of quality. Standard syntactic evaluation\nmetrics, such as BLEU, METEOR and ROUGE, are also not well correlated. The\nnewer SPICE and CIDEr metrics are better correlated, but have traditionally\nbeen hard to optimize for. In this paper, we show how to use a policy gradient\n(PG) method to directly optimize a linear combination of SPICE and CIDEr (a\ncombination we call SPIDEr): the SPICE score ensures our captions are\nsemantically faithful to the image, while CIDEr score ensures our captions are\nsyntactically fluent. The PG method we propose improves on the prior MIXER\napproach, by using Monte Carlo rollouts instead of mixing MLE training with PG.\nWe show empirically that our algorithm leads to easier optimization and\nimproved results compared to MIXER. Finally, we show that using our PG method\nwe can optimize any of the metrics, including the proposed SPIDEr metric which\nresults in image captions that are strongly preferred by human raters compared\nto captions generated by the same model but trained to optimize MLE or the COCO\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 18:10:48 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 08:36:58 GMT"}, {"version": "v3", "created": "Sat, 18 Mar 2017 09:24:38 GMT"}, {"version": "v4", "created": "Mon, 12 Mar 2018 18:53:06 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Liu", "Siqi", ""], ["Zhu", "Zhenhai", ""], ["Ye", "Ning", ""], ["Guadarrama", "Sergio", ""], ["Murphy", "Kevin", ""]]}, {"id": "1612.00377", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Alexander G. Ororbia II, Joelle Pineau, Aaron\n  Courville", "title": "Piecewise Latent Variables for Neural Variational Text Processing", "comments": "19 pages, 2 figures, 8 tables; EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in neural variational inference have facilitated the learning of\npowerful directed graphical models with continuous latent variables, such as\nvariational autoencoders. The hope is that such models will learn to represent\nrich, multi-modal latent factors in real-world data, such as natural language\ntext. However, current models often assume simplistic priors on the latent\nvariables - such as the uni-modal Gaussian distribution - which are incapable\nof representing complex latent factors efficiently. To overcome this\nrestriction, we propose the simple, but highly flexible, piecewise constant\ndistribution. This distribution has the capacity to represent an exponential\nnumber of modes of a latent target distribution, while remaining mathematically\ntractable. Our results demonstrate that incorporating this new latent\ndistribution into different models yields substantial improvements in natural\nlanguage processing tasks such as document modeling and natural language\ngeneration for dialogue.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 18:49:23 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 03:18:54 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 19:25:58 GMT"}, {"version": "v4", "created": "Sat, 23 Sep 2017 13:33:55 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Serban", "Iulian V.", ""], ["Ororbia", "Alexander G.", "II"], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""]]}, {"id": "1612.00385", "submitter": "Wenjie Pei", "authors": "Wenjie Pei, Tadas Baltru\\v{s}aitis, David M.J. Tax, Louis-Philippe\n  Morency", "title": "Temporal Attention-Gated Model for Robust Sequence Classification", "comments": "Accepted by CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical techniques for sequence classification are designed for\nwell-segmented sequences which have been edited to remove noisy or irrelevant\nparts. Therefore, such methods cannot be easily applied on noisy sequences\nexpected in real-world applications. In this paper, we present the Temporal\nAttention-Gated Model (TAGM) which integrates ideas from attention models and\ngated recurrent networks to better deal with noisy or unsegmented sequences.\nSpecifically, we extend the concept of attention model to measure the relevance\nof each observation (time step) of a sequence. We then use a novel gated\nrecurrent network to learn the hidden representation for the final prediction.\nAn important advantage of our approach is interpretability since the temporal\nattention weights provide a meaningful value for the salience of each time step\nin the sequence. We demonstrate the merits of our TAGM approach, both for\nprediction accuracy and interpretability, on three different tasks: spoken\ndigit recognition, text-based sentiment analysis and visual event recognition.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 19:11:24 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 12:53:28 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Pei", "Wenjie", ""], ["Baltru\u0161aitis", "Tadas", ""], ["Tax", "David M. J.", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1612.00394", "submitter": "Thanapon Noraset", "authors": "Thanapon Noraset, Chen Liang, Larry Birnbaum, Doug Downey", "title": "Definition Modeling: Learning to define word embeddings in natural\n  language", "comments": "To appear in AAAI Conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of words have been shown to capture lexical\nsemantics, as demonstrated by their effectiveness in word similarity and\nanalogical relation tasks. But, these tasks only evaluate lexical semantics\nindirectly. In this paper, we study whether it is possible to utilize\ndistributed representations to generate dictionary definitions of words, as a\nmore direct and transparent representation of the embeddings' semantics. We\nintroduce definition modeling, the task of generating a definition for a given\nword and its embedding. We present several definition model architectures based\non recurrent neural networks, and experiment with the models over multiple data\nsets. Our results show that a model that controls dependencies between the word\nbeing defined and the definition words performs significantly better, and that\na character-level convolution layer designed to leverage morphology can\ncomplement word-level embeddings. Finally, an error analysis suggests that the\nerrors made by a definition model may provide insight into the shortcomings of\nword embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 19:42:37 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Noraset", "Thanapon", ""], ["Liang", "Chen", ""], ["Birnbaum", "Larry", ""], ["Downey", "Doug", ""]]}, {"id": "1612.00467", "submitter": "Florian Schmidt", "authors": "Paulina Grnarova, Florian Schmidt, Stephanie L. Hyland and Carsten\n  Eickhoff", "title": "Neural Document Embeddings for Intensive Care Patient Mortality\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an automatic mortality prediction scheme based on the unstructured\ntextual content of clinical notes. Proposing a convolutional document embedding\napproach, our empirical investigation using the MIMIC-III intensive care\ndatabase shows significant performance gains compared to previously employed\nmethods such as latent topic distributions or generic doc2vec embeddings. These\nimprovements are especially pronounced for the difficult problem of\npost-discharge mortality prediction.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 21:06:54 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Grnarova", "Paulina", ""], ["Schmidt", "Florian", ""], ["Hyland", "Stephanie L.", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1612.00567", "submitter": "Jiangming Liu", "authors": "Jiangming Liu and Yue Zhang", "title": "Shift-Reduce Constituent Parsing with Neural Lookahead Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transition-based models can be fast and accurate for constituent parsing.\nCompared with chart-based models, they leverage richer features by extracting\nhistory information from a parser stack, which spans over non-local\nconstituents. On the other hand, during incremental parsing, constituent\ninformation on the right hand side of the current word is not utilized, which\nis a relative weakness of shift-reduce parsing. To address this limitation, we\nleverage a fast neural model to extract lookahead features. In particular, we\nbuild a bidirectional LSTM model, which leverages the full sentence information\nto predict the hierarchy of constituents that each word starts and ends. The\nresults are then passed to a strong transition-based constituent parser as\nlookahead features. The resulting parser gives 1.3% absolute improvement in WSJ\nand 2.3% in CTB compared to the baseline, given the highest reported accuracies\nfor fully-supervised parsing.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 04:55:24 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Liu", "Jiangming", ""], ["Zhang", "Yue", ""]]}, {"id": "1612.00584", "submitter": "Yuanzhi Ke", "authors": "Yuanzhi Ke, Masafumi Hagiwara", "title": "Alleviating Overfitting for Polysemous Words for Word Representation\n  Estimation Using Lexicons", "comments": "Accepted by IEEE IJCNN 2017. Copyright transferred to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though there are some works on improving distributed word representations\nusing lexicons, the improper overfitting of the words that have multiple\nmeanings is a remaining issue deteriorating the learning when lexicons are\nused, which needs to be solved. An alternative method is to allocate a vector\nper sense instead of a vector per word. However, the word representations\nestimated in the former way are not as easy to use as the latter one. Our\nprevious work uses a probabilistic method to alleviate the overfitting, but it\nis not robust with a small corpus. In this paper, we propose a new neural\nnetwork to estimate distributed word representations using a lexicon and a\ncorpus. We add a lexicon layer in the continuous bag-of-words model and a\nthreshold node after the output of the lexicon layer. The threshold rejects the\nunreliable outputs of the lexicon layer that are less likely to be the same\nwith their inputs. In this way, it alleviates the overfitting of the polysemous\nwords. The proposed neural network can be trained using negative sampling,\nwhich maximizing the log probabilities of target words given the context words,\nby distinguishing the target words from random noises. We compare the proposed\nneural network with the continuous bag-of-words model, the other works\nimproving it, and the previous works estimating distributed word\nrepresentations using both a lexicon and a corpus. The experimental results\nshow that the proposed neural network is more efficient and balanced for both\nsemantic tasks and syntactic tasks than the previous works, and robust to the\nsize of the corpus.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 07:45:40 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 12:36:26 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Ke", "Yuanzhi", ""], ["Hagiwara", "Masafumi", ""]]}, {"id": "1612.00694", "submitter": "Song Han", "authors": "Song Han, Junlong Kang, Huizi Mao, Yiming Hu, Xin Li, Yubin Li,\n  Dongliang Xie, Hong Luo, Song Yao, Yu Wang, Huazhong Yang, William J. Dally", "title": "ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA", "comments": "Accepted as full paper in FPGA'17, Monterey, CA; Also appeared at 1st\n  International Workshop on Efficient Methods for Deep Neural Networks at NIPS\n  2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is widely used in speech recognition. In order\nto achieve higher prediction accuracy, machine learning scientists have built\nlarger and larger models. Such large model is both computation intensive and\nmemory intensive. Deploying such bulky model results in high power consumption\nand leads to high total cost of ownership (TCO) of a data center. In order to\nspeedup the prediction and make it energy efficient, we first propose a\nload-balance-aware pruning method that can compress the LSTM model size by 20x\n(10x from pruning and 2x from quantization) with negligible loss of the\nprediction accuracy. The pruned model is friendly for parallel processing.\nNext, we propose scheduler that encodes and partitions the compressed model to\neach PE for parallelism, and schedule the complicated LSTM data flow. Finally,\nwe design the hardware architecture, named Efficient Speech Recognition Engine\n(ESE) that works directly on the compressed model. Implemented on Xilinx\nXCKU060 FPGA running at 200MHz, ESE has a performance of 282 GOPS working\ndirectly on the compressed LSTM network, corresponding to 2.52 TOPS on the\nuncompressed one, and processes a full LSTM for speech recognition with a power\ndissipation of 41 Watts. Evaluated on the LSTM for speech recognition\nbenchmark, ESE is 43x and 3x faster than Core i7 5930k CPU and Pascal Titan X\nGPU implementations. It achieves 40x and 11.5x higher energy efficiency\ncompared with the CPU and GPU respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 13:16:00 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 06:28:58 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Han", "Song", ""], ["Kang", "Junlong", ""], ["Mao", "Huizi", ""], ["Hu", "Yiming", ""], ["Li", "Xin", ""], ["Li", "Yubin", ""], ["Xie", "Dongliang", ""], ["Luo", "Hong", ""], ["Yao", "Song", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""], ["Dally", "William J.", ""]]}, {"id": "1612.00729", "submitter": "Sowmya Vajjala", "authors": "Sowmya Vajjala", "title": "Automated assessment of non-native learner essays: Investigating the\n  role of linguistic features", "comments": "Article accepted for publication at: International Journal of\n  Artificial Intelligence in Education (IJAIED). To appear in early 2017\n  (journal url: http://www.springer.com/computer/ai/journal/40593)", "journal-ref": null, "doi": "10.1007/s40593-017-0142-3", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic essay scoring (AES) refers to the process of scoring free text\nresponses to given prompts, considering human grader scores as the gold\nstandard. Writing such essays is an essential component of many language and\naptitude exams. Hence, AES became an active and established area of research,\nand there are many proprietary systems used in real life applications today.\nHowever, not much is known about which specific linguistic features are useful\nfor prediction and how much of this is consistent across datasets. This article\naddresses that by exploring the role of various linguistic features in\nautomatic essay scoring using two publicly available datasets of non-native\nEnglish essays written in test taking scenarios. The linguistic properties are\nmodeled by encoding lexical, syntactic, discourse and error types of learner\nlanguage in the feature set. Predictive models are then developed using these\nfeatures on both datasets and the most predictive features are compared. While\nthe results show that the feature set used results in good predictive models\nwith both datasets, the question \"what are the most predictive features?\" has a\ndifferent answer for each dataset.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 16:22:49 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Vajjala", "Sowmya", ""]]}, {"id": "1612.00837", "submitter": "Yash Goyal", "authors": "Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, Devi Parikh", "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in\n  Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems at the intersection of vision and language are of significant\nimportance both as challenging research questions and for the rich set of\napplications they enable. However, inherent structure in our world and bias in\nour language tend to be a simpler signal for learning than visual modalities,\nresulting in models that ignore visual information, leading to an inflated\nsense of their capability.\n  We propose to counter these language priors for the task of Visual Question\nAnswering (VQA) and make vision (the V in VQA) matter! Specifically, we balance\nthe popular VQA dataset by collecting complementary images such that every\nquestion in our balanced dataset is associated with not just a single image,\nbut rather a pair of similar images that result in two different answers to the\nquestion. Our dataset is by construction more balanced than the original VQA\ndataset and has approximately twice the number of image-question pairs. Our\ncomplete balanced dataset is publicly available at www.visualqa.org as part of\nthe 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA\nv2.0).\n  We further benchmark a number of state-of-art VQA models on our balanced\ndataset. All models perform significantly worse on our balanced dataset,\nsuggesting that these models have indeed learned to exploit language priors.\nThis finding provides the first concrete empirical evidence for what seems to\nbe a qualitative sense among practitioners.\n  Finally, our data collection protocol for identifying complementary images\nenables us to develop a novel interpretable model, which in addition to\nproviding an answer to the given (image, question) pair, also provides a\ncounter-example based explanation. Specifically, it identifies an image that is\nsimilar to the original image, but it believes has a different answer to the\nsame question. This can help in building trust for machines among their users.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 20:57:07 GMT"}, {"version": "v2", "created": "Fri, 14 Apr 2017 18:20:13 GMT"}, {"version": "v3", "created": "Mon, 15 May 2017 17:58:49 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Goyal", "Yash", ""], ["Khot", "Tejas", ""], ["Summers-Stay", "Douglas", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1612.00866", "submitter": "John Beieler", "authors": "John Beieler", "title": "Creating a Real-Time, Reproducible Event Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of political event data has remained much the same since the\nmid-1990s, both in terms of data acquisition and the process of coding text\ninto data. Since the 1990s, however, there have been significant improvements\nin open-source natural language processing software and in the availability of\ndigitized news content. This paper presents a new, next-generation event\ndataset, named Phoenix, that builds from these and other advances. This dataset\nincludes improvements in the underlying news collection process and event\ncoding software, along with the creation of a general processing pipeline\nnecessary to produce daily-updated data. This paper provides a face validity\nchecks by briefly examining the data for the conflict in Syria, and a\ncomparison between Phoenix and the Integrated Crisis Early Warning System data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 21:28:00 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Beieler", "John", ""]]}, {"id": "1612.00913", "submitter": "Xuesong Yang", "authors": "Xuesong Yang, Yun-Nung Chen, Dilek Hakkani-Tur, Paul Crook, Xiujun Li,\n  Jianfeng Gao, Li Deng", "title": "End-to-End Joint Learning of Natural Language Understanding and Dialogue\n  Manager", "comments": "Accepted in The 42nd IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding and dialogue policy learning are both\nessential in conversational systems that predict the next system actions in\nresponse to a current user utterance. Conventional approaches aggregate\nseparate models of natural language understanding (NLU) and system action\nprediction (SAP) as a pipeline that is sensitive to noisy outputs of\nerror-prone NLU. To address the issues, we propose an end-to-end deep recurrent\nneural network with limited contextual dialogue memory by jointly training NLU\nand SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our\nproposed model significantly outperforms the state-of-the-art pipeline models\nfor both NLU and SAP, which indicates that our joint model is capable of\nmitigating the affects of noisy NLU outputs, and NLU model can be refined by\nerror flows backpropagating from the extra supervised signals of system\nactions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 02:13:18 GMT"}, {"version": "v2", "created": "Wed, 4 Jan 2017 08:39:09 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Yang", "Xuesong", ""], ["Chen", "Yun-Nung", ""], ["Hakkani-Tur", "Dilek", ""], ["Crook", "Paul", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1612.00944", "submitter": "Muthu Kumar Chandrasekaran", "authors": "Muthu Kumar Chandrasekaran, Carrie Demmans Epp, Min-Yen Kan, Diane\n  Litman", "title": "Using Discourse Signals for Robust Instructor Intervention Prediction", "comments": "To appear in proceedings of the 31st AAAI Conference on Artificial\n  Intelligence, San Francisco, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the prediction of instructor intervention in student posts from\ndiscussion forums in Massive Open Online Courses (MOOCs). Our key finding is\nthat using automatically obtained discourse relations improves the prediction\nof when instructors intervene in student discussions, when compared with a\nstate-of-the-art, feature-rich baseline. Our supervised classifier makes use of\nan automatic discourse parser which outputs Penn Discourse Treebank (PDTB) tags\nthat represent in-post discourse features. We show PDTB relation-based features\nincrease the robustness of the classifier and complement baseline features in\nrecalling more diverse instructor intervention patterns. In comprehensive\nexperiments over 14 MOOC offerings from several disciplines, the PDTB discourse\nfeatures improve performance on average. The resultant models are less\ndependent on domain-specific vocabulary, allowing them to better generalize to\nnew courses.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 09:08:51 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Chandrasekaran", "Muthu Kumar", ""], ["Epp", "Carrie Demmans", ""], ["Kan", "Min-Yen", ""], ["Litman", "Diane", ""]]}, {"id": "1612.00969", "submitter": "Subhro Roy", "authors": "Subhro Roy and Dan Roth", "title": "Unit Dependency Graph and its Application to Arithmetic Word Problem\n  Solving", "comments": "AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Math word problems provide a natural abstraction to a range of natural\nlanguage understanding problems that involve reasoning about quantities, such\nas interpreting election results, news about casualties, and the financial\nsection of a newspaper. Units associated with the quantities often provide\ninformation that is essential to support this reasoning. This paper proposes a\nprincipled way to capture and reason about units and shows how it can benefit\nan arithmetic word problem solver. This paper presents the concept of Unit\nDependency Graphs (UDGs), which provides a compact representation of the\ndependencies between units of numbers mentioned in a given problem. Inducing\nthe UDG alleviates the brittleness of the unit extraction system and allows for\na natural way to leverage domain knowledge about unit compatibility, for word\nproblem solving. We introduce a decomposed model for inducing UDGs with minimal\nadditional annotations, and use it to augment the expressions used in the\narithmetic word problem solver of (Roy and Roth 2015) via a constrained\ninference framework. We show that introduction of UDGs reduces the error of the\nsolver by over 10 %, surpassing all existing systems for solving arithmetic\nword problems. In addition, it also makes the system more robust to adaptation\nto new vocabulary and equation forms .\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 14:14:11 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Roy", "Subhro", ""], ["Roth", "Dan", ""]]}, {"id": "1612.01039", "submitter": "Hu Xu", "authors": "Hu Xu, Sihong Xie, Lei Shu, Philip S. Yu", "title": "CER: Complementary Entity Recognition via Knowledge Expansion on Large\n  Unlabeled Product Reviews", "comments": "10 pages, 2 figures, IEEE BigData 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product reviews contain a lot of useful information about product features\nand customer opinions. One important product feature is the complementary\nentity (products) that may potentially work together with the reviewed product.\nKnowing complementary entities of the reviewed product is very important\nbecause customers want to buy compatible products and avoid incompatible ones.\nIn this paper, we address the problem of Complementary Entity Recognition\n(CER). Since no existing method can solve this problem, we first propose a\nnovel unsupervised method to utilize syntactic dependency paths to recognize\ncomplementary entities. Then we expand category-level domain knowledge about\ncomplementary entities using only a few general seed verbs on a large amount of\nunlabeled reviews. The domain knowledge helps the unsupervised method to adapt\nto different products and greatly improves the precision of the CER task. The\nadvantage of the proposed method is that it does not require any labeled data\nfor training. We conducted experiments on 7 popular products with about 1200\nreviews in total to demonstrate that the proposed approach is effective.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 00:22:44 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Xu", "Hu", ""], ["Xie", "Sihong", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1612.01197", "submitter": "Chen Liang", "authors": "Chen Liang, Jonathan Berant, Quoc Le, Kenneth D. Forbus, Ni Lao", "title": "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with\n  Weak Supervision (Short Version)", "comments": "Published in NAMPI workshop at NIPS 2016. Short version of\n  arXiv:1611.00020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending the success of deep neural networks to natural language\nunderstanding and symbolic reasoning requires complex operations and external\nmemory. Recent neural program induction approaches have attempted to address\nthis problem, but are typically limited to differentiable memory, and\nconsequently cannot scale beyond small synthetic tasks. In this work, we\npropose the Manager-Programmer-Computer framework, which integrates neural\nnetworks with non-differentiable memory to support abstract, scalable and\nprecise operations through a friendly neural computer interface. Specifically,\nwe introduce a Neural Symbolic Machine, which contains a sequence-to-sequence\nneural \"programmer\", and a non-differentiable \"computer\" that is a Lisp\ninterpreter with code assist. To successfully apply REINFORCE for training, we\naugment it with approximate gold programs found by an iterative maximum\nlikelihood training process. NSM is able to learn a semantic parser from weak\nsupervision over a large knowledge base. It achieves new state-of-the-art\nperformance on WebQuestionsSP, a challenging semantic parsing dataset, with\nweak supervision. Compared to previous approaches, NSM is end-to-end, therefore\ndoes not rely on feature engineering or domain specific knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 22:29:32 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Liang", "Chen", ""], ["Berant", "Jonathan", ""], ["Le", "Quoc", ""], ["Forbus", "Kenneth D.", ""], ["Lao", "Ni", ""]]}, {"id": "1612.01340", "submitter": "Ankesh Anand", "authors": "Ankesh Anand, Tanmoy Chakraborty, Noseong Park", "title": "We used Neural Networks to Detect Clickbaits: You won't believe what\n  happened Next!", "comments": "Accepted to the European Conference on Information Retrieval (ECIR),\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online content publishers often use catchy headlines for their articles in\norder to attract users to their websites. These headlines, popularly known as\nclickbaits, exploit a user's curiosity gap and lure them to click on links that\noften disappoint them. Existing methods for automatically detecting clickbaits\nrely on heavy feature engineering and domain knowledge. Here, we introduce a\nneural network architecture based on Recurrent Neural Networks for detecting\nclickbaits. Our model relies on distributed word representations learned from a\nlarge unannotated corpora, and character embeddings learned via Convolutional\nNeural Networks. Experimental results on a dataset of news headlines show that\nour model outperforms existing techniques for clickbait detection with an\naccuracy of 0.98 with F1-score of 0.98 and ROC-AUC of 0.99.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 13:18:48 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 02:44:49 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Anand", "Ankesh", ""], ["Chakraborty", "Tanmoy", ""], ["Park", "Noseong", ""]]}, {"id": "1612.01404", "submitter": "Eug\\'enio Ribeiro", "authors": "Eug\\'enio Ribeiro, Ricardo Ribeiro and David Martins de Matos", "title": "Mapping the Dialog Act Annotations of the LEGO Corpus into the\n  Communicative Functions of ISO 24617-2", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present strategies for mapping the dialog act annotations of\nthe LEGO corpus into the communicative functions of the ISO 24617-2 standard.\nUsing these strategies, we obtained an additional 347 dialogs annotated\naccording to the standard. This is particularly important given the reduced\namount of existing data in those conditions due to the recency of the standard.\nFurthermore, these are dialogs from a widely explored corpus for dialog related\ntasks. However, its dialog annotations have been neglected due to their high\ndomain-dependency, which renders them unuseful outside the context of the\ncorpus. Thus, through our mapping process, we both obtain more data annotated\naccording to a recent standard and provide useful dialog act annotations for a\nwidely explored corpus in the context of dialog research.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 15:48:06 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Ribeiro", "Eug\u00e9nio", ""], ["Ribeiro", "Ricardo", ""], ["de Matos", "David Martins", ""]]}, {"id": "1612.01556", "submitter": "Daniel Graziotin", "authors": "Mika Viking M\\\"antyl\\\"a, Daniel Graziotin, Miikka Kuutila", "title": "The Evolution of Sentiment Analysis - A Review of Research Topics,\n  Venues, and Top Cited Papers", "comments": "29 pages, 14 figures", "journal-ref": "Computer Science Review, Volume 27, February 2018, Pages 16-32", "doi": "10.1016/j.cosrev.2017.10.002", "report-no": null, "categories": "cs.CL cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is one of the fastest growing research areas in computer\nscience, making it challenging to keep track of all the activities in the area.\nWe present a computer-assisted literature review, where we utilize both text\nmining and qualitative coding, and analyze 6,996 papers from Scopus. We find\nthat the roots of sentiment analysis are in the studies on public opinion\nanalysis at the beginning of 20th century and in the text subjectivity analysis\nperformed by the computational linguistics community in 1990's. However, the\noutbreak of computer-based sentiment analysis only occurred with the\navailability of subjective texts on the Web. Consequently, 99% of the papers\nhave been published after 2004. Sentiment analysis papers are scattered to\nmultiple publication venues, and the combined number of papers in the top-15\nvenues only represent ca. 30% of the papers in total. We present the top-20\ncited papers from Google Scholar and Scopus and a taxonomy of research topics.\nIn recent years, sentiment analysis has shifted from analyzing online product\nreviews to social media texts from Twitter and Facebook. Many topics beyond\nproduct reviews like stock markets, elections, disasters, medicine, software\nengineering and cyberbullying extend the utilization of sentiment analysis\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 21:28:06 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 18:09:41 GMT"}, {"version": "v3", "created": "Tue, 14 Nov 2017 10:40:58 GMT"}, {"version": "v4", "created": "Tue, 21 Nov 2017 08:16:59 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["M\u00e4ntyl\u00e4", "Mika Viking", ""], ["Graziotin", "Daniel", ""], ["Kuutila", "Miikka", ""]]}, {"id": "1612.01627", "submitter": "Yu Wu", "authors": "Yu Wu, Wei Wu, Chen Xing, Ming Zhou, Zhoujun Li", "title": "Sequential Matching Network: A New Architecture for Multi-turn Response\n  Selection in Retrieval-based Chatbots", "comments": "ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study response selection for multi-turn conversation in retrieval-based\nchatbots. Existing work either concatenates utterances in context or matches a\nresponse with a highly abstract context vector finally, which may lose\nrelationships among utterances or important contextual information. We propose\na sequential matching network (SMN) to address both problems. SMN first matches\na response with each utterance in the context on multiple levels of\ngranularity, and distills important matching information from each pair as a\nvector with convolution and pooling operations. The vectors are then\naccumulated in a chronological order through a recurrent neural network (RNN)\nwhich models relationships among utterances. The final matching score is\ncalculated with the hidden states of the RNN. An empirical study on two public\ndata sets shows that SMN can significantly outperform state-of-the-art methods\nfor response selection in multi-turn conversation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 01:57:39 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 01:50:55 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Wu", "Yu", ""], ["Wu", "Wei", ""], ["Xing", "Chen", ""], ["Zhou", "Ming", ""], ["Li", "Zhoujun", ""]]}, {"id": "1612.01744", "submitter": "Laurent Besacier", "authors": "Alexandre Berard and Olivier Pietquin and Christophe Servan and\n  Laurent Besacier", "title": "Listen and Translate: A Proof of Concept for End-to-End Speech-to-Text\n  Translation", "comments": "accepted to NIPS workshop on End-to-end Learning for Speech and Audio\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a first attempt to build an end-to-end speech-to-text\ntranslation system, which does not use source language transcription during\nlearning or decoding. We propose a model for direct speech-to-text translation,\nwhich gives promising results on a small French-English synthetic corpus.\nRelaxing the need for source language transcription would drastically change\nthe data collection methodology in speech translation, especially in\nunder-resourced scenarios. For instance, in the former project DARPA TRANSTAC\n(speech translation from spoken Arabic dialects), a large effort was devoted to\nthe collection of speech transcripts (and a prerequisite to obtain transcripts\nwas often a detailed transcription guide for languages with little standardized\nspelling). Now, if end-to-end approaches for speech-to-text translation are\nsuccessful, one might consider collecting data by asking bilingual speakers to\ndirectly utter speech in the source language from target language text\nutterances. Such an approach has the advantage to be applicable to any\nunwritten (source) language.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 10:48:56 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Berard", "Alexandre", ""], ["Pietquin", "Olivier", ""], ["Servan", "Christophe", ""], ["Besacier", "Laurent", ""]]}, {"id": "1612.01848", "submitter": "Aaditya Prakash", "authors": "Aaditya Prakash, Siyuan Zhao, Sadid A. Hasan, Vivek Datla, Kathy Lee,\n  Ashequl Qadir, Joey Liu, Oladimeji Farri", "title": "Condensed Memory Networks for Clinical Diagnostic Inferencing", "comments": "Accepted to AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosis of a clinical condition is a challenging task, which often requires\nsignificant medical investigation. Previous work related to diagnostic\ninferencing problems mostly consider multivariate observational data (e.g.\nphysiological signals, lab tests etc.). In contrast, we explore the problem\nusing free-text medical notes recorded in an electronic health record (EHR).\nComplex tasks like these can benefit from structured knowledge bases, but those\nare not scalable. We instead exploit raw text from Wikipedia as a knowledge\nsource. Memory networks have been demonstrated to be effective in tasks which\nrequire comprehension of free-form text. They use the final iteration of the\nlearned representation to predict probable classes. We introduce condensed\nmemory neural networks (C-MemNNs), a novel model with iterative condensation of\nmemory representations that preserves the hierarchy of features in the memory.\nExperiments on the MIMIC-III dataset show that the proposed model outperforms\nother variants of memory networks to predict the most probable diagnoses given\na complex clinical scenario.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 15:15:27 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2017 20:41:20 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Prakash", "Aaditya", ""], ["Zhao", "Siyuan", ""], ["Hasan", "Sadid A.", ""], ["Datla", "Vivek", ""], ["Lee", "Kathy", ""], ["Qadir", "Ashequl", ""], ["Liu", "Joey", ""], ["Farri", "Oladimeji", ""]]}, {"id": "1612.01892", "submitter": "Gautam Singh", "authors": "Gautam Singh, Saemi Jang, Mun Y. Yi", "title": "Cross-Lingual Predicate Mapping Between Linked Data Ontologies", "comments": "11 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies in different natural languages often differ in quality in terms of\nrichness of schema or richness of internal links. This difference is markedly\nvisible when comparing a rich English language ontology with a non-English\nlanguage counterpart. Discovering alignment between them is a useful endeavor\nas it serves as a starting point in bridging the disparity. In particular, our\nwork is motivated by the absence of inter-language links for predicates in the\nlocalised versions of DBpedia. In this paper, we propose and demonstrate an\nad-hoc system to find possible owl:equivalentProperty links between predicates\nin ontologies of different natural languages. We seek to achieve this mapping\nby using pre-existing inter-language links of the resources connected by the\ngiven predicate. Thus, our methodology stresses on semantic similarity rather\nthan lexical. Moreover, through an evaluation, we show that our system is\ncapable of outperforming a baseline system that is similar to the one used in\nrecent OAEI campaigns.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 16:26:33 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Singh", "Gautam", ""], ["Jang", "Saemi", ""], ["Yi", "Mun Y.", ""]]}, {"id": "1612.01928", "submitter": "Dmitriy Serdyuk", "authors": "Dmitriy Serdyuk, Kartik Audhkhasi, Phil\\'emon Brakel, Bhuvana\n  Ramabhadran, Samuel Thomas, Yoshua Bengio", "title": "Invariant Representations for Noisy Speech Recognition", "comments": "5 pages, 1 figure, 1 table, NIPS workshop on end-to-end speech\n  recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern automatic speech recognition (ASR) systems need to be robust under\nacoustic variability arising from environmental, speaker, channel, and\nrecording conditions. Ensuring such robustness to variability is a challenge in\nmodern day neural network-based ASR systems, especially when all types of\nvariability are not seen during training. We attempt to address this problem by\nencouraging the neural network acoustic model to learn invariant feature\nrepresentations. We use ideas from recent research on image generation using\nGenerative Adversarial Networks and domain adaptation ideas extending\nadversarial gradient-based training. A recent work from Ganin et al. proposes\nto use adversarial training for image domain adaptation by using an\nintermediate representation from the main target classification network to\ndeteriorate the domain classifier performance through a separate neural\nnetwork. Our work focuses on investigating neural architectures which produce\nrepresentations invariant to noise conditions for ASR. We evaluate the proposed\narchitecture on the Aurora-4 task, a popular benchmark for noise robust ASR. We\nshow that our method generalizes better than the standard multi-condition\ntraining especially when only a few noise categories are seen during training.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 22:20:51 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Serdyuk", "Dmitriy", ""], ["Audhkhasi", "Kartik", ""], ["Brakel", "Phil\u00e9mon", ""], ["Ramabhadran", "Bhuvana", ""], ["Thomas", "Samuel", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1612.02251", "submitter": "Barbara Plank", "authors": "H\\'ector Mart\\'inez Alonso and Barbara Plank", "title": "When is multitask learning effective? Semantic sequence prediction under\n  varying data conditions", "comments": "In EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning has been applied successfully to a range of tasks, mostly\nmorphosyntactic. However, little is known on when MTL works and whether there\nare data characteristics that help to determine its success. In this paper we\nevaluate a range of semantic sequence labeling tasks in a MTL setup. We examine\ndifferent auxiliary tasks, amongst which a novel setup, and correlate their\nimpact to data-dependent conditions. Our results show that MTL is not always\neffective, significant improvements are obtained only for 1 out of 5 tasks.\nWhen successful, auxiliary tasks with compact and more uniform label\ndistributions are preferable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 14:03:15 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 18:26:26 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Alonso", "H\u00e9ctor Mart\u00ednez", ""], ["Plank", "Barbara", ""]]}, {"id": "1612.02482", "submitter": "Krupakar Hans", "authors": "Krupakar Hans, R S Milton", "title": "Improving the Performance of Neural Machine Translation Involving\n  Morphologically Rich Languages", "comments": "21 pages, 11 figures, 2 tables, Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the attention mechanism in neural machine translation models\nhas improved the performance of machine translation systems by enabling\nselective lookup into the source sentence. In this paper, the efficiencies of\ntranslation using bidirectional encoder attention decoder models were studied\nwith respect to translation involving morphologically rich languages. The\nEnglish - Tamil language pair was selected for this analysis. First, the use of\nWord2Vec embedding for both the English and Tamil words improved the\ntranslation results by 0.73 BLEU points over the baseline RNNSearch model with\n4.84 BLEU score. The use of morphological segmentation before word\nvectorization to split the morphologically rich Tamil words into their\nrespective morphemes before the translation, caused a reduction in the target\nvocabulary size by a factor of 8. Also, this model (RNNMorph) improved the\nperformance of neural machine translation by 7.05 BLEU points over the\nRNNSearch model used over the same corpus. Since the BLEU evaluation of the\nRNNMorph model might be unreliable due to an increase in the number of matching\ntokens per sentence, the performances of the translations were also compared by\nmeans of human evaluation metrics of adequacy, fluency and relative ranking.\nFurther, the use of morphological segmentation also improved the efficacy of\nthe attention mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 23:20:53 GMT"}, {"version": "v2", "created": "Sun, 8 Jan 2017 06:04:50 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Hans", "Krupakar", ""], ["Milton", "R S", ""]]}, {"id": "1612.02695", "submitter": "Jan Chorowski", "authors": "Jan Chorowski and Navdeep Jaitly", "title": "Towards better decoding and language model integration in sequence to\n  sequence models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Sequence-to-Sequence (seq2seq) framework advocates\nreplacing complex data processing pipelines, such as an entire automatic speech\nrecognition system, with a single neural network trained in an end-to-end\nfashion. In this contribution, we analyse an attention-based seq2seq speech\nrecognition system that directly transcribes recordings into characters. We\nobserve two shortcomings: overconfidence in its predictions and a tendency to\nproduce incomplete transcriptions when language models are used. We propose\npractical solutions to both problems achieving competitive speaker independent\nword error rates on the Wall Street Journal dataset: without separate language\nmodels we reach 10.6% WER, while together with a trigram language model, we\nreach 6.7% WER.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 15:23:44 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Chorowski", "Jan", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1612.02703", "submitter": "Jose Camacho-Collados", "authors": "Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci and\n  Roberto Navigli", "title": "Embedding Words and Senses Together via Joint Knowledge-Enhanced\n  Training", "comments": "Accepted in CoNLL 2017. 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are widely used in Natural Language Processing, mainly due to\ntheir success in capturing semantic information from massive corpora. However,\ntheir creation process does not allow the different meanings of a word to be\nautomatically separated, as it conflates them into a single vector. We address\nthis issue by proposing a new model which learns word and sense embeddings\njointly. Our model exploits large corpora and knowledge from semantic networks\nin order to produce a unified vector space of word and sense embeddings. We\nevaluate the main features of our approach both qualitatively and\nquantitatively in a variety of tasks, highlighting the advantages of the\nproposed method in comparison to state-of-the-art word- and sense-based models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 15:54:00 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 10:16:35 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Mancini", "Massimiliano", ""], ["Camacho-Collados", "Jose", ""], ["Iacobacci", "Ignacio", ""], ["Navigli", "Roberto", ""]]}, {"id": "1612.02706", "submitter": "Karl Stratos", "authors": "Karl Stratos", "title": "Entity Identification as Multitasking", "comments": "EMNLP 2017, Workshop on Structured Prediction for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard approaches in entity identification hard-code boundary detection and\ntype prediction into labels (e.g., John/B-PER Smith/I-PER) and then perform\nViterbi. This has two disadvantages: 1. the runtime complexity grows\nquadratically in the number of types, and 2. there is no natural segment-level\nrepresentation. In this paper, we propose a novel neural architecture that\naddresses these disadvantages. We frame the problem as multitasking, separating\nboundary detection and type prediction but optimizing them jointly. Despite its\nsimplicity, this architecture performs competitively with fully structured\nmodels such as BiLSTM-CRFs while scaling linearly in the number of types.\nFurthermore, by construction, the model induces type-disambiguating embeddings\nof predicted mentions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 16:05:03 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 16:03:13 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Stratos", "Karl", ""]]}, {"id": "1612.02741", "submitter": "Lili Mou", "authors": "Lili Mou, Zhengdong Lu, Hang Li, Zhi Jin", "title": "Coupling Distributed and Symbolic Execution for Natural Language Queries", "comments": "Accepted by ICML-17; also presented at ICLR-17 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building neural networks to query a knowledge base (a table) with natural\nlanguage is an emerging research topic in deep learning. An executor for table\nquerying typically requires multiple steps of execution because queries may\nhave complicated structures. In previous studies, researchers have developed\neither fully distributed executors or symbolic executors for table querying. A\ndistributed executor can be trained in an end-to-end fashion, but is weak in\nterms of execution efficiency and explicit interpretability. A symbolic\nexecutor is efficient in execution, but is very difficult to train especially\nat initial stages. In this paper, we propose to couple distributed and symbolic\nexecution for natural language queries, where the symbolic executor is\npretrained with the distributed executor's intermediate execution results in a\nstep-by-step fashion. Experiments show that our approach significantly\noutperforms both distributed and symbolic executors, exhibiting high accuracy,\nhigh learning efficiency, high execution efficiency, and high interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 17:45:16 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 11:37:44 GMT"}, {"version": "v3", "created": "Tue, 25 Apr 2017 20:39:57 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 14:33:31 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Mou", "Lili", ""], ["Lu", "Zhengdong", ""], ["Li", "Hang", ""], ["Jin", "Zhi", ""]]}, {"id": "1612.02801", "submitter": "Wenchao Du", "authors": "Wenchao Du, Pascal Poupart, Wei Xu", "title": "Discovering Conversational Dependencies between Messages in Dialogs", "comments": "AAAI2017 student abstract camera-ready version", "journal-ref": null, "doi": null, "report-no": "00", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the task of inferring conversational dependencies between\nmessages in one-on-one online chat, which has become one of the most popular\nforms of customer service. We propose a novel probabilistic classifier that\nleverages conversational, lexical and semantic information. The approach is\nevaluated empirically on a set of customer service chat logs from a Chinese\ne-commerce website. It outperforms heuristic baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 20:33:17 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Du", "Wenchao", ""], ["Poupart", "Pascal", ""], ["Xu", "Wei", ""]]}, {"id": "1612.03205", "submitter": "Peter Potash", "authors": "Peter Potash, Alexey Romanov, Anna Rumshisky", "title": "Evaluating Creative Language Generation: The Case of Rap Lyric\n  Ghostwriting", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language generation tasks that seek to mimic human ability to use language\ncreatively are difficult to evaluate, since one must consider creativity,\nstyle, and other non-trivial aspects of the generated text. The goal of this\npaper is to develop evaluation methods for one such task, ghostwriting of rap\nlyrics, and to provide an explicit, quantifiable foundation for the goals and\nfuture directions of this task. Ghostwriting must produce text that is similar\nin style to the emulated artist, yet distinct in content. We develop a novel\nevaluation methodology that addresses several complementary aspects of this\ntask, and illustrate how such evaluation can be used to meaningfully analyze\nsystem performance. We provide a corpus of lyrics for 13 rap artists, annotated\nfor stylistic similarity, which allows us to assess the feasibility of manual\nevaluation for generated verse.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 22:36:33 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Potash", "Peter", ""], ["Romanov", "Alexey", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1612.03216", "submitter": "Peter Potash", "authors": "Peter Potash, Alexey Romanov, Anna Rumshisky", "title": "#HashtagWars: Learning a Sense of Humor", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new dataset for computational humor, specifically\ncomparative humor ranking, which attempts to eschew the ubiquitous binary\napproach to humor detection. The dataset consists of tweets that are humorous\nresponses to a given hashtag. We describe the motivation for this new dataset,\nas well as the collection process, which includes a description of our\nsemi-automated system for data collection. We also present initial experiments\nfor this dataset using both unsupervised and supervised approaches. Our best\nsupervised system achieved 63.7% accuracy, suggesting that this task is much\nmore difficult than comparable humor detection tasks. Initial experiments\nindicate that a character-level model is more suitable for this task than a\ntoken-level model, likely due to a large amount of puns that can be captured by\na character-level model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 23:28:16 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 18:41:44 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Potash", "Peter", ""], ["Romanov", "Alexey", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1612.03226", "submitter": "Jiaji Huang Dr.", "authors": "Jiaji Huang, Rewon Child, Vinay Rao, Hairong Liu, Sanjeev Satheesh,\n  Adam Coates", "title": "Active Learning for Speech Recognition: the Power of Gradients", "comments": "published as a workshop paper at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In training speech recognition systems, labeling audio clips can be\nexpensive, and not all data is equally valuable. Active learning aims to label\nonly the most informative samples to reduce cost. For speech recognition,\nconfidence scores and other likelihood-based active learning methods have been\nshown to be effective. Gradient-based active learning methods, however, are\nstill not well-understood. This work investigates the Expected Gradient Length\n(EGL) approach in active learning for end-to-end speech recognition. We justify\nEGL from a variance reduction perspective, and observe that EGL's measure of\ninformativeness picks novel samples uncorrelated with confidence scores.\nExperimentally, we show that EGL can reduce word errors by 11\\%, or\nalternatively, reduce the number of samples to label by 50\\%, when compared to\nrandom sampling.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 00:09:45 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Huang", "Jiaji", ""], ["Child", "Rewon", ""], ["Rao", "Vinay", ""], ["Liu", "Hairong", ""], ["Satheesh", "Sanjeev", ""], ["Coates", "Adam", ""]]}, {"id": "1612.03231", "submitter": "Yongjun Zhu", "authors": "Yongjun Zhu, Erjia Yan, Il-Yeol Song", "title": "A natural language interface to a graph-based bibliographic information\n  retrieval system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing scientific literature, there is a need on a natural\nlanguage interface to bibliographic information retrieval systems to retrieve\nrelated information effectively. In this paper, we propose a natural language\ninterface, NLI-GIBIR, to a graph-based bibliographic information retrieval\nsystem. In designing NLI-GIBIR, we developed a novel framework that can be\napplicable to graph-based bibliographic information retrieval systems. Our\nframework integrates algorithms/heuristics for interpreting and analyzing\nnatural language bibliographic queries. NLI-GIBIR allows users to search for a\nvariety of bibliographic data through natural language. A series of text- and\nlinguistic-based techniques are used to analyze and answer natural language\nqueries, including tokenization, named entity recognition, and syntactic\nanalysis. We find that our framework can effectively represents and addresses\ncomplex bibliographic information needs. Thus, the contributions of this paper\nare as follows: First, to our knowledge, it is the first attempt to propose a\nnatural language interface to graph-based bibliographic information retrieval.\nSecond, we propose a novel customized natural language processing framework\nthat integrates a few original algorithms/heuristics for interpreting and\nanalyzing natural language bibliographic queries. Third, we show that the\nproposed framework and natural language interface provide a practical solution\nin building real-world natural language interface-based bibliographic\ninformation retrieval systems. Our experimental results show that the presented\nsystem can correctly answer 39 out of 40 example natural language queries with\nvarying lengths and complexities.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 00:32:28 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Zhu", "Yongjun", ""], ["Yan", "Erjia", ""], ["Song", "Il-Yeol", ""]]}, {"id": "1612.03266", "submitter": "Hannes Heikinheimo", "authors": "Matti Lankinen, Hannes Heikinheimo, Pyry Takala, Tapani Raiko and Juha\n  Karhunen", "title": "A Character-Word Compositional Neural Language Model for Finnish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent research, we explore ways to model the highly\nmorphological Finnish language at the level of characters while maintaining the\nperformance of word-level models. We propose a new\nCharacter-to-Word-to-Character (C2W2C) compositional language model that uses\ncharacters as input and output while still internally processing word level\nembeddings. Our preliminary experiments, using the Finnish Europarl V7 corpus,\nindicate that C2W2C can respond well to the challenges of morphologically rich\nlanguages such as high out of vocabulary rates, the prediction of novel words,\nand growing vocabulary size. Notably, the model is able to correctly score\ninflectional forms that are not present in the training data and sample\ngrammatically and semantically correct Finnish sentences character by\ncharacter.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 08:05:38 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Lankinen", "Matti", ""], ["Heikinheimo", "Hannes", ""], ["Takala", "Pyry", ""], ["Raiko", "Tapani", ""], ["Karhunen", "Juha", ""]]}, {"id": "1612.03277", "submitter": "Seyed-Mehdi-Reza Beheshti", "authors": "Seyed-Mehdi-Reza Beheshti and Alireza Tabebordbar and Boualem\n  Benatallah and Reza Nouri", "title": "Data Curation APIs", "comments": null, "journal-ref": null, "doi": null, "report-no": "UNSW-CSE-TR-201617", "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and analyzing big data is firmly recognized as a powerful and\nstrategic priority. For deeper interpretation of and better intelligence with\nbig data, it is important to transform raw data (unstructured, semi-structured\nand structured data sources, e.g., text, video, image data sets) into curated\ndata: contextualized data and knowledge that is maintained and made available\nfor use by end-users and applications. In particular, data curation acts as the\nglue between raw data and analytics, providing an abstraction layer that\nrelieves users from time consuming, tedious and error prone curation tasks. In\nthis context, the data curation process becomes a vital analytics asset for\nincreasing added value and insights.\n  In this paper, we identify and implement a set of curation APIs and make them\navailable (on GitHub) to researchers and developers to assist them transforming\ntheir raw data into curated data. The curation APIs enable developers to easily\nadd features - such as extracting keyword, part of speech, and named entities\nsuch as Persons, Locations, Organizations, Companies, Products, Diseases,\nDrugs, etc.; providing synonyms and stems for extracted information items\nleveraging lexical knowledge bases for the English language such as WordNet;\nlinking extracted entities to external knowledge bases such as Google Knowledge\nGraph and Wikidata; discovering similarity among the extracted information\nitems, such as calculating similarity between string, number, date and time\ndata; classifying, sorting and categorizing data into various types, forms or\nany other distinct class; and indexing structured and unstructured data - into\ntheir applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 10:54:45 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Beheshti", "Seyed-Mehdi-Reza", ""], ["Tabebordbar", "Alireza", ""], ["Benatallah", "Boualem", ""], ["Nouri", "Reza", ""]]}, {"id": "1612.03494", "submitter": "Vasileios Lampos", "authors": "Vasileios Lampos", "title": "Flu Detector: Estimating influenza-like illness rates from online\n  user-generated content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a brief technical description of an online platform for disease\nmonitoring, titled as the Flu Detector (fludetector.cs.ucl.ac.uk). Flu\nDetector, in its current version (v.0.5), uses either Twitter or Google search\ndata in conjunction with statistical Natural Language Processing models to\nestimate the rate of influenza-like illness in the population of England. Its\nback-end is a live service that collects online data, utilises modern\ntechnologies for large-scale text processing, and finally applies statistical\ninference models that are trained offline. The front-end visualises the various\ndisease rate estimates. Notably, the models based on Google data achieve a high\nlevel of accuracy with respect to the most recent four flu seasons in England\n(2012/13 to 2015/16). This highlighted Flu Detector as having a great potential\nof becoming a complementary source to the domestic traditional flu surveillance\nschemes.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 22:27:37 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Lampos", "Vasileios", ""]]}, {"id": "1612.03551", "submitter": "Xun Wang", "authors": "Xun Wang, Katsuhito Sudoh, Masaaki Nagata, Tomohide Shibata, Daisuke\n  Kawahara and Sadao Kurohashi", "title": "Reading Comprehension using Entity-based Memory Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel neural network model for question answering,\nthe \\emph{entity-based memory network}. It enhances neural networks' ability of\nrepresenting and calculating information over a long period by keeping records\nof entities contained in text. The core component is a memory pool which\ncomprises entities' states. These entities' states are continuously updated\naccording to the input text. Questions with regard to the input text are used\nto search the memory pool for related entities and answers are further\npredicted based on the states of retrieved entities. Compared with previous\nmemory network models, the proposed model is capable of handling fine-grained\ninformation and more sophisticated relations based on entities. We formulated\nseveral different tasks as question answering problems and tested the proposed\nmodel. Experiments reported satisfying results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 06:19:32 GMT"}, {"version": "v2", "created": "Sat, 28 Jan 2017 06:09:20 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2017 09:13:25 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Wang", "Xun", ""], ["Sudoh", "Katsuhito", ""], ["Nagata", "Masaaki", ""], ["Shibata", "Tomohide", ""], ["Kawahara", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1612.03597", "submitter": "Dat Quoc Nguyen", "authors": "Thanh Vu, Dat Quoc Nguyen, Mark Johnson, Dawei Song, Alistair Willis", "title": "Search Personalization with Embeddings", "comments": "In Proceedings of the 39th European Conference on Information\n  Retrieval, ECIR 2017, to appear", "journal-ref": null, "doi": "10.1007/978-3-319-56608-5_54", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that the performance of search personalization\ndepends on the richness of user profiles which normally represent the user's\ntopical interests. In this paper, we propose a new embedding approach to\nlearning user profiles, where users are embedded on a topical interest space.\nWe then directly utilize the user profiles for search personalization.\nExperiments on query logs from a major commercial web search engine demonstrate\nthat our embedding approach improves the performance of the search engine and\nalso achieves better search performance than other strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 10:27:31 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Vu", "Thanh", ""], ["Nguyen", "Dat Quoc", ""], ["Johnson", "Mark", ""], ["Song", "Dawei", ""], ["Willis", "Alistair", ""]]}, {"id": "1612.03628", "submitter": "Marc Bola\\~nos", "authors": "Marc Bola\\~nos, \\'Alvaro Peris, Francisco Casacuberta, Petia Radeva", "title": "VIBIKNet: Visual Bidirectional Kernelized Network for Visual Question\n  Answering", "comments": "Submitted to IbPRIA'17, 8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of visual question answering by\nproposing a novel model, called VIBIKNet. Our model is based on integrating\nKernelized Convolutional Neural Networks and Long-Short Term Memory units to\ngenerate an answer given a question about an image. We prove that VIBIKNet is\nan optimal trade-off between accuracy and computational load, in terms of\nmemory and time consumption. We validate our method on the VQA challenge\ndataset and compare it to the top performing methods in order to illustrate its\nperformance and speed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 11:41:46 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Bola\u00f1os", "Marc", ""], ["Peris", "\u00c1lvaro", ""], ["Casacuberta", "Francisco", ""], ["Radeva", "Petia", ""]]}, {"id": "1612.03651", "submitter": "Armand Joulin", "authors": "Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze,\n  H\\'erve J\\'egou, Tomas Mikolov", "title": "FastText.zip: Compressing text classification models", "comments": "Submitted to ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of producing compact architectures for text\nclassification, such that the full model fits in a limited amount of memory.\nAfter considering different solutions inspired by the hashing literature, we\npropose a method built upon product quantization to store word embeddings.\nWhile the original technique leads to a loss in accuracy, we adapt this method\nto circumvent quantization artefacts. Our experiments carried out on several\nbenchmarks show that our approach typically requires two orders of magnitude\nless memory than fastText while being only slightly inferior with respect to\naccuracy. As a result, it outperforms the state of the art by a good margin in\nterms of the compromise between memory usage and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 12:51:03 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Joulin", "Armand", ""], ["Grave", "Edouard", ""], ["Bojanowski", "Piotr", ""], ["Douze", "Matthijs", ""], ["J\u00e9gou", "H\u00e9rve", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1612.03659", "submitter": "Louis Onrust", "authors": "Iris Hendrickx, Louis Onrust, Florian Kunneman, Ali\n  H\\\"urriyeto\\u{g}lu, Antal van den Bosch, Wessel Stoop", "title": "Unraveling reported dreams with text analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate what distinguishes reported dreams from other personal\nnarratives. The continuity hypothesis, stemming from psychological dream\nanalysis work, states that most dreams refer to a person's daily life and\npersonal concerns, similar to other personal narratives such as diary entries.\nDifferences between the two texts may reveal the linguistic markers of dream\ntext, which could be the basis for new dream analysis work and for the\nautomatic detection of dream descriptions. We used three text analytics\nmethods: text classification, topic modeling, and text coherence analysis, and\napplied these methods to a balanced set of texts representing dreams, diary\nentries, and other personal stories. We observed that dream texts could be\ndistinguished from other personal narratives nearly perfectly, mostly based on\nthe presence of uncertainty markers and descriptions of scenes. Important\nmarkers for non-dream narratives are specific time expressions and\nconversational expressions. Dream texts also exhibit a lower discourse\ncoherence than other personal narratives.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 13:08:55 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Hendrickx", "Iris", ""], ["Onrust", "Louis", ""], ["Kunneman", "Florian", ""], ["H\u00fcrriyeto\u011flu", "Ali", ""], ["Bosch", "Antal van den", ""], ["Stoop", "Wessel", ""]]}, {"id": "1612.03762", "submitter": "Margherita Zorzi", "authors": "Carlo Combi, Margherita Zorzi, Gabriele Pozzani, Ugo Moretti", "title": "From narrative descriptions to MedDRA: automagically encoding adverse\n  drug reactions", "comments": "arXiv admin note: substantial text overlap with arXiv:1506.08052", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collection of narrative spontaneous reports is an irreplaceable source\nfor the prompt detection of suspected adverse drug reactions (ADRs): qualified\ndomain experts manually revise a huge amount of narrative descriptions and then\nencode texts according to MedDRA standard terminology. The manual annotation of\nnarrative documents with medical terminology is a subtle and expensive task,\nsince the number of reports is growing up day-by-day. MagiCoder, a Natural\nLanguage Processing algorithm, is proposed for the automatic encoding of\nfree-text descriptions into MedDRA terms. MagiCoder procedure is efficient in\nterms of computational complexity (in particular, it is linear in the size of\nthe narrative input and the terminology). We tested it on a large dataset of\nabout 4500 manually revised reports, by performing an automated comparison\nbetween human and MagiCoder revisions. For the current base version of\nMagiCoder, we measured: on short descriptions, an average recall of $86\\%$ and\nan average precision of $88\\%$; on medium-long descriptions (up to 255\ncharacters), an average recall of $64\\%$ and an average precision of $63\\%$.\nFrom a practical point of view, MagiCoder reduces the time required for\nencoding ADR reports. Pharmacologists have simply to review and validate the\nMagiCoder terms proposed by the application, instead of choosing the right\nterms among the 70K low level terms of MedDRA. Such improvement in the\nefficiency of pharmacologists' work has a relevant impact also on the quality\nof the subsequent data analysis. We developed MagiCoder for the Italian\npharmacovigilance language. However, our proposal is based on a general\napproach, not depending on the considered language nor the term dictionary.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 16:14:02 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Combi", "Carlo", ""], ["Zorzi", "Margherita", ""], ["Pozzani", "Gabriele", ""], ["Moretti", "Ugo", ""]]}, {"id": "1612.03769", "submitter": "Yushi Yao", "authors": "Yushi Yao, Guangjian Li", "title": "Context-aware Sentiment Word Identification: sentiword2vec", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional sentiment analysis often uses sentiment dictionary to extract\nsentiment information in text and classify documents. However, emerging\ninformal words and phrases in user generated content call for analysis aware to\nthe context. Usually, they have special meanings in a particular context.\nBecause of its great performance in representing inter-word relation, we use\nsentiment word vectors to identify the special words. Based on the distributed\nlanguage model word2vec, in this paper we represent a novel method about\nsentiment representation of word under particular context, to be detailed, to\nidentify the words with abnormal sentiment polarity in long answers. Result\nshows the improved model shows better performance in representing the words\nwith special meaning, while keep doing well in representing special idiomatic\npattern. Finally, we will discuss the meaning of vectors representing in the\nfield of sentiment, which may be different from general object-based\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 16:25:08 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Yao", "Yushi", ""], ["Li", "Guangjian", ""]]}, {"id": "1612.03791", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg and Adri\\`a de Gispert and Eva Hasler and Bill Byrne", "title": "Neural Machine Translation by Minimising the Bayes-risk with Respect to\n  Syntactic Translation Lattices", "comments": "EACL2017 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel scheme to combine neural machine translation (NMT) with\ntraditional statistical machine translation (SMT). Our approach borrows ideas\nfrom linearised lattice minimum Bayes-risk decoding for SMT. The NMT score is\ncombined with the Bayes-risk of the translation according the SMT lattice. This\nmakes our approach much more flexible than $n$-best list or lattice rescoring\nas the neural decoder is not restricted to the SMT search space. We show an\nefficient and simple way to integrate risk estimation into the NMT decoder\nwhich is suitable for word-level as well as subword-unit-level NMT. We test our\nmethod on English-German and Japanese-English and report significant gains over\nlattice rescoring on several data sets for both single and ensembled NMT. The\nMBR decoder produces entirely new hypotheses far beyond simply rescoring the\nSMT search space or fixing UNKs in the NMT output.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 17:12:44 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 14:29:34 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Stahlberg", "Felix", ""], ["de Gispert", "Adri\u00e0", ""], ["Hasler", "Eva", ""], ["Byrne", "Bill", ""]]}, {"id": "1612.03929", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar, Pascal Poupart, Xin Jiang, Hang Li", "title": "Deep Active Learning for Dialogue Generation", "comments": "Accepted at 6th Joint Conference on Lexical and Computational\n  Semantics (*SEM) 2017 (Previously titled \"Online Sequence-to-Sequence Active\n  Learning for Open-Domain Dialogue Generation\" on ArXiv)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online, end-to-end, neural generative conversational model for\nopen-domain dialogue. It is trained using a unique combination of offline\ntwo-phase supervised learning and online human-in-the-loop active learning.\nWhile most existing research proposes offline supervision or hand-crafted\nreward functions for online reinforcement, we devise a novel interactive\nlearning mechanism based on hamming-diverse beam search for response generation\nand one-character user-feedback at each step. Experiments show that our model\ninherently promotes the generation of semantically relevant and interesting\nresponses, and can be used to train agents with customized personas, moods and\nconversational styles.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 21:19:51 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 01:58:21 GMT"}, {"version": "v3", "created": "Fri, 16 Dec 2016 20:44:43 GMT"}, {"version": "v4", "created": "Wed, 1 Feb 2017 18:19:50 GMT"}, {"version": "v5", "created": "Fri, 16 Jun 2017 14:08:31 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Asghar", "Nabiha", ""], ["Poupart", "Pascal", ""], ["Jiang", "Xin", ""], ["Li", "Hang", ""]]}, {"id": "1612.03969", "submitter": "Mikael Henaff", "authors": "Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes and Yann\n  LeCun", "title": "Tracking the World State with Recurrent Entity Networks", "comments": null, "journal-ref": "ICLR 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new model, the Recurrent Entity Network (EntNet). It is\nequipped with a dynamic long-term memory which allows it to maintain and update\na representation of the state of the world as it receives new data. For\nlanguage understanding tasks, it can reason on-the-fly as it reads text, not\njust when it is required to answer a question or respond as is the case for a\nMemory Network (Sukhbaatar et al., 2015). Like a Neural Turing Machine or\nDifferentiable Neural Computer (Graves et al., 2014; 2016) it maintains a fixed\nsize memory and can learn to perform location and content-based read and write\noperations. However, unlike those models it has a simple parallel architecture\nin which several memory locations can be updated simultaneously. The EntNet\nsets a new state-of-the-art on the bAbI tasks, and is the first method to solve\nall the tasks in the 10k training examples setting. We also demonstrate that it\ncan solve a reasoning task which requires a large number of supporting facts,\nwhich other methods are not able to solve, and can generalize past its training\nhorizon. It can also be practically used on large scale datasets such as\nChildren's Book Test, where it obtains competitive performance, reading the\nstory in a single pass.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 23:29:40 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 03:05:14 GMT"}, {"version": "v3", "created": "Wed, 10 May 2017 16:52:56 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Henaff", "Mikael", ""], ["Weston", "Jason", ""], ["Szlam", "Arthur", ""], ["Bordes", "Antoine", ""], ["LeCun", "Yann", ""]]}, {"id": "1612.03975", "submitter": "Robyn Speer", "authors": "Robyn Speer, Joshua Chin and Catherine Havasi", "title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge", "comments": null, "journal-ref": "AAAI 31 (2017) 4444-4451", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning about language can be improved by supplying it with specific\nknowledge and sources of external information. We present here a new version of\nthe linked open data resource ConceptNet that is particularly well suited to be\nused with modern NLP techniques such as word embeddings.\n  ConceptNet is a knowledge graph that connects words and phrases of natural\nlanguage with labeled edges. Its knowledge is collected from many sources that\ninclude expert-created resources, crowd-sourcing, and games with a purpose. It\nis designed to represent the general knowledge involved in understanding\nlanguage, improving natural language applications by allowing the application\nto better understand the meanings behind the words people use.\n  When ConceptNet is combined with word embeddings acquired from distributional\nsemantics (such as word2vec), it provides applications with understanding that\nthey would not acquire from distributional semantics alone, nor from narrower\nresources such as WordNet or DBPedia. We demonstrate this with state-of-the-art\nresults on intrinsic evaluations of word relatedness that translate into\nimprovements on applications of word vectors, including solving SAT-style\nanalogies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 23:54:52 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 16:27:17 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Speer", "Robyn", ""], ["Chin", "Joshua", ""], ["Havasi", "Catherine", ""]]}, {"id": "1612.03990", "submitter": "Xiang Kong", "authors": "Xiang Kong, Jeung-Yoon Choi, Stefanie Shattuck-Hufnagel", "title": "Evaluating Automatic Speech Recognition Systems in Comparison With Human\n  Perception Results Using Distinctive Feature Measures", "comments": "ICASSP 2017", "journal-ref": "ICASSP 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes methods for evaluating automatic speech recognition\n(ASR) systems in comparison with human perception results, using measures\nderived from linguistic distinctive features. Error patterns in terms of\nmanner, place and voicing are presented, along with an examination of confusion\nmatrices via a distinctive-feature-distance metric. These evaluation methods\ncontrast with conventional performance criteria that focus on the phone or word\nlevel, and are intended to provide a more detailed profile of ASR system\nperformance,as well as a means for direct comparison with human perception\nresults at the sub-phonemic level.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 01:18:39 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Kong", "Xiang", ""], ["Choi", "Jeung-Yoon", ""], ["Shattuck-Hufnagel", "Stefanie", ""]]}, {"id": "1612.03991", "submitter": "Xiang Kong", "authors": "Xiang Kong, Preethi Jyothi, Mark Hasegawa-Johnson", "title": "Performance Improvements of Probabilistic Transcript-adapted ASR with\n  Recurrent Neural Network and Language-specific Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mismatched transcriptions have been proposed as a mean to acquire\nprobabilistic transcriptions from non-native speakers of a language.Prior work\nhas demonstrated the value of these transcriptions by successfully adapting\ncross-lingual ASR systems for different tar-get languages. In this work, we\ndescribe two techniques to refine these probabilistic transcriptions: a\nnoisy-channel model of non-native phone misperception is trained using a\nrecurrent neural net-work, and decoded using minimally-resourced\nlanguage-dependent pronunciation constraints. Both innovations improve quality\nof the transcript, and both innovations reduce phone error rate of a\ntrainedASR, by 7% and 9% respectively\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 01:25:14 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Kong", "Xiang", ""], ["Jyothi", "Preethi", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "1612.04061", "submitter": "Aditya Singh", "authors": "Aditya Singh, Saurabh Saini, Rajvi Shah, PJ Narayanan", "title": "Learning to Hash-tag Videos with Tag2Vec", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  User-given tags or labels are valuable resources for semantic understanding\nof visual media such as images and videos. Recently, a new type of labeling\nmechanism known as hash-tags have become increasingly popular on social media\nsites. In this paper, we study the problem of generating relevant and useful\nhash-tags for short video clips. Traditional data-driven approaches for tag\nenrichment and recommendation use direct visual similarity for label transfer\nand propagation. We attempt to learn a direct low-cost mapping from video to\nhash-tags using a two step training process. We first employ a natural language\nprocessing (NLP) technique, skip-gram models with neural network training to\nlearn a low-dimensional vector representation of hash-tags (Tag2Vec) using a\ncorpus of 10 million hash-tags. We then train an embedding function to map\nvideo features to the low-dimensional Tag2vec space. We learn this embedding\nfor 29 categories of short video clips with hash-tags. A query video without\nany tag-information can then be directly mapped to the vector space of tags\nusing the learned embedding and relevant tags can be found by performing a\nsimple nearest-neighbor retrieval in the Tag2Vec space. We validate the\nrelevance of the tags suggested by our system qualitatively and quantitatively\nwith a user study.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 08:32:02 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Singh", "Aditya", ""], ["Saini", "Saurabh", ""], ["Shah", "Rajvi", ""], ["Narayanan", "PJ", ""]]}, {"id": "1612.04113", "submitter": "Gustavo Henrique Paetzold", "authors": "Gustavo Henrique Paetzold and Lucia Specia", "title": "Vicinity-Driven Paragraph and Sentence Alignment for Comparable Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel corpora have driven great progress in the field of Text\nSimplification. However, most sentence alignment algorithms either offer a\nlimited range of alignment types supported, or simply ignore valuable clues\npresent in comparable documents. We address this problem by introducing a new\nset of flexible vicinity-driven paragraph and sentence alignment algorithms\nthat 1-N, N-1, N-N and long distance null alignments without the need for\nhard-to-replicate supervised models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 12:03:39 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Paetzold", "Gustavo Henrique", ""], ["Specia", "Lucia", ""]]}, {"id": "1612.04118", "submitter": "pmeerkamp", "authors": "Philipp Meerkamp (Bloomberg LP) and Zhengyi Zhou (AT&T Labs Research)", "title": "Information Extraction with Character-level Neural Networks and Free\n  Noisy Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an architecture for information extraction from text that augments\nan existing parser with a character-level neural network. The network is\ntrained using a measure of consistency of extracted data with existing\ndatabases as a form of noisy supervision. Our architecture combines the ability\nof constraint-based information extraction systems to easily incorporate domain\nknowledge and constraints with the ability of deep neural networks to leverage\nlarge amounts of data to learn complex features. Boosting the existing parser's\nprecision, the system led to large improvements over a mature and highly tuned\nconstraint-based production information extraction system used at Bloomberg for\nfinancial language text.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 12:12:20 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 01:01:28 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Meerkamp", "Philipp", "", "Bloomberg LP"], ["Zhou", "Zhengyi", "", "AT&T Labs Research"]]}, {"id": "1612.04174", "submitter": "Bruno Nicenboim", "authors": "Bruno Nicenboim and Shravan Vasishth", "title": "Models of retrieval in sentence comprehension: A computational\n  evaluation using Bayesian hierarchical modeling", "comments": "Accepted in Journal of Memory and Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on interference has provided evidence that the formation of\ndependencies between non-adjacent words relies on a cue-based retrieval\nmechanism. Two different models can account for one of the main predictions of\ninterference, i.e., a slowdown at a retrieval site, when several items share a\nfeature associated with a retrieval cue: Lewis and Vasishth's (2005)\nactivation-based model and McElree's (2000) direct access model. Even though\nthese two models have been used almost interchangeably, they are based on\ndifferent assumptions and predict differences in the relationship between\nreading times and response accuracy. The activation-based model follows the\nassumptions of ACT-R, and its retrieval process behaves as a lognormal race\nbetween accumulators of evidence with a single variance. Under this model,\naccuracy of the retrieval is determined by the winner of the race and retrieval\ntime by its rate of accumulation. In contrast, the direct access model assumes\na model of memory where only the probability of retrieval varies between items;\nin this model, differences in latencies are a by-product of the possibility and\nrepairing incorrect retrievals. We implemented both models in a Bayesian\nhierarchical framework in order to evaluate them and compare them. We show that\nsome aspects of the data are better fit under the direct access model than\nunder the activation-based model. We suggest that this finding does not rule\nout the possibility that retrieval may be behaving as a race model with\nassumptions that follow less closely the ones from the ACT-R framework. We show\nthat by introducing a modification of the activation model, i.e, by assuming\nthat the accumulation of evidence for retrieval of incorrect items is not only\nslower but noisier (i.e., different variances for the correct and incorrect\nitems), the model can provide a fit as good as the one of the direct access\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 13:55:39 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 11:05:55 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Nicenboim", "Bruno", ""], ["Vasishth", "Shravan", ""]]}, {"id": "1612.04211", "submitter": "Zhiguo Wang", "authors": "Zhiguo Wang, Haitao Mi, Wael Hamza and Radu Florian", "title": "Multi-Perspective Context Matching for Machine Comprehension", "comments": "8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous machine comprehension (MC) datasets are either too small to train\nend-to-end deep learning models, or not difficult enough to evaluate the\nability of current MC techniques. The newly released SQuAD dataset alleviates\nthese limitations, and gives us a chance to develop more realistic MC models.\nBased on this dataset, we propose a Multi-Perspective Context Matching (MPCM)\nmodel, which is an end-to-end system that directly predicts the answer\nbeginning and ending points in a passage. Our model first adjusts each\nword-embedding vector in the passage by multiplying a relevancy weight computed\nagainst the question. Then, we encode the question and weighted passage by\nusing bi-directional LSTMs. For each point in the passage, our model matches\nthe context of this point against the encoded question from multiple\nperspectives and produces a matching vector. Given those matched vectors, we\nemploy another bi-directional LSTM to aggregate all the information and predict\nthe beginning and ending points. Experimental result on the test set of SQuAD\nshows that our model achieves a competitive result on the leaderboard.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 14:49:47 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Wang", "Zhiguo", ""], ["Mi", "Haitao", ""], ["Hamza", "Wael", ""], ["Florian", "Radu", ""]]}, {"id": "1612.04342", "submitter": "Radu Soricut", "authors": "Radu Soricut and Nan Ding", "title": "Building Large Machine Reading-Comprehension Datasets using Paragraph\n  Vectors", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dual contribution to the task of machine reading-comprehension:\na technique for creating large-sized machine-comprehension (MC) datasets using\nparagraph-vector models; and a novel, hybrid neural-network architecture that\ncombines the representation power of recurrent neural networks with the\ndiscriminative power of fully-connected multi-layered networks. We use the\nMC-dataset generation technique to build a dataset of around 2 million\nexamples, for which we empirically determine the high-ceiling of human\nperformance (around 91% accuracy), as well as the performance of a variety of\ncomputer models. Among all the models we have experimented with, our hybrid\nneural-network architecture achieves the highest performance (83.2% accuracy).\nThe remaining gap to the human-performance ceiling provides enough room for\nfuture model improvements.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 20:22:36 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Soricut", "Radu", ""], ["Ding", "Nan", ""]]}, {"id": "1612.04403", "submitter": "Mason Bretan", "authors": "Mason Bretan", "title": "You Are What You Eat... Listen to, Watch, and Read", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a data driven method for deriving the relationship\nbetween personality and media preferences. A qunatifiable representation of\nsuch a relationship can be leveraged for use in recommendation systems and\nameliorate the \"cold start\" problem. Here, the data is comprised of an original\ncollection of 1,316 Okcupid dating profiles. Of these profiles, 800 are labeled\nwith one of 16 possible Myers-Briggs Type Indicators (MBTI). A personality\nspecific topic model describing a person's favorite books, movies, shows,\nmusic, and food was generated using latent Dirichlet allocation (LDA). There\nwere several significant findings, for example, intuitive thinking types\npreferred sci-fi/fantasy entertainment, extraversion correlated positively with\nupbeat dance music, and jazz, folk, and international cuisine correlated\npositively with those characterized by openness to experience. Many other\ncorrelations confirmed previous findings describing the relationship among\npersonality, writing style, and personal preferences. (For complete\nword/personality type assocations see the Appendix).\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 21:29:05 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Bretan", "Mason", ""]]}, {"id": "1612.04418", "submitter": "Alexey Drutsa", "authors": "Alexey Drutsa (Yandex, Moscow, Russia), Andrey Shutovich (Yandex,\n  Moscow, Russia), Philipp Pushnyakov (Yandex, Moscow, Russia), Evgeniy\n  Krokhalyov (Yandex, Moscow, Russia), Gleb Gusev (Yandex, Moscow, Russia),\n  Pavel Serdyukov (Yandex, Moscow, Russia)", "title": "User Model-Based Intent-Aware Metrics for Multilingual Search Evaluation", "comments": "7 pages, 1 figure, 3 tables", "journal-ref": "NIPS 2016 Workshop \"What If? Inference and Learning of\n  Hypothetical and Counterfactual Interventions in Complex Systems\" (What If\n  2016) pre-print", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing importance of multilingual aspect of web search, no\nappropriate offline metrics to evaluate its quality are proposed so far. At the\nsame time, personal language preferences can be regarded as intents of a query.\nThis approach translates the multilingual search problem into a particular task\nof search diversification. Furthermore, the standard intent-aware approach\ncould be adopted to build a diversified metric for multilingual search on the\nbasis of a classical IR metric such as ERR. The intent-aware approach estimates\nuser satisfaction under a user behavior model. We show however that the\nunderlying user behavior models is not realistic in the multilingual case, and\nthe produced intent-aware metric do not appropriately estimate the user\nsatisfaction. We develop a novel approach to build intent-aware user behavior\nmodels, which overcome these limitations and convert to quality metrics that\nbetter correlate with standard online metrics of user satisfaction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 22:09:24 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Drutsa", "Alexey", "", "Yandex, Moscow, Russia"], ["Shutovich", "Andrey", "", "Yandex,\n  Moscow, Russia"], ["Pushnyakov", "Philipp", "", "Yandex, Moscow, Russia"], ["Krokhalyov", "Evgeniy", "", "Yandex, Moscow, Russia"], ["Gusev", "Gleb", "", "Yandex, Moscow, Russia"], ["Serdyukov", "Pavel", "", "Yandex, Moscow, Russia"]]}, {"id": "1612.04426", "submitter": "Edouard Grave", "authors": "Edouard Grave, Armand Joulin, Nicolas Usunier", "title": "Improving Neural Language Models with a Continuous Cache", "comments": "Submitted to ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension to neural network language models to adapt their\nprediction to the recent history. Our model is a simplified version of memory\naugmented networks, which stores past hidden activations as memory and accesses\nthem through a dot product with the current hidden activation. This mechanism\nis very efficient and scales to very large memory sizes. We also draw a link\nbetween the use of external memory in neural network and cache models used with\ncount based language models. We demonstrate on several language model datasets\nthat our approach performs significantly better than recent memory augmented\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 23:09:49 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1612.04460", "submitter": "Vered Shwartz", "authors": "Vered Shwartz, Enrico Santus, and Dominik Schlechtweg", "title": "Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy\n  Detection", "comments": "EACL 2017. 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental role of hypernymy in NLP has motivated the development of\nmany methods for the automatic identification of this relation, most of which\nrely on word distribution. We investigate an extensive number of such\nunsupervised measures, using several distributional semantic models that differ\nby context type and feature weighting. We analyze the performance of the\ndifferent methods based on their linguistic motivation. Comparison to the\nstate-of-the-art supervised methods shows that while supervised methods\ngenerally outperform the unsupervised ones, the former are sensitive to the\ndistribution of training instances, hurting their reliability. Being based on\ngeneral linguistic hypotheses and independent from training data, unsupervised\nmeasures are more robust, and therefore are still useful artillery for\nhypernymy detection.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 02:28:29 GMT"}, {"version": "v2", "created": "Sun, 8 Jan 2017 08:41:18 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Shwartz", "Vered", ""], ["Santus", "Enrico", ""], ["Schlechtweg", "Dominik", ""]]}, {"id": "1612.04499", "submitter": "Hu Xu", "authors": "Hu Xu, Lei Shu, Jingyuan Zhang, Philip S. Yu", "title": "Mining Compatible/Incompatible Entities from Question and Answering via\n  Yes/No Answer Classification using Distant Label Expansion", "comments": "9 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product Community Question Answering (PCQA) provides useful information about\nproducts and their features (aspects) that may not be well addressed by product\ndescriptions and reviews. We observe that a product's compatibility issues with\nother products are frequently discussed in PCQA and such issues are more\nfrequently addressed in accessories, i.e., via a yes/no question \"Does this\nmouse work with windows 10?\". In this paper, we address the problem of\nextracting compatible and incompatible products from yes/no questions in PCQA.\nThis problem can naturally have a two-stage framework: first, we perform\nComplementary Entity (product) Recognition (CER) on yes/no questions; second,\nwe identify the polarities of yes/no answers to assign the complementary\nentities a compatibility label (compatible, incompatible or unknown). We\nleverage an existing unsupervised method for the first stage and a 3-class\nclassifier by combining a distant PU-learning method (learning from positive\nand unlabeled examples) together with a binary classifier for the second stage.\nThe benefit of using distant PU-learning is that it can help to expand more\nimplicit yes/no answers without using any human annotated data. We conduct\nexperiments on 4 products to show that the proposed method is effective.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 06:05:39 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Xu", "Hu", ""], ["Shu", "Lei", ""], ["Zhang", "Jingyuan", ""], ["Yu", "Philip S.", ""]]}, {"id": "1612.04538", "submitter": "Gayatri Bhat", "authors": "Gayatri Bhat and Monojit Choudhury and Kalika Bali", "title": "Grammatical Constraints on Intra-sentential Code-Switching: From\n  Theories to Working Models", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make one of the first attempts to build working models for\nintra-sentential code-switching based on the Equivalence-Constraint (Poplack\n1980) and Matrix-Language (Myers-Scotton 1993) theories. We conduct a detailed\ntheoretical analysis, and a small-scale empirical study of the two models for\nHindi-English CS. Our analyses show that the models are neither sound nor\ncomplete. Taking insights from the errors made by the models, we propose a new\nmodel that combines features of both the theories.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 09:00:21 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Bhat", "Gayatri", ""], ["Choudhury", "Monojit", ""], ["Bali", "Kalika", ""]]}, {"id": "1612.04609", "submitter": "Ruobing Xie", "authors": "Ruobing Xie, Zhiyuan Liu, Rui Yan, Maosong Sun", "title": "Neural Emoji Recommendation in Dialogue Systems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emoji is an essential component in dialogues which has been broadly utilized\non almost all social platforms. It could express more delicate feelings beyond\nplain texts and thus smooth the communications between users, making dialogue\nsystems more anthropomorphic and vivid. In this paper, we focus on\nautomatically recommending appropriate emojis given the contextual information\nin multi-turn dialogue systems, where the challenges locate in understanding\nthe whole conversations. More specifically, we propose the hierarchical long\nshort-term memory model (H-LSTM) to construct dialogue representations,\nfollowed by a softmax classifier for emoji classification. We evaluate our\nmodels on the task of emoji classification in a real-world dataset, with some\nfurther explorations on parameter sensitivity and case study. Experimental\nresults demonstrate that our method achieves the best performances on all\nevaluation metrics. It indicates that our method could well capture the\ncontextual information and emotion flow in dialogues, which is significant for\nemoji recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 12:46:18 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Xie", "Ruobing", ""], ["Liu", "Zhiyuan", ""], ["Yan", "Rui", ""], ["Sun", "Maosong", ""]]}, {"id": "1612.04629", "submitter": "Rico Sennrich", "authors": "Rico Sennrich", "title": "How Grammatical is Character-level Neural Machine Translation? Assessing\n  MT Quality with Contrastive Translation Pairs", "comments": "accepted at EACL 2017 (v3: minor fix to table 6 description)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing translation quality in regards to specific linguistic phenomena has\nhistorically been difficult and time-consuming. Neural machine translation has\nthe attractive property that it can produce scores for arbitrary translations,\nand we propose a novel method to assess how well NMT systems model specific\nlinguistic phenomena such as agreement over long distances, the production of\nnovel words, and the faithful translation of polarity. The core idea is that we\nmeasure whether a reference translation is more probable under a NMT model than\na contrastive translation which introduces a specific type of error. We present\nLingEval97, a large-scale data set of 97000 contrastive translation pairs based\non the WMT English->German translation task, with errors automatically created\nwith simple rules. We report results for a number of systems, and find that\nrecently introduced character-level NMT systems perform better at\ntransliteration than models with byte-pair encoding (BPE) segmentation, but\nperform more poorly at morphosyntactic agreement, and translating discontiguous\nunits of meaning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 13:45:35 GMT"}, {"version": "v2", "created": "Tue, 7 Feb 2017 09:51:20 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 09:59:05 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Sennrich", "Rico", ""]]}, {"id": "1612.04675", "submitter": "Peidong Wang", "authors": "Peidong Wang, Zhongqiu Wang, Deliang Wang", "title": "Recurrent Deep Stacking Networks for Speech Recognition", "comments": "The project was discontinued", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presented our work on applying Recurrent Deep Stacking Networks\n(RDSNs) to Robust Automatic Speech Recognition (ASR) tasks. In the paper, we\nalso proposed a more efficient yet comparable substitute to RDSN, Bi- Pass\nStacking Network (BPSN). The main idea of these two models is to add\nphoneme-level information into acoustic models, transforming an acoustic model\nto the combination of an acoustic model and a phoneme-level N-gram model.\nExperiments showed that RDSN and BPsn can substantially improve the\nperformances over conventional DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 15:07:51 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:20:50 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Peidong", ""], ["Wang", "Zhongqiu", ""], ["Wang", "Deliang", ""]]}, {"id": "1612.04683", "submitter": "Mauro Cettolo", "authors": "Mauro Cettolo, Mara Chinea Rios, Roldano Cattoni", "title": "Unsupervised Clustering of Commercial Domains for Adaptive Machine\n  Translation", "comments": "9 pages report on Summer Internship at FBK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report on domain clustering in the ambit of an adaptive MT\narchitecture. A standard bottom-up hierarchical clustering algorithm has been\ninstantiated with five different distances, which have been compared, on an MT\nbenchmark built on 40 commercial domains, in terms of dendrograms, intrinsic\nand extrinsic evaluations. The main outcome is that the most expensive distance\nis also the only one able to allow the MT engine to guarantee good performance\neven with few, but highly populated clusters of domains.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 15:21:48 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Cettolo", "Mauro", ""], ["Rios", "Mara Chinea", ""], ["Cattoni", "Roldano", ""]]}, {"id": "1612.04732", "submitter": "Radu Soricut", "authors": "Radu Soricut and Nan Ding", "title": "Multilingual Word Embeddings using Multigraphs", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of neural-network--inspired models for computing\ncontinuous word representations, specifically designed to exploit both\nmonolingual and multilingual text. This framework allows us to perform\nunsupervised training of embeddings that exhibit higher accuracy on syntactic\nand semantic compositionality, as well as multilingual semantic similarity,\ncompared to previous models trained in an unsupervised fashion. We also show\nthat such multilingual embeddings, optimized for semantic similarity, can\nimprove the performance of statistical machine translation with respect to how\nit handles words not present in the parallel data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 17:13:01 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Soricut", "Radu", ""], ["Ding", "Nan", ""]]}, {"id": "1612.04744", "submitter": "Peidong Wang", "authors": "Peidong Wang, Deliang Wang", "title": "Incorporating Language Level Information into Acoustic Models", "comments": "The project was discontinued", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed a class of novel Deep Recurrent Neural Networks which can\nincorporate language-level information into acoustic models. For simplicity, we\nnamed these networks Recurrent Deep Language Networks (RDLNs). Multiple\nvariants of RDLNs were considered, including two kinds of context information,\ntwo methods to process the context, and two methods to incorporate the\nlanguage-level information. RDLNs provided possible methods to fine-tune the\nwhole Automatic Speech Recognition (ASR) system in the acoustic modeling\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 17:40:02 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:20:33 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Peidong", ""], ["Wang", "Deliang", ""]]}, {"id": "1612.04757", "submitter": "Marcus Rohrbach", "authors": "Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Bernt Schiele,\n  Trevor Darrell, Marcus Rohrbach", "title": "Attentive Explanations: Justifying Decisions and Pointing to the\n  Evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models are the defacto standard in visual decision models due to their\nimpressive performance on a wide array of visual tasks. However, they are\nfrequently seen as opaque and are unable to explain their decisions. In\ncontrast, humans can justify their decisions with natural language and point to\nthe evidence in the visual world which led to their decisions. We postulate\nthat deep models can do this as well and propose our Pointing and Justification\n(PJ-X) model which can justify its decision with a sentence and point to the\nevidence by introspecting its decision and explanation process using an\nattention mechanism. Unfortunately there is no dataset available with reference\nexplanations for visual decision making. We thus collect two datasets in two\ndomains where it is interesting and challenging to explain decisions. First, we\nextend the visual question answering task to not only provide an answer but\nalso a natural language explanation for the answer. Second, we focus on\nexplaining human activities which is traditionally more challenging than object\nclassification. We extensively evaluate our PJ-X model, both on the\njustification and pointing tasks, by comparing it to prior models and ablations\nusing both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 18:12:47 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 09:33:03 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Park", "Dong Huk", ""], ["Hendricks", "Lisa Anne", ""], ["Akata", "Zeynep", ""], ["Schiele", "Bernt", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1612.04765", "submitter": "Uwe Reichel", "authors": "Uwe D. Reichel", "title": "CoPaSul Manual -- Contour-based parametric and superpositional\n  intonation stylization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purposes of the CoPaSul toolkit are (1) automatic prosodic annotation and\n(2) prosodic feature extraction from syllable to utterance level. CoPaSul\nstands for contour-based, parametric, superpositional intonation stylization.\nIn this framework intonation is represented as a superposition of global and\nlocal contours that are described parametrically in terms of polynomial\ncoefficients. On the global level (usually associated but not necessarily\nrestricted to intonation phrases) the stylization serves to represent register\nin terms of time-varying F0 level and range. On the local level (e.g. accent\ngroups), local contour shapes are described. From this parameterization several\nfeatures related to prosodic boundaries and prominence can be derived.\nFurthermore, by coefficient clustering prosodic contour classes can be obtained\nin a bottom-up way. Next to the stylization-based feature extraction also\nstandard F0 and energy measures (e.g. mean and variance) as well as rhythmic\naspects can be calculated. At the current state automatic annotation comprises:\nsegmentation into interpausal chunks, syllable nucleus extraction, and\nunsupervised localization of prosodic phrase boundaries and prominent\nsyllables. F0 and partly also energy feature sets can be derived for: standard\nmeasurements (as median and IQR), register in terms of F0 level and range,\nprosodic boundaries, local contour shapes, bottom-up derived contour classes,\nGestalt of accent groups in terms of their deviation from higher level prosodic\nunits, as well as for rhythmic aspects quantifying the relation between F0 and\nenergy contours and prosodic event rates.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 18:37:30 GMT"}, {"version": "v10", "created": "Fri, 10 Jul 2020 09:49:48 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 17:51:44 GMT"}, {"version": "v3", "created": "Tue, 31 Jan 2017 11:38:19 GMT"}, {"version": "v4", "created": "Mon, 19 Jun 2017 17:29:32 GMT"}, {"version": "v5", "created": "Mon, 20 Nov 2017 15:44:33 GMT"}, {"version": "v6", "created": "Wed, 10 Jan 2018 15:29:40 GMT"}, {"version": "v7", "created": "Tue, 31 Jul 2018 11:12:42 GMT"}, {"version": "v8", "created": "Mon, 17 Sep 2018 09:29:37 GMT"}, {"version": "v9", "created": "Sun, 28 Oct 2018 11:39:16 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Reichel", "Uwe D.", ""]]}, {"id": "1612.04868", "submitter": "I\\~nigo Lopez-Gazpio", "authors": "I. Lopez-Gazpio and M. Maritxalar and A. Gonzalez-Agirre and G. Rigau\n  and L. Uria and E. Agirre", "title": "Interpretable Semantic Textual Similarity: Finding and explaining\n  differences between sentences", "comments": "Preprint version, Knowledge-Based Systems (ISSN: 0950-7051). (2016)", "journal-ref": null, "doi": "10.1016/j.knosys.2016.12.013", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User acceptance of artificial intelligence agents might depend on their\nability to explain their reasoning, which requires adding an interpretability\nlayer that fa- cilitates users to understand their behavior. This paper focuses\non adding an in- terpretable layer on top of Semantic Textual Similarity (STS),\nwhich measures the degree of semantic equivalence between two sentences. The\ninterpretability layer is formalized as the alignment between pairs of segments\nacross the two sentences, where the relation between the segments is labeled\nwith a relation type and a similarity score. We present a publicly available\ndataset of sentence pairs annotated following the formalization. We then\ndevelop a system trained on this dataset which, given a sentence pair, explains\nwhat is similar and different, in the form of graded and typed segment\nalignments. When evaluated on the dataset, the system performs better than an\ninformed baseline, showing that the dataset and task are well-defined and\nfeasible. Most importantly, two user studies show how the system output can be\nused to automatically produce explanations in natural language. Users performed\nbetter when having access to the explanations, pro- viding preliminary evidence\nthat our dataset and method to automatically produce explanations is useful in\nreal applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 22:22:33 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Lopez-Gazpio", "I.", ""], ["Maritxalar", "M.", ""], ["Gonzalez-Agirre", "A.", ""], ["Rigau", "G.", ""], ["Uria", "L.", ""], ["Agirre", "E.", ""]]}, {"id": "1612.04936", "submitter": "Jason  Weston", "authors": "Jiwei Li, Alexander H. Miller, Sumit Chopra, Marc'Aurelio Ranzato,\n  Jason Weston", "title": "Learning through Dialogue Interactions by Asking Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good dialogue agent should have the ability to interact with users by both\nresponding to questions and by asking questions, and importantly to learn from\nboth types of interaction. In this work, we explore this direction by designing\na simulator and a set of synthetic tasks in the movie domain that allow such\ninteractions between a learner and a teacher. We investigate how a learner can\nbenefit from asking questions in both offline and online reinforcement learning\nsettings, and demonstrate that the learner improves when asking questions.\nFinally, real experiments with Mechanical Turk validate the approach. Our work\nrepresents a first step in developing such end-to-end learned interactive\ndialogue agents.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 05:46:27 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 19:47:12 GMT"}, {"version": "v3", "created": "Fri, 13 Jan 2017 21:07:04 GMT"}, {"version": "v4", "created": "Mon, 13 Feb 2017 17:30:42 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Li", "Jiwei", ""], ["Miller", "Alexander H.", ""], ["Chopra", "Sumit", ""], ["Ranzato", "Marc'Aurelio", ""], ["Weston", "Jason", ""]]}, {"id": "1612.04949", "submitter": "Yang Yang", "authors": "Hao Liu, Yang Yang, Fumin Shen, Lixin Duan and Heng Tao Shen", "title": "Recurrent Image Captioner: Describing Images with Spatial-Invariant\n  Transformation and Attention Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the prosperity of recurrent neural network in modelling sequential\ndata and the power of attention mechanism in automatically identify salient\ninformation, image captioning, a.k.a., image description, has been remarkably\nadvanced in recent years. Nonetheless, most existing paradigms may suffer from\nthe deficiency of invariance to images with different scaling, rotation, etc.;\nand effective integration of standalone attention to form a holistic end-to-end\nsystem. In this paper, we propose a novel image captioning architecture, termed\nRecurrent Image Captioner (\\textbf{RIC}), which allows visual encoder and\nlanguage decoder to coherently cooperate in a recurrent manner. Specifically,\nwe first equip CNN-based visual encoder with a differentiable layer to enable\nspatially invariant transformation of visual signals. Moreover, we deploy an\nattention filter module (differentiable) between encoder and decoder to\ndynamically determine salient visual parts. We also employ bidirectional LSTM\nto preprocess sentences for generating better textual representations. Besides,\nwe propose to exploit variational inference to optimize the whole architecture.\nExtensive experimental results on three benchmark datasets (i.e., Flickr8k,\nFlickr30k and MS COCO) demonstrate the superiority of our proposed architecture\nas compared to most of the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 07:19:46 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Liu", "Hao", ""], ["Yang", "Yang", ""], ["Shen", "Fumin", ""], ["Duan", "Lixin", ""], ["Shen", "Heng Tao", ""]]}, {"id": "1612.04988", "submitter": "Maya Ramanath", "authors": "Prajna Upadhyay and Tanuma Patra and Ashwini Purkar and Maya Ramanath", "title": "TeKnowbase: Towards Construction of a Knowledge-base of Technical\n  Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the construction of TeKnowbase, a knowledge-base\nof technical concepts in computer science. Our main information sources are\ntechnical websites such as Webopedia and Techtarget as well as Wikipedia and\nonline textbooks. We divide the knowledge-base construction problem into two\nparts -- the acquisition of entities and the extraction of relationships among\nthese entities. Our knowledge-base consists of approximately 100,000 triples.\nWe conducted an evaluation on a sample of triples and report an accuracy of a\nlittle over 90\\%. We additionally conducted classification experiments on\nStackOverflow data with features from TeKnowbase and achieved improved\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 09:14:35 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Upadhyay", "Prajna", ""], ["Patra", "Tanuma", ""], ["Purkar", "Ashwini", ""], ["Ramanath", "Maya", ""]]}, {"id": "1612.05131", "submitter": "Fuxiang Wu", "authors": "Fugen Zhou, Fuxiang Wu, Zhengchen Zhang, Minghui Dong", "title": "Transition-based Parsing with Context Enhancement and Future Reward\n  Reranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel reranking model, future reward reranking, to\nre-score the actions in a transition-based parser by using a global scorer.\nDifferent to conventional reranking parsing, the model searches for the best\ndependency tree in all feasible trees constraining by a sequence of actions to\nget the future reward of the sequence. The scorer is based on a first-order\ngraph-based parser with bidirectional LSTM, which catches different parsing\nview compared with the transition-based parser. Besides, since context\nenhancement has shown substantial improvement in the arc-stand transition-based\nparsing over the parsing accuracy, we implement context enhancement on an\narc-eager transition-base parser with stack LSTMs, the dynamic oracle and\ndropout supporting and achieve further improvement. With the global scorer and\ncontext enhancement, the results show that UAS of the parser increases as much\nas 1.20% for English and 1.66% for Chinese, and LAS increases as much as 1.32%\nfor English and 1.63% for Chinese. Moreover, we get state-of-the-art LASs,\nachieving 87.58% for Chinese and 93.37% for English.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 16:30:11 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Zhou", "Fugen", ""], ["Wu", "Fuxiang", ""], ["Zhang", "Zhengchen", ""], ["Dong", "Minghui", ""]]}, {"id": "1612.05202", "submitter": "Mickael Rouvier", "authors": "Mickael Rouvier, Benoit Favre", "title": "Building a robust sentiment lexicon with (almost) no resource", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating sentiment polarity lexicons is labor intensive. Automatically\ntranslating them from resourceful languages requires in-domain machine\ntranslation systems, which rely on large quantities of bi-texts. In this paper,\nwe propose to replace machine translation by transferring words from the\nlexicon through word embeddings aligned across languages with a simple linear\ntransform. The approach leads to no degradation, compared to machine\ntranslation, when tested on sentiment polarity classification on tweets from\nfour languages.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 19:28:17 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Rouvier", "Mickael", ""], ["Favre", "Benoit", ""]]}, {"id": "1612.05251", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Peter Szolovits", "title": "Neural Networks for Joint Sentence Classification in Medical Paper\n  Abstracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models based on artificial neural networks (ANNs) for sentence\nclassification often do not incorporate the context in which sentences appear,\nand classify sentences individually. However, traditional sentence\nclassification approaches have been shown to greatly benefit from jointly\nclassifying subsequent sentences, such as with conditional random fields. In\nthis work, we present an ANN architecture that combines the effectiveness of\ntypical ANN models to classify sentences in isolation, with the strength of\nstructured prediction. Our model achieves state-of-the-art results on two\ndifferent datasets for sequential sentence classification in medical abstracts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 20:57:56 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Szolovits", "Peter", ""]]}, {"id": "1612.05270", "submitter": "Daniela Moctezuma", "authors": "Eric S. Tellez, Sabino Miranda Jim\\'enez, Mario Graff, Daniela\n  Moctezuma, Ranyart R. Su\\'arez, Oscar S. Siordia", "title": "A Simple Approach to Multilingual Polarity Classification in Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, sentiment analysis has received a lot of attention due to the\ninterest in mining opinions of social media users. Sentiment analysis consists\nin determining the polarity of a given text, i.e., its degree of positiveness\nor negativeness. Traditionally, Sentiment Analysis algorithms have been\ntailored to a specific language given the complexity of having a number of\nlexical variations and errors introduced by the people generating content. In\nthis contribution, our aim is to provide a simple to implement and easy to use\nmultilingual framework, that can serve as a baseline for sentiment analysis\ncontests, and as starting point to build new sentiment analysis systems. We\ncompare our approach in eight different languages, three of them have important\ninternational contests, namely, SemEval (English), TASS (Spanish), and\nSENTIPOLC (Italian). Within the competitions our approach reaches from medium\nto high positions in the rankings; whereas in the remaining languages our\napproach outperforms the reported results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 21:07:12 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Tellez", "Eric S.", ""], ["Jim\u00e9nez", "Sabino Miranda", ""], ["Graff", "Mario", ""], ["Moctezuma", "Daniela", ""], ["Su\u00e1rez", "Ranyart R.", ""], ["Siordia", "Oscar S.", ""]]}, {"id": "1612.05310", "submitter": "Luis Gerardo Mojica de la Vega", "authors": "Luis Gerardo Mojica", "title": "Modeling Trolling in Social Media Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media websites, electronic newspapers and Internet forums allow\nvisitors to leave comments for others to read and interact. This exchange is\nnot free from participants with malicious intentions, who troll others by\npositing messages that are intended to be provocative, offensive, or menacing.\nWith the goal of facilitating the computational modeling of trolling, we\npropose a trolling categorization that is novel in the sense that it allows\ncomment-based analysis from both the trolls' and the responders' perspectives,\ncharacterizing these two perspectives using four aspects, namely, the troll's\nintention and his intention disclosure, as well as the responder's\ninterpretation of the troll's intention and her response strategy. Using this\ncategorization, we annotate and release a dataset containing excerpts of Reddit\nconversations involving suspected trolls and their interactions with other\nusers. Finally, we identify the difficult-to-classify cases in our corpus and\nsuggest potential solutions for them.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 23:41:13 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 16:36:17 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Mojica", "Luis Gerardo", ""]]}, {"id": "1612.05340", "submitter": "Jey Han Lau", "authors": "Shraey Bhatia, Jey Han Lau, Timothy Baldwin", "title": "Automatic Labelling of Topics with Neural Embeddings", "comments": "11 pages, 3 figures, published in COLING2016", "journal-ref": "Proceedings of the 26th International Conference on Computational\n  Linguistics (COLING 2016), pp 953--963", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topics generated by topic models are typically represented as list of terms.\nTo reduce the cognitive overhead of interpreting these topics for end-users, we\npropose labelling a topic with a succinct phrase that summarises its theme or\nidea. Using Wikipedia document titles as label candidates, we compute neural\nembeddings for documents and words to select the most relevant labels for\ntopics. Compared to a state-of-the-art topic labelling system, our methodology\nis simpler, more efficient, and finds better topic labels.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 02:49:53 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 01:51:41 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Bhatia", "Shraey", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1612.05348", "submitter": "Ndapandula Nakashole", "authors": "Ndapandula Nakashole, Tom M. Mitchell", "title": "Machine Reading with Background Knowledge", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent systems capable of automatically understanding natural language\ntext are important for many artificial intelligence applications including\nmobile phone voice assistants, computer vision, and robotics. Understanding\nlanguage often constitutes fitting new information into a previously acquired\nview of the world. However, many machine reading systems rely on the text alone\nto infer its meaning. In this paper, we pursue a different approach; machine\nreading methods that make use of background knowledge to facilitate language\nunderstanding. To this end, we have developed two methods: The first method\naddresses prepositional phrase attachment ambiguity. It uses background\nknowledge within a semi-supervised machine learning algorithm that learns from\nboth labeled and unlabeled data. This approach yields state-of-the-art results\non two datasets against strong baselines; The second method extracts\nrelationships from compound nouns. Our knowledge-aware method for compound noun\nanalysis accurately extracts relationships and significantly outperforms a\nbaseline that does not make use of background knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 03:33:07 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Nakashole", "Ndapandula", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "1612.05420", "submitter": "Arkanath Pathak", "authors": "Arkanath Pathak, Pawan Goyal and Plaban Bhowmick", "title": "A Two-Phase Approach Towards Identifying Argument Structure in Natural\n  Language", "comments": "Presented at NLPTEA 2016, held in conjunction with COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new approach for extracting argument structure from natural\nlanguage texts that contain an underlying argument. Our approach comprises of\ntwo phases: Score Assignment and Structure Prediction. The Score Assignment\nphase trains models to classify relations between argument units (Support,\nAttack or Neutral). To that end, different training strategies have been\nexplored. We identify different linguistic and lexical features for training\nthe classifiers. Through ablation study, we observe that our novel use of\nword-embedding features is most effective for this task. The Structure\nPrediction phase makes use of the scores from the Score Assignment phase to\narrive at the optimal structure. We perform experiments on three argumentation\ndatasets, namely, AraucariaDB, Debatepedia and Wikipedia. We also propose two\nbaselines and observe that the proposed approach outperforms baseline systems\nfor the final task of Structure Prediction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 10:39:53 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Pathak", "Arkanath", ""], ["Goyal", "Pawan", ""], ["Bhowmick", "Plaban", ""]]}, {"id": "1612.05555", "submitter": "\\'Alvaro Peris", "authors": "\\'Alvaro Peris, Mara Chinea-Rios and Francisco Casacuberta", "title": "Neural Networks Classifier for Data Selection in Statistical Machine\n  Translation", "comments": "Submitted to EACL'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the data selection problem in statistical machine translation\n(SMT) as a classification task. The new data selection method is based on a\nneural network classifier. We present a new method description and empirical\nresults proving that our data selection method provides better translation\nquality, compared to a state-of-the-art method (i.e., Cross entropy). Moreover,\nthe empirical results reported are coherent across different language pairs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 17:00:37 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 09:17:20 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Peris", "\u00c1lvaro", ""], ["Chinea-Rios", "Mara", ""], ["Casacuberta", "Francisco", ""]]}, {"id": "1612.05688", "submitter": "Xiujun Li", "authors": "Xiujun Li, Zachary C. Lipton, Bhuwan Dhingra, Lihong Li, Jianfeng Gao,\n  Yun-Nung Chen", "title": "A User Simulator for Task-Completion Dialogues", "comments": "14 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite widespread interests in reinforcement-learning for task-oriented\ndialogue systems, several obstacles can frustrate research and development\nprogress. First, reinforcement learners typically require interaction with the\nenvironment, so conventional dialogue corpora cannot be used directly. Second,\neach task presents specific challenges, requiring separate corpus of\ntask-specific annotated data. Third, collecting and annotating human-machine or\nhuman-human conversations for task-oriented dialogues requires extensive domain\nknowledge. Because building an appropriate dataset can be both financially\ncostly and time-consuming, one popular approach is to build a user simulator\nbased upon a corpus of example dialogues. Then, one can train reinforcement\nlearning agents in an online fashion as they interact with the simulator.\nDialogue agents trained on these simulators can serve as an effective starting\npoint. Once agents master the simulator, they may be deployed in a real\nenvironment to interact with humans, and continue to be trained online. To ease\nempirical algorithmic comparisons in dialogues, this paper introduces a new,\npublicly available simulation framework, where our simulator, designed for the\nmovie-booking domain, leverages both rules and collected data. The simulator\nsupports two tasks: movie ticket booking and movie seeking. Finally, we\ndemonstrate several agents and detail the procedure to add and test your own\nagent in the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2016 01:03:55 GMT"}, {"version": "v2", "created": "Thu, 5 Jan 2017 20:04:30 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 05:52:42 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Li", "Xiujun", ""], ["Lipton", "Zachary C.", ""], ["Dhingra", "Bhuwan", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1612.05734", "submitter": "Valentina Franzoni", "authors": "Valentina Franzoni, Giulio Biondi, Alfredo Milani, Yuanxi Li", "title": "Web-based Semantic Similarity for Emotion Recognition in Web Objects", "comments": "Authors preprint, including revision differences with respect to the\n  main publication 'Web-based Similarity for Emotion Recognition in Web\n  Objects' published in the UCC '16 workshop in IEEE UCC, December 06 - 09,\n  2016, Shanghai, China. DOI: http://dx.doi.org/10.1145/2996890.3007883", "journal-ref": "In Proc 9th International Conference on Utility and Cloud\n  Computing (UCC 2016). ACM, New York, NY, USA, 327-332", "doi": "10.1145/2996890.3007883", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project we propose a new approach for emotion recognition using\nweb-based similarity (e.g. confidence, PMI and PMING). We aim to extract basic\nemotions from short sentences with emotional content (e.g. news titles, tweets,\ncaptions), performing a web-based quantitative evaluation of semantic proximity\nbetween each word of the analyzed sentence and each emotion of a psychological\nmodel (e.g. Plutchik, Ekman, Lovheim). The phases of the extraction include:\ntext preprocessing (tokenization, stop words, filtering), search engine\nautomated query, HTML parsing of results (i.e. scraping), estimation of\nsemantic proximity, ranking of emotions according to proximity measures. The\nmain idea is that, since it is possible to generalize semantic similarity under\nthe assumption that similar concepts co-occur in documents indexed in search\nengines, therefore also emotions can be generalized in the same way, through\ntags or terms that express them in a particular language, ranking emotions.\nTraining results are compared to human evaluation, then additional comparative\ntests on results are performed, both for the global ranking correlation (e.g.\nKendall, Spearman, Pearson) both for the evaluation of the emotion linked to\neach single word. Different from sentiment analysis, our approach works at a\ndeeper level of abstraction, aiming at recognizing specific emotions and not\nonly the positive/negative sentiment, in order to predict emotions as semantic\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2016 11:36:06 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Franzoni", "Valentina", ""], ["Biondi", "Giulio", ""], ["Milani", "Alfredo", ""], ["Li", "Yuanxi", ""]]}, {"id": "1612.06027", "submitter": "Ryan Cotterell Ryan D Cotterell", "authors": "Katharina Kann and Ryan Cotterell and Hinrich Sch\\\"utze", "title": "Neural Multi-Source Morphological Reinflection", "comments": "Accepted at EACL 2017. Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the task of multi-source morphological reinflection, which\ngeneralizes the standard, single-source version. The input consists of (i) a\ntarget tag and (ii) multiple pairs of source form and source tag for a lemma.\nThe motivation is that it is beneficial to have access to more than one source\nform since different source forms can provide complementary information, e.g.,\ndifferent stems. We further present a novel extension to the encoder- decoder\nrecurrent neural architecture, consisting of multiple encoders, to better solve\nthe task. We show that our new architecture outperforms single-source\nreinflection models and publish our dataset for multi-source morphological\nreinflection to facilitate future research.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 02:21:24 GMT"}, {"version": "v2", "created": "Mon, 26 Dec 2016 06:22:45 GMT"}, {"version": "v3", "created": "Sun, 22 Jan 2017 09:30:10 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Kann", "Katharina", ""], ["Cotterell", "Ryan", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1612.06043", "submitter": "Raphael Shu", "authors": "Raphael Shu and Hideki Nakayama", "title": "An Empirical Study of Adequate Vision Span for Attention-Based Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the attention mechanism plays a key role to achieve high\nperformance for Neural Machine Translation models. However, as it computes a\nscore function for the encoder states in all positions at each decoding step,\nthe attention model greatly increases the computational complexity. In this\npaper, we investigate the adequate vision span of attention models in the\ncontext of machine translation, by proposing a novel attention framework that\nis capable of reducing redundant score computation dynamically. The term\n\"vision span\" means a window of the encoder states considered by the attention\nmodel in one step. In our experiments, we found that the average window size of\nvision span can be reduced by over 50% with modest loss in accuracy on\nEnglish-Japanese and German-English translation tasks.% This results indicate\nthat the conventional attention mechanism performs a significant amount of\nredundant computation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 04:23:22 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2016 01:43:35 GMT"}, {"version": "v3", "created": "Mon, 17 Apr 2017 05:58:12 GMT"}, {"version": "v4", "created": "Thu, 8 Jun 2017 07:52:36 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Shu", "Raphael", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1612.06062", "submitter": "Ganesh J", "authors": "Ganesh J, Manish Gupta and Vasudeva Varma", "title": "Improving Tweet Representations using Temporal and User Context", "comments": "To be presented at European Conference on Information Retrieval\n  (ECIR) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel representation learning model which computes\nsemantic representations for tweets accurately. Our model systematically\nexploits the chronologically adjacent tweets ('context') from users' Twitter\ntimelines for this task. Further, we make our model user-aware so that it can\ndo well in modeling the target tweet by exploiting the rich knowledge about the\nuser such as the way the user writes the post and also summarizing the topics\non which the user writes. We empirically demonstrate that the proposed models\noutperform the state-of-the-art models in predicting the user profile\nattributes like spouse, education and job by 19.66%, 2.27% and 2.22%\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 07:06:34 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["J", "Ganesh", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1612.06138", "submitter": "Josep Crego", "authors": "Dakun Zhang and Jungi Kim and Josep Crego and Jean Senellart", "title": "Boosting Neural Machine Translation", "comments": "published in IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training efficiency is one of the main problems for Neural Machine\nTranslation (NMT). Deep networks need for very large data as well as many\ntraining iterations to achieve state-of-the-art performance. This results in\nvery high computation cost, slowing down research and industrialisation. In\nthis paper, we propose to alleviate this problem with several training methods\nbased on data boosting and bootstrap with no modifications to the neural\nnetwork. It imitates the learning process of humans, which typically spend more\ntime when learning \"difficult\" concepts than easier ones. We experiment on an\nEnglish-French translation task showing accuracy improvements of up to 1.63\nBLEU while saving 20% of training time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 11:49:49 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 11:46:04 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Zhang", "Dakun", ""], ["Kim", "Jungi", ""], ["Crego", "Josep", ""], ["Senellart", "Jean", ""]]}, {"id": "1612.06139", "submitter": "Josep Crego", "authors": "Josep Crego and Jean Senellart", "title": "Neural Machine Translation from Simplified Translations", "comments": "Submitted to EACL 2017 Short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text simplification aims at reducing the lexical, grammatical and structural\ncomplexity of a text while keeping the same meaning. In the context of machine\ntranslation, we introduce the idea of simplified translations in order to boost\nthe learning ability of deep neural translation models. We conduct preliminary\nexperiments showing that translation complexity is actually reduced in a\ntranslation of a source bi-text compared to the target reference of the bi-text\nwhile using a neural machine translation (NMT) system learned on the exact same\nbi-text. Based on knowledge distillation idea, we then train an NMT system\nusing the simplified bi-text, and show that it outperforms the initial system\nthat was built over the reference data set. Performance is further boosted when\nboth reference and automatic translations are used to learn the network. We\nperform an elementary analysis of the translated corpus and report accuracy\nresults of the proposed approach on English-to-French and English-to-German\ntranslation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 11:50:58 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Crego", "Josep", ""], ["Senellart", "Jean", ""]]}, {"id": "1612.06140", "submitter": "Josep Crego", "authors": "Catherine Kobus and Josep Crego and Jean Senellart", "title": "Domain Control for Neural Machine Translation", "comments": "Published in RANLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation systems are very sensitive to the domains they were\ntrained on. Several domain adaptation techniques have been deeply studied. We\npropose a new technique for neural machine translation (NMT) that we call\ndomain control which is performed at runtime using a unique neural network\ncovering multiple domains. The presented approach shows quality improvements\nwhen compared to dedicated domains translating on any of the covered domains\nand even on out-of-domain data. In addition, model parameters do not need to be\nre-estimated for each domain, making this effective to real use cases.\nEvaluation is carried out on English-to-French translation for two different\ntesting scenarios. We first consider the case where an end-user performs\ntranslations on a known domain. Secondly, we consider the scenario where the\ndomain is not known and predicted at the sentence level before translating.\nResults show consistent accuracy improvements for both conditions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 11:51:35 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 12:01:40 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Kobus", "Catherine", ""], ["Crego", "Josep", ""], ["Senellart", "Jean", ""]]}, {"id": "1612.06141", "submitter": "Josep Crego", "authors": "Christophe Servan and Josep Crego and Jean Senellart", "title": "Domain specialization: a post-training domain adaptation for Neural\n  Machine Translation", "comments": "Submitted to EACL 2017 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is a key feature in Machine Translation. It generally\nencompasses terminology, domain and style adaptation, especially for human\npost-editing workflows in Computer Assisted Translation (CAT). With Neural\nMachine Translation (NMT), we introduce a new notion of domain adaptation that\nwe call \"specialization\" and which is showing promising results both in the\nlearning speed and in adaptation accuracy. In this paper, we propose to explore\nthis approach under several perspectives.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 11:52:08 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Servan", "Christophe", ""], ["Crego", "Josep", ""], ["Senellart", "Jean", ""]]}, {"id": "1612.06212", "submitter": "Thomas Laurent", "authors": "Thomas Laurent and James von Brecht", "title": "A recurrent neural network without chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exceptionally simple gated recurrent neural network (RNN)\nthat achieves performance comparable to well-known gated architectures, such as\nLSTMs and GRUs, on the word-level language modeling task. We prove that our\nmodel has simple, predicable and non-chaotic dynamics. This stands in stark\ncontrast to more standard gated architectures, whose underlying dynamical\nsystems exhibit chaotic behavior.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 14:59:14 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Laurent", "Thomas", ""], ["von Brecht", "James", ""]]}, {"id": "1612.06391", "submitter": "Chenhao Tan", "authors": "Chenhao Tan, Lillian Lee", "title": "Talk it up or play it down? (Un)expected correlations between\n  (de-)emphasis and recurrence of discussion points in consequential U.S.\n  economic policy meetings", "comments": "14 pages, 18 figures, presented at Text as Data 2016, data and more\n  at https://chenhaot.com/pages/de-emphasis-fomc.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In meetings where important decisions get made, what items receive more\nattention may influence the outcome. We examine how different types of\nrhetorical (de-)emphasis -- including hedges, superlatives, and contrastive\nconjunctions -- correlate with what gets revisited later, controlling for item\nfrequency and speaker. Our data consists of transcripts of recurring meetings\nof the Federal Reserve's Open Market Committee (FOMC), where important aspects\nof U.S. monetary policy are decided on. Surprisingly, we find that words\nappearing in the context of hedging, which is usually considered a way to\nexpress uncertainty, are more likely to be repeated in subsequent meetings,\nwhile strong emphasis indicated by superlatives has a slightly negative effect\non word recurrence in subsequent meetings. We also observe interesting patterns\nin how these effects vary depending on social factors such as status and gender\nof the speaker. For instance, the positive effects of hedging are more\npronounced for female speakers than for male speakers.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 21:00:02 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Tan", "Chenhao", ""], ["Lee", "Lillian", ""]]}, {"id": "1612.06475", "submitter": "James Cross", "authors": "James Cross and Liang Huang", "title": "Span-Based Constituency Parsing with a Structure-Label System and\n  Provably Optimal Dynamic Oracles", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing accuracy using efficient greedy transition systems has improved\ndramatically in recent years thanks to neural networks. Despite striking\nresults in dependency parsing, however, neural models have not surpassed\nstate-of-the-art approaches in constituency parsing. To remedy this, we\nintroduce a new shift-reduce system whose stack contains merely sentence spans,\nrepresented by a bare minimum of LSTM features. We also design the first\nprovably optimal dynamic oracle for constituency parsing, which runs in\namortized O(1) time, compared to O(n^3) oracles for standard dependency\nparsing. Training with this oracle, we achieve the best F1 scores on both\nEnglish and French of any parser that does not use reranking or external data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 01:23:00 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Cross", "James", ""], ["Huang", "Liang", ""]]}, {"id": "1612.06530", "submitter": "Shaodi You", "authors": "Shijie Zhang, Lizhen Qu, Shaodi You, Zhenglu Yang, Jiawan Zhang", "title": "Automatic Generation of Grounded Visual Questions", "comments": "VQA", "journal-ref": "IJCAI 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the first model to be able to generate visually\ngrounded questions with diverse types for a single image. Visual question\ngeneration is an emerging topic which aims to ask questions in natural language\nbased on visual input. To the best of our knowledge, it lacks automatic methods\nto generate meaningful questions with various types for the same visual input.\nTo circumvent the problem, we propose a model that automatically generates\nvisually grounded questions with varying types. Our model takes as input both\nimages and the captions generated by a dense caption model, samples the most\nprobable question types, and generates the questions in sequel. The\nexperimental results on two real world datasets show that our model outperforms\nthe strongest baseline in terms of both correctness and diversity with a wide\nmargin.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 07:20:16 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 12:54:35 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Zhang", "Shijie", ""], ["Qu", "Lizhen", ""], ["You", "Shaodi", ""], ["Yang", "Zhenglu", ""], ["Zhang", "Jiawan", ""]]}, {"id": "1612.06549", "submitter": "Heike Adel", "authors": "Heike Adel and Hinrich Sch\\\"utze", "title": "Exploring Different Dimensions of Attention for Uncertainty Detection", "comments": "accepted at EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with attention have proven effective for many natural\nlanguage processing tasks. In this paper, we develop attention mechanisms for\nuncertainty detection. In particular, we generalize standardly used attention\nmechanisms by introducing external attention and sequence-preserving attention.\nThese novel architectures differ from standard approaches in that they use\nexternal resources to compute attention weights and preserve sequence\ninformation. We compare them to other configurations along different dimensions\nof attention. Our novel architectures set the new state of the art on a\nWikipedia benchmark dataset and perform similar to the state-of-the-art model\non a biomedical benchmark which uses a large set of linguistic features.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 08:49:59 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 14:56:03 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Adel", "Heike", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1612.06572", "submitter": "Tomas Brychcin", "authors": "Tom\\'a\\v{s} Brychc\\'in and Pavel Kr\\'al", "title": "Unsupervised Dialogue Act Induction using Gaussian Mixtures", "comments": "Accepted to EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new unsupervised approach for dialogue act induction.\nGiven the sequence of dialogue utterances, the task is to assign them the\nlabels representing their function in the dialogue.\n  Utterances are represented as real-valued vectors encoding their meaning. We\nmodel the dialogue as Hidden Markov model with emission probabilities estimated\nby Gaussian mixtures. We use Gibbs sampling for posterior inference.\n  We present the results on the standard Switchboard-DAMSL corpus. Our\nalgorithm achieves promising results compared with strong supervised baselines\nand outperforms other unsupervised algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 09:52:36 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 13:01:04 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Brychc\u00edn", "Tom\u00e1\u0161", ""], ["Kr\u00e1l", "Pavel", ""]]}, {"id": "1612.06581", "submitter": "C. Maria Keet", "authors": "C. Maria Keet and Langa Khumalo", "title": "Grammar rules for the isiZulu complex verb", "comments": "21 pages, submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The isiZulu verb is known for its morphological complexity, which is a\nsubject for on-going linguistics research, as well as for prospects of\ncomputational use, such as controlled natural language interfaces, machine\ntranslation, and spellcheckers. To this end, we seek to answer the question as\nto what the precise grammar rules for the isiZulu complex verb are (and, by\nextension, the Bantu verb morphology). To this end, we iteratively specify the\ngrammar as a Context Free Grammar, and evaluate it computationally. The grammar\npresented in this paper covers the subject and object concords, negation,\npresent tense, aspect, mood, and the causative, applicative, stative, and the\nreciprocal verbal extensions, politeness, the wh-question modifiers, and aspect\ndoubling, ensuring their correct order as they appear in verbs. The grammar\nconforms to specification.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 10:10:34 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Keet", "C. Maria", ""], ["Khumalo", "Langa", ""]]}, {"id": "1612.06671", "submitter": "Jussi Karlgren", "authors": "Max Berggren, Jussi Karlgren, Robert \\\"Ostling, and Mikael Parkvall", "title": "Inferring the location of authors from words in their texts", "comments": "8 pages. Presented at NoDaLiDa: the 2015 Nordic Conference on\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the purposes of computational dialectology or other geographically bound\ntext analysis tasks, texts must be annotated with their or their authors'\nlocation. Many texts are locatable through explicit labels but most have no\nexplicit annotation of place. This paper describes a series of experiments to\ndetermine how positionally annotated microblog posts can be used to learn\nlocation-indicating words which then can be used to locate blog texts and their\nauthors. A Gaussian distribution is used to model the locational qualities of\nwords. We introduce the notion of placeness to describe how locational words\nare.\n  We find that modelling word distributions to account for several locations\nand thus several Gaussian distributions per word, defining a filter which picks\nout words with high placeness based on their local distributional context, and\naggregating locational information in a centroid for each text gives the most\nuseful results. The results are applied to data in the Swedish language.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 14:13:38 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Berggren", "Max", ""], ["Karlgren", "Jussi", ""], ["\u00d6stling", "Robert", ""], ["Parkvall", "Mikael", ""]]}, {"id": "1612.06685", "submitter": "Konstantinos Pappas", "authors": "Konstantinos Pappas, Steven Wilson, and Rada Mihalcea", "title": "Stateology: State-Level Interactive Charting of Language, Feelings, and\n  Values", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People's personality and motivations are manifest in their everyday language\nusage. With the emergence of social media, ample examples of such usage are\nprocurable. In this paper, we aim to analyze the vocabulary used by close to\n200,000 Blogger users in the U.S. with the purpose of geographically portraying\nvarious demographic, linguistic, and psychological dimensions at the state\nlevel. We give a description of a web-based tool for viewing maps that depict\nvarious characteristics of the social media users as derived from this large\nblog dataset of over two billion words.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 14:44:19 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Pappas", "Konstantinos", ""], ["Wilson", "Steven", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1612.06778", "submitter": "Vivek Gupta", "authors": "Dheeraj Mekala, Vivek Gupta, Bhargavi Paranjape, Harish Karnick", "title": "SCDV : Sparse Composite Document Vectors using soft clustering over\n  distributional representations", "comments": "10 pages, 5 figures. Update: Added results on Information Retrieval\n  and Topic Coherence with Discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a feature vector formation technique for documents - Sparse\nComposite Document Vector (SCDV) - which overcomes several shortcomings of the\ncurrent distributional paragraph vector representations that are widely used\nfor text representation. In SCDV, word embedding's are clustered to capture\nmultiple semantic contexts in which words occur. They are then chained together\nto form document topic-vectors that can express complex, multi-topic documents.\nThrough extensive experiments on multi-class and multi-label classification\ntasks, we outperform the previous state-of-the-art method, NTSG (Liu et al.,\n2015a). We also show that SCDV embedding's perform well on heterogeneous tasks\nlike Topic Coherence, context-sensitive Learning and Information Retrieval.\nMoreover, we achieve significant reduction in training and prediction times\ncompared to other representation methods. SCDV achieves best of both worlds -\nbetter performance with lower time and space complexity.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 17:38:57 GMT"}, {"version": "v2", "created": "Sun, 8 Jan 2017 17:26:54 GMT"}, {"version": "v3", "created": "Fri, 12 May 2017 09:48:04 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Mekala", "Dheeraj", ""], ["Gupta", "Vivek", ""], ["Paranjape", "Bhargavi", ""], ["Karnick", "Harish", ""]]}, {"id": "1612.06821", "submitter": "Vivek Gupta", "authors": "Rahul Wadbude, Vivek Gupta, Dheeraj Mekala, Harish Karnick", "title": "User Bias Removal in Review Score Prediction", "comments": "6 Pages, 3 Figures, Under Review. Update : Added more baselines\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Review score prediction of text reviews has recently gained a lot of\nattention in recommendation systems. A major problem in models for review score\nprediction is the presence of noise due to user-bias in review scores. We\npropose two simple statistical methods to remove such noise and improve review\nscore prediction. Compared to other methods that use multiple classifiers, one\nfor each user, our model uses a single global classifier to predict review\nscores. We empirically evaluate our methods on two major categories\n(\\textit{Electronics} and \\textit{Movies and TV}) of the SNAP published Amazon\ne-Commerce Reviews data-set and Amazon \\textit{Fine Food} reviews data-set. We\nobtain improved review score prediction for three commonly used text feature\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 19:39:59 GMT"}, {"version": "v2", "created": "Fri, 12 May 2017 10:15:43 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Wadbude", "Rahul", ""], ["Gupta", "Vivek", ""], ["Mekala", "Dheeraj", ""], ["Karnick", "Harish", ""]]}, {"id": "1612.06890", "submitter": "Justin Johnson", "authors": "Justin Johnson and Bharath Hariharan and Laurens van der Maaten and Li\n  Fei-Fei and C. Lawrence Zitnick and Ross Girshick", "title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary\n  Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When building artificial intelligence systems that can reason and answer\nquestions about visual data, we need diagnostic tests to analyze our progress\nand discover shortcomings. Existing benchmarks for visual question answering\ncan help, but have strong biases that models can exploit to correctly answer\nquestions without reasoning. They also conflate multiple sources of error,\nmaking it hard to pinpoint model weaknesses. We present a diagnostic dataset\nthat tests a range of visual reasoning abilities. It contains minimal biases\nand has detailed annotations describing the kind of reasoning each question\nrequires. We use this dataset to analyze a variety of modern visual reasoning\nsystems, providing novel insights into their abilities and limitations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 21:40:40 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Johnson", "Justin", ""], ["Hariharan", "Bharath", ""], ["van der Maaten", "Laurens", ""], ["Fei-Fei", "Li", ""], ["Zitnick", "C. Lawrence", ""], ["Girshick", "Ross", ""]]}, {"id": "1612.06897", "submitter": "Markus Freitag", "authors": "Markus Freitag and Yaser Al-Onaizan", "title": "Fast Domain Adaptation for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) is a new approach for automatic translation\nof text from one human language into another. The basic concept in NMT is to\ntrain a large Neural Network that maximizes the translation performance on a\ngiven parallel corpus. NMT is gaining popularity in the research community\nbecause it outperformed traditional SMT approaches in several translation tasks\nat WMT and other evaluation tasks/benchmarks at least for some language pairs.\nHowever, many of the enhancements in SMT over the years have not been\nincorporated into the NMT framework. In this paper, we focus on one such\nenhancement namely domain adaptation. We propose an approach for adapting a NMT\nsystem to a new domain. The main idea behind domain adaptation is that the\navailability of large out-of-domain training data and a small in-domain\ntraining data. We report significant gains with our proposed method in both\nautomatic metrics and a human subjective evaluation metric on two language\npairs. With our adaptation method, we show large improvement on the new domain\nwhile the performance of our general domain only degrades slightly. In\naddition, our approach is fast enough to adapt an already trained system to a\nnew domain within few hours without the need to retrain the NMT model on the\ncombined data which usually takes several days/weeks depending on the volume of\nthe data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 22:07:51 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Freitag", "Markus", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1612.07040", "submitter": "Ze Hu", "authors": "Ze Hu, Zhan Zhang, Qing Chen, Haiqin Yang, Decheng Zuo", "title": "A deep learning approach for predicting the quality of online health\n  expert question-answering services", "comments": "Submitted to Journal of Biomedical Informatics journal on Dec 10,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, a growing number of health consumers are asking health-related\nquestions online, at any time and from anywhere, which effectively lowers the\ncost of health care. The most common approach is using online health expert\nquestion-answering (HQA) services, as health consumers are more willing to\ntrust answers from professional physicians. However, these answers can be of\nvarying quality depending on circumstance. In addition, as the available HQA\nservices grow, how to predict the answer quality of HQA services via machine\nlearning becomes increasingly important and challenging. In an HQA service,\nanswers are normally short texts, which are severely affected by the data\nsparsity problem. Furthermore, HQA services lack community features such as\nbest answer and user votes. Therefore, the wisdom of the crowd is not available\nto rate answer quality. To address these problems, in this paper, the\nprediction of HQA answer quality is defined as a classification task. First,\nbased on the characteristics of HQA services and feedback from medical experts,\na standard for HQA service answer quality evaluation is defined. Next, based on\nthe characteristics of HQA services, several novel non-textual features are\nproposed, including surface linguistic features and social features. Finally, a\ndeep belief network (DBN)-based HQA answer quality prediction framework is\nproposed to predict the quality of answers by learning the high-level hidden\nsemantic representation from the physicians' answers. Our results prove that\nthe proposed framework overcomes the problem of overly sparse textual features\nin short text answers and effectively identifies high-quality answers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 10:09:30 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Hu", "Ze", ""], ["Zhang", "Zhan", ""], ["Chen", "Qing", ""], ["Yang", "Haiqin", ""], ["Zuo", "Decheng", ""]]}, {"id": "1612.07130", "submitter": "G\\'abor Berend", "authors": "G\\'abor Berend", "title": "Sparse Coding of Neural Word Embeddings for Multilingual Sequence\n  Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and carefully evaluate a sequence labeling framework\nwhich solely utilizes sparse indicator features derived from dense distributed\nword representations. The proposed model obtains (near) state-of-the art\nperformance for both part-of-speech tagging and named entity recognition for a\nvariety of languages. Our model relies only on a few thousand sparse\ncoding-derived features, without applying any modification of the word\nrepresentations employed for the different tasks. The proposed model has\nfavorable generalization properties as it retains over 89.8% of its average POS\ntagging accuracy when trained at 1.2% of the total available training data,\ni.e.~150 sentences per language.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 14:17:53 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Berend", "G\u00e1bor", ""]]}, {"id": "1612.07182", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Alexander Peysakhovich, Marco Baroni", "title": "Multi-Agent Cooperation and the Emergence of (Natural) Language", "comments": "Accepted at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current mainstream approach to train natural language systems is to\nexpose them to large amounts of text. This passive learning is problematic if\nwe are interested in developing interactive machines, such as conversational\nagents. We propose a framework for language learning that relies on multi-agent\ncommunication. We study this learning in the context of referential games. In\nthese games, a sender and a receiver see a pair of images. The sender is told\none of them is the target and is allowed to send a message from a fixed,\narbitrary vocabulary to the receiver. The receiver must rely on this message to\nidentify the target. Thus, the agents develop their own language interactively\nout of the need to communicate. We show that two networks with simple\nconfigurations are able to learn to coordinate in the referential game. We\nfurther explore how to make changes to the game environment to cause the \"word\nmeanings\" induced in the game to better reflect intuitive semantic properties\nof the images. In addition, we present a simple strategy for grounding the\nagents' code into natural language. Both of these are necessary steps towards\ndeveloping machines that are able to communicate with humans productively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 15:27:06 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 21:40:51 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Peysakhovich", "Alexander", ""], ["Baroni", "Marco", ""]]}, {"id": "1612.07215", "submitter": "Tengfei Ma", "authors": "Tengfei Ma, Tetsuya Nasukawa", "title": "Inverted Bilingual Topic Models for Lexicon Extraction from Non-parallel\n  Data", "comments": "To appear in IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have been successfully applied in lexicon extraction. However,\nmost previous methods are limited to document-aligned data. In this paper, we\ntry to address two challenges of applying topic models to lexicon extraction in\nnon-parallel data: 1) hard to model the word relationship and 2) noisy seed\ndictionary. To solve these two challenges, we propose two new bilingual topic\nmodels to better capture the semantic information of each word while\ndiscriminating the multiple translations in a noisy seed dictionary. We extend\nthe scope of topic models by inverting the roles of \"word\" and \"document\". In\naddition, to solve the problem of noise in seed dictionary, we incorporate the\nprobability of translation selection in our models. Moreover, we also propose\nan effective measure to evaluate the similarity of words in different languages\nand select the optimal translation pairs. Experimental results using real world\ndata demonstrate the utility and efficacy of the proposed models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 16:12:45 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 01:14:04 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Ma", "Tengfei", ""], ["Nasukawa", "Tetsuya", ""]]}, {"id": "1612.07411", "submitter": "Huayu Li", "authors": "Huayu Li, Martin Renqiang Min, Yong Ge, Asim Kadav", "title": "A Context-aware Attention Network for Interactive Question Answering", "comments": "9 pages", "journal-ref": null, "doi": "10.1145/3097983.3098115", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based sequence-to-sequence models in an encoder-decoder\nframework have been successfully applied to solve Question Answering (QA)\nproblems, predicting answers from statements and questions. However, almost all\nprevious models have failed to consider detailed context information and\nunknown states under which systems do not have enough information to answer\ngiven questions. These scenarios with incomplete or ambiguous information are\nvery common in the setting of Interactive Question Answering (IQA). To address\nthis challenge, we develop a novel model, employing context-dependent\nword-level attention for more accurate statement representations and\nquestion-guided sentence-level attention for better context modeling. We also\ngenerate unique IQA datasets to test our model, which will be made publicly\navailable. Employing these attention mechanisms, our model accurately\nunderstands when it can output an answer or when it requires generating a\nsupplementary question for additional input depending on different contexts.\nWhen available, user's feedback is encoded and directly applied to update\nsentence-level attention to infer an answer. Extensive experiments on QA and\nIQA datasets quantitatively demonstrate the effectiveness of our model with\nsignificant improvement over state-of-the-art conventional QA models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 01:25:20 GMT"}, {"version": "v2", "created": "Sun, 3 Sep 2017 21:41:07 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Li", "Huayu", ""], ["Min", "Martin Renqiang", ""], ["Ge", "Yong", ""], ["Kadav", "Asim", ""]]}, {"id": "1612.07486", "submitter": "J\\\"org Tiedemann", "authors": "Robert \\\"Ostling, J\\\"org Tiedemann", "title": "Continuous multilinguality with language vectors", "comments": "In Proceedings of the 15th Conference of the European Chapter of the\n  Association for Computational Linguistics (EACL), Valencia, Spain, April,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing models for multilingual natural language processing (NLP) treat\nlanguage as a discrete category, and make predictions for either one language\nor the other. In contrast, we propose using continuous vector representations\nof language. We show that these can be learned efficiently with a\ncharacter-based neural language model, and used to improve inference about\nlanguage varieties not seen during training. In experiments with 1303 Bible\ntranslations into 990 different languages, we empirically explore the capacity\nof multilingual language models, and also show that the language vectors\ncapture genetic relationships between languages.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 08:29:25 GMT"}, {"version": "v2", "created": "Sun, 19 Mar 2017 18:52:15 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["\u00d6stling", "Robert", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1612.07495", "submitter": "Heike Adel", "authors": "Yadollah Yaghoobzadeh and Heike Adel and Hinrich Sch\\\"utze", "title": "Noise Mitigation for Neural Entity Typing and Relation Extraction", "comments": "EACL 2017; the first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address two different types of noise in information\nextraction models: noise from distant supervision and noise from pipeline input\nfeatures. Our target tasks are entity typing and relation extraction. For the\nfirst noise type, we introduce multi-instance multi-label learning algorithms\nusing neural network models, and apply them to fine-grained entity typing for\nthe first time. This gives our models comparable performance with the\nstate-of-the-art supervised approach which uses global embeddings of entities.\nFor the second noise type, we propose ways to improve the integration of noisy\nentity type predictions into relation extraction. Our experiments show that\nprobabilistic predictions are more robust than discrete predictions and that\njoint training of the two tasks performs best.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 09:05:35 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 15:01:16 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Adel", "Heike", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1612.07600", "submitter": "Aykut Erdem", "authors": "Mert Kilickaya, Aykut Erdem, Nazli Ikizler-Cinbis, Erkut Erdem", "title": "Re-evaluating Automatic Metrics for Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of generating natural language descriptions from images has received\na lot of attention in recent years. Consequently, it is becoming increasingly\nimportant to evaluate such image captioning approaches in an automatic manner.\nIn this paper, we provide an in-depth evaluation of the existing image\ncaptioning metrics through a series of carefully designed experiments.\nMoreover, we explore the utilization of the recently proposed Word Mover's\nDistance (WMD) document metric for the purpose of image captioning. Our\nfindings outline the differences and/or similarities between metrics and their\nrelative robustness by means of extensive correlation, accuracy and distraction\nbased evaluations. Our results also demonstrate that WMD provides strong\nadvantages over other metrics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 14:00:28 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Kilickaya", "Mert", ""], ["Erdem", "Aykut", ""], ["Ikizler-Cinbis", "Nazli", ""], ["Erdem", "Erkut", ""]]}, {"id": "1612.07602", "submitter": "Hai Ye", "authors": "Hai Ye, Wenhan Chao, Zhunchen Luo, Zhoujun Li", "title": "Jointly Extracting Relations with Class Ties via Effective Deep Ranking", "comments": "To appear in ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections between relations in relation extraction, which we call class\nties, are common. In distantly supervised scenario, one entity tuple may have\nmultiple relation facts. Exploiting class ties between relations of one entity\ntuple will be promising for distantly supervised relation extraction. However,\nprevious models are not effective or ignore to model this property. In this\nwork, to effectively leverage class ties, we propose to make joint relation\nextraction with a unified model that integrates convolutional neural network\n(CNN) with a general pairwise ranking framework, in which three novel ranking\nloss functions are introduced. Additionally, an effective method is presented\nto relieve the severe class imbalance problem from NR (not relation) for model\ntraining. Experiments on a widely used dataset show that leveraging class ties\nwill enhance extraction and demonstrate the effectiveness of our model to learn\nclass ties. Our model outperforms the baselines significantly, achieving\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 14:08:08 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 11:15:55 GMT"}, {"version": "v3", "created": "Thu, 13 Apr 2017 08:21:37 GMT"}, {"version": "v4", "created": "Sat, 5 Aug 2017 12:03:18 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Ye", "Hai", ""], ["Chao", "Wenhan", ""], ["Luo", "Zhunchen", ""], ["Li", "Zhoujun", ""]]}, {"id": "1612.07833", "submitter": "Radu Soricut", "authors": "Nan Ding and Sebastian Goodman and Fei Sha and Radu Soricut", "title": "Understanding Image and Text Simultaneously: a Dual Vision-Language\n  Machine Comprehension Task", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new multi-modal task for computer systems, posed as a combined\nvision-language comprehension challenge: identifying the most suitable text\ndescribing a scene, given several similar options. Accomplishing the task\nentails demonstrating comprehension beyond just recognizing \"keywords\" (or\nkey-phrases) and their corresponding visual concepts. Instead, it requires an\nalignment between the representations of the two modalities that achieves a\nvisually-grounded \"understanding\" of various linguistic elements and their\ndependencies. This new task also admits an easy-to-compute and well-studied\nmetric: the accuracy in detecting the true target among the decoys.\n  The paper makes several contributions: an effective and extensible mechanism\nfor generating decoys from (human-created) image captions; an instance of\napplying this mechanism, yielding a large-scale machine comprehension dataset\n(based on the COCO images and captions) that we make publicly available; human\nevaluation results on this dataset, informing a performance upper-bound; and\nseveral baseline and competitive learning approaches that illustrate the\nutility of the proposed task and dataset in advancing both image and language\ncomprehension. We also show that, in a multi-task learning setting, the\nperformance on the proposed task is positively correlated with the end-to-end\ntask of image captioning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 22:44:17 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Ding", "Nan", ""], ["Goodman", "Sebastian", ""], ["Sha", "Fei", ""], ["Soricut", "Radu", ""]]}, {"id": "1612.07843", "submitter": "Wojciech Samek", "authors": "Leila Arras, Franziska Horn, Gr\\'egoire Montavon, Klaus-Robert\n  M\\\"uller, Wojciech Samek", "title": "\"What is Relevant in a Text Document?\": An Interpretable Machine\n  Learning Approach", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0181142", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text documents can be described by a number of abstract concepts such as\nsemantic category, writing style, or sentiment. Machine learning (ML) models\nhave been trained to automatically map documents to these abstract concepts,\nallowing to annotate very large text collections, more than could be processed\nby a human in a lifetime. Besides predicting the text's category very\naccurately, it is also highly desirable to understand how and why the\ncategorization process takes place. In this paper, we demonstrate that such\nunderstanding can be achieved by tracing the classification decision back to\nindividual words using layer-wise relevance propagation (LRP), a recently\ndeveloped technique for explaining predictions of complex non-linear\nclassifiers. We train two word-based ML models, a convolutional neural network\n(CNN) and a bag-of-words SVM classifier, on a topic categorization task and\nadapt the LRP method to decompose the predictions of these models onto words.\nResulting scores indicate how much individual words contribute to the overall\nclassification decision. This enables one to distill relevant information from\ntext documents without an explicit semantic information extraction step. We\nfurther use the word-wise relevance scores for generating novel vector-based\ndocument representations which capture semantic information. Based on these\ndocument vectors, we introduce a measure of model explanatory power and show\nthat, although the SVM and CNN models perform similarly in terms of\nclassification accuracy, the latter exhibits a higher level of explainability\nwhich makes it more comprehensible for humans and potentially more useful for\nother applications.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 00:31:30 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Arras", "Leila", ""], ["Horn", "Franziska", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1612.07940", "submitter": "Lei Shu", "authors": "Lei Shu, Bing Liu, Hu Xu, Annice Kim", "title": "Supervised Opinion Aspect Extraction by Exploiting Past Extraction\n  Results", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key tasks of sentiment analysis of product reviews is to extract\nproduct aspects or features that users have expressed opinions on. In this\nwork, we focus on using supervised sequence labeling as the base approach to\nperforming the task. Although several extraction methods using sequence\nlabeling methods such as Conditional Random Fields (CRF) and Hidden Markov\nModels (HMM) have been proposed, we show that this supervised approach can be\nsignificantly improved by exploiting the idea of concept sharing across\nmultiple domains. For example, \"screen\" is an aspect in iPhone, but not only\niPhone has a screen, many electronic devices have screens too. When \"screen\"\nappears in a review of a new domain (or product), it is likely to be an aspect\ntoo. Knowing this information enables us to do much better extraction in the\nnew domain. This paper proposes a novel extraction method exploiting this idea\nin the context of supervised sequence labeling. Experimental results show that\nit produces markedly better results than without using the past information.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 11:32:37 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Shu", "Lei", ""], ["Liu", "Bing", ""], ["Xu", "Hu", ""], ["Kim", "Annice", ""]]}, {"id": "1612.07956", "submitter": "Kamal Sarkar", "authors": "Kamal Sarkar", "title": "A CRF Based POS Tagger for Code-mixed Indian Social Media Text", "comments": "This work is awarded the first prize in the NLP tool contest on \"POS\n  Tagging for Code-Mixed Indian Social Media Text\", held in conjunction with\n  the 13th International Conference on Natural Language Processing 2016(ICON\n  2016), Indian Institute of Technology (BHU), India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe a conditional random fields (CRF) based system for\nPart-Of- Speech (POS) tagging of code-mixed Indian social media text as part of\nour participation in the tool contest on POS tagging for codemixed Indian\nsocial media text, held in conjunction with the 2016 International Conference\non Natural Language Processing, IIT(BHU), India. We participated only in\nconstrained mode contest for all three language pairs, Bengali-English,\nHindi-English and Telegu-English. Our system achieves the overall average F1\nscore of 79.99, which is the highest overall average F1 score among all 16\nsystems participated in constrained mode contest.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 12:58:58 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Sarkar", "Kamal", ""]]}, {"id": "1612.08083", "submitter": "Yann Dauphin", "authors": "Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier", "title": "Language Modeling with Gated Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-dominant approach to language modeling to date is based on recurrent\nneural networks. Their success on this task is often linked to their ability to\ncapture unbounded context. In this paper we develop a finite context approach\nthrough stacked convolutions, which can be more efficient since they allow\nparallelization over sequential tokens. We propose a novel simplified gating\nmechanism that outperforms Oord et al (2016) and investigate the impact of key\narchitectural decisions. The proposed approach achieves state-of-the-art on the\nWikiText-103 benchmark, even though it features long-term dependencies, as well\nas competitive results on the Google Billion Words benchmark. Our model reduces\nthe latency to score a sentence by an order of magnitude compared to a\nrecurrent baseline. To our knowledge, this is the first time a non-recurrent\napproach is competitive with strong recurrent models on these large scale\nlanguage tasks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 20:32:33 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 22:34:00 GMT"}, {"version": "v3", "created": "Fri, 8 Sep 2017 22:26:49 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Dauphin", "Yann N.", ""], ["Fan", "Angela", ""], ["Auli", "Michael", ""], ["Grangier", "David", ""]]}, {"id": "1612.08171", "submitter": "Kamal Sarkar", "authors": "Kamal Sarkar", "title": "KS_JU@DPIL-FIRE2016:Detecting Paraphrases in Indian Languages Using\n  Multinomial Logistic Regression Model", "comments": "This work is awarded SPRINGER BEST PAPER AWARD, DPIL track @ 8th\n  meeting of Forum for Information Retrieval Evaluation 2016, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we describe a system that detects paraphrases in Indian\nLanguages as part of our participation in the shared Task on detecting\nparaphrases in Indian Languages (DPIL) organized by Forum for Information\nRetrieval Evaluation (FIRE) in 2016. Our paraphrase detection method uses a\nmultinomial logistic regression model trained with a variety of features which\nare basically lexical and semantic level similarities between two sentences in\na pair. The performance of the system has been evaluated against the test set\nreleased for the FIRE 2016 shared task on DPIL. Our system achieves the highest\nf-measure of 0.95 on task1 in Punjabi language.The performance of our system on\ntask1 in Hindi language is f-measure of 0.90. Out of 11 teams participated in\nthe shared task, only four teams participated in all four languages, Hindi,\nPunjabi, Malayalam and Tamil, but the remaining 7 teams participated in one of\nthe four languages. We also participated in task1 and task2 both for all four\nIndian Languages. The overall average performance of our system including task1\nand task2 overall four languages is F1-score of 0.81 which is the second\nhighest score among the four systems that participated in all four languages.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 12:37:19 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Sarkar", "Kamal", ""]]}, {"id": "1612.08178", "submitter": "Kamal Sarkar", "authors": "Kamal Sarkar, Debanjan Das, Indra Banerjee, Mamta Kumari and Prasenjit\n  Biswas", "title": "JU_KS_Group@FIRE 2016: Consumer Health Information Search", "comments": "8th meeting of Forum for Information Retrieval Evaluation 2016, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the methodology used and the results obtained by\nus for completing the tasks given under the shared task on Consumer Health\nInformation Search (CHIS) collocated with the Forum for Information Retrieval\nEvaluation (FIRE) 2016, ISI Kolkata. The shared task consists of two sub-tasks\n- (1) task1: given a query and a document/set of documents associated with that\nquery, the task is to classify the sentences in the document as relevant to the\nquery or not and (2) task 2: the relevant sentences need to be further\nclassified as supporting the claim made in the query, or opposing the claim\nmade in the query. We have participated in both the sub-tasks. The percentage\naccuracy obtained by our developed system for task1 was 73.39 which is third\nhighest among the 9 teams participated in the shared task.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 13:30:23 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Sarkar", "Kamal", ""], ["Das", "Debanjan", ""], ["Banerjee", "Indra", ""], ["Kumari", "Mamta", ""], ["Biswas", "Prasenjit", ""]]}, {"id": "1612.08205", "submitter": "Konstantinos Pappas", "authors": "Konstantinos Pappas and Rada Mihalcea", "title": "Predicting the Industry of Users on Social Media", "comments": "8 pages, 3 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic profiling of social media users is an important task for supporting\na multitude of downstream applications. While a number of studies have used\nsocial media content to extract and study collective social attributes, there\nis a lack of substantial research that addresses the detection of a user's\nindustry. We frame this task as classification using both feature engineering\nand ensemble learning. Our industry-detection system uses both posted content\nand profile information to detect a user's industry with 64.3% accuracy,\nsignificantly outperforming the majority baseline in a taxonomy of fourteen\nindustry classes. Our qualitative analysis suggests that a person's industry\nnot only affects the words used and their perceived meanings, but also the\nnumber and type of emotions being expressed.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 17:09:21 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Pappas", "Konstantinos", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1612.08220", "submitter": "Jiwei Li", "authors": "Jiwei Li, Will Monroe and Dan Jurafsky", "title": "Understanding Neural Networks through Representation Erasure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have been successfully applied to many natural language\nprocessing tasks, they come at the cost of interpretability. In this paper, we\npropose a general methodology to analyze and interpret decisions from a neural\nmodel by observing the effects on the model of erasing various parts of the\nrepresentation, such as input word-vector dimensions, intermediate hidden\nunits, or input words. We present several approaches to analyzing the effects\nof such erasure, from computing the relative difference in evaluation metrics,\nto using reinforcement learning to erase the minimum set of input words in\norder to flip a neural model's decision. In a comprehensive analysis of\nmultiple NLP tasks, including linguistic feature classification, sentence-level\nsentiment analysis, and document level sentiment aspect prediction, we show\nthat the proposed methodology not only offers clear explanations about neural\nmodel decisions, but also provides a way to conduct error analysis on neural\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 21:36:07 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 17:30:37 GMT"}, {"version": "v3", "created": "Tue, 10 Jan 2017 01:40:51 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Li", "Jiwei", ""], ["Monroe", "Will", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1612.08333", "submitter": "Karthik Bangalore Mani", "authors": "Karthik Bangalore Mani", "title": "Text Summarization using Deep Learning and Ridge Regression", "comments": "4 pages,10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop models and extract relevant features for automatic text\nsummarization and investigate the performance of different models on the DUC\n2001 dataset. Two different models were developed, one being a ridge regressor\nand the other one was a multi-layer perceptron. The hyperparameters were varied\nand their performance were noted. We segregated the summarization task into 2\nmain steps, the first being sentence ranking and the second step being sentence\nselection. In the first step, given a document, we sort the sentences based on\ntheir Importance, and in the second step, in order to obtain non-redundant\nsentences, we weed out the sentences that are have high similarity with the\npreviously selected sentences.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 07:17:30 GMT"}, {"version": "v2", "created": "Tue, 13 Jun 2017 06:37:24 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 00:23:45 GMT"}, {"version": "v4", "created": "Thu, 15 Jun 2017 02:42:47 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Mani", "Karthik Bangalore", ""]]}, {"id": "1612.08354", "submitter": "Gwang Been Park", "authors": "Gwangbeen Park, Woobin Im", "title": "Image-Text Multi-Modal Representation Learning by Adversarial\n  Backpropagation", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel method for image-text multi-modal representation learning.\nIn our knowledge, this work is the first approach of applying adversarial\nlearning concept to multi-modal learning and not exploiting image-text pair\ninformation to learn multi-modal feature. We only use category information in\ncontrast with most previous methods using image-text pair information for\nmulti-modal embedding. In this paper, we show that multi-modal feature can be\nachieved without image-text pair information and our method makes more similar\ndistribution with image and text in multi-modal feature space than other\nmethods which use image-text pair information. And we show our multi-modal\nfeature has universal semantic information, even though it was trained for\ncategory prediction. Our model is end-to-end backpropagation, intuitive and\neasily extended to other multi-modal learning work.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 09:51:18 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Park", "Gwangbeen", ""], ["Im", "Woobin", ""]]}, {"id": "1612.08375", "submitter": "Lang-Chi Yu", "authors": "Lang-Chi Yu, Hung-yi Lee, Lin-shan Lee", "title": "Abstractive Headline Generation for Spoken Content by Attentive\n  Recurrent Neural Networks with ASR Error Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Headline generation for spoken content is important since spoken content is\ndifficult to be shown on the screen and browsed by the user. It is a special\ntype of abstractive summarization, for which the summaries are generated word\nby word from scratch without using any part of the original content. Many deep\nlearning approaches for headline generation from text document have been\nproposed recently, all requiring huge quantities of training data, which is\ndifficult for spoken document summarization. In this paper, we propose an ASR\nerror modeling approach to learn the underlying structure of ASR error patterns\nand incorporate this model in an Attentive Recurrent Neural Network (ARNN)\narchitecture. In this way, the model for abstractive headline generation for\nspoken content can be learned from abundant text data and the ASR data for some\nrecognizers. Experiments showed very encouraging results and verified that the\nproposed ASR error model works well even when the input spoken content is\nrecognized by a recognizer very different from the one the model learned from.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 13:13:38 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Yu", "Lang-Chi", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1612.08504", "submitter": "Juste Raimbault", "authors": "Antonin Bergeaud, Yoann Potiron and Juste Raimbault", "title": "Classifying Patents Based on their Semantic Content", "comments": "28 pages ; 9 figures ; 5 Supplementary Materials", "journal-ref": null, "doi": "10.1371/journal.pone.0176310", "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend some usual techniques of classification resulting\nfrom a large-scale data-mining and network approach. This new technology, which\nin particular is designed to be suitable to big data, is used to construct an\nopen consolidated database from raw data on 4 million patents taken from the US\npatent office from 1976 onward. To build the pattern network, not only do we\nlook at each patent title, but we also examine their full abstract and extract\nthe relevant keywords accordingly. We refer to this classification as semantic\napproach in contrast with the more common technological approach which consists\nin taking the topology when considering US Patent office technological classes.\nMoreover, we document that both approaches have highly different topological\nmeasures and strong statistical evidence that they feature a different model.\nThis suggests that our method is a useful tool to extract endogenous\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 05:59:55 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Bergeaud", "Antonin", ""], ["Potiron", "Yoann", ""], ["Raimbault", "Juste", ""]]}, {"id": "1612.08543", "submitter": "Amir Hossein Akhavan Rahnama", "authors": "Amir Hossein Akhavan Rahnama", "title": "Distributed Real-Time Sentiment Analysis for Big Data Social Streams", "comments": null, "journal-ref": "IEEE 2014 International Conference on Control, Decision and\n  Information Technologies (CoDIT)", "doi": "10.1109/CoDIT.2014.6996998", "report-no": null, "categories": "stat.ML cs.CL cs.DB cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data trend has enforced the data-centric systems to have continuous fast\ndata streams. In recent years, real-time analytics on stream data has formed\ninto a new research field, which aims to answer queries about\nwhat-is-happening-now with a negligible delay. The real challenge with\nreal-time stream data processing is that it is impossible to store instances of\ndata, and therefore online analytical algorithms are utilized. To perform\nreal-time analytics, pre-processing of data should be performed in a way that\nonly a short summary of stream is stored in main memory. In addition, due to\nhigh speed of arrival, average processing time for each instance of data should\nbe in such a way that incoming instances are not lost without being captured.\nLastly, the learner needs to provide high analytical accuracy measures.\nSentinel is a distributed system written in Java that aims to solve this\nchallenge by enforcing both the processing and learning process to be done in\ndistributed form. Sentinel is built on top of Apache Storm, a distributed\ncomputing platform. Sentinels learner, Vertical Hoeffding Tree, is a parallel\ndecision tree-learning algorithm based on the VFDT, with ability of enabling\nparallel classification in distributed environments. Sentinel also uses\nSpaceSaving to keep a summary of the data stream and stores its summary in a\nsynopsis data structure. Application of Sentinel on Twitter Public Stream API\nis shown and the results are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 09:10:18 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Rahnama", "Amir Hossein Akhavan", ""]]}, {"id": "1612.08989", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, Alexander Magidow, Maxim Romanov, Avi Shmidman,\n  Moshe Koppel", "title": "Shamela: A Large-Scale Historical Arabic Corpus", "comments": "Slightly expanded version of Coling LT4DH workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic is a widely-spoken language with a rich and long history spanning more\nthan fourteen centuries. Yet existing Arabic corpora largely focus on the\nmodern period or lack sufficient diachronic information. We develop a\nlarge-scale, historical corpus of Arabic of about 1 billion words from diverse\nperiods of time. We clean this corpus, process it with a morphological\nanalyzer, and enhance it by detecting parallel passages and automatically\ndating undated texts. We demonstrate its utility with selected case-studies in\nwhich we show its application to the digital humanities.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 21:10:28 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Magidow", "Alexander", ""], ["Romanov", "Maxim", ""], ["Shmidman", "Avi", ""], ["Koppel", "Moshe", ""]]}, {"id": "1612.08994", "submitter": "Peter Potash", "authors": "Peter Potash, Alexey Romanov and Anna Rumshisky", "title": "Here's My Point: Joint Pointer Architecture for Argument Mining", "comments": "10 pages; under review for ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major goals in automated argumentation mining is to uncover the\nargument structure present in argumentative text. In order to determine this\nstructure, one must understand how different individual components of the\noverall argument are linked. General consensus in this field dictates that the\nargument components form a hierarchy of persuasion, which manifests itself in a\ntree structure. This work provides the first neural network-based approach to\nargumentation mining, focusing on the two tasks of extracting links between\nargument components, and classifying types of argument components. In order to\nsolve this problem, we propose to use a joint model that is based on a Pointer\nNetwork architecture. A Pointer Network is appealing for this task for the\nfollowing reasons: 1) It takes into account the sequential nature of argument\ncomponents; 2) By construction, it enforces certain properties of the tree\nstructure present in argument relations; 3) The hidden representations can be\napplied to auxiliary tasks. In order to extend the contribution of the original\nPointer Network model, we construct a joint model that simultaneously attempts\nto learn the type of argument component, as well as continuing to predict links\nbetween argument components. The proposed joint model achieves state-of-the-art\nresults on two separate evaluation corpora, achieving far superior performance\nthan a regular Pointer Network model. Our results show that optimizing for both\ntasks, and adding a fully-connected layer prior to recurrent neural network\ninput, is crucial for high performance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 21:36:19 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 21:59:03 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Potash", "Peter", ""], ["Romanov", "Alexey", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1612.09113", "submitter": "Jonathan Godwin", "authors": "Jonathan Godwin, Pontus Stenetorp, Sebastian Riedel", "title": "Deep Semi-Supervised Learning with Linguistically Motivated Sequence\n  Labeling Task Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel Neural Network algorithm for conducting\nsemi-supervised learning for sequence labeling tasks arranged in a\nlinguistically motivated hierarchy. This relationship is exploited to\nregularise the representations of supervised tasks by backpropagating the error\nof the unsupervised task through the supervised tasks. We introduce a neural\nnetwork where lower layers are supervised by junior downstream tasks and the\nfinal layer task is an auxiliary unsupervised task. The architecture shows\nimprovements of up to two percentage points F1 for Chunking compared to a\nplausible baseline.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 12:01:22 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Godwin", "Jonathan", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1612.09213", "submitter": "Vladimir Bochkarev", "authors": "Vladimir V. Bochkarev, Eduard Yu.Lerner and Anna V. Shevlyakova", "title": "Verifying Heaps' law using Google Books Ngram data", "comments": "8 pages, 6 figures", "journal-ref": "Uchenye Zapiski Kazanskogo Universiteta. Seriya\n  Fiziko-Matematicheskie Nauki, 2013, vol. 155, no. 4, pp. 16-23. (In Russian)", "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is devoted to the verification of the empirical Heaps law in\nEuropean languages using Google Books Ngram corpus data. The connection between\nword distribution frequency and expected dependence of individual word number\non text size is analysed in terms of a simple probability model of text\ngeneration. It is shown that the Heaps exponent varies significantly within\ncharacteristic time intervals of 60-100 years.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 17:36:54 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Bochkarev", "Vladimir V.", ""], ["Lerner", "Eduard Yu.", ""], ["Shevlyakova", "Anna V.", ""]]}, {"id": "1612.09268", "submitter": "Sidarta Ribeiro", "authors": "Natalia Bezerra Mota, Sylvia Pinheiro, Mariano Sigman, Diego Fernandez\n  Slezak, Guillermo Cecchi, Mauro Copelli, Sidarta Ribeiro", "title": "The ontogeny of discourse structure mimics the development of literature", "comments": "Natalia Bezerra Mota and Sylvia Pinheiro: Equal contribution Sidarta\n  Ribeiro and Mauro Copelli: Corresponding authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse varies with age, education, psychiatric state and historical epoch,\nbut the ontogenetic and cultural dynamics of discourse structure remain to be\nquantitatively characterized. To this end we investigated word graphs obtained\nfrom verbal reports of 200 subjects ages 2-58, and 676 literary texts spanning\n~5,000 years. In healthy subjects, lexical diversity, graph size, and\nlong-range recurrence departed from initial near-random levels through a\nmonotonic asymptotic increase across ages, while short-range recurrence showed\na corresponding decrease. These changes were explained by education and suggest\na hierarchical development of discourse structure: short-range recurrence and\nlexical diversity stabilize after elementary school, but graph size and\nlong-range recurrence only stabilize after high school. This gradual maturation\nwas blurred in psychotic subjects, who maintained in adulthood a near-random\nstructure. In literature, monotonic asymptotic changes over time were\nremarkable: While lexical diversity, long-range recurrence and graph size\nincreased away from near-randomness, short-range recurrence declined, from\nabove to below random levels. Bronze Age texts are structurally similar to\nchildish or psychotic discourses, but subsequent texts converge abruptly to the\nhealthy adult pattern around the onset of the Axial Age (800-200 BC), a period\nof pivotal cultural change. Thus, individually as well as historically,\ndiscourse maturation increases the range of word recurrence away from\nrandomness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 21:58:42 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Mota", "Natalia Bezerra", ""], ["Pinheiro", "Sylvia", ""], ["Sigman", "Mariano", ""], ["Slezak", "Diego Fernandez", ""], ["Cecchi", "Guillermo", ""], ["Copelli", "Mauro", ""], ["Ribeiro", "Sidarta", ""]]}, {"id": "1612.09327", "submitter": "Moonish Maknojia", "authors": "Ahlam Ansari, Moonish Maknojia and Altamash Shaikh", "title": "Intelligent information extraction based on artificial neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering System (QAS) is used for information retrieval and natural\nlanguage processing (NLP) to reduce human effort. There are numerous QAS based\non the user documents present today, but they all are limited to providing\nobjective answers and process simple questions only. Complex questions cannot\nbe answered by the existing QAS, as they require interpretation of the current\nand old data as well as the question asked by the user. The above limitations\ncan be overcome by using deep cases and neural network. Hence we propose a\nmodified QAS in which we create a deep artificial neural network with\nassociative memory from text documents. The modified QAS processes the contents\nof the text document provided to it and find the answer to even complex\nquestions in the documents.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 06:09:36 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Ansari", "Ahlam", ""], ["Maknojia", "Moonish", ""], ["Shaikh", "Altamash", ""]]}, {"id": "1612.09535", "submitter": "Concei\\c{c}\\~ao Rocha", "authors": "Concei\\c{c}\\~ao Rocha, Al\\'ipio Jorge, Roberta Sionara, Paula Brito,\n  Carlos Pimenta and Solange Rezende", "title": "PAMPO: using pattern matching and pos-tagging for effective Named\n  Entities recognition in Portuguese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the entity extraction task (named entity recognition)\nof a text mining process that aims at unveiling non-trivial semantic\nstructures, such as relationships and interaction between entities or\ncommunities. In this paper we present a simple and efficient named entity\nextraction algorithm. The method, named PAMPO (PAttern Matching and POs tagging\nbased algorithm for NER), relies on flexible pattern matching, part-of-speech\ntagging and lexical-based rules. It was developed to process texts written in\nPortuguese, however it is potentially applicable to other languages as well.\n  We compare our approach with current alternatives that support Named Entity\nRecognition (NER) for content written in Portuguese. These are Alchemy, Zemanta\nand Rembrandt. Evaluation of the efficacy of the entity extraction method on\nseveral texts written in Portuguese indicates a considerable improvement on\n$recall$ and $F_1$ measures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 17:10:29 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Rocha", "Concei\u00e7\u00e3o", ""], ["Jorge", "Al\u00edpio", ""], ["Sionara", "Roberta", ""], ["Brito", "Paula", ""], ["Pimenta", "Carlos", ""], ["Rezende", "Solange", ""]]}, {"id": "1612.09542", "submitter": "Licheng Yu", "authors": "Licheng Yu, Hao Tan, Mohit Bansal, Tamara L. Berg", "title": "A Joint Speaker-Listener-Reinforcer Model for Referring Expressions", "comments": "Some typo fixed; comprehension results on refcocog updated; more\n  human evaluation results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referring expressions are natural language constructions used to identify\nparticular objects within a scene. In this paper, we propose a unified\nframework for the tasks of referring expression comprehension and generation.\nOur model is composed of three modules: speaker, listener, and reinforcer. The\nspeaker generates referring expressions, the listener comprehends referring\nexpressions, and the reinforcer introduces a reward function to guide sampling\nof more discriminative expressions. The listener-speaker modules are trained\njointly in an end-to-end learning framework, allowing the modules to be aware\nof one another during learning while also benefiting from the discriminative\nreinforcer's feedback. We demonstrate that this unified framework and training\nachieves state-of-the-art results for both comprehension and generation on\nthree referring expression datasets. Project and demo page:\nhttps://vision.cs.unc.edu/refer\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 17:39:19 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 20:13:49 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Yu", "Licheng", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1612.09574", "submitter": "Massimiliano Dal Mas", "authors": "Massimiliano Dal Mas", "title": "Automatic Data Deformation Analysis on Evolving Folksonomy Driven\n  Environment", "comments": "8 pages, 3 figures; 2 tables; for details see:\n  http://www.maxdalmas.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Folksodriven framework makes it possible for data scientists to define an\nontology environment where searching for buried patterns that have some kind of\npredictive power to build predictive models more effectively. It accomplishes\nthis through an abstractions that isolate parameters of the predictive modeling\nprocess searching for patterns and designing the feature set, too. To reflect\nthe evolving knowledge, this paper considers ontologies based on folksonomies\naccording to a new concept structure called \"Folksodriven\" to represent\nfolksonomies. So, the studies on the transformational regulation of the\nFolksodriven tags are regarded to be important for adaptive folksonomies\nclassifications in an evolving environment used by Intelligent Systems to\nrepresent the knowledge sharing. Folksodriven tags are used to categorize\nsalient data points so they can be fed to a machine-learning system and\n\"featurizing\" the data.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 19:52:09 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Mas", "Massimiliano Dal", ""]]}]