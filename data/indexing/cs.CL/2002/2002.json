[{"id": "2002.00037", "submitter": "Parker Riley", "authors": "Parker Riley and Daniel Gildea", "title": "Unsupervised Bilingual Lexicon Induction Across Writing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent embedding-based methods in unsupervised bilingual lexicon induction\nhave shown good results, but generally have not leveraged orthographic\n(spelling) information, which can be helpful for pairs of related languages.\nThis work augments a state-of-the-art method with orthographic features, and\nextends prior work in this space by proposing methods that can learn and\nutilize orthographic correspondences even between languages with different\nscripts. We demonstrate this by experimenting on three language pairs with\ndifferent scripts and varying degrees of lexical similarity.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:48:58 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Riley", "Parker", ""], ["Gildea", "Daniel", ""]]}, {"id": "2002.00119", "submitter": "Wei Zhang", "authors": "Qianming Xue, Wei Zhang, Hongyuan Zha", "title": "Improving Domain-Adapted Sentiment Classification by Deep Adversarial\n  Mutual Learning", "comments": "Accepted to appear in AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-adapted sentiment classification refers to training on a labeled\nsource domain to well infer document-level sentiment on an unlabeled target\ndomain. Most existing relevant models involve a feature extractor and a\nsentiment classifier, where the feature extractor works towards learning\ndomain-invariant features from both domains, and the sentiment classifier is\ntrained only on the source domain to guide the feature extractor. As such, they\nlack a mechanism to use sentiment polarity lying in the target domain. To\nimprove domain-adapted sentiment classification by learning sentiment from the\ntarget domain as well, we devise a novel deep adversarial mutual learning\napproach involving two groups of feature extractors, domain discriminators,\nsentiment classifiers, and label probers. The domain discriminators enable the\nfeature extractors to obtain domain-invariant features. Meanwhile, the label\nprober in each group explores document sentiment polarity of the target domain\nthrough the sentiment prediction generated by the classifier in the peer group,\nand guides the learning of the feature extractor in its own group. The proposed\napproach achieves the mutual learning of the two groups in an end-to-end\nmanner. Experiments on multiple public datasets indicate our method obtains the\nstate-of-the-art performance, validating the effectiveness of mutual learning\nthrough label probers.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:22:44 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Xue", "Qianming", ""], ["Zhang", "Wei", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.00163", "submitter": "Zekang Li", "authors": "Zekang Li, Zongjia Li, Jinchao Zhang, Yang Feng, Cheng Niu, Jie Zhou", "title": "Bridging Text and Video: A Universal Multimodal Transformer for\n  Video-Audio Scene-Aware Dialog", "comments": "Accepted by AAAI2020 DSTC8 workshop. Ranked 1st in DSTC8-AVSD track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-Visual Scene-Aware Dialog (AVSD) is a task to generate responses when\nchatting about a given video, which is organized as a track of the 8th Dialog\nSystem Technology Challenge (DSTC8). To solve the task, we propose a universal\nmultimodal transformer and introduce the multi-task learning method to learn\njoint representations among different modalities as well as generate\ninformative and fluent responses. Our method extends the natural language\ngeneration pre-trained model to multimodal dialogue generation task. Our system\nachieves the best performance in both objective and subjective evaluations in\nthe challenge.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 07:50:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Zekang", ""], ["Li", "Zongjia", ""], ["Zhang", "Jinchao", ""], ["Feng", "Yang", ""], ["Niu", "Cheng", ""], ["Zhou", "Jie", ""]]}, {"id": "2002.00171", "submitter": "Gayatri Venugopal-Wairagade", "authors": "Gayatri Venugopal-Wairagade, Jatinderkumar R. Saini, Dhanya Pramod", "title": "Novel Language Resources for Hindi: An Aesthetics Text Corpus and a\n  Comprehensive Stop Lemma List", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is an effort to complement the contributions made by researchers\nworking toward the inclusion of non-English languages in natural language\nprocessing studies. Two novel Hindi language resources have been created and\nreleased for public consumption. The first resource is a corpus consisting of\nnearly thousand pre-processed fictional and nonfictional texts spanning over\nhundred years. The second resource is an exhaustive list of stop lemmas created\nfrom 12 corpora across multiple domains, consisting of over 13 million words,\nfrom which more than 200,000 lemmas were generated, and 11 publicly available\nstop word lists comprising over 1000 words, from which nearly 400 unique lemmas\nwere generated. This research lays emphasis on the use of stop lemmas instead\nof stop words owing to the presence of various, but not all morphological forms\nof a word in stop word lists, as opposed to the presence of only the root form\nof the word, from which variations could be derived if required. It was also\nobserved that stop lemmas were more consistent across multiple sources as\ncompared to stop words. In order to generate a stop lemma list, the parts of\nspeech of the lemmas were investigated but rejected as it was found that there\nwas no significant correlation between the rank of a word in the frequency list\nand its part of speech. The stop lemma list was assessed using a comparative\nmethod. A formal evaluation method is suggested as future work arising from\nthis study.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 08:49:17 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Venugopal-Wairagade", "Gayatri", ""], ["Saini", "Jatinderkumar R.", ""], ["Pramod", "Dhanya", ""]]}, {"id": "2002.00175", "submitter": "Kiet Nguyen Van", "authors": "Quan Hoang Lam, Quang Duy Le, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "UIT-ViIC: A Dataset for the First Evaluation on Vietnamese Image\n  Captioning", "comments": "Submitted to the 2020 ICCCI Conference (The 12th International\n  Conference on Computational Collective Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Image Captioning, the task of automatic generation of image captions, has\nattracted attentions from researchers in many fields of computer science, being\ncomputer vision, natural language processing and machine learning in recent\nyears. This paper contributes to research on Image Captioning task in terms of\nextending dataset to a different language - Vietnamese. So far, there is no\nexisted Image Captioning dataset for Vietnamese language, so this is the\nforemost fundamental step for developing Vietnamese Image Captioning. In this\nscope, we first build a dataset which contains manually written captions for\nimages from Microsoft COCO dataset relating to sports played with balls, we\ncalled this dataset UIT-ViIC. UIT-ViIC consists of 19,250 Vietnamese captions\nfor 3,850 images. Following that, we evaluate our dataset on deep neural\nnetwork models and do comparisons with English dataset and two Vietnamese\ndatasets built by different methods. UIT-ViIC is published on our lab website\nfor research purposes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:26:07 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Lam", "Quan Hoang", ""], ["Le", "Quang Duy", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2002.00181", "submitter": "Yu-Ping Ruan", "authors": "Yu-Ping Ruan, Zhen-Hua Ling, Jia-Chen Gu, Quan Liu", "title": "Fine-Tuning BERT for Schema-Guided Zero-Shot Dialogue State Tracking", "comments": "Present on the DSTC8 Workshop @ AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our work on Track 4 in the Dialogue System Technology Challenges 8\n(DSTC8). The DSTC8-Track 4 aims to perform dialogue state tracking (DST) under\nthe zero-shot settings, in which the model needs to generalize on unseen\nservice APIs given a schema definition of these target APIs. Serving as the\ncore for many virtual assistants such as Siri, Alexa, and Google Assistant, the\nDST keeps track of the user's goal and what happened in the dialogue history,\nmainly including intent prediction, slot filling, and user state tracking,\nwhich tests models' ability of natural language understanding. Recently, the\npretrained language models have achieved state-of-the-art results and shown\nimpressive generalization ability on various NLP tasks, which provide a\npromising way to perform zero-shot learning for language understanding. Based\non this, we propose a schema-guided paradigm for zero-shot dialogue state\ntracking (SGP-DST) by fine-tuning BERT, one of the most popular pretrained\nlanguage models. The SGP-DST system contains four modules for intent\nprediction, slot prediction, slot transfer prediction, and user state\nsummarizing respectively. According to the official evaluation results, our\nSGP-DST (team12) ranked 3rd on the joint goal accuracy (primary evaluation\nmetric for ranking submissions) and 1st on the requsted slots F1 among 25\nparticipant teams.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 10:00:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ruan", "Yu-Ping", ""], ["Ling", "Zhen-Hua", ""], ["Gu", "Jia-Chen", ""], ["Liu", "Quan", ""]]}, {"id": "2002.00198", "submitter": "Kun Zhou", "authors": "Kun Zhou, Berrak Sisman, Haizhou Li", "title": "Transforming Spectrum and Prosody for Emotional Voice Conversion with\n  Non-Parallel Training Data", "comments": "accepted by Speaker Odyssey 2020 in Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotional voice conversion aims to convert the spectrum and prosody to change\nthe emotional patterns of speech, while preserving the speaker identity and\nlinguistic content. Many studies require parallel speech data between different\nemotional patterns, which is not practical in real life. Moreover, they often\nmodel the conversion of fundamental frequency (F0) with a simple linear\ntransform. As F0 is a key aspect of intonation that is hierarchical in nature,\nwe believe that it is more adequate to model F0 in different temporal scales by\nusing wavelet transform. We propose a CycleGAN network to find an optimal\npseudo pair from non-parallel training data by learning forward and inverse\nmappings simultaneously using adversarial and cycle-consistency losses. We also\nstudy the use of continuous wavelet transform (CWT) to decompose F0 into ten\ntemporal scales, that describes speech prosody at different time resolution,\nfor effective F0 conversion. Experimental results show that our proposed\nframework outperforms the baselines both in objective and subjective\nevaluations.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 12:36:55 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 12:43:26 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 07:25:24 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 05:21:37 GMT"}, {"version": "v5", "created": "Sat, 24 Oct 2020 06:37:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhou", "Kun", ""], ["Sisman", "Berrak", ""], ["Li", "Haizhou", ""]]}, {"id": "2002.00205", "submitter": "Xu Li", "authors": "Xu Li, Xixin Wu, Xunying Liu, Helen Meng", "title": "Deep segmental phonetic posterior-grams based discovery of\n  non-categories in L2 English speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second language (L2) speech is often labeled with the native, phone\ncategories. However, in many cases, it is difficult to decide on a categorical\nphone that an L2 segment belongs to. These segments are regarded as\nnon-categories. Most existing approaches for Mispronunciation Detection and\nDiagnosis (MDD) are only concerned with categorical errors, i.e. a phone\ncategory is inserted, deleted or substituted by another. However,\nnon-categorical errors are not considered. To model these non-categorical\nerrors, this work aims at exploring non-categorical patterns to extend the\ncategorical phone set. We apply a phonetic segment classifier to generate\nsegmental phonetic posterior-grams (SPPGs) to represent phone segment-level\ninformation. And then we explore the non-categories by looking for the SPPGs\nwith more than one peak. Compared with the baseline system, this approach\nexplores more non-categorical patterns, and also perceptual experimental\nresults show that the explored non-categories are more accurate with increased\nconfusion degree by 7.3% and 7.5% under two different measures. Finally, we\npreliminarily analyze the reason behind those non-categories.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 13:21:33 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Xu", ""], ["Wu", "Xixin", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "2002.00206", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Edgar Meij and Krisztian Balog and Ridho Reinanda", "title": "Novel Entity Discovery from Web Tables", "comments": "Proceedings of The Web Conference 2020 (WWW '20), 2020", "journal-ref": null, "doi": "10.1145/3366423.3380205", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working with any sort of knowledge base (KB) one has to make sure it is\nas complete and also as up-to-date as possible. Both tasks are non-trivial as\nthey require recall-oriented efforts to determine which entities and\nrelationships are missing from the KB. As such they require a significant\namount of labor. Tables on the Web, on the other hand, are abundant and have\nthe distinct potential to assist with these tasks. In particular, we can\nleverage the content in such tables to discover new entities, properties, and\nrelationships. Because web tables typically only contain raw textual content we\nfirst need to determine which cells refer to which known entities---a task we\ndub table-to-KB matching. This first task aims to infer table semantics by\nlinking table cells and heading columns to elements of a KB. Then second task\nbuilds upon these linked entities and properties to not only identify novel\nones in the same table but also to bootstrap their type and additional\nrelationships. We refer to this process as novel entity discovery and, to the\nbest of our knowledge, it is the first endeavor on mining the unlinked cells in\nweb tables. Our method identifies not only out-of-KB (``novel'') information\nbut also novel aliases for in-KB (``known'') entities. When evaluated using\nthree purpose-built test collections, we find that our proposed approaches\nobtain a marked improvement in terms of precision over our baselines whilst\nkeeping recall stable.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 13:24:03 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Shuo", ""], ["Meij", "Edgar", ""], ["Balog", "Krisztian", ""], ["Reinanda", "Ridho", ""]]}, {"id": "2002.00293", "submitter": "Max Bartolo", "authors": "Max Bartolo, Alastair Roberts, Johannes Welbl, Sebastian Riedel,\n  Pontus Stenetorp", "title": "Beat the AI: Investigating Adversarial Human Annotation for Reading\n  Comprehension", "comments": null, "journal-ref": "Transactions of the Association for Computational Linguistics,\n  Volume 8, 2020 p.662-678", "doi": "10.1162/tacl_a_00338", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Innovations in annotation methodology have been a catalyst for Reading\nComprehension (RC) datasets and models. One recent trend to challenge current\nRC models is to involve a model in the annotation process: humans create\nquestions adversarially, such that the model fails to answer them correctly. In\nthis work we investigate this annotation methodology and apply it in three\ndifferent settings, collecting a total of 36,000 samples with progressively\nstronger models in the annotation loop. This allows us to explore questions\nsuch as the reproducibility of the adversarial effect, transfer from data\ncollected with varying model-in-the-loop strengths, and generalisation to data\ncollected without a model. We find that training on adversarially collected\nsamples leads to strong generalisation to non-adversarially collected datasets,\nyet with progressive performance deterioration with increasingly stronger\nmodels-in-the-loop. Furthermore, we find that stronger models can still learn\nfrom datasets collected with substantially weaker models-in-the-loop. When\ntrained on data collected with a BiDAF model in the loop, RoBERTa achieves\n39.9F1 on questions that it cannot answer when trained on SQuAD - only\nmarginally lower than when trained on data collected using RoBERTa itself\n(41.0F1).\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 00:22:55 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 16:02:10 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bartolo", "Max", ""], ["Roberts", "Alastair", ""], ["Welbl", "Johannes", ""], ["Riedel", "Sebastian", ""], ["Stenetorp", "Pontus", ""]]}, {"id": "2002.00317", "submitter": "Rik Koncel-Kedziorski", "authors": "Kelvin Luu, Rik Koncel-Kedziorski, Kyle Lo, Isabel Cachola, and Noah\n  A. Smith", "title": "Citation Text Generation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of citation text generation: given a pair of scientific\ndocuments, explain their relationship in natural language text in the manner of\na citation from one text to the other. This task encourages systems to learn\nrich relationships between scientific texts and to express them concretely in\nnatural language. Models for citation text generation will require robust\ndocument understanding including the capacity to quickly adapt to new\nvocabulary and to reason about document content. We believe this challenging\ndirection of research will benefit high-impact applications such as automatic\nliterature review or scientific writing assistance systems. In this paper we\nestablish the task of citation text generation with a standard evaluation\ncorpus and develop several strong baseline models. We provide extensive\nautomatic and human evaluations to illustrate the successes and shortcomings of\ncurrent text generation techniques for this task.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 03:54:47 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 23:45:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Luu", "Kelvin", ""], ["Koncel-Kedziorski", "Rik", ""], ["Lo", "Kyle", ""], ["Cachola", "Isabel", ""], ["Smith", "Noah A.", ""]]}, {"id": "2002.00388", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Shirui Pan and Erik Cambria and Pekka Marttinen and\n  Philip S. Yu", "title": "A Survey on Knowledge Graphs: Representation, Acquisition and\n  Applications", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2021", "doi": "10.1109/TNNLS.2021.3070843", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human knowledge provides a formal understanding of the world. Knowledge\ngraphs that represent structural relations between entities have become an\nincreasingly popular research direction towards cognition and human-level\nintelligence. In this survey, we provide a comprehensive review of knowledge\ngraph covering overall research topics about 1) knowledge graph representation\nlearning, 2) knowledge acquisition and completion, 3) temporal knowledge graph,\nand 4) knowledge-aware applications, and summarize recent breakthroughs and\nperspective directions to facilitate future research. We propose a full-view\ncategorization and new taxonomies on these topics. Knowledge graph embedding is\norganized from four aspects of representation space, scoring function, encoding\nmodels, and auxiliary information. For knowledge acquisition, especially\nknowledge graph completion, embedding methods, path inference, and logical rule\nreasoning, are reviewed. We further explore several emerging topics, including\nmeta relational learning, commonsense reasoning, and temporal knowledge graphs.\nTo facilitate future research on knowledge graphs, we also provide a curated\ncollection of datasets and open-source libraries on different tasks. In the\nend, we have a thorough outlook on several promising research directions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 13:17:31 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 07:30:24 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 20:12:58 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 05:48:44 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Pan", "Shirui", ""], ["Cambria", "Erik", ""], ["Marttinen", "Pekka", ""], ["Yu", "Philip S.", ""]]}, {"id": "2002.00417", "submitter": "Rui Liu", "authors": "Rui Liu, Berrak Sisman, Feilong Bao, Guanglai Gao, Haizhou Li", "title": "WaveTTS: Tacotron-based TTS with Joint Time-Frequency Domain Loss", "comments": "To appear at Odyssey 2020, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tacotron-based text-to-speech (TTS) systems directly synthesize speech from\ntext input. Such frameworks typically consist of a feature prediction network\nthat maps character sequences to frequency-domain acoustic features, followed\nby a waveform reconstruction algorithm or a neural vocoder that generates the\ntime-domain waveform from acoustic features. As the loss function is usually\ncalculated only for frequency-domain acoustic features, that doesn't directly\ncontrol the quality of the generated time-domain waveform. To address this\nproblem, we propose a new training scheme for Tacotron-based TTS, referred to\nas WaveTTS, that has 2 loss functions: 1) time-domain loss, denoted as the\nwaveform loss, that measures the distortion between the natural and generated\nwaveform; and 2) frequency-domain loss, that measures the Mel-scale acoustic\nfeature loss between the natural and generated acoustic features. WaveTTS\nensures both the quality of the acoustic features and the resulting speech\nwaveform. To our best knowledge, this is the first implementation of Tacotron\nwith joint time-frequency domain loss. Experimental results show that the\nproposed framework outperforms the baselines and achieves high-quality\nsynthesized speech.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 15:51:22 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 10:43:20 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 01:24:14 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Liu", "Rui", ""], ["Sisman", "Berrak", ""], ["Bao", "Feilong", ""], ["Gao", "Guanglai", ""], ["Li", "Haizhou", ""]]}, {"id": "2002.00481", "submitter": "Benedict Guzman", "authors": "Benedict Guzman, MS and Isabel Metzger, MS and Yindalon\n  Aphinyanaphongs, M.D., Ph.D. and Himanshu Grover, Ph.D", "title": "Assessment of Amazon Comprehend Medical: Medication Information\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In November 27, 2018, Amazon Web Services (AWS) released Amazon Comprehend\nMedical (ACM), a deep learning based system that automatically extracts\nclinical concepts (which include anatomy, medical conditions, protected health\ninformation (PH)I, test names, treatment names, and medical procedures, and\nmedications) from clinical text notes. Uptake and trust in any new data product\nrelies on independent validation across benchmark datasets and tools to\nestablish and confirm expected quality of results. This work focuses on the\nmedication extraction task, and particularly, ACM was evaluated using the\nofficial test sets from the 2009 i2b2 Medication Extraction Challenge and 2018\nn2c2 Track 2: Adverse Drug Events and Medication Extraction in EHRs. Overall,\nACM achieved F-scores of 0.768 and 0.828. These scores ranked the lowest when\ncompared to the three best systems in the respective challenges. To further\nestablish the generalizability of its medication extraction performance, a set\nof random internal clinical text notes from NYU Langone Medical Center were\nalso included in this work. And in this corpus, ACM garnered an F-score of\n0.753.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 20:08:34 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Guzman", "Benedict", ""], ["MS", "", ""], ["Metzger", "Isabel", ""], ["MS", "", ""], ["Aphinyanaphongs", "Yindalon", ""], ["D.", "M.", ""], ["D.", "Ph.", ""], ["Grover", "Himanshu", ""], ["D", "Ph.", ""]]}, {"id": "2002.00527", "submitter": "Jayden Macklin-Cordes", "authors": "Jayden L. Macklin-Cordes, Claire Bowern and Erich R. Round", "title": "Phylogenetic signal in phonotactics", "comments": "Main text: 32 pages, 17 figures, 1 table. Supplementary Information:\n  17 pages, 1 figure. Code and data available at\n  http://doi.org/10.5281/zenodo.3936353. This article is in review but not yet\n  accepted for publication in a journal", "journal-ref": null, "doi": "10.1075/dia.20004.mac", "report-no": null, "categories": "cs.CL q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylogenetic methods have broad potential in linguistics beyond tree\ninference. Here, we show how a phylogenetic approach opens the possibility of\ngaining historical insights from entirely new kinds of linguistic data--in this\ninstance, statistical phonotactics. We extract phonotactic data from 111\nPama-Nyungan vocabularies and apply tests for phylogenetic signal, quantifying\nthe degree to which the data reflect phylogenetic history. We test three\ndatasets: (1) binary variables recording the presence or absence of biphones\n(two-segment sequences) in a lexicon (2) frequencies of transitions between\nsegments, and (3) frequencies of transitions between natural sound classes.\nAustralian languages have been characterized as having a high degree of\nphonotactic homogeneity. Nevertheless, we detect phylogenetic signal in all\ndatasets. Phylogenetic signal is greater in finer-grained frequency data than\nin binary data, and greatest in natural-class-based data. These results\ndemonstrate the viability of employing a new source of readily extractable data\nin historical and comparative linguistics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 01:23:41 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 04:50:02 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Macklin-Cordes", "Jayden L.", ""], ["Bowern", "Claire", ""], ["Round", "Erich R.", ""]]}, {"id": "2002.00544", "submitter": "C.-H. Huck Yang", "authors": "Jun Qi, Hu Hu, Yannan Wang, Chao-Han Huck Yang, Sabato Marco\n  Siniscalchi, Chin-Hui Lee", "title": "Tensor-to-Vector Regression for Multi-channel Speech Enhancement based\n  on Tensor-Train Network", "comments": "Accepted to ICASSP 2020. Update reproducible code", "journal-ref": "IEEE ICASSP 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a tensor-to-vector regression approach to multi-channel speech\nenhancement in order to address the issue of input size explosion and\nhidden-layer size expansion. The key idea is to cast the conventional deep\nneural network (DNN) based vector-to-vector regression formulation under a\ntensor-train network (TTN) framework. TTN is a recently emerged solution for\ncompact representation of deep models with fully connected hidden layers. Thus\nTTN maintains DNN's expressive power yet involves a much smaller amount of\ntrainable parameters. Furthermore, TTN can handle a multi-dimensional tensor\ninput by design, which exactly matches the desired setting in multi-channel\nspeech enhancement. We first provide a theoretical extension from DNN to TTN\nbased regression. Next, we show that TTN can attain speech enhancement quality\ncomparable with that for DNN but with much fewer parameters, e.g., a reduction\nfrom 27 million to only 5 million parameters is observed in a single-channel\nscenario. TTN also improves PESQ over DNN from 2.86 to 2.96 by slightly\nincreasing the number of trainable parameters. Finally, in 8-channel\nconditions, a PESQ of 3.12 is achieved using 20 million parameters for TTN,\nwhereas a DNN with 68 million parameters can only attain a PESQ of 3.06. Our\nimplementation is available online\nhttps://github.com/uwjunqi/Tensor-Train-Neural-Network.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:58:00 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Qi", "Jun", ""], ["Hu", "Hu", ""], ["Wang", "Yannan", ""], ["Yang", "Chao-Han Huck", ""], ["Siniscalchi", "Sabato Marco", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2002.00551", "submitter": "Takenori Yoshimura", "authors": "Takenori Yoshimura, Tomoki Hayashi, Kazuya Takeda and Shinji Watanabe", "title": "End-to-End Automatic Speech Recognition Integrated With CTC-Based Voice\n  Activity Detection", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper integrates a voice activity detection (VAD) function with\nend-to-end automatic speech recognition toward an online speech interface and\ntranscribing very long audio recordings. We focus on connectionist temporal\nclassification (CTC) and its extension of CTC/attention architectures. As\nopposed to an attention-based architecture, input-synchronous label prediction\ncan be performed based on a greedy search with the CTC (pre-)softmax output.\nThis prediction includes consecutive long blank labels, which can be regarded\nas a non-speech region. We use the labels as a cue for detecting speech\nsegments with simple thresholding. The threshold value is directly related to\nthe length of a non-speech region, which is more intuitive and easier to\ncontrol than conventional VAD hyperparameters. Experimental results on\nunsegmented data show that the proposed method outperformed the baseline\nmethods using the conventional energy-based and neural-network-based VAD\nmethods and achieved an RTF less than 0.2. The proposed method is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 03:36:34 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 06:15:58 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Yoshimura", "Takenori", ""], ["Hayashi", "Tomoki", ""], ["Takeda", "Kazuya", ""], ["Watanabe", "Shinji", ""]]}, {"id": "2002.00557", "submitter": "Amol Kelkar", "authors": "Amol Kelkar, Rohan Relan, Vaishali Bhardwaj, Saurabh Vaichal, Chandra\n  Khatri, Peter Relan", "title": "Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker", "comments": "Accepted at WeCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To access data stored in relational databases, users need to understand the\ndatabase schema and write a query using a query language such as SQL. To\nsimplify this task, text-to-SQL models attempt to translate a user's natural\nlanguage question to corresponding SQL query. Recently, several generative\ntext-to-SQL models have been developed. We propose a novel discriminative\nre-ranker to improve the performance of generative text-to-SQL models by\nextracting the best SQL query from the beam output predicted by the text-to-SQL\ngenerator, resulting in improved performance in the cases where the best query\nwas in the candidate list, but not at the top of the list. We build the\nre-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative\nstrengths of the text-to-SQL and re-ranker models across different query\nhardness levels, and suggest how to combine the two models for optimal\nperformance. We demonstrate the effectiveness of the re-ranker by applying it\nto two state-of-the-art text-to-SQL models, and achieve top 4 score on the\nSpider leaderboard at the time of writing this article.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 04:52:47 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:22:57 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kelkar", "Amol", ""], ["Relan", "Rohan", ""], ["Bhardwaj", "Vaishali", ""], ["Vaichal", "Saurabh", ""], ["Khatri", "Chandra", ""], ["Relan", "Peter", ""]]}, {"id": "2002.00571", "submitter": "Liu Yang", "authors": "Liu Yang, Minghui Qiu, Chen Qu, Cen Chen, Jiafeng Guo, Yongfeng Zhang,\n  W. Bruce Croft, Haiqing Chen", "title": "IART: Intent-aware Response Ranking with Transformers in\n  Information-seeking Conversation Systems", "comments": "Accepted by WWW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal assistant systems, such as Apple Siri, Google Assistant, Amazon\nAlexa, and Microsoft Cortana, are becoming ever more widely used. Understanding\nuser intent such as clarification questions, potential answers and user\nfeedback in information-seeking conversations is critical for retrieving good\nresponses. In this paper, we analyze user intent patterns in\ninformation-seeking conversations and propose an intent-aware neural response\nranking model \"IART\", which refers to \"Intent-Aware Ranking with Transformers\".\nIART is built on top of the integration of user intent modeling and language\nrepresentation learning with the Transformer architecture, which relies\nentirely on a self-attention mechanism instead of recurrent nets. It\nincorporates intent-aware utterance attention to derive an importance weighting\nscheme of utterances in conversation context with the aim of better\nconversation history understanding. We conduct extensive experiments with three\ninformation-seeking conversation data sets including both standard benchmarks\nand commercial data. Our proposed model outperforms all baseline methods with\nrespect to a variety of metrics. We also perform case studies and analysis of\nlearned user intent and its impact on response ranking in information-seeking\nconversations to provide interpretation of results.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 05:59:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Yang", "Liu", ""], ["Qiu", "Minghui", ""], ["Qu", "Chen", ""], ["Chen", "Cen", ""], ["Guo", "Jiafeng", ""], ["Zhang", "Yongfeng", ""], ["Croft", "W. Bruce", ""], ["Chen", "Haiqing", ""]]}, {"id": "2002.00583", "submitter": "Fei Huang", "authors": "Fei Huang, Dazhen Wan, Zhihong Shao, Pei Ke, Jian Guan, Yilin Niu,\n  Xiaoyan Zhu, Minlie Huang", "title": "CoTK: An Open-Source Toolkit for Fast Development and Fair Evaluation of\n  Text Generation", "comments": "Submitting to ACL2020 demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text generation evaluation, many practical issues, such as inconsistent\nexperimental settings and metric implementations, are often ignored but lead to\nunfair evaluation and untenable conclusions. We present CoTK, an open-source\ntoolkit aiming to support fast development and fair evaluation of text\ngeneration. In model development, CoTK helps handle the cumbersome issues, such\nas data processing, metric implementation, and reproduction. It standardizes\nthe development steps and reduces human errors which may lead to inconsistent\nexperimental settings. In model evaluation, CoTK provides implementation for\nmany commonly used metrics and benchmark models across different experimental\nsettings. As a unique feature, CoTK can signify when and which metric cannot be\nfairly compared. We demonstrate that it is convenient to use CoTK for model\ndevelopment and evaluation, particularly across different experimental\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 07:15:29 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Huang", "Fei", ""], ["Wan", "Dazhen", ""], ["Shao", "Zhihong", ""], ["Ke", "Pei", ""], ["Guan", "Jian", ""], ["Niu", "Yilin", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2002.00652", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Jiaqi Guo, Jian-Guang Lou, Bin Zhou, Dongmei Zhang", "title": "How Far are We from Effective Context Modeling? An Exploratory Study on\n  Semantic Parsing in Context", "comments": "Accepted by IJCAI2020\n  (http://static.ijcai.org/2020-accepted_papers.html). SOLE copyright holder is\n  IJCAI (International Joint Conferences on Artificial Intelligence), all\n  rights reserved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently semantic parsing in context has received considerable attention,\nwhich is challenging since there are complex contextual phenomena. Previous\nworks verified their proposed methods in limited scenarios, which motivates us\nto conduct an exploratory study on context modeling methods under real-world\nsemantic parsing in context. We present a grammar-based decoding semantic\nparser and adapt typical context modeling methods on top of it. We evaluate 13\ncontext modeling methods on two large complex cross-domain datasets, and our\nbest model achieves state-of-the-art performances on both datasets with\nsignificant improvements. Furthermore, we summarize the most frequent\ncontextual phenomena, with a fine-grained analysis on representative models,\nwhich may shed light on potential research directions. Our code is available at\nhttps://github.com/microsoft/ContextualSP.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:28:10 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 10:13:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Guo", "Jiaqi", ""], ["Lou", "Jian-Guang", ""], ["Zhou", "Bin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2002.00720", "submitter": "Valentin D. Richard", "authors": "Valentin D. Richard", "title": "Introduction of Quantification in Frame Semantics", "comments": "Master report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Structures (FSs) are a widespread tool used for decompositional\nframeworks of Attribute-Value associations. Even though they thrive in simple\nsystems, they lack a way of representing higher-order entities and relations.\nThis is however needed in Frame Semantics, where semantic dependencies should\nbe able to connect groups of individuals and their properties, especially to\nmodel quantification. To answer this issue, this master report introduces\nwrappings as a way to envelop a sub-FS and treat it as a node. Following the\nwork of [Kallmeyer, Osswald 2013], we extend its syntax, semantics and some\nproperties (translation to FOL, subsumption, unification). We can then expand\nthe proposed pipeline. Lexical minimal model sets are generated from formulas.\nThey unify by FS value equations obtained by LTAG parsing to an underspecified\nsentence representation. The syntactic approach of quantifiers allows us to use\nexisting methods to produce any possible reading. Finally, we give a\ntranscription to type-logical formulas to interact with the context in the view\nof dynamic semantics. Supported by ideas of Frame Types, this system provides a\nworkable and tractable tool for higher-order relations with FS.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:52:29 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Richard", "Valentin D.", ""]]}, {"id": "2002.00725", "submitter": "Valentin D. Richard", "authors": "Valentin D. Richard", "title": "Traduction des Grammaires Cat\\'egorielles de Lambek dans les Grammaires\n  Cat\\'egorielles Abstraites", "comments": "Bachelor internship report, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lambek Grammars (LG) are a computational modelling of natural language, based\non non-commutative compositional types. It has been widely studied, especially\nfor languages where the syntax plays a major role (like English). The goal of\nthis internship report is to demonstrate that every Lambek Grammar can be, not\nentirely but efficiently, expressed in Abstract Categorial Grammars (ACG). The\nlatter is a novel modelling based on higher-order signature homomorphisms\n(using $\\lambda$-calculus), aiming at uniting the currently used models. The\nmain idea is to transform the type rewriting system of LGs into that of\nContext-Free Grammars (CFG) by erasing introduction and elimination rules and\ngenerating enough axioms so that the cut rule suffices. This iterative approach\npreserves the derivations and enables us to stop the possible infinite\ngenerative process at any step. Although the underlying algorithm was not fully\nimplemented, this proof provides another argument in favour of the relevance of\nACGs in Natural Language Processing.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:23:03 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Richard", "Valentin D.", ""]]}, {"id": "2002.00730", "submitter": "Aaron Van Geffen", "authors": "Aaron van Geffen", "title": "Reducing Noise from Competing Neighbours: Word Retrieval with Lateral\n  Inhibition in Multilink", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilink is a computational model for word retrieval in monolingual and\nmultilingual individuals under different task circumstances (Dijkstra et al.,\n2018). In the present study, we added lateral inhibition to Multilink's lexical\nnetwork. Parameters were fit on the basis of reaction times from the English,\nBritish, and Dutch Lexicon Projects. We found a maximum correlation of 0.643\n(N=1,205) on these data sets as a whole. Furthermore, the simulations\nthemselves became faster as a result of adding lateral inhibition. We tested\nthe fitted model to stimuli from a neighbourhood study (Mulder et al., 2018).\nLateral inhibition was found to improve Multilink's correlations for this\nstudy, yielding an overall correlation of 0.67. Next, we explored the role of\nlateral inhibition as part of the model's task/decision system by running\nsimulations on data from two studies concerning interlingual homographs\n(Vanlangendonck et al., in press; Goertz, 2018). We found that, while lateral\ninhibition plays a substantial part in the word selection process, this alone\nis not enough to result in a correct response selection. To solve this problem,\nwe added a new task component to Multilink, especially designed to account for\nthe translation process of interlingual homographs, cognates, and\nlanguage-specific control words. The subsequent simulation results showed\npatterns remarkably similar to those in the Goertz study. The isomorphicity of\nthe simulated data to the empirical data was further attested by an overall\ncorrelation of 0.538 (N=254) between reaction times and simulated model cycle\ntimes, as well as a condition pattern correlation of 0.853 (N=8). We conclude\nthat Multilink yields an excellent fit to empirical data, particularly when a\ntask-specific setting of the inhibition parameters is allowed.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 16:40:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["van Geffen", "Aaron", ""]]}, {"id": "2002.00733", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi, George Han, Celine Liang", "title": "Generation-Distillation for Efficient Natural Language Understanding in\n  Low-Data Settings", "comments": "EMNLP 2019 Workshop on Deep Learning for Low-resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past year, the emergence of transfer learning with large-scale\nlanguage models (LM) has led to dramatic performance improvements across a\nbroad range of natural language understanding tasks. However, the size and\nmemory footprint of these large LMs makes them difficult to deploy in many\nscenarios (e.g. on mobile phones). Recent research points to knowledge\ndistillation as a potential solution, showing that when training data for a\ngiven task is abundant, it is possible to distill a large (teacher) LM into a\nsmall task-specific (student) network with minimal loss of performance.\nHowever, when such data is scarce, there remains a significant performance gap\nbetween large pretrained LMs and smaller task-specific models, even when\ntraining via distillation. In this paper, we bridge this gap with a novel\ntraining approach, called generation-distillation, that leverages large\nfinetuned LMs in two ways: (1) to generate new (unlabeled) training examples,\nand (2) to distill their knowledge into a small network using these examples.\nAcross three low-resource text classification datsets, we achieve comparable\nperformance to BERT while using 300x fewer parameters, and we outperform prior\napproaches to distillation for text classification while using 3x fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:20:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Melas-Kyriazi", "Luke", ""], ["Han", "George", ""], ["Liang", "Celine", ""]]}, {"id": "2002.00734", "submitter": "Andrew Krizhanovsky A", "authors": "A. Smirnov, T. Levashova, A. Karpov, I. Kipyatkova, A. Ronzhin, A.\n  Krizhanovsky, N. Krizhanovsky", "title": "Analysis of the quotation corpus of the Russian Wiktionary", "comments": "12 pages, 3 tables, 5 figures, published in the journal (preprint)", "journal-ref": "Research in Computing Science, Vol. 56, pp. 101-112, 2012", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The quantitative evaluation of quotations in the Russian Wiktionary was\nperformed using the developed Wiktionary parser. It was found that the number\nof quotations in the dictionary is growing fast (51.5 thousands in 2011, 62\nthousands in 2012). These quotations were extracted and saved in the relational\ndatabase of a machine-readable dictionary. For this database, tables related to\nthe quotations were designed. A histogram of distribution of quotations of\nliterary works written in different years was built. It was made an attempt to\nexplain the characteristics of the histogram by associating it with the years\nof the most popular and cited (in the Russian Wiktionary) writers of the\nnineteenth century. It was found that more than one-third of all the quotations\n(the example sentences) contained in the Russian Wiktionary are taken by the\neditors of a Wiktionary entry from the Russian National Corpus.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 12:30:17 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Smirnov", "A.", ""], ["Levashova", "T.", ""], ["Karpov", "A.", ""], ["Kipyatkova", "I.", ""], ["Ronzhin", "A.", ""], ["Krizhanovsky", "A.", ""], ["Krizhanovsky", "N.", ""]]}, {"id": "2002.00735", "submitter": "Jianfeng Deng", "authors": "Jianfeng Deng and Lianglun Cheng and Zhuowei Wang", "title": "Self-attention-based BiGRU and capsule network for named entity\n  recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition(NER) is one of the tasks of natural language\nprocessing(NLP). In view of the problem that the traditional character\nrepresentation ability is weak and the neural network method is unable to\ncapture the important sequence information. An self-attention-based\nbidirectional gated recurrent unit(BiGRU) and capsule network(CapsNet) for NER\nis proposed. This model generates character vectors through bidirectional\nencoder representation of transformers(BERT) pre-trained model. BiGRU is used\nto capture sequence context features, and self-attention mechanism is proposed\nto give different focus on the information captured by hidden layer of BiGRU.\nFinally, we propose to use CapsNet for entity recognition. We evaluated the\nrecognition performance of the model on two datasets. Experimental results show\nthat the model has better performance without relying on external dictionary\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:51:58 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Deng", "Jianfeng", ""], ["Cheng", "Lianglun", ""], ["Wang", "Zhuowei", ""]]}, {"id": "2002.00737", "submitter": "Taeuk Kim", "authors": "Taeuk Kim, Jihun Choi, Daniel Edmiston, and Sang-goo Lee", "title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong\n  Baselines for Grammar Induction", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success and popularity of pre-trained language models (LMs)\nin natural language processing, there has been a rise in efforts to understand\ntheir inner workings. In line with such interest, we propose a novel method\nthat assists us in investigating the extent to which pre-trained LMs capture\nthe syntactic notion of constituency. Our method provides an effective way of\nextracting constituency trees from the pre-trained LMs without training. In\naddition, we report intriguing findings in the induced trees, including the\nfact that pre-trained LMs outperform other approaches in correctly demarcating\nadverb phrases in sentences.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:06:49 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kim", "Taeuk", ""], ["Choi", "Jihun", ""], ["Edmiston", "Daniel", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2002.00738", "submitter": "Gopi Ramena", "authors": "Gopi Ramena, Divija Nagaraju, Sukumar Moharana, Debi Prasanna Mohanty,\n  Naresh Purre", "title": "An Efficient Architecture for Predicting the Case of Characters using\n  Sequence Models", "comments": "to be published in IEEE ICSC 2020 proceedings", "journal-ref": null, "doi": "10.1109/ICSC.2020.00035", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dearth of clean textual data often acts as a bottleneck in several\nnatural language processing applications. The data available often lacks proper\ncase (uppercase or lowercase) information. This often comes up when text is\nobtained from social media, messaging applications and other online platforms.\nThis paper attempts to solve this problem by restoring the correct case of\ncharacters, commonly known as Truecasing. Doing so improves the accuracy of\nseveral processing tasks further down in the NLP pipeline. Our proposed\narchitecture uses a combination of convolutional neural networks (CNN),\nbi-directional long short-term memory networks (LSTM) and conditional random\nfields (CRF), which work at a character level without any explicit feature\nengineering. In this study we compare our approach to previous statistical and\ndeep learning based approaches. Our method shows an increment of 0.83 in F1\nscore over the current state of the art. Since truecasing acts as a\npreprocessing step in several applications, every increment in the F1 score\nleads to a significant improvement in the language processing tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 06:54:39 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Ramena", "Gopi", ""], ["Nagaraju", "Divija", ""], ["Moharana", "Sukumar", ""], ["Mohanty", "Debi Prasanna", ""], ["Purre", "Naresh", ""]]}, {"id": "2002.00741", "submitter": "Jibang Wu", "authors": "Jibang Wu, Renqin Cai, Hongning Wang", "title": "D\\'ej\\`a vu: A Contextualized Temporal Attention Mechanism for\n  Sequential Recommendation", "comments": "Key Words: Sequential Recommendation, Self-attention mechanism,\n  Temporal Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting users' preferences based on their sequential behaviors in history\nis challenging and crucial for modern recommender systems. Most existing\nsequential recommendation algorithms focus on transitional structure among the\nsequential actions, but largely ignore the temporal and context information,\nwhen modeling the influence of a historical event to current prediction.\n  In this paper, we argue that the influence from the past events on a user's\ncurrent action should vary over the course of time and under different context.\nThus, we propose a Contextualized Temporal Attention Mechanism that learns to\nweigh historical actions' influence on not only what action it is, but also\nwhen and how the action took place. More specifically, to dynamically calibrate\nthe relative input dependence from the self-attention mechanism, we deploy\nmultiple parameterized kernel functions to learn various temporal dynamics, and\nthen use the context information to determine which of these reweighing kernels\nto follow for each input. In empirical evaluations on two large public\nrecommendation datasets, our model consistently outperformed an extensive set\nof state-of-the-art sequential recommendation methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 20:27:42 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wu", "Jibang", ""], ["Cai", "Renqin", ""], ["Wang", "Hongning", ""]]}, {"id": "2002.00743", "submitter": "Kshitij Jain", "authors": "Xin Lian, Kshitij Jain, Jakub Truszkowski, Pascal Poupart, and\n  Yaoliang Yu", "title": "Unsupervised Multilingual Alignment using Wasserstein Barycenter", "comments": "Code is available at https://github.com/alixxxin/multi-lang", "journal-ref": "Proceedings of International Joint Conference on Artificial\n  Intelligence (IJCAI), 2020", "doi": "10.24963/ijcai.2020/512", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study unsupervised multilingual alignment, the problem of finding\nword-to-word translations between multiple languages without using any parallel\ndata. One popular strategy is to reduce multilingual alignment to the much\nsimplified bilingual setting, by picking one of the input languages as the\npivot language that we transit through. However, it is well-known that\ntransiting through a poorly chosen pivot language (such as English) may\nseverely degrade the translation quality, since the assumed transitive\nrelations among all pairs of languages may not be enforced in the training\nprocess. Instead of going through a rather arbitrarily chosen pivot language,\nwe propose to use the Wasserstein barycenter as a more informative \"mean\"\nlanguage: it encapsulates information from all languages and minimizes all\npairwise transportation costs. We evaluate our method on standard benchmarks\nand demonstrate state-of-the-art performances.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:22:07 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 23:42:33 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Lian", "Xin", ""], ["Jain", "Kshitij", ""], ["Truszkowski", "Jakub", ""], ["Poupart", "Pascal", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2002.00744", "submitter": "Shoubin Li", "authors": "Shoubin Li, Wenzao Cui, Yujiang Liu, Xuran Ming, Jun Hu, YuanzheHu,\n  Qing Wang", "title": "PEL-BERT: A Joint Model for Protocol Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained models such as BERT are widely used in NLP tasks and are\nfine-tuned to improve the performance of various NLP tasks consistently.\nNevertheless, the fine-tuned BERT model trained on our protocol corpus still\nhas a weak performance on the Entity Linking (EL) task. In this paper, we\npropose a model that joints a fine-tuned language model with an RFC Domain\nModel. Firstly, we design a Protocol Knowledge Base as the guideline for\nprotocol EL. Secondly, we propose a novel model, PEL-BERT, to link named\nentities in protocols to categories in Protocol Knowledge Base. Finally, we\nconduct a comprehensive study on the performance of pre-trained language models\non descriptive texts and abstract concepts. Experimental results demonstrate\nthat our model achieves state-of-the-art performance in EL on our annotated\ndataset, outperforming all the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 16:42:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Shoubin", ""], ["Cui", "Wenzao", ""], ["Liu", "Yujiang", ""], ["Ming", "Xuran", ""], ["Hu", "Jun", ""], ["YuanzheHu", "", ""], ["Wang", "Qing", ""]]}, {"id": "2002.00745", "submitter": "Zihao Wang", "authors": "Zihao Wang, Yong Zhang, Hao Wu", "title": "Structural-Aware Sentence Similarity with Recursive Optimal Transport", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Measuring sentence similarity is a classic topic in natural language\nprocessing. Light-weighted similarities are still of particular practical\nsignificance even when deep learning models have succeeded in many other tasks.\nSome light-weighted similarities with more theoretical insights have been\ndemonstrated to be even stronger than supervised deep learning approaches.\nHowever, the successful light-weighted models such as Word Mover's Distance\n[Kusner et al., 2015] or Smooth Inverse Frequency [Arora et al., 2017] failed\nto detect the difference from the structure of sentences, i.e. order of words.\nTo address this issue, we present Recursive Optimal Transport (ROT) framework\nto incorporate the structural information with the classic OT. Moreover, we\nfurther develop Recursive Optimal Similarity (ROTS) for sentences with the\nvaluable semantic insights from the connections between cosine similarity of\nweighted average of word vectors and optimal transport. ROTS is\nstructural-aware and with low time complexity compared to optimal transport.\nOur experiments over 20 sentence textural similarity (STS) datasets show the\nclear advantage of ROTS over all weakly supervised approaches. Detailed\nablation study demonstrate the effectiveness of ROT and the semantic insights.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 09:07:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Zihao", ""], ["Zhang", "Yong", ""], ["Wu", "Hao", ""]]}, {"id": "2002.00747", "submitter": "Maartje ter Hoeve", "authors": "Maartje ter Hoeve, Robert Sim, Elnaz Nouri, Adam Fourney, Maarten de\n  Rijke, Ryen W. White", "title": "Conversations with Documents. An Exploration of Document-Centered\n  Assistance", "comments": "Accepted as full paper at CHIIR 2020; 9 pages + Appendix", "journal-ref": null, "doi": "10.1145/3343413.3377971", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of conversational assistants has become more prevalent in helping\npeople increase their productivity. Document-centered assistance, for example\nto help an individual quickly review a document, has seen less significant\nprogress, even though it has the potential to tremendously increase a user's\nproductivity. This type of document-centered assistance is the focus of this\npaper. Our contributions are three-fold: (1) We first present a survey to\nunderstand the space of document-centered assistance and the capabilities\npeople expect in this scenario. (2) We investigate the types of queries that\nusers will pose while seeking assistance with documents, and show that\ndocument-centered questions form the majority of these queries. (3) We present\na set of initial machine learned models that show that (a) we can accurately\ndetect document-centered questions, and (b) we can build reasonably accurate\nmodels for answering such questions. These positive results are encouraging,\nand suggest that even greater results may be attained with continued study of\nthis interesting and novel problem space. Our findings have implications for\nthe design of intelligent systems to support task completion via natural\ninteractions with documents.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:10:11 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["ter Hoeve", "Maartje", ""], ["Sim", "Robert", ""], ["Nouri", "Elnaz", ""], ["Fourney", "Adam", ""], ["de Rijke", "Maarten", ""], ["White", "Ryen W.", ""]]}, {"id": "2002.00748", "submitter": "Bang Liu", "authors": "Bang Liu, Haojie Wei, Di Niu, Haolan Chen, Yancheng He", "title": "Asking Questions the Human Way: Scalable Question-Answer Generation from\n  Text Corpus", "comments": "Accepted by The Web Conference 2020 (WWW 2020) as full paper (oral\n  presentation)", "journal-ref": null, "doi": "10.1145/3366423.3380270", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to ask questions is important in both human and machine\nintelligence. Learning to ask questions helps knowledge acquisition, improves\nquestion-answering and machine reading comprehension tasks, and helps a chatbot\nto keep the conversation flowing with a human. Existing question generation\nmodels are ineffective at generating a large amount of high-quality\nquestion-answer pairs from unstructured text, since given an answer and an\ninput passage, question generation is inherently a one-to-many mapping. In this\npaper, we propose Answer-Clue-Style-aware Question Generation (ACS-QG), which\naims at automatically generating high-quality and diverse question-answer pairs\nfrom unlabeled text corpus at scale by imitating the way a human asks\nquestions. Our system consists of: i) an information extractor, which samples\nfrom the text multiple types of assistive information to guide question\ngeneration; ii) neural question generators, which generate diverse and\ncontrollable questions, leveraging the extracted assistive information; and\niii) a neural quality controller, which removes low-quality generated data\nbased on text entailment. We compare our question generation models with\nexisting approaches and resort to voluntary human evaluation to assess the\nquality of the generated question-answer pairs. The evaluation results suggest\nthat our system dramatically outperforms state-of-the-art neural question\ngeneration models in terms of the generation quality, while being scalable in\nthe meantime. With models trained on a relatively smaller amount of data, we\ncan generate 2.8 million quality-assured question-answer pairs from a million\nsentences found in Wikipedia.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 05:27:09 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:06:21 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Liu", "Bang", ""], ["Wei", "Haojie", ""], ["Niu", "Di", ""], ["Chen", "Haolan", ""], ["He", "Yancheng", ""]]}, {"id": "2002.00750", "submitter": "Chandra Khatri", "authors": "Yue Weng, Sai Sumanth Miryala, Chandra Khatri, Runze Wang, Huaixiu\n  Zheng, Piero Molino, Mahdi Namazifar, Alexandros Papangelis, Hugh Williams,\n  Franziska Bell, Gokhan Tur", "title": "Joint Contextual Modeling for ASR Correction and Language Understanding", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of automatic speech recognition (ASR) is critical to Dialogue\nSystems as ASR errors propagate to and directly impact downstream tasks such as\nlanguage understanding (LU). In this paper, we propose multi-task neural\napproaches to perform contextual language correction on ASR outputs jointly\nwith LU to improve the performance of both tasks simultaneously. To measure the\neffectiveness of this approach we used a public benchmark, the 2nd Dialogue\nState Tracking (DSTC2) corpus. As a baseline approach, we trained task-specific\nStatistical Language Models (SLM) and fine-tuned state-of-the-art Generalized\nPre-training (GPT) Language Model to re-rank the n-best ASR hypotheses,\nfollowed by a model to identify the dialog act and slots. i) We further trained\nranker models using GPT and Hierarchical CNN-RNN models with discriminatory\nlosses to detect the best output given n-best hypotheses. We extended these\nranker models to first select the best ASR output and then identify the\ndialogue act and slots in an end to end fashion. ii) We also proposed a novel\njoint ASR error correction and LU model, a word confusion pointer network\n(WCN-Ptr) with multi-head self-attention on top, which consumes the word\nconfusions populated from the n-best. We show that the error rates of off the\nshelf ASR and following LU systems can be reduced significantly by 14% relative\nwith joint models trained using small amounts of in-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 22:09:25 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Weng", "Yue", ""], ["Miryala", "Sai Sumanth", ""], ["Khatri", "Chandra", ""], ["Wang", "Runze", ""], ["Zheng", "Huaixiu", ""], ["Molino", "Piero", ""], ["Namazifar", "Mahdi", ""], ["Papangelis", "Alexandros", ""], ["Williams", "Hugh", ""], ["Bell", "Franziska", ""], ["Tur", "Gokhan", ""]]}, {"id": "2002.00754", "submitter": "Utkarsh Desai", "authors": "Utkarsh Desai, Srikanth Tamilselvam, Jassimran Kaur, Senthil Mani,\n  Shreya Khare", "title": "Benchmarking Popular Classification Models' Robustness to Random and\n  Targeted Corruptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification models, especially neural networks based models, have\nreached very high accuracy on many popular benchmark datasets. Yet, such models\nwhen deployed in real world applications, tend to perform badly. The primary\nreason is that these models are not tested against sufficient real world\nnatural data. Based on the application users, the vocabulary and the style of\nthe model's input may greatly vary. This emphasizes the need for a model\nagnostic test dataset, which consists of various corruptions that are natural\nto appear in the wild. Models trained and tested on such benchmark datasets,\nwill be more robust against real world data. However, such data sets are not\neasily available. In this work, we address this problem, by extending the\nbenchmark datasets along naturally occurring corruptions such as Spelling\nErrors, Text Noise and Synonyms and making them publicly available. Through\nextensive experiments, we compare random and targeted corruption strategies\nusing Local Interpretable Model-Agnostic Explanations(LIME). We report the\nvulnerabilities in two popular text classification models along these\ncorruptions and also find that targeted corruptions can expose vulnerabilities\nof a model better than random choices in most cases.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:54:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Desai", "Utkarsh", ""], ["Tamilselvam", "Srikanth", ""], ["Kaur", "Jassimran", ""], ["Mani", "Senthil", ""], ["Khare", "Shreya", ""]]}, {"id": "2002.00757", "submitter": "Massimiliano Morrelli", "authors": "Massimiliano Morrelli, Giacomo Pansini, Massimiliano Polito, Arturo\n  Vitale", "title": "Similarit\\`a per la ricerca del dominio di una frase", "comments": "in Italian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  English. This document aims to study the best algorithms to verify the\nbelonging of a specific document to a related domain by comparing different\nmethods for calculating the distance between two vectors. This study has been\nmade possible with the help of the structures made available by the Apache\nSpark framework. Starting from the study illustrated in the publication \"New\nfrontier of textual classification: Big data and distributed calculus\" by\nMassimiliano Morrelli et al., We wanted to carry out a study on the possible\nimplementation of a solution capable of calculating the Similarity of a\nsentence using the distributed environment.\n  Italiano. Il presente documento persegue l'obiettivo di studiare gli\nalgoritmi migliori per verificare l'appartenenza di un determinato documento a\nun relativo dominio tramite un confronto di diversi metodi per il calcolo della\ndistanza fra due vettori. Tale studio \\`e stato condotto con l'ausilio delle\nstrutture messe a disposizione dal framework Apache Spark. Partendo dallo\nstudio illustrato nella pubblicazione \"Nuova frontiera della classificazione\ntestuale: Big data e calcolo distribuito\" di Massimiliano Morrelli et al., si\n\\`e voluto realizzare uno studio sulla possibile implementazione di una\nsoluzione in grado di calcolare la Similarit\\`a di una frase sfruttando\nl'ambiente distribuito.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:37:00 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Morrelli", "Massimiliano", ""], ["Pansini", "Giacomo", ""], ["Polito", "Massimiliano", ""], ["Vitale", "Arturo", ""]]}, {"id": "2002.00759", "submitter": "Son T. Luu", "authors": "Son T. Luu, Hung P. Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Comparison Between Traditional Machine Learning Models And Neural\n  Network Models For Vietnamese Hate Speech Detection", "comments": "Published in The 2020 RIVF International Conference on Computing and\n  Communication Technologies (RIVF)", "journal-ref": null, "doi": "10.1109/RIVF48685.2020.9140745", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hate-speech detection on social network language has become one of the main\nresearching fields recently due to the spreading of social networks like\nFacebook and Twitter. In Vietnam, the threat of offensive and harassment cause\nbad impacts for online user. The VLSP - Shared task about Hate Speech Detection\non social networks showed many proposed approaches for detecting whatever\ncomment is clean or not. However, this problem still needs further researching.\nConsequently, we compare traditional machine learning and deep learning on a\nlarge dataset about the user's comments on social network in Vietnamese and\nfind out what is the advantage and disadvantage of each model by comparing\ntheir accuracy on F1-score, then we pick two models in which has highest\naccuracy in traditional machine learning models and deep neural models\nrespectively. Next, we compare these two models capable of predicting the right\nlabel by referencing their confusion matrices and considering the advantages\nand disadvantages of each model. Finally, from the comparison result, we\npropose our ensemble method that concentrates the abilities of traditional\nmethods and deep learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:28:57 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 01:54:32 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Luu", "Son T.", ""], ["Nguyen", "Hung P.", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2002.00760", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman and Lv Zhonghou and Wang minghua", "title": "FastWordBug: A Fast Method To Generate Adversarial Text Against NLP\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel algorithm, FastWordBug, to efficiently\ngenerate small text perturbations in a black-box setting that forces a\nsentiment analysis or text classification mode to make an incorrect prediction.\nBy combining the part of speech attributes of words, we propose a scoring\nmethod that can quickly identify important words that affect text\nclassification. We evaluate FastWordBug on three real-world text datasets and\ntwo state-of-the-art machine learning models under black-box setting. The\nresults show that our method can significantly reduce the accuracy of the\nmodel, and at the same time, we can call the model as little as possible, with\nthe highest attack efficiency. We also attack two popular real-world cloud\nservices of NLP, and the results show that our method works as well.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:39:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Goodman", "Dou", ""], ["Zhonghou", "Lv", ""], ["minghua", "Wang", ""]]}, {"id": "2002.00761", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Francisco Guzm\\'an", "title": "Massively Multilingual Document Alignment with Cross-lingual\n  Sentence-Mover's Distance", "comments": "In Proceedings of AACL-IJCNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document alignment aims to identify pairs of documents in two distinct\nlanguages that are of comparable content or translations of each other. Such\naligned data can be used for a variety of NLP tasks from training cross-lingual\nrepresentations to mining parallel data for machine translation. In this paper\nwe develop an unsupervised scoring function that leverages cross-lingual\nsentence embeddings to compute the semantic distance between documents in\ndifferent languages. These semantic distances are then used to guide a document\nalignment algorithm to properly pair cross-lingual web documents across a\nvariety of low, mid, and high-resource language pairs. Recognizing that our\nproposed scoring function and other state of the art methods are\ncomputationally intractable for long web documents, we utilize a more tractable\ngreedy algorithm that performs comparably. We experimentally demonstrate that\nour distance metric performs better alignment than current baselines\noutperforming them by 7% on high-resource language pairs, 15% on mid-resource\nlanguage pairs, and 22% on low-resource language pairs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:14:16 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 05:26:32 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Guzm\u00e1n", "Francisco", ""]]}, {"id": "2002.00763", "submitter": "Xishuang Dong", "authors": "Xishuang Dong, Uboho Victor, and Lijun Qian", "title": "Two-path Deep Semi-supervised Learning for Timely Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them are labeled (as fake or true news) by\nprofessionals in near real time. In order to achieve timely detection of fake\nnews in social media, a novel framework of two-path deep semi-supervised\nlearning is proposed where one path is for supervised learning and the other is\nfor unsupervised learning. The supervised learning path learns on the limited\namount of labeled data while the unsupervised learning path is able to learn on\na huge amount of unlabeled data. Furthermore, these two paths implemented with\nconvolutional neural networks (CNN) are jointly optimized to complete\nsemi-supervised learning. In addition, we build a shared CNN to extract the low\nlevel features on both labeled data and unlabeled data to feed them into these\ntwo paths. To verify this framework, we implement a Word CNN based\nsemi-supervised learning model and test it on two datasets, namely, LIAR and\nPHEME. Experimental results demonstrate that the model built on the proposed\nframework can recognize fake news effectively with very few labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 02:28:35 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Dong", "Xishuang", ""], ["Victor", "Uboho", ""], ["Qian", "Lijun", ""]]}, {"id": "2002.00768", "submitter": "Vaishali Pal", "authors": "Vaishali Pal, Fabien Guillot, Manish Shrivastava, Jean-Michel Renders,\n  Laurent Besacier", "title": "Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion\n  Networks", "comments": "Accepted at Interspeech-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Spoken dialogue systems typically use a list of top-N ASR hypotheses for\ninferring the semantic meaning and tracking the state of the dialogue. However\nASR graphs, such as confusion networks (confnets), provide a compact\nrepresentation of a richer hypothesis space than a top-N ASR list. In this\npaper, we study the benefits of using confusion networks with a\nstate-of-the-art neural dialogue state tracker (DST). We encode the\n2-dimensional confnet into a 1-dimensional sequence of embeddings using an\nattentional confusion network encoder which can be used with any DST system.\nOur confnet encoder is plugged into the state-of-the-art 'Global-locally\nSelf-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains\nsignificant improvements in both accuracy and inference time compared to using\ntop-N ASR hypotheses.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:11:48 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 18:40:00 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Pal", "Vaishali", ""], ["Guillot", "Fabien", ""], ["Shrivastava", "Manish", ""], ["Renders", "Jean-Michel", ""], ["Besacier", "Laurent", ""]]}, {"id": "2002.00835", "submitter": "Sebastian Arnold", "authors": "Sebastian Arnold, Betty van Aken, Paul Grundmann, Felix A. Gers,\n  Alexander L\\\"oser", "title": "Learning Contextualized Document Representations for Healthcare Answer\n  Retrieval", "comments": "The Web Conference 2020 (WWW '20)", "journal-ref": null, "doi": "10.1145/3366423.3380208", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Contextual Discourse Vectors (CDV), a distributed document\nrepresentation for efficient answer retrieval from long healthcare documents.\nOur approach is based on structured query tuples of entities and aspects from\nfree text and medical taxonomies. Our model leverages a dual encoder\narchitecture with hierarchical LSTM layers and multi-task training to encode\nthe position of clinical entities and aspects alongside the document discourse.\nWe use our continuous representations to resolve queries with short latency\nusing approximate nearest neighbor search on sentence level. We apply the CDV\nmodel for retrieving coherent answer passages from nine English public health\nresources from the Web, addressing both patients and medical professionals.\nBecause there is no end-to-end training data available for all application\nscenarios, we train our model with self-supervised data from Wikipedia. We show\nthat our generalized model significantly outperforms several state-of-the-art\nbaselines for healthcare passage ranking and is able to adapt to heterogeneous\ndomains without additional fine-tuning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:47:19 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Arnold", "Sebastian", ""], ["van Aken", "Betty", ""], ["Grundmann", "Paul", ""], ["Gers", "Felix A.", ""], ["L\u00f6ser", "Alexander", ""]]}, {"id": "2002.00838", "submitter": "Bo Ni", "authors": "Bo Ni, Zhichun Guo, Jianing Li, Meng Jiang", "title": "Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 00:44:59 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ni", "Bo", ""], ["Guo", "Zhichun", ""], ["Li", "Jianing", ""], ["Jiang", "Meng", ""]]}, {"id": "2002.00876", "submitter": "Alexander M. Rush", "authors": "Alexander M. Rush", "title": "Torch-Struct: Deep Structured Prediction Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on structured prediction for NLP describes a rich collection\nof distributions and algorithms over sequences, segmentations, alignments, and\ntrees; however, these algorithms are difficult to utilize in deep learning\nframeworks. We introduce Torch-Struct, a library for structured prediction\ndesigned to take advantage of and integrate with vectorized,\nauto-differentiation based frameworks. Torch-Struct includes a broad collection\nof probabilistic structures accessed through a simple and flexible\ndistribution-based API that connects to any deep learning model. The library\nutilizes batched, vectorized operations and exploits auto-differentiation to\nproduce readable, fast, and testable code. Internally, we also include a number\nof general-purpose optimizations to provide cross-algorithm efficiency.\nExperiments show significant performance gains over fast baselines and\ncase-studies demonstrate the benefits of the library. Torch-Struct is available\nat https://github.com/harvardnlp/pytorch-struct.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:43:02 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Rush", "Alexander M.", ""]]}, {"id": "2002.01030", "submitter": "Mohammad Hadi Goldani", "authors": "Mohammad Hadi Goldani, Saeedeh Momtazi, Reza Safabakhsh", "title": "Detecting Fake News with Capsule Neural Networks", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:13:07 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Goldani", "Mohammad Hadi", ""], ["Momtazi", "Saeedeh", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2002.01065", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an, Cristina Puente, Rafael Palacios", "title": "Fake News Detection by means of Uncertainty Weighted Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:28:38 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 05:12:35 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Puente", "Cristina", ""], ["Palacios", "Rafael", ""]]}, {"id": "2002.01071", "submitter": "Karam Abdulahhad", "authors": "Karam Abdulahhad", "title": "Concept Embedding for Information Retrieval", "comments": "6 pages", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_45", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts are used to solve the term-mismatch problem. However, we need an\neffective similarity measure between concepts. Word embedding presents a\npromising solution. We present in this study three approaches to build concepts\nvectors based on words vectors. We use a vector-based measure to estimate\ninter-concepts similarity. Our experiments show promising results. Furthermore,\nwords and concepts become comparable. This could be used to improve conceptual\nindexing process.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:18:56 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Abdulahhad", "Karam", ""]]}, {"id": "2002.01093", "submitter": "Abhinav Gupta", "authors": "Ryan Lowe, Abhinav Gupta, Jakob Foerster, Douwe Kiela, Joelle Pineau", "title": "On the interaction between supervision and self-play in emergent\n  communication", "comments": "The first two authors contributed equally. Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising approach for teaching artificial agents to use natural language\ninvolves using human-in-the-loop training. However, recent work suggests that\ncurrent machine learning methods are too data inefficient to be trained in this\nway from scratch. In this paper, we investigate the relationship between two\ncategories of learning signals with the ultimate goal of improving sample\nefficiency: imitating human language data via supervised learning, and\nmaximizing reward in a simulated multi-agent environment via self-play (as done\nin emergent communication), and introduce the term supervised self-play (S2P)\nfor algorithms using both of these signals. We find that first training agents\nvia supervised learning on human data followed by self-play outperforms the\nconverse, suggesting that it is not beneficial to emerge languages from\nscratch. We then empirically investigate various S2P schedules that begin with\nsupervised learning in two environments: a Lewis signaling game with symbolic\ninputs, and an image-based referential game with natural language descriptions.\nLastly, we introduce population based approaches to S2P, which further improves\nthe performance over single-agent methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:35:19 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:48:08 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lowe", "Ryan", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Kiela", "Douwe", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.01127", "submitter": "Rong Ye", "authors": "Rong Ye, Wenxian Shi, Hao Zhou, Zhongyu Wei, Lei Li", "title": "Variational Template Machine for Data-to-Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to generate descriptions from structured data organized in tables?\nExisting approaches using neural encoder-decoder models often suffer from\nlacking diversity. We claim that an open set of templates is crucial for\nenriching the phrase constructions and realizing varied generations. Learning\nsuch templates is prohibitive since it often requires a large paired <table,\ndescription> corpus, which is seldom available. This paper explores the problem\nof automatically learning reusable \"templates\" from paired and non-paired data.\nWe propose the variational template machine (VTM), a novel method to generate\ntext descriptions from data tables. Our contributions include: a) we carefully\ndevise a specific model architecture and losses to explicitly disentangle text\ntemplate and semantic content information, in the latent spaces, and b)we\nutilize both small parallel data and large raw text without aligned tables to\nenrich the template learning. Experiments on datasets from a variety of\ndifferent domains show that VTM is able to generate more diversely while\nkeeping a good fluency and quality.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 04:53:45 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 09:50:56 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ye", "Rong", ""], ["Shi", "Wenxian", ""], ["Zhou", "Hao", ""], ["Wei", "Zhongyu", ""], ["Li", "Lei", ""]]}, {"id": "2002.01145", "submitter": "Hidetaka Kamigaito", "authors": "Hidetaka Kamigaito, Manabu Okumura", "title": "Syntactically Look-Ahead Attention Network for Sentence Compression", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence compression is the task of compressing a long sentence into a short\none by deleting redundant words. In sequence-to-sequence (Seq2Seq) based\nmodels, the decoder unidirectionally decides to retain or delete words. Thus,\nit cannot usually explicitly capture the relationships between decoded words\nand unseen words that will be decoded in the future time steps. Therefore, to\navoid generating ungrammatical sentences, the decoder sometimes drops important\nwords in compressing sentences. To solve this problem, we propose a novel\nSeq2Seq model, syntactically look-ahead attention network (SLAHAN), that can\ngenerate informative summaries by explicitly tracking both dependency parent\nand child words during decoding and capturing important words that will be\ndecoded in the future. The results of the automatic evaluation on the Google\nsentence compression dataset showed that SLAHAN achieved the best\nkept-token-based-F1, ROUGE-1, ROUGE-2 and ROUGE-L scores of 85.5, 79.3, 71.3\nand 79.1, respectively. SLAHAN also improved the summarization performance on\nlonger sentences. Furthermore, in the human evaluation, SLAHAN improved\ninformativeness without losing readability.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 06:26:37 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 13:33:00 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kamigaito", "Hidetaka", ""], ["Okumura", "Manabu", ""]]}, {"id": "2002.01196", "submitter": "JingHui Qin", "authors": "Jinghui Qin, Zheng Ye, Jianheng Tang, Xiaodan Liang", "title": "Dynamic Knowledge Routing Network For Target-Guided Open-Domain\n  Conversation", "comments": "8 pages, 2 figues, 6tables, AAAI2020, fix our model's abbreviation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target-guided open-domain conversation aims to proactively and naturally\nguide a dialogue agent or human to achieve specific goals, topics or keywords\nduring open-ended conversations. Existing methods mainly rely on single-turn\ndatadriven learning and simple target-guided strategy without considering\nsemantic or factual knowledge relations among candidate topics/keywords. This\nresults in poor transition smoothness and low success rate. In this work, we\nadopt a structured approach that controls the intended content of system\nresponses by introducing coarse-grained keywords, attains smooth conversation\ntransition through turn-level supervised learning and knowledge relations\nbetween candidate keywords, and drives an conversation towards an specified\ntarget with discourse-level guiding strategy. Specially, we propose a novel\ndynamic knowledge routing network (DKRN) which considers semantic knowledge\nrelations among candidate keywords for accurate next topic prediction of next\ndiscourse. With the help of more accurate keyword prediction, our\nkeyword-augmented response retrieval module can achieve better retrieval\nperformance and more meaningful conversations. Besides, we also propose a novel\ndual discourse-level target-guided strategy to guide conversations to reach\ntheir goals smoothly with higher success rate. Furthermore, to push the\nresearch boundary of target-guided open-domain conversation to match real-world\nscenarios better, we introduce a new large-scale Chinese target-guided\nopen-domain conversation dataset (more than 900K conversations) crawled from\nSina Weibo. Quantitative and human evaluations show our method can produce\nmeaningful and effective target-guided conversations, significantly improving\nover other state-of-the-art methods by more than 20% in success rate and more\nthan 0.6 in average smoothness score.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:49:36 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:44:42 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Qin", "Jinghui", ""], ["Ye", "Zheng", ""], ["Tang", "Jianheng", ""], ["Liang", "Xiaodan", ""]]}, {"id": "2002.01207", "submitter": "Kareem Darwish", "authors": "Kareem Darwish, Ahmed Abdelali, Hamdy Mubarak, Mohamed Eldesouki", "title": "Arabic Diacritic Recovery Using a Feature-Rich biLSTM Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diacritics (short vowels) are typically omitted when writing Arabic text, and\nreaders have to reintroduce them to correctly pronounce words. There are two\ntypes of Arabic diacritics: the first are core-word diacritics (CW), which\nspecify the lexical selection, and the second are case endings (CE), which\ntypically appear at the end of the word stem and generally specify their\nsyntactic roles. Recovering CEs is relatively harder than recovering core-word\ndiacritics due to inter-word dependencies, which are often distant. In this\npaper, we use a feature-rich recurrent neural network model that uses a variety\nof linguistic and surface-level features to recover both core word diacritics\nand case endings. Our model surpasses all previous state-of-the-art systems\nwith a CW error rate (CWER) of 2.86\\% and a CE error rate (CEER) of 3.7% for\nModern Standard Arabic (MSA) and CWER of 2.2% and CEER of 2.5% for Classical\nArabic (CA). When combining diacritized word cores with case endings, the\nresultant word error rate is 6.0% and 4.3% for MSA and CA respectively. This\nhighlights the effectiveness of feature engineering for such deep neural\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 10:09:42 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Darwish", "Kareem", ""], ["Abdelali", "Ahmed", ""], ["Mubarak", "Hamdy", ""], ["Eldesouki", "Mohamed", ""]]}, {"id": "2002.01214", "submitter": "Karl-Heinz Zimmermann", "authors": "Karl-Heinz Zimmermann, Merve Nur Cakir", "title": "On Stochastic Automata over Monoids", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic automata over monoids as input sets are studied. The\nwell-definedness of these automata requires an extension postulate that\nreplaces the inherent universal property of free monoids. As a generalization\nof Turakainen's result, it will be shown that the generalized automata over\nmonoids have the same acceptance power as their stochastic counterparts. The\nkey to homomorphisms is a commuting property between the monoid homomorphism of\ninput states and the monoid homomorphism of transition matrices. Closure\nproperties of the languages accepted by stochastic automata over monoids are\ninvestigated. matrices. Closure properties of the languages accepted by\nstochastic automata over monoids are investigated.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 10:30:49 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Zimmermann", "Karl-Heinz", ""], ["Cakir", "Merve Nur", ""]]}, {"id": "2002.01320", "submitter": "Changhan Wang", "authors": "Changhan Wang, Juan Pino, Anne Wu, Jiatao Gu", "title": "CoVoST: A Diverse Multilingual Speech-To-Text Translation Corpus", "comments": "LREC 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language translation has recently witnessed a resurgence in\npopularity, thanks to the development of end-to-end models and the creation of\nnew corpora, such as Augmented LibriSpeech and MuST-C. Existing datasets\ninvolve language pairs with English as a source language, involve very specific\ndomains or are low resource. We introduce CoVoST, a multilingual speech-to-text\ntranslation corpus from 11 languages into English, diversified with over 11,000\nspeakers and over 60 accents. We describe the dataset creation methodology and\nprovide empirical evidence of the quality of the data. We also provide initial\nbenchmarks, including, to our knowledge, the first end-to-end many-to-one\nmultilingual models for spoken language translation. CoVoST is released under\nCC0 license and free to use. We also provide additional evaluation data derived\nfrom Tatoeba under CC licenses.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:35:28 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 19:24:52 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wang", "Changhan", ""], ["Pino", "Juan", ""], ["Wu", "Anne", ""], ["Gu", "Jiatao", ""]]}, {"id": "2002.01335", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden, Christopher Pal", "title": "Structural Inductive Biases in Emergent Communication", "comments": "The first two authors contributed equally. Poster presented at CogSci\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:59:08 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 18:57:45 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 22:05:34 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 04:13:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""], ["Pal", "Christopher", ""]]}, {"id": "2002.01336", "submitter": "Feng Wei", "authors": "Feng Wei and Uyen Trang Nguyen", "title": "Twitter Bot Detection Using Bidirectional Long Short-term Memory Neural\n  Networks and Word Embeddings", "comments": "IEEE TPS 2019. arXiv admin note: text overlap with arXiv:1703.04482\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is a web application playing dual roles of online social networking\nand micro-blogging. The popularity and open structure of Twitter have attracted\na large number of automated programs, known as bots. Legitimate bots generate a\nlarge amount of benign contextual content, i.e., tweets delivering news and\nupdating feeds, while malicious bots spread spam or malicious contents. To\nassist human users in identifying who they are interacting with, this paper\nfocuses on the classification of human and spambot accounts on Twitter, by\nemploying recurrent neural networks, specifically bidirectional Long Short-term\nMemory (BiLSTM), to efficiently capture features across tweets. To the best of\nour knowledge, our work is the first that develops a recurrent neural model\nwith word embeddings to distinguish Twitter bots from human accounts, that\nrequires no prior knowledge or assumption about users' profiles, friendship\nnetworks, or historical behavior on the target account. Moreover, our model\ndoes not require any handcrafted features. The preliminary simulation results\nare very encouraging. Experiments on the cresci-2017 dataset show that our\napproach can achieve competitive performance compared with existing\nstate-of-the-art bot detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:07:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wei", "Feng", ""], ["Nguyen", "Uyen Trang", ""]]}, {"id": "2002.01359", "submitter": "Abhinav Rastogi", "authors": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, Pranav\n  Khaitan", "title": "Schema-Guided Dialogue State Tracking Task at DSTC8", "comments": "Presented at DSTC workshop, AAAI 2020. arXiv admin note: text overlap\n  with arXiv:1909.05855", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper gives an overview of the Schema-Guided Dialogue State Tracking\ntask of the 8th Dialogue System Technology Challenge. The goal of this task is\nto develop dialogue state tracking models suitable for large-scale virtual\nassistants, with a focus on data-efficient joint modeling across domains and\nzero-shot generalization to new APIs. This task provided a new dataset\nconsisting of over 16000 dialogues in the training set spanning 16 domains to\nhighlight these challenges, and a baseline model capable of zero-shot\ngeneralization to new APIs. Twenty-five teams participated, developing a range\nof neural network models, exceeding the performance of the baseline model by a\nvery high margin. The submissions incorporated a variety of pre-trained\nencoders and data augmentation techniques. This paper describes the task\ndefinition, dataset and evaluation methodology. We also summarize the approach\nand results of the submitted systems to highlight the overall trends in the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 05:59:27 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Rastogi", "Abhinav", ""], ["Zang", "Xiaoxue", ""], ["Sunkara", "Srinivas", ""], ["Gupta", "Raghav", ""], ["Khaitan", "Pranav", ""]]}, {"id": "2002.01365", "submitter": "Shangmin Guo", "authors": "Yi Ren, Shangmin Guo, Matthieu Labeau, Shay B. Cohen, Simon Kirby", "title": "Compositional Languages Emerge in a Neural Iterated Learning Model", "comments": "accepted by ICLR-2020", "journal-ref": "ICLR-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of compositionality, which enables natural language to\nrepresent complex concepts via a structured combination of simpler ones, allows\nus to convey an open-ended set of messages using a limited vocabulary. If\ncompositionality is indeed a natural property of language, we may expect it to\nappear in communication protocols that are created by neural agents in language\ngames. In this paper, we propose an effective neural iterated learning (NIL)\nalgorithm that, when applied to interacting neural agents, facilitates the\nemergence of a more structured type of language. Indeed, these languages\nprovide learning speed advantages to neural agents during training, which can\nbe incrementally amplified via NIL. We provide a probabilistic model of NIL and\nan explanation of why the advantage of compositional language exist. Our\nexperiments confirm our analysis, and also demonstrate that the emerged\nlanguages largely improve the generalizing power of the neural agent\ncommunication.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:19:09 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:22:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ren", "Yi", ""], ["Guo", "Shangmin", ""], ["Labeau", "Matthieu", ""], ["Cohen", "Shay B.", ""], ["Kirby", "Simon", ""]]}, {"id": "2002.01412", "submitter": "Neil Mallinar", "authors": "Neil Mallinar, Abhishek Shah, Tin Kam Ho, Rajendra Ugrani, Ayush Gupta", "title": "Iterative Data Programming for Expanding Text Classification Corpora", "comments": "6 pages, 2 figures, In Proceedings of the AAAI Conference on\n  Artificial Intelligence 2020 (IAAI Technical Track: Emerging Papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world text classification tasks often require many labeled training\nexamples that are expensive to obtain. Recent advancements in machine teaching,\nspecifically the data programming paradigm, facilitate the creation of training\ndata sets quickly via a general framework for building weak models, also known\nas labeling functions, and denoising them through ensemble learning techniques.\nWe present a fast, simple data programming method for augmenting text data sets\nby generating neighborhood-based weak models with minimal supervision.\nFurthermore, our method employs an iterative procedure to identify sparsely\ndistributed examples from large volumes of unlabeled data. The iterative data\nprogramming techniques improve newer weak models as more labeled data is\nconfirmed with human-in-loop. We show empirical results on sentence\nclassification tasks, including those from a task of improving intent\nrecognition in conversational agents.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:12:43 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mallinar", "Neil", ""], ["Shah", "Abhishek", ""], ["Ho", "Tin Kam", ""], ["Ugrani", "Rajendra", ""], ["Gupta", "Ayush", ""]]}, {"id": "2002.01415", "submitter": "Arlene Casey J", "authors": "Arlene Casey, Mike Bennett, Richard Tobin, Claire Grover, Iona Walker,\n  Lukas Engelmann, Beatrice Alex", "title": "Plague Dot Text: Text mining and annotation of outbreak reports of the\n  Third Plague Pandemic (1894-1952)", "comments": "Journal of Data Mining & Digital Humanities 2021", "journal-ref": "Journal of Data Mining & Digital Humanities, HistoInformatics,\n  HistoInformatics (January 20, 2021) jdmdh:7105", "doi": "10.46298/jdmdh.6071", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of models that govern diseases in population is commonly built on\ninformation and data gathered from past outbreaks. However, epidemic outbreaks\nare never captured in statistical data alone but are communicated by\nnarratives, supported by empirical observations. Outbreak reports discuss\ncorrelations between populations, locations and the disease to infer insights\ninto causes, vectors and potential interventions. The problem with these\nnarratives is usually the lack of consistent structure or strong conventions,\nwhich prohibit their formal analysis in larger corpora. Our interdisciplinary\nresearch investigates more than 100 reports from the third plague pandemic\n(1894-1952) evaluating ways of building a corpus to extract and structure this\nnarrative information through text mining and manual annotation. In this paper\nwe discuss the progress of our ongoing exploratory project, how we enhance\noptical character recognition (OCR) methods to improve text capture, our\napproach to structure the narratives and identify relevant entities in the\nreports. The structured corpus is made available via Solr enabling search and\nanalysis across the whole collection for future research dedicated, for\nexample, to the identification of concepts. We show preliminary visualisations\nof the characteristics of causation and differences with respect to gender as a\nresult of syntactic-category-dependent corpus statistics. Our goal is to\ndevelop structured accounts of some of the most significant concepts that were\nused to understand the epidemiology of the third plague pandemic around the\nglobe. The corpus enables researchers to analyse the reports collectively\nallowing for deep insights into the global epidemiological consideration of\nplague in the early twentieth century.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:16:36 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 19:16:54 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 11:08:08 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Casey", "Arlene", ""], ["Bennett", "Mike", ""], ["Tobin", "Richard", ""], ["Grover", "Claire", ""], ["Walker", "Iona", ""], ["Engelmann", "Lukas", ""], ["Alex", "Beatrice", ""]]}, {"id": "2002.01454", "submitter": "Alexander Mehler", "authors": "Alexander Mehler and R\\\"udiger Gleim and Regina Gaitsch and Wahed\n  Hemati and Tolga Uslu", "title": "From Topic Networks to Distributed Cognitive Maps: Zipfian Topic\n  Universes in the Area of Volunteered Geographic Information", "comments": "65 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are nearby places (e.g. cities) described by related words? In this article\nwe transfer this research question in the field of lexical encoding of\ngeographic information onto the level of intertextuality. To this end, we\nexplore Volunteered Geographic Information (VGI) to model texts addressing\nplaces at the level of cities or regions with the help of so-called topic\nnetworks. This is done to examine how language encodes and networks geographic\ninformation on the aboutness level of texts. Our hypothesis is that the\nnetworked thematizations of places are similar - regardless of their distances\nand the underlying communities of authors. To investigate this we introduce\nMultiplex Topic Networks (MTN), which we automatically derive from Linguistic\nMultilayer Networks (LMN) as a novel model, especially of thematic networking\nin text corpora. Our study shows a Zipfian organization of the thematic\nuniverse in which geographical places (especially cities) are located in online\ncommunication. We interpret this finding in the context of cognitive maps, a\nnotion which we extend by so-called thematic maps. According to our\ninterpretation of this finding, the organization of thematic maps as part of\ncognitive maps results from a tendency of authors to generate shareable content\nthat ensures the continued existence of the underlying media. We test our\nhypothesis by example of special wikis and extracts of Wikipedia. In this way\nwe come to the conclusion: Places, whether close to each other or not, are\nlocated in neighboring places that span similar subnetworks in the topic\nuniverse.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:31:25 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mehler", "Alexander", ""], ["Gleim", "R\u00fcdiger", ""], ["Gaitsch", "Regina", ""], ["Hemati", "Wahed", ""], ["Uslu", "Tolga", ""]]}, {"id": "2002.01462", "submitter": "Jesus Perez-Martin", "authors": "Jesus Perez-Martin, Benjamin Bustos, Magdalena Saldana", "title": "Semantic Search of Memes on Twitter", "comments": "Computational Methods Interest Group of the 70th International\n  Communication Association Conference, May 2020 Virtual conference\n  presentation link: https://player.vimeo.com/video/418320378", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memes are becoming a useful source of data for analyzing behavior on social\nmedia. However, a problem to tackle is how to correctly identify a meme. As the\nnumber of memes published every day on social media is huge, there is a need\nfor automatic methods for classifying and searching in large meme datasets.\nThis paper proposes and compares several methods for automatically classifying\nimages as memes. Also, we propose a method that allows us to implement a system\nfor retrieving memes from a dataset using a textual query. We experimentally\nevaluate the methods using a large dataset of memes collected from Twitter\nusers in Chile, which was annotated by a group of experts. Though some of the\nevaluated methods are effective, there is still room for improvement.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:40:38 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 02:41:50 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 03:44:35 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 23:44:26 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Perez-Martin", "Jesus", ""], ["Bustos", "Benjamin", ""], ["Saldana", "Magdalena", ""]]}, {"id": "2002.01464", "submitter": "Jiayuan Mao", "authors": "Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu", "title": "Visual Concept-Metaconcept Learning", "comments": "NeurIPS 2019. First two authors contributed equally. Project page:\n  http://vcml.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans reason with concepts and metaconcepts: we recognize red and green from\nvisual input; we also understand that they describe the same property of\nobjects (i.e., the color). In this paper, we propose the visual\nconcept-metaconcept learner (VCML) for joint learning of concepts and\nmetaconcepts from images and associated question-answer pairs. The key is to\nexploit the bidirectional connection between visual concepts and metaconcepts.\nVisual representations provide grounding cues for predicting relations between\nunseen pairs of concepts. Knowing that red and green describe the same property\nof objects, we generalize to the fact that cube and sphere also describe the\nsame property of objects, since they both categorize the shape of objects.\nMeanwhile, knowledge about metaconcepts empowers visual concept learning from\nlimited, noisy, and even biased data. From just a few examples of purple cubes\nwe can understand a new color purple, which resembles the hue of the cubes\ninstead of the shape of them. Evaluation on both synthetic and real-world\ndatasets validates our claims.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:42:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Han", "Chi", ""], ["Mao", "Jiayuan", ""], ["Gan", "Chuang", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "2002.01510", "submitter": "Robert Hawkins", "authors": "Robert D. Hawkins, Noah D. Goodman, Adele E. Goldberg, Thomas L.\n  Griffiths", "title": "Generalizing meanings from partners to populations: Hierarchical\n  inference supports convention formation on networks", "comments": "CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key property of linguistic conventions is that they hold over an entire\ncommunity of speakers, allowing us to communicate efficiently even with people\nwe have never met before. At the same time, much of our language use is\npartner-specific: we know that words may be understood differently by different\npeople based on our shared history. This poses a challenge for accounts of\nconvention formation. Exactly how do agents make the inferential leap to\ncommunity-wide expectations while maintaining partner-specific knowledge? We\npropose a hierarchical Bayesian model to explain how speakers and listeners\nsolve this inductive problem. To evaluate our model's predictions, we conducted\nan experiment where participants played an extended natural-language\ncommunication game with different partners in a small community. We examine\nseveral measures of generalization and find key signatures of both\npartner-specificity and community convergence that distinguish our model from\nalternatives. These results suggest that partner-specificity is not only\ncompatible with the formation of community-wide conventions, but may facilitate\nit when coupled with a powerful inductive mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 19:30:55 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 07:07:50 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hawkins", "Robert D.", ""], ["Goodman", "Noah D.", ""], ["Goldberg", "Adele E.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2002.01535", "submitter": "Shrey Desai", "authors": "Shrey Desai, Geoffrey Goh, Arun Babu, Ahmed Aly", "title": "Lightweight Convolutional Representations for On-Device Natural Language\n  Processing", "comments": "Accepted to MLSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing computational and memory complexities of deep neural networks\nhave made it difficult to deploy them on low-resource electronic devices (e.g.,\nmobile phones, tablets, wearables). Practitioners have developed numerous model\ncompression methods to address these concerns, but few have condensed input\nrepresentations themselves. In this work, we propose a fast, accurate, and\nlightweight convolutional representation that can be swapped into any neural\nmodel and compressed significantly (up to 32x) with a negligible reduction in\nperformance. In addition, we show gains over recurrent representations when\nconsidering resource-centric metrics (e.g., model file size, latency, memory\nusage) on a Samsung Galaxy S9.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:02:11 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Desai", "Shrey", ""], ["Goh", "Geoffrey", ""], ["Babu", "Arun", ""], ["Aly", "Ahmed", ""]]}, {"id": "2002.01664", "submitter": "Krishna D N", "authors": "Krishna D N, Ankita Patil, M.S.P Raj, Sai Prasad H S, Prabhu Aashish\n  Garapati", "title": "Identification of Indian Languages using Ghost-VLAD pooling", "comments": null, "journal-ref": "REJECTED ICASSP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a new pooling strategy for language identification\nby considering Indian languages. The idea is to obtain utterance level features\nfor any variable length audio for robust language recognition. We use the\nGhostVLAD approach to generate an utterance level feature vector for any\nvariable length input audio by aggregating the local frame level features\nacross time. The generated feature vector is shown to have very good language\ndiscriminative features and helps in getting state of the art results for\nlanguage identification task. We conduct our experiments on 635Hrs of audio\ndata for 7 Indian languages. Our method outperforms the previous state of the\nart x-vector [11] method by an absolute improvement of 1.88% in F1-score and\nachieves 98.43% F1-score on the held-out test data. We compare our system with\nvarious pooling approaches and show that GhostVLAD is the best pooling approach\nfor this task. We also provide visualization of the utterance level embeddings\ngenerated using Ghost-VLAD pooling and show that this method creates embeddings\nwhich has very good language discriminative features.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 07:07:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["N", "Krishna D", ""], ["Patil", "Ankita", ""], ["Raj", "M. S. P", ""], ["S", "Sai Prasad H", ""], ["Garapati", "Prabhu Aashish", ""]]}, {"id": "2002.01685", "submitter": "David Vilares", "authors": "David Vilares and Michalina Strzyz and Anders S{\\o}gaard and Carlos\n  G\\'omez-Rodr\\'iguez", "title": "Parsing as Pretraining", "comments": "AAAI 2020 - The Thirty-Fourth AAAI Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent analyses suggest that encoders pretrained for language modeling\ncapture certain morpho-syntactic structure. However, probing frameworks for\nword vectors still do not report results on standard setups such as constituent\nand dependency parsing. This paper addresses this problem and does full parsing\n(on English) relying only on pretraining architectures -- and no decoding. We\nfirst cast constituent and dependency parsing as sequence tagging. We then use\na single feed-forward layer to directly map word vectors to labels that encode\na linearized tree. This is used to: (i) see how far we can reach on syntax\nmodelling with just pretrained encoders, and (ii) shed some light about the\nsyntax-sensitivity of different word vectors (by freezing the weights of the\npretraining network during training). For evaluation, we use bracketing\nF1-score and LAS, and analyze in-depth differences across representations for\nspan lengths and dependency displacements. The overall results surpass existing\nsequence tagging parsers on the PTB (93.5%) and end-to-end EN-EWT UD (78.8%).\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 08:43:02 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Vilares", "David", ""], ["Strzyz", "Michalina", ""], ["S\u00f8gaard", "Anders", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2002.01761", "submitter": "Mingchen Li", "authors": "Mingchen Li and Zili Zhou and Yanna Wang", "title": "Multi-Fusion Chinese WordNet (MCW) : Compound of Machine Learning and\n  Manual Correction", "comments": "7 pages. CICLing 2019: International Conference on Computational\n  Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Princeton WordNet (PWN) is a lexicon-semantic network based on cognitive\nlinguistics, which promotes the development of natural language processing.\nBased on PWN, five Chinese wordnets have been developed to solve the problems\nof syntax and semantics. They include: Northeastern University Chinese WordNet\n(NEW), Sinica Bilingual Ontological WordNet (BOW), Southeast University Chinese\nWordNet (SEW), Taiwan University Chinese WordNet (CWN), Chinese Open WordNet\n(COW). By using them, we found that these word networks have low accuracy and\ncoverage, and cannot completely portray the semantic network of PWN. So we\ndecided to make a new Chinese wordnet called Multi-Fusion Chinese Wordnet (MCW)\nto make up those shortcomings. The key idea is to extend the SEW with the help\nof Oxford bilingual dictionary and Xinhua bilingual dictionary, and then\ncorrect it. More specifically, we used machine learning and manual adjustment\nin our corrections. Two standards were formulated to help our work. We\nconducted experiments on three tasks including relatedness calculation, word\nsimilarity and word sense disambiguation for the comparison of lemma's\naccuracy, at the same time, coverage also was compared. The results indicate\nthat MCW can benefit from coverage and accuracy via our method. However, it\nstill has room for improvement, especially with lemmas. In the future, we will\ncontinue to enhance the accuracy of MCW and expand the concepts in it.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 12:44:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Li", "Mingchen", ""], ["Zhou", "Zili", ""], ["Wang", "Yanna", ""]]}, {"id": "2002.01808", "submitter": "Ruize Wang", "authors": "Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Jianshu\n  ji, Guihong Cao, Daxin Jiang, Ming Zhou", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of injecting knowledge into large pre-trained models\nlike BERT and RoBERTa. Existing methods typically update the original\nparameters of pre-trained models when injecting knowledge. However, when\nmultiple kinds of knowledge are injected, the historically injected knowledge\nwould be flushed away. To address this, we propose K-Adapter, a framework that\nretains the original parameters of the pre-trained model fixed and supports the\ndevelopment of versatile knowledge-infused model. Taking RoBERTa as the\nbackbone model, K-Adapter has a neural adapter for each kind of infused\nknowledge, like a plug-in connected to RoBERTa. There is no information flow\nbetween different adapters, thus multiple adapters can be efficiently trained\nin a distributed way. As a case study, we inject two kinds of knowledge in this\nwork, including (1) factual knowledge obtained from automatically aligned\ntext-triplets on Wikipedia and Wikidata and (2) linguistic knowledge obtained\nvia dependency parsing. Results on three knowledge-driven tasks, including\nrelation classification, entity typing, and question answering, demonstrate\nthat each adapter improves the performance and the combination of both adapters\nbrings further improvements. Further analysis indicates that K-Adapter captures\nversatile knowledge than RoBERTa.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:30:49 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 03:30:44 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 06:29:54 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 16:11:45 GMT"}, {"version": "v5", "created": "Mon, 28 Dec 2020 06:07:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wang", "Ruize", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Wei", "Zhongyu", ""], ["Huang", "Xuanjing", ""], ["ji", "Jianshu", ""], ["Cao", "Guihong", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.01824", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "Discontinuous Constituent Parsing with Pointer Networks", "comments": "Proceedings of AAAI 2020. 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most complex syntactic representations used in computational\nlinguistics and NLP are discontinuous constituent trees, crucial for\nrepresenting all grammatical phenomena of languages such as German. Recent\nadvances in dependency parsing have shown that Pointer Networks excel in\nefficiently parsing syntactic relations between words in a sentence. This kind\nof sequence-to-sequence models achieve outstanding accuracies in building\nnon-projective dependency trees, but its potential has not been proved yet on a\nmore difficult task. We propose a novel neural network architecture that, by\nmeans of Pointer Networks, is able to generate the most accurate discontinuous\nconstituent representations to date, even without the need of Part-of-Speech\ntagging information. To do so, we internally model discontinuous constituent\nstructures as augmented non-projective dependency structures. The proposed\napproach achieves state-of-the-art results on the two widely-used NEGRA and\nTIGER benchmarks, outperforming previous work by a wide margin.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 15:12:03 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2002.01846", "submitter": "Elad Kravi Mr.", "authors": "Elad Kravi, Benny Kimelfeld, Yaron Kanza, Roi Reichart", "title": "Geosocial Location Classification: Associating Type to Places Based on\n  Geotagged Social-Media Posts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associating type to locations can be used to enrich maps and can serve a\nplethora of geospatial applications. An automatic method to do so could make\nthe process less expensive in terms of human labor, and faster to react to\nchanges. In this paper we study the problem of Geosocial Location\nClassification, where the type of a site, e.g., a building, is discovered based\non social-media posts. Our goal is to correctly associate a set of messages\nposted in a small radius around a given location with the corresponding\nlocation type, e.g., school, church, restaurant or museum. We explore two\napproaches to the problem: (a) a pipeline approach, where each message is first\nclassified, and then the location associated with the message set is inferred\nfrom the individual message labels; and (b) a joint approach where the\nindividual messages are simultaneously processed to yield the desired location\ntype. We tested the two approaches over a dataset of geotagged tweets. Our\nresults demonstrate the superiority of the joint approach. Moreover, we show\nthat due to the unique structure of the problem, where weakly-related messages\nare jointly processed to yield a single final label, linear classifiers\noutperform deep neural network alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:09:52 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 11:16:46 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Kravi", "Elad", ""], ["Kimelfeld", "Benny", ""], ["Kanza", "Yaron", ""], ["Reichart", "Roi", ""]]}, {"id": "2002.01861", "submitter": "Jimmy Lin", "authors": "Ruixue Zhang, Wei Yang, Luyun Lin, Zhengkai Tu, Yuqing Xie, Zihang Fu,\n  Yuhao Xie, Luchen Tan, Kun Xiong, Jimmy Lin", "title": "Rapid Adaptation of BERT for Information Extraction on Domain-Specific\n  Business Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for automatically extracting important content elements from\nbusiness documents such as contracts, statements, and filings have the\npotential to make business operations more efficient. This problem can be\nformulated as a sequence labeling task, and we demonstrate the adaption of BERT\nto two types of business documents: regulatory filings and property lease\nagreements. There are aspects of this problem that make it easier than\n\"standard\" information extraction tasks and other aspects that make it more\ndifficult, but on balance we find that modest amounts of annotated data (less\nthan 100 documents) are sufficient to achieve reasonable accuracy. We integrate\nour models into an end-to-end cloud platform that provides both an easy-to-use\nannotation interface as well as an inference interface that allows users to\nupload documents and inspect model outputs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:45:44 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Ruixue", ""], ["Yang", "Wei", ""], ["Lin", "Luyun", ""], ["Tu", "Zhengkai", ""], ["Xie", "Yuqing", ""], ["Fu", "Zihang", ""], ["Xie", "Yuhao", ""], ["Tan", "Luchen", ""], ["Xiong", "Kun", ""], ["Lin", "Jimmy", ""]]}, {"id": "2002.01862", "submitter": "Ziang Xiao", "authors": "Ziang Xiao, Michelle X. Zhou, Wenxi Chen, Huahai Yang, Changyan Chi", "title": "If I Hear You Correctly: Building and Evaluating Interview Chatbots with\n  Active Listening Skills", "comments": "Working draft. To appear in the ACM CHI Conference on Human Factors\n  in Computing Systems (CHI 2020)", "journal-ref": null, "doi": "10.1145/3313831.3376131", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interview chatbots engage users in a text-based conversation to draw out\ntheir views and opinions. It is, however, challenging to build effective\ninterview chatbots that can handle user free-text responses to open-ended\nquestions and deliver engaging user experience. As the first step, we are\ninvestigating the feasibility and effectiveness of using publicly available,\npractical AI technologies to build effective interview chatbots. To demonstrate\nfeasibility, we built a prototype scoped to enable interview chatbots with a\nsubset of active listening skills - the abilities to comprehend a user's input\nand respond properly. To evaluate the effectiveness of our prototype, we\ncompared the performance of interview chatbots with or without active listening\nskills on four common interview topics in a live evaluation with 206 users. Our\nwork presents practical design implications for building effective interview\nchatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:52:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Xiao", "Ziang", ""], ["Zhou", "Michelle X.", ""], ["Chen", "Wenxi", ""], ["Yang", "Huahai", ""], ["Chi", "Changyan", ""]]}, {"id": "2002.01984", "submitter": "Wlodek Zadrozny", "authors": "Sai Krishna Telukuntla, Aditya Kapri and Wlodek Zadrozny", "title": "UNCC Biomedical Semantic Question Answering Systems. BioASQ: Task-7B,\n  Phase-B", "comments": "28 pages, 8 figures. This is an expanded version of our submission to\n  2019 BioAsq competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we detail our submission to the 2019, 7th year, BioASQ\ncompetition. We present our approach for Task-7b, Phase B, Exact Answering\nTask. These Question Answering (QA) tasks include Factoid, Yes/No, List Type\nQuestion answering. Our system is based on a contextual word embedding model.\nWe have used a Bidirectional Encoder Representations from Transformers(BERT)\nbased system, fined tuned for biomedical question answering task using BioBERT.\nIn the third test batch set, our system achieved the highest MRR score for\nFactoid Question Answering task. Also, for List type question answering task\nour system achieved the highest recall score in the fourth test batch set.\nAlong with our detailed approach, we present the results for our submissions,\nand also highlight identified downsides for our current approach and ways to\nimprove them in our future experiments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 20:43:14 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Telukuntla", "Sai Krishna", ""], ["Kapri", "Aditya", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "2002.02000", "submitter": "Nuo Wang Pierse", "authors": "Nuo Wang Pierse, Jingwen Lu", "title": "Aligning the Pretraining and Finetuning Objectives of Language Models", "comments": "8 pages, 2 figures and 6 tables. Submitted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that explicitly aligning the pretraining objectives to the\nfinetuning objectives in language model training significantly improves the\nfinetuning task performance and reduces the minimum amount of finetuning\nexamples required. The performance margin gained from objective alignment\nallows us to build language models with smaller sizes for tasks with less\navailable training data. We provide empirical evidence of these claims by\napplying objective alignment to concept-of-interest tagging and acronym\ndetection tasks. We found that, with objective alignment, our 768 by 3 and 512\nby 3 transformer language models can reach accuracy of 83.9%/82.5% for\nconcept-of-interest tagging and 73.8%/70.2% for acronym detection using only\n200 finetuning examples per task, outperforming the 768 by 3 model pretrained\nwithout objective alignment by +4.8%/+3.4% and +9.9%/+6.3%. We name finetuning\nsmall language models in the presence of hundreds of training examples or less\n\"Few Example learning\". In practice, Few Example Learning enabled by objective\nalignment not only saves human labeling costs, but also makes it possible to\nleverage language models in more real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:40:50 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Pierse", "Nuo Wang", ""], ["Lu", "Jingwen", ""]]}, {"id": "2002.02031", "submitter": "Nabil Hossain", "authors": "Nabil Hossain, John Krumm, Tanvir Sajed and Henry Kautz", "title": "Stimulating Creativity with FunLines: A Case Study of Humor Generation\n  in Headlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building datasets of creative text, such as humor, is quite challenging. We\nintroduce FunLines, a competitive game where players edit news headlines to\nmake them funny, and where they rate the funniness of headlines edited by\nothers. FunLines makes the humor generation process fun, interactive,\ncollaborative, rewarding and educational, keeping players engaged and providing\nhumor data at a very low cost compared to traditional crowdsourcing approaches.\nFunLines offers useful performance feedback, assisting players in getting\nbetter over time at generating and assessing humor, as our analysis shows. This\nhelps to further increase the quality of the generated dataset. We show the\neffectiveness of this data by training humor classification models that\noutperform a previous benchmark, and we release this dataset to the public.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:56:11 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hossain", "Nabil", ""], ["Krumm", "John", ""], ["Sajed", "Tanvir", ""], ["Kautz", "Henry", ""]]}, {"id": "2002.02070", "submitter": "Habeeb Hooshmand", "authors": "Habeeb Hooshmand, James Caverlee", "title": "Understanding Car-Speak: Replacing Humans in Dealerships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large portion of the car-buying experience in the United States involves\ninteractions at a car dealership. At the dealership, the car-buyer relays their\nneeds to a sales representative. However, most car-buyers are only have an\nabstract description of the vehicle they need. Therefore, they are only able to\ndescribe their ideal car in \"car-speak\". Car-speak is abstract language that\npertains to a car's physical attributes. In this paper, we define car-speak. We\nalso aim to curate a reasonable data set of car-speak language. Finally, we\ntrain several classifiers in order to classify car-speak.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:10:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hooshmand", "Habeeb", ""], ["Caverlee", "James", ""]]}, {"id": "2002.02095", "submitter": "Yun-Zhu Song", "authors": "Yun-Zhu Song (1), Hong-Han Shuai (1), Sung-Lin Yeh (2), Yi-Lun Wu (1),\n  Lun-Wei Ku (3), Wen-Chih Peng (1) ((1) National Chiao Tung University,\n  Taiwan, (2) National Tsing Hua University, Taiwan, (3) Academia Sinica,\n  Taiwan)", "title": "Attractive or Faithful? Popularity-Reinforced Learning for Inspired\n  Headline Generation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid proliferation of online media sources and published news,\nheadlines have become increasingly important for attracting readers to news\narticles, since users may be overwhelmed with the massive information. In this\npaper, we generate inspired headlines that preserve the nature of news articles\nand catch the eye of the reader simultaneously. The task of inspired headline\ngeneration can be viewed as a specific form of Headline Generation (HG) task,\nwith the emphasis on creating an attractive headline from a given news article.\nTo generate inspired headlines, we propose a novel framework called\nPOpularity-Reinforced Learning for inspired Headline Generation (PORL-HG).\nPORL-HG exploits the extractive-abstractive architecture with 1) Popular Topic\nAttention (PTA) for guiding the extractor to select the attractive sentence\nfrom the article and 2) a popularity predictor for guiding the abstractor to\nrewrite the attractive sentence. Moreover, since the sentence selection of the\nextractor is not differentiable, techniques of reinforcement learning (RL) are\nutilized to bridge the gap with rewards obtained from a popularity score\npredictor. Through quantitative and qualitative experiments, we show that the\nproposed PORL-HG significantly outperforms the state-of-the-art headline\ngeneration models in terms of attractiveness evaluated by both human (71.03%)\nand the predictor (at least 27.60%), while the faithfulness of PORL-HG is also\ncomparable to the state-of-the-art generation model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:37:44 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Song", "Yun-Zhu", ""], ["Shuai", "Hong-Han", ""], ["Yeh", "Sung-Lin", ""], ["Wu", "Yi-Lun", ""], ["Ku", "Lun-Wei", ""], ["Peng", "Wen-Chih", ""]]}, {"id": "2002.02109", "submitter": "Herman Kamper", "authors": "Herman Kamper, Yevgen Matusevych, Sharon Goldwater", "title": "Multilingual acoustic word embedding models for processing zero-resource\n  languages", "comments": "5 pages, 4 figures, 1 table; accepted to ICASSP 2020. arXiv admin\n  note: text overlap with arXiv:1811.00403", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic word embeddings are fixed-dimensional representations of\nvariable-length speech segments. In settings where unlabelled speech is the\nonly available resource, such embeddings can be used in \"zero-resource\" speech\nsearch, indexing and discovery systems. Here we propose to train a single\nsupervised embedding model on labelled data from multiple well-resourced\nlanguages and then apply it to unseen zero-resource languages. For this\ntransfer learning approach, we consider two multilingual recurrent neural\nnetwork models: a discriminative classifier trained on the joint vocabularies\nof all training languages, and a correspondence autoencoder trained to\nreconstruct word pairs. We test these using a word discrimination task on six\ntarget zero-resource languages. When trained on seven well-resourced languages,\nboth models perform similarly and outperform unsupervised models trained on the\nzero-resource languages. With just a single training language, the second model\nworks better, but performance depends more on the particular training--testing\nlanguage pair.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 05:53:41 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 14:19:56 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Kamper", "Herman", ""], ["Matusevych", "Yevgen", ""], ["Goldwater", "Sharon", ""]]}, {"id": "2002.02153", "submitter": "Minghong Xu", "authors": "Minghong Xu, Piji Li, Haoran Yang, Pengjie Ren, Zhaochun Ren, Zhumin\n  Chen, Jun Ma", "title": "A Neural Topical Expansion Framework for Unstructured Persona-oriented\n  Dialogue Generation", "comments": "Accepted by ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured Persona-oriented Dialogue Systems (UPDS) has been demonstrated\neffective in generating persona consistent responses by utilizing predefined\nnatural language user persona descriptions (e.g., \"I am a vegan\"). However, the\npredefined user persona descriptions are usually short and limited to only a\nfew descriptive words, which makes it hard to correlate them with the\ndialogues. As a result, existing methods either fail to use the persona\ndescription or use them improperly when generating persona consistent\nresponses. To address this, we propose a neural topical expansion framework,\nnamely Persona Exploration and Exploitation (PEE), which is able to extend the\npredefined user persona description with semantically correlated content before\nutilizing them to generate dialogue responses. PEE consists of two main\nmodules: persona exploration and persona exploitation. The former learns to\nextend the predefined user persona description by mining and correlating with\nexisting dialogue corpus using a variational auto-encoder (VAE) based topic\nmodel. The latter learns to generate persona consistent responses by utilizing\nthe predefined and extended user persona description. In order to make persona\nexploitation learn to utilize user persona description more properly, we also\nintroduce two persona-oriented loss functions: Persona-oriented Matching\n(P-Match) loss and Persona-oriented Bag-of-Words (P-BoWs) loss which\nrespectively supervise persona selection in encoder and decoder. Experimental\nresults show that our approach outperforms state-of-the-art baselines, in terms\nof both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:24:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Xu", "Minghong", ""], ["Li", "Piji", ""], ["Yang", "Haoran", ""], ["Ren", "Pengjie", ""], ["Ren", "Zhaochun", ""], ["Chen", "Zhumin", ""], ["Ma", "Jun", ""]]}, {"id": "2002.02154", "submitter": "Kumar Shikhar Deep", "authors": "Kumar Shikhar Deep, Md Shad Akhtar, Asif Ekbal, and Pushpak\n  Bhattacharyya", "title": "Related Tasks can Share! A Multi-task Framework for Affective language", "comments": "12 pages, 3 figures and 3 tables. Accepted in 20th International\n  Conference on Intelligent Text Processing and Computational Linguistics,\n  CICLing 2019. To be published in Springer LNCS volume", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressing the polarity of sentiment as 'positive' and 'negative' usually\nhave limited scope compared with the intensity/degree of polarity. These two\ntasks (i.e. sentiment classification and sentiment intensity prediction) are\nclosely related and may offer assistance to each other during the learning\nprocess. In this paper, we propose to leverage the relatedness of multiple\ntasks in a multi-task learning framework. Our multi-task model is based on\nconvolutional-Gated Recurrent Unit (GRU) framework, which is further assisted\nby a diverse hand-crafted feature set. Evaluation and analysis suggest that\njoint-learning of the related tasks in a multi-task framework can outperform\neach of the individual tasks in the single-task frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:36:38 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Deep", "Kumar Shikhar", ""], ["Akhtar", "Md Shad", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2002.02224", "submitter": "Jakub Hara\\v{s}ta Ph.D", "authors": "Jakub Hara\\v{s}ta, Tereza Novotn\\'a, Jarom\\'ir \\v{S}avelka", "title": "Citation Data of Czech Apex Courts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the citation data of the Czech apex courts\n(Supreme Court, Supreme Administrative Court and Constitutional Court). This\ndataset was automatically extracted from the corpus of texts of Czech court\ndecisions - CzCDC 1.0. We obtained the citation data by building the natural\nlanguage processing pipeline for extraction of the court decision identifiers.\nThe pipeline included the (i) document segmentation model and the (ii)\nreference recognition model. Furthermore, the dataset was manually processed to\nachieve high-quality citation data as a base for subsequent qualitative and\nquantitative analyses. The dataset will be made available to the general\npublic.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:35:14 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hara\u0161ta", "Jakub", ""], ["Novotn\u00e1", "Tereza", ""], ["\u0160avelka", "Jarom\u00edr", ""]]}, {"id": "2002.02238", "submitter": "Rishabh Gupta", "authors": "Rishabh Gupta and Rajesh N Rao", "title": "Towards Semantic Noise Cleansing of Categorical Data based on Semantic\n  Infusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic Noise affects text analytics activities for the domain-specific\nindustries significantly. It impedes the text understanding which holds prime\nimportance in the critical decision making tasks. In this work, we formalize\nsemantic noise as a sequence of terms that do not contribute to the narrative\nof the text. We look beyond the notion of standard statistically-based stop\nwords and consider the semantics of terms to exclude the semantic noise. We\npresent a novel Semantic Infusion technique to associate meta-data with the\ncategorical corpus text and demonstrate its near-lossless nature. Based on this\ntechnique, we propose an unsupervised text-preprocessing framework to filter\nthe semantic noise using the context of the terms. Later we present the\nevaluation results of the proposed framework using a web forum dataset from the\nautomobile-domain.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:11:46 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Gupta", "Rishabh", ""], ["Rao", "Rajesh N", ""]]}, {"id": "2002.02265", "submitter": "Evin Pinar Ornek", "authors": "Evin Pinar Ornek", "title": "Zero-Shot Activity Recognition with Videos", "comments": "This is a research report done during master's studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examined the zero-shot activity recognition task with the\nusage of videos. We introduce an auto-encoder based model to construct a\nmultimodal joint embedding space between the visual and textual manifolds. On\nthe visual side, we used activity videos and a state-of-the-art 3D\nconvolutional action recognition network to extract the features. On the\ntextual side, we worked with GloVe word embeddings. The zero-shot recognition\nresults are evaluated by top-n accuracy. Then, the manifold learning ability is\nmeasured by mean Nearest Neighbor Overlap. In the end, we provide an extensive\ndiscussion over the results and the future directions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:33:10 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ornek", "Evin Pinar", ""]]}, {"id": "2002.02353", "submitter": "Yingcheng Sun", "authors": "Yingcheng Sun and Kenneth Loparo and Richard Kolacinski", "title": "Conversational Structure Aware and Context Sensitive Topic Model for\n  Online Discussions", "comments": null, "journal-ref": "2020 IEEE 14th International Conference on Semantic Computing\n  (ICSC)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of online discussions are generated everyday on social media\nplatforms. Topic modelling is an efficient way of better understanding large\ntext datasets at scale. Conventional topic models have had limited success in\nonline discussions, and to overcome their limitations, we use the discussion\nthread tree structure and propose a \"popularity\" metric to quantify the number\nof replies to a comment to extend the frequency of word occurrences, and the\n\"transitivity\" concept to characterize topic dependency among nodes in a nested\ndiscussion thread. We build a Conversational Structure Aware Topic Model\n(CSATM) based on popularity and transitivity to infer topics and their\nassignments to comments. Experiments on real forum datasets are used to\ndemonstrate improved performance for topic extraction with six different\nmeasurements of coherence and impressive accuracy for topic assignments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:57:27 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Sun", "Yingcheng", ""], ["Loparo", "Kenneth", ""], ["Kolacinski", "Richard", ""]]}, {"id": "2002.02406", "submitter": "Daniel Daza", "authors": "Daniel Daza and Michael Cochez", "title": "Message Passing Query Embedding", "comments": "Presented at ICML 2020 - GRL+ Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on representation learning for Knowledge Graphs have moved\nbeyond the problem of link prediction, to answering queries of an arbitrary\nstructure. Existing methods are based on ad-hoc mechanisms that require\ntraining with a diverse set of query structures. We propose a more general\narchitecture that employs a graph neural network to encode a graph\nrepresentation of the query, where nodes correspond to entities and variables.\nThe generality of our method allows it to encode a more diverse set of query\ntypes in comparison to previous work. Our method shows competitive performance\nagainst previous models for complex queries, and in contrast with these models,\nit can answer complex queries when trained for link prediction only. We show\nthat the model learns entity embeddings that capture the notion of entity type\nwithout explicit supervision.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:40:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 11:35:19 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Daza", "Daniel", ""], ["Cochez", "Michael", ""]]}, {"id": "2002.02427", "submitter": "Bilal Ghanem", "authors": "Bilal Ghanem, Jihen Karoui, Farah Benamara, Paolo Rosso, V\\'eronique\n  Moriceau", "title": "Irony Detection in a Multilingual Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes the first multilingual (French, English and Arabic) and\nmulticultural (Indo-European languages vs. less culturally close languages)\nirony detection system. We employ both feature-based models and neural\narchitectures using monolingual word representation. We compare the performance\nof these systems with state-of-the-art systems to identify their capabilities.\nWe show that these monolingual models trained separately on different languages\nusing multilingual word representation or text-based features can open the door\nto irony detection in languages that lack of annotated data for irony.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:23:27 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ghanem", "Bilal", ""], ["Karoui", "Jihen", ""], ["Benamara", "Farah", ""], ["Rosso", "Paolo", ""], ["Moriceau", "V\u00e9ronique", ""]]}, {"id": "2002.02450", "submitter": "Pavel Gulyaev", "authors": "Pavel Gulyaev, Eugenia Elistratova, Vasily Konovalov, Yuri Kuratov,\n  Leonid Pugachev, Mikhail Burtsev", "title": "Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue State Tracking (DST) is a core component of virtual assistants such\nas Alexa or Siri. To accomplish various tasks, these assistants need to support\nan increasing number of services and APIs. The Schema-Guided State Tracking\ntrack of the 8th Dialogue System Technology Challenge highlighted the DST\nproblem for unseen services. The organizers introduced the Schema-Guided\nDialogue (SGD) dataset with multi-domain conversations and released a zero-shot\ndialogue state tracking model. In this work, we propose a GOaL-Oriented\nMulti-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures\nfor reading comprehension question answering systems. The model \"queries\"\ndialogue history with descriptions of slots and services as well as possible\nvalues of slots. This allows to transfer slot values in multi-domain dialogues\nand have a capability to scale to unseen slot types. Our model achieves a joint\ngoal accuracy of 53.97% on the SGD dataset, outperforming the baseline model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:56:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Gulyaev", "Pavel", ""], ["Elistratova", "Eugenia", ""], ["Konovalov", "Vasily", ""], ["Kuratov", "Yuri", ""], ["Pugachev", "Leonid", ""], ["Burtsev", "Mikhail", ""]]}, {"id": "2002.02492", "submitter": "Sean Welleck", "authors": "Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang,\n  Kyunghyun Cho", "title": "Consistency of a Recurrent Language Model With Respect to Incomplete\n  Decoding", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite strong performance on a variety of tasks, neural sequence models\ntrained with maximum likelihood have been shown to exhibit issues such as\nlength bias and degenerate repetition. We study the related issue of receiving\ninfinite-length sequences from a recurrent language model when using common\ndecoding algorithms. To analyze this issue, we first define inconsistency of a\ndecoding algorithm, meaning that the algorithm can yield an infinite-length\nsequence that has zero probability under the model. We prove that commonly used\nincomplete decoding algorithms - greedy search, beam search, top-k sampling,\nand nucleus sampling - are inconsistent, despite the fact that recurrent\nlanguage models are trained to produce sequences of finite length. Based on\nthese insights, we propose two remedies which address inconsistency: consistent\nvariants of top-k and nucleus sampling, and a self-terminating recurrent\nlanguage model. Empirical results show that inconsistency occurs in practice,\nand that the proposed methods prevent inconsistency.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 19:56:15 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 22:36:49 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Welleck", "Sean", ""], ["Kulikov", "Ilia", ""], ["Kim", "Jaedeok", ""], ["Pang", "Richard Yuanzhe", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2002.02511", "submitter": "Brendan Bena", "authors": "Brendan Bena and Jugal Kalita", "title": "Introducing Aspects of Creativity in Automatic Poetry Generation", "comments": "10 pages, 10 figures, 4 tables, ICON-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poetry Generation involves teaching systems to automatically generate text\nthat resembles poetic work. A deep learning system can learn to generate poetry\non its own by training on a corpus of poems and modeling the particular style\nof language. In this paper, we propose taking an approach that fine-tunes\nGPT-2, a pre-trained language model, to our downstream task of poetry\ngeneration. We extend prior work on poetry generation by introducing creative\nelements. Specifically, we generate poems that express emotion and elicit the\nsame in readers, and poems that use the language of dreams---called dream\npoetry. We are able to produce poems that correctly elicit the emotions of\nsadness and joy 87.5 and 85 percent, respectively, of the time. We produce\ndreamlike poetry by training on a corpus of texts that describe dreams. Poems\nfrom this model are shown to capture elements of dream poetry with scores of no\nless than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for\nall our poems. We also make use of the Coh-Metrix tool, outlining metrics we\nuse to gauge the quality of text generated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:44:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bena", "Brendan", ""], ["Kalita", "Jugal", ""]]}, {"id": "2002.02520", "submitter": "Shiva Sundaram", "authors": "Taejin Park, Kenichi Kumatani, Minhua Wu, Shiva Sundaram", "title": "Robust Multi-channel Speech Recognition using Frequency Aligned Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional speech enhancement technique such as beamforming has known\nbenefits for far-field speech recognition. Our own work in frequency-domain\nmulti-channel acoustic modeling has shown additional improvements by training a\nspatial filtering layer jointly within an acoustic model. In this paper, we\nfurther develop this idea and use frequency aligned network for robust\nmulti-channel automatic speech recognition (ASR). Unlike an affine layer in the\nfrequency domain, the proposed frequency aligned component prevents one\nfrequency bin influencing other frequency bins. We show that this modification\nnot only reduces the number of parameters in the model but also significantly\nand improves the ASR performance. We investigate effects of frequency aligned\nnetwork through ASR experiments on the real-world far-field data where users\nare interacting with an ASR system in uncontrolled acoustic environments. We\nshow that our multi-channel acoustic model with a frequency aligned network\nshows up to 18% relative reduction in word error rate.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:47:39 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Park", "Taejin", ""], ["Kumatani", "Kenichi", ""], ["Wu", "Minhua", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2002.02562", "submitter": "Qian Zhang", "authors": "Qian Zhang, Han Lu, Hasim Sak, Anshuman Tripathi, Erik McDermott,\n  Stephen Koo, Shankar Kumar", "title": "Transformer Transducer: A Streamable Speech Recognition Model with\n  Transformer Encoders and RNN-T Loss", "comments": "This is the final version of the paper submitted to the ICASSP 2020\n  on Oct 21, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an end-to-end speech recognition model with\nTransformer encoders that can be used in a streaming speech recognition system.\nTransformer computation blocks based on self-attention are used to encode both\naudio and label sequences independently. The activations from both audio and\nlabel encoders are combined with a feed-forward layer to compute a probability\ndistribution over the label space for every combination of acoustic frame\nposition and label history. This is similar to the Recurrent Neural Network\nTransducer (RNN-T) model, which uses RNNs for information encoding instead of\nTransformer encoders. The model is trained with the RNN-T loss well-suited to\nstreaming decoding. We present results on the LibriSpeech dataset showing that\nlimiting the left context for self-attention in the Transformer layers makes\ndecoding computationally tractable for streaming, with only a slight\ndegradation in accuracy. We also show that the full attention version of our\nmodel beats the-state-of-the art accuracy on the LibriSpeech benchmarks. Our\nresults also show that we can bridge the gap between full attention and limited\nattention versions of our model by attending to a limited number of future\nframes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:04:04 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 21:47:10 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Qian", ""], ["Lu", "Han", ""], ["Sak", "Hasim", ""], ["Tripathi", "Anshuman", ""], ["McDermott", "Erik", ""], ["Koo", "Stephen", ""], ["Kumar", "Shankar", ""]]}, {"id": "2002.02631", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Sandipan Dandapat, Sushil Chordia", "title": "Translating Web Search Queries into Natural Language Questions", "comments": "Eleventh International Conference on Language Resources and\n  Evaluation, LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users often query a search engine with a specific question in mind and often\nthese queries are keywords or sub-sentential fragments. For example, if the\nusers want to know the answer for \"What's the capital of USA\", they will most\nprobably query \"capital of USA\" or \"USA capital\" or some keyword-based\nvariation of this. For example, for the user entered query \"capital of USA\",\nthe most probable question intent is \"What's the capital of USA?\". In this\npaper, we are proposing a method to generate well-formed natural language\nquestion from a given keyword-based query, which has the same question intent\nas the query. Conversion of keyword-based web query into a well-formed question\nhas lots of applications, with some of them being in search engines, Community\nQuestion Answering (CQA) website and bots communication. We found a synergy\nbetween query-to-question problem with standard machine translation(MT) task.\nWe have used both Statistical MT (SMT) and Neural MT (NMT) models to generate\nthe questions from the query. We have observed that MT models perform well in\nterms of both automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 05:52:06 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kumar", "Adarsh", ""], ["Dandapat", "Sandipan", ""], ["Chordia", "Sushil", ""]]}, {"id": "2002.02649", "submitter": "Chaoqun Duan", "authors": "Chaoqun Duan and Lei Cui and Shuming Ma and Furu Wei and Conghui Zhu\n  and Tiejun Zhao", "title": "Multimodal Matching Transformer for Live Commenting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic live commenting aims to provide real-time comments on videos for\nviewers. It encourages users engagement on online video sites, and is also a\ngood benchmark for video-to-text generation. Recent work on this task adopts\nencoder-decoder models to generate comments. However, these methods do not\nmodel the interaction between videos and comments explicitly, so they tend to\ngenerate popular comments that are often irrelevant to the videos. In this\nwork, we aim to improve the relevance between live comments and videos by\nmodeling the cross-modal interactions among different modalities. To this end,\nwe propose a multimodal matching transformer to capture the relationships among\ncomments, vision, and audio. The proposed model is based on the transformer\nframework and can iteratively learn the attention-aware representations for\neach modality. We evaluate the model on a publicly available live commenting\ndataset. Experiments show that the multimodal matching transformer model\noutperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 07:19:15 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Duan", "Chaoqun", ""], ["Cui", "Lei", ""], ["Ma", "Shuming", ""], ["Wei", "Furu", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2002.02734", "submitter": "Patrick Bordes Mr", "authors": "Patrick Bordes, Eloi Zablocki, Laure Soulier, Benjamin Piwowarski,\n  Patrick Gallinari", "title": "Incorporating Visual Semantics into Sentence Representations within a\n  Grounded Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language grounding is an active field aiming at enriching textual\nrepresentations with visual information. Generally, textual and visual elements\nare embedded in the same representation space, which implicitly assumes a\none-to-one correspondence between modalities. This hypothesis does not hold\nwhen representing words, and becomes problematic when used to learn sentence\nrepresentations --- the focus of this paper --- as a visual scene can be\ndescribed by a wide variety of sentences. To overcome this limitation, we\npropose to transfer visual information to textual representations by learning\nan intermediate representation space: the grounded space. We further propose\ntwo new complementary objectives ensuring that (1) sentences associated with\nthe same visual content are close in the grounded space and (2) similarities\nbetween related elements are preserved across modalities. We show that this\nmodel outperforms the previous state-of-the-art on classification and semantic\nrelatedness tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:26:41 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bordes", "Patrick", ""], ["Zablocki", "Eloi", ""], ["Soulier", "Laure", ""], ["Piwowarski", "Benjamin", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2002.02735", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan, Bhargavram Mysore, Prachi Singh,\n  Sriram Ganapathy", "title": "LEAP System for SRE19 CTS Challenge -- Improvements and Error Analysis", "comments": "Published In Proc. Odyssey 2020, the Speaker and Language Recognition\n  Workshop. Link to GitHub Implementation:\n  https://github.com/iiscleap/NeuralPlda", "journal-ref": "in Proc. Odyssey 2020 The Speaker and Language Recognition\n  Workshop, 281--288", "doi": "10.21437/Odyssey.2020-40", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NIST Speaker Recognition Evaluation - Conversational Telephone Speech\n(CTS) challenge 2019 was an open evaluation for the task of speaker\nverification in challenging conditions. In this paper, we provide a detailed\naccount of the LEAP SRE system submitted to the CTS challenge focusing on the\nnovel components in the back-end system modeling. All the systems used the\ntime-delay neural network (TDNN) based x-vector embeddings. The x-vector system\nin our SRE19 submission used a large pool of training speakers (about 14k\nspeakers). Following the x-vector extraction, we explored a neural network\napproach to backend score computation that was optimized for a speaker\nverification cost. The system combination of generative and neural PLDA models\nresulted in significant improvements for the SRE evaluation dataset. We also\nfound additional gains for the SRE systems based on score normalization and\ncalibration. Subsequent to the evaluations, we have performed a detailed\nanalysis of the submitted systems. The analysis revealed the incremental gains\nobtained for different training dataset combinations as well as the modeling\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:28:56 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 05:28:06 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", ""], ["Mysore", "Bhargavram", ""], ["Singh", "Prachi", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2002.02755", "submitter": "Shubham Vatsal", "authors": "Shubham Vatsal, Naresh Purre, Sukumar Moharana, Gopi Ramena, Debi\n  Prasanna Mohanty", "title": "On-Device Information Extraction from SMS using Hybrid Hierarchical\n  Classification", "comments": "to be published in IEEE ICSC 2020 proceedings", "journal-ref": null, "doi": "10.1109/ICSC.2020.00036", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cluttering of SMS inbox is one of the serious problems that users today face\nin the digital world where every online login, transaction, along with\npromotions generate multiple SMS. This problem not only prevents users from\nsearching and navigating messages efficiently but often results in users\nmissing out the relevant information associated with the corresponding SMS like\noffer codes, payment reminders etc. In this paper, we propose a unique\narchitecture to organize and extract the appropriate information from SMS and\nfurther display it in an intuitive template. In the proposed architecture, we\nuse a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural\nNetwork (CNN) to categorize SMS into multiple classes followed by a set of\nentity parsers used to extract the relevant information from the classified\nmessage. The architecture using its preprocessing techniques not only takes\ninto account the enormous variations observed in SMS data but also makes it\nefficient for its on-device (mobile phone) functionalities in terms of\ninference timing and size.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:24:45 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Vatsal", "Shubham", ""], ["Purre", "Naresh", ""], ["Moharana", "Sukumar", ""], ["Ramena", "Gopi", ""], ["Mohanty", "Debi Prasanna", ""]]}, {"id": "2002.02758", "submitter": "Parth Shah", "authors": "Parth Shah, Vishvajit Bakrola", "title": "Neural Machine Translation System of Indic Languages -- An Attention\n  based Approach", "comments": null, "journal-ref": "2019 Second International Conference on Advanced Computational and\n  Communication Paradigms (ICACCP), Gangtok, India, 2019, pp. 1-5", "doi": "10.1109/ICACCP.2019.8882969", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is a recent and effective technique which\nled to remarkable improvements in comparison of conventional machine\ntranslation techniques. Proposed neural machine translation model developed for\nthe Gujarati language contains encoder-decoder with attention mechanism. In\nIndia, almost all the languages are originated from their ancestral language -\nSanskrit. They are having inevitable similarities including lexical and named\nentity similarity. Translating into Indic languages is always be a challenging\ntask. In this paper, we have presented the neural machine translation system\n(NMT) that can efficiently translate Indic languages like Hindi and Gujarati\nthat together covers more than 58.49 percentage of total speakers in the\ncountry. We have compared the performance of our NMT model with automatic\nevaluation matrices such as BLEU, perplexity and TER matrix. The comparison of\nour network with Google translate is also presented where it outperformed with\na margin of 6 BLEU score on English-Gujarati translation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 07:15:18 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Shah", "Parth", ""], ["Bakrola", "Vishvajit", ""]]}, {"id": "2002.02800", "submitter": "Johan Bollen", "authors": "Krishna C. Bathina, Marijn ten Thij, Lorenzo Lorenzo-Luaces, Lauren A.\n  Rutter, and Johan Bollen", "title": "Depressed individuals express more distorted thinking on social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is a leading cause of disability worldwide, but is often\nunder-diagnosed and under-treated. One of the tenets of cognitive-behavioral\ntherapy (CBT) is that individuals who are depressed exhibit distorted modes of\nthinking, so-called cognitive distortions, which can negatively affect their\nemotions and motivation. Here, we show that individuals with a self-reported\ndiagnosis of depression on social media express higher levels of distorted\nthinking than a random sample. Some types of distorted thinking were found to\nbe more than twice as prevalent in our depressed cohort, in particular\nPersonalizing and Emotional Reasoning. This effect is specific to the distorted\ncontent of the expression and can not be explained by the presence of specific\ntopics, sentiment, or first-person pronouns. Our results point towards the\ndetection, and possibly mitigation, of patterns of online language that are\ngenerally deemed depressogenic. They may also provide insight into recent\nobservations that social media usage can have a negative impact on mental\nhealth.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:18:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bathina", "Krishna C.", ""], ["Thij", "Marijn ten", ""], ["Lorenzo-Luaces", "Lorenzo", ""], ["Rutter", "Lauren A.", ""], ["Bollen", "Johan", ""]]}, {"id": "2002.02848", "submitter": "Morgane Riviere", "authors": "Morgane Rivi\\`ere, Armand Joulin, Pierre-Emmanuel Mazar\\'e, Emmanuel\n  Dupoux", "title": "Unsupervised pretraining transfers well across languages", "comments": "6 pages. Accepted at ICASSP 2020. However the 2 pages of\n  supplementary materials will appear only in the arxiv version", "journal-ref": "ICASSP 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual and multi-lingual training of Automatic Speech Recognition\n(ASR) has been extensively investigated in the supervised setting. This assumes\nthe existence of a parallel corpus of speech and orthographic transcriptions.\nRecently, contrastive predictive coding (CPC) algorithms have been proposed to\npretrain ASR systems with unlabelled data. In this work, we investigate whether\nunsupervised pretraining transfers well across languages. We show that a slight\nmodification of the CPC pretraining extracts features that transfer well to\nother languages, being on par or even outperforming supervised pretraining.\nThis shows the potential of unsupervised methods for languages with few\nlinguistic resources.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:34:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Rivi\u00e8re", "Morgane", ""], ["Joulin", "Armand", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2002.02878", "submitter": "Jason  Weston", "authors": "Shrimai Prabhumoye and Margaret Li and Jack Urbanek and Emily Dinan\n  and Douwe Kiela and Jason Weston and Arthur Szlam", "title": "I love your chain mail! Making knights smile in a fantasy game world:\n  Open-domain goal-oriented dialogue agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue research tends to distinguish between chit-chat and goal-oriented\ntasks. While the former is arguably more naturalistic and has a wider use of\nlanguage, the latter has clearer metrics and a straightforward learning signal.\nHumans effortlessly combine the two, for example engaging in chit-chat with the\ngoal of exchanging information or eliciting a specific response. Here, we\nbridge the divide between these two domains in the setting of a rich\nmulti-player text-based fantasy environment where agents and humans engage in\nboth actions and dialogue. Specifically, we train a goal-oriented model with\nreinforcement learning against an imitation-learned ``chit-chat'' model with\ntwo approaches: the policy either learns to pick a topic or learns to pick an\nutterance given the top-K utterances from the chit-chat model. We show that\nboth models outperform an inverse model baseline and can converse naturally\nwith their dialogue partner in order to achieve goals.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:22:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 20:45:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Li", "Margaret", ""], ["Urbanek", "Jack", ""], ["Dinan", "Emily", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""], ["Szlam", "Arthur", ""]]}, {"id": "2002.02925", "submitter": "Canwen Xu", "authors": "Canwen Xu and Wangchunshu Zhou and Tao Ge and Furu Wei and Ming Zhou", "title": "BERT-of-Theseus: Compressing BERT by Progressive Module Replacing", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel model compression approach to effectively\ncompress BERT by progressive module replacing. Our approach first divides the\noriginal BERT into several modules and builds their compact substitutes. Then,\nwe randomly replace the original modules with their substitutes to train the\ncompact modules to mimic the behavior of the original modules. We progressively\nincrease the probability of replacement through the training. In this way, our\napproach brings a deeper level of interaction between the original and compact\nmodels. Compared to the previous knowledge distillation approaches for BERT\ncompression, our approach does not introduce any additional loss function. Our\napproach outperforms existing knowledge distillation approaches on GLUE\nbenchmark, showing a new perspective of model compression.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:52:16 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 18:45:41 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 15:20:44 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 12:18:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Xu", "Canwen", ""], ["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.02955", "submitter": "Xavier Garcia", "authors": "Xavier Garcia, Pierre Foret, Thibault Sellam, Ankur P. Parikh", "title": "A Multilingual View of Unsupervised Machine Translation", "comments": "Accepted at Findings of EMNLP 2020 [Fixed processing error.]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic framework for multilingual neural machine\ntranslation that encompasses supervised and unsupervised setups, focusing on\nunsupervised translation. In addition to studying the vanilla case where there\nis only monolingual data available, we propose a novel setup where one language\nin the (source, target) pair is not associated with any parallel data, but\nthere may exist auxiliary parallel data that contains the other. This auxiliary\ndata can naturally be utilized in our probabilistic framework via a novel\ncross-translation loss term. Empirically, we show that our approach results in\nhigher BLEU scores over state-of-the-art unsupervised models on the WMT'14\nEnglish-French, WMT'16 English-German, and WMT'16 English-Romanian datasets in\nmost directions. In particular, we obtain a +1.65 BLEU advantage over the\nbest-performing unsupervised model in the Romanian-English direction.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:50:21 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 20:39:34 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 20:55:25 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 20:41:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Garcia", "Xavier", ""], ["Foret", "Pierre", ""], ["Sellam", "Thibault", ""], ["Parikh", "Ankur P.", ""]]}, {"id": "2002.03049", "submitter": "Yuliang Li", "authors": "Zhengjie Miao, Yuliang Li, Xiaolan Wang, Wang-Chiew Tan", "title": "Snippext: Semi-supervised Opinion Mining with Augmented Data", "comments": "Accepted to WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380144", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online services are interested in solutions to opinion mining, which is the\nproblem of extracting aspects, opinions, and sentiments from text. One method\nto mine opinions is to leverage the recent success of pre-trained language\nmodels which can be fine-tuned to obtain high-quality extractions from reviews.\nHowever, fine-tuning language models still requires a non-trivial amount of\ntraining data. In this paper, we study the problem of how to significantly\nreduce the amount of labeled training data required in fine-tuning language\nmodels for opinion mining. We describe Snippext, an opinion mining system\ndeveloped over a language model that is fine-tuned through semi-supervised\nlearning with augmented data. A novelty of Snippext is its clever use of a\ntwo-prong approach to achieve state-of-the-art (SOTA) performance with little\nlabeled training data through: (1) data augmentation to automatically generate\nmore labeled training data from existing ones, and (2) a semi-supervised\nlearning technique to leverage the massive amount of unlabeled data in addition\nto the (limited amount of) labeled data. We show with extensive experiments\nthat Snippext performs comparably and can even exceed previous SOTA results on\nseveral opinion mining tasks with only half the training data required.\nFurthermore, it achieves new SOTA results when all training data are leveraged.\nBy comparison to a baseline pipeline, we found that Snippext extracts\nsignificantly more fine-grained opinions which enable new opportunities of\ndownstream applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 23:54:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Miao", "Zhengjie", ""], ["Li", "Yuliang", ""], ["Wang", "Xiaolan", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2002.03056", "submitter": "Janardan Misra", "authors": "Janardan Misra", "title": "autoNLP: NLP Feature Recommendations for Text Analytics Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While designing machine learning based text analytics applications, often,\nNLP data scientists manually determine which NLP features to use based upon\ntheir knowledge and experience with related problems. This results in increased\nefforts during feature engineering process and renders automated reuse of\nfeatures across semantically related applications inherently difficult. In this\npaper, we argue for standardization in feature specification by outlining\nstructure of a language for specifying NLP features and present an approach for\ntheir reuse across applications to increase likelihood of identifying optimal\nfeatures.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 00:42:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Misra", "Janardan", ""]]}, {"id": "2002.03067", "submitter": "Jiwei Li", "authors": "Duo Chai, Wei Wu, Qinghong Han, Fei Wu, Jiwei Li", "title": "Description Based Text Classification with Reinforcement Learning", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of text classification is usually divided into two stages: {\\it text\nfeature extraction} and {\\it classification}. In this standard formalization\ncategories are merely represented as indexes in the label vocabulary, and the\nmodel lacks for explicit instructions on what to classify. Inspired by the\ncurrent trend of formalizing NLP problems as question answering tasks, we\npropose a new framework for text classification, in which each category label\nis associated with a category description. Descriptions are generated by\nhand-crafted templates or using abstractive/extractive models from\nreinforcement learning. The concatenation of the description and the text is\nfed to the classifier to decide whether or not the current label should be\nassigned to the text. The proposed strategy forces the model to attend to the\nmost salient texts with respect to the label, which can be regarded as a hard\nversion of attention, leading to better performances. We observe significant\nperformance boosts over strong baselines on a wide range of text classification\ntasks including single-label classification, multi-label classification and\nmulti-aspect sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:14:28 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 14:56:01 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 13:18:34 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Chai", "Duo", ""], ["Wu", "Wei", ""], ["Han", "Qinghong", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2002.03079", "submitter": "Tianxiao Shen", "authors": "Tianxiao Shen, Victor Quach, Regina Barzilay, Tommi Jaakkola", "title": "Blank Language Models", "comments": "EMNLP 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Blank Language Model (BLM), a model that generates sequences by\ndynamically creating and filling in blanks. The blanks control which part of\nthe sequence to expand, making BLM ideal for a variety of text editing and\nrewriting tasks. The model can start from a single blank or partially completed\ntext with blanks at specified locations. It iteratively determines which word\nto place in a blank and whether to insert new blanks, and stops generating when\nno blanks are left to fill. BLM can be efficiently trained using a lower bound\nof the marginal data likelihood. On the task of filling missing text snippets,\nBLM significantly outperforms all other baselines in terms of both accuracy and\nfluency. Experiments on style transfer and damaged ancient text restoration\ndemonstrate the potential of this framework for a wide range of applications.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:41:37 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 02:54:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Shen", "Tianxiao", ""], ["Quach", "Victor", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.03084", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Yuxian Meng, Arianna Yuan, Fei Wu, Jiwei Li", "title": "LAVA NAT: A Non-Autoregressive Translation Model with Look-Around\n  Decoding and Vocabulary Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive translation (NAT) models generate multiple tokens in one\nforward pass and is highly efficient at inference stage compared with\nautoregressive translation (AT) methods. However, NAT models often suffer from\nthe multimodality problem, i.e., generating duplicated tokens or missing\ntokens. In this paper, we propose two novel methods to address this issue, the\nLook-Around (LA) strategy and the Vocabulary Attention (VA) mechanism. The\nLook-Around strategy predicts the neighbor tokens in order to predict the\ncurrent token, and the Vocabulary Attention models long-term token dependencies\ninside the decoder by attending the whole vocabulary for each position to\nacquire knowledge of which token is about to generate. %We also propose a\ndynamic bidirectional decoding approach to accelerate the inference process of\nthe LAVA model while preserving the high-quality of the generated output. Our\nproposed model uses significantly less time during inference compared with\nautoregressive models and most other NAT models. Our experiments on four\nbenchmarks (WMT14 En$\\rightarrow$De, WMT14 De$\\rightarrow$En, WMT16\nRo$\\rightarrow$En and IWSLT14 De$\\rightarrow$En) show that the proposed model\nachieves competitive performance compared with the state-of-the-art\nnon-autoregressive and autoregressive models while significantly reducing the\ntime cost in inference phase.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 04:11:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Li", "Xiaoya", ""], ["Meng", "Yuxian", ""], ["Yuan", "Arianna", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2002.03140", "submitter": "Qiming Bao", "authors": "Qiming Bao, Lin Ni and Jiamou Liu", "title": "HHH: An Online Medical Chatbot System based on Knowledge Graph and\n  Hierarchical Bi-Directional Attention", "comments": "10 pages, 9 figures, 3 tables. Proceedings of the Australasian\n  Computer Science Week Multiconference (ACSW 2020)", "journal-ref": null, "doi": "10.1145/3373017.3373049", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a chatbot framework that adopts a hybrid model which\nconsists of a knowledge graph and a text similarity model. Based on this\nchatbot framework, we build HHH, an online question-and-answer (QA) Healthcare\nHelper system for answering complex medical questions. HHH maintains a\nknowledge graph constructed from medical data collected from the Internet. HHH\nalso implements a novel text representation and similarity deep learning model,\nHierarchical BiLSTM Attention Model (HBAM), to find the most similar question\nfrom a large QA dataset. We compare HBAM with other state-of-the-art language\nmodels such as bidirectional encoder representation from transformers (BERT)\nand Manhattan LSTM Model (MaLSTM). We train and test the models with a subset\nof the Quora duplicate questions dataset in the medical area. The experimental\nresults show that our model is able to achieve a superior performance than\nthese existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:06:27 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Bao", "Qiming", ""], ["Ni", "Lin", ""], ["Liu", "Jiamou", ""]]}, {"id": "2002.03149", "submitter": "Yanyan Zou", "authors": "Yanyan Zou, Wei Lu and Xu Sun", "title": "Mining Commonsense Facts from the Physical World", "comments": "The experiment part is not insufficient which might confuses the\n  readers, while we are not planning to improve it for now. To ensure the\n  quality of arxiv papers, we would like to withdraw this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Textual descriptions of the physical world implicitly mention commonsense\nfacts, while the commonsense knowledge bases explicitly represent such facts as\ntriples. Compared to dramatically increased text data, the coverage of existing\nknowledge bases is far away from completion. Most of the prior studies on\npopulating knowledge bases mainly focus on Freebase. To automatically complete\ncommonsense knowledge bases to improve their coverage is under-explored. In\nthis paper, we propose a new task of mining commonsense facts from the raw text\nthat describes the physical world. We build an effective new model that fuses\ninformation from both sequence text and existing knowledge base resource. Then\nwe create two large annotated datasets each with approximate 200k instances for\ncommonsense knowledge base completion. Empirical results demonstrate that our\nmodel significantly outperforms baselines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:02:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 04:16:47 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 00:58:51 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Zou", "Yanyan", ""], ["Lu", "Wei", ""], ["Sun", "Xu", ""]]}, {"id": "2002.03184", "submitter": "Vasileios Lioutas", "authors": "Vasileios Lioutas, Yuhong Guo", "title": "Time-aware Large Kernel Convolutions", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, most state-of-the-art sequence modeling architectures use attention\nto build generative models for language based tasks. Some of these models use\nall the available sequence tokens to generate an attention distribution which\nresults in time complexity of $O(n^2)$. Alternatively, they utilize depthwise\nconvolutions with softmax normalized kernels of size $k$ acting as a\nlimited-window self-attention, resulting in time complexity of $O(k{\\cdot}n)$.\nIn this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a\nnovel adaptive convolution operation that learns to predict the size of a\nsummation kernel instead of using a fixed-sized kernel matrix. This method\nyields a time complexity of $O(n)$, effectively making the sequence encoding\nprocess linear to the number of tokens. We evaluate the proposed method on\nlarge-scale standard machine translation, abstractive summarization and\nlanguage modeling datasets and show that TaLK Convolutions constitute an\nefficient improvement over other attention/convolution based approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 15:30:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:11:18 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Guo", "Yuhong", ""]]}, {"id": "2002.03246", "submitter": "Andrew Best", "authors": "Andrew Best, Sahil Narang, Dinesh Manocha", "title": "SPA: Verbal Interactions between Agents and Avatars in Shared Virtual\n  Environments using Propositional Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for generating plausible verbal interactions\nbetween virtual human-like agents and user avatars in shared virtual\nenvironments. Sense-Plan-Ask, or SPA, extends prior work in propositional\nplanning and natural language processing to enable agents to plan with\nuncertain information, and leverage question and answer dialogue with other\nagents and avatars to obtain the needed information and complete their goals.\nThe agents are additionally able to respond to questions from the avatars and\nother agents using natural-language enabling real-time multi-agent multi-avatar\ncommunication environments.\n  Our algorithm can simulate tens of virtual agents at interactive rates\ninteracting, moving, communicating, planning, and replanning. We find that our\nalgorithm creates a small runtime cost and enables agents to complete their\ngoals more effectively than agents without the ability to leverage\nnatural-language communication. We demonstrate quantitative results on a set of\nsimulated benchmarks and detail the results of a preliminary user-study\nconducted to evaluate the plausibility of the virtual interactions generated by\nSPA. Overall, we find that participants prefer SPA to prior techniques in 84\\%\nof responses including significant benefits in terms of the plausibility of\nnatural-language interactions and the positive impact of those interactions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 23:15:06 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Best", "Andrew", ""], ["Narang", "Sahil", ""], ["Manocha", "Dinesh", ""]]}, {"id": "2002.03259", "submitter": "Nidhika Yadav", "authors": "Nidhika Yadav, Niladri Chatterjee", "title": "Rough Set based Aggregate Rank Measure & its Application to Supervised\n  Multi Document Summarization", "comments": "The paper proposes a novel Rough Set based technique to compute rank\n  in a decision system. This is further evaluated on the problem of Supervised\n  Text Summarization. The paper contains 9 pages, illustrative examples,\n  theoretical properties, and experimental evaluations on standard datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most problems in Machine Learning cater to classification and the objects of\nuniverse are classified to a relevant class. Ranking of classified objects of\nuniverse per decision class is a challenging problem. We in this paper propose\na novel Rough Set based membership called Rank Measure to solve to this\nproblem. It shall be utilized for ranking the elements to a particular class.\nIt differs from Pawlak Rough Set based membership function which gives an\nequivalent characterization of the Rough Set based approximations. It becomes\nparamount to look beyond the traditional approach of computing memberships\nwhile handling inconsistent, erroneous and missing data that is typically\npresent in real world problems. This led us to propose the aggregate Rank\nMeasure. The contribution of the paper is three fold. Firstly, it proposes a\nRough Set based measure to be utilized for numerical characterization of within\nclass ranking of objects. Secondly, it proposes and establish the properties of\nRank Measure and aggregate Rank Measure based membership. Thirdly, we apply the\nconcept of membership and aggregate ranking to the problem of supervised Multi\nDocument Summarization wherein first the important class of sentences are\ndetermined using various supervised learning techniques and are post processed\nusing the proposed ranking measure. The results proved to have significant\nimprovement in accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 01:03:25 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yadav", "Nidhika", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "2002.03350", "submitter": "Mingchen Li", "authors": "Mingchen Li and Gabtone.Clinton and Yijia Miao and Feng Gao", "title": "Short Text Classification via Knowledge powered Attention with\n  Similarity Matrix based CNN", "comments": "there is an error in this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text is becoming more and more popular on the web, such as Chat\nMessage, SMS and Product Reviews. Accurately classifying short text is an\nimportant and challenging task. A number of studies have difficulties in\naddressing this problem because of the word ambiguity and data sparsity. To\naddress this issue, we propose a knowledge powered attention with similarity\nmatrix based convolutional neural network (KASM) model, which can compute\ncomprehensive information by utilizing the knowledge and deep neural network.\nWe use knowledge graph (KG) to enrich the semantic representation of short\ntext, specially, the information of parent-entity is introduced in our model.\nMeanwhile, we consider the word interaction in the literal-level between short\ntext and the representation of label, and utilize similarity matrix based\nconvolutional neural network (CNN) to extract it. For the purpose of measuring\nthe importance of knowledge, we introduce the attention mechanisms to choose\nthe important information. Experimental results on five standard datasets show\nthat our model significantly outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 12:08:43 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 23:40:10 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Li", "Mingchen", ""], ["Clinton", "Gabtone.", ""], ["Miao", "Yijia", ""], ["Gao", "Feng", ""]]}, {"id": "2002.03405", "submitter": "Ahmed Magooda", "authors": "Ahmed Magooda and Cezary Marcjan", "title": "Attend to the beginning: A study on using bidirectional attention for\n  extractive summarization", "comments": "To be published in FLAIRS33 (https://www.flairs-33.info/) and appear\n  in he proceedings of AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forum discussion data differ in both structure and properties from generic\nform of textual data such as news. Henceforth, summarization techniques should,\nin turn, make use of such differences, and craft models that can benefit from\nthe structural nature of discussion data. In this work, we propose attending to\nthe beginning of a document, to improve the performance of extractive\nsummarization models when applied to forum discussion data. Evaluations\ndemonstrated that with the help of bidirectional attention mechanism, attending\nto the beginning of a document (initial comment/post) in a discussion thread,\ncan introduce a consistent boost in ROUGE scores, as well as introducing a new\nState Of The Art (SOTA) ROUGE scores on the forum discussions dataset.\nAdditionally, we explored whether this hypothesis is extendable to other\ngeneric forms of textual data. We make use of the tendency of introducing\nimportant information early in the text, by attending to the first few\nsentences in generic textual data. Evaluations demonstrated that attending to\nintroductory sentences using bidirectional attention, improves the performance\nof extractive summarization models when even applied to more generic form of\ntextual data.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 17:46:22 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 14:23:49 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 03:13:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Magooda", "Ahmed", ""], ["Marcjan", "Cezary", ""]]}, {"id": "2002.03407", "submitter": "Ahmed Magooda", "authors": "Ahmed Magooda, Diane Litman", "title": "Abstractive Summarization for Low Resource Data using Domain Transfer\n  and Data Synthesis", "comments": "To be published in FLAIRS33 (https://www.flairs-33.info/) and appear\n  in he proceedings of AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training abstractive summarization models typically requires large amounts of\ndata, which can be a limitation for many domains. In this paper we explore\nusing domain transfer and data synthesis to improve the performance of recent\nabstractive summarization methods when applied to small corpora of student\nreflections. First, we explored whether tuning state of the art model trained\non newspaper data could boost performance on student reflection data.\nEvaluations demonstrated that summaries produced by the tuned model achieved\nhigher ROUGE scores compared to model trained on just student reflection data\nor just newspaper data. The tuned model also achieved higher scores compared to\nextractive summarization baselines, and additionally was judged to produce more\ncoherent and readable summaries in human evaluations. Second, we explored\nwhether synthesizing summaries of student data could additionally boost\nperformance. We proposed a template-based model to synthesize new data, which\nwhen incorporated into training further increased ROUGE scores. Finally, we\nshowed that combining data synthesis with domain transfer achieved higher ROUGE\nscores compared to only using one of the two approaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 17:49:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Magooda", "Ahmed", ""], ["Litman", "Diane", ""]]}, {"id": "2002.03438", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Nitish Shirish Keskar, and Richard Socher", "title": "Limits of Detecting Text Generated by Large-Scale Language Models", "comments": "ITA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:53:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Varshney", "Lav R.", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "2002.03518", "submitter": "Steven Cao", "authors": "Steven Cao, Nikita Kitaev, Dan Klein", "title": "Multilingual Alignment of Contextual Word Representations", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose procedures for evaluating and strengthening contextual embedding\nalignment and show that they are useful in analyzing and improving multilingual\nBERT. In particular, after our proposed alignment procedure, BERT exhibits\nsignificantly improved zero-shot performance on XNLI compared to the base\nmodel, remarkably matching pseudo-fully-supervised translate-train models for\nBulgarian and Greek. Further, to measure the degree of alignment, we introduce\na contextual version of word retrieval and show that it correlates well with\ndownstream zero-shot transfer. Using this word retrieval task, we also analyze\nBERT and find that it exhibits systematic deficiencies, e.g. worse alignment\nfor open-class parts-of-speech and word pairs written in different scripts,\nthat are corrected by the alignment procedure. These results support contextual\nalignment as a useful concept for understanding large multilingual pre-trained\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:27:21 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 23:28:06 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Cao", "Steven", ""], ["Kitaev", "Nikita", ""], ["Klein", "Dan", ""]]}, {"id": "2002.03531", "submitter": "Khalid Saqr", "authors": "Khalid M. Saqr, Abdelrahman Elsharawy", "title": "A Novel Kuhnian Ontology for Epistemic Classification of STM Scholarly\n  Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Thomas Kuhn proposed his paradigmatic view of scientific discovery five\ndecades ago. The concept of paradigm has not only explained the progress of\nscience, but has also become the central epistemic concept among STM\nscientists. Here, we adopt the principles of Kuhnian philosophy to construct a\nnovel ontology aims at classifying and evaluating the impact of STM scholarly\narticles. First, we explain how the Kuhnian cycle of science describes research\nat different epistemic stages. Second, we show how the Kuhnian cycle could be\nreconstructed into modular ontologies which classify scholarly articles\naccording to their contribution to paradigm-centred knowledge. The proposed\nontology and its scenarios are discussed. To the best of the authors knowledge,\nthis is the first attempt for creating an ontology for describing scholarly\narticles based on the Kuhnian paradigmatic view of science.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:00:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Saqr", "Khalid M.", ""], ["Elsharawy", "Abdelrahman", ""]]}, {"id": "2002.03536", "submitter": "Cuiyun Gao", "authors": "Jichuan Zeng, Jing Li, Yulan He, Cuiyun Gao, Michael R. Lyu, Irwin\n  King", "title": "What Changed Your Mind: The Roles of Dynamic Topics and Discourse in\n  Argumentation Process", "comments": "12 pages, accepted by The Web Conference 2020 (WWW'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our world with full of uncertainty, debates and argumentation contribute\nto the progress of science and society. Despite of the increasing attention to\ncharacterize human arguments, most progress made so far focus on the debate\noutcome, largely ignoring the dynamic patterns in argumentation processes. This\npaper presents a study that automatically analyzes the key factors in argument\npersuasiveness, beyond simply predicting who will persuade whom. Specifically,\nwe propose a novel neural model that is able to dynamically track the changes\nof latent topics and discourse in argumentative conversations, allowing the\ninvestigation of their roles in influencing the outcomes of persuasion.\nExtensive experiments have been conducted on argumentative conversations on\nboth social media and supreme court. The results show that our model\noutperforms state-of-the-art models in identifying persuasive arguments via\nexplicitly exploring dynamic factors of topic and discourse. We further analyze\nthe effects of topics and discourse on persuasiveness, and find that they are\nboth useful - topics provide concrete evidence while superior discourse styles\nmay bias participants, especially in social media arguments. In addition, we\ndraw some findings from our empirical results, which will help people better\nengage in future persuasive conversations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:27:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zeng", "Jichuan", ""], ["Li", "Jing", ""], ["He", "Yulan", ""], ["Gao", "Cuiyun", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2002.03552", "submitter": "Cuiyun Gao", "authors": "Cuiyun Gao, Jichuan Zeng, Xin Xia, David Lo, Michael R. Lyu, Irwin\n  King", "title": "Automating App Review Response Generation", "comments": "12 pages, accepted by ASE'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies showed that replying to a user review usually has a positive\neffect on the rating that is given by the user to the app. For example, Hassan\net al. found that responding to a review increases the chances of a user\nupdating their given rating by up to six times compared to not responding. To\nalleviate the labor burden in replying to the bulk of user reviews, developers\nusually adopt a template-based strategy where the templates can express\nappreciation for using the app or mention the company email address for users\nto follow up. However, reading a large number of user reviews every day is not\nan easy task for developers. Thus, there is a need for more automation to help\ndevelopers respond to user reviews.\n  Addressing the aforementioned need, in this work we propose a novel approach\nRRGen that automatically generates review responses by learning knowledge\nrelations between reviews and their responses. RRGen explicitly incorporates\nreview attributes, such as user rating and review length, and learns the\nrelations between reviews and corresponding responses in a supervised way from\nthe available training data. Experiments on 58 apps and 309,246 review-response\npairs highlight that RRGen outperforms the baselines by at least 67.4% in terms\nof BLEU-4 (an accuracy measure that is widely used to evaluate dialogue\nresponse generation systems). Qualitative analysis also confirms the\neffectiveness of RRGen in generating relevant and accurate responses.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:23:38 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gao", "Cuiyun", ""], ["Zeng", "Jichuan", ""], ["Xia", "Xin", ""], ["Lo", "David", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2002.03562", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan, Sriram Ganapathy", "title": "NPLDA: A Deep Neural PLDA Model for Speaker Verification", "comments": "Published in Odyssey 2020, the Speaker and Language Recognition\n  Workshop (VOiCES Special Session). Link to GitHub Implementation:\n  https://github.com/iiscleap/NeuralPlda. arXiv admin note: substantial text\n  overlap with arXiv:2001.07034", "journal-ref": "in Proc. Odyssey 2020 The Speaker and Language Recognition\n  Workshop, Pages 202-209", "doi": "10.21437/Odyssey.2020-29", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art approach for speaker verification consists of a neural\nnetwork based embedding extractor along with a backend generative model such as\nthe Probabilistic Linear Discriminant Analysis (PLDA). In this work, we propose\na neural network approach for backend modeling in speaker recognition. The\nlikelihood ratio score of the generative PLDA model is posed as a\ndiscriminative similarity function and the learnable parameters of the score\nfunction are optimized using a verification cost. The proposed model, termed as\nneural PLDA (NPLDA), is initialized using the generative PLDA model parameters.\nThe loss function for the NPLDA model is an approximation of the minimum\ndetection cost function (DCF). The speaker recognition experiments using the\nNPLDA model are performed on the speaker verificiation task in the VOiCES\ndatasets as well as the SITW challenge dataset. In these experiments, the NPLDA\nmodel optimized using the proposed loss function improves significantly over\nthe state-of-art PLDA based speaker verification system.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:47:35 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 05:40:56 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2002.03604", "submitter": "Haggai Roitman", "authors": "Odellia Boni, Guy Feigenblat, Doron Cohen, Haggai Roitman, David\n  Konopnicki", "title": "A Study of Human Summaries of Scientific Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers and students face an explosion of newly published papers which\nmay be relevant to their work. This led to a trend of sharing human summaries\nof scientific papers. We analyze the summaries shared in one of these platforms\nShortscience.org. The goal is to characterize human summaries of scientific\npapers, and use some of the insights obtained to improve and adapt existing\nautomatic summarization systems to the domain of scientific papers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:53:27 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Boni", "Odellia", ""], ["Feigenblat", "Guy", ""], ["Cohen", "Doron", ""], ["Roitman", "Haggai", ""], ["Konopnicki", "David", ""]]}, {"id": "2002.03912", "submitter": "Junxian He", "authors": "Junxian He, Xinyi Wang, Graham Neubig, Taylor Berg-Kirkpatrick", "title": "A Probabilistic Formulation of Unsupervised Text Style Transfer", "comments": "ICLR 2020 conference paper (spotlight). The first two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep generative model for unsupervised text style transfer that\nunifies previously proposed non-generative techniques. Our probabilistic\napproach models non-parallel data from two domains as a partially observed\nparallel corpus. By hypothesizing a parallel latent sequence that generates\neach observed sequence, our model learns to transform sequences from one domain\nto another in a completely unsupervised fashion. In contrast with traditional\ngenerative sequence models (e.g. the HMM), our model makes few assumptions\nabout the data it generates: it uses a recurrent language model as a prior and\nan encoder-decoder as a transduction distribution. While computation of\nmarginal data likelihood is intractable in this model class, we show that\namortized variational inference admits a practical surrogate. Further, by\ndrawing connections between our variational objective and other recent\nunsupervised style transfer and machine translation techniques, we show how our\nprobabilistic view can unify some known non-generative objectives such as\nbacktranslation and adversarial loss. Finally, we demonstrate the effectiveness\nof our method on a wide range of unsupervised style transfer tasks, including\nsentiment transfer, formality transfer, word decipherment, author imitation,\nand related language translation. Across all style transfer tasks, our approach\nyields substantial gains over state-of-the-art non-generative baselines,\nincluding the state-of-the-art unsupervised machine translation techniques that\nour approach generalizes. Further, we conduct experiments on a standard\nunsupervised machine translation task and find that our unified approach\nmatches the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:20:49 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 02:44:13 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 23:26:16 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["He", "Junxian", ""], ["Wang", "Xinyi", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2002.03921", "submitter": "Xuankai Chang", "authors": "Xuankai Chang, Wangyou Zhang, Yanmin Qian, Jonathan Le Roux, Shinji\n  Watanabe", "title": "End-to-End Multi-speaker Speech Recognition with Transformer", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, fully recurrent neural network (RNN) based end-to-end models have\nbeen proven to be effective for multi-speaker speech recognition in both the\nsingle-channel and multi-channel scenarios. In this work, we explore the use of\nTransformer models for these tasks by focusing on two aspects. First, we\nreplace the RNN-based encoder-decoder in the speech recognition model with a\nTransformer architecture. Second, in order to use the Transformer in the\nmasking network of the neural beamformer in the multi-channel case, we modify\nthe self-attention component to be restricted to a segment rather than the\nwhole sequence in order to reduce computation. Besides the model architecture\nimprovements, we also incorporate an external dereverberation preprocessing,\nthe weighted prediction error (WPE), enabling our model to handle reverberated\nsignals. Experiments on the spatialized wsj1-2mix corpus show that the\nTransformer-based models achieve 40.9% and 25.6% relative WER reduction, down\nto 12.1% and 6.4% WER, under the anechoic condition in single-channel and\nmulti-channel tasks, respectively, while in the reverberant case, our methods\nachieve 41.5% and 13.8% relative WER reduction, down to 16.5% and 15.2% WER.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:29:26 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 00:50:39 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chang", "Xuankai", ""], ["Zhang", "Wangyou", ""], ["Qian", "Yanmin", ""], ["Roux", "Jonathan Le", ""], ["Watanabe", "Shinji", ""]]}, {"id": "2002.03932", "submitter": "Wei-Cheng Chang", "authors": "Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar", "title": "Pre-training Tasks for Embedding-based Large-scale Retrieval", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the large-scale query-document retrieval problem: given a query\n(e.g., a question), return the set of relevant documents (e.g., paragraphs\ncontaining the answer) from a large document corpus. This problem is often\nsolved in two steps. The retrieval phase first reduces the solution space,\nreturning a subset of candidate documents. The scoring phase then re-ranks the\ndocuments. Critically, the retrieval algorithm not only desires high recall but\nalso requires to be highly efficient, returning candidates in time sublinear to\nthe number of documents. Unlike the scoring phase witnessing significant\nadvances recently due to the BERT-style pre-training tasks on cross-attention\nmodels, the retrieval phase remains less well studied. Most previous works rely\non classic Information Retrieval (IR) methods such as BM-25 (token matching +\nTF-IDF weights). These models only accept sparse handcrafted features and can\nnot be optimized for different downstream tasks of interest. In this paper, we\nconduct a comprehensive study on the embedding-based retrieval models. We show\nthat the key ingredient of learning a strong embedding-based Transformer model\nis the set of pre-training tasks. With adequately designed paragraph-level\npre-training tasks, the Transformer models can remarkably improve over the\nwidely-used BM-25 as well as embedding models without Transformers. The\nparagraph-level pre-training tasks we studied are Inverse Cloze Task (ICT),\nBody First Selection (BFS), Wiki Link Prediction (WLP), and the combination of\nall three.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:44:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chang", "Wei-Cheng", ""], ["Yu", "Felix X.", ""], ["Chang", "Yin-Wen", ""], ["Yang", "Yiming", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2002.04095", "submitter": "Juan-Manuel Torres-Moreno", "authors": "R\\'emy Saksik, Alejandro Molina-Villegas, Andr\\'ea Carneiro Linhares,\n  Juan-Manuel Torres-Moreno", "title": "Automatic Discourse Segmentation: an evaluation in French", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe some discursive segmentation methods as well as\na preliminary evaluation of the segmentation quality. Although our experiment\nwere carried for documents in French, we have developed three discursive\nsegmentation models solely based on resources simultaneously available in\nseveral languages: marker lists and a statistic POS labeling. We have also\ncarried out automatic evaluations of these systems against the Annodis corpus,\nwhich is a manually annotated reference. The results obtained are very\nencouraging.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:35:39 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:27:29 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Saksik", "R\u00e9my", ""], ["Molina-Villegas", "Alejandro", ""], ["Linhares", "Andr\u00e9a Carneiro", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "2002.04108", "submitter": "Swabha Swayamdipta", "authors": "Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers,\n  Matthew E. Peters, Ashish Sabharwal, Yejin Choi", "title": "Adversarial Filters of Dataset Biases", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural models have demonstrated human-level performance on language and\nvision benchmarks, while their performance degrades considerably on adversarial\nor out-of-distribution samples. This raises the question of whether these\nmodels have learned to solve a dataset rather than the underlying task by\noverfitting to spurious dataset biases. We investigate one recently proposed\napproach, AFLite, which adversarially filters such dataset biases, as a means\nto mitigate the prevalent overestimation of machine performance. We provide a\ntheoretical understanding for AFLite, by situating it in the generalized\nframework for optimum bias reduction. We present extensive supporting evidence\nthat AFLite is broadly applicable for reduction of measurable dataset biases,\nand that models trained on the filtered datasets yield better generalization to\nout-of-distribution tasks. Finally, filtering results in a large drop in model\nperformance (e.g., from 92% to 62% for SNLI), while human performance still\nremains high. Our work thus shows that such filtered datasets can pose new\nresearch challenges for robust generalization by serving as upgraded\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:59:21 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:37:37 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 00:44:43 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bras", "Ronan Le", ""], ["Swayamdipta", "Swabha", ""], ["Bhagavatula", "Chandra", ""], ["Zellers", "Rowan", ""], ["Peters", "Matthew E.", ""], ["Sabharwal", "Ashish", ""], ["Choi", "Yejin", ""]]}, {"id": "2002.04165", "submitter": "Tongtao Zhang", "authors": "Tongtao Zhang, Heng Ji, Shih-Fu Chang, Marjorie Freedman", "title": "Training with Streaming Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address a practical scenario where training data is\nreleased in a sequence of small-scale batches and annotation in earlier phases\nhas lower quality than the later counterparts. To tackle the situation, we\nutilize a pre-trained transformer network to preserve and integrate the most\nsalient document information from the earlier batches while focusing on the\nannotation (presumably with higher quality) from the current batch. Using event\nextraction as a case study, we demonstrate in the experiments that our proposed\nframework can perform better than conventional approaches (the improvement\nranges from 3.6 to 14.9% absolute F-score gain), especially when there is more\nnoise in the early annotation; and our approach spares 19.1% time with regard\nto the best conventional method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:52:05 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 21:00:52 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Tongtao", ""], ["Ji", "Heng", ""], ["Chang", "Shih-Fu", ""], ["Freedman", "Marjorie", ""]]}, {"id": "2002.04181", "submitter": "Mona Jalal", "authors": "Mona Jalal, Kate K. Mays, Lei Guo, Margrit Betke", "title": "Performance Comparison of Crowdworkers and NLP Tools on Named-Entity\n  Recognition and Sentiment Analysis of Political Tweets", "comments": "4 pages, 1 figure, Accepted at WiNLP Workshop at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report results of a comparison of the accuracy of crowdworkers and seven\nNatural Language Processing (NLP) toolkits in solving two important NLP tasks,\nnamed-entity recognition (NER) and entity-level sentiment (ELS) analysis. We\nhere focus on a challenging dataset, 1,000 political tweets that were collected\nduring the U.S. presidential primary election in February 2016. Each tweet\nrefers to at least one of four presidential candidates, i.e., four named\nentities. The groundtruth, established by experts in political communication,\nhas entity-level sentiment information for each candidate mentioned in the\ntweet. We tested several commercial and open-source tools. Our experiments show\nthat, for our dataset of political tweets, the most accurate NER system, Google\nCloud NL, performed almost on par with crowdworkers, but the most accurate ELS\nanalysis system, TensiStrength, did not match the accuracy of crowdworkers by a\nlarge margin of more than 30 percent points.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:03:20 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 22:04:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Jalal", "Mona", ""], ["Mays", "Kate K.", ""], ["Guo", "Lei", ""], ["Betke", "Margrit", ""]]}, {"id": "2002.04250", "submitter": "Jiwei Li", "authors": "Qinghong Han, Yuxian Meng, Fei Wu, Jiwei Li", "title": "Non-Autoregressive Neural Dialogue Generation", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Mutual information (MMI), which models the bidirectional dependency\nbetween responses ($y$) and contexts ($x$), i.e., the forward probability $\\log\np(y|x)$ and the backward probability $\\log p(x|y)$, has been widely used as the\nobjective in the \\sts model to address the dull-response issue in open-domain\ndialog generation. Unfortunately, under the framework of the \\sts model, direct\ndecoding from $\\log p(y|x) + \\log p(x|y)$ is infeasible since the second part\n(i.e., $p(x|y)$) requires the completion of target generation before it can be\ncomputed, and the search space for $y$ is enormous. Empirically, an N-best list\nis first generated given $p(y|x)$, and $p(x|y)$ is then used to rerank the\nN-best list, which inevitably results in non-globally-optimal solutions. In\nthis paper, we propose to use non-autoregressive (non-AR) generation model to\naddress this non-global optimality issue. Since target tokens are generated\nindependently in non-AR generation, $p(x|y)$ for each target word can be\ncomputed as soon as it's generated, and does not have to wait for the\ncompletion of the whole sequence. This naturally resolves the non-global\noptimal issue in decoding. Experimental results demonstrate that the proposed\nnon-AR strategy produces more diverse, coherent, and appropriate responses,\nyielding substantive gains in BLEU scores and in human evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:19:28 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:37:24 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Han", "Qinghong", ""], ["Meng", "Yuxian", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2002.04306", "submitter": "Philip Arthur", "authors": "Philip Arthur, Trevor Cohn, Gholamreza Haffari", "title": "Learning Coupled Policies for Simultaneous Machine Translation using\n  Imitation Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to efficiently learn a simultaneous translation\nmodel with coupled programmer-interpreter policies. First, wepresent an\nalgorithmic oracle to produce oracle READ/WRITE actions for training bilingual\nsentence-pairs using the notion of word alignments. This oracle actions are\ndesigned to capture enough information from the partial input before writing\nthe output. Next, we perform a coupled scheduled sampling to effectively\nmitigate the exposure bias when learning both policies jointly with imitation\nlearning. Experiments on six language-pairs show our method outperforms strong\nbaselines in terms of translation quality while keeping the translation delay\nlow.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:56:42 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 05:48:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Arthur", "Philip", ""], ["Cohn", "Trevor", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2002.04326", "submitter": "Weihao Yu", "authors": "Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng", "title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning", "comments": "ICLR 2020 paper. Project page: http://whyu.me/reclor/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent powerful pre-trained language models have achieved remarkable\nperformance on most of the popular datasets for reading comprehension. It is\ntime to introduce more challenging datasets to push the development of this\nfield towards more comprehensive reasoning of text. In this paper, we introduce\na new Reading Comprehension dataset requiring logical reasoning (ReClor)\nextracted from standardized graduate admission examinations. As earlier studies\nsuggest, human-annotated datasets usually contain biases, which are often\nexploited by models to achieve high accuracy without truly understanding the\ntext. In order to comprehensively evaluate the logical reasoning ability of\nmodels on ReClor, we propose to identify biased data points and separate them\ninto EASY set while the rest as HARD set. Empirical results show that\nstate-of-the-art models have an outstanding ability to capture biases contained\nin the dataset with high accuracy on EASY set. However, they struggle on HARD\nset with poor performance near that of random guess, indicating more research\nis needed to essentially enhance the logical reasoning ability of current\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:54:29 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 09:23:26 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 07:14:30 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Yu", "Weihao", ""], ["Jiang", "Zihang", ""], ["Dong", "Yanfei", ""], ["Feng", "Jiashi", ""]]}, {"id": "2002.04374", "submitter": "Juan Camilo Vasquez Correa J. C. Vasquez-Correa", "authors": "J. C. V\\'asquez-Correa, T. Arias-Vergara, C. D. Rios-Urrego, M.\n  Schuster, J. Rusz, J. R. Orozco-Arroyave, E. N\\\"oth", "title": "Convolutional Neural Networks and a Transfer Learning Strategy to\n  Classify Parkinson's Disease from Speech in Three Different Languages", "comments": null, "journal-ref": "In Iberoamerican Congress on Pattern Recognition (pp. 697-706)\n  2019", "doi": "10.1007/978-3-030-33904-3_66", "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parkinson's disease patients develop different speech impairments that affect\ntheir communication capabilities. The automatic assessment of the speech of the\npatients allows the development of computer aided tools to support the\ndiagnosis and the evaluation of the disease severity. This paper introduces a\nmethodology to classify Parkinson's disease from speech in three different\nlanguages: Spanish, German, and Czech. The proposed approach considers\nconvolutional neural networks trained with time frequency representations and a\ntransfer learning strategy among the three languages. The transfer learning\nscheme aims to improve the accuracy of the models when the weights of the\nneural network are initialized with utterances from a different language than\nthe used for the test set. The results suggest that the proposed strategy\nimproves the accuracy of the models in up to 8\\% when the base model used to\ninitialize the weights of the classifier is robust enough. In addition, the\nresults obtained after the transfer learning are in most cases more balanced in\nterms of specificity-sensitivity than those trained without the transfer\nlearning strategy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:48:38 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["V\u00e1squez-Correa", "J. C.", ""], ["Arias-Vergara", "T.", ""], ["Rios-Urrego", "C. D.", ""], ["Schuster", "M.", ""], ["Rusz", "J.", ""], ["Orozco-Arroyave", "J. R.", ""], ["N\u00f6th", "E.", ""]]}, {"id": "2002.04397", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren, Jiawei Zhang", "title": "Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:09:13 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 03:16:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "2002.04494", "submitter": "Leon Derczynski", "authors": "Nanna Inie, Jeanette Falk Olesen, Leon Derczynski", "title": "The Rumour Mill: Making the Spread of Misinformation Explicit and\n  Tangible", "comments": "Accepted to CHI 2020 Interactivity", "journal-ref": null, "doi": "10.1145/3334480.3383159", "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Misinformation spread presents a technological and social threat to society.\nWith the advance of AI-based language models, automatically generated texts\nhave become difficult to identify and easy to create at scale. We present \"The\nRumour Mill\", a playful art piece, designed as a commentary on the spread of\nrumours and automatically-generated misinformation. The mill is a tabletop\ninteractive machine, which invites a user to experience the process of creating\nbelievable text by interacting with different tangible controls on the mill.\nThe user manipulates visible parameters to adjust the genre and type of an\nautomatically generated text rumour. The Rumour Mill is a physical\ndemonstration of the state of current technology and its ability to generate\nand manipulate natural language text, and of the act of starting and spreading\nrumours.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:49:32 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 14:23:28 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Inie", "Nanna", ""], ["Olesen", "Jeanette Falk", ""], ["Derczynski", "Leon", ""]]}, {"id": "2002.04513", "submitter": "Sandro Tsang Dr", "authors": "Sandro Tsang", "title": "An experiment exploring the theoretical and methodological challenges in\n  developing a semi-automated approach to analysis of small-N qualitative data", "comments": "Page 2: \"qualitative\" research (QR); Page 3 and Appendix: Cited the\n  second and third authors of a paper; Page 4: Redundant citation of author\n  names; Page 8: Replaced wordclouds with higher resolution ones (cited\n  facilities on page 3); Page 13: TM is a big-data/\"quantitative\" method and\n  replaced \"supplementary material\" with \"appendix\"; Showed author names after\n  see or cf. on pages 4, 5, 6 and 15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper experiments with designing a semi-automated qualitative data\nanalysis (QDA) algorithm to analyse 20 transcripts by using freeware.\nText-mining (TM) and QDA were guided by frequency and association measures,\nbecause these statistics remain robust when the sample size is small. The\nrefined TM algorithm split the text into various sizes based on a manually\nrevised dictionary. This lemmatisation approach may reflect the context of the\ntext better than uniformly tokenising the text into one single size. TM results\nwere used for initial coding. Code repacking was guided by association measures\nand external data to implement a general inductive QDA approach. The\ninformation retrieved by TM and QDA was depicted in subgraphs for comparisons.\nThe analyses were completed in 6-7 days. Both algorithms retrieved contextually\nconsistent and relevant information. However, the QDA algorithm retrieved more\nspecific information than TM alone. The QDA algorithm does not strictly comply\nwith the convention of TM or of QDA, but becomes a more efficient, systematic\nand transparent text analysis approach than a conventional QDA approach.\nScaling up QDA to reliably discover knowledge from text was exactly the\nresearch purpose. This paper also sheds light on understanding the relations\nbetween information technologies, theory and methodologies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:55:19 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 19:10:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tsang", "Sandro", ""]]}, {"id": "2002.04608", "submitter": "Mike Kuehne", "authors": "Michael Kuehne and Marius Radu", "title": "Constructing a Highlight Classifier with an Attention Based LSTM Neural\n  Network", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is being produced in larger quantities than ever before in human\nhistory. It's only natural to expect a rise in demand for technology that aids\nhumans in sifting through and analyzing this inexhaustible supply of\ninformation. This need exists in the market research industry, where large\namounts of consumer research data is collected through video recordings. At\npresent, the standard method for analyzing video data is human labor. Market\nresearchers manually review the vast majority of consumer research video in\norder to identify relevant portions - highlights. The industry state of the art\nturnaround ratio is 2.2 - for every hour of video content 2.2 hours of manpower\nare required. In this study we present a novel approach for NLP-based highlight\nidentification and extraction based on a supervised learning model that aides\nmarket researchers in sifting through their data. Our approach hinges on a\nmanually curated user-generated highlight clips constructed from long and\nshort-form video data. The problem is best suited for an NLP approach due to\nthe availability of video transcription. We evaluate multiple classes of\nmodels, from gradient boosting to recurrent neural networks, comparing their\nperformance in extraction and identification of highlights. The best performing\nmodels are then evaluated using four sampling methods designed to analyze\ndocuments much larger than the maximum input length of the classifiers. We\nreport very high performances for the standalone classifiers, ROC AUC scores in\nthe range 0.93-0.94, but observe a significant drop in effectiveness when\nevaluated on large documents. Based on our results we suggest combinations of\nmodels/sampling algorithms for various use cases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:18:31 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kuehne", "Michael", ""], ["Radu", "Marius", ""]]}, {"id": "2002.04678", "submitter": "Tzu-Hsiang Lin", "authors": "Tzu-Hsiang Lin, Alexander Rudnicky, Trung Bui, Doo Soon Kim, Jean Oh", "title": "Adjusting Image Attributes of Localized Regions with Low-level Dialogue", "comments": "Accepted as a Poster presentation at the 12th International\n  Conference on Language Resources and Evaluation (LREC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Image Editing (NLIE) aims to use natural language\ninstructions to edit images. Since novices are inexperienced with image editing\ntechniques, their instructions are often ambiguous and contain high-level\nabstractions that tend to correspond to complex editing steps to accomplish.\nMotivated by this inexperience aspect, we aim to smooth the learning curve by\nteaching the novices to edit images using low-level commanding terminologies.\nTowards this end, we develop a task-oriented dialogue system to investigate\nlow-level instructions for NLIE. Our system grounds language on the level of\nedit operations, and suggests options for a user to choose from. Though\ncompelled to express in low-level terms, a user evaluation shows that 25% of\nusers found our system easy-to-use, resonating with our motivation. An analysis\nshows that users generally adapt to utilizing the proposed low-level language\ninterface. In this study, we identify that object segmentation as the key\nfactor to the user satisfaction. Our work demonstrates the advantages of the\nlow-level, direct language-action mapping approach that can be applied to other\nproblem domains beyond image editing such as audio editing or industrial\ndesign.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:59:34 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Lin", "Tzu-Hsiang", ""], ["Rudnicky", "Alexander", ""], ["Bui", "Trung", ""], ["Kim", "Doo Soon", ""], ["Oh", "Jean", ""]]}, {"id": "2002.04689", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano, Ond\\v{r}ej Bojar", "title": "Two Huge Title and Keyword Generation Corpora of Research Articles", "comments": "9 pages, 8 tables. Published in proceedings of LREC 2020, the 12th\n  International Conference on Language Resources and Evaluation, Marseille,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in sequence-to-sequence learning with neural networks\nhave considerably improved the quality of automatically generated text\nsummaries and document keywords, stipulating the need for even bigger training\ncorpora. Metadata of research articles are usually easy to find online and can\nbe used to perform research on various tasks. In this paper, we introduce two\nhuge datasets for text summarization (OAGSX) and keyword generation (OAGKX)\nresearch, containing 34 million and 23 million records, respectively. The data\nwere retrieved from the Open Academic Graph which is a network of research\nprofiles and publications. We carefully processed each record and also tried\nseveral extractive and abstractive methods of both tasks to create performance\nbaselines for other researchers. We further illustrate the performance of those\nmethods previewing their outputs. In the near future, we would like to apply\ntopic modeling on the two sets to derive subsets of research articles from more\nspecific disciplines.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:17:29 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "2002.04723", "submitter": "Li Zhang", "authors": "John Anderson, Qingqing Huang, Walid Krichene, Steffen Rendle, Li\n  Zhang", "title": "Superbloom: Bloom filter meets Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the idea of word pieces in natural language models to machine\nlearning tasks on opaque ids. This is achieved by applying hash functions to\nmap each id to multiple hash tokens in a much smaller space, similarly to a\nBloom filter. We show that by applying a multi-layer Transformer to these Bloom\nfilter digests, we are able to obtain models with high accuracy. They\noutperform models of a similar size without hashing and, to a large degree,\nmodels of a much larger size trained using sampled softmax with the same\ncomputational budget. Our key observation is that it is important to use a\nmulti-layer Transformer for Bloom filter digests to remove ambiguity in the\nhashed input. We believe this provides an alternative method to solving\nproblems with large vocabulary size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:52:40 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Anderson", "John", ""], ["Huang", "Qingqing", ""], ["Krichene", "Walid", ""], ["Rendle", "Steffen", ""], ["Zhang", "Li", ""]]}, {"id": "2002.04745", "submitter": "Di He", "authors": "Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen\n  Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu", "title": "On Layer Normalization in the Transformer Architecture", "comments": null, "journal-ref": "Published on ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer is widely used in natural language processing tasks. To train\na Transformer however, one usually needs a carefully designed learning rate\nwarm-up stage, which is shown to be crucial to the final performance but will\nslow down the optimization and bring more hyper-parameter tunings. In this\npaper, we first study theoretically why the learning rate warm-up stage is\nessential and show that the location of layer normalization matters.\nSpecifically, we prove with mean field theory that at initialization, for the\noriginal-designed Post-LN Transformer, which places the layer normalization\nbetween the residual blocks, the expected gradients of the parameters near the\noutput layer are large. Therefore, using a large learning rate on those\ngradients makes the training unstable. The warm-up stage is practically helpful\nfor avoiding this problem. On the other hand, our theory also shows that if the\nlayer normalization is put inside the residual blocks (recently proposed as\nPre-LN Transformer), the gradients are well-behaved at initialization. This\nmotivates us to remove the warm-up stage for the training of Pre-LN\nTransformers. We show in our experiments that Pre-LN Transformers without the\nwarm-up stage can reach comparable results with baselines while requiring\nsignificantly less training time and hyper-parameter tuning on a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:33:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 07:55:12 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Ruibin", ""], ["Yang", "Yunchang", ""], ["He", "Di", ""], ["Zheng", "Kai", ""], ["Zheng", "Shuxin", ""], ["Xing", "Chen", ""], ["Zhang", "Huishuai", ""], ["Lan", "Yanyan", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2002.04760", "submitter": "Michele Tufano", "authors": "Michele Tufano, Jason Kimko, Shiya Wang, Cody Watson, Gabriele Bavota,\n  Massimiliano Di Penta, Denys Poshyvanyk", "title": "DeepMutation: A Neural Mutation Tool", "comments": "Accepted to the 42nd ACM/IEEE International Conference on Software\n  Engineering (ICSE 2020), Demonstrations Track - Seoul, South Korea, May\n  23-29, 2020, 4 pages", "journal-ref": null, "doi": "10.1145/3377812.3382146", "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutation testing can be used to assess the fault-detection capabilities of a\ngiven test suite. To this aim, two characteristics of mutation testing\nframeworks are of paramount importance: (i) they should generate mutants that\nare representative of real faults; and (ii) they should provide a complete tool\nchain able to automatically generate, inject, and test the mutants. To address\nthe first point, we recently proposed an approach using a Recurrent Neural\nNetwork Encoder-Decoder architecture to learn mutants from ~787k faults mined\nfrom real programs. The empirical evaluation of this approach confirmed its\nability to generate mutants representative of real faults. In this paper, we\naddress the second point, presenting DeepMutation, a tool wrapping our deep\nlearning model into a fully automated tool chain able to generate, inject, and\ntest mutants learned from real faults. Video:\nhttps://sites.google.com/view/learning-mutation/deepmutation\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:57:41 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 01:32:42 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tufano", "Michele", ""], ["Kimko", "Jason", ""], ["Wang", "Shiya", ""], ["Watson", "Cody", ""], ["Bavota", "Gabriele", ""], ["Di Penta", "Massimiliano", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "2002.04793", "submitter": "Qi Zhu", "authors": "Qi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi Takanobu, Jinchao Li,\n  Baolin Peng, Jianfeng Gao, Xiaoyan Zhu, Minlie Huang", "title": "ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and\n  Diagnosing Dialogue Systems", "comments": "Accepted by ACL 2020 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ConvLab-2, an open-source toolkit that enables researchers to\nbuild task-oriented dialogue systems with state-of-the-art models, perform an\nend-to-end evaluation, and diagnose the weakness of systems. As the successor\nof ConvLab (Lee et al., 2019b), ConvLab-2 inherits ConvLab's framework but\nintegrates more powerful dialogue models and supports more datasets. Besides,\nwe have developed an analysis tool and an interactive tool to assist\nresearchers in diagnosing dialogue systems. The analysis tool presents rich\nstatistics and summarizes common mistakes from simulated dialogues, which\nfacilitates error analysis and system improvement. The interactive tool\nprovides a user interface that allows developers to diagnose an assembled\ndialogue system by interacting with the system and modifying the output of each\nsystem component.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:31:40 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 14:02:43 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zhu", "Qi", ""], ["Zhang", "Zheng", ""], ["Fang", "Yan", ""], ["Li", "Xiang", ""], ["Takanobu", "Ryuichi", ""], ["Li", "Jinchao", ""], ["Peng", "Baolin", ""], ["Gao", "Jianfeng", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2002.04815", "submitter": "Zhiwei Liang", "authors": "Youwei Song, Jiahai Wang, Zhiwei Liang, Zhiyue Liu, Tao Jiang", "title": "Utilizing BERT Intermediate Layers for Aspect Based Sentiment Analysis\n  and Natural Language Inference", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based sentiment analysis aims to identify the sentimental tendency\ntowards a given aspect in text. Fine-tuning of pretrained BERT performs\nexcellent on this task and achieves state-of-the-art performances. Existing\nBERT-based works only utilize the last output layer of BERT and ignore the\nsemantic knowledge in the intermediate layers. This paper explores the\npotential of utilizing BERT intermediate layers to enhance the performance of\nfine-tuning of BERT. To the best of our knowledge, no existing work has been\ndone on this research. To show the generality, we also apply this approach to a\nnatural language inference task. Experimental results demonstrate the\neffectiveness and generality of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 06:11:48 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Song", "Youwei", ""], ["Wang", "Jiahai", ""], ["Liang", "Zhiwei", ""], ["Liu", "Zhiyue", ""], ["Jiang", "Tao", ""]]}, {"id": "2002.04936", "submitter": "Wei Shi", "authors": "Wei Shi, Siyuan Zhang, Zhiwei Zhang, Hong Cheng, Jeffrey Xu Yu", "title": "Joint Embedding in Named Entity Linking on Sentence Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity linking is to map an ambiguous mention in documents to an entity\nin a knowledge base. The named entity linking is challenging, given the fact\nthat there are multiple candidate entities for a mention in a document. It is\ndifficult to link a mention when it appears multiple times in a document, since\nthere are conflicts by the contexts around the appearances of the mention. In\naddition, it is difficult since the given training dataset is small due to the\nreason that it is done manually to link a mention to its mapping entity. In the\nliterature, there are many reported studies among which the recent embedding\nmethods learn vectors of entities from the training dataset at document level.\nTo address these issues, we focus on how to link entity for mentions at a\nsentence level, which reduces the noises introduced by different appearances of\nthe same mention in a document at the expense of insufficient information to be\nused. We propose a new unified embedding method by maximizing the relationships\nlearned from knowledge graphs. We confirm the effectiveness of our method in\nour experimental studies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 12:06:32 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Shi", "Wei", ""], ["Zhang", "Siyuan", ""], ["Zhang", "Zhiwei", ""], ["Cheng", "Hong", ""], ["Yu", "Jeffrey Xu", ""]]}, {"id": "2002.05058", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou and Ke Xu", "title": "Learning to Compare for Better Training and Evaluation of Open Domain\n  Natural Language Generation Models", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated evaluation of open domain natural language generation (NLG) models\nremains a challenge and widely used metrics such as BLEU and Perplexity can be\nmisleading in some cases. In our paper, we propose to evaluate natural language\ngeneration models by learning to compare a pair of generated sentences by\nfine-tuning BERT, which has been shown to have good natural language\nunderstanding ability. We also propose to evaluate the model-level quality of\nNLG models with sample-level comparison results with skill rating system. While\nable to be trained in a fully self-supervised fashion, our model can be further\nfine-tuned with a little amount of human preference annotation to better\nimitate human judgment. In addition to evaluating trained models, we propose to\napply our model as a performance indicator during training for better\nhyperparameter tuning and early-stopping. We evaluate our approach on both\nstory generation and chit-chat dialogue response generation. Experimental\nresults show that our model correlates better with human preference compared\nwith previous automated evaluation approaches. Training with the proposed\nmetric yields better performance in human evaluation, which further\ndemonstrates the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:52:21 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Xu", "Ke", ""]]}, {"id": "2002.05104", "submitter": "Camila Kolling", "authors": "Camila Kolling, J\\^onatas Wehrmann, and Rodrigo C. Barros", "title": "Component Analysis for Visual Question Answering Architectures", "comments": null, "journal-ref": "2020 - The International Joint Conference on Neural Networks\n  (IJCNN)", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research advances in Computer Vision and Natural Language Processing\nhave introduced novel tasks that are paving the way for solving AI-complete\nproblems. One of those tasks is called Visual Question Answering (VQA). A VQA\nsystem must take an image and a free-form, open-ended natural language question\nabout the image, and produce a natural language answer as the output. Such a\ntask has drawn great attention from the scientific community, which generated a\nplethora of approaches that aim to improve the VQA predictive accuracy. Most of\nthem comprise three major components: (i) independent representation learning\nof images and questions; (ii) feature fusion so the model can use information\nfrom both sources to answer visual questions; and (iii) the generation of the\ncorrect answer in natural language. With so many approaches being recently\nintroduced, it became unclear the real contribution of each component for the\nultimate performance of the model. The main goal of this paper is to provide a\ncomprehensive analysis regarding the impact of each component in VQA models.\nOur extensive set of experiments cover both visual and textual elements, as\nwell as the combination of these representations in form of fusion and\nattention mechanisms. Our major contribution is to identify core components for\ntraining VQA models so as to maximize their predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:25:50 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 01:08:38 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Kolling", "Camila", ""], ["Wehrmann", "J\u00f4natas", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "2002.05150", "submitter": "Julian Salazar", "authors": "Phillip Keung, Wei Niu, Yichao Lu, Julian Salazar, Vikas Bhardwaj", "title": "Attentional Speech Recognition Models Misbehave on Out-of-domain\n  Utterances", "comments": "Artifacts like our filtered Audio BNC dataset can be found at\n  https://github.com/aws-samples/seq2seq-asr-misbehaves", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of echographic transcription in autoregressive\nsequence-to-sequence attentional architectures for automatic speech\nrecognition, where a model produces very long sequences of repetitive outputs\nwhen presented with out-of-domain utterances. We decode audio from the British\nNational Corpus with an attentional encoder-decoder model trained solely on the\nLibriSpeech corpus. We observe that there are many 5-second recordings that\nproduce more than 500 characters of decoding output (i.e. more than 100\ncharacters per second). A frame-synchronous hybrid (DNN-HMM) model trained on\nthe same data does not produce these unusually long transcripts. These decoding\nissues are reproducible in a speech transformer model from ESPnet, and to a\nlesser extent in a self-attention CTC model, suggesting that these issues are\nintrinsic to the use of the attention mechanism. We create a separate length\nprediction model to predict the correct number of wordpieces in the output,\nwhich allows us to identify and truncate problematic decoding results without\nincreasing word error rates on the LibriSpeech task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:53:56 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Keung", "Phillip", ""], ["Niu", "Wei", ""], ["Lu", "Yichao", ""], ["Salazar", "Julian", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "2002.05162", "submitter": "Georges Nassif", "authors": "Georges Nassif, Catherine Gloaguen, and Philippe Martins", "title": "A Combined Stochastic and Physical Framework for Modeling Indoor 5G\n  Millimeter Wave Propagation", "comments": "30 pages, 18 figures, and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor coverage is a major challenge for 5G millimeter waves (mmWaves). In\nthis paper, we address this problem through a novel theoretical framework that\ncombines stochastic indoor environment modeling with advanced physical\npropagation simulation. This approach is particularly adapted to investigate\nindoor-to-indoor 5G mmWave propagation. Its system implementation, so-called\niGeoStat, generates parameterized typical environments that account for the\nindoor spatial variations, then simulates radio propagation based on the\nphysical interaction between electromagnetic waves and material properties.\nThis framework is not dedicated to a particular environment, material,\nfrequency or use case and aims to statistically understand the influence of\nindoor environment parameters on mmWave propagation properties, especially\ncoverage and path loss. Its implementation raises numerous computational\nchallenges that we solve by formulating an adapted link budget and designing\nnew memory optimization algorithms. The first simulation results for two major\n5G applications are validated with measurement data and show the efficiency of\niGeoStat to simulate multiple diffusion in realistic environments, within a\nreasonable amount of time and memory resources. Generated output maps confirm\nthat diffusion has a critical impact on indoor mmWave propagation and that\nproper physical modeling is of the utmost importance to generate relevant\npropagation models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:28:30 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:12:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Nassif", "Georges", ""], ["Gloaguen", "Catherine", ""], ["Martins", "Philippe", ""]]}, {"id": "2002.05201", "submitter": "Yen-Ling Kuo", "authors": "Yen-Ling Kuo, Boris Katz, Andrei Barbu", "title": "Deep compositional robotic planners that follow natural language\n  commands", "comments": "Accepted in ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how a sampling-based robotic planner can be augmented to learn\nto understand a sequence of natural language commands in a continuous\nconfiguration space to move and manipulate objects. Our approach combines a\ndeep network structured according to the parse of a complex command that\nincludes objects, verbs, spatial relations, and attributes, with a\nsampling-based planner, RRT. A recurrent hierarchical deep network controls how\nthe planner explores the environment, determines when a planned path is likely\nto achieve a goal, and estimates the confidence of each move to trade off\nexploitation and exploration between the network and the planner. Planners are\ndesigned to have near-optimal behavior when information about the task is\nmissing, while networks learn to exploit observations which are available from\nthe environment, making the two naturally complementary. Combining the two\nenables generalization to new maps, new kinds of obstacles, and more complex\nsentences that do not occur in the training set. Little data is required to\ntrain the model despite it jointly acquiring a CNN that extracts features from\nthe environment as it learns the meanings of words. The model provides a level\nof interpretability through the use of attention maps allowing users to see its\nreasoning steps despite being an end-to-end model. This end-to-end model allows\nrobots to learn to follow natural language commands in challenging continuous\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:56:58 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:21:46 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Kuo", "Yen-Ling", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2002.05235", "submitter": "Bowen Li", "authors": "Bowen Li, Xiaojuan Qi, Philip H. S. Torr, Thomas Lukasiewicz", "title": "Image-to-Image Translation with Text Guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to embed controllable factors, i.e., natural\nlanguage descriptions, into image-to-image translation with generative\nadversarial networks, which allows text descriptions to determine the visual\nattributes of synthetic images. We propose four key components: (1) the\nimplementation of part-of-speech tagging to filter out non-semantic words in\nthe given description, (2) the adoption of an affine combination module to\neffectively fuse different modality text and image features, (3) a novel\nrefined multi-stage architecture to strengthen the differential ability of\ndiscriminators and the rectification ability of generators, and (4) a new\nstructure loss to further improve discriminators to better distinguish real and\nsynthetic images. Extensive experiments on the COCO dataset demonstrate that\nour method has a superior performance on both visual realism and semantic\nconsistency with given descriptions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:09:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Li", "Bowen", ""], ["Qi", "Xiaojuan", ""], ["Torr", "Philip H. S.", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2002.05295", "submitter": "Viet Lai", "authors": "Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen", "title": "Exploiting the Matching Information in the Support Set for Few Shot\n  Event Classification", "comments": "Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2020", "journal-ref": null, "doi": "10.1007/978-3-030-47436-2_18", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The existing event classification (EC) work primarily focuseson the\ntraditional supervised learning setting in which models are unableto extract\nevent mentions of new/unseen event types. Few-shot learninghas not been\ninvestigated in this area although it enables EC models toextend their\noperation to unobserved event types. To fill in this gap, inthis work, we\ninvestigate event classification under the few-shot learningsetting. We propose\na novel training method for this problem that exten-sively exploit the support\nset during the training process of a few-shotlearning model. In particular, in\naddition to matching the query exam-ple with those in the support set for\ntraining, we seek to further matchthe examples within the support set\nthemselves. This method providesmore training signals for the models and can be\napplied to every metric-learning-based few-shot learning methods. Our extensive\nexperiments ontwo benchmark EC datasets show that the proposed method can\nimprovethe best reported few-shot learning models by up to 10% on accuracyfor\nevent classification\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:40:36 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 07:37:15 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lai", "Viet Dac", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "2002.05407", "submitter": "Yequan Wang", "authors": "Funan Mu, Zhenting Yu, LiFeng Wang, Yequan Wang, Qingyu Yin, Yibo Sun,\n  Liqun Liu, Teng Ma, Jing Tang, Xing Zhou", "title": "Keyphrase Extraction with Span-based Feature Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrases are capable of providing semantic metadata characterizing\ndocuments and producing an overview of the content of a document. Since\nkeyphrase extraction is able to facilitate the management, categorization, and\nretrieval of information, it has received much attention in recent years. There\nare three approaches to address keyphrase extraction: (i) traditional two-step\nranking method, (ii) sequence labeling and (iii) generation using neural\nnetworks. Two-step ranking approach is based on feature engineering, which is\nlabor intensive and domain dependent. Sequence labeling is not able to tackle\noverlapping phrases. Generation methods (i.e., Sequence-to-sequence neural\nnetwork models) overcome those shortcomings, so they have been widely studied\nand gain state-of-the-art performance. However, generation methods can not\nutilize context information effectively. In this paper, we propose a novelty\nSpan Keyphrase Extraction model that extracts span-based feature representation\nof keyphrase directly from all the content tokens. In this way, our model\nobtains representation for each keyphrase and further learns to capture the\ninteraction between keyphrases in one document to get better ranking results.\nIn addition, with the help of tokens, our model is able to extract overlapped\nkeyphrases. Experimental results on the benchmark datasets show that our\nproposed model outperforms the existing methods by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:48:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Mu", "Funan", ""], ["Yu", "Zhenting", ""], ["Wang", "LiFeng", ""], ["Wang", "Yequan", ""], ["Yin", "Qingyu", ""], ["Sun", "Yibo", ""], ["Liu", "Liqun", ""], ["Ma", "Teng", ""], ["Tang", "Jing", ""], ["Zhou", "Xing", ""]]}, {"id": "2002.05417", "submitter": "G\\\"okhan G\\\"uler", "authors": "G\\\"okhan G\\\"uler, A. C\\\"uneyd Tantu\\u{g}", "title": "Comparison of Turkish Word Representations Trained on Different\n  Morphological Forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increased popularity of different text representations has also brought many\nimprovements in Natural Language Processing (NLP) tasks. Without need of\nsupervised data, embeddings trained on large corpora provide us meaningful\nrelations to be used on different NLP tasks. Even though training these vectors\nis relatively easy with recent methods, information gained from the data\nheavily depends on the structure of the corpus language. Since the popularly\nresearched languages have a similar morphological structure, problems occurring\nfor morphologically rich languages are mainly disregarded in studies. For\nmorphologically rich languages, context-free word vectors ignore morphological\nstructure of languages. In this study, we prepared texts in morphologically\ndifferent forms in a morphologically rich language, Turkish, and compared the\nresults on different intrinsic and extrinsic tasks. To see the effect of\nmorphological structure, we trained word2vec model on texts which lemma and\nsuffixes are treated differently. We also trained subword model fastText and\ncompared the embeddings on word analogy, text classification, sentimental\nanalysis, and language model tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:09:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["G\u00fcler", "G\u00f6khan", ""], ["Tantu\u011f", "A. C\u00fcneyd", ""]]}, {"id": "2002.05527", "submitter": "Sridhama Prakhya", "authors": "Sridhama Prakhya, Deepak P", "title": "Unsupervised Separation of Native and Loanwords for Malayalam and Telugu", "comments": "submitted to Natural Language Engineering; 22 pages; 4 figures. This\n  is an extended version of a conference paper (arXiv:1803.09641) that has been\n  enriched with substantive new content, with significant extensions on both\n  the method modeling and the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quite often, words from one language are adopted within a different language\nwithout translation; these words appear in transliterated form in text written\nin the latter language. This phenomenon is particularly widespread within\nIndian languages where many words are loaned from English. In this paper, we\naddress the task of identifying loanwords automatically and in an unsupervised\nmanner, from large datasets of words from agglutinative Dravidian languages. We\ntarget two specific languages from the Dravidian family, viz., Malayalam and\nTelugu. Based on familiarity with the languages, we outline an observation that\nnative words in both these languages tend to be characterized by a much more\nversatile stem - stem being a shorthand to denote the subword sequence formed\nby the first few characters of the word - than words that are loaned from other\nlanguages. We harness this observation to build an objective function and an\niterative optimization formulation to optimize for it, yielding a scoring of\neach word's nativeness in the process. Through an extensive empirical analysis\nover real-world datasets from both Malayalam and Telugu, we illustrate the\neffectiveness of our method in quantifying nativeness effectively over\navailable baselines for the task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:01:57 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Prakhya", "Sridhama", ""], ["P", "Deepak", ""]]}, {"id": "2002.05556", "submitter": "Pedro Henrique Martins", "authors": "Pedro Henrique Martins, Vlad Niculae, Zita Marinho, Andr\\'e Martins", "title": "Sparse and Structured Visual Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attention mechanisms are widely used in multimodal tasks, as visual\nquestion answering (VQA). One drawback of softmax-based attention mechanisms is\nthat they assign some probability mass to all image regions, regardless of\ntheir adjacency structure and of their relevance to the text. In this paper, to\nbetter link the image structure with the text, we replace the traditional\nsoftmax attention mechanism with two alternative sparsity-promoting\ntransformations: sparsemax, which is able to select only the relevant regions\n(assigning zero weight to the rest), and a newly proposed Total-Variation\nSparse Attention (TVmax), which further encourages the joint selection of\nadjacent spatial locations. Experiments in VQA show gains in accuracy as well\nas higher similarity to human attention, which suggests better\ninterpretability.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:08:12 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 12:39:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Martins", "Pedro Henrique", ""], ["Niculae", "Vlad", ""], ["Marinho", "Zita", ""], ["Martins", "Andr\u00e9", ""]]}, {"id": "2002.05606", "submitter": "Ali Erkan", "authors": "Ali Erkan and Tunga Gungor", "title": "Sentiment Analysis Using Averaged Weighted Word Vector Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People use the world wide web heavily to share their experience with entities\nsuch as products, services, or travel destinations. Texts that provide online\nfeedback in the form of reviews and comments are essential to make consumer\ndecisions. These comments create a valuable source that may be used to measure\nsatisfaction related to products or services. Sentiment analysis is the task of\nidentifying opinions expressed in such text fragments. In this work, we develop\ntwo methods that combine different types of word vectors to learn and estimate\npolarity of reviews. We develop average review vectors from word vectors and\nadd weights to this review vectors using word frequencies in positive and\nnegative sensitivity-tagged reviews. We applied the methods to several datasets\nfrom different domains that are used as standard benchmarks for sentiment\nanalysis. We ensemble the techniques with each other and existing methods, and\nwe make a comparison with the approaches in the literature. The results show\nthat the performances of our approaches outperform the state-of-the-art success\nrates.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:30:34 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Erkan", "Ali", ""], ["Gungor", "Tunga", ""]]}, {"id": "2002.05607", "submitter": "Zheng Chen", "authors": "Zheng Chen, Xing Fan, Yuan Ling, Lambert Mathias, Chenlei Guo", "title": "Pre-Training for Query Rewriting in A Spoken Language Understanding\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Query rewriting (QR) is an increasingly important technique to reduce\ncustomer friction caused by errors in a spoken language understanding pipeline,\nwhere the errors originate from various sources such as speech recognition\nerrors, language understanding errors or entity resolution errors. In this\nwork, we first propose a neural-retrieval based approach for query rewriting.\nThen, inspired by the wide success of pre-trained contextual language\nembeddings, and also as a way to compensate for insufficient QR training data,\nwe propose a language-modeling (LM) based approach to pre-train query\nembeddings on historical user conversation data with a voice assistant. In\naddition, we propose to use the NLU hypotheses generated by the language\nunderstanding system to augment the pre-training. Our experiments show\npre-training provides rich prior information and help the QR task achieve\nstrong performance. We also show joint pre-training with NLU hypotheses has\nfurther benefit. Finally, after pre-training, we find a small set of rewrite\npairs is enough to fine-tune the QR model to outperform a strong baseline by\nfull training on all QR training data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:31:50 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chen", "Zheng", ""], ["Fan", "Xing", ""], ["Ling", "Yuan", ""], ["Mathias", "Lambert", ""], ["Guo", "Chenlei", ""]]}, {"id": "2002.05639", "submitter": "Tejas Srinivasan", "authors": "Tejas Srinivasan, Ramon Sanabria, Florian Metze", "title": "Looking Enhances Listening: Recovering Missing Speech Using Images", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech is understood better by using visual context; for this reason, there\nhave been many attempts to use images to adapt automatic speech recognition\n(ASR) systems. Current work, however, has shown that visually adapted ASR\nmodels only use images as a regularization signal, while completely ignoring\ntheir semantic content. In this paper, we present a set of experiments where we\nshow the utility of the visual modality under noisy conditions. Our results\nshow that multimodal ASR models can recover words which are masked in the input\nacoustic signal, by grounding its transcriptions using the visual\nrepresentations. We observe that integrating visual context can result in up to\n35% relative improvement in masked word recovery. These results demonstrate\nthat end-to-end multimodal ASR systems can become more robust to noise by\nleveraging the visual context.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:12:51 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Srinivasan", "Tejas", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""]]}, {"id": "2002.05674", "submitter": "Micha{\\l} Ku\\'zba", "authors": "Micha{\\l} Ku\\'zba, Przemys{\\l}aw Biecek", "title": "What Would You Ask the Machine Learning Model? Identification of User\n  Needs for Model Explanations Based on Human-Model Conversations", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we see a rising number of methods in the field of eXplainable\nArtificial Intelligence. To our surprise, their development is driven by model\ndevelopers rather than a study of needs for human end users. The analysis of\nneeds, if done, takes the form of an A/B test rather than a study of open\nquestions. To answer the question \"What would a human operator like to ask the\nML model?\" we propose a conversational system explaining decisions of the\npredictive model. In this experiment, we developed a chatbot called dr_ant to\ntalk about machine learning model trained to predict survival odds on Titanic.\nPeople can talk with dr_ant about different aspects of the model to understand\nthe rationale behind its predictions. Having collected a corpus of 1000+\ndialogues, we analyse the most common types of questions that users would like\nto ask. To our knowledge, it is the first study which uses a conversational\nsystem to collect the needs of human operators from the interactive and\niterative dialogue explorations of a predictive model.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:59:49 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:14:08 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 13:49:43 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ku\u017aba", "Micha\u0142", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2002.05829", "submitter": "Xiyou Zhou", "authors": "Xiyou Zhou, Zhiyu Chen, Xiaoyong Jin, William Yang Wang", "title": "HULK: An Energy Efficiency Benchmark Platform for Responsible Natural\n  Language Processing", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation-intensive pretrained models have been taking the lead of many\nnatural language processing benchmarks such as GLUE. However, energy efficiency\nin the process of model training and inference becomes a critical bottleneck.\nWe introduce HULK, a multi-task energy efficiency benchmarking platform for\nresponsible natural language processing. With HULK, we compare pretrained\nmodels' energy efficiency from the perspectives of time and cost. Baseline\nbenchmarking results are provided for further analysis. The fine-tuning\nefficiency of different pretrained models can differ a lot among different\ntasks and fewer parameter number does not necessarily imply better efficiency.\nWe analyzed such phenomenon and demonstrate the method of comparing the\nmulti-task efficiency of pretrained models. Our platform is available at\nhttps://sites.engineering.ucsb.edu/~xiyou/hulk/.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 01:04:19 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhou", "Xiyou", ""], ["Chen", "Zhiyu", ""], ["Jin", "Xiaoyong", ""], ["Wang", "William Yang", ""]]}, {"id": "2002.05867", "submitter": "Peter Clark", "authors": "Peter Clark, Oyvind Tafjord, Kyle Richardson", "title": "Transformers as Soft Reasoners over Language", "comments": "IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beginning with McCarthy's Advice Taker (1959), AI has pursued the goal of\nproviding a system with explicit, general knowledge and having the system\nreason over that knowledge. However, expressing the knowledge in a formal\n(logical or probabilistic) representation has been a major obstacle to this\nresearch. This paper investigates a modern approach to this problem where the\nfacts and rules are provided as natural language sentences, thus bypassing a\nformal representation. We train transformers to reason (or emulate reasoning)\nover these sentences using synthetically generated data. Our models, that we\ncall RuleTakers, provide the first empirical demonstration that this kind of\nsoft reasoning over language is learnable, can achieve high (99%) accuracy, and\ngeneralizes to test data requiring substantially deeper chaining than seen\nduring training (95%+ scores). We also demonstrate that the models transfer\nwell to two hand-authored rulebases, and to rulebases paraphrased into more\nnatural language. These findings are significant as it suggests a new role for\ntransformers, namely as limited \"soft theorem provers\" operating over explicit\ntheories in language. This in turn suggests new possibilities for\nexplainability, correctability, and counterfactual reasoning in\nquestion-answering.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:23:28 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 17:33:38 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Clark", "Peter", ""], ["Tafjord", "Oyvind", ""], ["Richardson", "Kyle", ""]]}, {"id": "2002.05902", "submitter": "Shameek Ghosh", "authors": "Budhaditya Saha, Sanal Lisboa, Shameek Ghosh", "title": "Understanding patient complaint characteristics using contextual\n  clinical BERT embeddings", "comments": "This paper has been communicated to 42nd IEEE Annual Conference of\n  Engineering in Medicine and Biology Society, Montreal, Canada. It is 5 pages\n  long. It has 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In clinical conversational applications, extracted entities tend to capture\nthe main subject of a patient's complaint, namely symptoms or diseases.\nHowever, they mostly fail to recognize the characterizations of a complaint\nsuch as the time, the onset, and the severity. For example, if the input is \"I\nhave a headache and it is extreme\", state-of-the-art models only recognize the\nmain symptom entity - headache, but ignore the severity factor of \"extreme\",\nthat characterizes headache. In this paper, we design a two-stage approach to\ndetect the characterizations of entities like symptoms presented by general\nusers in contexts where they would describe their symptoms to a clinician. We\nuse Word2Vec and BERT to encode clinical text given by the patients. We\ntransform the output and re-frame the task as multi-label classification\nproblem. Finally, we combine the processed encodings with the Linear\nDiscriminant Analysis (LDA) algorithm to classify the characterizations of the\nmain entity. Experimental results demonstrate that our method achieves 40-50%\nimprovement on the accuracy over the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 07:45:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Saha", "Budhaditya", ""], ["Lisboa", "Sanal", ""], ["Ghosh", "Shameek", ""]]}, {"id": "2002.05923", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Pascale Fung", "title": "Zero-Resource Cross-Domain Named Entity Recognition", "comments": "RepL4NLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models for cross-domain named entity recognition (NER) rely on\nnumerous unlabeled corpus or labeled NER training data in target domains.\nHowever, collecting data for low-resource target domains is not only expensive\nbut also time-consuming. Hence, we propose a cross-domain NER model that does\nnot use any external resources. We first introduce a Multi-Task Learning (MTL)\nby adding a new objective function to detect whether tokens are named entities\nor not. We then introduce a framework called Mixture of Entity Experts (MoEE)\nto improve the robustness for zero-resource domain adaptation. Finally,\nexperimental results show that our model outperforms strong unsupervised\ncross-domain sequence labeling models, and the performance of our model is\nclose to that of the state-of-the-art model which leverages extensive\nresources.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:04:18 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 11:56:07 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "2002.05955", "submitter": "Laurent Besacier", "authors": "Marco Dinarelli, Nikita Kapoor, Bassam Jabaian, and Laurent Besacier", "title": "A Data Efficient End-To-End Spoken Language Understanding Architecture", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end architectures have been recently proposed for spoken language\nunderstanding (SLU) and semantic parsing. Based on a large amount of data,\nthose models learn jointly acoustic and linguistic-sequential features. Such\narchitectures give very good results in the context of domain, intent and slot\ndetection, their application in a more complex semantic chunking and tagging\ntask is less easy. For that, in many cases, models are combined with an\nexternal language model to enhance their performance.\n  In this paper we introduce a data efficient system which is trained\nend-to-end, with no additional, pre-trained external module. One key feature of\nour approach is an incremental training procedure where acoustic, language and\nsemantic models are trained sequentially one after the other. The proposed\nmodel has a reasonable size and achieves competitive results with respect to\nstate-of-the-art while using a small training dataset. In particular, we reach\n24.02% Concept Error Rate (CER) on MEDIA/test while training on MEDIA/train\nwithout any additional data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 10:24:42 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Dinarelli", "Marco", ""], ["Kapoor", "Nikita", ""], ["Jabaian", "Bassam", ""], ["Besacier", "Laurent", ""]]}, {"id": "2002.05967", "submitter": "Silin Gao", "authors": "Silin Gao, Zhijian Ou, Wei Yang and Huifang Xu", "title": "Integrating Discrete and Neural Features via Mixed-feature\n  Trans-dimensional Random Field Language Models", "comments": "Accepted for presentation at ICASSP 2020, 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a long recognition that discrete features (n-gram features)\nand neural network based features have complementary strengths for language\nmodels (LMs). Improved performance can be obtained by model interpolation,\nwhich is, however, a suboptimal two-step integration of discrete and neural\nfeatures. The trans-dimensional random field (TRF) framework has the potential\nadvantage of being able to flexibly integrate a richer set of features.\nHowever, either discrete or neural features are used alone in previous TRF LMs.\nThis paper develops a mixed-feature TRF LM and demonstrates its advantage in\nintegrating discrete and neural features. Various LMs are trained over PTB and\nGoogle one-billion-word datasets, and evaluated in N-best list rescoring\nexperiments for speech recognition. Among all single LMs (i.e. without model\ninterpolation), the mixed-feature TRF LMs perform the best, improving over both\ndiscrete TRF LMs and neural TRF LMs alone, and also being significantly better\nthan LSTM LMs. Compared to interpolating two separately trained models with\ndiscrete and neural features respectively, the performance of mixed-feature TRF\nLMs matches the best interpolated model, and with simplified one-step training\nprocess and reduced training time.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:05:11 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 05:23:31 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Gao", "Silin", ""], ["Ou", "Zhijian", ""], ["Yang", "Wei", ""], ["Xu", "Huifang", ""]]}, {"id": "2002.05969", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Weihua Hu, Jure Leskovec", "title": "Query2box: Reasoning over Knowledge Graphs in Vector Space using Box\n  Embeddings", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex logical queries on large-scale incomplete knowledge graphs\n(KGs) is a fundamental yet challenging task. Recently, a promising approach to\nthis problem has been to embed KG entities as well as the query into a vector\nspace such that entities that answer the query are embedded close to the query.\nHowever, prior work models queries as single points in the vector space, which\nis problematic because a complex query represents a potentially large set of\nits answer entities, but it is unclear how such a set can be represented as a\nsingle point. Furthermore, prior work can only handle queries that use\nconjunctions ($\\wedge$) and existential quantifiers ($\\exists$). Handling\nqueries with logical disjunctions ($\\vee$) remains an open problem. Here we\npropose query2box, an embedding-based framework for reasoning over arbitrary\nqueries with $\\wedge$, $\\vee$, and $\\exists$ operators in massive and\nincomplete KGs. Our main insight is that queries can be embedded as boxes\n(i.e., hyper-rectangles), where a set of points inside the box corresponds to a\nset of answer entities of the query. We show that conjunctions can be naturally\nrepresented as intersections of boxes and also prove a negative result that\nhandling disjunctions would require embedding with dimension proportional to\nthe number of KG entities. However, we show that by transforming queries into a\nDisjunctive Normal Form, query2box is capable of handling arbitrary logical\nqueries with $\\wedge$, $\\vee$, $\\exists$ in a scalable manner. We demonstrate\nthe effectiveness of query2box on three large KGs and show that query2box\nachieves up to 25% relative improvement over the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:20:10 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 03:59:06 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ren", "Hongyu", ""], ["Hu", "Weihua", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.06012", "submitter": "Natalia Tomashenko", "authors": "Natalia Tomashenko, Christian Raymond, Antoine Caubriere, Renato De\n  Mori, Yannick Esteve", "title": "Dialogue history integration into end-to-end signal-to-concept spoken\n  language understanding systems", "comments": "Accepted for ICASSP 2020 (Submitted: October 21, 2019)", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9053247", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the embeddings for representing dialog history in\nspoken language understanding (SLU) systems. We focus on the scenario when the\nsemantic information is extracted directly from the speech signal by means of a\nsingle end-to-end neural network model. We proposed to integrate dialogue\nhistory into an end-to-end signal-to-concept SLU system. The dialog history is\nrepresented in the form of dialog history embedding vectors (so-called\nh-vectors) and is provided as an additional information to end-to-end SLU\nmodels in order to improve the system performance. Three following types of\nh-vectors are proposed and experimentally evaluated in this paper: (1)\nsupervised-all embeddings predicting bag-of-concepts expected in the answer of\nthe user from the last dialog system response; (2) supervised-freq embeddings\nfocusing on predicting only a selected set of semantic concept (corresponding\nto the most frequent errors in our experiments); and (3) unsupervised\nembeddings. Experiments on the MEDIA corpus for the semantic slot filling task\ndemonstrate that the proposed h-vectors improve the model performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 13:09:11 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Tomashenko", "Natalia", ""], ["Raymond", "Christian", ""], ["Caubriere", "Antoine", ""], ["De Mori", "Renato", ""], ["Esteve", "Yannick", ""]]}, {"id": "2002.06033", "submitter": "Sergey Novoselov", "authors": "Aleksei Gusev, Vladimir Volokhov, Tseren Andzhukaev, Sergey Novoselov,\n  Galina Lavrentyeva, Marina Volkova, Alice Gazizullina, Andrey Shulipa, Artem\n  Gorlanov, Anastasia Avdeeva, Artem Ivanov, Alexander Kozlov, Timur Pekhovsky,\n  Yuri Matveev", "title": "Deep Speaker Embeddings for Far-Field Speaker Recognition on Short\n  Utterances", "comments": "Submitted to Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition systems based on deep speaker embeddings have achieved\nsignificant performance in controlled conditions according to the results\nobtained for early NIST SRE (Speaker Recognition Evaluation) datasets. From the\npractical point of view, taking into account the increased interest in virtual\nassistants (such as Amazon Alexa, Google Home, AppleSiri, etc.), speaker\nverification on short utterances in uncontrolled noisy environment conditions\nis one of the most challenging and highly demanded tasks. This paper presents\napproaches aimed to achieve two goals: a) improve the quality of far-field\nspeaker verification systems in the presence of environmental noise,\nreverberation and b) reduce the system qualitydegradation for short utterances.\nFor these purposes, we considered deep neural network architectures based on\nTDNN (TimeDelay Neural Network) and ResNet (Residual Neural Network) blocks. We\nexperimented with state-of-the-art embedding extractors and their training\nprocedures. Obtained results confirm that ResNet architectures outperform the\nstandard x-vector approach in terms of speaker verification quality for both\nlong-duration and short-duration utterances. We also investigate the impact of\nspeech activity detector, different scoring models, adaptation and score\nnormalization techniques. The experimental results are presented for publicly\navailable data and verification protocols for the VoxCeleb1, VoxCeleb2, and\nVOiCES datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 13:34:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Gusev", "Aleksei", ""], ["Volokhov", "Vladimir", ""], ["Andzhukaev", "Tseren", ""], ["Novoselov", "Sergey", ""], ["Lavrentyeva", "Galina", ""], ["Volkova", "Marina", ""], ["Gazizullina", "Alice", ""], ["Shulipa", "Andrey", ""], ["Gorlanov", "Artem", ""], ["Avdeeva", "Anastasia", ""], ["Ivanov", "Artem", ""], ["Kozlov", "Alexander", ""], ["Pekhovsky", "Timur", ""], ["Matveev", "Yuri", ""]]}, {"id": "2002.06053", "submitter": "Hakime \\\"Ozt\\\"urk", "authors": "Hakime \\\"Ozt\\\"urk, Arzucan \\\"Ozg\\\"ur, Philippe Schwaller, Teodoro\n  Laino, Elif Ozkirimli", "title": "Exploring Chemical Space using Natural Language Processing Methodologies\n  for Drug Discovery", "comments": null, "journal-ref": null, "doi": "10.1016/j.drudis.2020.01.020", "report-no": null, "categories": "q-bio.BM cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based representations of chemicals and proteins can be thought of as\nunstructured languages codified by humans to describe domain-specific\nknowledge. Advances in natural language processing (NLP) methodologies in the\nprocessing of spoken languages accelerated the application of NLP to elucidate\nhidden knowledge in textual representations of these biochemical entities and\nthen use it to construct models to predict molecular properties or to design\nnovel molecules. This review outlines the impact made by these advances on drug\ndiscovery and aims to further the dialogue between medicinal chemists and\ncomputer scientists.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:02:05 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["\u00d6zt\u00fcrk", "Hakime", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["Schwaller", "Philippe", ""], ["Laino", "Teodoro", ""], ["Ozkirimli", "Elif", ""]]}, {"id": "2002.06071", "submitter": "Martin d'Hoffschmidt", "authors": "Martin d'Hoffschmidt, Wacim Belblidia, Tom Brendl\\'e, Quentin\n  Heinrich, Maxime Vidal", "title": "FQuAD: French Question Answering Dataset", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in the field of language modeling have improved\nstate-of-the-art results on many Natural Language Processing tasks. Among them,\nReading Comprehension has made significant progress over the past few years.\nHowever, most results are reported in English since labeled resources available\nin other languages, such as French, remain scarce. In the present work, we\nintroduce the French Question Answering Dataset (FQuAD). FQuAD is a French\nNative Reading Comprehension dataset of questions and answers on a set of\nWikipedia articles that consists of 25,000+ samples for the 1.0 version and\n60,000+ samples for the 1.1 version. We train a baseline model which achieves\nan F1 score of 92.2 and an exact match ratio of 82.1 on the test set. In order\nto track the progress of French Question Answering models we propose a\nleader-board and we have made the 1.0 version of our dataset freely available\nat https://illuin-tech.github.io/FQuAD-explorer/.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:23:38 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:09:17 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["d'Hoffschmidt", "Martin", ""], ["Belblidia", "Wacim", ""], ["Brendl\u00e9", "Tom", ""], ["Heinrich", "Quentin", ""], ["Vidal", "Maxime", ""]]}, {"id": "2002.06115", "submitter": "William Cohen", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "title": "Scalable Neural Methods for Reasoning With a Symbolic Knowledge Base", "comments": "Also published in ICLR2020\n  https://openreview.net/forum?id=BJlguT4YPr&noteId=BJlguT4YPr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel way of representing a symbolic knowledge base (KB) called\na sparse-matrix reified KB. This representation enables neural modules that are\nfully differentiable, faithful to the original semantics of the KB, expressive\nenough to model multi-hop inferences, and scalable enough to use with\nrealistically large KBs. The sparse-matrix reified KB can be distributed across\nmultiple GPUs, can scale to tens of millions of entities and facts, and is\norders of magnitude faster than naive sparse-matrix implementations. The\nreified KB enables very simple end-to-end architectures to obtain competitive\nperformance on several benchmarks representing two families of tasks: KB\ncompletion, and learning semantic parsers from denotations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:32:19 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Cohen", "William W.", ""], ["Sun", "Haitian", ""], ["Hofer", "R. Alex", ""], ["Siegler", "Matthew", ""]]}, {"id": "2002.06144", "submitter": "Rapha\\\"el Barman", "authors": "Rapha\\\"el Barman, Maud Ehrmann, Simon Clematide, Sofia Ares Oliveira,\n  Fr\\'ed\\'eric Kaplan", "title": "Combining Visual and Textual Features for Semantic Segmentation of\n  Historical Newspapers", "comments": null, "journal-ref": "Journal of Data Mining & Digital Humanities, HistoInformatics,\n  HistoInformatics (January 19, 2021) jdmdh:7097", "doi": "10.46298/jdmdh.6107", "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The massive amounts of digitized historical documents acquired over the last\ndecades naturally lend themselves to automatic processing and exploration.\nResearch work seeking to automatically process facsimiles and extract\ninformation thereby are multiplying with, as a first essential step, document\nlayout analysis. If the identification and categorization of segments of\ninterest in document images have seen significant progress over the last years\nthanks to deep learning techniques, many challenges remain with, among others,\nthe use of finer-grained segmentation typologies and the consideration of\ncomplex, heterogeneous documents such as historical newspapers. Besides, most\napproaches consider visual features only, ignoring textual signal. In this\ncontext, we introduce a multimodal approach for the semantic segmentation of\nhistorical newspapers that combines visual and textual features. Based on a\nseries of experiments on diachronic Swiss and Luxembourgish newspapers, we\ninvestigate, among others, the predictive power of visual and textual features\nand their capacity to generalize across time and sources. Results show\nconsistent improvement of multimodal models in comparison to a strong visual\nbaseline, as well as better robustness to high material variance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:56:18 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 11:59:18 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 07:45:29 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 16:56:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Barman", "Rapha\u00ebl", ""], ["Ehrmann", "Maud", ""], ["Clematide", "Simon", ""], ["Oliveira", "Sofia Ares", ""], ["Kaplan", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2002.06165", "submitter": "Niko Moritz", "authors": "Leda Sar{\\i}, Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Unsupervised Speaker Adaptation using Attention-based Speaker Memory for\n  End-to-End ASR", "comments": "To appear in Proc. ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised speaker adaptation method inspired by the neural\nTuring machine for end-to-end (E2E) automatic speech recognition (ASR). The\nproposed model contains a memory block that holds speaker i-vectors extracted\nfrom the training data and reads relevant i-vectors from the memory through an\nattention mechanism. The resulting memory vector (M-vector) is concatenated to\nthe acoustic features or to the hidden layer activations of an E2E neural\nnetwork model. The E2E ASR system is based on the joint connectionist temporal\nclassification and attention-based encoder-decoder architecture. M-vector and\ni-vector results are compared for inserting them at different layers of the\nencoder neural network using the WSJ and TED-LIUM2 ASR benchmarks. We show that\nM-vectors, which do not require an auxiliary speaker embedding extraction\nsystem at test time, achieve similar word error rates (WERs) compared to\ni-vectors for single speaker utterances and significantly lower WERs for\nutterances in which there are speaker changes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:31:31 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Sar\u0131", "Leda", ""], ["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2002.06170", "submitter": "Chenguang Wang", "authors": "Chenguang Wang, Zihao Ye, Aston Zhang, Zheng Zhang, Alexander J. Smola", "title": "Transformer on a Diet", "comments": "6 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has been widely used thanks to its ability to capture sequence\ninformation in an efficient way. However, recent developments, such as BERT and\nGPT-2, deliver only heavy architectures with a focus on effectiveness. In this\npaper, we explore three carefully-designed light Transformer architectures to\nfigure out whether the Transformer with less computations could produce\ncompetitive results. Experimental results on language model benchmark datasets\nhint that such trade-off is promising, and the light Transformer reduces 70%\nparameters at best, while obtains competitive perplexity compared to standard\nTransformer. The source code is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:41:58 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wang", "Chenguang", ""], ["Ye", "Zihao", ""], ["Zhang", "Aston", ""], ["Zhang", "Zheng", ""], ["Smola", "Alexander J.", ""]]}, {"id": "2002.06235", "submitter": "John Kelleher", "authors": "Magdalena Kacmajor and John D. Kelleher and Filip Klubicka and Alfredo\n  Maldonado", "title": "Semantic Relatedness and Taxonomic Word Embeddings", "comments": "7 pages 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper connects a series of papers dealing with taxonomic word\nembeddings. It begins by noting that there are different types of semantic\nrelatedness and that different lexical representations encode different forms\nof relatedness. A particularly important distinction within semantic\nrelatedness is that of thematic versus taxonomic relatedness. Next, we present\na number of experiments that analyse taxonomic embeddings that have been\ntrained on a synthetic corpus that has been generated via a random walk over a\ntaxonomy. These experiments demonstrate how the properties of the synthetic\ncorpus, such as the percentage of rare words, are affected by the shape of the\nknowledge graph the corpus is generated from. Finally, we explore the\ninteractions between the relative sizes of natural and synthetic corpora on the\nperformance of embeddings when taxonomic and thematic embeddings are combined.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:02:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kacmajor", "Magdalena", ""], ["Kelleher", "John D.", ""], ["Klubicka", "Filip", ""], ["Maldonado", "Alfredo", ""]]}, {"id": "2002.06305", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh\n  Hajishirzi, Noah Smith", "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data\n  Orders, and Early Stopping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pretrained contextual word embedding models to supervised\ndownstream tasks has become commonplace in natural language processing. This\nprocess, however, is often brittle: even with the same hyperparameter values,\ndistinct random seeds can lead to substantially different results. To better\nunderstand this phenomenon, we experiment with four datasets from the GLUE\nbenchmark, fine-tuning BERT hundreds of times on each while varying only the\nrandom seeds. We find substantial performance increases compared to previously\nreported results, and we quantify how the performance of the best-found model\nvaries as a function of the number of fine-tuning trials. Further, we examine\ntwo factors influenced by the choice of random seed: weight initialization and\ntraining data order. We find that both contribute comparably to the variance of\nout-of-sample performance, and that some weight initializations perform well\nacross all tasks explored. On small datasets, we observe that many fine-tuning\ntrials diverge part of the way through training, and we offer best practices\nfor practitioners to stop training less promising runs early. We publicly\nrelease all of our experimental data, including training and validation scores\nfor 2,100 trials, to encourage further analysis of training dynamics during\nfine-tuning.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 02:40:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dodge", "Jesse", ""], ["Ilharco", "Gabriel", ""], ["Schwartz", "Roy", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""], ["Smith", "Noah", ""]]}, {"id": "2002.06353", "submitter": "Huaishao Luo", "authors": "Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li,\n  Jason Li, Taroon Bharti, Ming Zhou", "title": "UniVL: A Unified Video and Language Pre-Training Model for Multimodal\n  Understanding and Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success of the pre-training technique for NLP and\nimage-linguistic tasks, some video-linguistic pre-training works are gradually\ndeveloped to improve video-text related downstream tasks. However, most of the\nexisting multimodal models are pre-trained for understanding tasks, leading to\na pretrain-finetune discrepancy for generation tasks. This paper proposes\nUniVL: a Unified Video and Language pre-training model for both multimodal\nunderstanding and generation. It comprises four components, including two\nsingle-modal encoders, a cross encoder, and a decoder with the Transformer\nbackbone. Five objectives, including video-text joint, conditioned masked\nlanguage model (CMLM), conditioned masked frame model (CMFM), video-text\nalignment, and language reconstruction, are designed to train each of the\ncomponents. We further develop two pre-training strategies, stage by stage\npre-training (StagedP) and enhanced video representation (EnhancedV), to make\nthe training process of the UniVL more effective. The pre-train is carried out\non a sizeable instructional video dataset HowTo100M. Experimental results\ndemonstrate that the UniVL can learn strong video-text representation and\nachieves state-of-the-art results on five downstream tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 10:03:25 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 14:21:43 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 13:27:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Luo", "Huaishao", ""], ["Ji", "Lei", ""], ["Shi", "Botian", ""], ["Huang", "Haoyang", ""], ["Duan", "Nan", ""], ["Li", "Tianrui", ""], ["Li", "Jason", ""], ["Bharti", "Taroon", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.06397", "submitter": "Wei Hu", "authors": "Ermei Cao and Difeng Wang and Jiacheng Huang and Wei Hu", "title": "Open Knowledge Enrichment for Long-tail Entities", "comments": "Accepted by the 29th International World Wide Web Conference (WWW\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) have gradually become a valuable asset for many AI\napplications. While many current KBs are quite large, they are widely\nacknowledged as incomplete, especially lacking facts of long-tail entities,\ne.g., less famous persons. Existing approaches enrich KBs mainly on completing\nmissing links or filling missing values. However, they only tackle a part of\nthe enrichment problem and lack specific considerations regarding long-tail\nentities. In this paper, we propose a full-fledged approach to knowledge\nenrichment, which predicts missing properties and infers true facts of\nlong-tail entities from the open Web. Prior knowledge from popular entities is\nleveraged to improve every enrichment step. Our experiments on the synthetic\nand real-world datasets and comparison with related work demonstrate the\nfeasibility and superiority of the approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:25:44 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:42:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Cao", "Ermei", ""], ["Wang", "Difeng", ""], ["Huang", "Jiacheng", ""], ["Hu", "Wei", ""]]}, {"id": "2002.06424", "submitter": "Phil Crone", "authors": "Phil Crone", "title": "Deeper Task-Specificity Improves Joint Entity and Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) is an effective method for learning related tasks,\nbut designing MTL models necessitates deciding which and how many parameters\nshould be task-specific, as opposed to shared between tasks. We investigate\nthis issue for the problem of jointly learning named entity recognition (NER)\nand relation extraction (RE) and propose a novel neural architecture that\nallows for deeper task-specificity than does prior work. In particular, we\nintroduce additional task-specific bidirectional RNN layers for both the NER\nand RE tasks and tune the number of shared and task-specific layers separately\nfor different datasets. We achieve state-of-the-art (SOTA) results for both\ntasks on the ADE dataset; on the CoNLL04 dataset, we achieve SOTA results on\nthe NER task and competitive results on the RE task while using an order of\nmagnitude fewer trainable parameters than the current SOTA architecture. An\nablation study confirms the importance of the additional task-specific layers\nfor achieving these results. Our work suggests that previous solutions to joint\nNER and RE undervalue task-specificity and demonstrates the importance of\ncorrectly balancing the number of shared and task-specific parameters for MTL\napproaches in general.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 18:34:52 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Crone", "Phil", ""]]}, {"id": "2002.06450", "submitter": "Manni Singh", "authors": "Manni Singh, David Weston, Mark Levene", "title": "Supervised Phrase-boundary Embeddings", "comments": "12 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new word embedding model, called SPhrase, that incorporates\nsupervised phrase information. Our method modifies traditional word embeddings\nby ensuring that all target words in a phrase have exactly the same context. We\ndemonstrate that including this information within a context window produces\nsuperior embeddings for both intrinsic evaluation tasks and downstream\nextrinsic tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 21:05:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Singh", "Manni", ""], ["Weston", "David", ""], ["Levene", "Mark", ""]]}, {"id": "2002.06484", "submitter": "Tzu-Hsiang Lin", "authors": "Tzu-Hsiang Lin, Trung Bui, Doo Soon Kim, Jean Oh", "title": "A Multimodal Dialogue System for Conversational Image Editing", "comments": "Accepted at 2nd Conversational AI Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a multimodal dialogue system for Conversational\nImage Editing. We formulate our multimodal dialogue system as a Partially\nObserved Markov Decision Process (POMDP) and trained it with Deep Q-Network\n(DQN) and a user simulator. Our evaluation shows that the DQN policy\noutperforms a rule-based baseline policy, achieving 90\\% success rate under\nhigh error rates. We also conducted a real user study and analyzed real user\nbehavior.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 01:09:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lin", "Tzu-Hsiang", ""], ["Bui", "Trung", ""], ["Kim", "Doo Soon", ""], ["Oh", "Jean", ""]]}, {"id": "2002.06525", "submitter": "Kevin Lin", "authors": "Kevin Lin, Ming-Yu Liu, Ming-Ting Sun, Jan Kautz", "title": "Learning to Generate Multiple Style Transfer Outputs for an Input\n  Sentence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer refers to the task of rephrasing a given text in a\ndifferent style. While various methods have been proposed to advance the state\nof the art, they often assume the transfer output follows a delta distribution,\nand thus their models cannot generate different style transfer results for a\ngiven input text. To address the limitation, we propose a one-to-many text\nstyle transfer framework. In contrast to prior works that learn a one-to-one\nmapping that converts an input sentence to one output sentence, our approach\nlearns a one-to-many mapping that can convert an input sentence to multiple\ndifferent output sentences, while preserving the input content. This is\nachieved by applying adversarial training with a latent decomposition scheme.\nSpecifically, we decompose the latent representation of the input sentence to a\nstyle code that captures the language style variation and a content code that\nencodes the language style-independent content. We then combine the content\ncode with the style code for generating a style transfer output. By combining\nthe same content code with a different style code, we generate a different\nstyle transfer output. Extensive experimental results with comparisons to\nseveral text style transfer approaches on multiple public datasets using a\ndiverse set of performance metrics validate effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 07:10:45 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lin", "Kevin", ""], ["Liu", "Ming-Yu", ""], ["Sun", "Ming-Ting", ""], ["Kautz", "Jan", ""]]}, {"id": "2002.06544", "submitter": "Hrituraj Singh", "authors": "Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy", "title": "Exploring Neural Models for Parsing Natural Language into First-Order\n  Logic", "comments": "11 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of obtaining machine-interpretable\nrepresentations from natural language text. We consider one such formal\nrepresentation - First-Order Logic (FOL) and explore the capability of neural\nmodels in parsing English sentences to FOL. We model FOL parsing as a sequence\nto sequence mapping task where given a natural language sentence, it is encoded\ninto an intermediate representation using an LSTM followed by a decoder which\nsequentially generates the predicates in the corresponding FOL formula. We\nimprove the standard encoder-decoder model by introducing a variable alignment\nmechanism that enables it to align variables across predicates in the predicted\nFOL. We further show the effectiveness of predicting the category of FOL entity\n- Unary, Binary, Variables and Scoped Entities, at each decoder step as an\nauxiliary task on improving the consistency of generated FOL. We perform\nrigorous evaluations and extensive ablations. We also aim to release our code\nas well as large scale FOL dataset along with models to aid further research in\nlogic-based parsing and inference in NLP.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:22:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Singh", "Hrituraj", ""], ["Aggrawal", "Milan", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2002.06546", "submitter": "Qiang Wang", "authors": "Yanyang Li, Qiang Wang, Tong Xiao, Tongran Liu, Jingbo Zhu", "title": "Neural Machine Translation with Joint Representation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though early successes of Statistical Machine Translation (SMT) systems are\nattributed in part to the explicit modelling of the interaction between any two\nsource and target units, e.g., alignment, the recent Neural Machine Translation\n(NMT) systems resort to the attention which partially encodes the interaction\nfor efficiency. In this paper, we employ Joint Representation that fully\naccounts for each possible interaction. We sidestep the inefficiency issue by\nrefining representations with the proposed efficient attention operation. The\nresulting Reformer models offer a new Sequence-to- Sequence modelling paradigm\nbesides the Encoder-Decoder framework and outperform the Transformer baseline\nin either the small scale IWSLT14 German-English, English-German and IWSLT15\nVietnamese-English or the large scale NIST12 Chinese-English translation tasks\nby about 1 BLEU point.We also propose a systematic model scaling approach,\nallowing the Reformer model to beat the state-of-the-art Transformer in IWSLT14\nGerman-English and NIST12 Chinese-English with about 50% fewer parameters. The\ncode is publicly available at https://github.com/lyy1994/reformer.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:42:01 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 01:59:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Li", "Yanyang", ""], ["Wang", "Qiang", ""], ["Xiao", "Tong", ""], ["Liu", "Tongran", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2002.06612", "submitter": "Zahra Abbasiantaeb", "authors": "Zahra Abbasiantaeb and Saeedeh Momtazi", "title": "Text-based Question Answering from Information Retrieval and Deep Neural\n  Network Perspectives: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based Question Answering (QA) is a challenging task which aims at\nfinding short concrete answers for users' questions. This line of research has\nbeen widely studied with information retrieval techniques and has received\nincreasing attention in recent years by considering deep neural network\napproaches. Deep learning approaches, which are the main focus of this paper,\nprovide a powerful technique to learn multiple layers of representations and\ninteraction between questions and texts. In this paper, we provide a\ncomprehensive overview of different models proposed for the QA task, including\nboth traditional information retrieval perspective, and more recent deep neural\nnetwork perspective. We also introduce well-known datasets for the task and\npresent available results from the literature to have a comparison between\ndifferent techniques.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:24:39 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:27:09 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Abbasiantaeb", "Zahra", ""], ["Momtazi", "Saeedeh", ""]]}, {"id": "2002.06644", "submitter": "Tanvi Dadu Miss", "authors": "Tanvi Dadu, Kartikey Pant and Radhika Mamidi", "title": "Towards Detection of Subjective Bias using Contextualized Word\n  Embeddings", "comments": "To appear in Companion Proceedings of the Web Conference 2020 (WWW\n  '20 Companion)", "journal-ref": null, "doi": "10.1145/3366424.3382704", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjective bias detection is critical for applications like propaganda\ndetection, content recommendation, sentiment analysis, and bias neutralization.\nThis bias is introduced in natural language via inflammatory words and phrases,\ncasting doubt over facts, and presupposing the truth. In this work, we perform\ncomprehensive experiments for detecting subjective bias using BERT-based models\non the Wiki Neutrality Corpus(WNC). The dataset consists of $360k$ labeled\ninstances, from Wikipedia edits that remove various instances of the bias. We\nfurther propose BERT-based ensembles that outperform state-of-the-art methods\nlike $BERT_{large}$ by a margin of $5.6$ F1 score.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 18:39:16 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dadu", "Tanvi", ""], ["Pant", "Kartikey", ""], ["Mamidi", "Radhika", ""]]}, {"id": "2002.06652", "submitter": "Bin Wang", "authors": "Bin Wang, C.-C. Jay Kuo", "title": "SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embedding is an important research topic in natural language\nprocessing (NLP) since it can transfer knowledge to downstream tasks.\nMeanwhile, a contextualized word representation, called BERT, achieves the\nstate-of-the-art performance in quite a few NLP tasks. Yet, it is an open\nproblem to generate a high quality sentence representation from BERT-based word\nmodels. It was shown in previous study that different layers of BERT capture\ndifferent linguistic properties. This allows us to fusion information across\nlayers to find better sentence representation. In this work, we study the\nlayer-wise pattern of the word representation of deep contextualized models.\nThen, we propose a new sentence embedding method by dissecting BERT-based word\nmodels through geometric analysis of the space spanned by the word\nrepresentation. It is called the SBERT-WK method. No further training is\nrequired in SBERT-WK. We evaluate SBERT-WK on semantic textual similarity and\ndownstream supervised tasks. Furthermore, ten sentence-level probing tasks are\npresented for detailed linguistic analysis. Experiments show that SBERT-WK\nachieves the state-of-the-art performance. Our codes are publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 19:02:52 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:39:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Bin", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2002.06670", "submitter": "Daniel Ranti", "authors": "Daniel Ranti, Katie Hanss, Shan Zhao, Varun Arvind, Joseph Titano,\n  Anthony Costa, Eric Oermann", "title": "The Utility of General Domain Transfer Learning for Medical Language\n  Tasks", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to analyze the efficacy of transfer learning\ntechniques and transformer-based models as applied to medical natural language\nprocessing (NLP) tasks, specifically radiological text classification. We used\n1,977 labeled head CT reports, from a corpus of 96,303 total reports, to\nevaluate the efficacy of pretraining using general domain corpora and a\ncombined general and medical domain corpus with a bidirectional representations\nfrom transformers (BERT) model for the purpose of radiological text\nclassification. Model performance was benchmarked to a logistic regression\nusing bag-of-words vectorization and a long short-term memory (LSTM)\nmulti-label multi-class classification model, and compared to the published\nliterature in medical text classification. The BERT models using either set of\npretrained checkpoints outperformed the logistic regression model, achieving\nsample-weighted average F1-scores of 0.87 and 0.87 for the general domain model\nand the combined general and biomedical-domain model. General text transfer\nlearning may be a viable technique to generate state-of-the-art results within\nmedical NLP tasks on radiological corpora, outperforming other deep models such\nas LSTMs. The efficacy of pretraining and transformer-based models could serve\nto facilitate the creation of groundbreaking NLP models in the uniquely\nchallenging data environment of medical text.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:20:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ranti", "Daniel", ""], ["Hanss", "Katie", ""], ["Zhao", "Shan", ""], ["Arvind", "Varun", ""], ["Titano", "Joseph", ""], ["Costa", "Anthony", ""], ["Oermann", "Eric", ""]]}, {"id": "2002.06675", "submitter": "Kohei Matsuura", "authors": "Kohei Matsuura, Sei Ueno, Masato Mimura, Shinsuke Sakai, Tatsuya\n  Kawahara", "title": "Speech Corpus of Ainu Folklore and End-to-end Speech Recognition for\n  Ainu Language", "comments": "Accepted in LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ainu is an unwritten language that has been spoken by Ainu people who are one\nof the ethnic groups in Japan. It is recognized as critically endangered by\nUNESCO and archiving and documentation of its language heritage is of paramount\nimportance. Although a considerable amount of voice recordings of Ainu folklore\nhas been produced and accumulated to save their culture, only a quite limited\nparts of them are transcribed so far. Thus, we started a project of automatic\nspeech recognition (ASR) for the Ainu language in order to contribute to the\ndevelopment of annotated language archives. In this paper, we report speech\ncorpus development and the structure and performance of end-to-end ASR for\nAinu. We investigated four modeling units (phone, syllable, word piece, and\nword) and found that the syllable-based model performed best in terms of both\nword and phone recognition accuracy, which were about 60% and over 85%\nrespectively in speaker-open condition. Furthermore, word and phone accuracy of\n80% and 90% has been achieved in a speaker-closed setting. We also found out\nthat a multilingual ASR training with additional speech corpora of English and\nJapanese further improves the speaker-open test accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:44:11 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:35:10 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 12:53:04 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Matsuura", "Kohei", ""], ["Ueno", "Sei", ""], ["Mimura", "Masato", ""], ["Sakai", "Shinsuke", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "2002.06701", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "Gaussian Smoothen Semantic Features (GSSF) -- Exploring the Linguistic\n  Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we have introduced Gaussian Smoothen Semantic Features (GSSF)\nfor Better Semantic Selection for Indian regional language-based image\ncaptioning and introduced a procedure where we used the existing translation\nand English crowd-sourced sentences for training. We have shown that this\narchitecture is a promising alternative source, where there is a crunch in\nresources. Our main contribution of this work is the development of deep\nlearning architectures for the Bengali language (is the fifth widely spoken\nlanguage in the world) with a completely different grammar and language\nattributes. We have shown that these are working well for complex applications\nlike language generation from image contexts and can diversify the\nrepresentation through introducing constraints, more extensive features, and\nunique feature spaces. We also established that we could achieve absolute\nprecision and diversity when we use smoothened semantic tensor with the\ntraditional LSTM and feature decomposition networks. With better learning\narchitecture, we succeeded in establishing an automated algorithm and\nassessment procedure that can help in the evaluation of competent applications\nwithout the requirement for expertise and human intervention.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:03:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2002.06714", "submitter": "Qiang Wang", "authors": "Qiang Wang, Fuxue Li, Tong Xiao, Yanyang Li, Yinqiao Li, Jingbo Zhu", "title": "Multi-layer Representation Fusion for Neural Machine Translation", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation systems require a number of stacked layers for\ndeep models. But the prediction depends on the sentence representation of the\ntop-most layer with no access to low-level representations. This makes it more\ndifficult to train the model and poses a risk of information loss to\nprediction. In this paper, we propose a multi-layer representation fusion\n(MLRF) approach to fusing stacked layers. In particular, we design three fusion\nfunctions to learn a better representation from the stack. Experimental results\nshow that our approach yields improvements of 0.92 and 0.56 BLEU points over\nthe strong Transformer baseline on IWSLT German-English and NIST\nChinese-English MT tasks respectively. The result is new state-of-the-art in\nGerman-English translation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:53:07 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Qiang", ""], ["Li", "Fuxue", ""], ["Xiao", "Tong", ""], ["Li", "Yanyang", ""], ["Li", "Yinqiao", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2002.06823", "submitter": "Yingce Xia", "authors": "Jinhua Zhu, Yingce Xia, Lijun Wu, Di He, Tao Qin, Wengang Zhou,\n  Houqiang Li and Tie-Yan Liu", "title": "Incorporating BERT into Neural Machine Translation", "comments": "Accepted to ICLR-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The recently proposed BERT has shown great power on a variety of natural\nlanguage understanding tasks, such as text classification, reading\ncomprehension, etc. However, how to effectively apply BERT to neural machine\ntranslation (NMT) lacks enough exploration. While BERT is more commonly used as\nfine-tuning instead of contextual embedding for downstream language\nunderstanding tasks, in NMT, our preliminary exploration of using BERT as\ncontextual embedding is better than using for fine-tuning. This motivates us to\nthink how to better leverage BERT for NMT along this direction. We propose a\nnew algorithm named BERT-fused model, in which we first use BERT to extract\nrepresentations for an input sequence, and then the representations are fused\nwith each layer of the encoder and decoder of the NMT model through attention\nmechanisms. We conduct experiments on supervised (including sentence-level and\ndocument-level translations), semi-supervised and unsupervised machine\ntranslation, and achieve state-of-the-art results on seven benchmark datasets.\nOur code is available at \\url{https://github.com/bert-nmt/bert-nmt}.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 08:13:36 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhu", "Jinhua", ""], ["Xia", "Yingce", ""], ["Wu", "Lijun", ""], ["He", "Di", ""], ["Qin", "Tao", ""], ["Zhou", "Wengang", ""], ["Li", "Houqiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2002.06851", "submitter": "Diego Antognini", "authors": "Diego Antognini, Boi Faltings", "title": "GameWikiSum: a Novel Large Multi-Document Summarization Dataset", "comments": "6 pages, 1 figure, 4 tables. Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's research progress in the field of multi-document summarization is\nobstructed by the small number of available datasets. Since the acquisition of\nreference summaries is costly, existing datasets contain only hundreds of\nsamples at most, resulting in heavy reliance on hand-crafted features or\nnecessitating additional, manually annotated data. The lack of large corpora\ntherefore hinders the development of sophisticated models. Additionally, most\npublicly available multi-document summarization corpora are in the news domain,\nand no analogous dataset exists in the video game domain. In this paper, we\npropose GameWikiSum, a new domain-specific dataset for multi-document\nsummarization, which is one hundred times larger than commonly used datasets,\nand in another domain than news. Input documents consist of long professional\nvideo game reviews as well as references of their gameplay sections in\nWikipedia pages. We analyze the proposed dataset and show that both abstractive\nand extractive models can be trained on it. We release GameWikiSum for further\nresearch: https://github.com/Diego999/GameWikiSum.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:25:19 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "2002.06854", "submitter": "Diego Antognini", "authors": "Diego Antognini, Boi Faltings", "title": "HotelRec: a Novel Very Large-Scale Hotel Recommendation Dataset", "comments": "7 pages, 3 figure, 5 tables. Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, recommender systems are an inevitable part of everyone's daily digital\nroutine and are present on most internet platforms. State-of-the-art deep\nlearning-based models require a large number of data to achieve their best\nperformance. Many datasets fulfilling this criterion have been proposed for\nmultiple domains, such as Amazon products, restaurants, or beers. However,\nworks and datasets in the hotel domain are limited: the largest hotel review\ndataset is below the million samples. Additionally, the hotel domain suffers\nfrom a higher data sparsity than traditional recommendation datasets and\ntherefore, traditional collaborative-filtering approaches cannot be applied to\nsuch data. In this paper, we propose HotelRec, a very large-scale hotel\nrecommendation dataset, based on TripAdvisor, containing 50 million reviews. To\nthe best of our knowledge, HotelRec is the largest publicly available dataset\nin the hotel domain (50M versus 0.9M) and additionally, the largest\nrecommendation dataset in a single domain and with textual reviews (50M versus\n22M). We release HotelRec for further research:\nhttps://github.com/Diego999/HotelRec.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:30:52 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "2002.06960", "submitter": "Gregorio Quintana-Ort\\'i", "authors": "Nathan Heavner, Per-Gunnar Martinsson, Gregorio Quintana-Ort\\'i", "title": "Computing rank-revealing factorizations of matrices stored out-of-core", "comments": "23 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CL cs.DC cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes efficient algorithms for computing rank-revealing\nfactorizations of matrices that are too large to fit in RAM, and must instead\nbe stored on slow external memory devices such as solid-state or spinning disk\nhard drives (out-of-core or out-of-memory). Traditional algorithms for\ncomputing rank revealing factorizations, such as the column pivoted QR\nfactorization, or techniques for computing a full singular value decomposition\nof a matrix, are very communication intensive. They are naturally expressed as\na sequence of matrix-vector operations, which become prohibitively expensive\nwhen data is not available in main memory. Randomization allows these methods\nto be reformulated so that large contiguous blocks of the matrix can be\nprocessed in bulk. The paper describes two distinct methods. The first is a\nblocked version of column pivoted Householder QR, organized as a \"left-looking\"\nmethod to minimize the number of write operations (which are more expensive\nthan read operations on a spinning disk drive). The second method results in a\nso called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where\n$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an\nalgorithm-by-blocks, in which floating point operations overlap read and write\noperations. The second method incorporates power iterations, and is\nexceptionally good at revealing the numerical rank; it can often be used as a\nsubstitute for a full singular value decomposition. Numerical experiments\ndemonstrate that the new algorithms are almost as fast when processing data\nstored on a hard drive as traditional algorithms are for data stored in main\nmemory. To be precise, the computational time for fully factorizing an $n\\times\nn$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only\nmarginally larger when the matrix is stored out of core.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:58:08 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 12:18:40 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Heavner", "Nathan", ""], ["Martinsson", "Per-Gunnar", ""], ["Quintana-Ort\u00ed", "Gregorio", ""]]}, {"id": "2002.07106", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Naveen Arivazhagan, Orhan Firat", "title": "Controlling Computation versus Quality for Neural Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural networks utilize the same amount of compute for every example\nindependent of the inherent complexity of the input. Further, methods that\nadapt the amount of computation to the example focus on finding a fixed\ninference-time computational graph per example, ignoring any external\ncomputational budgets or varying inference time limitations. In this work, we\nutilize conditional computation to make neural sequence models (Transformer)\nmore efficient and computation-aware during inference. We first modify the\nTransformer architecture, making each set of operations conditionally\nexecutable depending on the output of a learned control network. We then train\nthis model in a multi-task setting, where each task corresponds to a particular\ncomputation budget. This allows us to train a single model that can be\ncontrolled to operate on different points of the computation-quality trade-off\ncurve, depending on the available computation budget at inference time. We\nevaluate our approach on two tasks: (i) WMT English-French Translation and (ii)\nUnsupervised representation learning (BERT). Our experiments demonstrate that\nthe proposed Conditional Computation Transformer (CCT) is competitive with\nvanilla Transformers when allowed to utilize its full computational budget,\nwhile improving significantly over computationally equivalent baselines when\noperating on smaller computational budgets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:54:27 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 15:01:45 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bapna", "Ankur", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "2002.07306", "submitter": "Ke Tran", "authors": "Ke Tran", "title": "From English To Foreign Languages: Transferring Pre-trained Language\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained models have demonstrated their effectiveness in many downstream\nnatural language processing (NLP) tasks. The availability of multilingual\npre-trained models enables zero-shot transfer of NLP tasks from high resource\nlanguages to low resource ones. However, recent research in improving\npre-trained models focuses heavily on English. While it is possible to train\nthe latest neural architectures for other languages from scratch, it is\nundesirable due to the required amount of compute. In this work, we tackle the\nproblem of transferring an existing pre-trained model from English to other\nlanguages under a limited computational budget. With a single GPU, our approach\ncan obtain a foreign BERT base model within a day and a foreign BERT large\nwithin two days. Furthermore, evaluating our models on six languages, we\ndemonstrate that our models are better than multilingual BERT on two zero-shot\ntasks: natural language inference and dependency parsing.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:22:54 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 01:16:24 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Tran", "Ke", ""]]}, {"id": "2002.07338", "submitter": "Yujia Xie", "authors": "Yujia Xie, Tianyi Zhou, Yi Mao, Weizhu Chen", "title": "Conditional Self-Attention for Query-based Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention mechanisms have achieved great success on a variety of NLP\ntasks due to its flexibility of capturing dependency between arbitrary\npositions in a sequence. For problems such as query-based summarization (Qsumm)\nand knowledge graph reasoning where each input sequence is associated with an\nextra query, explicitly modeling such conditional contextual dependencies can\nlead to a more accurate solution, which however cannot be captured by existing\nself-attention mechanisms. In this paper, we propose \\textit{conditional\nself-attention} (CSA), a neural network module designed for conditional\ndependency modeling. CSA works by adjusting the pairwise attention between\ninput tokens in a self-attention module with the matching score of the inputs\nto the given query. Thereby, the contextual dependencies modeled by CSA will be\nhighly relevant to the query. We further studied variants of CSA defined by\ndifferent types of attention. Experiments on Debatepedia and HotpotQA benchmark\ndatasets show CSA consistently outperforms vanilla Transformer and previous\nmodels for the Qsumm problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:22:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xie", "Yujia", ""], ["Zhou", "Tianyi", ""], ["Mao", "Yi", ""], ["Chen", "Weizhu", ""]]}, {"id": "2002.07339", "submitter": "Fusataka Kuniyoshi", "authors": "Fusataka Kuniyoshi, Kohei Makino, Jun Ozawa, Makoto Miwa", "title": "Annotating and Extracting Synthesis Process of All-Solid-State Batteries\n  from Scientific Literature", "comments": "Proceedings of the 12th International Conference on Language\n  Resources and Evaluation (LREC 2020), Marseille, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synthesis process is essential for achieving computational experiment\ndesign in the field of inorganic materials chemistry. In this work, we present\na novel corpus of the synthesis process for all-solid-state batteries and an\nautomated machine reading system for extracting the synthesis processes buried\nin the scientific literature. We define the representation of the synthesis\nprocesses using flow graphs, and create a corpus from the experimental sections\nof 243 papers. The automated machine-reading system is developed by a deep\nlearning-based sequence tagger and simple heuristic rule-based relation\nextractor. Our experimental results demonstrate that the sequence tagger with\nthe optimal setting can detect the entities with a macro-averaged F1 score of\n0.826, while the rule-based relation extractor can achieve high performance\nwith a macro-averaged F1 score of 0.887.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:30:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kuniyoshi", "Fusataka", ""], ["Makino", "Kohei", ""], ["Ozawa", "Jun", ""], ["Miwa", "Makoto", ""]]}, {"id": "2002.07397", "submitter": "Kun Zhou", "authors": "Kun Zhou and Wayne Xin Zhao and Yutao Zhu and Ji-Rong Wen and Jingsong\n  Yu", "title": "Improving Multi-Turn Response Selection Models with Complementary\n  Last-Utterance Selection by Instance Weighting", "comments": "12 pages. Accepted by PAKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain retrieval-based dialogue systems require a considerable amount of\ntraining data to learn their parameters. However, in practice, the negative\nsamples of training data are usually selected from an unannotated conversation\ndata set at random. The generated training data is likely to contain noise and\naffect the performance of the response selection models. To address this\ndifficulty, we consider utilizing the underlying correlation in the data\nresource itself to derive different kinds of supervision signals and reduce the\ninfluence of noisy data. More specially, we consider a main-complementary task\npair. The main task (\\ie our focus) selects the correct response given the last\nutterance and context, and the complementary task selects the last utterance\ngiven the response and context. The key point is that the output of the\ncomplementary task is used to set instance weights for the main task. We\nconduct extensive experiments in two public datasets and obtain significant\nimprovement in both datasets. We also investigate the variant of our approach\nin multiple aspects, and the results have verified the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:29:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhou", "Kun", ""], ["Zhao", "Wayne Xin", ""], ["Zhu", "Yutao", ""], ["Wen", "Ji-Rong", ""], ["Yu", "Jingsong", ""]]}, {"id": "2002.07422", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Qiuchi Li, Lingyu Hua and Dawei Song", "title": "Assessing the Memory Ability of Recurrent Neural Networks", "comments": "Accepted by ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that Recurrent Neural Networks (RNNs) can remember, in their\nhidden layers, part of the semantic information expressed by a sequence (e.g.,\na sentence) that is being processed. Different types of recurrent units have\nbeen designed to enable RNNs to remember information over longer time spans.\nHowever, the memory abilities of different recurrent units are still\ntheoretically and empirically unclear, thus limiting the development of more\neffective and explainable RNNs. To tackle the problem, in this paper, we\nidentify and analyze the internal and external factors that affect the memory\nability of RNNs, and propose a Semantic Euclidean Space to represent the\nsemantics expressed by a sequence. Based on the Semantic Euclidean Space, a\nseries of evaluation indicators are defined to measure the memory abilities of\ndifferent recurrent units and analyze their limitations. These evaluation\nindicators also provide a useful guidance to select suitable sequence lengths\nfor different RNNs during training.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 08:07:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhang", "Cheng", ""], ["Li", "Qiuchi", ""], ["Hua", "Lingyu", ""], ["Song", "Dawei", ""]]}, {"id": "2002.07458", "submitter": "Yuze Zhao", "authors": "Yuze Zhao", "title": "A New Clustering neural network for Chinese word segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article I proposed a new model to achieve Chinese word\nsegmentation(CWS),which may have the potentiality to apply in other domains in\nthe future.It is a new thinking in CWS compared to previous works,to consider\nit as a clustering problem instead of a labeling problem.In this model,LSTM and\nself attention structures are used to collect context also sentence level\nfeatures in every layer,and after several layers,a clustering model is applied\nto split characters into groups,which are the final segmentation results.I call\nthis model CLNN.This algorithm can reach 98 percent of F score (without OOV\nwords) and 85 percent to 95 percent F score (with OOV words) in training data\nsets.Error analyses shows that OOV words will greatly reduce performances,which\nneeds a deeper research in the future.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:58:59 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhao", "Yuze", ""]]}, {"id": "2002.07510", "submitter": "Byeongchang Kim", "authors": "Byeongchang Kim, Jaewoo Ahn, Gunhee Kim", "title": "Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue", "comments": "Published in ICLR 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge-grounded dialogue is a task of generating an informative response\nbased on both discourse context and external knowledge. As we focus on better\nmodeling the knowledge selection in the multi-turn knowledge-grounded dialogue,\nwe propose a sequential latent variable model as the first approach to this\nmatter. The model named sequential knowledge transformer (SKT) can keep track\nof the prior and posterior distribution over knowledge; as a result, it can not\nonly reduce the ambiguity caused from the diversity in knowledge selection of\nconversation but also better leverage the response information for proper\nchoice of knowledge. Our experimental results show that the proposed model\nimproves the knowledge selection accuracy and subsequently the performance of\nutterance generation. We achieve the new state-of-the-art performance on Wizard\nof Wikipedia (Dinan et al., 2019) as one of the most large-scale and\nchallenging benchmarks. We further validate the effectiveness of our model over\nexisting conversation methods in another knowledge-based dialogue Holl-E\ndataset (Moghe et al., 2018).\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:59:59 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:04:57 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kim", "Byeongchang", ""], ["Ahn", "Jaewoo", ""], ["Kim", "Gunhee", ""]]}, {"id": "2002.07526", "submitter": "Shuoheng Yang", "authors": "Shuoheng Yang, Yuxin Wang, Xiaowen Chu", "title": "A Survey of Deep Learning Techniques for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, natural language processing (NLP) has got great development\nwith deep learning techniques. In the sub-field of machine translation, a new\napproach named Neural Machine Translation (NMT) has emerged and got massive\nattention from both academia and industry. However, with a significant number\nof researches proposed in the past several years, there is little work in\ninvestigating the development process of this new technology trend. This\nliterature survey traces back the origin and principal development timeline of\nNMT, investigates the important branches, categorizes different research\norientations, and discusses some future research trends in this field.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:49:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Shuoheng", ""], ["Wang", "Yuxin", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2002.07551", "submitter": "QingBiao Li", "authors": "QingBiao Li (Beijing University of Posts and Telecommunications),\n  ChunHua Wu (Beijing University of Posts and Telecommunications), KangFeng\n  Zheng (Beijing University of Posts and Telecommunications) and Zhe Wang\n  (Beijing University of Posts and Telecommunications)", "title": "Hierarchical Transformer Network for Utterance-level Emotion Recognition", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there have been significant advances in de-tecting emotions in text, in\nthe field of utter-ance-level emotion recognition (ULER), there are still many\nproblems to be solved. In this paper, we address some challenges in ULER in\ndialog sys-tems. (1) The same utterance can deliver different emotions when it\nis in different contexts or from different speakers. (2) Long-range contextual\nin-formation is hard to effectively capture. (3) Unlike the traditional text\nclassification problem, this task is supported by a limited number of datasets,\namong which most contain inadequate conversa-tions or speech. To address these\nproblems, we propose a hierarchical transformer framework (apart from the\ndescription of other studies, the \"transformer\" in this paper usually refers to\nthe encoder part of the transformer) with a lower-level transformer to model\nthe word-level input and an upper-level transformer to capture the context of\nutterance-level embeddings. We use a pretrained language model bidirectional\nencoder representa-tions from transformers (BERT) as the lower-level\ntransformer, which is equivalent to introducing external data into the model\nand solve the problem of data shortage to some extent. In addition, we add\nspeaker embeddings to the model for the first time, which enables our model to\ncapture the in-teraction between speakers. Experiments on three dialog emotion\ndatasets, Friends, EmotionPush, and EmoryNLP, demonstrate that our proposed\nhierarchical transformer network models achieve 1.98%, 2.83%, and 3.94%\nimprovement, respec-tively, over the state-of-the-art methods on each dataset\nin terms of macro-F1.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:44:49 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Li", "QingBiao", "", "Beijing University of Posts and Telecommunications"], ["Wu", "ChunHua", "", "Beijing University of Posts and Telecommunications"], ["Zheng", "KangFeng", "", "Beijing University of Posts and Telecommunications"], ["Wang", "Zhe", "", "Beijing University of Posts and Telecommunications"]]}, {"id": "2002.07563", "submitter": "Mohammad Reza Feizi Derakhshi", "authors": "Zoleikha Jahanbakhsh-Nagadeh, Mohammad-Reza Feizi-Derakhshi, Majid\n  Ramezani, Taymaz Rahkar-Farshi, Meysam Asgari-Chenaghlu, Narjes\n  Nikzad-Khasmakhi, Ali-Reza Feizi-Derakhshi, Mehrdad Ranjbar-Khadivi, Elnaz\n  Zafarani-Moattar and Mohammad-Ali Balafar", "title": "A Model to Measure the Spread Power of Rumors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, a significant portion of daily interacted posts in social media are\ninfected by rumors. This study investigates the problem of rumor analysis in\ndifferent areas from other researches. It tackles the unaddressed problem\nrelated to calculating the Spread Power of Rumor (SPR) for the first time and\nseeks to examine the spread power as the function of multi-contextual features.\nFor this purpose, the theory of Allport and Postman will be adopted. In which\nit claims that there are two key factors determinant to the spread power of\nrumors, namely importance and ambiguity. The proposed Rumor Spread Power\nMeasurement Model (RSPMM) computes SPR by utilizing a textual-based approach,\nwhich entails contextual features to compute the spread power of the rumors in\ntwo categories: False Rumor (FR) and True Rumor (TR). Totally 51 contextual\nfeatures are introduced to measure SPR and their impact on classification are\ninvestigated, then 42 features in two categories \"importance\" (28 features) and\n\"ambiguity\" (14 features) are selected to compute SPR. The proposed RSPMM is\nverified on two labelled datasets, which are collected from Twitter and\nTelegram. The results show that (i) the proposed new features are effective and\nefficient to discriminate between FRs and TRs. (ii) the proposed RSPMM approach\nfocused only on contextual features while existing techniques are based on\nStructure and Content features, but RSPMM achieves considerably outstanding\nresults (F-measure=83%). (iii) The result of T-Test shows that SPR criteria can\nsignificantly distinguish between FR and TR, besides it can be useful as a new\nmethod to verify the trueness of rumors.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:57:10 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 16:40:59 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 16:07:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Jahanbakhsh-Nagadeh", "Zoleikha", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Ramezani", "Majid", ""], ["Rahkar-Farshi", "Taymaz", ""], ["Asgari-Chenaghlu", "Meysam", ""], ["Nikzad-Khasmakhi", "Narjes", ""], ["Feizi-Derakhshi", "Ali-Reza", ""], ["Ranjbar-Khadivi", "Mehrdad", ""], ["Zafarani-Moattar", "Elnaz", ""], ["Balafar", "Mohammad-Ali", ""]]}, {"id": "2002.07591", "submitter": "QingBiao Li", "authors": "QingBiao LI (Beijing University of Posts and Telecommunications),\n  Chunhua Wu (Beijing University of Posts and Telecommunications), Kangfeng\n  Zheng (Beijing University of Posts and Telecommunications)", "title": "Text Classification with Lexicon from PreAttention Mechanism", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive and high-quality lexicon plays a crucial role in traditional\ntext classification approaches. And it improves the utilization of the\nlinguistic knowledge. Although it is helpful for the task, the lexicon has got\nlittle attention in recent neural network models. Firstly, getting a\nhigh-quality lexicon is not easy. We lack an effective automated lexicon\nextraction method, and most lexicons are hand crafted, which is very\ninefficient for big data. What's more, there is no an effective way to use a\nlexicon in a neural network. To address those limitations, we propose a\nPre-Attention mechanism for text classification in this paper, which can learn\nattention of different words according to their effects in the classification\ntasks. The words with different attention can form a domain lexicon.\nExperiments on three benchmark text classification tasks show that our models\nget competitive result comparing with the state-of-the-art methods. We get\n90.5% accuracy on Stanford Large Movie Review dataset, 82.3% on Subjectivity\ndataset, 93.7% on Movie Reviews. And compared with the text classification\nmodel without Pre-Attention mechanism, those with Pre-Attention mechanism\nimprove by 0.9%-2.4% accuracy, which proves the validity of the Pre-Attention\nmechanism. In addition, the Pre-Attention mechanism performs well followed by\ndifferent types of neural networks (e.g., convolutional neural networks and\nLong Short-Term Memory networks). For the same dataset, when we use\nPre-Attention mechanism to get attention value followed by different neural\nnetworks, those words with high attention values have a high degree of\ncoincidence, which proves the versatility and portability of the Pre-Attention\nmechanism. we can get stable lexicons by attention values, which is an\ninspiring method of information extraction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 14:40:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["LI", "QingBiao", "", "Beijing University of Posts and Telecommunications"], ["Wu", "Chunhua", "", "Beijing University of Posts and Telecommunications"], ["Zheng", "Kangfeng", "", "Beijing University of Posts and Telecommunications"]]}, {"id": "2002.07660", "submitter": "Paul Bell", "authors": "Paul C. Bell and Pavel Semukhin", "title": "Decidability of cutpoint isolation for probabilistic finite automata on\n  letter-bounded inputs", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the surprising result that the cutpoint isolation problem is\ndecidable for Probabilistic Finite Automata (PFA) where input words are taken\nfrom a letter-bounded context-free language. A context-free language\n$\\mathcal{L}$ is letter-bounded when $\\mathcal{L} \\subseteq a_1^*a_2^* \\cdots\na_\\ell^*$ for some finite $\\ell > 0$ where each letter is distinct. A cutpoint\nis isolated when it cannot be approached arbitrarily closely. The decidability\nof this problem is in marked contrast to the situation for the (strict)\nemptiness problem for PFA which is undecidable under the even more severe\nrestrictions of PFA with polynomial ambiguity, commutative matrices and input\nover a letter-bounded language as well as to the injectivity problem which is\nundecidable for PFA over letter-bounded languages. We provide a constructive\nnondeterministic algorithm to solve the cutpoint isolation problem, which holds\neven when the PFA is exponentially ambiguous. We also show that the problem is\nat least NP-hard and use our decision procedure to solve several related\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:47:14 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 09:58:42 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Bell", "Paul C.", ""], ["Semukhin", "Pavel", ""]]}, {"id": "2002.07715", "submitter": "Amin Abolghasemi", "authors": "Amin Abolghasemi, Saeedeh Momtazi", "title": "Neural Relation Prediction for Simple Question Answering over Knowledge\n  Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are widely used as a typical resource to provide answers to\nfactoid questions. In simple question answering over knowledge graphs, relation\nextraction aims to predict the relation of a factoid question from a set of\npredefined relation types. Most recent methods take advantage of neural\nnetworks to match a question with all predefined relations. In this paper, we\npropose an instance-based method to capture the underlying relation of question\nand to this aim, we detect matching paraphrases of a new question which share\nthe same relation, and their corresponding relation is selected as our\nprediction. The idea of our model roots in the fact that a relation can be\nexpressed with various forms of questions while these forms share lexically or\nsemantically similar terms and concepts. Our experiments on the SimpleQuestions\ndataset show that the proposed model achieves better accuracy compared to the\nstate-of-the-art relation extraction models.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:41:24 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 23:21:36 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 14:34:10 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abolghasemi", "Amin", ""], ["Momtazi", "Saeedeh", ""]]}, {"id": "2002.07725", "submitter": "Damian Jimenez", "authors": "Kevin Meng, Damian Jimenez, Fatma Arslan, Jacob Daniel Devasier,\n  Daniel Obembe, Chengkai Li", "title": "Gradient-Based Adversarial Training on Transformer Networks for\n  Detecting Check-Worthy Factual Claims", "comments": "11 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study on the efficacy of adversarial training on transformer\nneural network models, with respect to the task of detecting check-worthy\nclaims. In this work, we introduce the first adversarially-regularized,\ntransformer-based claim spotter model that achieves state-of-the-art results on\nmultiple challenging benchmarks. We obtain a 4.70 point F1-score improvement\nover current state-of-the-art models on the ClaimBuster Dataset and CLEF2019\nDataset, respectively. In the process, we propose a method to apply adversarial\ntraining to transformer models, which has the potential to be generalized to\nmany similar text classification tasks. Along with our results, we are\nreleasing our codebase and manually labeled datasets. We also showcase our\nmodels' real world usage via a live public API.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:51:05 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 12:33:18 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Meng", "Kevin", ""], ["Jimenez", "Damian", ""], ["Arslan", "Fatma", ""], ["Devasier", "Jacob Daniel", ""], ["Obembe", "Daniel", ""], ["Li", "Chengkai", ""]]}, {"id": "2002.07767", "submitter": "Wonjin Yoon", "authors": "Wonjin Yoon, Yoon Sun Yeo, Minbyul Jeong, Bong-Jun Yi, Jaewoo Kang", "title": "Learning by Semantic Similarity Makes Abstractive Summarization Better", "comments": "The initial version of the manuscript includes a model design\n  (semsim), experimental results, and discussions on the results. We found that\n  our model has flaws in its implementation and design. This final version of\n  the manuscript is from the rest of the initial paper; we included our\n  findings on the benchmark dataset, BART generated results and human\n  evaluations, and we excluded our model semsim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By harnessing pre-trained language models, summarization models had rapid\nprogress recently. However, the models are mainly assessed by automatic\nevaluation metrics such as ROUGE. Although ROUGE is known for having a positive\ncorrelation with human evaluation scores, it has been criticized for its\nvulnerability and the gap between actual qualities. In this paper, we compare\nthe generated summaries from recent LM, BART, and the reference summaries from\na benchmark dataset, CNN/DM, using a crowd-sourced human evaluation metric.\nInterestingly, model-generated summaries receive higher scores relative to\nreference summaries. Stemming from our experimental results, we first argue the\nintrinsic characteristics of the CNN/DM dataset, the progress of pre-trained\nlanguage models, and their ability to generalize on the training data. Finally,\nwe share our insights into the model-generated summaries and presents our\nthought on learning methods for abstractive summarization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:59:02 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 05:02:43 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Yoon", "Wonjin", ""], ["Yeo", "Yoon Sun", ""], ["Jeong", "Minbyul", ""], ["Yi", "Bong-Jun", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2002.07775", "submitter": "Jeena Kleenankandy", "authors": "Jeena Kleenankandy, K. A. Abdul Nazeer (Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India)", "title": "An enhanced Tree-LSTM architecture for sentence semantic modeling using\n  typed dependencies", "comments": "Accepted manuscript submitted to Journal of Information Processing\n  and Management ( Elsevier ) on June 11, 2020", "journal-ref": "Information Processing & Management, Elsevier (2020)", "doi": "10.1016/j.ipm.2020.102362", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based Long short term memory (LSTM) network has become state-of-the-art\nfor modeling the meaning of language texts as they can effectively exploit the\ngrammatical syntax and thereby non-linear dependencies among words of the\nsentence. However, most of these models cannot recognize the difference in\nmeaning caused by a change in semantic roles of words or phrases because they\ndo not acknowledge the type of grammatical relations, also known as typed\ndependencies, in sentence structure. This paper proposes an enhanced LSTM\narchitecture, called relation gated LSTM, which can model the relationship\nbetween two inputs of a sequence using a control input. We also introduce a\nTree-LSTM model called Typed Dependency Tree-LSTM that uses the sentence\ndependency parse structure as well as the dependency type to embed sentence\nmeaning into a dense vector. The proposed model outperformed its type-unaware\ncounterpart in two typical NLP tasks - Semantic Relatedness Scoring and\nSentiment Analysis, in a lesser number of training epochs. The results were\ncomparable or competitive with other state-of-the-art models. Qualitative\nanalysis showed that changes in the voice of sentences had little effect on the\nmodel's predicted scores, while changes in nominal (noun) words had a more\nsignificant impact. The model recognized subtle semantic relationships in\nsentence pairs. The magnitudes of learned typed dependencies embeddings were\nalso in agreement with human intuitions. The research findings imply the\nsignificance of grammatical relations in sentence modeling. The proposed models\nwould serve as a base for future researches in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:10:03 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 09:45:26 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Kleenankandy", "Jeena", "", "Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India"], ["Nazeer", "K. A. Abdul", "", "Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India"]]}, {"id": "2002.07845", "submitter": "Moniba Keymanesh", "authors": "Ritesh Sarkhel, Moniba Keymanesh, Arnab Nandi, Srinivasan\n  Parthasarathy", "title": "Interpretable Multi-Headed Attention for Abstractive Summarization at\n  Controllable Lengths", "comments": "9 pages, 5 figures", "journal-ref": "International Conference on Computational Linguistics (COLING)\n  2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization at controllable lengths is a challenging task in\nnatural language processing. It is even more challenging for domains where\nlimited training data is available or scenarios in which the length of the\nsummary is not known beforehand. At the same time, when it comes to trusting\nmachine-generated summaries, explaining how a summary was constructed in\nhuman-understandable terms may be critical. We propose Multi-level Summarizer\n(MLS), a supervised method to construct abstractive summaries of a text\ndocument at controllable lengths. The key enabler of our method is an\ninterpretable multi-headed attention mechanism that computes attention\ndistribution over an input document using an array of timestep independent\nsemantic kernels. Each kernel optimizes a human-interpretable syntactic or\nsemantic property. Exhaustive experiments on two low-resource datasets in the\nEnglish language show that MLS outperforms strong baselines by up to 14.70% in\nthe METEOR score. Human evaluation of the summaries also suggests that they\ncapture the key concepts of the document at various length-budgets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:40:20 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 21:22:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sarkhel", "Ritesh", ""], ["Keymanesh", "Moniba", ""], ["Nandi", "Arnab", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "2002.07927", "submitter": "Sashank Santhanam", "authors": "Sashank Santhanam, Alireza Karduni, Samira Shaikh", "title": "Studying the Effects of Cognitive Biases in Evaluation of Conversational\n  Agents", "comments": "Accepted at CHI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans quite frequently interact with conversational agents. The rapid\nadvancement in generative language modeling through neural networks has helped\nadvance the creation of intelligent conversational agents. Researchers\ntypically evaluate the output of their models through crowdsourced judgments,\nbut there are no established best practices for conducting such studies.\nMoreover, it is unclear if cognitive biases in decision-making are affecting\ncrowdsourced workers' judgments when they undertake these tasks. To\ninvestigate, we conducted a between-subjects study with 77 crowdsourced workers\nto understand the role of cognitive biases, specifically anchoring bias, when\nhumans are asked to evaluate the output of conversational agents. Our results\nprovide insight into how best to evaluate conversational agents. We find\nincreased consistency in ratings across two experimental conditions may be a\nresult of anchoring bias. We also determine that external factors such as time\nand prior experience in similar tasks have effects on inter-rater consistency.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 23:52:39 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 16:27:37 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Santhanam", "Sashank", ""], ["Karduni", "Alireza", ""], ["Shaikh", "Samira", ""]]}, {"id": "2002.07972", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Yu Wang, Jianshu Ji, Hao Cheng, Xueyun Zhu, Emmanuel\n  Awa, Pengcheng He, Weizhu Chen, Hoifung Poon, Guihong Cao and Jianfeng Gao", "title": "The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural\n  Language Understanding", "comments": "9 pages, 3 figures and 3 tables", "journal-ref": "ACL 2020 demo", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MT-DNN, an open-source natural language understanding (NLU)\ntoolkit that makes it easy for researchers and developers to train customized\ndeep learning models. Built upon PyTorch and Transformers, MT-DNN is designed\nto facilitate rapid customization for a broad spectrum of NLU tasks, using a\nvariety of objectives (classification, regression, structured prediction) and\ntext encoders (e.g., RNNs, BERT, RoBERTa, UniLM). A unique feature of MT-DNN is\nits built-in support for robust and transferable learning using the adversarial\nmulti-task learning paradigm. To enable efficient production deployment, MT-DNN\nsupports multi-task knowledge distillation, which can substantially compress a\ndeep neural model without significant performance drop. We demonstrate the\neffectiveness of MT-DNN on a wide range of NLU applications across general and\nbiomedical domains. The software and pre-trained models will be publicly\navailable at https://github.com/namisan/mt-dnn.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:05:28 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 21:47:31 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Liu", "Xiaodong", ""], ["Wang", "Yu", ""], ["Ji", "Jianshu", ""], ["Cheng", "Hao", ""], ["Zhu", "Xueyun", ""], ["Awa", "Emmanuel", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Poon", "Hoifung", ""], ["Cao", "Guihong", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2002.07982", "submitter": "Zaixiang Zheng", "authors": "Zaixiang Zheng, Xiang Yue, Shujian Huang, Jiajun Chen, Alexandra Birch", "title": "Towards Making the Most of Context in Neural Machine Translation", "comments": "Accepted by IJCAI'20. One-sentence summary: A general-purpose NMT\n  model that's supposed to deal with any-length text, e.g., an entire document\n  or a single sentence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level machine translation manages to outperform sentence level\nmodels by a small margin, but have failed to be widely adopted. We argue that\nprevious research did not make a clear use of the global context, and propose a\nnew document-level NMT framework that deliberately models the local context of\neach sentence with the awareness of the global context of the document in both\nsource and target languages. We specifically design the model to be able to\ndeal with documents containing any number of sentences, including single\nsentences. This unified approach allows our model to be trained elegantly on\nstandard datasets without needing to train on sentence and document level data\nseparately. Experimental results demonstrate that our model outperforms\nTransformer baselines and previous document-level NMT models with substantial\nmargins of up to 2.1 BLEU on state-of-the-art baselines. We also provide\nanalyses which show the benefit of context far beyond the neighboring two or\nthree sentences, which previous studies have typically incorporated.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:30:00 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 07:09:54 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zheng", "Zaixiang", ""], ["Yue", "Xiang", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""], ["Birch", "Alexandra", ""]]}, {"id": "2002.08024", "submitter": "Hung Le", "authors": "Hung Le, Richard Socher, Steven C.H. Hoi", "title": "Non-Autoregressive Dialog State Tracking", "comments": "Accepted at ICLR 2020. International Conference on Learning\n  Representations (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues\nhave progressed toward open-vocabulary or generation-based approaches where the\nmodels can generate slot value candidates from the dialogue history itself.\nThese approaches have shown good performance gain, especially in complicated\ndialogue domains with dynamic slot values. However, they fall short in two\naspects: (1) they do not allow models to explicitly learn signals across\ndomains and slots to detect potential dependencies among (domain, slot) pairs;\nand (2) existing models follow auto-regressive approaches which incur high time\ncost when the dialogue evolves over multiple domains and multiple turns. In\nthis paper, we propose a novel framework of Non-Autoregressive Dialog State\nTracking (NADST) which can factor in potential dependencies among domains and\nslots to optimize the models towards better prediction of dialogue states as a\ncomplete set rather than separate slots. In particular, the non-autoregressive\nnature of our method not only enables decoding in parallel to significantly\nreduce the latency of DST for real-time dialogue response generation, but also\ndetect dependencies among slots at token level in addition to slot and domain\nlevel. Our empirical results show that our model achieves the state-of-the-art\njoint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency\nof our model is an order of magnitude lower than the previous state of the art\nas the dialogue history extends over time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:39:26 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Le", "Hung", ""], ["Socher", "Richard", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2002.08046", "submitter": "Xuan Phi Nguyen", "authors": "Xuan-Phi Nguyen, Shafiq Joty, Steven C.H. Hoi, Richard Socher", "title": "Tree-structured Attention with Hierarchical Accumulation", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating hierarchical structures like constituency trees has been shown\nto be effective for various natural language processing (NLP) tasks. However,\nit is evident that state-of-the-art (SOTA) sequence-based models like the\nTransformer struggle to encode such structures inherently. On the other hand,\ndedicated models like the Tree-LSTM, while explicitly modeling hierarchical\nstructures, do not perform as efficiently as the Transformer. In this paper, we\nattempt to bridge this gap with \"Hierarchical Accumulation\" to encode parse\ntree structures into self-attention at constant time complexity. Our approach\noutperforms SOTA methods in four IWSLT translation tasks and the WMT'14\nEnglish-German translation task. It also yields improvements over Transformer\nand Tree-LSTM on three text classification tasks. We further demonstrate that\nusing hierarchical priors can compensate for data shortage, and that our model\nprefers phrase-level attentions over token-level attentions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 08:17:00 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Hoi", "Steven C. H.", ""], ["Socher", "Richard", ""]]}, {"id": "2002.08087", "submitter": "{\\L}ukasz Garncarek", "authors": "{\\L}ukasz Garncarek and Rafa{\\l} Powalski and Tomasz Stanis{\\l}awek\n  and Bartosz Topolski and Piotr Halama and Micha{\\l} Turski and Filip\n  Grali\\'nski", "title": "LAMBERT: Layout-Aware (Language) Modeling for information extraction", "comments": "accepted to ICDAR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple new approach to the problem of understanding documents\nwhere non-trivial layout influences the local semantics. To this end, we modify\nthe Transformer encoder architecture in a way that allows it to use layout\nfeatures obtained from an OCR system, without the need to re-learn language\nsemantics from scratch. We only augment the input of the model with the\ncoordinates of token bounding boxes, avoiding, in this way, the use of raw\nimages. This leads to a layout-aware language model which can then be\nfine-tuned on downstream tasks.\n  The model is evaluated on an end-to-end information extraction task using\nfour publicly available datasets: Kleister NDA, Kleister Charity, SROIE and\nCORD. We show that our model achieves superior performance on datasets\nconsisting of visually rich documents, while also outperforming the baseline\nRoBERTa on documents with flat layout (NDA \\(F_{1}\\) increase from 78.50 to\n80.42). Our solution ranked first on the public leaderboard for the Key\nInformation Extraction from the SROIE dataset, improving the SOTA\n\\(F_{1}\\)-score from 97.81 to 98.17.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:48:39 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 15:29:34 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 04:21:40 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 06:35:17 GMT"}, {"version": "v5", "created": "Fri, 28 May 2021 12:29:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Garncarek", "\u0141ukasz", ""], ["Powalski", "Rafa\u0142", ""], ["Stanis\u0142awek", "Tomasz", ""], ["Topolski", "Bartosz", ""], ["Halama", "Piotr", ""], ["Turski", "Micha\u0142", ""], ["Grali\u0144ski", "Filip", ""]]}, {"id": "2002.08126", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Ye Bai", "title": "Rnn-transducer with language bias for end-to-end Mandarin-English\n  code-switching speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, language identity information has been utilized to improve the\nperformance of end-to-end code-switching (CS) speech recognition. However,\nprevious works use an additional language identification (LID) model as an\nauxiliary module, which causes the system complex. In this work, we propose an\nimproved recurrent neural network transducer (RNN-T) model with language bias\nto alleviate the problem. We use the language identities to bias the model to\npredict the CS points. This promotes the model to learn the language identity\ninformation directly from transcription, and no additional LID model is needed.\nWe evaluate the approach on a Mandarin-English CS corpus SEAME. Compared to our\nRNN-T baseline, the proposed method can achieve 16.2% and 12.9% relative error\nreduction on two test sets, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:01:33 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Shuai", ""], ["Yi", "Jiangyan", ""], ["Tian", "Zhengkun", ""], ["Tao", "Jianhua", ""], ["Bai", "Ye", ""]]}, {"id": "2002.08131", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes and Vinit Ravishankar and Lilja {\\O}vrelid and Erik\n  Velldal", "title": "Hierarchical models vs. transfer learning for document-level sentiment\n  classification", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Documents are composed of smaller pieces - paragraphs, sentences, and tokens\n- that have complex relationships between one another. Sentiment classification\nmodels that take into account the structure inherent in these documents have a\ntheoretical advantage over those that do not. At the same time, transfer\nlearning models based on language model pretraining have shown promise for\ndocument classification. However, these two paradigms have not been\nsystematically compared and it is not clear under which circumstances one\napproach is better than the other. In this work we empirically compare\nhierarchical models and transfer learning for document-level sentiment\nclassification. We show that non-trivial hierarchical models outperform\nprevious baselines and transfer learning on document-level sentiment\nclassification in five languages.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:22:46 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Barnes", "Jeremy", ""], ["Ravishankar", "Vinit", ""], ["\u00d8vrelid", "Lilja", ""], ["Velldal", "Erik", ""]]}, {"id": "2002.08155", "submitter": "Zhangyin Feng", "authors": "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming\n  Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, Ming Zhou", "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages", "comments": "Accepted to Findings of EMNLP 2020. 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CodeBERT, a bimodal pre-trained model for programming language\n(PL) and nat-ural language (NL). CodeBERT learns general-purpose\nrepresentations that support downstream NL-PL applications such as natural\nlanguage codesearch, code documentation generation, etc. We develop CodeBERT\nwith Transformer-based neural architecture, and train it with a hybrid\nobjective function that incorporates the pre-training task of replaced token\ndetection, which is to detect plausible alternatives sampled from generators.\nThis enables us to utilize both bimodal data of NL-PL pairs and unimodal data,\nwhere the former provides input tokens for model training while the latter\nhelps to learn better generators. We evaluate CodeBERT on two NL-PL\napplications by fine-tuning model parameters. Results show that CodeBERT\nachieves state-of-the-art performance on both natural language code search and\ncode documentation generation tasks. Furthermore, to investigate what type of\nknowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and\nevaluate in a zero-shot setting where parameters of pre-trained models are\nfixed. Results show that CodeBERT performs better than previous pre-trained\nmodels on NL-PL probing.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:09:07 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 08:51:49 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 04:35:54 GMT"}, {"version": "v4", "created": "Fri, 18 Sep 2020 15:38:12 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Feng", "Zhangyin", ""], ["Guo", "Daya", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Feng", "Xiaocheng", ""], ["Gong", "Ming", ""], ["Shou", "Linjun", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.08241", "submitter": "Pui Yiu Carol Mak", "authors": "Carol Mak, Luke Ong", "title": "A Differential-form Pullback Programming Language for Higher-order\n  Reverse-mode Automatic Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Building on the observation that reverse-mode automatic differentiation (AD)\n-- a generalisation of backpropagation -- can naturally be expressed as\npullbacks of differential 1-forms, we design a simple higher-order programming\nlanguage with a first-class differential operator, and present a reduction\nstrategy which exactly simulates reverse-mode AD. We justify our reduction\nstrategy by interpreting our language in any differential $\\lambda$-category\nthat satisfies the Hahn-Banach Separation Theorem, and show that the reduction\nstrategy precisely captures reverse-mode AD in a truly higher-order setting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:38:03 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mak", "Carol", ""], ["Ong", "Luke", ""]]}, {"id": "2002.08267", "submitter": "Aman Shenoy", "authors": "Aman Shenoy and Ashish Sardana", "title": "Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection\n  and Sentiment Analysis in Conversation", "comments": "10 pages, 3 figures, 5 tables; Published in Proceedings of the Second\n  Grand Challenge and Workshop on Multimodal Language (Challenge-HML) in the\n  58th Annual Meeting of the Association for Computational Linguistics (ACL\n  2020)", "journal-ref": "Challenge-HML, ACL 2020, 19-28", "doi": "10.18653/v1/2020.challengehml-1.3", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment Analysis and Emotion Detection in conversation is key in several\nreal-world applications, with an increase in modalities available aiding a\nbetter understanding of the underlying emotions. Multi-modal Emotion Detection\nand Sentiment Analysis can be particularly useful, as applications will be able\nto use specific subsets of available modalities, as per the available data.\nCurrent systems dealing with Multi-modal functionality fail to leverage and\ncapture - the context of the conversation through all modalities, the\ndependency between the listener(s) and speaker emotional states, and the\nrelevance and relationship between the available modalities. In this paper, we\npropose an end to end RNN architecture that attempts to take into account all\nthe mentioned drawbacks. Our proposed model, at the time of writing,\nout-performs the state of the art on a benchmark dataset on a variety of\naccuracy and regression metrics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:21:00 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 04:43:19 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 20:03:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Shenoy", "Aman", ""], ["Sardana", "Ashish", ""]]}, {"id": "2002.08307", "submitter": "Mitchell Gordon", "authors": "Mitchell A. Gordon, Kevin Duh, Nicholas Andrews", "title": "Compressing BERT: Studying the Effects of Weight Pruning on Transfer\n  Learning", "comments": "Accepted to Rep4NLP 2020 Workshop at ACL 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained universal feature extractors, such as BERT for natural language\nprocessing and VGG for computer vision, have become effective methods for\nimproving deep learning models without requiring more labeled data. While\neffective, feature extractors like BERT may be prohibitively large for some\ndeployment scenarios. We explore weight pruning for BERT and ask: how does\ncompression during pre-training affect transfer learning? We find that pruning\naffects transfer learning in three broad regimes. Low levels of pruning\n(30-40%) do not affect pre-training loss or transfer to downstream tasks at\nall. Medium levels of pruning increase the pre-training loss and prevent useful\npre-training information from being transferred to downstream tasks. High\nlevels of pruning additionally prevent models from fitting downstream datasets,\nleading to further degradation. Finally, we observe that fine-tuning BERT on a\nspecific task does not improve its prunability. We conclude that BERT can be\npruned once during pre-training rather than separately for each task without\naffecting performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:40:57 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 21:58:57 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Gordon", "Mitchell A.", ""], ["Duh", "Kevin", ""], ["Andrews", "Nicholas", ""]]}, {"id": "2002.08325", "submitter": "Tejas Gokhale", "authors": "Tejas Gokhale, Pratyay Banerjee, Chitta Baral, Yezhou Yang", "title": "VQA-LOL: Visual Question Answering under the Lens of Logic", "comments": "Accepted to ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical connectives and their implications on the meaning of a natural\nlanguage sentence are a fundamental aspect of understanding. In this paper, we\ninvestigate whether visual question answering (VQA) systems trained to answer a\nquestion about an image, are able to answer the logical composition of multiple\nsuch questions. When put under this \\textit{Lens of Logic}, state-of-the-art\nVQA models have difficulty in correctly answering these logically composed\nquestions. We construct an augmentation of the VQA dataset as a benchmark, with\nquestions containing logical compositions and linguistic transformations\n(negation, disjunction, conjunction, and antonyms). We propose our {Lens of\nLogic (LOL)} model which uses question-attention and logic-attention to\nunderstand logical connectives in the question, and a novel\nFr\\'echet-Compatibility Loss, which ensures that the answers of the component\nquestions and the composed question are consistent with the inferred logical\noperation. Our model shows substantial improvement in learning logical\ncompositions while retaining performance on VQA. We suggest this work as a move\ntowards robustness by embedding logical connectives in visual understanding.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:57:46 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 22:39:12 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Gokhale", "Tejas", ""], ["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""], ["Yang", "Yezhou", ""]]}, {"id": "2002.08434", "submitter": "Vikram Shree", "authors": "Vikram Shree, Wei-Lun Chao and Mark Campbell", "title": "Interactive Natural Language-based Person Search", "comments": "8 pages, 12 figures, Published in IEEE Robotics and Automation\n  Letters (RA-L), \"Dataset at:\n  https://github.com/vikshree/QA_PersonSearchLanguageData\" , Video attachment\n  at: https://www.youtube.com/watch?v=Yyxu8uVUREE&feature=youtu.be", "journal-ref": "in IEEE Robotics and Automation Letters, vol. 5, no. 2, pp.\n  1851-1858, April 2020", "doi": "10.1109/LRA.2020.2969921", "report-no": null, "categories": "cs.RO cs.CL cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of searching people in an unconstrained\nenvironment, with natural language descriptions. Specifically, we study how to\nsystematically design an algorithm to effectively acquire descriptions from\nhumans. An algorithm is proposed by adapting models, used for visual and\nlanguage understanding, to search a person of interest (POI) in a principled\nway, achieving promising results without the need to re-design another\ncomplicated model. We then investigate an iterative question-answering (QA)\nstrategy that enable robots to request additional information about the POI's\nappearance from the user. To this end, we introduce a greedy algorithm to rank\nquestions in terms of their significance, and equip the algorithm with the\ncapability to dynamically adjust the length of human-robot interaction\naccording to model's uncertainty. Our approach is validated not only on\nbenchmark datasets but on a mobile robot, moving in a dynamic and crowded\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:42:19 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Shree", "Vikram", ""], ["Chao", "Wei-Lun", ""], ["Campbell", "Mark", ""]]}, {"id": "2002.08562", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Tim Miller", "title": "Federated pretraining and fine tuning of BERT using clinical notes from\n  multiple silos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale contextual representation models, such as BERT, have\nsignificantly advanced natural language processing (NLP) in recently years.\nHowever, in certain area like healthcare, accessing diverse large scale text\ndata from multiple institutions is extremely challenging due to privacy and\nregulatory reasons. In this article, we show that it is possible to both\npretrain and fine tune BERT models in a federated manner using clinical texts\nfrom different silos without moving the data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:14:35 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Liu", "Dianbo", ""], ["Miller", "Tim", ""]]}, {"id": "2002.08608", "submitter": "Haewoon Kwak", "authors": "Haewoon Kwak and Jisun An and Elise Jing and Yong-Yeol Ahn", "title": "FrameAxis: Characterizing Microframe Bias and Intensity with Word\n  Embedding", "comments": "24 pages; published in PeerJ CS", "journal-ref": "PeerJ Computer Science 7:e644, 2021", "doi": "10.7717/peerj-cs.644", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Framing is a process of emphasizing a certain aspect of an issue over the\nothers, nudging readers or listeners towards different positions on the issue\neven without making a biased argument. {Here, we propose FrameAxis, a method\nfor characterizing documents by identifying the most relevant semantic axes\n(\"microframes\") that are overrepresented in the text using word embedding. Our\nunsupervised approach can be readily applied to large datasets because it does\nnot require manual annotations. It can also provide nuanced insights by\nconsidering a rich set of semantic axes. FrameAxis is designed to\nquantitatively tease out two important dimensions of how microframes are used\nin the text. \\textit{Microframe bias} captures how biased the text is on a\ncertain microframe, and \\textit{microframe intensity} shows how actively a\ncertain microframe is used. Together, they offer a detailed characterization of\nthe text. We demonstrate that microframes with the highest bias and intensity\nwell align with sentiment, topic, and partisan spectrum by applying FrameAxis\nto multiple datasets from restaurant reviews to political news.} The existing\ndomain knowledge can be incorporated into FrameAxis {by using custom\nmicroframes and by using FrameAxis as an iterative exploratory analysis\ninstrument.} Additionally, we propose methods for explaining the results of\nFrameAxis at the level of individual words and documents. Our method may\naccelerate scalable and sophisticated computational analyses of framing across\ndisciplines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:01:28 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 02:21:21 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 06:47:08 GMT"}, {"version": "v4", "created": "Fri, 23 Jul 2021 01:45:20 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Kwak", "Haewoon", ""], ["An", "Jisun", ""], ["Jing", "Elise", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "2002.08614", "submitter": "Atsushi Fujita", "authors": "Raj Dabre, Raphael Rubino, Atsushi Fujita", "title": "Balancing Cost and Benefit with Tied-Multi Transformers", "comments": "Extended version of our previous manuscript available at\n  arXiv:1908.10118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose and evaluate a novel procedure for training multiple Transformers\nwith tied parameters which compresses multiple models into one enabling the\ndynamic choice of the number of encoder and decoder layers during decoding. In\nsequence-to-sequence modeling, typically, the output of the last layer of the\nN-layer encoder is fed to the M-layer decoder, and the output of the last\ndecoder layer is used to compute loss. Instead, our method computes a single\nloss consisting of NxM losses, where each loss is computed from the output of\none of the M decoder layers connected to one of the N encoder layers. Such a\nmodel subsumes NxM models with different number of encoder and decoder layers,\nand can be used for decoding with fewer than the maximum number of encoder and\ndecoder layers. We then propose a mechanism to choose a priori the number of\nencoder and decoder layers for faster decoding, and also explore recurrent\nstacking of layers and knowledge distillation for model compression. We present\na cost-benefit analysis of applying the proposed approaches for neural machine\ntranslation and show that they reduce decoding costs while preserving\ntranslation quality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:20:52 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Dabre", "Raj", ""], ["Rubino", "Raphael", ""], ["Fujita", "Atsushi", ""]]}, {"id": "2002.08795", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark O. Riedl", "title": "How To Avoid Being Eaten By a Grue: Exploration Strategies for\n  Text-Adventure Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games -- in which an agent interacts with the world through\ntextual natural language -- present us with the problem of\ncombinatorially-sized action-spaces. Most current reinforcement learning\nalgorithms are not capable of effectively handling such a large number of\npossible actions per turn. Poor sample efficiency, consequently, results in\nagents that are unable to pass bottleneck states, where they are unable to\nproceed because they do not see the right action sequence to pass the\nbottleneck enough times to be sufficiently reinforced. Building on prior work\nusing knowledge graphs in reinforcement learning, we introduce two new game\nstate exploration strategies. We compare our exploration strategies against\nstrong baselines on the classic text-adventure game, Zork1, where prior agent\nhave been unable to get past a bottleneck where the agent is eaten by a Grue.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:18:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Luo", "Zhaochen", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2002.08801", "submitter": "Pierre Colombo", "authors": "Pierre Colombo, Emile Chapuis, Matteo Manica, Emmanuel Vignon,\n  Giovanna Varni, Chloe Clavel", "title": "Guiding attention in Sequence-to-sequence models for Dialogue Act\n  prediction", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of predicting dialog acts (DA) based on conversational dialog is a\nkey component in the development of conversational agents. Accurately\npredicting DAs requires a precise modeling of both the conversation and the\nglobal tag dependencies. We leverage seq2seq approaches widely adopted in\nNeural Machine Translation (NMT) to improve the modelling of tag sequentiality.\nSeq2seq models are known to learn complex global dependencies while currently\nproposed approaches using linear conditional random fields (CRF) only model\nlocal tag dependencies. In this work, we introduce a seq2seq model tailored for\nDA classification using: a hierarchical encoder, a novel guided attention\nmechanism and beam search applied to both training and inference. Compared to\nthe state of the art our model does not require handcrafted features and is\ntrained end-to-end. Furthermore, the proposed approach achieves an unmatched\naccuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on\nMRDA.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:25:20 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:25:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Colombo", "Pierre", ""], ["Chapuis", "Emile", ""], ["Manica", "Matteo", ""], ["Vignon", "Emmanuel", ""], ["Varni", "Giovanna", ""], ["Clavel", "Chloe", ""]]}, {"id": "2002.08866", "submitter": "Jamie Kiros", "authors": "Jamie Kiros", "title": "Contextual Lensing of Universal Sentence Representations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a universal sentence encoder universal? The notion of a generic\nencoder of text appears to be at odds with the inherent contextualization and\nnon-permanence of language use in a dynamic world. However, mapping sentences\ninto generic fixed-length vectors for downstream similarity and retrieval tasks\nhas been fruitful, particularly for multilingual applications. How do we manage\nthis dilemma? In this work we propose Contextual Lensing, a methodology for\ninducing context-oriented universal sentence vectors. We break the construction\nof universal sentence vectors into a core, variable length, sentence matrix\nrepresentation equipped with an adaptable `lens' from which fixed-length\nvectors can be induced as a function of the lens context. We show that it is\npossible to focus notions of language similarity into a small number of lens\nparameters given a core universal matrix representation. For example, we\ndemonstrate the ability to encode translation similarity of sentences across\nseveral languages into a single weight matrix, even when the core encoder has\nnot seen parallel data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:06:27 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kiros", "Jamie", ""]]}, {"id": "2002.08878", "submitter": "Clement Moulin-Frier", "authors": "Cl\\'ement Moulin-Frier and Pierre-Yves Oudeyer", "title": "Multi-Agent Reinforcement Learning as a Computational Tool for Language\n  Evolution Research: Historical Context and Future Challenges", "comments": null, "journal-ref": "Challenges and Opportunities for Multi-Agent Reinforcement\n  Learning (COMARL AAAI 2020-2021), AAAI Spring Symposium Series, Stanford\n  University, Palo Alto, California, USA", "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models of emergent communication in agent populations are\ncurrently gaining interest in the machine learning community due to recent\nadvances in Multi-Agent Reinforcement Learning (MARL). Current contributions\nare however still relatively disconnected from the earlier theoretical and\ncomputational literature aiming at understanding how language might have\nemerged from a prelinguistic substance. The goal of this paper is to position\nrecent MARL contributions within the historical context of language evolution\nresearch, as well as to extract from this theoretical and computational\nbackground a few challenges for future research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:26:46 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 13:54:46 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Moulin-Frier", "Cl\u00e9ment", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2002.08880", "submitter": "Eva Hendrikx", "authors": "Eva Hendrikx (1) and Lisa Beinborn (1) ((1) University of Amsterdam)", "title": "The Fluidity of Concept Representations in Human Brain Signals", "comments": "12 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive theories of human language processing often distinguish between\nconcrete and abstract concepts. In this work, we analyze the discriminability\nof concrete and abstract concepts in fMRI data using a range of analysis\nmethods. We find that the distinction can be decoded from the signal with an\naccuracy significantly above chance, but it is not found to be a relevant\nstructuring factor in clustering and relational analyses. From our detailed\ncomparison, we obtain the impression that human concept representations are\nmore fluid than dichotomous categories can capture. We argue that fluid concept\nrepresentations lead to more realistic models of human language processing\nbecause they better capture the ambiguity and underspecification present in\nnatural language use.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:31:04 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Hendrikx", "Eva", "", "University of Amsterdam"], ["Beinborn", "Lisa", "", "University of Amsterdam"]]}, {"id": "2002.08898", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Peter Ku, Anuj Kumar Goyal, Angeliki Metallinou, Dilek\n  Hakkani-Tur", "title": "MA-DST: Multi-Attention Based Scalable Dialog State Tracking", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented dialog agents provide a natural language interface for users to\ncomplete their goal. Dialog State Tracking (DST), which is often a core\ncomponent of these systems, tracks the system's understanding of the user's\ngoal throughout the conversation. To enable accurate multi-domain DST, the\nmodel needs to encode dependencies between past utterances and slot semantics\nand understand the dialog context, including long-range cross-domain\nreferences. We introduce a novel architecture for this task to encode the\nconversation history and slot semantics more robustly by using attention\nmechanisms at multiple granularities. In particular, we use cross-attention to\nmodel relationships between the context and slots at different semantic levels\nand self-attention to resolve cross-domain coreferences. In addition, our\nproposed architecture does not rely on knowing the domain ontologies beforehand\nand can also be used in a zero-shot setting for new domains or unseen slot\nvalues. Our model improves the joint goal accuracy by 5% (absolute) in the\nfull-data setting and by up to 2% (absolute) in the zero-shot setting over the\npresent state-of-the-art on the MultiWoZ 2.1 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 05:34:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kumar", "Adarsh", ""], ["Ku", "Peter", ""], ["Goyal", "Anuj Kumar", ""], ["Metallinou", "Angeliki", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2002.08899", "submitter": "Tristan Thrush", "authors": "Tristan Thrush", "title": "Compositional Neural Machine Translation by Removing the Lexicon from\n  Syntax", "comments": "natural language processing; adversarial neural networks; machine\n  translation; aphasia; neural attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meaning of a natural language utterance is largely determined from its\nsyntax and words. Additionally, there is evidence that humans process an\nutterance by separating knowledge about the lexicon from syntax knowledge.\nTheories from semantics and neuroscience claim that complete word meanings are\nnot encoded in the representation of syntax. In this paper, we propose neural\nunits that can enforce this constraint over an LSTM encoder and decoder. We\ndemonstrate that our model achieves competitive performance across a variety of\ndomains including semantic parsing, syntactic parsing, and English to Mandarin\nChinese translation. In these cases, our model outperforms the standard LSTM\nencoder and decoder architecture on many or all of our metrics. To demonstrate\nthat our model achieves the desired separation between the lexicon and syntax,\nwe analyze its weights and explore its behavior when different neural modules\nare damaged. When damaged, we find that the model displays the knowledge\ndistortions that aphasics are evidenced to have.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:51:16 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Thrush", "Tristan", ""]]}, {"id": "2002.08901", "submitter": "Zeljko Kraljevic", "authors": "Rebecca Bendayan, Honghan Wu, Zeljko Kraljevic, Robert Stewart, Tom\n  Searle, Jaya Chaturvedi, Jayati Das-Munshi, Zina Ibrahim, Aurelie Mascio,\n  Angus Roberts, Daniel Bean, Richard Dobson", "title": "Identifying physical health comorbidities in a cohort of individuals\n  with severe mental illness: An application of SemEHR", "comments": "4 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimorbidity research in mental health services requires data from physical\nhealth conditions which is traditionally limited in mental health care\nelectronic health records. In this study, we aimed to extract data from\nphysical health conditions from clinical notes using SemEHR. Data was extracted\nfrom Clinical Record Interactive Search (CRIS) system at South London and\nMaudsley Biomedical Research Centre (SLaM BRC) and the cohort consisted of all\nindividuals who had received a primary or secondary diagnosis of severe mental\nillness between 2007 and 2018. Three pairs of annotators annotated 2403\ndocuments with an average Cohen's Kappa of 0.757. Results show that the NLP\nperformance varies across different diseases areas (F1 0.601 - 0.954)\nsuggesting that the language patterns or terminologies of different condition\ngroups entail different technical challenges to the same NLP task.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:14:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Bendayan", "Rebecca", ""], ["Wu", "Honghan", ""], ["Kraljevic", "Zeljko", ""], ["Stewart", "Robert", ""], ["Searle", "Tom", ""], ["Chaturvedi", "Jaya", ""], ["Das-Munshi", "Jayati", ""], ["Ibrahim", "Zina", ""], ["Mascio", "Aurelie", ""], ["Roberts", "Angus", ""], ["Bean", "Daniel", ""], ["Dobson", "Richard", ""]]}, {"id": "2002.08902", "submitter": "Yu Wang", "authors": "Yu Wang, Yining Sun, Zuchang Ma, Lisheng Gao, Yang Xu, Ting Sun", "title": "Application of Pre-training Models in Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is a fundamental Natural Language Processing\n(NLP) task to extract entities from unstructured data. The previous methods for\nNER were based on machine learning or deep learning. Recently, pre-training\nmodels have significantly improved performance on multiple NLP tasks. In this\npaper, firstly, we introduce the architecture and pre-training tasks of four\ncommon pre-training models: BERT, ERNIE, ERNIE2.0-tiny, and RoBERTa. Then, we\napply these pre-training models to a NER task by fine-tuning, and compare the\neffects of the different model architecture and pre-training tasks on the NER\ntask. The experiment results showed that RoBERTa achieved state-of-the-art\nresults on the MSRA-2006 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 08:18:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Yu", ""], ["Sun", "Yining", ""], ["Ma", "Zuchang", ""], ["Gao", "Lisheng", ""], ["Xu", "Yang", ""], ["Sun", "Ting", ""]]}, {"id": "2002.08909", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang", "title": "REALM: Retrieval-Augmented Language Model Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training has been shown to capture a surprising amount of\nworld knowledge, crucial for NLP tasks such as question answering. However,\nthis knowledge is stored implicitly in the parameters of a neural network,\nrequiring ever-larger networks to cover more facts.\n  To capture knowledge in a more modular and interpretable way, we augment\nlanguage model pre-training with a latent knowledge retriever, which allows the\nmodel to retrieve and attend over documents from a large corpus such as\nWikipedia, used during pre-training, fine-tuning and inference. For the first\ntime, we show how to pre-train such a knowledge retriever in an unsupervised\nmanner, using masked language modeling as the learning signal and\nbackpropagating through a retrieval step that considers millions of documents.\n  We demonstrate the effectiveness of Retrieval-Augmented Language Model\npre-training (REALM) by fine-tuning on the challenging task of Open-domain\nQuestion Answering (Open-QA). We compare against state-of-the-art models for\nboth explicit and implicit knowledge storage on three popular Open-QA\nbenchmarks, and find that we outperform all previous methods by a significant\nmargin (4-16% absolute accuracy), while also providing qualitative benefits\nsuch as interpretability and modularity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:40:59 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Guu", "Kelvin", ""], ["Lee", "Kenton", ""], ["Tung", "Zora", ""], ["Pasupat", "Panupong", ""], ["Chang", "Ming-Wei", ""]]}, {"id": "2002.08910", "submitter": "Colin Raffel", "authors": "Adam Roberts, Colin Raffel, and Noam Shazeer", "title": "How Much Knowledge Can You Pack Into the Parameters of a Language Model?", "comments": "Camera-ready version for EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been observed that neural language models trained on\nunstructured text can implicitly store and retrieve knowledge using natural\nlanguage queries. In this short paper, we measure the practical utility of this\napproach by fine-tuning pre-trained models to answer questions without access\nto any external context or knowledge. We show that this approach scales with\nmodel size and performs competitively with open-domain systems that explicitly\nretrieve answers from an external knowledge source when answering questions. To\nfacilitate reproducibility and future work, we release our code and trained\nmodels at https://goo.gle/t5-cbqa.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:55:58 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 04:54:34 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 16:04:06 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 21:26:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roberts", "Adam", ""], ["Raffel", "Colin", ""], ["Shazeer", "Noam", ""]]}, {"id": "2002.08911", "submitter": "Candace Ross", "authors": "Candace Ross, Boris Katz, Andrei Barbu", "title": "Measuring Social Biases in Grounded Vision and Language Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the notion of social biases from language embeddings to\ngrounded vision and language embeddings. Biases are present in grounded\nembeddings, and indeed seem to be equally or more significant than for\nungrounded embeddings. This is despite the fact that vision and language can\nsuffer from different biases, which one might hope could attenuate the biases\nin both. Multiple ways exist to generalize metrics measuring bias in word\nembeddings to this new setting. We introduce the space of generalizations\n(Grounded-WEAT and Grounded-SEAT) and demonstrate that three generalizations\nanswer different yet important questions about how biases, language, and vision\ninteract. These metrics are used on a new dataset, the first for grounded bias,\ncreated by augmenting extending standard linguistic bias benchmarks with 10,228\nimages from COCO, Conceptual Captions, and Google Images. Dataset construction\nis challenging because vision datasets are themselves very biased. The presence\nof these biases in systems will begin to have real-world consequences as they\nare deployed, making carefully measuring bias and then mitigating it critical\nto building a fair society.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:54:46 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ross", "Candace", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2002.08926", "submitter": "William Chan", "authors": "William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi,\n  Navdeep Jaitly", "title": "Imputer: Sequence Modelling via Imputation and Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Imputer, a neural sequence model that generates\noutput sequences iteratively via imputations. The Imputer is an iterative\ngenerative model, requiring only a constant number of generation steps\nindependent of the number of input or output tokens. The Imputer can be trained\nto approximately marginalize over all possible alignments between the input and\noutput sequences, and all possible generation orders. We present a tractable\ndynamic programming training algorithm, which yields a lower bound on the log\nmarginal likelihood. When applied to end-to-end speech recognition, the Imputer\noutperforms prior non-autoregressive models and achieves competitive results to\nautoregressive models. On LibriSpeech test-other, the Imputer achieves 11.1\nWER, outperforming CTC at 13.0 WER and seq2seq at 12.5 WER.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:21:30 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 17:32:18 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Chan", "William", ""], ["Saharia", "Chitwan", ""], ["Hinton", "Geoffrey", ""], ["Norouzi", "Mohammad", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "2002.08933", "submitter": "Neil Zeghidour", "authors": "Neil Zeghidour and David Grangier", "title": "Wavesplit: End-to-End Speech Separation by Speaker Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Wavesplit, an end-to-end source separation system. From a single\nmixture, the model infers a representation for each source and then estimates\neach source signal given the inferred representations. The model is trained to\njointly perform both tasks from the raw waveform. Wavesplit infers a set of\nsource representations via clustering, which addresses the fundamental\npermutation problem of separation. For speech separation, our sequence-wide\nspeaker representations provide a more robust separation of long, challenging\nrecordings compared to prior work. Wavesplit redefines the state-of-the-art on\nclean mixtures of 2 or 3 speakers (WSJ0-2/3mix), as well as in noisy and\nreverberated settings (WHAM/WHAMR). We also set a new benchmark on the recent\nLibriMix dataset. Finally, we show that Wavesplit is also applicable to other\ndomains, by separating fetal and maternal heart rates from a single abdominal\nelectrocardiogram.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:30:36 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 13:57:33 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zeghidour", "Neil", ""], ["Grangier", "David", ""]]}, {"id": "2002.09084", "submitter": "Jaehong Park", "authors": "Jonathan Pilault, Jaehong Park, Christopher Pal", "title": "On the impressive performance of randomly weighted encoders in\n  summarization tasks", "comments": "Accepted to ACL 2019 SRW. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the performance of untrained randomly\ninitialized encoders in a general class of sequence to sequence models and\ncompare their performance with that of fully-trained encoders on the task of\nabstractive summarization. We hypothesize that random projections of an input\ntext have enough representational power to encode the hierarchical structure of\nsentences and semantics of documents. Using a trained decoder to produce\nabstractive text summaries, we empirically demonstrate that architectures with\nuntrained randomly initialized encoders perform competitively with respect to\nthe equivalent architectures with fully-trained encoders. We further find that\nthe capacity of the encoder not only improves overall model generalization but\nalso closes the performance gap between untrained randomly initialized and\nfull-trained encoders. To our knowledge, it is the first time that general\nsequence to sequence models with attention are assessed for trained and\nrandomly projected representations on abstractive summarization.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 01:47:09 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Pilault", "Jonathan", ""], ["Park", "Jaehong", ""], ["Pal", "Christopher", ""]]}, {"id": "2002.09127", "submitter": "Eric Yuan", "authors": "Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre C\\^ot\\'e, Mikul\\'a\\v{s}\n  Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang,\n  Adam Trischler, William L. Hamilton", "title": "Learning Dynamic Belief Graphs to Generalize on Text-Based Games", "comments": "Bug fixed in Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playing text-based games requires skills in processing natural language and\nsequential decision making. Achieving human-level performance on text-based\ngames remains an open challenge, and prior research has largely relied on\nhand-crafted structured representations and heuristics. In this work, we\ninvestigate how an agent can plan and generalize in text-based games using\ngraph-structured representations learned end-to-end from raw text. We propose a\nnovel graph-aided transformer agent (GATA) that infers and updates latent\nbelief graphs during planning to enable effective action selection by capturing\nthe underlying game dynamics. GATA is trained using a combination of\nreinforcement and self-supervised learning. Our work demonstrates that the\nlearned graph-based representations help agents converge to better policies\nthan their text-only counterparts and facilitate effective generalization\nacross game configurations. Experiments on 500+ unique games from the TextWorld\nsuite show that our best agent outperforms text-based baselines by an average\nof 24.2%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:38:37 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:22:16 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 20:01:55 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 14:02:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Adhikari", "Ashutosh", ""], ["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Zelinka", "Mikul\u00e1\u0161", ""], ["Rondeau", "Marc-Antoine", ""], ["Laroche", "Romain", ""], ["Poupart", "Pascal", ""], ["Tang", "Jian", ""], ["Trischler", "Adam", ""], ["Hamilton", "William L.", ""]]}, {"id": "2002.09213", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska and Marta R. Costa-juss\\`a", "title": "Refinement of Unsupervised Cross-Lingual Word Embeddings", "comments": "Accepted at the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)", "journal-ref": null, "doi": "10.3233/FAIA200317", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cross-lingual word embeddings aim to bridge the gap between high-resource and\nlow-resource languages by allowing to learn multilingual word representations\neven without using any direct bilingual signal. The lion's share of the methods\nare projection-based approaches that map pre-trained embeddings into a shared\nlatent space. These methods are mostly based on the orthogonal transformation,\nwhich assumes language vector spaces to be isomorphic. However, this criterion\ndoes not necessarily hold, especially for morphologically-rich languages. In\nthis paper, we propose a self-supervised method to refine the alignment of\nunsupervised bilingual word embeddings. The proposed model moves vectors of\nwords and their corresponding translations closer to each other as well as\nenforces length- and center-invariance, thus allowing to better align\ncross-lingual embeddings. The experimental results demonstrate the\neffectiveness of our approach, as in most cases it outperforms state-of-the-art\nmethods in a bilingual lexicon induction task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:39:53 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2002.09247", "submitter": "Russa Biswas", "authors": "Russa Biswas, Mehwish Alam, and Harald Sack", "title": "Is Aligning Embedding Spaces a Challenging Task? A Study on\n  Heterogeneous Embedding Alignment Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Representation Learning of words and Knowledge Graphs (KG) into low\ndimensional vector spaces along with its applications to many real-world\nscenarios have recently gained momentum. In order to make use of multiple KG\nembeddings for knowledge-driven applications such as question answering, named\nentity disambiguation, knowledge graph completion, etc., alignment of different\nKG embedding spaces is necessary. In addition to multilinguality and\ndomain-specific information, different KGs pose the problem of structural\ndifferences making the alignment of the KG embeddings more challenging. This\npaper provides a theoretical analysis and comparison of the state-of-the-art\nalignment methods between two embedding spaces representing entity-entity and\nentity-word. This paper also aims at assessing the capability and short-comings\nof the existing alignment methods on the pretext of different applications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:37:12 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 15:49:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Biswas", "Russa", ""], ["Alam", "Mehwish", ""], ["Sack", "Harald", ""]]}, {"id": "2002.09253", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Tristan Karch, Nicolas Lair, Jean-Michel Dussoux,\n  Cl\\'ement Moulin-Frier, Peter Ford Dominey, Pierre-Yves Oudeyer", "title": "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven\n  Exploration", "comments": "Contains main article and supplementaries", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developmental machine learning studies how artificial agents can model the\nway children learn open-ended repertoires of skills. Such agents need to create\nand represent goals, select which ones to pursue and learn to achieve them.\nRecent approaches have considered goal spaces that were either fixed and\nhand-defined or learned using generative models of states. This limited agents\nto sample goals within the distribution of known effects. We argue that the\nability to imagine out-of-distribution goals is key to enable creative\ndiscoveries and open-ended learning. Children do so by leveraging the\ncompositionality of language as a tool to imagine descriptions of outcomes they\nnever experienced before, targeting them as goals during play. We introduce\nIMAGINE, an intrinsically motivated deep reinforcement learning architecture\nthat models this ability. Such imaginative agents, like children, benefit from\nthe guidance of a social peer who provides language descriptions. To take\nadvantage of goal imagination, agents must be able to leverage these\ndescriptions to interpret their imagined out-of-distribution goals. This\ngeneralization is made possible by modularity: a decomposition between learned\ngoal-achievement reward function and policy relying on deep sets, gated\nattention and object-centered representations. We introduce the Playground\nenvironment and study how this form of goal imagination improves generalization\nand exploration over agents lacking this capacity. In addition, we identify the\nproperties of goal imagination that enable these results and study the impacts\nof modularity and social interactions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:59:57 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 11:38:50 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 09:23:40 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 16:48:51 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Karch", "Tristan", ""], ["Lair", "Nicolas", ""], ["Dussoux", "Jean-Michel", ""], ["Moulin-Frier", "Cl\u00e9ment", ""], ["Dominey", "Peter Ford", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2002.09361", "submitter": "Wei Hu", "authors": "Jiacheng Huang and Wei Hu and Zhifeng Bao and Yuzhong Qu", "title": "Crowdsourced Collective Entity Resolution with Relational Match\n  Propagation", "comments": "Accepted by the 36th IEEE International Conference on Data\n  Engineering (ICDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) store rich yet heterogeneous entities and facts. Entity\nresolution (ER) aims to identify entities in KBs which refer to the same\nreal-world object. Recent studies have shown significant benefits of involving\nhumans in the loop of ER. They often resolve entities with pairwise similarity\nmeasures over attribute values and resort to the crowds to label uncertain\nones. However, existing methods still suffer from high labor costs and\ninsufficient labeling to some extent. In this paper, we propose a novel\napproach called crowdsourced collective ER, which leverages the relationships\nbetween entities to infer matches jointly rather than independently.\nSpecifically, it iteratively asks human workers to label picked entity pairs\nand propagates the labeling information to their neighbors in distance. During\nthis process, we address the problems of candidate entity pruning,\nprobabilistic propagation, optimal question selection and error-tolerant truth\ninference. Our experiments on real-world datasets demonstrate that, compared\nwith state-of-the-art methods, our approach achieves superior accuracy with\nmuch less labeling.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 15:33:53 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Huang", "Jiacheng", ""], ["Hu", "Wei", ""], ["Bao", "Zhifeng", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2002.09402", "submitter": "Sainbayar Sukhbaatar", "authors": "Angela Fan, Thibaut Lavril, Edouard Grave, Armand Joulin, Sainbayar\n  Sukhbaatar", "title": "Addressing Some Limitations of Transformers with Feedback Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have been successfully applied to sequential, auto-regressive\ntasks despite being feedforward networks. Unlike recurrent neural networks,\nTransformers use attention to capture temporal relations while processing input\ntokens in parallel. While this parallelization makes them computationally\nefficient, it restricts the model from fully exploiting the sequential nature\nof the input. The representation at a given layer can only access\nrepresentations from lower layers, rather than the higher level representations\nalready available. In this work, we propose the Feedback Transformer\narchitecture that exposes all previous representations to all future\nrepresentations, meaning the lowest representation of the current timestep is\nformed from the highest-level abstract representation of the past. We\ndemonstrate on a variety of benchmarks in language modeling, machine\ntranslation, and reinforcement learning that the increased representation\ncapacity can create small, shallow models with much stronger performance than\ncomparable Transformers.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:37:57 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 09:21:14 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 13:12:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fan", "Angela", ""], ["Lavril", "Thibaut", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Sukhbaatar", "Sainbayar", ""]]}, {"id": "2002.09419", "submitter": "Pierre Colombo", "authors": "Pierre Colombo, Emile Chapuis, Matteo Manica, Emmanuel Vignon,\n  Giovanna Varni, Chloe Clavel", "title": "Guider l'attention dans les modeles de sequence a sequence pour la\n  prediction des actes de dialogue", "comments": "in French", "journal-ref": "WACAI 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of predicting dialog acts (DA) based on conversational dialog is a\nkey component in the development of conversational agents. Accurately\npredicting DAs requires a precise modeling of both the conversation and the\nglobal tag dependencies. We leverage seq2seq approaches widely adopted in\nNeural Machine Translation (NMT) to improve the modelling of tag sequentiality.\nSeq2seq models are known to learn complex global dependencies while currently\nproposed approaches using linear conditional random fields (CRF) only model\nlocal tag dependencies. In this work, we introduce a seq2seq model tailored for\nDA classification using: a hierarchical encoder, a novel guided attention\nmechanism and beam search applied to both training and inference. Compared to\nthe state of the art our model does not require handcrafted features and is\ntrained end-to-end. Furthermore, the proposed approach achieves an unmatched\naccuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on\nMRDA.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:09:19 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:30:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Colombo", "Pierre", ""], ["Chapuis", "Emile", ""], ["Manica", "Matteo", ""], ["Vignon", "Emmanuel", ""], ["Varni", "Giovanna", ""], ["Clavel", "Chloe", ""]]}, {"id": "2002.09543", "submitter": "Kris Cao", "authors": "Kris Cao, Dani Yogatama", "title": "Modelling Latent Skills for Multitask Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model for multitask conditional language generation.\nOur guiding hypothesis is that a shared set of latent skills underlies many\ndisparate language generation tasks, and that explicitly modelling these skills\nin a task embedding space can help with both positive transfer across tasks and\nwith efficient adaptation to new tasks. We instantiate this task embedding\nspace as a latent variable in a latent variable sequence-to-sequence model. We\nevaluate this hypothesis by curating a series of monolingual text-to-text\nlanguage generation datasets - covering a broad range of tasks and domains -\nand comparing the performance of models both in the multitask and few-shot\nregimes. We show that our latent task variable model outperforms other\nsequence-to-sequence baselines on average across tasks in the multitask\nsetting. In the few-shot learning setting on an unseen test dataset (i.e., a\nnew task), we demonstrate that model adaptation based on inference in the\nlatent task space is more robust than standard fine-tuning based parameter\nadaptation and performs comparably in terms of overall performance. Finally, we\nexamine the latent task representations learnt by our model and show that they\ncluster tasks in a natural way.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:39:09 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cao", "Kris", ""], ["Yogatama", "Dani", ""]]}, {"id": "2002.09581", "submitter": "Yukio Ohsawa", "authors": "Yukio Ohsawa and Teruaki Hayashi", "title": "Extracting and Validating Explanatory Word Archipelagoes using Dual\n  Entropy", "comments": "7 pages, 2 figures, 2 columns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The logical connectivity of text is represented by the connectivity of words\nthat form archipelagoes. Here, each archipelago is a sequence of islands of the\noccurrences of a certain word. An island here means the local sequence of\nsentences where the word is emphasized, and an archipelago of a length\ncomparable to the target text is extracted using the co-variation of entropy A\n(the window-based entropy) on the distribution of the word's occurrences with\nthe width of each time window. Then, the logical connectivity of text is\nevaluated on entropy B (the graph-based entropy) computed on the distribution\nof sentences to connected word-clusters obtained on the co-occurrence of words.\nThe results show the parts of the target text with words forming archipelagoes\nextracted on entropy A, without learned or prepared knowledge, form an\nexplanatory part of the text that is of smaller entropy B than the parts\nextracted by the baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:35:26 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ohsawa", "Yukio", ""], ["Hayashi", "Teruaki", ""]]}, {"id": "2002.09599", "submitter": "Raul Puri", "authors": "Raul Puri, Ryan Spring, Mostofa Patwary, Mohammad Shoeybi, Bryan\n  Catanzaro", "title": "Training Question Answering Models From Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question and answer generation is a data augmentation method that aims to\nimprove question answering (QA) models given the limited amount of human\nlabeled data. However, a considerable gap remains between synthetic and\nhuman-generated question-answer pairs. This work aims to narrow this gap by\ntaking advantage of large language models and explores several factors such as\nmodel size, quality of pretrained models, scale of data synthesized, and\nalgorithmic choices. On the SQuAD1.1 question answering task, we achieve higher\naccuracy using solely synthetic questions and answers than when using the\nSQuAD1.1 training set questions alone. Removing access to real Wikipedia data,\nwe synthesize questions and answers from a synthetic corpus generated by an 8.3\nbillion parameter GPT-2 model. With no access to human supervision and only\naccess to other models, we are able to train state of the art question\nanswering networks on entirely model-generated data that achieve 88.4 Exact\nMatch (EM) and 93.9 F1 score on the SQuAD1.1 dev set. We further apply our\nmethodology to SQuAD2.0 and show a 2.8 absolute gain on EM score compared to\nprior work using synthetic data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:49:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Puri", "Raul", ""], ["Spring", "Ryan", ""], ["Patwary", "Mostofa", ""], ["Shoeybi", "Mohammad", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2002.09604", "submitter": "Jason Naradowsky", "authors": "Alexander I. Cowen-Rivers, Jason Naradowsky", "title": "Emergent Communication with World Models", "comments": "NeurIPS Workshop on Emergent Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Language World Models, a class of language-conditional\ngenerative model which interpret natural language messages by predicting latent\ncodes of future observations. This provides a visual grounding of the message,\nsimilar to an enhanced observation of the world, which may include objects\noutside of the listening agent's field-of-view. We incorporate this\n\"observation\" into a persistent memory state, and allow the listening agent's\npolicy to condition on it, akin to the relationship between memory and\ncontroller in a World Model. We show this improves effective communication and\ntask success in 2D gridworld speaker-listener navigation tasks. In addition, we\ndevelop two losses framed specifically for our model-based formulation to\npromote positive signalling and positive listening. Finally, because messages\nare interpreted in a generative model, we can visualize the model beliefs to\ngain insight into how the communication channel is utilized.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 02:34:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cowen-Rivers", "Alexander I.", ""], ["Naradowsky", "Jason", ""]]}, {"id": "2002.09616", "submitter": "Zehao Lin", "authors": "Zehao Lin, Xiaoming Kang, Guodun Li, Feng Ji, Haiqing Chen, Yin Zhang", "title": "\"Wait, I'm Still Talking!\" Predicting the Dialogue Interaction Behavior\n  Using Imagine-Then-Arbitrate Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing natural and accurate responses like human beings is the ultimate\ngoal of intelligent dialogue agents. So far, most of the past works concentrate\non selecting or generating one pertinent and fluent response according to\ncurrent query and its context. These models work on a one-to-one environment,\nmaking one response to one utterance each round. However, in real human-human\nconversations, human often sequentially sends several short messages for\nreadability instead of a long message in one turn. Thus messages will not end\nwith an explicit ending signal, which is crucial for agents to decide when to\nreply. So the first step for an intelligent dialogue agent is not replying but\ndeciding if it should reply at the moment. To address this issue, in this\npaper, we propose a novel Imagine-then-Arbitrate (ITA) neural dialogue model to\nhelp the agent decide whether to wait or to make a response directly. Our\nmethod has two imaginator modules and an arbitrator module. The two imaginators\nwill learn the agent's and user's speaking style respectively, generate\npossible utterances as the input of the arbitrator, combining with dialogue\nhistory. And the arbitrator decides whether to wait or to make a response to\nthe user directly. To verify the performance and effectiveness of our method,\nwe prepared two dialogue datasets and compared our approach with several\npopular models. Experimental results show that our model performs well on\naddressing ending prediction issue and outperforms baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:05:41 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 03:00:03 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 09:43:16 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Lin", "Zehao", ""], ["Kang", "Xiaoming", ""], ["Li", "Guodun", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhang", "Yin", ""]]}, {"id": "2002.09620", "submitter": "Bin Wang", "authors": "Bin Wang and Fenxiao Chen and Yuncheng Wang and C.-C. Jay Kuo", "title": "Efficient Sentence Embedding via Semantic Subspace Analysis", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel sentence embedding method built upon semantic subspace analysis,\ncalled semantic subspace sentence embedding (S3E), is proposed in this work.\nGiven the fact that word embeddings can capture semantic relationship while\nsemantically similar words tend to form semantic groups in a high-dimensional\nembedding space, we develop a sentence representation scheme by analyzing\nsemantic subspaces of its constituent words. Specifically, we construct a\nsentence model from two aspects. First, we represent words that lie in the same\nsemantic group using the intra-group descriptor. Second, we characterize the\ninteraction between multiple semantic groups with the inter-group descriptor.\nThe proposed S3E method is evaluated on both textual similarity tasks and\nsupervised tasks. Experimental results show that it offers comparable or better\nperformance than the state-of-the-art. The complexity of our S3E method is also\nmuch lower than other parameterized models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:12:37 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 04:49:45 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Wang", "Bin", ""], ["Chen", "Fenxiao", ""], ["Wang", "Yuncheng", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2002.09634", "submitter": "Xiaohui Song", "authors": "Xiaohui Song, Liangjun Zang, Yipeng Su, Xing Wu, Jizhong Han and\n  Songlin Hu", "title": "Data Augmentation for Copy-Mechanism in Dialogue State Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While several state-of-the-art approaches to dialogue state tracking (DST)\nhave shown promising performances on several benchmarks, there is still a\nsignificant performance gap between seen slot values (i.e., values that occur\nin both training set and test set) and unseen ones (values that occur in\ntraining set but not in test set). Recently, the copy-mechanism has been widely\nused in DST models to handle unseen slot values, which copies slot values from\nuser utterance directly. In this paper, we aim to find out the factors that\ninfluence the generalization ability of a common copy-mechanism model for DST.\nOur key observations include: 1) the copy-mechanism tends to memorize values\nrather than infer them from contexts, which is the primary reason for\nunsatisfactory generalization performance; 2) greater diversity of slot values\nin the training set increase the performance on unseen values but slightly\ndecrease the performance on seen values. Moreover, we propose a simple but\neffective algorithm of data augmentation to train copy-mechanism models, which\naugments the input dataset by copying user utterances and replacing the real\nslot values with randomly generated strings. Users could use two\nhyper-parameters to realize a trade-off between the performances on seen values\nand unseen ones, as well as a trade-off between overall performance and\ncomputational cost. Experimental results on three widely used datasets (WoZ\n2.0, DSTC2, and Multi-WoZ 2.0) show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:40:32 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Song", "Xiaohui", ""], ["Zang", "Liangjun", ""], ["Su", "Yipeng", ""], ["Wu", "Xing", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "2002.09637", "submitter": "Tianyi Ni", "authors": "Tianyi Ni", "title": "Markov Chain Monte-Carlo Phylogenetic Inference Construction in\n  Computational Historical Linguistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more languages in the world are under study nowadays, as a result,\nthe traditional way of historical linguistics study is facing some challenges.\nFor example, the linguistic comparative research among languages needs manual\nannotation, which becomes more and more impossible with the increasing amount\nof language data coming out all around the world. Although it could hardly\nreplace linguists work, the automatic computational methods have been taken\ninto consideration and it can help people reduce their workload. One of the\nmost important work in historical linguistics is word comparison from different\nlanguages and find the cognate words for them, which means people try to figure\nout if the two languages are related to each other or not. In this paper, I am\ngoing to use computational method to cluster the languages and use Markov Chain\nMonte Carlo (MCMC) method to build the language typology relationship tree\nbased on the clusters.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 06:01:52 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 02:03:54 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ni", "Tianyi", ""]]}, {"id": "2002.09646", "submitter": "Jason Naradowsky", "authors": "Jason Naradowsky, Xuan Zhang, Kevin Duh", "title": "Machine Translation System Selection from Bandit Feedback", "comments": "Accepted to AMTA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapting machine translation systems in the real world is a difficult\nproblem. In contrast to offline training, users cannot provide the type of\nfine-grained feedback (such as correct translations) typically used for\nimproving the system. Moreover, different users have different translation\nneeds, and even a single user's needs may change over time.\n  In this work we take a different approach, treating the problem of adaptation\nas one of selection. Instead of adapting a single system, we train many\ntranslation systems using different architectures, datasets, and optimization\nmethods. Using bandit learning techniques on simulated user feedback, we learn\na policy to choose which system to use for a particular translation task. We\nshow that our approach can (1) quickly adapt to address domain changes in\ntranslation tasks, (2) outperform the single best system in mixed-domain\ntranslation tasks, and (3) make effective instance-specific decisions when\nusing contextual bandit strategies.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 06:54:04 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 04:14:07 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Naradowsky", "Jason", ""], ["Zhang", "Xuan", ""], ["Duh", "Kevin", ""]]}, {"id": "2002.09673", "submitter": "Zongxi Li", "authors": "Xianming Li, Zongxi Li, Yingbin Zhao, Haoran Xie, Qing Li", "title": "Incorporating Effective Global Information via Adaptive Gate Attention\n  for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant text classification studies focus on training classifiers using\ntextual instances only or introducing external knowledge (e.g., hand-craft\nfeatures and domain expert knowledge). In contrast, some corpus-level\nstatistical features, like word frequency and distribution, are not well\nexploited. Our work shows that such simple statistical information can enhance\nclassification performance both efficiently and significantly compared with\nseveral baseline models. In this paper, we propose a classifier with gate\nmechanism named Adaptive Gate Attention model with Global Information (AGA+GI),\nin which the adaptive gate mechanism incorporates global statistical features\ninto latent semantic features and the attention layer captures dependency\nrelationship within the sentence. To alleviate the overfitting issue, we\npropose a novel Leaky Dropout mechanism to improve generalization ability and\nperformance stability. Our experiments show that the proposed method can\nachieve better accuracy than CNN-based and RNN-based approaches without global\ninformation on several benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:06:37 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Xianming", ""], ["Li", "Zongxi", ""], ["Zhao", "Yingbin", ""], ["Xie", "Haoran", ""], ["Li", "Qing", ""]]}, {"id": "2002.09685", "submitter": "Xuefeng Bai", "authors": "Xuefeng Bai, Pengbo Liu and Yue Zhang", "title": "Investigating Typed Syntactic Dependencies for Targeted Sentiment\n  Classification Using Graph Attention Neural Network", "comments": "Accepted by IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing (TASLP). See https://doi.org/10.1109/TASLP.2020.3042009 for final\n  version", "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing\n  (TASLP),2020", "doi": "10.1109/TASLP.2020.3042009", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeted sentiment classification predicts the sentiment polarity on given\ntarget mentions in input texts. Dominant methods employ neural networks for\nencoding the input sentence and extracting relations between target mentions\nand their contexts. Recently, graph neural network has been investigated for\nintegrating dependency syntax for the task, achieving the state-of-the-art\nresults. However, existing methods do not consider dependency label\ninformation, which can be intuitively useful. To solve the problem, we\ninvestigate a novel relational graph attention network that integrates typed\nsyntactic dependency information. Results on standard benchmarks show that our\nmethod can effectively leverage label information for improving targeted\nsentiment classification performances. Our final model significantly\noutperforms state-of-the-art syntax-based approaches.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 11:17:16 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 09:27:16 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 05:29:47 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bai", "Xuefeng", ""], ["Liu", "Pengbo", ""], ["Zhang", "Yue", ""]]}, {"id": "2002.09758", "submitter": "Ethan Perez", "authors": "Ethan Perez, Patrick Lewis, Wen-tau Yih, Kyunghyun Cho, Douwe Kiela", "title": "Unsupervised Question Decomposition for Question Answering", "comments": "EMNLP 2020 Camera-Ready. Code available at\n  https://github.com/facebookresearch/UnsupervisedDecomposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to improve question answering (QA) by decomposing hard questions into\nsimpler sub-questions that existing QA systems are capable of answering. Since\nlabeling questions with decompositions is cumbersome, we take an unsupervised\napproach to produce sub-questions, also enabling us to leverage millions of\nquestions from the internet. Specifically, we propose an algorithm for One-to-N\nUnsupervised Sequence transduction (ONUS) that learns to map one hard,\nmulti-hop question to many simpler, single-hop sub-questions. We answer\nsub-questions with an off-the-shelf QA model and give the resulting answers to\na recomposition model that combines them into a final answer. We show large QA\nimprovements on HotpotQA over a strong baseline on the original, out-of-domain,\nand multi-hop dev sets. ONUS automatically learns to decompose different kinds\nof questions, while matching the utility of supervised and heuristic\ndecomposition methods for QA and exceeding those methods in fluency.\nQualitatively, we find that using sub-questions is promising for shedding light\non why a QA system makes a prediction.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 19:40:35 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 18:49:59 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 18:47:48 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Perez", "Ethan", ""], ["Lewis", "Patrick", ""], ["Yih", "Wen-tau", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "2002.09812", "submitter": "Xin Yang", "authors": "Yingyu Liang, Zhao Song, Mengdi Wang, Lin F. Yang, Xin Yang", "title": "Sketching Transformed Matrices with Applications to Natural Language\n  Processing", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in\nmemory but is in a disk or is presented in a data stream. However, we need to\ncompute a matrix decomposition of the entry-wisely transformed matrix,\n$f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space\nefficient way? Many machine learning applications indeed need to deal with such\nlarge transformed matrices, for example word embedding method in NLP needs to\nwork with the pointwise mutual information (PMI) matrix, while the entrywise\ntransformation makes it difficult to apply known linear algebraic tools.\nExisting approaches for this problem either need to store the whole matrix and\nperform the entry-wise transformation afterwards, which is space consuming or\ninfeasible, or need to redesign the learning method, which is application\nspecific and requires substantial remodeling.\n  In this paper, we first propose a space-efficient sketching algorithm for\ncomputing the product of a given small matrix with the transformed matrix. It\nworks for a general family of transformations with provable small error bounds\nand thus can be used as a primitive in downstream learning tasks. We then apply\nthis primitive to a concrete application: low-rank approximation. We show that\nour approach obtains small error and is efficient in both space and time. We\ncomplement our theoretical results with experiments on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:07:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Liang", "Yingyu", ""], ["Song", "Zhao", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""], ["Yang", "Xin", ""]]}, {"id": "2002.09836", "submitter": "Oleg Vasilyev", "authors": "Oleg Vasilyev, Vedant Dharnidharka, John Bohannon", "title": "Fill in the BLANC: Human-free quality estimation of document summaries", "comments": "10 pages, 9 figures, 3 tables. In: Proceedings of the First Workshop\n  on Evaluation and Comparison of NLP Systems (Eval4NLP, Nov. 2020) p.11-20,\n  ACL", "journal-ref": "Proceedings of the First Workshop on Evaluation and Comparison of\n  NLP Systems (Nov.2020) 11-20", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BLANC, a new approach to the automatic estimation of document\nsummary quality. Our goal is to measure the functional performance of a summary\nwith an objective, reproducible, and fully automated method. Our approach\nachieves this by measuring the performance boost gained by a pre-trained\nlanguage model with access to a document summary while carrying out its\nlanguage understanding task on the document's text. We present evidence that\nBLANC scores have as good correlation with human evaluations as do the ROUGE\nfamily of summary quality measurements. And unlike ROUGE, the BLANC method does\nnot require human-written reference summaries, allowing for fully human-free\nsummary quality estimation.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:21:43 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 20:09:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Vasilyev", "Oleg", ""], ["Dharnidharka", "Vedant", ""], ["Bohannon", "John", ""]]}, {"id": "2002.09877", "submitter": "Sarai Sheinvald", "authors": "Borzoo Bonakdarpour and Sarai Sheinvald", "title": "Automata for Hyperlanguages", "comments": "12 pages of main paper and another 10 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperproperties lift conventional trace properties from a set of execution\ntraces to a set of sets of execution traces. Hyperproperties have been shown to\nbe a powerful formalism for expressing and reasoning about information-flow\nsecurity policies and important properties of cyber-physical systems such as\nsensitivity and robustness, as well as consistency conditions in distributed\ncomputing such as linearizability. Although there is an extensive body of work\non automata-based representation of trace properties, we currently lack such\ncharacterization for hyperproperties. We introduce hyperautomata for em\nhyperlanguages, which are languages over sets of words. Essentially,\nhyperautomata allow running multiple quantified words over an automaton. We\npropose a specific type of hyperautomata called nondeterministic finite\nhyperautomata (NFH), which accept regular hyperlanguages. We demonstrate the\nability of regular hyperlanguages to express hyperproperties for finite traces.\nWe then explore the fundamental properties of NFH and show their closure under\nthe Boolean operations. We show that while nonemptiness is undecidable in\ngeneral, it is decidable for several fragments of NFH. We further show the\ndecidability of the membership problem for finite sets and regular languages\nfor NFH, as well as the containment problem for several fragments of NFH.\nFinally, we introduce learning algorithms based on Angluin's L-star algorithm\nfor the fragments NFH in which the quantification is either strictly universal\nor strictly existential.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:52:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Bonakdarpour", "Borzoo", ""], ["Sheinvald", "Sarai", ""]]}, {"id": "2002.09901", "submitter": "Pravesh Koirala", "authors": "Pravesh Koirala and Aman Shakya", "title": "A Nepali Rule Based Stemmer and its performance on different NLP\n  applications", "comments": "5 pages, 2 figures, 3 tables", "journal-ref": "Proceedings of the 4th International IT Conference on ICT with\n  Smart Computing and 9th National Students' Conference on Information\n  Technology, (NaSCoIT 2018), Kathmandu, Nepal, ISSN No 2505-1075, pp. 16\n  (December 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stemming is an integral part of Natural Language Processing (NLP). It's a\npreprocessing step in almost every NLP application. Arguably, the most\nimportant usage of stemming is in Information Retrieval (IR). While there are\nlots of work done on stemming in languages like English, Nepali stemming has\nonly a few works. This study focuses on creating a Rule Based stemmer for\nNepali text. Specifically, it is an affix stripping system that identifies two\ndifferent class of suffixes in Nepali grammar and strips them separately. Only\na single negativity prefix (Na) is identified and stripped. This study focuses\non a number of techniques like exception word identification, morphological\nnormalization and word transformation to increase stemming performance. The\nstemmer is tested intrinsically using Paice's method and extrinsically on a\nbasic tf-idf based IR system and an elementary news topic classifier using\nMultinomial Naive Bayes Classifier. The difference in performance of these\nsystems with and without using the stemmer is analysed.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 13:33:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Koirala", "Pravesh", ""], ["Shakya", "Aman", ""]]}, {"id": "2002.09919", "submitter": "Yixuan Tang", "authors": "Yixuan Tang, Hwee Tou Ng, Anthony K.H. Tung", "title": "Do Multi-Hop Question Answering Systems Know How to Answer the\n  Single-Hop Sub-Questions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop question answering (QA) requires a model to retrieve and integrate\ninformation from different parts of a long text to answer a question. Humans\nanswer this kind of complex questions via a divide-and-conquer approach. In\nthis paper, we investigate whether top-performing models for multi-hop\nquestions understand the underlying sub-questions like humans. We adopt a\nneural decomposition model to generate sub-questions for a multi-hop complex\nquestion, followed by extracting the corresponding sub-answers. We show that\nmultiple state-of-the-art multi-hop QA models fail to correctly answer a large\nportion of sub-questions, although their corresponding multi-hop questions are\ncorrectly answered. This indicates that these models manage to answer the\nmulti-hop questions using some partial clues, instead of truly understanding\nthe reasoning paths. We also propose a new model which significantly improves\nthe performance on answering the sub-questions. Our work takes a step forward\ntowards building a more explainable multi-hop QA system.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:16:43 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 04:18:57 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Tang", "Yixuan", ""], ["Ng", "Hwee Tou", ""], ["Tung", "Anthony K. H.", ""]]}, {"id": "2002.10016", "submitter": "Hadi Abdi Khojasteh", "authors": "Hadi Abdi Khojasteh (1), Ebrahim Ansari (1 and 2), Parvin Razzaghi (1\n  and 3), Akbar Karimi (4) ((1) Institute for Advanced Studies in Basic\n  Sciences (IASBS), Zanjan, Iran, (2) Faculty of Mathematics and Physics,\n  Institute of Formal and Applied Linguistics, Charles University, Czechia, (3)\n  Institute for Research in Fundamental Sciences (IPM), Tehran, Iran, (4) IMP\n  Lab, Department of Engineering and Architecture, University of Parma, Parma,\n  Italy)", "title": "Deep Multimodal Image-Text Embeddings for Automatic Cross-Media\n  Retrieval", "comments": "6 pages and 2 figures, Learn more about this project at\n  https://iasbs.ac.ir/~ansari/deeptwitter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the task of matching images and sentences by learning a\nvisual-textual embedding space for cross-modal retrieval. Finding such a space\nis a challenging task since the features and representations of text and image\nare not comparable. In this work, we introduce an end-to-end deep multimodal\nconvolutional-recurrent network for learning both vision and language\nrepresentations simultaneously to infer image-text similarity. The model learns\nwhich pairs are a match (positive) and which ones are a mismatch (negative)\nusing a hinge-based triplet ranking. To learn about the joint representations,\nwe leverage our newly extracted collection of tweets from Twitter. The main\ncharacteristic of our dataset is that the images and tweets are not\nstandardized the same as the benchmarks. Furthermore, there can be a higher\nsemantic correlation between the pictures and tweets contrary to benchmarks in\nwhich the descriptions are well-organized. Experimental results on MS-COCO\nbenchmark dataset show that our model outperforms certain methods presented\npreviously and has competitive performance compared to the state-of-the-art.\nThe code and dataset have been made available publicly.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 23:58:04 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Khojasteh", "Hadi Abdi", "", "1 and 2"], ["Ansari", "Ebrahim", "", "1 and 2"], ["Razzaghi", "Parvin", "", "1\n  and 3"], ["Karimi", "Akbar", ""]]}, {"id": "2002.10096", "submitter": "Marian D\\\"ork", "authors": "Philipp Geuder, Marie Claire Leidinger, Martin von Lupin, Marian\n  D\\\"ork, Tobias Schr\\\"oder", "title": "Emosaic: Visualizing Affective Content of Text at Varying Granularity", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Emosaic, a tool for visualizing the emotional tone of\ntext documents, considering multiple dimensions of emotion and varying levels\nof semantic granularity. Emosaic is grounded in psychological research on the\nrelationship between language, affect, and color perception. We capitalize on\nan established three-dimensional model of human emotion: valence (good, nice\nvs. bad, awful), arousal (calm, passive vs. exciting, active) and dominance\n(weak, controlled vs. strong, in control). Previously, multi-dimensional models\nof emotion have been used rarely in visualizations of textual data, due to the\nperceptual challenges involved. Furthermore, until recently most text\nvisualizations remained at a high level, precluding closer engagement with the\ndeep semantic content of the text. Informed by empirical studies, we introduce\na color mapping that translates any point in three-dimensional affective space\ninto a unique color. Emosaic uses affective dictionaries of words annotated\nwith the three emotional parameters of the valence-arousal-dominance model to\nextract emotional meanings from texts and then assigns to them corresponding\ncolor parameters of the hue-saturation-brightness color space. This approach of\nmapping emotion to color is aimed at helping readers to more easily grasp the\nemotional tone of the text. Several features of Emosaic allow readers to\ninteractively explore the affective content of the text in more detail; e.g.,\nin aggregated form as histograms, in sequential form following the order of\ntext, and in detail embedded into the text display itself. Interaction\ntechniques have been included to allow for filtering and navigating of text and\nvisualizations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:25:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Geuder", "Philipp", ""], ["Leidinger", "Marie Claire", ""], ["von Lupin", "Martin", ""], ["D\u00f6rk", "Marian", ""], ["Schr\u00f6der", "Tobias", ""]]}, {"id": "2002.10101", "submitter": "Rongxiang Weng", "authors": "Rongxiang Weng, Haoran Wei, Shujian Huang, Heng Yu, Lidong Bing,\n  Weihua Luo, Jiajun Chen", "title": "GRET: Global Representation Enhanced Transformer", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer, based on the encoder-decoder framework, has achieved\nstate-of-the-art performance on several natural language generation tasks. The\nencoder maps the words in the input sentence into a sequence of hidden states,\nwhich are then fed into the decoder to generate the output sentence. These\nhidden states usually correspond to the input words and focus on capturing\nlocal information. However, the global (sentence level) information is seldom\nexplored, leaving room for the improvement of generation quality. In this\npaper, we propose a novel global representation enhanced Transformer (GRET) to\nexplicitly model global representation in the Transformer network.\nSpecifically, in the proposed model, an external state is generated for the\nglobal representation from the encoder. The global representation is then fused\ninto the decoder during the decoding process to improve generation quality. We\nconduct experiments in two text generation tasks: machine translation and text\nsummarization. Experimental results on four WMT machine translation tasks and\nLCSTS text summarization task demonstrate the effectiveness of the proposed\napproach on natural language generation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:37:17 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Weng", "Rongxiang", ""], ["Wei", "Haoran", ""], ["Huang", "Shujian", ""], ["Yu", "Heng", ""], ["Bing", "Lidong", ""], ["Luo", "Weihua", ""], ["Chen", "Jiajun", ""]]}, {"id": "2002.10107", "submitter": "Issa Annamoradnejad", "authors": "Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi", "title": "Predicting Subjective Features of Questions of QA Websites using BERT", "comments": "5 pages, 4 figures, 2 tables", "journal-ref": "2020 6th International Conference on Web Research (ICWR), Tehran,\n  Iran, 2020, pp. 240-244", "doi": "10.1109/ICWR49608.2020.9122318", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question-Answering websites, such as StackOverflow and Quora,\nexpect users to follow specific guidelines in order to maintain content\nquality. These systems mainly rely on community reports for assessing contents,\nwhich has serious problems such as the slow handling of violations, the loss of\nnormal and experienced users' time, the low quality of some reports, and\ndiscouraging feedback to new users. Therefore, with the overall goal of\nproviding solutions for automating moderation actions in Q&A websites, we aim\nto provide a model to predict 20 quality or subjective aspects of questions in\nQA websites. To this end, we used data gathered by the CrowdSource team at\nGoogle Research in 2019 and a fine-tuned pre-trained BERT model on our problem.\nBased on the evaluation by Mean-Squared-Error (MSE), the model achieved a value\nof 0.046 after 2 epochs of training, which did not improve substantially in the\nnext ones. Results confirm that by simple fine-tuning, we can achieve accurate\nmodels in little time and on less amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:56:02 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 08:10:16 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 13:22:04 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 14:37:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Annamoradnejad", "Issa", ""], ["Fazli", "Mohammadamin", ""], ["Habibi", "Jafar", ""]]}, {"id": "2002.10116", "submitter": "\\c{S}aziye Bet\\\"ul \\\"Ozate\\c{s}", "authors": "\\c{S}aziye Bet\\\"ul \\\"Ozate\\c{s} (1), Arzucan \\\"Ozg\\\"ur (1), Tunga\n  G\\\"ung\\\"or (1), Balk{\\i}z \\\"Ozt\\\"urk (2) ((1) Department of Computer\n  Engineering, Bo\\u{g}azi\\c{c}i University, (2) Department of Linguistics,\n  Bo\\u{g}azi\\c{c}i University)", "title": "A Hybrid Approach to Dependency Parsing: Combining Rules and Morphology\n  with Deep Learning", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully data-driven, deep learning-based models are usually designed as\nlanguage-independent and have been shown to be successful for many natural\nlanguage processing tasks. However, when the studied language is low-resourced\nand the amount of training data is insufficient, these models can benefit from\nthe integration of natural language grammar-based information. We propose two\napproaches to dependency parsing especially for languages with restricted\namount of training data. Our first approach combines a state-of-the-art deep\nlearning-based parser with a rule-based approach and the second one\nincorporates morphological information into the parser. In the rule-based\napproach, the parsing decisions made by the rules are encoded and concatenated\nwith the vector representations of the input words as additional information to\nthe deep network. The morphology-based approach proposes different methods to\ninclude the morphological structure of words into the parser network.\nExperiments are conducted on the IMST-UD Treebank and the results suggest that\nintegration of explicit knowledge about the target language to a neural parser\nthrough a rule-based parsing system and morphological analysis leads to more\naccurate annotations and hence, increases the parsing performance in terms of\nattachment scores. The proposed methods are developed for Turkish, but can be\nadapted to other languages as well.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:34:33 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["\u00d6zate\u015f", "\u015eaziye Bet\u00fcl", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["G\u00fcng\u00f6r", "Tunga", ""], ["\u00d6zt\u00fcrk", "Balk\u0131z", ""]]}, {"id": "2002.10127", "submitter": "Ahmad Mel", "authors": "Ahmad Mel, Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "FONDUE: A Framework for Node Disambiguation Using Network Embeddings", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data often presents itself in the form of a network. Examples\ninclude social networks, citation networks, biological networks, and knowledge\ngraphs. In their simplest form, networks represent real-life entities (e.g.\npeople, papers, proteins, concepts) as nodes, and describe them in terms of\ntheir relations with other entities by means of edges between these nodes. This\ncan be valuable for a range of purposes from the study of information diffusion\nto bibliographic analysis, bioinformatics research, and question-answering.\n  The quality of networks is often problematic though, affecting downstream\ntasks. This paper focuses on the common problem where a node in the network in\nfact corresponds to multiple real-life entities. In particular, we introduce\nFONDUE, an algorithm based on network embedding for node disambiguation. Given\na network, FONDUE identifies nodes that correspond to multiple entities, for\nsubsequent splitting. Extensive experiments on twelve benchmark datasets\ndemonstrate that FONDUE is substantially and uniformly more accurate for\nambiguous node identification compared to the existing state-of-the-art, at a\ncomparable computational cost, while less optimal for determining the best way\nto split ambiguous nodes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 09:34:18 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mel", "Ahmad", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.10198", "submitter": "Wei Ye", "authors": "Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang, Shikun\n  Zhang", "title": "Leveraging Code Generation to Improve Code Retrieval and Summarization\n  via Dual Learning", "comments": "Published at The Web Conference (WWW) 2020, full paper", "journal-ref": null, "doi": "10.1145/3366423.3380295", "report-no": null, "categories": "cs.IR cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code summarization generates brief natural language description given a\nsource code snippet, while code retrieval fetches relevant source code given a\nnatural language query. Since both tasks aim to model the association between\nnatural language and programming language, recent studies have combined these\ntwo tasks to improve their performance. However, researchers have yet been able\nto effectively leverage the intrinsic connection between the two tasks as they\ntrain these tasks in a separate or pipeline manner, which means their\nperformance can not be well balanced. In this paper, we propose a novel\nend-to-end model for the two tasks by introducing an additional code generation\ntask. More specifically, we explicitly exploit the probabilistic correlation\nbetween code summarization and code generation with dual learning, and utilize\nthe two encoders for code summarization and code generation to train the code\nretrieval task via multi-task learning. We have carried out extensive\nexperiments on an existing dataset of SQL and Python, and results show that our\nmodel can significantly improve the results of the code retrieval task over\nthe-state-of-art models, as well as achieve competitive performance in terms of\nBLEU score for the code summarization task.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:26:11 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 08:49:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ye", "Wei", ""], ["Xie", "Rui", ""], ["Zhang", "Jinglei", ""], ["Hu", "Tianxiang", ""], ["Wang", "Xiaoyin", ""], ["Zhang", "Shikun", ""]]}, {"id": "2002.10210", "submitter": "Yibo Sun", "authors": "Xiaocheng Feng, Yawei Sun, Bing Qin, Heng Gong, Yibo Sun, Wei Bi,\n  Xiaojiang Liu, Ting Liu", "title": "Learning to Select Bi-Aspect Information for Document-Scale Text Content\n  Manipulation", "comments": "accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on a new practical task, document-scale text content\nmanipulation, which is the opposite of text style transfer and aims to preserve\ntext styles while altering the content. In detail, the input is a set of\nstructured records and a reference text for describing another recordset. The\noutput is a summary that accurately describes the partial content in the source\nrecordset with the same writing style of the reference. The task is\nunsupervised due to lack of parallel data, and is challenging to select\nsuitable records and style words from bi-aspect inputs respectively and\ngenerate a high-fidelity long document. To tackle those problems, we first\nbuild a dataset based on a basketball game report corpus as our testbed, and\npresent an unsupervised neural model with interactive attention mechanism,\nwhich is used for learning the semantic relationship between records and\nreference texts to achieve better content transfer and better style\npreservation. In addition, we also explore the effectiveness of the\nback-translation in our task for constructing some pseudo-training pairs.\nEmpirical results show superiority of our approaches over competitive methods,\nand the models also yield a new state-of-the-art result on a sentence-level\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:52:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Feng", "Xiaocheng", ""], ["Sun", "Yawei", ""], ["Qin", "Bing", ""], ["Gong", "Heng", ""], ["Sun", "Yibo", ""], ["Bi", "Wei", ""], ["Liu", "Xiaojiang", ""], ["Liu", "Ting", ""]]}, {"id": "2002.10260", "submitter": "Alessandro Raganato", "authors": "Alessandro Raganato, Yves Scherrer and J\\\"org Tiedemann", "title": "Fixed Encoder Self-Attention Patterns in Transformer-Based Machine\n  Translation", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have brought a radical change to neural machine\ntranslation. A key feature of the Transformer architecture is the so-called\nmulti-head attention mechanism, which allows the model to focus simultaneously\non different parts of the input. However, recent works have shown that most\nattention heads learn simple, and often redundant, positional patterns. In this\npaper, we propose to replace all but one attention head of each encoder layer\nwith simple fixed -- non-learnable -- attentive patterns that are solely based\non position and do not require any external knowledge. Our experiments with\ndifferent data sizes and multiple language pairs show that fixing the attention\nheads on the encoder side of the Transformer at training time does not impact\nthe translation quality and even increases BLEU scores by up to 3 points in\nlow-resource scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:53:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 18:36:07 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 16:10:31 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Raganato", "Alessandro", ""], ["Scherrer", "Yves", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "2002.10266", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Stephanie Van Laere, Tim Verbelen, Bart Dhoedt", "title": "Rhythm, Chord and Melody Generation for Lead Sheets using Recurrent\n  Neural Networks", "comments": "8 pages, 2 figures, 3 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music that is generated by recurrent neural networks often lacks a sense of\ndirection and coherence. We therefore propose a two-stage LSTM-based model for\nlead sheet generation, in which the harmonic and rhythmic templates of the song\nare produced first, after which, in a second stage, a sequence of melody notes\nis generated conditioned on these templates. A subjective listening test shows\nthat our approach outperforms the baselines and increases perceived musical\ncoherence.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:36:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["De Boom", "Cedric", ""], ["Van Laere", "Stephanie", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2002.10284", "submitter": "Victor Swift", "authors": "Victor Swift", "title": "Word Embeddings Inherently Recover the Conceptual Organization of the\n  Human Mind", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a means to uncover deep patterns from rich sources of\ndata. Here, we find that machine learning can recover the conceptual\norganization of the human mind when applied to the natural language use of\nmillions of people. Utilizing text from billions of webpages, we recover most\nof the concepts contained in English, Dutch, and Japanese, as represented in\nlarge scale Word Association networks. Our results justify machine learning as\na means to probe the human mind, at a depth and scale that has been\nunattainable using self-report and observational methods. Beyond direct\npsychological applications, our methods may prove useful for projects concerned\nwith defining, assessing, relating, or uncovering concepts in any scientific\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 23:45:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Swift", "Victor", ""]]}, {"id": "2002.10309", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Mayank Lunayach and Vinay P. Namboodiri", "title": "Uncertainty based Class Activation Maps for Visual Question Answering", "comments": "This work is an extension of our ICCV-2019 work. arXiv admin note:\n  text overlap with arXiv:1908.06306", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding and explaining deep learning models is an imperative task.\nTowards this, we propose a method that obtains gradient-based certainty\nestimates that also provide visual attention maps. Particularly, we solve for\nvisual question answering task. We incorporate modern probabilistic deep\nlearning methods that we further improve by using the gradients for these\nestimates. These have two-fold benefits: a) improvement in obtaining the\ncertainty estimates that correlate better with misclassified samples and b)\nimproved attention maps that provide state-of-the-art results in terms of\ncorrelation with human attention regions. The improved attention maps result in\nconsistent improvement for various methods for visual question answering.\nTherefore, the proposed technique can be thought of as a recipe for obtaining\nimproved certainty estimates and explanations for deep learning models. We\nprovide detailed empirical analysis for the visual question answering task on\nall standard benchmarks and comparison with state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:54:19 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Patro", "Badri N.", ""], ["Lunayach", "Mayank", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2002.10329", "submitter": "Christoph Wernhard", "authors": "Jana Kittelmann, Christoph Wernhard", "title": "KBSET -- Knowledge-Based Support for Scholarly Editing and Text\n  Processing with Declarative LaTeX Markup and a Core Written in SWI-Prolog", "comments": "To appear in DECLARE 2019 Revised Selected Papers", "journal-ref": null, "doi": "10.1007/978-3-030-46714-2_12", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KBSET is an environment that provides support for scholarly editing in two\nflavors: First, as a practical tool KBSET/Letters that accompanies the\ndevelopment of editions of correspondences (in particular from the 18th and\n19th century), completely from source documents to PDF and HTML presentations.\nSecond, as a prototypical tool KBSET/NER for experimentally investigating novel\nforms of working on editions that are centered around automated named entity\nrecognition. KBSET can process declarative application-specific markup that is\nexpressed in LaTeX notation and incorporate large external fact bases that are\ntypically provided in RDF. KBSET includes specially developed LaTeX styles and\na core system that is written in SWI-Prolog, which is used there in many roles,\nutilizing that it realizes the potential of Prolog as a unifying language.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:57:41 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kittelmann", "Jana", ""], ["Wernhard", "Christoph", ""]]}, {"id": "2002.10336", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Ann Lee, Gabriel Synnaeve, Awni Hannun", "title": "Semi-Supervised Speech Recognition via Local Prior Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequence transduction tasks like speech recognition, a strong structured\nprior model encodes rich information about the target space, implicitly ruling\nout invalid sequences by assigning them low probability. In this work, we\npropose local prior matching (LPM), a semi-supervised objective that distills\nknowledge from a strong prior (e.g. a language model) to provide learning\nsignal to a discriminative model trained on unlabeled speech. We demonstrate\nthat LPM is theoretically well-motivated, simple to implement, and superior to\nexisting knowledge distillation techniques under comparable settings. Starting\nfrom a baseline trained on 100 hours of labeled speech, with an additional 360\nhours of unlabeled data, LPM recovers 54% and 73% of the word error rate on\nclean and noisy test sets relative to a fully supervised model on the same\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:07:11 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Lee", "Ann", ""], ["Synnaeve", "Gabriel", ""], ["Hannun", "Awni", ""]]}, {"id": "2002.10345", "submitter": "Yige Xu", "authors": "Yige Xu, Xipeng Qiu, Ligao Zhou, Xuanjing Huang", "title": "Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pre-trained language models like BERT has become an effective way\nin NLP and yields state-of-the-art results on many downstream tasks. Recent\nstudies on adapting BERT to new tasks mainly focus on modifying the model\nstructure, re-designing the pre-train tasks, and leveraging external data and\nknowledge. The fine-tuning strategy itself has yet to be fully explored. In\nthis paper, we improve the fine-tuning of BERT with two effective mechanisms:\nself-ensemble and self-distillation. The experiments on text classification and\nnatural language inference tasks show our proposed methods can significantly\nimprove the adaption of BERT without any external data or knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:17:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Xu", "Yige", ""], ["Qiu", "Xipeng", ""], ["Zhou", "Ligao", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2002.10348", "submitter": "Xueliang Zhao", "authors": "Xueliang Zhao, Wei Wu, Chongyang Tao, Can Xu, Dongyan Zhao, Rui Yan", "title": "Low-Resource Knowledge-Grounded Dialogue Generation", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responding with knowledge has been recognized as an important capability for\nan intelligent conversational agent. Yet knowledge-grounded dialogues, as\ntraining data for learning such a response generation model, are difficult to\nobtain. Motivated by the challenge in practice, we consider knowledge-grounded\ndialogue generation under a natural assumption that only limited training\nexamples are available. In such a low-resource setting, we devise a\ndisentangled response decoder in order to isolate parameters that depend on\nknowledge-grounded dialogues from the entire generation model. By this means,\nthe major part of the model can be learned from a large number of ungrounded\ndialogues and unstructured documents, while the remaining small parameters can\nbe well fitted using the limited training examples. Evaluation results on two\nbenchmarks indicate that with only 1/8 training data, our model can achieve the\nstate-of-the-art performance and generalize well on out-of-domain knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:20:32 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhao", "Xueliang", ""], ["Wu", "Wei", ""], ["Tao", "Chongyang", ""], ["Xu", "Can", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2002.10361", "submitter": "Xiaolei Huang", "authors": "Xiaolei Huang, Linzi Xing, Franck Dernoncourt, Michael J. Paul", "title": "Multilingual Twitter Corpus and Baselines for Evaluating Demographic\n  Bias in Hate Speech Recognition", "comments": "Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research on fairness evaluation of document classification models\nmainly uses synthetic monolingual data without ground truth for author\ndemographic attributes. In this work, we assemble and publish a multilingual\nTwitter corpus for the task of hate speech detection with inferred four author\ndemographic factors: age, country, gender and race/ethnicity. The corpus covers\nfive languages: English, Italian, Polish, Portuguese and Spanish. We evaluate\nthe inferred demographic labels with a crowdsourcing platform, Figure Eight. To\nexamine factors that can cause biases, we take an empirical analysis of\ndemographic predictability on the English corpus. We measure the performance of\nfour popular document classifiers and evaluate the fairness and bias of the\nbaseline classifiers on the author-level demographic attributes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:45:59 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:34:59 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Huang", "Xiaolei", ""], ["Xing", "Linzi", ""], ["Dernoncourt", "Franck", ""], ["Paul", "Michael J.", ""]]}, {"id": "2002.10375", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin\n  Piwowarski, Jacopo Staiano", "title": "Discriminative Adversarial Search for Abstractive Summarization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach for sequence decoding, Discriminative\nAdversarial Search (DAS), which has the desirable properties of alleviating the\neffects of exposure bias without requiring external metrics. Inspired by\nGenerative Adversarial Networks (GANs), wherein a discriminator is used to\nimprove the generator, our method differs from GANs in that the generator\nparameters are not updated at training time and the discriminator is only used\nto drive sequence generation at inference time.\n  We investigate the effectiveness of the proposed approach on the task of\nAbstractive Summarization: the results obtained show that a naive application\nof DAS improves over the state-of-the-art methods, with further gains obtained\nvia discriminator retraining. Moreover, we show how DAS can be effective for\ncross-domain adaptation. Finally, all results reported are obtained without\nadditional rule-based filtering strategies, commonly used by the best\nperforming systems available: this indicates that DAS can effectively be\ndeployed without relying on post-hoc modifications of the generated outputs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:07:32 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 07:21:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Scialom", "Thomas", ""], ["Dray", "Paul-Alexis", ""], ["Lamprier", "Sylvain", ""], ["Piwowarski", "Benjamin", ""], ["Staiano", "Jacopo", ""]]}, {"id": "2002.10416", "submitter": "Utku T\\\"urk", "authors": "Utku T\\\"urk (1), Furkan Atmaca (1), \\c{S}aziye Bet\\\"ul \\\"Ozate\\c{s}\n  (2), G\\\"ozde Berk (2), Seyyit Talha Bedir (1), Abdullatif K\\\"oksal (2),\n  Balk{\\i}z \\\"Ozt\\\"urk Ba\\c{s}aran (1), Tunga G\\\"ung\\\"or (2) and Arzucan\n  \\\"Ozg\\\"ur (2) ((1) Department of Linguistics Bo\\u{g}azi\\c{c}i University, (2)\n  Department of Computer Engineering Bo\\u{g}azi\\c{c}i University)", "title": "Resources for Turkish Dependency Parsing: Introducing the BOUN Treebank\n  and the BoAT Annotation Tool", "comments": "29 pages, 5 figures, 10 tables, submitted to Language Resources and\n  Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our contributions and efforts to develop Turkish\nresources, which include a new treebank (BOUN Treebank) with novel sentences,\nalong with the guidelines we adopted and a new annotation tool we developed\n(BoAT). The manual annotation process we employed was shaped and implemented by\na team of four linguists and five NLP specialists. Decisions regarding the\nannotation of the BOUN Treebank were made in line with the Universal\nDependencies framework, which originated from the works of De Marneffe et al.\n(2014) and Nivre et al. (2016). We took into account the recent unifying\nefforts based on the re-annotation of other Turkish treebanks in the UD\nframework (T\\\"urk et al., 2019). Through the BOUN Treebank, we introduced a\ntotal of 9,757 sentences from various topics including biographical texts,\nnational newspapers, instructional texts, popular culture articles, and essays.\nIn addition, we report the parsing results of a graph-based dependency parser\nobtained over each text type, the total of the BOUN Treebank, and all Turkish\ntreebanks that we either re-annotated or introduced. We show that a\nstate-of-the-art dependency parser has improved scores for identifying the\nproper head and the syntactic relationships between the heads and the\ndependents. In light of these results, we have observed that the unification of\nthe Turkish annotation scheme and introducing a more comprehensive treebank\nimproves performance with regards to dependency parsing\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:59:11 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["T\u00fcrk", "Utku", ""], ["Atmaca", "Furkan", ""], ["\u00d6zate\u015f", "\u015eaziye Bet\u00fcl", ""], ["Berk", "G\u00f6zde", ""], ["Bedir", "Seyyit Talha", ""], ["K\u00f6ksal", "Abdullatif", ""], ["Ba\u015faran", "Balk\u0131z \u00d6zt\u00fcrk", ""], ["G\u00fcng\u00f6r", "Tunga", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "2002.10546", "submitter": "Seth Kulick", "authors": "Seth Kulick and Neville Ryant", "title": "Parsing Early Modern English for Linguistic Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the question of whether advances in NLP over the last few\nyears make it possible to vastly increase the size of data usable for research\nin historical syntax. This brings together many of the usual tools in NLP -\nword embeddings, tagging, and parsing - in the service of linguistic queries\nover automatically annotated corpora. We train a part-of-speech (POS) tagger\nand parser on a corpus of historical English, using ELMo embeddings trained\nover a billion words of similar text. The evaluation is based on the standard\nmetrics, as well as on the accuracy of the query searches using the parsed\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:04:51 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Kulick", "Seth", ""], ["Ryant", "Neville", ""]]}, {"id": "2002.10582", "submitter": "Jim Samuel", "authors": "Jim Samuel, Richard Holowczak, Raquel Benbunan-Fich, Ilan Levine", "title": "Automating Discovery of Dominance in Synchronous Computer-Mediated\n  Communication", "comments": null, "journal-ref": "47th Hawaii International Conference on System Sciences, 2014, pp.\n  1804-1812", "doi": "10.1109/HICSS.2014.636", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of electronic interaction, dominance (or the assertion of\ncontrol over others) has acquired new dimensions. This study investigates the\ndynamics and characteristics of dominance in virtual interaction by analyzing\nelectronic chat transcripts of groups solving a hidden profile task. We\ninvestigate computer-mediated communication behavior patterns that demonstrate\ndominance and identify a number of relevant variables. These indicators are\ncalculated with automatic and manual coding of text transcripts. A comparison\nof both sets of variables indicates that automatic text analysis methods yield\nsimilar conclusions than manual coding. These findings are encouraging to\nadvance research in text analysis methods in general, and in the study of\nvirtual team dominance in particular.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 23:07:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Samuel", "Jim", ""], ["Holowczak", "Richard", ""], ["Benbunan-Fich", "Raquel", ""], ["Levine", "Ilan", ""]]}, {"id": "2002.10638", "submitter": "Chunyuan Li", "authors": "Weituo Hao, Chunyuan Li, Xiujun Li, Lawrence Carin, Jianfeng Gao", "title": "Towards Learning a Generic Agent for Vision-and-Language Navigation via\n  Pre-training", "comments": "To appear at CVPR 2020. The first two authors contributed equally to\n  this manuscript. Code: https://github.com/weituo12321/PREVALENT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to navigate in a visual environment following natural-language\ninstructions is a challenging task, because the multimodal inputs to the agent\nare highly variable, and the training data on a new task is often limited. In\nthis paper, we present the first pre-training and fine-tuning paradigm for\nvision-and-language navigation (VLN) tasks. By training on a large amount of\nimage-text-action triplets in a self-supervised learning manner, the\npre-trained model provides generic representations of visual environments and\nlanguage instructions. It can be easily used as a drop-in for existing VLN\nframeworks, leading to the proposed agent called Prevalent. It learns more\neffectively in new tasks and generalizes better in a previously unseen\nenvironment. The performance is validated on three VLN tasks. On the\nRoom-to-Room benchmark, our model improves the state-of-the-art from 47% to 51%\non success rate weighted by path length. Further, the learned representation is\ntransferable to other VLN tasks. On two recent tasks, vision-and-dialog\nnavigation and \"Help, Anna!\" the proposed Prevalent leads to significant\nimprovement over existing methods, achieving a new state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:08:12 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 03:20:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hao", "Weituo", ""], ["Li", "Chunyuan", ""], ["Li", "Xiujun", ""], ["Carin", "Lawrence", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2002.10640", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig,\n  Ruslan Salakhutdinov, William W. Cohen", "title": "Differentiable Reasoning over a Virtual Knowledge Base", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of answering complex multi-hop questions using a corpus\nas a virtual knowledge base (KB). In particular, we describe a neural module,\nDrKIT, that traverses textual data like a KB, softly following paths of\nrelations between mentions of entities in the corpus. At each step the module\nuses a combination of sparse-matrix TFIDF indices and a maximum inner product\nsearch (MIPS) on a special index of contextual representations of the mentions.\nThis module is differentiable, so the full system can be trained end-to-end\nusing gradient based methods, starting from natural language inputs. We also\ndescribe a pretraining scheme for the contextual representation encoder by\ngenerating hard negative examples using existing knowledge bases. We show that\nDrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,\ncutting the gap between text-based and KB-based state-of-the-art by 70%. On\nHotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking\napproach to retrieving the relevant passages required to answer a question.\nDrKIT is also very efficient, processing 10-100x more queries per second than\nexisting multi-hop systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:13:32 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Zaheer", "Manzil", ""], ["Balachandran", "Vidhisha", ""], ["Neubig", "Graham", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "2002.10665", "submitter": "Sumant Pushp", "authors": "Sumant Pushp, Pragya Kashmira, Shyamanta M Hazarika", "title": "Declarative Memory-based Structure for the Representation of Text Data", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of intelligent computing, computational progress in text\nprocessing is an essential consideration. Many systems have been developed to\nprocess text over different languages. Though, there is considerable\ndevelopment, they still lack in understanding of the text, i.e., instead of\nkeeping text as knowledge, many treat text as a data. In this work we introduce\na text representation scheme which is influenced by human memory\ninfrastructure. Since texts are declarative in nature, a structural\norganization would foster efficient computation over text. We exploit long term\nepisodic memory to keep text information observed over time. This not only keep\nfragments of text in an organized fashion but also reduces redundancy and\nstores the temporal relation among them. Wordnet has been used to imitate\nsemantic memory, which works at word level to facilitate the understanding\nabout individual words within text. Experimental results of various operation\nperformed over episodic memory and growth of knowledge infrastructure over time\nis reported.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 04:56:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Pushp", "Sumant", ""], ["Kashmira", "Pragya", ""], ["Hazarika", "Shyamanta M", ""]]}, {"id": "2002.10670", "submitter": "Eric Hulburd", "authors": "Eric Hulburd", "title": "Exploring BERT Parameter Efficiency on the Stanford Question Answering\n  Dataset v2.0", "comments": "11 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the parameter efficiency of BERT arXiv:1810.04805 on\nversion 2.0 of the Stanford Question Answering dataset (SQuAD2.0). We evaluate\nthe parameter efficiency of BERT while freezing a varying number of final\ntransformer layers as well as including the adapter layers proposed in\narXiv:1902.00751. Additionally, we experiment with the use of context-aware\nconvolutional (CACNN) filters, as described in arXiv:1709.08294v3, as a final\naugmentation layer for the SQuAD2.0 tasks.\n  This exploration is motivated in part by arXiv:1907.10597, which made a\ncompelling case for broadening the evaluation criteria of artificial\nintelligence models to include various measures of resource efficiency. While\nwe do not evaluate these models based on their floating point operation\nefficiency as proposed in arXiv:1907.10597, we examine efficiency with respect\nto training time, inference time, and total number of model parameters. Our\nresults largely corroborate those of arXiv:1902.00751 for adapter modules,\nwhile also demonstrating that gains in F1 score from adding context-aware\nconvolutional filters are not practical due to the increase in training and\ninference time.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:09:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 05:16:37 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hulburd", "Eric", ""]]}, {"id": "2002.10695", "submitter": "Hung Le", "authors": "Hung Le, Nancy F. Chen", "title": "Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge", "comments": "Accepted at DSTC Workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-Visual Scene-Aware Dialog (AVSD) is an extension from Video Question\nAnswering (QA) whereby the dialogue agent is required to generate natural\nlanguage responses to address user queries and carry on conversations. This is\na challenging task as it consists of video features of multiple modalities,\nincluding text, visual, and audio features. The agent also needs to learn\nsemantic dependencies among user utterances and system responses to make\ncoherent conversations with humans. In this work, we describe our submission to\nthe AVSD track of the 8th Dialogue System Technology Challenge. We adopt\ndot-product attention to combine text and non-text features of input video. We\nfurther enhance the generation capability of the dialogue agent by adopting\npointer networks to point to tokens from multiple source sequences in each\ngeneration step. Our systems achieve high performance in automatic metrics and\nobtain 5th and 6th place in human evaluation among all submissions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 06:41:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Le", "Hung", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2002.10710", "submitter": "Chen Zhang", "authors": "Haolin Song, Chen Zhang, Qiuchi Li, Dawei Song", "title": "End-to-end Emotion-Cause Pair Extraction via Learning to Link", "comments": "7 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion-cause pair extraction (ECPE), as an emergent natural language\nprocessing task, aims at jointly investigating emotions and their underlying\ncauses in documents. It extends the previous emotion cause extraction (ECE)\ntask, yet without requiring a set of pre-given emotion clauses as in ECE.\nExisting approaches to ECPE generally adopt a two-stage method, i.e., (1)\nemotion and cause detection, and then (2) pairing the detected emotions and\ncauses. Such pipeline method, while intuitive, suffers from two critical\nissues, including error propagation across stages that may hinder the\neffectiveness, and high computational cost that would limit the practical\napplication of the method. To tackle these issues, we propose a multi-task\nlearning model that can extract emotions, causes and emotion-cause pairs\nsimultaneously in an end-to-end manner. Specifically, our model regards pair\nextraction as a link prediction task, and learns to link from emotion clauses\nto cause clauses, i.e., the links are directional. Emotion extraction and cause\nextraction are incorporated into the model as auxiliary tasks, which further\nboost the pair extraction. Experiments are conducted on an ECPE benchmarking\ndataset. The results show that our proposed model outperforms a range of\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:49:12 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 13:31:10 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 07:40:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Song", "Haolin", ""], ["Zhang", "Chen", ""], ["Li", "Qiuchi", ""], ["Song", "Dawei", ""]]}, {"id": "2002.10757", "submitter": "Shiyao Cui", "authors": "Shiyao Cui, Bowen Yu, Tingwen Liu, Zhenyu Zhang, Xuebin Wang and\n  Jinqiao Shi", "title": "Edge-Enhanced Graph Convolution Networks for Event Detection with\n  Syntactic Relation", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection (ED), a key subtask of information extraction, aims to\nrecognize instances of specific event types in text. Previous studies on the\ntask have verified the effectiveness of integrating syntactic dependency into\ngraph convolutional networks. However, these methods usually ignore dependency\nlabel information, which conveys rich and useful linguistic knowledge for ED.\nIn this paper, we propose a novel architecture named Edge-Enhanced Graph\nConvolution Networks (EE-GCN), which simultaneously exploits syntactic\nstructure and typed dependency label information to perform ED. Specifically,\nan edge-aware node update module is designed to generate expressive word\nrepresentations by aggregating syntactically-connected words through specific\ndependency types. Furthermore, to fully explore clues hidden in dependency\nedges, a node-aware edge update module is introduced, which refines the\nrelation representations with contextual information. These two modules are\ncomplementary to each other and work in a mutual promotion way. We conduct\nexperiments on the widely used ACE2005 dataset and the results show significant\nimprovement over competitive baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:18:26 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 06:19:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Cui", "Shiyao", ""], ["Yu", "Bowen", ""], ["Liu", "Tingwen", ""], ["Zhang", "Zhenyu", ""], ["Wang", "Xuebin", ""], ["Shi", "Jinqiao", ""]]}, {"id": "2002.10772", "submitter": "Xien Liu", "authors": "Xien Liu, Song Wang, Xiao Zhang, Xinxin You, Ji Wu and Dejing Dou", "title": "Label-guided Learning for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is one of the most important and fundamental tasks in\nnatural language processing. Performance of this task mainly dependents on text\nrepresentation learning. Currently, most existing learning frameworks mainly\nfocus on encoding local contextual information between words. These methods\nalways neglect to exploit global clues, such as label information, for encoding\ntext information. In this study, we propose a label-guided learning framework\nLguidedLearn for text representation and classification. Our method is novel\nbut simple that we only insert a label-guided encoding layer into the commonly\nused text representation learning schemas. That label-guided layer performs\nlabel-based attentive encoding to map the universal text embedding (encoded by\na contextual information learner) into different label spaces, resulting in\nlabel-wise embeddings. In our proposed framework, the label-guided layer can be\neasily and directly applied with a contextual encoding method to perform\njointly learning. Text information is encoded based on both the local\ncontextual information and the global label clues. Therefore, the obtained text\nembeddings are more robust and discriminative for text classification.\nExtensive experiments are conducted on benchmark datasets to illustrate the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:05:56 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Liu", "Xien", ""], ["Wang", "Song", ""], ["Zhang", "Xiao", ""], ["You", "Xinxin", ""], ["Wu", "Ji", ""], ["Dou", "Dejing", ""]]}, {"id": "2002.10782", "submitter": "Martin Potthast", "authors": "Wei-Fan Chen, Shahbaz Syed, Benno Stein, Matthias Hagen, Martin\n  Potthast", "title": "Abstractive Snippet Generation", "comments": "Accepted by WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380206", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An abstractive snippet is an originally created piece of text to summarize a\nweb page on a search engine results page. Compared to the conventional\nextractive snippets, which are generated by extracting phrases and sentences\nverbatim from a web page, abstractive snippets circumvent copyright issues;\neven more interesting is the fact that they open the door for personalization.\nAbstractive snippets have been evaluated as equally powerful in terms of user\nacceptance and expressiveness---but the key question remains: Can abstractive\nsnippets be automatically generated with sufficient quality?\n  This paper introduces a new approach to abstractive snippet generation: We\nidentify the first two large-scale sources for distant supervision, namely\nanchor contexts and web directories. By mining the entire ClueWeb09 and\nClueWeb12 for anchor contexts and by utilizing the DMOZ Open Directory Project,\nwe compile the Webis Abstractive Snippet Corpus 2020, comprising more than 3.5\nmillion triples of the form $\\langle$query, snippet, document$\\rangle$ as\ntraining examples, where the snippet is either an anchor context or a web\ndirectory description in lieu of a genuine query-biased abstractive snippet of\nthe web document. We propose a bidirectional abstractive snippet generation\nmodel and assess the quality of both our corpus and the generated abstractive\nsnippets with standard measures, crowdsourcing, and in comparison to the state\nof the art. The evaluation shows that our novel data sources along with the\nproposed model allow for producing usable query-biased abstractive snippets\nwhile minimizing text reuse.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:36:17 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 22:50:12 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Wei-Fan", ""], ["Syed", "Shahbaz", ""], ["Stein", "Benno", ""], ["Hagen", "Matthias", ""], ["Potthast", "Martin", ""]]}, {"id": "2002.10829", "submitter": "Alina Karakanta", "authors": "Alina Karakanta, Matteo Negri, Marco Turchi", "title": "MuST-Cinema: a Speech-to-Subtitles corpus", "comments": "Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing needs in localising audiovisual content in multiple languages through\nsubtitles call for the development of automatic solutions for human subtitling.\nNeural Machine Translation (NMT) can contribute to the automatisation of\nsubtitling, facilitating the work of human subtitlers and reducing turn-around\ntimes and related costs. NMT requires high-quality, large, task-specific\ntraining data. The existing subtitling corpora, however, are missing both\nalignments to the source language audio and important information about\nsubtitle breaks. This poses a significant limitation for developing efficient\nautomatic approaches for subtitling, since the length and form of a subtitle\ndirectly depends on the duration of the utterance. In this work, we present\nMuST-Cinema, a multilingual speech translation corpus built from TED subtitles.\nThe corpus is comprised of (audio, transcription, translation) triplets.\nSubtitle breaks are preserved by inserting special symbols. We show that the\ncorpus can be used to build models that efficiently segment sentences into\nsubtitles and propose a method for annotating existing subtitling corpora with\nsubtitle breaks, conforming to the constraint of length.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:40:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Karakanta", "Alina", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "2002.10832", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Patrick Bordes, Paul-Alexis Dray, Jacopo Staiano,\n  Patrick Gallinari", "title": "What BERT Sees: Cross-Modal Transfer for Visual Question Generation", "comments": "INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have recently contributed to significant advances\nin NLP tasks. Recently, multi-modal versions of BERT have been developed, using\nheavy pre-training relying on vast corpora of aligned textual and image data,\nprimarily applied to classification tasks such as VQA. In this paper, we are\ninterested in evaluating the visual capabilities of BERT out-of-the-box, by\navoiding pre-training made on supplementary data. We choose to study Visual\nQuestion Generation, a task of great interest for grounded dialog, that enables\nto study the impact of each modality (as input can be visual and/or textual).\nMoreover, the generation aspect of the task requires an adaptation since BERT\nis primarily designed as an encoder. We introduce BERT-gen, a BERT-based\narchitecture for text generation, able to leverage on either mono- or multi-\nmodal representations. The results reported under different configurations\nindicate an innate capacity for BERT-gen to adapt to multi-modal data and text\ngeneration, even with few data available, avoiding expensive pre-training. The\nproposed model obtains substantial improvements over the state-of-the-art on\ntwo established VQG datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:44:36 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 13:07:57 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 15:48:35 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Scialom", "Thomas", ""], ["Bordes", "Patrick", ""], ["Dray", "Paul-Alexis", ""], ["Staiano", "Jacopo", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2002.10851", "submitter": "Th\\'eodore Bluche", "authors": "Th\\'eodore Bluche, Ma\\\"el Primet, Thibault Gisselbrecht", "title": "Small-Footprint Open-Vocabulary Keyword Spotting with Quantized LSTM\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a keyword-based spoken language understanding system, in which the\nintent of the user can directly be derived from the detection of a sequence of\nkeywords in the query. In this paper, we focus on an open-vocabulary keyword\nspotting method, allowing the user to define their own keywords without having\nto retrain the whole model. We describe the different design choices leading to\na fast and small-footprint system, able to run on tiny devices, for any\narbitrary set of user-defined keywords, without training data specific to those\nkeywords. The model, based on a quantized long short-term memory (LSTM) neural\nnetwork, trained with connectionist temporal classification (CTC), weighs less\nthan 500KB. Our approach takes advantage of some properties of the predictions\nof CTC-trained networks to calibrate the confidence scores and implement a fast\ndetection algorithm. The proposed system outperforms a standard keyword-filler\nmodel approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 13:27:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bluche", "Th\u00e9odore", ""], ["Primet", "Ma\u00ebl", ""], ["Gisselbrecht", "Thibault", ""]]}, {"id": "2002.10903", "submitter": "Chengyu Wang", "authors": "Chengyu Wang, Minghui Qiu, Jun Huang, Xiaofeng He", "title": "KEML: A Knowledge-Enriched Meta-Learning Framework for Lexical Relation\n  Classification", "comments": "aaai 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical relations describe how concepts are semantically related, in the form\nof relation triples. The accurate prediction of lexical relations between\nconcepts is challenging, due to the sparsity of patterns indicating the\nexistence of such relations. We propose the Knowledge-Enriched Meta-Learning\n(KEML) framework to address the task of lexical relation classification. In\nKEML, the LKB-BERT (Lexical Knowledge Base-BERT) model is presented to learn\nconcept representations from massive text corpora, with rich lexical knowledge\ninjected by distant supervision. A probabilistic distribution of auxiliary\ntasks is defined to increase the model's ability to recognize different types\nof lexical relations. We further combine a meta-learning process over the\nauxiliary task distribution and supervised learning to train the neural lexical\nrelation classifier. Experiments over multiple datasets show that KEML\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:43:56 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 02:34:19 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wang", "Chengyu", ""], ["Qiu", "Minghui", ""], ["Huang", "Jun", ""], ["He", "Xiaofeng", ""]]}, {"id": "2002.10931", "submitter": "Sashank Santhanam", "authors": "Bonnie J. Dorr, Archna Bhatia, Adam Dalton, Brodie Mather, Bryanna\n  Hebenstreit, Sashank Santhanam, Zhuo Cheng, Samira Shaikh, Alan Zemel, Tomek\n  Strzalkowski", "title": "Detecting Asks in SE attacks: Impact of Linguistic and Structural\n  Knowledge", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social engineers attempt to manipulate users into undertaking actions such as\ndownloading malware by clicking links or providing access to money or sensitive\ninformation. Natural language processing, computational sociolinguistics, and\nmedia-specific structural clues provide a means for detecting both the ask\n(e.g., buy gift card) and the risk/reward implied by the ask, which we call\nframing (e.g., lose your job, get a raise). We apply linguistic resources such\nas Lexical Conceptual Structure to tackle ask detection and also leverage\nstructural clues such as links and their proximity to identified asks to\nimprove confidence in our results. Our experiments indicate that the\nperformance of ask detection, framing detection, and identification of the top\nask is improved by linguistically motivated classes coupled with structural\nclues such as links. Our approach is implemented in a system that informs users\nabout social engineering risk situations.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:05:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dorr", "Bonnie J.", ""], ["Bhatia", "Archna", ""], ["Dalton", "Adam", ""], ["Mather", "Brodie", ""], ["Hebenstreit", "Bryanna", ""], ["Santhanam", "Sashank", ""], ["Cheng", "Zhuo", ""], ["Shaikh", "Samira", ""], ["Zemel", "Alan", ""], ["Strzalkowski", "Tomek", ""]]}, {"id": "2002.10937", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Hemant Purohit, and Huzefa Rangwala", "title": "Diversity-Based Generalization for Unsupervised Text Classification\n  under Domain Shift", "comments": "16 pages, 3 figures, 5 Tables, Source Code Available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation approaches seek to learn from a source domain and\ngeneralize it to an unseen target domain. At present, the state-of-the-art\nunsupervised domain adaptation approaches for subjective text classification\nproblems leverage unlabeled target data along with labeled source data. In this\npaper, we propose a novel method for domain adaptation of single-task text\nclassification problems based on a simple but effective idea of diversity-based\ngeneralization that does not require unlabeled target data but still matches\nthe state-of-the-art in performance. Diversity plays the role of promoting the\nmodel to better generalize and be indiscriminate towards domain shift by\nforcing the model not to rely on same features for prediction. We apply this\nconcept on the most explainable component of neural networks, the attention\nlayer. To generate sufficient diversity, we create a multi-head attention model\nand infuse a diversity constraint between the attention heads such that each\nhead will learn differently. We further expand upon our model by tri-training\nand designing a procedure with an additional diversity constraint between the\nattention heads of the tri-trained classifiers. Extensive evaluation using the\nstandard benchmark dataset of Amazon reviews and a newly constructed dataset of\nCrisis events shows that our fully unsupervised method matches with the\ncompeting baselines that uses unlabeled target data. Our results demonstrate\nthat machine learning architectures that ensure sufficient diversity can\ngeneralize better; encouraging future research to design ubiquitously usable\nlearning models without using unlabeled target data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:11:02 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 18:06:10 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Krishnan", "Jitin", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2002.10943", "submitter": "Balaji Ganesan", "authors": "Lingraj S Vannur, Balaji Ganesan, Lokesh Nagalapatti, Hima Patel, MN\n  Thippeswamy", "title": "Data Augmentation for Personal Knowledge Base Population", "comments": "8 pages, 9 figures, 6 tables. under review. arXiv admin note: text\n  overlap with arXiv:2001.08013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold start knowledge base population (KBP) is the problem of populating a\nknowledge base from unstructured documents. While artificial neural networks\nhave led to significant improvements in the different tasks that are part of\nKBP, the overall F1 of the end-to-end system remains quite low. This problem is\nmore acute in personal knowledge bases, which present additional challenges\nwith regard to data protection, fairness and privacy. In this work, we present\na system that uses rule based annotators and a graph neural network for missing\nlink prediction, to populate a more complete, fair and diverse knowledge base\nfrom the TACRED dataset.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:39:55 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 06:31:40 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Vannur", "Lingraj S", ""], ["Ganesan", "Balaji", ""], ["Nagalapatti", "Lokesh", ""], ["Patel", "Hima", ""], ["Thippeswamy", "MN", ""]]}, {"id": "2002.10957", "submitter": "Wenhui Wang", "authors": "Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, Ming Zhou", "title": "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression\n  of Pre-Trained Transformers", "comments": "Code and models:\n  https://github.com/microsoft/unilm/tree/master/minilm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (e.g., BERT (Devlin et al., 2018) and its\nvariants) have achieved remarkable success in varieties of NLP tasks. However,\nthese models usually consist of hundreds of millions of parameters which brings\nchallenges for fine-tuning and online serving in real-life applications due to\nlatency and capacity constraints. In this work, we present a simple and\neffective approach to compress large Transformer (Vaswani et al., 2017) based\npre-trained models, termed as deep self-attention distillation. The small model\n(student) is trained by deeply mimicking the self-attention module, which plays\na vital role in Transformer networks, of the large model (teacher).\nSpecifically, we propose distilling the self-attention module of the last\nTransformer layer of the teacher, which is effective and flexible for the\nstudent. Furthermore, we introduce the scaled dot-product between values in the\nself-attention module as the new deep self-attention knowledge, in addition to\nthe attention distributions (i.e., the scaled dot-product of queries and keys)\nthat have been used in existing works. Moreover, we show that introducing a\nteacher assistant (Mirzadeh et al., 2019) also helps the distillation of large\npre-trained Transformer models. Experimental results demonstrate that our\nmonolingual model outperforms state-of-the-art baselines in different parameter\nsize of student models. In particular, it retains more than 99% accuracy on\nSQuAD 2.0 and several GLUE benchmark tasks using 50% of the Transformer\nparameters and computations of the teacher model. We also obtain competitive\nresults in applying deep self-attention distillation to multilingual\npre-trained models.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:21:10 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 02:53:18 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Wenhui", ""], ["Wei", "Furu", ""], ["Dong", "Li", ""], ["Bao", "Hangbo", ""], ["Yang", "Nan", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.10959", "submitter": "Satyaki Chakraborty", "authors": "Satyaki Chakraborty, Xinya Li, Sayak Chakraborty", "title": "A more abstractive summarization model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointer-generator network is an extremely popular method of text\nsummarization. More recent works in this domain still build on top of the\nbaseline pointer generator by augmenting a content selection phase, or by\ndecomposing the decoder into a contextual network and a language model.\nHowever, all such models that are based on the pointer-generator base\narchitecture cannot generate novel words in the summary and mostly copy words\nfrom the source text. In our work, we first thoroughly investigate why the\npointer-generator network is unable to generate novel words, and then address\nthat by adding an Out-of-vocabulary (OOV) penalty. This enables us to improve\nthe amount of novelty/abstraction significantly. We use normalized n-gram\nnovelty scores as a metric for determining the level of abstraction. Moreover,\nwe also report rouge scores of our model since most summarization models are\nevaluated with R-1, R-2, R-L scores.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:22:23 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chakraborty", "Satyaki", ""], ["Li", "Xinya", ""], ["Chakraborty", "Sayak", ""]]}, {"id": "2002.11004", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Ryuichi Kiryo, Kosuke Tsujino, Haruki Yukawa", "title": "Language-Independent Tokenisation Rivals Language-Specific Tokenisation\n  for Word Similarity Prediction", "comments": "To appear in the 12th Language Resources and Evaluation (LREC 2020)\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-independent tokenisation (LIT) methods that do not require labelled\nlanguage resources or lexicons have recently gained popularity because of their\napplicability in resource-poor languages. Moreover, they compactly represent a\nlanguage using a fixed size vocabulary and can efficiently handle unseen or\nrare words. On the other hand, language-specific tokenisation (LST) methods\nhave a long and established history, and are developed using carefully created\nlexicons and training resources. Unlike subtokens produced by LIT methods, LST\nmethods produce valid morphological subwords. Despite the contrasting\ntrade-offs between LIT vs. LST methods, their performance on downstream NLP\ntasks remain unclear. In this paper, we empirically compare the two approaches\nusing semantic similarity measurement as an evaluation task across a diverse\nset of languages. Our experimental results covering eight languages show that\nLST consistently outperforms LIT when the vocabulary size is large, but LIT can\nproduce comparable or better results than LST in many languages with\ncomparatively smaller (i.e. less than 100K words) vocabulary sizes, encouraging\nthe use of LIT when language-specific resources are unavailable, incomplete or\na smaller model is required. Moreover, we find that smoothed inverse frequency\n(SIF) to be an accurate method to create word embeddings from subword\nembeddings for multilingual semantic similarity prediction tasks. Further\nanalysis of the nearest neighbours of tokens show that semantically and\nsyntactically related tokens are closely embedded in subword embedding spaces\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:24:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bollegala", "Danushka", ""], ["Kiryo", "Ryuichi", ""], ["Tsujino", "Kosuke", ""], ["Yukawa", "Haruki", ""]]}, {"id": "2002.11023", "submitter": "Carlos Bobed", "authors": "Mar\\'ia G. Buey and Carlos Bobed and Jorge Gracia and Eduardo Mena", "title": "Semantic Relatedness for Keyword Disambiguation: Exploiting Different\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of words is crucial for many tasks that involve\nhuman-machine interaction. This has been tackled by research in Word Sense\nDisambiguation (WSD) in the Natural Language Processing (NLP) field. Recently,\nWSD and many other NLP tasks have taken advantage of embeddings-based\nrepresentation of words, sentences, and documents. However, when it comes to\nWSD, most embeddings models suffer from ambiguity as they do not capture the\ndifferent possible meanings of the words. Even when they do, the list of\npossible meanings for a word (sense inventory) has to be known in advance at\ntraining time to be included in the embeddings space. Unfortunately, there are\nsituations in which such a sense inventory is not known in advance (e.g., an\nontology selected at run-time), or it evolves with time and its status diverges\nfrom the one at training time. This hampers the use of embeddings models for\nWSD. Furthermore, traditional WSD techniques do not perform well in situations\nin which the available linguistic information is very scarce, such as the case\nof keyword-based queries. In this paper, we propose an approach to keyword\ndisambiguation which grounds on a semantic relatedness between words and senses\nprovided by an external inventory (ontology) that is not known at training\ntime. Building on previous works, we present a semantic relatedness measure\nthat uses word embeddings, and explore different disambiguation algorithms to\nalso exploit both word and sentence representations. Experimental results show\nthat this approach achieves results comparable with the state of the art when\napplied for WSD, without training for a particular domain.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:44:50 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Buey", "Mar\u00eda G.", ""], ["Bobed", "Carlos", ""], ["Gracia", "Jorge", ""], ["Mena", "Eduardo", ""]]}, {"id": "2002.11102", "submitter": "Boyi Li", "authors": "Boyi Li and Felix Wu and Ser-Nam Lim and Serge Belongie and Kilian Q.\n  Weinberger", "title": "On Feature Normalization and Data Augmentation", "comments": "CVPR 2021. Code is available at https://github.com/Boyiliee/MoEx", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moments (a.k.a., mean and standard deviation) of latent features are\noften removed as noise when training image recognition models, to increase\nstability and reduce training time. However, in the field of image generation,\nthe moments play a much more central role. Studies have shown that the moments\nextracted from instance normalization and positional normalization can roughly\ncapture style and shape information of an image. Instead of being discarded,\nthese moments are instrumental to the generation process. In this paper we\npropose Moment Exchange, an implicit data augmentation method that encourages\nthe model to utilize the moment information also for recognition models.\nSpecifically, we replace the moments of the learned features of one training\nimage by those of another, and also interpolate the target labels -- forcing\nthe model to extract training signal from the moments in addition to the\nnormalized features. As our approach is fast, operates entirely in feature\nspace, and mixes different signals than prior methods, one can effectively\ncombine it with existing augmentation approaches. We demonstrate its efficacy\nacross several recognition benchmark data sets where it improves the\ngeneralization capability of highly competitive baseline networks with\nremarkable consistency.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:59:05 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:59:02 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 18:00:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Li", "Boyi", ""], ["Wu", "Felix", ""], ["Lim", "Ser-Nam", ""], ["Belongie", "Serge", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.11143", "submitter": "Debanjan Chaudhuri", "authors": "Rostislav Nedelchev, Debanjan Chaudhuri, Jens Lehmann and Asja Fischer", "title": "End-to-End Entity Linking and Disambiguation leveraging Word and\n  Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking - connecting entity mentions in a natural language utterance\nto knowledge graph (KG) entities is a crucial step for question answering over\nKGs. It is often based on measuring the string similarity between the entity\nlabel and its mention in the question. The relation referred to in the question\ncan help to disambiguate between entities with the same label. This can be\nmisleading if an incorrect relation has been identified in the relation linking\nstep. However, an incorrect relation may still be semantically similar to the\nrelation in which the correct entity forms a triple within the KG; which could\nbe captured by the similarity of their KG embeddings. Based on this idea, we\npropose the first end-to-end neural network approach that employs KG as well as\nword embeddings to perform joint relation and entity classification of simple\nquestions while implicitly performing entity disambiguation with the help of a\nnovel gating mechanism. An empirical evaluation shows that the proposed\napproach achieves a performance comparable to state-of-the-art entity linking\nwhile requiring less post-processing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:07:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Nedelchev", "Rostislav", ""], ["Chaudhuri", "Debanjan", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "2002.11213", "submitter": "Edresson Casanova", "authors": "Edresson Casanova, Arnaldo Candido Junior, Christopher Shulby,\n  Frederico Santos de Oliveira, Lucas Rafael Stefanel Gris, Hamilton Pereira da\n  Silva, Sandra Maria Aluisio, Moacir Antonelli Ponti", "title": "Speech2Phone: A Novel and Efficient Method for Training Speaker\n  Recognition Models", "comments": "Submitted to BRACIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an efficient method for training models for speaker\nrecognition using small or under-resourced datasets. This method requires less\ndata than other SOTA (State-Of-The-Art) methods, e.g. the Angular Prototypical\nand GE2E loss functions, while achieving similar results to those methods. This\nis done using the knowledge of the reconstruction of a phoneme in the speaker's\nvoice. For this purpose, a new dataset was built, composed of 40 male speakers,\nwho read sentences in Portuguese, totaling approximately 3h. We compare the\nthree best architectures trained using our method to select the best one, which\nis the one with a shallow architecture. Then, we compared this model with the\nSOTA method for the speaker recognition task: the Fast ResNet-34 trained with\napproximately 2,000 hours, using the loss functions Angular Prototypical and\nGE2E. Three experiments were carried out with datasets in different languages.\nAmong these three experiments, our model achieved the second best result in two\nexperiments and the best result in one of them. This highlights the importance\nof our method, which proved to be a great competitor to SOTA speaker\nrecognition models, with 500x less data and a simpler approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 22:59:36 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 21:50:49 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Casanova", "Edresson", ""], ["Junior", "Arnaldo Candido", ""], ["Shulby", "Christopher", ""], ["de Oliveira", "Frederico Santos", ""], ["Gris", "Lucas Rafael Stefanel", ""], ["da Silva", "Hamilton Pereira", ""], ["Aluisio", "Sandra Maria", ""], ["Ponti", "Moacir Antonelli", ""]]}, {"id": "2002.11268", "submitter": "Erik McDermott", "authors": "Erik McDermott, Hasim Sak, Ehsan Variani", "title": "A Density Ratio Approach to Language Model Fusion in End-To-End\n  Automatic Speech Recognition", "comments": "8 pages, 4 figures, presented at 2019 IEEE Automatic Speech\n  Recognition and Understanding Workshop (ASRU 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a density ratio approach to integrating external\nLanguage Models (LMs) into end-to-end models for Automatic Speech Recognition\n(ASR). Applied to a Recurrent Neural Network Transducer (RNN-T) ASR model\ntrained on a given domain, a matched in-domain RNN-LM, and a target domain\nRNN-LM, the proposed method uses Bayes' Rule to define RNN-T posteriors for the\ntarget domain, in a manner directly analogous to the classic hybrid model for\nASR based on Deep Neural Networks (DNNs) or LSTMs in the Hidden Markov Model\n(HMM) framework (Bourlard & Morgan, 1994). The proposed approach is evaluated\nin cross-domain and limited-data scenarios, for which a significant amount of\ntarget domain text data is used for LM training, but only limited (or no)\n{audio, transcript} training data pairs are used to train the RNN-T.\nSpecifically, an RNN-T model trained on paired audio & transcript data from\nYouTube is evaluated for its ability to generalize to Voice Search data. The\nDensity Ratio method was found to consistently outperform the dominant approach\nto LM and end-to-end ASR integration, Shallow Fusion.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:53:42 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:12:12 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 01:40:54 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["McDermott", "Erik", ""], ["Sak", "Hasim", ""], ["Variani", "Ehsan", ""]]}, {"id": "2002.11296", "submitter": "Yi Tay", "authors": "Yi Tay, Dara Bahri, Liu Yang, Donald Metzler, and Da-Cheng Juan", "title": "Sparse Sinkhorn Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Sparse Sinkhorn Attention, a new efficient and sparse method for\nlearning to attend. Our method is based on differentiable sorting of internal\nrepresentations. Concretely, we introduce a meta sorting network that learns to\ngenerate latent permutations over sequences. Given sorted sequences, we are\nthen able to compute quasi-global attention with only local windows, improving\nthe memory efficiency of the attention module. To this end, we propose new\nalgorithmic innovations such as Causal Sinkhorn Balancing and SortCut, a\ndynamic sequence truncation method for tailoring Sinkhorn Attention for\nencoding and/or decoding purposes. Via extensive experiments on algorithmic\nseq2seq sorting, language modeling, pixel-wise image generation, document\nclassification and natural language inference, we demonstrate that our memory\nefficient Sinkhorn Attention method is competitive with vanilla attention and\nconsistently outperforms recently proposed efficient Transformer models such as\nSparse Transformers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:18:01 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tay", "Yi", ""], ["Bahri", "Dara", ""], ["Yang", "Liu", ""], ["Metzler", "Donald", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "2002.11402", "submitter": "Swapnil Jadhav", "authors": "Swapnil Ashok Jadhav", "title": "Detecting Potential Topics In News Using BERT, CRF and Wikipedia", "comments": "6 pages, 5 tables, 1 figure, 2 examples. This is a report based on\n  applied research work conducted at Dailyhunt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a news content distribution platform like Dailyhunt, Named Entity\nRecognition is a pivotal task for building better user recommendation and\nnotification algorithms. Apart from identifying names, locations, organisations\nfrom the news for 13+ Indian languages and use them in algorithms, we also need\nto identify n-grams which do not necessarily fit in the definition of\nNamed-Entity, yet they are important. For example, \"me too movement\", \"beef\nban\", \"alwar mob lynching\". In this exercise, given an English language text,\nwe are trying to detect case-less n-grams which convey important information\nand can be used as topics and/or hashtags for a news. Model is built using\nWikipedia titles data, private English news corpus and BERT-Multilingual\npre-trained model, Bi-GRU and CRF architecture. It shows promising results when\ncompared with industry best Flair, Spacy and Stanford-caseless-NER in terms of\nF1 and especially Recall.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:48:53 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 18:44:07 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Jadhav", "Swapnil Ashok", ""]]}, {"id": "2002.11506", "submitter": "Abhik Jana", "authors": "Abhik Jana, Nikhil Reddy Varimalla and Pawan Goyal", "title": "Using Distributional Thesaurus Embedding for Co-hyponymy Detection", "comments": "Accepted in LREC 2020. arXiv admin note: text overlap with\n  arXiv:1802.04609", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating lexical relations among distributionally similar words has\nalways been a challenge for natural language processing (NLP) community. In\nthis paper, we investigate whether the network embedding of distributional\nthesaurus can be effectively utilized to detect co-hyponymy relations. By\nextensive experiments over three benchmark datasets, we show that the vector\nrepresentation obtained by applying node2vec on distributional thesaurus\noutperforms the state-of-the-art models for binary classification of\nco-hyponymy vs. hypernymy, as well as co-hyponymy vs. meronymy, by huge\nmargins.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:11:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Jana", "Abhik", ""], ["Varimalla", "Nikhil Reddy", ""], ["Goyal", "Pawan", ""]]}, {"id": "2002.11566", "submitter": "Ziqi Zhang", "authors": "Ziqi Zhang, Yaya Shi, Chunfeng Yuan, Bing Li, Peijin Wang, Weiming Hu,\n  Zhengjun Zha", "title": "Object Relational Graph with Teacher-Recommended Learning for Video\n  Captioning", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking full advantage of the information from both vision and language is\ncritical for the video captioning task. Existing models lack adequate visual\nrepresentation due to the neglect of interaction between object, and sufficient\ntraining for content-related words due to long-tailed problems. In this paper,\nwe propose a complete video captioning system including both a novel model and\nan effective training strategy. Specifically, we propose an object relational\ngraph (ORG) based encoder, which captures more detailed interaction features to\nenrich visual representation. Meanwhile, we design a teacher-recommended\nlearning (TRL) method to make full use of the successful external language\nmodel (ELM) to integrate the abundant linguistic knowledge into the caption\nmodel. The ELM generates more semantically similar word proposals which extend\nthe ground-truth words used for training to deal with the long-tailed problem.\nExperimental evaluations on three benchmarks: MSVD, MSR-VTT and VATEX show the\nproposed ORG-TRL system achieves state-of-the-art performance. Extensive\nablation studies and visualizations illustrate the effectiveness of our system.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:34:52 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Zhang", "Ziqi", ""], ["Shi", "Yaya", ""], ["Yuan", "Chunfeng", ""], ["Li", "Bing", ""], ["Wang", "Peijin", ""], ["Hu", "Weiming", ""], ["Zha", "Zhengjun", ""]]}, {"id": "2002.11623", "submitter": "Muhidin Mohamed", "authors": "Muhidin Mohamed, Philip Weber", "title": "Trends of digitalization and adoption of big data & analytics among UK\n  SMEs: Analysis and lessons drawn from a case study of 53 SMEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small and Medium Enterprises (SMEs) now generate digital data at an\nunprecedented rate from online transactions, social media marketing and\nassociated customer interactions, online product or service reviews and\nfeedback, clinical diagnosis, Internet of Things (IoT) sensors, and production\nprocesses. All these forms of data can be transformed into monetary value if\nput into a proper data value chain. This requires both skills and IT\ninvestments for the long-term benefit of businesses. However, such spending is\nbeyond the capacity of most SMEs due to their limited resources and restricted\naccess to finances. This paper presents lessons learned from a case study of 53\nUK SMEs, mostly from the West Midlands region of England, supported as part of\na 3-year ERDF project, Big Data Corridor, in the areas of big data management,\nanalytics and related IT issues. Based on our study's sample companies, several\nperspectives including the digital technology trends, challenges facing the UK\nSMEs, and the state of their adoption in data analytics and big data, are\npresented in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:51:24 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 10:10:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Mohamed", "Muhidin", ""], ["Weber", "Philip", ""]]}, {"id": "2002.11643", "submitter": "Swapnil Jadhav", "authors": "Swapnil Ashok Jadhav", "title": "Marathi To English Neural Machine Translation With Near Perfect Corpus\n  And Transformers", "comments": "5 pages, 5 tables. This report is based on applied research work done\n  at Dailyhunt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been very few attempts to benchmark performances of\nstate-of-the-art algorithms for Neural Machine Translation task on Indian\nLanguages. Google, Bing, Facebook and Yandex are some of the very few companies\nwhich have built translation systems for few of the Indian Languages. Among\nthem, translation results from Google are supposed to be better, based on\ngeneral inspection. Bing-Translator do not even support Marathi language which\nhas around 95 million speakers and ranks 15th in the world in terms of combined\nprimary and secondary speakers. In this exercise, we trained and compared\nvariety of Neural Machine Marathi to English Translators trained with\nBERT-tokenizer by huggingface and various Transformer based architectures using\nFacebook's Fairseq platform with limited but almost correct parallel corpus to\nachieve better BLEU scores than Google on Tatoeba and Wikimedia open datasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:18:49 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Jadhav", "Swapnil Ashok", ""]]}, {"id": "2002.11768", "submitter": "Maximilian Wolff", "authors": "Max Wolff, Stuart Wolff", "title": "Attacking Neural Text Detectors", "comments": "Accepted at the ICLR 2020 workshop \"Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based language models have recently made significant\nprogress, which introduces a danger to spread misinformation. To combat this\npotential danger, several methods have been proposed for detecting text written\nby these language models. This paper presents two classes of black-box attacks\non these detectors, one which randomly replaces characters with homoglyphs, and\nthe other a simple scheme to purposefully misspell words. The homoglyph and\nmisspelling attacks decrease a popular neural text detector's recall on neural\ntext from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that\nthe attacks are transferable to other neural text detectors.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 04:18:45 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 07:08:21 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 05:15:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wolff", "Max", ""], ["Wolff", "Stuart", ""]]}, {"id": "2002.11781", "submitter": "Xinjian Li", "authors": "Xinjian Li, Siddharth Dalmia, David R. Mortensen, Juncheng Li, Alan W\n  Black, Florian Metze", "title": "Towards Zero-shot Learning for Automatic Phonemic Transcription", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic phonemic transcription tools are useful for low-resource language\ndocumentation. However, due to the lack of training sets, only a tiny fraction\nof languages have phonemic transcription tools. Fortunately, multilingual\nacoustic modeling provides a solution given limited audio training data. A more\nchallenging problem is to build phonemic transcribers for languages with zero\ntraining data. The difficulty of this task is that phoneme inventories often\ndiffer between the training languages and the target language, making it\ninfeasible to recognize unseen phonemes. In this work, we address this problem\nby adopting the idea of zero-shot learning. Our model is able to recognize\nunseen phonemes in the target language without any training data. In our model,\nwe decompose phonemes into corresponding articulatory attributes such as vowel\nand consonant. Instead of predicting phonemes directly, we first predict\ndistributions over articulatory attributes, and then compute phoneme\ndistributions with a customized acoustic model. We evaluate our model by\ntraining it using 13 languages and testing it using 7 unseen languages. We find\nthat it achieves 7.7% better phoneme error rate on average over a standard\nmultilingual model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 20:38:42 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Li", "Xinjian", ""], ["Dalmia", "Siddharth", ""], ["Mortensen", "David R.", ""], ["Li", "Juncheng", ""], ["Black", "Alan W", ""], ["Metze", "Florian", ""]]}, {"id": "2002.11794", "submitter": "Eric Wallace", "authors": "Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, Kurt Keutzer, Dan\n  Klein, Joseph E. Gonzalez", "title": "Train Large, Then Compress: Rethinking Model Size for Efficient Training\n  and Inference of Transformers", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since hardware resources are limited, the objective of training deep learning\nmodels is typically to maximize accuracy subject to the time and memory\nconstraints of training and inference. We study the impact of model size in\nthis setting, focusing on Transformer models for NLP tasks that are limited by\ncompute: self-supervised pretraining and high-resource machine translation. We\nfirst show that even though smaller Transformer models execute faster per\niteration, wider and deeper models converge in significantly fewer steps.\nMoreover, this acceleration in convergence typically outpaces the additional\ncomputational overhead of using larger models. Therefore, the most\ncompute-efficient training strategy is to counterintuitively train extremely\nlarge models but stop after a small number of iterations.\n  This leads to an apparent trade-off between the training efficiency of large\nTransformer models and the inference efficiency of small Transformer models.\nHowever, we show that large models are more robust to compression techniques\nsuch as quantization and pruning than small models. Consequently, one can get\nthe best of both worlds: heavily compressed, large models achieve higher\naccuracy than lightly compressed, small models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:17:13 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 00:23:39 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Zhuohan", ""], ["Wallace", "Eric", ""], ["Shen", "Sheng", ""], ["Lin", "Kevin", ""], ["Keutzer", "Kurt", ""], ["Klein", "Dan", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2002.11800", "submitter": "Xinjian Li", "authors": "Xinjian Li, Siddharth Dalmia, Juncheng Li, Matthew Lee, Patrick\n  Littell, Jiali Yao, Antonios Anastasopoulos, David R. Mortensen, Graham\n  Neubig, Alan W Black, Florian Metze", "title": "Universal Phone Recognition with a Multilingual Allophone System", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual models can improve language processing, particularly for low\nresource situations, by sharing parameters across languages. Multilingual\nacoustic models, however, generally ignore the difference between phonemes\n(sounds that can support lexical contrasts in a particular language) and their\ncorresponding phones (the sounds that are actually spoken, which are language\nindependent). This can lead to performance degradation when combining a variety\nof training languages, as identically annotated phonemes can actually\ncorrespond to several different underlying phonetic realizations. In this work,\nwe propose a joint model of both language-independent phone and\nlanguage-dependent phoneme distributions. In multilingual ASR experiments over\n11 languages, we find that this model improves testing performance by 2%\nphoneme error rate absolute in low-resource conditions. Additionally, because\nwe are explicitly modeling language-independent phones, we can build a\n(nearly-)universal phone recognizer that, when combined with the PHOIBLE large,\nmanually curated database of phone inventories, can be customized into 2,000\nlanguage dependent recognizers. Experiments on two low-resourced indigenous\nlanguages, Inuktitut and Tusom, show that our recognizer achieves phone\naccuracy improvements of more than 17%, moving a step closer to speech\nrecognition for all languages in the world.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:28:57 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Li", "Xinjian", ""], ["Dalmia", "Siddharth", ""], ["Li", "Juncheng", ""], ["Lee", "Matthew", ""], ["Littell", "Patrick", ""], ["Yao", "Jiali", ""], ["Anastasopoulos", "Antonios", ""], ["Mortensen", "David R.", ""], ["Neubig", "Graham", ""], ["Black", "Alan W", ""], ["Metze", "Florian", ""]]}, {"id": "2002.11847", "submitter": "Ankush Garg", "authors": "Ankush Garg, Yuan Cao, and Qi Ge", "title": "Echo State Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present neural machine translation (NMT) models inspired by echo state\nnetwork (ESN), named Echo State NMT (ESNMT), in which the encoder and decoder\nlayer weights are randomly generated then fixed throughout training. We show\nthat even with this extremely simple model construction and training procedure,\nESNMT can already reach 70-80% quality of fully trainable baselines. We examine\nhow spectral radius of the reservoir, a key quantity that characterizes the\nmodel, determines the model behavior. Our findings indicate that randomized\nnetworks can work well even for complicated sequence-to-sequence prediction NLP\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:08:45 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Garg", "Ankush", ""], ["Cao", "Yuan", ""], ["Ge", "Qi", ""]]}, {"id": "2002.11848", "submitter": "Ruotian Luo", "authors": "Ruotian Luo, Gregory Shakhnarovich", "title": "Analysis of diversity-accuracy tradeoff in image captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of different model architectures, training\nobjectives, hyperparameter settings and decoding procedures on the diversity of\nautomatically generated image captions. Our results show that 1) simple\ndecoding by naive sampling, coupled with low temperature is a competitive and\nfast method to produce diverse and accurate caption sets; 2) training with\nCIDEr-based reward using Reinforcement learning harms the diversity properties\nof the resulting generator, which cannot be mitigated by manipulating decoding\nparameters. In addition, we propose a new metric AllSPICE for evaluating both\naccuracy and diversity of a set of captions by a single value.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:09:25 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Luo", "Ruotian", ""], ["Shakhnarovich", "Gregory", ""]]}, {"id": "2002.11893", "submitter": "Qi Zhu", "authors": "Qi Zhu, Kaili Huang, Zheng Zhang, Xiaoyan Zhu, Minlie Huang", "title": "CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue\n  Dataset", "comments": "Accepted by TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To advance multi-domain (cross-domain) dialogue modeling as well as alleviate\nthe shortage of Chinese task-oriented datasets, we propose CrossWOZ, the first\nlarge-scale Chinese Cross-Domain Wizard-of-Oz task-oriented dataset. It\ncontains 6K dialogue sessions and 102K utterances for 5 domains, including\nhotel, restaurant, attraction, metro, and taxi. Moreover, the corpus contains\nrich annotation of dialogue states and dialogue acts at both user and system\nsides. About 60% of the dialogues have cross-domain user goals that favor\ninter-domain dependency and encourage natural transition across domains in\nconversation. We also provide a user simulator and several benchmark models for\npipelined task-oriented dialogue systems, which will facilitate researchers to\ncompare and evaluate their models on this corpus. The large size and rich\nannotation of CrossWOZ make it suitable to investigate a variety of tasks in\ncross-domain dialogue modeling, such as dialogue state tracking, policy\nlearning, user simulation, etc.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:06:35 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 06:04:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhu", "Qi", ""], ["Huang", "Kaili", ""], ["Zhang", "Zheng", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2002.11910", "submitter": "Zhaoheng Gong", "authors": "Zhaoheng Gong, Ping Chen, Jiang Zhou", "title": "Integrating Boundary Assembling into a DNN Framework for Named Entity\n  Recognition in Chinese Social Media Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition is a challenging task in Natural Language\nProcessing, especially for informal and noisy social media text. Chinese word\nboundaries are also entity boundaries, therefore, named entity recognition for\nChinese text can benefit from word boundary detection, outputted by Chinese\nword segmentation. Yet Chinese word segmentation poses its own difficulty\nbecause it is influenced by several factors, e.g., segmentation criteria,\nemployed algorithm, etc. Dealt improperly, it may generate a cascading failure\nto the quality of named entity recognition followed. In this paper we integrate\na boundary assembling method with the state-of-the-art deep neural network\nmodel, and incorporate the updated word boundary information into a conditional\nrandom field model for named entity recognition. Our method shows a 2% absolute\nimprovement over previous state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:29:13 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Gong", "Zhaoheng", ""], ["Chen", "Ping", ""], ["Zhou", "Jiang", ""]]}, {"id": "2002.12005", "submitter": "Zhenisbek Assylbekov", "authors": "Zhenisbek Assylbekov and Alibi Jangeldin", "title": "Squashed Shifted PMI Matrix: Bridging Word Embeddings and Hyperbolic\n  Spaces", "comments": "AJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that removing sigmoid transformation in the skip-gram with negative\nsampling (SGNS) objective does not harm the quality of word vectors\nsignificantly and at the same time is related to factorizing a squashed shifted\nPMI matrix which, in turn, can be treated as a connection probabilities matrix\nof a random graph. Empirically, such graph is a complex network, i.e. it has\nstrong clustering and scale-free degree distribution, and is tightly connected\nwith hyperbolic spaces. In short, we show the connection between static word\nembeddings and hyperbolic spaces through the squashed shifted PMI matrix using\nanalytical and empirical methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:50:41 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 15:06:00 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Assylbekov", "Zhenisbek", ""], ["Jangeldin", "Alibi", ""]]}, {"id": "2002.12097", "submitter": "Ayan Das", "authors": "Ayan Das and Sudeshna Sarkar", "title": "Improving cross-lingual model transfer by chunking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a shallow parser guided cross-lingual model transfer approach in\norder to address the syntactic differences between source and target languages\nmore effectively. In this work, we assume the chunks or phrases in a sentence\nas transfer units in order to address the syntactic differences between the\nsource and target languages arising due to the differences in ordering of words\nin the phrases and the ordering of phrases in a sentence separately.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 14:02:31 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Das", "Ayan", ""], ["Sarkar", "Sudeshna", ""]]}, {"id": "2002.12196", "submitter": "Aniruddha Uttam Tammewar", "authors": "Aniruddha Tammewar, Alessandra Cervone, Eva-Maria Messner, Giuseppe\n  Riccardi", "title": "Annotation of Emotion Carriers in Personal Narratives", "comments": "published in LREC 2020\n  http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.188.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of understanding personal narratives (PN) -\nspoken or written - recollections of facts, events, and thoughts. In PN,\nemotion carriers are the speech or text segments that best explain the\nemotional state of the user. Such segments may include entities, verb or noun\nphrases. Advanced automatic understanding of PNs requires not only the\nprediction of the user emotional state but also to identify which events (e.g.\n\"the loss of relative\" or \"the visit of grandpa\") or people ( e.g. \"the old\ngroup of high school mates\") carry the emotion manifested during the personal\nrecollection. This work proposes and evaluates an annotation model for\nidentifying emotion carriers in spoken personal narratives. Compared to other\ntext genres such as news and microblogs, spoken PNs are particularly\nchallenging because a narrative is usually unstructured, involving multiple\nsub-events and characters as well as thoughts and associated emotions perceived\nby the narrator. In this work, we experiment with annotating emotion carriers\nfrom speech transcriptions in the Ulm State-of-Mind in Speech (USoMS) corpus, a\ndataset of German PNs. We believe this resource could be used for experiments\nin the automatic extraction of emotion carriers from PN, a task that could\nprovide further advancements in narrative understanding.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:42:39 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:11:09 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 19:52:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Cervone", "Alessandra", ""], ["Messner", "Eva-Maria", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "2002.12231", "submitter": "Arya D. McCarthy", "authors": "Arya D. McCarthy and Liezl Puzon and Juan Pino", "title": "SkinAugment: Auto-Encoding Speaker Conversions for Automatic Speech\n  Translation", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose autoencoding speaker conversion for training data augmentation in\nautomatic speech translation. This technique directly transforms an audio\nsequence, resulting in audio synthesized to resemble another speaker's voice.\nOur method compares favorably to SpecAugment on English$\\to$French and\nEnglish$\\to$Romanian automatic speech translation (AST) tasks as well as on a\nlow-resource English automatic speech recognition (ASR) task. Further, in\nablations, we show the benefits of both quantity and diversity in augmented\ndata. Finally, we show that we can combine our approach with augmentation by\nmachine-translated transcripts to obtain a competitive end-to-end AST model\nthat outperforms a very strong cascade model on an English$\\to$French AST task.\nOur method is sufficiently general that it can be applied to other speech\ngeneration and analysis tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:22:42 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["McCarthy", "Arya D.", ""], ["Puzon", "Liezl", ""], ["Pino", "Juan", ""]]}, {"id": "2002.12327", "submitter": "Olga Kovaleva", "authors": "Anna Rogers, Olga Kovaleva, Anna Rumshisky", "title": "A Primer in BERTology: What we know about how BERT works", "comments": "Accepted to TACL. Please note that the multilingual BERT section is\n  only available in version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have pushed state of the art in many areas of NLP,\nbut our understanding of what is behind their success is still limited. This\npaper is the first survey of over 150 studies of the popular BERT model. We\nreview the current state of knowledge about how BERT works, what kind of\ninformation it learns and how it is represented, common modifications to its\ntraining objectives and architecture, the overparameterization issue and\napproaches to compression. We then outline directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:46:42 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 22:01:57 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 15:33:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Rogers", "Anna", ""], ["Kovaleva", "Olga", ""], ["Rumshisky", "Anna", ""]]}, {"id": "2002.12328", "submitter": "Baolin Peng", "authors": "Baolin Peng, Chenguang Zhu, Chunyuan Li, Xiujun Li, Jinchao Li,\n  Michael Zeng, and Jianfeng Gao", "title": "Few-shot Natural Language Generation for Task-Oriented Dialog", "comments": "Project website: https://aka.ms/scgpt ; Code and data:\n  https://github.com/pengbaolin/SC-GPT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a crucial component in task-oriented dialog systems, the Natural Language\nGeneration (NLG) module converts a dialog act represented in a semantic form\ninto a response in natural language. The success of traditional template-based\nor statistical models typically relies on heavily annotated data, which is\ninfeasible for new domains. Therefore, it is pivotal for an NLG system to\ngeneralize well with limited labelled data in real applications. To this end,\nwe present FewShotWoz, the first NLG benchmark to simulate the few-shot\nlearning setting in task-oriented dialog systems. Further, we develop the\nSC-GPT model. It is pre-trained on a large set of annotated NLG corpus to\nacquire the controllable generation ability, and fine-tuned with only a few\ndomain-specific labels to adapt to new domains. Experiments on FewShotWoz and\nthe large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly\noutperforms existing methods, measured by various automatic metrics and human\nevaluations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:48:33 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Peng", "Baolin", ""], ["Zhu", "Chenguang", ""], ["Li", "Chunyuan", ""], ["Li", "Xiujun", ""], ["Li", "Jinchao", ""], ["Zeng", "Michael", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2002.12344", "submitter": "Christopher Malon", "authors": "Christopher Malon and Bing Bai", "title": "Generating Followup Questions for Interpretable Multi-hop Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a framework for answering open domain multi-hop questions in which\npartial information is read and used to generate followup questions, to finally\nbe answered by a pretrained single-hop answer extractor. This framework makes\neach hop interpretable, and makes the retrieval associated with later hops as\nflexible and specific as for the first hop. As a first instantiation of this\nframework, we train a pointer-generator network to predict followup questions\nbased on the question and partial information. This provides a novel\napplication of a neural question generation network, which is applied to give\nweak ground truth single-hop followup questions based on the final answers and\ntheir supporting facts. Learning to generate followup questions that select the\nrelevant answer spans against downstream supporting facts, while avoiding\ndistracting premises, poses an exciting semantic challenge for text generation.\nWe present an evaluation using the two-hop bridge questions of HotpotQA.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:58:15 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Malon", "Christopher", ""], ["Bai", "Bing", ""]]}, {"id": "2002.12457", "submitter": "Curtis Northcutt", "authors": "Curtis G. Northcutt, Kimberly A. Leon, Naichun Chen", "title": "Comment Ranking Diversification in Forum Discussions", "comments": "5 pages, 7 figures, published in Learning @ Scale, 2017", "journal-ref": "Proceedings of the Sixth {ACM} Conference on Learning @ Scale, L@S\n  2017", "doi": "10.1145/3051457.3054016", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Viewing consumption of discussion forums with hundreds or more comments\ndepends on ranking because most users only view top-ranked comments. When\ncomments are ranked by an ordered score (e.g. number of replies or up-votes)\nwithout adjusting for semantic similarity of near-ranked comments, top-ranked\ncomments are more likely to emphasize the majority opinion and incur\nredundancy. In this paper, we propose a top K comment diversification\nre-ranking model using Maximal Marginal Relevance (MMR) and evaluate its impact\nin three categories: (1) semantic diversity, (2) inclusion of the semantics of\nlower-ranked comments, and (3) redundancy, within the context of a HarvardX\ncourse discussion forum. We conducted a double-blind, small-scale evaluation\nexperiment requiring subjects to select between the top 5 comments of a\ndiversified ranking and a baseline ranking ordered by score. For three\nsubjects, across 100 trials, subjects selected the diversified (75% score, 25%\ndiversification) ranking as significantly (1) more diverse, (2) more inclusive,\nand (3) less redundant. Within each category, inter-rater reliability showed\nmoderate consistency, with typical Cohen-Kappa scores near 0.2. Our findings\nsuggest that our model improves (1) diversification, (2) inclusion, and (3)\nredundancy, among top K ranked comments in online discussion forums.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:44:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Northcutt", "Curtis G.", ""], ["Leon", "Kimberly A.", ""], ["Chen", "Naichun", ""]]}, {"id": "2002.12530", "submitter": "Furao Shen", "authors": "Hongyan Hao, Yan Wang, Yudi Xia, Jian Zhao, Furao Shen", "title": "Temporal Convolutional Attention-based Network For Sequence Modeling", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of feed-forward models, the default model for sequence\nmodeling has gradually evolved to replace recurrent networks. Many powerful\nfeed-forward models based on convolutional networks and attention mechanism\nwere proposed and show more potential to handle sequence modeling tasks. We\nwonder that is there an architecture that can not only achieve an approximate\nsubstitution of recurrent network, but also absorb the advantages of\nfeed-forward models. So we propose an exploratory architecture referred to\nTemporal Convolutional Attention-based Network (TCAN) which combines temporal\nconvolutional network and attention mechanism. TCAN includes two parts, one is\nTemporal Attention (TA) which captures relevant features inside the sequence,\nthe other is Enhanced Residual (ER) which extracts shallow layer's important\ninformation and transfers to deep layers. We improve the state-of-the-art\nresults of bpc/perplexity to 26.92 on word-level PTB, 1.043 on character-level\nPTB, and 6.66 on WikiText-2.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 03:53:31 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:16:05 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Hao", "Hongyan", ""], ["Wang", "Yan", ""], ["Xia", "Yudi", ""], ["Zhao", "Jian", ""], ["Shen", "Furao", ""]]}, {"id": "2002.12540", "submitter": "Ali Septiandri", "authors": "Ali Akbar Septiandri, Yosef Ardhito Winatmoko", "title": "UKARA 1.0 Challenge Track 1: Automatic Short-Answer Scoring in Bahasa\n  Indonesia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe our third-place solution to the UKARA 1.0 challenge on automated\nessay scoring. The task consists of a binary classification problem on two\ndatasets | answers from two different questions. We ended up using two\ndifferent models for the two datasets. For task A, we applied a random forest\nalgorithm on features extracted using unigram with latent semantic analysis\n(LSA). On the other hand, for task B, we only used logistic regression on\nTF-IDF features. Our model results in F1 score of 0.812.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 04:32:16 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Septiandri", "Ali Akbar", ""], ["Winatmoko", "Yosef Ardhito", ""]]}, {"id": "2002.12549", "submitter": "Haipeng Sun", "authors": "Haipeng Sun, Rui Wang, Kehai Chen, Xugang Lu, Masao Utiyama, Eiichiro\n  Sumita, and Tiejun Zhao", "title": "Robust Unsupervised Neural Machine Translation with Adversarial\n  Denoising Training", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised neural machine translation (UNMT) has recently attracted great\ninterest in the machine translation community. The main advantage of the UNMT\nlies in its easy collection of required large training text sentences while\nwith only a slightly worse performance than supervised neural machine\ntranslation which requires expensive annotated translation pairs on some\ntranslation tasks. In most studies, the UMNT is trained with clean data without\nconsidering its robustness to the noisy data. However, in real-world scenarios,\nthere usually exists noise in the collected input sentences which degrades the\nperformance of the translation system since the UNMT is sensitive to the small\nperturbations of the input sentences. In this paper, we first time explicitly\ntake the noisy data into consideration to improve the robustness of the UNMT\nbased systems. First of all, we clearly defined two types of noises in training\nsentences, i.e., word noise and word order noise, and empirically investigate\nits effect in the UNMT, then we propose adversarial training methods with\ndenoising process in the UNMT. Experimental results on several language pairs\nshow that our proposed methods substantially improved the robustness of the\nconventional UNMT systems in noisy scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:17:55 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 03:19:36 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Sun", "Haipeng", ""], ["Wang", "Rui", ""], ["Chen", "Kehai", ""], ["Lu", "Xugang", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2002.12558", "submitter": "Chaoqun Duan", "authors": "Chaoqun Duan, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita,\n  Conghui Zhu and Tiejun Zhao", "title": "Modeling Future Cost for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural machine translation (NMT) systems utilize\nsequence-to-sequence neural networks to generate target translation word by\nword, and then make the generated word at each time-step and the counterpart in\nthe references as consistent as possible. However, the trained translation\nmodel tends to focus on ensuring the accuracy of the generated target word at\nthe current time-step and does not consider its future cost which means the\nexpected cost of generating the subsequent target translation (i.e., the next\ntarget word). To respond to this issue, we propose a simple and effective\nmethod to model the future cost of each target word for NMT systems. In detail,\na time-dependent future cost is estimated based on the current generated target\nword and its contextual information to boost the training of the NMT model.\nFurthermore, the learned future context representation at the current time-step\nis used to help the generation of the next target word in the decoding.\nExperimental results on three widely-used translation datasets, including the\nWMT14 German-to-English, WMT14 English-to-French, and WMT17 Chinese-to-English,\nshow that the proposed approach achieves significant improvements over strong\nTransformer-based NMT baseline.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:37:06 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Duan", "Chaoqun", ""], ["Chen", "Kehai", ""], ["Wang", "Rui", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2002.12570", "submitter": "Yoichi Sasaki", "authors": "Yoichi Sasaki, Kosuke Akimoto, Takanori Maehara", "title": "Learning Directly from Grammar Compressed Text", "comments": "12 pages, 4 Postscript figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks using numerous text data have been successfully applied to a\nvariety of tasks. While massive text data is usually compressed using\ntechniques such as grammar compression, almost all of the previous machine\nlearning methods assume already decompressed sequence data as their input. In\nthis paper, we propose a method to directly apply neural sequence models to\ntext data compressed with grammar compression algorithms without decompression.\nTo encode the unique symbols that appear in compression rules, we introduce\ncomposer modules to incrementally encode the symbols into vector\nrepresentations. Through experiments on real datasets, we empirically showed\nthat the proposal model can achieve both memory and computational efficiency\nwhile maintaining moderate performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 06:51:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sasaki", "Yoichi", ""], ["Akimoto", "Kosuke", ""], ["Maehara", "Takanori", ""]]}, {"id": "2002.12585", "submitter": "Fenglin Liu", "authors": "Fenglin Liu, Xuancheng Ren, Yuanxin Liu, Kai Lei and Xu Sun", "title": "Exploring and Distilling Cross-Modal Information for Image Captioning", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, attention-based encoder-decoder models have been used extensively\nin image captioning. Yet there is still great difficulty for the current\nmethods to achieve deep image understanding. In this work, we argue that such\nunderstanding requires visual attention to correlated image regions and\nsemantic attention to coherent attributes of interest. Based on the\nTransformer, to perform effective attention, we explore image captioning from a\ncross-modal perspective and propose the Global-and-Local Information\nExploring-and-Distilling approach that explores and distills the source\ninformation in vision and language. It globally provides the aspect vector, a\nspatial and relational representation of images based on caption contexts,\nthrough the extraction of salient region groupings and attribute collocations,\nand locally extracts the fine-grained regions and attributes in reference to\nthe aspect vector for word selection. Our Transformer-based model achieves a\nCIDEr score of 129.3 in offline COCO evaluation on the COCO testing set with\nremarkable efficiency in terms of accuracy, speed, and parameter budget.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 07:46:48 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 11:53:51 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Liu", "Fenglin", ""], ["Ren", "Xuancheng", ""], ["Liu", "Yuanxin", ""], ["Lei", "Kai", ""], ["Sun", "Xu", ""]]}, {"id": "2002.12591", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Ping Nie, Xiubo Geng, Arun Ramamurthy, Le Song, Daxin\n  Jiang", "title": "DC-BERT: Decoupling Question and Document for Efficient Contextual\n  Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on open-domain question answering have achieved prominent\nperformance improvement using pre-trained language models such as BERT.\nState-of-the-art approaches typically follow the \"retrieve and read\" pipeline\nand employ BERT-based reranker to filter retrieved documents before feeding\nthem into the reader module. The BERT retriever takes as input the\nconcatenation of question and each retrieved document. Despite the success of\nthese approaches in terms of QA accuracy, due to the concatenation, they can\nbarely handle high-throughput of incoming questions each with a large\ncollection of retrieved documents. To address the efficiency problem, we\npropose DC-BERT, a decoupled contextual encoding framework that has dual BERT\nmodels: an online BERT which encodes the question only once, and an offline\nBERT which pre-encodes all the documents and caches their encodings. On SQuAD\nOpen and Natural Questions Open datasets, DC-BERT achieves 10x speedup on\ndocument retrieval, while retaining most (about 98%) of the QA performance\ncompared to state-of-the-art approaches for open-domain question answering.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:18:37 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Yuyu", ""], ["Nie", "Ping", ""], ["Geng", "Xiubo", ""], ["Ramamurthy", "Arun", ""], ["Song", "Le", ""], ["Jiang", "Daxin", ""]]}, {"id": "2002.12612", "submitter": "Francesco Pierri", "authors": "Francesco Pierri, Carlo Piccardi, Stefano Ceri", "title": "A multi-layer approach to disinformation detection on Twitter", "comments": "A revised version of this pre-print has been published on EPJ Data\n  Science with the title \"A multi-layer approach to disinformation detection in\n  US and Italian news spreading on Twitter\"", "journal-ref": "Published version on EPJ Data Science (\"A multi-layer approach to\n  disinformation detection in US and Italian news spreading on Twitter\") Dec\n  2020", "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of classifying news articles pertaining to\ndisinformation vs mainstream news by solely inspecting their diffusion\nmechanisms on Twitter. Our technique is inherently simple compared to existing\ntext-based approaches, as it allows to by-pass the multiple levels of\ncomplexity which are found in news content (e.g. grammar, syntax, style). We\nemploy a multi-layer representation of Twitter diffusion networks, and we\ncompute for each layer a set of global network features which quantify\ndifferent aspects of the sharing process. Experimental results with two\nlarge-scale datasets, corresponding to diffusion cascades of news shared\nrespectively in the United States and Italy, show that a simple Logistic\nRegression model is able to classify disinformation vs mainstream networks with\nhigh accuracy (AUROC up to 94%), also when considering the political bias of\ndifferent sources in the classification task. We also highlight differences in\nthe sharing patterns of the two news domains which appear to be\ncountry-independent. We believe that our network-based approach provides useful\ninsights which pave the way to the future development of a system to detect\nmisleading and harmful information spreading on social media.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:25:53 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 08:23:47 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Pierri", "Francesco", ""], ["Piccardi", "Carlo", ""], ["Ceri", "Stefano", ""]]}, {"id": "2002.12620", "submitter": "Yiming Cui", "authors": "Ziqing Yang, Yiming Cui, Zhipeng Chen, Wanxiang Che, Ting Liu, Shijin\n  Wang, Guoping Hu", "title": "TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural\n  Language Processing", "comments": "To appear at ACL 2020 Demo Session", "journal-ref": null, "doi": "10.18653/v1/2020.acl-demos.2", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce TextBrewer, an open-source knowledge distillation\ntoolkit designed for natural language processing. It works with different\nneural network models and supports various kinds of supervised learning tasks,\nsuch as text classification, reading comprehension, sequence labeling.\nTextBrewer provides a simple and uniform workflow that enables quick setting up\nof distillation experiments with highly flexible configurations. It offers a\nset of predefined distillation methods and can be extended with custom code. As\na case study, we use TextBrewer to distill BERT on several typical NLP tasks.\nWith simple configurations, we achieve results that are comparable with or even\nhigher than the public distilled BERT models with similar numbers of\nparameters. Our toolkit is available through: http://textbrewer.hfl-rc.com\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:44:07 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 02:34:38 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Yang", "Ziqing", ""], ["Cui", "Yiming", ""], ["Chen", "Zhipeng", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "2002.12645", "submitter": "Joanna Rownicka", "authors": "Jennifer Williams, Joanna Rownicka, Pilar Oplustil, Simon King", "title": "Comparison of Speech Representations for Automatic Quality Estimation in\n  Multi-Speaker Text-to-Speech Synthesis", "comments": "accepted at Speaker Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to characterize how different speakers contribute to the perceived\noutput quality of multi-speaker Text-to-Speech (TTS) synthesis. We\nautomatically rate the quality of TTS using a neural network (NN) trained on\nhuman mean opinion score (MOS) ratings. First, we train and evaluate our NN\nmodel on 13 different TTS and voice conversion (VC) systems from the ASVSpoof\n2019 Logical Access (LA) Dataset. Since it is not known how best to represent\nspeech for this task, we compare 8 different representations alongside MOSNet\nframe-based features. Our representations include image-based spectrogram\nfeatures and x-vector embeddings that explicitly model different types of noise\nsuch as T60 reverberation time. Our NN predicts MOS with a high correlation to\nhuman judgments. We report prediction correlation and error. A key finding is\nthe quality achieved for certain speakers seems consistent, regardless of the\nTTS or VC system. It is widely accepted that some speakers give higher quality\nthan others for building a TTS system: our method provides an automatic way to\nidentify such speakers. Finally, to see if our quality prediction models\ngeneralize, we predict quality scores for synthetic speech using a separate\nmulti-speaker TTS system that was trained on LibriTTS data, and conduct our own\nMOS listening test to compare human ratings with our NN predictions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:44:32 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 09:25:25 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Williams", "Jennifer", ""], ["Rownicka", "Joanna", ""], ["Oplustil", "Pilar", ""], ["King", "Simon", ""]]}, {"id": "2002.12683", "submitter": "Jie Gao", "authors": "Jie Gao, Sooji Han, Xingyi Song, Fabio Ciravegna", "title": "RP-DNN: A Tweet level propagation context based deep neural networks for\n  early rumor detection in Social Media", "comments": "Manuscript accepted for publication at The LREC 2020 Proceedings. The\n  International Conference on Language Resources and Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Early rumor detection (ERD) on social media platform is very challenging when\nlimited, incomplete and noisy information is available. Most of the existing\nmethods have largely worked on event-level detection that requires the\ncollection of posts relevant to a specific event and relied only on\nuser-generated content. They are not appropriate to detect rumor sources in the\nvery early stages, before an event unfolds and becomes widespread. In this\npaper, we address the task of ERD at the message level. We present a novel\nhybrid neural network architecture, which combines a task-specific\ncharacter-based bidirectional language model and stacked Long Short-Term Memory\n(LSTM) networks to represent textual contents and social-temporal contexts of\ninput source tweets, for modelling propagation patterns of rumors in the early\nstages of their development. We apply multi-layered attention models to jointly\nlearn attentive context embeddings over multiple context inputs. Our\nexperiments employ a stringent leave-one-out cross-validation (LOO-CV)\nevaluation setup on seven publicly available real-life rumor event data sets.\nOur models achieve state-of-the-art(SoA) performance for detecting unseen\nrumors on large augmented data which covers more than 12 events and 2,967\nrumors. An ablation study is conducted to understand the relative contribution\nof each component of our proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 12:44:34 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 10:47:53 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gao", "Jie", ""], ["Han", "Sooji", ""], ["Song", "Xingyi", ""], ["Ciravegna", "Fabio", ""]]}, {"id": "2002.12699", "submitter": "Roman Klinger", "authors": "Valentino Sabbatino and Laura Bostan and Roman Klinger", "title": "Automatic Section Recognition in Obituaries", "comments": "9 pages, 1 figure, accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Obituaries contain information about people's values across times and\ncultures, which makes them a useful resource for exploring cultural history.\nThey are typically structured similarly, with sections corresponding to\nPersonal Information, Biographical Sketch, Characteristics, Family, Gratitude,\nTribute, Funeral Information and Other aspects of the person. To make this\ninformation available for further studies, we propose a statistical model which\nrecognizes these sections. To achieve that, we collect a corpus of 20058\nEnglish obituaries from TheDaily Item, Remembering.CA and The London Free\nPress. The evaluation of our annotation guidelines with three annotators on\n1008 obituaries shows a substantial agreement of Fleiss k = 0.87. Formulated as\nan automatic segmentation task, a convolutional neural network outperforms\nbag-of-words and embedding-based BiLSTMs and BiLSTM-CRFs with a micro F1 =\n0.81.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 13:20:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sabbatino", "Valentino", ""], ["Bostan", "Laura", ""], ["Klinger", "Roman", ""]]}, {"id": "2002.12798", "submitter": "Yida Wang", "authors": "Hongbin Zheng, Sejong Oh, Huiqing Wang, Preston Briggs, Jiading Gai,\n  Animesh Jain, Yizhi Liu, Rich Heaton, Randy Huang, Yida Wang", "title": "Optimizing Memory-Access Patterns for Deep Learning Accelerators", "comments": "Extended abstract for a poster presented at C4ML workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) workloads are moving towards accelerators for faster\nprocessing and lower cost. Modern DL accelerators are good at handling the\nlarge-scale multiply-accumulate operations that dominate DL workloads; however,\nit is challenging to make full use of the compute power of an accelerator since\nthe data must be properly staged in a software-managed scratchpad memory.\nFailing to do so can result in significant performance loss. This paper\nproposes a systematic approach which leverages the polyhedral model to analyze\nall operators of a DL model together to minimize the number of memory accesses.\nExperiments show that our approach can substantially reduce the impact of\nmemory accesses required by common neural-network models on a homegrown AWS\nmachine-learning inference chip named Inferentia, which is available through\nAmazon EC2 Inf1 instances.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 05:06:19 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zheng", "Hongbin", ""], ["Oh", "Sejong", ""], ["Wang", "Huiqing", ""], ["Briggs", "Preston", ""], ["Gai", "Jiading", ""], ["Jain", "Animesh", ""], ["Liu", "Yizhi", ""], ["Heaton", "Rich", ""], ["Huang", "Randy", ""], ["Wang", "Yida", ""]]}, {"id": "2002.12804", "submitter": "Li Dong", "authors": "Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu\n  Wang, Songhao Piao, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon", "title": "UniLMv2: Pseudo-Masked Language Models for Unified Language Model\n  Pre-Training", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to pre-train a unified language model for both autoencoding and\npartially autoregressive language modeling tasks using a novel training\nprocedure, referred to as a pseudo-masked language model (PMLM). Given an input\ntext with masked tokens, we rely on conventional masks to learn inter-relations\nbetween corrupted tokens and context via autoencoding, and pseudo masks to\nlearn intra-relations between masked spans via partially autoregressive\nmodeling. With well-designed position embeddings and self-attention masks, the\ncontext encodings are reused to avoid redundant computation. Moreover,\nconventional masks used for autoencoding provide global masking information, so\nthat all the position embeddings are accessible in partially autoregressive\nlanguage modeling. In addition, the two tasks pre-train a unified language\nmodel as a bidirectional encoder and a sequence-to-sequence decoder,\nrespectively. Our experiments show that the unified language models pre-trained\nusing PMLM achieve new state-of-the-art results on a wide range of natural\nlanguage understanding and generation tasks across several widely used\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 15:28:49 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bao", "Hangbo", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Wang", "Wenhui", ""], ["Yang", "Nan", ""], ["Liu", "Xiaodong", ""], ["Wang", "Yu", ""], ["Piao", "Songhao", ""], ["Gao", "Jianfeng", ""], ["Zhou", "Ming", ""], ["Hon", "Hsiao-Wuen", ""]]}, {"id": "2002.12854", "submitter": "Kevin Stowe", "authors": "Kevin Stowe and Leonardo Ribeiro and Iryna Gurevych", "title": "Metaphoric Paraphrase Generation", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes the task of metaphoric paraphrase generation, in which we\nare given a literal sentence and are charged with generating a metaphoric\nparaphrase. We propose two different models for this task: a lexical\nreplacement baseline and a novel sequence to sequence model, 'metaphor\nmasking', that generates free metaphoric paraphrases. We use crowdsourcing to\nevaluate our results, as well as developing an automatic metric for evaluating\nmetaphoric paraphrases. We show that while the lexical replacement baseline is\ncapable of producing accurate paraphrases, they often lack metaphoricity, while\nour metaphor masking model excels in generating metaphoric sentences while\nperforming nearly as well with regard to fluency and paraphrase quality.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 16:30:33 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Stowe", "Kevin", ""], ["Ribeiro", "Leonardo", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2002.12867", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Noe Casas, Eneko Agirre", "title": "Do all Roads Lead to Rome? Understanding the Role of Initialization in\n  Iterative Back-Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-translation provides a simple yet effective approach to exploit\nmonolingual corpora in Neural Machine Translation (NMT). Its iterative variant,\nwhere two opposite NMT models are jointly trained by alternately using a\nsynthetic parallel corpus generated by the reverse model, plays a central role\nin unsupervised machine translation. In order to start producing sound\ntranslations and provide a meaningful training signal to each other, existing\napproaches rely on either a separate machine translation system to warm up the\niterative procedure, or some form of pre-training to initialize the weights of\nthe model. In this paper, we analyze the role that such initialization plays in\niterative back-translation. Is the behavior of the final system heavily\ndependent on it? Or does iterative back-translation converge to a similar\nsolution given any reasonable initialization? Through a series of empirical\nexperiments over a diverse set of warmup systems, we show that, although the\nquality of the initial system does affect final performance, its effect is\nrelatively small, as iterative back-translation has a strong tendency to\nconvergence to a similar solution. As such, the margin of improvement left for\nthe initialization method is narrow, suggesting that future research should\nfocus more on improving the iterative mechanism itself.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:05:55 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Casas", "Noe", ""], ["Agirre", "Eneko", ""]]}]