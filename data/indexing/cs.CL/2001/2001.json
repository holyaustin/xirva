[{"id": "2001.00003", "submitter": "Chengyue Jiang", "authors": "Chengyue Jiang, Zhonglin Nian, Kaihao Guo, Shanbo Chu, Yinggong Zhao,\n  Libin Shen, Kewei Tu", "title": "Learning Numeral Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is an essential building block for deep learning methods for\nnatural language processing. Although word embedding has been extensively\nstudied over the years, the problem of how to effectively embed numerals, a\nspecial subset of words, is still underexplored. Existing word embedding\nmethods do not learn numeral embeddings well because there are an infinite\nnumber of numerals and their individual appearances in training corpora are\nhighly scarce. In this paper, we propose two novel numeral embedding methods\nthat can handle the out-of-vocabulary (OOV) problem for numerals. We first\ninduce a finite set of prototype numerals using either a self-organizing map or\na Gaussian mixture model. We then represent the embedding of a numeral as a\nweighted average of the prototype number embeddings. Numeral embeddings\nrepresented in this manner can be plugged into existing word embedding learning\napproaches such as skip-gram for training. We evaluated our methods and showed\nits effectiveness on four intrinsic and extrinsic tasks: word similarity,\nembedding numeracy, numeral prediction, and sequence labeling.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 03:15:43 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 13:57:12 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 14:00:55 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jiang", "Chengyue", ""], ["Nian", "Zhonglin", ""], ["Guo", "Kaihao", ""], ["Chu", "Shanbo", ""], ["Zhao", "Yinggong", ""], ["Shen", "Libin", ""], ["Tu", "Kewei", ""]]}, {"id": "2001.00009", "submitter": "Ankit Chadha Mr.", "authors": "Ankit Chadha and Mohamed Masoud", "title": "Deep Reinforced Self-Attention Masks for Abstractive Summarization\n  (DR.SAS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel architectural scheme to tackle the abstractive\nsummarization problem based on the CNN/DMdataset which fuses Reinforcement\nLearning (RL) withUniLM, which is a pre-trained Deep Learning Model, to solve\nvarious natural language tasks. We have tested the limits of learning\nfine-grained attention in Transformers to improve the summarization quality.\nUniLM applies attention to the entire token space in a global fashion. We\npropose DR.SAS which applies the Actor-Critic (AC) algorithm to learn a dynamic\nself-attention distribution over the tokens to reduce redundancy and generate\nfactual and coherent summaries to improve the quality of summarization. After\nperforming hyperparameter tuning, we achievedbetter ROUGE results compared to\nthe baseline. Our model tends to be more extractive/factual yet coherent in\ndetail because of optimization over ROUGE rewards. We present detailed error\nanalysis with examples of the strengths and limitations of our model. Our\ncodebase will be publicly available on our GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 01:32:42 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chadha", "Ankit", ""], ["Masoud", "Mohamed", ""]]}, {"id": "2001.00051", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Yulong Pei, Katia Sycara", "title": "Simultaneous Identification of Tweet Purpose and Position", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tweet classification has attracted considerable attention recently. Most of\nthe existing work on tweet classification focuses on topic classification,\nwhich classifies tweets into several predefined categories, and sentiment\nclassification, which classifies tweets into positive, negative and neutral.\nSince tweets are different from conventional text in that they generally are of\nlimited length and contain informal, irregular or new words, so it is difficult\nto determine user intention to publish a tweet and user attitude towards\ncertain topic. In this paper, we aim to simultaneously classify tweet purpose,\ni.e., the intention for user to publish a tweet, and position, i.e.,\nsupporting, opposing or being neutral to a given topic. By transforming this\nproblem to a multi-label classification problem, a multi-label classification\nmethod with post-processing is proposed. Experiments on real-world data sets\ndemonstrate the effectiveness of this method and the results outperform the\nindividual classification methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 17:09:54 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Pei", "Yulong", ""], ["Sycara", "Katia", ""]]}, {"id": "2001.00056", "submitter": "Dhanajit Brahma", "authors": "Pawan Kumar, Dhanajit Brahma, Harish Karnick, Piyush Rai", "title": "Deep Attentive Ranking Networks for Learning to Order Sentences", "comments": "Accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an attention-based ranking framework for learning to order\nsentences given a paragraph. Our framework is built on a bidirectional sentence\nencoder and a self-attention based transformer network to obtain an input order\ninvariant representation of paragraphs. Moreover, it allows seamless training\nusing a variety of ranking based loss functions, such as pointwise, pairwise,\nand listwise ranking. We apply our framework on two tasks: Sentence Ordering\nand Order Discrimination. Our framework outperforms various state-of-the-art\nmethods on these tasks on a variety of evaluation metrics. We also show that it\nachieves better results when using pairwise and listwise ranking losses, rather\nthan the pointwise ranking loss, which suggests that incorporating relative\npositions of two or more sentences in the loss function contributes to better\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:54:27 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kumar", "Pawan", ""], ["Brahma", "Dhanajit", ""], ["Karnick", "Harish", ""], ["Rai", "Piyush", ""]]}, {"id": "2001.00059", "submitter": "Petros Maniatis", "authors": "Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi", "title": "Learning and Evaluating Contextual Embedding of Source Code", "comments": "Published in ICML 2020. This version (v.3) is the final camera-ready\n  version of the paper. It contains the re-computed results, based on the\n  open-sourced datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has achieved impressive results on understanding and\nimproving source code by building up on machine-learning techniques developed\nfor natural languages. A significant advancement in natural-language\nunderstanding has come with the development of pre-trained contextual\nembeddings, such as BERT, which can be fine-tuned for downstream tasks with\nless labeled data and training budget, while achieving better accuracies.\nHowever, there is no attempt yet to obtain a high-quality contextual embedding\nof source code, and to evaluate it on multiple program-understanding tasks\nsimultaneously; that is the gap that this paper aims to mitigate. Specifically,\nfirst, we curate a massive, deduplicated corpus of 7.4M Python files from\nGitHub, which we use to pre-train CuBERT, an open-sourced code-understanding\nBERT model; and, second, we create an open-sourced benchmark that comprises\nfive classification tasks and one program-repair task, akin to\ncode-understanding tasks proposed in the literature before. We fine-tune CuBERT\non our benchmark tasks, and compare the resulting models to different variants\nof Word2Vec token embeddings, BiLSTM and Transformer models, as well as\npublished state-of-the-art models, showing that CuBERT outperforms them all,\neven with shorter training, and with fewer labeled examples. Future work on\nsource-code embedding can benefit from reusing our benchmark, and from\ncomparing against CuBERT models as a strong baseline.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 05:05:22 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 22:06:21 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 21:40:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kanade", "Aditya", ""], ["Maniatis", "Petros", ""], ["Balakrishnan", "Gogul", ""], ["Shi", "Kensen", ""]]}, {"id": "2001.00100", "submitter": "Walid Shalaby PhD", "authors": "Walid Shalaby, Adriano Arantes, Teresa GonzalezDiaz, Chetan Gupta", "title": "Building chatbots from large scale domain-specific knowledge bases:\n  challenges and opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular conversational agents frameworks such as Alexa Skills Kit (ASK) and\nGoogle Actions (gActions) offer unprecedented opportunities for facilitating\nthe development and deployment of voice-enabled AI solutions in various\nverticals. Nevertheless, understanding user utterances with high accuracy\nremains a challenging task with these frameworks. Particularly, when building\nchatbots with large volume of domain-specific entities. In this paper, we\ndescribe the challenges and lessons learned from building a large scale virtual\nassistant for understanding and responding to equipment-related complaints. In\nthe process, we describe an alternative scalable framework for: 1) extracting\nthe knowledge about equipment components and their associated problem entities\nfrom short texts, and 2) learning to identify such entities in user utterances.\nWe show through evaluation on a real dataset that the proposed framework,\ncompared to off-the-shelf popular ones, scales better with large volume of\nentities being up to 30% more accurate, and is more effective in understanding\nuser utterances with domain-specific entities.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:40:30 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Shalaby", "Walid", ""], ["Arantes", "Adriano", ""], ["GonzalezDiaz", "Teresa", ""], ["Gupta", "Chetan", ""]]}, {"id": "2001.00137", "submitter": "Gwenaelle Cunha Sergio", "authors": "Gwenaelle Cunha Sergio and Minho Lee", "title": "Stacked DeBERT: All Attention in Incomplete Data for Text Classification", "comments": "Published (https://doi.org/10.1016/j.neunet.2020.12.018), Code\n  (https://github.com/gcunhase/StackedDeBERT)", "journal-ref": "Neural Networks 136 (2021) 87-96", "doi": "10.1016/j.neunet.2020.12.018", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose Stacked DeBERT, short for Stacked Denoising\nBidirectional Encoder Representations from Transformers. This novel model\nimproves robustness in incomplete data, when compared to existing systems, by\ndesigning a novel encoding scheme in BERT, a powerful language representation\nmodel solely based on attention mechanisms. Incomplete data in natural language\nprocessing refer to text with missing or incorrect words, and its presence can\nhinder the performance of current models that were not implemented to withstand\nsuch noises, but must still perform well even under duress. This is due to the\nfact that current approaches are built for and trained with clean and complete\ndata, and thus are not able to extract features that can adequately represent\nincomplete data. Our proposed approach consists of obtaining intermediate input\nrepresentations by applying an embedding layer to the input tokens followed by\nvanilla transformers. These intermediate features are given as input to novel\ndenoising transformers which are responsible for obtaining richer input\nrepresentations. The proposed approach takes advantage of stacks of multilayer\nperceptrons for the reconstruction of missing words' embeddings by extracting\nmore abstract and meaningful hidden feature vectors, and bidirectional\ntransformers for improved embedding representation. We consider two datasets\nfor training and evaluation: the Chatbot Natural Language Understanding\nEvaluation Corpus and Kaggle's Twitter Sentiment Corpus. Our model shows\nimproved F1-scores and better robustness in informal/incorrect texts present in\ntweets and in texts with Speech-to-Text error in the sentiment and intent\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 04:49:23 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 14:13:49 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sergio", "Gwenaelle Cunha", ""], ["Lee", "Minho", ""]]}, {"id": "2001.00295", "submitter": "Chengkun Lang", "authors": "Huiwei Zhou, Shixian Ning, Yunlong Yang, Zhuang Liu, Chengkun Lang,\n  Yingyu Lin", "title": "Chemical-induced Disease Relation Extraction with Dependency Information\n  and Prior Knowledge", "comments": "Published on Journal of Biomedical Informatics, 13 pages", "journal-ref": "Journal of Biomedical Informatics, 2018, 84:171-178", "doi": "10.1016/j.jbi.2018.07.007", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical-disease relation (CDR) extraction is significantly important to\nvarious areas of biomedical research and health care. Nowadays, many\nlarge-scale biomedical knowledge bases (KBs) containing triples about entity\npairs and their relations have been built. KBs are important resources for\nbiomedical relation extraction. However, previous research pays little\nattention to prior knowledge. In addition, the dependency tree contains\nimportant syntactic and semantic information, which helps to improve relation\nextraction. So how to effectively use it is also worth studying. In this paper,\nwe propose a novel convolutional attention network (CAN) for CDR extraction.\nFirstly, we extract the shortest dependency path (SDP) between chemical and\ndisease pairs in a sentence, which includes a sequence of words, dependency\ndirections, and dependency relation tags. Then the convolution operations are\nperformed on the SDP to produce deep semantic dependency features. After that,\nan attention mechanism is employed to learn the importance/weight of each\nsemantic dependency vector related to knowledge representations learned from\nKBs. Finally, in order to combine dependency information and prior knowledge,\nthe concatenation of weighted semantic dependency representations and knowledge\nrepresentations is fed to the softmax layer for classification. Experiments on\nthe BioCreative V CDR dataset show that our method achieves comparable\nperformance with the state-of-the-art systems, and both dependency information\nand prior knowledge play important roles in CDR extraction task.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 02:24:53 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zhou", "Huiwei", ""], ["Ning", "Shixian", ""], ["Yang", "Yunlong", ""], ["Liu", "Zhuang", ""], ["Lang", "Chengkun", ""], ["Lin", "Yingyu", ""]]}, {"id": "2001.00372", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Thomas Dubuisson, Thierry Dutoit", "title": "Phase-based Information for Voice Pathology Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most current approaches of speech processing, information is extracted\nfrom the magnitude spectrum. However recent perceptual studies have underlined\nthe importance of the phase component. The goal of this paper is to investigate\nthe potential of using phase-based features for automatically detecting voice\ndisorders. It is shown that group delay functions are appropriate for\ncharacterizing irregularities in the phonation. Besides the respect of the\nmixed-phase model of speech is discussed. The proposed phase-based features are\nevaluated and compared to other parameters derived from the magnitude spectrum.\nBoth streams are shown to be interestingly complementary. Furthermore\nphase-based features turn out to convey a great amount of relevant information,\nleading to high discrimination performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:51:51 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Drugman", "Thomas", ""], ["Dubuisson", "Thomas", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00459", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Abeer Alwan", "title": "Joint Robust Voicing Detection and Pitch Estimation Based on Residual\n  Harmonics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of pitch tracking in noisy conditions. A\nmethod using harmonic information in the residual signal is presented. The\nproposed criterion is used both for pitch estimation, as well as for\ndetermining the voicing segments of speech. In the experiments, the method is\ncompared to six state-of-the-art pitch trackers on the Keele and CSTR\ndatabases. The proposed technique is shown to be particularly robust to\nadditive noise, leading to a significant improvement in adverse conditions.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 13:45:29 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Drugman", "Thomas", ""], ["Alwan", "Abeer", ""]]}, {"id": "2001.00471", "submitter": "Haruna Isah", "authors": "Kennedy Ralston, Yuhao Chen, Haruna Isah, Farhana Zulkernine", "title": "A Voice Interactive Multilingual Student Support System using IBM Watson", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems powered by artificial intelligence are being developed to be more\nuser-friendly by communicating with users in a progressively human-like\nconversational way. Chatbots, also known as dialogue systems, interactive\nconversational agents, or virtual agents are an example of such systems used in\na wide variety of applications ranging from customer support in the business\ndomain to companionship in the healthcare sector. It is becoming increasingly\nimportant to develop chatbots that can best respond to the personalized needs\nof their users so that they can be as helpful to the user as possible in a real\nhuman way. This paper investigates and compares three popular existing chatbots\nAPI offerings and then propose and develop a voice interactive and multilingual\nchatbot that can effectively respond to users mood, tone, and language using\nIBM Watson Assistant, Tone Analyzer, and Language Translator. The chatbot was\nevaluated using a use case that was targeted at responding to users needs\nregarding exam stress based on university students survey data generated using\nGoogle Forms. The results of measuring the chatbot effectiveness at analyzing\nresponses regarding exam stress indicate that the chatbot responding\nappropriately to the user queries regarding how they are feeling about exams\n76.5%. The chatbot could also be adapted for use in other application areas\nsuch as student info-centers, government kiosks, and mental health support\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:58:25 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ralston", "Kennedy", ""], ["Chen", "Yuhao", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""]]}, {"id": "2001.00473", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Mark Thomas, Jon Gudnason, Patrick Naylor, Thierry\n  Dutoit", "title": "Detection of Glottal Closure Instants from Speech Signals: a\n  Quantitative Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pseudo-periodicity of voiced speech can be exploited in several speech\nprocessing applications. This requires however that the precise locations of\nthe Glottal Closure Instants (GCIs) are available. The focus of this paper is\nthe evaluation of automatic methods for the detection of GCIs directly from the\nspeech waveform. Five state-of-the-art GCI detection algorithms are compared\nusing six different databases with contemporaneous electroglottographic\nrecordings as ground truth, and containing many hours of speech by multiple\nspeakers. The five techniques compared are the Hilbert Envelope-based detection\n(HE), the Zero Frequency Resonator-based method (ZFR), the Dynamic Programming\nPhase Slope Algorithm (DYPSA), the Speech Event Detection using the Residual\nExcitation And a Mean-based Signal (SEDREAMS) and the Yet Another GCI Algorithm\n(YAGA). The efficacy of these methods is first evaluated on clean speech, both\nin terms of reliabililty and accuracy. Their robustness to additive noise and\nto reverberation is also assessed. A further contribution of the paper is the\nevaluation of their performance on a concrete application of speech processing:\nthe causal-anticausal decomposition of speech. It is shown that for clean\nspeech, SEDREAMS and YAGA are the best performing techniques, both in terms of\nidentification rate and accuracy. ZFR and SEDREAMS also show a superior\nrobustness to additive noise and reverberation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 14:12:16 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Drugman", "Thomas", ""], ["Thomas", "Mark", ""], ["Gudnason", "Jon", ""], ["Naylor", "Patrick", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00569", "submitter": "Massimiliano Dal Mas", "authors": "Massimiliano Dal Mas", "title": "Emergent Behaviors from Folksonomy Driven Interactions", "comments": "6 pages, 5 figures; for details see: http://www.maxdalmas.com arXiv\n  admin note: text overlap with arXiv:1612.09574", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reflect the evolving knowledge on the Web this paper considers ontologies\nbased on folksonomies according to a new concept structure called\n\"Folksodriven\" to represent folksonomies. This paper describes a research\nprogram for studying Folksodriven tags interactions leading to Folksodriven\ncluster behavior. The goal of the research is to understand the type of simple\nlocal interactions which produce complex and purposive group behaviors on\nFolksodriven tags. We describe a synthetic, bottom-up approach to studying\ngroup behavior, consisting of designing and testing a variety of social\ninteractions and cultural scenarios with Folksodriven tags. We propose a set of\nbasic interactions which can be used to structure and simplify the process of\nboth designing and analyzing emergent group behaviors. The presented behavior\nrepertories was developed and tested on a folksonomy environment.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:33:03 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Mas", "Massimiliano Dal", ""]]}, {"id": "2001.00571", "submitter": "Tamirlan Seidakhmetov", "authors": "Tamirlan Seidakhmetov", "title": "Question Type Classification Methods Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a comparative study of state-of-the-art approaches for\nquestion classification task: Logistic Regression, Convolutional Neural\nNetworks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent\nNeural Networks (QRNN). All models use pre-trained GLoVe word embeddings and\ntrained on human-labeled data. The best accuracy is achieved using CNN model\nwith five convolutional layers and various kernel sizes stacked in parallel,\nfollowed by one fully connected layer. The model reached 90.7% accuracy on TREC\n10 test set. All the model architectures in this paper were developed from\nscratch on PyTorch, in few cases based on reliable open-source implementation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 00:16:46 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Seidakhmetov", "Tamirlan", ""]]}, {"id": "2001.00572", "submitter": "Guoxiu He", "authors": "Guoxiu He, Zhe Gao, Zhuoren Jiang, Yangyang Kang, Changlong Sun,\n  Xiaozhong Liu, Wei Lu", "title": "Read Beyond the Lines: Understanding the Implied Textual Meaning via a\n  Skim and Intensive Reading Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonliteral interpretation of a text is hard to be understood by machine\nmodels due to its high context-sensitivity and heavy usage of figurative\nlanguage. In this study, inspired by human reading comprehension, we propose a\nnovel, simple, and effective deep neural framework, called Skim and Intensive\nReading Model (SIRM), for figuring out implied textual meaning. The proposed\nSIRM consists of two main components, namely the skim reading component and\nintensive reading component. N-gram features are quickly extracted from the\nskim reading component, which is a combination of several convolutional neural\nnetworks, as skim (entire) information. An intensive reading component enables\na hierarchical investigation for both local (sentence) and global (paragraph)\nrepresentation, which encapsulates the current embedding and the contextual\ninformation with a dense connection. More specifically, the contextual\ninformation includes the near-neighbor information and the skim information\nmentioned above. Finally, besides the normal training loss function, we employ\nan adversarial loss function as a penalty over the skim reading component to\neliminate noisy information arisen from special figurative words in the\ntraining data. To verify the effectiveness, robustness, and efficiency of the\nproposed architecture, we conduct extensive comparative experiments on several\nsarcasm benchmarks and an industrial spam dataset with metaphors. Experimental\nresults indicate that (1) the proposed model, which benefits from context\nmodeling and consideration of figurative language, outperforms existing\nstate-of-the-art solutions, with comparable parameter scale and training speed;\n(2) the SIRM yields superior robustness in terms of parameter size sensitivity;\n(3) compared with ablation and addition variants of the SIRM, the final\nframework is efficient enough.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 03:43:35 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 14:27:21 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["He", "Guoxiu", ""], ["Gao", "Zhe", ""], ["Jiang", "Zhuoren", ""], ["Kang", "Yangyang", ""], ["Sun", "Changlong", ""], ["Liu", "Xiaozhong", ""], ["Lu", "Wei", ""]]}, {"id": "2001.00573", "submitter": "Sucheta Ghosh", "authors": "Sucheta Ghosh", "title": "A Hybrid Framework for Topic Structure using Laughter Occurrences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conversational discourse coherence depends on both linguistic and\nparalinguistic phenomena. In this work we combine both paralinguistic and\nlinguistic knowledge into a hybrid framework through a multi-level hierarchy.\nThus it outputs the discourse-level topic structures. The laughter occurrences\nare used as paralinguistic information from the multiparty meeting transcripts\nof ICSI database. A clustering-based algorithm is proposed that chose the best\ntopic-segment cluster from two independent, optimized clusters, namely,\nhierarchical agglomerative clustering and $K$-medoids. Then it is iteratively\nhybridized with an existing lexical cohesion based Bayesian topic segmentation\nframework. The hybrid approach improves the performance of both of the\nstand-alone approaches. This leads to the brief study of interactions between\ntopic structures with discourse relational structure. This training-free topic\nstructuring approach can be applicable to online understanding of spoken\ndialogs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:31:42 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Ghosh", "Sucheta", ""]]}, {"id": "2001.00575", "submitter": "Singamsetti Mohan Sai", "authors": "Mona teja K, Mohan Sai. S, H S S S Raviteja D, Sai Kushagra P V", "title": "Smart Summarizer for Blind People", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's world, time is a very important resource. In our busy lives, most\nof us hardly have time to read the complete news so what we have to do is just\ngo through the headlines and satisfy ourselves with that. As a result, we might\nmiss a part of the news or misinterpret the complete thing. The situation is\neven worse for the people who are visually impaired or have lost their ability\nto see. The inability of these people to read text has a huge impact on their\nlives. There are a number of methods for blind people to read the text. Braille\nscript, in particular, is one of the examples, but it is a highly inefficient\nmethod as it is really time taking and requires a lot of practice. So, we\npresent a method for visually impaired people based on the sense of sound which\nis obviously better and more accurate than the sense of touch. This paper deals\nwith an efficient method to summarize news into important keywords so as to\nsave the efforts to go through the complete text every single time. This paper\ndeals with many API's and modules like the tesseract, GTTS, and many algorithms\nthat have been discussed and implemented in detail such as Luhn's Algorithm,\nLatent Semantic Analysis Algorithm, Text Ranking Algorithm. And the other\nfunctionality that this paper deals with is converting the summarized text to\nspeech so that the system can aid even the blind people.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 20:39:22 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["K", "Mona teja", ""], ["S", "Mohan Sai.", ""], ["D", "H S S S Raviteja", ""], ["P", "Sai Kushagra", "V"]]}, {"id": "2001.00579", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Thierry Dutoit", "title": "A Comparative Evaluation of Pitch Modification Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of pitch modification, as an important\nmodule for an efficient voice transformation system. The Deterministic plus\nStochastic Model of the residual signal we proposed in a previous work is\ncompared to TDPSOLA, HNM and STRAIGHT. The four methods are compared through an\nimportant subjective test. The influence of the speaker gender and of the pitch\nmodification ratio is analyzed. Despite its higher compression level, the DSM\ntechnique is shown to give similar or better results than other methods,\nespecially for male speakers and important ratios of modification. The DSM\nturns out to be only outperformed by STRAIGHT for female voices.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:25:30 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00581", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Geoffrey Wilfart, Thierry Dutoit", "title": "Eigenresiduals for improved Parametric Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical parametric speech synthesizers have recently shown their ability\nto produce natural-sounding and flexible voices. Unfortunately the delivered\nquality suffers from a typical buzziness due to the fact that speech is\nvocoded. This paper proposes a new excitation model in order to reduce this\nundesirable effect. This model is based on the decomposition of\npitch-synchronous residual frames on an orthonormal basis obtained by Principal\nComponent Analysis. This basis contains a limited number of eigenresiduals and\nis computed on a relatively small speech database. A stream of PCA-based\ncoefficients is added to our HMM-based synthesizer and allows to generate the\nvoiced excitation during the synthesis. An improvement compared to the\ntraditional excitation is reported while the synthesis engine footprint remains\nunder about 1Mb.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:39:07 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Wilfart", "Geoffrey", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00582", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Thierry Dutoit, Baris Bozkurt", "title": "Excitation-based Voice Quality Analysis and Modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the differences occuring in the excitation for\ndifferent voice qualities. Its goal is two-fold. First a large corpus\ncontaining three voice qualities (modal, soft and loud) uttered by the same\nspeaker is analyzed and significant differences in characteristics extracted\nfrom the excitation are observed. Secondly rules of modification derived from\nthe analysis are used to build a voice quality transformation system applied as\na post-process to HMM-based speech synthesis. The system is shown to\neffectively achieve the transformations while maintaining the delivered\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:44:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Dutoit", "Thierry", ""], ["Bozkurt", "Baris", ""]]}, {"id": "2001.00583", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Thomas Dubuisson, Thierry Dutoit", "title": "On the Mutual Information between Source and Filter Contributions for\n  Voice Pathology Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of automatic detection of voice pathologies\ndirectly from the speech signal. For this, we investigate the use of the\nglottal source estimation as a means to detect voice disorders. Three sets of\nfeatures are proposed, depending on whether they are related to the speech or\nthe glottal signal, or to prosody. The relevancy of these features is assessed\nthrough mutual information-based measures. This allows an intuitive\ninterpretation in terms of discrimation power and redundancy between the\nfeatures, independently of any subsequent classifier. It is discussed which\ncharacteristics are interestingly informative or complementary for detecting\nvoice pathologies.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 10:04:37 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Dubuisson", "Thomas", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00623", "submitter": "Kai Shu", "authors": "Kai Shu, Suhang Wang, Dongwon Lee, and Huan Liu", "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "comments": "Submitted as an introductory chapter for the edited book on \"Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities\", Springer Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:01:02 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Shu", "Kai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""], ["Liu", "Huan", ""]]}, {"id": "2001.00725", "submitter": "Chenguang Zhu", "authors": "Ziyi Yang, Chenguang Zhu, Robert Gmyr, Michael Zeng, Xuedong Huang,\n  Eric Darve", "title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling\n  and Denoising", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization aims to extract essential information from a piece of text\nand transform the text into a concise version. Existing unsupervised\nabstractive summarization models leverage recurrent neural networks framework\nwhile the recently proposed transformer exhibits much more capability.\nMoreover, most of previous summarization models ignore abundant unlabeled\ncorpora resources available for pretraining. In order to address these issues,\nwe propose TED, a transformer-based unsupervised abstractive summarization\nsystem with pretraining on large-scale data. We first leverage the lead bias in\nnews articles to pretrain the model on millions of unlabeled corpora. Next, we\nfinetune TED on target domains through theme modeling and a denoising\nautoencoder to enhance the quality of generated summaries. Notably, TED\noutperforms all unsupervised abstractive baselines on NYT, CNN/DM and English\nGigaword datasets with various document styles. Further analysis shows that the\nsummaries generated by TED are highly abstractive, and each component in the\nobjective function of TED is highly effective.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 05:15:41 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 02:12:26 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 00:26:09 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Yang", "Ziyi", ""], ["Zhu", "Chenguang", ""], ["Gmyr", "Robert", ""], ["Zeng", "Michael", ""], ["Huang", "Xuedong", ""], ["Darve", "Eric", ""]]}, {"id": "2001.00733", "submitter": "Hao Fu", "authors": "Danning Zheng, Ruihua Song, Tianran Hu, Hao Fu, Jin Zhou", "title": "\"Love is as Complex as Math\": Metaphor Generation System for Social\n  Chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the wide adoption of intelligent chatbot in human daily life, user demands\nfor such systems evolve from basic task-solving conversations to more casual\nand friend-like communication. To meet the user needs and build emotional bond\nwith users, it is essential for social chatbots to incorporate more human-like\nand advanced linguistic features. In this paper, we investigate the usage of a\ncommonly used rhetorical device by human -- metaphor for social chatbot. Our\nwork first designs a metaphor generation framework, which generates topic-aware\nand novel figurative sentences. By embedding the framework into a chatbot\nsystem, we then enables the chatbot to communicate with users using figurative\nlanguage. Human annotators validate the novelty and properness of the generated\nmetaphors. More importantly, we evaluate the effects of employing metaphors in\nhuman-chatbot conversations. Experiments indicate that our system effectively\narouses user interests in communicating with our chatbot, resulting in\nsignificantly longer human-chatbot conversations.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 05:56:13 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zheng", "Danning", ""], ["Song", "Ruihua", ""], ["Hu", "Tianran", ""], ["Fu", "Hao", ""], ["Zhou", "Jin", ""]]}, {"id": "2001.00781", "submitter": "Matthias A{\\ss}enmacher", "authors": "Matthias A{\\ss}enmacher, Christian Heumann", "title": "On the comparability of Pre-trained Language Models", "comments": null, "journal-ref": "Proceedings of the 5th Swiss Text Analytics Conference (SwissText)\n  & 16th Conference on Natural Language Processing (KONVENS), Zurich,\n  Switzerland, June 23-25, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in unsupervised representation learning have successfully\nestablished the concept of transfer learning in NLP. Mainly three forces are\ndriving the improvements in this area of research: More elaborated\narchitectures are making better use of contextual information. Instead of\nsimply plugging in static pre-trained representations, these are learned based\non surrounding context in end-to-end trainable models with more intelligently\ndesigned language modelling objectives. Along with this, larger corpora are\nused as resources for pre-training large language models in a self-supervised\nfashion which are afterwards fine-tuned on supervised tasks. Advances in\nparallel computing as well as in cloud computing, made it possible to train\nthese models with growing capacities in the same or even in shorter time than\npreviously established models. These three developments agglomerate in new\nstate-of-the-art (SOTA) results being revealed in a higher and higher\nfrequency. It is not always obvious where these improvements originate from, as\nit is not possible to completely disentangle the contributions of the three\ndriving forces. We set ourselves to providing a clear and concise overview on\nseveral large pre-trained language models, which achieved SOTA results in the\nlast two years, with respect to their use of new architectures and resources.\nWe want to clarify for the reader where the differences between the models are\nand we furthermore attempt to gain some insight into the single contributions\nof lexical/computational improvements as well as of architectural changes. We\nexplicitly do not intend to quantify these contributions, but rather see our\nwork as an overview in order to identify potential starting points for\nbenchmark comparisons. Furthermore, we tentatively want to point at potential\npossibilities for improvement in the field of open-sourcing and reproducible\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 10:53:35 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["A\u00dfenmacher", "Matthias", ""], ["Heumann", "Christian", ""]]}, {"id": "2001.00840", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Baris Bozkurt, Thierry Dutoit", "title": "A Comparative Study of Glottal Source Estimation Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source-tract decomposition (or glottal flow estimation) is one of the basic\nproblems of speech processing. For this, several techniques have been proposed\nin the literature. However studies comparing different approaches are almost\nnonexistent. Besides, experiments have been systematically performed either on\nsynthetic speech or on sustained vowels. In this study we compare three of the\nmain representative state-of-the-art methods of glottal flow estimation:\nclosed-phase inverse filtering, iterative and adaptive inverse filtering, and\nmixed-phase decomposition. These techniques are first submitted to an objective\nassessment test on synthetic speech signals. Their sensitivity to various\nfactors affecting the estimation quality, as well as their robustness to noise\nare studied. In a second experiment, their ability to label voice quality\n(tensed, modal, soft) is studied on a large corpus of real connected speech. It\nis shown that changes of voice quality are reflected by significant\nmodifications in glottal feature distributions. Techniques based on the\nmixed-phase decomposition and on a closed-phase inverse filtering process turn\nout to give the best results on both clean synthetic and real speech signals.\nOn the other hand, iterative and adaptive inverse filtering is recommended in\nnoisy environments for its high robustness.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 20:40:08 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Bozkurt", "Baris", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00841", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Thierry Dutoit", "title": "Glottal Closure and Opening Instant Detection from Speech Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new procedure to detect Glottal Closure and Opening\nInstants (GCIs and GOIs) directly from speech waveforms. The procedure is\ndivided into two successive steps. First a mean-based signal is computed, and\nintervals where speech events are expected to occur are extracted from it.\nSecondly, at each interval a precise position of the speech event is assigned\nby locating a discontinuity in the Linear Prediction residual. The proposed\nmethod is compared to the DYPSA algorithm on the CMU ARCTIC database. A\nsignificant improvement as well as a better noise robustness are reported.\nBesides, results of GOI identification accuracy are promising for the glottal\nsource characterization.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 19:27:45 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00842", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Geoffrey Wilfart, Thierry Dutoit", "title": "A Deterministic plus Stochastic Model of the Residual Signal for\n  Improved Parametric Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech generated by parametric synthesizers generally suffers from a typical\nbuzziness, similar to what was encountered in old LPC-like vocoders. In order\nto alleviate this problem, a more suited modeling of the excitation should be\nadopted. For this, we hereby propose an adaptation of the Deterministic plus\nStochastic Model (DSM) for the residual. In this model, the excitation is\ndivided into two distinct spectral bands delimited by the maximum voiced\nfrequency. The deterministic part concerns the low-frequency contents and\nconsists of a decomposition of pitch-synchronous residual frames on an\northonormal basis obtained by Principal Component Analysis. The stochastic\ncomponent is a high-pass filtered noise whose time structure is modulated by an\nenergy-envelope, similarly to what is done in the Harmonic plus Noise Model\n(HNM). The proposed residual model is integrated within a HMM-based speech\nsynthesizer and is compared to the traditional excitation through a subjective\ntest. Results show a significative improvement for both male and female voices.\nIn addition the proposed model requires few computational load and memory,\nwhich is essential for its integration in commercial applications.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 07:26:47 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Drugman", "Thomas", ""], ["Wilfart", "Geoffrey", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.00862", "submitter": "Bob Coecke", "authors": "Bob Coecke and Konstantinos Meichanetzidis", "title": "Meaning updating of density matrices", "comments": "24 pages, many figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DisCoCat model of natural language meaning assigns meaning to a sentence\ngiven: (i) the meanings of its words, and, (ii) its grammatical structure. The\nrecently introduced DisCoCirc model extends this to text consisting of multiple\nsentences. While in DisCoCat all meanings are fixed, in DisCoCirc each sentence\nupdates meanings of words. In this paper we explore different update mechanisms\nfor DisCoCirc, in the case where meaning is encoded in density matrices---which\ncome with several advantages as compared to vectors.\n  Our starting point are two non-commutative update mechanisms, borrowing one\nfrom quantum foundations research, from Leifer and Spekkens. Unfortunately,\nneither of these satisfies any desirable algebraic properties, nor are internal\nto the meaning category. By passing to double density matrices we do get an\nelegant internal diagrammatic update mechanism.\n  We also show that (commutative) spiders can be cast as an instance of the\nLeifer-Spekkens update mechanism. This result is of interest to quantum\nfoundations, as it bridges the work in Categorical Quantum Mechanics (CQM) with\nthat on conditional quantum states. Our work also underpins implementation of\ntext-level natural language processing on quantum hardware (a.k.a. QNLP), for\nwhich exponential space-gain and quadratic speed-up have previously been\nidentified.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 15:28:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Coecke", "Bob", ""], ["Meichanetzidis", "Konstantinos", ""]]}, {"id": "2001.00891", "submitter": "Goran Glava\\v{s}", "authors": "Goran Glava\\v{s} and Swapna Somasundaran", "title": "Two-Level Transformer and Auxiliary Coherence Modeling for Improved Text\n  Segmentation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Breaking down the structure of long texts into semantically coherent segments\nmakes the texts more readable and supports downstream applications like\nsummarization and retrieval. Starting from an apparent link between text\ncoherence and segmentation, we introduce a novel supervised model for text\nsegmentation with simple but explicit coherence modeling. Our model -- a neural\narchitecture consisting of two hierarchically connected Transformer networks --\nis a multi-task learning model that couples the sentence-level segmentation\nobjective with the coherence objective that differentiates correct sequences of\nsentences from corrupt ones. The proposed model, dubbed Coherence-Aware Text\nSegmentation (CATS), yields state-of-the-art segmentation performance on a\ncollection of benchmark datasets. Furthermore, by coupling CATS with\ncross-lingual word embeddings, we demonstrate its effectiveness in zero-shot\nlanguage transfer: it can successfully segment texts in languages unseen in\ntraining.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:06:41 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Glava\u0161", "Goran", ""], ["Somasundaran", "Swapna", ""]]}, {"id": "2001.00926", "submitter": "Ephrem Wu", "authors": "Ephrem Wu", "title": "Learning Accurate Integer Transformer Machine-Translation Models", "comments": null, "journal-ref": null, "doi": "10.1007/s42979-021-00688-4", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for training accurate Transformer machine-translation\nmodels to run inference using 8-bit integer (INT8) hardware matrix multipliers,\nas opposed to the more costly single-precision floating-point (FP32) hardware.\nUnlike previous work, which converted only 85 Transformer matrix\nmultiplications to INT8, leaving 48 out of 133 of them in FP32 because of\nunacceptable accuracy loss, we convert them all to INT8 without compromising\naccuracy. Tested on the newstest2014 English-to-German translation task, our\nINT8 Transformer Base and Transformer Big models yield BLEU scores that are\n99.3% to 100% relative to those of the corresponding FP32 models. Our approach\nconverts all matrix-multiplication tensors from an existing FP32 model into\nINT8 tensors by automatically making range-precision trade-offs during\ntraining. To demonstrate the robustness of this approach, we also include\nresults from INT6 Transformer models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:40:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wu", "Ephrem", ""]]}, {"id": "2001.01000", "submitter": "Thomas Drugman", "authors": "Thomas Drugman, Thierry Dutoit", "title": "The Deterministic plus Stochastic Model of the Residual Signal and its\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling of speech production often relies on a source-filter approach.\nAlthough methods parameterizing the filter have nowadays reached a certain\nmaturity, there is still a lot to be gained for several speech processing\napplications in finding an appropriate excitation model. This manuscript\npresents a Deterministic plus Stochastic Model (DSM) of the residual signal.\nThe DSM consists of two contributions acting in two distinct spectral bands\ndelimited by a maximum voiced frequency. Both components are extracted from an\nanalysis performed on a speaker-dependent dataset of pitch-synchronous residual\nframes. The deterministic part models the low-frequency contents and arises\nfrom an orthonormal decomposition of these frames. As for the stochastic\ncomponent, it is a high-frequency noise modulated both in time and frequency.\nSome interesting phonetic and computational properties of the DSM are also\nhighlighted. The applicability of the DSM in two fields of speech processing is\nthen studied. First, it is shown that incorporating the DSM vocoder in\nHMM-based speech synthesis enhances the delivered quality. The proposed\napproach turns out to significantly outperform the traditional pulse excitation\nand provides a quality equivalent to STRAIGHT. In a second application, the\npotential of glottal signatures derived from the proposed DSM is investigated\nfor speaker identification purpose. Interestingly, these signatures are shown\nto lead to better recognition rates than other glottal-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 07:52:37 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Drugman", "Thomas", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2001.01037", "submitter": "Jiamei Sun", "authors": "Jiamei Sun, Sebastian Lapuschkin, Wojciech Samek, Alexander Binder", "title": "Understanding Image Captioning Models beyond Visualizing Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper interprets the predictions of image captioning models with\nattention mechanisms beyond visualizing the attention itself. In this paper, we\ndevelop variants of layer-wise relevance propagation (LRP) and gradient-based\nexplanation methods, tailored to image captioning models with attention\nmechanisms. We compare the interpretability of attention heatmaps\nsystematically against the explanations computed with explanation methods such\nas LRP, Grad-CAM, and Guided Grad-CAM. We show that explanation methods provide\nsimultaneously pixel-wise image explanation (supporting and opposing pixels of\nthe input image) and linguistic explanation (supporting and opposing words of\nthe preceding sequence) for each word in the predicted captions. We demonstrate\nwith extensive experiments that explanation methods can 1) reveal more related\nevidence used by the model to make decisions than attention; 2) correlate to\nobject locations with high precision; 3) is helpful to `debug' the model such\nas analyzing the reasons for hallucinated object words. With the observed\nproperties of explanations, we further design an LRP-inference fine-tuning\nstrategy that can alleviate the object hallucination of image captioning\nmodels, meanwhile, maintain the sentence fluency. We conduct experiments with\ntwo widely used attention mechanisms: the adaptive attention mechanism\ncalculated with the additive attention and the multi-head attention calculated\nwith the scaled dot product.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 05:15:11 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 02:09:36 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 02:41:41 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 01:41:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Sun", "Jiamei", ""], ["Lapuschkin", "Sebastian", ""], ["Samek", "Wojciech", ""], ["Binder", "Alexander", ""]]}, {"id": "2001.01047", "submitter": "Muhammad Haroon Shakeel", "authors": "Muhammad Haroon Shakeel, Asim Karim", "title": "Adapting Deep Learning for Sentiment Classification of Code-Switched\n  Informal Short Text", "comments": null, "journal-ref": "The 35th ACM/SIGAPP Symposium on Applied Computing (SAC) 2020", "doi": "10.1145/3341105.3374091", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, an abundance of short text is being generated that uses nonstandard\nwriting styles influenced by regional languages. Such informal and\ncode-switched content are under-resourced in terms of labeled datasets and\nlanguage models even for popular tasks like sentiment classification. In this\nwork, we (1) present a labeled dataset called MultiSenti for sentiment\nclassification of code-switched informal short text, (2) explore the\nfeasibility of adapting resources from a resource-rich language for an informal\none, and (3) propose a deep learning-based model for sentiment classification\nof code-switched informal short text. We aim to achieve this without any\nlexical normalization, language translation, or code-switching indication. The\nperformance of the proposed models is compared with three existing multilingual\nsentiment classification models. The results show that the proposed model\nperforms better in general and adapting character-based embeddings yield\nequivalent performance while being computationally more efficient than training\nword-based domain-specific embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 06:31:15 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Shakeel", "Muhammad Haroon", ""], ["Karim", "Asim", ""]]}, {"id": "2001.01115", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre, Chenhui Chu, Anoop Kunchukuttan", "title": "A Comprehensive Survey of Multilingual Neural Machine Translation", "comments": "This is an extended version of our survey paper on multilingual NMT.\n  The previous version [arXiv:1905.05395] is rather condensed and is useful for\n  speed-reading whereas this version is more beginner friendly. Under review at\n  the computing surveys journal. We have intentionally decided to maintain both\n  short and long versions of our survey paper for different reader groups", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a survey on multilingual neural machine translation (MNMT), which\nhas gained a lot of traction in the recent years. MNMT has been useful in\nimproving translation quality as a result of translation knowledge transfer\n(transfer learning). MNMT is more promising and interesting than its\nstatistical machine translation counterpart because end-to-end modeling and\ndistributed representations open new avenues for research on machine\ntranslation. Many approaches have been proposed in order to exploit\nmultilingual parallel corpora for improving translation quality. However, the\nlack of a comprehensive survey makes it difficult to determine which approaches\nare promising and hence deserve further exploration. In this paper, we present\nan in-depth survey of existing literature on MNMT. We first categorize various\napproaches based on their central use-case and then further categorize them\nbased on resource scenarios, underlying modeling principles, core-issues and\nchallenges. Wherever possible we address the strengths and weaknesses of\nseveral techniques by comparing them with each other. We also discuss the\nfuture directions that MNMT research might take. This paper is aimed towards\nboth, beginners and experts in NMT. We hope this paper will serve as a starting\npoint as well as a source of new ideas for researchers and engineers interested\nin MNMT.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 19:38:00 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 16:54:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Dabre", "Raj", ""], ["Chu", "Chenhui", ""], ["Kunchukuttan", "Anoop", ""]]}, {"id": "2001.01126", "submitter": "Alexander Ruch", "authors": "Alexander Ruch", "title": "Can x2vec Save Lives? Integrating Graph and Language Embeddings for\n  Automatic Mental Health Classification", "comments": "25 pages (23 body, 2 supplemental material), 12 figures (10 body, 2\n  supplemental material), 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph and language embedding models are becoming commonplace in large scale\nanalyses given their ability to represent complex sparse data densely in\nlow-dimensional space. Integrating these models' complementary relational and\ncommunicative data may be especially helpful if predicting rare events or\nclassifying members of hidden populations - tasks requiring huge and sparse\ndatasets for generalizable analyses. For example, due to social stigma and\ncomorbidities, mental health support groups often form in amorphous online\ngroups. Predicting suicidality among individuals in these settings using\nstandard network analyses is prohibitive due to resource limits (e.g., memory),\nand adding auxiliary data like text to such models exacerbates complexity- and\nsparsity-related issues. Here, I show how merging graph and language embedding\nmodels (metapath2vec and doc2vec) avoids these limits and extracts unsupervised\nclustering data without domain expertise or feature engineering. Graph and\nlanguage distances to a suicide support group have little correlation (\\r{ho} <\n0.23), implying the two models are not embedding redundant information. When\nused separately to predict suicidality among individuals, graph and language\ndata generate relatively accurate results (69% and 76%, respectively); however,\nwhen integrated, both data produce highly accurate predictions (90%, with 10%\nfalse-positives and 12% false-negatives). Visualizing graph embeddings\nannotated with predictions of potentially suicidal individuals shows the\nintegrated model could classify such individuals even if they are positioned\nfar from the support group. These results extend research on the importance of\nsimultaneously analyzing behavior and language in massive networks and efforts\nto integrate embedding models for different kinds of data when predicting and\nclassifying, particularly when they involve rare events.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 20:56:21 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ruch", "Alexander", ""]]}, {"id": "2001.01140", "submitter": "Kareem Nassar", "authors": "Kareem Nassar", "title": "Transformer-based language modeling and decoding for conversational\n  speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a way to use a transformer-based language model in conversational\nspeech recognition. Specifically, we focus on decoding efficiently in a\nweighted finite-state transducer framework. We showcase an approach to lattice\nre-scoring that allows for longer range history captured by a transfomer-based\nlanguage model and takes advantage of a transformer's ability to avoid\ncomputing sequentially.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 23:27:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Nassar", "Kareem", ""]]}, {"id": "2001.01167", "submitter": "Brian Lester", "authors": "Brian Lester, Daniel Pressel, Amy Hemmeter, and Sagnik Ray Choudhury", "title": "Computationally Efficient NER Taggers with Combined Embeddings and\n  Constrained Decoding", "comments": "This paper has since been split into two. See arXiv:2009.14394 for\n  the paper on Combined Embeddings and arXiv:2010.04362 for the paper on\n  Constrained Decoding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current State-of-the-Art models in Named Entity Recognition (NER) are neural\nmodels with a Conditional Random Field (CRF) as the final network layer, and\npre-trained \"contextual embeddings\". The CRF layer is used to facilitate global\ncoherence between labels, and the contextual embeddings provide a better\nrepresentation of words in context. However, both of these improvements come at\na high computational cost. In this work, we explore two simple techniques that\nsubstantially improve NER performance over a strong baseline with negligible\ncost. First, we use multiple pre-trained embeddings as word representations via\nconcatenation. Second, we constrain the tagger, trained using a cross-entropy\nloss, during decoding to eliminate illegal transitions. While training a tagger\non CoNLL 2003 we find a $786$\\% speed-up over a contextual embeddings-based\ntagger without sacrificing strong performance. We also show that the\nconcatenation technique works across multiple tasks and datasets. We analyze\naspects of similarity and coverage between pre-trained embeddings and the\ndynamics of tag co-occurrence to explain why these techniques work. We provide\nan open source implementation of our tagger using these techniques in three\npopular deep learning frameworks --- TensorFlow, Pytorch, and DyNet.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 04:50:38 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:21:07 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Lester", "Brian", ""], ["Pressel", "Daniel", ""], ["Hemmeter", "Amy", ""], ["Choudhury", "Sagnik Ray", ""]]}, {"id": "2001.01243", "submitter": "Xue Han", "authors": "Xue Han, Lianxue Hu, Yabin Dang, Shivali Agarwal, Lijun Mei, Shaochun\n  Li, Xin Zhou", "title": "Automatic Business Process Structure Discovery using Ordered Neurons\n  LSTM: A Preliminary Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic process discovery from textual process documentations is highly\ndesirable to reduce time and cost of Business Process Management (BPM)\nimplementation in organizations. However, existing automatic process discovery\napproaches mainly focus on identifying activities out of the documentations.\nDeriving the structural relationships between activities, which is important in\nthe whole process discovery scope, is still a challenge. In fact, a business\nprocess has latent semantic hierarchical structure which defines different\nlevels of detail to reflect the complex business logic. Recent findings in\nneural machine learning area show that the meaningful linguistic structure can\nbe induced by joint language modeling and structure learning. Inspired by these\nfindings, we propose to retrieve the latent hierarchical structure present in\nthe textual business process documents by building a neural network that\nleverages a novel recurrent architecture, Ordered Neurons LSTM (ON-LSTM), with\nprocess-level language model objective. We tested the proposed approach on data\nset of Process Description Documents (PDD) from our practical Robotic Process\nAutomation (RPA) projects. Preliminary experiments showed promising results.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 14:19:11 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Han", "Xue", ""], ["Hu", "Lianxue", ""], ["Dang", "Yabin", ""], ["Agarwal", "Shivali", ""], ["Mei", "Lijun", ""], ["Li", "Shaochun", ""], ["Zhou", "Xin", ""]]}, {"id": "2001.01269", "submitter": "Cem R{\\i}fk{\\i} Ayd{\\i}n Ph.D.", "authors": "Cem R{\\i}fk{\\i} Ayd{\\i}n, Tunga G\\\"ung\\\"or, Ali Erkan", "title": "Generating Word and Document Embeddings for Sentiment Analysis", "comments": "Accepted and presented as a full paper at the 20th International\n  Conference on Computational Linguistics and Intelligent Text Processing\n  (CICLing 2019), April 7-13, 2019, La Rochelle, France", "journal-ref": "Springer LNCS Proceedings for CICLing 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiments of words differ from one corpus to another. Inducing general\nsentiment lexicons for languages and using them cannot, in general, produce\nmeaningful results for different domains. In this paper, we combine contextual\nand supervised information with the general semantic representations of words\noccurring in the dictionary. Contexts of words help us capture the\ndomain-specific information and supervised scores of words are indicative of\nthe polarities of those words. When we combine supervised features of words\nwith the features extracted from their dictionary definitions, we observe an\nincrease in the success rates. We try out the combinations of contextual,\nsupervised, and dictionary-based approaches, and generate original vectors. We\nalso combine the word2vec approach with hand-crafted features. We induce\ndomain-specific sentimental vectors for two corpora, which are the movie domain\nand the Twitter datasets in Turkish. When we thereafter generate document\nvectors and employ the support vector machines method utilising those vectors,\nour approaches perform better than the baseline studies for Turkish with a\nsignificant margin. We evaluated our models on two English corpora as well and\nthese also outperformed the word2vec approach. It shows that our approaches are\ncross-domain and portable to other languages.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 16:34:32 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 18:33:45 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ayd\u0131n", "Cem R\u0131fk\u0131", ""], ["G\u00fcng\u00f6r", "Tunga", ""], ["Erkan", "Ali", ""]]}, {"id": "2001.01323", "submitter": "Jishnu Ray Chowdhury", "authors": "Jishnu Ray Chowdhury, Cornelia Caragea, Doina Caragea", "title": "On Identifying Hashtags in Disaster Twitter Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tweet hashtags have the potential to improve the search for information\nduring disaster events. However, there is a large number of disaster-related\ntweets that do not have any user-provided hashtags. Moreover, only a small\nnumber of tweets that contain actionable hashtags are useful for disaster\nresponse. To facilitate progress on automatic identification (or extraction) of\ndisaster hashtags for Twitter data, we construct a unique dataset of\ndisaster-related tweets annotated with hashtags useful for filtering actionable\ninformation. Using this dataset, we further investigate Long Short Term\nMemory-based models within a Multi-Task Learning framework. The best performing\nmodel achieves an F1-score as high as 92.22%. The dataset, code, and other\nresources are available on Github.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 22:37:17 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chowdhury", "Jishnu Ray", ""], ["Caragea", "Cornelia", ""], ["Caragea", "Doina", ""]]}, {"id": "2001.01447", "submitter": "Shuang Chen", "authors": "Shuang Chen, Jinpeng Wang, Feng Jiang, Chin-Yew Lin", "title": "Improving Entity Linking by Modeling Latent Entity Type Information", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing state of the art neural entity linking models employ attention-based\nbag-of-words context model and pre-trained entity embeddings bootstrapped from\nword embeddings to assess topic level context compatibility. However, the\nlatent entity type information in the immediate context of the mention is\nneglected, which causes the models often link mentions to incorrect entities\nwith incorrect type. To tackle this problem, we propose to inject latent entity\ntype information into the entity embeddings based on pre-trained BERT. In\naddition, we integrate a BERT-based entity similarity score into the local\ncontext model of a state-of-the-art model to better capture latent entity type\ninformation. Our model significantly outperforms the state-of-the-art entity\nlinking models on standard benchmark (AIDA-CoNLL). Detailed experiment analysis\ndemonstrates that our model corrects most of the type errors produced by the\ndirect baseline.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 09:18:29 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chen", "Shuang", ""], ["Wang", "Jinpeng", ""], ["Jiang", "Feng", ""], ["Lin", "Chin-Yew", ""]]}, {"id": "2001.01557", "submitter": "Zhiyun Fan", "authors": "Zhiyun Fan, Jie Li, Shiyu Zhou, Bo Xu", "title": "Speaker-aware speech-transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, end-to-end (E2E) models become a competitive alternative to the\nconventional hybrid automatic speech recognition (ASR) systems. However, they\nstill suffer from speaker mismatch in training and testing condition. In this\npaper, we use Speech-Transformer (ST) as the study platform to investigate\nspeaker aware training of E2E models. We propose a model called Speaker-Aware\nSpeech-Transformer (SAST), which is a standard ST equipped with a speaker\nattention module (SAM). The SAM has a static speaker knowledge block (SKB) that\nis made of i-vectors. At each time step, the encoder output attends to the\ni-vectors in the block, and generates a weighted combined speaker embedding\nvector, which helps the model to normalize the speaker variations. The SAST\nmodel trained in this way becomes independent of specific training speakers and\nthus generalizes better to unseen testing speakers. We investigate different\nfactors of SAM. Experimental results on the AISHELL-1 task show that SAST\nachieves a relative 6.5% CER reduction (CERR) over the speaker-independent (SI)\nbaseline. Moreover, we demonstrate that SAST still works quite well even if the\ni-vectors in SKB all come from a different data source other than the acoustic\ntraining set.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:04:08 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Fan", "Zhiyun", ""], ["Li", "Jie", ""], ["Zhou", "Shiyu", ""], ["Xu", "Bo", ""]]}, {"id": "2001.01565", "submitter": "Johannes Daxenberger", "authors": "Benjamin Schiller, Johannes Daxenberger, Iryna Gurevych", "title": "Stance Detection Benchmark: How Robust Is Your Stance Detection?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stance Detection (StD) aims to detect an author's stance towards a certain\ntopic or claim and has become a key component in applications like fake news\ndetection, claim validation, and argument search. However, while stance is\neasily detected by humans, machine learning models are clearly falling short of\nthis task. Given the major differences in dataset sizes and framing of StD\n(e.g. number of classes and inputs), we introduce a StD benchmark that learns\nfrom ten StD datasets of various domains in a multi-dataset learning (MDL)\nsetting, as well as from related tasks via transfer learning. Within this\nbenchmark setup, we are able to present new state-of-the-art results on five of\nthe datasets. Yet, the models still perform well below human capabilities and\neven simple adversarial attacks severely hurt the performance of MDL models.\nDeeper investigation into this phenomenon suggests the existence of biases\ninherited from multiple datasets by design. Our analysis emphasizes the need of\nfocus on robustness and de-biasing strategies in multi-task learning\napproaches. The benchmark dataset and code is made available.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 13:37:51 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Schiller", "Benjamin", ""], ["Daxenberger", "Johannes", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2001.01582", "submitter": "Hossein Amirkhani", "authors": "Razieh Baradaran, Razieh Ghiasi, and Hossein Amirkhani", "title": "A Survey on Machine Reading Comprehension Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension is a challenging task and hot topic in natural\nlanguage processing. Its goal is to develop systems to answer the questions\nregarding a given context. In this paper, we present a comprehensive survey on\ndifferent aspects of machine reading comprehension systems, including their\napproaches, structures, input/outputs, and research novelties. We illustrate\nthe recent trends in this field based on 241 reviewed papers from 2016 to 2020.\nOur investigations demonstrate that the focus of research has changed in recent\nyears from answer extraction to answer generation, from single to\nmulti-document reading comprehension, and from learning from scratch to using\npre-trained embeddings. We also discuss the popular datasets and the evaluation\nmetrics in this field. The paper ends with investigating the most cited papers\nand their contributions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 13:54:06 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:50:51 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Baradaran", "Razieh", ""], ["Ghiasi", "Razieh", ""], ["Amirkhani", "Hossein", ""]]}, {"id": "2001.01588", "submitter": "Chantana Chantrapornchai", "authors": "Chantana Chantrapornchai, Aphisit Tunsakul", "title": "Information Extraction based on Named Entity for Tourism Corpus", "comments": "6 pages, 9 figures", "journal-ref": "16th International Joint Conference on Computer Science and\n  Software Engineering (JCSSE), 2019, pp. 187-192", "doi": "10.1109/JCSSE.2019.8864166", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Tourism information is scattered around nowadays. To search for the\ninformation, it is usually time consuming to browse through the results from\nsearch engine, select and view the details of each accommodation. In this\npaper, we present a methodology to extract particular information from full\ntext returned from the search engine to facilitate the users. Then, the users\ncan specifically look to the desired relevant information. The approach can be\nused for the same task in other domains. The main steps are 1) building\ntraining data and 2) building recognition model. First, the tourism data is\ngathered and the vocabularies are built. The raw corpus is used to train for\ncreating vocabulary embedding. Also, it is used for creating annotated data.\nThe process of creating named entity annotation is presented. Then, the\nrecognition model of a given entity type can be built. From the experiments,\ngiven hotel description, the model can extract the desired entity,i.e, name,\nlocation, facility. The extracted data can further be stored as a structured\ninformation, e.g., in the ontology format, for future querying and inference.\nThe model for automatic named entity identification, based on machine learning,\nyields the error ranging 8%-25%.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:16:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chantrapornchai", "Chantana", ""], ["Tunsakul", "Aphisit", ""]]}, {"id": "2001.01589", "submitter": "Yirong Pan", "authors": "Yirong Pan, Xiao Li, Yating Yang and Rui Dong", "title": "Morphological Word Segmentation on Agglutinative Languages for Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has achieved impressive performance on\nmachine translation task in recent years. However, in consideration of\nefficiency, a limited-size vocabulary that only contains the top-N highest\nfrequency words are employed for model training, which leads to many rare and\nunknown words. It is rather difficult when translating from the low-resource\nand morphologically-rich agglutinative languages, which have complex morphology\nand large vocabulary. In this paper, we propose a morphological word\nsegmentation method on the source-side for NMT that incorporates morphology\nknowledge to preserve the linguistic and semantic information in the word\nstructure while reducing the vocabulary size at training time. It can be\nutilized as a preprocessing tool to segment the words in agglutinative\nlanguages for other natural language processing (NLP) tasks. Experimental\nresults show that our morphologically motivated word segmentation method is\nbetter suitable for the NMT model, which achieves significant improvements on\nTurkish-English and Uyghur-Chinese machine translation tasks on account of\nreducing data sparseness and language complexity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 10:05:02 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Pan", "Yirong", ""], ["Li", "Xiao", ""], ["Yang", "Yating", ""], ["Dong", "Rui", ""]]}, {"id": "2001.01595", "submitter": "Jean-Baptiste Camps", "authors": "Florian Cafiero and Jean-Baptiste Camps", "title": "Why Moli\\`ere most likely did write his plays", "comments": null, "journal-ref": "Science Advances, 27 Nov 2019: Vol. 5, no. 11, eaax5489", "doi": "10.1126/sciadv.aax5489", "report-no": null, "categories": "cs.CL stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As for Shakespeare, a hard-fought debate has emerged about Moli\\`ere, a\nsupposedly uneducated actor who, according to some, could not have written the\nmasterpieces attributed to him. In the past decades, the century-old thesis\naccording to which Pierre Corneille would be their actual author has become\npopular, mostly because of new works in computational linguistics. These\nresults are reassessed here through state-of-the-art attribution methods. We\nstudy a corpus of comedies in verse by major authors of Moli\\`ere and\nCorneille's time. Analysis of lexicon, rhymes, word forms, affixes,\nmorphosyntactic sequences, and function words do not give any clue that another\nauthor among the major playwrights of the time would have written the plays\nsigned under the name Moli\\`ere.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:23:11 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Cafiero", "Florian", ""], ["Camps", "Jean-Baptiste", ""]]}, {"id": "2001.01622", "submitter": "Tom Kocmi", "authors": "Tom Kocmi", "title": "Exploring Benefits of Transfer Learning in Neural Machine Translation", "comments": "Defended PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation is known to require large numbers of parallel\ntraining sentences, which generally prevent it from excelling on low-resource\nlanguage pairs. This thesis explores the use of cross-lingual transfer learning\non neural networks as a way of solving the problem with the lack of resources.\nWe propose several transfer learning approaches to reuse a model pretrained on\na high-resource language pair. We pay particular attention to the simplicity of\nthe techniques. We study two scenarios: (a) when we reuse the high-resource\nmodel without any prior modifications to its training process and (b) when we\ncan prepare the first-stage high-resource model for transfer learning in\nadvance. For the former scenario, we present a proof-of-concept method by\nreusing a model trained by other researchers. In the latter scenario, we\npresent a method which reaches even larger improvements in translation\nperformance. Apart from proposed techniques, we focus on an in-depth analysis\nof transfer learning techniques and try to shed some light on transfer learning\nimprovements. We show how our techniques address specific problems of\nlow-resource languages and are suitable even in high-resource transfer\nlearning. We evaluate the potential drawbacks and behavior by studying transfer\nlearning in various situations, for example, under artificially damaged\ntraining corpora, or with fixed various model parts.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:11:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kocmi", "Tom", ""]]}, {"id": "2001.01669", "submitter": "Mi Khine Oo", "authors": "Mi Khine Oo and May Aye Khine", "title": "Topic Extraction of Crawled Documents Collection using Correlated Topic\n  Model in MapReduce Framework", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous increase in the amount of available research documents impels\nresearchers to propose topic models to extract the latent semantic themes of a\ndocuments collection. However, how to extract the hidden topics of the\ndocuments collection has become a crucial task for many topic model\napplications. Moreover, conventional topic modeling approaches suffer from the\nscalability problem when the size of documents collection increases. In this\npaper, the Correlated Topic Model with variational Expectation-Maximization\nalgorithm is implemented in MapReduce framework to solve the scalability\nproblem. The proposed approach utilizes the dataset crawled from the public\ndigital library. In addition, the full-texts of the crawled documents are\nanalysed to enhance the accuracy of MapReduce CTM. The experiments are\nconducted to demonstrate the performance of the proposed algorithm. From the\nevaluation, the proposed approach has a comparable performance in terms of\ntopic coherences with LDA implemented in MapReduce framework.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:09:21 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Oo", "Mi Khine", ""], ["Khine", "May Aye", ""]]}, {"id": "2001.01795", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yashesh Gaur, Jinyu Li, Yifan Gong", "title": "Character-Aware Attention-Based End-to-End Speech Recognition", "comments": "7 pages, 3 figures, ASRU 2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting words and subword units (WSUs) as the output has shown to be\neffective for the attention-based encoder-decoder (AED) model in end-to-end\nspeech recognition. However, as one input to the decoder recurrent neural\nnetwork (RNN), each WSU embedding is learned independently through context and\nacoustic information in a purely data-driven fashion. Little effort has been\nmade to explicitly model the morphological relationships among WSUs. In this\nwork, we propose a novel character-aware (CA) AED model in which each WSU\nembedding is computed by summarizing the embeddings of its constituent\ncharacters using a CA-RNN. This WSU-independent CA-RNN is jointly trained with\nthe encoder, the decoder and the attention network of a conventional AED to\npredict WSUs. With CA-AED, the embeddings of morphologically similar WSUs are\nnaturally and directly correlated through the CA-RNN in addition to the\nsemantic and acoustic relations modeled by a traditional AED. Moreover, CA-AED\nsignificantly reduces the model parameters in a traditional AED by replacing\nthe large pool of WSU embeddings with a much smaller set of character\nembeddings. On a 3400 hours Microsoft Cortana dataset, CA-AED achieves up to\n11.9% relative WER improvement over a strong AED baseline with 27.1% fewer\nmodel parameters.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:19:17 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Meng", "Zhong", ""], ["Gaur", "Yashesh", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2001.01798", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yashesh Gaur, Yifan Gong", "title": "Domain Adaptation via Teacher-Student Learning for End-to-End Speech\n  Recognition", "comments": "8 pages, 2 figures, ASRU 2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teacher-student (T/S) has shown to be effective for domain adaptation of deep\nneural network acoustic models in hybrid speech recognition systems. In this\nwork, we extend the T/S learning to large-scale unsupervised domain adaptation\nof an attention-based end-to-end (E2E) model through two levels of knowledge\ntransfer: teacher's token posteriors as soft labels and one-best predictions as\ndecoder guidance. To further improve T/S learning with the help of ground-truth\nlabels, we propose adaptive T/S (AT/S) learning. Instead of conditionally\nchoosing from either the teacher's soft token posteriors or the one-hot\nground-truth label, in AT/S, the student always learns from both the teacher\nand the ground truth with a pair of adaptive weights assigned to the soft and\none-hot labels quantifying the confidence on each of the knowledge sources. The\nconfidence scores are dynamically estimated at each decoder step as a function\nof the soft and one-hot labels. With 3400 hours parallel close-talk and\nfar-field Microsoft Cortana data for domain adaptation, T/S and AT/S achieve\n6.3% and 10.3% relative word error rate improvement over a strong E2E model\ntrained with the same amount of far-field data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:30:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Meng", "Zhong", ""], ["Li", "Jinyu", ""], ["Gaur", "Yashesh", ""], ["Gong", "Yifan", ""]]}, {"id": "2001.01819", "submitter": "Austin Wright", "authors": "Austin P. Wright, Omar Shaikh, Haekyu Park, Will Epperson, Muhammed\n  Ahmed, Stephane Pinel, Diyi Yang, Duen Horng Chau", "title": "RECAST: Interactive Auditing of Automatic Toxicity Detection Models", "comments": "8 Pages, 3 figures, The eighth International Workshop of Chinese CHI\n  Proceedings", "journal-ref": null, "doi": "10.1145/3403676.3403691", "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As toxic language becomes nearly pervasive online, there has been increasing\ninterest in leveraging the advancements in natural language processing (NLP),\nfrom very large transformer models to automatically detecting and removing\ntoxic comments. Despite the fairness concerns, lack of adversarial robustness,\nand limited prediction explainability for deep learning systems, there is\ncurrently little work for auditing these systems and understanding how they\nwork for both developers and users. We present our ongoing work, RECAST, an\ninteractive tool for examining toxicity detection models by visualizing\nexplanations for predictions and providing alternative wordings for detected\ntoxic speech.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:17:52 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 15:36:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wright", "Austin P.", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Epperson", "Will", ""], ["Ahmed", "Muhammed", ""], ["Pinel", "Stephane", ""], ["Yang", "Diyi", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.01863", "submitter": "Zakaria Kurdi", "authors": "M. Zakaria Kurdi", "title": "Text Complexity Classification Based on Linguistic Information:\n  Application to Intelligent Tutoring of ESL", "comments": "This is an unpublished pre-print, the JDMDH journal requires\n  submission to arxiv.org before the submission to the journal (see the link:\n  https://jdmdh.episciences.org/page/submissions#)", "journal-ref": "Journal of Data Mining & Digital Humanities, 2020 (September 19,\n  2020) jdmdh:6674", "doi": "10.46298/jdmdh.6012", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to build a classifier that can identify text\ncomplexity within the context of teaching reading to English as a Second\nLanguage (ESL) learners. To present language learners with texts that are\nsuitable to their level of English, a set of features that can describe the\nphonological, morphological, lexical, syntactic, discursive, and psychological\ncomplexity of a given text were identified. Using a corpus of 6171 texts, which\nhad already been classified into three different levels of difficulty by ESL\nexperts, different experiments were conducted with five machine learning\nalgorithms. The results showed that the adopted linguistic features provide a\ngood overall classification performance (F-Score = 0.97). A scalability\nevaluation was conducted to test if such a classifier could be used within real\napplications, where it can be, for example, plugged into a search engine or a\nweb-scraping module. In this evaluation, the texts in the test set are not only\ndifferent from those from the training set but also of different types (ESL\ntexts vs. children reading texts). Although the overall performance of the\nclassifier decreased significantly (F-Score = 0.65), the confusion matrix shows\nthat most of the classification errors are between the classes two and three\n(the middle-level classes) and that the system has a robust performance in\ncategorizing texts of class one and four. This behavior can be explained by the\ndifference in classification criteria between the two corpora. Hence, the\nobserved results confirm the usability of such a classifier within a real-world\napplication.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:42:57 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 21:17:31 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 10:36:02 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 03:11:49 GMT"}, {"version": "v5", "created": "Sun, 14 Jun 2020 20:38:03 GMT"}, {"version": "v6", "created": "Wed, 24 Jun 2020 15:55:51 GMT"}, {"version": "v7", "created": "Wed, 29 Jul 2020 14:33:08 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Kurdi", "M. Zakaria", ""]]}, {"id": "2001.01871", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu, Jamin Shin, Pascale\n  Fung", "title": "Attention over Parameters for Dialogue Systems", "comments": "NeurIPS Conversational AI Workshops (Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems require a great deal of different but complementary\nexpertise to assist, inform, and entertain humans. For example, different\ndomains (e.g., restaurant reservation, train ticket booking) of goal-oriented\ndialogue systems can be viewed as different skills, and so does ordinary\nchatting abilities of chit-chat dialogue systems. In this paper, we propose to\nlearn a dialogue system that independently parameterizes different dialogue\nskills, and learns to select and combine each of them through Attention over\nParameters (AoP). The experimental results show that this approach achieves\ncompetitive performance on a combined dataset of MultiWOZ, In-Car Assistant,\nand Persona-Chat. Finally, we demonstrate that each dialogue skill is\neffectively learned and can be combined with other skills to produce selective\nresponses.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 03:10:42 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:02:14 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Wu", "Chien-Sheng", ""], ["Shin", "Jamin", ""], ["Fung", "Pascale", ""]]}, {"id": "2001.01895", "submitter": "Philip Andrew Collender", "authors": "Philip A. Collender, Zhiyue Tom Hu, Charles Li, Qu Cheng, Xintong Li,\n  Yue You, Song Liang, Changhong Yang, Justin V. Remais", "title": "Machine-learning classifiers for logographic name matching in public\n  health applications: approaches for incorporating phonetic, visual, and\n  keystroke similarity in large-scale probabilistic record linkage", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Approximate string-matching methods to account for complex variation in\nhighly discriminatory text fields, such as personal names, can enhance\nprobabilistic record linkage. However, discriminating between matching and\nnon-matching strings is challenging for logographic scripts, where similarities\nin pronunciation, appearance, or keystroke sequence are not directly encoded in\nthe string data. We leverage a large Chinese administrative dataset with known\nmatch status to develop logistic regression and Xgboost classifiers integrating\nmeasures of visual, phonetic, and keystroke similarity to enhance\nidentification of potentially-matching name pairs. We evaluate three methods of\nleveraging name similarity scores in large-scale probabilistic record linkage,\nwhich can adapt to varying match prevalence and information in supporting\nfields: (1) setting a threshold score based on predicted quality of\nname-matching across all record pairs; (2) setting a threshold score based on\npredicted discriminatory power of the linkage model; and (3) using empirical\nscore distributions among matches and nonmatches to perform Bayesian adjustment\nof matching probabilities estimated from exact-agreement linkage. In\nexperiments on holdout data, as well as data simulated with varying name error\nrates and supporting fields, a logistic regression classifier incorporated via\nthe Bayesian method demonstrated marked improvements over exact-agreement\nlinkage with respect to discriminatory power, match probability estimation, and\naccuracy, reducing the total number of misclassified record pairs by 21% in\ntest data and up to an average of 93% in simulated datasets. Our results\ndemonstrate the value of incorporating visual, phonetic, and keystroke\nsimilarity for logographic name matching, as well as the promise of our\nBayesian approach to leverage name-matching within large-scale record linkage.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:21:21 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Collender", "Philip A.", ""], ["Hu", "Zhiyue Tom", ""], ["Li", "Charles", ""], ["Cheng", "Qu", ""], ["Li", "Xintong", ""], ["You", "Yue", ""], ["Liang", "Song", ""], ["Yang", "Changhong", ""], ["Remais", "Justin V.", ""]]}, {"id": "2001.01941", "submitter": "Yao Fu", "authors": "Yao Fu, Yansong Feng and John P. Cunningham", "title": "Paraphrase Generation with Latent Bag of Words", "comments": "NeurIPS 19 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrase generation is a longstanding important problem in natural language\nprocessing.\n  In addition, recent progress in deep generative models has shown promising\nresults on discrete latent variables for text generation.\n  Inspired by variational autoencoders with discrete latent structures, in this\nwork, we propose a latent bag of words (BOW) model for paraphrase generation.\n  We ground the semantics of a discrete latent variable by the BOW from the\ntarget sentences.\n  We use this latent variable to build a fully differentiable content planning\nand surface realization model.\n  Specifically, we use source words to predict their neighbors and model the\ntarget BOW with a mixture of softmax.\n  We use Gumbel top-k reparameterization to perform differentiable subset\nsampling from the predicted BOW distribution.\n  We retrieve the sampled word embeddings and use them to augment the decoder\nand guide its generation search space.\n  Our latent BOW model not only enhances the decoder, but also exhibits clear\ninterpretability.\n  We show the model interpretability with regard to \\emph{(i)} unsupervised\nlearning of word neighbors \\emph{(ii)} the step-by-step generation procedure.\n  Extensive experiments demonstrate the transparent and effective generation\nprocess of this model.\\footnote{Our code can be found at\n\\url{https://github.com/FranxYao/dgm_latent_bow}}\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 09:22:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Fu", "Yao", ""], ["Feng", "Yansong", ""], ["Cunningham", "John P.", ""]]}, {"id": "2001.01986", "submitter": "Ke Ding", "authors": "Ke Ding and Xuanji He and Guanglu Wan", "title": "Learning Speaker Embedding with Momentum Contrast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification can be formulated as a representation learning task,\nwhere speaker-discriminative embeddings are extracted from utterances of\nvariable lengths. Momentum Contrast (MoCo) is a recently proposed unsupervised\nrepresentation learning framework, and has shown its effectiveness for learning\ngood feature representation for downstream vision tasks. In this work, we apply\nMoCo to learn speaker embedding from speech segments. We explore MoCo for both\nunsupervised learning and pretraining settings. In the unsupervised scenario,\nembedding is learned by MoCo from audio data without using any speaker specific\ninformation. On a large scale dataset with $2,500$ speakers, MoCo can achieve\nEER $4.275\\%$ trained unsupervisedly, and the EER can decrease further to\n$3.58\\%$ if extra unlabelled data are used. In the pretraining scenario,\nencoder trained by MoCo is used to initialize the downstream supervised\ntraining. With finetuning on the MoCo trained model, the equal error rate (EER)\nreduces $13.7\\%$ relative ($1.44\\%$ to $1.242\\%$) compared to a carefully tuned\nbaseline training from scratch. Comparative study confirms the effectiveness of\nMoCo learning good speaker embedding.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:47:05 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 08:00:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ding", "Ke", ""], ["He", "Xuanji", ""], ["Wan", "Guanglu", ""]]}, {"id": "2001.01989", "submitter": "Zhen Wu", "authors": "Zhen Wu, Fei Zhao, Xin-Yu Dai, Shujian Huang, Jiajun Chen", "title": "Latent Opinions Transfer Network for Target-Oriented Opinion Words\n  Extraction", "comments": "Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target-oriented opinion words extraction (TOWE) is a new subtask of ABSA,\nwhich aims to extract the corresponding opinion words for a given opinion\ntarget in a sentence. Recently, neural network methods have been applied to\nthis task and achieve promising results. However, the difficulty of annotation\ncauses the datasets of TOWE to be insufficient, which heavily limits the\nperformance of neural models. By contrast, abundant review sentiment\nclassification data are easily available at online review sites. These reviews\ncontain substantial latent opinions information and semantic patterns. In this\npaper, we propose a novel model to transfer these opinions knowledge from\nresource-rich review sentiment classification datasets to low-resource task\nTOWE. To address the challenges in the transfer process, we design an effective\ntransformation method to obtain latent opinions, then integrate them into TOWE.\nExtensive experimental results show that our model achieves better performance\ncompared to other state-of-the-art methods and significantly outperforms the\nbase model without transferring opinions knowledge. Further analysis validates\nthe effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:50:54 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wu", "Zhen", ""], ["Zhao", "Fei", ""], ["Dai", "Xin-Yu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "2001.02091", "submitter": "Chengkun Lang", "authors": "Huiwei Zhou, Zhuang Liu1, Shixian Ning, Chengkun Lang, Yingyu Lin, Lei\n  Du", "title": "Knowledge-aware Attention Network for Protein-Protein Interaction\n  Extraction", "comments": "Published on Journal of Biomedical Informatics, 14 pages, 5 figures", "journal-ref": "Journal of Biomedical Informatics, 2019, 96: 103234", "doi": "10.1016/j.jbi.2019.103234", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein-protein interaction (PPI) extraction from published scientific\nliterature provides additional support for precision medicine efforts. However,\nmany of the current PPI extraction methods need extensive feature engineering\nand cannot make full use of the prior knowledge in knowledge bases (KB). KBs\ncontain huge amounts of structured information about entities and\nrelationships, therefore plays a pivotal role in PPI extraction. This paper\nproposes a knowledge-aware attention network (KAN) to fuse prior knowledge\nabout protein-protein pairs and context information for PPI extraction. The\nproposed model first adopts a diagonal-disabled multi-head attention mechanism\nto encode context sequence along with knowledge representations learned from\nKB. Then a novel multi-dimensional attention mechanism is used to select the\nfeatures that can best describe the encoded context. Experiment results on the\nBioCreative VI PPI dataset show that the proposed approach could acquire\nknowledge-aware dependencies between different words in a sequence and lead to\na new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:02:28 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhou", "Huiwei", ""], ["Liu1", "Zhuang", ""], ["Ning", "Shixian", ""], ["Lang", "Chengkun", ""], ["Lin", "Yingyu", ""], ["Du", "Lei", ""]]}, {"id": "2001.02107", "submitter": "Chengkun Lang", "authors": "Huiwei Zhou, Zhuang Liu, Shixian Ning, Yunlong Yang, Chengkun Lang,\n  Yingyu Lin, Kun Ma", "title": "Leveraging Prior Knowledge for Protein-Protein Interaction Extraction\n  with Memory Network", "comments": "Published on Database-The Journal of Biological Databases and\n  Curation, 11 pages, 5 figures", "journal-ref": "Database-The Journal of Biological Databases and Curation, 2018,\n  2018: bay071", "doi": "10.1093/database/bay071", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically extracting Protein-Protein Interactions (PPI) from biomedical\nliterature provides additional support for precision medicine efforts. This\npaper proposes a novel memory network-based model (MNM) for PPI extraction,\nwhich leverages prior knowledge about protein-protein pairs with memory\nnetworks. The proposed MNM captures important context clues related to\nknowledge representations learned from knowledge bases. Both entity embeddings\nand relation embeddings of prior knowledge are effective in improving the PPI\nextraction model, leading to a new state-of-the-art performance on the\nBioCreative VI PPI dataset. The paper also shows that multiple computational\nlayers over an external memory are superior to long short-term memory networks\nwith the local memories.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:11:27 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhou", "Huiwei", ""], ["Liu", "Zhuang", ""], ["Ning", "Shixian", ""], ["Yang", "Yunlong", ""], ["Lang", "Chengkun", ""], ["Lin", "Yingyu", ""], ["Ma", "Kun", ""]]}, {"id": "2001.02178", "submitter": "Damian H. Zanette", "authors": "Andr\\'es Chacoma and Dami\\'an H. Zanette", "title": "Heaps' law and Heaps functions in tagged texts: Evidences of their\n  linguistic relevance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between vocabulary size and text length in a corpus\nof $75$ literary works in English, authored by six writers, distinguishing\nbetween the contributions of three grammatical classes (or ``tags,'' namely,\n{\\it nouns}, {\\it verbs}, and {\\it others}), and analyze the progressive\nappearance of new words of each tag along each individual text. While the\npower-law relation prescribed by Heaps' law is satisfactorily fulfilled by\ntotal vocabulary sizes and text lengths, the appearance of new words in each\ntext is on the whole well described by the average of random shufflings of the\ntext, which does not obey a power law. Deviations from this average, however,\nare statistically significant and show a systematic trend across the corpus.\nSpecifically, they reveal that the appearance of new words along each text is\npredominantly retarded with respect to the average of random shufflings.\nMoreover, different tags are shown to add systematically distinct contributions\nto this tendency, with {\\it verbs} and {\\it others} being respectively more and\nless retarded than the mean trend, and {\\it nouns} following instead this\noverall mean. These statistical systematicities are likely to point to the\nexistence of linguistically relevant information stored in the different\nvariants of Heaps' law, a feature that is still in need of extensive\nassessment.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 17:05:16 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Chacoma", "Andr\u00e9s", ""], ["Zanette", "Dami\u00e1n H.", ""]]}, {"id": "2001.02214", "submitter": "Nguyen Vo", "authors": "Di You, Nguyen Vo, Kyumin Lee, Qiang Liu", "title": "Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation", "comments": "CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 18:26:38 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["You", "Di", ""], ["Vo", "Nguyen", ""], ["Lee", "Kyumin", ""], ["Liu", "Qiang", ""]]}, {"id": "2001.02284", "submitter": "Alena Moiseeva", "authors": "Alena Moiseeva, Dietrich Trautmann, Michael Heimann, Hinrich Sch\\\"utze", "title": "Multipurpose Intelligent Process Automation via Conversational Assistant", "comments": "Presented at the AAAI-20 Workshop on Intelligent Process Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Process Automation (IPA) is an emerging technology with a primary\ngoal to assist the knowledge worker by taking care of repetitive, routine and\nlow-cognitive tasks. Conversational agents that can interact with users in a\nnatural language are potential application for IPA systems. Such intelligent\nagents can assist the user by answering specific questions and executing\nroutine tasks that are ordinarily performed in a natural language (i.e.,\ncustomer support). In this work, we tackle a challenge of implementing an IPA\nconversational assistant in a real-world industrial setting with a lack of\nstructured training data. Our proposed system brings two significant benefits:\nFirst, it reduces repetitive and time-consuming activities and, therefore,\nallows workers to focus on more intelligent processes. Second, by interacting\nwith users, it augments the resources with structured and to some extent\nlabeled training data. We showcase the usage of the latter by re-implementing\nseveral components of our system with Transfer Learning (TL) methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 21:47:37 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 12:10:49 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Moiseeva", "Alena", ""], ["Trautmann", "Dietrich", ""], ["Heimann", "Michael", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2001.02332", "submitter": "Pengda Qin", "authors": "Pengda Qin, Xin Wang, Wenhu Chen, Chunyun Zhang, Weiran Xu, William\n  Yang Wang", "title": "Generative Adversarial Zero-Shot Relational Learning for Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale knowledge graphs (KGs) are shown to become more important in\ncurrent information systems. To expand the coverage of KGs, previous studies on\nknowledge graph completion need to collect adequate training instances for\nnewly-added relations. In this paper, we consider a novel formulation,\nzero-shot learning, to free this cumbersome curation. For newly-added\nrelations, we attempt to learn their semantic features from their text\ndescriptions and hence recognize the facts of unseen relations with no examples\nbeing seen. For this purpose, we leverage Generative Adversarial Networks\n(GANs) to establish the connection between text and knowledge graph domain: The\ngenerator learns to generate the reasonable relation embeddings merely with\nnoisy text descriptions. Under this setting, zero-shot learning is naturally\nconverted to a traditional supervised classification task. Empirically, our\nmethod is model-agnostic that could be potentially applied to any version of KG\nembeddings, and consistently yields performance improvements on NELL and Wiki\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 01:19:08 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Qin", "Pengda", ""], ["Wang", "Xin", ""], ["Chen", "Wenhu", ""], ["Zhang", "Chunyun", ""], ["Xu", "Weiran", ""], ["Wang", "William Yang", ""]]}, {"id": "2001.02380", "submitter": "Yang Liu", "authors": "Amir Zeldes and Yang Liu", "title": "A Neural Approach to Discourse Relation Signal Detection", "comments": "33 pages, 7 figures. Submitted to Dialogue & Discourse (D&D);\n  Addressed reviewers' comments: strengthened arguments, added references,\n  corrected typos etc", "journal-ref": null, "doi": "10.5087/dad", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous data-driven work investigating the types and distributions of\ndiscourse relation signals, including discourse markers such as 'however' or\nphrases such as 'as a result' has focused on the relative frequencies of signal\nwords within and outside text from each discourse relation. Such approaches do\nnot allow us to quantify the signaling strength of individual instances of a\nsignal on a scale (e.g. more or less discourse-relevant instances of 'and'), to\nassess the distribution of ambiguity for signals, or to identify words that\nhinder discourse relation identification in context ('anti-signals' or\n'distractors'). In this paper we present a data-driven approach to signal\ndetection using a distantly supervised neural network and develop a metric,\nDelta s (or 'delta-softmax'), to quantify signaling strength. Ranging between\n-1 and 1 and relying on recent advances in contextualized words embeddings, the\nmetric represents each word's positive or negative contribution to the\nidentifiability of a relation in specific instances in context. Based on an\nEnglish corpus annotated for discourse relations using Rhetorical Structure\nTheory and signal type annotations anchored to specific tokens, our analysis\nexamines the reliability of the metric, the places where it overlaps with and\ndiffers from human judgments, and the implications for identifying features\nthat neural models may need in order to perform better on automatic discourse\nrelation classification.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 05:14:49 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 19:56:42 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zeldes", "Amir", ""], ["Liu", "Yang", ""]]}, {"id": "2001.02462", "submitter": "Nobuhiro Ito", "authors": "Nobuhiro Ito, Yuya Suzuki and Akiko Aizawa", "title": "From Natural Language Instructions to Complex Processes: Issues in\n  Chaining Trigger Action Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation services for complex business processes usually require a high\nlevel of information technology literacy. There is a strong demand for a\nsmartly assisted process automation (IPA: intelligent process automation)\nservice that enables even general users to easily use advanced automation. A\nnatural language interface for such automation is expected as an elemental\ntechnology for the IPA realization. The workflow targeted by IPA is generally\ncomposed of a combination of multiple tasks. However, semantic parsing, one of\nthe natural language processing methods, for such complex workflows has not yet\nbeen fully studied. The reasons are that (1) the formal expression and grammar\nof the workflow required for semantic analysis have not been sufficiently\nexamined and (2) the dataset of the workflow formal expression with its\ncorresponding natural language description required for learning workflow\nsemantics did not exist. This paper defines a new grammar for complex workflows\nwith chaining machine-executable meaning representations for semantic parsing.\nThe representations are at a high abstraction level. Additionally, an approach\nto creating datasets is proposed based on this grammar.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 11:44:47 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ito", "Nobuhiro", ""], ["Suzuki", "Yuya", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2001.02524", "submitter": "Mingyi Liu", "authors": "Mingyi Liu, Zhiying Tu, Tong Zhang, Tonghua Su, Zhongjie Wang", "title": "LTP: A New Active Learning Strategy for CRF-Based Named Entity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has achieved great success in many natural\nlanguage processing tasks including named entity recognition. The shortcoming\nis that a large amount of manually-annotated data is usually required. Previous\nstudies have demonstrated that active learning could elaborately reduce the\ncost of data annotation, but there is still plenty of room for improvement. In\nreal applications we found existing uncertainty-based active learning\nstrategies have two shortcomings. Firstly, these strategies prefer to choose\nlong sequence explicitly or implicitly, which increase the annotation burden of\nannotators. Secondly, some strategies need to invade the model and modify to\ngenerate some additional information for sample selection, which will increase\nthe workload of the developer and increase the training/prediction time of the\nmodel. In this paper, we first examine traditional active learning strategies\nin a specific case of BiLstm-CRF that has widely used in named entity\nrecognition on several typical datasets. Then we propose an uncertainty-based\nactive learning strategy called Lowest Token Probability (LTP) which combines\nthe input and output of CRF to select informative instance. LTP is simple and\npowerful strategy that does not favor long sequences and does not need to\ninvade the model. We test LTP on multiple datasets, and the experiments show\nthat LTP performs slightly better than traditional strategies with obviously\nless annotation tokens on both sentence-level accuracy and entity-level\nF1-score. Related code have been release on https://github.com/HIT-ICES/AL-NER\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:44:10 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 16:13:13 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Liu", "Mingyi", ""], ["Tu", "Zhiying", ""], ["Zhang", "Tong", ""], ["Su", "Tonghua", ""], ["Wang", "Zhongjie", ""]]}, {"id": "2001.02660", "submitter": "Joobin Gharibshah", "authors": "Joobin Gharibshah, Evangelos E. Papalexakis, Michalis Faloutsos", "title": "REST: A Thread Embedding Approach for Identifying and Classifying\n  User-specified Information in Security Forums", "comments": "Accepted in ICWSM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can we extract useful information from a security forum? We focus on\nidentifying threads of interest to a security professional: (a) alerts of\nworrisome events, such as attacks, (b) offering of malicious services and\nproducts, (c) hacking information to perform malicious acts, and (d) useful\nsecurity-related experiences. The analysis of security forums is in its infancy\ndespite several promising recent works. Novel approaches are needed to address\nthe challenges in this domain: (a) the difficulty in specifying the \"topics\" of\ninterest efficiently, and (b) the unstructured and informal nature of the text.\nWe propose, REST, a systematic methodology to: (a) identify threads of interest\nbased on a, possibly incomplete, bag of words, and (b) classify them into one\nof the four classes above. The key novelty of the work is a multi-step weighted\nembedding approach: we project words, threads and classes in appropriate\nembedding spaces and establish relevance and similarity there. We evaluate our\nmethod with real data from three security forums with a total of 164k posts and\n21K threads. First, REST robustness to initial keyword selection can extend the\nuser-provided keyword set and thus, it can recover from missing keywords.\nSecond, REST categorizes the threads into the classes of interest with superior\naccuracy compared to five other methods: REST exhibits an accuracy between\n63.3-76.9%. We see our approach as a first step for harnessing the wealth of\ninformation of online forums in a user-friendly way, since the user can loosely\nspecify her keywords of interest.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:04:52 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 19:14:16 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Gharibshah", "Joobin", ""], ["Papalexakis", "Evangelos E.", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "2001.02669", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Manish Sharma, Vijaya Saradhi", "title": "A Correspondence Analysis Framework for Author-Conference\n  Recommendations", "comments": "49 pages including references, 6 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many years, achievements and discoveries made by scientists are made\naware through research papers published in appropriate journals or conferences.\nOften, established scientists and especially newbies are caught up in the\ndilemma of choosing an appropriate conference to get their work through. Every\nscientific conference and journal is inclined towards a particular field of\nresearch and there is a vast multitude of them for any particular field.\nChoosing an appropriate venue is vital as it helps in reaching out to the right\naudience and also to further one's chance of getting their paper published. In\nthis work, we address the problem of recommending appropriate conferences to\nthe authors to increase their chances of acceptance. We present three different\napproaches for the same involving the use of social network of the authors and\nthe content of the paper in the settings of dimensionality reduction and topic\nmodeling. In all these approaches, we apply Correspondence Analysis (CA) to\nderive appropriate relationships between the entities in question, such as\nconferences and papers. Our models show promising results when compared with\nexisting methods such as content-based filtering, collaborative filtering and\nhybrid filtering.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:52:39 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Sharma", "Manish", ""], ["Saradhi", "Vijaya", ""]]}, {"id": "2001.02674", "submitter": "Niko Moritz", "authors": "Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Streaming automatic speech recognition with the transformer model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder based sequence-to-sequence models have demonstrated\nstate-of-the-art results in end-to-end automatic speech recognition (ASR).\nRecently, the transformer architecture, which uses self-attention to model\ntemporal context information, has been shown to achieve significantly lower\nword error rates (WERs) compared to recurrent neural network (RNN) based system\narchitectures. Despite its success, the practical usage is limited to offline\nASR tasks, since encoder-decoder architectures typically require an entire\nspeech utterance as input. In this work, we propose a transformer based\nend-to-end ASR system for streaming ASR, where an output must be generated\nshortly after each spoken word. To achieve this, we apply time-restricted\nself-attention for the encoder and triggered attention for the encoder-decoder\nattention mechanism. Our proposed streaming transformer architecture achieves\n2.8% and 7.2% WER for the \"clean\" and \"other\" test data of LibriSpeech, which\nto our knowledge is the best published streaming end-to-end ASR result for this\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:58:02 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 16:08:51 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 15:10:13 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 21:34:25 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2020 18:29:07 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2001.02731", "submitter": "Xumeng Chen", "authors": "Xumeng Chen, Leo Yu-Ho Lo, Huamin Qu", "title": "SirenLess: reveal the intention behind news", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News articles tend to be increasingly misleading nowadays, preventing readers\nfrom making subjective judgments towards certain events. While some machine\nlearning approaches have been proposed to detect misleading news, most of them\nare black boxes that provide limited help for humans in decision making. In\nthis paper, we present SirenLess, a visual analytical system for misleading\nnews detection by linguistic features. The system features article explorer, a\nnovel interactive tool that integrates news metadata and linguistic features to\nreveal semantic structures of news articles and facilitate textual analysis. We\nuse SirenLess to analyze 18 news articles from different sources and summarize\nsome helpful patterns for misleading news detection. A user study with\njournalism professionals and university students is conducted to confirm the\nusefulness and effectiveness of our system.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 20:36:17 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chen", "Xumeng", ""], ["Lo", "Leo Yu-Ho", ""], ["Qu", "Huamin", ""]]}, {"id": "2001.02836", "submitter": "Jiaxin Bai", "authors": "Hongming Zhang, Jiaxin Bai, Yan Song, Kun Xu, Changlong Yu, Yangqiu\n  Song, Wilfred Ng and Dong Yu", "title": "Multiplex Word Embeddings for Selectional Preference Acquisition", "comments": "emnlp-ijcnlp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional word embeddings represent words with fixed vectors, which are\nusually trained based on co-occurrence patterns among words. In doing so,\nhowever, the power of such representations is limited, where the same word\nmight be functionalized separately under different syntactic relations. To\naddress this limitation, one solution is to incorporate relational dependencies\nof different words into their embeddings. Therefore, in this paper, we propose\na multiplex word embedding model, which can be easily extended according to\nvarious relations among words. As a result, each word has a center embedding to\nrepresent its overall semantics, and several relational embeddings to represent\nits relational dependencies. Compared to existing models, our model can\neffectively distinguish words with respect to different relations without\nintroducing unnecessary sparseness. Moreover, to accommodate various relations,\nwe use a small dimension for relational embeddings and our model is able to\nkeep their effectiveness. Experiments on selectional preference acquisition and\nword similarity demonstrate the effectiveness of the proposed model, and a\nfurther study of scalability also proves that our embeddings only need 1/20 of\nthe original embedding size to achieve better performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 04:47:14 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhang", "Hongming", ""], ["Bai", "Jiaxin", ""], ["Song", "Yan", ""], ["Xu", "Kun", ""], ["Yu", "Changlong", ""], ["Song", "Yangqiu", ""], ["Ng", "Wilfred", ""], ["Yu", "Dong", ""]]}, {"id": "2001.02885", "submitter": "Benita Kathleen Britto", "authors": "Benita Kathleen Britto, Aditya Khandelwal", "title": "Resolving the Scope of Speculation and Negation using Transformer-Based\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speculation is a naturally occurring phenomena in textual data, forming an\nintegral component of many systems, especially in the biomedical information\nretrieval domain. Previous work addressing cue detection and scope resolution\n(the two subtasks of speculation detection) have ranged from rule-based systems\nto deep learning-based approaches. In this paper, we apply three popular\ntransformer-based architectures, BERT, XLNet and RoBERTa to this task, on two\npublicly available datasets, BioScope Corpus and SFU Review Corpus, reporting\nsubstantial improvements over previously reported results (by at least 0.29 F1\npoints on cue detection and 4.27 F1 points on scope resolution). We also\nexperiment with joint training of the model on multiple datasets, which\noutperforms the single dataset training approach by a good margin. We observe\nthat XLNet consistently outperforms BERT and RoBERTa, contrary to results on\nother benchmark datasets. To confirm this observation, we apply XLNet and\nRoBERTa to negation detection and scope resolution, reporting state-of-the-art\nresults on negation scope resolution for the BioScope Corpus (increase of 3.16\nF1 points on the BioScope Full Papers, 0.06 F1 points on the BioScope\nAbstracts) and the SFU Review Corpus (increase of 0.3 F1 points).\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:43:30 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Britto", "Benita Kathleen", ""], ["Khandelwal", "Aditya", ""]]}, {"id": "2001.02943", "submitter": "Liesbeth Allein", "authors": "Liesbeth Allein, Artuur Leeuwenberg and Marie-Francine Moens", "title": "Binary and Multitask Classification Model for Dutch Anaphora Resolution:\n  Die/Dat Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correct use of Dutch pronouns 'die' and 'dat' is a stumbling block for\nboth native and non-native speakers of Dutch due to the multiplicity of\nsyntactic functions and the dependency on the antecedent's gender and number.\nDrawing on previous research conducted on neural context-dependent dt-mistake\ncorrection models (Heyman et al. 2018), this study constructs the first neural\nnetwork model for Dutch demonstrative and relative pronoun resolution that\nspecifically focuses on the correction and part-of-speech prediction of these\ntwo pronouns. Two separate datasets are built with sentences obtained from,\nrespectively, the Dutch Europarl corpus (Koehn 2015) - which contains the\nproceedings of the European Parliament from 1996 to the present - and the SoNaR\ncorpus (Oostdijk et al. 2013) - which contains Dutch texts from a variety of\ndomains such as newspapers, blogs and legal texts. Firstly, a binary\nclassification model solely predicts the correct 'die' or 'dat'. The classifier\nwith a bidirectional long short-term memory architecture achieves 84.56%\naccuracy. Secondly, a multitask classification model simultaneously predicts\nthe correct 'die' or 'dat' and its part-of-speech tag. The model containing a\ncombination of a sentence and context encoder with both a bidirectional long\nshort-term memory architecture results in 88.63% accuracy for die/dat\nprediction and 87.73% accuracy for part-of-speech prediction. More\nevenly-balanced data, larger word embeddings, an extra bidirectional long\nshort-term memory layer and integrated part-of-speech knowledge positively\naffects die/dat prediction performance, while a context encoder architecture\nraises part-of-speech prediction performance. This study shows promising\nresults and can serve as a starting point for future research on machine\nlearning models for Dutch anaphora resolution.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 12:34:01 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:17:59 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Allein", "Liesbeth", ""], ["Leeuwenberg", "Artuur", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2001.03041", "submitter": "Tomasz Zi\\k{e}tkiewicz", "authors": "Marek Kubis, Zygmunt Vetulani, Miko{\\l}aj Wypych, Tomasz\n  Zi\\k{e}tkiewicz", "title": "Open Challenge for Correcting Errors of Speech Recognition Systems", "comments": null, "journal-ref": "Vetulani, Zygmunt, Paroubek, Patrick (eds.): Proceedings of the\n  9th Language and Technology Conference, pp. 219-223, Wydawnictwo Nauka i\n  Innowacje, Pozna\\'n, Poland, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper announces the new long-term challenge for improving the performance\nof automatic speech recognition systems. The goal of the challenge is to\ninvestigate methods of correcting the recognition results on the basis of\npreviously made errors by the speech processing system. The dataset prepared\nfor the task is described and evaluation criteria are presented.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:07:32 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Kubis", "Marek", ""], ["Vetulani", "Zygmunt", ""], ["Wypych", "Miko\u0142aj", ""], ["Zi\u0119tkiewicz", "Tomasz", ""]]}, {"id": "2001.03131", "submitter": "Vyshnav M T", "authors": "Vyshnav M T, Sachin Kumar S, Soman K P", "title": "Offensive Language Detection: A Comparative Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offensive behaviour has become pervasive in the Internet community.\nIndividuals take the advantage of anonymity in the cyber world and indulge in\noffensive communications which they may not consider in the real life.\nGovernments, online communities, companies etc are investing into prevention of\noffensive behaviour content in social media. One of the most effective solution\nfor tacking this enigmatic problem is the use of computational techniques to\nidentify offensive content and take action. The current work focuses on\ndetecting offensive language in English tweets. The dataset used for the\nexperiment is obtained from SemEval-2019 Task 6 on Identifying and Categorizing\nOffensive Language in Social Media (OffensEval). The dataset contains 14,460\nannotated English tweets. The present paper provides a comparative analysis and\nRandom kitchen sink (RKS) based approach for offensive language detection. We\nexplore the effectiveness of Google sentence encoder, Fasttext, Dynamic mode\ndecomposition (DMD) based features and Random kitchen sink (RKS) method for\noffensive language detection. From the experiments and evaluation we observed\nthat RKS with fastetxt achieved competing results. The evaluation measures used\nare accuracy, precision, recall, f1-score.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:48:44 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["T", "Vyshnav M", ""], ["S", "Sachin Kumar", ""], ["P", "Soman K", ""]]}, {"id": "2001.03216", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg and Sabine Schulte im Walde", "title": "Simulating Lexical Semantic Change from Sense-Annotated Data", "comments": "EvoLang, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel procedure to simulate lexical semantic change from\nsynchronic sense-annotated data, and demonstrate its usefulness for assessing\nlexical semantic change detection models. The induced dataset represents a\nstronger correspondence to empirically observed lexical semantic change than\nprevious synthetic datasets, because it exploits the intimate relationship\nbetween synchronic polysemy and diachronic change. We publish the data and\nprovide the first large-scale evaluation gold standard for LSC detection\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 20:37:49 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "2001.03278", "submitter": "Seung Hee Yang", "authors": "Sihyeon Jo, Seungryong Yoo, Sangwon Im, Seung Hee Yang, Tong Zuo,\n  Hee-Eun Kim, SangWook Han, Seong-Woo Kim", "title": "A Scalable Chatbot Platform Leveraging Online Community Posts: A\n  Proof-of-Concept Study", "comments": "To be Published on the 10th February, 2020, in HCI (Human-Computer\n  Interaction) Conference 2020, Republic of Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of natural language processing algorithms and the explosive\ngrowth of conversational data are encouraging researches on the human-computer\nconversation. Still, getting qualified conversational data on a large scale is\ndifficult and expensive. In this paper, we verify the feasibility of\nconstructing a data-driven chatbot with processed online community posts by\nusing them as pseudo-conversational data. We argue that chatbots for various\npurposes can be built extensively through the pipeline exploiting the common\nstructure of community posts. Our experiment demonstrates that chatbots created\nalong the pipeline can yield the proper responses.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 01:45:45 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Jo", "Sihyeon", ""], ["Yoo", "Seungryong", ""], ["Im", "Sangwon", ""], ["Yang", "Seung Hee", ""], ["Zuo", "Tong", ""], ["Kim", "Hee-Eun", ""], ["Han", "SangWook", ""], ["Kim", "Seong-Woo", ""]]}, {"id": "2001.03294", "submitter": "Gholamreza Haffari", "authors": "Poorya Zaremoodi, Gholamreza Haffari", "title": "Learning to Multi-Task Learn for Better Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of parallel sentence pairs is a major challenge for training high\nquality neural machine translation (NMT) models in bilingually low-resource\nscenarios, as NMT is data-hungry. Multi-task learning is an elegant approach to\ninject linguistic-related inductive biases into NMT, using auxiliary syntactic\nand semantic tasks, to improve generalisation. The challenge, however, is to\ndevise effective training schedules, prescribing when to make use of the\nauxiliary tasks during the training process to fill the knowledge gaps of the\nmain translation task, a setting referred to as biased-MTL. Current approaches\nfor the training schedule are based on hand-engineering heuristics, whose\neffectiveness vary in different MTL settings. We propose a novel framework for\nlearning the training schedule, ie learning to multi-task learn, for the MTL\nsetting of interest. We formulate the training schedule as a Markov decision\nprocess which paves the way to employ policy learning methods to learn the\nscheduling policy. We effectively and efficiently learn the training schedule\npolicy within the imitation learning framework using an oracle policy algorithm\nthat dynamically sets the importance weights of auxiliary tasks based on their\ncontributions to the generalisability of the main NMT task. Experiments on\nlow-resource NMT settings show the resulting automatically learned training\nschedulers are competitive with the best heuristics, and lead to up to +1.1\nBLEU score improvements.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 03:12:28 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zaremoodi", "Poorya", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2001.03303", "submitter": "Jacob Danovitch", "authors": "Jacob Danovitch", "title": "Linking Social Media Posts to News with Siamese Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computational social science projects examine online discourse\nsurrounding a specific trending topic. These works often involve the\nacquisition of large-scale corpora relevant to the event in question to analyze\naspects of the response to the event. Keyword searches present a\nprecision-recall trade-off and crowd-sourced annotations, while effective, are\ncostly. This work aims to enable automatic and accurate ad-hoc retrieval of\ncomments discussing a trending topic from a large corpus, using only a handful\nof seed news articles.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 04:39:44 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Danovitch", "Jacob", ""]]}, {"id": "2001.03324", "submitter": "Ibrahim Gashaw", "authors": "Ibrahim Gashaw and H L. Shashirekha", "title": "Machine Learning Approaches for Amharic Parts-of-speech Tagging", "comments": "15th International Conference on Natural Language Processing\n  (ICON-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Part-of-speech (POS) tagging is considered as one of the basic but necessary\ntools which are required for many Natural Language Processing (NLP)\napplications such as word sense disambiguation, information retrieval,\ninformation processing, parsing, question answering, and machine translation.\nPerformance of the current POS taggers in Amharic is not as good as that of the\ncontemporary POS taggers available for English and other European languages.\nThe aim of this work is to improve POS tagging performance for the Amharic\nlanguage, which was never above 91%. Usage of morphological knowledge, an\nextension of the existing annotated data, feature extraction, parameter tuning\nby applying grid search and the tagging algorithms have been examined and\nobtained significant performance difference from the previous works. We have\nused three different datasets for POS experiments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 06:40:49 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Gashaw", "Ibrahim", ""], ["Shashirekha", "H L.", ""]]}, {"id": "2001.03361", "submitter": "Gautier Dagan", "authors": "Gautier Dagan, Dieuwke Hupkes and Elia Bruni", "title": "Co-evolution of language and agents in referential games", "comments": "12 pages, 9 figures, EACL 2021 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referential games offer a grounded learning environment for neural agents\nwhich accounts for the fact that language is functionally used to communicate.\nHowever, they do not take into account a second constraint considered to be\nfundamental for the shape of human language: that it must be learnable by new\nlanguage learners.\n  Cogswell et al. (2019) introduced cultural transmission within referential\ngames through a changing population of agents to constrain the emerging\nlanguage to be learnable. However, the resulting languages remain inherently\nbiased by the agents' underlying capabilities.\n  In this work, we introduce Language Transmission Engine to model both\ncultural and architectural evolution in a population of agents. As our core\ncontribution, we empirically show that the optimal situation is to take into\naccount also the learning biases of the language learners and thus let language\nand agents co-evolve. When we allow the agent population to evolve through\narchitectural evolution, we achieve across the board improvements on all\nconsidered metrics and surpass the gains made with cultural transmission. These\nresults stress the importance of studying the underlying agent architecture and\npave the way to investigate the co-evolution of language and agent in language\nemergence studies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 09:29:20 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 21:29:07 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 09:33:04 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dagan", "Gautier", ""], ["Hupkes", "Dieuwke", ""], ["Bruni", "Elia", ""]]}, {"id": "2001.03369", "submitter": "Robin Brochier", "authors": "Robin Brochier, Adrien Guille and Julien Velcin", "title": "Inductive Document Network Embedding with Topic-Word Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document network embedding aims at learning representations for a structured\ntext corpus i.e. when documents are linked to each other. Recent algorithms\nextend network embedding approaches by incorporating the text content\nassociated with the nodes in their formulations. In most cases, it is hard to\ninterpret the learned representations. Moreover, little importance is given to\nthe generalization to new documents that are not observed within the network.\nIn this paper, we propose an interpretable and inductive document network\nembedding method. We introduce a novel mechanism, the Topic-Word Attention\n(TWA), that generates document representations based on the interplay between\nword and topic representations. We train these word and topic vectors through\nour general model, Inductive Document Network Embedding (IDNE), by leveraging\nthe connections in the document network. Quantitative evaluations show that our\napproach achieves state-of-the-art performance on various networks and we\nqualitatively show that our model produces meaningful and interpretable\nrepresentations of the words, topics and documents.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:14:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "2001.03436", "submitter": "Marcel Hildebrandt", "authors": "Marcel Hildebrandt, Jorge Andres Quintero Serna, Yunpu Ma, Martin\n  Ringsquandl, Mitchell Joblin, Volker Tresp", "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "comments": "AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text\n  overlap with arXiv:2001.00461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:19:45 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hildebrandt", "Marcel", ""], ["Serna", "Jorge Andres Quintero", ""], ["Ma", "Yunpu", ""], ["Ringsquandl", "Martin", ""], ["Joblin", "Mitchell", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.03521", "submitter": "Yiyuan Li", "authors": "Yiyuan Li, Antonios Anastasopoulos and Alan W Black", "title": "Towards Minimal Supervision BERT-based Grammar Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current grammatical error correction (GEC) models typically consider the task\nas sequence generation, which requires large amounts of annotated data and\nlimit the applications in data-limited settings. We try to incorporate\ncontextual information from pre-trained language model to leverage annotation\nand benefit multilingual scenarios. Results show strong potential of\nBidirectional Encoder Representations from Transformers (BERT) in grammatical\nerror correction task.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:45:59 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Li", "Yiyuan", ""], ["Anastasopoulos", "Antonios", ""], ["Black", "Alan W", ""]]}, {"id": "2001.03632", "submitter": "Tom McCoy", "authors": "R. Thomas McCoy, Robert Frank, Tal Linzen", "title": "Does syntax need to grow on trees? Sources of hierarchical inductive\n  bias in sequence-to-sequence networks", "comments": "12 pages, 10 figures; accepted to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learners that are exposed to the same training data might generalize\ndifferently due to differing inductive biases. In neural network models,\ninductive biases could in theory arise from any aspect of the model\narchitecture. We investigate which architectural factors affect the\ngeneralization behavior of neural sequence-to-sequence models trained on two\nsyntactic tasks, English question formation and English tense reinflection. For\nboth tasks, the training set is consistent with a generalization based on\nhierarchical structure and a generalization based on linear order. All\narchitectural factors that we investigated qualitatively affected how models\ngeneralized, including factors with no clear connection to hierarchical\nstructure. For example, LSTMs and GRUs displayed qualitatively different\ninductive biases. However, the only factor that consistently contributed a\nhierarchical bias across tasks was the use of a tree-structured model rather\nthan a model with sequential recurrence, suggesting that human-like syntactic\ngeneralization requires architectural syntactic structure.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 19:02:52 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["McCoy", "R. Thomas", ""], ["Frank", "Robert", ""], ["Linzen", "Tal", ""]]}, {"id": "2001.03671", "submitter": "Harsh Mehta", "authors": "Harsh Mehta, Yoav Artzi, Jason Baldridge, Eugene Ie, Piotr Mirowski", "title": "Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for\n  Language Grounding Tasks in Street View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Touchdown dataset (Chen et al., 2019) provides instructions by human\nannotators for navigation through New York City streets and for resolving\nspatial descriptions at a given location. To enable the wider research\ncommunity to work effectively with the Touchdown tasks, we are publicly\nreleasing the 29k raw Street View panoramas needed for Touchdown. We follow the\nprocess used for the StreetLearn data release (Mirowski et al., 2019) to check\npanoramas for personally identifiable information and blur them as necessary.\nThese have been added to the StreetLearn dataset and can be obtained via the\nsame process as used previously for StreetLearn. We also provide a reference\nimplementation for both of the Touchdown tasks: vision and language navigation\n(VLN) and spatial description resolution (SDR). We compare our model results to\nthose given in Chen et al. (2019) and show that the panoramas we have added to\nStreetLearn fully support both Touchdown tasks and can be used effectively for\nfurther research and comparison.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 21:35:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Mehta", "Harsh", ""], ["Artzi", "Yoav", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""], ["Mirowski", "Piotr", ""]]}, {"id": "2001.03708", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "PatentTransformer-2: Controlling Patent Text Generation by Structural\n  Metadata", "comments": "demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PatentTransformer is our codename for patent text generation based on\nTransformer-based models. Our goal is \"Augmented Inventing.\" In this second\nversion, we leverage more of the structural metadata in patents. The structural\nmetadata includes patent title, abstract, and dependent claim, in addition to\nindependent claim previously. Metadata controls what kind of patent text for\nthe model to generate. Also, we leverage the relation between metadata to build\na text-to-text generation flow, for example, from a few words to a title, the\ntitle to an abstract, the abstract to an independent claim, and the independent\nclaim to multiple dependent claims. The text flow can go backward because the\nrelation is trained bidirectionally. We release our GPT-2 models trained from\nscratch and our code for inference so that readers can verify and generate\npatent text on their own. As for generation quality, we measure it by both\nROUGE and Google Universal Sentence Encoder.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 03:54:31 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "2001.03712", "submitter": "Geondo Park", "authors": "Geondo Park, Chihye Han, Wonjun Yoon, Daeshik Kim", "title": "MHSAN: Multi-Head Self-Attention Network for Visual Semantic Embedding", "comments": "Accepted by the 2020 IEEE Winter Conference on Applications of\n  Computer Vision (WACV 20), 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual-semantic embedding enables various tasks such as image-text retrieval,\nimage captioning, and visual question answering. The key to successful\nvisual-semantic embedding is to express visual and textual data properly by\naccounting for their intricate relationship. While previous studies have\nachieved much advance by encoding the visual and textual data into a joint\nspace where similar concepts are closely located, they often represent data by\na single vector ignoring the presence of multiple important components in an\nimage or text. Thus, in addition to the joint embedding space, we propose a\nnovel multi-head self-attention network to capture various components of visual\nand textual data by attending to important parts in data. Our approach achieves\nthe new state-of-the-art results in image-text retrieval tasks on MS-COCO and\nFlicker30K datasets. Through the visualization of the attention maps that\ncapture distinct semantic components at multiple positions in the image and the\ntext, we demonstrate that our method achieves an effective and interpretable\nvisual-semantic joint space.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 05:50:19 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Park", "Geondo", ""], ["Han", "Chihye", ""], ["Yoon", "Wonjun", ""], ["Kim", "Daeshik", ""]]}, {"id": "2001.03765", "submitter": "Thibault F\\'evry", "authors": "Jeffrey Ling, Nicholas FitzGerald, Zifei Shan, Livio Baldini Soares,\n  Thibault F\\'evry, David Weiss, Tom Kwiatkowski", "title": "Learning Cross-Context Entity Representations from Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Language modeling tasks, in which words, or word-pieces, are predicted on the\nbasis of a local context, have been very effective for learning word embeddings\nand context dependent representations of phrases. Motivated by the observation\nthat efforts to code world knowledge into machine readable knowledge bases or\nhuman readable encyclopedias tend to be entity-centric, we investigate the use\nof a fill-in-the-blank task to learn context independent representations of\nentities from the text contexts in which those entities were mentioned. We show\nthat large scale training of neural models allows us to learn high quality\nentity representations, and we demonstrate successful results on four domains:\n(1) existing entity-level typing benchmarks, including a 64% error reduction\nover previous work on TypeNet (Murty et al., 2018); (2) a novel few-shot\ncategory reconstruction task; (3) existing entity linking benchmarks, where we\nmatch the state-of-the-art on CoNLL-Aida without linking-specific features and\nobtain a score of 89.8% on TAC-KBP 2010 without using any alias table, external\nknowledge base or in domain training data and (4) answering trivia questions,\nwhich uniquely identify entities. Our global entity representations encode\nfine-grained type categories, such as Scottish footballers, and can answer\ntrivia questions such as: Who was the last inmate of Spandau jail in Berlin?\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 15:30:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ling", "Jeffrey", ""], ["FitzGerald", "Nicholas", ""], ["Shan", "Zifei", ""], ["Soares", "Livio Baldini", ""], ["F\u00e9vry", "Thibault", ""], ["Weiss", "David", ""], ["Kwiatkowski", "Tom", ""]]}, {"id": "2001.03830", "submitter": "Hongmin Wang", "authors": "Hongmin Wang", "title": "Revisiting Challenges in Data-to-Text Generation with Fact Grounding", "comments": "Best Paper Runner-up at INLG 2019 (12th International Conference on\n  Natural Language Generation)", "journal-ref": null, "doi": "10.18653/v1/W19-8639", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-to-text generation models face challenges in ensuring data fidelity by\nreferring to the correct input source. To inspire studies in this area, Wiseman\net al. (2017) introduced the RotoWire corpus on generating NBA game summaries\nfrom the box- and line-score tables. However, limited attempts have been made\nin this direction and the challenges remain. We observe a prominent bottleneck\nin the corpus where only about 60% of the summary contents can be grounded to\nthe boxscore records. Such information deficiency tends to misguide a\nconditioned language model to produce unconditioned random facts and thus leads\nto factual hallucinations. In this work, we restore the information balance and\nrevamp this task to focus on fact-grounded data-to-text generation. We\nintroduce a purified and larger-scale dataset, RotoWire-FG (Fact-Grounding),\nwith 50% more data from the year 2017-19 and enriched input tables, hoping to\nattract more research focuses in this direction. Moreover, we achieve improved\ndata fidelity over the state-of-the-art models by integrating a new form of\ntable reconstruction as an auxiliary task to boost the generation quality.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 02:31:07 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Hongmin", ""]]}, {"id": "2001.03844", "submitter": "Jinlan Fu", "authors": "Jinlan Fu, Pengfei Liu, Qi Zhang, Xuanjing Huang", "title": "Rethinking Generalization of Neural Models: A Named Entity Recognition\n  Case Study", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural network-based models have achieved impressive performance on a\nlarge body of NLP tasks, the generalization behavior of different models\nremains poorly understood: Does this excellent performance imply a perfect\ngeneralization model, or are there still some limitations? In this paper, we\ntake the NER task as a testbed to analyze the generalization behavior of\nexisting models from different perspectives and characterize the differences of\ntheir generalization abilities through the lens of our proposed measures, which\nguides us to better design models and training methods. Experiments with\nin-depth analyses diagnose the bottleneck of existing neural NER models in\nterms of breakdown performance analysis, annotation errors, dataset bias, and\ncategory relationships, which suggest directions for improvement. We have\nreleased the datasets: (ReCoNLL, PLONER) for the future research at our project\npage: http://pfliu.com/InterpretNER/. As a by-product of this paper, we have\nopen-sourced a project that involves a comprehensive summary of recent NER\npapers and classifies them into different research topics:\nhttps://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 04:33:53 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Fu", "Jinlan", ""], ["Liu", "Pengfei", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2001.03897", "submitter": "Elham Seifossadat", "authors": "Elham Seifossadat and Hossein Sameti", "title": "Stochastic Natural Language Generation Using Dependency Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a stochastic corpus-based model for generating natural\nlanguage text. Our model first encodes dependency relations from training data\nthrough a feature set, then concatenates these features to produce a new\ndependency tree for a given meaning representation, and finally generates a\nnatural language utterance from the produced dependency tree. We test our model\non nine domains from tabular, dialogue act and RDF format. Our model\noutperforms the corpus-based state-of-the-art methods trained on tabular\ndatasets and also achieves comparable results with neural network-based\napproaches trained on dialogue act, E2E and WebNLG datasets for BLEU and ERR\nevaluation metrics. Also, by reporting Human Evaluation results, we show that\nour model produces high-quality utterances in aspects of informativeness and\nnaturalness as well as quality.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 09:40:11 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Seifossadat", "Elham", ""], ["Sameti", "Hossein", ""]]}, {"id": "2001.04063", "submitter": "Weizhen Qi", "authors": "Weizhen Qi, Yu Yan, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen,\n  Ruofei Zhang, Ming Zhou", "title": "ProphetNet: Predicting Future N-gram for Sequence-to-Sequence\n  Pre-training", "comments": "Accepted to EMNLP 2020 Findings. Project page:\n  https://github.com/microsoft/ProphetNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new sequence-to-sequence pre-training model called\nProphetNet, which introduces a novel self-supervised objective named future\nn-gram prediction and the proposed n-stream self-attention mechanism. Instead\nof optimizing one-step-ahead prediction in the traditional sequence-to-sequence\nmodel, the ProphetNet is optimized by n-step ahead prediction that predicts the\nnext n tokens simultaneously based on previous context tokens at each time\nstep. The future n-gram prediction explicitly encourages the model to plan for\nthe future tokens and prevent overfitting on strong local correlations. We\npre-train ProphetNet using a base scale dataset (16GB) and a large-scale\ndataset (160GB), respectively. Then we conduct experiments on CNN/DailyMail,\nGigaword, and SQuAD 1.1 benchmarks for abstractive summarization and question\ngeneration tasks. Experimental results show that ProphetNet achieves new\nstate-of-the-art results on all these datasets compared to the models using the\nsame scale pre-training corpus.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 05:12:38 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 09:29:12 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 05:45:35 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Qi", "Weizhen", ""], ["Yan", "Yu", ""], ["Gong", "Yeyun", ""], ["Liu", "Dayiheng", ""], ["Duan", "Nan", ""], ["Chen", "Jiusheng", ""], ["Zhang", "Ruofei", ""], ["Zhou", "Ming", ""]]}, {"id": "2001.04170", "submitter": "Simon Razniewski", "authors": "Yohan Chalier, Simon Razniewski, and Gerhard Weikum", "title": "Joint Reasoning for Multi-Faceted Commonsense Knowledge", "comments": "11 pages", "journal-ref": "AKBC 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge (CSK) supports a variety of AI applications, from\nvisual understanding to chatbots. Prior works on acquiring CSK, such as\nConceptNet, have compiled statements that associate concepts, like everyday\nobjects or activities, with properties that hold for most or some instances of\nthe concept. Each concept is treated in isolation from other concepts, and the\nonly quantitative measure (or ranking) of properties is a confidence score that\nthe statement is valid. This paper aims to overcome these limitations by\nintroducing a multi-faceted model of CSK statements and methods for joint\nreasoning over sets of inter-related statements. Our model captures four\ndifferent dimensions of CSK statements: plausibility, typicality, remarkability\nand salience, with scoring and ranking along each dimension. For example,\nhyenas drinking water is typical but not salient, whereas hyenas eating\ncarcasses is salient. For reasoning and ranking, we develop a method with soft\nconstraints, to couple the inference over concepts that are related in in a\ntaxonomic hierarchy. The reasoning is cast into an integer linear programming\n(ILP), and we leverage the theory of reduction costs of a relaxed LP to compute\ninformative rankings. This methodology is applied to several large CSK\ncollections. Our evaluation shows that we can consolidate these inputs into\nmuch cleaner and more expressive knowledge. Results are available at\nhttps://dice.mpi-inf.mpg.de.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:34:25 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 20:58:16 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chalier", "Yohan", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2001.04192", "submitter": "Bernard Espinasse", "authors": "Rinaldo Lima, Bernard Espinasse (LIS, R2I), Fred Freitas", "title": "A logic-based relational learning approach to relation extraction: The\n  OntoILPER system", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence, Elsevier,\n  2019, 78, pp.142-157", "doi": "10.1016/j.engappai.2018.11.001", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Extraction (RE), the task of detecting and characterizing semantic\nrelations between entities in text, has gained much importance in the last two\ndecades, mainly in the biomedical domain. Many papers have been published on\nRelation Extraction using supervised machine learning techniques. Most of these\ntechniques rely on statistical methods, such as feature-based and\ntree-kernels-based methods. Such statistical learning techniques are usually\nbased on a propositional hypothesis space for representing examples, i.e., they\nemploy an attribute-value representation of features. This kind of\nrepresentation has some drawbacks, particularly in the extraction of complex\nrelations which demand more contextual information about the involving\ninstances, i.e., it is not able to effectively capture structural information\nfrom parse trees without loss of information. In this work, we present\nOntoILPER, a logic-based relational learning approach to Relation Extraction\nthat uses Inductive Logic Programming for generating extraction models in the\nform of symbolic extraction rules. OntoILPER takes profit of a rich relational\nrepresentation of examples, which can alleviate the aforementioned drawbacks.\nThe proposed relational approach seems to be more suitable for Relation\nExtraction than statistical ones for several reasons that we argue. Moreover,\nOntoILPER uses a domain ontology that guides the background knowledge\ngeneration process and is used for storing the extracted relation instances.\nThe induced extraction rules were evaluated on three protein-protein\ninteraction datasets from the biomedical domain. The performance of OntoILPER\nextraction models was compared with other state-of-the-art RE systems. The\nencouraging results seem to demonstrate the effectiveness of the proposed\nsolution.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:47:49 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lima", "Rinaldo", "", "LIS, R2I"], ["Espinasse", "Bernard", "", "LIS, R2I"], ["Freitas", "Fred", ""]]}, {"id": "2001.04200", "submitter": "Bernard Yannou", "authors": "Tianjun Hou (LGI), Bernard Yannou (LGI), Yann Leroy, Emilie Poirson\n  (IRCCyN)", "title": "Mining customer product reviews for product development: A summarization\n  process", "comments": null, "journal-ref": "Expert Systems with Applications, Elsevier, 2019, 132, pp.141-150", "doi": "10.1016/j.eswa.2019.04.069", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research set out to identify and structure from online reviews the words\nand expressions related to customers' likes and dislikes to guide product\ndevelopment. Previous methods were mainly focused on product features. However,\nreviewers express their preference not only on product features. In this paper,\nbased on an extensive literature review in design science, the authors propose\na summarization model containing multiples aspects of user preference, such as\nproduct affordances, emotions, usage conditions. Meanwhile, the linguistic\npatterns describing these aspects of preference are discovered and drafted as\nannotation guidelines. A case study demonstrates that with the proposed model\nand the annotation guidelines, human annotators can structure the online\nreviews with high inter-agreement. As high inter-agreement human annotation\nresults are essential for automatizing the online review summarization process\nwith the natural language processing, this study provides materials for the\nfuture study of automatization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:01:14 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hou", "Tianjun", "", "LGI"], ["Yannou", "Bernard", "", "LGI"], ["Leroy", "Yann", "", "IRCCyN"], ["Poirson", "Emilie", "", "IRCCyN"]]}, {"id": "2001.04219", "submitter": "Markus Hecher", "authors": "Markus Hecher, Michael Morak, Stefan Woltran", "title": "Structural Decompositions of Epistemic Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic logic programs (ELPs) are a popular generalization of standard\nAnswer Set Programming (ASP) providing means for reasoning over answer sets\nwithin the language. This richer formalism comes at the price of higher\ncomputational complexity reaching up to the fourth level of the polynomial\nhierarchy. However, in contrast to standard ASP, dedicated investigations\ntowards tractability have not been undertaken yet. In this paper, we give first\nresults in this direction and show that central ELP problems can be solved in\nlinear time for ELPs exhibiting structural properties in terms of bounded\ntreewidth. We also provide a full dynamic programming algorithm that adheres to\nthese bounds. Finally, we show that applying treewidth to a novel dependency\nstructure---given in terms of epistemic literals---allows to bound the number\nof ASP solver calls in typical ELP solving procedures.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:16:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hecher", "Markus", ""], ["Morak", "Michael", ""], ["Woltran", "Stefan", ""]]}, {"id": "2001.04246", "submitter": "Yaliang Li", "authors": "Daoyuan Chen, Yaliang Li, Minghui Qiu, Zhen Wang, Bofang Li, Bolin\n  Ding, Hongbo Deng, Jun Huang, Wei Lin, Jingren Zhou", "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\n  Architecture Search", "comments": "accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models such as BERT have shown their effectiveness\nin various natural language processing tasks. However, the huge parameter size\nmakes them difficult to be deployed in real-time applications that require\nquick inference with limited resources. Existing methods compress BERT into\nsmall models while such compression is task-independent, i.e., the same\ncompressed BERT for all different downstream tasks. Motivated by the necessity\nand benefits of task-oriented BERT compression, we propose a novel compression\nmethod, AdaBERT, that leverages differentiable Neural Architecture Search to\nautomatically compress BERT into task-adaptive small models for specific tasks.\nWe incorporate a task-oriented knowledge distillation loss to provide search\nhints and an efficiency-aware loss as search constraints, which enables a good\ntrade-off between efficiency and effectiveness for task-adaptive BERT\ncompression. We evaluate AdaBERT on several NLP tasks, and the results\ndemonstrate that those task-adaptive compressed models are 12.7x to 29.3x\nfaster than BERT in inference time and 11.5x to 17.0x smaller in terms of\nparameter size, while comparable performance is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:03:26 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 10:58:24 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Chen", "Daoyuan", ""], ["Li", "Yaliang", ""], ["Qiu", "Minghui", ""], ["Wang", "Zhen", ""], ["Li", "Bofang", ""], ["Ding", "Bolin", ""], ["Deng", "Hongbo", ""], ["Huang", "Jun", ""], ["Lin", "Wei", ""], ["Zhou", "Jingren", ""]]}, {"id": "2001.04260", "submitter": "Seung Hee Yang", "authors": "Seung Hee Yang, Minhwa Chung", "title": "Improving Dysarthric Speech Intelligibility Using Cycle-consistent\n  Adversarial Training", "comments": "To be Published on the 24th February in BIOSIGNALS 2020. arXiv admin\n  note: text overlap with arXiv:1904.09407", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dysarthria is a motor speech impairment affecting millions of people.\nDysarthric speech can be far less intelligible than those of non-dysarthric\nspeakers, causing significant communication difficulties. The goal of our work\nis to develop a model for dysarthric to healthy speech conversion using\nCycle-consistent GAN. Using 18,700 dysarthric and 8,610 healthy control Korean\nutterances that were recorded for the purpose of automatic recognition of voice\nkeyboard in a previous study, the generator is trained to transform dysarthric\nto healthy speech in the spectral domain, which is then converted back to\nspeech. Objective evaluation using automatic speech recognition of the\ngenerated utterance on a held-out test set shows that the recognition\nperformance is improved compared with the original dysarthic speech after\nperforming adversarial training, as the absolute WER has been lowered by 33.4%.\nIt demonstrates that the proposed GAN-based conversion method is useful for\nimproving dysarthric speech intelligibility.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 01:40:27 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Yang", "Seung Hee", ""], ["Chung", "Minhwa", ""]]}, {"id": "2001.04345", "submitter": "Mukul Kumar", "authors": "Mukul Kumar, Youna Hu, Will Headden, Rahul Goutam, Heran Lin, Bing Yin", "title": "Shareable Representations for Search Query Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding search queries is critical for shopping search engines to\ndeliver a satisfying customer experience. Popular shopping search engines\nreceive billions of unique queries yearly, each of which can depict any of\nhundreds of user preferences or intents. In order to get the right results to\ncustomers it must be known queries like \"inexpensive prom dresses\" are intended\nto not only surface results of a certain product type but also products with a\nlow price. Referred to as query intents, examples also include preferences for\nauthor, brand, age group, or simply a need for customer service. Recent works\nsuch as BERT have demonstrated the success of a large transformer encoder\narchitecture with language model pre-training on a variety of NLP tasks. We\nadapt such an architecture to learn intents for search queries and describe\nmethods to account for the noisiness and sparseness of search query data. We\nalso describe cost effective ways of hosting transformer encoder models in\ncontext with low latency requirements. With the right domain-specific training\nwe can build a shareable deep learning model whose internal representation can\nbe reused for a variety of query understanding tasks including query intent\nidentification. Model sharing allows for fewer large models needed to be served\nat inference time and provides a platform to quickly build and roll out new\nsearch query classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 22:12:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kumar", "Mukul", ""], ["Hu", "Youna", ""], ["Headden", "Will", ""], ["Goutam", "Rahul", ""], ["Lin", "Heran", ""], ["Yin", "Bing", ""]]}, {"id": "2001.04346", "submitter": "Xin Dong", "authors": "Xin Dong, Jingchao Ni, Wei Cheng, Zhengzhang Chen, Bo Zong, Dongjin\n  Song, Yanchi Liu, Haifeng Chen, Gerard de Melo", "title": "Asymmetrical Hierarchical Networks with Attentive Interactions for\n  Interpretable Review-Based Recommendation", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, recommender systems have been able to emit substantially improved\nrecommendations by leveraging user-provided reviews. Existing methods typically\nmerge all reviews of a given user or item into a long document, and then\nprocess user and item documents in the same manner. In practice, however, these\ntwo sets of reviews are notably different: users' reviews reflect a variety of\nitems that they have bought and are hence very heterogeneous in their topics,\nwhile an item's reviews pertain only to that single item and are thus topically\nhomogeneous. In this work, we develop a novel neural network model that\nproperly accounts for this important difference by means of asymmetric\nattentive modules. The user module learns to attend to only those signals that\nare relevant with respect to the target item, whereas the item module learns to\nextract the most salient contents with regard to properties of the item. Our\nmulti-hierarchical paradigm accounts for the fact that neither are all reviews\nequally useful, nor are all sentences within each review equally pertinent.\nExtensive experimental results on a variety of real datasets demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:48:42 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Dong", "Xin", ""], ["Ni", "Jingchao", ""], ["Cheng", "Wei", ""], ["Chen", "Zhengzhang", ""], ["Zong", "Bo", ""], ["Song", "Dongjin", ""], ["Liu", "Yanchi", ""], ["Chen", "Haifeng", ""], ["de Melo", "Gerard", ""]]}, {"id": "2001.04351", "submitter": "Liang  Xu", "authors": "Liang Xu, Yu tong, Qianqian Dong, Yixuan Liao, Cong Yu, Yin Tian,\n  Weitang Liu, Lu Li, Caiquan Liu, Xuanwei Zhang", "title": "CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark\n  for Chinese", "comments": "6 pages, 5 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the NER dataset from CLUE organization\n(CLUENER2020), a well-defined fine-grained dataset for named entity recognition\nin Chinese. CLUENER2020 contains 10 categories. Apart from common labels like\nperson, organization, and location, it contains more diverse categories. It is\nmore challenging than current other Chinese NER datasets and could better\nreflect real-world applications. For comparison, we implement several\nstate-of-the-art baselines as sequence labeling tasks and report human\nperformance, as well as its analysis. To facilitate future work on fine-grained\nNER for Chinese, we release our dataset, baselines, and leader-board.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:39:56 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 19:06:49 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 16:18:16 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 16:32:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xu", "Liang", ""], ["tong", "Yu", ""], ["Dong", "Qianqian", ""], ["Liao", "Yixuan", ""], ["Yu", "Cong", ""], ["Tian", "Yin", ""], ["Liu", "Weitang", ""], ["Li", "Lu", ""], ["Liu", "Caiquan", ""], ["Zhang", "Xuanwei", ""]]}, {"id": "2001.04362", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Source Domain Adaptation for Text Classification via\n  DistanceNet-Bandits", "comments": "AAAI 2020 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation performance of a learning algorithm on a target domain is a\nfunction of its source domain error and a divergence measure between the data\ndistribution of these two domains. We present a study of various distance-based\nmeasures in the context of NLP tasks, that characterize the dissimilarity\nbetween domains based on sample estimates. We first conduct analysis\nexperiments to show which of these distance measures can best differentiate\nsamples from same versus different domains, and are correlated with empirical\nresults. Next, we develop a DistanceNet model which uses these distance\nmeasures, or a mixture of these distance measures, as an additional loss\nfunction to be minimized jointly with the task's loss function, so as to\nachieve better unsupervised domain adaptation. Finally, we extend this model to\na novel DistanceNet-Bandit model, which employs a multi-armed bandit controller\nto dynamically switch between multiple source domains and allow the model to\nlearn an optimal trajectory and mixture of domains for transfer to the\nlow-resource target domain. We conduct experiments on popular sentiment\nanalysis datasets with several diverse domains and show that our DistanceNet\nmodel, as well as its dynamic bandit variant, can outperform competitive\nbaselines in the context of unsupervised domain adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:53:41 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 17:01:49 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 21:21:22 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.04425", "submitter": "Hiba Arnaout", "authors": "Hiba Arnaout, Simon Razniewski, Gerhard Weikum, and Jeff Z. Pan", "title": "Negative Statements Considered Useful", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) about notable entities and their properties are an\nimportant asset in applications such as search, question answering and\ndialogue. All popular KBs capture virtually only positive statements, and\nabstain from taking any stance on statements not stored in the KB. This paper\nmakes the case for explicitly stating salient statements that do not hold.\nNegative statements are useful to overcome limitations of question answering,\nand can often contribute to informative summaries of entities. Due to the\nabundance of such invalid statements, any effort to compile them needs to\naddress ranking by saliency. We present a statistical inference method for\ncompiling and ranking negative statements,based on expectations from positive\nstatements of related entities in peer groups. Experimental results, with a\nvariety of datasets, show that the method can effectively discover notable\nnegative statements, and extrinsic studies underline their usefulness for\nentity summarization. Datasets and code are released as resources for further\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:49:37 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 14:42:40 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 14:45:01 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 09:00:13 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Arnaout", "Hiba", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""], ["Pan", "Jeff Z.", ""]]}, {"id": "2001.04437", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins", "title": "LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured\n  Prediction", "comments": "34 pages, 5 tables, 4 figures. ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction requires manipulating a large number of combinatorial\nstructures, e.g., dependency trees or alignments, either as latent or output\nvariables. Recently, the SparseMAP method has been proposed as a\ndifferentiable, sparse alternative to maximum a posteriori (MAP) and marginal\ninference. SparseMAP returns a combination of a small number of structures, a\ndesirable property in some downstream applications. However, SparseMAP requires\na tractable MAP inference oracle. This excludes, e.g., loopy graphical models\nor factor graphs with logic constraints, which generally require approximate\ninference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP\nthat addresses this limitation via a local polytope relaxation. LP-SparseMAP\nuses the flexible and powerful domain specific language of factor graphs for\ndefining and backpropagating through arbitrary hidden structure, supporting\ncoarse decompositions, hard logic constraints, and higher-order correlations.\nWe derive the forward and backward algorithms needed for using LP-SparseMAP as\na hidden or output layer. Experiments in three structured prediction tasks show\nbenefits compared to SparseMAP and Structured SVM.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:16:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:05:12 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 15:36:49 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "2001.04451", "submitter": "Nikita Kitaev", "authors": "Nikita Kitaev, {\\L}ukasz Kaiser, Anselm Levskaya", "title": "Reformer: The Efficient Transformer", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformer models routinely achieve state-of-the-art results on a\nnumber of tasks but training these models can be prohibitively costly,\nespecially on long sequences. We introduce two techniques to improve the\nefficiency of Transformers. For one, we replace dot-product attention by one\nthat uses locality-sensitive hashing, changing its complexity from O($L^2$) to\nO($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use\nreversible residual layers instead of the standard residuals, which allows\nstoring activations only once in the training process instead of $N$ times,\nwhere $N$ is the number of layers. The resulting model, the Reformer, performs\non par with Transformer models while being much more memory-efficient and much\nfaster on long sequences.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:38:28 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:01:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kitaev", "Nikita", ""], ["Kaiser", "\u0141ukasz", ""], ["Levskaya", "Anselm", ""]]}, {"id": "2001.04484", "submitter": "Luca Papariello", "authors": "Luca Papariello, Alexandros Bampoulidis, Mihai Lupu", "title": "On the Replicability of Combining Word Embeddings and Retrieval Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We replicate recent experiments attempting to demonstrate an attractive\nhypothesis about the use of the Fisher kernel framework and mixture models for\naggregating word embeddings towards document representations and the use of\nthese representations in document classification, clustering, and retrieval.\nSpecifically, the hypothesis was that the use of a mixture model of von\nMises-Fisher (VMF) distributions instead of Gaussian distributions would be\nbeneficial because of the focus on cosine distances of both VMF and the vector\nspace model traditionally used in information retrieval. Previous experiments\nhad validated this hypothesis. Our replication was not able to validate it,\ndespite a large parameter scan space.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:01:07 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Papariello", "Luca", ""], ["Bampoulidis", "Alexandros", ""], ["Lupu", "Mihai", ""]]}, {"id": "2001.04586", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Zhou Zhao, Yueting Zhuang, Deng Cai", "title": "Bi-Decoder Augmented Network for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has become a popular technology in recent\nyears, and the encoder-decoder framework is the mainstream among all the\nmethods. It's obvious that the quality of the semantic representations from\nencoding is very crucial and can significantly affect the performance of the\nmodel. However, existing unidirectional source-to-target architectures may\nhardly produce a language-independent representation of the text because they\nrely heavily on the specific relations of the given language pairs. To\nalleviate this problem, in this paper, we propose a novel Bi-Decoder Augmented\nNetwork (BiDAN) for the neural machine translation task. Besides the original\ndecoder which generates the target language sequence, we add an auxiliary\ndecoder to generate back the source language sequence at the training time.\nSince each decoder transforms the representations of the input text into its\ncorresponding language, jointly training with two target ends can make the\nshared encoder has the potential to produce a language-independent semantic\nspace. We conduct extensive experiments on several NMT benchmark datasets and\nthe results demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 02:05:14 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Zhao", "Zhou", ""], ["Zhuang", "Yueting", ""], ["Cai", "Deng", ""]]}, {"id": "2001.04589", "submitter": "Ciprian Chelba", "authors": "Ciprian Chelba, Mia Chen, Ankur Bapna, and Noam Shazeer", "title": "Faster Transformer Decoding: N-gram Masked Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fact that most of the information relevant to the prediction\nof target tokens is drawn from the source sentence $S=s_1, \\ldots, s_S$, we\npropose truncating the target-side window used for computing self-attention by\nmaking an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show\nthat the $N$-gram masked self-attention model loses very little in BLEU score\nfor $N$ values in the range $4, \\ldots, 8$, depending on the task.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 02:14:09 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chelba", "Ciprian", ""], ["Chen", "Mia", ""], ["Bapna", "Ankur", ""], ["Shazeer", "Noam", ""]]}, {"id": "2001.04619", "submitter": "Ruixi Lin", "authors": "Charles Jankowski, Vishwas Mruthyunjaya, Ruixi Lin", "title": "Improved Robust ASR for Social Robots in Public Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social robots deployed in public spaces present a challenging task for ASR\nbecause of a variety of factors, including noise SNR of 20 to 5 dB. Existing\nASR models perform well for higher SNRs in this range, but degrade considerably\nwith more noise. This work explores methods for providing improved ASR\nperformance in such conditions. We use the AiShell-1 Chinese speech corpus and\nthe Kaldi ASR toolkit for evaluations. We were able to exceed state-of-the-art\nASR performance with SNR lower than 20 dB, demonstrating the feasibility of\nachieving relatively high performing ASR with open-source toolkits and hundreds\nof hours of training data, which is commonly available.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 04:21:18 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Jankowski", "Charles", ""], ["Mruthyunjaya", "Vishwas", ""], ["Lin", "Ruixi", ""]]}, {"id": "2001.04693", "submitter": "Stephanie Brandl", "authors": "Stephanie Brandl, David Lassner, Maximilian Alber", "title": "Balancing the composition of word embeddings across heterogenous data\n  sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings capture semantic relationships based on contextual\ninformation and are the basis for a wide variety of natural language processing\napplications. Notably these relationships are solely learned from the data and\nsubsequently the data composition impacts the semantic of embeddings which\narguably can lead to biased word vectors. Given qualitatively different data\nsubsets, we aim to align the influence of single subsets on the resulting word\nvectors, while retaining their quality. In this regard we propose a criteria to\nmeasure the shift towards a single data subset and develop approaches to meet\nboth objectives. We find that a weighted average of the two subset embeddings\nbalances the influence of those subsets while word similarity performance\ndecreases. We further propose a promising optimization approach to balance\ninfluences and quality of word embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:12:50 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Brandl", "Stephanie", ""], ["Lassner", "David", ""], ["Alber", "Maximilian", ""]]}, {"id": "2001.04701", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller", "title": "A (Simplified) Supreme Being Necessarily Exists, says the Computer:\n  Computationally Explored Variants of G\\\"odel's Ontological Argument", "comments": "11 pages, 11 figures", "journal-ref": "KR 2020 -- The 17th International Conference on Principles of\n  Knowledge Representation and Reasoning, Rhodes, Greece, September 12-18, 2020", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CL math.GN math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to universal (meta-)logical reasoning in classical higher-order\nlogic is employed to explore and study simplifications of Kurt G\\\"odel's modal\nontological argument. Some argument premises are modified, others are dropped,\nmodal collapse is avoided and validity is shown already in weak modal logics K\nand T. Key to the gained simplifications of G\\\"odel's original theory is the\nexploitation of a link to the notions of filter and ultrafilter from topology.\nThe paper illustrates how modern knowledge representation and reasoning\ntechnology for quantified non-classical logics can contribute new knowledge to\nother disciplines. The contributed material is also well suited to support\nteaching of non-trivial logic formalisms in classroom.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:26:51 GMT"}, {"version": "v10", "created": "Sun, 14 Jun 2020 06:25:33 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 12:16:56 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2020 09:27:58 GMT"}, {"version": "v4", "created": "Sun, 9 Feb 2020 08:32:22 GMT"}, {"version": "v5", "created": "Tue, 11 Feb 2020 10:13:53 GMT"}, {"version": "v6", "created": "Sat, 15 Feb 2020 17:06:34 GMT"}, {"version": "v7", "created": "Thu, 12 Mar 2020 08:52:54 GMT"}, {"version": "v8", "created": "Wed, 25 Mar 2020 14:43:57 GMT"}, {"version": "v9", "created": "Mon, 4 May 2020 15:17:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""]]}, {"id": "2001.04809", "submitter": "Joshua Kim", "authors": "Joshua Y. Kim, Greyson Y. Kim and Kalina Yacef", "title": "Detecting depression in dyadic conversations with multimodal narratives\n  and visualizations", "comments": "12 pages", "journal-ref": "AI 2019: Advances in Artificial Intelligence. AI 2019 vol 11919", "doi": "10.1007/978-3-030-35288-2_25", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations contain a wide spectrum of multimodal information that gives us\nhints about the emotions and moods of the speaker. In this paper, we developed\na system that supports humans to analyze conversations. Our main contribution\nis the identification of appropriate multimodal features and the integration of\nsuch features into verbatim conversation transcripts. We demonstrate the\nability of our system to take in a wide range of multimodal information and\nautomatically generated a prediction score for the depression state of the\nindividual. Our experiments showed that this approach yielded better\nperformance than the baseline model. Furthermore, the multimodal narrative\napproach makes it easy to integrate learnings from other disciplines, such as\nconversational analysis and psychology. Lastly, this interdisciplinary and\nautomated approach is a step towards emulating how practitioners record the\ncourse of treatment as well as emulating how conversational analysts have been\nanalyzing conversations by hand.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 10:47:13 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 23:16:48 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kim", "Joshua Y.", ""], ["Kim", "Greyson Y.", ""], ["Yacef", "Kalina", ""]]}, {"id": "2001.04935", "submitter": "Roei Schuster", "authors": "Roei Schuster, Tal Schuster, Yoav Meri, Vitaly Shmatikov", "title": "Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning", "comments": "Accepted at IEEE S&P 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings, i.e., low-dimensional vector representations such as GloVe\nand SGNS, encode word \"meaning\" in the sense that distances between words'\nvectors correspond to their semantic proximity. This enables transfer learning\nof semantics for a variety of natural language processing tasks.\n  Word embeddings are typically trained on large public corpora such as\nWikipedia or Twitter. We demonstrate that an attacker who can modify the corpus\non which the embedding is trained can control the \"meaning\" of new and existing\nwords by changing their locations in the embedding space. We develop an\nexplicit expression over corpus features that serves as a proxy for distance\nbetween words and establish a causative relationship between its values and\nembedding distances. We then show how to use this relationship for two\nadversarial objectives: (1) make a word a top-ranked neighbor of another word,\nand (2) move a word from one semantic cluster to another.\n  An attack on the embedding can affect diverse downstream tasks, demonstrating\nfor the first time the power of data poisoning in transfer learning scenarios.\nWe use this attack to manipulate query expansion in information retrieval\nsystems such as resume search, make certain names more or less visible to named\nentity recognition models, and cause new words to be translated to a particular\ntarget word regardless of the language. Finally, we show how the attacker can\ngenerate linguistically likely corpus modifications, thus fooling defenses that\nattempt to filter implausible sentences from the corpus using a language model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:48:52 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Schuster", "Roei", ""], ["Schuster", "Tal", ""], ["Meri", "Yoav", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2001.04980", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Rohan Kohli, Shrimai Prabhumoye", "title": "Modeling Product Search Relevance in e-Commerce", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of e-Commerce, online product search has emerged as a\npopular and effective paradigm for customers to find desired products and\nengage in online shopping. However, there is still a big gap between the\nproducts that customers really desire to purchase and relevance of products\nthat are suggested in response to a query from the customer. In this paper, we\npropose a robust way of predicting relevance scores given a search query and a\nproduct, using techniques involving machine learning, natural language\nprocessing and information retrieval. We compare conventional information\nretrieval models such as BM25 and Indri with deep learning models such as\nword2vec, sentence2vec and paragraph2vec. We share some of our insights and\nfindings from our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:17:55 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Kohli", "Rohan", ""], ["Prabhumoye", "Shrimai", ""]]}, {"id": "2001.05031", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Qiang Huang, Thomas Hain", "title": "Robust Speaker Recognition Using Speech Enhancement And Attention Model", "comments": "Acceptted by Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel architecture for speaker recognition is proposed by\ncascading speech enhancement and speaker processing. Its aim is to improve\nspeaker recognition performance when speech signals are corrupted by noise.\nInstead of individually processing speech enhancement and speaker recognition,\nthe two modules are integrated into one framework by a joint optimisation using\ndeep neural networks. Furthermore, to increase robustness against noise, a\nmulti-stage attention mechanism is employed to highlight the speaker related\nfeatures learned from context information in time and frequency domain. To\nevaluate speaker identification and verification performance of the proposed\napproach, we test it on the dataset of VoxCeleb1, one of mostly used benchmark\ndatasets. Moreover, the robustness of our proposed approach is also tested on\nVoxCeleb1 data when being corrupted by three types of interferences, general\nnoise, music, and babble, at different signal-to-noise ratio (SNR) levels. The\nobtained results show that the proposed approach using speech enhancement and\nmulti-stage attention models outperforms two strong baselines not using them in\nmost acoustic conditions in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:03:07 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 09:16:56 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Shi", "Yanpei", ""], ["Huang", "Qiang", ""], ["Hain", "Thomas", ""]]}, {"id": "2001.05136", "submitter": "Jungo Kasai", "authors": "Jungo Kasai, James Cross, Marjan Ghazvininejad, Jiatao Gu", "title": "Non-Autoregressive Machine Translation with Disentangled Context\n  Transformer", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural machine translation models generate a translation\nfrom left to right and every step is conditioned on the previously generated\ntokens. The sequential nature of this generation process causes fundamental\nlatency in inference since we cannot generate multiple tokens in each sentence\nin parallel. We propose an attention-masking based model, called Disentangled\nContext (DisCo) transformer, that simultaneously generates all tokens given\ndifferent contexts. The DisCo transformer is trained to predict every output\ntoken given an arbitrary subset of the other reference tokens. We also develop\nthe parallel easy-first inference algorithm, which iteratively refines every\ntoken in parallel and reduces the number of required iterations. Our extensive\nexperiments on 7 translation directions with varying data sizes demonstrate\nthat our model achieves competitive, if not better, performance compared to the\nstate of the art in non-autoregressive machine translation while significantly\nreducing decoding time on average. Our code is available at\nhttps://github.com/facebookresearch/DisCo.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:32:18 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:31:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kasai", "Jungo", ""], ["Cross", "James", ""], ["Ghazvininejad", "Marjan", ""], ["Gu", "Jiatao", ""]]}, {"id": "2001.05139", "submitter": "Jian Guan", "authors": "Jian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, Minlie Huang", "title": "A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation", "comments": "Accept at Transactions of the Association for Computational\n  Linguistics 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Story generation, namely generating a reasonable story from a leading\ncontext, is an important but challenging task. In spite of the success in\nmodeling fluency and local coherence, existing neural language generation\nmodels (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of\nlong-range coherence in generated stories. We conjecture that this is because\nof the difficulty of associating relevant commonsense knowledge, understanding\nthe causal relationships, and planning entities and events with proper temporal\norder. In this paper, we devise a knowledge-enhanced pretraining model for\ncommonsense story generation. We propose to utilize commonsense knowledge from\nexternal knowledge bases to generate reasonable stories. To further capture the\ncausal and temporal dependencies between the sentences in a reasonable story,\nwe employ multi-task learning which combines a discriminative objective to\ndistinguish true and fake stories during fine-tuning. Automatic and manual\nevaluation shows that our model can generate more reasonable stories than\nstate-of-the-art baselines, particularly in terms of logic and global\ncoherence.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:42:27 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Guan", "Jian", ""], ["Huang", "Fei", ""], ["Zhao", "Zhihao", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2001.05171", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Xiong Zhang and Jonathan Engel and Sara Evensen and Yuliang Li and\n  \\c{C}a\\u{g}atay Demiralp and Wang-Chiew Tan", "title": "Teddy: A System for Interactive Review Analysis", "comments": "CHI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reviews are integral to e-commerce services and products. They contain a\nwealth of information about the opinions and experiences of users, which can\nhelp better understand consumer decisions and improve user experience with\nproducts and services. Today, data scientists analyze reviews by developing\nrules and models to extract, aggregate, and understand information embedded in\nthe review text. However, working with thousands of reviews, which are\ntypically noisy incomplete text, can be daunting without proper tools. Here we\nfirst contribute results from an interview study that we conducted with fifteen\ndata scientists who work with review text, providing insights into their\npractices and challenges. Results suggest data scientists need interactive\nsystems for many review analysis tasks. In response we introduce Teddy, an\ninteractive system that enables data scientists to quickly obtain insights from\nreviews and improve their extraction and modeling pipelines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:19:01 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhang", "Xiong", ""], ["Engel", "Jonathan", ""], ["Evensen", "Sara", ""], ["Li", "Yuliang", ""], ["Demiralp", "\u00c7a\u011fatay", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2001.05272", "submitter": "Zhenyu Xuan", "authors": "Zhenyu Xuan, Rui Bao, Shengyi Jiang", "title": "FGN: Fusion Glyph Network for Chinese Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese NER is a challenging task. As pictographs, Chinese characters contain\nlatent glyph information, which is often overlooked. In this paper, we propose\nthe FGN, Fusion Glyph Network for Chinese NER. Except for adding glyph\ninformation, this method may also add extra interactive information with the\nfusion mechanism. The major innovations of FGN include: (1) a novel CNN\nstructure called CGS-CNN is proposed to capture both glyph information and\ninteractive information between glyphs from neighboring characters. (2) we\nprovide a method with sliding window and Slice-Attention to fuse the BERT\nrepresentation and glyph representation for a character, which may capture\npotential interactive knowledge between context and glyph. Experiments are\nconducted on four NER datasets, showing that FGN with LSTM-CRF as tagger\nachieves new state-of-the-arts performance for Chinese NER. Further, more\nexperiments are conducted to investigate the influences of various components\nand settings in FGN.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:39:20 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:58:51 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 05:05:45 GMT"}, {"version": "v4", "created": "Sat, 27 Jun 2020 13:28:21 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 07:54:43 GMT"}, {"version": "v6", "created": "Thu, 8 Oct 2020 11:46:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Xuan", "Zhenyu", ""], ["Bao", "Rui", ""], ["Jiang", "Shengyi", ""]]}, {"id": "2001.05284", "submitter": "Mingda Li", "authors": "Mingda Li, Weitong Ruan, Xinyue Liu, Luca Soldaini, Wael Hamza,\n  Chengwei Su", "title": "Improving Spoken Language Understanding By Exploiting ASR N-best\n  Hypotheses", "comments": "Submitted to ICASSP 2020. Have signed an e-copyright agreement with\n  the IEEE during ICASSP 2020 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a modern spoken language understanding (SLU) system, the natural language\nunderstanding (NLU) module takes interpretations of a speech from the automatic\nspeech recognition (ASR) module as the input. The NLU module usually uses the\nfirst best interpretation of a given speech in downstream tasks such as domain\nand intent classification. However, the ASR module might misrecognize some\nspeeches and the first best interpretation could be erroneous and noisy. Solely\nrelying on the first best interpretation could make the performance of\ndownstream tasks non-optimal. To address this issue, we introduce a series of\nsimple yet efficient models for improving the understanding of semantics of the\ninput speeches by collectively exploiting the n-best speech interpretations\nfrom the ASR module.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 05:48:52 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Li", "Mingda", ""], ["Ruan", "Weitong", ""], ["Liu", "Xinyue", ""], ["Soldaini", "Luca", ""], ["Hamza", "Wael", ""], ["Su", "Chengwei", ""]]}, {"id": "2001.05285", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Andr\\'es Torres-Rivera and Juan-Manuel Torres-Moreno", "title": "Detecting New Word Meanings: A Comparison of Word Embedding Models in\n  Spanish", "comments": "16 pages, 3 figures", "journal-ref": "COnference en Recherche d'Informations et Applications {CORIA}\n  2019 France", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic neologisms (SN) are defined as words that acquire a new word meaning\nwhile maintaining their form. Given the nature of this kind of neologisms, the\ntask of identifying these new word meanings is currently performed manually by\nspecialists at observatories of neology. To detect SN in a semi-automatic way,\nwe developed a system that implements a combination of the following\nstrategies: topic modeling, keyword extraction, and word sense disambiguation.\nThe role of topic modeling is to detect the themes that are treated in the\ninput text. Themes within a text give clues about the particular meaning of the\nwords that are used, for example: viral has one meaning in the context of\ncomputer science (CS) and another when talking about health. To extract\nkeywords, we used TextRank with POS tag filtering. With this method, we can\nobtain relevant words that are already part of the Spanish lexicon. We use a\ndeep learning model to determine if a given keyword could have a new meaning.\nEmbeddings that are different from all the known meanings (or topics) indicate\nthat a word might be a valid SN candidate. In this study, we examine the\nfollowing word embedding models: Word2Vec, Sense2Vec, and FastText. The models\nwere trained with equivalent parameters using Wikipedia in Spanish as corpora.\nThen we used a list of words and their concordances (obtained from our database\nof neologisms) to show the different embeddings that each model yields.\nFinally, we present a comparison of these outcomes with the concordances of\neach word to show how we can determine if a word could be a valid candidate for\nSN.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 21:54:52 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Torres-Rivera", "Andr\u00e9s", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "2001.05286", "submitter": "Kashyap Coimbatore Murali", "authors": "Kashyap Coimbatore Murali", "title": "Exploring and Improving Robustness of Multi Task Deep Neural Networks\n  via Domain Agnostic Defenses", "comments": "10 pages, 3 figures, 3 tables, 24 citations, 11 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the robustness of the Multi-Task Deep Neural\nNetworks (MT-DNN) against non-targeted adversarial attacks across Natural\nLanguage Understanding (NLU) tasks as well as some possible ways to defend\nagainst them. Liu et al., have shown that the Multi-Task Deep Neural Network,\ndue to the regularization effect produced when training as a result of its\ncross task data, is more robust than a vanilla BERT model trained only on one\ntask (1.1%-1.5% absolute difference). We further show that although the MT-DNN\nhas generalized better, making it easily transferable across domains and tasks,\nit can still be compromised as after only 2 attacks (1-character and\n2-character) the accuracy drops by 42.05% and 32.24% for the SNLI and SciTail\ntasks. Finally, we propose a domain agnostic defense which restores the model's\naccuracy (36.75% and 25.94% respectively) as opposed to a general-purpose\ndefense or an off-the-shelf spell checker.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 18:05:15 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Murali", "Kashyap Coimbatore", ""]]}, {"id": "2001.05292", "submitter": "Michael Ramscar", "authors": "Michael Ramscar", "title": "The empirical structure of word frequency distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The frequencies at which individual words occur across languages follow power\nlaw distributions, a pattern of findings known as Zipf's law. A vast literature\nargues over whether this serves to optimize the efficiency of human\ncommunication, however this claim is necessarily post hoc, and it has been\nsuggested that Zipf's law may in fact describe mixtures of other distributions.\nFrom this perspective, recent findings that Sinosphere first (family) names are\ngeometrically distributed are notable, because this is actually consistent with\ninformation theoretic predictions regarding optimal coding. First names form\nnatural communicative distributions in most languages, and I show that when\nanalyzed in relation to the communities in which they are used, first name\ndistributions across a diverse set of languages are both geometric and,\nhistorically, remarkably similar, with power law distributions only emerging\nwhen empirical distributions are aggregated. I then show this pattern of\nfindings replicates in communicative distributions of English nouns and verbs.\nThese results indicate that if lexical distributions support efficient\ncommunication, they do so because their functional structures directly satisfy\nthe constraints described by information theory, and not because of Zipf's law.\nUnderstanding the function of these information structures is likely to be key\nto explaining humankind's remarkable communicative capacities.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 20:52:38 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Ramscar", "Michael", ""]]}, {"id": "2001.05295", "submitter": "Ethan Steinberg", "authors": "Ethan Steinberg, Ken Jung, Jason A. Fries, Conor K. Corbin, Stephen R.\n  Pfohl, Nigam H. Shah", "title": "Language Models Are An Effective Patient Representation Learning\n  Technique For Electronic Health Record Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread adoption of electronic health records (EHRs) has fueled the\ndevelopment of using machine learning to build prediction models for various\nclinical outcomes. This process is often constrained by having a relatively\nsmall number of patient records for training the model. We demonstrate that\nusing patient representation schemes inspired from techniques in natural\nlanguage processing can increase the accuracy of clinical prediction models by\ntransferring information learned from the entire patient population to the task\nof training a specific model, where only a subset of the population is\nrelevant. Such patient representation schemes enable a 3.5% mean improvement in\nAUROC on five prediction tasks compared to standard baselines, with the average\nimprovement rising to 19% when only a small number of patient records are\navailable for training the clinical prediction model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:24:59 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 20:58:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Steinberg", "Ethan", ""], ["Jung", "Ken", ""], ["Fries", "Jason A.", ""], ["Corbin", "Conor K.", ""], ["Pfohl", "Stephen R.", ""], ["Shah", "Nigam H.", ""]]}, {"id": "2001.05296", "submitter": "Usman Mohyuddin", "authors": "Usman Mohy ud Din", "title": "Urdu-English Machine Transliteration using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation has gained much attention in recent years. It is a\nsub-field of computational linguistic which focus on translating text from one\nlanguage to other language. Among different translation techniques, neural\nnetwork currently leading the domain with its capabilities of providing a\nsingle large neural network with attention mechanism, sequence-to-sequence and\nlong-short term modelling. Despite significant progress in domain of machine\ntranslation, translation of out-of-vocabulary words(OOV) which include\ntechnical terms, named-entities, foreign words are still a challenge for\ncurrent state-of-art translation systems, and this situation becomes even worse\nwhile translating between low resource languages or languages having different\nstructures. Due to morphological richness of a language, a word may have\ndifferent meninges in different context. In such scenarios, translation of word\nis not only enough in order provide the correct/quality translation.\nTransliteration is a way to consider the context of word/sentence during\ntranslation. For low resource language like Urdu, it is very difficult to\nhave/find parallel corpus for transliteration which is large enough to train\nthe system. In this work, we presented transliteration technique based on\nExpectation Maximization (EM) which is un-supervised and language independent.\nSystems learns the pattern and out-of-vocabulary (OOV) words from parallel\ncorpus and there is no need to train it on transliteration corpus explicitly.\nThis approach is tested on three models of statistical machine translation\n(SMT) which include phrasebased, hierarchical phrase-based and factor based\nmodels and two models of neural machine translation which include LSTM and\ntransformer model.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 17:30:42 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Din", "Usman Mohy ud", ""]]}, {"id": "2001.05297", "submitter": "Chundra Cathcart", "authors": "Chundra Aroor Cathcart", "title": "Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process\n  Approach to Linguistic Relationships", "comments": "28 pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper addresses a series of complex and unresolved issues in the\nhistorical phonology of West Iranian languages. The West Iranian languages\n(Persian, Kurdish, Balochi, and other languages) display a high degree of\nnon-Lautgesetzlich behavior. Most of this irregularity is undoubtedly due to\nlanguage contact; we argue, however, that an oversimplified view of the\nprocesses at work has prevailed in the literature on West Iranian dialectology,\nwith specialists assuming that deviations from an expected outcome in a given\nnon-Persian language are due to lexical borrowing from some chronological stage\nof Persian. It is demonstrated that this qualitative approach yields at times\nproblematic conclusions stemming from the lack of explicit probabilistic\ninferences regarding the distribution of the data: Persian may not be the sole\ndonor language; additionally, borrowing at the lexical level is not always the\nmechanism that introduces irregularity. In many cases, the possibility that\nWest Iranian languages show different reflexes in different conditioning\nenvironments remains under-explored. We employ a novel Bayesian approach\ndesigned to overcome these problems and tease apart the different determinants\nof irregularity in patterns of West Iranian sound change. Our methodology\nallows us to provisionally resolve a number of outstanding questions in the\nliterature on West Iranian dialectology concerning the dialectal affiliation of\ncertain sound changes. We outline future directions for work of this sort.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:23:28 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 22:54:57 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 08:54:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cathcart", "Chundra Aroor", ""]]}, {"id": "2001.05308", "submitter": "Yang Li", "authors": "Yang Li, Julien Amelot, Xin Zhou, Samy Bengio, Si Si", "title": "Auto Completion of User Interface Layout Design Using Transformer-Based\n  Tree Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been of increasing interest in the field to develop automatic\nmachineries to facilitate the design process. In this paper, we focus on\nassisting graphical user interface (UI) layout design, a crucial task in app\ndevelopment. Given a partial layout, which a designer has entered, our model\nlearns to complete the layout by predicting the remaining UI elements with a\ncorrect position and dimension as well as the hierarchical structures. Such\nautomation will significantly ease the effort of UI designers and developers.\nWhile we focus on interface layout prediction, our model can be generally\napplicable for other layout prediction problems that involve tree structures\nand 2-dimensional placements. Particularly, we design two versions of\nTransformer-based tree decoders: Pointer and Recursive Transformer, and\nexperiment with these models on a public dataset. We also propose several\nmetrics for measuring the accuracy of tree prediction and ground these metrics\nin the domain of user experience. These contribute a new task and methods to\ndeep learning research.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:24:41 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Li", "Yang", ""], ["Amelot", "Julien", ""], ["Zhou", "Xin", ""], ["Bengio", "Samy", ""], ["Si", "Si", ""]]}, {"id": "2001.05313", "submitter": "Xien Liu", "authors": "Xien Liu, Xinxin You, Xiao Zhang, Ji Wu and Ping Lv", "title": "Tensor Graph Convolutional Networks for Text Classification", "comments": "8 pages, 4 figures", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to sequential learning models, graph-based neural networks exhibit\nsome excellent properties, such as ability capturing global information. In\nthis paper, we investigate graph-based neural networks for text classification\nproblem. A new framework TensorGCN (tensor graph convolutional networks), is\npresented for this task. A text graph tensor is firstly constructed to describe\nsemantic, syntactic, and sequential contextual information. Then, two kinds of\npropagation learning perform on the text graph tensor. The first is intra-graph\npropagation used for aggregating information from neighborhood nodes in a\nsingle graph. The second is inter-graph propagation used for harmonizing\nheterogeneous information between graphs. Extensive experiments are conducted\non benchmark datasets, and the results illustrate the effectiveness of our\nproposed framework. Our proposed TensorGCN presents an effective way to\nharmonize and integrate heterogeneous information from different kinds of\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 14:28:33 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Liu", "Xien", ""], ["You", "Xinxin", ""], ["Zhang", "Xiao", ""], ["Wu", "Ji", ""], ["Lv", "Ping", ""]]}, {"id": "2001.05314", "submitter": "Siyu Liao", "authors": "Siyu Liao, Jie Chen, Yanzhi Wang, Qinru Qiu, Bo Yuan", "title": "Embedding Compression with Isotropic Iterative Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous representation of words is a standard component in deep\nlearning-based NLP models. However, representing a large vocabulary requires\nsignificant memory, which can cause problems, particularly on\nresource-constrained platforms. Therefore, in this paper we propose an\nisotropic iterative quantization (IIQ) approach for compressing embedding\nvectors into binary ones, leveraging the iterative quantization technique well\nestablished for image retrieval, while satisfying the desired isotropic\nproperty of PMI based models. Experiments with pre-trained embeddings (i.e.,\nGloVe and HDC) demonstrate a more than thirty-fold compression ratio with\ncomparable and sometimes even improved performance over the original\nreal-valued embedding vectors.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 20:53:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 01:01:56 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liao", "Siyu", ""], ["Chen", "Jie", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""], ["Yuan", "Bo", ""]]}, {"id": "2001.05315", "submitter": "Md Saiful Islam", "authors": "Hemayet Ahmed Chowdhury, Md. Azizul Haque Imon, Anisur Rahman, Aisha\n  Khatun, Md. Saiful Islam", "title": "A Continuous Space Neural Language Model for Bengali Language", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models are generally employed to estimate the probability\ndistribution of various linguistic units, making them one of the fundamental\nparts of natural language processing. Applications of language models include a\nwide spectrum of tasks such as text summarization, translation and\nclassification. For a low resource language like Bengali, the research in this\narea so far can be considered to be narrow at the very least, with some\ntraditional count based models being proposed. This paper attempts to address\nthe issue and proposes a continuous-space neural language model, or more\nspecifically an ASGD weight dropped LSTM language model, along with techniques\nto efficiently train it for Bengali Language. The performance analysis with\nsome currently existing count based models illustrated in this paper also shows\nthat the proposed architecture outperforms its counterparts by achieving an\ninference perplexity as low as 51.2 on the held out data set for Bengali.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 14:50:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Chowdhury", "Hemayet Ahmed", ""], ["Imon", "Md. Azizul Haque", ""], ["Rahman", "Anisur", ""], ["Khatun", "Aisha", ""], ["Islam", "Md. Saiful", ""]]}, {"id": "2001.05316", "submitter": "Md Saiful Islam", "authors": "Aisha Khatun, Anisur Rahman, Md. Saiful Islam, Marium-E-Jannat", "title": "Authorship Attribution in Bangla literature using Character-level CNN", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 14:54:04 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Khatun", "Aisha", ""], ["Rahman", "Anisur", ""], ["Islam", "Md. Saiful", ""], ["Marium-E-Jannat", "", ""]]}, {"id": "2001.05320", "submitter": "Dhruv Khandelwal", "authors": "Dhruv Khandelwal, Maarten Schoukens and Roland T\\'oth", "title": "A Tree Adjoining Grammar Representation for Models Of Stochastic\n  Dynamical Systems", "comments": "Accepted as brief paper by Automatica", "journal-ref": null, "doi": "10.1016/J.AUTOMATICA.2020.109099", "report-no": null, "categories": "eess.SY cs.CL cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model structure and complexity selection remains a challenging problem in\nsystem identification, especially for parametric non-linear models. Many\nEvolutionary Algorithm (EA) based methods have been proposed in the literature\nfor estimating model structure and complexity. In most cases, the proposed\nmethods are devised for estimating structure and complexity within a specified\nmodel class and hence these methods do not extend to other model structures\nwithout significant changes. In this paper, we propose a Tree Adjoining Grammar\n(TAG) for stochastic parametric models. TAGs can be used to generate models in\nan EA framework while imposing desirable structural constraints and\nincorporating prior knowledge. In this paper, we propose a TAG that can\nsystematically generate models ranging from FIRs to polynomial NARMAX models.\nFurthermore, we demonstrate that TAGs can be easily extended to more general\nmodel classes, such as the non-linear Box-Jenkins model class, enabling the\nrealization of flexible and automatic model structure and complexity selection\nvia EA.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:35:19 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 13:24:49 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Khandelwal", "Dhruv", ""], ["Schoukens", "Maarten", ""], ["T\u00f3th", "Roland", ""]]}, {"id": "2001.05326", "submitter": "Lin Li", "authors": "Lingyun Zhao, Lin Li, Xinhao Zheng", "title": "A BERT based Sentiment Analysis and Key Entity Detection Approach for\n  Online Financial Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence and rapid progress of the Internet have brought ever-increasing\nimpact on financial domain. How to rapidly and accurately mine the key\ninformation from the massive negative financial texts has become one of the key\nissues for investors and decision makers. Aiming at the issue, we propose a\nsentiment analysis and key entity detection approach based on BERT, which is\napplied in online financial text mining and public opinion analysis in social\nmedia. By using pre-train model, we first study sentiment analysis, and then we\nconsider key entity detection as a sentence matching or Machine Reading\nComprehension (MRC) task in different granularity. Among them, we mainly focus\non negative sentimental information. We detect the specific entity by using our\napproach, which is different from traditional Named Entity Recognition (NER).\nIn addition, we also use ensemble learning to improve the performance of\nproposed approach. Experimental results show that the performance of our\napproach is generally higher than SVM, LR, NBM, and BERT for two financial\nsentiment analysis and key entity detection datasets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:50:08 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhao", "Lingyun", ""], ["Li", "Lin", ""], ["Zheng", "Xinhao", ""]]}, {"id": "2001.05467", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses", "comments": "AAAI 2020 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequence-to-sequence dialogue models tend to generate safe,\nuninformative responses. There have been various useful efforts on trying to\neliminate them. However, these approaches either improve decoding algorithms\nduring inference, rely on hand-crafted features, or employ complex models. In\nour work, we build dialogue models that are dynamically aware of what\nutterances or tokens are dull without any feature-engineering. Specifically, we\nstart with a simple yet effective automatic metric, AvgOut, which calculates\nthe average output probability distribution of all time steps on the decoder\nside during training. This metric directly estimates which tokens are more\nlikely to be generated, thus making it a faithful evaluation of the model\ndiversity (i.e., for diverse models, the token probabilities should be more\nevenly distributed rather than peaked at a few dull tokens). We then leverage\nthis novel metric to propose three models that promote diversity without losing\nrelevance. The first model, MinAvgOut, directly maximizes the diversity score\nthrough the output distributions of each batch; the second model, Label\nFine-Tuning (LFT), prepends to the source sequence a label continuously scaled\nby the diversity score to control the diversity level; the third model, RL,\nadopts Reinforcement Learning and treats the diversity score as a reward\nsignal. Moreover, we experiment with a hybrid model by combining the loss terms\nof MinAvgOut and RL. All four models outperform their base LSTM-RNN model on\nboth diversity and relevance by a large margin, and are comparable to or better\nthan competitive baselines (also verified via human evaluation). Moreover, our\napproaches are orthogonal to the base model, making them applicable as an\nadd-on to other emerging better dialogue models in the future.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:32:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.05493", "submitter": "Anant Khandelwal", "authors": "Anant Khandelwal, Niraj Kumar", "title": "A Unified System for Aggression Identification in English Code-Mixed and\n  Uni-Lingual Texts", "comments": "10 pages, 5 Figures, 6 Tables, accepted at CoDS-COMAD 2020", "journal-ref": null, "doi": "10.1145/3371158.3371165", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wide usage of social media platforms has increased the risk of aggression,\nwhich results in mental stress and affects the lives of people negatively like\npsychological agony, fighting behavior, and disrespect to others. Majority of\nsuch conversations contains code-mixed languages[28]. Additionally, the way\nused to express thought or communication style also changes from one social\nmedia plat-form to another platform (e.g., communication styles are different\nin twitter and Facebook). These all have increased the complexity of the\nproblem. To solve these problems, we have introduced a unified and robust\nmulti-modal deep learning architecture which works for English code-mixed\ndataset and uni-lingual English dataset both.The devised system, uses\npsycho-linguistic features and very ba-sic linguistic features. Our multi-modal\ndeep learning architecture contains, Deep Pyramid CNN, Pooled BiLSTM, and\nDisconnected RNN(with Glove and FastText embedding, both). Finally, the system\ntakes the decision based on model averaging. We evaluated our system on English\nCode-Mixed TRAC 2018 dataset and uni-lingual English dataset obtained from\nKaggle. Experimental results show that our proposed system outperforms all the\nprevious approaches on English code-mixed dataset and uni-lingual English\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:06:29 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 06:50:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Khandelwal", "Anant", ""], ["Kumar", "Niraj", ""]]}, {"id": "2001.05495", "submitter": "Pinkesh Badjatiya", "authors": "Pinkesh Badjatiya, Manish Gupta, Vasudeva Varma", "title": "Stereotypical Bias Removal for Hate Speech Detection Task using\n  Knowledge-based Generalizations", "comments": null, "journal-ref": "In The World Wide Web Conference (WWW '19). Association for\n  Computing Machinery, New York, NY, USA, 49-59. 2019", "doi": "10.1145/3308558.3313504", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing cases of hate spread on social media platforms, it\nis critical to design abuse detection mechanisms to proactively avoid and\ncontrol such incidents. While there exist methods for hate speech detection,\nthey stereotype words and hence suffer from inherently biased training. Bias\nremoval has been traditionally studied for structured datasets, but we aim at\nbias mitigation from unstructured text data. In this paper, we make two\nimportant contributions. First, we systematically design methods to quantify\nthe bias for any model and propose algorithms for identifying the set of words\nwhich the model stereotypes. Second, we propose novel methods leveraging\nknowledge-based generalizations for bias-free learning. Knowledge-based\ngeneralization provides an effective way to encode knowledge because the\nabstraction they provide not only generalizes content but also facilitates\nretraction of information from the hate speech detection classifier, thereby\nreducing the imbalance. We experiment with multiple knowledge generalization\npolicies and analyze their effect on general performance and in mitigating\nbias. Our experiments with two real-world datasets, a Wikipedia Talk Pages\ndataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that\nthe use of knowledge-based generalizations results in better performance by\nforcing the classifier to learn from generalized content. Our methods utilize\nexisting knowledge-bases and can easily be extended to other tasks\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:17:36 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Badjatiya", "Pinkesh", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "2001.05540", "submitter": "Laura Ruis", "authors": "Laura Ruis, Mitchell Stern, Julia Proskurnia, William Chan", "title": "Insertion-Deletion Transformer", "comments": "Accepted as an Extended Abstract at the Workshop of Neural Generation\n  and Translation (WNGT 2019) at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Insertion-Deletion Transformer, a novel transformer-based\nneural architecture and training method for sequence generation. The model\nconsists of two phases that are executed iteratively, 1) an insertion phase and\n2) a deletion phase. The insertion phase parameterizes a distribution of\ninsertions on the current output hypothesis, while the deletion phase\nparameterizes a distribution of deletions over the current output hypothesis.\nThe training method is a principled and simple algorithm, where the deletion\nmodel obtains its signal directly on-policy from the insertion model output. We\ndemonstrate the effectiveness of our Insertion-Deletion Transformer on\nsynthetic translation tasks, obtaining significant BLEU score improvement over\nan insertion-only model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:26:48 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ruis", "Laura", ""], ["Stern", "Mitchell", ""], ["Proskurnia", "Julia", ""], ["Chan", "William", ""]]}, {"id": "2001.05609", "submitter": "Silei Xu", "authors": "Silei Xu, Giovanni Campagna, Jian Li and Monica S. Lam", "title": "Schema2QA: High-Quality and Low-Cost Q&A Agents for the Structured Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Building a question-answering agent currently requires large annotated\ndatasets, which are prohibitively expensive. This paper proposes Schema2QA, an\nopen-source toolkit that can generate a Q&A system from a database schema\naugmented with a few annotations for each field. The key concept is to cover\nthe space of possible compound queries on the database with a large number of\nin-domain questions synthesized with the help of a corpus of generic query\ntemplates. The synthesized data and a small paraphrase set are used to train a\nnovel neural network based on the BERT pretrained model. We use Schema2QA to\ngenerate Q&A systems for five Schema.org domains, restaurants, people, movies,\nbooks and music, and obtain an overall accuracy between 64% and 75% on\ncrowdsourced questions for these domains. Once annotations and paraphrases are\nobtained for a Schema.org schema, no additional manual effort is needed to\ncreate a Q&A agent for any website that uses the same schema. Furthermore, we\ndemonstrate that learning can be transferred from the restaurant to the hotel\ndomain, obtaining a 64% accuracy on crowdsourced questions with no manual\neffort. Schema2QA achieves an accuracy of 60% on popular restaurant questions\nthat can be answered using Schema.org. Its performance is comparable to Google\nAssistant, 7% lower than Siri, and 15% higher than Alexa. It outperforms all\nthese assistants by at least 18% on more complex, long-tail questions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 01:49:16 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 20:32:49 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 19:44:06 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 17:13:27 GMT"}, {"version": "v5", "created": "Mon, 24 Aug 2020 21:35:26 GMT"}, {"version": "v6", "created": "Tue, 8 Jun 2021 01:30:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Xu", "Silei", ""], ["Campagna", "Giovanni", ""], ["Li", "Jian", ""], ["Lam", "Monica S.", ""]]}, {"id": "2001.05614", "submitter": "Haoran Chen", "authors": "Haoran Chen, Jianmin Li and Xiaolin Hu", "title": "Delving Deeper into the Decoder for Video Captioning", "comments": "8 pages, 3 figures, European Conference on Artificial Intelligence.\n  ECAI 2020", "journal-ref": null, "doi": "10.3233/FAIA200204", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video captioning is an advanced multi-modal task which aims to describe a\nvideo clip using a natural language sentence. The encoder-decoder framework is\nthe most popular paradigm for this task in recent years. However, there exist\nsome problems in the decoder of a video captioning model. We make a thorough\ninvestigation into the decoder and adopt three techniques to improve the\nperformance of the model. First of all, a combination of variational dropout\nand layer normalization is embedded into a recurrent unit to alleviate the\nproblem of overfitting. Secondly, a new online method is proposed to evaluate\nthe performance of a model on a validation set so as to select the best\ncheckpoint for testing. Finally, a new training strategy called professional\nlearning is proposed which uses the strengths of a captioning model and\nbypasses its weaknesses. It is demonstrated in the experiments on Microsoft\nResearch Video Description Corpus (MSVD) and MSR-Video to Text (MSR-VTT)\ndatasets that our model has achieved the best results evaluated by BLEU, CIDEr,\nMETEOR and ROUGE-L metrics with significant gains of up to 18% on MSVD and 3.5%\non MSR-VTT compared with the previous state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 02:18:27 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 06:36:17 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 01:31:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Chen", "Haoran", ""], ["Li", "Jianmin", ""], ["Hu", "Xiaolin", ""]]}, {"id": "2001.05672", "submitter": "Trung Tran Quang", "authors": "Trung Q. Tran", "title": "AandP: Utilizing Prolog for converting between active sentence and\n  passive sentence with three-steps conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce a simple but efficient method to solve one of the critical\naspects of English grammar which is the relationship between active sentence\nand passive sentence. In fact, an active sentence and its corresponding passive\nsentence express the same meaning, but their structure is different. I utilized\nProlog [4] along with Definite Clause Grammars (DCG) [5] for doing the\nconversion between active sentence and passive sentence. Some advanced\ntechniques were also used such as Extra Arguments, Extra Goals, Lexicon, etc. I\ntried to solve a variety of cases of active and passive sentences such as 12\nEnglish tenses, modal verbs, negative form, etc. More details and my\ncontributions will be presented in the following sections. The source code is\navailable at https://github.com/tqtrunghnvn/ActiveAndPassive.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:31:53 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Tran", "Trung Q.", ""]]}, {"id": "2001.05687", "submitter": "Kiet Nguyen", "authors": "Kiet Van Nguyen, Khiem Vinh Tran, Son T. Luu, Anh Gia-Tuan Nguyen,\n  Ngan Luu-Thuy Nguyen", "title": "Enhancing lexical-based approach with external knowledge for Vietnamese\n  multiple-choice machine reading comprehension", "comments": null, "journal-ref": "IEEE Access, 2020", "doi": "10.1109/ACCESS.2020.3035701", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although Vietnamese is the 17th most popular native-speaker language in the\nworld, there are not many research studies on Vietnamese machine reading\ncomprehension (MRC), the task of understanding a text and answering questions\nabout it. One of the reasons is because of the lack of high-quality benchmark\ndatasets for this task. In this work, we construct a dataset which consists of\n2,783 pairs of multiple-choice questions and answers based on 417 Vietnamese\ntexts which are commonly used for teaching reading comprehension for elementary\nschool pupils. In addition, we propose a lexical-based MRC method that utilizes\nsemantic similarity measures and external knowledge sources to analyze\nquestions and extract answers from the given text. We compare the performance\nof the proposed model with several baseline lexical-based and neural\nnetwork-based models. Our proposed method achieves 61.81% by accuracy, which is\n5.51% higher than the best baseline model. We also measure human performance on\nour dataset and find that there is a big gap between machine-model and human\nperformances. This indicates that significant progress can be made on this\ntask. The dataset is freely available on our website for research purposes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:09:51 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 10:07:39 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 03:45:33 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 10:02:23 GMT"}, {"version": "v5", "created": "Sun, 1 Nov 2020 16:04:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Van Nguyen", "Kiet", ""], ["Tran", "Khiem Vinh", ""], ["Luu", "Son T.", ""], ["Nguyen", "Anh Gia-Tuan", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2001.05714", "submitter": "Jan Trienes", "authors": "Jan Trienes, Dolf Trieschnigg, Christin Seifert, Djoerd Hiemstra", "title": "Comparing Rule-based, Feature-based and Deep Neural Methods for\n  De-identification of Dutch Medical Records", "comments": "Proceedings of the 1st ACM WSDM Health Search and Data Mining\n  Workshop (HSDM2020), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unstructured information in electronic health records provide an invaluable\nresource for medical research. To protect the confidentiality of patients and\nto conform to privacy regulations, de-identification methods automatically\nremove personally identifying information from these medical records. However,\ndue to the unavailability of labeled data, most existing research is\nconstrained to English medical text and little is known about the\ngeneralizability of de-identification methods across languages and domains. In\nthis study, we construct a varied dataset consisting of the medical records of\n1260 patients by sampling data from 9 institutes and three domains of Dutch\nhealthcare. We test the generalizability of three de-identification methods\nacross languages and domains. Our experiments show that an existing rule-based\nmethod specifically developed for the Dutch language fails to generalize to\nthis new data. Furthermore, a state-of-the-art neural architecture performs\nstrongly across languages and domains, even with limited training data.\nCompared to feature-based and rule-based methods the neural method requires\nsignificantly less configuration effort and domain-knowledge. We make all code\nand pre-trained de-identification models available to the research community,\nallowing practitioners to apply them to their datasets and to enable future\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 09:42:29 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Trienes", "Jan", ""], ["Trieschnigg", "Dolf", ""], ["Seifert", "Christin", ""], ["Hiemstra", "Djoerd", ""]]}, {"id": "2001.05727", "submitter": "Antoine Gourru", "authors": "Antoine Gourru, Adrien Guille, Julien Velcin and Julien Jacques", "title": "Document Network Projection in Pretrained Word Embedding Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Regularized Linear Embedding (RLE), a novel method that projects a\ncollection of linked documents (e.g. citation network) into a pretrained word\nembedding space. In addition to the textual content, we leverage a matrix of\npairwise similarities providing complementary information (e.g., the network\nproximity of two documents in a citation graph). We first build a simple word\nvector average for each document, and we use the similarities to alter this\naverage representation. The document representations can help to solve many\ninformation retrieval tasks, such as recommendation, classification and\nclustering. We demonstrate that our approach outperforms or matches existing\ndocument network embedding methods on node classification and link prediction\ntasks. Furthermore, we show that it helps identifying relevant keywords to\ndescribe document classes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:16:37 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Gourru", "Antoine", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""], ["Jacques", "Julien", ""]]}, {"id": "2001.05839", "submitter": "David Noever", "authors": "David Noever, Wes Regian, Matt Ciolino, Josh Kalin, Dom Hambrick, Kaye\n  Blankenship", "title": "Discoverability in Satellite Imagery: A Good Sentence is Worth a\n  Thousand Pictures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small satellite constellations provide daily global coverage of the earth's\nlandmass, but image enrichment relies on automating key tasks like change\ndetection or feature searches. For example, to extract text annotations from\nraw pixels requires two dependent machine learning models, one to analyze the\noverhead image and the other to generate a descriptive caption. We evaluate\nseven models on the previously largest benchmark for satellite image captions.\nWe extend the labeled image samples five-fold, then augment, correct and prune\nthe vocabulary to approach a rough min-max (minimum word, maximum description).\nThis outcome compares favorably to previous work with large pre-trained image\nmodels but offers a hundred-fold reduction in model size without sacrificing\noverall accuracy (when measured with log entropy loss). These smaller models\nprovide new deployment opportunities, particularly when pushed to edge\nprocessors, on-board satellites, or distributed ground stations. To quantify a\ncaption's descriptiveness, we introduce a novel multi-class confusion or error\nmatrix to score both human-labeled test data and never-labeled images that\ninclude bounding box detection but lack full sentence captions. This work\nsuggests future captioning strategies, particularly ones that can enrich the\nclass coverage beyond land use applications and that lessen color-centered and\nadjacency adjectives (\"green\", \"near\", \"between\", etc.). Many modern language\ntransformers present novel and exploitable models with world knowledge gleaned\nfrom training from their vast online corpus. One interesting, but easy example\nmight learn the word association between wind and waves, thus enriching a beach\nscene with more than just color descriptions that otherwise might be accessed\nfrom raw pixels without text annotation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 20:41:18 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Noever", "David", ""], ["Regian", "Wes", ""], ["Ciolino", "Matt", ""], ["Kalin", "Josh", ""], ["Hambrick", "Dom", ""], ["Blankenship", "Kaye", ""]]}, {"id": "2001.05865", "submitter": "Raghav Goyal", "authors": "Shubham Agarwal, Raghav Goyal", "title": "Ensemble based discriminative models for Visual Dialog Challenge 2018", "comments": "Rankings: https://visualdialog.org/challenge/2018#winners", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This manuscript describes our approach for the Visual Dialog Challenge 2018.\nWe use an ensemble of three discriminative models with different encoders and\ndecoders for our final submission. Our best performing model on 'test-std'\nsplit achieves the NDCG score of 55.46 and the MRR value of 63.77, securing\nthird position in the challenge.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:20:54 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Agarwal", "Shubham", ""], ["Goyal", "Raghav", ""]]}, {"id": "2001.05871", "submitter": "Vivian Lai", "authors": "Vivian Lai, Han Liu, Chenhao Tan", "title": "\"Why is 'Chicago' deceptive?\" Towards Building Model-Driven Tutorials\n  for Humans", "comments": "26 pages, 48 figures, CHI 2020", "journal-ref": null, "doi": "10.1145/10.1145/3313831.3376873", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support human decision making with machine learning models, we often need\nto elucidate patterns embedded in the models that are unsalient, unknown, or\ncounterintuitive to humans. While existing approaches focus on explaining\nmachine predictions with real-time assistance, we explore model-driven\ntutorials to help humans understand these patterns in a training phase. We\nconsider both tutorials with guidelines from scientific papers, analogous to\ncurrent practices of science communication, and automatically selected examples\nfrom training data with explanations. We use deceptive review detection as a\ntestbed and conduct large-scale, randomized human-subject experiments to\nexamine the effectiveness of such tutorials. We find that tutorials indeed\nimprove human performance, with and without real-time assistance. In\nparticular, although deep learning provides superior predictive performance\nthan simple models, tutorials and explanations from simple models are more\nuseful to humans. Our work suggests future directions for human-centered\ntutorials and explanations towards a synergy between humans and AI.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:00:00 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Lai", "Vivian", ""], ["Liu", "Han", ""], ["Tan", "Chenhao", ""]]}, {"id": "2001.05876", "submitter": "Li Wang", "authors": "Li Wang, Zechen Bai, Yonghua Zhang, Hongtao Lu", "title": "Show, Recall, and Tell: Image Captioning with Recall Mechanism", "comments": "Published in AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i07.6898", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating natural and accurate descriptions in image cap-tioning has always\nbeen a challenge. In this paper, we pro-pose a novel recall mechanism to\nimitate the way human con-duct captioning. There are three parts in our recall\nmecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS).\nRecall unit is a text-retrieval module designedto retrieve recalled words for\nimages. SG and RWS are de-signed for the best use of recalled words. SG branch\ncangenerate a recalled context, which can guide the process ofgenerating\ncaption. RWS branch is responsible for copyingrecalled words to the caption.\nInspired by pointing mecha-nism in text summarization, we adopt a soft switch\nto balancethe generated-word probabilities between SG and RWS. Inthe CIDEr\noptimization step, we also introduce an individualrecalled-word reward (WR) to\nboost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr /\nSPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 /\n22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the\nresults of other state-of-the-artmethods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:32:51 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:09:06 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 05:00:56 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Wang", "Li", ""], ["Bai", "Zechen", ""], ["Zhang", "Yonghua", ""], ["Lu", "Hongtao", ""]]}, {"id": "2001.05908", "submitter": "Chunyi Wang", "authors": "Chunyi Wang", "title": "Speech Emotion Recognition Based on Multi-feature and Multi-lingual\n  Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A speech emotion recognition algorithm based on multi-feature and\nMulti-lingual fusion is proposed in order to resolve low recognition accuracy\ncaused by lack of large speech dataset and low robustness of acoustic features\nin the recognition of speech emotion. First, handcrafted and deep automatic\nfeatures are extracted from existing data in Chinese and English speech\nemotions. Then, the various features are fused respectively. Finally, the fused\nfeatures of different languages are fused again and trained in a classification\nmodel. Distinguishing the fused features with the unfused ones, the results\nmanifest that the fused features significantly enhance the accuracy of speech\nemotion recognition algorithm. The proposed solution is evaluated on the two\nChinese corpus and two English corpus, and is shown to provide more accurate\npredictions compared to original solution. As a result of this study, the\nmulti-feature and Multi-lingual fusion algorithm can significantly improve the\nspeech emotion recognition accuracy when the dataset is small.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:53:13 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Wang", "Chunyi", ""]]}, {"id": "2001.05954", "submitter": "Jiaju Du", "authors": "Jiaju Du, Fanchao Qi, Maosong Sun, Zhiyuan Liu", "title": "Lexical Sememe Prediction using Dictionary Definitions by Capturing\n  Local Semantic Correspondence", "comments": "Accepted by Journal of Chinese Information Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sememes, defined as the minimum semantic units of human languages in\nlinguistics, have been proven useful in many NLP tasks. Since manual\nconstruction and update of sememe knowledge bases (KBs) are costly, the task of\nautomatic sememe prediction has been proposed to assist sememe annotation. In\nthis paper, we explore the approach of applying dictionary definitions to\npredicting sememes for unannotated words. We find that sememes of each word are\nusually semantically matched to different words in its dictionary definition,\nand we name this matching relationship local semantic correspondence.\nAccordingly, we propose a Sememe Correspondence Pooling (SCorP) model, which is\nable to capture this kind of matching to predict sememes. We evaluate our model\nand baseline methods on a famous sememe KB HowNet and find that our model\nachieves state-of-the-art performance. Moreover, further quantitative analysis\nshows that our model can properly learn the local semantic correspondence\nbetween sememes and words in dictionary definitions, which explains the\neffectiveness of our model. The source codes of this paper can be obtained from\nhttps://github.com/thunlp/scorp.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:30:36 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Du", "Jiaju", ""], ["Qi", "Fanchao", ""], ["Sun", "Maosong", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "2001.05970", "submitter": "Viet Duong", "authors": "Viet Duong, Phu Pham, Ritwik Bose, Jiebo Luo", "title": "#MeToo on Campus: Studying College Sexual Assault at Scale Using Data\n  Reported on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the emergence of the #MeToo trend on social media has empowered\nthousands of people to share their own sexual harassment experiences. This\nviral trend, in conjunction with the massive personal information and content\navailable on Twitter, presents a promising opportunity to extract data driven\ninsights to complement the ongoing survey based studies about sexual harassment\nin college. In this paper, we analyze the influence of the #MeToo trend on a\npool of college followers. The results show that the majority of topics\nembedded in those #MeToo tweets detail sexual harassment stories, and there\nexists a significant correlation between the prevalence of this trend and\nofficial reports on several major geographical regions. Furthermore, we\ndiscover the outstanding sentiments of the #MeToo tweets using deep semantic\nmeaning representations and their implications on the affected users\nexperiencing different types of sexual harassment. We hope this study can raise\nfurther awareness regarding sexual misconduct in academia.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:05:46 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Duong", "Viet", ""], ["Pham", "Phu", ""], ["Bose", "Ritwik", ""], ["Luo", "Jiebo", ""]]}, {"id": "2001.06007", "submitter": "Nicolas Lair", "authors": "Nicolas Lair, Cl\\'ement Delgrange, David Mugisha, Jean-Michel Dussoux,\n  Pierre-Yves Oudeyer, and Peter Ford Dominey", "title": "User-in-the-loop Adaptive Intent Detection for Instructable Digital\n  Assistant", "comments": "To be published as a conference paper in the proceedings of IUI'20", "journal-ref": "25th International Conference on Intelligent User Interfaces (IUI\n  '20), March 17--20, 2020, Cagliari, Italy", "doi": "10.1145/3377325.3377490", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People are becoming increasingly comfortable using Digital Assistants (DAs)\nto interact with services or connected objects. However, for non-programming\nusers, the available possibilities for customizing their DA are limited and do\nnot include the possibility of teaching the assistant new tasks. To make the\nmost of the potential of DAs, users should be able to customize assistants by\ninstructing them through Natural Language (NL). To provide such\nfunctionalities, NL interpretation in traditional assistants should be\nimproved: (1) The intent identification system should be able to recognize new\nforms of known intents, and to acquire new intents as they are expressed by the\nuser. (2) In order to be adaptive to novel intents, the Natural Language\nUnderstanding module should be sample efficient, and should not rely on a\npretrained model. Rather, the system should continuously collect the training\ndata as it learns new intents from the user. In this work, we propose AidMe\n(Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop\nadaptive intent detection framework that allows the assistant to adapt to its\nuser by learning his intents as their interaction progresses. AidMe builds its\nrepertoire of intents and collects data to train a model of semantic similarity\nevaluation that can discriminate between the learned intents and autonomously\ndiscover new forms of known intents. AidMe addresses two major issues - intent\nlearning and user adaptation - for instructable digital assistants. We\ndemonstrate the capabilities of AidMe as a standalone system by comparing it\nwith a one-shot learning system and a pretrained NLU module through simulations\nof interactions with a user. We also show how AidMe can smoothly integrate to\nan existing instructable digital assistant.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:06:43 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Lair", "Nicolas", ""], ["Delgrange", "Cl\u00e9ment", ""], ["Mugisha", "David", ""], ["Dussoux", "Jean-Michel", ""], ["Oudeyer", "Pierre-Yves", ""], ["Dominey", "Peter Ford", ""]]}, {"id": "2001.06094", "submitter": "Debi Prasanna Mohanty Mr", "authors": "Sumit Kumar, Gopi Ramena, Manoj Goyal, Debi Mohanty, Ankur Agarwal,\n  Benu Changmai, Sukumar Moharana", "title": "On- Device Information Extraction from Screenshots in form of tags", "comments": null, "journal-ref": null, "doi": "10.1145/3371158.3371200", "report-no": null, "categories": "cs.CV cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a method to make mobile screenshots easily searchable. In this\npaper, we present the workflow in which we: 1) preprocessed a collection of\nscreenshots, 2) identified script presentin image, 3) extracted unstructured\ntext from images, 4) identifiedlanguage of the extracted text, 5) extracted\nkeywords from the text, 6) identified tags based on image features, 7) expanded\ntag set by identifying related keywords, 8) inserted image tags with relevant\nimages after ranking and indexed them to make it searchable on device. We made\nthe pipeline which supports multiple languages and executed it on-device, which\naddressed privacy concerns. We developed novel architectures for components in\nthe pipeline, optimized performance and memory for on-device computation. We\nobserved from experimentation that the solution developed can reduce overall\nuser effort and improve end user experience while searching, whose results are\npublished.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 12:15:30 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kumar", "Sumit", ""], ["Ramena", "Gopi", ""], ["Goyal", "Manoj", ""], ["Mohanty", "Debi", ""], ["Agarwal", "Ankur", ""], ["Changmai", "Benu", ""], ["Moharana", "Sukumar", ""]]}, {"id": "2001.06206", "submitter": "Yun-Wei Chu", "authors": "Yun-Wei Chu, Kuan-Yen Lin, Chao-Chun Hsu, Lun-Wei Ku", "title": "Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue\n  System", "comments": "DSTC8 collocated with AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding dynamic scenes and dialogue contexts in order to converse with\nusers has been challenging for multimodal dialogue systems. The 8-th Dialog\nSystem Technology Challenge (DSTC8) proposed an Audio Visual Scene-Aware Dialog\n(AVSD) task, which contains multiple modalities including audio, vision, and\nlanguage, to evaluate how dialogue systems understand different modalities and\nresponse to users. In this paper, we proposed a multi-step joint-modality\nattention network (JMAN) based on recurrent neural network (RNN) to reason on\nvideos. Our model performs a multi-step attention mechanism and jointly\nconsiders both visual and textual representations in each reasoning process to\nbetter integrate information from the two different modalities. Compared to the\nbaseline released by AVSD organizers, our model achieves a relative 12.1% and\n22.4% improvement over the baseline on ROUGE-L score and CIDEr score.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 09:18:00 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Chu", "Yun-Wei", ""], ["Lin", "Kuan-Yen", ""], ["Hsu", "Chao-Chun", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "2001.06286", "submitter": "Pieter Delobelle", "authors": "Pieter Delobelle, Thomas Winters, Bettina Berendt", "title": "RobBERT: a Dutch RoBERTa-based Language Model", "comments": "11 pages, 4 tables, 3 figures. Accepted in EMNLP Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have been dominating the field of natural\nlanguage processing in recent years, and have led to significant performance\ngains for various complex natural language tasks. One of the most prominent\npre-trained language models is BERT, which was released as an English as well\nas a multilingual version. Although multilingual BERT performs well on many\ntasks, recent studies show that BERT models trained on a single language\nsignificantly outperform the multilingual version. Training a Dutch BERT model\nthus has a lot of potential for a wide range of Dutch NLP tasks. While previous\napproaches have used earlier implementations of BERT to train a Dutch version\nof BERT, we used RoBERTa, a robustly optimized BERT approach, to train a Dutch\nlanguage model called RobBERT. We measured its performance on various tasks as\nwell as the importance of the fine-tuning dataset size. We also evaluated the\nimportance of language-specific tokenizers and the model's fairness. We found\nthat RobBERT improves state-of-the-art results for various tasks, and\nespecially significantly outperforms other models when dealing with smaller\ndatasets. These results indicate that it is a powerful pre-trained model for a\nlarge variety of Dutch language tasks. The pre-trained and fine-tuned models\nare publicly available to support further downstream Dutch NLP applications.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 13:25:44 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 13:42:16 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Delobelle", "Pieter", ""], ["Winters", "Thomas", ""], ["Berendt", "Bettina", ""]]}, {"id": "2001.06350", "submitter": "Maira Gatti de Bayser", "authors": "Maira Gatti de Bayser, Melina Alberio Guerra, Paulo Cavalin, Claudio\n  Pinhanez", "title": "A Hybrid Solution to Learn Turn-Taking in Multi-Party Service-based Chat\n  Groups", "comments": "arXiv admin note: text overlap with arXiv:1907.02090", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To predict the next most likely participant to interact in a multi-party\nconversation is a difficult problem. In a text-based chat group, the only\ninformation available is the sender, the content of the text and the dialogue\nhistory. In this paper we present our study on how these information can be\nused on the prediction task through a corpus and architecture that integrates\nturn-taking classifiers based on Maximum Likelihood Expectation (MLE),\nConvolutional Neural Networks (CNN) and Finite State Automata (FSA). The corpus\nis a synthetic adaptation of the Multi-Domain Wizard-of-Oz dataset (MultiWOZ)\nto a multiple travel service-based bots scenario with dialogue errors and was\ncreated to simulate user's interaction and evaluate the architecture. We\npresent experimental results which show that the CNN approach achieves better\nperformance than the baseline with an accuracy of 92.34%, but the integrated\nsolution with MLE, CNN and FSA achieves performance even better, with 95.65%.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:37:21 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["de Bayser", "Maira Gatti", ""], ["Guerra", "Melina Alberio", ""], ["Cavalin", "Paulo", ""], ["Pinhanez", "Claudio", ""]]}, {"id": "2001.06354", "submitter": "Hyounghun Kim", "authors": "Hyounghun Kim, Hao Tan, Mohit Bansal", "title": "Modality-Balanced Models for Visual Dialogue", "comments": "AAAI 2020 (11 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Visual Dialog task requires a model to exploit both image and\nconversational context information to generate the next response to the\ndialogue. However, via manual analysis, we find that a large number of\nconversational questions can be answered by only looking at the image without\nany access to the context history, while others still need the conversation\ncontext to predict the correct answers. We demonstrate that due to this reason,\nprevious joint-modality (history and image) models over-rely on and are more\nprone to memorizing the dialogue history (e.g., by extracting certain keywords\nor patterns in the context information), whereas image-only models are more\ngeneralizable (because they cannot memorize or extract keywords from history)\nand perform substantially better at the primary normalized discounted\ncumulative gain (NDCG) task metric which allows multiple correct answers.\nHence, this observation encourages us to explicitly maintain two models, i.e.,\nan image-only model and an image-history joint model, and combine their\ncomplementary abilities for a more balanced multimodal model. We present\nmultiple methods for this integration of the two models, via ensemble and\nconsensus dropout fusion with shared parameters. Empirically, our models\nachieve strong results on the Visual Dialog challenge 2019 (rank 3 on NDCG and\nhigh balance across metrics), and substantially outperform the winner of the\nVisual Dialog challenge 2018 on most metrics.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 14:57:12 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Kim", "Hyounghun", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.06381", "submitter": "Iker Garc\\'ia", "authors": "Iker Garc\\'ia, Rodrigo Agerri, German Rigau", "title": "A Common Semantic Space for Monolingual and Cross-Lingual\n  Meta-Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new technique for creating monolingual and\ncross-lingual meta-embeddings. Our method integrates multiple word embeddings\ncreated from complementary techniques, textual sources, knowledge bases and\nlanguages. Existing word vectors are projected to a common semantic space using\nlinear transformations and averaging. With our method the resulting\nmeta-embeddings maintain the dimensionality of the original embeddings without\nlosing information while dealing with the out-of-vocabulary problem. An\nextensive empirical evaluation demonstrates the effectiveness of our technique\nwith respect to previous work on various intrinsic and extrinsic multilingual\nevaluations, obtaining competitive results for Semantic Textual Similarity and\nstate-of-the-art performance for word similarity and POS tagging (English and\nSpanish). The resulting cross-lingual meta-embeddings also exhibit excellent\ncross-lingual transfer learning capabilities. In other words, we can leverage\npre-trained source embeddings from a resource-rich language in order to improve\nthe word representations for under-resourced languages.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:42:29 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Garc\u00eda", "Iker", ""], ["Agerri", "Rodrigo", ""], ["Rigau", "German", ""]]}, {"id": "2001.06397", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Thomas Hain", "title": "Supervised Speaker Embedding De-Mixing in Two-Speaker Environment", "comments": "Published at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating different speaker properties from a multi-speaker environment is\nchallenging. Instead of separating a two-speaker signal in signal space like\nspeech source separation, a speaker embedding de-mixing approach is proposed.\nThe proposed approach separates different speaker properties from a two-speaker\nsignal in embedding space. The proposed approach contains two steps. In step\none, the clean speaker embeddings are learned and collected by a residual TDNN\nbased network. In step two, the two-speaker signal and the embedding of one of\nthe speakers are both input to a speaker embedding de-mixing network. The\nde-mixing network is trained to generate the embedding of the other speaker by\nreconstruction loss. Speaker identification accuracy and the cosine similarity\nscore between the clean embeddings and the de-mixed embeddings are used to\nevaluate the quality of the obtained embeddings. Experiments are done in two\nkind of data: artificial augmented two-speaker data (TIMIT) and real world\nrecording of two-speaker data (MC-WSJ). Six different speaker embedding\nde-mixing architectures are investigated. Comparing with the performance on the\nclean speaker embeddings, the obtained results show that one of the proposed\narchitectures obtained close performance, reaching 96.9% identification\naccuracy and 0.89 cosine similarity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:13:43 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:46:54 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shi", "Yanpei", ""], ["Hain", "Thomas", ""]]}, {"id": "2001.06463", "submitter": "Alexandros Papangelis", "authors": "Alexandros Papangelis, Mahdi Namazifar, Chandra Khatri, Yi-Chia Wang,\n  Piero Molino, Gokhan Tur", "title": "Plato Dialogue System: A Flexible Conversational AI Research Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the field of Spoken Dialogue Systems and Conversational AI grows, so does\nthe need for tools and environments that abstract away implementation details\nin order to expedite the development process, lower the barrier of entry to the\nfield, and offer a common test-bed for new ideas. In this paper, we present\nPlato, a flexible Conversational AI platform written in Python that supports\nany kind of conversational agent architecture, from standard architectures to\narchitectures with jointly-trained components, single- or multi-party\ninteractions, and offline or online training of any conversational agent\ncomponent. Plato has been designed to be easy to understand and debug and is\nagnostic to the underlying learning frameworks that train each component.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 18:27:29 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Papangelis", "Alexandros", ""], ["Namazifar", "Mahdi", ""], ["Khatri", "Chandra", ""], ["Wang", "Yi-Chia", ""], ["Molino", "Piero", ""], ["Tur", "Gokhan", ""]]}, {"id": "2001.06626", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Cheng Zhang, Yonghao Song, Xiaofang Zhao,\n  Dawei Yin", "title": "Adaptive Parameterization for Neural Dialogue Generation", "comments": "Published as a long paper in EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1188", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversation systems generate responses based on the\nsequence-to-sequence (SEQ2SEQ) paradigm. Typically, the model is equipped with\na single set of learned parameters to generate responses for given input\ncontexts. When confronting diverse conversations, its adaptability is rather\nlimited and the model is hence prone to generate generic responses. In this\nwork, we propose an {\\bf Ada}ptive {\\bf N}eural {\\bf D}ialogue generation\nmodel, \\textsc{AdaND}, which manages various conversations with\nconversation-specific parameterization. For each conversation, the model\ngenerates parameters of the encoder-decoder by referring to the input context.\nIn particular, we propose two adaptive parameterization mechanisms: a\ncontext-aware and a topic-aware parameterization mechanism. The context-aware\nparameterization directly generates the parameters by capturing local semantics\nof the given context. The topic-aware parameterization enables parameter\nsharing among conversations with similar topics by first inferring the latent\ntopics of the given context and then generating the parameters with respect to\nthe distributional topics. Extensive experiments conducted on a large-scale\nreal-world conversational dataset show that our model achieves superior\nperformance in terms of both quantitative metrics and human evaluations.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 08:18:19 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Zhang", "Cheng", ""], ["Song", "Yonghao", ""], ["Zhao", "Xiaofang", ""], ["Yin", "Dawei", ""]]}, {"id": "2001.06629", "submitter": "Syrielle Montariol", "authors": "Matej Martinc, Syrielle Montariol, Elaine Zosa and Lidia Pivovarova", "title": "Capturing Evolution in Word Usage: Just Add More Clusters?", "comments": null, "journal-ref": "WWW 20 Companion Proceedings of the Web Conference 2020 (April\n  2020) p. 343-349", "doi": "10.1145/3366424.3382186", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The way the words are used evolves through time, mirroring cultural or\ntechnological evolution of society. Semantic change detection is the task of\ndetecting and analysing word evolution in textual data, even in short periods\nof time. In this paper we focus on a new set of methods relying on\ncontextualised embeddings, a type of semantic modelling that revolutionised the\nNLP field recently. We leverage the ability of the transformer-based BERT model\nto generate contextualised embeddings capable of detecting semantic change of\nwords across time. Several approaches are compared in a common setting in order\nto establish strengths and weaknesses for each of them. We also propose several\nideas for improvements, managing to drastically improve the performance of\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 09:04:42 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 01:58:05 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Martinc", "Matej", ""], ["Montariol", "Syrielle", ""], ["Zosa", "Elaine", ""], ["Pivovarova", "Lidia", ""]]}, {"id": "2001.06674", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Arman Cohan, Nazli Goharian, Ross Filice", "title": "Ranking Significant Discrepancies in Clinical Reports", "comments": "ECIR 2020 (short)", "journal-ref": null, "doi": "10.1007/978-3-030-45442-5_30", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical errors are a major public health concern and a leading cause of death\nworldwide. Many healthcare centers and hospitals use reporting systems where\nmedical practitioners write a preliminary medical report and the report is\nlater reviewed, revised, and finalized by a more experienced physician. The\nrevisions range from stylistic to corrections of critical errors or\nmisinterpretations of the case. Due to the large quantity of reports written\ndaily, it is often difficult to manually and thoroughly review all the\nfinalized reports to find such errors and learn from them. To address this\nchallenge, we propose a novel ranking approach, consisting of textual and\nontological overlaps between the preliminary and final versions of reports. The\napproach learns to rank the reports based on the degree of discrepancy between\nthe versions. This allows medical practitioners to easily identify and learn\nfrom the reports in which their interpretation most substantially differed from\nthat of the attending physician (who finalized the report). This is a crucial\nstep towards uncovering potential errors and helping medical practitioners to\nlearn from such errors, thus improving patient-care in the long run. We\nevaluate our model on a dataset of radiology reports and show that our approach\noutperforms both previously-proposed approaches and more recent language models\nby 4.5% to 15.4%.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 14:47:10 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["MacAvaney", "Sean", ""], ["Cohan", "Arman", ""], ["Goharian", "Nazli", ""], ["Filice", "Ross", ""]]}, {"id": "2001.06693", "submitter": "Vijay Arya", "authors": "Karan Dabas, Nishtha Madan, Vijay Arya, Sameep Mehta, Gautam Singh,\n  Tanmoy Chakraborty", "title": "Fair Transfer of Multiple Style Attributes in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To preserve anonymity and obfuscate their identity on online platforms users\nmay morph their text and portray themselves as a different gender or\ndemographic. Similarly, a chatbot may need to customize its communication style\nto improve engagement with its audience. This manner of changing the style of\nwritten text has gained significant attention in recent years. Yet these past\nresearch works largely cater to the transfer of single style attributes. The\ndisadvantage of focusing on a single style alone is that this often results in\ntarget text where other existing style attributes behave unpredictably or are\nunfairly dominated by the new style. To counteract this behavior, it would be\nnice to have a style transfer mechanism that can transfer or control multiple\nstyles simultaneously and fairly. Through such an approach, one could obtain\nobfuscated or written text incorporated with a desired degree of multiple soft\nstyles such as female-quality, politeness, or formalness.\n  In this work, we demonstrate that the transfer of multiple styles cannot be\nachieved by sequentially performing multiple single-style transfers. This is\nbecause each single style-transfer step often reverses or dominates over the\nstyle incorporated by a previous transfer step. We then propose a neural\nnetwork architecture for fairly transferring multiple style attributes in a\ngiven text. We test our architecture on the Yelp data set to demonstrate our\nsuperior performance as compared to existing one-style transfer steps performed\nin a sequence.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:38:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Dabas", "Karan", ""], ["Madan", "Nishtha", ""], ["Arya", "Vijay", ""], ["Mehta", "Sameep", ""], ["Singh", "Gautam", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2001.06785", "submitter": "Marcello Federico", "authors": "Marcello Federico, Robert Enyedi, Roberto Barra-Chicote, Ritwik Giri,\n  Umut Isik, Arvindh Krishnaswamy and Hassan Sawaf", "title": "From Speech-to-Speech Translation to Automatic Dubbing", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present enhancements to a speech-to-speech translation pipeline in order\nto perform automatic dubbing. Our architecture features neural machine\ntranslation generating output of preferred length, prosodic alignment of the\ntranslation with the original speech segments, neural text-to-speech with fine\ntuning of the duration of each utterance, and, finally, audio rendering to\nenriches text-to-speech output with background noise and reverberation\nextracted from the original audio. We report on a subjective evaluation of\nautomatic dubbing of excerpts of TED Talks from English into Italian, which\nmeasures the perceived naturalness of automatic dubbing and the relative\nimportance of each proposed enhancement.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 07:03:05 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 00:12:30 GMT"}, {"version": "v3", "created": "Sun, 2 Feb 2020 21:54:13 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Federico", "Marcello", ""], ["Enyedi", "Robert", ""], ["Barra-Chicote", "Roberto", ""], ["Giri", "Ritwik", ""], ["Isik", "Umut", ""], ["Krishnaswamy", "Arvindh", ""], ["Sawaf", "Hassan", ""]]}, {"id": "2001.06888", "submitter": "Meysam Asgari-Chenaghlu", "authors": "Meysam Asgari-Chenaghlu, M.Reza Feizi-Derakhshi, Leili Farzinvash, M.\n  A. Balafar, Cina Motamed", "title": "A multimodal deep learning approach for named entity recognition from\n  social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) from social media posts is a challenging task.\nUser generated content that forms the nature of social media, is noisy and\ncontains grammatical and linguistic errors. This noisy content makes it much\nharder for tasks such as named entity recognition. We propose two novel deep\nlearning approaches utilizing multimodal deep learning and Transformers. Both\nof our approaches use image features from short social media posts to provide\nbetter results on the NER task. On the first approach, we extract image\nfeatures using InceptionV3 and use fusion to combine textual and image\nfeatures. This presents more reliable name entity recognition when the images\nrelated to the entities are provided by the user. On the second approach, we\nuse image features combined with text and feed it into a BERT like Transformer.\nThe experimental results, namely, the precision, recall and F1 score metrics\nshow the superiority of our work compared to other state-of-the-art NER\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 19:37:45 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:00:12 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 12:29:04 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Asgari-Chenaghlu", "Meysam", ""], ["Feizi-Derakhshi", "M. Reza", ""], ["Farzinvash", "Leili", ""], ["Balafar", "M. A.", ""], ["Motamed", "Cina", ""]]}, {"id": "2001.06927", "submitter": "Ramprasaath R. Selvaraju", "authors": "Ramprasaath R. Selvaraju, Purva Tendulkar, Devi Parikh, Eric Horvitz,\n  Marco Ribeiro, Besmira Nushi, Ece Kamar", "title": "SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions", "comments": "Accepted to CVPR'20 as an Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing VQA datasets contain questions with varying levels of complexity.\nWhile the majority of questions in these datasets require perception for\nrecognizing existence, properties, and spatial relationships of entities, a\nsignificant portion of questions pose challenges that correspond to reasoning\ntasks - tasks that can only be answered through a synthesis of perception and\nknowledge about the world, logic and / or reasoning. Analyzing performance\nacross this distinction allows us to notice when existing VQA models have\nconsistency issues; they answer the reasoning questions correctly but fail on\nassociated low-level perception questions. For example, in Figure 1, models\nanswer the complex reasoning question \"Is the banana ripe enough to eat?\"\ncorrectly, but fail on the associated perception question \"Are the bananas\nmostly green or yellow?\" indicating that the model likely answered the\nreasoning question correctly but for the wrong reason. We quantify the extent\nto which this phenomenon occurs by creating a new Reasoning split of the VQA\ndataset and collecting VQA-introspect, a new dataset1 which consists of 238K\nnew perception questions which serve as sub questions corresponding to the set\nof perceptual tasks needed to effectively answer the complex reasoning\nquestions in the Reasoning split. Our evaluation shows that state-of-the-art\nVQA models have comparable performance in answering perception and reasoning\nquestions, but suffer from consistency problems. To address this shortcoming,\nwe propose an approach called Sub-Question Importance-aware Network Tuning\n(SQuINT), which encourages the model to attend to the same parts of the image\nwhen answering the reasoning question and the perception sub question. We show\nthat SQuINT improves model consistency by ~5%, also marginally improving\nperformance on the Reasoning questions in VQA, while also displaying better\nattention maps.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:02:36 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:54:16 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Selvaraju", "Ramprasaath R.", ""], ["Tendulkar", "Purva", ""], ["Parikh", "Devi", ""], ["Horvitz", "Eric", ""], ["Ribeiro", "Marco", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""]]}, {"id": "2001.06944", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Changyou Chen, Zhe Gan, Zheng Wen, Wenlin Wang, Lawrence\n  Carin", "title": "Nested-Wasserstein Self-Imitation Learning for Sequence Generation", "comments": "Accepted by AISTATS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been widely studied for improving\nsequence-generation models. However, the conventional rewards used for RL\ntraining typically cannot capture sufficient semantic information and therefore\nrender model bias. Further, the sparse and delayed rewards make RL exploration\ninefficient. To alleviate these issues, we propose the concept of\nnested-Wasserstein distance for distributional semantic matching. To further\nexploit it, a novel nested-Wasserstein self-imitation learning framework is\ndeveloped, encouraging the model to exploit historical high-rewarded sequences\nfor enhanced exploration and better semantic matching. Our solution can be\nunderstood as approximately executing proximal policy optimization with\nWasserstein trust-regions. Experiments on a variety of unconditional and\nconditional sequence-generation tasks demonstrate the proposed approach\nconsistently leads to improved performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 02:19:13 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Chen", "Changyou", ""], ["Gan", "Zhe", ""], ["Wen", "Zheng", ""], ["Wang", "Wenlin", ""], ["Carin", "Lawrence", ""]]}, {"id": "2001.07098", "submitter": "Carlos-Emiliano Gonz\\'alez-Gallardo", "authors": "Carlos-Emiliano Gonz\\'alez-Gallardo, Romain Deveaud, Eric SanJuan, and\n  Juan-Manuel Torres-Moreno", "title": "Audio Summarization with Audio Features and Probability Distribution\n  Divergence", "comments": "20th International Conference on Computational Linguistics and\n  Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The automatic summarization of multimedia sources is an important task that\nfacilitates the understanding of an individual by condensing the source while\nmaintaining relevant information. In this paper we focus on audio summarization\nbased on audio features and the probability of distribution divergence. Our\nmethod, based on an extractive summarization approach, aims to select the most\nrelevant segments until a time threshold is reached. It takes into account the\nsegment's length, position and informativeness value. Informativeness of each\nsegment is obtained by mapping a set of audio features issued from its\nMel-frequency Cepstral Coefficients and their corresponding Jensen-Shannon\ndivergence score. Results over a multi-evaluator scheme shows that our approach\nprovides understandable and informative summaries.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 13:10:01 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 09:28:02 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Gonz\u00e1lez-Gallardo", "Carlos-Emiliano", ""], ["Deveaud", "Romain", ""], ["SanJuan", "Eric", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "2001.07194", "submitter": "Yichao Zhou", "authors": "Yichao Zhou, Shaunak Mishra, Manisha Verma, Narayan Bhamidipati, and\n  Wei Wang", "title": "Recommending Themes for Ad Creative Design via Visual-Linguistic\n  Representations", "comments": "7 pages, 8 figures, 2 tables, accepted by The Web Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380001", "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a perennial need in the online advertising industry to refresh ad\ncreatives, i.e., images and text used for enticing online users towards a\nbrand. Such refreshes are required to reduce the likelihood of ad fatigue among\nonline users, and to incorporate insights from other successful campaigns in\nrelated product categories. Given a brand, to come up with themes for a new ad\nis a painstaking and time consuming process for creative strategists.\nStrategists typically draw inspiration from the images and text used for past\nad campaigns, as well as world knowledge on the brands. To automatically infer\nad themes via such multimodal sources of information in past ad campaigns, we\npropose a theme (keyphrase) recommender system for ad creative strategists. The\ntheme recommender is based on aggregating results from a visual question\nanswering (VQA) task, which ingests the following: (i) ad images, (ii) text\nassociated with the ads as well as Wikipedia pages on the brands in the ads,\nand (iii) questions around the ad. We leverage transformer based cross-modality\nencoders to train visual-linguistic representations for our VQA task. We study\ntwo formulations for the VQA task along the lines of classification and\nranking; via experiments on a public dataset, we show that cross-modal\nrepresentations lead to significantly better classification accuracy and\nranking precision-recall metrics. Cross-modal representations show better\nperformance compared to separate image and text representations. In addition,\nthe use of multimodal information shows a significant lift over using only\ntextual or visual information.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 18:04:10 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 23:05:46 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhou", "Yichao", ""], ["Mishra", "Shaunak", ""], ["Verma", "Manisha", ""], ["Bhamidipati", "Narayan", ""], ["Wang", "Wei", ""]]}, {"id": "2001.07209", "submitter": "Jing Yi Xie", "authors": "Jing Yi Xie, Renato Ferreira Pinto Jr., Graeme Hirst, Yang Xu", "title": "Text-based inference of moral sentiment change", "comments": "In Proceedings of EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a text-based framework for investigating moral sentiment change of\nthe public via longitudinal corpora. Our framework is based on the premise that\nlanguage use can inform people's moral perception toward right or wrong, and we\nbuild our methodology by exploring moral biases learned from diachronic word\nembeddings. We demonstrate how a parameter-free model supports inference of\nhistorical shifts in moral sentiment toward concepts such as slavery and\ndemocracy over centuries at three incremental levels: moral relevance, moral\npolarity, and fine-grained moral dimensions. We apply this methodology to\nvisualizing moral time courses of individual concepts and analyzing the\nrelations between psycholinguistic variables and rates of moral sentiment\nchange at scale. Our work offers opportunities for applying natural language\nprocessing toward characterizing moral sentiment change in society.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 18:52:45 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xie", "Jing Yi", ""], ["Pinto", "Renato Ferreira", "Jr."], ["Hirst", "Graeme", ""], ["Xu", "Yang", ""]]}, {"id": "2001.07234", "submitter": "Shuohang Wang", "authors": "Shuohang Wang, Yunshi Lan, Yi Tay, Jing Jiang, Jingjing Liu", "title": "Multi-level Head-wise Match and Aggregation in Transformer for Textual\n  Sequence Matching", "comments": "AAAI 2020, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has been successfully applied to many natural language processing\ntasks. However, for textual sequence matching, simple matching between the\nrepresentation of a pair of sequences might bring in unnecessary noise. In this\npaper, we propose a new approach to sequence pair matching with Transformer, by\nlearning head-wise matching representations on multiple levels. Experiments\nshow that our proposed approach can achieve new state-of-the-art performance on\nmultiple tasks that rely only on pre-computed sequence-vector-representation,\nsuch as SNLI, MNLI-match, MNLI-mismatch, QQP, and SQuAD-binary.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 20:02:02 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Shuohang", ""], ["Lan", "Yunshi", ""], ["Tay", "Yi", ""], ["Jiang", "Jing", ""], ["Liu", "Jingjing", ""]]}, {"id": "2001.07263", "submitter": "Zolt\\'an T\\\"uske", "authors": "Zolt\\'an T\\\"uske, George Saon, Kartik Audhkhasi, Brian Kingsbury", "title": "Single headed attention based sequence-to-sequence model for\n  state-of-the-art results on Switchboard", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally believed that direct sequence-to-sequence (seq2seq) speech\nrecognition models are competitive with hybrid models only when a large amount\nof data, at least a thousand hours, is available for training. In this paper,\nwe show that state-of-the-art recognition performance can be achieved on the\nSwitchboard-300 database using a single headed attention, LSTM based model.\nUsing a cross-utterance language model, our single-pass speaker independent\nsystem reaches 6.4% and 12.5% word error rate (WER) on the Switchboard and\nCallHome subsets of Hub5'00, without a pronunciation lexicon. While careful\nregularization and data augmentation are crucial in achieving this level of\nperformance, experiments on Switchboard-2000 show that nothing is more useful\nthan more data. Overall, the combination of various regularizations and a\nsimple but fairly large model results in a new state of the art, 4.7% and 7.8%\nWER on the Switchboard and CallHome sets, using SWB-2000 without any external\ndata resources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 22:03:42 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 01:57:28 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 03:33:19 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["T\u00fcske", "Zolt\u00e1n", ""], ["Saon", "George", ""], ["Audhkhasi", "Kartik", ""], ["Kingsbury", "Brian", ""]]}, {"id": "2001.07320", "submitter": "Dongyun Liang", "authors": "Dongyun Liang, Guohua Wang, Jing Nie, Binxu Zhai and Xiusen Gu", "title": "A Hierarchical Location Normalization System for Text", "comments": "7 pages, submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It's natural these days for people to know the local events from massive\ndocuments. Many texts contain location information, such as city name or road\nname, which is always incomplete or latent. It's significant to extract the\nadministrative area of the text and organize the hierarchy of area, called\nlocation normalization. Existing detecting location systems either exclude\nhierarchical normalization or present only a few specific regions. We propose a\nsystem named ROIBase that normalizes the text by the Chinese hierarchical\nadministrative divisions. ROIBase adopts a co-occurrence constraint as the\nbasic framework to score the hit of the administrative area, achieves the\ninference by special embeddings, and expands the recall by the ROI (region of\ninterest). It has high efficiency and interpretability because it mainly\nestablishes on the definite knowledge and has less complex logic than the\nsupervised models. We demonstrate that ROIBase achieves better performance\nagainst feasible solutions and is useful as a strong support system for\nlocation normalization.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:10:02 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Liang", "Dongyun", ""], ["Wang", "Guohua", ""], ["Nie", "Jing", ""], ["Zhai", "Binxu", ""], ["Gu", "Xiusen", ""]]}, {"id": "2001.07331", "submitter": "Itsumi Saito", "authors": "Itsumi Saito, Kyosuke Nishida, Kosuke Nishida, Atsushi Otsuka, Hisako\n  Asano, Junji Tomita, Hiroyuki Shindo, Yuji Matsumoto", "title": "Length-controllable Abstractive Summarization by Guiding with Summary\n  Prototype", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new length-controllable abstractive summarization model. Recent\nstate-of-the-art abstractive summarization models based on encoder-decoder\nmodels generate only one summary per source text. However, controllable\nsummarization, especially of the length, is an important aspect for practical\napplications. Previous studies on length-controllable abstractive summarization\nincorporate length embeddings in the decoder module for controlling the summary\nlength. Although the length embeddings can control where to stop decoding, they\ndo not decide which information should be included in the summary within the\nlength constraint. Unlike the previous models, our length-controllable\nabstractive summarization model incorporates a word-level extractive module in\nthe encoder-decoder model instead of length embeddings. Our model generates a\nsummary in two steps. First, our word-level extractor extracts a sequence of\nimportant words (we call it the \"prototype text\") from the source text\naccording to the word-level importance scores and the length constraint.\nSecond, the prototype text is used as additional input to the encoder-decoder\nmodel, which generates a summary by jointly encoding and copying words from\nboth the prototype text and source text. Since the prototype text is a guide to\nboth the content and length of the summary, our model can generate an\ninformative and length-controlled summary. Experiments with the CNN/Daily Mail\ndataset and the NEWSROOM dataset show that our model outperformed previous\nmodels in length-controlled settings.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 04:01:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Saito", "Itsumi", ""], ["Nishida", "Kyosuke", ""], ["Nishida", "Kosuke", ""], ["Otsuka", "Atsushi", ""], ["Asano", "Hisako", ""], ["Tomita", "Junji", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "2001.07418", "submitter": "Caglar Demir", "authors": "Caglar Demir and Axel-Cyrille Ngonga Ngomo", "title": "A Physical Embedding Model for Knowledge Graphs", "comments": "9th Joint International Conference, JIST 2019, Hangzhou, China", "journal-ref": null, "doi": "10.1007/978-981-15-3412-6", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding methods learn continuous vector representations for\nentities in knowledge graphs and have been used successfully in a large number\nof applications. We present a novel and scalable paradigm for the computation\nof knowledge graph embeddings, which we dub PYKE . Our approach combines a\nphysical model based on Hooke's law and its inverse with ideas from simulated\nannealing to compute embeddings for knowledge graphs efficiently. We prove that\nPYKE achieves a linear space complexity. While the time complexity for the\ninitialization of our approach is quadratic, the time complexity of each of its\niterations is linear in the size of the input knowledge graph. Hence, PYKE's\noverall runtime is close to linear. Consequently, our approach easily scales up\nto knowledge graphs containing millions of triples. We evaluate our approach\nagainst six state-of-the-art embedding approaches on the DrugBank and DBpedia\ndatasets in two series of experiments. The first series shows that the cluster\npurity achieved by PYKE is up to 26% (absolute) better than that of the state\nof art. In addition, PYKE is more than 22 times faster than existing embedding\nsolutions in the best case. The results of our second series of experiments\nshow that PYKE is up to 23% (absolute) better than the state of art on the task\nof type prediction while maintaining its superior scalability. Our\nimplementation and results are open-source and are available at\nhttp://github.com/dice-group/PYKE.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 10:02:18 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Demir", "Caglar", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2001.07526", "submitter": "Vevake Balaraman", "authors": "Vevake Balaraman and Bernardo Magnini", "title": "Domain-Aware Dialogue State Tracker for Multi-Domain Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In task-oriented dialogue systems the dialogue state tracker (DST) component\nis responsible for predicting the state of the dialogue based on the dialogue\nhistory. Current DST approaches rely on a predefined domain ontology, a fact\nthat limits their effective usage for large scale conversational agents, where\nthe DST constantly needs to be interfaced with ever-increasing services and\nAPIs. Focused towards overcoming this drawback, we propose a domain-aware\ndialogue state tracker, that is completely data-driven and it is modeled to\npredict for dynamic service schemas. The proposed model utilizes domain and\nslot information to extract both domain and slot specific representations for a\ngiven dialogue, and then uses such representations to predict the values of the\ncorresponding slot. Integrating this mechanism with a pretrained language model\n(i.e. BERT), our approach can effectively learn semantic relations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:41:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Balaraman", "Vevake", ""], ["Magnini", "Bernardo", ""]]}, {"id": "2001.07569", "submitter": "Luca Benedetto", "authors": "Luca Benedetto, Andrea Cappelli, Roberto Turrin, Paolo Cremonesi", "title": "R2DE: a NLP approach to estimating IRT parameters of newly generated\n  questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of exams consists in performing an assessment of students'\nexpertise on a specific subject. Such expertise, also referred to as skill or\nknowledge level, can then be leveraged in different ways (e.g., to assign a\ngrade to the students, to understand whether a student might need some support,\netc.). Similarly, the questions appearing in the exams have to be assessed in\nsome way before being used to evaluate students. Standard approaches to\nquestions' assessment are either subjective (e.g., assessment by human experts)\nor introduce a long delay in the process of question generation (e.g.,\npretesting with real students). In this work we introduce R2DE (which is a\nRegressor for Difficulty and Discrimination Estimation), a model capable of\nassessing newly generated multiple-choice questions by looking at the text of\nthe question and the text of the possible choices. In particular, it can\nestimate the difficulty and the discrimination of each question, as they are\ndefined in Item Response Theory. We also present the results of extensive\nexperiments we carried out on a real world large scale dataset coming from an\ne-learning platform, showing that our model can be used to perform an initial\nassessment of newly created questions and ease some of the problems that arise\nin question generation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:31:01 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Benedetto", "Luca", ""], ["Cappelli", "Andrea", ""], ["Turrin", "Roberto", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2001.07574", "submitter": "Jessica Rodrigues Da Silva", "authors": "Jessica Rodrigues da Silva, Helena de Medeiros Caseli", "title": "Generating Sense Embeddings for Syntactic and Semantic Analogy for\n  Portuguese", "comments": "14 pages, STIL 2019 Full paper", "journal-ref": "STIL XII (2019) 104-113", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are numerical vectors which can represent words or concepts\nin a low-dimensional continuous space. These vectors are able to capture useful\nsyntactic and semantic information. The traditional approaches like Word2Vec,\nGloVe and FastText have a strict drawback: they produce a single vector\nrepresentation per word ignoring the fact that ambiguous words can assume\ndifferent meanings. In this paper we use techniques to generate sense\nembeddings and present the first experiments carried out for Portuguese. Our\nexperiments show that sense vectors outperform traditional word vectors in\nsyntactic and semantic analogy tasks, proving that the language resource\ngenerated here can improve the performance of NLP tasks in Portuguese.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:39:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["da Silva", "Jessica Rodrigues", ""], ["Caseli", "Helena de Medeiros", ""]]}, {"id": "2001.07615", "submitter": "Stefan Ultes", "authors": "Stefan Ultes", "title": "Improving Interaction Quality Estimation with BiLSTMs and the Impact on\n  Dialogue Policy Learning", "comments": "Published at SIGDIAL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning suitable and well-performing dialogue behaviour in statistical\nspoken dialogue systems has been in the focus of research for many years. While\nmost work which is based on reinforcement learning employs an objective measure\nlike task success for modelling the reward signal, we use a reward based on\nuser satisfaction estimation. We propose a novel estimator and show that it\noutperforms all previous estimators while learning temporal dependencies\nimplicitly. Furthermore, we apply this novel user satisfaction estimation model\nlive in simulated experiments where the satisfaction estimation model is\ntrained on one domain and applied in many other domains which cover a similar\ntask. We show that applying this model results in higher estimated\nsatisfaction, similar task success rates and a higher robustness to noise.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:39:12 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ultes", "Stefan", ""]]}, {"id": "2001.07676", "submitter": "Timo Schick", "authors": "Timo Schick and Hinrich Sch\\\"utze", "title": "Exploiting Cloze Questions for Few Shot Text Classification and Natural\n  Language Inference", "comments": "Accepted at EACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some NLP tasks can be solved in a fully unsupervised fashion by providing a\npretrained language model with \"task descriptions\" in natural language (e.g.,\nRadford et al., 2019). While this approach underperforms its supervised\ncounterpart, we show in this work that the two ideas can be combined: We\nintroduce Pattern-Exploiting Training (PET), a semi-supervised training\nprocedure that reformulates input examples as cloze-style phrases to help\nlanguage models understand a given task. These phrases are then used to assign\nsoft labels to a large set of unlabeled examples. Finally, standard supervised\ntraining is performed on the resulting training set. For several tasks and\nlanguages, PET outperforms supervised training and strong semi-supervised\napproaches in low-resource settings by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 17:57:33 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 15:58:33 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 10:56:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2001.07740", "submitter": "Maria Ryskina", "authors": "Maria Ryskina, Ella Rabinovich, Taylor Berg-Kirkpatrick, David R.\n  Mortensen, Yulia Tsvetkov", "title": "Where New Words Are Born: Distributional Semantic Analysis of Neologisms\n  and Their Semantic Neighborhoods", "comments": "SCiL 2020", "journal-ref": "Proceedings of the Society for Computation in Linguistics 3.1\n  (2020): 43-52", "doi": "10.7275/1jra-8m83", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform statistical analysis of the phenomenon of neology, the process by\nwhich new words emerge in a language, using large diachronic corpora of\nEnglish. We investigate the importance of two factors, semantic sparsity and\nfrequency growth rates of semantic neighbors, formalized in the distributional\nsemantics paradigm. We show that both factors are predictive of word emergence\nalthough we find more support for the latter hypothesis. Besides presenting a\nnew linguistic application of distributional semantics, this study tackles the\nlinguistic question of the role of language-internal factors (in our case,\nsparsity) in language change motivated by language-external factors (reflected\nin frequency growth).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:09:49 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Ryskina", "Maria", ""], ["Rabinovich", "Ella", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Mortensen", "David R.", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2001.07752", "submitter": "Luyao Yuan", "authors": "Luyao Yuan, Zipeng Fu, Jingyue Shen, Lu Xu, Junhong Shen, Song-Chun\n  Zhu", "title": "Emergence of Pragmatics from Referential Game between Theory of Mind\n  Agents", "comments": null, "journal-ref": "Emergent Communication Workshop, 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pragmatics studies how context can contribute to language meanings [1]. In\nhuman communication, language is never interpreted out of context, and\nsentences can usually convey more information than their literal meanings [2].\nHowever, this mechanism is missing in most multi-agent systems [3, 4, 5, 6],\nrestricting the communication efficiency and the capability of human-agent\ninteraction. In this paper, we propose an algorithm, using which agents can\nspontaneously learn the ability to \"read between lines\" without any explicit\nhand-designed rules. We integrate the theory of mind (ToM) [7, 8] in a\ncooperative multi-agent pedagogical situation and propose an adaptive\nreinforcement learning (RL) algorithm to develop a communication protocol. ToM\nis a profound cognitive science concept, claiming that people regularly reason\nabout other's mental states, including beliefs, goals, and intentions, to\nobtain performance advantage in competition, cooperation or coalition. With\nthis ability, agents consider language as not only messages but also rational\nacts reflecting others' hidden states. Our experiments demonstrate the\nadvantage of pragmatic protocols over non-pragmatic protocols. We also show the\nteaching complexity following the pragmatic protocol empirically approximates\nto recursive teaching dimension (RTD).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:37:33 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yuan", "Luyao", ""], ["Fu", "Zipeng", ""], ["Shen", "Jingyue", ""], ["Xu", "Lu", ""], ["Shen", "Junhong", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2001.07786", "submitter": "Fabian Lang", "authors": "Adnan Ahmad, Kiflom Desta, Fabian Lang and Dominik Schlechtweg", "title": "Shared task: Lexical semantic change detection in German (Student\n  Project Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent NLP architectures have illustrated in various ways how semantic change\ncan be captured across time and domains. However, in terms of evaluation there\nis a lack of benchmarks to compare the performance of these systems against\neach other. We present the results of the first shared task on unsupervised\nlexical semantic change detection (LSCD) in German based on the evaluation\nframework proposed by Schlechtweg et al. (2019).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 21:47:27 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 20:19:13 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Ahmad", "Adnan", ""], ["Desta", "Kiflom", ""], ["Lang", "Fabian", ""], ["Schlechtweg", "Dominik", ""]]}, {"id": "2001.07820", "submitter": "Ying Xu", "authors": "Ying Xu, Xu Zhong, Antonio Jose Jimeno Yepes, Jey Han Lau", "title": "Elephant in the Room: An Evaluation Framework for Assessing Adversarial\n  Examples in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial example is an input transformed by small perturbations that\nmachine learning models consistently misclassify. While there are a number of\nmethods proposed to generate adversarial examples for text data, it is not\ntrivial to assess the quality of these adversarial examples, as minor\nperturbations (such as changing a word in a sentence) can lead to a significant\nshift in their meaning, readability and classification label. In this paper, we\npropose an evaluation framework consisting of a set of automatic evaluation\nmetrics and human evaluation guidelines, to rigorously assess the quality of\nadversarial examples based on the aforementioned properties. We experiment with\nsix benchmark attacking methods and found that some methods generate\nadversarial examples with poor readability and content preservation. We also\nlearned that multiple factors could influence the attacking performance, such\nas the length of the text inputs and architecture of the classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:05:45 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 06:09:37 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 04:16:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Xu", "Ying", ""], ["Zhong", "Xu", ""], ["Yepes", "Antonio Jose Jimeno", ""], ["Lau", "Jey Han", ""]]}, {"id": "2001.07849", "submitter": "Wen-Chin Huang", "authors": "Wen-Chin Huang, Hao Luo, Hsin-Te Hwang, Chen-Chou Lo, Yu-Huai Peng, Yu\n  Tsao, Hsin-Min Wang", "title": "Unsupervised Representation Disentanglement using Cross Domain Features\n  and Adversarial Learning in Variational Autoencoder based Voice Conversion", "comments": "Accepted to IEEE Transactions on Emerging Topics in Computational\n  Intelligence", "journal-ref": null, "doi": "10.1109/TETCI.2020.2977678", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective approach for voice conversion (VC) is to disentangle linguistic\ncontent from other components in the speech signal. The effectiveness of\nvariational autoencoder (VAE) based VC (VAE-VC), for instance, strongly relies\non this principle. In our prior work, we proposed a cross-domain VAE-VC\n(CDVAE-VC) framework, which utilized acoustic features of different properties,\nto improve the performance of VAE-VC. We believed that the success came from\nmore disentangled latent representations. In this paper, we extend the CDVAE-VC\nframework by incorporating the concept of adversarial learning, in order to\nfurther increase the degree of disentanglement, thereby improving the quality\nand similarity of converted speech. More specifically, we first investigate the\neffectiveness of incorporating the generative adversarial networks (GANs) with\nCDVAE-VC. Then, we consider the concept of domain adversarial training and add\nan explicit constraint to the latent representation, realized by a speaker\nclassifier, to explicitly eliminate the speaker information that resides in the\nlatent code. Experimental results confirm that the degree of disentanglement of\nthe learned latent representation can be enhanced by both GANs and the speaker\nclassifier. Meanwhile, subjective evaluation results in terms of quality and\nsimilarity scores demonstrate the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:06:06 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 04:24:04 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 10:16:28 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Huang", "Wen-Chin", ""], ["Luo", "Hao", ""], ["Hwang", "Hsin-Te", ""], ["Lo", "Chen-Chou", ""], ["Peng", "Yu-Huai", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "2001.07876", "submitter": "Xingbo Wang", "authors": "Xingbo Wang, Haipeng Zeng, Yong Wang, Aoyu Wu, Zhida Sun, Xiaojuan Ma,\n  Huamin Qu", "title": "VoiceCoach: Interactive Evidence-based Training for Voice Modulation\n  Skills in Public Speaking", "comments": "Accepted by CHI '20", "journal-ref": "Proceedings of the 2020 CHI Conference on Human Factors in\n  Computing Systems", "doi": "10.1145/3313831.3376726", "report-no": null, "categories": "cs.HC cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modulation of voice properties, such as pitch, volume, and speed, is\ncrucial for delivering a successful public speech. However, it is challenging\nto master different voice modulation skills. Though many guidelines are\navailable, they are often not practical enough to be applied in different\npublic speaking situations, especially for novice speakers. We present\nVoiceCoach, an interactive evidence-based approach to facilitate the effective\ntraining of voice modulation skills. Specifically, we have analyzed the voice\nmodulation skills from 2623 high-quality speeches (i.e., TED Talks) and use\nthem as the benchmark dataset. Given a voice input, VoiceCoach automatically\nrecommends good voice modulation examples from the dataset based on the\nsimilarity of both sentence structures and voice modulation skills. Immediate\nand quantitative visual feedback is provided to guide further improvement. The\nexpert interviews and the user study provide support for the effectiveness and\nusability of VoiceCoach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 04:52:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Xingbo", ""], ["Zeng", "Haipeng", ""], ["Wang", "Yong", ""], ["Wu", "Aoyu", ""], ["Sun", "Zhida", ""], ["Ma", "Xiaojuan", ""], ["Qu", "Huamin", ""]]}, {"id": "2001.07885", "submitter": "Jinyang Liu", "authors": "Jinyang Liu, Yujia Zhai, Zizhong Chen", "title": "Normalization of Input-output Shared Embeddings in Text Generation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network based models have been state-of-the-art models for various\nNatural Language Processing tasks, however, the input and output dimension\nproblem in the networks has still not been fully resolved, especially in text\ngeneration tasks (e.g. Machine Translation, Text Summarization), in which input\nand output both have huge sizes of vocabularies. Therefore, input-output\nembedding weight sharing has been introduced and adopted widely, which remains\nto be improved. Based on linear algebra and statistical theories, this paper\nlocates the shortcoming of existed input-output embedding weight sharing\nmethod, then raises methods for improving input-output weight shared embedding,\namong which methods of normalization of embedding weight matrices show best\nperformance. These methods are nearly computational cost-free, can get combined\nwith other embedding techniques, and show good effectiveness when applied on\nstate-of-the-art Neural Network models. For Transformer-big models, the\nnormalization techniques can get at best 0.6 BLEU improvement compared to the\noriginal version of model on WMT'16 En-De dataset, and similar BLEU\nimprovements on IWSLT 14' datasets. For DynamicConv models, 0.5 BLEU\nimprovement can be attained on WMT'16 En-De dataset, and 0.41 BLEU improvement\non IWSLT 14' De-En translation task is achieved.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 05:34:45 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 04:42:13 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Liu", "Jinyang", ""], ["Zhai", "Yujia", ""], ["Chen", "Zizhong", ""]]}, {"id": "2001.08010", "submitter": "Mahieddine Djoudi", "authors": "Zitouni Abdelhafid (LIRE), Hichem Rahab (ICOSI, LIRE), Abdelhafid\n  Zitouni (LIRE), Mahieddine Djoudi (TECHN\\'E - EA 6316)", "title": "ARAACOM: ARAbic Algerian Corpus for Opinion Mining", "comments": null, "journal-ref": "ICCES '17: Proceedings of the International Conference on\n  Computing for Engineering and Sciences, Jul 2017, Istanbul, France. pp.35-39", "doi": "10.1145/3129186.3129193", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, it is no more needed to do an enormous effort to distribute a lot\nof forms to thousands of people and collect them, then convert this from into\nelectronic format to track people opinion about some subjects. A lot of web\nsites can today reach a large spectrum with less effort. The majority of web\nsites suggest to their visitors to leave backups about their feeling of the\nsite or events. So, this makes for us a lot of data which need powerful mean to\nexploit. Opinion mining in the web becomes more and more an attracting task,\ndue the increasing need for individuals and societies to track the mood of\npeople against several subjects of daily life (sports, politics,\ntelevision,...). A lot of works in opinion mining was developed in western\nlanguages especially English, such works in Arabic language still very scarce.\nIn this paper, we propose our approach, for opinion mining in Arabic Algerian\nnews paper. CCS CONCEPTS $\\bullet$Information systems~Sentiment analysis\n$\\bullet$ Computing methodologies~Natural language processing\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:45:34 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Abdelhafid", "Zitouni", "", "LIRE"], ["Rahab", "Hichem", "", "ICOSI, LIRE"], ["Zitouni", "Abdelhafid", "", "LIRE"], ["Djoudi", "Mahieddine", "", "TECHN\u00c9 - EA 6316"]]}, {"id": "2001.08013", "submitter": "Balaji Ganesan", "authors": "Balaji Ganesan, Riddhiman Dasgupta, Akshay Parekh, Hima Patel, and\n  Berthold Reinwald", "title": "A Neural Architecture for Person Ontology population", "comments": "6 pages, 10 figures. arXiv admin note: substantial text overlap with\n  arXiv:1811.09368", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A person ontology comprising concepts, attributes and relationships of people\nhas a number of applications in data protection, didentification, population of\nknowledge graphs for business intelligence and fraud prevention. While\nartificial neural networks have led to improvements in Entity Recognition,\nEntity Classification, and Relation Extraction, creating an ontology largely\nremains a manual process, because it requires a fixed set of semantic relations\nbetween concepts. In this work, we present a system for automatically\npopulating a person ontology graph from unstructured data using neural models\nfor Entity Classification and Relation Extraction. We introduce a new dataset\nfor these tasks and discuss our results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:49:14 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Ganesan", "Balaji", ""], ["Dasgupta", "Riddhiman", ""], ["Parekh", "Akshay", ""], ["Patel", "Hima", ""], ["Reinwald", "Berthold", ""]]}, {"id": "2001.08034", "submitter": "Darryl Hannan", "authors": "Darryl Hannan, Akshay Jain, and Mohit Bansal", "title": "ManyModalQA: Modality Disambiguation and QA over Diverse Inputs", "comments": "AAAI 2020 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new multimodal question answering challenge, ManyModalQA, in\nwhich an agent must answer a question by considering three distinct modalities:\ntext, images, and tables. We collect our data by scraping Wikipedia and then\nutilize crowdsourcing to collect question-answer pairs. Our questions are\nambiguous, in that the modality that contains the answer is not easily\ndetermined based solely upon the question. To demonstrate this ambiguity, we\nconstruct a modality selector (or disambiguator) network, and this model gets\nsubstantially lower accuracy on our challenge set, compared to existing\ndatasets, indicating that our questions are more ambiguous. By analyzing this\nmodel, we investigate which words in the question are indicative of the\nmodality. Next, we construct a simple baseline ManyModalQA model, which, based\non the prediction from the modality selector, fires a corresponding pre-trained\nstate-of-the-art unimodal QA model. We focus on providing the community with a\nnew manymodal evaluation set and only provide a fine-tuning set, with the\nexpectation that existing datasets and approaches will be transferred for most\nof the training, to encourage low-resource generalization without large,\nmonolithic training sets for each new task. There is a significant gap between\nour baseline models and human performance; therefore, we hope that this\nchallenge encourages research in end-to-end modality disambiguation and\nmultimodal QA models, as well as transfer learning. Code and data available at:\nhttps://github.com/hannandarryl/ManyModalQA\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:39:28 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Hannan", "Darryl", ""], ["Jain", "Akshay", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.08051", "submitter": "Daniele Falavigna", "authors": "Roberto Gretter, Marco Matassoni, Stefano Bann\\`o, Daniele Falavigna", "title": "TLT-school: a Corpus of Non Native Children Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes \"TLT-school\" a corpus of speech utterances collected in\nschools of northern Italy for assessing the performance of students learning\nboth English and German. The corpus was recorded in the years 2017 and 2018\nfrom students aged between nine and sixteen years, attending primary, middle\nand high school. All utterances have been scored, in terms of some predefined\nproficiency indicators, by human experts. In addition, most of utterances\nrecorded in 2017 have been manually transcribed carefully. Guidelines and\nprocedures used for manual transcriptions of utterances will be described in\ndetail, as well as results achieved by means of an automatic speech recognition\nsystem developed by us. Part of the corpus is going to be freely distributed to\nscientific community particularly interested both in non-native speech\nrecognition and automatic assessment of second language proficiency.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:14:09 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Gretter", "Roberto", ""], ["Matassoni", "Marco", ""], ["Bann\u00f2", "Stefano", ""], ["Falavigna", "Daniele", ""]]}, {"id": "2001.08053", "submitter": "Vincent Guigue", "authors": "Bruno Taill\\'e, Vincent Guigue, Patrick Gallinari", "title": "Contextualized Embeddings in Named-Entity Recognition: An Empirical\n  Study on Generalization", "comments": null, "journal-ref": "ECIR 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized embeddings use unsupervised language model pretraining to\ncompute word representations depending on their context. This is intuitively\nuseful for generalization, especially in Named-Entity Recognition where it is\ncrucial to detect mentions never seen during training. However, standard\nEnglish benchmarks overestimate the importance of lexical over contextual\nfeatures because of an unrealistic lexical overlap between train and test\nmentions. In this paper, we perform an empirical analysis of the generalization\ncapabilities of state-of-the-art contextualized embeddings by separating\nmentions by novelty and with out-of-domain evaluation. We show that they are\nparticularly beneficial for unseen mentions detection, especially\nout-of-domain. For models trained on CoNLL03, language model contextualization\nleads to a +1.2% maximal relative micro-F1 score increase in-domain against\n+13% out-of-domain on the WNUT dataset\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:15:34 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Taill\u00e9", "Bruno", ""], ["Guigue", "Vincent", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2001.08140", "submitter": "Di Jin", "authors": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits", "title": "A Simple Baseline to Semi-Supervised Domain Adaptation for Machine\n  Translation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural machine translation (NMT) systems are data-hungry and\nperform poorly on new domains with no supervised data. As data collection is\nexpensive and infeasible in many cases, domain adaptation methods are needed.\nIn this work, we propose a simple but effect approach to the semi-supervised\ndomain adaptation scenario of NMT, where the aim is to improve the performance\nof a translation model on the target domain consisting of only non-parallel\ndata with the help of supervised source domain data. This approach iteratively\ntrains a Transformer-based NMT model via three training objectives: language\nmodeling, back-translation, and supervised translation. We evaluate this method\non two adaptation settings: adaptation between specific domains and adaptation\nfrom a general domain to specific domains, and on two language pairs: German to\nEnglish and Romanian to English. With substantial performance improvement\nachieved---up to +19.31 BLEU over the strongest baseline, and +47.69 BLEU\nimprovement over the unadapted model---we present this method as a simple but\ntough-to-beat baseline in the field of semi-supervised domain adaptation for\nNMT.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:42:06 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 02:45:10 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Zhou", "Joey Tianyi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2001.08210", "submitter": "Jiatao Gu", "authors": "Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan\n  Ghazvininejad, Mike Lewis, Luke Zettlemoyer", "title": "Multilingual Denoising Pre-training for Neural Machine Translation", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates that multilingual denoising pre-training produces\nsignificant performance gains across a wide variety of machine translation (MT)\ntasks. We present mBART -- a sequence-to-sequence denoising auto-encoder\npre-trained on large-scale monolingual corpora in many languages using the BART\nobjective. mBART is one of the first methods for pre-training a complete\nsequence-to-sequence model by denoising full texts in multiple languages, while\nprevious approaches have focused only on the encoder, decoder, or\nreconstructing parts of the text. Pre-training a complete model allows it to be\ndirectly fine tuned for supervised (both sentence-level and document-level) and\nunsupervised machine translation, with no task-specific modifications. We\ndemonstrate that adding mBART initialization produces performance gains in all\nbut the highest-resource settings, including up to 12 BLEU points for low\nresource MT and over 5 BLEU points for many document-level and unsupervised\nmodels. We also show it also enables new types of transfer to language pairs\nwith no bi-text or that were not in the pre-training corpus, and present\nextensive analysis of which factors contribute the most to effective\npre-training.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:59:17 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 18:58:48 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liu", "Yinhan", ""], ["Gu", "Jiatao", ""], ["Goyal", "Naman", ""], ["Li", "Xian", ""], ["Edunov", "Sergey", ""], ["Ghazvininejad", "Marjan", ""], ["Lewis", "Mike", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2001.08279", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Miguel Ballesteros, Chris Dyer, Robert\n  Frederking", "title": "Transition-Based Dependency Parsing using Perceptron Learner", "comments": "This was part of an assignment at my graduate course at LTI. This\n  does not offer any major novelties", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic parsing using dependency structures has become a standard technique\nin natural language processing with many different parsing models, in\nparticular data-driven models that can be trained on syntactically annotated\ncorpora. In this paper, we tackle transition-based dependency parsing using a\nPerceptron Learner. Our proposed model, which adds more relevant features to\nthe Perceptron Learner, outperforms a baseline arc-standard parser. We beat the\nUAS of the MALT and LSTM parsers. We also give possible ways to address parsing\nof non-projective trees.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:58:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 22:09:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Ballesteros", "Miguel", ""], ["Dyer", "Chris", ""], ["Frederking", "Robert", ""]]}, {"id": "2001.08353", "submitter": "Haiyue Song", "authors": "Haiyue Song, Raj Dabre, Zhuoyuan Mao, Fei Cheng, Sadao Kurohashi,\n  Eiichiro Sumita", "title": "Pre-training via Leveraging Assisting Languages and Data Selection for\n  Neural Machine Translation", "comments": "Work in progress. Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (S2S) pre-training using large monolingual data is known\nto improve performance for various S2S NLP tasks in low-resource settings.\nHowever, large monolingual corpora might not always be available for the\nlanguages of interest (LOI). To this end, we propose to exploit monolingual\ncorpora of other languages to complement the scarcity of monolingual corpora\nfor the LOI. A case study of low-resource Japanese-English neural machine\ntranslation (NMT) reveals that leveraging large Chinese and French monolingual\ncorpora can help overcome the shortage of Japanese and English monolingual\ncorpora, respectively, for S2S pre-training. We further show how to utilize\nscript mapping (Chinese to Japanese) to increase the similarity between the two\nmonolingual corpora leading to further improvements in translation quality.\nAdditionally, we propose simple data-selection techniques to be used prior to\npre-training that significantly impact the quality of S2S pre-training. An\nempirical comparison of our proposed methods reveals that leveraging assisting\nlanguage monolingual corpora, data selection and script mapping are extremely\nimportant for NMT pre-training in low-resource scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 02:47:39 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Song", "Haiyue", ""], ["Dabre", "Raj", ""], ["Mao", "Zhuoyuan", ""], ["Cheng", "Fei", ""], ["Kurohashi", "Sadao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "2001.08378", "submitter": "Marc Delcroix", "authors": "Marc Delcroix, Tsubasa Ochiai, Katerina Zmolikova, Keisuke Kinoshita,\n  Naohiro Tawara, Tomohiro Nakatani, Shoko Araki", "title": "Improving speaker discrimination of target speech extraction with\n  time-domain SpeakerBeam", "comments": "5 pages, 3 figures. Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target speech extraction, which extracts a single target source in a mixture\ngiven clues about the target speaker, has attracted increasing attention. We\nhave recently proposed SpeakerBeam, which exploits an adaptation utterance of\nthe target speaker to extract his/her voice characteristics that are then used\nto guide a neural network towards extracting speech of that speaker.\nSpeakerBeam presents a practical alternative to speech separation as it enables\ntracking speech of a target speaker across utterances, and achieves promising\nspeech extraction performance. However, it sometimes fails when speakers have\nsimilar voice characteristics, such as in same-gender mixtures, because it is\ndifficult to discriminate the target speaker from the interfering speakers. In\nthis paper, we investigate strategies for improving the speaker discrimination\ncapability of SpeakerBeam. First, we propose a time-domain implementation of\nSpeakerBeam similar to that proposed for a time-domain audio separation network\n(TasNet), which has achieved state-of-the-art performance for speech\nseparation. Besides, we investigate (1) the use of spatial features to better\ndiscriminate speakers when microphone array recordings are available, (2)\nadding an auxiliary speaker identification loss for helping to learn more\ndiscriminative voice characteristics. We show experimentally that these\nstrategies greatly improve speech extraction performance, especially for\nsame-gender mixtures, and outperform TasNet in terms of target speech\nextraction.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:36:06 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Delcroix", "Marc", ""], ["Ochiai", "Tsubasa", ""], ["Zmolikova", "Katerina", ""], ["Kinoshita", "Keisuke", ""], ["Tawara", "Naohiro", ""], ["Nakatani", "Tomohiro", ""], ["Araki", "Shoko", ""]]}, {"id": "2001.08546", "submitter": "Preslav Nakov", "authors": "Alberto Barron-Cedeno, Tamer Elsayed, Preslav Nakov, Giovanni Da San\n  Martino, Maram Hasanain, Reem Suwaileh, and Fatima Haouari", "title": "CheckThat! at CLEF 2020: Enabling the Automatic Identification and\n  Verification of Claims in Social Media", "comments": "Computational journalism, Check-worthiness, Fact-checking, Veracity,\n  CLEF-2020 CheckThat! Lab", "journal-ref": "CLEF-2018 ECIR-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the third edition of the CheckThat! Lab, which is part of the\n2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four\ncomplementary tasks and a related task from previous lab editions, offered in\nEnglish, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter\nstream are worth fact-checking. Task 2 asks to determine whether a claim posted\nin a tweet can be verified using a set of previously fact-checked claims. Task\n3 asks to retrieve text snippets from a given set of Web pages that would be\nuseful for verifying a target tweet's claim. Task 4 asks to predict the\nveracity of a target tweet's claim using a set of Web pages and potentially\nuseful snippets in them. Finally, the lab offers a fifth task that asks to\npredict the check-worthiness of the claims made in English political debates\nand speeches. CheckThat! features a full evaluation framework. The evaluation\nis carried out using mean average precision or precision at rank k for ranking\ntasks, and F1 for classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:47:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Barron-Cedeno", "Alberto", ""], ["Elsayed", "Tamer", ""], ["Nakov", "Preslav", ""], ["Martino", "Giovanni Da San", ""], ["Hasanain", "Maram", ""], ["Suwaileh", "Reem", ""], ["Haouari", "Fatima", ""]]}, {"id": "2001.08604", "submitter": "Kang Min Yoo", "authors": "Kang Min Yoo, Hanbit Lee, Franck Dernoncourt, Trung Bui, Walter Chang,\n  Sang-goo Lee", "title": "Variational Hierarchical Dialog Autoencoder for Dialog State Tracking\n  Data Augmentation", "comments": "11 pages (main) + 9 pages (appendix), 1 figure, 6 tables, accepted to\n  EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that generative data augmentation, where synthetic\nsamples generated from deep generative models complement the training dataset,\nbenefit NLP tasks. In this work, we extend this approach to the task of dialog\nstate tracking for goal-oriented dialogs. Due to the inherent hierarchical\nstructure of goal-oriented dialogs over utterances and related annotations, the\ndeep generative model must be capable of capturing the coherence among\ndifferent hierarchies and types of dialog features. We propose the Variational\nHierarchical Dialog Autoencoder (VHDA) for modeling the complete aspects of\ngoal-oriented dialogs, including linguistic features and underlying structured\nannotations, namely speaker information, dialog acts, and goals. The proposed\narchitecture is designed to model each aspect of goal-oriented dialogs using\ninter-connected latent variables and learns to generate coherent goal-oriented\ndialogs from the latent spaces. To overcome training issues that arise from\ntraining complex variational models, we propose appropriate training\nstrategies. Experiments on various dialog datasets show that our model improves\nthe downstream dialog trackers' robustness via generative data augmentation. We\nalso discover additional benefits of our unified approach to modeling\ngoal-oriented dialogs: dialog response generation and user simulation, where\nour model outperforms previous strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:34:56 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 12:15:35 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 01:39:34 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Yoo", "Kang Min", ""], ["Lee", "Hanbit", ""], ["Dernoncourt", "Franck", ""], ["Bui", "Trung", ""], ["Chang", "Walter", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2001.08635", "submitter": "Chao Wang", "authors": "Chao Wang", "title": "A Study of the Tasks and Models in Machine Reading Comprehension", "comments": "PhD Qualifying Examination Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide a survey on the existing tasks and models in Machine Reading\nComprehension (MRC), this report reviews: 1) the dataset collection and\nperformance evaluation of some representative simple-reasoning and\ncomplex-reasoning MRC tasks; 2) the architecture designs, attention mechanisms,\nand performance-boosting approaches for developing neural-network-based MRC\nmodels; 3) some recently proposed transfer learning approaches to incorporating\ntext-style knowledge contained in external corpora into the neural networks of\nMRC models; 4) some recently proposed knowledge base encoding approaches to\nincorporating graph-style knowledge contained in external knowledge bases into\nthe neural networks of MRC models. Besides, according to what has been achieved\nand what are still deficient, this report also proposes some open problems for\nthe future research.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:11:44 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wang", "Chao", ""]]}, {"id": "2001.08665", "submitter": "Qing Wan", "authors": "Qing Wan, Yoonsuck Choe", "title": "Action Recognition and State Change Prediction in a Recipe Understanding\n  Task Using a Lightweight Neural Network Model", "comments": "AAAI-2020 Student Abstract and Poster Program (Accept)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a natural language sentence describing a specific step in a food\nrecipe. In such instructions, recognizing actions (such as press, bake, etc.)\nand the resulting changes in the state of the ingredients (shape molded,\ncustard cooked, temperature hot, etc.) is a challenging task. One way to cope\nwith this challenge is to explicitly model a simulator module that applies\nactions to entities and predicts the resulting outcome (Bosselut et al. 2018).\nHowever, such a model can be unnecessarily complex. In this paper, we propose a\nsimplified neural network model that separates action recognition and state\nchange prediction, while coupling the two through a novel loss function. This\nallows learning to indirectly influence each other. Our model, although\nsimpler, achieves higher state change prediction performance (67% average\naccuracy for ours vs. 55% in (Bosselut et al. 2018)) and takes fewer samples to\ntrain (10K ours vs. 65K+ by (Bosselut et al. 2018)).\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:04:00 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wan", "Qing", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "2001.08700", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem and Calton Pu", "title": "EventMapper: Detecting Real-World Physical Events Using Corroborative\n  and Probabilistic Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of social media makes it a rich source for physical event\ndetection, such as disasters, and as a potential resource for crisis management\nresource allocation. There have been some recent works on leveraging social\nmedia sources for retrospective, after-the-fact event detection of large events\nsuch as earthquakes or hurricanes. Similarly, there is a long history of using\ntraditional physical sensors such as climate satellites to perform regional\nevent detection. However, combining social media with corroborative physical\nsensors for real-time, accurate, and global physical detection has remained\nunexplored.\n  This paper presents EventMapper, a framework to support event recognition of\nsmall yet equally costly events (landslides, flooding, wildfires). EventMapper\nintegrates high-latency, high-accuracy corroborative sources such as physical\nsensors with low-latency, noisy probabilistic sources such as social media\nstreams to deliver real-time, global event recognition. Furthermore,\nEventMapper is resilient to the concept drift phenomenon, where machine\nlearning models require continuous fine-tuning to maintain high performance.\n  By exploiting the common features of probabilistic and corroborative sources,\nEventMapper automates machine learning model updates, maintenance, and\nfine-tuning. We describe three applications built on EventMapper for landslide,\nwildfire, and flooding detection.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:47:31 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Suprem", "Abhijit", ""], ["Pu", "Calton", ""]]}, {"id": "2001.08728", "submitter": "Kun Xu", "authors": "Kun Xu, Linfeng Song, Yansong Feng, Yan Song, Dong Yu", "title": "Coordinated Reasoning for Cross-Lingual Knowledge Graph Alignment", "comments": "in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing entity alignment methods mainly vary on the choices of encoding the\nknowledge graph, but they typically use the same decoding method, which\nindependently chooses the local optimal match for each source entity. This\ndecoding method may not only cause the \"many-to-one\" problem but also neglect\nthe coordinated nature of this task, that is, each alignment decision may\nhighly correlate to the other decisions. In this paper, we introduce two\ncoordinated reasoning methods, i.e., the Easy-to-Hard decoding strategy and\njoint entity alignment algorithm. Specifically, the Easy-to-Hard strategy first\nretrieves the model-confident alignments from the predicted results and then\nincorporates them as additional knowledge to resolve the remaining\nmodel-uncertain alignments. To achieve this, we further propose an enhanced\nalignment model that is built on the current state-of-the-art baseline. In\naddition, to address the many-to-one problem, we propose to jointly predict\nentity alignments so that the one-to-one constraint can be naturally\nincorporated into the alignment prediction. Experimental results show that our\nmodel achieves the state-of-the-art performance and our reasoning methods can\nalso significantly improve existing baselines.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:41:21 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Xu", "Kun", ""], ["Song", "Linfeng", ""], ["Feng", "Yansong", ""], ["Song", "Yan", ""], ["Yu", "Dong", ""]]}, {"id": "2001.08730", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Shivansh Pate, and Vinay P. Namboodiri", "title": "Robust Explanations for Visual Question Answering", "comments": "WACV-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a method to obtain robust explanations for visual\nquestion answering(VQA) that correlate well with the answers. Our model\nexplains the answers obtained through a VQA model by providing visual and\ntextual explanations. The main challenges that we address are i) Answers and\ntextual explanations obtained by current methods are not well correlated and\nii) Current methods for visual explanation do not focus on the right location\nfor explaining the answer. We address both these challenges by using a\ncollaborative correlated module which ensures that even if we do not train for\nnoise based attacks, the enhanced correlation ensures that the right\nexplanation and answer can be generated. We further show that this also aids in\nimproving the generated visual and textual explanations. The use of the\ncorrelated module can be thought of as a robust method to verify if the answer\nand explanations are coherent. We evaluate this model using VQA-X dataset. We\nobserve that the proposed method yields better textual and visual justification\nthat supports the decision. We showcase the robustness of the model against a\nnoise-based perturbation attack using corresponding visual and textual\nexplanations. A detailed empirical analysis is shown. Here we provide source\ncode link for our model \\url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:43:34 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Patro", "Badri N.", ""], ["Pate", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.08764", "submitter": "Xiangyu Peng", "authors": "Xiangyu Peng, Siyan Li, Spencer Frazier, Mark Riedl", "title": "Reducing Non-Normative Text Generation from Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale, transformer-based language models such as GPT-2 are pretrained\non diverse corpora scraped from the internet. Consequently, they are prone to\ngenerating non-normative text (i.e. in violation of social norms). We introduce\na technique for fine-tuning GPT-2, using a policy gradient reinforcement\nlearning technique and a normative text classifier to produce reward and\npunishment values. We evaluate our technique on five data sets using automated\nand human participant experiments. The normative text classifier is 81-90%\naccurate when compared to gold-standard human judgments of normative and\nnon-normative generated text. Our normative fine-tuning technique is able to\nreduce non-normative text by 27-61%, depending on the data set.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:06:18 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 19:37:27 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Peng", "Xiangyu", ""], ["Li", "Siyan", ""], ["Frazier", "Spencer", ""], ["Riedl", "Mark", ""]]}, {"id": "2001.08779", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Vinod K. Kurmi, Sandeep Kumar, and Vinay P. Namboodiri", "title": "Deep Bayesian Network for Visual Question Generation", "comments": "WACV-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating natural questions from an image is a semantic task that requires\nusing vision and language modalities to learn multimodal representations.\nImages can have multiple visual and language cues such as places, captions, and\ntags. In this paper, we propose a principled deep Bayesian learning framework\nthat combines these cues to produce natural questions. We observe that with the\naddition of more cues and by minimizing uncertainty in the among cues, the\nBayesian network becomes more confident. We propose a Minimizing Uncertainty of\nMixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues\nexperts for generating probabilistic questions. This is a Bayesian framework\nand the results show a remarkable similarity to natural questions as validated\nby a human study. We observe that with the addition of more cues and by\nminimizing uncertainty among the cues, the Bayesian framework becomes more\nconfident. Ablation studies of our model indicate that a subset of cues is\ninferior at this task and hence the principled fusion of cues is preferred.\nFurther, we observe that the proposed approach substantially improves over\nstate-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE,\nand CIDEr). Here we provide project link for Deep Bayesian VQG\n\\url{https://delta-lab-iitk.github.io/BVQG/}\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:37:20 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Patro", "Badri N.", ""], ["Kurmi", "Vinod K.", ""], ["Kumar", "Sandeep", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.08785", "submitter": "Marjan Ghazvininejad", "authors": "Marjan Ghazvininejad, Omer Levy, Luke Zettlemoyer", "title": "Semi-Autoregressive Training Improves Mask-Predict Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed mask-predict decoding algorithm has narrowed the\nperformance gap between semi-autoregressive machine translation models and the\ntraditional left-to-right approach. We introduce a new training method for\nconditional masked language models, SMART, which mimics the semi-autoregressive\nbehavior of mask-predict, producing training examples that contain model\npredictions as part of their inputs. Models trained with SMART produce\nhigher-quality translations when using mask-predict decoding, effectively\nclosing the remaining performance gap with fully autoregressive models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:56:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ghazvininejad", "Marjan", ""], ["Levy", "Omer", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2001.08837", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Matthew Hausknecht", "title": "Graph Constrained Reinforcement Learning for Natural Language Action\n  Spaces", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Fiction games are text-based simulations in which an agent\ninteracts with the world purely through natural language. They are ideal\nenvironments for studying how to extend reinforcement learning agents to meet\nthe challenges of natural language understanding, partial observability, and\naction generation in combinatorially-large text-based action spaces. We present\nKG-A2C, an agent that builds a dynamic knowledge graph while exploring and\ngenerates actions using a template-based action space. We contend that the dual\nuses of the knowledge graph to reason about game state and to constrain natural\nlanguage generation are the keys to scalable exploration of combinatorially\nlarge natural language actions. Results across a wide variety of IF games show\nthat KG-A2C outperforms current IF agents despite the exponential increase in\naction space size.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:33:18 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "2001.08845", "submitter": "Anna Feldman", "authors": "Kei Yin Ng, Anna Feldman, Jing Peng", "title": "Linguistic Fingerprints of Internet Censorship: the Case of SinaWeibo", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how the linguistic components of blogposts collected from\nSina Weibo, a Chinese microblogging platform, might affect the blogposts'\nlikelihood of being censored. Our results go along with King et al. (2013)'s\nCollective Action Potential (CAP) theory, which states that a blogpost's\npotential of causing riot or assembly in real life is the key determinant of it\ngetting censored. Although there is not a definitive measure of this construct,\nthe linguistic features that we identify as discriminatory go along with the\nCAP theory. We build a classifier that significantly outperforms non-expert\nhumans in predicting whether a blogpost will be censored. The crowdsourcing\nresults suggest that while humans tend to see censored blogposts as more\ncontroversial and more likely to trigger action in real life than the\nuncensored counterparts, they in general cannot make a better guess than our\nmodel when it comes to `reading the mind' of the censors in deciding whether a\nblogpost should be censored. We do not claim that censorship is only determined\nby the linguistic features. There are many other factors contributing to\ncensorship decisions. The focus of the present paper is on the linguistic form\nof blogposts. Our work suggests that it is possible to use linguistic\nproperties of social media posts to automatically predict if they are going to\nbe censored.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 23:08:24 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ng", "Kei Yin", ""], ["Feldman", "Anna", ""], ["Peng", "Jing", ""]]}, {"id": "2001.08868", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Mahdi Namazifar, Joost Huizinga, Piero Molino, Adrien\n  Ecoffet, Huaixiu Zheng, Alexandros Papangelis, Dian Yu, Chandra Khatri,\n  Gokhan Tur", "title": "Exploration Based Language Learning for Text-Based Games", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an exploration and imitation-learning-based agent capable\nof state-of-the-art performance in playing text-based computer games.\nText-based computer games describe their world to the player through natural\nlanguage and expect the player to interact with the game using text. These\ngames are of interest as they can be seen as a testbed for language\nunderstanding, problem-solving, and language generation by artificial agents.\nMoreover, they provide a learning environment in which these skills can be\nacquired through interactions with an environment rather than using fixed\ncorpora. One aspect that makes these games particularly challenging for\nlearning agents is the combinatorially large action space. Existing methods for\nsolving text-based games are limited to games that are either very simple or\nhave an action space restricted to a predetermined set of admissible actions.\nIn this work, we propose to use the exploration approach of Go-Explore for\nsolving text-based games. More specifically, in an initial exploration phase,\nwe first extract trajectories with high rewards, after which we train a policy\nto solve the game by imitating these trajectories. Our experiments show that\nthis approach outperforms existing solutions in solving text-based games, and\nit is more sample efficient in terms of the number of interactions with the\nenvironment. Moreover, we show that the learned policy can generalize better\nthan existing solutions to unseen games without using any restriction on the\naction space.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 03:03:51 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 02:27:49 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Madotto", "Andrea", ""], ["Namazifar", "Mahdi", ""], ["Huizinga", "Joost", ""], ["Molino", "Piero", ""], ["Ecoffet", "Adrien", ""], ["Zheng", "Huaixiu", ""], ["Papangelis", "Alexandros", ""], ["Yu", "Dian", ""], ["Khatri", "Chandra", ""], ["Tur", "Gokhan", ""]]}, {"id": "2001.08896", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Paul N. Whatmough, Zhi-Gang Liu, Matthew Mattina,\n  Jesse Beu", "title": "Compressing Language Models using Doped Kronecker Products", "comments": "Link to Workshop\n  (https://research.fb.com/programs/on-device-intelligence-workshop/)", "journal-ref": "Presented at On-device Intelligence Workshop at Third Conference\n  on Machine Learning and Systems (MLSys) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Kronecker Products (KP) have been used to compress IoT RNN Applications by\n15-38x compression factors, achieving better results than traditional\ncompression methods. However when KP is applied to large Natural Language\nProcessing tasks, it leads to significant accuracy loss (approx 26%). This\npaper proposes a way to recover accuracy otherwise lost when applying KP to\nlarge NLP tasks, by allowing additional degrees of freedom in the KP matrix.\nMore formally, we propose doping, a process of adding an extremely sparse\noverlay matrix on top of the pre-defined KP structure. We call this compression\nmethod doped kronecker product compression. To train these models, we present a\nnew solution to the phenomenon of co-matrix adaption (CMA), which uses a new\nregularization scheme called co matrix dropout regularization (CMR). We present\nexperimental results that demonstrate compression of a large language model\nwith LSTM layers of size 25 MB by 25x with 1.4% loss in perplexity score. At\n25x compression, an equivalent pruned network leads to 7.9% loss in perplexity\nscore, while HMD and LMF lead to 15% and 27% loss in perplexity score\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 06:07:21 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 05:36:36 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:58:58 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 07:07:22 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 05:27:00 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Thakker", "Urmish", ""], ["Whatmough", "Paul N.", ""], ["Liu", "Zhi-Gang", ""], ["Mattina", "Matthew", ""], ["Beu", "Jesse", ""]]}, {"id": "2001.08904", "submitter": "Muhammad Khan", "authors": "Muhammad Raza Khan, Morteza Ziyadi and Mohamed AbdelHady", "title": "MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition\n  using Deep Bidirectional Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents such as Cortana, Alexa and Siri are continuously\nworking on increasing their capabilities by adding new domains. The support of\na new domain includes the design and development of a number of NLU components\nfor domain classification, intents classification and slots tagging (including\nnamed entity recognition). Each component only performs well when trained on a\nlarge amount of labeled data. Second, these components are deployed on\nlimited-memory devices which requires some model compression. Third, for some\ndomains such as the health domain, it is hard to find a single training data\nset that covers all the required slot types. To overcome these mentioned\nproblems, we present a multi-task transformer-based neural architecture for\nslot tagging. We consider the training of a slot tagger using multiple data\nsets covering different slot types as a multi-task learning problem. The\nexperimental results on the biomedical domain have shown that the proposed\napproach outperforms the previous state-of-the-art systems for slot tagging on\nthe different benchmark biomedical datasets in terms of (time and memory)\nefficiency and effectiveness. The output slot tagger can be used by the\nconversational agent to better identify entities in the input utterances.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 07:16:32 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Khan", "Muhammad Raza", ""], ["Ziyadi", "Morteza", ""], ["AbdelHady", "Mohamed", ""]]}, {"id": "2001.08950", "submitter": "Saurabh Goyal", "authors": "Saurabh Goyal, Anamitra R. Choudhury, Saurabh M. Raje, Venkatesan T.\n  Chakaravarthy, Yogish Sabharwal, Ashish Verma", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector\n  Elimination", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel method, called PoWER-BERT, for improving the inference\ntime of the popular BERT model, while maintaining the accuracy. It works by: a)\nexploiting redundancy pertaining to word-vectors (intermediate encoder outputs)\nand eliminating the redundant vectors. b) determining which word-vectors to\neliminate by developing a strategy for measuring their significance, based on\nthe self-attention mechanism. c) learning how many word-vectors to eliminate by\naugmenting the BERT model and the loss function. Experiments on the standard\nGLUE benchmark shows that PoWER-BERT achieves up to 4.5x reduction in inference\ntime over BERT with <1% loss in accuracy. We show that PoWER-BERT offers\nsignificantly better trade-off between accuracy and inference time compared to\nprior methods. We demonstrate that our method attains up to 6.8x reduction in\ninference time with <1% loss in accuracy when applied over ALBERT, a highly\ncompressed version of BERT. The code for PoWER-BERT is publicly available at\nhttps://github.com/IBM/PoWER-BERT.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 11:36:12 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:53:56 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 12:22:08 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 18:35:54 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 14:11:33 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Goyal", "Saurabh", ""], ["Choudhury", "Anamitra R.", ""], ["Raje", "Saurabh M.", ""], ["Chakaravarthy", "Venkatesan T.", ""], ["Sabharwal", "Yogish", ""], ["Verma", "Ashish", ""]]}, {"id": "2001.09063", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden", "title": "Towards Graph Representation Learning in Emergent Communication", "comments": "The first two authors contributed equally. Accepted at the\n  Reinforcement Learning in Games workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in neuroscience suggest that the human brain represents\ninformation in a geometric structure (for instance, through conceptual spaces).\nIn order to communicate, we flatten the complex representation of entities and\ntheir attributes into a single word or a sentence. In this paper we use graph\nconvolutional networks to support the evolution of language and cooperation in\nmulti-agent systems. Motivated by an image-based referential game, we propose a\ngraph referential game with varying degrees of complexity, and we provide\nstrong baseline models that exhibit desirable properties in terms of language\nemergence and cooperation. We show that the emerged communication protocol is\nrobust, that the agents uncover the true factors of variation in the game, and\nthat they learn to generalize beyond the samples encountered during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:55:59 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 14:18:31 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""]]}, {"id": "2001.09099", "submitter": "Jie Lei", "authors": "Jie Lei, Licheng Yu, Tamara L. Berg, Mohit Bansal", "title": "TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval", "comments": "ECCV 2020 (extended version, with TVC dataset+models; 35 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TV show Retrieval (TVR), a new multimodal retrieval dataset. TVR\nrequires systems to understand both videos and their associated subtitle\n(dialogue) texts, making it more realistic. The dataset contains 109K queries\ncollected on 21.8K videos from 6 TV shows of diverse genres, where each query\nis associated with a tight temporal window. The queries are also labeled with\nquery types that indicate whether each of them is more related to video or\nsubtitle or both, allowing for in-depth analysis of the dataset and the methods\nthat built on top of it. Strict qualification and post-annotation verification\ntests are applied to ensure the quality of the collected data. Further, we\npresent several baselines and a novel Cross-modal Moment Localization (XML )\nnetwork for multimodal moment retrieval tasks. The proposed XML model uses a\nlate fusion design with a novel Convolutional Start-End detector (ConvSE),\nsurpassing baselines by a large margin and with better efficiency, providing a\nstrong starting point for future work. We have also collected additional\ndescriptions for each annotated moment in TVR to form a new multimodal\ncaptioning dataset with 262K captions, named TV show Caption (TVC). Both\ndatasets are publicly available. TVR: https://tvr.cs.unc.edu, TVC:\nhttps://tvr.cs.unc.edu/tvc.html.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 17:09:39 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:12:14 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Lei", "Jie", ""], ["Yu", "Licheng", ""], ["Berg", "Tamara L.", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.09128", "submitter": "Yang Chen", "authors": "Yang Chen, Weiran Wang, Chao Wang", "title": "Semi-supervised ASR by End-to-end Self-training", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning based end-to-end automatic speech recognition (ASR)\nsystems have greatly simplified modeling pipelines, they suffer from the data\nsparsity issue. In this work, we propose a self-training method with an\nend-to-end system for semi-supervised ASR. Starting from a Connectionist\nTemporal Classification (CTC) system trained on the supervised data, we\niteratively generate pseudo-labels on a mini-batch of unsupervised utterances\nwith the current model, and use the pseudo-labels to augment the supervised\ndata for immediate model update. Our method retains the simplicity of\nend-to-end ASR systems, and can be seen as performing alternating optimization\nover a well-defined learning objective. We also perform empirical\ninvestigations of our method, regarding the effect of data augmentation,\ndecoding beamsize for pseudo-label generation, and freshness of pseudo-labels.\nOn a commonly used semi-supervised ASR setting with the WSJ corpus, our method\ngives 14.4% relative WER improvement over a carefully-trained base system with\ndata augmentation, reducing the performance gap between the base system and the\noracle system by 50%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:22:57 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 14:48:51 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Chen", "Yang", ""], ["Wang", "Weiran", ""], ["Wang", "Chao", ""]]}, {"id": "2001.09215", "submitter": "Akash Kumar Gautam", "authors": "Gyanesh Anand, Akash Gautam, Puneet Mathur, Debanjan Mahata, Rajiv\n  Ratn Shah, Ramit Sawhney", "title": "An Iterative Approach for Identifying Complaint Based Tweets in Social\n  Media Platforms", "comments": "Preprint of paper accepted at AAAI, student abstract 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is a social media platform where users express opinions over a\nvariety of issues. Posts offering grievances or complaints can be utilized by\nprivate/ public organizations to improve their service and promptly gauge a\nlow-cost assessment. In this paper, we propose an iterative methodology which\naims to identify complaint based posts pertaining to the transport domain. We\nperform comprehensive evaluations along with releasing a novel dataset for the\nresearch purposes.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:23:22 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:36:01 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Anand", "Gyanesh", ""], ["Gautam", "Akash", ""], ["Mathur", "Puneet", ""], ["Mahata", "Debanjan", ""], ["Shah", "Rajiv Ratn", ""], ["Sawhney", "Ramit", ""]]}, {"id": "2001.09221", "submitter": "Yang Chen", "authors": "Yang Chen, Weiran Wang, I-Fan Chen, Chao Wang", "title": "Data Techniques For Online End-to-end Speech Recognition", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners often need to build ASR systems for new use cases in a short\namount of time, given limited in-domain data. While recently developed\nend-to-end methods largely simplify the modeling pipelines, they still suffer\nfrom the data sparsity issue. In this work, we explore a few\nsimple-to-implement techniques for building online ASR systems in an end-to-end\nfashion, with a small amount of transcribed data in the target domain. These\ntechniques include data augmentation in the target domain, domain adaptation\nusing models previously trained on a large source domain, and knowledge\ndistillation on non-transcribed target domain data, using an adapted\nbi-directional model as the teacher; they are applicable in real scenarios with\ndifferent types of resources. Our experiments demonstrate that each technique\nis independently useful in the improvement of the online ASR performance in the\ntarget domain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:59:46 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 22:58:12 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chen", "Yang", ""], ["Wang", "Weiran", ""], ["Chen", "I-Fan", ""], ["Wang", "Chao", ""]]}, {"id": "2001.09239", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski,\n  Joao Monteiro, Jan Trmal, Yoshua Bengio", "title": "Multi-task self-supervised learning for Robust Speech Recognition", "comments": "In Proc. of ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the growing interest in unsupervised learning, extracting meaningful\nknowledge from unlabelled audio remains an open challenge. To take a step in\nthis direction, we recently proposed a problem-agnostic speech encoder (PASE),\nthat combines a convolutional encoder followed by multiple neural networks,\ncalled workers, tasked to solve self-supervised problems (i.e., ones that do\nnot require manual annotations as ground truth). PASE was shown to capture\nrelevant speech information, including speaker voice-print and phonemes. This\npaper proposes PASE+, an improved version of PASE for robust speech recognition\nin noisy and reverberant environments. To this end, we employ an online speech\ndistortion module, that contaminates the input signals with a variety of random\ndisturbances. We then propose a revised encoder that better learns short- and\nlong-term speech dynamics with an efficient combination of recurrent and\nconvolutional networks. Finally, we refine the set of workers used in\nself-supervision to encourage better cooperation. Results on TIMIT, DIRHA and\nCHiME-5 show that PASE+ significantly outperforms both the previous version of\nPASE as well as common acoustic features. Interestingly, PASE+ learns\ntransferable representations suitable for highly mismatched acoustic\nconditions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 00:24:45 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 19:40:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Zhong", "Jianyuan", ""], ["Pascual", "Santiago", ""], ["Swietojanski", "Pawel", ""], ["Monteiro", "Joao", ""], ["Trmal", "Jan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.09246", "submitter": "Hyun-Jin Park", "authors": "Hyun-Jin Park, Patrick Violette, Niranjan Subrahmanya", "title": "Learning To Detect Keyword Parts And Whole By Smoothed Max Pooling", "comments": "Accepted in International Conference on Acoustics, Speech, and Signal\n  Processing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose smoothed max pooling loss and its application to keyword spotting\nsystems. The proposed approach jointly trains an encoder (to detect keyword\nparts) and a decoder (to detect whole keyword) in a semi-supervised manner. The\nproposed new loss function allows training a model to detect parts and whole of\na keyword, without strictly depending on frame-level labeling from LVCSR (Large\nvocabulary continuous speech recognition), making further optimization\npossible. The proposed system outperforms the baseline keyword spotting model\nin [1] due to increased optimizability. Further, it can be more easily adapted\nfor on-device learning applications due to reduced dependency on LVCSR.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:19:19 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Park", "Hyun-Jin", ""], ["Violette", "Patrick", ""], ["Subrahmanya", "Niranjan", ""]]}, {"id": "2001.09309", "submitter": "Tsung-Han Wu", "authors": "Wei-Tsung Kao, Tsung-Han Wu, Po-Han Chi, Chun-Cheng Hsieh, Hung-Yi Lee", "title": "BERT's output layer recognizes all hidden layers? Some Intriguing\n  Phenomena and a simple way to boost BERT", "comments": "7 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Bidirectional Encoder Representations from Transformers (BERT) have\nachieved tremendous success in many natural language processing (NLP) tasks, it\nremains a black box. A variety of previous works have tried to lift the veil of\nBERT and understand each layer's functionality. In this paper, we found that\nsurprisingly the output layer of BERT can reconstruct the input sentence by\ndirectly taking each layer of BERT as input, even though the output layer has\nnever seen the input other than the final hidden layer. This fact remains true\nacross a wide variety of BERT-based models, even when some layers are\nduplicated. Based on this observation, we propose a quite simple method to\nboost the performance of BERT. By duplicating some layers in the BERT-based\nmodels to make it deeper (no extra training required in this step), they obtain\nbetter performance in the downstream tasks after fine-tuning.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 13:35:34 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:54:30 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kao", "Wei-Tsung", ""], ["Wu", "Tsung-Han", ""], ["Chi", "Po-Han", ""], ["Hsieh", "Chun-Cheng", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "2001.09330", "submitter": "Amedeo Buonanno", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Antonio Di Girolamo, Armando\n  Ospedale, Francesco A.N. Palmieri", "title": "Intent Classification in Question-Answering Using LSTM Architectures", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -\n  June 2019", "journal-ref": "Progresses in Artificial Intelligence and Neural Systems. Smart\n  Innovation, Systems and Technologies, vol 184. Springer, Singapore - First\n  Online: July 2020", "doi": "10.1007/978-981-15-5093-5_11", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) is certainly the best known and probably also one of\nthe most complex problem within Natural Language Processing (NLP) and\nartificial intelligence (AI). Since the complete solution to the problem of\nfinding a generic answer still seems far away, the wisest thing to do is to\nbreak down the problem by solving single simpler parts. Assuming a modular\napproach to the problem, we confine our research to intent classification for\nan answer, given a question. Through the use of an LSTM network, we show how\nthis type of classification can be approached effectively and efficiently, and\nhow it can be properly used within a basic prototype responder.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:07:07 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Di Girolamo", "Antonio", ""], ["Ospedale", "Armando", ""], ["Palmieri", "Francesco A. N.", ""]]}, {"id": "2001.09332", "submitter": "Amedeo Buonanno", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Antonio Di Girolamo, Armando\n  Ospedale, Francesco A.N. Palmieri, Gianfranco Fedele", "title": "An Analysis of Word2Vec for the Italian Language", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -\n  June 2019", "journal-ref": "Progresses in Artificial Intelligence and Neural Systems. Smart\n  Innovation, Systems and Technologies, vol 184. Springer, Singapore - First\n  Online: July 2020", "doi": "10.1007/978-981-15-5093-5_13", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representation is fundamental in NLP tasks, because it is precisely from\nthe coding of semantic closeness between words that it is possible to think of\nteaching a machine to understand text. Despite the spread of word embedding\nconcepts, still few are the achievements in linguistic contexts other than\nEnglish. In this work, analysing the semantic capacity of the Word2Vec\nalgorithm, an embedding for the Italian language is produced. Parameter setting\nsuch as the number of epochs, the size of the context window and the number of\nnegatively backpropagated samples is explored.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:12:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Di Girolamo", "Antonio", ""], ["Ospedale", "Armando", ""], ["Palmieri", "Francesco A. N.", ""], ["Fedele", "Gianfranco", ""]]}, {"id": "2001.09386", "submitter": "Xiaotao Gu", "authors": "Xiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, Hongkun Yu, You Wu,\n  Cong Yu, Daniel Finnie, Jiaqi Zhai, Nicholas Zukoski", "title": "Generating Representative Headlines for News Stories", "comments": "WebConf 2020 (WWW 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Millions of news articles are published online every day, which can be\noverwhelming for readers to follow. Grouping articles that are reporting the\nsame event into news stories is a common way of assisting readers in their news\nconsumption. However, it remains a challenging research problem to efficiently\nand effectively generate a representative headline for each story. Automatic\nsummarization of a document set has been studied for decades, while few studies\nhave focused on generating representative headlines for a set of articles.\nUnlike summaries, which aim to capture most information with least redundancy,\nheadlines aim to capture information jointly shared by the story articles in\nshort length, and exclude information that is too specific to each individual\narticle. In this work, we study the problem of generating representative\nheadlines for news stories. We develop a distant supervision approach to train\nlarge-scale generation models without any human annotation. This approach\ncenters on two technical components. First, we propose a multi-level\npre-training framework that incorporates massive unlabeled corpus with\ndifferent quality-vs.-quantity balance at different levels. We show that models\ntrained within this framework outperform those trained with pure human curated\ncorpus. Second, we propose a novel self-voting-based article attention layer to\nextract salient information shared by multiple articles. We show that models\nthat incorporate this layer are robust to potential noises in news stories and\noutperform existing baselines with or without noises. We can further enhance\nour model by incorporating human labels, and we show our distant supervision\napproach significantly reduces the demand on labeled data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:08:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 02:13:59 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 21:39:47 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 21:47:52 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Gu", "Xiaotao", ""], ["Mao", "Yuning", ""], ["Han", "Jiawei", ""], ["Liu", "Jialu", ""], ["Yu", "Hongkun", ""], ["Wu", "You", ""], ["Yu", "Cong", ""], ["Finnie", "Daniel", ""], ["Zhai", "Jiaqi", ""], ["Zukoski", "Nicholas", ""]]}, {"id": "2001.09415", "submitter": "Pengfei Zhu", "authors": "Pengfei Zhu and Hai Zhao and Xiaoguang Li", "title": "DUMA: Reading Comprehension with Transposition Thinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-choice Machine Reading Comprehension (MRC) requires model to decide the\ncorrect answer from a set of answer options when given a passage and a\nquestion. Thus in addition to a powerful Pre-trained Language Model (PrLM) as\nencoder, multi-choice MRC especially relies on a matching network design which\nis supposed to effectively capture the relationships among the triplet of\npassage, question and answers. While the newer and more powerful PrLMs have\nshown their mightiness even without the support from a matching network, we\npropose a new DUal Multi-head Co-Attention (DUMA) model, which is inspired by\nhuman's transposition thinking process solving the multi-choice MRC problem:\nrespectively considering each other's focus from the standpoint of passage and\nquestion. The proposed DUMA has been shown effective and is capable of\ngenerally promoting PrLMs. Our proposed method is evaluated on two benchmark\nmulti-choice MRC tasks, DREAM and RACE, showing that in terms of powerful\nPrLMs, DUMA can still boost the model to reach new state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 07:35:02 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:59:48 GMT"}, {"version": "v3", "created": "Sat, 8 Feb 2020 03:47:36 GMT"}, {"version": "v4", "created": "Wed, 18 Mar 2020 12:53:23 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 07:16:15 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhu", "Pengfei", ""], ["Zhao", "Hai", ""], ["Li", "Xiaoguang", ""]]}, {"id": "2001.09466", "submitter": "Luciano Del Corro", "authors": "Luciano Del Corro and Johannes Hoffart", "title": "From Stock Prediction to Financial Relevance: Repurposing Attention\n  Weights to Assess News Relevance Without Manual Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to automatically identify financially relevant news using\nstock price movements and news headlines as input. The method repurposes the\nattention weights of a neural network initially trained to predict stock prices\nto assign a relevance score to each headline, eliminating the need for manually\nlabeled training data. Our experiments on the four most relevant US stock\nindices and 1.5M news headlines show that the method ranks relevant news\nhighly, positively correlated with the accuracy of the initial stock price\nprediction task.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:16:37 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 18:39:37 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 16:26:18 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Del Corro", "Luciano", ""], ["Hoffart", "Johannes", ""]]}, {"id": "2001.09519", "submitter": "Siddharth Sigtia", "authors": "Siddharth Sigtia, Pascal Clark, Rob Haynes, Hywel Richards, John\n  Bridle", "title": "Multi-task Learning for Voice Trigger Detection", "comments": null, "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7449-7453", "doi": "10.1109/ICASSP40776.2020.9053577", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design of a voice trigger detection system for smart\nspeakers. In this study, we address two major challenges. The first is that the\ndetectors are deployed in complex acoustic environments with external noise and\nloud playback by the device itself. Secondly, collecting training examples for\na specific keyword or trigger phrase is challenging resulting in a scarcity of\ntrigger phrase specific training data. We describe a two-stage cascaded\narchitecture where a low-power detector is always running and listening for the\ntrigger phrase. If a detection is made at this stage, the candidate audio\nsegment is re-scored by larger, more complex models to verify that the segment\ncontains the trigger phrase. In this study, we focus our attention on the\narchitecture and design of these second-pass detectors. We start by training a\ngeneral acoustic model that produces phonetic transcriptions given a large\nlabelled training dataset. Next, we collect a much smaller dataset of examples\nthat are challenging for the baseline system. We then use multi-task learning\nto train a model to simultaneously produce accurate phonetic transcriptions on\nthe larger dataset \\emph{and} discriminate between true and easily confusable\nexamples using the smaller dataset. Our results demonstrate that the proposed\nmodel reduces errors by half compared to the baseline in a range of challenging\ntest conditions \\emph{without} requiring extra parameters.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:13:07 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 09:05:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sigtia", "Siddharth", ""], ["Clark", "Pascal", ""], ["Haynes", "Rob", ""], ["Richards", "Hywel", ""], ["Bridle", "John", ""]]}, {"id": "2001.09522", "submitter": "Jiaming Shen", "authors": "Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang,\n  Jiawei Han", "title": "TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced\n  Graph Neural Network", "comments": "WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380132", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies consist of machine-interpretable semantics and provide valuable\nknowledge for many web applications. For example, online retailers (e.g.,\nAmazon and eBay) use taxonomies for product recommendation, and web search\nengines (e.g., Google and Bing) leverage taxonomies to enhance query\nunderstanding. Enormous efforts have been made on constructing taxonomies\neither manually or semi-automatically. However, with the fast-growing volume of\nweb content, existing taxonomies will become outdated and fail to capture\nemerging knowledge. Therefore, in many applications, dynamic expansions of an\nexisting taxonomy are in great demand. In this paper, we study how to expand an\nexisting taxonomy by adding a set of new concepts. We propose a novel\nself-supervised framework, named TaxoExpan, which automatically generates a set\nof <query concept, anchor concept> pairs from the existing taxonomy as training\ndata. Using such self-supervision data, TaxoExpan learns a model to predict\nwhether a query concept is the direct hyponym of an anchor concept. We develop\ntwo innovative techniques in TaxoExpan: (1) a position-enhanced graph neural\nnetwork that encodes the local structure of an anchor concept in the existing\ntaxonomy, and (2) a noise-robust training objective that enables the learned\nmodel to be insensitive to the label noise in the self-supervision data.\nExtensive experiments on three large-scale datasets from different domains\ndemonstrate both the effectiveness and the efficiency of TaxoExpan for taxonomy\nexpansion.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:30:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Shen", "Jiaming", ""], ["Shen", "Zhihong", ""], ["Xiong", "Chenyan", ""], ["Wang", "Chi", ""], ["Wang", "Kuansan", ""], ["Han", "Jiawei", ""]]}, {"id": "2001.09694", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Junjie Yang, Hai Zhao", "title": "Retrospective Reader for Machine Reading Comprehension", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension (MRC) is an AI challenge that requires machine\nto determine the correct answers to questions based on a given passage. MRC\nsystems must not only answer question when necessary but also distinguish when\nno answer is available according to the given passage and then tactfully\nabstain from answering. When unanswerable questions are involved in the MRC\ntask, an essential verification module called verifier is especially required\nin addition to the encoder, though the latest practice on MRC modeling still\nmost benefits from adopting well pre-trained language models as the encoder\nblock by only focusing on the \"reading\". This paper devotes itself to exploring\nbetter verifier design for the MRC task with unanswerable questions. Inspired\nby how humans solve reading comprehension questions, we proposed a\nretrospective reader (Retro-Reader) that integrates two stages of reading and\nverification strategies: 1) sketchy reading that briefly investigates the\noverall interactions of passage and question, and yield an initial judgment; 2)\nintensive reading that verifies the answer and gives the final prediction. The\nproposed reader is evaluated on two benchmark MRC challenge datasets SQuAD2.0\nand NewsQA, achieving new state-of-the-art results. Significance tests show\nthat our model is significantly better than the strong ELECTRA and ALBERT\nbaselines. A series of analysis is also conducted to interpret the\neffectiveness of the proposed reader.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:14:34 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:42:50 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 02:52:35 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 09:28:12 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Yang", "Junjie", ""], ["Zhao", "Hai", ""]]}, {"id": "2001.09727", "submitter": "Vineel Pratap", "authors": "Vineel Pratap, Qiantong Xu, Jacob Kahn, Gilad Avidov, Tatiana\n  Likhomanenko, Awni Hannun, Vitaliy Liptchinsky, Gabriel Synnaeve, Ronan\n  Collobert", "title": "Scaling Up Online Speech Recognition Using ConvNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an online end-to-end speech recognition system based on Time-Depth\nSeparable (TDS) convolutions and Connectionist Temporal Classification (CTC).\nWe improve the core TDS architecture in order to limit the future context and\nhence reduce latency while maintaining accuracy. The system has almost three\ntimes the throughput of a well tuned hybrid ASR baseline while also having\nlower latency and a better word error rate. Also important to the efficiency of\nthe recognizer is our highly optimized beam search decoder. To show the impact\nof our design choices, we analyze throughput, latency, accuracy, and discuss\nhow these metrics can be tuned based on the user requirements.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 12:55:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pratap", "Vineel", ""], ["Xu", "Qiantong", ""], ["Kahn", "Jacob", ""], ["Avidov", "Gilad", ""], ["Likhomanenko", "Tatiana", ""], ["Hannun", "Awni", ""], ["Liptchinsky", "Vitaliy", ""], ["Synnaeve", "Gabriel", ""], ["Collobert", "Ronan", ""]]}, {"id": "2001.09830", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "What's happened in MOOC Posts Analysis, Knowledge Tracing and Peer\n  Feedbacks? A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning Management Systems (LMS) and Educational Data Mining (EDM) are two\nimportant parts of online educational environment with the former being a\ncentralised web-based information systems where the learning content is managed\nand learning activities are organised (Stone and Zheng,2014) and latter\nfocusing on using data mining techniques for the analysis of data so generated.\nAs part of this work, we present a literature review of three major tasks of\nEDM (See section 2), by identifying shortcomings and existing open problems,\nand a Blumenfield chart (See section 3). The consolidated set of papers and\nresources so used are released in\nhttps://github.com/manikandan-ravikiran/cs6460-Survey. The coverage statistics\nand review matrix of the survey are as shown in Figure 1 & Table 1\nrespectively. Acronym expansions are added in the Appendix Section 4.1.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:45:55 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2001.09876", "submitter": "Sandipan Sikdar", "authors": "Binny Mathew, Sandipan Sikdar, Florian Lemmerich and Markus Strohmaier", "title": "The POLAR Framework: Polar Opposites Enable Interpretability of\n  Pre-Trained Word Embeddings", "comments": "Accepted at Web Conference (WWW) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce POLAR - a framework that adds interpretability to pre-trained\nword embeddings via the adoption of semantic differentials. Semantic\ndifferentials are a psychometric construct for measuring the semantics of a\nword by analysing its position on a scale between two polar opposites (e.g.,\ncold -- hot, soft -- hard). The core idea of our approach is to transform\nexisting, pre-trained word embeddings via semantic differentials to a new\n\"polar\" space with interpretable dimensions defined by such polar opposites.\nOur framework also allows for selecting the most discriminative dimensions from\na set of polar dimensions provided by an oracle, i.e., an external source. We\ndemonstrate the effectiveness of our framework by deploying it to various\ndownstream tasks, in which our interpretable word embeddings achieve a\nperformance that is comparable to the original word embeddings. We also show\nthat the interpretable dimensions selected by our framework align with human\njudgement. Together, these results demonstrate that interpretability can be\nadded to word embeddings without compromising performance. Our work is relevant\nfor researchers and engineers interested in interpreting pre-trained word\nembeddings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:58:57 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:40:53 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mathew", "Binny", ""], ["Sikdar", "Sandipan", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2001.09879", "submitter": "Saket Gurukar", "authors": "Saket Gurukar, Deepak Ajwani, Sourav Dutta, Juho Lauri, Srinivasan\n  Parthasarathy, Alessandra Sala", "title": "Towards Quantifying the Distance between Opinions", "comments": "Accepted in ICWSM '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly, critical decisions in public policy, governance, and business\nstrategy rely on a deeper understanding of the needs and opinions of\nconstituent members (e.g. citizens, shareholders). While it has become easier\nto collect a large number of opinions on a topic, there is a necessity for\nautomated tools to help navigate the space of opinions. In such contexts\nunderstanding and quantifying the similarity between opinions is key. We find\nthat measures based solely on text similarity or on overall sentiment often\nfail to effectively capture the distance between opinions. Thus, we propose a\nnew distance measure for capturing the similarity between opinions that\nleverages the nuanced observation -- similar opinions express similar sentiment\npolarity on specific relevant entities-of-interest. Specifically, in an\nunsupervised setting, our distance measure achieves significantly better\nAdjusted Rand Index scores (up to 56x) and Silhouette coefficients (up to 21x)\ncompared to existing approaches. Similarly, in a supervised setting, our\nopinion distance measure achieves considerably better accuracy (up to 20%\nincrease) compared to extant approaches that rely on text similarity, stance\nsimilarity, and sentiment similarity\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:01:10 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Gurukar", "Saket", ""], ["Ajwani", "Deepak", ""], ["Dutta", "Sourav", ""], ["Lauri", "Juho", ""], ["Parthasarathy", "Srinivasan", ""], ["Sala", "Alessandra", ""]]}, {"id": "2001.09896", "submitter": "Vinicius Carid\\'a", "authors": "Amir Jalilifard, Vinicius F. Carid\\'a, Alex F. Mansano, Rogers S.\n  Cristo, Felipe Penhorate C. da Fonseca", "title": "Semantic Sensitive TF-IDF to Determine Word Relevance in Documents", "comments": "11 pages, 2 figures, 22 references", "journal-ref": null, "doi": "10.1007/978-981-33-6977-1", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword extraction has received an increasing attention as an important\nresearch topic which can lead to have advancements in diverse applications such\nas document context categorization, text indexing and document classification.\nIn this paper we propose STF-IDF, a novel semantic method based on TF-IDF, for\nscoring word importance of informal documents in a corpus. A set of nearly four\nmillion documents from health-care social media was collected and was trained\nin order to draw semantic model and to find the word embeddings. Then, the\nfeatures of semantic space were utilized to rearrange the original TF-IDF\nscores through an iterative solution so as to improve the moderate performance\nof this algorithm on informal texts. After testing the proposed method with 200\nrandomly chosen documents, our method managed to decrease the TF-IDF mean error\nrate by a factor of 50% and reaching the mean error of 13.7%, as opposed to\n27.2% of the original TF-IDF.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 00:23:11 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 23:52:07 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Jalilifard", "Amir", ""], ["Carid\u00e1", "Vinicius F.", ""], ["Mansano", "Alex F.", ""], ["Cristo", "Rogers S.", ""], ["da Fonseca", "Felipe Penhorate C.", ""]]}, {"id": "2001.09899", "submitter": "Juan Manuel Ortiz De Zarate", "authors": "Juan Manuel Ortiz de Zarate and Esteban Feuerstein", "title": "Vocabulary-based Method for Quantifying Controversy in Social Media", "comments": "arXiv admin note: text overlap with arXiv:1507.05224 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying controversial topics is not only interesting from a social point\nof view, it also enables the application of methods to avoid the information\nsegregation, creating better discussion contexts and reaching agreements in the\nbest cases. In this paper we develop a systematic method for controversy\ndetection based primarily on the jargon used by the communities in social\nmedia. Our method dispenses with the use of domain-specific knowledge, is\nlanguage-agnostic, efficient and easy to apply. We perform an extensive set of\nexperiments across many languages, regions and contexts, taking controversial\nand non-controversial topics. We find that our vocabulary-based measure\nperforms better than state of the art measures that are based only on the\ncommunity graph structure. Moreover, we shows that it is possible to detect\npolarization through text analysis.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:43:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["de Zarate", "Juan Manuel Ortiz", ""], ["Feuerstein", "Esteban", ""]]}, {"id": "2001.09907", "submitter": "Barry Haddow", "authors": "Barry Haddow and Faheem Kirefu", "title": "PMIndia -- A Collection of Parallel Corpora of Languages of India", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parallel text is required for building high-quality machine translation (MT)\nsystems, as well as for other multilingual NLP applications. For many South\nAsian languages, such data is in short supply. In this paper, we described a\nnew publicly available corpus (PMIndia) consisting of parallel sentences which\npair 13 major languages of India with English. The corpus includes up to 56000\nsentences for each language pair. We explain how the corpus was constructed,\nincluding an assessment of two different automatic sentence alignment methods,\nand present some initial NMT results on the corpus.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:51:39 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Haddow", "Barry", ""], ["Kirefu", "Faheem", ""]]}, {"id": "2001.09977", "submitter": "Daniel de Freitas Adiwardana", "authors": "Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah\n  Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng\n  Lu, Quoc V. Le", "title": "Towards a Human-like Open-Domain Chatbot", "comments": "38 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Meena, a multi-turn open-domain chatbot trained end-to-end on data\nmined and filtered from public domain social media conversations. This 2.6B\nparameter neural network is simply trained to minimize perplexity of the next\ntoken. We also propose a human evaluation metric called Sensibleness and\nSpecificity Average (SSA), which captures key elements of a human-like\nmulti-turn conversation. Our experiments show strong correlation between\nperplexity and SSA. The fact that the best perplexity end-to-end trained Meena\nscores high on SSA (72% on multi-turn evaluation) suggests that a human-level\nSSA of 86% is potentially within reach if we can better optimize perplexity.\nAdditionally, the full version of Meena (with a filtering mechanism and tuned\ndecoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots\nwe evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:53:15 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:58:14 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 07:36:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Adiwardana", "Daniel", ""], ["Luong", "Minh-Thang", ""], ["So", "David R.", ""], ["Hall", "Jamie", ""], ["Fiedel", "Noah", ""], ["Thoppilan", "Romal", ""], ["Yang", "Zi", ""], ["Kulshreshtha", "Apoorv", ""], ["Nemade", "Gaurav", ""], ["Lu", "Yifeng", ""], ["Le", "Quoc V.", ""]]}, {"id": "2001.10071", "submitter": "Lucas Oliveira E S", "authors": "Lucas Emanuel Silva e Oliveira, Ana Carolina Peters, Adalniza Moura\n  Pucca da Silva, Caroline P. Gebeluca, Yohan Bonescki Gumiel, Lilian Mie Mukai\n  Cintho, Deborah Ribeiro Carvalho, Sadid A. Hasan, Claudia Maria Cabral Moro", "title": "SemClinBr -- a multi institutional and multi specialty semantically\n  annotated corpus for Portuguese clinical NLP tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high volume of research focusing on extracting patient's information from\nelectronic health records (EHR) has led to an increase in the demand for\nannotated corpora, which are a very valuable resource for both the development\nand evaluation of natural language processing (NLP) algorithms. The absence of\na multi-purpose clinical corpus outside the scope of the English language,\nespecially in Brazilian Portuguese, is glaring and severely impacts scientific\nprogress in the biomedical NLP field. In this study, we developed a\nsemantically annotated corpus using clinical texts from multiple medical\nspecialties, document types, and institutions. We present the following: (1) a\nsurvey listing common aspects and lessons learned from previous research, (2) a\nfine-grained annotation schema which could be replicated and guide other\nannotation initiatives, (3) a web-based annotation tool focusing on an\nannotation suggestion feature, and (4) both intrinsic and extrinsic evaluation\nof the annotations. The result of this work is the SemClinBr, a corpus that has\n1,000 clinical notes, labeled with 65,117 entities and 11,263 relations, and\ncan support a variety of clinical NLP tasks and boost the EHR's secondary use\nfor the Portuguese language.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 20:39:32 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Oliveira", "Lucas Emanuel Silva e", ""], ["Peters", "Ana Carolina", ""], ["da Silva", "Adalniza Moura Pucca", ""], ["Gebeluca", "Caroline P.", ""], ["Gumiel", "Yohan Bonescki", ""], ["Cintho", "Lilian Mie Mukai", ""], ["Carvalho", "Deborah Ribeiro", ""], ["Hasan", "Sadid A.", ""], ["Moro", "Claudia Maria Cabral", ""]]}, {"id": "2001.10106", "submitter": "Jiaxin Huang", "authors": "Jiaxin Huang, Yiqing Xie, Yu Meng, Jiaming Shen, Yunyi Zhang and\n  Jiawei Han", "title": "Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and\n  Co-Expansion", "comments": "WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380284", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given a small set of seed entities (e.g., ``USA'', ``Russia''), corpus-based\nset expansion is to induce an extensive set of entities which share the same\nsemantic class (Country in this example) from a given corpus. Set expansion\nbenefits a wide range of downstream applications in knowledge discovery, such\nas web search, taxonomy construction, and query suggestion. Existing\ncorpus-based set expansion algorithms typically bootstrap the given seeds by\nincorporating lexical patterns and distributional similarity. However, due to\nno negative sets provided explicitly, these methods suffer from semantic drift\ncaused by expanding the seed set freely without guidance. We propose a new\nframework, Set-CoExpan, that automatically generates auxiliary sets as negative\nsets that are closely related to the target set of user's interest, and then\nperforms multiple sets co-expansion that extracts discriminative features by\ncomparing target set with auxiliary sets, to form multiple cohesive sets that\nare distinctive from one another, thus resolving the semantic drift issue. In\nthis paper we demonstrate that by generating auxiliary sets, we can guide the\nexpansion process of target set to avoid touching those ambiguous areas around\nthe border with auxiliary sets, and we show that Set-CoExpan outperforms strong\nbaseline methods significantly.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:34:07 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Huang", "Jiaxin", ""], ["Xie", "Yiqing", ""], ["Meng", "Yu", ""], ["Shen", "Jiaming", ""], ["Zhang", "Yunyi", ""], ["Han", "Jiawei", ""]]}, {"id": "2001.10112", "submitter": "Zhiyu Chen", "authors": "Zhiyu Chen, Haiyan Jia, Jeff Heflin, Brian D. Davison", "title": "Leveraging Schema Labels to Enhance Dataset Search", "comments": "Accepted at the 42nd European Conference on IR Research, ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A search engine's ability to retrieve desirable datasets is important for\ndata sharing and reuse. Existing dataset search engines typically rely on\nmatching queries to dataset descriptions. However, a user may not have enough\nprior knowledge to write a query using terms that match with description\ntext.We propose a novel schema label generation model which generates possible\nschema labels based on dataset table content. We incorporate the generated\nschema labels into a mixed ranking model which not only considers the relevance\nbetween the query and dataset metadata but also the similarity between the\nquery and generated schema labels. To evaluate our method on real-world\ndatasets, we create a new benchmark specifically for the dataset retrieval\ntask. Experiments show that our approach can effectively improve the precision\nand NDCG scores of the dataset retrieval task compared with baseline methods.\nWe also test on a collection of Wikipedia tables to show that the features\ngenerated from schema labels can improve the unsupervised and supervised web\ntable retrieval task as well.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:41:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Chen", "Zhiyu", ""], ["Jia", "Haiyan", ""], ["Heflin", "Jeff", ""], ["Davison", "Brian D.", ""]]}, {"id": "2001.10161", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Wesley Cheung, Dan Tu, William Broniec, Mark\n  O. Riedl", "title": "Bringing Stories Alive: Generating Interactive Fiction Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World building forms the foundation of any task that requires narrative\nintelligence. In this work, we focus on procedurally generating interactive\nfiction worlds---text-based worlds that players \"see\" and \"talk to\" using\nnatural language. Generating these worlds requires referencing everyday and\nthematic commonsense priors in addition to being semantically consistent,\ninteresting, and coherent throughout. Using existing story plots as\ninspiration, we present a method that first extracts a partial knowledge graph\nencoding basic information regarding world structure such as locations and\nobjects. This knowledge graph is then automatically completed utilizing\nthematic knowledge and used to guide a neural language generation model that\nfleshes out the rest of the world. We perform human participant-based\nevaluations, testing our neural model's ability to extract and fill-in a\nknowledge graph and to generate language conditioned on it against rule-based\nand human-made baselines. Our code is available at\nhttps://github.com/rajammanabrolu/WorldGeneration.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:13:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Cheung", "Wesley", ""], ["Tu", "Dan", ""], ["Broniec", "William", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2001.10169", "submitter": "Kumar Shikhar Deep", "authors": "Kumar Shikhar Deep, Asif Ekbal, Pushpak Bhattacharyya", "title": "A Deep Neural Framework for Contextual Affect Detection", "comments": "12 pages, 5 tables and 3 figures. Accepted in ICONIP 2019\n  (International Conference on Neural Information Processing) Published in\n  Lecture Notes in Computer Science, vol 11955. Springer, Cham\n  https://link.springer.com/chapter/10.1007/978-3-030-36718-3_34", "journal-ref": "LNCS 11955 (2019) 398-409", "doi": "10.1007/978-3-030-36718-3_34", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A short and simple text carrying no emotion can represent some strong\nemotions when reading along with its context, i.e., the same sentence can\nexpress extreme anger as well as happiness depending on its context. In this\npaper, we propose a Contextual Affect Detection (CAD) framework which learns\nthe inter-dependence of words in a sentence, and at the same time the\ninter-dependence of sentences in a dialogue. Our proposed CAD framework is\nbased on a Gated Recurrent Unit (GRU), which is further assisted by contextual\nword embeddings and other diverse hand-crafted feature sets. Evaluation and\nanalysis suggest that our model outperforms the state-of-the-art methods by\n5.49% and 9.14% on Friends and EmotionPush dataset, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:03:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Deep", "Kumar Shikhar", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2001.10175", "submitter": "Kumiko Tanaka-Ishii", "authors": "Daiki Hirano, Kumiko Tanaka-Ishii and Andrew Finch", "title": "Extraction of Templates from Phrases Using Sequence Binary Decision\n  Diagrams", "comments": null, "journal-ref": "Natural Language Engineering, 2018", "doi": "10.1017/S1351324918000268", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of templates such as ``regard X as Y'' from a set of related\nphrases requires the identification of their internal structures. This paper\npresents an unsupervised approach for extracting templates on-the-fly from only\ntagged text by using a novel relaxed variant of the Sequence Binary Decision\nDiagram (SeqBDD). A SeqBDD can compress a set of sequences into a graphical\nstructure equivalent to a minimal DFA, but more compact and better suited to\nthe task of template extraction. The main contribution of this paper is a\nrelaxed form of the SeqBDD construction algorithm that enables it to form\ngeneral representations from a small amount of data. The process of compression\nof shared structures in the text during Relaxed SeqBDD construction, naturally\ninduces the templates we wish to extract. Experiments show that the method is\ncapable of high-quality extraction on tasks based on verb+preposition templates\nfrom corpora and phrasal templates from short messages from social media.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:30:53 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Hirano", "Daiki", ""], ["Tanaka-Ishii", "Kumiko", ""], ["Finch", "Andrew", ""]]}, {"id": "2001.10179", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Hao Sha, Michael Lin", "title": "Multi-modal Sentiment Analysis using Super Characters Method on\n  Low-power CNN Accelerator Device", "comments": "9 pages, 2 figures, 6 tables. Accepted by AAAI 2020 Affective Content\n  Analysis Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years NLP research has witnessed the record-breaking accuracy\nimprovement by DNN models. However, power consumption is one of the practical\nconcerns for deploying NLP systems. Most of the current state-of-the-art\nalgorithms are implemented on GPUs, which is not power-efficient and the\ndeployment cost is also very high. On the other hand, CNN Domain Specific\nAccelerator (CNN-DSA) has been in mass production providing low-power and low\ncost computation power. In this paper, we will implement the Super Characters\nmethod on the CNN-DSA. In addition, we modify the Super Characters method to\nutilize the multi-modal data, i.e. text plus tabular data in the CL-Aff\nsharedtask.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:45:03 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Sha", "Hao", ""], ["Lin", "Michael", ""]]}, {"id": "2001.10337", "submitter": "Michael Bloodgood", "authors": "Thomas Orth and Michael Bloodgood", "title": "Early Forecasting of Text Classification Accuracy and F-Measure with\n  Active Learning", "comments": "8 pages, 9 figures, 2 tables; published in Proceedings of the IEEE\n  14th International Conference on Semantic Computing (ICSC), San Diego, CA,\n  USA, pages 77-84, February 2020", "journal-ref": "In Proceedings of the 2020 IEEE 14th International Conference on\n  Semantic Computing (ICSC), pages 77-84, San Diego, CA, USA, February 2020.\n  IEEE", "doi": "10.1109/ICSC.2020.00018", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating text classification systems, one of the major bottlenecks is\nthe annotation of training data. Active learning has been proposed to address\nthis bottleneck using stopping methods to minimize the cost of data annotation.\nAn important capability for improving the utility of stopping methods is to\neffectively forecast the performance of the text classification models.\nForecasting can be done through the use of logarithmic models regressed on some\nportion of the data as learning is progressing. A critical unexplored question\nis what portion of the data is needed for accurate forecasting. There is a\ntension, where it is desirable to use less data so that the forecast can be\nmade earlier, which is more useful, versus it being desirable to use more data,\nso that the forecast can be more accurate. We find that when using active\nlearning it is even more important to generate forecasts earlier so as to make\nthem more useful and not waste annotation effort. We investigate the difference\nin forecasting difficulty when using accuracy and F-measure as the text\nclassification system performance metrics and we find that F-measure is more\ndifficult to forecast. We conduct experiments on seven text classification\ndatasets in different semantic domains with different characteristics and with\nthree different base machine learning algorithms. We find that forecasting is\neasiest for decision tree learning, moderate for Support Vector Machines, and\nmost difficult for neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 06:27:33 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 08:59:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Orth", "Thomas", ""], ["Bloodgood", "Michael", ""]]}, {"id": "2001.10340", "submitter": "Raviraj Joshi", "authors": "Ramchandra Joshi, Purvi Goel, Raviraj Joshi", "title": "Deep Learning for Hindi Text Classification: A Comparison", "comments": "Accepted at International Conference on Intelligent Human Computer\n  Interaction(IHCI) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-44689-5_9", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) and especially natural language text\nanalysis have seen great advances in recent times. Usage of deep learning in\ntext processing has revolutionized the techniques for text processing and\nachieved remarkable results. Different deep learning architectures like CNN,\nLSTM, and very recent Transformer have been used to achieve state of the art\nresults variety on NLP tasks. In this work, we survey a host of deep learning\narchitectures for text classification tasks. The work is specifically concerned\nwith the classification of Hindi text. The research in the classification of\nmorphologically rich and low resource Hindi language written in Devanagari\nscript has been limited due to the absence of large labeled corpus. In this\nwork, we used translated versions of English data-sets to evaluate models based\non CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based\non BERT and LASER are also compared to evaluate their effectiveness for the\nHindi language. The paper also serves as a tutorial for popular text\nclassification techniques.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 09:29:12 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Joshi", "Ramchandra", ""], ["Goel", "Purvi", ""], ["Joshi", "Raviraj", ""]]}, {"id": "2001.10468", "submitter": "Firas Kassawat", "authors": "Firas Kassawat, Debanjan Chaudhuri, Jens Lehmann", "title": "Incorporating Joint Embeddings into Goal-Oriented Dialogues with\n  Multi-Task Learning", "comments": "The Semantic Web - 16th International Conference, ESWC 2019,\n  Portoro\\v{z}, Slovenia, June 2-6, 2019, Proceedings, page 225-239", "journal-ref": null, "doi": "10.1007/978-3-030-21348-0_15", "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder neural network models have recently shown\npromising results in goal-oriented dialogue systems. However, these models\nstruggle to reason over and incorporate state-full knowledge while preserving\ntheir end-to-end text generation functionality. Since such models can greatly\nbenefit from user intent and knowledge graph integration, in this paper we\npropose an RNN-based end-to-end encoder-decoder architecture which is trained\nwith joint embeddings of the knowledge graph and the corpus as input. The model\nprovides an additional integration of user intent along with text generation,\ntrained with a multi-task learning paradigm along with an additional\nregularization technique to penalize generating the wrong entity as output. The\nmodel further incorporates a Knowledge Graph entity lookup during inference to\nguarantee the generated output is state-full based on the local knowledge graph\nprovided. We finally evaluated the model using the BLEU score, empirical\nevaluation depicts that our proposed architecture can aid in the betterment of\ntask-oriented dialogue system`s performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:15:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kassawat", "Firas", ""], ["Chaudhuri", "Debanjan", ""], ["Lehmann", "Jens", ""]]}, {"id": "2001.10590", "submitter": "Milad Taleby Ahvanooey", "authors": "Amir Vatani, Milad Taleby Ahvanooey, Mostafa Rahimi", "title": "An Effective Automatic Image Annotation Model Via Attention Model and\n  Data Equilibrium", "comments": "9 pages, 3 figures", "journal-ref": "Int. J. Adv. Comput. Sci. Appl, 9(3), pp.269-277 (2018)", "doi": "10.14569/IJACSA.2018.090338", "report-no": null, "categories": "cs.MM cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, a huge number of images are available. However, retrieving a\nrequired image for an ordinary user is a challenging task in computer vision\nsystems. During the past two decades, many types of research have been\nintroduced to improve the performance of the automatic annotation of images,\nwhich are traditionally focused on content-based image retrieval. Although,\nrecent research demonstrates that there is a semantic gap between content-based\nimage retrieval and image semantics understandable by humans. As a result,\nexisting research in this area has caused to bridge the semantic gap between\nlow-level image features and high-level semantics. The conventional method of\nbridging the semantic gap is through the automatic image annotation (AIA) that\nextracts semantic features using machine learning techniques. In this paper, we\npropose a novel AIA model based on the deep learning feature extraction method.\nThe proposed model has three phases, including a feature extractor, a tag\ngenerator, and an image annotator. First, the proposed model extracts\nautomatically the high and low-level features based on dual-tree continues\nwavelet transform (DT-CWT), singular value decomposition, distribution of color\nton, and the deep neural network. Moreover, the tag generator balances the\ndictionary of the annotated keywords by a new log-entropy auto-encoder (LEAE)\nand then describes these keywords by word embedding. Finally, the annotator\nworks based on the long-short-term memory (LSTM) network in order to obtain the\nimportance degree of specific features of the image. The experiments conducted\non two benchmark datasets confirm that the superiority of the proposed model\ncompared to the previous models in terms of performance criteria.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 05:59:57 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Vatani", "Amir", ""], ["Ahvanooey", "Milad Taleby", ""], ["Rahimi", "Mostafa", ""]]}, {"id": "2001.10613", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Alexandre Nadjem and Juan-Manuel Torres-Moreno and Marc El-B\\`eze and\n  Guillaume Marrel and Beno\\^it Bonte", "title": "Predicting Personalized Academic and Career Roads: First Steps Toward a\n  Multi-Uses Recommender System", "comments": "4 pages, 3 figures, 4 tables", "journal-ref": "Digital Tools & Uses Congress (DTUC '18), pp 1--4, 2018, Paris,\n  France", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nobody knows what one's do in the future and everyone will have had a\ndifferent answer to the question : how do you see yourself in five years after\nyour current job/diploma? In this paper we introduce concepts, large categories\nof fields of studies or job domains in order to represent the vision of the\nfuture of the user's trajectory. Then, we show how they can influence the\nprediction when proposing him a set of next steps to take.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:00:54 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Nadjem", "Alexandre", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["El-B\u00e8ze", "Marc", ""], ["Marrel", "Guillaume", ""], ["Bonte", "Beno\u00eet", ""]]}, {"id": "2001.10617", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Systematic Review of Approaches to Improve Peer Assessment at Scale", "comments": "This is a review assignment, work on progress. Expected to be updated\n  regularly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer Assessment is a task of analysis and commenting on student's writing by\npeers, is core of all educational components both in campus and in MOOC's.\nHowever, with the sheer scale of MOOC's & its inherent personalised open ended\nlearning, automatic grading and tools assisting grading at scale is highly\nimportant. Previously we presented survey on tasks of post classification,\nknowledge tracing and ended with brief review on Peer Assessment (PA), with\nsome initial problems. In this review we shall continue review on PA from\nperspective of improving the review process itself. As such rest of this review\nfocus on three facets of PA namely Auto grading and Peer Assessment Tools (we\nshall look only on how peer reviews/auto-grading is carried), strategies to\nhandle Rogue Reviews, Peer Review Improvement using Natural Language\nProcessing. The consolidated set of papers and resources so used are released\nin https://github.com/manikandan-ravikiran/cs6460-Survey-2.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:59:24 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2001.10667", "submitter": "Serena Khoo", "authors": "Ling Min Serena Khoo, Hai Leong Chieu, Zhong Qian and Jing Jiang", "title": "Interpretable Rumor Detection in Microblogs by Attending to User\n  Interactions", "comments": "8 pages, 3 figures, AAAI 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address rumor detection by learning to differentiate between the\ncommunity's response to real and fake claims in microblogs. Existing\nstate-of-the-art models are based on tree models that model conversational\ntrees. However, in social media, a user posting a reply might be replying to\nthe entire thread rather than to a specific user. We propose a post-level\nattention model (PLAN) to model long distance interactions between tweets with\nthe multi-head attention mechanism in a transformer network. We investigated\nvariants of this model: (1) a structure aware self-attention model (StA-PLAN)\nthat incorporates tree structure information in the transformer network, and\n(2) a hierarchical token and post-level attention model (StA-HiTPLAN) that\nlearns a sentence representation with token-level self-attention. To the best\nof our knowledge, we are the first to evaluate our models on two rumor\ndetection data sets: the PHEME data set as well as the Twitter15 and Twitter16\ndata sets. We show that our best models outperform current state-of-the-art\nmodels for both data sets. Moreover, the attention mechanism allows us to\nexplain rumor detection predictions at both token-level and post-level.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 02:37:11 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Khoo", "Ling Min Serena", ""], ["Chieu", "Hai Leong", ""], ["Qian", "Zhong", ""], ["Jiang", "Jing", ""]]}, {"id": "2001.10816", "submitter": "Siddharth Sigtia", "authors": "Siddharth Sigtia, Erik Marchi, Sachin Kajarekar, Devang Naik, John\n  Bridle", "title": "Multi-task Learning for Speaker Verification and Voice Trigger Detection", "comments": null, "journal-ref": "International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Spain, 2020, pp. 6844-6848", "doi": "10.1109/ICASSP40776.2020.9054760", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech transcription and speaker recognition are usually treated as\nseparate tasks even though they are interdependent. In this study, we\ninvestigate training a single network to perform both tasks jointly. We train\nthe network in a supervised multi-task learning setup, where the speech\ntranscription branch of the network is trained to minimise a phonetic\nconnectionist temporal classification (CTC) loss while the speaker recognition\nbranch of the network is trained to label the input sequence with the correct\nlabel for the speaker. We present a large-scale empirical study where the model\nis trained using several thousand hours of labelled training data for each\ntask. We evaluate the speech transcription branch of the network on a voice\ntrigger detection task while the speaker recognition branch is evaluated on a\nspeaker verification task. Results demonstrate that the network is able to\nencode both phonetic \\emph{and} speaker information in its learnt\nrepresentations while yielding accuracies at least as good as the baseline\nmodels for each task, with the same number of parameters as the independent\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:19:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sigtia", "Siddharth", ""], ["Marchi", "Erik", ""], ["Kajarekar", "Sachin", ""], ["Naik", "Devang", ""], ["Bridle", "John", ""]]}, {"id": "2001.10822", "submitter": "Pranay Dighe", "authors": "Pranay Dighe, Saurabh Adya, Nuoyu Li, Srikanth Vishnubhotla, Devang\n  Naik, Adithya Sagar, Ying Ma, Stephen Pulman, Jason Williams", "title": "Lattice-based Improvements for Voice Triggering Using Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-triggered smart assistants often rely on detection of a trigger-phrase\nbefore they start listening for the user request. Mitigation of false triggers\nis an important aspect of building a privacy-centric non-intrusive smart\nassistant. In this paper, we address the task of false trigger mitigation (FTM)\nusing a novel approach based on analyzing automatic speech recognition (ASR)\nlattices using graph neural networks (GNN). The proposed approach uses the fact\nthat decoding lattice of a falsely triggered audio exhibits uncertainties in\nterms of many alternative paths and unexpected words on the lattice arcs as\ncompared to the lattice of a correctly triggered audio. A pure trigger-phrase\ndetector model doesn't fully utilize the intent of the user speech whereas by\nusing the complete decoding lattice of user audio, we can effectively mitigate\nspeech not intended for the smart assistant. We deploy two variants of GNNs in\nthis paper based on 1) graph convolution layers and 2) self-attention mechanism\nrespectively. Our experiments demonstrate that GNNs are highly accurate in FTM\ntask by mitigating ~87% of false triggers at 99% true positive rate (TPR).\nFurthermore, the proposed models are fast to train and efficient in parameter\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:34:15 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Dighe", "Pranay", ""], ["Adya", "Saurabh", ""], ["Li", "Nuoyu", ""], ["Vishnubhotla", "Srikanth", ""], ["Naik", "Devang", ""], ["Sagar", "Adithya", ""], ["Ma", "Ying", ""], ["Pulman", "Stephen", ""], ["Williams", "Jason", ""]]}, {"id": "2001.10929", "submitter": "Juri Opitz", "authors": "Juri Opitz and Letitia Parcalabescu and Anette Frank", "title": "AMR Similarity Metrics from Principles", "comments": "TACL 2020 https://doi.org/10.1162/tacl_a_00329", "journal-ref": null, "doi": "10.1162/tacl_a_00329", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different metrics have been proposed to compare Abstract Meaning\nRepresentation (AMR) graphs. The canonical Smatch metric (Cai and Knight, 2013)\naligns the variables of two graphs and assesses triple matches. The recent\nSemBleu metric (Song and Gildea, 2019) is based on the machine-translation\nmetric Bleu (Papineni et al., 2002) and increases computational efficiency by\nablating the variable-alignment.\n  In this paper, i) we establish criteria that enable researchers to perform a\nprincipled assessment of metrics comparing meaning representations like AMR;\nii) we undertake a thorough analysis of Smatch and SemBleu where we show that\nthe latter exhibits some undesirable properties. For example, it does not\nconform to the identity of indiscernibles rule and introduces biases that are\nhard to control; iii) we propose a novel metric S$^2$match that is more\nbenevolent to only very slight meaning deviations and targets the fulfilment of\nall established criteria. We assess its suitability and show its advantages\nover Smatch and SemBleu.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:19:44 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:34:56 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Opitz", "Juri", ""], ["Parcalabescu", "Letitia", ""], ["Frank", "Anette", ""]]}, {"id": "2001.10980", "submitter": "Jing Jiang", "authors": "Jing Jiang", "title": "Multimodal Story Generation on Plural Images", "comments": "This is an undergraduate project report. Completed Dec. 2019 at the\n  Cooper Union", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:39:00 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 10:44:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jiang", "Jing", ""]]}, {"id": "2001.11003", "submitter": "Leonardo F. R. Ribeiro", "authors": "Leonardo F. R. Ribeiro, Yue Zhang, Claire Gardent and Iryna Gurevych", "title": "Modeling Global and Local Node Contexts for Text Generation from\n  Knowledge Graphs", "comments": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2020; Author's final version; pre-MIT Press\n  publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent graph-to-text models generate text from graph-based data using either\nglobal or local aggregation to learn node representations. Global node encoding\nallows explicit communication between two distant nodes, thereby neglecting\ngraph topology as all nodes are directly connected. In contrast, local node\nencoding considers the relations between neighbor nodes capturing the graph\nstructure, but it can fail to capture long-range relations. In this work, we\ngather both encoding strategies, proposing novel neural models which encode an\ninput graph combining both global and local node contexts, in order to learn\nbetter contextualized node embeddings. In our experiments, we demonstrate that\nour approaches lead to significant improvements on two graph-to-text datasets\nachieving BLEU scores of 18.01 on AGENDA dataset, and 63.69 on the WebNLG\ndataset for seen categories, outperforming state-of-the-art models by 3.7 and\n3.1 points, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:24:14 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 16:34:10 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ribeiro", "Leonardo F. R.", ""], ["Zhang", "Yue", ""], ["Gardent", "Claire", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2001.11121", "submitter": "Zuohui Fu", "authors": "Zuohui Fu, Yikun Xian, Shijie Geng, Yingqiang Ge, Yuting Wang, Xin\n  Dong, Guang Wang and Gerard de Melo", "title": "ABSent: Cross-Lingual Sentence Representation Mapping with Bidirectional\n  GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of cross-lingual transfer learning approaches based on neural\nnetworks have been proposed for the case when large amounts of parallel text\nare at our disposal. However, in many real-world settings, the size of parallel\nannotated training data is restricted. Additionally, prior cross-lingual\nmapping research has mainly focused on the word level. This raises the question\nof whether such techniques can also be applied to effortlessly obtain\ncross-lingually aligned sentence representations. To this end, we propose an\nAdversarial Bi-directional Sentence Embedding Mapping (ABSent) framework, which\nlearns mappings of cross-lingual sentence representations from limited\nquantities of parallel data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 22:44:05 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Fu", "Zuohui", ""], ["Xian", "Yikun", ""], ["Geng", "Shijie", ""], ["Ge", "Yingqiang", ""], ["Wang", "Yuting", ""], ["Dong", "Xin", ""], ["Wang", "Guang", ""], ["de Melo", "Gerard", ""]]}, {"id": "2001.11128", "submitter": "Kazuya Kawakami", "authors": "Kazuya Kawakami, Luyu Wang, Chris Dyer, Phil Blunsom, Aaron van den\n  Oord", "title": "Learning Robust and Multilingual Speech Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised speech representation learning has shown remarkable success at\nfinding representations that correlate with phonetic structures and improve\ndownstream speech recognition performance. However, most research has been\nfocused on evaluating the representations in terms of their ability to improve\nthe performance of speech recognition systems on read English (e.g. Wall Street\nJournal and LibriSpeech). This evaluation methodology overlooks two important\ndesiderata that speech representations should have: robustness to domain shifts\nand transferability to other languages. In this paper we learn representations\nfrom up to 8000 hours of diverse and noisy speech data and evaluate the\nrepresentations by looking at their robustness to domain shifts and their\nability to improve recognition performance in many languages. We find that our\nrepresentations confer significant robustness advantages to the resulting\nrecognition systems: we see significant improvements in out-of-domain transfer\nrelative to baseline feature sets and the features likewise provide\nimprovements in 25 phonetically diverse languages including tonal languages and\nlow-resource languages.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 23:24:56 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kawakami", "Kazuya", ""], ["Wang", "Luyu", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""], ["Oord", "Aaron van den", ""]]}, {"id": "2001.11136", "submitter": "Ivan Vuli\\'c", "authors": "Haim Dubossarsky, Ivan Vuli\\'c, Roi Reichart, Anna Korhonen", "title": "The Secret is in the Spectra: Predicting Cross-lingual Task Performance\n  with Spectral Similarity Measures", "comments": "EMNLP 2020: Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performance in cross-lingual NLP tasks is impacted by the (dis)similarity of\nlanguages at hand: e.g., previous work has suggested there is a connection\nbetween the expected success of bilingual lexicon induction (BLI) and the\nassumption of (approximate) isomorphism between monolingual embedding spaces.\nIn this work we present a large-scale study focused on the correlations between\nmonolingual embedding space similarity and task performance, covering thousands\nof language pairs and four different tasks: BLI, parsing, POS tagging and MT.\nWe hypothesize that statistics of the spectrum of each monolingual embedding\nspace indicate how well they can be aligned. We then introduce several\nisomorphism measures between two embedding spaces, based on the relevant\nstatistics of their individual spectra. We empirically show that 1) language\nsimilarity scores derived from such spectral isomorphism measures are strongly\nassociated with performance observed in different cross-lingual tasks, and 2)\nour spectral-based measures consistently outperform previous standard\nisomorphism measures, while being computationally more tractable and easier to\ninterpret. Finally, our measures capture complementary information to\ntypologically driven language distance measures, and the combination of\nmeasures from the two families yields even higher task performance\ncorrelations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:09:53 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 15:13:13 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Dubossarsky", "Haim", ""], ["Vuli\u0107", "Ivan", ""], ["Reichart", "Roi", ""], ["Korhonen", "Anna", ""]]}, {"id": "2001.11164", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Samuel Cahyawijaya, Andrea Madotto,\n  Zhaojiang Lin, Pascale Fung", "title": "On the Importance of Word Order Information in Cross-lingual Sequence\n  Labeling", "comments": "Accepted in AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word order variances generally exist in different languages. In this paper,\nwe hypothesize that cross-lingual models that fit into the word order of the\nsource language might fail to handle target languages. To verify this\nhypothesis, we investigate whether making models insensitive to the word order\nof the source language can improve the adaptation performance in target\nlanguages. To do so, we reduce the source language word order information\nfitted to sequence encoders and observe the performance changes. In addition,\nbased on this hypothesis, we propose a new method for fine-tuning multilingual\nBERT in downstream cross-lingual sequence labeling tasks. Experimental results\non dialogue natural language understanding, part-of-speech tagging, and named\nentity recognition tasks show that reducing word order information fitted to\nthe model can achieve better zero-shot cross-lingual performance. Furthermore,\nour proposed methods can also be applied to strong cross-lingual baselines, and\nimprove their performances.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:35:44 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 12:18:32 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 15:31:19 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 11:04:04 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Cahyawijaya", "Samuel", ""], ["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2001.11224", "submitter": "Tuomo Hiippala", "authors": "Tuomo Hiippala and John A. Bateman", "title": "Introducing the diagrammatic mode", "comments": "16 pages; submitted to Diagrams 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a multimodal perspective to diagrammatic\nrepresentations by sketching a description of what may be tentatively termed\nthe diagrammatic mode. We consider diagrammatic representations in the light of\ncontemporary multimodality theory and explicate what enables diagrammatic\nrepresentations to integrate natural language, various forms of graphics,\ndiagrammatic elements such as arrows, lines and other expressive resources into\ncoherent organisations. We illustrate the proposed approach using two recent\ndiagram corpora and show how a multimodal approach supports the empirical\nanalysis of diagrammatic representations, especially in identifying\ndiagrammatic constituents and describing their interrelations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 09:17:32 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Hiippala", "Tuomo", ""], ["Bateman", "John A.", ""]]}, {"id": "2001.11258", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Ashiqur R. KhudaBukhsh, Shriphani Palakodety, Jaime G. Carbonell", "title": "Harnessing Code Switching to Transcend the Linguistic Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code mixing (or code switching) is a common phenomenon observed in\nsocial-media content generated by a linguistically diverse user-base. Studies\nshow that in the Indian sub-continent, a substantial fraction of social media\nposts exhibit code switching. While the difficulties posed by code mixed\ndocuments to further downstream analyses are well-understood, lending\nvisibility to code mixed documents under certain scenarios may have utility\nthat has been previously overlooked. For instance, a document written in a\nmixture of multiple languages can be partially accessible to a wider audience;\nthis could be particularly useful if a considerable fraction of the audience\nlacks fluency in one of the component languages. In this paper, we provide a\nsystematic approach to sample code mixed documents leveraging a polyglot\nembedding based method that requires minimal supervision. In the context of the\n2019 India-Pakistan conflict triggered by the Pulwama terror attack, we\ndemonstrate an untapped potential of harnessing code mixing for human\nwell-being: starting from an existing hostility diffusing \\emph{hope speech}\nclassifier solely trained on English documents, code mixed documents are\nutilized as a bridge to retrieve \\emph{hope speech} content written in a\nlow-resource but widely used language - Romanized Hindi. Our proposed pipeline\nrequires minimal supervision and holds promise in substantially reducing web\nmoderation efforts.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:25:06 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:31:14 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["KhudaBukhsh", "Ashiqur R.", ""], ["Palakodety", "Shriphani", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "2001.11268", "submitter": "Lena Schmidt", "authors": "Lena Schmidt, Julie Weeds, Julian P. T. Higgins", "title": "Data Mining in Clinical Trial Text: Transformers for Classification and\n  Question Answering Tasks", "comments": null, "journal-ref": "HEALTHINF 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research on data extraction methods applies recent advances in natural\nlanguage processing to evidence synthesis based on medical texts. Texts of\ninterest include abstracts of clinical trials in English and in multilingual\ncontexts. The main focus is on information characterized via the Population,\nIntervention, Comparator, and Outcome (PICO) framework, but data extraction is\nnot limited to these fields. Recent neural network architectures based on\ntransformers show capacities for transfer learning and increased performance on\ndownstream natural language processing tasks such as universal reading\ncomprehension, brought forward by this architecture's use of contextualized\nword embeddings and self-attention mechanisms. This paper contributes to\nsolving problems related to ambiguity in PICO sentence prediction tasks, as\nwell as highlighting how annotations for training named entity recognition\nsystems are used to train a high-performing, but nevertheless flexible\narchitecture for question answering in systematic review automation.\nAdditionally, it demonstrates how the problem of insufficient amounts of\ntraining annotations for PICO entity extraction is tackled by augmentation. All\nmodels in this paper were created with the aim to support systematic review\n(semi)automation. They achieve high F1 scores, and demonstrate the feasibility\nof applying transformer-based classification methods to support data mining in\nthe biomedical literature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:45:59 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Schmidt", "Lena", ""], ["Weeds", "Julie", ""], ["Higgins", "Julian P. T.", ""]]}, {"id": "2001.11285", "submitter": "Andrew Krizhanovsky A", "authors": "Elena Klyachko and Alexey Sorokin and Natalia Krizhanovskaya and\n  Andrew Krizhanovsky and Galina Ryazanskaya", "title": "LowResourceEval-2019: a shared task on morphological analysis for\n  low-resource languages", "comments": "16 pages, 4 tables, 2 figures, published in the conference proceeding", "journal-ref": "Dialog 2019, Issue 18, Supplementary volume, Pp. 45-62", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper describes the results of the first shared task on morphological\nanalysis for the languages of Russia, namely, Evenki, Karelian, Selkup, and\nVeps. For the languages in question, only small-sized corpora are available.\nThe tasks include morphological analysis, word form generation and morpheme\nsegmentation. Four teams participated in the shared task. Most of them use\nmachine-learning approaches, outperforming the existing rule-based ones. The\narticle describes the datasets prepared for the shared tasks and contains\nanalysis of the participants' solutions. Language corpora having different\nformats were transformed into CONLL-U format. The universal format makes the\ndatasets comparable to other language corpura and facilitates using them in\nother NLP tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:47:50 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Klyachko", "Elena", ""], ["Sorokin", "Alexey", ""], ["Krizhanovskaya", "Natalia", ""], ["Krizhanovsky", "Andrew", ""], ["Ryazanskaya", "Galina", ""]]}, {"id": "2001.11314", "submitter": "Yu-Kun Li", "authors": "Dongling Xiao, Han Zhang, Yukun Li, Yu Sun, Hao Tian, Hua Wu and\n  Haifeng Wang", "title": "ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework\n  for Natural Language Generation", "comments": "The source codes and pre-trained models have been released at\n  https://github.com/PaddlePaddle/ERNIE. We have also updated the performances\n  of ERNIE-GEN under a larger scaled pre-training corpora in appendix A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current pre-training works in natural language generation pay little\nattention to the problem of exposure bias on downstream tasks. To address this\nissue, we propose an enhanced multi-flow sequence to sequence pre-training and\nfine-tuning framework named ERNIE-GEN, which bridges the discrepancy between\ntraining and inference with an infilling generation mechanism and a noise-aware\ngeneration method. To make generation closer to human writing patterns, this\nframework introduces a span-by-span generation flow that trains the model to\npredict semantically-complete spans consecutively rather than predicting word\nby word. Unlike existing pre-training methods, ERNIE-GEN incorporates\nmulti-granularity target sampling to construct pre-training data, which\nenhances the correlation between encoder and decoder. Experimental results\ndemonstrate that ERNIE-GEN achieves state-of-the-art results with a much\nsmaller amount of pre-training data and parameters on a range of language\ngeneration tasks, including abstractive summarization (Gigaword and\nCNN/DailyMail), question generation (SQuAD), dialogue generation (Persona-Chat)\nand generative question answering (CoQA).\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:54:49 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 06:48:44 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 08:09:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Xiao", "Dongling", ""], ["Zhang", "Han", ""], ["Li", "Yukun", ""], ["Sun", "Yu", ""], ["Tian", "Hao", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "2001.11316", "submitter": "Akbar Karimi", "authors": "Akbar Karimi, Leonardo Rossi, Andrea Prati", "title": "Adversarial Training for Aspect-Based Sentiment Analysis with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of\nsentiments and their targets. Collecting labeled data for this task in order to\nhelp neural networks generalize better can be laborious and time-consuming. As\nan alternative, similar data to the real-world examples can be produced\nartificially through an adversarial process which is carried out in the\nembedding space. Although these examples are not real sentences, they have been\nshown to act as a regularization method which can make neural networks more\nrobust. In this work, we apply adversarial training, which was put forward by\nGoodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model\nproposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and\nAspect Sentiment Classification in sentiment analysis. After improving the\nresults of post-trained BERT by an ablation study, we propose a novel\narchitecture called BERT Adversarial Training (BAT) to utilize adversarial\ntraining in ABSA. The proposed model outperforms post-trained BERT in both\ntasks. To the best of our knowledge, this is the first study on the application\nof adversarial training in ABSA.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:53:58 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 12:33:57 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:39:32 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 07:39:17 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Karimi", "Akbar", ""], ["Rossi", "Leonardo", ""], ["Prati", "Andrea", ""]]}, {"id": "2001.11327", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin, Bashir Shehu Galadanci, Abubakar Isa", "title": "Iterative Batch Back-Translation for Neural Machine Translation: A\n  Conceptual Model", "comments": "This article was a proposal, a conceptual model and, thereby,\n  substantially overlapping with arXiv:1912.10514. This research has been\n  substantially reworked. Some of the findings are presented in\n  arXiv:1912.10514, arXiv:2006.02876 and arXiv:2011.07403. The final work will\n  be submitted for publishing in due course", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective method to generate a large number of parallel sentences for\ntraining improved neural machine translation (NMT) systems is the use of\nback-translations of the target-side monolingual data. Recently, iterative\nback-translation has been shown to outperform standard back-translation albeit\non some language pairs. This work proposes the iterative batch back-translation\nthat is aimed at enhancing the standard iterative back-translation and enabling\nthe efficient utilization of more monolingual data. After each iteration,\nimproved back-translations of new sentences are added to the parallel data that\nwill be used to train the final forward model. The work presents a conceptual\nmodel of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:59:41 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 18:41:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""], ["Isa", "Abubakar", ""]]}, {"id": "2001.11381", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Luis-Gil Moreno-Jim\\'enez, Juan-Manuel Torres-Moreno, Roseli S.\n  Wedemann", "title": "Generaci\\'on autom\\'atica de frases literarias en espa\\~nol", "comments": "13 pages, in Spanish, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a state of the art in the area of Computational\nCreativity (CC). In particular, we address the automatic generation of literary\nsentences in Spanish. We propose three models of text generation based mainly\non statistical algorithms and shallow parsing analysis. We also present some\nrather encouraging preliminary results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:42:14 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Moreno-Jim\u00e9nez", "Luis-Gil", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["Wedemann", "Roseli S.", ""]]}, {"id": "2001.11382", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Jean Val\\`ere Cossu, Juan-Manuel Torres-Moreno, Eric SanJuan, Marc\n  El-B\\`eze", "title": "Intweetive Text Summarization", "comments": "8 pages, 4 tables", "journal-ref": "International Journal of Computational Linguistics and\n  Applications vol. 7, no. 1, 2016, pp. 67-83", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of user generated contents from various social medias allows\nanalyst to handle a wide view of conversations on several topics related to\ntheir business. Nevertheless keeping up-to-date with this amount of information\nis not humanly feasible. Automatic Summarization then provides an interesting\nmean to digest the dynamics and the mass volume of contents. In this paper, we\naddress the issue of tweets summarization which remains scarcely explored. We\npropose to automatically generated summaries of Micro-Blogs conversations\ndealing with public figures E-Reputation. These summaries are generated using\nkey-word queries or sample tweet and offer a focused view of the whole\nMicro-Blog network. Since state-of-the-art is lacking on this point we conduct\nand evaluate our experiments over the multilingual CLEF RepLab Topic-Detection\ndataset according to an experimental evaluation process.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:38:40 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Cossu", "Jean Val\u00e8re", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["SanJuan", "Eric", ""], ["El-B\u00e8ze", "Marc", ""]]}, {"id": "2001.11383", "submitter": "Yinuo Guo", "authors": "Yinuo Guo, Tao Ge, Furu Wei", "title": "Fact-aware Sentence Split and Rephrase with Permutation Invariant\n  Training", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence Split and Rephrase aims to break down a complex sentence into\nseveral simple sentences with its meaning preserved. Previous studies tend to\naddress the issue by seq2seq learning from parallel sentence pairs, which takes\na complex sentence as input and sequentially generates a series of simple\nsentences. However, the conventional seq2seq learning has two limitations for\nthis task: (1) it does not take into account the facts stated in the long\nsentence; As a result, the generated simple sentences may miss or inaccurately\nstate the facts in the original sentence. (2) The order variance of the simple\nsentences to be generated may confuse the seq2seq model during training because\nthe simple sentences derived from the long source sentence could be in any\norder.\n  To overcome the challenges, we first propose the Fact-aware Sentence\nEncoding, which enables the model to learn facts from the long sentence and\nthus improves the precision of sentence split; then we introduce Permutation\nInvariant Training to alleviate the effects of order variance in seq2seq\nlearning for this task. Experiments on the WebSplit-v1.0 benchmark dataset show\nthat our approaches can largely improve the performance over the previous\nseq2seq learning approaches. Moreover, an extrinsic evaluation on oie-benchmark\nverifies the effectiveness of our approaches by an observation that splitting\nlong sentences with our state-of-the-art model as preprocessing is helpful for\nimproving OpenIE performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 07:30:19 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 01:52:51 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Guo", "Yinuo", ""], ["Ge", "Tao", ""], ["Wei", "Furu", ""]]}, {"id": "2001.11384", "submitter": "Siddharth Yadav", "authors": "Siddharth Yadav, Tanmoy Chakraborty", "title": "Unsupervised Sentiment Analysis for Code-mixed Data", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence 2021\n  vol. 35, no. 18, pp. 15941-15942,", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-mixing is the practice of alternating between two or more languages.\nMostly observed in multilingual societies, its occurrence is increasing and\ntherefore its importance. A major part of sentiment analysis research has been\nmonolingual, and most of them perform poorly on code-mixed text. In this work,\nwe introduce methods that use different kinds of multilingual and cross-lingual\nembeddings to efficiently transfer knowledge from monolingual text to\ncode-mixed text for sentiment analysis of code-mixed text. Our methods can\nhandle code-mixed text through a zero-shot learning. Our methods beat\nstate-of-the-art on English-Spanish code-mixed sentiment analysis by absolute\n3\\% F1-score. We are able to achieve 0.58 F1-score (without parallel corpus)\nand 0.62 F1-score (with parallel corpus) on the same benchmark in a zero-shot\nway as compared to 0.68 F1-score in supervised settings. Our code is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 06:12:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Yadav", "Siddharth", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2001.11453", "submitter": "Edoardo Maria Ponti", "authors": "Edoardo M. Ponti, Ivan Vuli\\'c, Ryan Cotterell, Marinela Parovic, Roi\n  Reichart and Anna Korhonen", "title": "Parameter Space Factorization for Zero-Shot Learning across Tasks and\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most combinations of NLP tasks and language varieties lack in-domain examples\nfor supervised training because of the paucity of annotated data. How can\nneural models make sample-efficient generalizations from task-language\ncombinations with available data to low-resource ones? In this work, we propose\na Bayesian generative model for the space of neural parameters. We assume that\nthis space can be factorized into latent variables for each language and each\ntask. We infer the posteriors over such latent variables based on data from\nseen task-language combinations through variational inference. This enables\nzero-shot classification on unseen combinations at prediction time. For\ninstance, given training data for named entity recognition (NER) in Vietnamese\nand for part-of-speech (POS) tagging in Wolof, our model can perform accurate\npredictions for NER in Wolof. In particular, we experiment with a typologically\ndiverse sample of 33 languages from 4 continents and 11 families, and show that\nour model yields comparable or better results than state-of-the-art, zero-shot\ncross-lingual transfer methods. Moreover, we demonstrate that approximate\nBayesian model averaging results in smoother predictive distributions, whose\nentropy inversely correlates with accuracy. Hence, the proposed framework also\noffers robust estimates of prediction uncertainty. Our code is located at\ngithub.com/cambridgeltl/parameter-factorization\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 16:58:56 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 23:30:01 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 19:06:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ponti", "Edoardo M.", ""], ["Vuli\u0107", "Ivan", ""], ["Cotterell", "Ryan", ""], ["Parovic", "Marinela", ""], ["Reichart", "Roi", ""], ["Korhonen", "Anna", ""]]}, {"id": "2001.11458", "submitter": "Subendhu Rongali", "authors": "Subendhu Rongali (University of Massachusetts Amherst), Luca Soldaini\n  (Amazon Alexa Search), Emilio Monti (Amazon Alexa), Wael Hamza (Amazon Alexa\n  AI)", "title": "Don't Parse, Generate! A Sequence to Sequence Architecture for\n  Task-Oriented Semantic Parsing", "comments": "To be published in The Web Conference (WWW 2020)", "journal-ref": null, "doi": "10.1145/3366423.3380064", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Virtual assistants such as Amazon Alexa, Apple Siri, and Google Assistant\noften rely on a semantic parsing component to understand which action(s) to\nexecute for an utterance spoken by its users. Traditionally, rule-based or\nstatistical slot-filling systems have been used to parse \"simple\" queries; that\nis, queries that contain a single action and can be decomposed into a set of\nnon-overlapping entities. More recently, shift-reduce parsers have been\nproposed to process more complex utterances. These methods, while powerful,\nimpose specific limitations on the type of queries that can be parsed; namely,\nthey require a query to be representable as a parse tree.\n  In this work, we propose a unified architecture based on Sequence to Sequence\nmodels and Pointer Generator Network to handle both simple and complex queries.\nUnlike other works, our approach does not impose any restriction on the\nsemantic parse schema. Furthermore, experiments show that it achieves state of\nthe art performance on three publicly available datasets (ATIS, SNIPS, Facebook\nTOP), relatively improving between 3.3% and 7.7% in exact match accuracy over\nprevious systems. Finally, we show the effectiveness of our approach on two\ninternal datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:11:00 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rongali", "Subendhu", "", "University of Massachusetts Amherst"], ["Soldaini", "Luca", "", "Amazon Alexa Search"], ["Monti", "Emilio", "", "Amazon Alexa"], ["Hamza", "Wael", "", "Amazon Alexa\n  AI"]]}, {"id": "2001.11479", "submitter": "Andrea Fronzetti Colladon PhD", "authors": "A. Fronzetti Colladon and F. Grippa", "title": "Brand Intelligence Analytics", "comments": null, "journal-ref": "In A. Przegalinska, F. Grippa, & P. A. Gloor (Eds.), Digital\n  Transformation of Collaboration (pp. 125-141). Springer Nature Switzerland\n  (2020)", "doi": "10.1007/978-3-030-48993-9_10", "report-no": null, "categories": "cs.SE cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leveraging the power of big data represents an opportunity for brand managers\nto reveal patterns and trends in consumer perceptions, while monitoring\npositive or negative associations of the brand with desired topics. This\nchapter describes the functionalities of the SBS Brand Intelligence App (SBS\nBI), which has been designed to assess brand importance and provides brand\nanalytics through the analysis of (big) textual data. To better describe the\nSBS BI's functionalities, we present a case study focused on the 2020 US\nDemocratic Presidential Primaries. We downloaded 50,000 online articles from\nthe Event Registry database, which contains both mainstream and blog news\ncollected from around the world. These online news articles were transformed\ninto networks of co-occurring words and analyzed by combining methods and tools\nfrom social network analysis and text mining.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:57:56 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 11:05:37 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Colladon", "A. Fronzetti", ""], ["Grippa", "F.", ""]]}, {"id": "2001.11552", "submitter": "Amir Karami", "authors": "Amir Karami, Cynthia Nicole White, Kayla Ford, Suzanne Swan, Melek\n  Yildiz Spinel", "title": "Unwanted Advances in Higher Education: Uncovering Sexual Harassment\n  Experiences in Academia with Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexual harassment in academia is often a hidden problem because victims are\nusually reluctant to report their experiences. Recently, a web survey was\ndeveloped to provide an opportunity to share thousands of sexual harassment\nexperiences in academia. Using an efficient approach, this study collected and\ninvestigated more than 2,000 sexual harassment experiences to better understand\nthese unwanted advances in higher education. This paper utilized text mining to\ndisclose hidden topics and explore their weight across three variables:\nharasser gender, institution type, and victim's field of study. We mapped the\ntopics on five themes drawn from the sexual harassment literature and found\nthat more than 50% of the topics were assigned to the unwanted sexual attention\ntheme. Fourteen percent of the topics were in the gender harassment theme, in\nwhich insulting, sexist, or degrading comments or behavior was directed towards\nwomen. Five percent of the topics involved sexual coercion (a benefit is\noffered in exchange for sexual favors), 5% involved sex discrimination, and 7%\nof the topics discussed retaliation against the victim for reporting the\nharassment, or for simply not complying with the harasser. Findings highlight\nthe power differential between faculty and students, and the toll on students\nwhen professors abuse their power. While some topics did differ based on type\nof institution, there were no differences between the topics based on gender of\nharasser or field of study. This research can be beneficial to researchers in\nfurther investigation of this paper's dataset, and to policymakers in improving\nexisting policies to create a safe and supportive environment in academia.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:37:45 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Karami", "Amir", ""], ["White", "Cynthia Nicole", ""], ["Ford", "Kayla", ""], ["Swan", "Suzanne", ""], ["Spinel", "Melek Yildiz", ""]]}, {"id": "2001.11631", "submitter": "Md Rashadul Hasan Rakib", "authors": "Md Rashadul Hasan Rakib, Norbert Zeh, Magdalena Jankowska, Evangelos\n  Milios", "title": "Enhancement of Short Text Clustering by Iterative Classification", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text clustering is a challenging task due to the lack of signal\ncontained in such short texts. In this work, we propose iterative\nclassification as a method to b o ost the clustering quality (e.g., accuracy)\nof short texts. Given a clustering of short texts obtained using an arbitrary\nclustering algorithm, iterative classification applies outlier removal to\nobtain outlier-free clusters. Then it trains a classification algorithm using\nthe non-outliers based on their cluster distributions. Using the trained\nclassification model, iterative classification reclassifies the outliers to\nobtain a new set of clusters. By repeating this several times, we obtain a much\nimproved clustering of texts. Our experimental results show that the proposed\nclustering enhancement method not only improves the clustering quality of\ndifferent clustering methods (e.g., k-means, k-means--, and hierarchical\nclustering) but also outperforms the state-of-the-art short text clustering\nmethods on several short text datasets by a statistically significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 02:12:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Rakib", "Md Rashadul Hasan", ""], ["Zeh", "Norbert", ""], ["Jankowska", "Magdalena", ""], ["Milios", "Evangelos", ""]]}, {"id": "2001.11673", "submitter": "Mehrdad Alizadeh", "authors": "Mehrdad Alizadeh, Barbara Di Eugenio", "title": "Augmenting Visual Question Answering with Semantic Frame Information in\n  a Multitask Learning Approach", "comments": "14th IEEE International Conference on SEMANTIC COMPUTING, 8 Pages,\n  February 2020, San Diego CA USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual Question Answering (VQA) concerns providing answers to Natural\nLanguage questions about images. Several deep neural network approaches have\nbeen proposed to model the task in an end-to-end fashion. Whereas the task is\ngrounded in visual processing, if the question focuses on events described by\nverbs, the language understanding component becomes crucial. Our hypothesis is\nthat models should be aware of verb semantics, as expressed via semantic role\nlabels, argument types, and/or frame elements. Unfortunately, no VQA dataset\nexists that includes verb semantic information. Our first contribution is a new\nVQA dataset (imSituVQA) that we built by taking advantage of the imSitu\nannotations. The imSitu dataset consists of images manually labeled with\nsemantic frame elements, mostly taken from FrameNet. Second, we propose a\nmultitask CNN-LSTM VQA model that learns to classify the answers as well as the\nsemantic frame elements. Our experiments show that semantic frame element\nclassification helps the VQA system avoid inconsistent responses and improves\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 06:31:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Alizadeh", "Mehrdad", ""], ["Di Eugenio", "Barbara", ""]]}, {"id": "2001.11691", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, Ming Zhou", "title": "Self-Adversarial Learning with Comparative Discrimination for Text\n  Generation", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Generative Adversarial Networks (GANs) for text generation tend\nto have issues of reward sparsity and mode collapse that affect the quality and\ndiversity of generated samples. To address the issues, we propose a novel\nself-adversarial learning (SAL) paradigm for improving GANs' performance in\ntext generation. In contrast to standard GANs that use a binary classifier as\nits discriminator to predict whether a sample is real or generated, SAL employs\na comparative discriminator which is a pairwise classifier for comparing the\ntext quality between a pair of samples. During training, SAL rewards the\ngenerator when its currently generated sentence is found to be better than its\npreviously generated samples. This self-improvement reward mechanism allows the\nmodel to receive credits more easily and avoid collapsing towards the limited\nnumber of real samples, which not only helps alleviate the reward sparsity\nissue but also reduces the risk of mode collapse. Experiments on text\ngeneration benchmark datasets show that our proposed approach substantially\nimproves both the quality and the diversity, and yields more stable performance\ncompared to the previous GANs for text generation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:50:25 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:18:24 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Xu", "Ke", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "2001.11694", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou, Tao Ge, Ke Xu", "title": "Pseudo-Bidirectional Decoding for Local Sequence Transduction", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local sequence transduction (LST) tasks are sequence transduction tasks where\nthere exists massive overlapping between the source and target sequences, such\nas Grammatical Error Correction (GEC) and spell or OCR correction. Previous\nwork generally tackles LST tasks with standard sequence-to-sequence (seq2seq)\nmodels that generate output tokens from left to right and suffer from the issue\nof unbalanced outputs. Motivated by the characteristic of LST tasks, in this\npaper, we propose a simple but versatile approach named Pseudo-Bidirectional\nDecoding (PBD) for LST tasks. PBD copies the corresponding representation of\nsource tokens to the decoder as pseudo future context to enable the decoder to\nattends to its bi-directional context. In addition, the bidirectional decoding\nscheme and the characteristic of LST tasks motivate us to share the encoder and\nthe decoder of seq2seq models. The proposed PBD approach provides right side\ncontext information for the decoder and models the inductive bias of LST tasks,\nreducing the number of parameters by half and providing good regularization\neffects. Experimental results on several benchmark datasets show that our\napproach consistently improves the performance of standard seq2seq models on\nLST tasks.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:55:39 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 14:28:41 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 16:01:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Xu", "Ke", ""]]}, {"id": "2001.11701", "submitter": "Jiwei Li", "authors": "Jiwei Li", "title": "Teaching Machines to Converse", "comments": "phd thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of a machine to communicate with humans has long been associated\nwith the general success of AI. This dates back to Alan Turing's epoch-making\nwork in the early 1950s, which proposes that a machine's intelligence can be\ntested by how well it, the machine, can fool a human into believing that the\nmachine is a human through dialogue conversations. Many systems learn\ngeneration rules from a minimal set of authored rules or labels on top of\nhand-coded rules or templates, and thus are both expensive and difficult to\nextend to open-domain scenarios. Recently, the emergence of neural network\nmodels the potential to solve many of the problems in dialogue learning that\nearlier systems cannot tackle: the end-to-end neural frameworks offer the\npromise of scalability and language-independence, together with the ability to\ntrack the dialogue state and then mapping between states and dialogue actions\nin a way not possible with conventional systems. On the other hand, neural\nsystems bring about new challenges: they tend to output dull and generic\nresponses; they lack a consistent or a coherent persona; they are usually\noptimized through single-turn conversations and are incapable of handling the\nlong-term success of a conversation; and they are not able to take the\nadvantage of the interactions with humans. This dissertation attempts to tackle\nthese challenges: Contributions are two-fold: (1) we address new challenges\npresented by neural network models in open-domain dialogue generation systems;\n(2) we develop interactive question-answering dialogue systems by (a) giving\nthe agent the ability to ask questions and (b) training a conversation agent\nthrough interactions with humans in an online fashion, where a bot improves\nthrough communicating with humans and learning from the mistakes that it makes.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:28:07 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Li", "Jiwei", ""]]}, {"id": "2001.11770", "submitter": "Tomer Wolfson", "authors": "Tomer Wolfson, Mor Geva, Ankit Gupta, Matt Gardner, Yoav Goldberg,\n  Daniel Deutch, Jonathan Berant", "title": "Break It Down: A Question Understanding Benchmark", "comments": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2020. Author's final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding natural language questions entails the ability to break down a\nquestion into the requisite steps for computing its answer. In this work, we\nintroduce a Question Decomposition Meaning Representation (QDMR) for questions.\nQDMR constitutes the ordered list of steps, expressed through natural language,\nthat are necessary for answering a question. We develop a crowdsourcing\npipeline, showing that quality QDMRs can be annotated at scale, and release the\nBreak dataset, containing over 83K pairs of questions and their QDMRs. We\ndemonstrate the utility of QDMR by showing that (a) it can be used to improve\nopen-domain question answering on the HotpotQA dataset, (b) it can be\ndeterministically converted to a pseudo-SQL formal language, which can\nalleviate annotation in semantic parsing applications. Last, we use Break to\ntrain a sequence-to-sequence model with copying that parses questions into QDMR\nstructures, and show that it substantially outperforms several natural\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:04:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Wolfson", "Tomer", ""], ["Geva", "Mor", ""], ["Gupta", "Ankit", ""], ["Gardner", "Matt", ""], ["Goldberg", "Yoav", ""], ["Deutch", "Daniel", ""], ["Berant", "Jonathan", ""]]}, {"id": "2001.11857", "submitter": "Maria Mihaela Trusca", "authors": "Maria Mihaela Trusca and Gerasimos Spanakis", "title": "Hybrid Tiled Convolutional Neural Networks for Text Sentiment\n  Classification", "comments": "8 pages, 2 figures, accepted for publication in the 12th\n  International Conference on Agents and Artificial Intelligence (ICAART 2020),\n  Malta, 22-24 February 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tiled convolutional neural network (tiled CNN) has been applied only to\ncomputer vision for learning invariances. We adjust its architecture to NLP to\nimprove the extraction of the most salient features for sentiment analysis.\nKnowing that the major drawback of the tiled CNN in the NLP field is its\ninflexible filter structure, we propose a novel architecture called hybrid\ntiled CNN that applies a filter only on the words that appear in the similar\ncontexts and on their neighbor words (a necessary step for preventing the loss\nof some n-grams). The experiments on the datasets of IMDB movie reviews and\nSemEval 2017 demonstrate the efficiency of the hybrid tiled CNN that performs\nbetter than both CNN and tiled CNN.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 14:08:15 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Trusca", "Maria Mihaela", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "2001.11899", "submitter": "David Gilbert", "authors": "Gabija Mikulyte and David Gilbert", "title": "An efficient automated data analytics approach to large scale\n  computational comparative linguistics", "comments": "50 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research project aimed to overcome the challenge of analysing human\nlanguage relationships, facilitate the grouping of languages and formation of\ngenealogical relationship between them by developing automated comparison\ntechniques. Techniques were based on the phonetic representation of certain key\nwords and concept. Example word sets included numbers 1-10 (curated), large\ndatabase of numbers 1-10 and sheep counting numbers 1-10 (other sources),\ncolours (curated), basic words (curated).\n  To enable comparison within the sets the measure of Edit distance was\ncalculated based on Levenshtein distance metric. This metric between two\nstrings is the minimum number of single-character edits, operations including:\ninsertions, deletions or substitutions. To explore which words exhibit more or\nless variation, which words are more preserved and examine how languages could\nbe grouped based on linguistic distances within sets, several data analytics\ntechniques were involved. Those included density evaluation, hierarchical\nclustering, silhouette, mean, standard deviation and Bhattacharya coefficient\ncalculations. These techniques lead to the development of a workflow which was\nlater implemented by combining Unix shell scripts, a developed R package and\nSWI Prolog. This proved to be computationally efficient and permitted the fast\nexploration of large language sets and their analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:25:56 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Mikulyte", "Gabija", ""], ["Gilbert", "David", ""]]}, {"id": "2001.11985", "submitter": "Denis Lukovnikov", "authors": "D. Lukovnikov, A. Fischer, J. Lehmann", "title": "Pretrained Transformers for Simple Question Answering over Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering simple questions over knowledge graphs is a well-studied problem in\nquestion answering. Previous approaches for this task built on recurrent and\nconvolutional neural network based architectures that use pretrained word\nembeddings. It was recently shown that finetuning pretrained transformer\nnetworks (e.g. BERT) can outperform previous approaches on various natural\nlanguage processing tasks. In this work, we investigate how well BERT performs\non SimpleQuestions and provide an evaluation of both BERT and BiLSTM-based\nmodels in datasparse scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:14:17 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lukovnikov", "D.", ""], ["Fischer", "A.", ""], ["Lehmann", "J.", ""]]}]